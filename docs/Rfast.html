<!DOCTYPE html><html><head><title>Help for package Rfast</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Rfast}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='# Check if any column or row is fill with values '>
<p>Check if any column or row is fill with values</p></a></li>
<li><a href='# Deep copy '>
<p>Deep copy</p></a></li>
<li><a href='# Design Matrix '>
<p>Design Matrix</p></a></li>
<li><a href='# Insert/remove function names in/from the NAMESPACE file '>
<p>Insert/remove function names in/from the NAMESPACE file</p></a></li>
<li><a href='# Lower and Upper triangular of a matrix '>
<p>Lower and Upper triangular of a matrix</p></a></li>
<li><a href='# Match '>
<p>Match</p></a></li>
<li><a href='# Permutation '>
<p>Permutation</p></a></li>
<li><a href='# Replicate columns/rows '>
<p>Replicate columns/rows</p></a></li>
<li><a href='# Represantation of Stack '>
<p>Represantation of Stack</p></a></li>
<li><a href='# Sort and unique numbers '>
<p>Sort and unique</p></a></li>
<li><a href='#All k possible combinations from n elements'>
<p>All k possible combinations from n elements</p></a></li>
<li><a href='#Analysis of covariance'>
<p>Analysis of covariance</p></a></li>
<li><a href='#Analysis of variance with a count variable'>
<p>Analysis of variance with a count variable</p></a></li>
<li><a href='#Angular central Gaussian random values simulation'>
<p>Angular central Gaussian random values simulation</p></a></li>
<li><a href='#ANOVA for two quasi Poisson regression models'>
<p>ANOVA for two quasi Poisson regression models</p></a></li>
<li><a href='#Apply method to Positive and Negative number'>
<p>Apply method to Positive and Negative number</p></a></li>
<li><a href='#Apply to each column a method under condition'>
<p>Apply to each column a method under condition</p></a></li>
<li><a href='#Backward selection regression'>
<p>Backward selection regression</p></a></li>
<li><a href='#BIC (using partial correlation) forward regression'>
<p>BIC (using partial correlation) forward regression</p></a></li>
<li><a href='#BIC forward regression with generalised linear models'>
<p>BIC forward regression with generalised linear models</p></a></li>
<li><a href='#Binary search algorithm'>
<p>Binary search algorithm</p></a></li>
<li><a href='#Binomial coefficient and its logarithm'>
<p>Binomial coefficient and its logarithm</p></a></li>
<li><a href='#Bootstrap t-test for 2 independent samples'>
<p>Bootstrap t-test for 2 independent samples</p></a></li>
<li><a href='#Check if values are integers and convert to integer'>
<p>Check if values are integers and convert to integer</p></a></li>
<li><a href='#Check Namespace and Rd files'>
<p>Check Namespace and Rd files</p></a></li>
<li><a href='#Check whether a square matrix is symmetric'>
<p>Check whether a square matrix is symmetric</p></a></li>
<li><a href='#Chi-square and G-square tests of (unconditional) indepdence'>
<p>Chi-square and G-square tests of (unconditional) indepdence</p></a></li>
<li><a href='#Cholesky decomposition of a square matrix'>
<p>Cholesky decomposition of a square matrix</p></a></li>
<li><a href='#Circular or angular regression'>
<p>Circular or angular regression</p></a></li>
<li><a href='#Circular-linear correlation'>
<p>Circular-linear correlation</p></a></li>
<li><a href='#Coefficient matrices'>
<p>Coefficient matrices.</p></a></li>
<li><a href='#Colum-wise cumulative operations (sum, prod, min, max)'>
<p>Colum-wise cumulative operations (sum, prod, min, max)</p></a></li>
<li><a href='#Column and row wise coefficients of variation'>
<p>Column and row wise coefficients of variation</p></a></li>
<li><a href='#Column and row-wise Any/All'>
<p>Column and row-wise Any</p></a></li>
<li><a href='#Column and row-wise means of a matrix'>
<p>Column and row-wise means of a matrix</p></a></li>
<li><a href='#Column and row-wise medians of a matrix or median of a vector.'>
<p>Column and row-wise medians of a matrix or median of a vector.</p></a></li>
<li><a href='#Column and row-wise nth smallest value of a matrix/vector'>
<p>Column and row-wise nth smallest value of a matrix/vector</p></a></li>
<li><a href='#Column and row-wise Order - Sort Indices'>
<p>Column and row-wise Order - Sort Indices</p></a></li>
<li><a href='#Column and row-wise products'>
<p>Column and row-wise products</p></a></li>
<li><a href='#Column and row-wise range of values of a matrix'>
<p>Column and row-wise range of values of a matrix.</p></a></li>
<li><a href='#Column and row-wise ranks'>
<p>Column and row-wise ranks</p></a></li>
<li><a href='#Column and row-wise Shuffle'>
<p>Column and row-wise Shuffle</p></a></li>
<li><a href='#Column and row-wise sums of a matrix'>
<p>Column and row-wise sums of a matrix</p></a></li>
<li><a href='#Column and row-wise tabulate'>
<p>Column and row-wise tabulate</p></a></li>
<li><a href='#Column and row-wise variances and standard deviations'>
<p>Column and row-wise variances and standard deviations of a matrix</p></a></li>
<li><a href='#Column and rows-wise mean absolute deviations'>
<p>Column and row-wise mean absolute deviations</p></a></li>
<li><a href='#Column-wise differences'>
<p>Column-wise differences</p></a></li>
<li><a href='#Column-wise kurtosis and skewness coefficients'>
<p>Column-wise kurtosis and skewness coefficients</p></a></li>
<li><a href='#Column-wise matching coefficients'>
<p>Column-wise matching coefficients</p></a></li>
<li><a href='#Column-wise minimum and maximum '>
<p>Column-wise minimum and maximum of a matrix</p></a></li>
<li><a href='#Column-wise MLE of some univariate distributions'>
<p>Column-wise MLE of some univariate distributions</p></a></li>
<li><a href='#Column-wise true/false value '>
<p>Column-wise true/false value of a matrix</p></a></li>
<li><a href='#Column-wise uniformity Watson test for circular data'>
<p>Column-wise uniformity tests for circular data</p></a></li>
<li><a href='#Column-wise Yule's Y (coefficient of colligation)'>
<p>Column-wise Yule's Y (coefficient of colligation)</p></a></li>
<li><a href='#Convert a dataframe to matrix'>
<p>Convert a dataframe to matrix</p></a></li>
<li><a href='#Convert R function to the Rfast's coresponding'>
<p>Convert R function to the Rfast's coresponding</p></a></li>
<li><a href='#Correlation based forward regression'>
<p>Correlation based forward regression.</p></a></li>
<li><a href='#Correlation between pairs of variables'>
<p>Correlation between pairs of variables</p></a></li>
<li><a href='#Correlations'>
<p>Correlation between a vector and a set of variables</p></a></li>
<li><a href='#Covariance and correlation matrix'>
<p>Fast covariance and correlation matrix calculation</p></a></li>
<li><a href='#Cox confidence interval for the ratio of two Poisson variables'>
<p>Cox confidence interval for the ratio of two Poisson variables</p></a></li>
<li><a href='#Cross-Validation for the k-NN algorithm'>
<p>Cross-Validation for the k-NN algorithm</p></a></li>
<li><a href='#Cross-Validation for the k-NN algorithm using the arc cosinus distance'>
<p>Cross-Validation for the k-NN algorithm using the arc cosinus distance</p></a></li>
<li><a href='#Density of the multivariate normal and t distributions'>
<p>Density of the multivariate normal and t distributions</p></a></li>
<li><a href='#Diagonal Matrix'>
<p>Diagonal Matrix</p></a></li>
<li><a href='#Distance between vectors and a matrix - Sum of all pairwise distances in a distance matrix.'><p>Distance between vectors and a matrix - Sum of all pairwise distances in a distance matrix.</p></a></li>
<li><a href='#Distance correlation'>
<p>Distance correlation</p></a></li>
<li><a href='#Distance matrix - Sum of all pairwise distances in a distance matrix'>
<p>Distance matrix - Sum of all pairwise distances in a distance matrix</p></a></li>
<li><a href='#Distance variance and covariance'>
<p>Distance variance and covariance</p></a></li>
<li><a href='#Eigenvalues and eigenvectors in high dimensional principal component analysis'>
<p>Eigenvalues in high dimensional principal component analysis</p></a></li>
<li><a href='#Empirical and exponential empirical likelihood tests for one sample'>
<p>Empirical and exponential empirical likelihood tests for one sample</p></a></li>
<li><a href='#Empirical and exponential empirical likelihood tests for two samples'>
<p>Empirical and exponential empirical likelihood tests for two samples</p></a></li>
<li><a href='#Energy distance between matrices'>
<p>Energy distance between matrices</p></a></li>
<li><a href='#Equality of objects'><p>Equality of objects</p></a></li>
<li><a href='#Estimation of an AR(1) model'>
<p>Estimation of an AR(1) model</p></a></li>
<li><a href='#Estimation of the Box-Cox transformation'>
<p>Estimation of the Box-Cox transformation</p></a></li>
<li><a href='#Exact t-test for 2 independent samples'>
<p>Exact t-test for 2 independent samples</p></a></li>
<li><a href='#Exponential empirical likelihood for a one sample mean vector hypothesis testing'>
<p>Exponential empirical likelihood for a one sample mean vector hypothesis testing</p></a></li>
<li><a href='#Exponential empirical likelihood hypothesis testing for two mean vectors'>
<p>Exponential empirical likelihood hypothesis testing for two mean vectors</p></a></li>
<li><a href='#Fast and general - untyped represantation of a factor variable'>
<p>Fast and general represantation of a factor variable</p></a></li>
<li><a href='#FBED variable selection method using the correlation'>
<p>FBED variable selection method using the correlation</p></a></li>
<li><a href='#Find element'>
<p>Find element</p></a></li>
<li><a href='#Find the given value in a hash table'>
<p>Find the given value in a hash table</p></a></li>
<li><a href='#Fitted probabilities of the Terry-Bradley model'>
<p>Fitted probabilities of the Terry-Bradley model</p></a></li>
<li><a href='#Fitting a Dirichlet distribution via Newton-Rapshon'>
<p>Fitting a Dirichlet distribution via Newton-Rapshon</p></a></li>
<li><a href='#Floyd-Warshall algorithm'>
<p>Floyd-Warshall algorithm for shortest paths in a directed graph</p></a></li>
<li><a href='#Forward selection with generalised linear regression models'>
<p>Variable selection in generalised linear regression models with forward selection</p></a></li>
<li><a href='#G-square and Chi-square test of conditional indepdence'>
<p>G-square test of conditional indepdence</p></a></li>
<li><a href='#Gamma regression with a log-link'>
<p>Gamma regression with a log-link</p></a></li>
<li><a href='#Gaussian regression with a log-link'>
<p>Gaussian regression with a log-link</p></a></li>
<li><a href='#Generates random values from a normal and puts them in a matrix'>
<p>Generates random values from a normal and puts them in a matrix</p></a></li>
<li><a href='#Get specific columns/rows fo a matrix'>
<p>Get specific columns/rows fo a matrix</p></a></li>
<li><a href='#Hash - Pair function'>
<p>Hash - Pair function</p></a></li>
<li><a href='#Hash object'>
<p>Hash object</p></a></li>
<li><a href='#Hash object to a list object'>
<p>Hash object to a list object</p></a></li>
<li><a href='#High dimensional MCD based detection of outliers'>
<p>High dimensional MCD based detection of outliers</p></a></li>
<li><a href='#Hypothesis test for the distance correlation'>
<p>Hypothesis test for the distance correlation</p></a></li>
<li><a href='#Hypothesis test for two means of percentages'>
<p>Hypothesis test for two means of percentages</p></a></li>
<li><a href='#Hypothesis test for von Mises-Fisher distribution over Kent distribution'>
<p>Hypothesis test for von Mises-Fisher distribution over Kent distribution</p></a></li>
<li><a href='#Hypothesis testing between two skewness or kurtosis coefficients'>
<p>Hypothesis testing between two skewness or kurtosis coefficients</p></a></li>
<li><a href='#Index of the columns of a data.frame which are a specific type'>
<p>Index of the columns of a data.frame which are a specific type</p></a></li>
<li><a href='#Inverse Gaussian regression with a log-link'>
<p>Inverese Gaussian regression with a log-link</p></a></li>
<li><a href='#Inverse of a symmetric positive definite matrix'>
<p>Inverse of a symmetric positive definite matrix</p></a></li>
<li><a href='#Iterator'>
<p>Iterator</p></a></li>
<li><a href='#James multivariate version of the t-test'>
<p>James multivariate version of the t-test</p></a></li>
<li><a href='#k nearest neighbours algorithm (k-NN)'>
<p>k nearest neighbours algorithm (k-NN)</p></a></li>
<li><a href='#k-NN algorithm using the arc cosinus distance'>
<p>k-NN algorithm using the arc cosinus distance</p></a></li>
<li><a href='#Limited number of eigenvalues and eigenvectors of a symmetric matrix'>
<p>Limited number of eigenvalues and eigenvectors of a symmetric matrix</p></a></li>
<li><a href='#Linear models for large scale data'>
<p>Linear models for large scale data</p></a></li>
<li><a href='#Logistic and Poisson regression models'>
<p>Logistic and Poisson regression models</p></a></li>
<li><a href='#Logistic or Poisson regression with a single categorical predictor'>
<p>Logistic or Poisson regression with a single categorical predictor</p></a></li>
<li><a href='#Mahalanobis distance'><p>Mahalanobis distance</p></a></li>
<li><a href='#Many (and one) area under the curve values'>
<p>Many area under the curve values</p></a></li>
<li><a href='#Many 2 sample proportions tests'>
<p>Many 2 sample proportions tests</p></a></li>
<li><a href='#Many 2 sample tests'>
<p>Many 2 sample tests tests</p></a></li>
<li><a href='#Many analysis of variance tests with a discrete variable'>
<p>Many analysis of variance tests with a discrete variable</p></a></li>
<li><a href='#Many ANCOVAs'>
<p>Many ANCOVAs</p></a></li>
<li><a href='#Many ANOVAS for count data with Poisson or quasi Poisson models'>
<p>Many ANOVAS for count data with Poisson or quasi Poisson models</p></a></li>
<li><a href='#Many exponential regressions'>
<p>Many exponential regressions</p></a></li>
<li><a href='#Many F-tests with really huge matrices'>
<p>Many F-tests with really huge matrices</p></a></li>
<li><a href='#Many G-square and Chi-square tests of indepedence'>
<p>Many G-square tests of indepedence</p></a></li>
<li><a href='#Many Gini coefficients'>
<p>Many Gini coefficients</p></a></li>
<li><a href='#Many hypothesis tests for two means of percentages'>
<p>Many hypothesis tests for two means of percentages</p></a></li>
<li><a href='#Many moment and maximum likelihood estimations of variance components'>
<p>Many moment and maximum likelihood estimations of variance components</p></a></li>
<li><a href='#Many multi-sample tests'>
<p>Many multi-sample tests</p></a></li>
<li><a href='#Many multivariate simple linear regressions coefficients'><p>Many multivariate simple linear regressions coefficients</p></a></li>
<li><a href='#Many non parametric multi-sample tests'>
<p>Many multi-sample tests</p></a></li>
<li><a href='#Many odds ratio tests'>
<p>Many odds ratio tests</p></a></li>
<li><a href='#Many one sample goodness of fit tests for categorical data'>
<p>Many one sample goodness of fit tests for categorical data</p></a></li>
<li><a href='#Many one sample tests'>
<p>Many one sample tests</p></a></li>
<li><a href='#Many random intercepts LMMs for balanced data with a single identical covariate.'>
<p>Many random intercepts LMMs for balanced data with a single identical covariate</p></a></li>
<li><a href='#Many regression based tests for single sample repeated measures'>
<p>Many regression based tests for single sample repeated measures</p></a></li>
<li><a href='#Many score based regressions'>
<p>Many score based regressions</p></a></li>
<li><a href='#Many Shapiro-Francia normality tests'>
<p>Many Shapiro-Francia normality tests</p></a></li>
<li><a href='#Many simple circular or angular regressions'>
<p>Many simple circular or angular regressions</p></a></li>
<li><a href='#Many simple geometric regressions'>
<p>Many simple geometric regressions.</p></a></li>
<li><a href='#Many simple linear mixed model regressions'>
<p>Many simple linear mixed model regressions</p></a></li>
<li><a href='#Many simple linear regressions coefficients'><p>Simple linear regressions coefficients</p></a></li>
<li><a href='#Many simple multinomial regressions'>
<p>Many simple multinomial regressions.</p></a></li>
<li><a href='#Many simple regressions for positive valued data'>
<p>Many simple regressions for positive valued data</p></a></li>
<li><a href='#Many tests for the dispersion parameter in Poisson distribution'>
<p>Many tests for the dispersion parameter in Poisson distribution</p></a></li>
<li><a href='#Many two-way ANOVAs'>
<p>Many two-way ANOVAs</p></a></li>
<li><a href='#Many univariate generalised linear models'>
<p>Many univariate generalised linear regressions</p></a></li>
<li><a href='#Many univariate simple linear regressions'>
<p>Many univariate simple linear regressions</p></a></li>
<li><a href='#Many univariate simple logistic and Poisson regressions'>
<p>Many univariate simple binary logistic regressions</p></a></li>
<li><a href='#Many univariate simple quasi poisson regressions'>
<p>Many univariate simple poisson regressions</p></a></li>
<li><a href='#Many Welch's F-tests'>
<p>Many Welch's F-tests</p></a></li>
<li><a href='#Matrix multiplication'>
<p>Matrix multiplication, Cross and Tcross product.</p></a></li>
<li><a href='#Matrix with all pairs of t-tests'>
<p>Matrix with all pairs of t-tests</p></a></li>
<li><a href='#Matrix with G-square tests of indepedence'>
<p>Matrix with G-square tests of indepdence</p></a></li>
<li><a href='#Minima and maxima of two vectors/matrices and Column-row wise minima and maxima of two matrices'>
<p>Minima and maxima of two vectors/matrices and Column-row wise minima and maxima of two matrices</p></a></li>
<li><a href='#Minimum and maximum '>
<p>Minimum and maximum of a vector</p></a></li>
<li><a href='#Minimum and maximum frequencies '>
<p>Minimum and maximum frequencies of a vector</p></a></li>
<li><a href='#MLE for multivariate discrete data'>
<p>MLE for multivariate discrete data</p></a></li>
<li><a href='#MLE of (hyper-)spherical distributions'>
<p>MLE of (hyper-)spherical distributions</p></a></li>
<li><a href='#MLE of continuous univariate distributions defined on the positive line'>
<p>MLE of continuous univariate distributions defined on the positive line</p></a></li>
<li><a href='#MLE of continuous univariate distributions defined on the real line'>
<p>MLE of continuous univariate distributions defined on the real line</p></a></li>
<li><a href='#MLE of count data (univariate discrete distributions)'>
<p>MLE of count data</p></a></li>
<li><a href='#MLE of distributions defined in the (0, 1) interval'>
<p>MLE of distributions defined in the (0, 1) interval</p></a></li>
<li><a href='#MLE of some circular distributions'>
<p>MLE of some circular distributions</p></a></li>
<li><a href='#MLE of the inverted Dirichlet distribution'>
<p>MLE of the inverted Dirichlet distribution</p></a></li>
<li><a href='#MLE of the multivariate (log-) normal distribution'>
<p>MLE of the multivariate (log-) normal distribution</p></a></li>
<li><a href='#MLE of the multivariate t distribution'>
<p>MLE of the multivariate t distribution</p></a></li>
<li><a href='#MLE of the ordinal model without covariates'>
<p>MLE of the ordinal model without covariates</p></a></li>
<li><a href='#MLE of the tobit model'>
<p>MLE of the tobit model</p></a></li>
<li><a href='#Moment and maximum likelihood estimation of variance components'>
<p>Moment and maximum likelihood estimation of variance components</p></a></li>
<li><a href='#Multi-sample tests for vectors'>
<p>Multi-sample tests for vectors</p></a></li>
<li><a href='#Multinomial regression'>
<p>Multinomial regression</p></a></li>
<li><a href='#Multivariate kurtosis'>
<p>Multivariate kurtosis</p></a></li>
<li><a href='#Multivariate Laplace random values simulation'>
<p>Multivariate Laplace random values simulation</p></a></li>
<li><a href='#Multivariate normal and t random values simulation'>
<p>Multivariate normal and t random values simulation</p></a></li>
<li><a href='#Naive Bayes classifiers'>
<p>Naive Bayes classifiers</p></a></li>
<li><a href='#Natural Logarithm each element of a matrix'>
<p>Natural Logarithm each element of a matrix</p></a></li>
<li><a href='#Natural logarithm of the beta function'>
<p>Natural logarithm of the beta function</p></a></li>
<li><a href='#Natural logarithm of the gamma function and its derivatives'>
<p>Natural logarithm of the gamma function and its derivatives.</p></a></li>
<li><a href='#Norm of a matrix'>
<p>Norm of a matrix</p></a></li>
<li><a href='#Number of equal columns between two matrices'><p>Number of equal columns between two matrices</p></a></li>
<li><a href='#Odds ratio and relative risk'>
<p>Odds ratio and relative risk</p></a></li>
<li><a href='#One sample t-test for a vector'>
<p>One sample t-test for a vector</p></a></li>
<li><a href='#Operations between two matrices or matrix and vector'>
<p>Operations between two matrices or matrix and vector</p></a></li>
<li><a href='#Orthogonal matching pursuit variable selection'>
<p>Orthogonal matching pursuit variable selection</p></a></li>
<li><a href='#Outer function'>
<p>Outer function</p></a></li>
<li><a href='#Permutation based p-value for the Pearson correlation coefficient'>
<p>Permutation based p-value for the Pearson correlation coefficient</p></a></li>
<li><a href='#Polyserial correlation'>
<p>Polyserial correlation</p></a></li>
<li><a href='#Pooled covariance matrix'>
<p>Pooled covariance matrix</p></a></li>
<li><a href='#Prediction with some naive Bayes classifiers'>
<p>Prediction with some naive Bayes classifiers</p></a></li>
<li><a href='#Quasi binomial regression for proportions'>
<p>Quasi binomial regression for proportions</p></a></li>
<li><a href='#Quasi Poisson regression for count data'>
<p>Quasi Poisson regression</p></a></li>
<li><a href='#Random intercepts linear mixed models'>
<p>Random intercepts linear mixed models</p></a></li>
<li><a href='#Random values simulation from a von Mises distribution'>
<p>Random values simulation from a von Mises distribution</p></a></li>
<li><a href='#Reading the files of a directory'>
<p>Reading the files of a directory</p></a></li>
<li><a href='#Repeated measures anova'>
<p>Repeated measures anova</p></a></li>
<li><a href='#Rfast-package'>
<p>A Collection of Efficient and Extremely Fast R Functions</p></a></li>
<li><a href='#Round each element of a matrix/vector'>
<p>Round each element of a matrix/vector</p></a></li>
<li><a href='#Row - Wise matrix/vector count the frequency of a value '>
<p>Row - Wise matrix/vector count the frequency of a value</p></a></li>
<li><a href='#Row-wise minimum and maximum'>
<p>Row-wise minimum and maximum of a matrix.</p></a></li>
<li><a href='#Row-wise true value '>
<p>Row-wise true value of a matrix</p></a></li>
<li><a href='#Search for variables with zero range in a matrix'><p>Search for variables with zero range in a matrix</p></a></li>
<li><a href='#Significance testing for the coefficients of Quasi binomial or the quasi Poisson regression'>
<p>Significance testing for the coefficients of Quasi binomial or the quasi Poisson regression</p></a></li>
<li><a href='#Simulation of random values from a Bingham distribution'>
<p>Simulating from a Bingham distribution</p></a></li>
<li><a href='#Simulation of random values from a Bingham distribution with any symmetric matrix'>
<p>Simulation of random values from a Bingham distribution with any symmetric matrix</p></a></li>
<li><a href='#Simulation of random values from a normal distribution'>
<p>Simulation of random values from a normal distribution</p></a></li>
<li><a href='#Simulation of random values from a von Mises-Fisher distribution'>
<p>Random values simulation from a von Mises-Fisher distribution</p></a></li>
<li><a href='#Skeleton of the PC algorithm'>
<p>The skeleton of a Bayesian network produced by the PC algorithm</p></a></li>
<li><a href='#Skewness and kurtosis coefficients'>
<p>Skewness and kurtosis coefficients</p></a></li>
<li><a href='#Some summary statistics of a vector for each level of a grouping variable'>
<p>Some summary statistics of a vector for each level of a grouping variable.</p></a></li>
<li><a href='#Sort - Integer Sort - Sort a vector coresponding to another'>
<p>Sort - Integer Sort - Sort a vector coresponding to another</p></a></li>
<li><a href='#Sorting of the columns-rows of a matrix'>
<p>Sorting of the columns-rows of a matrix</p></a></li>
<li><a href='#Source many R files'>
<p>Source many R files</p></a></li>
<li><a href='#Spatial median for Euclidean data'>
<p>Spatial median for Euclidean data</p></a></li>
<li><a href='#Spatial median regression'>
<p>Spatial median regression</p></a></li>
<li><a href='#Spatial sign covariance matrix'>
<p>Spatial sign covariance matrix</p></a></li>
<li><a href='#Spherical and hyperspherical median'>
<p>Fast calculation of the spherical and hyperspherical median</p></a></li>
<li><a href='#Standardisation'>
<p>Standardisation</p></a></li>
<li><a href='#Sub-matrix'><p>Sub-matrix</p></a></li>
<li><a href='#Table Creation - Frequency of each value'>
<p>Table Creation - Frequency of each value</p></a></li>
<li><a href='#Tests for the dispersion parameter in Poisson distribution'>
<p>Tests for the dispersion parameter in Poisson distribution</p></a></li>
<li><a href='#Topological sort of a DAG'>
<p>Topological sort of a DAG</p></a></li>
<li><a href='#Transpose of a matrix'>
<p>Transpose of a matrix</p></a></li>
<li><a href='#Uniformity test for circular data'>
<p>Uniformity tests for circular data</p></a></li>
<li><a href='#Variance of a vector'>
<p>Variance (and standard deviation)  of a vector</p></a></li>
<li><a href='#Vector allocation in a symmetric matrix'>
<p>Vector allocation in a symmetric matrix</p></a></li>
<li><a href='#Weibull regression model'>
<p>Weibull regression model</p></a></li>
<li><a href='#Yule's Y (coefficient of colligation)'>
<p>Yule's Y (coefficient of colligation)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Collection of Efficient and Extremely Fast R Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-08</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Manos Papadakis &lt;rfastofficial@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), Rcpp (&ge; 0.12.3), RcppZiggurat, RcppParallel</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp (&ge; 0.12.3), RcppArmadillo, RcppParallel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>philentropy</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/RfastOfficial/Rfast/issues">https://github.com/RfastOfficial/Rfast/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/RfastOfficial/Rfast">https://github.com/RfastOfficial/Rfast</a></td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of fast (utility) functions for data analysis. Column and row wise means, medians, variances, minimums, maximums, many t, F and G-square tests, many regressions (normal, logistic, Poisson), are some of the many fast functions. References: a) Tsagris M., Papadakis M. (2018). Taking R to its limits: 70+ tips. PeerJ Preprints 6:e26605v1 &lt;<a href="https://doi.org/10.7287%2Fpeerj.preprints.26605v1">doi:10.7287/peerj.preprints.26605v1</a>&gt;. b) Tsagris M. and Papadakis M. (2018). Forward regression in R: from the extreme slow to the extreme fast. Journal of Data Science, 16(4): 771&ndash;780. &lt;<a href="https://doi.org/10.6339%2FJDS.201810_16%284%29.00006">doi:10.6339/JDS.201810_16(4).00006</a>&gt;. c) Chatzipantsiou C., Dimitriadis M., Papadakis M. and Tsagris M. (2020). Extremely Efficient Permutation and Bootstrap Hypothesis Tests Using Hypothesis Tests Using R. Journal of Modern Applied Statistical Methods, 18(2), eP2898. &lt;<a href="https://doi.org/10.48550%2FarXiv.1806.10947">doi:10.48550/arXiv.1806.10947</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-08 12:34:23 UTC; epapadakis</td>
</tr>
<tr>
<td>Author:</td>
<td>Manos Papadakis [aut, cre, cph],
  Michail Tsagris [aut],
  Marios Dimitriadis [ctb],
  Stefanos Fafalios [aut],
  Ioannis Tsamardinos [ctb],
  Matteo Fasiolo [ctb],
  Giorgos Borboudakis [ctb],
  John Burkardt [ctb],
  Changliang Zou [ctb],
  Kleanthi Lakiotaki [ctb],
  Christina Chatzipantsiou [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 09:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+20Check+20if+20any+20column+20or+20row+20is+20fill+20with+20values+20'>
Check if any column or row is fill with values
</h2><span id='topic+colrow.value'></span>

<h3>Description</h3>

<p>Check if any column or row is fill with values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colrow.value(x,value=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Check+2B20if+2B20any+2B20column+2B20or+2B20row+2B20is+2B20fill+2B20with+2B20values+2B20_+3A_x">x</code></td>
<td>

<p>A vector with data.
</p>
</td></tr>
<tr><td><code id="+2B20Check+2B20if+2B20any+2B20column+2B20or+2B20row+2B20is+2B20fill+2B20with+2B20values+2B20_+3A_value">value</code></td>
<td>

<p>A value to check.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Check all the column if any has all its elements equal to argument value. If found, return &quot;TRUE&quot;. Otherwise continues with rows. If columns and rows hasn't any value vector then return &quot;FALSE&quot;. Even if it returns &quot;FALSE&quot; that doesn't mean the determinant can't be value. It might be but if check before and found any value vector then for sure the determinant it'll be value.
</p>


<h3>Value</h3>

<p>A boolean value, &quot;TRUE&quot; if any column OR row is all filled with value. &quot;FALSE&quot; otherwise.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowFalse">rowFalse</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>, <a href="#topic+rowTrue">rowTrue</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(runif(10*10),10,10)
res&lt;-colrow.value(x) 

x&lt;-NULL
</code></pre>

<hr>
<h2 id='+20Deep+20copy+20'>
Deep copy
</h2><span id='topic+env.copy'></span>

<h3>Description</h3>

<p>Deep copy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>env.copy(x,all.names=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Deep+2B20copy+2B20_+3A_x">x</code></td>
<td>

<p>An environment object.
</p>
</td></tr>
<tr><td><code id="+2B20Deep+2B20copy+2B20_+3A_all.names">all.names</code></td>
<td>

<p>An logical value (TRUE or FALSE). Copy all the hidden variables or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Deep copy of the environment object.
</p>


<h3>Value</h3>

<p>A copy of the first argument.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colShuffle">colShuffle</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+read.directory">read.directory</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- new.env()
x$imaginary &lt;- NULL
x$real &lt;- NULL

# you can library the package and just press x and R will understand 
# and search automatically for a function to print the environment
x

y &lt;- env.copy(x)

x$real &lt;- 10

x$real == y$real # FALSE

</code></pre>

<hr>
<h2 id='+20Design+20Matrix+20'>
Design Matrix
</h2><span id='topic+design_matrix'></span>

<h3>Description</h3>

<p>Design Matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>design_matrix(x, ones = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Design+2B20Matrix+2B20_+3A_x">x</code></td>
<td>

<p>A character vector or a factor type vector or a dataframe. Do not supply a numerical vector. 
</p>
</td></tr>
<tr><td><code id="+2B20Design+2B20Matrix+2B20_+3A_ones">ones</code></td>
<td>

<p>A boolean variable specifying whether to include the ones in the design matrix or not. The default value is TRUE. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the R's &quot;model.matrix&quot; function and is used only when the x is a factor/charactervector or Dataframe. 
</p>


<h3>Value</h3>

<p>Returns the same matrix with model.matrix.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+model.matrix">model.matrix</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- design_matrix( iris[, 5] )
b &lt;- model.matrix( ~ iris[,5] )  ## R's built-in function
all.equal(as.vector(a),as.vector(b)) ## true

a&lt;-b&lt;-NULL
</code></pre>

<hr>
<h2 id='+20Insert+2Fremove+20function+20names+20in+2Ffrom+20the+20NAMESPACE+20file+20'>
Insert/remove function names in/from the NAMESPACE file
</h2><span id='topic+AddToNamespace'></span><span id='topic+RemoveFromNamespace'></span>

<h3>Description</h3>

<p>Insert/remove function names in/from the NAMESPACE file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AddToNamespace(path.namespace,path.rfolder)
RemoveFromNamespace(path.namespace,files.to.remove)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Insert+2B2Fremove+2B20function+2B20names+2B20in+2B2Ffrom+2B20the+2B20NAMESPACE+2B20file+2B20_+3A_path.namespace">path.namespace</code></td>
<td>

<p>An full path to the NAMESPACE file.
</p>
</td></tr>
<tr><td><code id="+2B20Insert+2B2Fremove+2B20function+2B20names+2B20in+2B2Ffrom+2B20the+2B20NAMESPACE+2B20file+2B20_+3A_path.rfolder">path.rfolder</code></td>
<td>

<p>An full path to the directory the new files to be added are stored.
</p>
</td></tr>
<tr><td><code id="+2B20Insert+2B2Fremove+2B20function+2B20names+2B20in+2B2Ffrom+2B20the+2B20NAMESPACE+2B20file+2B20_+3A_files.to.remove">files.to.remove</code></td>
<td>

<p>An character with the names of the functions to be removed from file NAMESPACE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AddToNameSpace: Reads the files that are exported in NAMESPACE and the functions that are inside rfolder (where R files are) and insert every function that is not exported. For that you must add the attribute &quot;#[export]&quot; above every function you wish to export. Also you can use the attribute &quot;#[export s3]&quot; for exporting S3methods. Finally, if you don't want the program to read a file just add at the top of the file the attribute &quot;#[dont read]&quot;.
</p>
<p>RemoveFromNamespace: Remove every function, from argument &quot;files.to.remove&quot;, from NAMESPACE.
</p>


<h3>Value</h3>

<p>AddToNameSpace:
</p>
<table>
<tr><td><code>without export</code></td>
<td>

<p>A character vector with the names of the R functions that don't have te &quot;#[export]&quot; attribute.
</p>
</td></tr>
<tr><td><code>hidden functions</code></td>
<td>

<p>A character vector with the names of the R functions that are hidden.
</p>
</td></tr>
</table>
<p>RemoveFromNamespace: Return the files that could not be removed.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colShuffle">colShuffle</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+read.directory">read.directory</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
	#for example: path.namespace="C:\some_file\NAMESPACE" where is NAMESPACE file
	#path.rfolder="C:\some_file\R\" where is R files are
	#system.time( a&lt;-AddToNamespace(path.namespace,path.rfolder) )
	#if(length(a)==0){
	#	print("all the files are inserted")
	#}else{
	#	print("The new files that inserted are: \n")
	#	a
	#}
	#system.time( a&lt;-RemoveFromNamespace(path.namespace,c("a","b")) )
	#if(length(a)==0){
	#	print("all the files are inserted")
	#}else{
	#	print("The files thatcould not be deleted are: \n")
	#	a
	#}

## End(Not run)
</code></pre>

<hr>
<h2 id='+20Lower+20and+20Upper+20triangular+20of+20a+20matrix+20'>
Lower and Upper triangular of a matrix
</h2><span id='topic+lower_tri'></span><span id='topic+upper_tri'></span><span id='topic+lower_tri.assign'></span><span id='topic+upper_tri.assign'></span>

<h3>Description</h3>

<p>Lower/upper triangular matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lower_tri(x, suma = FALSE, diag = FALSE)
upper_tri(x, suma = FALSE, diag = FALSE)
lower_tri.assign(x, v, diag = FALSE)
upper_tri.assign(x, v, diag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Lower+2B20and+2B20Upper+2B20triangular+2B20of+2B20a+2B20matrix+2B20_+3A_x">x</code></td>
<td>

<p>A matrix with data <b>or</b> a vector with 2 values which is the dimension of the logical matrix to be returned with the upper or lower triangular filled with &quot;TRUE&quot;.
</p>
</td></tr>
<tr><td><code id="+2B20Lower+2B20and+2B20Upper+2B20triangular+2B20of+2B20a+2B20matrix+2B20_+3A_v">v</code></td>
<td>

<p>A numeric vector for assign to the lower/upper triangular.
</p>
</td></tr>
<tr><td><code id="+2B20Lower+2B20and+2B20Upper+2B20triangular+2B20of+2B20a+2B20matrix+2B20_+3A_suma">suma</code></td>
<td>

<p>A logical value for returning the sum of the upper or lower triangular. By default is &quot;FALSE&quot;.
Works only <b>if</b> argument &quot;x&quot; is matrix.
</p>
</td></tr>
<tr><td><code id="+2B20Lower+2B20and+2B20Upper+2B20triangular+2B20of+2B20a+2B20matrix+2B20_+3A_diag">diag</code></td>
<td>

<p>A logical value include the diagonal to the result.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Get a lower/upper triangular logical matrix with values <b>TRUE</b>/<b>FALSE</b>, a vector with the values of a lower/upper triangular, the sum of the upper/lower triangular if suma is set <b>TRUE</b> or assign to the lower/upper (only for large matrices) triangular. You can also include diagonal with any operation if argument diag is set to &quot;TRUE&quot;.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+colFalse">colFalse</a>, <a href="#topic+nth">nth</a>, <a href="#topic+rowrange">rowrange</a>, <a href="#topic+rowMedians">rowMedians</a>, <a href="#topic+rowVars">rowVars</a>, <a href="#topic+colTrue">colTrue</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(runif(10*10),10,10)

all.equal(lower_tri(c(10,10)),lower.tri(x))

all.equal(lower_tri(x),x[lower.tri(x)])

#all.equal(upper_tri(c(10,10)),upper.tri(x))

#all.equal(upper_tri(x),x[upper.tri(x)])



#all.equal(lower_tri(c(10,10),diag = TRUE),lower.tri(x,diag = TRUE))

#all.equal(lower_tri(x,diag = TRUE),x[lower.tri(x,diag = TRUE)])

#all.equal(upper_tri(c(10,10),diag = TRUE),upper.tri(x,diag = TRUE))

#all.equal(upper_tri(x,diag = TRUE),x[upper.tri(x,diag = TRUE)])

all.equal(lower_tri.assign(x,diag = TRUE,v=rep(1,1000)),x[lower.tri(x,diag = TRUE)]&lt;-1)

all.equal(upper_tri.assign(x,diag = TRUE,v=rep(1,1000)),x[upper.tri(x,diag = TRUE)]&lt;-1)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='+20Match+20'>
Match
</h2><span id='topic+Match'></span>

<h3>Description</h3>

<p>Return the positions of its first argument that matches in its second.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Match(x,key=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Match+2B20_+3A_x">x</code></td>
<td>

<p>A numeric vector.
</p>
</td></tr>
<tr><td><code id="+2B20Match+2B20_+3A_key">key</code></td>
<td>

<p>The value/vector for searching in vector x. For now let it NULL. <b>dont't use it!</b>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the R's \&quot;match\&quot; function.
This version basicaly calculates the match(x,sort(unique(x))) for now. Do not use the argument key!
</p>


<h3>Value</h3>

<p>Returns the position/positions of the given key/keys in the x vector.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+match">match</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
a &lt;- Match(y)
b &lt;-50
all.equal(as.vector(a),as.vector(b))
</code></pre>

<hr>
<h2 id='+20Permutation+20'>
Permutation
</h2><span id='topic+permutation'></span><span id='topic+permutation.next'></span><span id='topic+permutation.prev'></span><span id='topic+bincomb'></span>

<h3>Description</h3>

<p>Permute the given vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permutation(x, nperm = gamma(length(x)+1))
permutation.next(x, nperm = gamma(length(x)+1))
permutation.prev(x, nperm = gamma(length(x)+1))
bincomb(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Permutation+2B20_+3A_x">x</code></td>
<td>

<p>A numeric vector with data. 
</p>
</td></tr>
<tr><td><code id="+2B20Permutation+2B20_+3A_nperm">nperm</code></td>
<td>

<p>An integer value for returning specific number of combinations. By defualt is set to all combinations. Must be between <b>0&lt;=nperm&lt;=gamma(length(x)+1)</b>
</p>
</td></tr>
<tr><td><code id="+2B20Permutation+2B20_+3A_n">n</code></td>
<td>

<p>An integer value for the length of the binary number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements &quot;Permutation&quot;, which means all the possible combinations. In the permutation.next and permutation.prev
if there aren't possible combinations it returns the same vector. &quot;Binary Combinations&quot; for &quot;bincomb&quot;, means all the possible combinations for the binary number with length &quot;n&quot;.
</p>


<h3>Value</h3>

<p>Returns a matrix with all possible combinations of the given vector or a matrix row with one possible combinations.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+combn">combn</a>,<a href="#topic+comb_n">comb_n</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(3)
b &lt;- permutation(y)
b &lt;- permutation.next(y)
b &lt;- permutation.prev(y)
g &lt;- bincomb(3)
</code></pre>

<hr>
<h2 id='+20Replicate+20columns+2Frows+20'>
Replicate columns/rows
</h2><span id='topic+rep_col'></span><span id='topic+rep_row'></span>

<h3>Description</h3>

<p>Replicate columns/rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rep_col(x,n)
rep_row(x,n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Replicate+2B20columns+2B2Frows+2B20_+3A_x">x</code></td>
<td>

<p>A vector with data.
</p>
</td></tr>
<tr><td><code id="+2B20Replicate+2B20columns+2B2Frows+2B20_+3A_n">n</code></td>
<td>

<p>Number of new columns/rows.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix where each column/row is equal to &quot;x&quot;.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowFalse">rowFalse</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>, <a href="#topic+rowTrue">rowTrue</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(10)
all.equal(rep_col(x,10),matrix(x,nrow=length(x),ncol=10))
all.equal(rep_row(x,10),matrix(x,ncol=length(x),nrow=10,byrow=TRUE))
</code></pre>

<hr>
<h2 id='+20Represantation+20of+20Stack+20'>
Represantation of Stack
</h2><span id='topic+Stack'></span>

<h3>Description</h3>

<p>Represantation of Stack.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stack(x,type=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Represantation+2B20of+2B20Stack+2B20_+3A_x">x</code></td>
<td>

<p>Any type that could be convert to vector or an integer value.
</p>
</td></tr>
<tr><td><code id="+2B20Represantation+2B20of+2B20Stack+2B20_+3A_type">type</code></td>
<td>

<p>A type for the Stack, &quot;integer&quot;, &quot;numeric&quot; or any other that accepts one argument.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stack is an abstract data type - data structure based on the principle of last in first out. 
To access the 3 fields, use operator &quot;$&quot;.
</p>


<h3>Value</h3>

<p>An object of class &quot;Stack&quot;. This object holds 3 fields:
</p>
<p>pop: remove the first element (from the top).
top: access the first element (from the top).
push: add an element to the top of the Stack.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colShuffle">colShuffle</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+read.directory">read.directory</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-Stack(10,type=integer)

x$push(5)
x$push(10)
x$top()  == 10
x$pop()
x$top() == 5

y&lt;-rnorm(10)
x&lt;-Stack(x)

x$push(5) # length increased to 11
x$top() # access the last element that pushed, 5
x$pop() # pop the last element that pushed
</code></pre>

<hr>
<h2 id='+20Sort+20and+20unique+20numbers+20'>
Sort and unique
</h2><span id='topic+sort_unique'></span><span id='topic+sort_unique.length'></span>

<h3>Description</h3>

<p>Sort and unique numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort_unique(x)
sort_unique.length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B20Sort+2B20and+2B20unique+2B20numbers+2B20_+3A_x">x</code></td>
<td>

<p>A numeric vector. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;sort_unique&quot; function implements R's &quot;unique&quot; function using C++'s function but also sort the result. The &quot;sort_unique.length&quot; returns the length of the unique numbers only for <b>itegers</b>. 
</p>


<h3>Value</h3>

<p>Returns the discrete values but sorted or their length (depending on the function you do).
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>, <a href="#topic+sort_cor_vectors">sort_cor_vectors</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
a &lt;- sort_unique(y)
b &lt;- sort.int(unique(y))
all.equal(as.vector(a),as.vector(b))
x &lt;- rpois(1000,10)
sort_unique.length(x)
length(sort_unique(x))

x&lt;-a&lt;-b&lt;-NULL
</code></pre>

<hr>
<h2 id='All+20k+20possible+20combinations+20from+20n+20elements'>
All k possible combinations from n elements
</h2><span id='topic+comb_n'></span>

<h3>Description</h3>

<p>All k possible combinations from n elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comb_n(n, k,simplify=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="All+2B20k+2B20possible+2B20combinations+2B20from+2B20n+2B20elements_+3A_n">n</code></td>
<td>

<p>A positive <b>INTEGER</b> number or a vector with numbers. 
</p>
</td></tr>
<tr><td><code id="All+2B20k+2B20possible+2B20combinations+2B20from+2B20n+2B20elements_+3A_k">k</code></td>
<td>

<p>A positive integer number at most equal to n or at most equal to the length of n, if n is a vector.
</p>
</td></tr>
<tr><td><code id="All+2B20k+2B20possible+2B20combinations+2B20from+2B20n+2B20elements_+3A_simplify">simplify</code></td>
<td>

<p>A logical value for return List instead of matrix.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with k columns and rows equal to the number of possible unique combinations of n with k elements.
If simplify is set to TRUE then a list with k values where each value has length equal to the number of 
possible unique combinations of n with k elements.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Marios Dimitriadis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; and Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Nijenhuis A. and Wilf H.S. (1978). Combinatorial Algorithms for Computers and Calculators. Academic Press, NY. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nth">nth</a>, <a href="#topic+colMaxs">colMaxs</a>, <a href="#topic+colMins">colMins</a>, <a href="#topic+colrange">colrange</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>comb_n(20, 4)
combn(20, 4)
x &lt;- rnorm(5)
res&lt;-comb_n(x, 3)
</code></pre>

<hr>
<h2 id='Analysis+20of+20covariance'>
Analysis of covariance
</h2><span id='topic+ancova1'></span>

<h3>Description</h3>

<p>Analysis of covariance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ancova1(y, ina, x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Analysis+2B20of+2B20covariance_+3A_y">y</code></td>
<td>

<p>A numerical vector with the data, the response variable.
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20covariance_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Be careful, the function 
is desinged to accept numbers greater than zero. 
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20covariance_+3A_x">x</code></td>
<td>

<p>A numerical vector whose length is equal to the number of rows of y. This is the covariate. 
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20covariance_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Analysis of covariance is performed. No interaction between the factor and the covariate 
is tested. Only the main effects. The design need not be balanced. The values of ina need not have the 
same frequency. The sums of squares have been adjusted to accept balanced and unbalanced designs. 
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value for the factor variable and the covariate. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>D.C. Montgomery (2001). Design and analysis of experiments (5th Edition). New York: John Wiley &amp; Sons 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ancovas">ancovas</a>, <a href="#topic+ftests">ftests</a>, <a href="#topic+ttests">ttests</a>, <a href="#topic+anova1">anova1</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(90)
ina &lt;- rbinom(90, 2, 0.5) + 1
x &lt;- rnorm(90)
a &lt;- ancova1(y, ina, x)
</code></pre>

<hr>
<h2 id='Analysis+20of+20variance+20with+20a+20count+20variable'>
Analysis of variance with a count variable
</h2><span id='topic+poisson.anova'></span><span id='topic+geom.anova'></span><span id='topic+quasipoisson.anova'></span>

<h3>Description</h3>

<p>Analysis of variance with a count variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisson.anova(y, ina, logged = FALSE)
geom.anova(y, ina, type = 1, logged = FALSE)
quasipoisson.anova(y, ina, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Analysis+2B20of+2B20variance+2B20with+2B20a+2B20count+2B20variable_+3A_y">y</code></td>
<td>

<p>A numerical vector with discrete valued data, i.e. counts.
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20variance+2B20with+2B20a+2B20count+2B20variable_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with discrete numbers starting from 1, i.e. 1, 2, 3, 4,... or a factor variable. 
This is suppose to be a categorical predictor. If you supply a continuous valued vector the function 
will obviously provide wrong results.
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20variance+2B20with+2B20a+2B20count+2B20variable_+3A_type">type</code></td>
<td>

<p>This argument is for the geometric distribution. Type 1 refers to the case where the minimum is zero and type 2 for the case of the minimum being 1. 
</p>
</td></tr>
<tr><td><code id="Analysis+2B20of+2B20variance+2B20with+2B20a+2B20count+2B20variable_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the analysis of variance with Poisson or geometric distributed data. What we do is a log-likelihood ratio 
test. However, this is exactly the same as Poisson regression with a single predictor variable who happens to be 
categorical. Needless to say that this is faster function than the glm command in R. For the same purpose with 
a Bernoulli variable use <code><a href="#topic+g2Test">g2Test</a></code>. The quasinpoisson.anova is when in the glm function you specify 
family = quasipoisson. This is suitable for the case of over or under-dispersed data. 
</p>


<h3>Value</h3>

<p>A vector with two values, the difference in the deviances (or the scale difference in the case of quasi poisson)
and the relevant p-value. The quasipoisson.anova also returns the estimate of the <code class="reqn">\phi</code> parameter.  
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+logistic.cat1">logistic.cat1</a>, <a href="#topic+g2Test">g2Test</a>, <a href="#topic+poisson.anovas">poisson.anovas</a>, <a href="stats.html#topic+anova">anova</a>, <a href="#topic+poisson_only">poisson_only</a>, 
<a href="#topic+poisson.mle">poisson.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rpois(300, 10)
ina &lt;- rbinom(300, 3, 0.5) + 1 
a1 &lt;- poisson.anova(y, ina) 
a2 &lt;- glm(y ~ ina, poisson) 


res&lt;-anova(a2, test = "Chisq")

y &lt;- rgeom(300, 0.7)
res&lt;-geom.anova(y, ina) 
</code></pre>

<hr>
<h2 id='Angular+20central+20Gaussian+20random+20values+20simulation'>
Angular central Gaussian random values simulation
</h2><span id='topic+racg'></span>

<h3>Description</h3>

<p>Angular central Gaussian random values simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>racg(n, sigma, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Angular+2B20central+2B20Gaussian+2B20random+2B20values+2B20simulation_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Angular+2B20central+2B20Gaussian+2B20random+2B20values+2B20simulation_+3A_sigma">sigma</code></td>
<td>

<p>The covariance matrix in <code class="reqn">R^d</code>.
</p>
</td></tr>
<tr><td><code id="Angular+2B20central+2B20Gaussian+2B20random+2B20values+2B20simulation_+3A_seed">seed</code></td>
<td>

<p>If you want the same to be generated again use a seed for the generator, an integer number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm uses univariate normal random values and transforms them to multivariate via a spectral decomposition.
The vectors are then scaled to have unit length. 
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Tyler D. E. (1987). Statistical analysis for the angular central Gaussian distribution on the sphere. Biometrika 74(3): 579-589. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acg.mle">acg.mle</a>, <a href="#topic+rmvnorm">rmvnorm</a>, <a href="#topic+rmvlaplace">rmvlaplace</a>, <a href="#topic+rmvt">rmvt</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- cov( iris[, 1:4] )
x &lt;- racg(100, s)
res&lt;-acg.mle(x)  
res&lt;-vmf.mle(x)  ## the concentration parameter, kappa, is very low, close to zero, as expected.
</code></pre>

<hr>
<h2 id='ANOVA+20for+20two+20quasi+20Poisson+20regression+20models'>
ANOVA for two quasi Poisson regression models
</h2><span id='topic+anova_quasipois.reg'></span>

<h3>Description</h3>

<p>ANOVA for two quasi Poisson regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anova_quasipois.reg(mod0, mod1, n) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ANOVA+2B20for+2B20two+2B20quasi+2B20Poisson+2B20regression+2B20models_+3A_mod0">mod0</code></td>
<td>

<p>An object as returned by the &quot;qpois.reg&quot; function. This is the null model.
</p>
</td></tr>
<tr><td><code id="ANOVA+2B20for+2B20two+2B20quasi+2B20Poisson+2B20regression+2B20models_+3A_mod1">mod1</code></td>
<td>

<p>An object as returned by the &quot;qpois.reg&quot; function. This is the alternative model.
</p>
</td></tr>
<tr><td><code id="ANOVA+2B20for+2B20two+2B20quasi+2B20Poisson+2B20regression+2B20models_+3A_n">n</code></td>
<td>

<p>The sample size. This is necessary to calculate the degrees of freedom.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an ANOVA type significance testing for two quasi Poisson models. 
</p>


<h3>Value</h3>

<p>A vector with 4 elements, the test statistic value, its associated p-value and the relevant 
degrees of freedom of the numerator and the denominator.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Papke L. E. &amp; Wooldridge J. (1996). Econometric methods for fractional response variables with 
an application to 401(K) plan participation rates. Journal of Applied Econometrics, 11(6): 619&ndash;632.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+anova_qpois.reg">anova_qpois.reg</a>, <a href="#topic+qpois.reg">qpois.reg</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+quasipoisson.anova">quasipoisson.anova</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- rnbinom(200, 10, 0.5)
x &lt;- matrix(rnorm(200 * 3), ncol = 3)
a1 &lt;- qpois.reg(x, y)
a0 &lt;- qpois.reg(x[, 1], y)
res&lt;-anova_quasipois.reg(a0, a1, 200)
b1 &lt;- glm(y ~ x, family = quasipoisson)
b0 &lt;- glm(y ~ x[, 1], family = quasipoisson)
res&lt;-anova(b0, b1, test = "F")
c1 &lt;- glm(y ~ x, family = poisson)
c0 &lt;- glm(y ~ x[, 1], family = poisson)
res&lt;-anova(c0, c1, test = "Chisq")

</code></pre>

<hr>
<h2 id='Apply+20method+20to+20Positive+20and+20Negative+20number'>
Apply method to Positive and Negative number
</h2><span id='topic+negative'></span><span id='topic+positive'></span><span id='topic+positive.negative'></span>

<h3>Description</h3>

<p>Apply method to Positive and Negative number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>negative(x,method = "min")
positive(x,method = "min")
positive.negative(x,method = "min")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Apply+2B20method+2B20to+2B20Positive+2B20and+2B20Negative+2B20number_+3A_x">x</code></td>
<td>

<p>A numerical vector with data.
</p>
</td></tr>
<tr><td><code id="Apply+2B20method+2B20to+2B20Positive+2B20and+2B20Negative+2B20number_+3A_method">method</code></td>
<td>

<p>Accept 3 values. &quot;min&quot;, &quot;max&quot;, &quot;min.max&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions apply the chosen method to the chosen subset (negative, positive, or both) from the vector and return the result. 
</p>


<h3>Value</h3>

<p>negative: apply the chosen method to every negative number of the input vector.
positive: apply the chosen method to every positive number of the input vector.
positive.negative: apply the chosen method to every negative and positive number of the input vector.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nth">nth</a>, <a href="#topic+colnth">colnth</a>, <a href="#topic+rownth">rownth</a>,<a href="#topic+sort_unique">sort_unique</a>, <a href="#topic+Round">Round</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(1000)

identical(negative(x,"min"), min(x&lt;0))
identical(positive(x,"min"), min(x&gt;0))
identical(positive.negative(x,"min"), c(min(x&lt;0),min(x&gt;0)))

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Apply+20to+20each+20column+20a+20method+20under+20condition'>
Apply to each column a method under condition
</h2><span id='topic+apply.condition'></span>

<h3>Description</h3>

<p>Apply to each column a method under condition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply.condition(x,method = "+",oper = "&gt;",cond.val = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Apply+2B20to+2B20each+2B20column+2B20a+2B20method+2B20under+2B20condition_+3A_x">x</code></td>
<td>

<p>An integer matrix.
</p>
</td></tr>
<tr><td><code id="Apply+2B20to+2B20each+2B20column+2B20a+2B20method+2B20under+2B20condition_+3A_method">method</code></td>
<td>

<p>One of: &quot;+&quot;, &quot;-&quot;, &quot;*&quot;, &quot;min&quot;, &quot;max&quot;.
</p>
</td></tr>
<tr><td><code id="Apply+2B20to+2B20each+2B20column+2B20a+2B20method+2B20under+2B20condition_+3A_oper">oper</code></td>
<td>

<p>One of: &quot;&gt;, &quot;&lt;&quot;, &quot;&gt;=&quot;, &quot;&lt;=&quot;.
</p>
</td></tr>
<tr><td><code id="Apply+2B20to+2B20each+2B20column+2B20a+2B20method+2B20under+2B20condition_+3A_cond.val">cond.val</code></td>
<td>

<p>An integer value for the condition.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Apply to each col the specified method using the condition.
</p>


<h3>Value</h3>

<p>An integer vector with the coresponding values.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Michail Tsagris
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; 
and Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colsums">colsums</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rpois(100,6),10, 10)
identical(apply(x,2,function(x){ sum(x[x&gt;0]) }), apply.condition(x,"+","&gt;",0))
x&lt;-NULL
</code></pre>

<hr>
<h2 id='Backward+20selection+20regression'>
Backward selection regression
</h2><span id='topic+bs.reg'></span>

<h3>Description</h3>

<p>Backward selection regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bs.reg(y, x, alpha = 0.05, type = "logistic")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Backward+2B20selection+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical vector with the response variable values. It can either be of 0 and 1 values (Logistic regression) or of integer values 0, 1, 2,... (Poisson regression).
</p>
</td></tr>
<tr><td><code id="Backward+2B20selection+2B20regression_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the candidate variables.
</p>
</td></tr>
<tr><td><code id="Backward+2B20selection+2B20regression_+3A_alpha">alpha</code></td>
<td>

<p>Threshold (suitable values are in [0,1]) for assessing the significance of p-values. The default value is at 0.05.
</p>
</td></tr>
<tr><td><code id="Backward+2B20selection+2B20regression_+3A_type">type</code></td>
<td>

<p>For the Logistic regression put &quot;logistic&quot; (default value) and for Poisson type &quot;poisson&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function currently implements only the binary Logistic and Poisson regressions. If the sample size is less than the number of variables a notification message 
will appear and no backward regression will be performed. 
</p>


<h3>Value</h3>

<p>The output of the algorithm is an S3 object including:
</p>
<table>
<tr><td><code>info</code></td>
<td>

<p>A matrix with the non selected variables and their latest test statistics and p-values.
</p>
</td></tr>
<tr><td><code>Vars</code></td>
<td>

<p>A vector with the selected variables.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marios Dimitriadis
</p>
<p>R implementation and documentation: Marios Dimitriadis &lt;mtsagris@csd.uoc.gr&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fs.reg">fs.reg</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+cor.fsreg">cor.fsreg</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(50, 1, 0.5)
x &lt;- matrnorm(50, 10)
res&lt;-bs.reg(y, x)
</code></pre>

<hr>
<h2 id='BIC+20+28using+20partial+20correlation+29+20forward+20regression'>
BIC (using partial correlation) forward regression
</h2><span id='topic+bic.corfsreg'></span>

<h3>Description</h3>

<p>BIC (using partial correlation) forward regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bic.corfsreg(y, x, tol = 2) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC+2B20+2B28using+2B20partial+2B20correlation+2B29+2B20forward+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical vector.
</p>
</td></tr>
<tr><td><code id="BIC+2B20+2B28using+2B20partial+2B20correlation+2B29+2B20forward+2B20regression_+3A_x">x</code></td>
<td>

<p>A matrix with data, the predictor variables. 
</p>
</td></tr>
<tr><td><code id="BIC+2B20+2B28using+2B20partial+2B20correlation+2B29+2B20forward+2B20regression_+3A_tol">tol</code></td>
<td>

<p>If the BIC difference between two successive models is less than the tolerance value, the variable will not enter the model.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The forward regression tries one by one the variables using the F-test, basically partial F-test every time for 
the latest variable. This is the same as testing the significance of the coefficient of this latest enetered 
variable. Alternatively the correlation can be used and this case the partial correlation coefficient. There is 
a direct relationship between the t-test statistic and the partial correlation coefficient. Now, instead of 
having to calculate the test statistic, we calculate the partial correlation coefficient. The largest partial correlation
indicates the candidate variable to enter the model. If the BIC of the regression model with that variable included, reduces, 
less than &quot;tol&quot; from the previous model without this variable, the variable enters. 
</p>


<h3>Value</h3>

<p>A matrix with two columns, the index of the selected variable(s) and the BIC of each model. The first line is always 
0 and the BIC of the model with no predictor variables. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Draper, N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+cor.fsreg">cor.fsreg</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+logistic_only">logistic_only</a>,  
<a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 200 variables, hence 200 univariate regressions are to be fitted
x &lt;- matrix( rnorm(200 * 200), ncol = 200 )
y &lt;- rnorm(200)
a1 &lt;- bic.corfsreg(y, x)
a2 &lt;- cor.fsreg(y, x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='BIC+20forward+20regression+20with+20generalised+20linear+20models'>
BIC forward regression with generalised linear models
</h2><span id='topic+bic.fs.reg'></span>

<h3>Description</h3>

<p>BIC forward regression with generalised linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bic.fs.reg(y, x, tol = 2, type = "logistic") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC+2B20forward+2B20regression+2B20with+2B20generalised+2B20linear+2B20models_+3A_y">y</code></td>
<td>

<p>A numerical vector.
</p>
</td></tr>
<tr><td><code id="BIC+2B20forward+2B20regression+2B20with+2B20generalised+2B20linear+2B20models_+3A_x">x</code></td>
<td>

<p>A matrix with data, the predictor variables. 
</p>
</td></tr>
<tr><td><code id="BIC+2B20forward+2B20regression+2B20with+2B20generalised+2B20linear+2B20models_+3A_tol">tol</code></td>
<td>

<p>If the BIC difference between two successive models is less than the tolerance value, 
the variable will not enter the model.
</p>
</td></tr>
<tr><td><code id="BIC+2B20forward+2B20regression+2B20with+2B20generalised+2B20linear+2B20models_+3A_type">type</code></td>
<td>

<p>If you have a binary dependent variable, put &quot;logistic&quot;. If you have count data, put &quot;poisson&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The forward regression tries one by one the variables using the BIC at each step for 
the latest variable. If the BIC of the regression model with that variable included, 
is less than &quot;tol&quot; from the previous model without this variable, the variable enters. 
</p>


<h3>Value</h3>

<p>A matrix with two columns, the index of the selected variable(s) and the BIC of each model. 
</p>


<h3>Author(s)</h3>

<p>Marios Dimitriadis
</p>
<p>R implementation and documentation: Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Draper, N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+fs.reg">fs.reg</a>, <a href="#topic+bic.corfsreg">bic.corfsreg</a>, <a href="#topic+cor.fsreg">cor.fsreg</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+logistic_only">logistic_only</a>,  
<a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(200 * 50), ncol = 50)
## 200 variables, hence 200 univariate regressions are to be fitted
y &lt;- rbinom(200, 1, 0.5)
a &lt;- bic.fs.reg(y, x)
x &lt;- NULL

</code></pre>

<hr>
<h2 id='Binary+20search+20algorithm'>
Binary search algorithm
</h2><span id='topic+binary_search'></span>

<h3>Description</h3>

<p>Search a value in an ordered vector. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binary_search(x, v, index=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Binary+2B20search+2B20algorithm_+3A_x">x</code></td>
<td>

<p>A vector with the data.
</p>
</td></tr>
<tr><td><code id="Binary+2B20search+2B20algorithm_+3A_v">v</code></td>
<td>

<p>A value to check if exists in the vector x.
</p>
</td></tr>
<tr><td><code id="Binary+2B20search+2B20algorithm_+3A_index">index</code></td>
<td>

<p>A boolean value for choose to return the position inside the vector.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>Search if the v exists in x. Then returns TRUE/FALSE if the value is been found.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is_element">is_element</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sort(rnorm(1000))
v &lt;- x[50]
b &lt;- binary_search(x,v) 
b1 &lt;- binary_search(x,v,TRUE) 
</code></pre>

<hr>
<h2 id='Binomial+20coefficient+20and+20its+20logarithm'>
Binomial coefficient and its logarithm
</h2><span id='topic+Lchoose'></span><span id='topic+Choose'></span>

<h3>Description</h3>

<p>Binomial coefficient and its logarithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lchoose(x, k)
Choose(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Binomial+2B20coefficient+2B20and+2B20its+2B20logarithm_+3A_x">x</code></td>
<td>

<p>A vector with integer values numbers.
</p>
</td></tr>
<tr><td><code id="Binomial+2B20coefficient+2B20and+2B20its+2B20logarithm_+3A_k">k</code></td>
<td>

<p>A positive non zero at most equal to x.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The binomial coefficient or its logarithm are evaluated.
</p>


<h3>Value</h3>

<p>A vector with the answers.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+comb_n">comb_n</a>, <a href="#topic+Lbeta">Lbeta</a>, <a href="#topic+Lgamma">Lgamma</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sample(20:30, 100, replace = TRUE)
res&lt;-Choose(x, 4)
res&lt;-Lchoose(x, 4)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Bootstrap+20t-test+20for+202+20independent+20samples'>
Bootstrap t-test for 2 independent samples
</h2><span id='topic+boot.ttest2'></span>

<h3>Description</h3>

<p>Bootstrap t-test for 2 independent samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.ttest2(x, y, B = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bootstrap+2B20t-test+2B20for+2B202+2B20independent+2B20samples_+3A_x">x</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
<tr><td><code id="Bootstrap+2B20t-test+2B20for+2B202+2B20independent+2B20samples_+3A_y">y</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
<tr><td><code id="Bootstrap+2B20t-test+2B20for+2B202+2B20independent+2B20samples_+3A_b">B</code></td>
<td>

<p>The number of bootstrap samples to use.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of sampling B times from each sample, we sample <code class="reqn">\sqrt{B}</code> from each of them and then take all pairs. 
Each bootstrap sample is independent of each other, hence there is no violation of the theory. 
</p>


<h3>Value</h3>

<p>A vector with the test statistic and the bootstrap p-value. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Christina Chatzipantsiou
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Christina Chatzipantsiou &lt;chatzipantsiou@gmail.com&gt;.
</p>


<h3>References</h3>

<p>B.L. Welch (1951). On the comparison of several mean values: an alternative approach. Biometrika, 38(3/4), 330-336.
</p>
<p>Efron Bradley and Robert J. Tibshirani (1993). An introduction to the bootstrap. New York: Chapman &amp; Hall/CRC.
</p>
<p>Chatzipantsiou C., Dimitriadis M., Papadakis M. and Tsagris M. (2019). 
Extremely efficient permutation and bootstrap hypothesis tests using R. 
To appear in the Journal of Modern Applied Statistical Methods.
</p>
<p>https://arxiv.org/ftp/arxiv/papers/1806/1806.10947.pdf 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ttest2">ttest2</a>, <a href="#topic+exact.ttest2">exact.ttest2</a>, <a href="#topic+ftest">ftest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tic &lt;- proc.time()
x &lt;- rexp(40, 4)
y &lt;- rbeta(50, 2.5, 7.5)
a &lt;- boot.ttest2(x, y, 9999)
a
</code></pre>

<hr>
<h2 id='Check+20if+20values+20are+20integers+20and+20convert+20to+20integer'>
Check if values are integers and convert to integer
</h2><span id='topic+is_integer'></span><span id='topic+as_integer'></span>

<h3>Description</h3>

<p>Check if values are integers and convert to integer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_integer(x)
as_integer(x,result.sort = TRUE,init = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Check+2B20if+2B20values+2B20are+2B20integers+2B20and+2B20convert+2B20to+2B20integer_+3A_x">x</code></td>
<td>

<p>is_integer: A vector with numeric data.
as_integer: A vector with data.
</p>
</td></tr>
<tr><td><code id="Check+2B20if+2B20values+2B20are+2B20integers+2B20and+2B20convert+2B20to+2B20integer_+3A_result.sort">result.sort</code></td>
<td>

<p>A logical value for sorting the result.
</p>
</td></tr>
<tr><td><code id="Check+2B20if+2B20values+2B20are+2B20integers+2B20and+2B20convert+2B20to+2B20integer_+3A_init">init</code></td>
<td>

<p>An integer value to start.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The behavior of these functions are different than R's built in. 
</p>
<p>is_integer: 
check if all the values are integers in memory. If typeof is double, and the values are integers in range -2^31 : 2^31 then it is  better to convert to integer vector for using less memory. Also you can decrease the time complexity.
</p>
<p>as_integer: 
converts the discrete values to integers.
</p>


<h3>Value</h3>

<p>is_integer: A logical value, TRUE if all values are integers and in range -2^31 : 2^31. Otherwise FALSE.
</p>
<p>as_integer: By default the function will return the same result with &quot;as.numeric&quot; but the user can change the &quot;init&quot; value not start from 1 like R's. Also the result can be unsorted using &quot;result.sort&quot;.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as_integer">as_integer</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+read.directory">read.directory</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-runif(10)
y1&lt;-is_integer(x) # y1 is FALSE
x&lt;-as.numeric(rpois(10,10)) # integers but typeof is double
y1&lt;-is_integer(x) # y1 is TRUE so you can convert to integer vector.

as_integer(letters) ## as.numeric(letters) produce errors
x&lt;-y1&lt;-NULL
</code></pre>

<hr>
<h2 id='Check+20Namespace+20and+20Rd+20files'>
Check Namespace and Rd files
</h2><span id='topic+checkNamespace'></span><span id='topic+checkAliases'></span><span id='topic+checkExamples'></span><span id='topic+checkTF'></span><span id='topic+checkUsage'></span>

<h3>Description</h3>

<p>Check Namespace/Rd and examples files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkNamespace(path.namespace,path.rfolder)
checkAliases(path.man,path.rfolder)
checkTF(path.man)
checkExamples(path.man,package,each = 1,print.errors = stderr(),
	print.names = FALSE)
checkUsage(path.man,path.rfolder)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Check+2B20Namespace+2B20and+2B20Rd+2B20files_+3A_path.namespace">path.namespace</code></td>
<td>

<p>An full path to the &quot;NAMESPACE&quot; file.
</p>
</td></tr>
<tr><td><code id="Check+2B20Namespace+2B20and+2B20Rd+2B20files_+3A_package">package</code></td>
<td>

<p>A character vector with the name of the package.
</p>
</td></tr>
<tr><td><code id="Check+2B20Namespace+2B20and+2B20Rd+2B20files_+3A_path.rfolder">path.rfolder</code></td>
<td>

<p>An full path to the directory that contains the &quot;R&quot; files.
</p>
</td></tr>
<tr><td><code id="Check+2B20Namespace+2B20and+2B20Rd+2B20files_+3A_path.man">path.man</code></td>
<td>

<p>An full path to the directory that contains the &quot;Rd&quot; files.
</p>
</td></tr>
<tr><td><code id="Check+2B20Namespace+2B20and+2B20Rd+2B20files_+3A_each">each</code></td>
<td>

<p>An integer value for running <b>each</b> example.
</p>
</td></tr>
<tr><td><code id="Check+2B20Namespace+2B20and+2B20Rd+2B20files_+3A_print.errors">print.errors</code></td>
<td>

<p>Print the errors to a file. By default it's &quot;stderr()&quot;.
</p>
</td></tr>
<tr><td><code id="Check+2B20Namespace+2B20and+2B20Rd+2B20files_+3A_print.names">print.names</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for printing the names of the files before running the examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b><a href="#topic+checkNamespace">checkNamespace</a></b>: reads from the NAMESPACE folder all the export R functions, reads from folder R all the R functions and check if all the functions are export.
</p>
<p><b><a href="#topic+checkAliases">checkAliases</a></b>: reads from the man directory all the Rd files, then reads from each file the aliases and check if:
</p>

<ul>
<li><p> All the R files has man file or an alias.
</p>
</li>
<li><p> All aliases belongs to functions.
</p>
</li>
<li><p> If there are dublicated aliases.
</p>
</li></ul>

<p><b><a href="#topic+checkExamples">checkExamples</a></b>: reads from the man directory all the Rd files, then read from each file the examples and then run each of them. If you want to print the errors in any file then set &quot;print.errors=file_name&quot; or in the standard error &quot;print.errors=stderr()&quot; and then you will see all the errors for every file. Set to argument &quot;package&quot; the name of your package. 
The argument &quot;print.names&quot; it is very helpful because if any of you function crashes R during running you will never know which one was. 
So setting it &quot;TRUE&quot;, it will print the name of each file before running it's example.It might crash, but you will know which file. 
<b>Remember that there is always an error timeout so it might didn't crash the current file but one from the previous.</b>
</p>
<p><b><a href="#topic+checkTF">checkTF</a></b>: reads from the man directory all the Rd files, then read from each file the examples and checks if any examples has the values &quot;T&quot; and &quot;F&quot; instead &quot;TRUE&quot; and &quot;FALSE&quot;. The &quot;T&quot;,&quot;F&quot; is wrong.
</p>
<p><b><a href="#topic+checkUsage">checkUsage</a></b>: reads from the man directory all the Rd files and for each man check if the usage section has the right signature for the functions from the R directory.
</p>
<p><b><a href="#topic+checkTF">checkTF</a></b>, <b><a href="#topic+checkUsage">checkUsage</a></b>, <b><a href="#topic+checkAliases">checkAliases</a></b>: you can choose which files not to read for both R and Rd. You must add in the first line of the file in comment the &quot;attribute&quot; &quot;[dont read]&quot;. Then each function will know which file to read or not. For Rd you add &quot;%[dont read]&quot; and for R &quot;#[dont read]&quot;. Finally, these functions will return in the result a list of which files had this attribute.
</p>


<h3>Value</h3>

<p><b><a href="#topic+checkNamespace">checkNamespace</a></b>: a vector with the names of missing R files. (Don't use it for now)
</p>
<p><b><a href="#topic+checkAliases">checkAliases</a></b>: a list with 4 fields.
</p>

<ul>
<li> <p><b>Missing Man files</b>: A vector with the names of the missing Rd files or nothing.
</p>
</li>
<li> <p><b>Missing R files</b>: A vector with the names of the missing R files or nothing.
</p>
</li>
<li> <p><b>Duplicate alias</b>: A vector with the names of the dublicate aliases or nothing.
</p>
</li>
<li> <p><b>dont read</b>: A list with 2 fields
</p>

<ul>
<li> <p><b>R</b>: A character vector whith the names of the files that had attribute &quot;#[dont read]&quot; or nothing.
</p>
</li>
<li> <p><b>Rd</b>: A character vector whith the names of the files that had attribute &quot;%[dont read]&quot; or nothing.
</p>
</li></ul>

</li></ul>


<p><b><a href="#topic+checkExamples">checkExamples</a></b>: a list with 3 fields 
</p>

<ul>
<li> <p><b>Errors</b>: A character vector with the names of the Rd files that produced an error.
</p>
</li>
<li> <p><b>Big Examples</b>: A character vector with the names of the Rd files that has big examples per line.
</p>
</li>
<li> <p><b>dont read</b>: A list with 2 fields
</p>

<ul>
<li> <p><b>R</b>: A character vector whith the names of the files that had attribute &quot;#[dont read]&quot; or nothing.
</p>
</li>
<li> <p><b>Rd</b>: A character vector whith the names of the files that had attribute &quot;%[dont read]&quot; or nothing.
</p>
</li></ul>

</li></ul>


<p><b><a href="#topic+checkTF">checkTF</a></b>: a list with 3 fields 
</p>

<ul>
<li> <p><b>TRUE</b>: A character vector with the names of the Rd files that has &quot;T&quot; or nothing.
</p>
</li>
<li> <p><b>FALSE</b>: A character vector with the names of the Rd files that has &quot;F&quot; or nothing.
</p>
</li>
<li> <p><b>dont read</b>: A list with 2 fields
</p>

<ul>
<li> <p><b>R</b>: A character vector whith the names of the files that had attribute &quot;#[dont read]&quot; or nothing.
</p>
</li>
<li> <p><b>Rd</b>: A character vector whith the names of the files that had attribute &quot;%[dont read]&quot; or nothing.
</p>
</li></ul>

</li></ul>


<p><b><a href="#topic+checkUsage">checkUsage</a></b>: a list with 3 fields 
</p>

<ul>
<li> <p><b>missing functions</b>: A character vector with the name of the file that is missing and the Rd file that is found or nothing.
</p>
</li>
<li> <p><b>missmatch functions</b>: A character vector with the name of the file that has missmatch function and the Rd file that is found or nothing.
</p>
</li>
<li> <p><b>dont read</b>: A list with 2 fields
</p>

<ul>
<li> <p><b>R</b>: A character vector whith the names of the files that had attribute &quot;#[dont read]&quot; or nothing.
</p>
</li>
<li> <p><b>Rd</b>: A character vector whith the names of the files that had attribute &quot;%[dont read]&quot; or nothing.
</p>
</li></ul>

</li>
<li> <p><b>hidden functions</b>: A character vector with the name of the functions thath have been declared as hidden.
</p>
</li>
<li> <p><b>usage lines wider than 90 characters</b>: A list with the Rd's that have usages that are wider than 90 characters.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.directory">read.directory</a>, <a href="#topic+AddToNamespace">AddToNamespace</a>, <a href="#topic+sourceR">sourceR</a>, <a href="#topic+sourceRd">sourceRd</a>, <a href="#topic+read.examples">read.examples</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
	#for example: path.namespace="C:\some_file\NAMESPACE"
	#for example: path.rfolder="C:\some_file\R\"
	#for example: path.man="C:\some_file\man\"
	#system.time( a&lt;-checkNamespace(path.namespace,path.rfolder) )
	#system.time( b&lt;-checkAliases(path.man,path.rfolder) )
	#system.time( b&lt;-checkExamples(path.man) )
	#system.time( b&lt;-checkExamples(path.man,2) )
	#system.time( b&lt;-checkTF(path.man) )
	#system.time( b&lt;-checkTF(path.man,path.rfolder) )

</code></pre>

<hr>
<h2 id='Check+20whether+20a+20square+20matrix+20is+20symmetric'>
Check whether a square matrix is symmetric
</h2><span id='topic+is.symmetric'></span>

<h3>Description</h3>

<p>Check whether a square matrix is symmetric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.symmetric(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Check+2B20whether+2B20a+2B20square+2B20matrix+2B20is+2B20symmetric_+3A_x">x</code></td>
<td>

<p>A square matrix with data. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of going through the whole matrix, the function will stop if the first disagreement is met. 
</p>


<h3>Value</h3>

<p>A boolean value, TRUE of FALSE.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cholesky">cholesky</a>, <a href="#topic+cora">cora</a>, <a href="#topic+cova">cova</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;-matrix( rnorm( 100 * 400), ncol = 400 )
s1 &lt;- cor(x)
is.symmetric(s1)
x &lt;- x[1:100, ]
is.symmetric(x)

x&lt;-s1&lt;-NULL
</code></pre>

<hr>
<h2 id='Chi-square+20and+20G-square+20tests+20of+20+28unconditional+29+20indepdence'>
Chi-square and G-square tests of (unconditional) indepdence
</h2><span id='topic+gchi2Test'></span>

<h3>Description</h3>

<p>Chi-square and G-square tests of (unconditional) indepdence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gchi2Test(x, y, logged = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Chi-square+2B20and+2B20G-square+2B20tests+2B20of+2B20+2B28unconditional+2B29+2B20indepdence_+3A_x">x</code></td>
<td>

<p>A numerical vector or a factor variable with data. The data must be consecutive numbers.
</p>
</td></tr>
<tr><td><code id="Chi-square+2B20and+2B20G-square+2B20tests+2B20of+2B20+2B28unconditional+2B29+2B20indepdence_+3A_y">y</code></td>
<td>

<p>A numerical vector or a factor variable with data. The data must be consecutive numbers.
</p>
</td></tr>
<tr><td><code id="Chi-square+2B20and+2B20G-square+2B20tests+2B20of+2B20+2B28unconditional+2B29+2B20indepdence_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)? 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the test statistic of the <code class="reqn">\chi^2</code> and the <code class="reqn">G^2</code> tests of unconditional 
independence between x and y. x and y need not be numerical vectors like in <code><a href="#topic+g2Test">g2Test</a></code>. This 
function is more close to the spirit of MASS' <code><a href="MASS.html#topic+loglm">loglm</a></code> function which calculates both statistics 
using Poisson log-linear models (Tsagris, 2017). 
</p>


<h3>Value</h3>

<p>A matrix with two rows. In each row the X2 or G2 test statistic, its p-value and the degrees of freedom are returned.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Michail Tsagris
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; 
and Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. (2017). Conditional independence test for categorical data using Poisson log-linear model. 
Journal of Data Science, 15(2):347-356. 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+g2Test_univariate">g2Test_univariate</a>, <a href="#topic+g2Test_univariate_perm">g2Test_univariate_perm</a>, <a href="#topic+g2Test">g2Test</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nvalues &lt;- 3
nvars &lt;- 2
nsamples &lt;- 5000
data &lt;- matrix( sample( 0:(nvalues - 1), nvars * nsamples, replace = TRUE ), nsamples, nvars )

res&lt;-gchi2Test(data[, 1], data[, 2])
res&lt;-g2Test_univariate( data, rep(3, 2) )  ## G^2 test
res&lt;-chisq.test(data[, 1], data[, 2])  ## X^2 test from R
  
data&lt;-NULL
</code></pre>

<hr>
<h2 id='Cholesky+20decomposition+20of+20a+20square+20matrix'>
Cholesky decomposition of a square matrix
</h2><span id='topic+cholesky'></span>

<h3>Description</h3>

<p>Cholesky decomposition of a square matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cholesky(x,parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cholesky+2B20decomposition+2B20of+2B20a+2B20square+2B20matrix_+3A_x">x</code></td>
<td>

<p>A square positive definite matrix.
</p>
</td></tr>
<tr><td><code id="Cholesky+2B20decomposition+2B20of+2B20a+2B20square+2B20matrix_+3A_parallel">parallel</code></td>
<td>

<p>A boolean value for parallel version.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cholesky decomposition of a square positive definite matrix is computed. The use of parallel is suggested for matrices with dimensions of 1000 or more.  
</p>


<h3>Value</h3>

<p>An upper triangular matrix.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.symmetric">is.symmetric</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(1000 * 50), ncol = 50)
s = cov(x)
a1 &lt;- cholesky(s)
#a2 &lt;- chol(s)
#all.equal(a1[upper.tri(a1)], a2[upper.tri(a2)])
x &lt;- NULL
s &lt;- NULL
a1 &lt;- NULL
a2 &lt;- NULL
</code></pre>

<hr>
<h2 id='Circular+20or+20angular+20regression'>
Circular or angular regression
</h2><span id='topic+spml.reg'></span>

<h3>Description</h3>

<p>Regression with circular dependent variable and Euclidean or categorical independent variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spml.reg(y, x, tol = 1e-07, seb = FALSE, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Circular+2B20or+2B20angular+2B20regression_+3A_y">y</code></td>
<td>

<p>The dependent variable, it can be a numerical vector with data expressed in radians or it can be a matrix with
two columns, the cosinus and the sinus of the circular data. The benefit of the matrix is that if the function 
is to be called multiple times with the same response, there is no need to transform the vector every time into 
a matrix. 
</p>
</td></tr>
<tr><td><code id="Circular+2B20or+2B20angular+2B20regression_+3A_x">x</code></td>
<td>

<p>The independent variable(s). Can be Euclidean or categorical (factor variables).
</p>
</td></tr>
<tr><td><code id="Circular+2B20or+2B20angular+2B20regression_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminatate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Circular+2B20or+2B20angular+2B20regression_+3A_seb">seb</code></td>
<td>

<p>Do you want the standard error of the estimates to be returned? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Circular+2B20or+2B20angular+2B20regression_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations to implement.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Newton-Raphson algorithm is fitted in this regression as described in Presnell et al. (1998).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required until convergence of the EM algorithm.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The regression coefficients.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The standard errors of the coefficients.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>seb</code></td>
<td>

<p>The covariance matrix of the beta values.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis
&lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>Presnell Brett, Morrison Scott P. and Littell Ramon C. (1998). Projected multivariate linear models for 
directional data. Journal of the American Statistical Association, 93(443): 1068-1077.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spml.mle">spml.mle</a>, <a href="#topic+iag.mle">iag.mle</a>, <a href="#topic+acg.mle">acg.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rnorm(100)
z &lt;- cbind(3 + 2 * x, 1 -3 * x)
y &lt;- cbind( rnorm(100,z[ ,1], 1), rnorm(100, z[ ,2], 1) )
y &lt;- y / sqrt( rowsums(y^2) )
a1 &lt;- spml.reg(y, x)
y &lt;- atan( y[, 2] / y[, 1] ) + pi * I(y[, 1] &lt; 0) 
a2 &lt;- spml.reg(y, x)

</code></pre>

<hr>
<h2 id='Circular-linear+20correlation'>
Circular-linear correlation
</h2><span id='topic+circlin.cor'></span>

<h3>Description</h3>

<p>It calculates the squared correlation between a circular and one or more linear variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>circlin.cor(theta, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Circular-linear+2B20correlation_+3A_theta">theta</code></td>
<td>

<p>A circular variable expressed in radians.
</p>
</td></tr>
<tr><td><code id="Circular-linear+2B20correlation_+3A_x">x</code></td>
<td>

<p>The linear variable or a matrix containing many linear variables.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared correlation between a circular and one or more linear variables is calculated.
</p>


<h3>Value</h3>

<p>A matrix with as many rows as linear variables including:
</p>
<table>
<tr><td><code>R-squared</code></td>
<td>

<p>The value of the squared correlation.
</p>
</td></tr>
<tr><td><code>p-value</code></td>
<td>

<p>The p-value of the zero correlation hypothesis testing.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Mardia, K. V. and Jupp, P. E. (2000). Directional statistics. Chicester: John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+spml.reg">spml.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>phi &lt;- rvonmises(50, 2, 20, rads = TRUE)
x &lt;- 2 * phi + rnorm(50)
y &lt;- matrix(rnorm(50 * 5), ncol = 5)
res&lt;-circlin.cor(phi, x)
res&lt;-circlin.cor(phi, y)
y &lt;- NULL
</code></pre>

<hr>
<h2 id='Coefficient+20matrices'>
Coefficient matrices.
</h2><span id='topic+coeff'></span>

<h3>Description</h3>

<p>Coefficient matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coeff(x, method,vector = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coefficient+2B20matrices_+3A_x">x</code></td>
<td>

<p>A matrix with data. The distances will be calculated between pairs of rows. 
In the case of <b>vecdist</b> this is a vector. 
For the <b>haversine</b> distance it must be a matrix with two columns, 
the first column is the latitude and the second the longitude. 
</p>
</td></tr>
<tr><td><code id="Coefficient+2B20matrices_+3A_method">method</code></td>
<td>

<p>See details for the available methods.
</p>
</td></tr>
<tr><td><code id="Coefficient+2B20matrices_+3A_vector">vector</code></td>
<td>

<p>For return a vector instead a matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> bhattacharyya : <code class="reqn">  \sum \sqrt(P_i * Q_i)</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A square matrix with the pairwise coefficients. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis.
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dista">dista</a>, <a href="#topic+Dist">Dist</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(50 * 10), ncol = 10)
a1 &lt;- coeff(x,"bhattacharyya")
x&lt;-a1&lt;-NULL
</code></pre>

<hr>
<h2 id='Colum-wise+20cumulative+20operations+20+28sum+2C+20prod+2C+20min+2C+20max+29'>
Colum-wise cumulative operations (sum, prod, min, max)
</h2><span id='topic+colCumSums'></span><span id='topic+colCumProds'></span><span id='topic+colCumMins'></span><span id='topic+colCumMaxs'></span>

<h3>Description</h3>

<p>Colum-wise cumulative operations (sum, prod, min, max).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colCumSums(x)
colCumProds(x)
colCumMins(x)
colCumMaxs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Colum-wise+2B20cumulative+2B20operations+2B20+2B28sum+2B2C+2B20prod+2B2C+2B20min+2B2C+2B20max+2B29_+3A_x">x</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cumulative mins, maxs, sums and prods are returned. 
</p>


<h3>Value</h3>

<p>A matrix with the results. It has one row less than the initial matrix.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Michail Tsagris
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; 
and Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colsums">colsums</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(10, 10)
res&lt;-colCumSums(x)
res&lt;-colCumMins(x)
res&lt;-colCumMaxs(x)
res&lt;-colCumProds(x)
</code></pre>

<hr>
<h2 id='Column+20and+20row+20wise+20coefficients+20of+20variation'>
Column and row wise coefficients of variation
</h2><span id='topic+colcvs'></span><span id='topic+rowcvs'></span>

<h3>Description</h3>

<p>Column and row wise coefficients of variation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colcvs(x, ln = FALSE, unbiased = FALSE) 
rowcvs(x, ln = FALSE, unbiased = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row+2B20wise+2B20coefficients+2B20of+2B20variation_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the data. 
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row+2B20wise+2B20coefficients+2B20of+2B20variation_+3A_ln">ln</code></td>
<td>

<p>If you have log-normally distributed data (or assume you do), then set this to TRUE. 
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row+2B20wise+2B20coefficients+2B20of+2B20variation_+3A_unbiased">unbiased</code></td>
<td>

<p>A boolean variable indicating whether the unbiased for shpould be returned. This is applicable in case of small samples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The colum-wise coefficients of variation are calculated.
</p>


<h3>Value</h3>

<p>A vector with the coefficient of variation for each column or row.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colsums">colsums</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- rnorm(100, 10)
x &lt;- matrix(rnorm(100 * 100, m, 1), ncol = 100)
a1 &lt;- colcvs(x)
a2 &lt;- colcvs(x[1:25, ], unbiased = TRUE)
a3 &lt;- colcvs( exp(x), ln = TRUE)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20Any+2FAll'>
Column and row-wise Any
</h2><span id='topic+colAny'></span><span id='topic+rowAny'></span><span id='topic+colAll'></span><span id='topic+rowAll'></span>

<h3>Description</h3>

<p>Column and row-wise Any/All of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colAny(x)
rowAny(x)
colAll(x, parallel = FALSE, cores = 0)
rowAll(x, parallel = FALSE, cores = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Any+2B2FAll_+3A_x">x</code></td>
<td>

<p>A logical matrix with the data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Any+2B2FAll_+3A_parallel">parallel</code></td>
<td>

<p>Do you want the computations to take place in parallel? The default value is FALSE.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Any+2B2FAll_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>A vector where item &quot;i&quot; is true if found Any/All true in column/row &quot;i&quot;. Otherwise false.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Median">Median</a>, <a href="#topic+colMedians">colMedians</a>, <a href="Matrix.html#topic+colMeans">colMeans</a> (buit-in R function)
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(as.logical(rbinom(100*100,1,0.5)),100,100)
a&lt;-colAny(x)
#b&lt;-apply(x,2,any)
#all.equal(a,b)

a&lt;-rowAny(x)
#b&lt;-apply(x,1,any)
#all.equal(a,b)

a&lt;-colAll(x)
#b&lt;-apply(x,2,all)
#all.equal(a,b)

a&lt;-b&lt;-x&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20means+20of+20a+20matrix'>
Column and row-wise means of a matrix
</h2><span id='topic+colmeans'></span><span id='topic+colmeans.matrix'></span><span id='topic+colmeans.data.frame'></span><span id='topic+rowmeans'></span><span id='topic+colhameans'></span><span id='topic+rowhameans'></span>

<h3>Description</h3>

<p>Column and row-wise means of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colmeans(x, parallel = FALSE, cores = 0)
## S3 method for class 'matrix'
colmeans(x, parallel = FALSE, cores = 0)
## S3 method for class 'data.frame'
colmeans(x, parallel = FALSE, cores = 0)
rowmeans(x)
colhameans(x, parallel = FALSE)
rowhameans(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20means+2B20of+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A numerical matrix or data.frame with data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20means+2B20of+2B20a+2B20matrix_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel in C++? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20means+2B20of+2B20a+2B20matrix_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the column or row arithmetic or harmonic means.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colsums">colsums</a>, <a href="#topic+rowsums">rowsums</a>, <a href="#topic+colMins">colMins</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colMads">colMads</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rpois(100 * 100, 10),ncol = 100)
x1 &lt;- colmeans(x)
#x2 &lt;- colMeans(x)
#all.equal(x1,x2)

x1 &lt;- rowmeans(x)
#x2 &lt;- rowMeans(x)
#all.equal(x1,x2)

colhameans(x)
rowhameans(x) 

x&lt;-x1&lt;-x2&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20medians+20of+20a+20matrix+20or+20median+20of+20a+20vector.'>
Column and row-wise medians of a matrix or median of a vector.
</h2><span id='topic+colMedians'></span><span id='topic+rowMedians'></span><span id='topic+Median'></span><span id='topic+med'></span>

<h3>Description</h3>

<p>Column and row-wise medians of a matrix or median of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colMedians(x,na.rm = FALSE, parallel = FALSE, cores = 0)
rowMedians(x,na.rm = FALSE, parallel = FALSE, cores = 0)
Median(x,na.rm=FALSE)
med(x,na.rm=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20medians+2B20of+2B20a+2B20matrix+2B20or+2B20median+2B20of+2B20a+2B20vector._+3A_x">x</code></td>
<td>

<p>A vector, matrix or data.frame with the data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20medians+2B20of+2B20a+2B20matrix+2B20or+2B20median+2B20of+2B20a+2B20vector._+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel in C++? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20medians+2B20of+2B20a+2B20matrix+2B20or+2B20median+2B20of+2B20a+2B20vector._+3A_na.rm">na.rm</code></td>
<td>

<p>TRUE or FAlSE for remove NAs if exists.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20medians+2B20of+2B20a+2B20matrix+2B20or+2B20median+2B20of+2B20a+2B20vector._+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>A vector with the column medians.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Median">Median</a>, <a href="#topic+colVars">colVars</a>, <a href="Matrix.html#topic+colMeans">colMeans</a> (buit-in R function)
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
a &lt;- apply(x, 2, median) 
b1 &lt;- colMedians(x) 
all.equal(as.vector(a), b1)

x&lt;-a&lt;-b1&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20nth+20smallest+20value+20of+20a+20matrix+2Fvector'>
Column and row-wise nth smallest value of a matrix/vector
</h2><span id='topic+colnth'></span><span id='topic+rownth'></span><span id='topic+nth'></span>

<h3>Description</h3>

<p>Column and row-wise nth smallest value of a matrix/vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colnth(x,elems, num.of.nths = 1,descending = FALSE,na.rm = FALSE,
	index.return = FALSE, parallel = FALSE, cores = 0)
rownth(x,elems, num.of.nths = 1,descending = FALSE,na.rm = FALSE,
	index.return = FALSE, parallel = FALSE, cores = 0)
nth(x, k, num.of.nths = 1,descending = FALSE,index.return = FALSE,na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_x">x</code></td>
<td>

<p>A matrix with the data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_elems">elems</code></td>
<td>

<p>An integer vector with the kth smallest number to be returned for each column/row.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_k">k</code></td>
<td>

<p>The kth smallest/biggest number to be returned. 
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_num.of.nths">num.of.nths</code></td>
<td>

<p>The number of the returned nths. By default is 1. Not use with argument parallel, for now.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_descending">descending</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for descending order (biggest number). By default is ascending (smallest number).
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_index.return">index.return</code></td>
<td>

<p>Return the index of the kth smallest/biggest number.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel in C++? TRUE or FALSE only for col-row wise.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_na.rm">na.rm</code></td>
<td>

<p>TRUE or FAlSE for remove NAs if exists. Only for function &quot;nth&quot;.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20nth+2B20smallest+2B20value+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>For &quot;colnth&quot; , &quot;rownth&quot;: A vector with the column/row nth
</p>
<p>For &quot;nth&quot;: The nth value.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Median">Median</a>, <a href="#topic+colMedians">colMedians</a>, <a href="Matrix.html#topic+colMeans">colMeans</a> (buit-in R function)
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
elems &lt;- sample(1:100,100,TRUE)
colnth(x,elems)
rownth(x,elems)
x &lt;- rnorm(1000)

nth(x, 500)
#sort(x)[500]

x&lt;-elems&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20Order+20-+20Sort+20Indices'>
Column and row-wise Order - Sort Indices
</h2><span id='topic+colOrder'></span><span id='topic+rowOrder'></span><span id='topic+Order'></span>

<h3>Description</h3>

<p>Column and row-wise Order - Sort Indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colOrder(x,stable=FALSE,descending=FALSE, parallel = FALSE, cores = 0)
rowOrder(x,stable=FALSE,descending=FALSE, parallel = FALSE, cores = 0)
Order(x,stable=FALSE,descending=FALSE,partial = NULL,parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Order+2B20-+2B20Sort+2B20Indices_+3A_x">x</code></td>
<td>

<p>A matrix with numbers or a numeric/character vector.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Order+2B20-+2B20Sort+2B20Indices_+3A_stable">stable</code></td>
<td>

<p>A boolean value for using a stable sorting algorithm. 
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Order+2B20-+2B20Sort+2B20Indices_+3A_descending">descending</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for sorting the vector in descending order. By default sorts the vector in ascending.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Order+2B20-+2B20Sort+2B20Indices_+3A_parallel">parallel</code></td>
<td>

<p>A boolean value for parallel version.
For Order, this argument is supported on Windows and most of the unix.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Order+2B20-+2B20Sort+2B20Indices_+3A_partial">partial</code></td>
<td>

<p>A boolean value for partial sorting.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Order+2B20-+2B20Sort+2B20Indices_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE column - major ordering. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function applies &quot;order&quot; in a column or row-wise fashion or Order a vector. If you want the same results as R's, then set &quot;stable=TRUE&quot; because &quot;stable=FALSE&quot; uses a sorting algorithm that it is not stable like R's sort. But it is faster to use the default. This verion is faster for large data, more than 300.
</p>


<h3>Value</h3>

<p>For &quot;colOrder&quot; and &quot;rowOrder&quot; a matrix with integer numbers. The result is the same as apply(x, 2, order) or apply(x, 1, order).
</p>
<p>For &quot;Order&quot; sort the vector and returns the indices of each element that it has before the sorting.
The result is the same as order(x) but for the same exactly results set argument &quot;stable&quot; to &quot;TRUE&quot;.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colsums">colsums</a>, <a href="#topic+coldiffs">coldiffs</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colprods">colprods</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( runif(10 * 10), ncol = 10 )
res&lt;-colOrder(x)
res&lt;-apply(x, 2, order)
res&lt;-rowOrder(x)
t(apply(x, 1, order))

y &lt;- rnorm(100)
b &lt;- Order(y)
a &lt;- order(y)
all.equal(a,b) ## false because it is not stable
b &lt;- Order(y,stable=TRUE)
all.equal(a,b) ## true because it is stable

x&lt;-y&lt;-b&lt;-a&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20products'>
Column and row-wise products
</h2><span id='topic+colprods'></span><span id='topic+rowprods'></span>

<h3>Description</h3>

<p>Column and row-wise products.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colprods(x, method = "direct")
rowprods(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20products_+3A_x">x</code></td>
<td>

<p>A matrix with numbers.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20products_+3A_method">method</code></td>
<td>

<p>The type of colCumProds to use. For direct multiplication use &quot;direct&quot; or 
&quot;expsumlog&quot; for a more numerically stable, but slower way.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The product of the numbers in a matrix is returned either column-wise or row-wise.
</p>


<h3>Value</h3>

<p>A vector with the column or the row products.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colsums">colsums</a>, <a href="#topic+coldiffs">coldiffs</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( runif(100 * 10), ncol = 10 )
res&lt;-colprods(x)
res&lt;-rowprods(x)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20range+20of+20values+20of+20a+20matrix'>
Column and row-wise range of values of a matrix.
</h2><span id='topic+colrange'></span><span id='topic+rowrange'></span>

<h3>Description</h3>

<p>Column and row-wise range of values of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colrange(x, cont = TRUE, parallel = FALSE,cores = 0)
rowrange(x, cont = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20range+2B20of+2B20values+2B20of+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A numerical matrix or data.frame with data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20range+2B20of+2B20values+2B20of+2B20a+2B20matrix_+3A_parallel">parallel</code></td>
<td>

<p>Execute algorithm in parallel for data.frame.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20range+2B20of+2B20values+2B20of+2B20a+2B20matrix_+3A_cont">cont</code></td>
<td>

<p>If the data are continuous, leave this TRUE and it will return the range of values for each variable (column). If the data are integers, categorical, or if you want 
to find out the number of unique numbers in each column set this to FALSE.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20range+2B20of+2B20values+2B20of+2B20a+2B20matrix_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the relevant values.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colMins">colMins</a>, <a href="#topic+colMaxs">colMaxs</a>, <a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowMaxs">rowMaxs</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )

a1 &lt;- colrange(x) 
a2 &lt;- apply(x, 2, function(x) diff( range(x)) ) 
all.equal(a1, a2)

a1 &lt;- rowrange(x) 
a2 &lt;- apply(x, 1, function(x) diff( range(x)) ) 
all.equal(a1, a2)

x&lt;-a1&lt;-a2&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20ranks'>
Column and row-wise ranks
</h2><span id='topic+colRanks'></span><span id='topic+rowRanks'></span><span id='topic+Rank'></span>

<h3>Description</h3>

<p>Column and row-wise ranks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colRanks(x,method = "average",descending = FALSE,
     stable = FALSE, parallel = FALSE, cores = 0)
rowRanks(x,method = "average",descending = FALSE,
     stable = FALSE, parallel = FALSE, cores = 0)
Rank(x,method = "average",descending = FALSE,stable = FALSE, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20ranks_+3A_x">x</code></td>
<td>

<p>A mumerical matrix or data.frame with the data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20ranks_+3A_parallel">parallel</code></td>
<td>

<p>A boolean value for parallel version.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20ranks_+3A_method">method</code></td>
<td>

<p>a character string for choosing method. Must be one of:
</p>

<ul>
<li><p> average : a permutation with theri mean values at each index set of ties
</p>
</li>
<li><p> min : a permutation with minimum values at each index set of ties
</p>
</li>
<li><p> max : a permutation with maximum values at each index set of ties
</p>
</li>
<li><p> first : a permutation with increasing values at each index set of ties
</p>
</li>
<li><p> random : a permutation with random values at each index set of ties
</p>
</li></ul>

</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20ranks_+3A_descending">descending</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for sorting the vector in descending order. By default sorts the vector in ascending.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20ranks_+3A_stable">stable</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for choosing a stable sort algorithm. Stable means that discriminates on the same elements. Only for the method &quot;first&quot;.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20ranks_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each column or row of a matrix the ranks are calculated and they are returned. 
</p>


<h3>Value</h3>

<p>A matrix with the column or row-wise ranks.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rank">Rank</a>, <a href="#topic+correls">correls</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 10)
a1 &lt;- colRanks(x)
a2 &lt;- apply(x, 2, rank)
b1 &lt;- rowRanks(x)
b2 &lt;- apply(x, 1, rank)

a1 &lt;- Rank(x[,1])
a1 &lt;- rank(x[,1])

x&lt;-a1&lt;-a2&lt;-b1&lt;-b2&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20Shuffle'>
Column and row-wise Shuffle
</h2><span id='topic+colShuffle'></span><span id='topic+rowShuffle'></span>

<h3>Description</h3>

<p>Column and row-wise shuffle of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colShuffle(x)
rowShuffle(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20Shuffle_+3A_x">x</code></td>
<td>

<p>A matrix or data.frame with the data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>A vector with the column/row Shuffle.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Median">Median</a>, <a href="#topic+colVars">colVars</a>, <a href="Matrix.html#topic+colMeans">colMeans</a> (buit-in R function)
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
colShuffle(x)
rowShuffle(x)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20sums+20of+20a+20matrix'>
Column and row-wise sums of a matrix
</h2><span id='topic+colsums'></span><span id='topic+rowsums'></span>

<h3>Description</h3>

<p>Column and row-wise sums of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colsums(x,indices = NULL, parallel = FALSE, na.rm = FALSE, cores = 0)
rowsums(x,indices = NULL, parallel = FALSE, na.rm = FALSE, cores = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20sums+2B20of+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A numerical matrix with data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20sums+2B20of+2B20a+2B20matrix_+3A_indices">indices</code></td>
<td>

<p>An integer vector with the indices to sum the columns/rows.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20sums+2B20of+2B20a+2B20matrix_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel in C++? TRUE or FALSE. Doens't work with argument &quot;indices&quot;.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20sums+2B20of+2B20a+2B20matrix_+3A_na.rm">na.rm</code></td>
<td>

<p>A logical value indicating to remove NAs. The algorithm run in parallel so do not use with option parallel.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20sums+2B20of+2B20a+2B20matrix_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with sums.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colMedians">colMedians</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rpois(500 * 100, 10),ncol = 100)
x1 &lt;- colsums(x)
x2 &lt;- colSums(x)
all.equal(x1,x2)

x1 &lt;- rowsums(x)
x2 &lt;- rowSums(x)
all.equal(x1,x2)

x&lt;-x1&lt;-x2&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20tabulate'>
Column and row-wise tabulate
</h2><span id='topic+colTabulate'></span><span id='topic+rowTabulate'></span>

<h3>Description</h3>

<p>Column and row-wise tabulate of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colTabulate(x, max_number = max(x))
rowTabulate(x, max_number = max(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20tabulate_+3A_x">x</code></td>
<td>

<p>An integer matrix with the data. The numbers must start from 1, i.e. 1, 2, 3, 4,... No zeros are allowed. Anything else may cause a crash.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20tabulate_+3A_max_number">max_number</code></td>
<td>

<p>The maximum value of vector x. If you know which is the max number use this argument for faster results or by default max(x). 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>A matrix where in each column the command &quot;tabulate&quot; has been performed. The number of rows of the returned matrix will be equal to the max_number if given. Otherwise, the functions
will find this number. 
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colShuffle">colShuffle</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rbinom(100 * 100, 4, 0.5), ncol = 100 )
colTabulate(x)
rowTabulate(x)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20row-wise+20variances+20and+20standard+20deviations'>
Column and row-wise variances and standard deviations of a matrix
</h2><span id='topic+colVars'></span><span id='topic+colVars.matrix'></span><span id='topic+colVars.data.frame'></span><span id='topic+rowVars'></span>

<h3>Description</h3>

<p>Column and row-wise variances and standard deviations of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'matrix'
colVars(x, std = FALSE, na.rm = FALSE, parallel = FALSE, cores = 0)
## S3 method for class 'data.frame'
colVars(x, std = FALSE, na.rm = FALSE, parallel = FALSE, cores = 0)
colVars(x, std = FALSE, na.rm = FALSE, parallel = FALSE, cores = 0)
rowVars(x, std = FALSE, na.rm = FALSE, parallel = FALSE, cores = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20variances+2B20and+2B20standard+2B20deviations_+3A_x">x</code></td>
<td>

<p>A matrix with the data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20variances+2B20and+2B20standard+2B20deviations_+3A_std">std</code></td>
<td>

<p>A boolean variable specyfying whether you want the variances (FALSE) 
or the standard deviations (TRUE) of each column.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20variances+2B20and+2B20standard+2B20deviations_+3A_na.rm">na.rm</code></td>
<td>

<p>TRUE or FAlSE for remove NAs if exists.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20variances+2B20and+2B20standard+2B20deviations_+3A_parallel">parallel</code></td>
<td>

<p>Should parallel implentations take place in C++? The default value is FALSE.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20row-wise+2B20variances+2B20and+2B20standard+2B20deviations_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We found this on stackoverflow which was created by David Arenburg. We then modified the function to match the sums type formula of the variance, which is faster.
</p>


<h3>Value</h3>

<p>A vector with the column variances or standard deviations.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colrange">colrange</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
a2 &lt;- colVars(x)
x&lt;-a2&lt;-NULL
</code></pre>

<hr>
<h2 id='Column+20and+20rows-wise+20mean+20absolute+20deviations'>
Column and row-wise mean absolute deviations
</h2><span id='topic+colMads'></span><span id='topic+rowMads'></span><span id='topic+Mad'></span>

<h3>Description</h3>

<p>Column and row-wise mean absolute deviations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colMads(x,method = "median",na.rm=FALSE,parallel = FALSE, cores = 0)
rowMads(x,method = "median",na.rm=FALSE,parallel = FALSE, cores = 0)
Mad(x,method = "median",na.rm=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column+2B20and+2B20rows-wise+2B20mean+2B20absolute+2B20deviations_+3A_x">x</code></td>
<td>

<p>A vector, matrix or data.frame with the data.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20rows-wise+2B20mean+2B20absolute+2B20deviations_+3A_method">method</code></td>
<td>

<p>A character vector with values &quot;median&quot;, for median absolute deviation or &quot;mean&quot;, for mean absolute deviation. 
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20rows-wise+2B20mean+2B20absolute+2B20deviations_+3A_na.rm">na.rm</code></td>
<td>

<p>A logical value TRUE/FALSE to remove NAs.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20rows-wise+2B20mean+2B20absolute+2B20deviations_+3A_parallel">parallel</code></td>
<td>

<p>A boolean value for parallel version.
</p>
</td></tr>
<tr><td><code id="Column+2B20and+2B20rows-wise+2B20mean+2B20absolute+2B20deviations_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>A vector with the column-wise mean absolute deviations.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colMedians">colMedians</a>, <a href="#topic+rowMedians">rowMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="Matrix.html#topic+colMeans">colMeans</a> (buit-in R function)
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
a &lt;- colMads(x)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Column-wise+20differences'>
Column-wise differences
</h2><span id='topic+coldiffs'></span>

<h3>Description</h3>

<p>Column-wise differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coldiffs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20differences_+3A_x">x</code></td>
<td>

<p>A matrix with numbers.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simply does this function x[, -1] - x[, -k], where k is the last column of the matrix x. But it does it a lot faster. 
That is, 2nd column - 1st column, 3rd column - 2nd column, and so on.
</p>


<h3>Value</h3>

<p>A matrix with one column less containing the differences between the successive columns. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+Dist">Dist</a>, <a href="#topic+dista">dista</a>, <a href="#topic+colmeans">colmeans</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(50 * 10), ncol = 10 )
res&lt;-coldiffs(x)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Column-wise+20kurtosis+20and+20skewness+20coefficients'>
Column-wise kurtosis and skewness coefficients
</h2><span id='topic+colkurtosis'></span><span id='topic+colskewness'></span>

<h3>Description</h3>

<p>Column-wise kurtosis and skewness coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colkurtosis(x, pvalue = FALSE)

colskewness(x, pvalue = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20kurtosis+2B20and+2B20skewness+2B20coefficients_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20kurtosis+2B20and+2B20skewness+2B20coefficients_+3A_pvalue">pvalue</code></td>
<td>

<p>If you want a hypothesis test that the skewness or kurtosis are significant set this to TRUE. This checks
whether the skewness is significantly different from 0 and whether the kurtosis is significantly different from
3.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The skewness and kurtosis coefficients are calculated. For the skewness coefficient we use the sample 
unbiased version of the standard deviation. For the kurtosis, we do not subtract 3. 
</p>


<h3>Value</h3>

<p>If &quot;pvalue&quot; is FALSE, a vector with the relevant coefficient. Otherwise a matrix with two columns. 
The kurtosis or skewness coefficient and the p-value from the hypothesis test that they are significantly different
from 3 or 0 respectively.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+skew">skew</a>, <a href="#topic+skew.test2">skew.test2</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+sftests">sftests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 200 variables, hence 200 F-tests will be performed
x = matrix( rnorm(200 * 50), ncol = 50 )
## 200 observations in total
colkurtosis(x)
colskewness(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Column-wise+20matching+20coefficients'>
Column-wise matching coefficients
</h2><span id='topic+match.coefs'></span>

<h3>Description</h3>

<p>Column-wise matching coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>match.coefs(x, y = NULL, ina, type = "jacc") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20matching+2B20coefficients_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20matching+2B20coefficients_+3A_y">y</code></td>
<td>

<p>A second matrix with the data of the second group. If this is NULL (default value) then the argument ina must be 
supplied. Notice that when you supply the two matrices the procedure is two times faster.
</p>
</td></tr> 
<tr><td><code id="Column-wise+2B20matching+2B20coefficients_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s and 2s indicating the two groups. Be careful, the function is designed to accept only
these two numbers. In addition, if your &quot;y&quot; is NULL, you must specify &quot;ina&quot;.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20matching+2B20coefficients_+3A_type">type</code></td>
<td>

<p>This denotes the type of matching coefficient to calculate. For the Jaccard index put &quot;jacc&quot;. For the simple 
matching coefficient put &quot;smc&quot; or else both of them will be calculated. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two matrices are given as imput and for each column matching coefficients are calculated, either the Jaccard or 
the simple matching coefficient or both.  
</p>


<h3>Value</h3>

<p>A matrix with one or two columns, depending on the type you have specified. If you specify &quot;both&quot;, there will be
two columns, if you specify &quot;jacc&quot; or &quot;smc&quot; then just one column.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+odds">odds</a>, <a href="#topic+colTabulate">colTabulate</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rbinom(400 * 10, 1, 0.5), ncol = 10)
y &lt;- matrix(rbinom(400 * 10, 1, 0.5), ncol = 10)
a &lt;- match.coefs(x, y, type = "both")
x &lt;- NULL
y &lt;- NULL
</code></pre>

<hr>
<h2 id='Column-wise+20minimum+20and+20maximum+20'>
Column-wise minimum and maximum of a matrix
</h2><span id='topic+colMins'></span><span id='topic+colMaxs'></span><span id='topic+colMinsMaxs'></span>

<h3>Description</h3>

<p>Column-wise minimum and maximum of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colMins(x, value = FALSE, parallel = FALSE, cores = 0)
colMaxs(x, value = FALSE, parallel = FALSE, cores = 0)
colMinsMaxs(x, parallel = FALSE, cores = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20minimum+2B20and+2B20maximum+2B20_+3A_x">x</code></td>
<td>

<p>A numerical matrix or data.frame with data.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20minimum+2B20and+2B20maximum+2B20_+3A_value">value</code></td>
<td>

<p>If the value is FALSE it returns the indices of the minimum/maximum, otherwise it returns the minimum and maximum values.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20minimum+2B20and+2B20maximum+2B20_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel in C++? TRUE or FALSE. The parallel will return the minimum/maximum value only. It will never return the indices.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20minimum+2B20and+2B20maximum+2B20_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the relevant values.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowMaxs">rowMaxs</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 200), ncol = 200 )

s1 &lt;- colMins(x) 
s2 &lt;- apply(x, 2, min) 

s1 &lt;- colMaxs(x) 
s2 &lt;- apply(x, 2, max) 

s1 &lt;- colMinsMaxs(x)
s2 &lt;- c(apply(x, 2, min), apply(x, 2, max)) 

x&lt;-s1&lt;-s2&lt;-NULL
</code></pre>

<hr>
<h2 id='Column-wise+20MLE+20of+20some+20univariate+20distributions'>
Column-wise MLE of some univariate distributions
</h2><span id='topic+colexpmle'></span><span id='topic+colexp2.mle'></span><span id='topic+colgammamle'></span><span id='topic+colinvgauss.mle'></span><span id='topic+collaplace.mle'></span><span id='topic+collindley.mle'></span><span id='topic+colmaxboltz.mle'></span><span id='topic+colnormal.mle'></span><span id='topic+colpareto.mle'></span><span id='topic+colrayleigh.mle'></span><span id='topic+colvm.mle'></span><span id='topic+colweibull.mle'></span><span id='topic+colnormlog.mle'></span>

<h3>Description</h3>

<p>Column-wise MLE of some univariate distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colexpmle(x)
colexp2.mle(x)
colgammamle(x, tol = 1e-07)
colinvgauss.mle(x)
collaplace.mle(x)
collindley.mle(x)
colmaxboltz.mle(x)
colnormal.mle(x)
colpareto.mle(x)
colrayleigh.mle(x)
colvm.mle(x, tol = 1e-07)
colweibull.mle(x, tol = 1e-09, maxiters = 100, parallel = FALSE)
colnormlog.mle(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_x">x</code></td>
<td>

<p>A numerical matrix with data. Each column refers to a different vector of observations of the same distribution.
For exponential, 2 parameter exponential, Weibull, gamma, inverse Gaussian, Maxwell-Boltzman, Lindley, Rayleigh and Pareto
distributions, the numbers must be greater than zero. For the Poisson and geometric distributions, the numbers
must be integers, 0, 1, 2,... For the Normal and Laplace distribution the numbers can take any value. The von
Mises distribution takes values beween 0 and 2 * pi (radians).
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Fisher algorithm.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations to implement.
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20MLE+2B20of+2B20some+2B20univariate+2B20distributions_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to calculations to take place in parallel? The default value is FALSE
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each column, the same distribution is fitted and its parameter and log-likelihood are computed.
</p>


<h3>Value</h3>

<p>A matrix with two, three or five (for the colnormlog.mle) columns. The first one or the first two contain the parameter(s) of the distribution
and the other columns contain the log-likelihood values.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Stefanos Fafalios
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Stefanos Fafalios
&lt;stefanosfafalios@gmail.com&gt;
</p>


<h3>References</h3>

<p>Kalimuthu Krishnamoorthy, Meesook Lee and Wang Xiao (2015). Likelihood ratio tests for comparing several
gamma distributions. Environmetrics, 26(8):571-583.
</p>
<p>N.L. Johnson, S. Kotz and N. Balakrishnan (1994). Continuous Univariate Distributions, Volume 1 (2nd Edition).
</p>
<p>N.L. Johnson, S. Kotz and N. Balakrishnan (1970). Distributions in statistics: continuous univariate distributions,
Volume 2.
</p>
<p>Sharma V. K., Singh S. K., Singh U. and Agiwal V. (2015). The inverse Lindley distribution: a stress-strength
reliability model with application to head and neck cancer data. Journal of Industrial and Production
Engineering, 32(3): 162-173.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vm.mle">vm.mle</a>, <a href="#topic+poisson.mle">poisson.mle</a>, <a href="#topic+normal.mle">normal.mle</a>, <a href="#topic+gammamle">gammamle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(1000 * 50), ncol = 50)
a &lt;- colnormal.mle(x)
b &lt;- collaplace.mle(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Column-wise+20true+2Ffalse+20value+20'>
Column-wise true/false value of a matrix
</h2><span id='topic+colTrue'></span><span id='topic+colFalse'></span><span id='topic+colTrueFalse'></span>

<h3>Description</h3>

<p>Column-wise true/false value of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colTrue(x)
colFalse(x)
colTrueFalse(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20true+2B2Ffalse+2B20value+2B20_+3A_x">x</code></td>
<td>

<p>A logical matrix with data.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer vector where item &quot;i&quot; is the number of the true/false values of &quot;i&quot; column.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowFalse">rowFalse</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>, <a href="#topic+rowTrue">rowTrue</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(as.logical(rbinom(100*100,1,0.5)),100,100)

s1 &lt;- colTrue(x) 

s1 &lt;- colFalse(x)  

s1 &lt;- colTrueFalse(x)

x&lt;-s1&lt;-NULL
</code></pre>

<hr>
<h2 id='Column-wise+20uniformity+20Watson+20test+20for+20circular+20data'>
Column-wise uniformity tests for circular data
</h2><span id='topic+colwatsons'></span>

<h3>Description</h3>

<p>Column-wise uniformity tests for circular data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colwatsons(u)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20uniformity+2B20Watson+2B20test+2B20for+2B20circular+2B20data_+3A_u">u</code></td>
<td>

<p>A numeric matrix containing the circular data which are expressed in radians. Each column is a different sample.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These tests are used to test the hypothesis that the data come from a circular uniform distribution. 
The Kuiper test is much more time consuming and this is why it not implemented yet. Once we figure out a way to
make it fast, we will incldue it. 
</p>


<h3>Value</h3>

<p>A matrix with two columns, the value of the test statistic and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Jammalamadaka, S. Rao and SenGupta, A. (2001). Topics in Circular Statistics, pg. 153-55 (Kuiper's test) &amp; 
156-157 (Watson's test).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+watson">watson</a>, <a href="#topic+vmf.mle">vmf.mle</a>, <a href="#topic+rvonmises">rvonmises</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rvonmises(n = 50 * 10, m = 2, k = 0), ncol = 10 )
res&lt;-colwatsons(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Column-wise+20Yule+27s+20Y+20+28coefficient+20of+20colligation+29'>
Column-wise Yule's Y (coefficient of colligation)
</h2><span id='topic+col.yule'></span>

<h3>Description</h3>

<p>Column-wise Yule's Y (coefficient of colligation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>col.yule(x, y = NULL, ina)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Column-wise+2B20Yule+2B27s+2B20Y+2B20+2B28coefficient+2B20of+2B20colligation+2B29_+3A_x">x</code></td>
<td>

<p>A matrix with 0 and 1. Every column refers to a different sample or variable. 
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20Yule+2B27s+2B20Y+2B20+2B28coefficient+2B20of+2B20colligation+2B29_+3A_y">y</code></td>
<td>

<p>A second matrix, of the same dimensions as x, with 0 and 1. Every column refers to a different sample or variable. 
</p>
</td></tr>
<tr><td><code id="Column-wise+2B20Yule+2B27s+2B20Y+2B20+2B28coefficient+2B20of+2B20colligation+2B29_+3A_ina">ina</code></td>
<td>

<p>If y is NULL, ina must be specified. This is a numeric vector with 1s and 2s, indicating the group of each row.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yule's coefficient of colligation is calculated for every column.
</p>


<h3>Value</h3>

<p>A vector with Yule's Y, one for every column of x is returned.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Yule G. Udny (1912). On the Methods of Measuring Association Between Two Attributes. 
Journal of the Royal Statistical Society, 75(6):579-652.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+yule">yule</a>, <a href="#topic+odds">odds</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rbinom(300 * 10, 1, 0.5), ncol = 10)
ina &lt;- rep(1:2, each = 150)
res&lt;-col.yule( x, ina = ina )
</code></pre>

<hr>
<h2 id='Convert+20a+20dataframe+20to+20matrix'>
Convert a dataframe to matrix
</h2><span id='topic+data.frame.to_matrix'></span>

<h3>Description</h3>

<p>Convert a dataframe to matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.frame.to_matrix(x,col.names = NULL,row.names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Convert+2B20a+2B20dataframe+2B20to+2B20matrix_+3A_x">x</code></td>
<td>

<p>A Numeric matrix with data and NAs.
</p>
</td></tr>
<tr><td><code id="Convert+2B20a+2B20dataframe+2B20to+2B20matrix_+3A_col.names">col.names</code></td>
<td>

<p>A boolean value for keeping the colnames for argument x or a character vector for the new colnames.
</p>
</td></tr>
<tr><td><code id="Convert+2B20a+2B20dataframe+2B20to+2B20matrix_+3A_row.names">row.names</code></td>
<td>

<p>A boolean value for keeping the rownames for argument x or a character vector for the new rownames.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions converts a dataframe to matrix. Even if there are factors, the function converts them into numerical values. Attributes are not allowed for now.
</p>


<h3>Value</h3>

<p>A matrix wich has the numrical values from the dataframe.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Match">Match</a>, <a href="#topic+is.symmetric">is.symmetric</a>, <a href="#topic+permutation">permutation</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res&lt;-data.frame.to_matrix(iris)
</code></pre>

<hr>
<h2 id='Convert+20R+20function+20to+20the+20Rfast+27s+20coresponding'>
Convert R function to the Rfast's coresponding
</h2><span id='topic+as.Rfast.function'></span>

<h3>Description</h3>

<p>Convert R function to the Rfast's coresponding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.Rfast.function(Rfunction.name,margin=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Convert+2B20R+2B20function+2B20to+2B20the+2B20Rfast+2B27s+2B20coresponding_+3A_rfunction.name">Rfunction.name</code></td>
<td>

<p>An character value with the name of the function.
</p>
</td></tr>
<tr><td><code id="Convert+2B20R+2B20function+2B20to+2B20the+2B20Rfast+2B27s+2B20coresponding_+3A_margin">margin</code></td>
<td>

<p>A logical function for return the column-row wise function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the name of R function, it returns the coresponding function's name from Rfast.
</p>


<h3>Value</h3>

<p>The coresponding Rfast function.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Michail Tsagris
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; 
and Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colsums">colsums</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
res&lt;-as.Rfast.function("var")

</code></pre>

<hr>
<h2 id='Correlation+20based+20forward+20regression'>
Correlation based forward regression.
</h2><span id='topic+cor.fsreg'></span>

<h3>Description</h3>

<p>Correlation based forward regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.fsreg(y, x, ystand = TRUE, xstand = TRUE, threshold = 0.05, 
tolb = 2, tolr = 0.02, stopping = "BIC") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_y">y</code></td>
<td>

<p>A numerical vector.
</p>
</td></tr>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_x">x</code></td>
<td>

<p>A matrix with data, the predictor variables. 
</p>
</td></tr>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_ystand">ystand</code></td>
<td>

<p>If this is TRUE the response variable is centered. The mean is subtracted from every value.
</p>
</td></tr>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_xstand">xstand</code></td>
<td>

<p>If this is TRUE the independent variables are standardised. 
</p>
</td></tr>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_threshold">threshold</code></td>
<td>

<p>The significance level, set to 0.05 by default. Bear in mind that the logarithm of it is used, as the 
logarithm of the p-values is calculated at every point. This will avoid numerical overflows and
small p-values, less than the machine epsilon, being returned as zero.
</p>
</td></tr>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_tolb">tolb</code></td>
<td>

<p>If we see only the significane of the variables, many may enter the linear regression model. For this reason, 
we also use the BIC as a way to validate the inclusion of a candidate variable. If the BIC difference between 
two successive models is less than the tolerance value, the variable will not enter the model, even if it 
statistically significant. Set it to 0 if you do not want this extra check. 
</p>
</td></tr>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_tolr">tolr</code></td>
<td>

<p>This is an alternative to the BIC change and it uses the adjusted coefficient of determination. If the increase in the 
adjusted <code class="reqn">R^2</code> is more than the tolr continue.
</p>
</td></tr>
<tr><td><code id="Correlation+2B20based+2B20forward+2B20regression_+3A_stopping">stopping</code></td>
<td>

<p>This refers to the type of extra checking to do. If you want the BIC check, set it to &quot;BIC&quot;. If you want the adjusted <code class="reqn">R^2</code> check 
set this to &quot;ar2&quot;. Or, if you want both of them to take place, both of these criteria to be satisfied make this &quot;BICR2&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The forward regression tries one by one the variables using the F-test, basically partial F-test every time for 
the latest variable. This is the same as testing the significance of the coefficient of this latest enetered 
variable. Alternatively the correlation can be used and this case the partial correlation coefficient. There is 
a direct relationship between the t-test statistic and the partial correlation coefficient. Now, instead of 
having to calculate the test statistic, we calculate the partial correlation coefficient. Using Fisher's 
z-transform we get the variance imediately. The partial correlation coefficient, using Fisher's z-transform, 
and the partial F-test (or the coefficient's t-test statistic) are not identical. They will be identical for 
large sample sizes though.
</p>


<h3>Value</h3>

<p>A matrix with three columns, the index of the selected variables, the logged p-value and the the test 
statistic value and the BIC or adjusted <code class="reqn">R^2</code> of each model. In the case of stopping=&quot;BICR2&quot; both of 
these criteria will be returned.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Draper, N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+score.glms">score.glms</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+logistic_only">logistic_only</a>,  <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 200 variables, hence 200 univariate regressions are to be fitted
x &lt;- matrnorm(200,  100)
y &lt;- rnorm(200)
cor.fsreg(y, x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Correlation+20between+20pairs+20of+20variables'>
Correlation between pairs of variables
</h2><span id='topic+corpairs'></span>

<h3>Description</h3>

<p>Correlations between pairs of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corpairs(x, y, rho = NULL, logged = FALSE, parallel = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Correlation+2B20between+2B20pairs+2B20of+2B20variables_+3A_x">x</code></td>
<td>

<p>A matrix with real valued data.
</p>
</td></tr>
<tr><td><code id="Correlation+2B20between+2B20pairs+2B20of+2B20variables_+3A_y">y</code></td>
<td>

<p>A matrix with real valued data whose dimensions match those of x.
</p>
</td></tr>
<tr><td><code id="Correlation+2B20between+2B20pairs+2B20of+2B20variables_+3A_rho">rho</code></td>
<td>

<p>This can be a vector of assumed correlations (equal to the number of variables or the columns of x or y) to 
be tested. If this is not the case, leave it NULL and only the correlations will be returned.
</p>
</td></tr>
<tr><td><code id="Correlation+2B20between+2B20pairs+2B20of+2B20variables_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)? This is taken into account only if &quot;rho&quot; is 
a vector. 
</p>
</td></tr>
<tr><td><code id="Correlation+2B20between+2B20pairs+2B20of+2B20variables_+3A_parallel">parallel</code></td>
<td>

<p>Should parallel implentations take place in C++? The default value is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The paired correlations are calculated. For each column of the matrices x and y the correlation between them is 
calculated.
</p>


<h3>Value</h3>

<p>A vector of correlations in the case of &quot;rho&quot; being NULL, or a matrix with two extra columns, the test 
statistic and the (logged) p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Lambert Diane (1992). Zero-Inflated Poisson Regression, with an Application to Defects in 
Manufacturing. Technometrics. 34(1):1-14.
</p>
<p>Johnson Norman L., Kotz Samuel and Kemp Adrienne W. (1992). Univariate Discrete 
Distributions (2nd ed.). Wiley
</p>
<p>Cohen, A. Clifford (1960). Estimating parameters in a conditional Poisson distribution. Biometrics. 16:203-211.
</p>
<p>Johnson, Norman L. Kemp, Adrianne W. Kotz, Samuel (2005). Univariate Discrete Distributions (third edition). 
Hoboken, NJ: Wiley-Interscience.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+correls">correls</a>, <a href="#topic+allbetas">allbetas</a>, <a href="#topic+mvbetas">mvbetas</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 100)
y &lt;- matrnorm(100, 100)
corpairs(x, y)
a &lt;- corpairs(x, y)
x &lt;- NULL
y &lt;- NULL
</code></pre>

<hr>
<h2 id='Correlations'>
Correlation between a vector and a set of variables
</h2><span id='topic+correls'></span><span id='topic+groupcorrels'></span>

<h3>Description</h3>

<p>Correlation between a vector and a set of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correls(y, x, type = "pearson", a = 0.05, rho = 0)
groupcorrels(y, x, type = "pearson", ina)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Correlations_+3A_y">y</code></td>
<td>

<p>A numerical vector.
</p>
</td></tr>
<tr><td><code id="Correlations_+3A_x">x</code></td>
<td>

<p>A matrix with the data.
</p>
</td></tr>
<tr><td><code id="Correlations_+3A_type">type</code></td>
<td>

<p>The type of correlation you want. &quot;pearson&quot; and &quot;spearman&quot; are the two supported types for the &quot;correls&quot; because their standard error is easily calculated. For the &quot;groupcorrels&quot; you can also put &quot;kendall&quot; because no hypothesis test is performed in that function.
</p>
</td></tr>
<tr><td><code id="Correlations_+3A_a">a</code></td>
<td>

<p>The significance level used for the confidence intervals.
</p>
</td></tr>
<tr><td><code id="Correlations_+3A_rho">rho</code></td>
<td>

<p>The value of the hypothesised correlation to be used in the hypothesis testing.
</p>
</td></tr>
<tr><td><code id="Correlations_+3A_ina">ina</code></td>
<td>

<p>A factor variable or a numeric variable idicating the group of each observation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions uses the built-in function &quot;cor&quot; which is very fast and then includes confidence intervals and produces a p-value for the hypothesis test. 
</p>


<h3>Value</h3>

<p>For the &quot;correls&quot; a matrix with 5 column; the correlation, the p-value for the hypothesis test that each of them is eaqual to &quot;rho&quot;, the test statistic and the $a/2%$ lower and upper confidence limits.
</p>
<p>For the &quot;groupcorrels&quot; a matrix with rows equal to the number of groups and columns equal to the number of columns of x. The matrix contains the correlations only, no statistical hypothesis test is performed.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+allbetas">allbetas</a>, <a href="#topic+univglms">univglms</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(60, 100 )
y &lt;- rnorm(60)
r &lt;- cor(y, x)  ## correlation of y with each of the xs
a &lt;- allbetas(y, x)  ## the coefficients of each simple linear regression of y with x
b &lt;- correls(y, x)
ina &lt;- rep(1:2, each = 30)
b2 &lt;- groupcorrels(y, x, ina = ina) 
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Covariance+20and+20correlation+20matrix'>
Fast covariance and correlation matrix calculation
</h2><span id='topic+cova'></span><span id='topic+cora'></span>

<h3>Description</h3>

<p>Fast covariance and correlation matrix calculation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cova(x, center = FALSE, large = FALSE)

cora(x, large = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Covariance+2B20and+2B20correlation+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with data. It has to be matrix, if it is data.frame for example the function does not turn it into a matrix.
</p>
</td></tr>
<tr><td><code id="Covariance+2B20and+2B20correlation+2B20matrix_+3A_center">center</code></td>
<td>

<p>If you want to center the data prior to applying the cross product of the mateix set this equal to TRUE, otherwise leave it NULL.
</p>
</td></tr>
<tr><td><code id="Covariance+2B20and+2B20correlation+2B20matrix_+3A_large">large</code></td>
<td>

<p>If you have large matrices, with thousands of rows and or many tens or hundreds of columns set this equal to TRUE in 
order to use Rfast's <code><a href="#topic+Crossprod">Crossprod</a></code> or <code><a href="#topic+Tcrossprod">Tcrossprod</a></code> functions. These functions are twice or up to
3 times faster than the correpsonding built-in functions. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculations take place faster than the built-in functions <code><a href="stats.html#topic+cor">cor</a></code> 
as the number of variables increases. This is true if the number of variables is high, 
say from 500 and above. The &quot;cova&quot; on the other hand is always faster. For the &quot;cova&quot; in specific, 
we have an option to center the data prior to the cross product. This can be more stable if you 
have many tens of thousands of rows due to numerical issues that can arise. 
</p>
<p>For the correlation matrix we took the code from here
</p>
<p>https://stackoverflow.com/questions/18964837/fast-correlation-in-r-using-c-and-parallelization/18965892#18965892
</p>


<h3>Value</h3>

<p>The covariance or the correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colVars">colVars</a>, <a href="stats.html#topic+cor">cor</a>, <a href="stats.html#topic+cov">cov</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 40)
s1 &lt;- cov(x) 
s2 &lt;- cova(x)
all.equal(s1, s2)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Cox+20confidence+20interval+20for+20the+20ratio+20of+20two+20Poisson+20variables'>
Cox confidence interval for the ratio of two Poisson variables
</h2><span id='topic+cox.poisrat'></span><span id='topic+col.coxpoisrat'></span>

<h3>Description</h3>

<p>Cox confidence interval for the ratio of two Poisson variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cox.poisrat(x, y, alpha = 0.05)
col.coxpoisrat(x, y, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cox+2B20confidence+2B20interval+2B20for+2B20the+2B20ratio+2B20of+2B20two+2B20Poisson+2B20variables_+3A_x">x</code></td>
<td>

<p>A numeric vector or a matrix with count data.
</p>
</td></tr>
<tr><td><code id="Cox+2B20confidence+2B20interval+2B20for+2B20the+2B20ratio+2B20of+2B20two+2B20Poisson+2B20variables_+3A_y">y</code></td>
<td>

<p>A numeric vector or a matrix with count data.
</p>
</td></tr>
<tr><td><code id="Cox+2B20confidence+2B20interval+2B20for+2B20the+2B20ratio+2B20of+2B20two+2B20Poisson+2B20variables_+3A_alpha">alpha</code></td>
<td>

<p>The 1 - confidence level. The default value is 0.05.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cox confidence interval for the ratio of two Poisson means is calculated. 
</p>


<h3>Value</h3>

<p>For the cox.poisrat a vector with three elements, the ratio and the lower and upper confidence interval limits.
For the col.coxpoisrat a matrix with three columns, the ratio and the lower and upper confidence interval limits.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;
</p>


<h3>References</h3>

<p>Krishnamoorthy K., Peng J. and Zhang D. (2016). Modified large sample confidence intervals for Poisson distributions: 
Ratio, weighted average, and product of means. Communications in Statistics-Theory and Methods, 45(1): 83-97.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+correls">correls</a>, <a href="#topic+Table">Table</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rpois(100, 10)
y &lt;- rpois(100, 10)
res&lt;-cox.poisrat(x, y)
</code></pre>

<hr>
<h2 id='Cross-Validation+20for+20the+20k-NN+20algorithm'>
Cross-Validation for the k-NN algorithm
</h2><span id='topic+knn.cv'></span>

<h3>Description</h3>

<p>Cross-Validation for the k-NN algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn.cv(folds = NULL, nfolds = 10, stratified = FALSE, seed = NULL, y, x, k, 
dist.type = "euclidean", type = "C", method = "average", freq.option = 0, 
pred.ret = FALSE, mem.eff = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_folds">folds</code></td>
<td>

<p>A list with the indices of the folds.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if &quot;folds&quot; is NULL.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be selected using stratified random sampling? This preserves the analogy of the samples of each group. Make this 
TRUE if you wish, but only for the classification. 
If you have regression (type = &quot;R&quot;), do not put this to TRUE as it will cause problems or return wrong results.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_seed">seed</code></td>
<td>

<p>If NULL different folds will be created every time. Otherwise set your own seed. 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_y">y</code></td>
<td>

<p>A vector of data. The response variable, which can be either continuous or categorical (factor is acceptable).  
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_x">x</code></td>
<td>

<p>A matrix with the available data, the predictor variables. 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_k">k</code></td>
<td>

<p>A vector with the possible numbers of nearest neighbours to be considered.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_dist.type">dist.type</code></td>
<td>

<p>The type of distance to be used, &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_type">type</code></td>
<td>

<p>Do you want to do classification (&quot;C&quot;) or regression (&quot;R&quot;)? 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_method">method</code></td>
<td>

<p>If you do regression (type = &quot;R&quot;), then how should the predicted values be calculated? Choose among the average (&quot;average&quot;), median (&quot;median&quot;) or 
the harmonic mean (&quot;harmonic&quot;) of the closest neighbours.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_freq.option">freq.option</code></td>
<td>

<p>If classification (type = &quot;C&quot;) and ties occur in the prediction, more than one class have the same number 
of k nearest neighbours, there are three strategies available. Option 0 selects the first most frequent encountered. 
Option 1 randomly selects the most frequent value, in the case that there are duplicates. 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_pred.ret">pred.ret</code></td>
<td>

<p>If you want the predicted values returned set this to TRUE.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm_+3A_mem.eff">mem.eff</code></td>
<td>

<p>Boolean value indicating a conservative or not use of memory. Lower usage of memory/Having this option on will lead to a slight 
decrease in execution speed and should ideally be on when the amount of memory in demand might be a concern.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concept behind k-NN is simple. Suppose we have a matrix with predictor variables and a vector with the 
response variable (numerical or categorical). When a new vector with observations (predictor variables) is 
available, its corresponding response value, numerical or categorical, is to be predicted. Instead of using a 
model, parametric or not, one can use this ad hoc algorithm. 
</p>
<p>The k smallest distances between the new predictor variables and the existing ones are calculated. In the 
case of regression, the average, median, or harmonic mean of the corresponding response values of these closest
predictor values are calculated. In the case of classification, i.e. categorical response value, a voting rule 
is applied. The most frequent group (response value) is where the new observation is to be allocated. 
</p>
<p>This function does the cross-validation procedure to select the optimal k, the optimal number of nearest neighbours. 
The optimal in terms of some accuracy metric. For the classification it is the percentage of correct classification and for the
regression the mean squared error.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>preds</code></td>
<td>

<p>If pred.ret is TRUE the predicted values for each fold are returned as elements in a list.
</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>

<p>A vector whose length is equal to the number of k and is the accuracy metric for each k.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marios Dimitriadis
</p>
<p>R implementation and documentation: Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning. 
New York: Springer.
</p>
<p>Cover TM and Hart PE (1967). Nearest neighbor pattern classification. IEEE Transactions on 
Information Theory. 13(1):21-27.
</p>
<p>Tsagris Michail, Simon Preston and Andrew T.A. Wood (2016). Improved classification for compositional data using the 
<code class="reqn">\alpha</code>-transformation. Journal of classification 33(2): 243-261.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+knn">knn</a>, <a href="#topic+Dist">Dist</a>, <a href="#topic+dista">dista</a>, <a href="#topic+dirknn.cv">dirknn.cv</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
y &lt;- iris[, 5]
mod &lt;- knn.cv(folds = NULL, nfolds = 10, stratified = FALSE, seed = NULL, y = y, x = x, 
k = c(3, 4), dist.type = "euclidean", type = "C", method = "average", 
freq.option = 0, pred.ret = FALSE, mem.eff = FALSE) 
</code></pre>

<hr>
<h2 id='Cross-Validation+20for+20the+20k-NN+20algorithm+20using+20the+20arc+20cosinus+20distance'>
Cross-Validation for the k-NN algorithm using the arc cosinus distance
</h2><span id='topic+dirknn.cv'></span>

<h3>Description</h3>

<p>Cross-Validation for the k-NN algorithm using the arc cosinus distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirknn.cv(y, x, k = 5:10, type = "C", folds = NULL, nfolds = 10,
stratified = TRUE, seed = NULL, parallel = FALSE, pred.ret = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_y">y</code></td>
<td>

<p>A vector of data. The response variable, which can be either continuous or 
categorical (factor is acceptable).  
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_x">x</code></td>
<td>

<p>A matrix with the available data, the predictor variables. 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_k">k</code></td>
<td>

<p>A vector with the possible numbers of nearest neighbours to be considered.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_type">type</code></td>
<td>

<p>If your response variable y is numerical data, then this should be &quot;R&quot; (regression) or &quot;WR&quot;
for distance weighted based nearest neighbours. If y is in general categorical set this argument 
to &quot;C&quot; (classification) or to &quot;WC&quot; for distance weighted based nearest neighbours. 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_folds">folds</code></td>
<td>

<p>A list with the indices of the folds.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_nfolds">nfolds</code></td>
<td>

<p>The number of folds to be used. This is taken into consideration only if &quot;folds&quot; is NULL.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_stratified">stratified</code></td>
<td>

<p>Do you want the folds to be selected using stratified random sampling? This preserves the analogy of the samples of each group. 
Make this TRUE if you wish, but only for the classification. If you have regression (type = &quot;R&quot;), do not put this to TRUE as 
it will cause problems or return wrong results.
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_seed">seed</code></td>
<td>

<p>If NULL different folds will be created every time. Otherwise set your own seed. 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_parallel">parallel</code></td>
<td>

<p>Do you want th ecalculations to take place in parallel? The default value is FALSE. 
</p>
</td></tr>
<tr><td><code id="Cross-Validation+2B20for+2B20the+2B20k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_pred.ret">pred.ret</code></td>
<td>

<p>If you want the predicted values returned set this to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concept behind k-NN is simple. Suppose we have a matrix with predictor variables and a vector with the 
response variable (numerical or categorical). When a new vector with observations (predictor variables) is 
available, its corresponding response value, numerical or categorical, is to be predicted. Instead of using a 
model, parametric or not, one can use this ad hoc algorithm. 
</p>
<p>The k smallest distances between the new predictor variables and the existing ones are calculated. In the 
case of regression, the average, median, or harmonic mean of the corresponding response values of these closest
predictor values are calculated. In the case of classification, i.e. categorical response value, a voting rule 
is applied. The most frequent group (response value) is where the new observation is to be allocated. 
</p>
<p>This function does the cross-validation procedure to select the optimal k, the optimal number of nearest neighbours. 
The optimal in terms of some accuracy metric. For the classification it is the percentage of correct classification 
and for the regression the mean squared error.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>preds</code></td>
<td>

<p>If pred.ret is TRUE the predicted values for each fold are returned as elements in a list.
</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>

<p>A vector whose length is equal to the number of k and is the accuracy metric for each k. 
For the classification case it is the percentage of correct classification. For the regression
case the mean square of prediction error.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning. 
New York: Springer.
</p>
<p>Cover TM and Hart PE (1967). Nearest neighbor pattern classification. IEEE Transactions on 
Information Theory. 13(1):21-27.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dirknn">dirknn</a>, <a href="#topic+knn.cv">knn.cv</a>, <a href="#topic+knn">knn</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x / sqrt( Rfast::rowsums(x^2) )
y &lt;- iris[, 5]
mod &lt;- dirknn.cv(y = y, x = x, k = c(3, 4) )
</code></pre>

<hr>
<h2 id='Density+20of+20the+20multivariate+20normal+20and+20t+20distributions'>
Density of the multivariate normal and t distributions
</h2><span id='topic+dmvnorm'></span><span id='topic+dmvt'></span>

<h3>Description</h3>

<p>Density of the multivariate normal and t distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmvnorm(x, mu, sigma, logged = FALSE) 
dmvt(x, mu, sigma, nu, logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Density+2B20of+2B20the+2B20multivariate+2B20normal+2B20and+2B20t+2B20distributions_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the data. The rows correspond to observations and the columns to variables.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20multivariate+2B20normal+2B20and+2B20t+2B20distributions_+3A_mu">mu</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20multivariate+2B20normal+2B20and+2B20t+2B20distributions_+3A_sigma">sigma</code></td>
<td>

<p>The covariance matrix.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20multivariate+2B20normal+2B20and+2B20t+2B20distributions_+3A_nu">nu</code></td>
<td>

<p>The degrees of freedom for the multivariate t distribution.
</p>
</td></tr>
<tr><td><code id="Density+2B20of+2B20the+2B20multivariate+2B20normal+2B20and+2B20t+2B20distributions_+3A_logged">logged</code></td>
<td>

<p>Should the logarithm of the density be returned (TRUE) or not (FALSE)? 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (log) density of the multivariate normal distribution is calculated for given mean vector and covariance matrix.
</p>


<h3>Value</h3>

<p>A numerical vector with the density values calculated at each vector (row of the matrix x).
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Kanti V. Mardia, John T. Kent and John M. Bibby (1979). Multivariate analysis. Academic Press, London.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rmvnorm">rmvnorm</a>, <a href="#topic+rmvt">rmvt</a>, <a href="#topic+mvnorm.mle">mvnorm.mle</a>, <a href="#topic+iag.mle">iag.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 20)
mu &lt;- colmeans(x)
s &lt;- cova(x)
a1 &lt;- dmvnorm(x, mu, s) 
a2 &lt;- dmvt(x, mu, s, 1)
x &lt;- NULL 
</code></pre>

<hr>
<h2 id='Diagonal+20Matrix'>
Diagonal Matrix
</h2><span id='topic+Diag.fill'></span><span id='topic+Diag.matrix'></span>

<h3>Description</h3>

<p>Fill the diagonal of a matrix or create a diagonal and initialize it with a specific value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Diag.fill(x,v=0)
Diag.matrix(len,v=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Diagonal+2B20Matrix_+3A_x">x</code></td>
<td>

<p>A matrix with data.
</p>
</td></tr>
<tr><td><code id="Diagonal+2B20Matrix_+3A_len">len</code></td>
<td>

<p>Number of columns or rows.
</p>
</td></tr>
<tr><td><code id="Diagonal+2B20Matrix_+3A_v">v</code></td>
<td>

<p>Value or vector to initialize the diagonal of a matrix.By default &quot;v=0&quot;.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Diag.fill returns a diagonal matrix where all the elements in the diagonal are equal to &quot;v&quot;. 
</p>
<p>Diag.matrix returns a diagonal matrix where has dimension &quot;len,len&quot; and all the elements in the diagonal are equal to &quot;v&quot;. It is fast for huge matrices with dimensions more than [row,col] = [500,500]
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+colFalse">colFalse</a>, <a href="#topic+nth">nth</a>, <a href="#topic+rowrange">rowrange</a>, <a href="#topic+rowMedians">rowMedians</a>, <a href="#topic+rowVars">rowVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>, <a href="#topic+colTrue">colTrue</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rbinom(100*100,1,0.5),100,100)

f &lt;- Diag.fill(x,1)
f &lt;- Diag.fill(x,1:100) ##equals to diag(x)&lt;-1:100
f &lt;- Diag.matrix(100,1) ##equals to diag(1,100,100)
f &lt;- Diag.matrix(100,1:100) ##equals to diag(1:100,100,100)

f&lt;-x&lt;-NULL
</code></pre>

<hr>
<h2 id='Distance+20between+20vectors+20and+20a+20matrix+20-+20Sum+20of+20all+20pairwise+20distances+20in+20a+20distance+20matrix.'>Distance between vectors and a matrix - Sum of all pairwise distances in a distance matrix.
</h2><span id='topic+dista'></span><span id='topic+total.dista'></span>

<h3>Description</h3>

<p>Distance between vectors and a matrix - Sum of all pairwise distances in a distance matrix..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dista(xnew, x, type = "euclidean", k = 0, index = FALSE, 
 trans = TRUE, square = FALSE, p = 0, parallel = FALSE)
total.dista(xnew, x, type = "euclidean", k = 0,
 square = FALSE, p = 0, parallel = FALSE)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_xnew">xnew</code></td>
<td>

<p>A matrix with some data or a vector.
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_x">x</code></td>
<td>

<p>A matrix with the data, where rows denotes observations (vectors) and the columns contain the variables.
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_type">type</code></td>
<td>

<p>This can be either &quot;euclidean&quot; or &quot;manhattan&quot;.
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_k">k</code></td>
<td>

<p>Should the k smaller distances or their indices be returned? If k &gt; 0 this will happen.
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_index">index</code></td>
<td>

<p>In case k is greater than 0, you have the option to get the indices of the k smallest distances.
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_trans">trans</code></td>
<td>

<p>Do you want the returned matrix to be transposed? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_square">square</code></td>
<td>

<p>If you choose &quot;euclidean&quot; or &quot;hellinger&quot; as the method, then you can have the option to return the 
squared Euclidean distances by setting this argument to TRUE. 
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_p">p</code></td>
<td>

<p>This is for the the Minkowski, the power of the metric. 
</p>
</td></tr>
<tr><td><code id="Distance+2B20between+2B20vectors+2B20and+2B20a+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix._+3A_parallel">parallel</code></td>
<td>

<p>For methods <b>kullback_leibler</b>, <b>jensen_shannon</b> and <b>itakura_saito</b>, you can run the 
algorithm in parallel. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The target of this function is to calculate the distances between xnew and x without having to calculate the whole 
distance matrix of xnew and x. The latter does extra calculations, which can be avoided.
</p>

<ul>
<li><p> euclidean : <code class="reqn"> \sum \sqrt( \sum | P_i - Q_i |^2)</code>
</p>
</li>
<li><p> manhattan : <code class="reqn"> \sum \sum | P_i - Q_i |</code>
</p>
</li>
<li><p> minimum : <code class="reqn"> \sum \min | P_i - Q_i |</code>
</p>
</li>
<li><p> maximum : <code class="reqn"> \sum \max | P_i - Q_i |</code>
</p>
</li>
<li><p> minkowski : <code class="reqn"> \sum ( \sum | P_i - Q_i |^p)^(1/p)</code>
</p>
</li>
<li><p> bhattacharyya : <code class="reqn"> \sum - ln \sum \sqrt(P_i * Q_i)</code>
</p>
</li>
<li><p> hellinger : <code class="reqn"> \sum 2 * \sqrt( 1 - \sum \sqrt(P_i * Q_i))</code>
</p>
</li>
<li><p> kullback_leibler : <code class="reqn"> \sum \sum P_i * log(P_i / Q_i)</code>
</p>
</li>
<li><p> jensen_shannon : <code class="reqn"> \sum 0.5 * ( \sum P_i * log(2 * P_i / P_i + Q_i) + \sum Q_i * log(2 * Q_i / P_i + Q_i))</code>
</p>
</li>
<li><p> canberra : <code class="reqn"> \sum \sum | P_i - Q_i | / (P_i + Q_i)</code>
</p>
</li>
<li><p> chi_square <code class="reqn">X</code>^2 : <code class="reqn"> \sum \sum ( (P_i - Q_i )^2 / (P_i + Q_i) )</code>
</p>
</li>
<li><p> soergel : <code class="reqn"> \sum \sum | P_i - Q_i | / \sum \max(P_i , Q_i)</code>
</p>
</li>
<li><p> sorensen : <code class="reqn"> \sum \sum | P_i - Q_i | / \sum (P_i + Q_i)</code>
</p>
</li>
<li><p> cosine : <code class="reqn"> \sum (P_i * Q_i) / \sqrt(\sum P_i^2) * \sqrt(\sum Q_i^2)</code>
</p>
</li>
<li><p> wave_hedges : <code class="reqn"> \sum \sum | P_i - Q_i | / \max(P_i , Q_i)</code>
</p>
</li>
<li><p> motyka : <code class="reqn"> \sum \sum \min(P_i , Q_i) / (P_i + Q_i)</code>
</p>
</li>
<li><p> harmonic_mean : <code class="reqn"> 2 * \sum (P_i * Q_i) / (P_i + Q_i)</code>
</p>
</li>
<li><p> jeffries_matusita : <code class="reqn"> \sum \sqrt( 2 - 2 * \sum \sqrt(P_i * Q_i))</code>
</p>
</li>
<li><p> gower : <code class="reqn"> \sum 1/d * \sum | P_i - Q_i |</code>
</p>
</li>
<li><p> kulczynski : <code class="reqn"> \sum 1 / \sum | P_i - Q_i | / \sum \min(P_i , Q_i)</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A matrix with the distances of each xnew from each vector of x. The number of rows of the xnew and and the number 
of columns of xnew are the dimensions of this matrix.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mahala">mahala</a>, <a href="#topic+Dist">Dist</a>, <a href="#topic+total.dist">total.dist</a>, <a href="#topic+total.dista">total.dista</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xnew &lt;- as.matrix( iris[1:10, 1:4] )
x &lt;- as.matrix( iris[-c(1:10), 1:4] )
a &lt;- dista(xnew, x)
b &lt;- as.matrix( dist( rbind(xnew, x) ) )
b &lt;- b[ 1:10, -c(1:10) ]
sum( abs(a - b) )

## see the time
x &lt;- matrix( rnorm(1000 * 4), ncol = 4 )
dista(xnew, x)
as.matrix( dist( rbind(xnew, x) ) )

x&lt;-b&lt;-a&lt;-xnew&lt;-NULL
</code></pre>

<hr>
<h2 id='Distance+20correlation'>
Distance correlation
</h2><span id='topic+dcor'></span><span id='topic+bcdcor'></span>

<h3>Description</h3>

<p>Distance correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcor(x, y)
bcdcor(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Distance+2B20correlation_+3A_x">x</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
<tr><td><code id="Distance+2B20correlation_+3A_y">y</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance correlation or the bias corrected distance correlation of two matrices is calculated. The latter one 
is used for the hypothesis test that the distance correlation is zero (see <code><a href="#topic+dcor.ttest">dcor.ttest</a></code>).
</p>


<h3>Value</h3>

<p>For the bias corrected distance correlation its value only. 
For the distance correlation a list including:
</p>
<table>
<tr><td><code>dcov</code></td>
<td>

<p>The distance covariance.
</p>
</td></tr>
<tr><td><code>dvarX</code></td>
<td>

<p>The distance variance of x.
</p>
</td></tr>
<tr><td><code>dvarY</code></td>
<td>

<p>The distance variance of Y.
</p>
</td></tr>
<tr><td><code>dcor</code></td>
<td>

<p>The distance correlation.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>G.J. Szekely, M.L. Rizzo and N. K. Bakirov (2007). Measuring and Testing Independence 
by Correlation of Distances. Annals of Statistics, 35(6):2769-2794.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+dcov">dcov</a>, <a href="#topic+dcor.ttest">dcor.ttest</a>, <a href="#topic+edist">edist</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:50, 1:4])
y &lt;- as.matrix(iris[51:100, 1:4])
res&lt;-dcor(x, y)
res&lt;-bcdcor(x, y)

x&lt;-y&lt;-NULL
</code></pre>

<hr>
<h2 id='Distance+20matrix+20-+20Sum+20of+20all+20pairwise+20distances+20in+20a+20distance+20matrix'>
Distance matrix - Sum of all pairwise distances in a distance matrix
</h2><span id='topic+Dist'></span><span id='topic+total.dist'></span><span id='topic+vecdist'></span>

<h3>Description</h3>

<p>Distance matrix - Sum of all pairwise distances in a distance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dist(x, method = "euclidean", square = FALSE, p = 0,vector = FALSE)
total.dist(x, method = "euclidean", square = FALSE, p = 0)
vecdist(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Distance+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with data. The distances will be calculated between pairs of rows. 
In the case of <b>vecdist</b> this is a vector. 
For the <b>haversine</b> distance it must be a matrix with two columns, 
the first column is the latitude and the second the longitude (in radians). 
</p>
</td></tr>
<tr><td><code id="Distance+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix_+3A_method">method</code></td>
<td>

<p>See details for the available methods.
</p>
</td></tr>
<tr><td><code id="Distance+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix_+3A_square">square</code></td>
<td>

<p>If you choose &quot;euclidean&quot; or &quot;hellinger&quot; as the method, then you can have the option to return the 
squared Euclidean distances by setting this argument to TRUE. 
</p>
</td></tr>
<tr><td><code id="Distance+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix_+3A_p">p</code></td>
<td>

<p>This is for the the Minkowski, the power of the metric. 
</p>
</td></tr>
<tr><td><code id="Distance+2B20matrix+2B20-+2B20Sum+2B20of+2B20all+2B20pairwise+2B20distances+2B20in+2B20a+2B20distance+2B20matrix_+3A_vector">vector</code></td>
<td>

<p>For return a vector instead a matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance matrix is compute with an extra argument for the Euclidean distances. 
The &quot;kullback_leibler&quot; refers to the symmetric Kullback-Leibler divergence. 
</p>

<ul>
<li><p> euclidean : <code class="reqn">  \sqrt( \sum | P_i - Q_i |^2)</code>
</p>
</li>
<li><p> manhattan : <code class="reqn">  \sum | P_i - Q_i |</code>
</p>
</li>
<li><p> minimum : <code class="reqn">  \min | P_i - Q_i |</code>
</p>
</li>
<li><p> maximum : <code class="reqn">  \max | P_i - Q_i |</code>
</p>
</li>
<li><p> minkowski : <code class="reqn">  ( \sum | P_i - Q_i |^p)^(1/p)</code>
</p>
</li>
<li><p> bhattacharyya : <code class="reqn">  - ln \sum \sqrt(P_i * Q_i)</code>
</p>
</li>
<li><p> hellinger : <code class="reqn">  2 * \sqrt( 1 - \sum \sqrt(P_i * Q_i))</code>
</p>
</li>
<li><p> kullback_leibler : <code class="reqn">  \sum P_i * log(P_i / Q_i)</code>
</p>
</li>
<li><p> jensen_shannon : <code class="reqn">  0.5 * ( \sum P_i * log(2 * P_i / P_i + Q_i) + \sum Q_i * log(2 * Q_i / P_i + Q_i))</code>
</p>
</li>
<li><p> haversine : <code class="reqn"> 2 * R * \arcsin(\sqrt(\sin((lat_2 - lat_1)/2)^2 + \cos(lat_1) * \cos(lat_2) * \sin((lon_2 - lon_1)/2)^2)) </code>
</p>
</li>
<li><p> canberra : <code class="reqn">  \sum | P_i - Q_i | / (P_i + Q_i)</code>
</p>
</li>
<li><p> chi_square <code class="reqn">X</code>^2 : <code class="reqn">  \sum ( (P_i - Q_i )^2 / (P_i + Q_i) )</code>
</p>
</li>
<li><p> soergel : <code class="reqn">  \sum | P_i - Q_i | / \sum \max(P_i , Q_i)</code>
</p>
</li>
<li><p> sorensen : <code class="reqn">  \sum | P_i - Q_i | / \sum (P_i + Q_i)</code>
</p>
</li>
<li><p> cosine : <code class="reqn"> \sum (P_i * Q_i) / \sqrt(\sum P_i^2) * \sqrt(\sum Q_i^2)</code>
</p>
</li>
<li><p> wave_hedges : <code class="reqn">  \sum | P_i - Q_i | / \max(P_i , Q_i)</code>
</p>
</li>
<li><p> motyka : <code class="reqn">  \sum \min(P_i , Q_i) / (P_i + Q_i)</code>
</p>
</li>
<li><p> harmonic_mean : <code class="reqn"> 2 * \sum (P_i * Q_i) / (P_i + Q_i)</code>
</p>
</li>
<li><p> jeffries_matusita : <code class="reqn">  \sqrt( 2 - 2 * \sum \sqrt(P_i * Q_i))</code>
</p>
</li>
<li><p> gower : <code class="reqn">  1/d * \sum | P_i - Q_i |</code>
</p>
</li>
<li><p> kulczynski : <code class="reqn">  1 / \sum | P_i - Q_i | / \sum \min(P_i , Q_i)</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A square matrix with the pairwise distances. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis.
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Mardia K. V., Kent J. T. and Bibby J. M. (1979). Multivariate Analysis. Academic Press. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dista">dista</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(50 * 10), ncol = 10)
a1 &lt;- Dist(x)
a2 &lt;- as.matrix( dist(x) )

x&lt;-a1&lt;-a2&lt;-NULL
</code></pre>

<hr>
<h2 id='Distance+20variance+20and+20covariance'>
Distance variance and covariance
</h2><span id='topic+dvar'></span><span id='topic+dcov'></span>

<h3>Description</h3>

<p>Distance variance and covariances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dvar(x)
dcov(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Distance+2B20variance+2B20and+2B20covariance_+3A_x">x</code></td>
<td>

<p>A numerical matrix or a vector.
</p>
</td></tr>
<tr><td><code id="Distance+2B20variance+2B20and+2B20covariance_+3A_y">y</code></td>
<td>

<p>A numerical matrix or a vector.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance variance of a matrix/vector or the distance covariance of two matrices is calculated.
For the distance variance of a vector we use the fast method of Huo and Szekely (2016).
</p>


<h3>Value</h3>

<p>The distance covariance or distance variance.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Szekely G.J., Rizzo M.L. and Bakirov N.K.(2007). Measuring and Testing Independence 
by Correlation of Distances. Annals of Statistics, 35(6):2769-2794.
</p>
<p>Huo X. and Szekely G. J. (2016). Fast computing for distance covariance. 
Technometrics, 58(4): 435-447.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+dcor">dcor</a>, <a href="#topic+edist">edist</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:50, 1:4])
y &lt;- as.matrix(iris[51:100, 1:4])
res &lt;- dcov(x, y)
res &lt;- dvar(x[, 1])
</code></pre>

<hr>
<h2 id='Eigenvalues+20and+20eigenvectors+20in+20high+20dimensional+20principal+20component+20analysis'>
Eigenvalues in high dimensional principal component analysis
</h2><span id='topic+hd.eigen'></span>

<h3>Description</h3>

<p>Eigenvalues in high dimensional (n&lt;&lt;p) principal component analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hd.eigen(x, center = TRUE, scale = FALSE, k = NULL, vectors = FALSE, large = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Eigenvalues+2B20and+2B20eigenvectors+2B20in+2B20high+2B20dimensional+2B20principal+2B20component+2B20analysis_+3A_x">x</code></td>
<td>

<p>A numerical <code class="reqn">n \times p</code> matrix with data where the rows are the observations and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="Eigenvalues+2B20and+2B20eigenvectors+2B20in+2B20high+2B20dimensional+2B20principal+2B20component+2B20analysis_+3A_center">center</code></td>
<td>

<p>Do you want your data centered? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Eigenvalues+2B20and+2B20eigenvectors+2B20in+2B20high+2B20dimensional+2B20principal+2B20component+2B20analysis_+3A_scale">scale</code></td>
<td>

<p>Do you want each of your variables scaled, i.e. to have unit variance? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Eigenvalues+2B20and+2B20eigenvectors+2B20in+2B20high+2B20dimensional+2B20principal+2B20component+2B20analysis_+3A_k">k</code></td>
<td>

<p>If you want a specific number of eigenvalues and eigenvectors set it here, otherwise all 
eigenvalues (and eigenvectors if requested) will be returned.
</p>
</td></tr>
<tr><td><code id="Eigenvalues+2B20and+2B20eigenvectors+2B20in+2B20high+2B20dimensional+2B20principal+2B20component+2B20analysis_+3A_vectors">vectors</code></td>
<td>

<p>Do you want the eigenvectors be returned? By dafault this is FALSE.
</p>
</td></tr>
<tr><td><code id="Eigenvalues+2B20and+2B20eigenvectors+2B20in+2B20high+2B20dimensional+2B20principal+2B20component+2B20analysis_+3A_large">large</code></td>
<td>

<p>If you have large matrices, with thousands of rows and or many tens or hundreds of columns set this equal to TRUE in 
order to use Rfast's <code><a href="#topic+Crossprod">Crossprod</a></code> or <code><a href="#topic+Tcrossprod">Tcrossprod</a></code> functions. These functions are twice or up to
3 times faster than the correpsonding built-in functions. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code class="reqn">n&lt;&lt;p</code>, at most the first n eigenvalues are non zero. Hence, there is no need to calculate the other 
p-n zero eigenvalues. When center is TRUE, the eigenvalues of the covariance matrix are calculated. 
When both the center and scale is TRUE the eigenvalues of the correlation matrix are calculated. One or more
eigenvectors (towards the end) will be 0. In general the signs might be the opposite than R's, but this makes
no difference. We use the <code><a href="#topic+Crossprod">Crossprod</a></code> instead of the relevant built-in function. The higher the 
dimensions of the matrix are the faster this function becomes. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>values</code></td>
<td>

<p>A vector with the n (or first k) eigenvalues. The divisor in the crossproduc matrix is n-1 and not n. 
</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>

<p>A matrix of <code class="reqn">p \times n</code> or <code class="reqn">p \times k</code> eigenvectors.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rmdp">rmdp</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm( 40, 100)
a &lt;- hd.eigen(x, FALSE, FALSE)
b &lt;- prcomp(x, center = FALSE, scale = FALSE)
a
b$sdev^2
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Empirical+20and+20exponential+20empirical+20likelihood+20tests+20for+20one+20sample'>
Empirical and exponential empirical likelihood tests for one sample
</h2><span id='topic+eel.test1'></span><span id='topic+el.test1'></span>

<h3>Description</h3>

<p>Empirical and exponential empirical likelihood tests for one sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eel.test1(x, mu, tol = 1e-09, logged = FALSE)
el.test1(x, mu, tol = 1e-07, logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20one+2B20sample_+3A_x">x</code></td>
<td>

<p>A numerical vector. 
</p>
</td></tr>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20one+2B20sample_+3A_mu">mu</code></td>
<td>

<p>The hypothesised mean value.
</p>
</td></tr>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20one+2B20sample_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to stop the iterations of the Newton-Raphson.
</p>
</td></tr>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20one+2B20sample_+3A_logged">logged</code></td>
<td>

<p>Should the logarithm of the p-value be returned? TRUE or FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exponential empirical likelihood is a non parametric method. In this case we use it as the non parametric alternative to the t-test.
Newton-Raphson is used to maximise the log-likelihood ratio test statistic. In the case of no solution, NULL is returned. 
Despite the function having beeen written in R, it is pretty fast. As for the empirical likelihood ratio test, there is a condition for the 
range of possible values of mu. If mu is outside this range it is rejected immediately. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson algorithm. If no covnergence occured this is NULL. This is not returned for the
empircial likelihood ratio test.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A vector with three elements, the value of the <code class="reqn">\lambda</code>, the likelihood ratio test statistic and the relevant p-value.
If no convergence occured, the value of the <code class="reqn">\lambda</code> before is becomes NA, the value of test statistic is <code class="reqn">10^5</code> and the p-value is 0.
No convergence can be interpreted as rejection of the hypothesis test.
</p>
</td></tr>
<tr><td><code>p</code></td>
<td>

<p>The estimated probabilities, one for each observation. If no covnergence occured this is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Owen A. B. (2001). Empirical likelihood. Chapman and Hall/CRC Press.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ftest">ftest</a>, <a href="#topic+ttest1">ttest1</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(500)
a1 &lt;- eel.test1(x, 0)
a2 &lt;- el.test1(x, 0)
</code></pre>

<hr>
<h2 id='Empirical+20and+20exponential+20empirical+20likelihood+20tests+20for+20two+20samples'>
Empirical and exponential empirical likelihood tests for two samples
</h2><span id='topic+eel.test2'></span><span id='topic+el.test2'></span>

<h3>Description</h3>

<p>Empirical and exponential empirical likelihood tests for two samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eel.test2(x, y, tol = 1e-09, logged = FALSE)
el.test2(x, y, tol = 1e-07, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20two+2B20samples_+3A_x">x</code></td>
<td>

<p>A numerical vector. 
</p>
</td></tr>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20two+2B20samples_+3A_y">y</code></td>
<td>

<p>Another numerical vector.
</p>
</td></tr>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20two+2B20samples_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to stop the iterations of the Newton-Raphson.
</p>
</td></tr>
<tr><td><code id="Empirical+2B20and+2B20exponential+2B20empirical+2B20likelihood+2B20tests+2B20for+2B20two+2B20samples_+3A_logged">logged</code></td>
<td>

<p>Should the logarithm of the p-value be returned? TRUE or FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Empirical and exponential empirical likelihood are two non parametric hypothesis testing methods. We can use them as 
non parametric alternatives to the t-test. Newton-Raphson is used to maximise the log-likelihood ratio test statistic. 
In the case of no solution, NULL is returned.  
</p>


<h3>Value</h3>

<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson algorithm. If no covnergence occured this is NULL.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A vector with three elements, the value of the <code class="reqn">\lambda</code>, the likelihood ratio test statistic and the relevant p-value.
If no convergence occured, the value of the <code class="reqn">\lambda</code> before is becomes NA, the value of test statistic is <code class="reqn">10^5</code> and the p-value is 0.
No convergence can be interpreted as rejection of the hypothesis test.
</p>
</td></tr>
<tr><td><code>p1</code></td>
<td>

<p>The estimated probabilities, one for each observation for the first sample. If no covnergence occured this is NULL.
</p>
</td></tr>
<tr><td><code>p2</code></td>
<td>

<p>The estimated probabilities, one for each observation for the second sample. If no covnergence occured this is NULL.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Owen A. B. (2001). Empirical likelihood. Chapman and Hall/CRC Press.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ftests">ftests</a>, <a href="#topic+ttests">ttests</a>, <a href="#topic+ttest">ttest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(200)
y &lt;- rnorm(300)
eel.test2(x, y)
el.test2(x, y)
</code></pre>

<hr>
<h2 id='Energy+20distance+20between+20matrices'>
Energy distance between matrices
</h2><span id='topic+edist'></span>

<h3>Description</h3>

<p>Energy distance between matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edist(x, y=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Energy+2B20distance+2B20between+2B20matrices_+3A_x">x</code></td>
<td>

<p>A matrix with numbers or a list with matrices. 
</p>
</td></tr>
<tr><td><code id="Energy+2B20distance+2B20between+2B20matrices_+3A_y">y</code></td>
<td>

<p>A second matrix with data. The number of columns of x and y must match. The number of rows can be different. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This calculates the energy distance between two matrices. It will work even for tens of thousands of rows, 
it will just take some time. See the references for more information. If you have many matrices and want to 
calculate the distance matrix, then put them in a list and use the function.
</p>


<h3>Value</h3>

<p>If &quot;x&quot; is matrix, a numerical value, the energy distance. If &quot;x&quot; is list, a matrix with all pairwsie distances of the matrices.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Szekely G. J. and Rizzo M. L. (2004) Testing for Equal Distributions in High Dimension, InterStat, November (5).
</p>
<p>Szekely G. J. (2000) Technical Report 03-05, E-statistics: Energy of Statistical Samples, Department of 
Mathematics and Statistics, Bowling Green State University. 
</p>
<p>Sejdinovic D., Sriperumbudur B., Gretton A. and Fukumizu, K. (2013). Equivalence of distance-based and
RKHS-based statistics in hypothesis testing. The Annals of Statistics, 41(5), 2263-2291.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+dvar">dvar</a>, <a href="#topic+total.dist">total.dist</a>, <a href="#topic+total.dista">total.dista</a>, <a href="#topic+Dist">Dist</a>, <a href="#topic+dista">dista</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[1:50, 1:4] )
y &lt;- as.matrix( iris[51:100, 1:4] )
res&lt;-edist(x, y)
z &lt;- as.matrix(iris[101:150, 1:4])
a &lt;- list()
a[[ 1 ]] &lt;- x
a[[ 2 ]] &lt;- y
a[[ 3 ]] &lt;- z
res&lt;-edist(a)

x&lt;-y&lt;-z&lt;-a&lt;-NULL
</code></pre>

<hr>
<h2 id='Equality+20of+20objects'>Equality of objects
</h2><span id='topic+all_equals'></span>

<h3>Description</h3>

<p>Equality of objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>all_equals(x,y,round_digits = FALSE,without_attr=FALSE,fast_result=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Equality+2B20of+2B20objects_+3A_x">x</code></td>
<td>

<p>A Matrix, List, Dataframe or Vector.
</p>
</td></tr>
<tr><td><code id="Equality+2B20of+2B20objects_+3A_y">y</code></td>
<td>

<p>A Matrix, List, Dataframe or Vector.
</p>
</td></tr>
<tr><td><code id="Equality+2B20of+2B20objects_+3A_round_digits">round_digits</code></td>
<td>

<p>The digit for rounding numbers.
</p>
</td></tr>
<tr><td><code id="Equality+2B20of+2B20objects_+3A_without_attr">without_attr</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for deleting attributes. Be carefull although because some atributes are very important for you item.
</p>
</td></tr>
<tr><td><code id="Equality+2B20of+2B20objects_+3A_fast_result">fast_result</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for using just identical.But you can combine only with round_digits argument.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean (TRUE/FALSE) value which represents if the items x and y are equal.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+Match">Match</a>, <a href="#topic+mvbetas">mvbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+colsums">colsums</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
y &lt;- matrix( rnorm(100 * 100), ncol = 100 )
all_equals(x,y) 
all_equals(x, x)
</code></pre>

<hr>
<h2 id='Estimation+20of+20an+20AR+281+29+20model'>
Estimation of an AR(1) model
</h2><span id='topic+ar1'></span><span id='topic+colar1'></span>

<h3>Description</h3>

<p>Estimation of an AR(1) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ar1(y, method = "cmle") 
colar1(y, method = "cmle")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estimation+2B20of+2B20an+2B20AR+2B281+2B29+2B20model_+3A_y">y</code></td>
<td>

<p>For the case of <b>ar1</b> this is a vector of time series. For the case of <b>colar1</b> this is a matrix where weach column represents a time series. 
</p>
</td></tr>
<tr><td><code id="Estimation+2B20of+2B20an+2B20AR+2B281+2B29+2B20model_+3A_method">method</code></td>
<td>

<p>This can be either &quot;cmle&quot; for conditional maximum likelihood or &quot;yw&quot; for the Yule-Walker equations.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of the classical MLE for the AR(1) model which requires numerical optimsation (Newton-Raphson for example) we estimate the parameters of the AR(1) model using 
conditional maximum likelihood. This procedure is described in Chapter 17 in Lee (2006). In some, it assumes that the first observation is deterministic and hence 
conditioning on that observation, there is a closed form solution for the parameters. The second alternative is to use the method of moments and hence the Yule-Walker equations. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>param</code></td>
<td>

<p>For the case of <b>ar1</b> this is a vector with three elements, the constant term, the <code class="reqn">\phi</code> term (lag coefficient) and the variance.
For the case of <b>colar1</b> this is a matrix with three columns, eahc of which carries the same aforementioned elements. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>http://econ.nsysu.edu.tw/ezfiles/124/1124/img/Chapter17_MaximumLikelihoodEstimation.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rm.lines">rm.lines</a>, <a href="#topic+varcomps.mle">varcomps.mle</a>, <a href="#topic+rm.anovas">rm.anovas</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- as.vector(lh)
ar1(y)
ar(y, FALSE, 1, "ols")

ar1(y, method = "yw")
ar(y, FALSE, 1, "yw")

a1 &lt;- colar1(cbind(y, y) )
b1 &lt;- colar1(cbind(y, y), method = "yw")
</code></pre>

<hr>
<h2 id='Estimation+20of+20the+20Box-Cox+20transformation'>
Estimation of the Box-Cox transformation
</h2><span id='topic+bc'></span>

<h3>Description</h3>

<p>Estimation of the Box-Cox transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bc(x, low = -1, up = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estimation+2B20of+2B20the+2B20Box-Cox+2B20transformation_+3A_x">x</code></td>
<td>

<p>A numerical vector with strictly positive values.
</p>
</td></tr>
<tr><td><code id="Estimation+2B20of+2B20the+2B20Box-Cox+2B20transformation_+3A_low">low</code></td>
<td>

<p>The lowest value to search for the best <code class="reqn">\lambda</code> parameter.
</p>
</td></tr>
<tr><td><code id="Estimation+2B20of+2B20the+2B20Box-Cox+2B20transformation_+3A_up">up</code></td>
<td>

<p>The highest value to search for the best <code class="reqn">\lambda</code> parameter.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions estimates the best <code class="reqn">\lambda</code> in the Box-Cox power transformation.
</p>


<h3>Value</h3>

<p>The optimal value of <code class="reqn">\lambda</code>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Box George E. P. and Cox D. R. (1964). An analysis of transformations. 
Journal of the Royal Statistical Society, Series B, 26 (2):211-252. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+correls">correls</a>, <a href="#topic+auc">auc</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- exp(rnorm(1000))
res&lt;-bc(x)
</code></pre>

<hr>
<h2 id='Exact+20t-test+20for+202+20independent+20samples'>
Exact t-test for 2 independent samples
</h2><span id='topic+exact.ttest2'></span>

<h3>Description</h3>

<p>Exact t-test for 2 independent samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exact.ttest2(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Exact+2B20t-test+2B20for+2B202+2B20independent+2B20samples_+3A_x">x</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
<tr><td><code id="Exact+2B20t-test+2B20for+2B202+2B20independent+2B20samples_+3A_y">y</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs an exact t-test. With few observations, permutation or bootstrap calculation
of the p-value is advisable. However, with even fewer observations, one can perform all possible 
permutations and calculate the exact p-value. This is what this function does. BUT, pay attention, 
as this works with few samples. If for example each sample contains 15 numbers, you will need a lot 
of memory (more than 17 GB) for this function to work. the reason is that we create the matrix with 
all possible permutations first and then perform the two-sample t-test. 
</p>


<h3>Value</h3>

<p>A vector with the number of permutations, test statistic and the permutation based p-value. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>B.L. Welch (1951). On the comparison of several mean values: an alternative approach. 
Biometrika, 38(3/4), 330-336.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+boot.ttest2">boot.ttest2</a>, <a href="#topic+ttest2">ttest2</a>, <a href="#topic+ftest">ftest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(7)
y &lt;- rnorm(7)
res&lt;-exact.ttest2(x, y)
</code></pre>

<hr>
<h2 id='Exponential+20empirical+20likelihood+20for+20a+20one+20sample+20mean+20vector+20hypothesis+20testing'>
Exponential empirical likelihood for a one sample mean vector hypothesis testing
</h2><span id='topic+mv.eeltest1'></span>

<h3>Description</h3>

<p>Exponential empirical likelihood for a one sample mean vector hypothesis testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mv.eeltest1(x, mu, tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Exponential+2B20empirical+2B20likelihood+2B20for+2B20a+2B20one+2B20sample+2B20mean+2B20vector+2B20hypothesis+2B20testing_+3A_x">x</code></td>
<td>

<p>A matrix containing Euclidean data.
</p>
</td></tr>
<tr><td><code id="Exponential+2B20empirical+2B20likelihood+2B20for+2B20a+2B20one+2B20sample+2B20mean+2B20vector+2B20hypothesis+2B20testing_+3A_mu">mu</code></td>
<td>

<p>The hypothesized mean vector.
</p>
</td></tr>
<tr><td><code id="Exponential+2B20empirical+2B20likelihood+2B20for+2B20a+2B20one+2B20sample+2B20mean+2B20vector+2B20hypothesis+2B20testing_+3A_tol">tol</code></td>
<td>

<p>The tolerance value used to stop the Newton-Raphson algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multivariate hypothesis test for a one sample mean vector. This is a non parametric test and it works for univariate and multivariate data. The p-value is currently computed only asymptotically (no bootstrap calibration at the moment).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>p</code></td>
<td>

<p>The estimated probabiities.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>The value of the Lagrangian parameter <code class="reqn">\lambda</code>.
</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>The value of the log-likelihood ratio test statistic along with its corresponding p-value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Jing Bing-Yi and Andrew TA Wood (1996). Exponential empirical likelihood is not Bartlett correctable. Annals of Statistics 24(1): 365-369.
</p>
<p>Owen A. B. (2001). Empirical likelihood. Chapman and Hall/CRC Press.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+james">james</a>, <a href="#topic+mv.eeltest2">mv.eeltest2</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Rfast::rmvnorm(100, numeric(10), diag( rexp(10, 0.5) ) )
res&lt;-mv.eeltest1(x, numeric(10) )
</code></pre>

<hr>
<h2 id='Exponential+20empirical+20likelihood+20hypothesis+20testing+20for+20two+20mean+20vectors'>
Exponential empirical likelihood hypothesis testing for two mean vectors
</h2><span id='topic+mv.eeltest2'></span>

<h3>Description</h3>

<p>Exponential empirical likelihood hypothesis testing for two mean vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mv.eeltest2(y1, y2, tol = 1e-07, R = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Exponential+2B20empirical+2B20likelihood+2B20hypothesis+2B20testing+2B20for+2B20two+2B20mean+2B20vectors_+3A_y1">y1</code></td>
<td>

<p>A matrix containing the Euclidean data of the first group.
</p>
</td></tr>
<tr><td><code id="Exponential+2B20empirical+2B20likelihood+2B20hypothesis+2B20testing+2B20for+2B20two+2B20mean+2B20vectors_+3A_y2">y2</code></td>
<td>

<p>A matrix containing the Euclidean data of the second group.
</p>
</td></tr>
<tr><td><code id="Exponential+2B20empirical+2B20likelihood+2B20hypothesis+2B20testing+2B20for+2B20two+2B20mean+2B20vectors_+3A_tol">tol</code></td>
<td>

<p>The tolerance level used to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Exponential+2B20empirical+2B20likelihood+2B20hypothesis+2B20testing+2B20for+2B20two+2B20mean+2B20vectors_+3A_r">R</code></td>
<td>

<p>If R is 0, the classical chi-sqaure distribution is used, if R = 1, the corrected chi-square distribution (James, 1954) is used and if R = 2, the modified F distribution (Krishnamoorthy and Yanping, 2006) is used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exponential empirical likelihood is a non parametric hypothesis testing procedure for one sample. The generalisation to two (or more samples) is via searching for the mean vector that minimises the sum of the two test statistics.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>test</code></td>
<td>

<p>The empirical likelihood test statistic value.</p>
</td></tr>
<tr><td><code>modif.test</code></td>
<td>

<p>The modified test statistic, either via the chi-square or the F distribution.
</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>

<p>The p-value.
</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The estimated common mean vector.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Jing Bing-Yi and Andrew TA Wood (1996). Exponential empirical likelihood is not Bartlett correctable. Annals of Statistics 24(1): 365-369.
</p>
<p>G.S. James (1954). Tests of Linear Hypothese in Univariate and Multivariate Analysis
when the Ratios of the Population Variances are Unknown. Biometrika, 41(1/2): 19-43.
</p>
<p>Krishnamoorthy K. and Yanping Xia (2006).  On Selecting Tests for Equality of Two Normal Mean Vectors.
Multivariate Behavioral Research 41(4): 533-548.
</p>
<p>Owen A. B. (2001). Empirical likelihood. Chapman and Hall/CRC Press.
</p>
<p>Amaral G.J.A., Dryden I.L. and Wood A.T.A. (2007). Pivotal bootstrap methods for k-sample problems in directional statistics and shape analysis. 
Journal of the American Statistical Association 102(478): 695-707.
</p>
<p>Preston S.P. and Wood A.T.A. (2010). Two-Sample Bootstrap Hypothesis Tests for Three-Dimensional Labelled Landmark Data. Scandinavian Journal of 
Statistics 37(4): 568-587.
</p>
<p>Tsagris M., Preston S. and Wood A.T.A. (2017). Nonparametric hypothesis testing for equality of means on the
simplex. Journal of Statistical Computation and Simulation, 87(2): 406-422.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+james">james</a>, <a href="#topic+mv.eeltest1">mv.eeltest1</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res&lt;-mv.eeltest2( as.matrix(iris[1:25, 1:4]), as.matrix(iris[26:50, 1:4]), R = 0 )
res&lt;-mv.eeltest2( as.matrix(iris[1:25, 1:4]), as.matrix(iris[26:50, 1:4]), R = 1 )
</code></pre>

<hr>
<h2 id='Fast+20and+20general+20-+20untyped+20represantation+20of+20a+20factor+20variable'>
Fast and general represantation of a factor variable
</h2><span id='topic+ufactor'></span><span id='topic+print.ufactor'></span><span id='topic++5B.ufactor'></span>

<h3>Description</h3>

<p>Fast and general represantation of a factor variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ufactor(x)
## S3 method for class 'ufactor'
x[i]
## S3 method for class 'ufactor'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fast+2B20and+2B20general+2B20-+2B20untyped+2B20represantation+2B20of+2B20a+2B20factor+2B20variable_+3A_x">x</code></td>
<td>

<p>A vector with data. 
</p>
</td></tr>
<tr><td><code id="Fast+2B20and+2B20general+2B20-+2B20untyped+2B20represantation+2B20of+2B20a+2B20factor+2B20variable_+3A_i">i</code></td>
<td>

<p>An integer value/vector which is the index/indices to the element you want to access.
</p>
</td></tr>
<tr><td><code id="Fast+2B20and+2B20general+2B20-+2B20untyped+2B20represantation+2B20of+2B20a+2B20factor+2B20variable_+3A_...">...</code></td>
<td>

<p>Anything the user want.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a general implementation of factor structure. For access the fields of a &quot;ufactor&quot; use the &quot;$&quot; operator.
</p>


<h3>Value</h3>

<p>An object of class &quot;ufactor&quot;. This object holds 2 fields:
</p>
<p>levels: the levels of the variable in his initial type
values: the values of the variable in his initial type
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colVars">colVars</a>, <a href="base.html#topic+factor">factor</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(10)
R.factor&lt;- as.factor(x)
Rfast.factor &lt;- ufactor(x)

identical(levels(R.factor),Rfast.factor$levels) # TRUE
identical(as.numeric(R.factor),Rfast.factor$values) # TRUE
x&lt;-R.factor&lt;-Rfast.factor&lt;-NULL
</code></pre>

<hr>
<h2 id='FBED+20variable+20selection+20method+20using+20the+20correlation'>
FBED variable selection method using the correlation
</h2><span id='topic+cor.fbed'></span>

<h3>Description</h3>

<p>FBED variable selection method using the correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.fbed(y, x, ystand = TRUE, xstand = TRUE, alpha = 0.05, K = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FBED+2B20variable+2B20selection+2B20method+2B20using+2B20the+2B20correlation_+3A_y">y</code></td>
<td>

<p>The response variable, a numeric vector.
</p>
</td></tr>
<tr><td><code id="FBED+2B20variable+2B20selection+2B20method+2B20using+2B20the+2B20correlation_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples and the columns are the variables. 
</p>
</td></tr>
<tr><td><code id="FBED+2B20variable+2B20selection+2B20method+2B20using+2B20the+2B20correlation_+3A_ystand">ystand</code></td>
<td>

<p>If this is TRUE the response variable is centered. The mean is subtracted from every value.
</p>
</td></tr>
<tr><td><code id="FBED+2B20variable+2B20selection+2B20method+2B20using+2B20the+2B20correlation_+3A_xstand">xstand</code></td>
<td>

<p>If this is TRUE the independent variables are standardised. 
</p>
</td></tr>
<tr><td><code id="FBED+2B20variable+2B20selection+2B20method+2B20using+2B20the+2B20correlation_+3A_alpha">alpha</code></td>
<td>

<p>The significance level, set to 0.05 by default.
</p>
</td></tr>
<tr><td><code id="FBED+2B20variable+2B20selection+2B20method+2B20using+2B20the+2B20correlation_+3A_k">K</code></td>
<td>

<p>The number of times to repeat the process. The default value is 0.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FBED stands for Forward Backward with Earcly Dropping. It is a variation of the classical forward selection, where at each step, only the 
statistically significant variables carry on. The rest are dropped. The process stops when no other variables can be selected. If K = 1, the process
is repeated testing sequentially again all those that have not been selected. If K &gt; 1, then this is repeated. 
</p>
<p>In the end, the backward selection is performed to remove any falsely included variables. This backward phase has not been implemented yet.  
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The duration of the process.
</p>
</td></tr>
<tr><td><code>res</code></td>
<td>

<p>A matrix with the index of the selected variable, their test statistic value and the associated p-value.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A matrix with two columns. The cumulative number of variables selected and the number of tests for each value of K.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Borboudakis G. and Tsamardinos I. (2019). Forward-backward selection with early dropping. 
Journal of Machine Learning Research, 20(8): 1-39.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+cor.fsreg">cor.fsreg</a>, <a href="#topic+ompr">ompr</a>, <a href="#topic+correls">correls</a>, <a href="#topic+fs.reg">fs.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 100)
y &lt;- rnorm(100)
a &lt;- cor.fbed(y, x)
a
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Find+20element'>
Find element
</h2><span id='topic+is_element'></span>

<h3>Description</h3>

<p>Search a value in an unordered vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_element(x, key)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Find+2B20element_+3A_x">x</code></td>
<td>

<p>A vector or matrix with the data.
</p>
</td></tr>
<tr><td><code id="Find+2B20element_+3A_key">key</code></td>
<td>

<p>A value to check if exists in the vector x.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Find if the key exists in the vector and return returns TRUE/FALSE if the value is been found. If the vector is unordered  it is fast but if the vector is ordered then use binary_search. The functions is written in C++ in order to be as fast as possible. 
</p>


<h3>Value</h3>

<p>TRUE/FALSE if the value is been found.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+binary_search">binary_search</a> (buit-in R function)
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(500)
key &lt;- x[50]
b &lt;- is_element(x, key) 
</code></pre>

<hr>
<h2 id='Find+20the+20given+20value+20in+20a+20hash+20table'>
Find the given value in a hash table
</h2><span id='topic+hash.find'></span>

<h3>Description</h3>

<p>Find the given value in a hash table or list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hash.find(x,key)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Find+2B20the+2B20given+2B20value+2B20in+2B20a+2B20hash+2B20table_+3A_x">x</code></td>
<td>

<p>A hash table or list.
</p>
</td></tr>
<tr><td><code id="Find+2B20the+2B20given+2B20value+2B20in+2B20a+2B20hash+2B20table_+3A_key">key</code></td>
<td>

<p>The key for searching the table.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function search the given key.
</p>


<h3>Value</h3>

<p>If the given key exists return its value else returns 0.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hash.list">hash.list</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- hash.list(letters,c(1:26))
value &lt;- hash.find(x,"a")
x[["a"]]==value
</code></pre>

<hr>
<h2 id='Fitted+20probabilities+20of+20the+20Terry-Bradley+20model'>
Fitted probabilities of the Terry-Bradley model
</h2><span id='topic+btmprobs'></span>

<h3>Description</h3>

<p>Fitted probabilities of the Terry-Bradley model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>btmprobs(x, tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fitted+2B20probabilities+2B20of+2B20the+2B20Terry-Bradley+2B20model_+3A_x">x</code></td>
<td>

<p>A numerical square, usually not symmetric, matrix with discrete valued data. Each entry is a frequency, to give an example, the number of wins. x[i, j] is the number 
of wins of home team i against guest team j. x[j, i] is the number of wins of home team j against guest team i. 
</p>
</td></tr>
<tr><td><code id="Fitted+2B20probabilities+2B20of+2B20the+2B20Terry-Bradley+2B20model_+3A_tol">tol</code></td>
<td>

<p>The tolerance level to terminate the iterative algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It fits a Bradley-Terry model to the given matrix and returns the fitted probabilities only.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The numbetr of iterations required.
</p>
</td></tr>
<tr><td><code>probs</code></td>
<td>

<p>A vector with probabilities which sum to 1. This is the probability of win for each item (or team in our hypothetical example). 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Bradley R.A. and Terry M.E. (1952). Rank Analysis of Incomplete Block Designs: I. The Method of Paired Comparisons. Biometrika, 39(3/4):324-345.
</p>
<p>Huang Tzu-Kuo, Ruby C. Weng and Chih-Jen Lin (2006). Generalized Bradley-Terry models and multi-class probability estimates. Journal of Machine Learning Research, 7:85-115.
</p>
<p>Agresti A. (2002). Categorical Data Analysis (2nd ed). New York: Wiley.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+g2tests">g2tests</a>, <a href="#topic+poisson.anova">poisson.anova</a>, <a href="stats.html#topic+anova">anova</a>, <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+poisson.mle">poisson.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rpois(10 * 10, 10), ncol = 10) ## not the best example though
res&lt;-btmprobs(x)
</code></pre>

<hr>
<h2 id='Fitting+20a+20Dirichlet+20distribution+20via+20Newton-Rapshon'>
Fitting a Dirichlet distribution via Newton-Rapshon
</h2><span id='topic+diri.nr2'></span>

<h3>Description</h3>

<p>Fitting a Dirichlet distribution via Newton-Rapshon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diri.nr2(x, type = 1, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fitting+2B20a+2B20Dirichlet+2B20distribution+2B20via+2B20Newton-Rapshon_+3A_x">x</code></td>
<td>

<p>A matrix containing the compositional data. Zeros are not allowed.
</p>
</td></tr>
<tr><td><code id="Fitting+2B20a+2B20Dirichlet+2B20distribution+2B20via+2B20Newton-Rapshon_+3A_type">type</code></td>
<td>

<p>Type 1 uses a vectorised version of the Newton-Raphson (Minka, 2012). In high dimensions this is to be preferred. 
If the data are too concentrated, regardless of the dimensions, this is also to be preferrred. 
Type 2 uses the regular Newton-Raphson, with matrix multiplications. In small dimensions this can be considerably
faster. 
</p>
</td></tr>
<tr><td><code id="Fitting+2B20a+2B20Dirichlet+2B20distribution+2B20via+2B20Newton-Rapshon_+3A_tol">tol</code></td>
<td>

<p>The tolerance level idicating no further increase in the log-likelihood.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood estimation of the parameters of a Dirichlet distribution is performed via Newton-Raphson. 
Initial values suggested by Minka (2012) are used. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>The estimated parameters.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>Minka Thomas (2012). Estimating a Dirichlet distribution. Technical report.
</p>
<p>Ng Kai Wang, Guo-Liang Tian, and Man-Lai Tang (2011). Dirichlet and related distributions: Theory, methods and 
applications. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+beta.mle">beta.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rgamma(100 * 4, c(5, 6, 7, 8), 1), ncol = 4)
x &lt;- x / rowsums(x)
res&lt;-diri.nr2(x) 
</code></pre>

<hr>
<h2 id='Floyd-Warshall+20algorithm'>
Floyd-Warshall algorithm for shortest paths in a directed graph
</h2><span id='topic+floyd'></span>

<h3>Description</h3>

<p>Floyd-Warshall algorithm for shortest paths in a directed graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>floyd(x) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Floyd-Warshall+2B20algorithm_+3A_x">x</code></td>
<td>

<p>The adjacency matrix of a directed graph. A positive number (including) in x[i, j] indicates that there is an arrow
from i to j and it also shows the cost of going from i to j. Hence, the algorithm will find not only the shortest path but also the with the smallest cost. 
A value of NA means that there is no path. Put positive number only, as negative will cause problems.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Floyd-Warshall algorithm is designed to find the shortest path (if it exists) between two nodes in a graph. 
</p>


<h3>Value</h3>

<p>A matrix, say z, with 0 and positive numbers. The elements denote the length of the shortest path between 
each pair of points. If z[i, j] is zero it  means that there is no cost from i to j. If z[i, j] has a positive 
value it means that the length of going from i to j is equal to that value. 
</p>


<h3>Author(s)</h3>

<p>John Burkardt (C++ code)
</p>
<p>Ported into R and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Floyd, Robert W. (1962). Algorithm 97: Shortest Path. Communications of the ACM. 5(6): 345.
</p>
<p>Warshall, Stephen (1962). A theorem on Boolean matrices. Journal of the ACM. 9 (1): 11-12.
</p>
<p>https://en.wikipedia.org/wiki/Floyd
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(NA, 10, 10)
x[sample(1:100, 10)] &lt;- rpois(10, 3)
res&lt;-floyd(x)
</code></pre>

<hr>
<h2 id='Forward+20selection+20with+20generalised+20linear+20regression+20models'>
Variable selection in generalised linear regression models with forward selection
</h2><span id='topic+fs.reg'></span>

<h3>Description</h3>

<p>Variable selection in generalised linear regression models with forward selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fs.reg(y, ds, sig = 0.05, tol = 2, type = "logistic") 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Forward+2B20selection+2B20with+2B20generalised+2B20linear+2B20regression+2B20models_+3A_y">y</code></td>
<td>

<p>The dependent variable. This can either be a binary numeric (0, 1) or a vector with integers (numeric or integer class), count data. The first case is for
the binary logistic regression and the second for the Poisson regression. 
</p>
</td></tr>
<tr><td><code id="Forward+2B20selection+2B20with+2B20generalised+2B20linear+2B20regression+2B20models_+3A_ds">ds</code></td>
<td>

<p>The dataset; provide a matrix where columns denote the variables and the rows the observations. The variables must be continuous, no categorical variables
are accepted. 
</p>
</td></tr>
<tr><td><code id="Forward+2B20selection+2B20with+2B20generalised+2B20linear+2B20regression+2B20models_+3A_sig">sig</code></td>
<td>

<p>Significance level for assessing the p-values significance. Default value is 0.05.
</p>
</td></tr>
<tr><td><code id="Forward+2B20selection+2B20with+2B20generalised+2B20linear+2B20regression+2B20models_+3A_tol">tol</code></td>
<td>

<p>The difference bewtween two successive values of the stopping rule. By default this is is set to 2. If for example, the BIC difference between two 
succesive models is less than 2, the process stops and the last variable, even though significant does not enter the model.
</p>
</td></tr>
<tr><td><code id="Forward+2B20selection+2B20with+2B20generalised+2B20linear+2B20regression+2B20models_+3A_type">type</code></td>
<td>

<p>If you have a binary dependent variable, put &quot;logistic&quot; or &quot;quasibinomial&quot;. If you have percentages, values between 0 and 1, including 0 and or 1, use &quot;quasibinomial&quot; as well. 
If you have count data put &quot;poisson&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The classical forward regression is implemented. The difference is that we have an extra step of check. Even if a variable is significant, the BIC of the model 
(with that variable) is calculated. If the decrease from the previous BIC (of the model without this variable) is less thatn a prespecified by the user value 
(default is 2) the variable wil enter. This way, we guard somehow against over-fitting. 
</p>


<h3>Value</h3>

<p>A matrix with for columns, the selected variables, the logarithm of their p-value, their test statistic and the BIC of the model with these variables included.
If no variable is selected, the matrix is empty.
</p>


<h3>Author(s)</h3>

<p>Marios Dimitriadis
</p>
<p>Documentation: Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cor.fsreg">cor.fsreg</a>, <a href="#topic+logistic_only">logistic_only</a>, <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+glm_logistic">glm_logistic</a>, <a href="#topic+glm_poisson">glm_poisson</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(123)

#simulate a dataset with continuous data
x &lt;- matrnorm(100, 50)
y &lt;- rpois(100, 10)
a &lt;- fs.reg(y, x, sig = 0.05, tol = 2, type = "poisson") 
x &lt;- NULL

</code></pre>

<hr>
<h2 id='G-square+20and+20Chi-square+20test+20of+20conditional+20indepdence'>
G-square test of conditional indepdence
</h2><span id='topic+g2Test'></span><span id='topic+g2Test_perm'></span><span id='topic+chi2Test'></span>

<h3>Description</h3>

<p>G-square test of conditional indepdence with and without permutations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g2Test(data, x, y, cs, dc)
g2Test_perm(data, x, y, cs, dc, nperm)
chi2Test(data, x, y, cs, dc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="G-square+2B20and+2B20Chi-square+2B20test+2B20of+2B20conditional+2B20indepdence_+3A_data">data</code></td>
<td>

<p>A numerical matrix with the data. <b>The minimum must be 0, otherwise the function can crash or will produce 
wrong results</b>. The data must be consecutive numbers.
</p>
</td></tr>
<tr><td><code id="G-square+2B20and+2B20Chi-square+2B20test+2B20of+2B20conditional+2B20indepdence_+3A_x">x</code></td>
<td>

<p>A number between 1 and the number of columns of data. This indicates which variable to take. 
</p>
</td></tr>
<tr><td><code id="G-square+2B20and+2B20Chi-square+2B20test+2B20of+2B20conditional+2B20indepdence_+3A_y">y</code></td>
<td>

<p>A number between 1 and the number of columns of data (other than x). This indicates the other variable whose independence with x is to be tested. 
</p>
</td></tr>
<tr><td><code id="G-square+2B20and+2B20Chi-square+2B20test+2B20of+2B20conditional+2B20indepdence_+3A_cs">cs</code></td>
<td>

<p>A vector with the indices of the variables to condition upon. It must be non zero and between 1 and the number of variables. 
If you want unconditional independence test see <code><a href="#topic+g2Test_univariate">g2Test_univariate</a></code> and <code><a href="#topic+g2Test_univariate_perm">g2Test_univariate_perm</a></code>.
If there is an overlap between x, y and cs you will get 0 as the value of the test statistic.
</p>
</td></tr>
<tr><td><code id="G-square+2B20and+2B20Chi-square+2B20test+2B20of+2B20conditional+2B20indepdence_+3A_dc">dc</code></td>
<td>

<p>A numerical value equal to the number of variables (or columns of the data matrix) indicating the number of distinct, unique values (or levels) of each variable.
Make sure you give the correct numbers here, otherwise the degrees of freedom will be wrong.
</p>
</td></tr>
<tr><td><code id="G-square+2B20and+2B20Chi-square+2B20test+2B20of+2B20conditional+2B20indepdence_+3A_nperm">nperm</code></td>
<td>

<p>The number of permutations. The permutations test is slower than without permutations and should be used with small sample sizes or when 
the contigency tables have zeros. When there are few variables, R's &quot;chisq.test&quot; function is faster, but as the number of variables increase the time difference 
with R's procedure becomes larger and larger.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions calculates the test statistic of the <code class="reqn">G^2</code> test of conditional independence between x and y conditional on a set of variable(s) cs.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>

<p>The <code class="reqn">G^2</code> or <code class="reqn">chi^2</code> test statistic.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>The degrees of freedom of the test statistic.
</p>
</td></tr>
<tr><td><code>x</code></td>
<td>

<p>The row or variable of the data.
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>

<p>The column or variable of the data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giorgos Borboudakis. The permutation version used a C++ code by John Burkardt.
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsamardinos, I., &amp; Borboudakis, G. (2010). Permutation testing improves Bayesian network learning. 
In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 322-337). Springer Berlin Heidelberg
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+g2Test_univariate">g2Test_univariate</a>, <a href="#topic+g2Test_univariate_perm">g2Test_univariate_perm</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nvalues &lt;- 3
nvars &lt;- 10
nsamples &lt;- 5000
data &lt;- matrix( sample( 0:(nvalues - 1), nvars * nsamples, replace = TRUE ), nsamples, nvars )
dc &lt;- rep(nvalues, nvars)

res&lt;-g2Test( data, 1, 2, 3, c(3, 3, 3) )
res&lt;-g2Test_perm( data, 1, 2, 3, c(3, 3, 3), 1000 )

dc&lt;-data&lt;-NULL
</code></pre>

<hr>
<h2 id='Gamma+20regression+20with+20a+20log-link'>
Gamma regression with a log-link
</h2><span id='topic+gammareg'></span><span id='topic+gammacon'></span>

<h3>Description</h3>

<p>Gamma regression with a log-link.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammareg(y, x, tol = 1e-07, maxiters = 100)
gammacon(y, tol = 1e-08, maxiters =50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gamma+2B20regression+2B20with+2B20a+2B20log-link_+3A_y">y</code></td>
<td>

<p>The dependent variable, a numerical variable with non negative numbers.
</p>
</td></tr>
<tr><td><code id="Gamma+2B20regression+2B20with+2B20a+2B20log-link_+3A_x">x</code></td>
<td>

<p>A matrix or data.frame with the indendent variables.
</p>
</td></tr>
<tr><td><code id="Gamma+2B20regression+2B20with+2B20a+2B20log-link_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Gamma+2B20regression+2B20with+2B20a+2B20log-link_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations that can take place in the regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The gamma.reg fits a Gamma regression with a log-link. The gamma.con fits a Gamma regression
with a log link with the intercept only ( glm(y ~ 1, Gamma(log) ) ). 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>deviance</code></td>
<td>

<p>The deviance value.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The dispersion parameter (<code class="reqn">\phi</code>) of the regression. This is necessary if you want to 
perform an F hypothesis test for the significance of one or more independent variables.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The regression coefficient(s). 
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>The number of iterations, the deviance and the dispersion parameter.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989. 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+gammaregs">gammaregs</a>, <a href="#topic+normlog.reg">normlog.reg</a>, <a href="#topic+invgauss.reg">invgauss.reg</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- abs( rnorm(100) )
x &lt;- matrix( rnorm(100 * 2), ncol = 2)
mod &lt;- glm(y ~ x, family = Gamma(log) )
res&lt;-summary(mod)

res&lt;-gammareg(y, x)

mod &lt;- glm(y ~ 1, family = Gamma(log) )
res&lt;-summary(mod)
res&lt;-gammacon(y)
</code></pre>

<hr>
<h2 id='Gaussian+20regression+20with+20a+20log-link'>
Gaussian regression with a log-link
</h2><span id='topic+normlog.reg'></span>

<h3>Description</h3>

<p>Gaussian regression with a log-link.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normlog.reg(y, x, tol = 1e-07, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_y">y</code></td>
<td>

<p>The dependent variable, a numerical variable with non negative numbers.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_x">x</code></td>
<td>

<p>A matrix or data.frame with the indendent variables.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations that can take place in the regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Gaussian regression with a log-link is fitted.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>i</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood value.
</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>

<p>The deviance value.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The regression coefficients
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefanos Fafalios
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+normlog.regs">normlog.regs</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+prop.regs">prop.regs</a>, <a href="#topic+allbetas">allbetas</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- abs( rnorm(100) )
x &lt;- matrix( rnorm(100 * 2), ncol = 2)
a &lt;- normlog.reg(y, x)
b &lt;- glm(y ~ x, family = gaussian(log) )
summary(b)
a

</code></pre>

<hr>
<h2 id='Generates+20random+20values+20from+20a+20normal+20and+20puts+20them+20in+20a+20matrix'>
Generates random values from a normal and puts them in a matrix
</h2><span id='topic+matrnorm'></span>

<h3>Description</h3>

<p>Generates random values from a normal and puts them in a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrnorm(n, p, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Generates+2B20random+2B20values+2B20from+2B20a+2B20normal+2B20and+2B20puts+2B20them+2B20in+2B20a+2B20matrix_+3A_n">n</code></td>
<td>

<p>The sample size, the number of rows the matrix will have. 
</p>
</td></tr>
<tr><td><code id="Generates+2B20random+2B20values+2B20from+2B20a+2B20normal+2B20and+2B20puts+2B20them+2B20in+2B20a+2B20matrix_+3A_p">p</code></td>
<td>

<p>The dimensionality of the data, the nubmer of columns of the matrix.
</p>
</td></tr>
<tr><td><code id="Generates+2B20random+2B20values+2B20from+2B20a+2B20normal+2B20and+2B20puts+2B20them+2B20in+2B20a+2B20matrix_+3A_seed">seed</code></td>
<td>

<p>If you want the same to be generated again use a seed for the generator, an integer number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>How many times did you have to simulated data from a (standard) normal distribution in order to test 
something? For example, in order to see the speed of <code><a href="#topic+logistic_only">logistic_only</a></code>, one needs to generate 
a matrix with predictor variables. The same is true for other similar functions. In <code><a href="#topic+sftests">sftests</a></code>,
one would like to examine the typer I error of this test under the null hypothesis. 
</p>
<p>By using the Ziggurat method of generating standard normal variates, this function is really fast when you 
want to generate big matrices. 
</p>


<h3>Value</h3>

<p>An n x p matrix with data simulated from a standard normal distribution. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rvmf">rvmf</a>, <a href="#topic+Rnorm">Rnorm</a>, <a href="#topic+rmvnorm">rmvnorm</a>, <a href="#topic+rvonmises">rvonmises</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 100)
</code></pre>

<hr>
<h2 id='Get+20specific+20columns+2Frows+20fo+20a+20matrix'>
Get specific columns/rows fo a matrix
</h2><span id='topic+columns'></span><span id='topic+rows'></span>

<h3>Description</h3>

<p>Get specific columns/rows of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>columns(x,indices)
rows(x,indices)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Get+2B20specific+2B20columns+2B2Frows+2B20fo+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with data.
</p>
</td></tr>
<tr><td><code id="Get+2B20specific+2B20columns+2B2Frows+2B20fo+2B20a+2B20matrix_+3A_indices">indices</code></td>
<td>

<p>An integer vector with the indices.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the specific columns/rows of argumment indices.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowFalse">rowFalse</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>, <a href="#topic+rowTrue">rowTrue</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(runif(100*100),100,100)
indices = sample(1:100,50)
all.equal(x[,indices],columns(x,indices))
all.equal(x[indices,],rows(x,indices))

x&lt;-indices&lt;-NULL
</code></pre>

<hr>
<h2 id='Hash+20-+20Pair+20function'>
Hash - Pair function
</h2><span id='topic+hash.list'></span>

<h3>Description</h3>

<p>Hash - Pair function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hash.list(key,x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hash+2B20-+2B20Pair+2B20function_+3A_key">key</code></td>
<td>

<p>The keys of the given values.
</p>
</td></tr>
<tr><td><code id="Hash+2B20-+2B20Pair+2B20function_+3A_x">x</code></td>
<td>

<p>The values.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function pairs each item of of key and value make a unique hash table.
</p>


<h3>Value</h3>

<p>Returns the hash-list table.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hash.find">hash.find</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- hash.list(letters,c(1:26))
x[["a"]]==1
</code></pre>

<hr>
<h2 id='Hash+20object'>
Hash object
</h2><span id='topic+Hash'></span><span id='topic+Hash.key.multi'></span><span id='topic+print.Hash'></span><span id='topic+length.Hash'></span><span id='topic++5B.Hash'></span><span id='topic++5B+3C-.Hash'></span>

<h3>Description</h3>

<p>Hash object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hash(keys=NULL,values=NULL)
Hash.key.multi(x,...,sep = " ")
## S3 replacement method for class 'Hash'
x[...,sep = " "] &lt;- value
## S3 method for class 'Hash'
x[...,sep = " "]
## S3 method for class 'Hash'
print(x,...)
## S3 method for class 'Hash'
length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hash+2B20object_+3A_x">x</code></td>
<td>

<p>A Hash object, using Hash function.
</p>
</td></tr>
<tr><td><code id="Hash+2B20object_+3A_values">values</code></td>
<td>

<p>A vector with the values you want to store.
</p>
</td></tr>
<tr><td><code id="Hash+2B20object_+3A_value">value</code></td>
<td>

<p>The values you want to store.
</p>
</td></tr>
<tr><td><code id="Hash+2B20object_+3A_keys">keys</code></td>
<td>

<p>A vector with keys for each values.
</p>
</td></tr>
<tr><td><code id="Hash+2B20object_+3A_sep">sep</code></td>
<td>

<p>A character value using to separate the multiple keys for each value.
</p>
</td></tr>
<tr><td><code id="Hash+2B20object_+3A_...">...</code></td>
<td>

<p>One or more values for access or find elements.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you want to delete a key just insert the global variable &quot;Rfast:::delete&quot;.
</p>
<p>Hash: Create Hash object where every key has a value. Specify the type from the beggining (for speed). Use the argument &quot;type&quot; with one of the values &quot;new.env, logical, character, integer, numeric&quot;.
Hash.key.multi: search if key exists. If the keys are multiple, then use the argument &quot;substr&quot; to search inside each multiple for the specific key.
</p>


<h3>Value</h3>

<p>A Hash object.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code>  <a href="#topic+hash.list">hash.list</a>, <a href="#topic+hash.find">hash.find</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Hash(rnorm(10),sample(1:10))

x[1,2,13] &lt;- 0.1234 # insert value using multi key. the same as x["1 2 13"] &lt;- 0.1234
x[1,2,3] &lt;- 15 # insert value using multi key. the same as x["1 2 3"] &lt;- 15

Hash.key.multi(x,"1")
x # print Hash object using S3 generic
#x[1,2,3] &lt;- Rfast:::delete # delete multi key. the same as x["1 2 3"] &lt;- NULL
length(x)
</code></pre>

<hr>
<h2 id='Hash+20object+20to+20a+20list+20object'>
Hash object to a list object
</h2><span id='topic+hash2list'></span>

<h3>Description</h3>

<p>Hash object to a list object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hash2list(x, sorting = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hash+2B20object+2B20to+2B20a+2B20list+2B20object_+3A_x">x</code></td>
<td>

<p>A hash table with two parts, the keys (number(s) as string) and the key values (a single number). 
</p>
</td></tr>
<tr><td><code id="Hash+2B20object+2B20to+2B20a+2B20list+2B20object_+3A_sorting">sorting</code></td>
<td>

<p>This is if you you want the numbers in the keys sorted. The default value is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For every key, there is a key value. This function creates a list and puts every pair of keys and value in a component of a list.
</p>


<h3>Value</h3>

<p>A list whose length is equal to the size of the hash table.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code>  <a href="#topic+hash.list">hash.list</a>, <a href="#topic+hash.find">hash.find</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=list("1 2 4 3"=2.56,"2.34 1.05"=2)
res&lt;-hash2list(x)
res&lt;-hash2list(x,TRUE)
</code></pre>

<hr>
<h2 id='High+20dimensional+20MCD+20based+20detection+20of+20outliers'>
High dimensional MCD based detection of outliers
</h2><span id='topic+rmdp'></span>

<h3>Description</h3>

<p>High dimensional MCD based detection of outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmdp(y, alpha = 0.05, itertime = 100, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="High+2B20dimensional+2B20MCD+2B20based+2B20detection+2B20of+2B20outliers_+3A_y">y</code></td>
<td>

<p>A matrix with numerical data with more columns (p) than rows (n), i.e. n&lt;p.
</p>
</td></tr>
<tr><td><code id="High+2B20dimensional+2B20MCD+2B20based+2B20detection+2B20of+2B20outliers_+3A_alpha">alpha</code></td>
<td>

<p>The significance level, i.e. used to decide whether an observation is said to be considered a possible outlier. 
The default value is 0.05.
</p>
</td></tr>
<tr><td><code id="High+2B20dimensional+2B20MCD+2B20based+2B20detection+2B20of+2B20outliers_+3A_itertime">itertime</code></td>
<td>

<p>The number of iterations the algorithm will be ran. The higher the sample size, the larger this number must be. 
With 50 observations in <code class="reqn">R^1000</code> maybe this has to be 1000 in order to produce stable results.  
</p>
</td></tr>
<tr><td><code id="High+2B20dimensional+2B20MCD+2B20based+2B20detection+2B20of+2B20outliers_+3A_parallel">parallel</code></td>
<td>

<p>A logical value for parallel version.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>High dimensional outliers (n&lt;&lt;p) are detected using a properly constructed MCD. The variances of the variables are 
used and the determinant is simply their product. 
</p>


<h3>Value</h3>

<p>A list including:
runtime = runtime, dis = dis, wei = wei
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The duration of the process.
</p>
</td></tr>
<tr><td><code>dis</code></td>
<td>

<p>The final estimated Mahalanobis type normalised distances.
</p>
</td></tr>
<tr><td><code>wei</code></td>
<td>

<p>A bollean variable vector specifying whether an observation is &quot;clean&quot; (TRUE) or a possible outlier (FALSE).
</p>
</td></tr>
<tr><td><code>cova</code></td>
<td>

<p>The estimated covatriance matrix.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Initial R code: Changliang Zou &lt;nk.chlzou@gmail.com&gt;
R code modifications: Michail Tsagris &lt;mtsagris@uoc.gr&gt;
C++ implementation: Manos Papadakis &lt;papadakm95@gmail.com&gt;
Documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Changliang Zhou &lt;nk.chlzou@gmail.com&gt;
</p>


<h3>References</h3>

<p>Ro K., Zou C., Wang Z. and Yin G. (2015). Outlier detection for high-dimensional data. Biometrika, 102(3):589-599.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colMedians">colMedians</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(50 * 400), ncol = 400)
a &lt;- rmdp(x, itertime = 500)

x&lt;-a&lt;-NULL
</code></pre>

<hr>
<h2 id='Hypothesis+20test+20for+20the+20distance+20correlation'>
Hypothesis test for the distance correlation
</h2><span id='topic+dcor.ttest'></span>

<h3>Description</h3>

<p>Hypothesis test for the distance correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcor.ttest(x, y, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20the+2B20distance+2B20correlation_+3A_x">x</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20the+2B20distance+2B20correlation_+3A_y">y</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20the+2B20distance+2B20correlation_+3A_logged">logged</code></td>
<td>

<p>Do you want the logarithm of the p-value to be returned? If yes, set this to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bias corrected distance correlation is used. The hypothesis test is whether the two matrices are independent or
not. Note, that this test is size correct as both the sample size and the dimensionality goes to infinity. It will
not have the correct type I error for univariate data or for matrices with just a couple of variables.
</p>


<h3>Value</h3>

<p>A vector with 4 elements, the bias corrected distance correlation, the degrees of freedom, the test statistic and
its associated p-value. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>G.J. Szekely, M.L. Rizzo and N. K. Bakirov (2007). Measuring and Testing Independence 
by Correlation of Distances. Annals of Statistics, 35(6):2769-2794.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+bcdcor">bcdcor</a>, <a href="#topic+dcov">dcov</a>, <a href="#topic+edist">edist</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:50, 1:4])
y &lt;- as.matrix(iris[51:100, 1:4])
res&lt;-dcor.ttest(x, y)
</code></pre>

<hr>
<h2 id='Hypothesis+20test+20for+20two+20means+20of+20percentages'>
Hypothesis test for two means of percentages
</h2><span id='topic+percent.ttest'></span>

<h3>Description</h3>

<p>Hypothesis test for two means of percentages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percent.ttest(x, y, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20two+2B20means+2B20of+2B20percentages_+3A_x">x</code></td>
<td>

<p>A numerical vector with the percentages of the first sample. Any value between 0 and 1 
(inclusive) is allowed.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20two+2B20means+2B20of+2B20percentages_+3A_y">y</code></td>
<td>

<p>A numerical vector with the percentages of the first sample. Any value between 0 and 1 
(inclusive) is allowed.
</p>
</td></tr> 
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20two+2B20means+2B20of+2B20percentages_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the <code><a href="#topic+prop.reg">prop.reg</a></code> but with a single categorical predictor which has two 
levels only. It is like a t-test for the means of two samples haivng percentages. 
</p>


<h3>Value</h3>

<p>A vector with three elements, the phi parameter, the test statistic and its associated 
p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Papke L. E. &amp; Wooldridge J. (1996). Econometric methods for fractional response 
variables with an application to 401(K) plan participation rates. Journal of Applied 
Econometrics, 11(6): 619-632.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 
2nd edition, 1989.  
</p>


<h3>See Also</h3>

<p><code> link{percent.ttests}, <a href="#topic+prop.reg">prop.reg</a>, <a href="#topic+ttest2">ttest2</a>, <a href="#topic+ftest">ftest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rbeta(100, 3, 1)
y &lt;- rbeta(100, 7.5, 2.5)
res&lt;-percent.ttest(x, y)
</code></pre>

<hr>
<h2 id='Hypothesis+20test+20for+20von+20Mises-Fisher+20distribution+20over+20Kent+20distribution'>
Hypothesis test for von Mises-Fisher distribution over Kent distribution
</h2><span id='topic+fish.kent'></span>

<h3>Description</h3>

<p>The null hypothesis is whether a von Mises-Fisher distribution fits the data well, and the
altenrative is that the Kent distribution is more suitable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fish.kent(x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20von+2B20Mises-Fisher+2B20distribution+2B20over+2B20Kent+2B20distribution_+3A_x">x</code></td>
<td>

<p>A numeric matrix containing the data as unit vectors in Euclidean coordinates.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20test+2B20for+2B20von+2B20Mises-Fisher+2B20distribution+2B20over+2B20Kent+2B20distribution_+3A_logged">logged</code></td>
<td>

<p>If you want the logarithm of the p-value ot be returned set this to TRUE. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Essentially it is a test of rotational symmetry, whether Kent's ovalness parameter (beta) is equal to zero. 
This works for spherical data only.
</p>


<h3>Value</h3>

<p>A vector with two elements, the value of the test statistic and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Rivest, L. P. (1986). Modified Kent's statistics for testing goodness of fit for the Fisher distribution in 
small concentrated samples. Statistics &amp; probability letters, 4(1): 1-4.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vmf.mle">vmf.mle</a>, <a href="#topic+iag.mle">iag.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rvmf(100, rnorm(3), 15)
res&lt;-fish.kent(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Hypothesis+20testing+20between+20two+20skewness+20or+20kurtosis+20coefficients'>
Hypothesis testing between two skewness or kurtosis coefficients
</h2><span id='topic+skew.test2'></span><span id='topic+kurt.test2'></span>

<h3>Description</h3>

<p>Hypothesis testing between two skewness or kurtosis coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skew.test2(x, y)

kurt.test2(x, y) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hypothesis+2B20testing+2B20between+2B20two+2B20skewness+2B20or+2B20kurtosis+2B20coefficients_+3A_x">x</code></td>
<td>

<p>A numerical vector with data.
</p>
</td></tr>
<tr><td><code id="Hypothesis+2B20testing+2B20between+2B20two+2B20skewness+2B20or+2B20kurtosis+2B20coefficients_+3A_y">y</code></td>
<td>

<p>A numerical vector with data, not necessarily of the same size.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The skewness of kurtosis coefficients between two samples are being compared.
</p>


<h3>Value</h3>

<p>A vector with the test statistic and its associated p-value. 
</p>


<h3>Author(s)</h3>

<p>Klio Lakiotaki
</p>
<p>R implementation and documentation: Klio Lakiotaki &lt;kliolak@gmail.com&gt;.
</p>


<h3>References</h3>

<p>https://en.wikipedia.org/wiki/Skewness
</p>
<p>https://en.wikipedia.org/wiki/Kurtosis
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+skew">skew</a>, <a href="#topic+colskewness">colskewness</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgamma(150,1, 4)
y &lt;- rgamma(100, 1, 4)
res&lt;-skew.test2(x, y)
res&lt;-kurt.test2(x, y)
</code></pre>

<hr>
<h2 id='Index+20of+20the+20columns+20of+20a+20data.frame+20which+20are+20a+20specific+20type'>
Index of the columns of a data.frame which are a specific type
</h2><span id='topic+which.is'></span>

<h3>Description</h3>

<p>Index of the columns of a data.frame which are a specific type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>which.is(x,method="factor")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Index+2B20of+2B20the+2B20columns+2B20of+2B20a+2B20data.frame+2B20which+2B20are+2B20a+2B20specific+2B20type_+3A_x">x</code></td>
<td>

<p>A data.frame where some columns are expected to be factor variables.
</p>
</td></tr>
<tr><td><code id="Index+2B20of+2B20the+2B20columns+2B20of+2B20a+2B20data.frame+2B20which+2B20are+2B20a+2B20specific+2B20type_+3A_method">method</code></td>
<td>

<p>A character value about the type. One of, &quot;numeric&quot;,&quot;factor&quot;,&quot;integer&quot;,&quot;logical&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is written in C++ and this is why it is very fast. 
</p>


<h3>Value</h3>

<p>A vector with the column indices which are factor variables. If there are no factor variables it will return an empty vector. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+nth">nth</a>, <a href="#topic+Match">Match</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res&lt;-which.is(iris)
</code></pre>

<hr>
<h2 id='Inverse+20Gaussian+20regression+20with+20a+20log-link'>
Inverese Gaussian regression with a log-link
</h2><span id='topic+invgauss.reg'></span>

<h3>Description</h3>

<p>Inverse Gaussian regression with a log-link.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invgauss.reg(y, x, tol = 1e-07, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inverse+2B20Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_y">y</code></td>
<td>

<p>The dependent variable, a numerical variable with non negative numbers.
</p>
</td></tr>
<tr><td><code id="Inverse+2B20Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_x">x</code></td>
<td>

<p>A matrix or data.frame with the indendent variables.
</p>
</td></tr>
<tr><td><code id="Inverse+2B20Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Inverse+2B20Gaussian+2B20regression+2B20with+2B20a+2B20log-link_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations that can take place in the regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An inverse Gaussian regression with a log-link is fitted.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>i</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood value.
</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>

<p>The deviance value.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The dispersion parameter (<code class="reqn">\phi</code>) of the regression. This is necessary if you want to perform an F hypothesis test for 
the significance of one or more independent variables.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The regression coefficients
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;mtsagris@uoc.gr&gt;
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989. 
</p>
<p>Zakariya Yahya Algamal and Intisar Ibrahim Allyas (2017). Prediction of blood lead level in maternal and fetal 
using generalized linear model. International Journal of Advanced Statistics and Probability, 5(2): 65-69.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+invgauss.regs">invgauss.regs</a>, <a href="#topic+normlog.reg">normlog.reg</a>, <a href="#topic+score.glms">score.glms</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- abs( rnorm(100) )
x &lt;- matrix( rnorm(100 * 2), ncol = 2)
a &lt;- invgauss.reg(y, x)
a

</code></pre>

<hr>
<h2 id='Inverse+20of+20a+20symmetric+20positive+20definite+20matrix'>
Inverse of a symmetric positive definite matrix
</h2><span id='topic+spdinv'></span>

<h3>Description</h3>

<p>Inverse of a symmetric positive definite matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spdinv(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inverse+2B20of+2B20a+2B20symmetric+2B20positive+2B20definite+2B20matrix_+3A_a">A</code></td>
<td>

<p>A square positive definite matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After calculating the Cholesky decomposition of the matrix we use this upper triangular matrix to 
invert the original matrix.
</p>


<h3>Value</h3>

<p>The inverse of the input matrix.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>http://econ.nsysu.edu.tw/ezfiles/124/1124/img/Chapter17_MaximumLikelihoodEstimation.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+cholesky">cholesky</a>, <a href="#topic+cova">cova</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>s &lt;- cova( as.matrix(iris[, 1:4]) )
res&lt;-spdinv(s)
res&lt;-solve(s)
</code></pre>

<hr>
<h2 id='Iterator'>
Iterator
</h2><span id='topic+iterator'></span><span id='topic+print.iterator'></span><span id='topic+Elem+3C-'></span><span id='topic+Elem'></span><span id='topic+Elem+3C-.iterator'></span><span id='topic+Elem.iterator'></span><span id='topic++3D+3D.iterator'></span><span id='topic++21+3D.iterator'></span>

<h3>Description</h3>

<p>A way to traverse a list, data.frame, matrix or vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterator(x,method="ceil",type="vector",by=1)
## S3 method for class 'iterator'
print(x,...)
## S3 replacement method for class 'iterator'
Elem(x) &lt;- value
Elem(x)
Elem(x) &lt;- value
## S3 method for class 'iterator'
Elem(x)
## S3 method for class 'iterator'
x == y
## S3 method for class 'iterator'
x != y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Iterator_+3A_x">x</code></td>
<td>

<p>A variable with any type, or iterator object.
</p>
</td></tr>
<tr><td><code id="Iterator_+3A_value">value</code></td>
<td>

<p>An value depending the method of the iterator.
</p>
</td></tr>
<tr><td><code id="Iterator_+3A_y">y</code></td>
<td>

<p>An iterator.
</p>
</td></tr>
<tr><td><code id="Iterator_+3A_method">method</code></td>
<td>

<p>Method of the iterator class. One of &quot;ceil&quot;,&quot;col&quot;,&quot;row&quot;.
</p>
</td></tr>
<tr><td><code id="Iterator_+3A_type">type</code></td>
<td>

<p>One of &quot;vector&quot;,&quot;matrix&quot;,&quot;data.frame&quot;,&quot;list&quot;.
</p>
</td></tr>
<tr><td><code id="Iterator_+3A_by">by</code></td>
<td>

<p>An integer value to iterate through element.
</p>
</td></tr>
<tr><td><code id="Iterator_+3A_...">...</code></td>
<td>

<p>Anything the user want.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>iterator: is an object that helps a programmer to traverse the given object.
</p>
<p>print.iterator: print an object of class iterator.
</p>
<p>&quot;Elem&lt;-&quot;: access to element and change the value.
</p>
<p>Elem: access to element.
</p>


<h3>Value</h3>

<p>An object of class &quot;iterator&quot;. This object holds 4 fields:
</p>
<p>copy: deep copy of iterator.
end: get iterator tha have access to points to the last element.
equals: equality of iterators
nextElem: move iterator to point to the next element using argument &quot;by&quot;.
prevElem: move iterator to point to the previous element using argument &quot;by&quot;.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colShuffle">colShuffle</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+read.directory">read.directory</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y&lt;-rnorm(100)
x&lt;-iterator(y,method="ceil",type="vector",by=1)

s&lt;-0
while(x != x$end()){
	s &lt;- s + Elem(x)
	x$nextElem()
}

all.equal(s,sum(y))
</code></pre>

<hr>
<h2 id='James+20multivariate+20version+20of+20the+20t-test'>
James multivariate version of the t-test
</h2><span id='topic+james'></span>

<h3>Description</h3>

<p>James test for testing the equality of two population mean vectors without assuming equality of the covariance matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>james(y1, y2, a = 0.05, R = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="James+2B20multivariate+2B20version+2B20of+2B20the+2B20t-test_+3A_y1">y1</code></td>
<td>

<p>A matrix containing the Euclidean data of the first group.
</p>
</td></tr>
<tr><td><code id="James+2B20multivariate+2B20version+2B20of+2B20the+2B20t-test_+3A_y2">y2</code></td>
<td>

<p>A matrix containing the Euclidean data of the second group.
</p>
</td></tr>
<tr><td><code id="James+2B20multivariate+2B20version+2B20of+2B20the+2B20t-test_+3A_a">a</code></td>
<td>

<p>The significance level, set to 0.05 by default.
</p>
</td></tr>
<tr><td><code id="James+2B20multivariate+2B20version+2B20of+2B20the+2B20t-test_+3A_r">R</code></td>
<td>

<p>If R is 1 the classical James test is returned. 
If R is 2 the MNV modficiation is implemented.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multivariate analysis of variance without assuming equality of the covariance matrices. The p-value can be calculated either asymptotically or via bootstrap. The James test (1954) or a modification proposed by Krishnamoorthy and Yanping (2006) is implemented. The James test uses a corected chi-square distribution, whereas the modified version uses an F distribution.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>note</code></td>
<td>

<p>A message informing the user about the test used.
</p>
</td></tr>
<tr><td><code>mesoi</code></td>
<td>

<p>The two mean vectors.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>The test statistic, the p-value, the correction factor and the corrected critical 
value of the chi-square distribution if the James test has been used or,
the test statistic, the p-value, the critical value and the degrees of freedom 
(numerator and denominator) of the F distribution if the modified James test 
has been used.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>G.S. James (1954). Tests of Linear Hypothese in Univariate and Multivariate Analysis
when the Ratios of the Population Variances are Unknown. Biometrika, 41(1/2): 19-43
</p>
<p>Krishnamoorthy K. and Yanping Xia.  On Selecting Tests for Equality of Two Normal Mean Vectors (2006).
Multivariate Behavioral Research 41(4): 533-548
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mv.eeltest2">mv.eeltest2</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>james( as.matrix(iris[1:25, 1:4]), as.matrix(iris[26:50, 1:4]), R = 1 )
james( as.matrix(iris[1:25, 1:4]), as.matrix(iris[26:50, 1:4]), R = 2 )
</code></pre>

<hr>
<h2 id='k+20nearest+20neighbours+20algorithm+20+28k-NN+29'>
k nearest neighbours algorithm (k-NN)
</h2><span id='topic+knn'></span>

<h3>Description</h3>

<p>k nearest neighbours algorithm (k-NN). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn(xnew, y, x, k, dist.type = "euclidean", type = "C", method = "average", 
freq.option = 0, mem.eff = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_xnew">xnew</code></td>
<td>

<p>The new data, new predictor variable values. A matrix with numerical data. 
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_y">y</code></td>
<td>

<p>A vector with the response variable, whose values for the new data we wish to predict. This can be 
numerical data, factor or discrete, 0, 1, ... The latter two cases are for classification.
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_x">x</code></td>
<td>

<p>The dataset. A matrix with numerical data.
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to use. The number can either be a single value or a vector with multiple values.
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_dist.type">dist.type</code></td>
<td>

<p>The type of distance to be used. Either \&quot;euclidean\&quot; or \&quot;manhattan\&quot;. 
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_type">type</code></td>
<td>

<p>If your response variable \&quot;y\&quot; is numerical data, then this should be \&quot;R\&quot; (regression). If \&quot;y\&quot; is in general 
categorical, factor or discrete set this argument to \&quot;C\&quot; (classification).
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_method">method</code></td>
<td>

<p>In case you have regression (type = \&quot;R\&quot;) you want a way to summarise the prediction. If you want to take the 
average of the reponses of the k closest observations, type \&quot;average\&quot;. For the median, type \&quot;median\&quot; and for the 
harmonic mean, type \&quot;harmonic\&quot;.
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_freq.option">freq.option</code></td>
<td>

<p>If classification (type = \&quot;C\&quot;) and ties occur in the prediction, more than one class has the same number 
of k nearest neighbours, in which case there are two strategies available: Option 0 selects the first most frequent encountered. Option 1 randomly selects the most frequent value, in the case that there are duplicates. 
</p>
</td></tr>
<tr><td><code id="k+2B20nearest+2B20neighbours+2B20algorithm+2B20+2B28k-NN+2B29_+3A_mem.eff">mem.eff</code></td>
<td>

<p>Boolean value indicating a conservative or not use of memory. Lower usage of memory/Having this option on will lead to a slight 
decrease in execution speed and should ideally be on when the amount of memory in demand might be a concern.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concept behind k-NN is simple. Suppose we have a matrix with predictor variables and a vector with the 
response variable (numerical or categorical). When a new vector with observations (predictor variables) is 
available, its corresponding response value, numerical or category is to be predicted. Instead of using a 
model, parametric or not, one can use this ad hoc algorithm. 
</p>
<p>The k smallest distances between the new predictor variables and the existing ones are calculated. In the 
case of regression, the average, median or harmonic mean of the corresponding respone values of these closest
predictor values are calculated. In the case of classification, i.e. categorical response value, a voting rule 
is applied. The most frequent group (response value) is where the new observation is to be allocated. 
</p>


<h3>Value</h3>

<p>A matrix whose number of columns is equal to the size of k. If in the input you provided there is just one value of
k, then a matrix with one column is returned containing the predicted values. If more than one value was supplied,
the matrix will contain the predicted values for every value of k. 
</p>


<h3>Author(s)</h3>

<p>Marios Dimitriadis
</p>
<p>R implementation and documentation: Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;
</p>


<h3>References</h3>

<p>Cover TM and Hart PE (1967). Nearest neighbor pattern classification. IEEE Transactions on 
Information Theory. 13(1):21-27.
</p>
<p>Friedman J., Hastie T. and Tibshirani R. (2017). The elements of statistical learning. 
New York: Springer.
</p>
<p>http://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf 	
</p>
<p>http://statlink.tripod.com/id3.html
</p>


<h3>See Also</h3>

<p><code><a href="#topic+knn.cv">knn.cv</a>, <a href="#topic+dirknn">dirknn</a>, <a href="#topic+logistic_only">logistic_only</a>, <a href="#topic+fs.reg">fs.reg</a>, <a href="#topic+cor.fsreg">cor.fsreg</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate a dataset with continuous data
x &lt;- as.matrix(iris[, 1:4])
y &lt;- as.numeric(iris[, 5])
id &lt;- sample(1:150, 120)
mod &lt;- knn(x[-id, ], y[id], x[id, ], k = c(4, 5, 6), type = "C", mem.eff = FALSE)
mod # Predicted values of y for 3 values of k. 
res&lt;-table(mod[, 1], y[-id] )  # Confusion matrix for k = 4
res&lt;-table(mod[, 2], y[-id] )  # Confusion matrix for k = 5
res&lt;-table(mod[, 3], y[-id] )  # Confusion matrix for k = 6
</code></pre>

<hr>
<h2 id='k-NN+20algorithm+20using+20the+20arc+20cosinus+20distance'>
k-NN algorithm using the arc cosinus distance
</h2><span id='topic+dirknn'></span>

<h3>Description</h3>

<p>It classifies new observations to some known groups via the k-NN algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirknn(xnew, x, y, k, type = "C", parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_xnew">xnew</code></td>
<td>

<p>The new data whose membership is to be predicted, a numeric matrix with unit vectors. 
In case you have one vector only make it a row vector (i.e. matrix with one row).
</p>
</td></tr>
<tr><td><code id="k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_x">x</code></td>
<td>

<p>The data, a numeric matrix with unit vectors.
</p>
</td></tr>
<tr><td><code id="k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours. It can also be a vector with many values.
</p>
</td></tr>
<tr><td><code id="k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_y">y</code></td>
<td>

<p>A numerical vector representing the class or label of each vector of x. 1, 2, 3, and so on.
It can also be a numerical vector with data in order to perform regression.
</p>
</td></tr>
<tr><td><code id="k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_type">type</code></td>
<td>
	
<p>If your response variable y is numerical data, then this should be &quot;R&quot; (regression) or &quot;WR&quot;
for distance weighted based nearest neighbours. If y is in general categorical set this argument 
to &quot;C&quot; (classification) or to &quot;WC&quot; for distance weighted based nearest neighbours. 
</p>
</td></tr>
<tr><td><code id="k-NN+2B20algorithm+2B20using+2B20the+2B20arc+2B20cosinus+2B20distance_+3A_parallel">parallel</code></td>
<td>

<p>Do you want th ecalculations to take place in parallel? The default value is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard algorithm is to keep the k nearest observations and see the groups of these observations. 
The new observation is allocated to the most frequent seen group. The non standard algorithm is to 
calculate the classical mean or the harmonic mean of the k nearest observations for each group. 
The new observation is allocated to the group with the smallest mean distance.
</p>
<p>If you want regression, the predicted value is calculated as the average of the responses of the k nearest 
observations.
</p>


<h3>Value</h3>

<p>A matrix with the predicted group(s). It has as many columns as the values of k.
</p>


<h3>Author(s)</h3>

<p>Stefanos Fafalios
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dirknn.cv">dirknn.cv</a>, <a href="#topic+knn">knn</a>, <a href="#topic+vmf.mle">vmf.mle</a>, <a href="#topic+spml.mle">spml.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
x &lt;- x/sqrt( rowSums(x^2) )
y&lt;- as.numeric( iris[, 5] )
a &lt;- dirknn(x, x, y, k = 2:10)
</code></pre>

<hr>
<h2 id='Limited+20number+20of+20eigenvalues+20and+20eigenvectors+20of+20a+20symmetric+20matrix'>
Limited number of eigenvalues and eigenvectors of a symmetric matrix
</h2><span id='topic+eigen.sym'></span>

<h3>Description</h3>

<p>Limited number of eigenvalues and eigenvectors of a symmetric matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigen.sym(A, k, vectors = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Limited+2B20number+2B20of+2B20eigenvalues+2B20and+2B20eigenvectors+2B20of+2B20a+2B20symmetric+2B20matrix_+3A_a">A</code></td>
<td>

<p>A symmetric matrix.
</p>
</td></tr>
<tr><td><code id="Limited+2B20number+2B20of+2B20eigenvalues+2B20and+2B20eigenvectors+2B20of+2B20a+2B20symmetric+2B20matrix_+3A_k">k</code></td>
<td>

<p>The number of eigenvalues and eigenvectors to extract.
</p>
</td></tr>
<tr><td><code id="Limited+2B20number+2B20of+2B20eigenvalues+2B20and+2B20eigenvectors+2B20of+2B20a+2B20symmetric+2B20matrix_+3A_vectors">vectors</code></td>
<td>

<p>A flag that indicates if the eigenvectors will be returned (default: vectors = True)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls the same function from the Armadillo library in C++. 
It is quite faster than R's built in function &quot;eigen&quot; if the number of 
eigenvalues and eigenvectors (argument k) is small. 
</p>
<p>The k largest, in magnitude, eigenvalues are returned. Hence, if the matrix 
is not positive definite you may get negative eigenvalues as well. So, it is 
advised to use it with positive definite matrices.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>values</code></td>
<td>

<p>The eigenvalues.
</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>

<p>The eigenvectors.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Armadillo library in C++ and Stefanos Fafalios and Manos Papadakis.
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hd.eigen">hd.eigen</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrnorm(500, 100 )
s &lt;- Rfast::cova(x)
res&lt;-eigen.sym(s, 5)
x &lt;- s &lt;- NULL

</code></pre>

<hr>
<h2 id='Linear+20models+20for+20large+20scale+20data'>
Linear models for large scale data
</h2><span id='topic+lmfit'></span>

<h3>Description</h3>

<p>Linear models for large scale data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmfit(x, y, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Linear+2B20models+2B20for+2B20large+2B20scale+2B20data_+3A_x">x</code></td>
<td>

<p>The design matrix with the data, where each column refers to a different sample of subjects. 
You must supply the design matrix, with the column of 1s. This function is the analogue of 
lm.fit and .lm.fit. 
</p>
</td></tr>
<tr><td><code id="Linear+2B20models+2B20for+2B20large+2B20scale+2B20data_+3A_y">y</code></td>
<td>

<p>A numerical vector or a numerical matrix. 
</p>
</td></tr>
<tr><td><code id="Linear+2B20models+2B20for+2B20large+2B20scale+2B20data_+3A_w">w</code></td>
<td>

<p>An optional numerical vector with weights. Note that if you supply this, the function does not make them sum to 1. So, you should do it. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We have simply exploitted R's powerful function and managed to do better than .lm.fit which is a really powerful 
function as well. This is a bare bones function as it returns only two things, the coefficients and the residuals. 
<a href="stats.html#topic+.lm.fit">.lm.fit</a> returns more and <a href="stats.html#topic+lm.fit">lm.fit</a> even more and finally <a href="stats.html#topic+lm">lm</a> returns too much.  
The motivatrion came form this site https://m-clark.github.io/docs/fastr.html . We changed the function a bit.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>

<p>The residuals of the linear model(s). 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Draper, N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition. 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+regression">regression</a>, <a href="#topic+allbetas">allbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+mvbetas">mvbetas</a>, <a href="#topic+cor.fsreg">cor.fsreg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200  ;  p &lt;- 5
X &lt;- matrnorm(n, p)
y &lt;- rnorm(n)
a1 &lt;- .lm.fit(X, y) 
a2 &lt;- lmfit(X, y) 
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Logistic+20and+20Poisson+20regression+20models'>
Logistic and Poisson regression models
</h2><span id='topic+glm_logistic'></span><span id='topic+glm_poisson'></span>

<h3>Description</h3>

<p>Logistic and Poisson regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm_logistic(x, y, full = FALSE,tol = 1e-09, maxiters = 100)
glm_poisson(x, y, full = FALSE,tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Logistic+2B20and+2B20Poisson+2B20regression+2B20models_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) and the columns are the variables. 
This can be a matrix or a data.frame (with factors).
</p>
</td></tr>
<tr><td><code id="Logistic+2B20and+2B20Poisson+2B20regression+2B20models_+3A_y">y</code></td>
<td>

<p>The dependent variable; a numerical vector with two values (0 and 1) for the logistic regression
or integer values, 0, 1, 2,... for the Poisson regression. 
</p>
</td></tr>
<tr><td><code id="Logistic+2B20and+2B20Poisson+2B20regression+2B20models_+3A_full">full</code></td>
<td>

<p>If this is FALSE, the coefficients and the deviance will be returned only. If this is TRUE, more information is returned.
</p>
</td></tr>
<tr><td><code id="Logistic+2B20and+2B20Poisson+2B20regression+2B20models_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Logistic+2B20and+2B20Poisson+2B20regression+2B20models_+3A_maxiters">maxiters</code></td>
<td>

<p>The max number of iterations that can take place in each regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is written in C++ and this is why it is very fast. 
</p>


<h3>Value</h3>

<p>When full is FALSE a list including:
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The regression coefficients.
</p>
</td></tr>
<tr><td><code>devi</code></td>
<td>

<p>The deviance of the model.
</p>
</td></tr>
</table>
<p>When full is TRUE a list including:
</p>
<table>
<tr><td><code>info</code></td>
<td>

<p>The regression coefficients, their standard error, their Wald test statistic and their p-value.
</p>
</td></tr>
<tr><td><code>devi</code></td>
<td>

<p>The deviance.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+logistic_only">logistic_only</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(100 * 3), ncol = 3)
y &lt;- rbinom(100, 1, 0.6)   ## binary logistic regression
a1 &lt;- glm_logistic(x, y, full = TRUE) 
a2 &lt;- glm(y ~ x, binomial)

x &lt;- matrix(rnorm(100 * 3), ncol = 3)
y &lt;- rpois(100, 10)   ## binary logistic regression
b1 &lt;- glm_poisson(x, y, full = TRUE) 
b2 &lt;- glm(y ~ x, poisson)

x&lt;-y&lt;-a1&lt;-a2&lt;-b1&lt;-b2&lt;-NULL

</code></pre>

<hr>
<h2 id='Logistic+20or+20Poisson+20regression+20with+20a+20single+20categorical+20predictor'>
Logistic or Poisson regression with a single categorical predictor
</h2><span id='topic+logistic.cat1'></span><span id='topic+poisson.cat1'></span>

<h3>Description</h3>

<p>Logistic or Poisson regression with a single categorical predictor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic.cat1(y, x, logged = FALSE)
poisson.cat1(y, x, logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20a+2B20single+2B20categorical+2B20predictor_+3A_y">y</code></td>
<td>

<p>A numerical vector with values 0 or 1. 
</p>
</td></tr>
<tr><td><code id="Logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20a+2B20single+2B20categorical+2B20predictor_+3A_x">x</code></td>
<td>

<p>A numerical vector with discrete numbers or a factor variable. This is suppose to be a categorical predictor. 
If you supply a continuous valued vector the function will obviously provide wrong results. 
<b>Note:</b> For the &quot;binomial.anova&quot; if this is a numerical vector it must contain strictly positive numbers, i.e.
1, 2, 3, 4, ..., no zeros are allowed. 
</p>
</td></tr>
<tr><td><code id="Logistic+2B20or+2B20Poisson+2B20regression+2B20with+2B20a+2B20single+2B20categorical+2B20predictor_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is a closed form solution for the logistic regression in the case of a single predictor variable. 
See the references for more information. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>info</code></td>
<td>

<p>A matrix similar to the one produced by the glm command. The estimates, their standard error, the Wald value and
the relevant p-value.
</p>
</td></tr>
<tr><td><code>devs</code></td>
<td>

<p>For the logistic regression case a vector with the null and the residual deviances, their difference and the 
significance of this difference.  
</p>
</td></tr>
<tr><td><code>res</code></td>
<td>

<p>For the Poisson regression case a vector with the log likelihood ratio test statistic value and its significance. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Stan Lipovetsky (2015). Analytical closed-form solution for binary logit regression by categorical
predictors. Journal of Applied Statistics, 42(1): 37&ndash;49.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson.anova">poisson.anova</a>, <a href="#topic+poisson.anovas">poisson.anovas</a>, <a href="stats.html#topic+anova">anova</a>, <a href="#topic+logistic_only">logistic_only</a>, <a href="#topic+poisson_only">poisson_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(20000, 1, 0.6)
x &lt;- as.factor( rbinom(20000, 3, 0.5) )
a1 &lt;- logistic.cat1(y, x)
#a2 &lt;- glm(y ~ x, binomial) 

y &lt;- rpois(20000, 10)
x &lt;- as.factor( rbinom(20000, 3, 0.5) )
a1 &lt;- poisson.cat1(y, x)
#a2 &lt;- glm(y ~ x, poisson) 

x&lt;-y&lt;-a1&lt;-a2&lt;-NULL
</code></pre>

<hr>
<h2 id='Mahalanobis+20distance'>Mahalanobis distance
</h2><span id='topic+mahala'></span>

<h3>Description</h3>

<p>Mahalanobis distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mahala(x, mu, sigma, ischol = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mahalanobis+2B20distance_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where rows denotes observations (vectors) and the columns contain the variables.
</p>
</td></tr>
<tr><td><code id="Mahalanobis+2B20distance_+3A_mu">mu</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code id="Mahalanobis+2B20distance_+3A_sigma">sigma</code></td>
<td>

<p>The covariance or any square symmetric matrix.
</p>
</td></tr>
<tr><td><code id="Mahalanobis+2B20distance_+3A_ischol">ischol</code></td>
<td>

<p>A boolean variable set to true if the Cholesky decomposition of the covariance matrix is supplied in the argument \&quot;sigma\&quot;.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the Mahalanobis distances.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;, 
</p>
<p>C++ and R implementation and documentation: Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dista">dista</a>, <a href="#topic+colmeans">colmeans</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 50), ncol = 50 )
m &lt;- colmeans(x)
s &lt;- cov(x)
a1 &lt;- mahala(x, m, s) 
</code></pre>

<hr>
<h2 id='Many+20+28and+20one+29+20area+20under+20the+20curve+20values'>
Many area under the curve values
</h2><span id='topic+colaucs'></span><span id='topic+auc'></span>

<h3>Description</h3>

<p>Many area under the curve values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colaucs(group, preds)
auc(group, preds)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20+2B28and+2B20one+2B29+2B20area+2B20under+2B20the+2B20curve+2B20values_+3A_group">group</code></td>
<td>

<p>A numerical vector with two values, one of which must be strictly 1. 
</p>
</td></tr>
<tr><td><code id="Many+2B20+2B28and+2B20one+2B29+2B20area+2B20under+2B20the+2B20curve+2B20values_+3A_preds">preds</code></td>
<td>

<p>A numerical matrix with scores, probabilities or any other measure. 
In the case of auc this is a vector.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AUCs are calculated column-wise or just an AUC if the vector function is used. 
</p>


<h3>Value</h3>

<p>A vector with length equal to the number of columns of the &quot;preds&quot; argument, with  
the AUC values for each column. If the &quot;auc&quot; function is used then a signle number is returned.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ttests">ttests</a>, <a href="#topic+ttest">ttest</a>, <a href="#topic+ftests">ftests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 200 variables, hence 200 AUCs will be calculated
x &lt;- matrix( rnorm(100 * 200), ncol = 200 )
ina &lt;- rbinom(100, 1, 0.6)
colaucs(ina, x)
a &lt;- colaucs(ina, x) 
b &lt;- auc(ina, x[, 1])
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+202+20sample+20proportions+20tests'>
Many 2 sample proportions tests
</h2><span id='topic+proptests'></span>

<h3>Description</h3>

<p>It performs very many 2 sample proportions tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proptests(x1, x2, n1, n2) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B202+2B20sample+2B20proportions+2B20tests_+3A_x1">x1</code></td>
<td>

<p>A vector with the successes of the one group.
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20proportions+2B20tests_+3A_x2">x2</code></td>
<td>

<p>A vector with the successes of the one group.
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20proportions+2B20tests_+3A_n1">n1</code></td>
<td>

<p>A vector with the number of trials of the one group.
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20proportions+2B20tests_+3A_n2">n2</code></td>
<td>

<p>A vector with the number of trials of the one group.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 2-sample proportions test is performed for each pair of proportions of teh two groups. 
</p>


<h3>Value</h3>

<p>A matrix with the proportions of each group (two columns), the test statistic and the p-value of each test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>B. L. Welch (1951). On the comparison of several mean values: an alternative approach. Biometrika, 38(3/4), 330-336.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ttests">ttests</a>, <a href="#topic+ftests">ftests</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 10000 variables, hence 10000 t-tests will be performed
set.seed(12345)
x1 &lt;- rpois(500, 5)
x2 &lt;- rpois(500, 5)
n1 &lt;- rpois(1000, 40)
n2 &lt;- rpois(1000, 40)
a &lt;- proptests(x1, x2, n1, n2)
mean(a[, 4]&lt;0.05)

x1 &lt;- rbinom(500, 500, 0.6)
x2 &lt;- rbinom(500, 500, 0.6)
b &lt;- proptests(x1, x2, 500, 500)
mean(b[, 4]&lt;0.05)
</code></pre>

<hr>
<h2 id='Many+202+20sample+20tests'>
Many 2 sample tests tests
</h2><span id='topic+ttests'></span><span id='topic+mcnemars'></span><span id='topic+var2tests'></span>

<h3>Description</h3>

<p>It performs very many 2 sample tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ttests(x, y = NULL, ina, paired = FALSE, logged = FALSE, parallel = FALSE)
mcnemars(x, y = NULL, ina, logged = FALSE) 
var2tests(x, y = NULL, ina, alternative = "unequal", logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B202+2B20sample+2B20tests_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20tests_+3A_y">y</code></td>
<td>

<p>A second matrix with the data of the second group. If this is NULL (default value) then the argument ina must be supplied. Notice that when you supply the two matrices the procedure is two times faster.
</p>
</td></tr> 
<tr><td><code id="Many+2B202+2B20sample+2B20tests_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s and 2s indicating the two groups. Be careful, the function is designed to accept only these two numbers. In addition, if your &quot;y&quot; is NULL, you must specify &quot;ina&quot;.
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20tests_+3A_alternative">alternative</code></td>
<td>

<p>The type of hypothesis to be checked, &quot;equal&quot;, &quot;greater&quot;, &quot;less&quot;. 
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20tests_+3A_paired">paired</code></td>
<td>

<p>If the groups are not independent paired t-tests should be performed and this must be TRUE, otherwise, 
leave it FALSE. In this case, the two groups must have equal smaple sizes, otherwise no test will be performed.
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20tests_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
<tr><td><code id="Many+2B202+2B20sample+2B20tests_+3A_parallel">parallel</code></td>
<td>

<p>Should parallel implentations take place in C++? The default value is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the ttests, if the groups are independent, the Welch's t-test (without assuming equal variances) is 
performed. Otherwise many paired t-tests are performed. The McNemar's test requires a number of observations, 
at least 30 would be good in order for the test to have some power and be size corect.  
</p>


<h3>Value</h3>

<p>A matrix with the test statistic, the degrees of freedom (if the groups are independent) and the p-value 
(or their logarithm) of each test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>B. L. Welch (1951). On the comparison of several mean values: an alternative approach. Biometrika, 38(3/4), 330-336.
</p>
<p>McNemar Q. (1947). Note on the sampling error of the difference between correlated proportions or percentages. Psychometrika. 12(2):153-157. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftests">ftests</a>, <a href="#topic+anovas">anovas</a>, <a href="#topic+ttest">ttest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1000 variables, hence 1000 t-tests will be performed
x = matrnorm(100, 100)
## 100 observations in total
ina = rbinom(100, 1, 0.6) + 1   ## independent samples t-test
ttests(x, ina = ina)
x1 = x[ina == 1, ]
x2 = x[ina == 2, ]
ttests(x1, x2)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20analysis+20of+20variance+20tests+20with+20a+20discrete+20variable'>
Many analysis of variance tests with a discrete variable
</h2><span id='topic+poisson.anovas'></span><span id='topic+quasipoisson.anovas'></span><span id='topic+geom.anovas'></span>

<h3>Description</h3>

<p>Many analysis of variance tests with a discrete variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisson.anovas(y, ina, logged = FALSE) 
quasipoisson.anovas(y, ina, logged = FALSE)
geom.anovas(y, ina, type = 1, logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20analysis+2B20of+2B20variance+2B20tests+2B20with+2B20a+2B20discrete+2B20variable_+3A_y">y</code></td>
<td>

<p>A numerical matrix with discrete valued data, i.e. counts for the case of the Poisson, or with 0s and 1s for the 
case of the Bernoulli distribution. Each column represents a variable. 
</p>
</td></tr>
<tr><td><code id="Many+2B20analysis+2B20of+2B20variance+2B20tests+2B20with+2B20a+2B20discrete+2B20variable_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with discrete numbers starting from 1, i.e. 1, 2, 3, 4,... or a factor variable. 
This is suppose to be a categorical predictor. If you supply a continuous valued vector the function 
will obviously provide wrong results.
</p>
</td></tr>
<tr><td><code id="Many+2B20analysis+2B20of+2B20variance+2B20tests+2B20with+2B20a+2B20discrete+2B20variable_+3A_type">type</code></td>
<td>

<p>This rgument is for the geometric distribution. Type 1 refers to the case where the minimum is zero and type 2 for the case of the minimum being 1. 
</p>
</td></tr>
<tr><td><code id="Many+2B20analysis+2B20of+2B20variance+2B20tests+2B20with+2B20a+2B20discrete+2B20variable_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the analysis of variance with count data. 
What we do is many log-likelihood ratio tests. For the quasi Poisson case we scale the difference 
in the deviances.
</p>


<h3>Value</h3>

<p>A matrix with two values, the difference in the deviances (test statistic) and the relevant p-value. 
For the case of quasi Poisson the estimated <code class="reqn">\phi</code> parameter is also returned.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+g2tests">g2tests</a>, <a href="#topic+poisson.anova">poisson.anova</a>, <a href="stats.html#topic+anova">anova</a>, <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+poisson.mle">poisson.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ina &lt;- rbinom(500, 3, 0.5) + 1 
## Poisson example
y &lt;- matrix( rpois(500 * 100, 10), ncol= 100 )
a1 &lt;- poisson.anovas(y, ina)
y &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20ANCOVAs'>
Many ANCOVAs
</h2><span id='topic+ancovas'></span>

<h3>Description</h3>

<p>Many ANCOVAs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ancovas(y, ina, x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20ANCOVAs_+3A_y">y</code></td>
<td>

<p>A matrix with the data, where the rows denote the observations and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20ANCOVAs_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Be careful, the function 
is desinged to accept numbers greater than zero. 
</p>
</td></tr>
<tr><td><code id="Many+2B20ANCOVAs_+3A_x">x</code></td>
<td>

<p>A numerical vector whose length is equal to the number of rows of y. This is the covariate. 
</p>
</td></tr>
<tr><td><code id="Many+2B20ANCOVAs_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many Analysis of covariance tests are performed. No interaction between the factor and the covariate 
is tested. Only the main effects. The design need not be balanced. The values of ina need not have the 
same frequency. The sums of squares have been adjusted to accept balanced and unbalanced designs. 
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value for the factor variable and the covariate. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>D.C. Montgomery (2001). Design and analysis of experiments (5th Edition). New York: John Wiley &amp; Sons 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftests">ftests</a>, <a href="#topic+ttests">ttests</a>, <a href="#topic+anovas">anovas</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 100 variables, hence 100 F-tests will be performed
y &lt;- matrix( rnorm(90 * 100), ncol = 100 )
ina &lt;- rbinom(90, 2, 0.5) + 1
x &lt;- rnorm(90)
a &lt;- ancovas(y, ina, x)

m1 &lt;- lm(y[, 15] ~ factor(ina) + x)
m2 &lt;- lm(y[, 15] ~ x + factor(ina))
res&lt;-anova(m1)
res&lt;-anova(m2)
y &lt;- NULL
a[15, ]  ## the same with the m2 model, but not the m1

</code></pre>

<hr>
<h2 id='Many+20ANOVAS+20for+20count+20data+20with+20Poisson+20or+20quasi+20Poisson+20models'>
Many ANOVAS for count data with Poisson or quasi Poisson models
</h2><span id='topic+colpoisson.anovas'></span><span id='topic+colquasipoisson.anovas'></span>

<h3>Description</h3>

<p>Many ANOVAS for count data with Poisson or quasi Poisson models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colpoisson.anovas(y, x, logged = FALSE) 
colquasipoisson.anovas(y, x, logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20ANOVAS+2B20for+2B20count+2B20data+2B20with+2B20Poisson+2B20or+2B20quasi+2B20Poisson+2B20models_+3A_y">y</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
<tr><td><code id="Many+2B20ANOVAS+2B20for+2B20count+2B20data+2B20with+2B20Poisson+2B20or+2B20quasi+2B20Poisson+2B20models_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) 
and the columns are the variables. This must be a matrix with the categorical 
variables as numbers, starting from 1. Poisson or quassi Poisson ANOVA takes place
for each column.
</p>
</td></tr>
<tr><td><code id="Many+2B20ANOVAS+2B20for+2B20count+2B20data+2B20with+2B20Poisson+2B20or+2B20quasi+2B20Poisson+2B20models_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Poisson or quassi Poisson ANOVA takes place at each column.
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the (logged) p-value for each predictor variable. 
In the case of the quasi Poisson, the <code class="reqn">\phi</code> is returned as well. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson.anova">poisson.anova</a> <a href="#topic+boot.ttest2">boot.ttest2</a>, <a href="#topic+ttest2">ttest2</a>, <a href="#topic+ftest">ftest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rpois(200, 10)
x &lt;- matrix(rbinom(200 * 10, 3, 0.5 ), ncol = 10)
</code></pre>

<hr>
<h2 id='Many+20exponential+20regressions'>
Many exponential regressions</h2><span id='topic+expregs'></span>

<h3>Description</h3>

<p>Many exponential regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expregs(y, x, di, tol = 1e-09, logged = FALSE)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20exponential+2B20regressions_+3A_y">y</code></td>
<td>

<p>A vector with positive data (including zeros).
</p>
</td></tr>
<tr><td><code id="Many+2B20exponential+2B20regressions_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the predictor variables.  
</p>
</td></tr>
<tr><td><code id="Many+2B20exponential+2B20regressions_+3A_di">di</code></td>
<td>

<p>A vector of size equal to that of y with 0s and 1s indicating censoring or not respectively.
</p>
</td></tr>
<tr><td><code id="Many+2B20exponential+2B20regressions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to stop the newton-Raphson iterations. It is set to 1e-09 by default. 
</p>
</td></tr>
<tr><td><code id="Many+2B20exponential+2B20regressions_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We have implemented the newton-Raphson in order to avoid unnecessary calculations.  
</p>


<h3>Value</h3>

<p>A matrix with three columns, the test statistic, its associated (logged) p-value and the BIC of each model.   
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+univglms">univglms</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+logistic_only">logistic_only</a>,  <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 200 variables, hence 200 univariate regressions are to be fitted
x &lt;- matrnorm(100, 100)
y &lt;- rexp(100, 4)
expregs(y, x, di = rep(1, length(y)))
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20F-tests+20with+20really+20huge+20matrices'>
Many F-tests with really huge matrices
</h2><span id='topic+list.ftests'></span>

<h3>Description</h3>

<p>Many F-tests with really huge matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list.ftests(x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20F-tests+2B20with+2B20really+2B20huge+2B20matrices_+3A_x">x</code></td>
<td>

<p>A list with many big size matrices. Each element of the list contains a matrix. This is the <code><a href="#topic+ftests">ftests</a></code>
function but with really huge matrices, which cannot be loaded into R as a single matrix.
</p>
</td></tr>
<tr><td><code id="Many+2B20F-tests+2B20with+2B20really+2B20huge+2B20matrices_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Welch's F-test (without assuming equal variances) is performed just like in the &quot;ftests&quot; function.
The difference is that you have a really huge matrix which you cannot load into R. In the &quot;ftests&quot; function,
the argument &quot;ina&quot; denotes the different groups. Here, you &quot;cut&quot; the matrix into smaller ones, each of which
denotes a different group and put them in a list.
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value of each test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>B.L. Welch (1951). On the comparison of several mean values: an alternative approach. Biometrika, 38(3/4), 330-336.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ftests">ftests</a>, <a href="#topic+ttests">ttests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(300, 500)
ina &lt;- rbinom(300, 2, 0.6) + 1
a &lt;- list()
a[[ 1 ]] &lt;- x[ina == 1, ]
a[[ 2 ]] &lt;- x[ina == 2, ]
a[[ 3 ]] &lt;- x[ina == 3, ]
mod &lt;- list.ftests(a)
z &lt;- NULL
a &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20G-square+20and+20Chi-square+20tests+20of+20indepedence'>
Many G-square tests of indepedence
</h2><span id='topic+g2tests'></span><span id='topic+g2tests_perm'></span><span id='topic+chi2tests'></span>

<h3>Description</h3>

<p>Many G-square tests of indepdence with and without permutations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g2tests(data, x, y, dc)
g2tests_perm(data, x, y, dc, nperm) 
chi2tests(data, x, y, dc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20G-square+2B20and+2B20Chi-square+2B20tests+2B20of+2B20indepedence_+3A_data">data</code></td>
<td>

<p>A numerical matrix with the data. <b>The minimum must be 0, otherwise the function can crash or will produce 
wrong results</b>. The data must be consecutive numbers.
</p>
</td></tr>
<tr><td><code id="Many+2B20G-square+2B20and+2B20Chi-square+2B20tests+2B20of+2B20indepedence_+3A_x">x</code></td>
<td>

<p>An integer number or a vector of integer numbers showing the other variable(s) to be used for the <code class="reqn">G^2</code> test of 
independence.
</p>
</td></tr>
<tr><td><code id="Many+2B20G-square+2B20and+2B20Chi-square+2B20tests+2B20of+2B20indepedence_+3A_y">y</code></td>
<td>

<p>An integer number showing which column of data to be used.
</p>
</td></tr>
<tr><td><code id="Many+2B20G-square+2B20and+2B20Chi-square+2B20tests+2B20of+2B20indepedence_+3A_dc">dc</code></td>
<td>

<p>A numerical value equal to the number of variables (or columns of the data matrix) indicating the number of distinct, 
unique values (or levels) of each variable. Make sure you give the correct numbers here, otherwise the degrees of 
freedom will be wrong.
</p>
</td></tr>
<tr><td><code id="Many+2B20G-square+2B20and+2B20Chi-square+2B20tests+2B20of+2B20indepedence_+3A_nperm">nperm</code></td>
<td>

<p>The number of permutations. The permutations test is slower than without permutations and should be used with small 
sample sizes or when the contigency tables have zeros. When there are few variables, R's &quot;chisq.test&quot; function is 
faster, but as the number of variables increase the time difference with R's procedure becomes larger and larger.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function does all the pairwise <code class="reqn">G^2</code> test of independence and gives the position inside the matrix. 
The user must build the associations matrix now, similarly to the correlation matrix. See the examples of how to do 
that. The p-value is not returned, we leave this to the user. See the examples of how to obtain it. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>

<p>The <code class="reqn">G^2</code> or <code class="reqn">\chi^2</code> test statistic for each pair of variables.
</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>

<p>This is returned when you have selected the permutation based <code class="reqn">G^2</code> test.
</p>
</td></tr>
<tr><td><code>x</code></td>
<td>

<p>The row or variable of the data.
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>

<p>The column or variable of the data.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>The degrees of freedom of each test.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giorgos Borboudakis. The permutation version used a C++ code by John Burkardt.
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. (2017). Conditional independence test for categorical data using Poisson log-linear model. 
Journal of Data Science, 15(2):347-356.
</p>
<p>Tsamardinos, I., &amp; Borboudakis, G. (2010). Permutation testing improves Bayesian network learning. 
In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 322-337). 
Springer Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+g2Test">g2Test</a>, <a href="#topic+g2Test_perm">g2Test_perm</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nvalues &lt;- 3
nvars &lt;- 10
nsamples &lt;- 2000
data &lt;- matrix( sample( 0:(nvalues - 1), nvars * nsamples, replace = TRUE ), nsamples, nvars )
dc &lt;- rep(nvalues, nvars)
a &lt;- g2tests(data = data, x = 2:9, y = 1, dc = dc)
pval &lt;- pchisq(a$statistic, a$df, lower.tail = FALSE)  ## p-value
b &lt;- g2tests_perm(data = data, x = 2:9, y = 1, dc = dc, nperm = 1000)
a&lt;-b&lt;-data&lt;-NULL
</code></pre>

<hr>
<h2 id='Many+20Gini+20coefficients'>
Many Gini coefficients
</h2><span id='topic+ginis'></span>

<h3>Description</h3>

<p>Many Gini coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ginis(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20Gini+2B20coefficients_+3A_x">x</code></td>
<td>

<p>A matrix with non negative data. The rows are observations and the columns denote the variables.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We have implemented the fast version of the Gini coefficient. See <a href="https://en.wikipedia.org/wiki/Gini_coefficient">wikipedia</a> for more details.
</p>


<h3>Value</h3>

<p>A vector with the Gini coefficient, one for each variable.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colskewness">colskewness</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+corpairs">corpairs</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rpois(500 * 1000, 1000), ncol = 1000 )
a &lt;- ginis(x)
</code></pre>

<hr>
<h2 id='Many+20hypothesis+20tests+20for+20two+20means+20of+20percentages'>
Many hypothesis tests for two means of percentages
</h2><span id='topic+percent.ttests'></span>

<h3>Description</h3>

<p>Many hypothesis tests for two means of percentages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percent.ttests(x, y, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20hypothesis+2B20tests+2B20for+2B20two+2B20means+2B20of+2B20percentages_+3A_x">x</code></td>
<td>

<p>A numericalmatrix with the percentages of the first sample. Any value between 0 and 1 
(inclusive) is allowed.
</p>
</td></tr>
<tr><td><code id="Many+2B20hypothesis+2B20tests+2B20for+2B20two+2B20means+2B20of+2B20percentages_+3A_y">y</code></td>
<td>

<p>A numerical matrix with the percentages of the first sample. Any value between 0 and 1 
(inclusive) is allowed.
</p>
</td></tr> 
<tr><td><code id="Many+2B20hypothesis+2B20tests+2B20for+2B20two+2B20means+2B20of+2B20percentages_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the <code><a href="#topic+prop.reg">prop.reg</a></code> but with a single categorical predictor which has two 
levels only. It is like a t-test for the means of two samples haivng percentages. 
</p>


<h3>Value</h3>

<p>A matrix with three columns, the phi parameter, the test statistic and its associated 
p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Papke L. E. &amp; Wooldridge J. (1996). Econometric methods for fractional response 
variables with an application to 401(K) plan participation rates. Journal of Applied 
Econometrics, 11(6): 619-632.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 
2nd edition, 1989.  
</p>


<h3>See Also</h3>

<p><code> link{percent.ttest}, <a href="#topic+prop.reg">prop.reg</a>, <a href="#topic+ttest2">ttest2</a>, <a href="#topic+ftest">ftest</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rbeta(100 * 10, 3, 1), ncol = 10)
y &lt;- matrix( rbeta(50 * 10, 7.5, 2.5), ncol = 10)
res&lt;-percent.ttests(x, y)
</code></pre>

<hr>
<h2 id='Many+20moment+20and+20maximum+20likelihood+20estimations+20of+20variance+20components'>
Many moment and maximum likelihood estimations of variance components
</h2><span id='topic+colvarcomps.mom'></span><span id='topic+colvarcomps.mle'></span>

<h3>Description</h3>

<p>Many moment and maximum likelihood estimations of variance components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colvarcomps.mom(x, id, parallel = FALSE) 
colvarcomps.mle(x, id, ranef = FALSE, tol= 1e-08, maxiters = 100, 
parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20moment+2B20and+2B20maximum+2B20likelihood+2B20estimations+2B20of+2B20variance+2B20components_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where each column refers to a different sample of subjects. 
</p>
</td></tr>
<tr><td><code id="Many+2B20moment+2B20and+2B20maximum+2B20likelihood+2B20estimations+2B20of+2B20variance+2B20components_+3A_id">id</code></td>
<td>

<p>A numerical vector indicating the subject. You must put consecutive numbers and no zero values. 
Alternatively this can be a factor variable.
</p>
</td></tr>
<tr><td><code id="Many+2B20moment+2B20and+2B20maximum+2B20likelihood+2B20estimations+2B20of+2B20variance+2B20components_+3A_ranef">ranef</code></td>
<td>

<p>Do you also want the random effects to be returned? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Many+2B20moment+2B20and+2B20maximum+2B20likelihood+2B20estimations+2B20of+2B20variance+2B20components_+3A_tol">tol</code></td>
<td>

<p>The tolerance level to terminate the golden ratio search. 
</p>
</td></tr>
<tr><td><code id="Many+2B20moment+2B20and+2B20maximum+2B20likelihood+2B20estimations+2B20of+2B20variance+2B20components_+3A_maxiters">maxiters</code></td>
<td>
<p>The maximum number of iterations to perform.
</p>
</td></tr>
<tr><td><code id="Many+2B20moment+2B20and+2B20maximum+2B20likelihood+2B20estimations+2B20of+2B20variance+2B20components_+3A_parallel">parallel</code></td>
<td>

<p>Should the computations run in parallel? TRUE or FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the &quot;colvarcomp.mom&quot; works for <b>balanced designs only</b>, i.e. for each subject the same number of
measurements have been taken. The &quot;colvarcomps.mle&quot; works for unbalanced as well.
</p>
<p>The variance components, the variance of the between measurements and the 
variance of the within are estimated using moment estimators. The &quot;colvarcomps.mom&quot; 
is the moment analogue of a random effects model which uses likelihood estimation (&quot;colvarcomps.mle&quot;). 
It is much faster, but can give negative variance of the random effects, in which case it becomes zero.
</p>
<p>The maximum likelihood version is a bit slower (try youselves to see the difference), but statistically 
speaking is to be preferred when small samples are available. The reason why it is only a little bit slower 
and not a lot slower as one would imagine is because we are using a closed formula to calculate the two variance
components (Demidenko, 2013, pg. 67-69). Yes, there are closed formulas for linear mixed models.     
</p>


<h3>Value</h3>

<p>For the &quot;colvarcomps.mom&quot;:
A matrix with 5 columns, The MSE, the estimate of the between variance, 
the variance components ratio and a 95% confidence 
for the ratio.
</p>
<p>For the &quot;colvarcomps.mle&quot;:
<b>If ranef = FALSE</b> 
a list with a single component called &quot;info&quot;. That is a matrix with 3 columns, The MSE, the estimate of 
the between variance and the log-likelihood value. <b>If ranef = TRUE</b> a list including &quot;info&quot; and an 
extra component called &quot;ranef&quot; containing the random effects. It is a matrix with the same number of columns
as the data. Each column contains the randome effects of each variable. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>D.C. Montgomery (2001). Design and analysis of experiments (5th Edition). New York: John Wiley &amp; Sons. 
</p>
<p>Charles S. Davis (2002). Statistical methods for the analysis of repeated measures. New York: Springer-Verlag.
</p>
<p>Demidenko E. (2013). Mixed Models: Thoery and Applications with R 2nd Edition). New Jersey: 
John Wiley &amp; Sons (Excellent book).
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+varcomps.mle">varcomps.mle</a>, <a href="#topic+colrint.regbx">colrint.regbx</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example taken from Montgomery, page 514-517.
y &lt;- c(98, 97, 99, 96, 91, 90, 93, 92,
96, 95, 97, 95, 95, 96, 99, 98)
y &lt;- matrix(y)
id &lt;- rep(1:4, each = 4)

x &lt;- rmvnorm(100, numeric(100), diag(rexp(100)) )
id &lt;- rep(1:25, each = 4)
n &lt;- 25  ;  d &lt;- 4
a &lt;- colvarcomps.mom(x, id) 
mean(a[, 4]&lt;0 &amp; a[, 5]&gt;0)  
b &lt;- colvarcomps.mle(x, id) 
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20multi-sample+20tests'>
Many multi-sample tests
</h2><span id='topic+ftests'></span><span id='topic+anovas'></span><span id='topic+vartests'></span><span id='topic+block.anovas'></span>

<h3>Description</h3>

<p>Many multi-sample tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftests(x, ina, logged = FALSE)
anovas(x, ina, logged = FALSE)
vartests(x, ina, type = "levene", logged = FALSE)
block.anovas(x, treat, block, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20multi-sample+2B20tests_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the observations (and the two groups) and the columns are the 
variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20multi-sample+2B20tests_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Be careful, the function is desinged to 
accept numbers greater than zero. 
Alternatively it can be a factor variable.
</p>
</td></tr>
<tr><td><code id="Many+2B20multi-sample+2B20tests_+3A_type">type</code></td>
<td>

<p>This is for the variances test and can be either &quot;levene&quot; or &quot;bf&quot; corresponding to Levene's or Brown-Forsythe's 
testing procedure.
</p>
</td></tr>
<tr><td><code id="Many+2B20multi-sample+2B20tests_+3A_treat">treat</code></td>
<td>

<p>In the case of the blocking ANOVA this argument plays the role of the &quot;ina&quot; argument.
</p>
</td></tr>
<tr><td><code id="Many+2B20multi-sample+2B20tests_+3A_block">block</code></td>
<td>
<p>This item, in the blocking ANOVA denotes the subjects which are the same. 
Similarly to &quot;ina&quot; a numeric vector with 1s, 2s, 3s and so on.
</p>
</td></tr>
<tr><td><code id="Many+2B20multi-sample+2B20tests_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Welch's F-test (without assuming equal variances) is performed with the &quot;ftests&quot; function. The &quot;anovas&quot; 
function perform the classical (Fisher's) one-way analysis of variance (ANOVA) which assumes equal variance 
across the groups. 
</p>
<p>The &quot;vartests&quot; perform hypothesis test for the equality of the variances in two ways, either via the Levene or via 
the Brown-Forshythe procedure. Levene's test employs the means, whereas the Brown-Forsythe procedure employs the 
medians and is therefore more robust to outliers. The &quot;var2tests&quot; implement the classical F test.
</p>
<p>The &quot;block.anova&quot; is the ANOVA with blocking, randomised complete block design (RCBD). In this case, for every 
combination of the block and treatment values, there is only one observation. The mathematics are the same as 
in the case of two way ANOVA, but the assumptions different and the testing procedure also different. 
In addition, no interaction is present. 
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value of each test. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Welch B.L. (1951). On the comparison of several mean values: an alternative approach. 
Biometrika, 38(3/4), 330-336.
</p>
<p>Montgomery D.C. (2001). Design and analysis of experiments (5th Edition). 
New York: John Wiley &amp; Sons. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ttests">ttests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(300 * 50), ncol = 50 )
## 300 observations in total
ina &lt;- rbinom(300, 3, 0.6) + 1   
a1 &lt;- ftests(x, ina) 
a2 &lt;- anovas(x, ina) 
a3 &lt;- vartests(x, ina) 
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20multivariate+20simple+20linear+20regressions+20coefficients'>Many multivariate simple linear regressions coefficients
</h2><span id='topic+mvbetas'></span>

<h3>Description</h3>

<p>Many multivariate simple linear regressions coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvbetas(y, x, pvalue = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20multivariate+2B20simple+2B20linear+2B20regressions+2B20coefficients_+3A_y">y</code></td>
<td>

<p>A matrix with the data, where rows denotes the observations and the columns contain the dependent variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20multivariate+2B20simple+2B20linear+2B20regressions+2B20coefficients_+3A_x">x</code></td>
<td>

<p>A numerical vector with one continuous independent variable only. 
</p>
</td></tr>
<tr><td><code id="Many+2B20multivariate+2B20simple+2B20linear+2B20regressions+2B20coefficients_+3A_pvalue">pvalue</code></td>
<td>

<p>If you want a hypothesis test that each slope (beta coefficient) is equal to zero set this equal to TRUE. It will also produce all the correlations between y and x.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is a function somehow opposite to the <code><a href="#topic+allbetas">allbetas</a></code>. Instead of having one y and many xs we have many ys and one x.
</p>


<h3>Value</h3>

<p>A matrix with the constant (alpha) and the slope (beta) for each simple linear regression. 
If the p-value is set to TRUE, the correlation of each y with the x is calculated along with the relevant p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+allbetas">allbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- matrnorm(100, 100)
x &lt;- rnorm(100)
a &lt;- mvbetas(y, x, pvalue = FALSE)
b &lt;- matrix(nrow = 100, ncol = 2)
z &lt;- cbind(1, x)

a &lt;- mvbetas(y, x)
b[2, ] &lt;- coef( lm.fit( z, y[, 1] ) )
b[2, ] &lt;- coef( lm.fit( z, y[, 2] ) )
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20non+20parametric+20multi-sample+20tests'>
Many multi-sample tests
</h2><span id='topic+kruskaltests'></span><span id='topic+cqtests'></span>

<h3>Description</h3>

<p>Many multi-sample tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kruskaltests(x, ina, logged = FALSE) 
cqtests(x, treat, block, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20non+2B20parametric+2B20multi-sample+2B20tests_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20non+2B20parametric+2B20multi-sample+2B20tests_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Be careful, the function is desinged to 
accept numbers greater than zero.
</p>
</td></tr>
<tr><td><code id="Many+2B20non+2B20parametric+2B20multi-sample+2B20tests_+3A_treat">treat</code></td>
<td>

<p>In the case of the Cochran's Q test, this argument plays the role of the &quot;ina&quot; argument.
</p>
</td></tr>
<tr><td><code id="Many+2B20non+2B20parametric+2B20multi-sample+2B20tests_+3A_block">block</code></td>
<td>
<p>This item denotes the subjects which are the same. Similarly to &quot;ina&quot; a numeric vector with 1s, 
2s, 3s and so on.
</p>
</td></tr>
<tr><td><code id="Many+2B20non+2B20parametric+2B20multi-sample+2B20tests_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;kruskaltests&quot; performs the Kruskal-Wallis non parametric alternative to analysis of variance test.
The &quot;cqtests&quot; performs the Cocrhan's Q test for the equality of more than two groups whose values are 
strictly binary (0 or 1). This is a generalisation of the McNemar's test in the multi-sample case.
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value of each test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+block.anovas">block.anovas</a>, <a href="#topic+ftests">ftests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rexp(300 * 200), ncol = 200 )
ina &lt;- rbinom(300, 3, 0.6) + 1   
kruskaltests(x, ina)
x &lt;- matrix( rbinom(300 * 200, 1, 0.6), ncol = 200 )
treat &lt;- rep(1:3, each = 100)
block &lt;- rep(1:3, 100)  
cqtests(x, treat, block)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20odds+20ratio+20tests'>
Many odds ratio tests
</h2><span id='topic+odds'></span>

<h3>Description</h3>

<p>It performs very many odds ratio tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>odds(x, y = NULL, ina, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20odds+2B20ratio+2B20tests_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the observations and the columns are the variables. 
They must be 0s and 1s only.
</p>
</td></tr>
<tr><td><code id="Many+2B20odds+2B20ratio+2B20tests_+3A_y">y</code></td>
<td>

<p>A second matrix with the data of the second group. If this is NULL (default value) then the argument ina must 
be supplied. Notice that when you supply the two matrices the procedure is two times faster. They must be 0s and 1s
only.
</p>
</td></tr> 
<tr><td><code id="Many+2B20odds+2B20ratio+2B20tests_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s and 2s indicating the two groups. Be careful, the function is designed to accept only these two numbers. 
In addition, if your &quot;y&quot; is NULL, you must specify &quot;ina&quot;.
</p>
</td></tr>
<tr><td><code id="Many+2B20odds+2B20ratio+2B20tests_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many odds ratio tests are performed. 
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value (or their logarithm) of each test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Mosteller Frederick (1968). Association and Estimation in Contingency Tables. Journal of the American 
Statistical Association. 63(321):1-28.
</p>
<p>Edwards A.W.F. (1963). The measure of association in a 2x2 table. Journal of the Royal Statistical Society, Series A. 
126(1):109-114. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+odds.ratio">odds.ratio</a>, <a href="#topic+g2Test_univariate">g2Test_univariate</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rbinom(100 * 100, 1, 0.5), ncol = 100 )
ina &lt;- rep(1:2, each = 50)
a &lt;- odds(x, ina = ina)
</code></pre>

<hr>
<h2 id='Many+20one+20sample+20goodness+20of+20fit+20tests+20for+20categorical+20data'>
Many one sample goodness of fit tests for categorical data
</h2><span id='topic+cat.goftests'></span>

<h3>Description</h3>

<p>Many one sample goodness of fit tests for categorical data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cat.goftests(x, props, type = "gsquare", logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20one+2B20sample+2B20goodness+2B20of+2B20fit+2B20tests+2B20for+2B20categorical+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples and the columns are the variables. The data must be 
integers and be of the form 1, 2, 3, and so on. The minimum must be 1, and not zero. 
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20goodness+2B20of+2B20fit+2B20tests+2B20for+2B20categorical+2B20data_+3A_props">props</code></td>
<td>

<p>The assumed distribution of the data. A vector or percentages summing to 1. 
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20goodness+2B20of+2B20fit+2B20tests+2B20for+2B20categorical+2B20data_+3A_type">type</code></td>
<td>

<p>Either Pearson's <code class="reqn">\chi^2</code> test (&quot;chisquare&quot;) is used or the <code class="reqn">G^2</code> test (&quot;qsquare&quot;, default value). 
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20goodness+2B20of+2B20fit+2B20tests+2B20for+2B20categorical+2B20data_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a matrix of integers, where each column refers to a sample, the values of a categorical variable the 
function tests wether these values can be assumed to fit a specific distribution. 
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value of each test.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ttests">ttests</a>, <a href="#topic+ttest">ttest</a>, <a href="#topic+ftests">ftests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rbinom(300 * 100, 4, 0.6), ncol = 100 ) + 1
props &lt;- dbinom(0:4, 4, 0.6)
## can we assume that each column comes from a distribution  whose mass is given by props?
cat.goftests(x, props)
a1 &lt;- cat.goftests(x, props)  ## G-square test
a2 &lt;- cat.goftests(x, props, type = "chisq")  ## Chi-square test
cor(a1, a2)
mean( abs(a1 - a2) ) 
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20one+20sample+20tests'>
Many one sample tests
</h2><span id='topic+ttest'></span><span id='topic+proptest'></span><span id='topic+vartest'></span>

<h3>Description</h3>

<p>Many one sample tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proptest(x, n, p, alternative = "unequal", logged = FALSE) 
ttest(x, m, alternative = "unequal", logged = FALSE, conf = NULL)
vartest(x, sigma, alternative = "unequal", logged = FALSE, conf = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_x">x</code></td>
<td>

<p>A matrix with numerical data. Each column of the matrix corresponds to a sample, or a group. In the case of the &quot;proptest&quot; this is a vector integers ranging from 0 up to n. It is the number of &quot;successes&quot;. 
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_n">n</code></td>
<td>

<p>This is for the &quot;proptest&quot; only and is a vector with integer numbers specifying the number of tries for the proptest. Its size is equal to the size of x.
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_p">p</code></td>
<td>

<p>A vector with the assumed probabilities of success in the &quot;proptest&quot;. Its size is equal to the number of colums of the matrix x.
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_m">m</code></td>
<td>

<p>A vector with the assumed means. Its size is equal to the number of colums of the matrix x.
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_sigma">sigma</code></td>
<td>

<p>A vector with assumed variances. Its size is equal to the number of colums of the matrix x.
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_alternative">alternative</code></td>
<td>

<p>The type of hypothesis to be checked. Equal to (&quot;unequal&quot;), grater than(&quot;greater&quot;) or less than (&quot;less&quot;) the assumed parameter.
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
<tr><td><code id="Many+2B20one+2B20sample+2B20tests_+3A_conf">conf</code></td>
<td>

<p>If you want confidence intervals to be returned specify the confidence level, otherwise leave it NULL.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Despite the functions having been written in R, they are very fast.  
</p>


<h3>Value</h3>

<p>For all tests except for the &quot;sftests&quot; a matrix with two colums, the test statistic and the p-value respectively. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ftests">ftests</a>, <a href="#topic+ttests">ttests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>R &lt;- 100
## protest
x &lt;- rbinom(R, 50, 0.6)
n &lt;- rep(50, R)
p &lt;- rep(0.6, R)
a1 &lt;- proptest(x, n, p, "unequal", logged = FALSE)
res&lt;-sum( a1[, 2] &lt; 0.05 ) / R

## vartest
x &lt;- matrnorm(100, 100)
a2 &lt;- vartest(x, rep(1, R) )
res&lt;-sum( a2[, 2] &lt; 0.05 )

## ttest
a4 &lt;- ttest(x, numeric(R) )
res&lt;-sum(a4[, 2] &lt; 0.05) / R
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20random+20intercepts+20LMMs+20for+20balanced+20data+20with+20a+20single+20identical+20covariate.'>
Many random intercepts LMMs for balanced data with a single identical covariate
</h2><span id='topic+colrint.regbx'></span>

<h3>Description</h3>

<p>Many random intercepts LMMs for balanced data with a single identical covariate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colrint.regbx(y, x, id)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20random+2B20intercepts+2B20LMMs+2B20for+2B20balanced+2B20data+2B20with+2B20a+2B20single+2B20identical+2B20covariate._+3A_y">y</code></td>
<td>

<p>A numerical matrix with the data. The subject values.
</p>
</td></tr>
<tr><td><code id="Many+2B20random+2B20intercepts+2B20LMMs+2B20for+2B20balanced+2B20data+2B20with+2B20a+2B20single+2B20identical+2B20covariate._+3A_x">x</code></td>
<td>

<p>A numerical vector with the same length as the number of rows of y indicating the fixed predictor variable. 
Its values are the same for all levels of y. An example of this x is time which is the same for all subjects.
</p>
</td></tr>
<tr><td><code id="Many+2B20random+2B20intercepts+2B20LMMs+2B20for+2B20balanced+2B20data+2B20with+2B20a+2B20single+2B20identical+2B20covariate._+3A_id">id</code></td>
<td>

<p>A numerical variable with 1, 2, ... indicating the subject. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a special case of a balanced random intercepts model with a compound symmetric covariance matrix and one 
single covariate which is constant for all replicates. An example, is time, which is the same for all subjects. 
Maximum likelihood estimation has been performed. In this case the mathematics exist in a closed formula 
(Demidenko, 2013, pg. 67-69). 
</p>
<p>This is the generalistion of <code><a href="#topic+rint.regbx">rint.regbx</a></code> to matrices. Assume you have many observations, gene 
expressions over time for example, and you want to calculate the random effects or something else for each 
expression. Instead of using a &quot;for&quot; loop with <code><a href="#topic+rint.regbx">rint.regbx</a></code> function we have used amtrix operations to 
make it even faster.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>info</code></td>
<td>

<p>A matrix with the random intercepts variance (between), the variance of the errors (within), the log-likelihood, the 
deviance (twice the log-likelihood) and the BIC. In the case of &quot;rint.reg&quot; it also includes the number of iterations 
required by the generalised least squares. 
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The estimated regression coefficients, which in the case of &quot;rint.regbx&quot; are simply two: the constant and the slope 
(time effect). 
</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>

<p>A matrix with random intercepts effects. Each row corresponds to a column in y. Instead of having a matrix with the 
same number of columns as y we return a transposed matrix. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Eugene Demidenko (2013). Mixed Models: Theory and Applications with R, 2nd Edition. New Jersey: Wiley &amp; Sons 
(excellent book).
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colvarcomps.mle">colvarcomps.mle</a>, <a href="#topic+rint.regbx">rint.regbx</a>, <a href="#topic+rm.lines">rm.lines</a>, <a href="#topic+varcomps.mom">varcomps.mom</a>, <a href="#topic+rint.reg">rint.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- matrix( rnorm(100 * 50), ncol = 50)
id &lt;- rep(1:20, each = 5)
x &lt;- rep(1:10, 10)
a&lt;- colrint.regbx(y, x, id)
</code></pre>

<hr>
<h2 id='Many+20regression+20based+20tests+20for+20single+20sample+20repeated+20measures'>
Many regression based tests for single sample repeated measures
</h2><span id='topic+rm.lines'></span><span id='topic+rm.anovas'></span>

<h3>Description</h3>

<p>Many regression based tests for single sample repeated measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm.lines(y, x, logged = FALSE)
rm.anovas(y, x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20regression+2B20based+2B20tests+2B20for+2B20single+2B20sample+2B20repeated+2B20measures_+3A_y">y</code></td>
<td>

<p>A matrix with the data, where each column refers to a different sample of subjects. For example, the first
column is the repeated measurements of a sample of subjects, the second column contains repeated measurements of
a second sample of subjects and so on. Within each column, the measurements of each subjects are stacked one
upon the other. Say for examples there are n subjects and each of them has been measured d times (in time or at
different experimental conditions). We put these in a matrix with just one column. The first d rows are the
measurements of subject 1, the next d rows are the measurements of subject 2 and so on.
</p>
</td></tr>
<tr><td><code id="Many+2B20regression+2B20based+2B20tests+2B20for+2B20single+2B20sample+2B20repeated+2B20measures_+3A_x">x</code></td>
<td>

<p>A numerical vector with time (usually) or the the predictor variable. For example the temperature,
or the pressure. See the details for more information. Its length is equal to the time points for example,
i.e. it must not have the same length as the number of rows of y. For the &quot;rm.lines&quot; this is a continuous
variable.
</p>
<p>For the &quot;rm.anovas&quot; this is treated as a categorical variable, indicating say the type of experimental condition,
but no difference between the points is important. Hence, for this function only, x can also be a facto variable.
</p>
</td></tr>
<tr><td><code id="Many+2B20regression+2B20based+2B20tests+2B20for+2B20single+2B20sample+2B20repeated+2B20measures_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to see whether the repeated measurements are associated with a single covariate, e.g. time we
perform many regressions and each time calculate the slope. For each subject, its regression slope with
the covariate is calculated. In the end a t-test for the hypothesis that the average slopes is zero is performed.
The regression slopes ignore that the measurements are not independent, but note that the slopes are independent,
because they come from different subjects. This is a simple, summary statistics based approach found in Davis
(2002), yet it can provide satisfactory results.
</p>
<p>The second approach (&quot;rm.anovas&quot;) found in Davis (2002) is the usual repeated measures ANOVA. In this case,
suppose you have taken measurements on one or more variables from the same group of people. See the example below
on how to put such data.
</p>


<h3>Value</h3>

<p>A matrix with the test statistic (t-test) and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Charles S. Davis (2002). Statistical methods for the analysis of repeated measures. Springer-Verlag, New York.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rint.regbx">rint.regbx</a>, <a href="#topic+rint.reg">rint.reg</a>, <a href="#topic+varcomps.mle">varcomps.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- c(74.5,81.5,83.6,68.6,73.1,79.4,
75.5,84.6,70.6,87.3,73.0,75.0,
68.9,71.6,55.9,61.9,60.5,61.8,
57.0,61.3,54.1,59.2,56.6,58.8,
78.3,84.9,64.0,62.2,60.1,78.7,
54.0,62.8,63.0,58.0,56.0,51.5,
72.5,68.3,67.8,71.5,65.0,67.7,
80.8,89.9,83.2,83.0,85.7,79.6)
y &lt;- as.matrix(y)
### the first 6 measurements are from subject 1, measurments 7-12 are from subject 2,
## measurements 13-18 are from subject 3 and so on.
x &lt;- c(-10, 25, 37, 50, 65, 80) ## all subjects were measured at the same time points
res&lt;-rm.lines(y, x) ## Is linear trend between the measurements and the temperature?
res&lt;-rm.anovas(y, x)  ## Tests whether the means of the individuals are the same
## the temperature is treated as categorical variable here.

## fake example
y &lt;- matrnorm(10, 4)
## the y matrix contains 4 repeated measurements for each of the 10 persons.
x &lt;- 1:4
## we stack the measurements of each subject, one under the other in a matrix form.
y1 &lt;- matrix( t(y) )
res&lt;-rm.anovas(y1, x)  ## perform the test
z &lt;- matrix( rnorm(20 * 8), ncol = 2) ## same example, but with 2 sets of measurements.
res&lt;-rm.anovas(z, x)
</code></pre>

<hr>
<h2 id='Many+20score+20based+20regressions'>
Many score based regressions
</h2><span id='topic+score.glms'></span><span id='topic+score.multinomregs'></span><span id='topic+score.negbinregs'></span><span id='topic+score.weibregs'></span><span id='topic+score.betaregs'></span><span id='topic+score.gammaregs'></span><span id='topic+score.expregs'></span><span id='topic+score.invgaussregs'></span><span id='topic+score.ztpregs'></span><span id='topic+score.geomregs'></span>

<h3>Description</h3>

<p>Many score based GLM regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score.glms(y, x, oiko = NULL, logged = FALSE) 
score.multinomregs(y, x, logged = FALSE) 
score.negbinregs(y, x, type = 1, logged = FALSE) 
score.weibregs(y, x, logged = FALSE) 
score.betaregs(y, x, logged = FALSE) 
score.gammaregs(y, x, logged = FALSE) 
score.expregs(y, x, logged = FALSE)
score.invgaussregs(y, x, logged = FALSE)
score.ztpregs(y, x, logged = FALSE)
score.geomregs(y, x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20score+2B20based+2B20regressions_+3A_y">y</code></td>
<td>

<p>A vector with either discrete or binary data for the Poisson, geometric, or negative binomial and binary logistic 
regressions, respectively. A vector with discrete values or factor values for the multinomial regression. If the 
vector is binary and choose multinomial regression the function checks and transfers to the binary logistic regression. 
</p>
<p>For the Weibull, gamma, inverse Gaussian and exponential regressions they must be strictly positive data, 
lifetimes or durations for example. For the beta regression they must be numbers between 0 and 1. For the 
zero truncated Poisson regression (score.ztpregs) they must be integer valued data strictly greater than 0. 
</p>
</td></tr>
<tr><td><code id="Many+2B20score+2B20based+2B20regressions_+3A_x">x</code></td>
<td>

<p>A matrix with data, the predictor variables. 
</p>
</td></tr>
<tr><td><code id="Many+2B20score+2B20based+2B20regressions_+3A_oiko">oiko</code></td>
<td>

<p>This can be either &quot;poisson&quot; or &quot;binomial&quot;. If you are not sure leave it NULL and the function will check 
internally. 
</p>
</td></tr>
<tr><td><code id="Many+2B20score+2B20based+2B20regressions_+3A_type">type</code></td>
<td>

<p>This argument is for the negative binomial distribution. In the negative binomial you can choose which way
your prefer. Type 1 is for smal sample sizes, whereas type 2 is for larger ones as is faster. 
</p>
</td></tr>
<tr><td><code id="Many+2B20score+2B20based+2B20regressions_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of maximising the log-likelihood via the Newton-Raphson algorithm in order to perform the hypothesis 
testing that <code class="reqn">\beta_i=0</code> we use the score test. This is dramatcially faster as no model needs to be fitted. 
The first derivative (score) of the log-likelihood is known and in closed form and under the null hypothesis 
the fitted values are all equal to the mean of the response variable y. The variance of the score is also known 
in closed form. The test is not the same as the likelihood ratio test. It is size correct nonetheless but it 
is a bit less efficient and less powerful. For big sample sizes though (5000 or more) the results are the same. 
We have seen via simulation studies is that it is size correct to large sample sizes, at elast a few thousands. 
You can try for yourselves and see that even with 500 the results are pretty close. The score test is pretty 
faster than the classical log-likelihood ratio test.  
</p>


<h3>Value</h3>

<p>A matrix with two columns, the test statistic and its associated p-value. For the Poisson and logistic 
regression the p-value is derived via the t distribution, whereas for the multinomial regressions 
via the <code class="reqn">\chi^2</code> distribution. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M., Alenazi A. and Fafalios S. (2020). Computationally efficient univariate filtering for massive data. 
Electronic Journal of Applied Statistical Analysis, 13(2):390-412.
</p>
<p>Hosmer DW. JR, Lemeshow S. and Sturdivant R.X. (2013). Applied Logistic Regression. New Jersey ,Wiley, 3rd Edition.
</p>
<p>Campbell M.J. (2001). Statistics at Square Two: Understand Modern Statistical Applications in Medicine, pg. 112.
London, BMJ Books. 
</p>
<p>Draper N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition.
</p>
<p>McCullagh Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>
<p>Agresti Alan (1996). An introduction to categorical data analysis. New York: Wiley.
</p>
<p>Joseph M.H. (2011). Negative Binomial Regression. Cambridge University Press, 2nd edition.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+univglms">univglms</a>, <a href="#topic+logistic_only">logistic_only</a>,  <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(500, 500)
y &lt;- rbinom(500, 1, 0.6)   ## binary logistic regression
a2 &lt;- score.glms(y, x)
y &lt;- rweibull(500, 2, 3)   
a &lt;- score.weibregs(y, x) 
mean(a[, 2] &lt; 0.05) 
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20Shapiro-Francia+20normality+20tests'>
Many Shapiro-Francia normality tests
</h2><span id='topic+sftests'></span><span id='topic+sftest'></span>

<h3>Description</h3>

<p>Many Shapiro-Francia normality tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sftests(x, logged = FALSE)
sftest(x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20Shapiro-Francia+2B20normality+2B20tests_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the observations and the columns are the variables. 
In the case of a single sample, then this must be a vector and &quot;sftest&quot; is to be used.
</p>
</td></tr>
<tr><td><code id="Many+2B20Shapiro-Francia+2B20normality+2B20tests_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Shapiro-Francia univariate normality test is performed for each column (variable) of the matrix x. 
</p>


<h3>Value</h3>

<p>A matrix with the squared correlation between the ordered values and the standard normal ordered statistics, 
the test statistic and the p-value of each test. If the &quot;sftest&quot; has been used, the output is a vector with these three elements. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Royston J. P. (1983). A simple method for evaluating the Shapiro-Francia W' test of non-normality. 
The Statistician, 32(3): 297-300.
</p>
<p>Mbah A. K. &amp; Paothong A. (2015). Shapiro-Francia test compared to other normality test using expected p-value. 
Journal of Statistical Computation and Simulation, 85(15): 3002-3016.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+ttests">ttests</a>, <a href="#topic+ttest">ttest</a>, <a href="#topic+ftests">ftests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(200, 100)
sftests(x)
a &lt;- sftests(x)
mean(a[, 3]&lt;0.05) 
x &lt;- rnorm(100)
res&lt;-sftest(x)
</code></pre>

<hr>
<h2 id='Many+20simple+20circular+20or+20angular+20regressions'>
Many simple circular or angular regressions
</h2><span id='topic+spml.regs'></span>

<h3>Description</h3>

<p>Many regressions with one circular dependent variable and one Euclidean independent variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spml.regs(y, x, tol = 1e-07, logged = FALSE, maxiters = 100, parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20simple+2B20circular+2B20or+2B20angular+2B20regressions_+3A_y">y</code></td>
<td>

<p>The dependent variable, it can be a numerical vector with data expressed in radians or it can be a matrix with
two columns, the cosinus and the sinus of the circular data. The benefit of the matrix is that if the function
is to be called multiple times with the same response, there is no need to transform the vector every time into
a matrix.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20circular+2B20or+2B20angular+2B20regressions_+3A_x">x</code></td>
<td>

<p>A matrix with independent variable.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20circular+2B20or+2B20angular+2B20regressions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminatate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20circular+2B20or+2B20angular+2B20regressions_+3A_logged">logged</code></td>
<td>

<p>Do you want the logarithm of the p-value be returned? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20circular+2B20or+2B20angular+2B20regressions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations to implement.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20circular+2B20or+2B20angular+2B20regressions_+3A_parallel">parallel</code></td>
<td>

<p>Do you want the calculations to take plac ein parallel? The default value if FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Newton-Raphson algorithm is fitted in these regression as described in Presnell et al. (1998). For each colum of x a circual
regression model is fitted and the hypothesis testing of no association between y and this variable is performed.
</p>


<h3>Value</h3>

<p>A matrix with two columns, the test statistics and their associated (log) p-values.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Stefanos Fafalios
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Stefanos Fafalios
&lt;stefanosfafalios@gmail.com&gt;
</p>


<h3>References</h3>

<p>Presnell Brett, Morrison Scott P. and Littell Ramon C. (1998). Projected multivariate linear models for
directional data. Journal of the American Statistical Association, 93(443): 1068-1077.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spml.mle">spml.mle</a>, <a href="#topic+iag.mle">iag.mle</a>, <a href="#topic+acg.mle">acg.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
z &lt;- cbind(3 + 2 * x, 1 -3 * x)
y &lt;- cbind( rnorm(100,z[ ,1], 1), rnorm(100, z[ ,2], 1) )
y &lt;- y / sqrt( rowsums(y^2) )
x &lt;- matrnorm(100, 100)
a &lt;- spml.regs(y, x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20simple+20geometric+20regressions'>
Many simple geometric regressions.
</h2><span id='topic+geom.regs'></span>

<h3>Description</h3>

<p>Many simple geometric regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geom.regs(y, x, tol = 1e-07, type = 1, logged = FALSE, parallel = FALSE, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20simple+2B20geometric+2B20regressions_+3A_y">y</code></td>
<td>

<p>The dependent variable, count data.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20geometric+2B20regressions_+3A_x">x</code></td>
<td>

<p>A matrix with the indendent variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20geometric+2B20regressions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20geometric+2B20regressions_+3A_type">type</code></td>
<td>

<p>Type 1 refers to the case where the minimum is zero and type 2 for the case of the minimum being 1.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20geometric+2B20regressions_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20geometric+2B20regressions_+3A_parallel">parallel</code></td>
<td>

<p>Do you want this to be executed in parallel or not. The parallel takes place in C++, and the number of threads is defined by each system's availiable cores.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20geometric+2B20regressions_+3A_maxiters">maxiters</code></td>
<td>

<p>The max number of iterations that can take place in each regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many simple geometric regressions are fitted.
</p>


<h3>Value</h3>

<p>A matrix with the test statistic values, their relevant (logged) p-values and the BIC values.
</p>


<h3>Author(s)</h3>

<p>Stefanos Fafalios
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+prop.regs">prop.regs</a>, <a href="#topic+score.geomregs">score.geomregs</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rgeom(100, 0.6)
x &lt;- matrix( rnorm(100 * 50), ncol = 50)
a &lt;- geom.regs(y, x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20simple+20linear+20mixed+20model+20regressions'>
Many simple linear mixed model regressions
</h2><span id='topic+rint.regs'></span>

<h3>Description</h3>

<p>Many simple linear mixed model regressions with random intercepts only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rint.regs(y, x, id, tol = 1e-08, logged = FALSE, parallel = FALSE, maxiters = 100) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20simple+2B20linear+2B20mixed+2B20model+2B20regressions_+3A_y">y</code></td>
<td>

<p>A numerical vector with the data. The subject values, the clustered data. 
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20mixed+2B20model+2B20regressions_+3A_x">x</code></td>
<td>

<p>A numerical matrix with data ,the independent variables. 
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20mixed+2B20model+2B20regressions_+3A_id">id</code></td>
<td>

<p>A numerical variable with 1, 2, ... indicating the subject. Unbalanced design is of course welcome.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20mixed+2B20model+2B20regressions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm. This is set to <code class="reqn">10^{-9}</code> by default.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20mixed+2B20model+2B20regressions_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?  
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20mixed+2B20model+2B20regressions_+3A_parallel">parallel</code></td>
<td>

<p>Do you want this to be executed in parallel or not. The parallel takes place in C++, and the number of threads 
is defined by each system's availiable cores.
</p>
</td></tr>




<tr><td><code id="Many+2B20simple+2B20linear+2B20mixed+2B20model+2B20regressions_+3A_maxiters">maxiters</code></td>
<td>

<p>The max number of iterations that can take place in each regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many linear mixed models with a single covariate are fitted. We use Newton-Raphson as described in Demidenko (2013). The test statistic is the 
usual F-test. This model allows for random intercepts only.
</p>


<h3>Value</h3>

<p>A two-column matrix with the test statistics (Wald statistic) and the associated p-values 
(or their loggarithm). 


</p>


<h3>Author(s)</h3>

<p>Stefanos Fafalios.
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Eugene Demidenko (2013). Mixed Models: Theory and Applications with R, 2nd Edition. 
New Jersey: Wiley &amp; Sons (excellent book). 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rint.reg">rint.reg</a>, <a href="#topic+allbetas">allbetas</a> <a href="#topic+univglms">univglms</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+logistic_only">logistic_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## not a so good example
y &lt;- rnorm(100)
id &lt;- sample(1:10, 100, replace = TRUE)
x &lt;- matrix( rnorm(100 * 100), ncol = 100)
a &lt;- rint.regs(y, x, id)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20simple+20linear+20regressions+20coefficients'>Simple linear regressions coefficients
</h2><span id='topic+allbetas'></span>

<h3>Description</h3>

<p>Simple linear regressions coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allbetas(y, x, pvalue = FALSE, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20simple+2B20linear+2B20regressions+2B20coefficients_+3A_y">y</code></td>
<td>

<p>A numerical vector with the response variable. 
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20regressions+2B20coefficients_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where rows denotes the observations and the columns contain the independent variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20regressions+2B20coefficients_+3A_pvalue">pvalue</code></td>
<td>

<p>If you want a hypothesis test that each slope (beta coefficient) is equal to zero set this equal to TRUE. It will also produce all the correlations between y and x.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20linear+2B20regressions+2B20coefficients_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the constant (alpha) and the slope (beta) for each simple linear regression. 
If the p-value is set to TRUE, the correlation of each y with the x is calculated along with the relevant test statistic and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+mvbetas">mvbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+colsums">colsums</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 50), ncol = 50 )
y &lt;- rnorm(100)
r &lt;- cor(y, x)  ## correlation of y with each of the xs
a &lt;- allbetas(y, x)  ## the coefficients of each simple linear regression of y with x
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20simple+20multinomial+20regressions'>
Many simple multinomial regressions.
</h2><span id='topic+multinom.regs'></span>

<h3>Description</h3>

<p>Many simple multinomial regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multinom.regs(y, x, tol = 1e-08, logged = FALSE, parallel = FALSE, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20simple+2B20multinomial+2B20regressions_+3A_y">y</code></td>
<td>

<p>The dependent variable, either a numerical variable or a factor variable.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20multinomial+2B20regressions_+3A_x">x</code></td>
<td>

<p>A matrix with the indendent variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20multinomial+2B20regressions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20multinomial+2B20regressions_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20multinomial+2B20regressions_+3A_parallel">parallel</code></td>
<td>

<p>Do you want this to be executed in parallel or not. The parallel takes place in C++, and the number of threads 
is defined by each system's availiable cores.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20multinomial+2B20regressions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations that can take place in each regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many simple multinomial regressions are fitted.
</p>


<h3>Value</h3>

<p>A matrix with the test statistic values, their relevant (logged) p-values and the BIC values.
</p>


<h3>Author(s)</h3>

<p>Stefanos Fafalios
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+prop.regs">prop.regs</a>, <a href="#topic+score.geomregs">score.geomregs</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rbinom(100, 2, 0.5)
x &lt;- matrnorm(100, 100)
a &lt;- multinom.regs(y, x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20simple+20regressions+20for+20positive+20valued+20data'>
Many simple regressions for positive valued data
</h2><span id='topic+normlog.regs'></span><span id='topic+gammaregs'></span><span id='topic+invgauss.regs'></span>

<h3>Description</h3>

<p>Many simple regressions for positive valued data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normlog.regs(y, x, tol = 1e-08, logged = FALSE, parallel = FALSE, maxiters = 100)
gammaregs(y, x, tol = 1e-07, logged = FALSE, maxiters = 100)
invgauss.regs(y, x, tol = 1e-08, logged = FALSE, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20simple+2B20regressions+2B20for+2B20positive+2B20valued+2B20data_+3A_y">y</code></td>
<td>

<p>The dependent variable, a numerical variable with non negative numbers for the Gamma and inverse Gaussian regressions. 
For the Gaussian with a log-link zero values are allowed.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20regressions+2B20for+2B20positive+2B20valued+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with the indendent variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20regressions+2B20for+2B20positive+2B20valued+2B20data_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20regressions+2B20for+2B20positive+2B20valued+2B20data_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20regressions+2B20for+2B20positive+2B20valued+2B20data_+3A_parallel">parallel</code></td>
<td>

<p>Do you want this to be executed in parallel or not. The parallel takes place in C++, therefore you do not have the option to set the number of cores.
</p>
</td></tr>
<tr><td><code id="Many+2B20simple+2B20regressions+2B20for+2B20positive+2B20valued+2B20data_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations that can take place in each regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many simple Gamma, inverse Gaussian or Gaussian regressions with a log-link are fitted.
</p>


<h3>Value</h3>

<p>A matrix with the test statistic values and their relevant (logged) p-values.
</p>


<h3>Author(s)</h3>

<p>Stefanos Fafalios and and Michail Tsagris
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt; and Michail Tsagris &lt;mtsagris@uoc.gr&gt;
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989. 
</p>
<p>Zakariya Yahya Algamal and Intisar Ibrahim Allyas (2017). Prediction of blood lead level in maternal and fetal 
using generalized linear model. International Journal of Advanced Statistics and Probability, 5(2): 65-69.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+normlog.reg">normlog.reg</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+prop.regs">prop.regs</a>, <a href="#topic+allbetas">allbetas</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- abs( rnorm(100) )
x &lt;- matrnorm(100, 100)
a &lt;- normlog.regs(y, x)
b &lt;- glm(y ~ x[, 1], family = gaussian(log) )
anova(b, test= "F")
a[1, ]
a2 &lt;- gammaregs(y, x)
a3 &lt;- invgauss.regs(y, x)
x &lt;- NULL

</code></pre>

<hr>
<h2 id='Many+20tests+20for+20the+20dispersion+20parameter+20in+20Poisson+20distribution'>
Many tests for the dispersion parameter in Poisson distribution
</h2><span id='topic+colpoisdisp.tests'></span><span id='topic+colpois.tests'></span>

<h3>Description</h3>

<p>Many tests for the dispersion parameter in Poisson distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colpoisdisp.tests(y, alternative = "either", logged = FALSE)
colpois.tests(y, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20tests+2B20for+2B20the+2B20dispersion+2B20parameter+2B20in+2B20Poisson+2B20distribution_+3A_y">y</code></td>
<td>

<p>A numerical matrix with count data, 0, 1,...
</p>
</td></tr>
<tr><td><code id="Many+2B20tests+2B20for+2B20the+2B20dispersion+2B20parameter+2B20in+2B20Poisson+2B20distribution_+3A_alternative">alternative</code></td>
<td>

<p>Do you want to test specifically for either over or underspirsion (&quot;either&quot;), overdispersion (&quot;over&quot;) or undersispersion (&quot;under&quot;)? 
</p>
</td></tr>
<tr><td><code id="Many+2B20tests+2B20for+2B20the+2B20dispersion+2B20parameter+2B20in+2B20Poisson+2B20distribution_+3A_logged">logged</code></td>
<td>

<p>Set to TRUE if you want the logarithm of the p-value.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with two columns, the test statistic and the (logged) p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Yang Zhao, James W. Hardin, and Cheryl L. Addy. (2009). A score test for overdispersion in Poisson regression based on the generalized Poisson-2 model. 
Journal of statistical planning and inference 139(4):1514-1521.
</p>
<p>Dimitris Karlis and Evdokia Xekalaki (2000). A Simulation Comparison of Several Procedures for 
Testing the Poisson Assumption. Journal of the Royal Statistical Society. Series D (The Statistician), 
49(3): 355-382.
</p>
<p>Bohning, D., Dietz, E., Schaub, R., Schlattmann, P. and Lindsay, B. (1994) The distribution of the likelihood 
ratio for mixtures of densities from the one-parameter exponential family. Annals of the Institute of 
Statistical Mathematics, 46(): 373-388.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson.mle">poisson.mle</a>, <a href="#topic+negbin.mle">negbin.mle</a>, <a href="#topic+poisson.anova">poisson.anova</a>, <a href="#topic+poisson.anovas">poisson.anovas</a>, <a href="#topic+poisson_only">poisson_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- matrix(rnbinom(100* 50, 10, 0.6), ncol = 50)
a1 &lt;- colpoisdisp.tests(y, "over")
b1 &lt;- colpois.tests(y)

y &lt;- matrix(rpois(100* 50, 10), ncol = 50)
a2 &lt;- colpoisdisp.tests(y, "either")
b2 &lt;- colpois.tests(y)
y &lt;- NULL
</code></pre>

<hr>
<h2 id='Many+20two-way+20ANOVAs'>
Many two-way ANOVAs
</h2><span id='topic+twoway.anovas'></span>

<h3>Description</h3>

<p>Many two-way ANOVAs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twoway.anovas(y, x1, x2, interact = FALSE, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20two-way+2B20ANOVAs_+3A_y">y</code></td>
<td>

<p>A matrix with the data, where the rows denote the observations (and the two groups) and the columns are the variables.
</p>
</td></tr>
<tr><td><code id="Many+2B20two-way+2B20ANOVAs_+3A_x1">x1</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Alternatively it can be a factor variable. 
This is the one factor.
</p>
</td></tr>
<tr><td><code id="Many+2B20two-way+2B20ANOVAs_+3A_x2">x2</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Alternatively it can be a factor variable. 
This is the other factor.
</p>
</td></tr>
<tr><td><code id="Many+2B20two-way+2B20ANOVAs_+3A_interact">interact</code></td>
<td>

<p>A boolean variable specifying whether you want to test for interaction.  
</p>
</td></tr>
<tr><td><code id="Many+2B20two-way+2B20ANOVAs_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The classical two-way ANOVA design is performed. Note that the design must be balanced. For every combination
of values of the two factors, x1 and x2 the same number of observations must exist. If that's not the case, 
regression models must be used. 
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value of each test. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>D.C. Montgomery (2001). Design and analysis of experiments (5th Edition). New York: John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ancovas">ancovas</a>, <a href="#topic+ftests">ftests</a>, <a href="#topic+ttests">ttests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- as.matrix( rnorm(125) )
x1 &lt;- rep(1:5, 25)
x2 &lt;- rep(1:5, each = 25)
x1 &lt;- factor(x1)
x2 &lt;- factor(x2)  
res&lt;-anova( lm(y ~ x1 + x2) )
res&lt;-twoway.anovas(y, x1, x2)
res&lt;-anova( lm(y ~ x1*x2) )
res&lt;-twoway.anovas(y, x1, x2, interact = TRUE) 
y &lt;- matrnorm(125, 100)
a1 &lt;- twoway.anovas(y, x1, x2)
a2 &lt;- twoway.anovas(y, x1, x2, interact = TRUE)
y &lt;- NULL

</code></pre>

<hr>
<h2 id='Many+20univariate+20generalised+20linear+20models'>
Many univariate generalised linear regressions
</h2><span id='topic+univglms'></span><span id='topic+univglms2'></span>

<h3>Description</h3>

<p>It performs very many univariate generalised linear regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univglms(y, x, oiko = NULL, logged = FALSE)

univglms2(y, x, oiko = NULL, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20univariate+2B20generalised+2B20linear+2B20models_+3A_y">y</code></td>
<td>

<p>The dependent variable. It can be a factor or a numerical variable with two values only (binary logistic 
regression), a discrete valued vector (count data) corresponding to a poisson regression or a numerical 
vector with continuous values (normal regression). 
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20generalised+2B20linear+2B20models_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) and the 
columns are the variables. For the &quot;univglms&quot; only continuous variables are allowed. You are advised to 
standardise the data before hand to avoid numerical overflow or similar issues. 
If you see NaN in the outcome, this might be the case. For the &quot;univglms2&quot; categorical variables are allowed
and hence this accepts data.frames. In this case, the categorical variables must be given as factor variables,
otherwise you might get wrong results.
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20generalised+2B20linear+2B20models_+3A_oiko">oiko</code></td>
<td>

<p>This can be either &quot;normal&quot;, &quot;poisson&quot;, &quot;quasipoisson&quot; or &quot;binomial&quot;. If you are not sure leave it NULL and 
the function will check internally. However, you might have discrete data (e.g. years of age)
and want to perform many simple linear regressions. In this case you should specify the family. 
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20generalised+2B20linear+2B20models_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you specify no family of distributions the function internally checkes the type of your data and 
decides on the type of regression to perform. The function is written in C++ and this is why it is very 
fast. It can accept thousands of predictor variables. It is usefull for univariate screening. We provide 
no p-value correction (such as fdr or q-values); this is up to the user. 
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value for each predictor variable.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Draper, N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logistic_only">logistic_only</a>, <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+allbetas">allbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrnorm(100, 50)
y &lt;- rbinom(100, 1, 0.6)   ## binary logistic regression
a1 &lt;- univglms(y, x) 
a2 &lt;- glm(y ~ x[, 1], binomial)$deviance
a2 &lt;- glm(y ~ 1, binomial)$null.dev - a2
x &lt;- NULL

</code></pre>

<hr>
<h2 id='Many+20univariate+20simple+20linear+20regressions'>
Many univariate simple linear regressions
</h2><span id='topic+regression'></span>

<h3>Description</h3>

<p>It performs very many univariate simple linear regressions with or without categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regression(x, y, poia = NULL, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20linear+2B20regressions_+3A_x">x</code></td>
<td>

<p>A data.frame or a matrix with the data, where the rows denote the samples (and the two groups) and the columns 
are the variables. A data frame is expected if you have categorical predictor variables. If you only have continuous 
predictor variables you should the function <code><a href="#topic+allbetas">allbetas</a></code> instead as it is faster. 
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20linear+2B20regressions_+3A_y">y</code></td>
<td>

<p>The dependent variable; a numerical vector.
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20linear+2B20regressions_+3A_poia">poia</code></td>
<td>

<p>If the &quot;x&quot; is a data.frame and you know the indices of the columns which are categorical variables supply it here.
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20linear+2B20regressions_+3A_logged">logged</code></td>
<td>

<p>Do you want the logarithm of the p-values be returned? The default value is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some parts of the function will be transferred in C++. It can accept thousands of predictor variables. 
It is usefull for univariate screening. We provide no p-value correction (such as fdr or q-values); this is 
up to the user. 
</p>


<h3>Value</h3>

<p>A matrix with two columns, the test statistic value and its corresponding (logged) p-value.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Draper, N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+univglms">univglms</a>, <a href="#topic+allbetas">allbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+mvbetas">mvbetas</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(150)   
a &lt;- regression(iris, y)
a
summary(lm(y ~ iris[, 5]) )  ## check the F-test
</code></pre>

<hr>
<h2 id='Many+20univariate+20simple+20logistic+20and+20Poisson+20regressions'>
Many univariate simple binary logistic regressions
</h2><span id='topic+logistic_only'></span><span id='topic+poisson_only'></span>

<h3>Description</h3>

<p>It performs very many univariate simple binary logistic regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic_only(x, y, tol = 1e-09, b_values = FALSE)
poisson_only(x, y, tol = 1e-09, b_values = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20logistic+2B20and+2B20Poisson+2B20regressions_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) and the columns are the variables. Currently only continuous variables are allowed.
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20logistic+2B20and+2B20Poisson+2B20regressions_+3A_y">y</code></td>
<td>

<p>The dependent variable; a numerical vector with two values (0 and 1) for the logistic regressions and 
a vector with many discrete values (count data) for the Poisson regressions. 
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20logistic+2B20and+2B20Poisson+2B20regressions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20logistic+2B20and+2B20Poisson+2B20regressions_+3A_b_values">b_values</code></td>
<td>

<p>Do you want the values of the coefficients returned? If yes, set this to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is written in C++ and this is why it is very fast. It can accept thousands of predictor variables. It is usefull for univariate screening. 
We provide no p-value correction (such as fdr or q-values); this is up to the user. 
</p>


<h3>Value</h3>

<p>A vector with the deviance of each simple binayr logistic regression model for each predictor variable.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+univglms">univglms</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+prop.regs">prop.regs</a>, <a href="#topic+quasi.poisson_only">quasi.poisson_only</a>, <a href="#topic+allbetas">allbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 300 variables, hence 300 univariate regressions are to be fitted
x &lt;- matrix( rnorm(100 * 300), ncol = 300 )

## 100 observations in total
y &lt;- rbinom(100, 1, 0.6)   ## binary logistic regression
a1 &lt;- logistic_only(x, y)
 
a2 &lt;- glm(y ~ x[, 1], binomial)$deviance 
a2 &lt;- as.vector(a2)

y &lt;- rpois(100, 10)
a1 &lt;- poisson_only(x, y) 

a1 &lt;- x &lt;- NULL

</code></pre>

<hr>
<h2 id='Many+20univariate+20simple+20quasi+20poisson+20regressions'>
Many univariate simple poisson regressions
</h2><span id='topic+quasi.poisson_only'></span>

<h3>Description</h3>

<p>It performs very many univariate simple poisson regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quasi.poisson_only(x, y, tol = 1e-09, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20quasi+2B20poisson+2B20regressions_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) and the columns are the variables. Currently only continuous variables are allowed.
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20quasi+2B20poisson+2B20regressions_+3A_y">y</code></td>
<td>

<p>The dependent variable; a numerical vector with many discrete values (count data). 
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20quasi+2B20poisson+2B20regressions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations after which the Newton-Raphson algorithm is terminated.
</p>
</td></tr>
<tr><td><code id="Many+2B20univariate+2B20simple+2B20quasi+2B20poisson+2B20regressions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is written in C++ and this is why it is very fast. It can accept thousands of predictor variables. It is usefull for univariate screening. 
We provide no p-value correction (such as fdr or q-values); this is up to the user. 
</p>


<h3>Value</h3>

<p>A matrix with the deviance and the estimated phi parameter (dispersion parameter) of each simple poisson regression model for each predictor variable.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis &lt;papadakm95@gmail.com&gt; and Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;, Manos Papadakis &lt;papadakm95@gmail.com&gt; and Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;.
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+poisson_only">poisson_only</a> <a href="#topic+univglms">univglms</a>, <a href="#topic+logistic_only">logistic_only</a>, <a href="#topic+allbetas">allbetas</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 200 variables, hence 200 univariate regressions are to be fitted
x &lt;- matrix( rnorm(100 * 200), ncol = 200 )
y &lt;- rpois(100, 10)
poisson_only(x, y)
b1 &lt;- poisson_only(x, y) 
b2 &lt;- quasi.poisson_only(x, y) 

b1&lt;-b2&lt;-x&lt;-y&lt;-NULL
</code></pre>

<hr>
<h2 id='Many+20Welch+27s+20F-tests'>
Many Welch's F-tests
</h2><span id='topic+colanovas'></span>

<h3>Description</h3>

<p>Many Welch's F-tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colanovas(y, x, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Many+2B20Welch+2B27s+2B20F-tests_+3A_y">y</code></td>
<td>

<p>A numerical vector with the dependent variable. 
</p>
</td></tr>
<tr><td><code id="Many+2B20Welch+2B27s+2B20F-tests_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) and the 
columns are the variables. This must be a matrix with the categorical variables as numbers, starting from 1.
Welch's F-test is performed for each variable. 
</p>
</td></tr>
<tr><td><code id="Many+2B20Welch+2B27s+2B20F-tests_+3A_logged">logged</code></td>
<td>

<p>A boolean variable; it will return the logarithm of the pvalue if set to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each categorical variable in the x matrix Welch's F test is performed. This is the opposie of <code><a href="#topic+ftests">ftests</a>,
where there are many dependent variables and one categorical variable.
</code>
</p>


<h3>Value</h3>

<p>A matrix with the test statistic and the p-value for each predictor variable.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Draper, N.R. and Smith H. (1988). Applied regression analysis. New York, Wiley, 3rd edition.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regression">regression</a>, <a href="#topic+ftests">ftests</a>, <a href="#topic+allbetas">allbetas</a>, <a href="#topic+correls">correls</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;-  rnorm(100)
x &lt;- matrix( rbinom(100 * 50, 2, 0.5) + 1 , ncol = 50)  
a &lt;- colanovas(y, x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Matrix+20multiplication'>
Matrix multiplication, Cross and Tcross product.
</h2><span id='topic+mat.mult'></span><span id='topic+Crossprod'></span><span id='topic+Tcrossprod'></span>

<h3>Description</h3>

<p>Matrix multiplication, Cross and Tcross product.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mat.mult(x, y)
Crossprod(x,y)
Tcrossprod(x,y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Matrix+2B20multiplication_+3A_x">x</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
<tr><td><code id="Matrix+2B20multiplication_+3A_y">y</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions performs matrix multiplication, croos product and transpose cross product. There are faster(!) than R's function
for large matrices. Depending on the computer, maybe higher dimensions are 
required for the function to make a difference. The function runs in parallel
in C++. 
</p>


<h3>Value</h3>

<p>A matrix, the result of the matrix multiplication.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+transpose">transpose</a>, <a href="#topic+colsums">colsums</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrnorm(100, 100)
y &lt;- matrnorm(100, 100)
a &lt;- x 
b &lt;- mat.mult(x, y)
b &lt;- Crossprod(x, y)
b &lt;- Tcrossprod(x, y)
x &lt;- NULL
y &lt;- NULL
b &lt;- NULL

</code></pre>

<hr>
<h2 id='Matrix+20with+20all+20pairs+20of+20t-tests'>
Matrix with all pairs of t-tests
</h2><span id='topic+allttests'></span><span id='topic+ttests.pairs'></span>

<h3>Description</h3>

<p>Matrix with all pairs of t-tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allttests(x, y = NULL, ina, logged = FALSE) 
ttests.pairs(x, logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Matrix+2B20with+2B20all+2B20pairs+2B20of+2B20t-tests_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the data.
</p>
</td></tr>
<tr><td><code id="Matrix+2B20with+2B20all+2B20pairs+2B20of+2B20t-tests_+3A_y">y</code></td>
<td>

<p>For the case of &quot;all.tests&quot;, if you have the second group or sample provide it here, otherwise leave it NULL.
For the case of &quot;ttests.pairs&quot; this is not required.
</p>
</td></tr>
<tr><td><code id="Matrix+2B20with+2B20all+2B20pairs+2B20of+2B20t-tests_+3A_ina">ina</code></td>
<td>

<p>If you have the data in one matric then provide this indicator variable separating the samples. 
This numerical vector must contain 1s and 2s only as values. For the case of &quot;ttests.pairs&quot; this is not required.
</p>
</td></tr>
<tr><td><code id="Matrix+2B20with+2B20all+2B20pairs+2B20of+2B20t-tests_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function does all the pairwise t-tests assuming unequal variances (Welch's t-test). The &quot;all.ttests&quot; does all the pairs
formed by &quot;cutting&quot; the matrices x and y in two and everything between them. The &quot;ttests.pairs&quot; accepts a matrix x
and does all the pairs of t-tests. This is similar to the correlation matrix style. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>stat</code></td>
<td>

<p>A matrix with t-test statistic for each pair of variables.
</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>

<p>A matrix with the corresponding p-values.
</p>
</td></tr>
<tr><td><code>dof</code></td>
<td>

<p>A matrix with the relevant degrees of freedom.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ttests">ttests</a>, <a href="#topic+ftests">ftests</a>, <a href="#topic+ttest">ttest</a>, <a href="#topic+g2Test_univariate">g2Test_univariate</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix( iris[1:100, 1:4] )
ina &lt;- as.numeric(iris[1:100, 5])
a &lt;- allttests(x, ina = ina)
b &lt;- ttests.pairs(x)  ## less tests
</code></pre>

<hr>
<h2 id='Matrix+20with+20G-square+20tests+20of+20indepedence'>
Matrix with G-square tests of indepdence
</h2><span id='topic+g2Test_univariate'></span><span id='topic+g2Test_univariate_perm'></span><span id='topic+chi2Test_univariate'></span>

<h3>Description</h3>

<p>Matrix with G-square tests of indepdence with and without permutations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g2Test_univariate(data, dc)
g2Test_univariate_perm(data, dc, nperm) 
chi2Test_univariate(data, dc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Matrix+2B20with+2B20G-square+2B20tests+2B20of+2B20indepedence_+3A_data">data</code></td>
<td>

<p>A numerical matrix with the data. <b>The minimum must be 0, otherwise the function can crash or will produce 
wrong results</b>. The data must be consecutive numbers.
</p>
</td></tr>
<tr><td><code id="Matrix+2B20with+2B20G-square+2B20tests+2B20of+2B20indepedence_+3A_dc">dc</code></td>
<td>

<p>A numerical value equal to the number of variables (or columns of the data matrix) indicating the number of distinct, unique values (or levels) of each variable.
Make sure you give the correct numbers here, otherwise the degrees of freedom will be wrong.
</p>
</td></tr>
<tr><td><code id="Matrix+2B20with+2B20G-square+2B20tests+2B20of+2B20indepedence_+3A_nperm">nperm</code></td>
<td>

<p>The number of permutations. The permutations test is slower than without permutations and should be used with small sample sizes or when 
the contigency tables have zeros. When there are few variables, R's &quot;chisq.test&quot; function is faster, but as the number of variables increase the time difference 
with R's procedure becomes larger and larger.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function does all the pairwise <code class="reqn">G^2</code> test of independence and gives the position inside the matrix. 
The user must build the associations matrix now, similarly to the correlation matrix. See the examples of how to do that. 
The p-value is not returned, we live this to the user. See the examples of how to obtain it. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>

<p>The <code class="reqn">G^2</code> or <code class="reqn">chi^2</code> test statistic for each pair of variables.
</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>

<p>This is returned when you have selected the permutation based <code class="reqn">G^2</code> test.
</p>
</td></tr>
<tr><td><code>x</code></td>
<td>

<p>The row or variable of the data.
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>

<p>The column or variable of the data.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>The degrees of freedom of each test.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giorgos Borboudakis. The permutation version used a C++ code by John Burkardt.
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tsagris M. (2017). Conditional independence test for categorical data using Poisson log-linear model. 
Journal of Data Science, 15(2):347-356.
</p>
<p>Tsamardinos, I., &amp; Borboudakis, G. (2010). Permutation testing improves Bayesian network learning. 
In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 322-337). Springer Berlin Heidelberg
</p>


<h3>See Also</h3>

<p><code><a href="#topic+g2Test">g2Test</a>, <a href="#topic+g2Test_perm">g2Test_perm</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nvalues &lt;- 3
nvars &lt;- 10
nsamples &lt;- 2000
data &lt;- matrix( sample( 0:(nvalues - 1), nvars * nsamples, replace = TRUE ), nsamples, nvars )
dc &lt;- rep(nvalues, nvars)
g2Test_univariate(data = data, dc = dc)
a &lt;- g2Test_univariate(data = data, dc = dc)
pval &lt;- pchisq(a$statistic, a$df, lower.tail = FALSE)

g &lt;- matrix(0, nvars, nvars)
g[ cbind(a$x, a$y) ] &lt;- a$statistic
g &lt;- g + t(g)
diag(g) &lt;- 0
## g ## matrix of G^2 test statistics

g&lt;-a&lt;-dc&lt;-data&lt;-NULL

</code></pre>

<hr>
<h2 id='Minima+20and+20maxima+20of+20two+20vectors+2Fmatrices+20and+20Column-row+20wise+20minima+20and+20maxima+20of+20two+20matrices'>
Minima and maxima of two vectors/matrices and Column-row wise minima and maxima of two matrices
</h2><span id='topic+colPmax'></span><span id='topic+colPmin'></span><span id='topic+Pmax'></span><span id='topic+Pmin'></span><span id='topic+Pmin_Pmax'></span>

<h3>Description</h3>

<p>Minima and maxima of two vectors/matrices and Column-row wise minima and maxima of two matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colPmax(x, y)
colPmin(x, y)
Pmax(x, y,na.rm = FALSE)
Pmin(x, y,na.rm = FALSE)
Pmin_Pmax(x, y,na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Minima+2B20and+2B20maxima+2B20of+2B20two+2B20vectors+2B2Fmatrices+2B20and+2B20Column-row+2B20wise+2B20minima+2B20and+2B20maxima+2B20of+2B20two+2B20matrices_+3A_x">x</code></td>
<td>

<p>A numerical vector or matrix with numbers.
</p>
</td></tr>
<tr><td><code id="Minima+2B20and+2B20maxima+2B20of+2B20two+2B20vectors+2B2Fmatrices+2B20and+2B20Column-row+2B20wise+2B20minima+2B20and+2B20maxima+2B20of+2B20two+2B20matrices_+3A_y">y</code></td>
<td>

<p>A numerical vector with numbers.
</p>
</td></tr>
<tr><td><code id="Minima+2B20and+2B20maxima+2B20of+2B20two+2B20vectors+2B2Fmatrices+2B20and+2B20Column-row+2B20wise+2B20minima+2B20and+2B20maxima+2B20of+2B20two+2B20matrices_+3A_na.rm">na.rm</code></td>
<td>

<p>TRUE or FAlSE for remove NAs if exists.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parallel minima or maxima are returned. This are the same as the base functions pmax and pmin. 
</p>


<h3>Value</h3>

<p>A numerical vector/matrix with numbers, whose length is equal to the length of the initital matrices containing the maximum or minimum between each pair. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+Sort">Sort</a>, <a href="#topic+colMins">colMins</a>, <a href="#topic+colMaxs">colMaxs</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100),10,10)
y &lt;- matrix(rnorm(100),10,10)
res&lt;-colPmax(x, y)
res&lt;-colPmin(x, y)
x&lt;-y&lt;-NULL
</code></pre>

<hr>
<h2 id='Minimum+20and+20maximum+20'>
Minimum and maximum of a vector
</h2><span id='topic+min_max'></span>

<h3>Description</h3>

<p>Minimum and maximum of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>min_max(x,index=FALSE, percent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Minimum+2B20and+2B20maximum+2B20_+3A_x">x</code></td>
<td>

<p>A numerical vector with data. NAs are handled naturally.
</p>
</td></tr>
<tr><td><code id="Minimum+2B20and+2B20maximum+2B20_+3A_index">index</code></td>
<td>

<p>A boolean value for the indices of the minimum and the maximum value.
</p>
</td></tr>
<tr><td><code id="Minimum+2B20and+2B20maximum+2B20_+3A_percent">percent</code></td>
<td>

<p>A boolean value for the percent of the positive and negative numbers.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the relevant values, min and max.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowMaxs">rowMaxs</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+colMedians">colMedians</a>,<a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100 * 500)
s1 &lt;- min_max(x) 
s2 &lt;- c(min(x), max(x)) 

</code></pre>

<hr>
<h2 id='Minimum+20and+20maximum+20frequencies+20'>
Minimum and maximum frequencies of a vector
</h2><span id='topic+freq.min'></span><span id='topic+freq.max'></span>

<h3>Description</h3>

<p>Minimum and maximum frequencies of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq.min(x,na.rm = FALSE)
freq.max(x,na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Minimum+2B20and+2B20maximum+2B20frequencies+2B20_+3A_x">x</code></td>
<td>

<p>A numerical/integer vector with data but without NAs.
</p>
</td></tr>
<tr><td><code id="Minimum+2B20and+2B20maximum+2B20frequencies+2B20_+3A_na.rm">na.rm</code></td>
<td>

<p>TRUE or FAlSE for remove NAs if exists.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Those functions are the same with max(table(x) or min(table(x)) but with one exception.
freq.min and freq.max will return also which value has the minimum/maximum frequency.
More Efficient than max(table(x) or min(table(x)).
</p>


<h3>Value</h3>

<p>A vector with 2 values, the value with minimum/maximum frequency and the frequency.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; and Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+rowMaxs">rowMaxs</a>, <a href="#topic+nth">nth</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+colMedians">colMedians</a>,<a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
f1 &lt;- freq.min(x) 
f2 &lt;- freq.max(x) 
# f1r &lt;- min(table(x))
# f2r &lt;- max(table(x))
# f1[2]==f1r ## the frequencies are the same
# f2[2]==f2r ## the frequencies are the same

</code></pre>

<hr>
<h2 id='MLE+20for+20multivariate+20discrete+20data'>
MLE for multivariate discrete data
</h2><span id='topic+multinom.mle'></span><span id='topic+dirimultinom.mle'></span><span id='topic+colpoisson.mle'></span><span id='topic+colgeom.mle'></span>

<h3>Description</h3>

<p>MLE for multivariate discrete data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multinom.mle(x)
dirimultinom.mle(x, tol = 1e-07) 
colpoisson.mle(x)
colgeom.mle(x, type = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20for+2B20multivariate+2B20discrete+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with discrete valued non negative data.
</p>
</td></tr>
<tr><td><code id="MLE+2B20for+2B20multivariate+2B20discrete+2B20data_+3A_tol">tol</code></td>
<td>
<p>the tolerance level to terminate the Newton-Raphson algorithm for the Dirichlet multinomial distribution.
</p>
</td></tr>
<tr><td><code id="MLE+2B20for+2B20multivariate+2B20discrete+2B20data_+3A_type">type</code></td>
<td>

<p>This is for the geometric distribution only. Type 1 refers to the case where the minimum is zero and type 2 for the 
case of the minimum being 1. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the Poisson and geometric distributions we simply fit independent Poisson and geometric distributions 
respectively.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>
<p>A vector with the value of the maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>A vector of the parameters.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Johnson Norman L., Kotz Samuel and Balakrishnan (1997). Discrete Multivariate Distributions. Wiley
</p>
<p>Minka Thomas (2012). Estimating a Dirichlet distribution. Technical report. 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson.mle">poisson.mle</a>, <a href="#topic+zip.mle">zip.mle</a>, <a href="#topic+ztp.mle">ztp.mle</a>, <a href="#topic+negbin.mle">negbin.mle</a>, <a href="#topic+poisson.nb">poisson.nb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- t( rmultinom(1000, 20, c(0.4, 0.5, 0.1) ) )
res&lt;-multinom.mle(x)
res&lt;-colpoisson.mle(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='MLE+20of+20+28hyper-+29spherical+20distributions'>
MLE of (hyper-)spherical distributions
</h2><span id='topic+vmf.mle'></span><span id='topic+multivmf.mle'></span><span id='topic+acg.mle'></span><span id='topic+iag.mle'></span>

<h3>Description</h3>

<p>MLE of (hyper-)spherical distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vmf.mle(x, tol = 1e-07)
multivmf.mle(x, ina, tol = 1e-07, ell = FALSE)
acg.mle(x, tol = 1e-07)
iag.mle(x, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20+2B28hyper-+2B29spherical+2B20distributions_+3A_x">x</code></td>
<td>

<p>A matrix with directional data, i.e. unit vectors.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20+2B28hyper-+2B29spherical+2B20distributions_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with discrete numbers starting from 1, i.e. 1, 2, 3, 4,... or a factor variable. Each number denotes a sample or group. 
If you supply a continuous valued vector the function will obviously provide wrong results.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20+2B28hyper-+2B29spherical+2B20distributions_+3A_ell">ell</code></td>
<td>

<p>This is for the multivmf.mle only. Do you want the log-likelihood returned? The default value is TRUE. 
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20+2B28hyper-+2B29spherical+2B20distributions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value at which to terminate the iterations.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the von Mises-Fisher, the normalised mean is the mean direction. For the concentration parameter, a Newton-Raphson is implemented. 
For the angular central Gaussian distribution there is a constraint on the estimated covariance matrix; its trace is equal to the number of variables. 
An iterative algorithm takes place and convergence is guaranteed. Newton-Raphson for the projected normal distribution, on the sphere, is implemented as well. Finally, 
the von Mises-Fisher distribution for groups of data is also implemented. 
</p>


<h3>Value</h3>

<p>For the von Mises-Fisher a list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The maximum log-likelihood value.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean direction.
</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>

<p>The concentration parameter.
</p>
</td></tr>
</table>
<p>For the multi von Mises-Fisher a list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>A vector with the maximum log-likelihood values if ell is set to TRUE. Otherwise NULL is returned.
</p>
</td></tr>
<tr><td><code>mi</code></td>
<td>

<p>A matrix with the group mean directions.
</p>
</td></tr>
<tr><td><code>ki</code></td>
<td>

<p>A vector with the group concentration parameters.
</p>
</td></tr>
</table>
<p>For the angular central Gaussian a list including:
</p>
<table>
<tr><td><code>iter</code></td>
<td>

<p>The number if iterations required by the algorithm to converge to the solution.
</p>
</td></tr>
<tr><td><code>cova</code></td>
<td>

<p>The estimated covariance matrix.
</p>
</td></tr>
</table>
<p>For the spherical projected normal a list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iteration required by the Newton-Raphson. 
</p>
</td></tr>
<tr><td><code>mesi</code></td>
<td>

<p>A matrix with two rows. The first row is the mean direction and the second is the mean vector. 
The first comes from the second by normalising to have unit length.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>A vector with the elements, the norm of mean vector, the log-likelihood and the log-likelihood of the spherical uniform distribution. 
The third value helps in case you want to do a log-likleihood ratio test for uniformity.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Mardia, K. V. and Jupp, P. E. (2000). Directional statistics. Chicester: John Wiley &amp; Sons.
</p>
<p>Sra, S. (2012). A short note on parameter approximation for von Mises-Fisher distributions: and a fast implementation of Is(x). 
Computational Statistics, 27(1): 177&ndash;190.
</p>
<p>Tyler D. E. (1987). Statistical analysis for the angular central Gaussian distribution on the sphere.
Biometrika 74(3): 579-589.
</p>
<p>Paine P.J., Preston S.P., Tsagris M and Wood A.T.A. (2017). An Elliptically Symmetric Angular Gaussian Distribution. Statistics and Computing (To appear). 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+racg">racg</a>, <a href="#topic+vm.mle">vm.mle</a>, <a href="#topic+rvmf">rvmf</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- c(0, 0, 0, 0)
s &lt;- cov(iris[, 1:4])
x &lt;- racg(100, s)
mod &lt;- acg.mle(x)
mod
res&lt;-cov2cor(mod$cova)  ## estimated covariance matrix turned into a correlation matrix
res&lt;-cov2cor(s)  ## true covariance matrix turned into a correlation matrix
res&lt;-vmf.mle(x)
x &lt;- rbind( rvmf(100,rnorm(4), 10), rvmf(100,rnorm(4), 20) )
a &lt;- multivmf.mle(x, rep(1:2, each = 100) )
</code></pre>

<hr>
<h2 id='MLE+20of+20continuous+20univariate+20distributions+20defined+20on+20the+20positive+20line'>
MLE of continuous univariate distributions defined on the positive line</h2><span id='topic+gammamle'></span><span id='topic+chisq.mle'></span><span id='topic+weibull.mle'></span><span id='topic+lomax.mle'></span><span id='topic+foldnorm.mle'></span><span id='topic+betaprime.mle'></span><span id='topic+logcauchy.mle'></span><span id='topic+loglogistic.mle'></span><span id='topic+halfnorm.mle'></span><span id='topic+invgauss.mle'></span><span id='topic+lognorm.mle'></span><span id='topic+pareto.mle'></span><span id='topic+expmle'></span><span id='topic+exp2.mle'></span><span id='topic+maxboltz.mle'></span><span id='topic+rayleigh.mle'></span><span id='topic+normlog.mle'></span><span id='topic+lindley.mle'></span>

<h3>Description</h3>

<p>MLE of continuous univariate distributions defined on the positive line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammamle(x, tol = 1e-09) 
chisq.mle(x, tol = 1e-09)
weibull.mle(x, tol = 1e-09, maxiters = 100)
lomax.mle(x, tol = 1e-09)
foldnorm.mle(x, tol = 1e-09)
betaprime.mle(x, tol = 1e-09)
logcauchy.mle(x, tol = 1e-09)
loglogistic.mle(x, tol = 1e-09)
halfnorm.mle(x)
invgauss.mle(x)
lognorm.mle(x)
pareto.mle(x)
expmle(x)
exp2.mle(x)
maxboltz.mle(x)
rayleigh.mle(x)
normlog.mle(x)
lindley.mle(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20continuous+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20positive+2B20line_+3A_x">x</code></td>
<td>

<p>A vector with positive valued data (zeros are not allowed).
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20continuous+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20positive+2B20line_+3A_tol">tol</code></td>
<td>

<p>The tolerance level up to which the maximisation stops; set to 1e-09 by default.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20continuous+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20positive+2B20line_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations the Newton-Raphson will perform. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of maximising the log-likelihood via a numerical optimiser we have used a Newton-Raphson algorithm which is faster. See wikipedia for the equations to be solved. 
For the t distribution we need the degrees of freedom and estimate the location and scatter parameters. If you want to to fit an inverse gamma distribution simply do 
&quot;gamma.mle(1/x)&quot;. The log-likelihood and the parameters are for the inverse gamma. 
</p>
<p>The &quot;normlog.mle&quot; is simply the normal distribution where all values are positive. Note, this is not log-normal. It is the normal with a log link. Similarly to the inverse gaussian
distribution where the mean is an exponentiated. This comes from the GLM theory. 
</p>


<h3>Value</h3>

<p>Usually a list with three elements, but this is not for all cases. 
</p>
<table>
<tr><td><code>iters</code></td>
<td>
<p>The number of iterations required for the Newton-Raphson to converge.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The value of the maximised log-likelihood.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>The vector of the parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Kalimuthu Krishnamoorthy, Meesook Lee and Wang Xiao (2015). Likelihood ratio tests for comparing several 
gamma distributions. Environmetrics, 26(8):571-583.
</p>
<p>N.L. Johnson, S. Kotz and N. Balakrishnan (1994). Continuous Univariate Distributions, Volume 1 (2nd Edition).
</p>
<p>N.L. Johnson, S. Kotz a nd N. Balakrishnan (1970). Distributions in statistics: continuous univariate 
distributions, Volume 2.
</p>
<p>Tsagris M., Beneki C. and Hassani H. (2014). On the folded normal distribution. Mathematics, 2(1):12-28.
</p>
<p>Sharma V. K., Singh S. K., Singh U. and Agiwal V. (2015). The inverse Lindley distribution: 
a stress-strength reliability model with application to head and neck cancer data. Journal of 
Industrial and Production Engineering, 32(3): 162-173.
</p>
<p>You can also check the relevant wikipedia pages for these distributions.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+zip.mle">zip.mle</a>, <a href="#topic+normal.mle">normal.mle</a>, <a href="#topic+beta.mle">beta.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgamma(100, 3, 4)
for (i in 1:20) gammamle(x)
## for (i in 1:20) fitdistr(x,"gamma")
#a &lt;- glm(x ~ 1, gaussian(log) )
res&lt;-normlog.mle(x)
</code></pre>

<hr>
<h2 id='MLE+20of+20continuous+20univariate+20distributions+20defined+20on+20the+20real+20line'>
MLE of continuous univariate distributions defined on the real line</h2><span id='topic+normal.mle'></span><span id='topic+gumbel.mle'></span><span id='topic+cauchy.mle'></span><span id='topic+logistic.mle'></span><span id='topic+ct.mle'></span><span id='topic+tmle'></span><span id='topic+wigner.mle'></span><span id='topic+laplace.mle'></span>

<h3>Description</h3>

<p>MLE of continuous univariate distributions defined on the real line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normal.mle(x) 
gumbel.mle(x, tol = 1e-09)
cauchy.mle(x, tol = 1e-09)
logistic.mle(x, tol = 1e-07)
ct.mle(x, tol = 1e-09)
tmle(x, v = 5, tol = 1e-08)
wigner.mle(x, tol = 1e-09)
laplace.mle(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20continuous+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20real+2B20line_+3A_x">x</code></td>
<td>

<p>A numerical vector with data.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20continuous+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20real+2B20line_+3A_v">v</code></td>
<td>
<p>The degrees of freedom of the t distribution.</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20continuous+2B20univariate+2B20distributions+2B20defined+2B20on+2B20the+2B20real+2B20line_+3A_tol">tol</code></td>
<td>

<p>The tolerance level up to which the maximisation stops set to 1e-09 by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of maximising the log-likelihood via a numerical optimiser we have used a Newton-Raphson algorithm which 
is faster. See wikipedia for the equation to be solved. For the t distribution we need the degrees of freedom and 
estimate the location and scatter parameters. 
</p>
<p>The Cauchy is the t distribution with 1 degree of freedom. If you want to fit such a distribution used the
cauchy.mle and not the t.mle with 1 degree of freedom as it's faster. The Laplace distribution is also called 
double exponential distribution.
</p>
<p>The wigner.mle refers to the wigner semicircle distribution.
</p>


<h3>Value</h3>

<p>Usually a list with three elements, but this is not for all cases. 
</p>
<table>
<tr><td><code>iters</code></td>
<td>
<p>The number of iterations required for the Newton-Raphson to converge.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The value of the maximised log-likelihood.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>The vector of the parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Johnson, Norman L. Kemp, Adrianne W. Kotz, Samuel (2005). Univariate Discrete Distributions (third edition). 
Hoboken, NJ: Wiley-Interscience.
</p>
<p>https://en.wikipedia.org/wiki/Wigner_semicircle_distribution
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+zip.mle">zip.mle</a>, <a href="#topic+gammamle">gammamle</a>, <a href="#topic+vm.mle">vm.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rt(1000,10)
a &lt;- ct.mle(x)
res&lt;-tmle(x, v = a$nu)
res&lt;-cauchy.mle(x)
res&lt;-normal.mle(x)
res&lt;-logistic.mle(x)
res&lt;-gumbel.mle(x)
</code></pre>

<hr>
<h2 id='MLE+20of+20count+20data+20+28univariate+20discrete+20distributions+29'>
MLE of count data
</h2><span id='topic+zip.mle'></span><span id='topic+ztp.mle'></span><span id='topic+negbin.mle'></span><span id='topic+binom.mle'></span><span id='topic+borel.mle'></span><span id='topic+geom.mle'></span><span id='topic+logseries.mle'></span><span id='topic+poisson.mle'></span><span id='topic+betageom.mle'></span><span id='topic+betabinom.mle'></span>

<h3>Description</h3>

<p>MLE of count data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zip.mle(x, tol = 1e-09)
ztp.mle(x, tol = 1e-09)
negbin.mle(x, type = 1, tol = 1e-09) 
binom.mle(x, N = NULL, tol = 1e-07)
borel.mle(x)
geom.mle(x, type = 1)
logseries.mle(x, tol = 1e-09)
poisson.mle(x)
betageom.mle(x, tol = 1e-07)
betabinom.mle(x, N, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20count+2B20data+2B20+2B28univariate+2B20discrete+2B20distributions+2B29_+3A_x">x</code></td>
<td>

<p>A vector with discrete valued data.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20count+2B20data+2B20+2B28univariate+2B20discrete+2B20distributions+2B29_+3A_type">type</code></td>
<td>

<p>This argument is for the negative binomial and the geometric distribution. 
In the negative binomial you can choose which way your prefer. Type 1 is for smal sample sizes, whereas 
type 2 is for larger ones as is faster. For the geometric it is related to its two forms. Type 1 refers to the case
where the minimum is zero and type 2 for the case of the minimum being 1. 
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20count+2B20data+2B20+2B28univariate+2B20discrete+2B20distributions+2B29_+3A_n">N</code></td>
<td>

<p>This is for the binomial distribution only, specifying the total number of successes. If NULL, it is sestimated by the data.
It can also be a vector of successes.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20count+2B20data+2B20+2B28univariate+2B20discrete+2B20distributions+2B29_+3A_tol">tol</code></td>
<td>

<p>The tolerance level up to which the maximisation stops set to 1e-09 by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of maximising the log-likelihood via a numerical optimiser we used a Newton-Raphson algorithm which is faster. 
</p>
<p>See wikipedia for the equation to be solved in the case of the zero inflated distribution. https://en.wikipedia.org/wiki/Zero-inflated_model. 
In order to avoid negative values we have used link functions, log for the <code class="reqn">lambda</code> and logit for the <code class="reqn">\pi</code> as suggested by Lambert (1992). 
As for the zero truncated Poisson see https://en.wikipedia.org/wiki/Zero-truncated_Poisson_distribution.
</p>
<p>zip.mle is for the zero inflated Poisson, whereas ztp.mle is for the zero truncated Poisson distribution.
</p>


<h3>Value</h3>

<p>The following list is not inclusive of all cases. Different functions have different names. In general a list including:
</p>
<table>
<tr><td><code>mess</code></td>
<td>

<p>This is for the negbin.mle only. If there is no reason to use the negative binomial distribution a message will appear, otherwise this is NULL.
</p>
</td></tr>
<tr><td><code>iters</code></td>
<td>
<p>The number of iterations required for the Newton-Raphson to converge.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The value of the maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>The probability parameter of the distribution. In some distributions this argument might have a different name. 
For example, param in the zero inflated Poisson.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Lambert Diane (1992). Zero-Inflated Poisson Regression, with an Application to Defects in 
Manufacturing. Technometrics. 34 (1): 1-14
</p>
<p>Johnson Norman L., Kotz Samuel and Kemp Adrienne W. (1992). Univariate Discrete 
Distributions (2nd ed.). Wiley
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+colrange">colrange</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rpois(100, 2)
res&lt;-zip.mle(x)
res&lt;-poisson.mle(x)
## small difference in the two log-likelihoods as expected.

x &lt;- rpois(100, 10)
x[x == 0 ] &lt;- 1
res&lt;-ztp.mle(x)
res&lt;-poisson.mle(x)
## significant difference in the two log-likelihoods. 

x &lt;- rnbinom(100, 10, 0.6)
res&lt;-poisson.mle(x)
res&lt;-negbin.mle(x)
</code></pre>

<hr>
<h2 id='MLE+20of+20distributions+20defined+20in+20the+20+280+2C+201+29+20interval'>
MLE of distributions defined in the (0, 1) interval
</h2><span id='topic+beta.mle'></span><span id='topic+ibeta.mle'></span><span id='topic+logitnorm.mle'></span><span id='topic+hsecant01.mle'></span>

<h3>Description</h3>

<p>MLE of distributions defined in the (0, 1) interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta.mle(x, tol = 1e-09)
ibeta.mle(x, tol = 1e-09)
logitnorm.mle(x)
hsecant01.mle(x, tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20distributions+2B20defined+2B20in+2B20the+2B20+2B280+2B2C+2B201+2B29+2B20interval_+3A_x">x</code></td>
<td>

<p>A numerical vector with proportions, i.e. numbers in (0, 1) (zeros and ones are not allowed).
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20distributions+2B20defined+2B20in+2B20the+2B20+2B280+2B2C+2B201+2B29+2B20interval_+3A_tol">tol</code></td>
<td>

<p>The tolerance level up to which the maximisation stops.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood estimation of the parameters of the beta  distribution is performed via Newton-Raphson. The distributions and hence the functions 
does not accept zeros. &quot;logitnorm.mle&quot; fits the logistic normal, hence no nwewton-Raphson is required and the &quot;hypersecant01.mle&quot; uses the golden ratio 
search as is it faster than the Newton-Raphson (less calculations)
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>The estimated parameters. In the case of &quot;hypersecant01.mle&quot; this is called &quot;theta&quot; as there is only one parameter.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+diri.nr2">diri.nr2</a>, 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rbeta(1000, 1, 4)
for(i in 1:1000) beta.mle(x)
res&lt;-beta.mle(x)
res&lt;-ibeta.mle(x)

x &lt;- runif(1000)
res&lt;-hsecant01.mle(x)
res&lt;-logitnorm.mle(x)
res&lt;-ibeta.mle(x)

x &lt;- rbeta(1000, 2, 5)
x[sample(1:1000, 50)] &lt;- 0
res&lt;-ibeta.mle(x)




</code></pre>

<hr>
<h2 id='MLE+20of+20some+20circular+20distributions'>
MLE of some circular distributions
</h2><span id='topic+vm.mle'></span><span id='topic+spml.mle'></span><span id='topic+wrapcauchy.mle'></span>

<h3>Description</h3>

<p>MLE of some circular distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vm.mle(x, tol = 1e-09)
spml.mle(x, tol = 1e-09, maxiters = 100)
wrapcauchy.mle(x, tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20some+2B20circular+2B20distributions_+3A_x">x</code></td>
<td>

<p>A numerical vector with the circular data. They must be expressed in radians. For the &quot;spml.mle&quot; this can also
be a matrix with two columns, the cosinus and the sinus of the circular data.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20some+2B20circular+2B20distributions_+3A_tol">tol</code></td>
<td>

<p>The tolerance level to stop the iterative process of finding the MLEs.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20some+2B20circular+2B20distributions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations to implement.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters of the von Mises, the bivariate angular Gaussian and wrapped Cauchy distributions are estimated. For the Wrapped Cauchy,
the iterative procedure described by Kent and Tyler (1988) is used. As for the von Mises distribution,
we use a Newton-Raphson to estimate the concentration parameter. The angular Gaussian is described, in the regression setting in Presnell
et al. (1998).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The iterations required until convergence. This is returned in the wrapped Cauchy distribution only.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>A vector consisting of the estimates of the two parameters, the mean direction for both distributions
and the concentration parameter kappa and the rho for the von Mises and wrapped Cauchy respectively.
</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>

<p>The norm of the mean vector of the angualr Gaussian distribution.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean vector of the angular Gaussian distribution.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris and Stefanos Fafalios
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Stefanos Fafalios
&lt;stefanosfafalios@gmail.com&gt;
</p>


<h3>References</h3>

<p>Mardia K. V. and Jupp P. E. (2000). Directional statistics. Chicester: John Wiley &amp; Sons.
</p>
<p>Sra S. (2012). A short note on parameter approximation for von Mises-Fisher distributions:
and a fast implementation of Is(x). Computational Statistics, 27(1): 177-190.
</p>
<p>Presnell Brett, Morrison Scott P. and Littell Ramon C. (1998). Projected multivariate linear models for directional data.
Journal of the American Statistical Association, 93(443): 1068-1077.
</p>
<p>Kent J. and Tyler D. (1988). Maximum likelihood estimation for the wrapped Cauchy distribution.
Journal of Applied Statistics, 15(2): 247&ndash;254.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vmf.mle">vmf.mle</a>, <a href="#topic+rvonmises">rvonmises</a>, <a href="#topic+rvmf">rvmf</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rcauchy(100, 3, 1)
x &lt;- y 
res&lt;-vm.mle(x)
res&lt;-spml.mle(x)
res&lt;-wrapcauchy.mle(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20inverted+20Dirichlet+20distribution'>
MLE of the inverted Dirichlet distribution
</h2><span id='topic+invdir.mle'></span>

<h3>Description</h3>

<p>MLE of the inverted Dirichlet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invdir.mle(x, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20inverted+2B20Dirichlet+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix with strictly positive data (no zeros are allowed).
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20inverted+2B20Dirichlet+2B20distribution_+3A_tol">tol</code></td>
<td>

<p>The tolerance level up to which the maximisation stops.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood estimation of the parameters of the inverted  is performed via Newton-Raphson. We took the initial values suggested by Bdiri T. and Bouguila N. (2012) and modified them a bit. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton Raphson.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the log-likelihood.
</p>
</td></tr>
<tr><td><code>param</code></td>
<td>

<p>The estimated parameters.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>Bdiri T. and Bouguila N. (2012). Positive vectors clustering using inverted Dirichlet finite mixture models. Expert Systems with Applications, 39(2): 1869-1882.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diri.nr2">diri.nr2</a>, <a href="#topic+multinom.mle">multinom.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
for(i in 1:10) invdir.mle(x)
res&lt;-invdir.mle(x)
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20multivariate+20+28log-+29+20normal+20distribution'>
MLE of the multivariate (log-) normal distribution
</h2><span id='topic+mvnorm.mle'></span><span id='topic+mvlnorm.mle'></span>

<h3>Description</h3>

<p>MLE of the multivariate (log-) normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnorm.mle(x)
mvlnorm.mle(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20multivariate+2B20+2B28log-+2B29+2B20normal+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix with numerical data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean vector, covariance matrix and the value of the log-likelihood of the multivariate normal or log-normal distribution is calculated. 
For the log-normal distribution we also provide the expected value and the covariance matrix. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood multivariate distribution.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>

<p>The covariance matrix.
</p>
</td></tr>
<tr><td><code>m</code></td>
<td>

<p>The expected mean vector of the multivariate log-normal distribution.
</p>
</td></tr>
<tr><td><code>s</code></td>
<td>

<p>The expected covariance matrix of the multivariate log-normal distribution.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Kotz, S., Balakrishnan, N., &amp; Johnson, N. L. (2004). Continuous multivariate distributions, Volume 1: Models and applications (Vol. 1). John wiley &amp; sons.
</p>
<p>http://isi.cbs.nl/iamamember/CD2/pdf/329.PDF
</p>
<p>https://en.wikipedia.org/wiki/Log-normal_distribution#Multivariate_log-normal
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+multinom.mle">multinom.mle</a>, <a href="#topic+dmvnorm">dmvnorm</a>, <a href="#topic+gaussian.nb">gaussian.nb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 4)
res&lt;-mvnorm.mle(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20multivariate+20t+20distribution'>
MLE of the multivariate t distribution
</h2><span id='topic+mvt.mle'></span>

<h3>Description</h3>

<p>MLE of the multivariate t distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvt.mle(x, v = 5, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20multivariate+2B20t+2B20distribution_+3A_x">x</code></td>
<td>

<p>A matrix with numerical data.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20multivariate+2B20t+2B20distribution_+3A_v">v</code></td>
<td>

<p>The degrees of freedom. Must be a positive number, greater than zero.
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20multivariate+2B20t+2B20distribution_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the EM algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The location vector, scatter matrix and the value of the log-likelihood is calculated.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>
<p>The number of iterations required for the EM algorihm to converge.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The value of the maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>location</code></td>
<td>

<p>The location vector.
</p>
</td></tr>
<tr><td><code>scatter</code></td>
<td>

<p>The scatter matrix.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Nadarajah S. and Kotz S. (2008). Estimation methods for the multivariate t distribution.
Acta Applicandae Mathematicae, 102(1):99-118.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+mvnorm.mle">mvnorm.mle</a>, <a href="#topic+dmvnorm">dmvnorm</a>, <a href="#topic+gaussian.nb">gaussian.nb</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 4)
res&lt;-mvnorm.mle(x)
res&lt;-mvt.mle(x, v = 5)
res&lt;-mvt.mle(x, v = 100)
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20ordinal+20model+20without+20covariates'>
MLE of the ordinal model without covariates
</h2><span id='topic+ordinal.mle'></span>

<h3>Description</h3>

<p>MLE of the ordinal model without covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordinal.mle(y, link = "logit")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20ordinal+2B20model+2B20without+2B20covariates_+3A_y">y</code></td>
<td>

<p>A numerical vector with values 1, 2, 3,..., not zeros, or an ordered factor. 
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20ordinal+2B20model+2B20without+2B20covariates_+3A_link">link</code></td>
<td>

<p>This can either be &quot;logit&quot; or &quot;probit&quot;. It is the link function to be used. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Maximum likelihood of the ordinal model (proportional odds) is implemented. See for example the &quot;polr&quot; command 
in R or the examples.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood of the model.
</p>
</td></tr>
<tr><td><code>a</code></td>
<td>

<p>The intercepts (threshold coefficients) of the model.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Agresti, A. (2002) Categorical Data. Second edition. Wiley. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+beta.mle">beta.mle</a>, <a href="#topic+diri.nr2">diri.nr2</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- factor( rbinom(100,3,0.5), ordered = TRUE )
res&lt;-ordinal.mle(y)
res&lt;-ordinal.mle(y, link = "probit")
</code></pre>

<hr>
<h2 id='MLE+20of+20the+20tobit+20model'>
MLE of the tobit model
</h2><span id='topic+tobit.mle'></span>

<h3>Description</h3>

<p>MLE of the tobit model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tobit.mle(y, tol = 1e-09) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLE+2B20of+2B20the+2B20tobit+2B20model_+3A_y">y</code></td>
<td>

<p>A vector with positive valued data and zero values. If there are no zero values, a simple normal model is fitted in the end. 
</p>
</td></tr>
<tr><td><code id="MLE+2B20of+2B20the+2B20tobit+2B20model_+3A_tol">tol</code></td>
<td>

<p>The tolerance level up to which the maximisation stops; set to 1e-09 by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tobin model is useful for (univariate) positive data with left censoring at zero. There is the assumption of a latent variable. Tthe values of that variable which are positive
concide with the observed values. If some values are negative, they are left censored and the observed values are zero. 
Instead of maximising the log-likelihood via a numerical optimiser we have used a Newton-Raphson algorithm which is faster. 
</p>


<h3>Value</h3>

<p>A list with three elements including 
</p>
<table>
<tr><td><code>iters</code></td>
<td>
<p>The number of iterations required for the Newton-Raphson to converge.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>The value of the maximised log-likelihood.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>The vector of the parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Tobin James (1958). Estimation of relationships for limited dependent variables. Econometrica. 26(1):24&ndash;36. 
</p>
<p>https://en.wikipedia.org/wiki/Tobit_model
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+gammamle">gammamle</a>, <a href="#topic+normal.mle">normal.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(300, 3, 5)
x[ x &lt; 0 ] &lt;- 0   ## left censoring. Values below zero become zero
for (i in 1:50) tobit.mle(x)
</code></pre>

<hr>
<h2 id='Moment+20and+20maximum+20likelihood+20estimation+20of+20variance+20components'>
Moment and maximum likelihood estimation of variance components
</h2><span id='topic+rint.mle'></span><span id='topic+varcomps.mom'></span><span id='topic+varcomps.mle'></span>

<h3>Description</h3>

<p>Moment and maximum likelihood estimation of variance components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rint.mle(x, ina, ranef = FALSE, tol = 1e-09, maxiters = 100)
varcomps.mom(x, ina)
varcomps.mle(x, ina, tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Moment+2B20and+2B20maximum+2B20likelihood+2B20estimation+2B20of+2B20variance+2B20components_+3A_x">x</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
<tr><td><code id="Moment+2B20and+2B20maximum+2B20likelihood+2B20estimation+2B20of+2B20variance+2B20components_+3A_ranef">ranef</code></td>
<td>

<p>Should the random effects be returned as well? The default value is FALSE.
</p>
</td></tr>
<tr><td><code id="Moment+2B20and+2B20maximum+2B20likelihood+2B20estimation+2B20of+2B20variance+2B20components_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Be careful, the function is desinged to 
accept numbers greater than zero. Alternatively it can be a factor variable.
</p>
</td></tr>
<tr><td><code id="Moment+2B20and+2B20maximum+2B20likelihood+2B20estimation+2B20of+2B20variance+2B20components_+3A_tol">tol</code></td>
<td>

<p>The tolerance level to terminate the golden ratio search. the default value is 10^(-9).
</p>
</td></tr>
<tr><td><code id="Moment+2B20and+2B20maximum+2B20likelihood+2B20estimation+2B20of+2B20variance+2B20components_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations Newton-Raphson will implement.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the &quot;varcomps.mle&quot; and &quot;varcomp.mom&quot; work for <b>balanced designs only</b>, i.e. for each subject the same number of
measurements have been taken. The &quot;rint.mle&quot; works for both the balanced and unbalanced designs.
</p>
<p>The variance components, the variance of the between measurements and the 
variance of the within are estimated using moment estimators. The &quot;colvarcomsp.mom&quot; 
is the moment analogue of a random effects model which uses likelihood estimation (&quot;colvarcomps.mle&quot;). 
It is much faster, but can give negative variance of the random effects, in which case it becomes zero.
</p>
<p>The maximum likelihood version is a bit slower (try youselves to see the difference), but statistically 
speaking is to be preferred when small samples are available. The reason why it is only a little bit slower 
and not a lot slower as one would imagine is because we are using a closed formula to calculate the two variance
components (Demidenko, 2013, pg. 67-69). Yes, there are closed formulas for linear mixed models.     
</p>


<h3>Value</h3>

<p>For the &quot;varcomps.mom&quot;:
A vector with 5 elemets, The MSE, the estimate of the between variance, 
the variance components ratio and a 95% confidence for the ratio.
</p>
<p>For the &quot;varcomps.mle&quot;:
a list with a single component called &quot;info&quot;. That is a matrix with 3 columns, The MSE, the estimate of 
the between variance and the log-likelihood value. <b>If ranef = TRUE</b> a list including &quot;info&quot; 
and an extra component called &quot;ranef&quot; containing the random effects. It is a matrix with the same number of columns as the data. 
Each column contains the randome effects of each variable. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Montgomery D.C. (2001). Design and analysis of experiments (5th Edition). New York: John Wiley &amp; Sons. 
</p>
<p>Davis C.S. (2002). Statistical methods for the analysis of repeated measures. New York: Springer-Verlag.
</p>
<p>Demidenko E. (2013). Mixed Models: Theory and Applications with R 2nd Edition). New Jersey: John Wiley &amp; Sons (Excellent book).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colvarcomps.mle">colvarcomps.mle</a>, <a href="#topic+rint.reg">rint.reg</a>, <a href="#topic+rint.regbx">rint.regbx</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example from Montgomery, pages 514-517
x &lt;- c(98,97,99,96,91,90,93,92,96,95,97,95,95,96,99,98)
ina &lt;- rep(1:4, each = 4)
res&lt;-varcomps.mom(x, ina)
res&lt;-varcomps.mle(x, ina)
</code></pre>

<hr>
<h2 id='Multi-sample+20tests+20for+20vectors'>
Multi-sample tests for vectors
</h2><span id='topic+ftest'></span><span id='topic+anova1'></span><span id='topic+kruskaltest'></span><span id='topic+var2test'></span><span id='topic+ttest2'></span><span id='topic+mcnemar'></span><span id='topic+cqtest'></span><span id='topic+block.anova'></span><span id='topic+twoway.anova'></span>

<h3>Description</h3>

<p>Multi-sample tests for vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ftest(x, ina, logged = FALSE)
anova1(x, ina, logged = FALSE)
kruskaltest(x, ina, logged = FALSE) 
var2test(x, y, alternative = "unequal", logged = FALSE)
mcnemar(x, y, logged = FALSE)
ttest2(x, y, paired = FALSE, logged = FALSE)
cqtest(x, treat, block, logged = FALSE) 
block.anova(x, treat, block, logged = FALSE) 
twoway.anova(y, x1, x2, interact = FALSE, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_x">x</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_y">y</code></td>
<td>

<p>A numerical vector with the data.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with 1s, 2s, 3s and so one indicating the two groups. Be careful, the function is desinged to 
accept numbers greater than zero. 
Alternatively it can be a factor variable.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_paired">paired</code></td>
<td>

<p>This is for the two sample t-test  only and is TRUE or FALSE specifying whether the two samples are paired or not.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_alternative">alternative</code></td>
<td>

<p>This can either be &quot;unequal&quot;, &quot;greater&quot; or &quot;less&quot;.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_treat">treat</code></td>
<td>

<p>In the case of the blocking ANOVA and Cochran's Q test, this argument plays the role of the &quot;ina&quot; argument.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_block">block</code></td>
<td>
<p>This item (in the blocking ANOVA and Cochran's Q test) denotes the subjects which are the same. 
Similarly to &quot;ina&quot; a numeric vector with 1s, 2s, 3s and so on.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_x1">x1</code></td>
<td>

<p>The first factor in the two way ANOVA.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_x2">x2</code></td>
<td>

<p>The second factor in the two way ANOVA. The orderis not important.
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_interact">interact</code></td>
<td>

<p>Should interaction in the two way ANOVA be included? The default value is FALSE (no interaction). 
</p>
</td></tr>
<tr><td><code id="Multi-sample+2B20tests+2B20for+2B20vectors_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Welch's F-test (without assuming equal variances) is performed with the &quot;ftest&quot; function. The &quot;anova&quot; function 
perform the classical (Fisher's) one-way analysis of variance (ANOVA) which assumes equal variance across the groups. 
The &quot;kruskaltest&quot; performs the Kruskal-Wallis non parametric alternative to analysis of variance test.
The &quot;var2tests&quot; implement the classical F test for the equality of two sample variances. The &quot;cqtest&quot; performs the 
Cocrhan's Q test for the equality of more than two groups whose values are strictly binary (0 or 1). This is a 
generalisation of the McNemar's test in the multi-sample case. The &quot;block.anova&quot; is the ANOVA with blocking, 
randomised complete block design (RCBD). In this case, for every combination of the block and treatment values, there 
is only one observation. The mathematics are the same as in the case of &quot;twoway.anova&quot;, but the assumptions different
and the testing procedure also different. In addition, no interaction is present. 
</p>


<h3>Value</h3>

<p>A vector with the test statistic and the p-value of each test. For the case of t-test, an extra column with the 
degrees of freedom is given. For the two way ANOVA there can can be either 2 or three F test statistics and hence 
the same number of p-values. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>B.L. Welch (1951). On the comparison of several mean values: an alternative approach. Biometrika, 38(3/4), 330-336.
</p>
<p>D.C. Montgomery (2001). Design and analysis of experiments (5th Edition). New York: John Wiley &amp; Sons.
</p>
<p>McNemar Q. (1947). Note on the sampling error of the difference between correlated proportions or percentages. 
Psychometrika. 12(2):153-157. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ttests">ttests</a>, <a href="#topic+ftests">ftests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(200)
ina &lt;- rbinom(200, 3, 0.5) + 1
res&lt;-anova1(x, ina)
res&lt;-ftest(x, ina)
ina &lt;- rbinom(200, 1, 0.5) + 1
x1 &lt;- x[ ina == 1 ]   ; x2 &lt;- x[ ina == 2 ]
res&lt;-ttest2(x1, x2)
res&lt;-var2test(x1, x2)

## RCBD example 4.1 from Montgomery (2001), page 131-132
x &lt;- c(9.3, 9.4, 9.2, 9.7, 9.4, 9.3, 9.4, 9.6, 9.6, 9.8, 9.5, 10,
10, 9.9, 9.7, 10.2)
tr &lt;- rep(1:4, 4)
bl &lt;- rep(1:4, each = 4)
res&lt;-block.anova(x, tr, bl)
</code></pre>

<hr>
<h2 id='Multinomial+20regression'>
Multinomial regression
</h2><span id='topic+multinom.reg'></span>

<h3>Description</h3>

<p>Multinomial regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multinom.reg(y, x, tol = 1e-07, maxiters = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multinomial+2B20regression_+3A_y">y</code></td>
<td>

<p>The response variable. A numerical or a factor type vector.
</p>
</td></tr>
<tr><td><code id="Multinomial+2B20regression_+3A_x">x</code></td>
<td>

<p>A matrix or a data.frame with the predictor variables.
</p>
</td></tr>
<tr><td><code id="Multinomial+2B20regression_+3A_tol">tol</code></td>
<td>

<p>This tolerance value to terminate the Newton-Raphson algorithm. 
</p>
</td></tr>
<tr><td><code id="Multinomial+2B20regression_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations Newton-Raphson will perform.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The value of the maximised log-likelihood.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>A matrix with the estimated regression coefficients.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos 
Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Bohning, D. (1992). Multinomial logistic regression algorithm. Annals of the 
Institute of Statistical Mathematics, 44(1): 197-200.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+glm_logistic">glm_logistic</a>, <a href="#topic+score.multinomregs">score.multinomregs</a> <a href="#topic+logistic_only">logistic_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- iris[, 5]
x &lt;- matrnorm(150, 3)
res &lt;- multinom.reg(y, x)

</code></pre>

<hr>
<h2 id='Multivariate+20kurtosis'>
Multivariate kurtosis
</h2><span id='topic+mvkurtosis'></span>

<h3>Description</h3>

<p>Multivariate kurtosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvkurtosis(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20kurtosis_+3A_x">x</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The multivariate kurtosis is calcualted.
</p>


<h3>Value</h3>

<p>A number, the multivariate kurtosis.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>K. V. Mardia (1970). Measures of Multivariate Skewness and Kurtosis with Applications
Biometrika, 57(3):519-530.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colskewness">colskewness</a>, <a href="#topic+skew.test2">skew.test2</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
res&lt;-mvkurtosis(x)
</code></pre>

<hr>
<h2 id='Multivariate+20Laplace+20random+20values+20simulation'>
Multivariate Laplace random values simulation
</h2><span id='topic+rmvlaplace'></span>

<h3>Description</h3>

<p>Multivariate Laplace random values simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvlaplace(n, lam, mu, G, seed = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20Laplace+2B20random+2B20values+2B20simulation_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20Laplace+2B20random+2B20values+2B20simulation_+3A_lam">lam</code></td>
<td>

<p>The the parameter of the exponential distribution, a positive number.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20Laplace+2B20random+2B20values+2B20simulation_+3A_mu">mu</code></td>
<td>

<p>The mean vector.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20Laplace+2B20random+2B20values+2B20simulation_+3A_g">G</code></td>
<td>

<p>A <code class="reqn">d \times d</code> covariance matrix with determinant 1. 
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20Laplace+2B20random+2B20values+2B20simulation_+3A_seed">seed</code></td>
<td>

<p>If you want the same to be generated again use a seed for the generator, an integer number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm uses univariate normal random values and transforms them to multivariate via a spectral decomposition.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Eltoft T., Kim T., and Lee T.W. (2006). On the multivariate laplace distribution. Signal Processing Letters, IEEE, 13(5):300-303.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rmvnorm">rmvnorm</a>, <a href="#topic+racg">racg</a>, <a href="#topic+rmvt">rmvt</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- colmeans( as.matrix( iris[, 1:4] ) )
s &lt;- cov(iris[,1:4])
s &lt;- s / det(s)^0.25
lam &lt;- 3
x &lt;- rmvlaplace(100, lam, m, s)
</code></pre>

<hr>
<h2 id='Multivariate+20normal+20and+20t+20random+20values+20simulation'>
Multivariate normal and t random values simulation
</h2><span id='topic+rmvnorm'></span><span id='topic+rmvt'></span>

<h3>Description</h3>

<p>Multivariate normal and t random values simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvnorm(n, mu, sigma, seed = NULL)
rmvt(n, mu, sigma, v, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Multivariate+2B20normal+2B20and+2B20t+2B20random+2B20values+2B20simulation_+3A_n">n</code></td>
<td>

<p>The sample size, a numerical value.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20normal+2B20and+2B20t+2B20random+2B20values+2B20simulation_+3A_mu">mu</code></td>
<td>

<p>The mean vector in <code class="reqn">R^d</code>.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20normal+2B20and+2B20t+2B20random+2B20values+2B20simulation_+3A_sigma">sigma</code></td>
<td>

<p>The covariance matrix in <code class="reqn">R^d</code>.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20normal+2B20and+2B20t+2B20random+2B20values+2B20simulation_+3A_v">v</code></td>
<td>

<p>The degrees of freedom.
</p>
</td></tr>
<tr><td><code id="Multivariate+2B20normal+2B20and+2B20t+2B20random+2B20values+2B20simulation_+3A_seed">seed</code></td>
<td>

<p>If you want the same to be generated again use a seed for the generator, an integer number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm uses univariate normal random values and transforms them to multivariate via a spectral decomposition.
It is faster than the command &quot;mvrnorm&quot; available from MASS, and it allows for singular covariance matrices.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Aitchison J. (1986). The statistical analysis of compositional data. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+racg">racg</a>, <a href="#topic+rmvlaplace">rmvlaplace</a>, <a href="#topic+rmvt">rmvt</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
m &lt;- colmeans(x)
s &lt;- cov(x)
y &lt;- rmvnorm(1000, m, s)
res&lt;-colmeans(y)
res&lt;-cov(y)
y &lt;- NULL
</code></pre>

<hr>
<h2 id='Naive+20Bayes+20classifiers'>
Naive Bayes classifiers
</h2><span id='topic+gaussian.nb'></span><span id='topic+poisson.nb'></span><span id='topic+multinom.nb'></span><span id='topic+geom.nb'></span><span id='topic+gammanb'></span>

<h3>Description</h3>

<p>Gaussian, Poisson, geometric and multinomial naive Bayes classifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussian.nb(xnew = NULL, x, ina, parallel = FALSE)
poisson.nb(xnew, x, ina)
multinom.nb(xnew, x, ina) 
geom.nb(xnew, x, ina, type = 1)
gammanb(xnew = NULL, x, ina, tol = 1e-07)   
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers_+3A_xnew">xnew</code></td>
<td>

<p>A numerical matrix with new predictor variables whose group is to be predicted. For the Gaussian naive Bayes, 
this is set to NUUL, as you might want just the model and not to predict the membership of new observations. 
For the Gaussian case this contains any numbers, but for the multinomial and Poisson cases, the matrix must 
contain integer valued numbers only. 
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the observed predictor variable values. For the Gaussian case this contains any numbers, 
but for the multinomial and Poisson
cases, the matrix must contain integer valued numbers only. 
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with strictly positive numbers, i.e. 1,2,3 indicating the groups of the dataset. 
Alternatively this can be a factor variable.
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers_+3A_type">type</code></td>
<td>

<p>Type 1 refers to the case where the minimum is zero and type 2 for the case of the minimum being 1. This 
is for the geometric distribution. This argument is for the geometric distribution. Type 1 refers to the case where 
the minimum is zero and type 2 for 
the case of the minimum being 1. 
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm in the gamma distribution.
</p>
</td></tr>
<tr><td><code id="Naive+2B20Bayes+2B20classifiers_+3A_parallel">parallel</code></td>
<td>

<p>If you want parallel computations set this equal to TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For the Poisson and Multinomial naive Bayes classifiers the estimated group, a numerical vector with
1, 2, 3 and so on. For the Gaussian naive Bayes classifier a list including:
</p>
<table>
<tr><td><code>mu</code></td>
<td>

<p>A matrix with the mean vector of each group based on the dataset.
</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>

<p>A matrix with the variance of each group and variable based on the dataset.
</p>
</td></tr>
<tr><td><code>ni</code></td>
<td>

<p>The sample size of each group in the dataset.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated group of the xnew observations. It returns a numerical value back regardless of the target 
variable being numerical as well or factor. Hence, it is suggested that you do \&quot;as.numeric(target)\&quot; in order to 
see what is the predicted class of the new data. 
</p>
</td></tr>
</table>
<p>For the Gamma classifier a list including:
</p>
<table>
<tr><td><code>a</code></td>
<td>

<p>A matrix with the shape parameters.
</p>
</td></tr>
<tr><td><code>b</code></td>
<td>

<p>A matrix with the scale parameters.
</p>
</td></tr>
<tr><td><code>est</code></td>
<td>

<p>The estimated group of the xnew observations. It returns a numerical value back regardless of the target 
variable being numerical as well or factor. Hence, it is suggested that you do \&quot;as.numeric(target)\&quot; in order to 
see what is the predicted class of the new data. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+gaussiannb.pred">gaussiannb.pred</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:4])
a &lt;- gaussian.nb(x, x, iris[, 5])
x1 &lt;- matrix( rpois(100 * 4, 5), ncol = 4)
x2 &lt;- matrix( rpois(50 * 4, 10), ncol = 4)
x &lt;- rbind(x1, x2)
ina &lt;- c( rep(1, 100), rep(2, 50) )
res&lt;-poisson.nb(x, x, ina)
res&lt;-geom.nb(x, x, ina)
res&lt;-multinom.nb(x, x, ina)
</code></pre>

<hr>
<h2 id='Natural+20Logarithm+20each+20element+20of+20a+20matrix'>
Natural Logarithm each element of a matrix
</h2><span id='topic+Log'></span>

<h3>Description</h3>

<p>Natural Logarithm each element of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Log(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Natural+2B20Logarithm+2B20each+2B20element+2B20of+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with data. 
</p>
</td></tr>
<tr><td><code id="Natural+2B20Logarithm+2B20each+2B20element+2B20of+2B20a+2B20matrix_+3A_na.rm">na.rm</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for removing NA. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument must be a matrix. For vector the time was the same as R's &quot;log&quot; function so we did not add it.
</p>


<h3>Value</h3>

<p>A matrix where each element is the natural logarithm of the given argument.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lbeta">Lbeta</a>, <a href="#topic+Lchoose">Lchoose</a>, <a href="#topic+Choose">Choose</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;-matrix( runif( 100 * 100), ncol = 100 )
a &lt;- log(x) 
b &lt;- Log(x) 
all.equal(a, b) # true

x&lt;-a&lt;-b&lt;-NULL
</code></pre>

<hr>
<h2 id='Natural+20logarithm+20of+20the+20beta+20function'>
Natural logarithm of the beta function
</h2><span id='topic+Lbeta'></span>

<h3>Description</h3>

<p>Natural logarithm of the beta function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lbeta(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Natural+2B20logarithm+2B20of+2B20the+2B20beta+2B20function_+3A_x">x</code></td>
<td>

<p>A numerical matrix, or a vector or just a number with positive numbers in either case.
</p>
</td></tr>
<tr><td><code id="Natural+2B20logarithm+2B20of+2B20the+2B20beta+2B20function_+3A_y">y</code></td>
<td>

<p>A numerical matrix, or a vector or just a number with positive numbers in either case. The dimensions of y 
must match those of x.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is faster than R's lbeta when the dimensions of x any are large. If you have only two numbers, 
then lbeta is faster. But if you have for example two vectors of 1000 values each, Lbeta becomes two times 
faster than lbeta.
</p>


<h3>Value</h3>

<p>The matrix, vector or number with the resulting values.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972) Handbook of Mathematical Functions. New York: Dover. https://en.wikipedia.org/wiki/Abramowitz_and_Stegun provides links to the full text which is in public domain.
Chapter 6: Gamma and Related Functions. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lgamma">Lgamma</a>, <a href="#topic+beta.mle">beta.mle</a>, <a href="#topic+diri.nr2">diri.nr2</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rexp(1000)
y &lt;- rexp(1000)
a1 &lt;- Lbeta(x, y)

x&lt;-y&lt;-a1&lt;-NULL
</code></pre>

<hr>
<h2 id='Natural+20logarithm+20of+20the+20gamma+20function+20and+20its+20derivatives'>
Natural logarithm of the gamma function and its derivatives.
</h2><span id='topic+Lgamma'></span><span id='topic+Digamma'></span><span id='topic+Trigamma'></span>

<h3>Description</h3>

<p>Natural logarithm of the gamma function and its derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lgamma(x)
Digamma(x)
Trigamma(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Natural+2B20logarithm+2B20of+2B20the+2B20gamma+2B20function+2B20and+2B20its+2B20derivatives_+3A_x">x</code></td>
<td>

<p>A numerical matrix or vector with positive numbers in either case.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We have spotted that the time savings come when there are more than 50 elements, with vector or matrix.
</p>


<h3>Value</h3>

<p>The matrix or the vector with the resulting values.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Abramowitz, M. and Stegun, I. A. (1972) Handbook of Mathematical Functions. New York: Dover. https://en.wikipedia.org/wiki/Abramowitz_and_Stegun provides links to the full text which is in public domain.
Chapter 6: Gamma and Related Functions. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+beta.mle">beta.mle</a>, <a href="#topic+diri.nr2">diri.nr2</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(500 * 500), ncol = 500 )
 a1 &lt;- Lgamma(x) 
a2 &lt;- lgamma(x) 
all.equal(as.vector(a1), as.vector(a2))

a1 &lt;- Digamma(x) 
a2 &lt;- digamma(x) 
all.equal(as.vector(a1), as.vector(a2))

x&lt;-a1&lt;-a2&lt;-NULL
</code></pre>

<hr>
<h2 id='Norm+20of+20a+20matrix'>
Norm of a matrix
</h2><span id='topic+Norm'></span>

<h3>Description</h3>

<p>Norm of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Norm(x, type = "F")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Norm+2B20of+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with numbers.
</p>
</td></tr>
<tr><td><code id="Norm+2B20of+2B20a+2B20matrix_+3A_type">type</code></td>
<td>

<p>The type of norm to be calculated. The default is &quot;F&quot; standing for Frobenius norm (&quot;f&quot; in R's norm). The other 
options are &quot;C&quot; standing for the one norm (&quot;o&quot; in R's norm), &quot;R&quot; for the identiy norm (&quot;I&quot; in R's norm) and &quot;M&quot; 
for the maximum modulus among elements of a matrix (&quot;M&quot; in R's norm)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number, the norm of the matrix.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+Dist">Dist</a>, <a href="#topic+dista">dista</a>, <a href="#topic+colmeans">colmeans</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(10 * 10), ncol = 10 )
res&lt;-Norm(x, "F")
res&lt;-norm(x, "F")
res&lt;-Norm(x, "M")
res&lt;-norm(x, "M")
</code></pre>

<hr>
<h2 id='Number+20of+20equal+20columns+20between+20two+20matrices'>Number of equal columns between two matrices
</h2><span id='topic+mat.mat'></span>

<h3>Description</h3>

<p>Number of equal columns between two matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mat.mat(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Number+2B20of+2B20equal+2B20columns+2B20between+2B20two+2B20matrices_+3A_x">x</code></td>
<td>

<p>A numerical matrix. See details for more information. It must have the same number of rows as y.
</p>
</td></tr>
<tr><td><code id="Number+2B20of+2B20equal+2B20columns+2B20between+2B20two+2B20matrices_+3A_y">y</code></td>
<td>

<p>A numerical matrix. See details for more information. It must have the same number of rows as x.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function takes each column of x and checks the number of times it matches a column of y. In the example below, we take the first 3 columns of iris 
as the x matrix. The y matrix is the whole of iris. We will see how many times, each column of x appears in the y matrix. The answer is 1 for each column. 
</p>


<h3>Value</h3>

<p>A numerical vector of size equal to the number of columns of x. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis 
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Match">Match</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[, 1:3])
y &lt;- iris
y[, 5] &lt;- as.numeric(y[, 5])
y &lt;- as.matrix(y)
res&lt;-mat.mat(x, y)

x&lt;-y&lt;-NULL
</code></pre>

<hr>
<h2 id='Odds+20ratio+20and+20relative+20risk'>
Odds ratio and relative risk
</h2><span id='topic+odds.ratio'></span><span id='topic+rel.risk'></span>

<h3>Description</h3>

<p>Odds ratio and relative risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>odds.ratio(x, a = 0.05, logged = FALSE)
rel.risk(x, a = 0.05, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Odds+2B20ratio+2B20and+2B20relative+2B20risk_+3A_x">x</code></td>
<td>

<p>A 2 x 2 matrix or a vector with 4 elements. In the case of the vector make sure it corresponds to the correct table.
</p>
</td></tr>
<tr><td><code id="Odds+2B20ratio+2B20and+2B20relative+2B20risk_+3A_a">a</code></td>
<td>

<p>The significance level, set to 0.05 by default.
</p>
</td></tr>
<tr><td><code id="Odds+2B20ratio+2B20and+2B20relative+2B20risk_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The odds ratio and the confidence interval are calculated.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>res</code></td>
<td>

<p>The estimated odds ratio and the p-value for the null hypothesis test that it is equal to 1.
</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>

<p>The (1-a)% confidence interval for the true value of the odds ratio.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Mosteller Frederick (1968). Association and Estimation in Contingency Tables. Journal of the American Statistical 
Association. 63(321):1-28.
</p>
<p>Edwards A.W.F. (1963). The measure of association in a 2x2 table. Journal of the Royal Statistical Society, Series A. 
126(1):109-114. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+odds">odds</a>, <a href="#topic+g2Test">g2Test</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rpois(4, 30)+2
res&lt;-odds.ratio(x)
res&lt;-odds.ratio( matrix(x, ncol = 2) )
</code></pre>

<hr>
<h2 id='One+20sample+20t-test+20for+20a+20vector'>
One sample t-test for a vector
</h2><span id='topic+ttest1'></span>

<h3>Description</h3>

<p>One sample t-test for a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ttest1(x, m, alternative = "unequal", logged = FALSE, conf = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="One+2B20sample+2B20t-test+2B20for+2B20a+2B20vector_+3A_x">x</code></td>
<td>

<p>A numerical vector with the data. 
</p>
</td></tr>
<tr><td><code id="One+2B20sample+2B20t-test+2B20for+2B20a+2B20vector_+3A_m">m</code></td>
<td>

<p>The mean value under the null hypothesis.
</p>
</td></tr>
<tr><td><code id="One+2B20sample+2B20t-test+2B20for+2B20a+2B20vector_+3A_alternative">alternative</code></td>
<td>

<p>The alternative hypothesis, &quot;unequal&quot;, &quot;greater&quot; or &quot;less&quot;.
</p>
</td></tr>
<tr><td><code id="One+2B20sample+2B20t-test+2B20for+2B20a+2B20vector_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
<tr><td><code id="One+2B20sample+2B20t-test+2B20for+2B20a+2B20vector_+3A_conf">conf</code></td>
<td>

<p>If you want a confidence interval supply the confidence level.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The usual one sample t-test is implemented, only faster.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>res</code></td>
<td>

<p>A two valued vector with the test statistic and its (logged) p-value.
</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>

<p>In the case you supplied a number in the input argument &quot;conf&quot; the relevant confidence interval will 
be returned as well.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ttest">ttest</a>, <a href="#topic+anova1">anova1</a>, <a href="#topic+ttests">ttests</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = rnorm(500)
res&lt;-t.test(x, mu = 0)
res&lt;-ttest1(x, 0, conf = 0.95)
</code></pre>

<hr>
<h2 id='Operations+20between+20two+20matrices+20or+20matrix+20and+20vector'>
Operations between two matrices or matrix and vector
</h2><span id='topic+XopY.sum'></span><span id='topic+eachrow'></span><span id='topic+eachcol.apply'></span>

<h3>Description</h3>

<p>Operations between two matrices or matrix and vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XopY.sum(x, y = NULL, oper = "*")
eachrow(x,y,oper = "*",method = NULL)
eachcol.apply(x,y,indices = NULL,oper = "*",apply = "sum", parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Operations+2B20between+2B20two+2B20matrices+2B20or+2B20matrix+2B20and+2B20vector_+3A_x">x</code></td>
<td>

<p>A numerical matrix.
</p>
</td></tr>
<tr><td><code id="Operations+2B20between+2B20two+2B20matrices+2B20or+2B20matrix+2B20and+2B20vector_+3A_y">y</code></td>
<td>

<p>A second numerical matrix for &quot;XopY.sum&quot; whose dimensions must match the ones of x, or vector for &quot;eachrow&quot;,&quot;eachcol.apply&quot; whose length must match with the rows of x.
</p>
</td></tr>
<tr><td><code id="Operations+2B20between+2B20two+2B20matrices+2B20or+2B20matrix+2B20and+2B20vector_+3A_oper">oper</code></td>
<td>

<p>The operation to be performed, either &quot;*&quot;, &quot;/&quot;, &quot;+&quot;, &quot;-&quot; or &quot;==&quot;.
</p>
</td></tr>
<tr><td><code id="Operations+2B20between+2B20two+2B20matrices+2B20or+2B20matrix+2B20and+2B20vector_+3A_method">method</code></td>
<td>

<p>A character value for choosing option to apply in the result.
Options:
1) sum
2) max
3) min
</p>
<p>Does not work for oper=&quot;==&quot;.
</p>
</td></tr>
<tr><td><code id="Operations+2B20between+2B20two+2B20matrices+2B20or+2B20matrix+2B20and+2B20vector_+3A_indices">indices</code></td>
<td>

<p>An integer vector with indices to specific columns. Only for &quot;eachcol.apply&quot;.
</p>
</td></tr>
<tr><td><code id="Operations+2B20between+2B20two+2B20matrices+2B20or+2B20matrix+2B20and+2B20vector_+3A_apply">apply</code></td>
<td>

<p>A character value with the function to be applied in the columns of the matrix. Only for &quot;eachcol.apply&quot;. 
Options:
1) sum
2) median
3) max
4) min
</p>
</td></tr>
<tr><td><code id="Operations+2B20between+2B20two+2B20matrices+2B20or+2B20matrix+2B20and+2B20vector_+3A_parallel">parallel</code></td>
<td>

<p>A boolean value for parallel version.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>XopY.sum: sum(X op Y) where op can be on of &quot;+,-,*,/&quot;.
</p>
<p>eachrow: X op Y <b>by row</b> or <b>FUNCTION</b>(X op Y) where &quot;x&quot; is matrix, &quot;y&quot; is vector with length as much an the columns of x and &quot;op&quot; is one of &quot;+,-,*,/,==&quot;, and &quot;FUNCTION&quot; is a specific method for applying in the result matrix (see argument method).
</p>
<p>eachcol.apply: <b>FUNCTION</b>(X op Y) <b>by column</b> where &quot;x&quot; is matrix, &quot;y&quot; is vector with length as much an the rows of x, &quot;op&quot; is one of &quot;+,-,*,/&quot; and &quot;FUNCTION&quot; is a specific method (see argument apply).
</p>
<p><b>NOTE:</b> Arguments &quot;method&quot; does not work for oper=&quot;==&quot; and this operation works only in &quot;eachrow&quot;.
</p>


<h3>Value</h3>

<p>XopY.sum: sum(X op Y) where &quot;op&quot; can be on of &quot;+,-,*,/&quot;.
</p>
<p>eachrow: operation by row between a matrix and a vector.&quot;op&quot; can be on of &quot;+,-,*,/&quot;.
If &quot;suma=TRUE&quot; then returns the sum of this operation.
</p>
<p>eachcol.apply: operation by column between a matrix and a vector and applied a specific function.&quot;op&quot; can be on of &quot;+,-,*,/&quot;.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+Dist">Dist</a>, <a href="#topic+dista">dista</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+Diag.fill">Diag.fill</a>, 
<a href="#topic+colMads">colMads</a>, <a href="#topic+rowMads">rowMads</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(5 * 5), ncol = 5 )
y &lt;- matrix( rnorm(5 * 5), ncol = 5 )
res&lt;-XopY.sum(x, y, oper = "*")
y &lt;- x[,1]
res&lt;-eachrow(x,y)

all.equal(eachcol.apply(x,y),colsums(x*y))


x&lt;-y&lt;-NULL
</code></pre>

<hr>
<h2 id='Orthogonal+20matching+20pursuit+20variable+20selection'>
Orthogonal matching pursuit variable selection
</h2><span id='topic+ompr'></span><span id='topic+omp'></span>

<h3>Description</h3>

<p>Orthogonal matching pursuit variable selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ompr(y, x, ystand = TRUE, xstand = TRUE, method = "BIC", tol = 2 )
omp(y, x, xstand = TRUE, tol = qchisq(0.95, 1) + log( length(y) ), type = "logistic" ) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Orthogonal+2B20matching+2B20pursuit+2B20variable+2B20selection_+3A_y">y</code></td>
<td>

<p>The response variable, a numeric vector. For &quot;ompr&quot; this is a continuous variable.
For &quot;omp&quot; this can be either a vector with discrete (count) data, 0 and 1, non negative
values, strictly positive or proportions including 0 and 1.
</p>
</td></tr>
<tr><td><code id="Orthogonal+2B20matching+2B20pursuit+2B20variable+2B20selection_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the observations and the columns are the variables. 
</p>
</td></tr>
<tr><td><code id="Orthogonal+2B20matching+2B20pursuit+2B20variable+2B20selection_+3A_ystand">ystand</code></td>
<td>

<p>If this is TRUE the response variable is centered. The mean is subtracted from every value.
</p>
</td></tr>
<tr><td><code id="Orthogonal+2B20matching+2B20pursuit+2B20variable+2B20selection_+3A_xstand">xstand</code></td>
<td>

<p>If this is TRUE the independent variables are standardised. 
</p>
</td></tr>
<tr><td><code id="Orthogonal+2B20matching+2B20pursuit+2B20variable+2B20selection_+3A_method">method</code></td>
<td>

<p>You can choose between the change in the BIC (&quot;BIC&quot;), the adjusted <code class="reqn">R^2</code> (&quot;ar2&quot;),  
the SSE (&quot;SSE&quot;) or the classical p-value based (&quot;pvalue&quot;). 
</p>
</td></tr>
<tr><td><code id="Orthogonal+2B20matching+2B20pursuit+2B20variable+2B20selection_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the algorithm. This is the change in the criterion value 
between two successive steps. For &quot;ompr&quot; the default value is 2 because the default method
is &quot;BIC&quot;. For &quot;omp&quot; the default value is the 95% quantile of the <code class="reqn">\chi^2</code> distribution
with 1 degree of freedom plus the logarithm of the sample size.
</p>
</td></tr>
<tr><td><code id="Orthogonal+2B20matching+2B20pursuit+2B20variable+2B20selection_+3A_type">type</code></td>
<td>

<p>This denotes the parametric model to be used each time. It depends upon the nature of y. 
The possible values are &quot;logistic&quot;, &quot;poisson&quot;, &quot;quasipoisson&quot;, &quot;quasibinomial&quot;, &quot;normlog&quot;,
&quot;gamma&quot;, &quot;weibull&quot;, &quot;mv&quot; (for multivariate response variable) or &quot;multinomial&quot;.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For &quot;ompr&quot; a list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the algorithm.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A matrix with two columns. The selected variable(s) and the criterion value at every step. 
</p>
</td></tr>
</table>
<p>For &quot;omp&quot; a list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The runtime of the algorithm.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The <code class="reqn">\phi</code> parameter. In the cases of &quot;quasipoisson&quot;, &quot;quasibinomial&quot; and &quot;normlog&quot; this is useful. For all other cases this is NULL.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A matrix with two columns. The selected variable(s) and the criterion value at every step. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Pati Y. C., Rezaiifar R. &amp; Krishnaprasad P. S. (1993). Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition. In Signals, Systems and Computers. 1993 Conference Record of The Twenty-Seventh Asilomar Conference on. IEEE.
</p>
<p>Mazin Abdulrasool Hameed (2012). Comparative analysis of orthogonal matching pursuit and least angle regression. MSc thesis, Michigan State University.
https://www.google.gr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0ahUKEwik9P3Yto7XAhUiCZoKHQ8XDr8QFgglMAA&amp;url=https
</p>
<p>Lozano A., Swirszcz G., &amp; Abe N. (2011). Group orthogonal matching pursuit for logistic regression. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics.
</p>
<p>The <code class="reqn">\gamma</code>-OMP algorithm for feature selection with application to gene expression data. 
IEEE/ACM Transactions on Computational Biology and Bioinformatics (Accepted for publication)
https://arxiv.org/pdf/2004.00281.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+cor.fbed">cor.fbed</a>, <a href="#topic+cor.fsreg">cor.fsreg</a>, <a href="#topic+correls">correls</a>, <a href="#topic+fs.reg">fs.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm(100, 400)
y &lt;- rnorm(100)
a &lt;- ompr(y, x)
a
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Outer+20function'>
Outer function
</h2><span id='topic+Outer'></span>

<h3>Description</h3>

<p>The outer function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Outer(x, y, oper = "*")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Outer+2B20function_+3A_x">x</code></td>
<td>

<p>A numerical vector.
</p>
</td></tr>
<tr><td><code id="Outer+2B20function_+3A_y">y</code></td>
<td>

<p>A numerical vector.
</p>
</td></tr>
<tr><td><code id="Outer+2B20function_+3A_oper">oper</code></td>
<td>

<p>The available options are &quot;*&quot; (multiplication), &quot;/&quot; (division), &quot;+&quot; (sum), &quot;-&quot; (substraction), 
&quot;^&quot; (power raise), and &quot;
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is the same as R's &quot;outer&quot;, but works with vectors only and probably has less 
capabilities, but faster.
</p>


<h3>Value</h3>

<p>A matrix with all the combinations.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Michail Tsagris
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; 
and Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+mat.mult">mat.mult</a>, <a href="#topic+vecdist">vecdist</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(10)
y &lt;- rnorm(10)
res&lt;-Outer(x, y)
</code></pre>

<hr>
<h2 id='Permutation+20based+20p-value+20for+20the+20Pearson+20correlation+20coefficient'>
Permutation based p-value for the Pearson correlation coefficient
</h2><span id='topic+permcor'></span>

<h3>Description</h3>

<p>Permutation based p-value for the Pearson correlation coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permcor(x, y, R = 999) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Permutation+2B20based+2B20p-value+2B20for+2B20the+2B20Pearson+2B20correlation+2B20coefficient_+3A_x">x</code></td>
<td>

<p>A numerical vector with the first variable. 
</p>
</td></tr>
<tr><td><code id="Permutation+2B20based+2B20p-value+2B20for+2B20the+2B20Pearson+2B20correlation+2B20coefficient_+3A_y">y</code></td>
<td>

<p>A numerical vector with the second variable. 
</p>
</td></tr>
<tr><td><code id="Permutation+2B20based+2B20p-value+2B20for+2B20the+2B20Pearson+2B20correlation+2B20coefficient_+3A_r">R</code></td>
<td>

<p>The number of permutations to be conducted; set to 999 by default. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a very low computational calculation of the p-value. Try it yourselves. 
</p>


<h3>Value</h3>

<p>A vector consisting of two values, the Pearson correlation and the permutation based p-value. 
</p>


<h3>Author(s)</h3>

<p>Marios Dimitriadis and Michail Tsagris
</p>
<p>R implementation and documentation: Marios Dimitriadis and Michail Tsagris &lt;kmdimitriadis@gmail.com&gt; 
and &lt;mtsagris@csd.uoc.gr&gt;
</p>


<h3>References</h3>

<p>Chatzipantsiou C., Dimitriadis M., Papadakis M. and Tsagris M. (2019). 
Extremely efficient permutation and bootstrap hypothesis tests using R. 
To appear in the Journal of Modern Applied Statistical Methods.
</p>
<p>https://arxiv.org/ftp/arxiv/papers/1806/1806.10947.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pc.skel">pc.skel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, 1]
y &lt;- iris[, 2]
res&lt;-permcor(x, y)
res&lt;-permcor(x, y, R = 9999)
</code></pre>

<hr>
<h2 id='Polyserial+20correlation'>
Polyserial correlation
</h2><span id='topic+poly.cor'></span>

<h3>Description</h3>

<p>Polyserial correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poly.cor(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Polyserial+2B20correlation_+3A_x">x</code></td>
<td>

<p>The continuous variable.
</p>
</td></tr>
<tr><td><code id="Polyserial+2B20correlation_+3A_y">y</code></td>
<td>

<p>The ordinal variable, a numeric vector with numbers starting from 1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The polyserial correlation between a continuous and an ordinal variable is calculated. The function is not 
super fast, yet is faster than other implementations we found. 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>est</code></td>
<td>

<p>A vector with the polyserial correlation and its estimated variance.
</p>
</td></tr>
<tr><td><code>test</code></td>
<td>

<p>A vector with the test statistic and its associated p-value.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;
</p>


<h3>References</h3>

<p>Olsson U., Drasgow F. and Dorans N. J. (1982). 
The polyserial correlation coefficient. Psychometrika, 47(3):337-347.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+correls">correls</a>, <a href="#topic+Table">Table</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
y &lt;- rpois(100, 10) + 1
res&lt;-poly.cor(x, y)
</code></pre>

<hr>
<h2 id='Pooled+20covariance+20matrix'>
Pooled covariance matrix
</h2><span id='topic+pooled.cov'></span>

<h3>Description</h3>

<p>Pooled covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pooled.cov(x, ina)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pooled+2B20covariance+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with continuous data.
</p>
</td></tr>
<tr><td><code id="Pooled+2B20covariance+2B20matrix_+3A_ina">ina</code></td>
<td>

<p>A numerical vector indicating the groups. <b>The nubmers must be consecutive and start from 1</b>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The spatial median is at first computed (if not supplied) and then the covariance matrix. 
</p>


<h3>Value</h3>

<p>The spatial sign covariance matrix.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Durre A, Vogel D. and D.E. Tyler D.E.(2014). The spatial sign covariance matrix with unknown location.  Journal of Multivariate Analysis, 130: 107-117.
http://arxiv.org/pdf/1307.5706v2.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spat.med">spat.med</a>, <a href="#topic+spatmed.reg">spatmed.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
res&lt;-sscov( as.matrix(iris[, 1:4]) )

</code></pre>

<hr>
<h2 id='Prediction+20with+20some+20naive+20Bayes+20classifiers'>
Prediction with some naive Bayes classifiers
</h2><span id='topic+gaussiannb.pred'></span><span id='topic+poissonnb.pred'></span><span id='topic+multinomnb.pred'></span><span id='topic+gammanb.pred'></span><span id='topic+geomnb.pred'></span>

<h3>Description</h3>

<p>Prediction with some naive Bayes classifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussiannb.pred(xnew, m, s, ni)
poissonnb.pred(xnew, m)
multinomnb.pred(xnew, m)  
gammanb.pred(xnew, a, b)  
geomnb.pred(xnew, prob)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Prediction+2B20with+2B20some+2B20naive+2B20Bayes+2B20classifiers_+3A_xnew">xnew</code></td>
<td>

<p>A numerical matrix with new predictor variables whose group is to be predicted. For the Gaussian case this contains any numbers, but for the multinomial 
and Poisson cases, the matrix must contain integer valued numbers only. 
</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20some+2B20naive+2B20Bayes+2B20classifiers_+3A_m">m</code></td>
<td>

<p>A matrix with the group means. Each row corresponds to a group.
</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20some+2B20naive+2B20Bayes+2B20classifiers_+3A_s">s</code></td>
<td>

<p>A matrix with the group colum-wise variances. Each row corresponds to a group.
</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20some+2B20naive+2B20Bayes+2B20classifiers_+3A_ni">ni</code></td>
<td>

<p>A vector with the frequencies of each group.
</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20some+2B20naive+2B20Bayes+2B20classifiers_+3A_a">a</code></td>
<td>

<p>A vector with the shape parameters of each group.
</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20some+2B20naive+2B20Bayes+2B20classifiers_+3A_b">b</code></td>
<td>

<p>A vector with the scale parameters of each group.
</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20some+2B20naive+2B20Bayes+2B20classifiers_+3A_prob">prob</code></td>
<td>

<p>A vector with the sprobability parameters of each group.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numerical vector with 1, 2, ... denoting the predicted group. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+gaussian.nb">gaussian.nb</a>, <a href="#topic+colpoisson.mle">colpoisson.mle</a> <a href="#topic+colVars">colVars</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ina &lt;- sample(1:150, 100)
x &lt;- as.matrix(iris[, 1:4])
id &lt;- as.numeric(iris[, 5])
a &lt;- gaussian.nb(xnew = NULL, x[ina, ], id[ina])
est &lt;- gaussiannb.pred(x[-ina, ], a$mu, a$sigma, a$ni)
res&lt;-table(id[-ina], est)
</code></pre>

<hr>
<h2 id='Quasi+20binomial+20regression+20for+20proportions'>
Quasi binomial regression for proportions
</h2><span id='topic+prop.reg'></span><span id='topic+prop.regs'></span>

<h3>Description</h3>

<p>Quasi binomial regression for proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prop.reg(y, x, varb = "quasi", tol = 1e-09, maxiters = 100) 
prop.regs(y, x, varb = "quasi", tol = 1e-09, logged = FALSE, maxiters = 100) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_y">y</code></td>
<td>

<p>A numerical vector proportions. 0s and 1s are allowed. 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_x">x</code></td>
<td>

<p>For the &quot;prop.reg&quot; a matrix with data, the predictor variables. This can be a matrix or a data frame.
For the &quot;prop.regs&quot; this must be a numerical matrix, where each columns denotes a variable.
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm. This is set to <code class="reqn">10^{-9}</code> by default.
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_varb">varb</code></td>
<td>

<p>The type of estimate to be used in order to estimate the covariance matrix of the regression coefficients. 
There are two options, either &quot;quasi&quot; (default value) or &quot;glm&quot;. See the references for more information. 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?  
</p>
</td></tr>
<tr><td><code id="Quasi+2B20binomial+2B20regression+2B20for+2B20proportions_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations before the Newton-Raphson is terminated automatically.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We are using the Newton-Raphson, but unlike R's built-in function &quot;glm&quot; we do no checks and no extra calculations, 
or whatever. Simply the model. The &quot;prop.regs&quot; is to be used for very many univariate regressions. The &quot;x&quot; is a 
matrix in this case and the significance of each variable (column of the matrix) is tested. The function accepts binary 
responses as well (0 or 1).
</p>


<h3>Value</h3>

<p>For the &quot;prop.reg&quot; function a list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations required by the Newton-Raphson.
</p>
</td></tr>
<tr><td><code>varb</code></td>
<td>

<p>The covariance matrix of the regression coefficients.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The phi parameter is returned if the input argument &quot;varb&quot; was set to &quot;glm&quot;, othwerise this is NULL.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>

<p>A table similar to the one produced by &quot;glm&quot; with the estimated regression coefficients, their standard error,
Wald test statistic and p-values.
</p>
</td></tr>
</table>
<p>For the &quot;prop.regs&quot; a two-column matrix with the test statistics (Wald statistic) and the associated p-values 
(or their loggarithm). 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Papke L. E. &amp; Wooldridge J. (1996). Econometric methods for fractional response variables with 
an application to 401(K) plan participation rates. Journal of Applied Econometrics, 11(6): 619&ndash;632.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+anova_propreg">anova_propreg</a> <a href="#topic+univglms">univglms</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+logistic_only">logistic_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- rbeta(100, 1, 4)
x &lt;- matrix(rnorm(100 * 3), ncol = 3)
a &lt;- prop.reg(y, x)
y &lt;- rbeta(100, 1, 4)
x &lt;- matrix(rnorm(400 * 100), ncol = 400)
b &lt;- prop.regs(y, x)
res&lt;-mean(b[, 2] &lt; 0.05)

</code></pre>

<hr>
<h2 id='Quasi+20Poisson+20regression+20for+20count+20data'>
Quasi Poisson regression
</h2><span id='topic+qpois.reg'></span><span id='topic+qpois.regs'></span>

<h3>Description</h3>

<p>Quasi Poisson regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qpois.reg(x, y, full = FALSE, tol = 1e-09,maxiters = 100) 
qpois.regs(x, y, tol = 1e-09, logged = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Quasi+2B20Poisson+2B20regression+2B20for+2B20count+2B20data_+3A_x">x</code></td>
<td>

<p>For the &quot;qpois.reg&quot; a matrix with data, the predictor variables. This can be a matrix or a 
data frame. For the &quot;qpois.regs&quot; this must be a numerical matrix, where each columns denotes 
a variable. 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20Poisson+2B20regression+2B20for+2B20count+2B20data_+3A_y">y</code></td>
<td>

<p>A numerical vector with positive discrete data. 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20Poisson+2B20regression+2B20for+2B20count+2B20data_+3A_full">full</code></td>
<td>

<p>If this is FALSE, the coefficients, the deviance and the estimated phi parameter will be 
returned only. If this is TRUE, more information is returned. 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20Poisson+2B20regression+2B20for+2B20count+2B20data_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm. This is set to <code class="reqn">10^{-9}</code> by default.
</p>
</td></tr>
<tr><td><code id="Quasi+2B20Poisson+2B20regression+2B20for+2B20count+2B20data_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)? 
</p>
</td></tr>
<tr><td><code id="Quasi+2B20Poisson+2B20regression+2B20for+2B20count+2B20data_+3A_maxiters">maxiters</code></td>
<td>

<p>The maximum number of iterations before the Newton-Raphson is terminated automatically.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We are using the Newton-Raphson, but unlike R's built-in function &quot;glm&quot; we do no checks 
and no extra calculations, or whatever. Simply the model, unless the user requests for the 
Wald tests of the coefficients.  The &quot;qpois.regs&quot; is to be used for very many univariate 
regressions. The &quot;x&quot; is a matrix in this case and the significance of each variable 
(column of the matrix) is tested. 
</p>


<h3>Value</h3>

<p>For the &quot;prop.reg&quot; a list including:
When full is FALSE 
</p>
<table>
<tr><td><code>be</code></td>
<td>

<p>The regression coefficients.
</p>
</td></tr>
<tr><td><code>devi</code></td>
<td>

<p>The deviance of the model.
</p>
</td></tr>
<tr><td><code>varb</code></td>
<td>

<p>The covariance matrix of the beta coefficients.
</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>

<p>The phi parameter, the estimate of dispersion.
</p>
</td></tr>
</table>
<p>When full is TRUE, the additional item is:
</p>
<table>
<tr><td><code>info</code></td>
<td>

<p>The regression coefficients, their standard error, their Wald test statistic and their p-value. 
</p>
</td></tr>
</table>
<p>For the &quot;prop.regs&quot; a two-column matrix with the test statistics (Wald statistic) and 
the associated p-values (or their loggarithm). 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Marios Dimitriadis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; and 
Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;.
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+prop.reg">prop.reg</a> <a href="#topic+univglms">univglms</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+poisson_only">poisson_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- rnbinom(100, 10, 0.6)
x &lt;- matrix(rnorm(100*3), ncol = 3)
mod1 &lt;- glm(y ~ x, quasipoisson)
res&lt;-summary(mod1)
res&lt;-qpois.reg(x, y, full = TRUE)
res&lt;-qpois.regs(x, y)

</code></pre>

<hr>
<h2 id='Random+20intercepts+20linear+20mixed+20models'>
Random intercepts linear mixed models
</h2><span id='topic+rint.reg'></span><span id='topic+rint.regbx'></span>

<h3>Description</h3>

<p>Random intercepts linear mixed models (for balanced data with a single identical covariate).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rint.reg(y, x, id ,tol = 1e-08, ranef = FALSE, maxiters = 100)
rint.regbx(y, x, id)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Random+2B20intercepts+2B20linear+2B20mixed+2B20models_+3A_y">y</code></td>
<td>

<p>A numerical vector with the data. The subject values.
</p>
</td></tr>
<tr><td><code id="Random+2B20intercepts+2B20linear+2B20mixed+2B20models_+3A_x">x</code></td>
<td>

<p>For the case of &quot;rint.reg&quot; this can be a vector or a numerical matrix with data. In the case of &quot;rint.regbx&quot; this is a numerical 
vector with the same length as y indicating the fixed predictor variable. Its values are the same for all levels of y. 
An example of this x is time which is the same for all subjects.
</p>
</td></tr>
<tr><td><code id="Random+2B20intercepts+2B20linear+2B20mixed+2B20models_+3A_id">id</code></td>
<td>

<p>A numerical variable with 1, 2, ... indicating the subject. 
</p>
</td></tr>
<tr><td><code id="Random+2B20intercepts+2B20linear+2B20mixed+2B20models_+3A_tol">tol</code></td>
<td>

<p>The tolerance level to terminate the generalised elast squares algorithm. 
</p>
</td></tr>
<tr><td><code id="Random+2B20intercepts+2B20linear+2B20mixed+2B20models_+3A_ranef">ranef</code></td>
<td>

<p>If you want to obtain the random effects (random intercepts) set this equal to TRUE.
</p>
</td></tr>
<tr><td><code id="Random+2B20intercepts+2B20linear+2B20mixed+2B20models_+3A_maxiters">maxiters</code></td>
<td>

<p>The max number of iterations that can take place in a regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Random intercepts linear mixed models with compound covariance structure is fitted in both functions. The &quot;rint.reg&quot; allows any numerical 
matrix, with balanced or unbalanced data. See Demidenko (2013, pg. 65-67) for more information. 
</p>
<p>The &quot;rint.regbx&quot; is a special case of a balanced random intercepts model with a compound symmetric covariance matrix and one single covariate 
which is constant for all replicates. An example, is time, which is the same for all subjects. Maximum likelihood estimation has been performed. 
In this case the mathematics exist in a closed formula (Demidenko, 2013, pg. 67-69). 
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>info</code></td>
<td>

<p>A vector with the random intercepts variance (between), the variance of the errors (within), the log-likelihood, the deviance 
(twice the log-likelihood) and the BIC. In the case of &quot;rint.reg&quot; it also includes the number of iterations required by the 
generalised least squares. 
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The estimated regression coefficients, which in the case of &quot;rint.regbx&quot; are simply two: the constant and the slope (time effect). 
</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>

<p>The random intercepts effects. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Eugene Demidenko (2013). Mixed Models: Theory and Applications with R, 2nd Edition. New Jersey: Wiley &amp; Sons (excellent book).
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rm.lines">rm.lines</a>, <a href="#topic+varcomps.mom">varcomps.mom</a>, <a href="#topic+colvarcomps.mom">colvarcomps.mom</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- rnorm(100) 
x &lt;- rnorm(10)
x &lt;- rep(x, 10)
id &lt;- rep(1:10, each = 10)
for (i in 1:20) a &lt;- rint.reg(y, x, id)

</code></pre>

<hr>
<h2 id='Random+20values+20simulation+20from+20a+20von+20Mises+20distribution'>
Random values simulation from a von Mises distribution
</h2><span id='topic+rvonmises'></span>

<h3>Description</h3>

<p>It generates random vectors following the von Mises distribution. The data can be spherical or hyper-spherical.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rvonmises(n, m, k, rads = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Random+2B20values+2B20simulation+2B20from+2B20a+2B20von+2B20Mises+2B20distribution_+3A_n">n</code></td>
<td>

<p>The sample size.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20simulation+2B20from+2B20a+2B20von+2B20Mises+2B20distribution_+3A_m">m</code></td>
<td>

<p>The mean angle expressed in radians or degrees.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20simulation+2B20from+2B20a+2B20von+2B20Mises+2B20distribution_+3A_k">k</code></td>
<td>

<p>The concentration parameter. If k is zero the sample will be generated from the uniform distribution over <code class="reqn">(0, 2\pi)</code>.
</p>
</td></tr>
<tr><td><code id="Random+2B20values+2B20simulation+2B20from+2B20a+2B20von+2B20Mises+2B20distribution_+3A_rads">rads</code></td>
<td>

<p>If the mean angle is expressed in radians, this should be TRUE and FALSE otherwise. The simulated data will be expressed in radians or degrees depending on what the mean angle is expressed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean direction is transformed to the Euclidean coordinates (i.e. unit vector) and then the fvmf function is employed. It uses a rejection smapling as suggested by Andrew Wood in 1994. I have mentioned the description of the algorithm as I found it in Dhillon and Sra in 2003. Finally, the data are transformed to radians or degrees.
</p>


<h3>Value</h3>

<p>A vector with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm85@gmail.com&gt;
</p>


<h3>References</h3>

<p>Wood, A. T. (1994). Simulation of the von Mises Fisher distribution. Communications in statistics-simulation 
and computation, 23(1): 157-164. 
</p>
<p>Dhillon, I. S., &amp; Sra, S. (2003). Modeling data using directional distributions. Technical Report TR-03-06, 
Department of Computer Sciences, The University of Texas at Austin.
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.4122&amp;rep=rep1&amp;type=pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vm.mle">vm.mle</a>, <a href="#topic+rvmf">rvmf</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rvonmises(1000, 2, 25, rads = TRUE)
res&lt;-vm.mle(x)
</code></pre>

<hr>
<h2 id='Reading+20the+20files+20of+20a+20directory'>
Reading the files of a directory
</h2><span id='topic+read.directory'></span><span id='topic+read.examples'></span>

<h3>Description</h3>

<p>Reading the files of a directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.directory(path.directory)
read.examples(path.man)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Reading+2B20the+2B20files+2B20of+2B20a+2B20directory_+3A_path.directory">path.directory</code></td>
<td>

<p>The full path to the directory. 
For example: \&quot;C:\Users\username\Documents\R\Rfast_1.8.0\R\&quot;
</p>
</td></tr>
<tr><td><code id="Reading+2B20the+2B20files+2B20of+2B20a+2B20directory_+3A_path.man">path.man</code></td>
<td>

<p>The full path to the directory with the Rd files in it. 
For example: \&quot;C:\Users\username\Documents\R\Rfast_1.8.0\man\\&quot;
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For function \&quot;read.directory\&quot;: 
Takes as an argument a full path to a directory and returns the names of the files.
</p>
<p>For function \&quot;read.examples\&quot;:
Takes as an argument a full path to the directory of the Rd files. If you don't want the program to read any file add at the top of the file the attribute &quot;%[dont read]&quot;.
</p>


<h3>Value</h3>

<p>For function \&quot;read.directory\&quot;: The names of the files.
</p>
<p>For function \&quot;read.examples\&quot;: a list with 2 fields
</p>
<table>
<tr><td><code>examples</code></td>
<td>

<p>A character vector with the examples of each Rd file.
</p>
</td></tr>
<tr><td><code>files</code></td>
<td>

<p>A character vector with the name of the file that each examples belongs.
</p>
</td></tr>
<tr><td><code>long_lines</code></td>
<td>

<p>A character vector with the name of the file that has large examples.
</p>
</td></tr>
</table>
<p>You can choose which files not to read for both R and Rd. You must add in the first line of the file in comment the &quot;attribute&quot; &quot;%[dont read]&quot;. Finally, that function wil return in the result a list of which files had this attribute.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AddToNamespace">AddToNamespace</a>, <a href="#topic+sourceR">sourceR</a>, <a href="#topic+sourceRd">sourceRd</a>, <a href="tools.html#topic+checkRd">checkRd</a>, <a href="#topic+checkExamples">checkExamples</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for example: path="C:\some_file\"
# system.time( read.directory(path) )
# system.time( list.dirs(path) )

# for example: path.man="C:\some_file\man\"
# system.time( read.examples(path.man) )
# system.time( read.examples(path.man,dont.read=c("somef_1.Rd",...,"somef_n.Rd") ) )
</code></pre>

<hr>
<h2 id='Repeated+20measures+20anova'>
Repeated measures anova
</h2><span id='topic+rm.anova'></span>

<h3>Description</h3>

<p>Repeated measures anova.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rm.anova(y, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Repeated+2B20measures+2B20anova_+3A_y">y</code></td>
<td>

<p>A matrix with the data, where each column refers to a different measurement. The rows denote the subjects.
</p>
</td></tr>
<tr><td><code id="Repeated+2B20measures+2B20anova_+3A_logged">logged</code></td>
<td>

<p>Should the p-values be returned (FALSE) or their logarithm (TRUE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Found in Davis (2002) is the usual repeated measures ANOVA. In this case,
suppose you have taken measurements on one or more variables from the same group of people. See the example below
on how to put such data.
</p>


<h3>Value</h3>

<p>A vector with the test statistic (t-test) and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Charles S. Davis (2002). Statistical methods for the analysis of repeated measures. Springer-Verlag, New York.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+rm.anovas">rm.anovas</a>, <a href="#topic+rint.reg">rint.reg</a>, <a href="#topic+varcomps.mle">varcomps.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- c(74.5,81.5,83.6,68.6,73.1,79.4,
75.5,84.6,70.6,87.3,73.0,75.0,
68.9,71.6,55.9,61.9,60.5,61.8,
57.0,61.3,54.1,59.2,56.6,58.8,
78.3,84.9,64.0,62.2,60.1,78.7,
54.0,62.8,63.0,58.0,56.0,51.5,
72.5,68.3,67.8,71.5,65.0,67.7,
80.8,89.9,83.2,83.0,85.7,79.6)
y &lt;- matrix(y, ncol = 6, byrow = TRUE)
res&lt;-rm.anova(y)
</code></pre>

<hr>
<h2 id='Rfast-package'>
A Collection of Efficient and Extremely Fast R Functions
</h2><span id='topic+Rfast-package'></span>

<h3>Description</h3>

<p>A collection of fast (utility) functions for data analysis. Column and row wise means, medians, variances, minimums, maximums, many t, F and G-square tests, many regressions (normal, logistic, Poisson), are some of the many fast functions. References: a) Tsagris M., Papadakis M. (2018). Taking R to its limits: 70+ tips. PeerJ Preprints 6:e26605v1 &lt;doi:10.7287/peerj.preprints.26605v1&gt;. b) Tsagris M. and Papadakis M. (2018). Forward regression in R: from the extreme slow to the extreme fast. Journal of Data Science, 16(4): 771&ndash;780. &lt;doi:10.6339/JDS.201810_16(4).00006&gt;. c) Chatzipantsiou C., Dimitriadis M., Papadakis M. and Tsagris M. (2020). Extremely Efficient Permutation and Bootstrap Hypothesis Tests Using Hypothesis Tests Using R. Journal of Modern Applied Statistical Methods, 18(2), eP2898. &lt;doi:10.48550/arXiv.1806.10947&gt;.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> Rfast</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.1.0 </td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-11-08</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Maintainers</h3>

<p>Manos Papadakis &lt;rfastofficial@gmail.com&gt;
</p>


<h3>Note</h3>

<p>Acknowledgments: We would like to acknowledge:
</p>

<ul>
<li><p> Professor Kurt Hornik, Doctor Uwe Ligges (and the rest of R core team) for 
their invaluable help with this R package. 
</p>
</li>
<li><p> Erich Studerus for his invaluable comments.
</p>
</li>
<li><p> Neal Fultz for his suggestions. 
</p>
</li>
<li><p> Vassilis Vasdekis for his invaluable help with the random effects models. 
</p>
</li>
<li><p> Marios Dimitriadis' work was funded by the Special Account for Research Funds of the University of Crete, Department of Computer Science. 
</p>
</li>
<li><p> Phillip Si is greatly acknowledged for his help with the Floyd-Warshal algorithm. 
</p>
</li>
<li><p> Keefe Murphy for his invaluable help with NEWS file and for his suggestions. 
</p>
</li>
<li><p> Zacharias Papadovassilakis gave us the inspiration for the memory efficient version of the k-NN algorithm. 
</p>
</li>
<li><p> Yannis Pantazis explained us how the orhtogonal matching pursuit works. 
</p>
</li>
<li><p> Achim Zeileis for his help with the quasi Poisson regression models. 
</p>
</li>
<li><p> Pedro J. Aphalo for finding a bug.
</p>
</li>
<li><p> Dimitris Kyriakis for finding a bug. 
</p>
</li>
<li><p> Cyrille Conord for finding a bug.
</p>
</li>
<li><p> Aaron Robotham for finding a bug.
</p>
</li>
<li><p> Calvin Pan from the Department of Human Genetics at UCLA found a bug in the function glm_logistic and he is greatly acknowledged for that.
</p>
</li>
<li><p> Adam Muschielok from Rodenstock GmbH found a bug in the function vmf.mle and he is greatly acknowledged for that.
</p>
</li>
<li><p> Bret Presnell for detecting and correcting a bug in the function rvmf.
</p>
</li>
<li><p> Gabriel Hoffman for spotting a mistake in the fuction dirimultinom.mle.
</p>
</li>
<li><p> Lutz von der Burchard for spotting a bug in the function bic.corfsreg.
</p>
</li></ul>



<h3>Author(s)</h3>


<ul>
<li><p> Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>
</li>
<li><p> Michail Tsagris &lt;mtsagris@uoc.gr&gt;
</p>
</li>
<li><p> Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;
</p>
</li>
<li><p> Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;
</p>
</li>
<li><p> Ioannis Tsamardinos &lt;tsamard@csd.uoc.gr&gt;
</p>
</li>
<li><p> Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;
</p>
</li>
<li><p> Giorgos Borboudakis &lt;borbudak@gmail.com&gt;
</p>
</li>
<li><p> John Burkardt &lt;jburkardt@fsu.edu&gt;
</p>
</li>
<li><p> Kleanthi Lakiotaki &lt;kliolak@gmail.com&gt;
</p>
</li>
<li><p> Changliang Zou &lt;nk.chlzou@gmail.com&gt;
</p>
</li>
<li><p> Christina Chatzipantsiou &lt;chatzipantsiou@gmail.com&gt;
</p>
</li></ul>


<hr>
<h2 id='Round+20each+20element+20of+20a+20matrix+2Fvector'>
Round each element of a matrix/vector
</h2><span id='topic+Round'></span>

<h3>Description</h3>

<p>Round each element of a matrix/vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Round(x,digit=0,na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Round+2B20each+2B20element+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_x">x</code></td>
<td>

<p>A numeric matrix/vector with data or NA. NOT integer values. 
</p>
</td></tr>
<tr><td><code id="Round+2B20each+2B20element+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_digit">digit</code></td>
<td>

<p>An integer value for 0...N-1 where N is the number of the digits. By default is 0.
</p>
</td></tr>
<tr><td><code id="Round+2B20each+2B20element+2B20of+2B20a+2B20matrix+2B2Fvector_+3A_na.rm">na.rm</code></td>
<td>

<p>TRUE or FAlSE for remove NAs if exists.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Round is a very fast C++ implementation. Especially for large data. It handles NA.
</p>


<h3>Value</h3>

<p>A vector/matrix where each element is been rounded in the given digit.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lchoose">Lchoose</a>, <a href="#topic+Log">Log</a>, <a href="#topic+Choose">Choose</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;-matrix( rnorm( 50 * 10), ncol = 10 )
a &lt;- Round(x,5)
b &lt;- round(x,5)
all.equal(a,b) #true
x &lt;-rnorm( 1000)
a &lt;- Round(x,5)
b &lt;- round(x,5)
all.equal(a,b) # true
</code></pre>

<hr>
<h2 id='Row+20-+20Wise+20matrix+2Fvector+20count+20the+20frequency+20of+20a+20value+20'>
Row - Wise matrix/vector count the frequency of a value
</h2><span id='topic+colCountValues'></span><span id='topic+rowCountValues'></span><span id='topic+count_value'></span>

<h3>Description</h3>

<p>Row - Wise matrix/vector count the frequency of a value. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_value(x, value)
colCountValues(x, values, parallel = FALSE,cores = 0)
rowCountValues(x, values, parallel = FALSE,cores = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Row+2B20-+2B20Wise+2B20matrix+2B2Fvector+2B20count+2B20the+2B20frequency+2B20of+2B20a+2B20value+2B20_+3A_x">x</code></td>
<td>

<p>A vector with the data (numeric or character) or a numeric matrix.
</p>
</td></tr>
<tr><td><code id="Row+2B20-+2B20Wise+2B20matrix+2B2Fvector+2B20count+2B20the+2B20frequency+2B20of+2B20a+2B20value+2B20_+3A_value">value</code></td>
<td>

<p>The value, numeric or character, to check its frequency in the vector &quot;x&quot;. 
</p>
</td></tr>
<tr><td><code id="Row+2B20-+2B20Wise+2B20matrix+2B2Fvector+2B20count+2B20the+2B20frequency+2B20of+2B20a+2B20value+2B20_+3A_values">values</code></td>
<td>

<p>a vector with the values to check its frequency in the matrix &quot;x&quot; by row or column.
</p>
</td></tr>
<tr><td><code id="Row+2B20-+2B20Wise+2B20matrix+2B2Fvector+2B20count+2B20the+2B20frequency+2B20of+2B20a+2B20value+2B20_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel in C++? TRUE or FALSE. Works with every other argument.
</p>
</td></tr>
<tr><td><code id="Row+2B20-+2B20Wise+2B20matrix+2B2Fvector+2B20count+2B20the+2B20frequency+2B20of+2B20a+2B20value+2B20_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible. The &quot;x&quot; and &quot;value&quot; must have the same type. The type can be numeric or character.
</p>


<h3>Value</h3>

<p>The frequency of a value/values in a vector in linear time or by row/column in a matrix.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Median">Median</a>, <a href="#topic+binary_search">binary_search</a>, <a href="#topic+Order">Order</a>, <a href="#topic+nth">nth</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
value &lt;- x[50]
count_value(x,value)
y &lt;- sample(letters,replace=TRUE)
value &lt;- "r"
count_value(y,value)
values &lt;- sample(x,100,replace=TRUE)
x &lt;- matrix(x,100,100)
res&lt;-colCountValues(x,values)
res&lt;-rowCountValues(x,values)
x&lt;-value&lt;-values&lt;-y&lt;-NULL
</code></pre>

<hr>
<h2 id='Row-wise+20minimum+20and+20maximum'>
Row-wise minimum and maximum of a matrix.
</h2><span id='topic+rowMins'></span><span id='topic+rowMaxs'></span><span id='topic+rowMinsMaxs'></span>

<h3>Description</h3>

<p>Row-wise minimum and maximum of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowMins(x, value = FALSE)
rowMaxs(x, value = FALSE)
rowMinsMaxs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Row-wise+2B20minimum+2B20and+2B20maximum_+3A_x">x</code></td>
<td>

<p>A numerical matrix with data.
</p>
</td></tr>
<tr><td><code id="Row-wise+2B20minimum+2B20and+2B20maximum_+3A_value">value</code></td>
<td>

<p>If the value is FALSE it returns the indices of the minimum/maximum, otherwise it returns the minimum and maximum values.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the relevant values.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colMins">colMins</a>, <a href="#topic+colMaxs">colMaxs</a>, <a href="#topic+nth">nth</a>, <a href="#topic+rowrange">rowrange</a> <a href="#topic+colMedians">colMedians</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colSort">colSort</a>, <a href="#topic+rowSort">rowSort</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(10 * 10), ncol = 10 )

s1 &lt;- rowMins(x)
#s2 &lt;- apply(x, 1, min)

s1 &lt;- rowMaxs(x)
#s2 &lt;- apply(x, 1, max)

#s1 &lt;- c(apply(x, 1, min),apply(x, 1, max) )
s2 &lt;- rowMinsMaxs(x)

x&lt;-s1&lt;-s2&lt;-NULL
</code></pre>

<hr>
<h2 id='Row-wise+20true+20value+20'>
Row-wise true value of a matrix
</h2><span id='topic+rowTrue'></span><span id='topic+rowFalse'></span><span id='topic+rowTrueFalse'></span>

<h3>Description</h3>

<p>Row-wise true value of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowTrue(x)
rowFalse(x)
rowTrueFalse(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Row-wise+2B20true+2B20value+2B20_+3A_x">x</code></td>
<td>

<p>A logical matrix with data.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer vector where item &quot;i&quot; is the number of the true/false values of &quot;i&quot; row.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowMins">rowMins</a>, <a href="#topic+colFalse">colFalse</a>, <a href="#topic+nth">nth</a>, <a href="#topic+rowrange">rowrange</a>, <a href="#topic+rowMedians">rowMedians</a>, <a href="#topic+rowVars">rowVars</a>, <a href="#topic+colTrue">colTrue</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(as.logical(rbinom(100*100,1,0.5)),100,100)

s1 &lt;- rowTrue(x) 

s1 &lt;- rowFalse(x)  

s1 &lt;- rowTrueFalse(x)

x&lt;-s1&lt;-NULL
</code></pre>

<hr>
<h2 id='Search+20for+20variables+20with+20zero+20range+20in+20a+20matrix'>Search for variables with zero range in a matrix
</h2><span id='topic+check_data'></span>

<h3>Description</h3>

<p>Search for variables with zero range in a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_data(x, ina = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Search+2B20for+2B20variables+2B20with+2B20zero+2B20range+2B20in+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix or a data.frame with the data, where rows denotes the observations and the columns contain the dependent variables.
</p>
</td></tr>
<tr><td><code id="Search+2B20for+2B20variables+2B20with+2B20zero+2B20range+2B20in+2B20a+2B20matrix_+3A_ina">ina</code></td>
<td>

<p>If your data are grouped, for example there is a factor or numerical variable indicating the groups of the data supply it here, otherwise leave it NULL. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function identifies the variabels with zero range, instead of a zero variance as this is faster. It will work with matrices and data.frames. 
</p>


<h3>Value</h3>

<p>A numerical vector of length zero if no zero ranged variable exists, or of length at least one with the index (or indices) of the variable(s) that need 
attention or need to be removed.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colrange">colrange</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
res&lt;-check_data(x)

## some variables have a constant value
x[, c(1,10, 50, 70)] &lt;- 1
res&lt;-check_data(x)
id &lt;- rep(1:4, each = 25 )
x[1:25, 2] &lt;- 0
res&lt;-check_data(x)  ## did not use the id variable
res&lt;-check_data(x, id)  ## see now
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Significance+20testing+20for+20the+20coefficients+20of+20Quasi+20binomial+20or+20the+20quasi+20Poisson+20regression'>
Significance testing for the coefficients of Quasi binomial or the quasi Poisson regression
</h2><span id='topic+anova_propreg'></span><span id='topic+anova_qpois.reg'></span>

<h3>Description</h3>

<p>Significance testing for the coefficients of Quasi binomial or the quasi Poisson regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anova_propreg(mod, poia = NULL)
anova_qpois.reg(mod, poia = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Significance+2B20testing+2B20for+2B20the+2B20coefficients+2B20of+2B20Quasi+2B20binomial+2B20or+2B20the+2B20quasi+2B20Poisson+2B20regression_+3A_mod">mod</code></td>
<td>

<p>An object as returned by the &quot;prop.reg&quot; or the &quot;qpois.reg&quot; function.
</p>
</td></tr>
<tr><td><code id="Significance+2B20testing+2B20for+2B20the+2B20coefficients+2B20of+2B20Quasi+2B20binomial+2B20or+2B20the+2B20quasi+2B20Poisson+2B20regression_+3A_poia">poia</code></td>
<td>

<p>If you want to test the significance of a single coefficient this must be a number. In this case, the &quot;prop.reg&quot; or the &quot;qpois.reg&quot; function contains
this information. If you want more coefficients to be testes simultaneously, e.g. for a categorical predictor, then this must 
contain the positions of the coefficients. If you want to see if all coefficients are zero, like an overall F-test, leave this NULL. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Even though the name of this function starts with anova it is not an ANOVA type significance testing, but a Wald type.  
</p>


<h3>Value</h3>

<p>A vector with three elements, the test statistic value, its associated p-value and the relevant degrees of freedom.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Papke L. E. &amp; Wooldridge J. (1996). Econometric methods for fractional response variables with 
an application to 401(K) plan participation rates. Journal of Applied Econometrics, 11(6): 619-632.
</p>
<p>McCullagh, Peter, and John A. Nelder. Generalized linear models.  CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+prop.reg">prop.reg</a>, <a href="#topic+qpois.reg">qpois.reg</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+score.glms">score.glms</a>, <a href="#topic+logistic_only">logistic_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
y &lt;- rbeta(1000, 1, 4)
x &lt;- matrix(rnorm(1000 * 3), ncol = 3)
a &lt;- prop.reg(y, x)
## all coefficients are tested
res&lt;-anova_propreg(a)  
## the first predictor variable is tested 
res&lt;-anova_propreg(a, 2)  
a  ## this information is already included in the model output
## the first and the second predictor variables are tested 
res&lt;-anova_propreg(a, 2:3)

</code></pre>

<hr>
<h2 id='Simulation+20of+20random+20values+20from+20a+20Bingham+20distribution'>
Simulating from a Bingham distribution</h2><span id='topic+rbing'></span>

<h3>Description</h3>

<p>Simulation from a Bingham distribution using the code suggested by Kent et al. (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbing(n, lam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20Bingham+2B20distribution_+3A_n">n</code></td>
<td>

<p>Sample size.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20Bingham+2B20distribution_+3A_lam">lam</code></td>
<td>

<p>Eigenvalues of the diagonal symmetric matrix of the Bingham distribution. 
See details for more information on this.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user must have calculated the eigenvalues of the diagonal symmetric matrix of the 
Bingham distribution. The function accepts the q-1 eigenvalues only. This means, that 
the user must have subtracted the lowest eigenvalue from the rest and give the non 
zero ones. The function uses rejection sampling. 
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>Kent J.T., Ganeiber A.M. and Mardia K.V. (2013).
A new method to simulate the Bingham and related distributions
in directional data analysis with applications.
http://arxiv.org/pdf/1310.8110v1.pdf
</p>
<p>C.J. Fallaize and T. Kypraios (2014).
Exact Bayesian Inference for the Bingham Distribution.
Statistics and Computing (No volum assigned yet).
http://arxiv.org/pdf/1401.2894v1.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rvmf">rvmf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rbing( 100, c(1, 0.6, 0.1) )
x
</code></pre>

<hr>
<h2 id='Simulation+20of+20random+20values+20from+20a+20Bingham+20distribution+20with+20any+20symmetric+20matrix'>
Simulation of random values from a Bingham distribution with any symmetric matrix
</h2><span id='topic+rbingham'></span>

<h3>Description</h3>

<p>Simulation of random values from a Bingham distribution with any symmetric matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbingham(n, A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20Bingham+2B20distribution+2B20with+2B20any+2B20symmetric+2B20matrix_+3A_n">n</code></td>
<td>

<p>Sample size.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20Bingham+2B20distribution+2B20with+2B20any+2B20symmetric+2B20matrix_+3A_a">A</code></td>
<td>

<p>A symmetric matrix. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The eigenvalues of the q x q symmetric matrix A are calculated and the smallest of 
them is subtracted from the rest. The q - 1 non zero eiqenvalues are then passed to 
<code><a href="#topic+rbing">rbing</a></code>. The generated data are then right multiplied by <code class="reqn">V^T</code>, where
V is the matrix of eigenvectors of the matrix A.
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and 
Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>Kent J.T., Ganeiber A.M. and Mardia K.V. (2013).
A new method to simulate the Bingham and related distributions
in directional data analysis with applications.
http://arxiv.org/pdf/1310.8110v1.pdf
</p>
<p>C.J. Fallaize and T. Kypraios (2014).
Exact Bayesian Inference for the Bingham Distribution.
Statistics and Computing (No volum assigned yet).
http://arxiv.org/pdf/1401.2894v1.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rvmf">rvmf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- cov( iris[, 1:4] )
x &lt;- rbingham(100, A)
x
</code></pre>

<hr>
<h2 id='Simulation+20of+20random+20values+20from+20a+20normal+20distribution'>
Simulation of random values from a normal distribution
</h2><span id='topic+Rnorm'></span>

<h3>Description</h3>

<p>Simulation of random values from a normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rnorm(n, m = 0, s = 1, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20normal+2B20distribution_+3A_n">n</code></td>
<td>

<p>The sample size. 
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20normal+2B20distribution_+3A_m">m</code></td>
<td>

<p>The mean, set to 0 by default.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20normal+2B20distribution_+3A_s">s</code></td>
<td>

<p>The standard devation, set to 1 by default.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20normal+2B20distribution_+3A_seed">seed</code></td>
<td>

<p>If you want the same to be generated again use a seed for the generator, an integer number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By using the Ziggurat method of generating standard normal variates, this function is really fast when you 
want to generate large vectors. For less than 2,000 this might make no difference when compared with R's 
&quot;rnorm&quot;, but for 10,000 this will be 6-7 times faster.
</p>


<h3>Value</h3>

<p>A vector with n values. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+matrnorm">matrnorm</a>, <a href="#topic+rvonmises">rvonmises</a>, <a href="#topic+rvmf">rvmf</a>, <a href="#topic+rmvnorm">rmvnorm</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Rnorm(500)
</code></pre>

<hr>
<h2 id='Simulation+20of+20random+20values+20from+20a+20von+20Mises-Fisher+20distribution'>
Random values simulation from a von Mises-Fisher distribution
</h2><span id='topic+rvmf'></span>

<h3>Description</h3>

<p>It generates random vectors following the von Mises-Fisher distribution. The data can be spherical or hyper-spherical.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rvmf(n, mu, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20von+2B20Mises-Fisher+2B20distribution_+3A_n">n</code></td>
<td>

<p>The sample size.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20von+2B20Mises-Fisher+2B20distribution_+3A_mu">mu</code></td>
<td>

<p>The mean direction, a unit vector.
</p>
</td></tr>
<tr><td><code id="Simulation+2B20of+2B20random+2B20values+2B20from+2B20a+2B20von+2B20Mises-Fisher+2B20distribution_+3A_k">k</code></td>
<td>

<p>The concentration parameter. If k = 0, random values from the spherical uniform will be drwan. 
Values from a multivariate normal distribution with zero mean vector and the identity matrix as 
the covariance matrix. Then each vector becomes a unit vector.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It uses a rejection smapling as suggested by Andrew Wood (1994). 
</p>


<h3>Value</h3>

<p>A matrix with the simulated data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm85@gmail.com&gt;
</p>


<h3>References</h3>

<p>Wood A. T. A. (1994). Simulation of the von Mises Fisher distribution. Communications in statistics-simulation 
and computation, 23(1): 157&ndash;164.
</p>
<p>Dhillon I. S. &amp; Sra S. (2003). Modeling data using directional distributions. Technical Report TR-03-06, 
Department of Computer Sciences, The University of Texas at Austin.
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.4122&amp;rep=rep1&amp;type=pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vmf.mle">vmf.mle</a>, <a href="#topic+rvonmises">rvonmises</a>, <a href="#topic+iag.mle">iag.mle</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- rnorm(4)
m &lt;- m/sqrt(sum(m^2))
x &lt;- rvmf(1000, m, 25)
m
res&lt;-vmf.mle(x)
</code></pre>

<hr>
<h2 id='Skeleton+20of+20the+20PC+20algorithm'>
The skeleton of a Bayesian network produced by the PC algorithm
</h2><span id='topic+pc.skel'></span>

<h3>Description</h3>

<p>The skeleton of a Bayesian network produced by the PC algorithm. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pc.skel(dataset, method = "pearson", alpha = 0.01, R = 1, stat = NULL, ini.pvalue = NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Skeleton+2B20of+2B20the+2B20PC+2B20algorithm_+3A_dataset">dataset</code></td>
<td>

<p>A numerical matrix with the variables. If you have a data.frame (i.e. categorical data) turn them into a matrix
using <code><a href="#topic+data.frame.to_matrix">data.frame.to_matrix</a></code>. Note, that for the categorical case data, the numbers must start from 0.   
No missing data are allowed.
</p>
</td></tr>
<tr><td><code id="Skeleton+2B20of+2B20the+2B20PC+2B20algorithm_+3A_method">method</code></td>
<td>

<p>If you have continuous data, you can choose either &quot;pearson&quot; or &quot;spearman&quot;. If you have categorical data though, 
this must be &quot;cat&quot;. In this case, make sure the minimum value of each variable is zero. The <code><a href="#topic+g2Test">g2Test</a></code> 
and the relevant functions work that way.  
</p>
</td></tr>
<tr><td><code id="Skeleton+2B20of+2B20the+2B20PC+2B20algorithm_+3A_alpha">alpha</code></td>
<td>

<p>The significance level (suitable values in (0, 1)) for assessing the p-values. Default (preferred) value is 0.01. 
</p>
</td></tr>
<tr><td><code id="Skeleton+2B20of+2B20the+2B20PC+2B20algorithm_+3A_r">R</code></td>
<td>

<p>The number of permutations to be conducted. The p-values are assessed via permutations. Use the default value
if you want no permutation based assessment.
</p>
</td></tr>
<tr><td><code id="Skeleton+2B20of+2B20the+2B20PC+2B20algorithm_+3A_stat">stat</code></td>
<td>

<p>If the initial test statistics (univariate associations) are available, pass them through this parameter. 
</p>
</td></tr>
<tr><td><code id="Skeleton+2B20of+2B20the+2B20PC+2B20algorithm_+3A_ini.pvalue">ini.pvalue</code></td>
<td>

<p>if the initial p-values of the univariate associations are available, pass them through this parameter. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PC algorithm as proposed by Spirtes et al. (2000) is implemented. The variables must be either continuous or 
categorical, only. The skeleton of the PC algorithm is order independent, since we are using the third heuristic 
(Spirte et al., 2000, pg. 90). At every stage of the algorithm use the pairs which are least statistically associated.
The conditioning set consists of variables which are most statistically associated with each other of the pair of 
variables. 
</p>
<p>For example, for the pair (X, Y) there can be two conditioning sets for example (Z1, Z2) and (W1, W2). All p-values 
and test statistics and degrees of freedom have been computed at the first step of the algorithm. Take the p-values 
between (Z1, Z2) and (X, Y) and between (Z1, Z2) and (X, Y). The conditioning set with the minimum p-value is used 
first. If the minimum p-values are the same, use the second lowest p-value. If the unlikely, but not impossible, 
event of all p-values being the same, the test statistic divided by the degrees of freedom is used as a means of 
choosing which conditioning set is to be used first. 
</p>
<p>If two or more p-values are below the machine epsilon (.Machine$double.eps which is equal to 2.220446e-16), all of 
them are set to 0. To make the comparison or the ordering feasible we use the logarithm of p-value. Hence, 
the logarithm of the p-values is always calculated and used.
</p>
<p>In the case of the <code class="reqn">G^2</code> test of independence (for categorical data) with no permutations, we have incorporated 
a rule of thumb. If the number of samples is at least 5 times the number of the parameters to be estimated, the test 
is performed, otherwise, independence is not rejected according to Tsamardinos et al. (2006). We have modified it so
that it calculates the p-value using permutations.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>stat</code></td>
<td>

<p>The test statistics of the univariate associations. 
</p>
</td></tr>
<tr><td><code>ini.pvalue</code></td>
<td>

<p>The initial p-values univariate associations.
</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>

<p>The logarithm of the p-values of the univariate associations. 
</p>
</td></tr>
<tr><td><code>runtime</code></td>
<td>

<p>The amount of time it took to run the algorithm.
</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>

<p>The maximum value of k, the maximum cardinality of the conditioning set at which the algorithm stopped.
</p>
</td></tr>
<tr><td><code>n.tests</code></td>
<td>

<p>The number of tests conducted during each k.
</p>
</td></tr>
<tr><td><code>G</code></td>
<td>

<p>The adjancency matrix. A value of 1 in G[i, j] appears in G[j, i] also, indicating that i and j have an edge between them.
</p>
</td></tr>
<tr><td><code>sepset</code></td>
<td>

<p>A list with the separating sets for every value of k.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marios Dimitriadis.
</p>
<p>R implementation and documentation: Marios Dimitriadis &lt;kmdimitriadis@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Spirtes P.,  Glymour C. and Scheines R. (2001). Causation, Prediction, and Search. The MIT Press, Cambridge, MA, 
USA, 3nd edition.
</p>
<p>Tsamardinos I., Borboudakis G. (2010) Permutation Testing Improves Bayesian Network Learning. In Machine Learning 
and Knowledge Discovery in Databases. ECML PKDD 2010. 322-337.
</p>
<p>Tsamardinos I., Brown E.L. and Aliferis F.C. (2006). The max-min hill-climbing Bayesian network 
structure learning algorithm. Machine learning 65(1):31-78.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+g2Test">g2Test</a>, <a href="#topic+g2Test_univariate">g2Test_univariate</a>, <a href="#topic+cora">cora</a>, <a href="#topic+correls">correls</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simulate a dataset with continuous data
dataset &lt;- matrix(rnorm(100 * 50, 1, 100), nrow = 100) 
a &lt;- pc.skel(dataset, method = "pearson", alpha = 0.05) 
</code></pre>

<hr>
<h2 id='Skewness+20and+20kurtosis+20coefficients'>
Skewness and kurtosis coefficients
</h2><span id='topic+skew'></span><span id='topic+kurt'></span>

<h3>Description</h3>

<p>Skewness and kurtosis coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skew(x, pvalue = FALSE)

kurt(x, pvalue = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Skewness+2B20and+2B20kurtosis+2B20coefficients_+3A_x">x</code></td>
<td>

<p>A numerical vector with data.
</p>
</td></tr>
<tr><td><code id="Skewness+2B20and+2B20kurtosis+2B20coefficients_+3A_pvalue">pvalue</code></td>
<td>

<p>If you want a hypothesis test that the skewness or kurtosis are significant set this to TRUE. This checks
whether the skewness is significantly different from 0 and whether the kurtosis is significantly different from
3.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample skewness and kurtosis coefficient are calculated. For the kurtosis we do not subtract 3. 
</p>


<h3>Value</h3>

<p>If &quot;pvalue&quot; is FALSE (default value) the skewness or kurtosis coefficients are returned. Otherwise, 
the p-value of the significance of the coefficient is returned.
</p>


<h3>Author(s)</h3>

<p>Klio Lakiotaki
</p>
<p>R implementation and documentation: Klio Lakiotaki &lt;kliolak@gmail.com&gt;.
</p>


<h3>References</h3>

<p>https://en.wikipedia.org/wiki/Skewness
</p>
<p>https://en.wikipedia.org/wiki/Kurtosis
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colskewness">colskewness</a>, <a href="#topic+skew.test2">skew.test2</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgamma(500,1, 4)
res&lt;-skew(x)
res&lt;-kurt(x, TRUE)
</code></pre>

<hr>
<h2 id='Some+20summary+20statistics+20of+20a+20vector+20for+20each+20level+20of+20a+20grouping+20variable'>
Some summary statistics of a vector for each level of a grouping variable. 
</h2><span id='topic+group'></span><span id='topic+group.sum'></span>

<h3>Description</h3>

<p>Some summary statistics of a vector for each level of a grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>group(x,ina,method="sum",ina.min=NULL,ina.max = NULL,
	ina.length.unique=NULL,mad.method="median")
group.sum(x, ina,ina.max = NULL,ina.min = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Some+2B20summary+2B20statistics+2B20of+2B20a+2B20vector+2B20for+2B20each+2B20level+2B20of+2B20a+2B20grouping+2B20variable_+3A_x">x</code></td>
<td>

<p>A numerical vector with data.
</p>
</td></tr>
<tr><td><code id="Some+2B20summary+2B20statistics+2B20of+2B20a+2B20vector+2B20for+2B20each+2B20level+2B20of+2B20a+2B20grouping+2B20variable_+3A_ina">ina</code></td>
<td>

<p>A numerical vector with numbers. Note that zero and negative values are not allowed as this can cause R to run forever or crash.
</p>
</td></tr>
<tr><td><code id="Some+2B20summary+2B20statistics+2B20of+2B20a+2B20vector+2B20for+2B20each+2B20level+2B20of+2B20a+2B20grouping+2B20variable_+3A_ina.length.unique">ina.length.unique</code></td>
<td>

<p>Length of the unique numerical values of ina argument.
</p>
</td></tr>
<tr><td><code id="Some+2B20summary+2B20statistics+2B20of+2B20a+2B20vector+2B20for+2B20each+2B20level+2B20of+2B20a+2B20grouping+2B20variable_+3A_method">method</code></td>
<td>

<p>A character vector with values &quot;sum&quot;, &quot;var&quot;, &quot;all&quot;, &quot;any&quot;, &quot;mad&quot;, &quot;mean&quot;, &quot;med&quot;, &quot;min&quot;, &quot;max&quot;, &quot;min.max&quot;.
</p>
</td></tr>
<tr><td><code id="Some+2B20summary+2B20statistics+2B20of+2B20a+2B20vector+2B20for+2B20each+2B20level+2B20of+2B20a+2B20grouping+2B20variable_+3A_ina.max">ina.max</code></td>
<td>

<p>Maximum number for vector ina. 
</p>
</td></tr>
<tr><td><code id="Some+2B20summary+2B20statistics+2B20of+2B20a+2B20vector+2B20for+2B20each+2B20level+2B20of+2B20a+2B20grouping+2B20variable_+3A_ina.min">ina.min</code></td>
<td>

<p>Minimum number for vector ina. 
</p>
</td></tr>
<tr><td><code id="Some+2B20summary+2B20statistics+2B20of+2B20a+2B20vector+2B20for+2B20each+2B20level+2B20of+2B20a+2B20grouping+2B20variable_+3A_mad.method">mad.method</code></td>
<td>

<p>A character vector with values &quot;median&quot;, for median absolute deviation or &quot;mean&quot;, for mean absolute deviation. This works only with method=&quot;mad&quot;. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This command works only for vectors. Median absolute deviation, mean, median, minimum, maximum are some of the options offered.
</p>


<h3>Value</h3>

<p>A vector with the variance, or standard deviation, or mean, or minimum, or maximum, or median, or minimum-maximum of x for each distinct value of ina. 
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Michail Tsagris
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt; and Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rgamma(100,1, 4)
ina &lt;- sample(1:5, 100, TRUE)
res&lt;-group(x, ina,method="var")

</code></pre>

<hr>
<h2 id='Sort+20-+20Integer+20Sort+20-+20Sort+20a+20vector+20coresponding+20to+20another'>
Sort - Integer Sort - Sort a vector coresponding to another 
</h2><span id='topic+Sort'></span><span id='topic+Sort.int'></span><span id='topic+sort_cor_vectors'></span>

<h3>Description</h3>

<p>Fast sorting a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sort(x,descending=FALSE,partial=NULL,stable=FALSE,na.last=NULL,parallel = FALSE)
Sort.int(x)
sort_cor_vectors(x, base, stable = FALSE, descending = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sort+2B20-+2B20Integer+2B20Sort+2B20-+2B20Sort+2B20a+2B20vector+2B20coresponding+2B20to+2B20another_+3A_x">x</code></td>
<td>

<p>A numerical/integer/character vector with data.
</p>
</td></tr>
<tr><td><code id="Sort+2B20-+2B20Integer+2B20Sort+2B20-+2B20Sort+2B20a+2B20vector+2B20coresponding+2B20to+2B20another_+3A_base">base</code></td>
<td>

<p>A numerical/character vector to help sorting the x.
</p>
</td></tr>
<tr><td><code id="Sort+2B20-+2B20Integer+2B20Sort+2B20-+2B20Sort+2B20a+2B20vector+2B20coresponding+2B20to+2B20another_+3A_descending">descending</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for sorting the vector in descending order. By default sorts the vector in ascending.
</p>
</td></tr>
<tr><td><code id="Sort+2B20-+2B20Integer+2B20Sort+2B20-+2B20Sort+2B20a+2B20vector+2B20coresponding+2B20to+2B20another_+3A_partial">partial</code></td>
<td>

<p>This argument has two usages. The first is an index number for sorting partial the vector.
The second is a vector with 2 values, start and end c(start,end). Gives you a vector where the elements between 
start and end will be sorted only. Not character vector.
</p>
</td></tr>
<tr><td><code id="Sort+2B20-+2B20Integer+2B20Sort+2B20-+2B20Sort+2B20a+2B20vector+2B20coresponding+2B20to+2B20another_+3A_stable">stable</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for choosing a stable sort algorithm. Stable means that discriminates on the same elements. Not character vector.
</p>
</td></tr>
<tr><td><code id="Sort+2B20-+2B20Integer+2B20Sort+2B20-+2B20Sort+2B20a+2B20vector+2B20coresponding+2B20to+2B20another_+3A_na.last">na.last</code></td>
<td>

<p>Accept 4 values. TRUE, FALSE, NA, NULL.
</p>
<p>TRUE/FALSE: for put NAs last or first.
</p>
<p>NA:  for remove NAs completely from vector.
</p>
<p>NULL: by default. Leave it like that if there is no NA values.
</p>
</td></tr>
<tr><td><code id="Sort+2B20-+2B20Integer+2B20Sort+2B20-+2B20Sort+2B20a+2B20vector+2B20coresponding+2B20to+2B20another_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel, in C++? TRUE or FALSE. (Supported on Windows and most of the unix)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the sorting algorithm from C++. The implementation is very fast and highly optimised. 
Especially for large data.
</p>


<h3>Value</h3>

<p>Sort and Sort.int: The sorted vector.
</p>
<p>sort_cor_vectors: The first argument but sorted acording to the second.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nth">nth</a>, <a href="#topic+colnth">colnth</a>, <a href="#topic+rownth">rownth</a>,<a href="#topic+sort_unique">sort_unique</a>, <a href="#topic+Round">Round</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(1000)
s1 &lt;- Sort(x)
s2 &lt;- sort(x)
all.equal(s1,s2) #true  but not if many duplicates.

s1 &lt;- Sort(x,partial=100)
s2 &lt;- sort(x,partial=100)
all.equal(s1,s2) #true


s1 &lt;- Sort(x,stable=TRUE)
s2 &lt;- sort(x)
all.equal(s1,s2) #true

x &lt;- as.character(x)
s1 &lt;- Sort(x)
s2 &lt;- sort(x)
all.equal(s1,s2) #true

y &lt;- runif(1000)
b &lt;- sort_cor_vectors(x,y)

x&lt;-rpois(100,100)
all.equal(Sort.int(x),sort.int(x))

x&lt;-y&lt;-y&lt;-s1&lt;-s2&lt;-NULL
</code></pre>

<hr>
<h2 id='Sorting+20of+20the+20columns-rows+20of+20a+20matrix'>
Sorting of the columns-rows of a matrix 
</h2><span id='topic+colSort'></span><span id='topic+rowSort'></span><span id='topic+sort_mat'></span>

<h3>Description</h3>

<p>Fast sorting of the columns-rows of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colSort(x, descending = FALSE, stable = FALSE, parallel=FALSE, cores = 0)
rowSort(x, descending = FALSE, stable = FALSE, parallel=FALSE, cores = 0)
sort_mat(x,by.row=FALSE,descending=FALSE,stable=FALSE,parallel=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sorting+2B20of+2B20the+2B20columns-rows+2B20of+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A numerical matrix or data.frame with data.
</p>
</td></tr>
<tr><td><code id="Sorting+2B20of+2B20the+2B20columns-rows+2B20of+2B20a+2B20matrix_+3A_descending">descending</code></td>
<td>

<p>If you want the sorting in descending order, set this to TRUE.
</p>
</td></tr>
<tr><td><code id="Sorting+2B20of+2B20the+2B20columns-rows+2B20of+2B20a+2B20matrix_+3A_stable">stable</code></td>
<td>

<p>If you the stable version, so that the results are the same as R's (in the case of ties) set this to TRUE.
If this is TRUE, the algorithm is a bit slower.
</p>
</td></tr>
<tr><td><code id="Sorting+2B20of+2B20the+2B20columns-rows+2B20of+2B20a+2B20matrix_+3A_parallel">parallel</code></td>
<td>

<p>Do you want to do it in parallel in C++? TRUE or FALSE. Works with every other argument.
</p>
</td></tr>
<tr><td><code id="Sorting+2B20of+2B20the+2B20columns-rows+2B20of+2B20a+2B20matrix_+3A_by.row">by.row</code></td>
<td>

<p>TRUE or FALSE for applying sort in rows or column.
</p>
</td></tr>
<tr><td><code id="Sorting+2B20of+2B20the+2B20columns-rows+2B20of+2B20a+2B20matrix_+3A_cores">cores</code></td>
<td>

<p>Number of cores to use for parallelism. Valid only when argument parallel is set to TRUE. 
Default value is 0 and it means the maximum supported cores.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The matrix with its columns-rows (or rows) independently sorted.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nth">nth</a>, <a href="#topic+colMaxs">colMaxs</a>, <a href="#topic+colMins">colMins</a>, <a href="#topic+colrange">colrange</a>, <a href="#topic+sort_cor_vectors">sort_cor_vectors</a>, 
<a href="#topic+sort_unique">sort_unique</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 200), ncol = 200 )
s1 &lt;- colSort(x)
#s2 &lt;- apply(x, 2, sort)
#all.equal(as.vector(s1), as.vector(s2))

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Source+20many+20R+20files'>
Source many R files
</h2><span id='topic+sourceR'></span><span id='topic+sourceRd'></span>

<h3>Description</h3>

<p>Source many R/Rd files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sourceR(path,local=FALSE,encode = "UTF-8",print.errors=FALSE)
sourceRd(path,print.errors=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Source+2B20many+2B20R+2B20files_+3A_path">path</code></td>
<td>

<p>An full path to the directory where R file are.
</p>
</td></tr>
<tr><td><code id="Source+2B20many+2B20R+2B20files_+3A_local">local</code></td>
<td>

<p>TRUE, FALSE or an environment, determining where the parsed expressions are evaluated. FALSE (the default) corresponds to the user's workspace (the global environment) and TRUE to the environment from which source is called.
</p>
</td></tr>
<tr><td><code id="Source+2B20many+2B20R+2B20files_+3A_encode">encode</code></td>
<td>

<p>Character vector. The encoding(s) to be assumed when file is a character string: see file. A possible value is &quot;unknown&quot; when the encoding is guessed: see the &quot;Encodings&quot; section.
</p>
</td></tr>
<tr><td><code id="Source+2B20many+2B20R+2B20files_+3A_print.errors">print.errors</code></td>
<td>

<p>A boolean value (TRUE/FALSE) for printing the errors, if exists, for every file.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads many R files and source them.
</p>


<h3>Value</h3>

<p>Returns the files that had produced errors during source.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.directory">read.directory</a>, <a href="#topic+AddToNamespace">AddToNamespace</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for example: path="C:\some_file\R\" where is R files are
# system.time( a&lt;-sourceR(path) )
# for example: path="C:\some_file\man\" where is Rd files are
# system.time( a&lt;-sourceRd(path) )
</code></pre>

<hr>
<h2 id='Spatial+20median+20for+20Euclidean+20data'>
Spatial median for Euclidean data
</h2><span id='topic+spat.med'></span>

<h3>Description</h3>

<p>Spatial median for Euclidean data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spat.med(x, tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Spatial+2B20median+2B20for+2B20Euclidean+2B20data_+3A_x">x</code></td>
<td>

<p>A matrix with Euclidean data, continuous variables.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20median+2B20for+2B20Euclidean+2B20data_+3A_tol">tol</code></td>
<td>

<p>A tolerance level to terminate the process. This is set to 1e-09 by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The spatial median, using a fixed point iterative algorithm, for Euclidean data is calculated. It is a robust location estimate.
</p>


<h3>Value</h3>

<p>A vector with the spatial median.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis and Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>Jyrki Mottonen, Klaus Nordhausen and Hannu Oja (2010). Asymptotic theory of the spatial median.
In Nonparametrics and Robustness in Modern Statistical Inference and Time Series Analysis:
A Festschrift in honor of Professor Jana Jureckova.
</p>
<p>T. Karkkaminen and S. Ayramo (2005). On computation of spatial median for robust data mining.
Evolutionary and Deterministic Methods for Design, Optimization and Control with Applications to
Industrial and Societal Problems, EUROGEN 2005, R. Schilling, W.Haase, J. Periaux, H. Baier, G. Bugeda (Eds)
FLM, Munich. http://users.jyu.fi/~samiayr/pdf/ayramo_eurogen05.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colMedians">colMedians</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res&lt;-spat.med( as.matrix( iris[, 1:4] ) )
res&lt;-colMeans( as.matrix(iris[, 1:4]) )
res&lt;-colMedians( as.matrix(iris[, 1:4]) )
</code></pre>

<hr>
<h2 id='Spatial+20median+20regression'>
Spatial median regression
</h2><span id='topic+spatmed.reg'></span>

<h3>Description</h3>

<p>Spatial median regression with Euclidean data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spatmed.reg(y, x, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_y">y</code></td>
<td>

<p>A matrix with the response variable. 
</p>
</td></tr>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_x">x</code></td>
<td>

<p>The predictor variable(s), they have to be continuous.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20median+2B20regression_+3A_tol">tol</code></td>
<td>

<p>The threshold upon which to stop the iterations of the Newton-Rapshon algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The objective function is the minimization of the sum of the absolute residuals. 
It is the multivariate generalisation of the median regression.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The number of iterations that were required.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The beta coefficients.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Biman Chakraborty (2003) On multivariate quantile regression. Journal of Statistical 
Planning and Inference http://www.stat.nus.edu.sg/export/sites/dsap/research/documents/tr01_2000.pdf
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+spat.med">spat.med</a>, <a href="#topic+sscov">sscov</a>, <a href="#topic+lmfit">lmfit</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- as.matrix(iris[, 3:4])
y &lt;- as.matrix(iris[, 1:2])
mod1 &lt;- spatmed.reg(y, x)

</code></pre>

<hr>
<h2 id='Spatial+20sign+20covariance+20matrix'>
Spatial sign covariance matrix
</h2><span id='topic+sscov'></span>

<h3>Description</h3>

<p>Spatial sign covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sscov(x, me = NULL, tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Spatial+2B20sign+2B20covariance+2B20matrix_+3A_x">x</code></td>
<td>

<p>A matrix with continuous data.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20sign+2B20covariance+2B20matrix_+3A_me">me</code></td>
<td>

<p>If you have already computed the spatial median plug it in here.
</p>
</td></tr>
<tr><td><code id="Spatial+2B20sign+2B20covariance+2B20matrix_+3A_tol">tol</code></td>
<td>

<p>A tolerance level to terminate the process of finding the spatial median. This is set to 1e-09 by default.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The spatial median is at first computed (if not supplied) and then the covariance matrix. 
</p>


<h3>Value</h3>

<p>The spatial sign covariance matrix.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;.
</p>


<h3>References</h3>

<p>Durre A, Vogel D. and D.E. Tyler D.E.(2014). The spatial sign covariance matrix with unknown location.  Journal of Multivariate Analysis, 130: 107-117.
http://arxiv.org/pdf/1307.5706v2.pdf
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spat.med">spat.med</a>, <a href="#topic+spatmed.reg">spatmed.reg</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res&lt;-sscov( as.matrix(iris[, 1:4]) )
</code></pre>

<hr>
<h2 id='Spherical+20and+20hyperspherical+20median'>
Fast calculation of the spherical and hyperspherical median
</h2><span id='topic+mediandir'></span>

<h3>Description</h3>

<p>It calculates, very fast, the (hyper-)spherical median of a sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mediandir(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Spherical+2B20and+2B20hyperspherical+2B20median_+3A_x">x</code></td>
<td>

<p>The data, a numeric matrix with unit vectors.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;mediandir&quot; employes a fixed poit iterative algorithm stemming from the first derivative (Cabrera and Watson, 1990)
to find the median direction as described in Fisher (1985) and Fisher, Lewis and Embleton (1987).
</p>


<h3>Value</h3>

<p>The median direction.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Fisher N. I. (1985). Spherical medians. Journal of the Royal Statistical Society. Series B, 47(2): 342-348.
</p>
<p>Fisher N. I., Lewis T. and Embleton B. J. (1987). Statistical analysis of spherical data. Cambridge university press.
</p>
<p>Cabrera J. and Watson G. S. (1990). On a spherical median related distribution. Communications in Statistics-Theory and Methods, 19(6): 1973-1986.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+vmf.mle">vmf.mle</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- rnorm(3)
m &lt;- m / sqrt( sum(m^2) )
x &lt;- rvmf(100, m, 10)
res&lt;-mediandir(x)
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Standardisation'>
Standardisation
</h2><span id='topic+standardise'></span>

<h3>Description</h3>

<p>Standardisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardise(x, center = TRUE, scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Standardisation_+3A_x">x</code></td>
<td>

<p>A matrix with data. It has to be matrix, if it is data.frame for example the function does not turn it into a matrix.
</p>
</td></tr>
<tr><td><code id="Standardisation_+3A_center">center</code></td>
<td>

<p>Should the data be centred as well? TRUE or FALSE.
</p>
</td></tr>
<tr><td><code id="Standardisation_+3A_scale">scale</code></td>
<td>

<p>Should the columns have unit variance, yes (TRUE) or no (FALSE)?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to R's built in functions &quot;scale&quot; there is the option for centering or scaling only or both (default).
</p>


<h3>Value</h3>

<p>A matrix with the standardised data.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+colMads">colMads</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrnorm( 100, 100 )
a1 &lt;- scale(x)[1:100, ] 
a2 &lt;- standardise(x) 
all.equal(as.vector(a1), as.vector(a2))
x &lt;- NULL
</code></pre>

<hr>
<h2 id='Sub-matrix'>Sub-matrix
</h2><span id='topic+submatrix'></span>

<h3>Description</h3>

<p>Sub-matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>submatrix(x,rowStart=1,rowEnd=1,colStart=1,colEnd=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sub-matrix_+3A_x">x</code></td>
<td>

<p>A Matrix, List, Dataframe or Vector.
</p>
</td></tr>
<tr><td><code id="Sub-matrix_+3A_rowstart">rowStart</code></td>
<td>

<p>Start of the row.
</p>
</td></tr>
<tr><td><code id="Sub-matrix_+3A_rowend">rowEnd</code></td>
<td>

<p>End of the row.
</p>
</td></tr>
<tr><td><code id="Sub-matrix_+3A_colstart">colStart</code></td>
<td>

<p>Start of the col.
</p>
</td></tr>
<tr><td><code id="Sub-matrix_+3A_colend">colEnd</code></td>
<td>

<p>End of the col.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sub matrix like R's, x[startrow:endrow,startcol:endcol]. Fast especially for big sub matrices.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+Match">Match</a>, <a href="#topic+mvbetas">mvbetas</a>, <a href="#topic+correls">correls</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+colsums">colsums</a>, <a href="#topic+colVars">colVars</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100 )
res&lt;-submatrix(x,1,50,1,25) # x[1:50,1:25]

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Table+20Creation+20-+20Frequency+20of+20each+20value'>
Table Creation - Frequency of each value
</h2><span id='topic+Table'></span><span id='topic+Table.sign'></span>

<h3>Description</h3>

<p>Table Creation - Frequency of each value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Table(x,y=NULL,names = TRUE,useNA = FALSE,rm.zeros = FALSE)
Table.sign(x,names = TRUE,useNA = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Table+2B20Creation+2B20-+2B20Frequency+2B20of+2B20each+2B20value_+3A_x">x</code></td>
<td>

<p>A vector with numeric/character data.
</p>
</td></tr>
<tr><td><code id="Table+2B20Creation+2B20-+2B20Frequency+2B20of+2B20each+2B20value_+3A_names">names</code></td>
<td>

<p>A logical value (TRUE/FALSE) for add names.
</p>
</td></tr>
<tr><td><code id="Table+2B20Creation+2B20-+2B20Frequency+2B20of+2B20each+2B20value_+3A_y">y</code></td>
<td>

<p>A vector with numeric/character data. Doesn't work with &quot;useNA&quot;.
</p>
</td></tr>
<tr><td><code id="Table+2B20Creation+2B20-+2B20Frequency+2B20of+2B20each+2B20value_+3A_rm.zeros">rm.zeros</code></td>
<td>

<p>A logical value for removing zero columns/rows. Only for integer vectors for now.
</p>
</td></tr>
<tr><td><code id="Table+2B20Creation+2B20-+2B20Frequency+2B20of+2B20each+2B20value_+3A_usena">useNA</code></td>
<td>

<p>Table: 
Integer/logical value:
</p>
<p>FALSE: not NA values in vector.
TRUE: count NAs and add the value in the last position of the returned vector.
any other integer except 0,1: for just removing NAs.
</p>
<p>Table.sign:
Logical value, TRUE, for count NAs. Otherwise FALSE.
</p>
<p>Doesn't work character data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Like R's &quot;table&quot;:
</p>
<p>for giving one argument,&quot;x&quot;:
If &quot;names&quot; is FALSE then, if &quot;useNA&quot; is TRUE  then the NAs will be count, if is  FALSE it means there are no NAs and for any other integer value the NAs will be ignored.
</p>
<p>for giving two arguments,&quot;x&quot;,&quot;y&quot;:
If &quot;names&quot; is FALSE then, creates the contigency table, otherwise sets the col-row names with discrete values. If &quot;rm.zeros&quot; is FALSE then it won't remove the zero columns/rows from the result but it will work only for positive integers for now. For this if &quot;names&quot; is TRUE then the col-row names will be the seq(min(),max()) for &quot;x&quot;,&quot;y&quot;. In future updates it will be changed. 
</p>
<p>for both algorithms: 
You can't use &quot;useNA&quot; with &quot;names&quot; for now. 
It is much faster to get the result without names (names = FALSE) but all the algorithms are more efficient than R's. 
</p>
<p>Like R's &quot;table(sign())&quot; but more efficient. Count the frequencies of positives, negatives, zeros and NAs values. If argument &quot;names&quot; is FALSE then the returned vector doesn't have names. Otherwise &quot;-1,0,+1,NA&quot;.
If &quot;useNA&quot; is TRUE then the NAs will be count, otherwise not. You can use &quot;useNA&quot; with &quot;names&quot;.
</p>


<h3>Value</h3>

<p>Table: 
</p>
<p>for giving one argument,&quot;x&quot;:	
if &quot;names&quot; is TRUE then return a vector with names the discrete values of &quot;x&quot; and values there frequencies, otherwise only the frequencies
</p>
<p>for giving two arguments,&quot;x&quot;,&quot;y&quot;:
if &quot;names&quot; is TRUE then return a contigency matrix with rownames the discrete values of &quot;x&quot;, colnames the dicrete values of &quot;y&quot; and values the freuquencies of the pairs, otherwise only the freuquencies of the pairs.
</p>
<p>Table.sign:
A vector with 4 values/frequencies:
index 1: negatives
index 2: zeros
index 3: postives
if &quot;names&quot; is TRUE then the returned vector have names &quot;-1,0,+1&quot;.
if &quot;useNA&quot; is TRUE then 4th value has the frequencies of NAs and the returned vector will have one more name, &quot;-1,0,+1,NA&quot;, if &quot;names&quot; is also TRUE.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colShuffle">colShuffle</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a>, <a href="#topic+read.directory">read.directory</a>, <a href="#topic+is_integer">is_integer</a>, <a href="#topic+as_integer">as_integer</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x&lt;-runif(10)
y1&lt;-Table(x)
y2&lt;-as.vector(table(x)) # Neads a lot of time.
all.equal(y1,y2)
y1&lt;-Table(x,names=FALSE)
all.equal(y1,y2) # the name attribute of y1 is null 

y1&lt;-Table.sign(x)
y2&lt;-table(sign(x))
all.equal(y1,y2)

x&lt;-y1&lt;-y2&lt;-NULL
</code></pre>

<hr>
<h2 id='Tests+20for+20the+20dispersion+20parameter+20in+20Poisson+20distribution'>
Tests for the dispersion parameter in Poisson distribution
</h2><span id='topic+poisdisp.test'></span><span id='topic+pois.test'></span>

<h3>Description</h3>

<p>Tests for the dispersion parameter in Poisson distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poisdisp.test(y, alternative = "either", logged = FALSE)
pois.test(y, logged = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tests+2B20for+2B20the+2B20dispersion+2B20parameter+2B20in+2B20Poisson+2B20distribution_+3A_y">y</code></td>
<td>

<p>A numerical vector with count data, 0, 1,...
</p>
</td></tr>
<tr><td><code id="Tests+2B20for+2B20the+2B20dispersion+2B20parameter+2B20in+2B20Poisson+2B20distribution_+3A_alternative">alternative</code></td>
<td>

<p>Do you want to test specifically for either over or underspirsion (&quot;either&quot;), overdispersion (&quot;over&quot;) or undersispersion (&quot;under&quot;)? 
</p>
</td></tr>
<tr><td><code id="Tests+2B20for+2B20the+2B20dispersion+2B20parameter+2B20in+2B20Poisson+2B20distribution_+3A_logged">logged</code></td>
<td>

<p>Set to TRUE if you want the logarithm of the p-value.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with two elements, the test statistic and the (logged) p-value. 
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Yang Zhao, James W. Hardin, and Cheryl L. Addy. (2009). A score test for overdispersion in Poisson regression 
based on the generalized Poisson-2 model. Journal of statistical planning and inference 139(4): 1514-1521.
</p>
<p>Dimitris Karlis and Evdokia Xekalaki (2000). A Simulation Comparison of Several Procedures for 
Testing the Poisson Assumption. Journal of the Royal Statistical Society. Series D (The Statistician), 
49(3): 355-382.
</p>
<p>Bohning, D., Dietz, E., Schaub, R., Schlattmann, P. and Lindsay, B. (1994) The distribution of the likelihood 
ratio for mixtures of densities from the one-parameter exponential family. Annals of the Institute of 
Statistical Mathematics, 46(): 373-388.
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+poisson.mle">poisson.mle</a>, <a href="#topic+negbin.mle">negbin.mle</a>, <a href="#topic+poisson.anova">poisson.anova</a>, <a href="#topic+poisson.anovas">poisson.anovas</a>, <a href="#topic+poisson_only">poisson_only</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnbinom(500, 10, 0.6)
res&lt;-poisdisp.test(y, "either")
res&lt;-poisdisp.test(y, "over")
res&lt;-pois.test(y)

y &lt;- rpois(500, 10)
res&lt;-poisdisp.test(y, "either")
res&lt;-poisdisp.test(y, "over")
res&lt;-pois.test(y)
</code></pre>

<hr>
<h2 id='Topological+20sort+20of+20a+20DAG'>
Topological sort of a DAG
</h2><span id='topic+topological_sort'></span>

<h3>Description</h3>

<p>Topological sort of a DAG.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topological_sort(dag)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Topological+2B20sort+2B20of+2B20a+2B20DAG_+3A_dag">dag</code></td>
<td>

<p>A square matrix representing a directed graph which contains 0s and 1s. If G[i, j] = 1 it 
means there is an arrow from node i to node j. When there is no edge between nodes i and j if G[i, j] = 0.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is an R translation from an old matlab code.
</p>


<h3>Value</h3>

<p>A vector with numbers indicating the sorting. If the dag is not a Directed acyclic Graph, NA will be returned.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris and Manos Papadakis
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>


<h3>References</h3>

<p>Chickering, D.M. (1995). A transformational characterization of equivalent Bayesian network structures. 
Proceedings of the 11th Conference on Uncertainty in Artificial Intelligence, Montreal, Canada, 87-98. 
</p>


<h3>See Also</h3>

<p><code> <a href="#topic+floyd">floyd</a>, <a href="#topic+pc.skel">pc.skel</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>G &lt;- matrix(0, 5, 5)
G[2, 1] &lt;- 1
G[3, 1] &lt;- 1
G[4, 2] &lt;- 1
G[5, 4] &lt;- 1
res&lt;-topological_sort(G)
G[2, 4] &lt;- 1
res&lt;-topological_sort(G)
</code></pre>

<hr>
<h2 id='Transpose+20of+20a+20matrix'>
Transpose of a matrix
</h2><span id='topic+transpose'></span>

<h3>Description</h3>

<p>Transpose of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transpose(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Transpose+2B20of+2B20a+2B20matrix_+3A_x">x</code></td>
<td>

<p>A numerical <b>square</b> matrix with data.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transposed matrix.
</p>


<h3>Author(s)</h3>

<p>Manos Papadakis
</p>
<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Gilbert Strang (2006). Linear Algebra and its Applications (4th edition). 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nth">nth</a>, <a href="#topic+colMaxs">colMaxs</a>, <a href="#topic+colMins">colMins</a>, <a href="#topic+colrange">colrange</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix( rnorm(100 * 100), ncol = 100, nrow=100 )
transpose(x) #t(x)

x&lt;-NULL
</code></pre>

<hr>
<h2 id='Uniformity+20test+20for+20circular+20data'>
Uniformity tests for circular data
</h2><span id='topic+kuiper'></span><span id='topic+watson'></span>

<h3>Description</h3>

<p>Hypothesis tests of uniformity for circular data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kuiper(u)

watson(u)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Uniformity+2B20test+2B20for+2B20circular+2B20data_+3A_u">u</code></td>
<td>

<p>A numeric vector containing the circular data which are expressed in radians.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These tests are used to test the hypothesis that the data come from a circular uniform distribution. 
</p>


<h3>Value</h3>

<p>A vector with two elements, the value of the test statistic and its associated p-value.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; 
</p>


<h3>References</h3>

<p>Jammalamadaka, S. Rao and SenGupta, A. (2001). Topics in Circular Statistics, pg. 153-55 (Kuiper's test) &amp; 
156-157 (Watson's test).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vmf.mle">vmf.mle</a>, <a href="#topic+rvonmises">rvonmises</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rvonmises(n = 50, m = 2, k = 10)
res&lt;-kuiper(x)
res&lt;-watson(x)
x &lt;- runif(50, 0, 2 * pi)
res&lt;-kuiper(x)
res&lt;-watson(x)
</code></pre>

<hr>
<h2 id='Variance+20of+20a+20vector'>
Variance (and standard deviation)  of a vector
</h2><span id='topic+Var'></span>

<h3>Description</h3>

<p>Variance (and standard deviation)  of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Var(x, std = FALSE,na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Variance+2B20of+2B20a+2B20vector_+3A_x">x</code></td>
<td>

<p>A vector with data. 
</p>
</td></tr>
<tr><td><code id="Variance+2B20of+2B20a+2B20vector_+3A_std">std</code></td>
<td>

<p>If you want the standard deviation set this to TRUE, otherwise leave it FALSE.
</p>
</td></tr>
<tr><td><code id="Variance+2B20of+2B20a+2B20vector_+3A_na.rm">na.rm</code></td>
<td>

<p>TRUE or FAlSE for remove NAs if exists.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a faster calculation of the usual variance of a matrix. 
</p>


<h3>Value</h3>

<p>The variance of the vector.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt; and Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colVars">colVars</a>, <a href="#topic+cova">cova</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
a1 &lt;- Var(x)
a2 &lt;- var(x)
x&lt;-NULL
</code></pre>

<hr>
<h2 id='Vector+20allocation+20in+20a+20symmetric+20matrix'>
Vector allocation in a symmetric matrix
</h2><span id='topic+squareform'></span>

<h3>Description</h3>

<p>Vector allocation in a symmetric matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>squareform(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Vector+2B20allocation+2B20in+2B20a+2B20symmetric+2B20matrix_+3A_x">x</code></td>
<td>

<p>An numverical vector whose size must be the one that matches the dimensions of the final matrix. See examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is written in C++ in order to be as fast as possible.
</p>


<h3>Value</h3>

<p>A symmetric matrix. The vector is allocated in the upper and in the lower part of the matrix. The diagonal is filled
with zeros.
</p>


<h3>Author(s)</h3>

<p>R implementation and documentation: Manos Papadakis &lt;papadakm95@gmail.com&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+colShuffle">colShuffle</a>, <a href="#topic+colVars">colVars</a>, <a href="#topic+colmeans">colmeans</a> 
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(1)
res&lt;-squareform(x)  ## OK
x &lt;- rnorm(3)
res&lt;-squareform(x)  ## OK
x &lt;- rnorm(4)
res&lt;-squareform(x)  ## not OK
</code></pre>

<hr>
<h2 id='Weibull+20regression+20model'>
Weibull regression model
</h2><span id='topic+weib.reg'></span>

<h3>Description</h3>

<p>Weibull regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weib.reg(y, x, tol = 1e-07, maxiters = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Weibull+2B20regression+2B20model_+3A_y">y</code></td>
<td>

<p>The dependent variable; a numerical vector with strictly positive data, i.e. greater than zero. 
</p>
</td></tr>
<tr><td><code id="Weibull+2B20regression+2B20model_+3A_x">x</code></td>
<td>

<p>A matrix with the data, where the rows denote the samples (and the two groups) and the columns are the variables. 
This can be a matrix or a data.frame (with factors).
</p>
</td></tr>
<tr><td><code id="Weibull+2B20regression+2B20model_+3A_tol">tol</code></td>
<td>

<p>The tolerance value to terminate the Newton-Raphson algorithm.
</p>
</td></tr>
<tr><td><code id="Weibull+2B20regression+2B20model_+3A_maxiters">maxiters</code></td>
<td>

<p>The max number of iterations that can take place in each regression.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is written in C++ and this is why it is very fast. No standard errors are returned as they are not 
corectly estimated. We focused on speed.
</p>


<h3>Value</h3>

<p>When full is FALSE a list including:
</p>
<table>
<tr><td><code>iters</code></td>
<td>

<p>The iterations required by the Newton-Raphson.
</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>

<p>The log-likelihood of the model.
</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>

<p>The shape parameter of the Weibull regression.
</p>
</td></tr>
<tr><td><code>be</code></td>
<td>

<p>The regression coefficients. 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stefanos Fafalios
</p>
<p>R implementation and documentation: Stefanos Fafalios &lt;stefanosfafalios@gmail.com&gt;.
</p>


<h3>References</h3>

<p>McCullagh, Peter, and John A. Nelder. Generalized linear models. CRC press, USA, 2nd edition, 1989.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+poisson_only">poisson_only</a>, <a href="#topic+logistic_only">logistic_only</a>, <a href="#topic+univglms">univglms</a>, <a href="#topic+regression">regression</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- matrix(rnorm(100 * 2), ncol = 2)
y &lt;- rexp(100, 1)
res&lt;-weib.reg(y, x)

</code></pre>

<hr>
<h2 id='Yule+27s+20Y+20+28coefficient+20of+20colligation+29'>
Yule's Y (coefficient of colligation)
</h2><span id='topic+yule'></span>

<h3>Description</h3>

<p>Yule's Y (coefficient of colligation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yule(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Yule+2B27s+2B20Y+2B20+2B28coefficient+2B20of+2B20colligation+2B29_+3A_x">x</code></td>
<td>

<p>A 2 x 2 matrix or a vector with 4 elements. In the case of the vector make sure it corresponds to the correct table.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yule's coefficient of colligation is calculated.
</p>


<h3>Value</h3>

<p>Yule's Y is returned.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris
</p>
<p>R implementation and documentation: Michail Tsagris &lt;mtsagris@uoc.gr&gt;
</p>


<h3>References</h3>

<p>Yule G. Udny (1912). On the Methods of Measuring Association Between Two Attributes. 
Journal of the Royal Statistical Society, 75(6):579-652.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+col.yule">col.yule</a>, <a href="#topic+odds.ratio">odds.ratio</a>
</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rpois(4, 30) + 2
res&lt;-yule(x)
res&lt;-yule( matrix(x, ncol = 2) )
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
