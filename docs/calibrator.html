<!DOCTYPE html><html lang="en"><head><title>Help for package calibrator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {calibrator}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calibrator-package'>
<p>Bayesian Calibration of Complex Computer Codes</p></a></li>
<li><a href='#beta1hat.fun'><p>beta1 estimator</p></a></li>
<li><a href='#beta2hat.fun'><p>estimator for beta2</p></a></li>
<li><a href='#betahat.fun.koh'><p>Expectation of beta, given theta, phi and d</p></a></li>
<li><a href='#blockdiag'><p>Assembles matrices blockwise into a block diagonal matrix</p></a></li>
<li><a href='#C1'><p>Matrix of distances from D1 to D2</p></a></li>
<li><a href='#cov.p5.supp'><p>Covariance function for posterior distribution of z</p></a></li>
<li><a href='#create.new.toy.datasets'><p>Create new toy datasets</p></a></li>
<li><a href='#D1.fun'><p>Function to join x.star to t.vec to give matrix D1</p></a></li>
<li><a href='#D2.fun'><p>Augments observation points with parameters</p></a></li>
<li><a href='#dists.2frames'><p>Distance between two points</p></a></li>
<li><a href='#E.theta.toy'><p>Expectation and variance with respect to theta</p></a></li>
<li><a href='#EK.eqn10.supp'><p>Posterior mean of K</p></a></li>
<li><a href='#etahat'><p>Expectation of computer output</p></a></li>
<li><a href='#extractor.toy'><p>Extracts lat/long matrix and theta matrix from D2.</p></a></li>
<li><a href='#Ez.eqn7.supp'><p>Expectation of z given y, beta2, phi</p></a></li>
<li><a href='#Ez.eqn9.supp'><p>Expectation as per equation 10 of KOH2001</p></a></li>
<li><a href='#H.fun'><p>H function</p></a></li>
<li><a href='#h1.toy'><p>Basis functions</p></a></li>
<li><a href='#H1.toy'><p>Basis functions for D1 and D2</p></a></li>
<li><a href='#hbar.fun.toy'><p>Toy example of hbar (section 4.2)</p></a></li>
<li><a href='#is.positive.definite'><p>Is a matrix positive definite?</p></a></li>
<li><a href='#MH'><p>Very basic implementation of the Metropolis-Hastings algorithm</p></a></li>
<li><a href='#p.eqn4.supp'><p>Apostiori probability of psi1</p></a></li>
<li><a href='#p.eqn8.supp'><p>A postiori probability of hyperparameters</p></a></li>
<li><a href='#p.page4'><p>A postiori probability of hyperparameters</p></a></li>
<li><a href='#phi.fun.toy'><p>Functions to create or change hyperparameters</p></a></li>
<li><a href='#prob.psi1'><p>A priori probability of psi1, psi2, and theta</p></a></li>
<li><a href='#reality'><p>Reality</p></a></li>
<li><a href='#stage1'><p>Stage 1,2 and 3 optimization on toy dataset</p></a></li>
<li><a href='#symmetrize'><p>Symmetrize an upper triangular matrix</p></a></li>
<li><a href='#tee'><p>Auxiliary functions for equation 9 of the supplement</p></a></li>
<li><a href='#toys'><p>Toy datasets</p></a></li>
<li><a href='#tt.fun'><p>Integrals needed in KOH2001</p></a></li>
<li><a href='#V.fun'><p>Variance matrix for observations</p></a></li>
<li><a href='#V1'><p>Distance matrix</p></a></li>
<li><a href='#V2'><p>distance between observation points</p></a></li>
<li><a href='#Vd'><p>Variance matrix for d</p></a></li>
<li><a href='#W'><p>covariance matrix for beta</p></a></li>
<li><a href='#W1'><p>Variance matrix for beta1hat</p></a></li>
<li><a href='#W2'><p>variance matrix for beta2</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Calibration of Complex Computer Codes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.0.0), emulator (&ge; 1.2-11), mvtnorm</td>
</tr>
<tr>
<td>Imports:</td>
<td>cubature</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Robin K. S. Hankin &lt;hankin.robin@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs Bayesian calibration of computer models as per
 Kennedy and O'Hagan 2001.  The package includes routines to find the
 hyperparameters and parameters; see the help page for stage1() for a
 worked example using the toy dataset.  A tutorial is provided in the
 calex.Rnw vignette; and a suite of especially simple one dimensional
 examples appears in inst/doc/one.dim/.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/RobinHankin/calibrator.git">https://github.com/RobinHankin/calibrator.git</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/RobinHankin/calibrator/issues">https://github.com/RobinHankin/calibrator/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-03-06 20:06:53 UTC; rhankin</td>
</tr>
<tr>
<td>Author:</td>
<td>Robin K. S. Hankin
    <a href="https://orcid.org/0000-0001-5982-0415"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-03-07 06:52:58 UTC</td>
</tr>
</table>
<hr>
<h2 id='calibrator-package'>
Bayesian Calibration of Complex Computer Codes
</h2><span id='topic+calibrator-package'></span><span id='topic+calibrator'></span>

<h3>Description</h3>

<p>Performs Bayesian calibration of computer models as per
Kennedy and O'Hagan 2001.  The package includes routines to find the
hyperparameters and parameters; see the help page for stage1() for a
worked example using the toy dataset.  A tutorial is provided in the
calex.Rnw vignette; and a suite of especially simple one dimensional
examples appears in inst/doc/one.dim/.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> calibrator</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Bayesian Calibration of Complex Computer Codes</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.2-8</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> person(given=c("Robin", "K. S."), family="Hankin", role = c("aut","cre"), email="hankin.robin@gmail.com", comment = c(ORCID = "0000-0001-5982-0415"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.0.0), emulator (&gt;= 1.2-11), mvtnorm</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> cubature</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Robin K. S. Hankin &lt;hankin.robin@gmail.com&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Performs Bayesian calibration of computer models as per
 Kennedy and O'Hagan 2001.  The package includes routines to find the
 hyperparameters and parameters; see the help page for stage1() for a
 worked example using the toy dataset.  A tutorial is provided in the
 calex.Rnw vignette; and a suite of especially simple one dimensional
 examples appears in inst/doc/one.dim/.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> https://github.com/RobinHankin/calibrator.git</td>
</tr>
<tr>
 <td style="text-align: left;">
BugReports: </td><td style="text-align: left;"> https://github.com/RobinHankin/calibrator/issues</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Robin K. S. Hankin [aut, cre] (&lt;https://orcid.org/0000-0001-5982-0415&gt;)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Index of help topics:
</p>
<pre>
C1                      Matrix of distances from D1 to D2
D1.fun                  Function to join x.star to t.vec to give matrix
                        D1
D2.fun                  Augments observation points with parameters
E.theta.toy             Expectation and variance with respect to theta
EK.eqn10.supp           Posterior mean of K
Ez.eqn7.supp            Expectation of z given y, beta2, phi
Ez.eqn9.supp            Expectation as per equation 10 of KOH2001
H.fun                   H function
H1.toy                  Basis functions for D1 and D2
MH                      Very basic implementation of the
                        Metropolis-Hastings algorithm
V.fun                   Variance matrix for observations
V1                      Distance matrix
V2                      distance between observation points
Vd                      Variance matrix for d
W                       covariance matrix for beta
W1                      Variance matrix for beta1hat
W2                      variance matrix for beta2
beta1hat.fun            beta1 estimator
beta2hat.fun            estimator for beta2
betahat.fun.koh         Expectation of beta, given theta, phi and d
blockdiag               Assembles matrices blockwise into a block
                        diagonal matrix
calibrator-package      Bayesian Calibration of Complex Computer Codes
cov.p5.supp             Covariance function for posterior distribution
                        of z
create.new.toy.datasets
                        Create new toy datasets
dists.2frames           Distance between two points
etahat                  Expectation of computer output
extractor.toy           Extracts lat/long matrix and theta matrix from
                        D2.
h1.toy                  Basis functions
hbar.fun.toy            Toy example of hbar (section 4.2)
is.positive.definite    Is a matrix positive definite?
p.eqn4.supp             Apostiori probability of psi1
p.eqn8.supp             A postiori probability of hyperparameters
p.page4                 A postiori probability of hyperparameters
phi.fun.toy             Functions to create or change hyperparameters
prob.psi1               A priori probability of psi1, psi2, and theta
reality                 Reality
stage1                  Stage 1,2 and 3 optimization on toy dataset
symmetrize              Symmetrize an upper triangular matrix
tee                     Auxiliary functions for equation 9 of the
                        supplement
toys                    Toy datasets
tt.fun                  Integrals needed in KOH2001
</pre>
<p>Further information is available in the following vignettes:<br /><br />
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>calex</code> </td><td style="text-align: left;"> Calex: a cookbook for the emulator package (source)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>NA
</p>
<p>Maintainer: Robin K. S. Hankin &lt;hankin.robin@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. &ldquo;Bayesian calibration of
computer models&rdquo;.  Journal of the Royal Statistical Society, Series B,
63(3): 425&ndash;464
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. &ldquo;Introducing BACCO, an R bundle for
Bayesian analysis of computer code output&rdquo;, Journal of Statistical
Software, 14(16)
</p>
</li></ul>


<hr>
<h2 id='beta1hat.fun'>beta1 estimator</h2><span id='topic+beta1hat.fun'></span>

<h3>Description</h3>

<p>Least squares estimator for beta1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta1hat.fun(D1, H1, y, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="beta1hat.fun_+3A_d1">D1</code></td>
<td>
<p>code run points</p>
</td></tr>
<tr><td><code id="beta1hat.fun_+3A_h1">H1</code></td>
<td>
<p>regressor basis funs</p>
</td></tr>
<tr><td><code id="beta1hat.fun_+3A_y">y</code></td>
<td>
<p>code outputs</p>
</td></tr>
<tr><td><code id="beta1hat.fun_+3A_phi">phi</code></td>
<td>
<p>hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+beta2hat.fun">beta2hat.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
y.toy &lt;- create.new.toy.datasets(D1=D1.toy , D2=D2.toy)$y.toy
beta1hat.fun(D1=D1.toy, H1=H1.toy, y=y.toy, phi=phi.toy)

      # now cheat: force the hyperparameters to have the correct psi1:
 phi.fix &lt;- phi.change(old.phi=phi.toy,psi1=c(1, 0.5, 1.0, 1.0, 0.5, 0.4),phi.fun=phi.fun.toy)
      # The value for psi1 is obtained by cheating and #examining the source
      # code for computer.model(); see ?phi.change 


      # Create a new toy dataset with 40 observations:
D1.big &lt;- latin.hypercube(40,5)

jj &lt;- create.new.toy.datasets(D1=D1.big , D2=D2.toy)

      # We know that the real coefficients are 4:9 because we
      # we can cheat and look at the source code for computer.model()

      # Now estimate the coefficients without cheating:

beta1hat.fun(D1=D1.big, H1=H1.toy, jj$y, phi=phi.toy)

     # Not bad!



     # We can do slightly better by cheating and using the
     # correct value for the hyperparameters:

beta1hat.fun(D1=D1.big, H1=H1.toy, jj$y,phi=phi.true.toy(phi=phi.toy))

     #marginally worse.


</code></pre>

<hr>
<h2 id='beta2hat.fun'>estimator for beta2</h2><span id='topic+beta2hat.fun'></span>

<h3>Description</h3>

<p>estimates beta2 as per the equation of page 4 of the supplement.  Used
by <code>p.page4()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta2hat.fun(D1, D2, H1, H2, V, z, etahat.d2, extractor, E.theta,
Edash.theta, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="beta2hat.fun_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_d2">D2</code></td>
<td>
<p>Matrix of observation points</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_h1">H1</code></td>
<td>
<p>regression basis functions</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_h2">H2</code></td>
<td>
<p>regression basis functions</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_v">V</code></td>
<td>
<p>overall covariance matrix</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_z">z</code></td>
<td>
<p>vector of observations</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_etahat.d2">etahat.d2</code></td>
<td>
<p>expectation as per <code>etahat.vector</code></p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_extractor">extractor</code></td>
<td>
<p>extractor function</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_e.theta">E.theta</code></td>
<td>
<p>Expectation</p>
</td></tr>
<tr><td><code id="beta2hat.fun_+3A_edash.theta">Edash.theta</code></td>
<td>
<p>Expectation wrt thetadash</p>
</td></tr>  
<tr><td><code id="beta2hat.fun_+3A_phi">phi</code></td>
<td>
<p>hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+W2">W2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)

etahat.d2 &lt;- etahat(D1=D1.toy, D2=D2.toy, H1=H1.toy, y=y.toy,
E.theta=E.theta.toy, extractor=extractor.toy, phi=phi.toy)

beta2hat.fun(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, V=NULL,
z=z.toy, etahat.d2=etahat.d2, extractor=extractor.toy,
E.theta=E.theta.toy, Edash.theta=Edash.theta.toy, phi=phi.toy)

jj &lt;- create.new.toy.datasets(D1.toy , D2.toy)
phi.true &lt;- phi.true.toy(phi=phi.toy)
y.toy &lt;- jj$y.toy
z.toy &lt;- jj$z.toy
d.toy &lt;- jj$d.toy

etahat.d2 &lt;- etahat(D1=D1.toy, D2=D2.toy, H1=H1.toy, y=y.toy,
E.theta=E.theta.toy, extractor=extractor.toy, phi=phi.toy)

beta2hat &lt;- beta2hat.fun(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, V=NULL,
z=z.toy, etahat.d2=etahat.d2, extractor=extractor.toy,
E.theta=E.theta.toy, Edash.theta=Edash.theta.toy,
phi=phi.toy)

print(beta2hat)

plot(z.toy , H2.toy(D2.toy) %*% beta2hat) 


</code></pre>

<hr>
<h2 id='betahat.fun.koh'>Expectation of beta, given theta, phi and d</h2><span id='topic+betahat.fun.koh'></span><span id='topic+betahat.fun.koh.vector'></span>

<h3>Description</h3>

<p>Determines the mean of <code class="reqn">\beta</code>, given parameters <code class="reqn">\theta</code>,
hyperparameters <code class="reqn">\phi</code>, and the vector of code outputs and observations
<code class="reqn">d</code>.  It is named so as to avoid conflict with 
function <code>betahat.fun</code> of package <span class="pkg">emulator</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betahat.fun.koh(D1, D2, H1, H2, theta, d, phi)
betahat.fun.koh.vector(D1, D2, H1, H2, theta, d, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betahat.fun.koh_+3A_d1">D1</code></td>
<td>
<p>Matrix whose rows are observation points and parameter
values at which the code has been run</p>
</td></tr>
<tr><td><code id="betahat.fun.koh_+3A_d2">D2</code></td>
<td>
<p>Matrix whose rows are the observation points</p>
</td></tr>
<tr><td><code id="betahat.fun.koh_+3A_h1">H1</code></td>
<td>
<p>Regression function for D1</p>
</td></tr>
<tr><td><code id="betahat.fun.koh_+3A_h2">H2</code></td>
<td>
<p>Regression function for D2</p>
</td></tr>
<tr><td><code id="betahat.fun.koh_+3A_theta">theta</code></td>
<td>
<p>Parameters</p>
</td></tr>
<tr><td><code id="betahat.fun.koh_+3A_d">d</code></td>
<td>
<p>Vector of code outputs and observations</p>
</td></tr>
<tr><td><code id="betahat.fun.koh_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is defined between equations 2 and 3 of the
supplement.  It is used in functions <code>Ez.eqn9.supp()</code> and
<code>p.eqn8.supp()</code>.
</p>
<p>The user should always use <code>betahat.fun.koh()</code>, which is a
wrapper for <code>betahat.fun.koh.vector()</code>.  The forms differ in
their treatment of <code class="reqn">\theta</code>.  In the former,
<code class="reqn">\theta</code> must be a vector; in the latter,
<code class="reqn">\theta</code> may be a matrix, in which case
<code>betahat.fun.koh.vector()</code> is applied to the rows.
</p>
<p>In <code>betahat.fun.koh()</code>, the rownames are assigned by a kludgy
call to <code>H.fun()</code>,  which itself uses a kludge to determine
colnames. 
</p>
<p>The function returns
</p>
<p style="text-align: center;"><code class="reqn">
    \hat{\mathbf\beta} (\theta)=
    {\mathbf W}(\theta)^T {\mathbf H}(\theta)^T {\mathbf
      V}_d(\theta)^{-1}{\mathbf d}.
  </code>
</p>



<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
betahat.fun.koh(theta=theta.toy, d=d.toy, D1=D1.toy, D2=D2.toy,
      H1=H1.toy, H2=H2.toy, phi=phi.toy)

betahat.fun.koh.vector(theta=theta.toy, d=d.toy, D1=D1.toy,
      D2=D2.toy, H1=H1.toy, H2=H2.toy, phi=phi.toy)
## should be identical

jj.theta &lt;- rbind(theta.toy,theta.toy+1,theta.toy+2,theta.toy*0)
betahat.fun.koh(theta=jj.theta, d=d.toy, D1=D1.toy, D2=D2.toy,
     H1=H1.toy, H2=H2.toy, phi=phi.toy)

## Now try with true hyperparameters:
phi.true &lt;- phi.true.toy(phi=phi.toy)

## And magically create the REAL parameters:
theta.REAL &lt;- create.new.toy.datasets(export=TRUE)$REAL.PARAMS
jj.theta &lt;- rbind(jj.theta, theta.REAL)

## Generate some data:
jj &lt;- create.new.toy.datasets(D1.toy , D2.toy)
d.toy &lt;- jj$d.toy


## And finally, observe that the estimated values for beta are pretty
## close to the real values (which omniscient beings can extract using
## reality() and computer.model()):

betahat.fun.koh(theta=jj.theta, d=d.toy, D1=D1.toy, D2=D2.toy,
       H1=H1.toy, H2=H2.toy, phi=phi.true)

## [
##  that is, compare the last column of the above with
##  c(computer.model(ex=T)$REAL.COEFFS, reality(ex=T)$REAL.BETA2)
## ]


</code></pre>

<hr>
<h2 id='blockdiag'>Assembles matrices blockwise into a block diagonal matrix</h2><span id='topic+blockdiag'></span>

<h3>Description</h3>

<p>Assembles matrices blockwise into a block diagonal matrix with optional
padding value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockdiag(m1, m2, p.tr = 0, p.ll = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blockdiag_+3A_m1">m1</code></td>
<td>
<p>Upper left matrix</p>
</td></tr>
<tr><td><code id="blockdiag_+3A_m2">m2</code></td>
<td>
<p>Lower right matrix</p>
</td></tr>
<tr><td><code id="blockdiag_+3A_p.tr">p.tr</code></td>
<td>
<p>Padding value for top right quadrant.  Defaults to zero.</p>
</td></tr>
<tr><td><code id="blockdiag_+3A_p.ll">p.ll</code></td>
<td>
<p>Padding value for lower left quadrant.  Defaults to zero.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function documented here is a subset of <code>adiag</code> of
package <span class="pkg">magic</span>
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
blockdiag(D1.toy,D2.toy)
</code></pre>

<hr>
<h2 id='C1'>Matrix of distances from D1 to D2</h2><span id='topic+C1'></span>

<h3>Description</h3>

<p>Returns a matrix of distances from the code run points to the
augmented observation points.  A wrapper for <code>c1.fun()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C1(D1, D2,  theta, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="C1_+3A_d1">D1</code></td>
<td>
<p>D1</p>
</td></tr>
<tr><td><code id="C1_+3A_d2">D2</code></td>
<td>
<p>D2</p>
</td></tr>
<tr><td><code id="C1_+3A_theta">theta</code></td>
<td>
<p>Parameters</p>
</td></tr>
<tr><td><code id="C1_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+t.fun">t.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
C1(D1=D1.toy, D2=D2.toy, theta=theta.toy, phi=phi.toy)
</code></pre>

<hr>
<h2 id='cov.p5.supp'>Covariance function for posterior distribution of z</h2><span id='topic+cov.p5.supp'></span><span id='topic+Cov.eqn9.supp'></span>

<h3>Description</h3>

<p>Covariance function for posterior distribution of <code class="reqn">z(\cdot)</code>
conditional on estimated hyperparameters and calibration parameters
<code class="reqn">\theta</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cov.eqn9.supp(x, xdash=NULL, theta, d, D1, D2, H1, H2, phi)
cov.p5.supp  (x, xdash=NULL, theta, d, D1, D2, H1, H2, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov.p5.supp_+3A_x">x</code></td>
<td>
<p>first point, or (<code>Cov.eqn9.supp()</code>) a matrix whose rows
are the points of interest</p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_xdash">xdash</code></td>
<td>
<p>The second point, or (<code>Cov.eqn9.supp()</code>) 
a matrix whose rows are the points of interest.  The default of
<code>NULL</code> means to use <code>xdash=x</code></p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_theta">theta</code></td>
<td>
<p>Parameters.  For <code>Cov.eqn9.supp()</code>, supply a vector
which will be interpreted as a single point in parameter space.  For
<code>cov.p5.supp()</code>, supply a matrix whose rows will be interpreted
as points in parameter space</p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_d">d</code></td>
<td>
<p>Observed values</p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_d1">D1</code></td>
<td>
<p>Code run design matrix</p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_d2">D2</code></td>
<td>
<p>Observation points of real process</p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_h1">H1</code></td>
<td>
<p>Basis function for <code>D1</code></p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_h2">H2</code></td>
<td>
<p>Basis function for <code>D2</code></p>
</td></tr>
<tr><td><code id="cov.p5.supp_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Evaluates the covariance function: the last formula on page 5 of the
supplement.  The two functions documented here are vectorized
differently.
</p>
<p>Function <code>Cov.eqn9.supp()</code> takes matrices for arguments <code>x</code>
and <code>xdash</code> and a single vector for <code>theta</code>.  Evaluation is
thus taken at a single, fixed value of <code>theta</code>.  The function
returns a matrix whose rows correspond to rows of <code>x</code> and whose
columns correspond to rows of <code>xdash</code>.
</p>
<p>Function <code>cov.p5.supp()</code> takes a vector for arguments <code>x</code> and
<code>xdash</code> and a matrix for argument <code>theta</code> whose rows are the
points in parameter space.  A vector <code>V</code>, with elements
corresponding to the rows of argument <code>theta</code> is returned:
</p>
<p style="text-align: center;"><code class="reqn">V[i] = \mbox{cov}\left(z(x),z(x')|\theta_i\right)</code>
</p>



<h3>Value</h3>

<p>Returns a matrix of covariances
</p>


<h3>Note</h3>

<p>May return the transpose of the desired object
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
x &lt;- rbind(x.toy,x.toy+1,x.toy,x.toy,x.toy)
rownames(x) &lt;- letters[1:5]
xdash &lt;- rbind(x*2,x.toy)
rownames(xdash) &lt;- LETTERS[1:6]

Cov.eqn9.supp(x=x,xdash=xdash,theta=theta.toy,d=d.toy,D1=D1.toy,
    D2=D2.toy,H1=H1.toy,H2=H2.toy,phi=phi.toy)

phi.true &lt;- phi.true.toy(phi=phi.toy)

Cov.eqn9.supp(x=x,xdash=xdash,theta=theta.toy,d=d.toy,D1=D1.toy,
     D2=D2.toy,H1=H1.toy,H2=H2.toy,phi=phi.true)


# Now try a sequence of thetas:
cov.p5.supp(x=x.toy,theta=t.vec.toy,d=d.toy,D1=D1.toy,D2=D2.toy,
    H1=H1.toy,H2=H2.toy,phi=phi.toy)

</code></pre>

<hr>
<h2 id='create.new.toy.datasets'>Create new toy datasets</h2><span id='topic+create.new.toy.datasets'></span>

<h3>Description</h3>

<p>Creates new toy datasets, by sampling from an explicitly specified
multivariate Gaussian distribution whose covariance matrix is that
required for a Gaussian process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.new.toy.datasets(D1,D2,export=FALSE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create.new.toy.datasets_+3A_export">export</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return toy
datasets and <code>TRUE</code> meaning to return, instead, a list of the
true values of the parameters</p>
</td></tr>
<tr><td><code id="create.new.toy.datasets_+3A_d1">D1</code></td>
<td>
<p>D1; set of code run points</p>
</td></tr>
<tr><td><code id="create.new.toy.datasets_+3A_d2">D2</code></td>
<td>
<p>D2; set of field observation points</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of three elements:
</p>
<table role = "presentation">
<tr><td><code>y.toy</code></td>
<td>
</td></tr>
<tr><td><code>z.toy</code></td>
<td>
</td></tr>
<tr><td><code>d.toy</code></td>
<td>
</td></tr>
</table>


<h3>Note</h3>

<p>Because function <code>create.new.toy.datasets()</code> calls
<code>computer.model()</code> and <code>model.inadequacy()</code>, the datasets
returned are drawn from a multivariate Gaussian distribution which
<strong>is</strong> a Gaussian process
</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+toys">toys</a></code>, <code><a href="#topic+reality">reality</a></code>, <code><a href="emulator.html#topic+latin.hypercube">latin.hypercube</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
create.new.toy.datasets(D1=D1.toy , D2=D2.toy)

</code></pre>

<hr>
<h2 id='D1.fun'>Function to join x.star to t.vec to give matrix D1</h2><span id='topic+D1.fun'></span>

<h3>Description</h3>

<p>Function to join <code>x.star</code> to <code>t.vec</code> to give matrix <code>D1</code> with correct row-
and column- names. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D1.fun(x.star, t.vec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="D1.fun_+3A_x.star">x.star</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="D1.fun_+3A_t.vec">t.vec</code></td>
<td>
<p>Matrix of parameter theta values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the matrix returned is a D1 matrix: it is a design matrix for
code observations as it contains both x and theta
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+toys">toys</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
jj &lt;- extractor.toy(D1.toy)
x.star.toy &lt;- jj$x.star
t.vec.toy  &lt;- jj$t.vec
D1.fun(x.star.toy , t.vec.toy)  # both dataframes
D1.fun(x.star.toy , theta.toy)  # one dataframe, one vector
D1.fun(x.toy , t.vec.toy)       # one vector, one dataframe
D1.fun(x.toy,theta.toy)         # two vectors
</code></pre>

<hr>
<h2 id='D2.fun'>Augments observation points with parameters</h2><span id='topic+D2.fun'></span>

<h3>Description</h3>

<p>Augments observation points with parameters; will recycle if necessary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D2.fun(D2, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="D2.fun_+3A_d2">D2</code></td>
<td>
<p>Observation points</p>
</td></tr>
<tr><td><code id="D2.fun_+3A_theta">theta</code></td>
<td>
<p>Parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2001. &ldquo;Bayesian
calibration of computer models&rdquo;.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
<p>M. C. Kennedy and A. O'Hagan 2001.  &ldquo;Supplementary details on
Bayesian calibration of computer models&rdquo;, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
<p>R. K. S. Hankin 2005. &ldquo;Introducing BACCO, an R bundle for
Bayesian analysis of computer code output&rdquo;, Journal of Statistical
Software, 14(16)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D1.toy">D1.toy</a></code>,
<code><a href="#topic+theta.toy">theta.toy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
D2.fun(D2=D2.toy, theta=theta.toy)
D2.fun(D2=t(x.toy), theta=theta.toy)
D2.fun(D2=D2.toy[1,,drop=FALSE], theta=theta.toy)
</code></pre>

<hr>
<h2 id='dists.2frames'>Distance between two points</h2><span id='topic+dists.2frames'></span>

<h3>Description</h3>

<p>Distance between points specified by rows of two matrices, according to a
positive definite matrix.  If not specified, the second matrix used is
the first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dists.2frames(a, b=NULL, A=NULL, A.lower=NULL, test.for.symmetry=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dists.2frames_+3A_a">a</code></td>
<td>
<p>First dataframe whose rows are the points</p>
</td></tr>
<tr><td><code id="dists.2frames_+3A_b">b</code></td>
<td>
<p>Second dataframe whose rows are the points; if <code>NULL</code>,
use <code>a</code></p>
</td></tr>
<tr><td><code id="dists.2frames_+3A_a">A</code></td>
<td>
<p>Positive definite matrix; if <code>NULL</code>, a value for
<code>A.lower</code> is needed.  If a value for <code>A</code> is supplied, use
a clear but possibly slower method</p>
</td></tr>
<tr><td><code id="dists.2frames_+3A_a.lower">A.lower</code></td>
<td>
<p>The lower triangular Cholesky decomposition of
<code>A</code> (only needed if <code>A</code> is <code>NULL</code>).
</p>
<p>If a value for <code>A.lower</code> is specified, this means that a
relatively opaque but possibly faster method will be used.  The time
saving ought to be negligible unless <code>nrow(a)</code> (or
<code>nrow(b)</code> if supplied), is huge.  <strong>Note that this option does
not test for symmetry of matrix A</strong></p>
</td></tr>
<tr><td><code id="dists.2frames_+3A_test.for.symmetry">test.for.symmetry</code></td>
<td>
<p>Boolean, with default <code>TRUE</code> meaning
to calculate all element arrays (elegantly), and <code>FALSE</code>
meaning to calculate only the upper triangular elements (using
loops), which ought to be faster.  The value of this argument should
not affect the returned value, up to numerical accuracy</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+dists.2frames">dists.2frames</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)

dists.2frames(a=D2.toy,A=diag(2))

A &lt;- diag(2) + matrix(0.2,2,2)
A.lower &lt;- t(chol(A))
jj.1 &lt;- dists.2frames(a=D2.toy, A=A, test=TRUE)
jj.2 &lt;- dists.2frames(a=D2.toy, A=A, test=FALSE)

jj.3 &lt;- dists.2frames(a=D2.toy, A.lower=A.lower, test=FALSE)
jj.4 &lt;- dists.2frames(a=D2.toy, A.lower=A.lower, test=TRUE)


</code></pre>

<hr>
<h2 id='E.theta.toy'>Expectation and variance with respect to theta</h2><span id='topic+E.theta.toy'></span><span id='topic+Edash.theta.toy'></span>

<h3>Description</h3>

<p>Function 
<code>E.theta.toy</code> returns expectation of <code>H_1(D)</code> with respect to
<code class="reqn">\theta</code>; <code>Edash.theta.toy</code> returns expectation with
respect to <code class="reqn">E'</code>.  Function <code>E.theta.toy</code> also returns
information about nonlinear behaviour of <code>h1(x,theta)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>E.theta.toy(D2=NULL,  H1=NULL, x1=NULL, x2=NULL, phi, give.mean=TRUE)
Edash.theta.toy(x, t.vec, k,  H1, fast.but.opaque=FALSE, a=NULL, b=NULL,
phi=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="E.theta.toy_+3A_d2">D2</code></td>
<td>
<p>Observation points</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_h1">H1</code></td>
<td>
<p>Regression function for D1</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_phi">phi</code></td>
<td>
<p>hyperparameters.  Default value of <code>NULL</code> only to be
used in <code>Edash.theta.toy()</code> when <code>fast.but.opaque</code> is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_x">x</code></td>
<td>
<p>lat/long point (for <code>Edash.theta.toy</code>)</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_t.vec">t.vec</code></td>
<td>
<p>Matrix whose rows are parameter values (for <code>Edash.theta.toy</code>)</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_k">k</code></td>
<td>
<p>Integer specifying column (for <code>Edash.theta.toy</code>)</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_give.mean">give.mean</code></td>
<td>
<p>In <code>E.theta.toy()</code>, Boolean, with default <code>TRUE</code> meaning to return
the mean (expectation), and <code>FALSE</code> meaning to return the &ldquo;variance&rdquo;</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_fast.but.opaque">fast.but.opaque</code></td>
<td>
<p>In <code>Edash.theta.toy()</code>, Boolean, with
default <code>FALSE</code> meaning to use a slow but clear method.  If
<code>TRUE</code>, use faster code but parameters <code>a</code> and <code>b</code> must then be specified</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_a">a</code></td>
<td>
<p>Constant term, needed if <code>fast.but.opaque</code> is
<code>TRUE</code>: 
<code class="reqn">\left(V_\theta^{-1}+2\Omega_t\right)^{-1}V_\theta^{-1}m_\theta</code>.
Specifying <code>a</code> in advance saves execution time</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_b">b</code></td>
<td>
<p>Linear term, needed if <code>fast.but.opaque</code> is <code>TRUE</code>:
<code class="reqn">2\left(V_\theta^{-1}+2\Omega_t\right)^{-1}\Omega_t</code>
(multiplied by <code>t[k,]</code> in <code>Edash.theta.toy()</code>).</p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_x1">x1</code></td>
<td>
<p>In <code>E.theta.toy(g=F,...)</code>, the value of <code>x</code> in
<code class="reqn">h_1(x,\theta)</code>.  The default value is <code>NULL</code>
because in simple cases such as that implemented here, the output is
independent of <code>x1</code> and <code>x2</code></p>
</td></tr>
<tr><td><code id="E.theta.toy_+3A_x2">x2</code></td>
<td>
<p>In <code>E.theta.toy(g=F,...)</code>, the value of <code>x</code> in
<code class="reqn">h_1(x,\theta)</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>A terse discussion follows; see the <code>calex.pdf</code> vignette and the
1D case study in directory <code>inst/doc/one/dim/</code> for more details
and examples.
</p>
<p>Function <code>E.theta.toy(give.mean=FALSE,...)</code> does <strong>not</strong>
return the variance!  The matrix returned is a <strong>different size</strong>
from the variance matrix!
</p>
<p>It returns the thing that must be added to
<code>crossprod(E_theta(h1(x,theta)),t(E_theta(h1(x,theta))))</code> to give
<code>E_theta(h1(x,theta).t(h1(x,theta)))</code>.
</p>
<p>In other words, it returns
<code>E_theta(h1(x,theta).t(h1(x,theta)))</code>-
<code>crossprod(E_theta(h1(x,theta)),t(E_theta(h1(x,theta))))</code>.
</p>
<p>If the terms of
<code>h1()</code> are of the form <code>c(o,theta)</code> (where <code>o</code> is a
vector that is a function of <code>x</code> alone, and independent of
<code>theta</code>), then the function will include the variance matrix, in
the lower right corner (zeroes elsewhere).
</p>
<p>Function <code>E.theta()</code> must be updated if <code>h1.toy()</code>
changes: unlike <code>E.theta()</code> and <code>Edash.theta()</code>, it does not
&ldquo;know&rdquo; where the elements that vary with <code>theta</code> are, nor
their (possibly x-dependent) coefficients.
</p>
<p>This form of the function requires <code>x1</code> and <code>x2</code> arguments,
for good form's sake, even though the returned value is independent of
<code>x</code> in the toy example.  To see why it is
necessary to include <code>x</code>, consider a simple case with
<code class="reqn">h_1(x,\theta)=(1,x\theta)^T</code>.  Now
<code class="reqn">E_\theta\left(h(x,\theta)\right)</code> is just
<code class="reqn">(1,x\overline{\theta})^T</code> but
</p>
<p style="text-align: center;"><code class="reqn">E_\theta\left(h_1(x,\theta)h_1(x,\theta)^T\right)</code>
</p>

<p>is a 2-by-2 matrix (<code class="reqn">M</code>, say) with
<code class="reqn">E_\theta(M)=h_1(x,\overline{\theta})h_1(x,\overline{\theta})^T +
  \mbox{variance terms}</code>.
</p>
<p style="text-align: center;"><code class="reqn">
  E_\theta\left(
  \begin{array}{cc}
      1 &amp; x\theta\\
      x\theta &amp; x^2\theta^2
      \end{array}\right)
      </code>
</p>

<p>All three functions here are intimately connected to the form of
<code>h1.toy()</code> and changing it (or indeed <code>H1.toy()</code>) will
usually require rewriting all three functions documented here.  Look
at the definition of <code>E.theta.toy(give=F)</code>, and you will see that
even changing the meat of <code>h1.toy()</code> from <code>c(1,x)</code> to
<code>c(x,1)</code> would require a redefinition of <code>E.theta.toy(g=F)</code>.
</p>
<p>The only place that <code>E.theta.toy(g=F)</code> is used is internally in
<code>hh.fun()</code>.  
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+toys">toys</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
E.theta.toy(D2=D2.toy,      H1=H1.toy,phi=phi.toy)
E.theta.toy(D2=D2.toy[1,],  H1=H1.toy,phi=phi.toy)
E.theta.toy(D2=x.toy,       H1=H1.toy,phi=phi.toy)
Edash.theta.toy(x=x.toy,t.vec=t.vec.toy,k=1, H1=H1.toy,phi=phi.toy)
</code></pre>

<hr>
<h2 id='EK.eqn10.supp'>Posterior mean of K</h2><span id='topic+EK.eqn10.supp'></span>

<h3>Description</h3>

<p>Estimates the posterior mean of K as per equation 10 of KOH2001S,
section 4.2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EK.eqn10.supp(X.dist, D1, D2, H1, H2, d, hbar.fun,
   lower.theta, upper.theta, extractor, give.info=FALSE,
   include.prior=FALSE, phi, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EK.eqn10.supp_+3A_x.dist">X.dist</code></td>
<td>
<p>Probability distribution of <code>X</code>, in the form of a
two-element list.  The first element is the mean (which should have
name &ldquo;<code>mean</code>&rdquo;), and the second element is the variance
matrix, which should  be a positive definite matrix of the correct
size, and have name &ldquo;var&rdquo;</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_d1">D1</code></td>
<td>
<p>Matrix whose rows are the code run points</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_d2">D2</code></td>
<td>
<p>Matrix whose rows are field observation points</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_h1">H1</code></td>
<td>
<p>Regression function for <code>D1</code></p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_h2">H2</code></td>
<td>
<p>Regression function for <code>D2</code></p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_d">d</code></td>
<td>
<p>Vector of code outputs and field observations</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_include.prior">include.prior</code></td>
<td>
<p>Boolean; passed to function <code>p.eqn8.supp()</code> (qv)</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_hbar.fun">hbar.fun</code></td>
<td>
<p>Function that gives expectation (with respect to <code>X</code>)
of <code>h1(x,theta)</code> and <code>h2(x)</code> as per section 4.2</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_lower.theta">lower.theta</code></td>
<td>
<p>Lower integration limit for <code>theta</code> (NB: a vector)</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_upper.theta">upper.theta</code></td>
<td>
<p>Lower integration limit for <code>theta</code> (NB: a
vector)</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_extractor">extractor</code></td>
<td>
<p>Extractor function; see <code>extractor.toy()</code> for
an example</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_give.info">give.info</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return
just the answer and <code>TRUE</code> to return the answer along with all
output from both integrations as performed by <code>adaptIntegrate()</code></p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
<tr><td><code id="EK.eqn10.supp_+3A_...">...</code></td>
<td>
<p>Extra arguments passed to the integration
function.  If multidimensional (ie <code>length(theta)&gt;1</code>), then the
arguments are passed to <code>adaptIntegrate()</code>; if one dimensional, they
are passed to <code>integrate()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates a numerical approximation to equation 10 of
section 4.2 of the supplement.
</p>
<p>Equation 10 integrates over the prior distribution of <code>theta</code>.  If
<code>theta</code> is a vector, multidimensional integration is necessary.
</p>
<p>In the case of multidimensional integration, function
<code>adaptIntegrate()</code> is used.
</p>
<p>In the case of one dimensional integration&mdash;theta being a
scalar&mdash;function <code>integrate()</code> of the stats package is used.
</p>
<p>Note that equation 10 is conditional on the observed data <strong>and</strong>
the hyperparameters
</p>


<h3>Value</h3>

<p>Returns a scalar
</p>


<h3>Note</h3>

<p>The function was not reviewed by the Journal of Statistical Software.
</p>
<p>The package formely used adapt package, but this is no longer
available on CRAN.  The package now uses the cubature package.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>1+1
## Not run: 
# Not run because it takes R CMD check too long

data(toys)
EK.eqn10.supp(X.dist=X.dist.toy, D1=D1.toy, D2=D2.toy,
          H1=H1.toy, H2=H2.toy, d=d.toy,
          hbar.fun=hbar.fun.toy, lower.theta=c(-3,-3,-3),
          upper.theta=c(3,3,3),extractor=extractor.toy,
          phi=phi.toy)

## End(Not run)
</code></pre>

<hr>
<h2 id='etahat'>Expectation of computer output</h2><span id='topic+etahat'></span>

<h3>Description</h3>

<p>Returns the apostiori expectation of the computer program at a particular point
with a particular set of parameters, given the code output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>etahat(D1, D2, H1, y, E.theta, extractor, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="etahat_+3A_d1">D1</code></td>
<td>
<p>Matrix of code observation points and parameters</p>
</td></tr>
<tr><td><code id="etahat_+3A_d2">D2</code></td>
<td>
<p>Matrix of field observation points</p>
</td></tr>
<tr><td><code id="etahat_+3A_h1">H1</code></td>
<td>
<p>Basis functions</p>
</td></tr>
<tr><td><code id="etahat_+3A_y">y</code></td>
<td>
<p>Code observations corresponding to rows of <code>D1</code></p>
</td></tr>
<tr><td><code id="etahat_+3A_e.theta">E.theta</code></td>
<td>
<p>expectation wrt theta; see details</p>
</td></tr>
<tr><td><code id="etahat_+3A_extractor">extractor</code></td>
<td>
<p>Extractor function</p>
</td></tr>
<tr><td><code id="etahat_+3A_theta">theta</code></td>
<td>
<p>Parameters</p>
</td></tr>
<tr><td><code id="etahat_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Argument <code>E.theta</code> is officially a function that, given
<code class="reqn">x</code>,y returns
<code class="reqn">E_\theta\left(h_1(x,\theta)\right)</code>.
</p>
<p>However, if supplied a non-function (this is tested by
<code>is.function()</code> in the code), <code>E.theta</code> is interpreted as
values of <code class="reqn">\theta</code> to use.  Recycling is carried out by
function <code>D1.fun()</code>
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+p.page4">p.page4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)

etahat(D1=D1.toy, D2=D2.toy, H1=H1.toy, y=y.toy,
    E.theta=E.theta.toy, extractor=extractor.toy, phi=phi.toy)

# Now try giving E.theta=1:3, which will be interpreted as a value for theta:
etahat(D1=D1.toy, D2=D2.toy, H1=H1.toy, y=y.toy, E.theta=1:3,
     extractor=extractor.toy, phi=phi.toy)

</code></pre>

<hr>
<h2 id='extractor.toy'>Extracts lat/long matrix and theta matrix from D2.
</h2><span id='topic+extractor.toy'></span>

<h3>Description</h3>

<p>Extracts <code>x.star.toy</code> and <code>t.vec.toy</code> from <code>D2</code>; toy
example needed because the extraction differs from case to case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractor.toy(D1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extractor.toy_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first two columns give the elements of <code>x.star</code>
and columns 3 through 5 give the elements of <code>t.vec</code>.
</p>
<p>Function <code>extractor.toy</code> is the inverse of function
<code>D1.fun</code>, in the sense that <code>extractor.toy</code> splits up
<code>D1</code>  into <code>x.star</code> and <code>t.vec</code>, while <code>D1.fun</code>
joins them up again
</p>


<h3>Value</h3>

<p>Returns a list with two elements:
</p>
<table role = "presentation">
<tr><td><code>x.star</code></td>
<td>
<p>A matrix containing the lat/longs of the code run points</p>
</td></tr>
<tr><td><code>t.vec</code></td>
<td>
<p>A matrix containing the parameters used for the code runs</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+toys">toys</a></code>, <code><a href="#topic+D1.fun">D1.fun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
extractor.toy(D1.toy)
extractor.toy(D1.toy[1,,drop=FALSE])
(jj &lt;- extractor.toy(D1.fun(x.star=x.toy , t.vec=theta.toy)))
D1.fun(jj$x.star,jj$t.vec)

</code></pre>

<hr>
<h2 id='Ez.eqn7.supp'>Expectation of z given y, beta2, phi</h2><span id='topic+Ez.eqn7.supp'></span>

<h3>Description</h3>

<p>Expectation as per equation 7 on the supplement
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ez.eqn7.supp(z, D1, H1, D2, H2,  extractor, beta2, y, E.theta,  phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ez.eqn7.supp_+3A_z">z</code></td>
<td>
<p>Vector of observations</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_d1">D1</code></td>
<td>
<p>Matrix whose rows are code run points</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_h1">H1</code></td>
<td>
<p>Regressor basis functions</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_d2">D2</code></td>
<td>
<p>Matrix whose rows are observation points</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_h2">H2</code></td>
<td>
<p>Regressor basis functions</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_extractor">extractor</code></td>
<td>
<p>Function to split D1</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_beta2">beta2</code></td>
<td>
<p>coefficients</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_y">y</code></td>
<td>
<p>Code outputs at points corresponding to rows of <code>D1</code></p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_e.theta">E.theta</code></td>
<td>
<p>Expectation function to use</p>
</td></tr>
<tr><td><code id="Ez.eqn7.supp_+3A_phi">phi</code></td>
<td>
<p>hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+V.fun">V.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
etahat.d2 &lt;- etahat(D1=D1.toy, D2=D2.toy, H1=H1.toy, y=y.toy,
    E.theta=E.theta.toy, extractor=extractor.toy, phi=phi.toy)
beta2 &lt;- beta2hat.fun(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, V=V.toy, z=z.toy,
etahat.d2=etahat.d2, extractor=extractor.toy, E.theta=E.theta.toy,
Edash.theta=Edash.theta.toy, phi=phi.toy)
Ez.eqn7.supp(z=z.toy, 
    D1=D1.toy, H1=H1.toy, D2=D2.toy, H2=H2.toy, 
    extractor=extractor.toy, beta2=beta2, y=y.toy, 
    E.theta=E.theta.toy, 
    phi=phi.toy)
</code></pre>

<hr>
<h2 id='Ez.eqn9.supp'>Expectation as per equation 10 of KOH2001</h2><span id='topic+Ez.eqn9.supp'></span><span id='topic+Ez.eqn9.supp.vector'></span>

<h3>Description</h3>

<p>Expectation as per equation 10 of KOH2001 (not the supplement)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ez.eqn9.supp(x, theta, d, D1, D2, H1, H2,  phi)
Ez.eqn9.supp.vector(x, theta, d, D1, D2, H1, H2, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ez.eqn9.supp_+3A_x">x</code></td>
<td>
<p>point at which expectation is needed</p>
</td></tr>
<tr><td><code id="Ez.eqn9.supp_+3A_theta">theta</code></td>
<td>
<p>parameters</p>
</td></tr>
<tr><td><code id="Ez.eqn9.supp_+3A_d">d</code></td>
<td>
<p>observations and code outputs</p>
</td></tr>
<tr><td><code id="Ez.eqn9.supp_+3A_d1">D1</code></td>
<td>
<p>code run points</p>
</td></tr>
<tr><td><code id="Ez.eqn9.supp_+3A_d2">D2</code></td>
<td>
<p>observation points</p>
</td></tr>
<tr><td><code id="Ez.eqn9.supp_+3A_h1">H1</code></td>
<td>
<p>regression function for D1</p>
</td></tr>
<tr><td><code id="Ez.eqn9.supp_+3A_h2">H2</code></td>
<td>
<p>regression function for D2</p>
</td></tr>
<tr><td><code id="Ez.eqn9.supp_+3A_phi">phi</code></td>
<td>
<p>hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user should always use <code>Ez.eqn9.supp()</code>, which is a wrapper
for <code>Ez.eqn9.supp.vector()</code>.  The forms differ in their treatment
of <code class="reqn">\theta</code>.  In the former, <code class="reqn">\theta</code> must be a
vector; in the latter, <code class="reqn">\theta</code> may be a matrix, in which
case <code>Ez.eqn9.supp.vector()</code> is applied to the rows.
</p>
<p>Note that <code>Ez.eqn9.supp.vector()</code> is vectorized in <code>x</code> but
not <code class="reqn">\theta</code> (if given a multi-row object,
<code>apply(theta,1,...)</code> is used to evaluate the function for each
row supplied).
</p>
<p>Function <code>Ez.eqn9.supp()</code> will take  multiple-row arguments for
<code>x</code> and <code>theta</code>.  The output will be a matrix, with rows
corresponding to the rows of <code>x</code> and columns corresponding to the
rows of <code>theta</code>.  See the third example below.
</p>
<p>Note that function <code>Ez.eqn9.supp()</code> determines whether there are
multiple values of <code class="reqn">\theta</code> by <code>is.vector(theta)</code>.  If
this returns <code>TRUE</code>, it is assumed that <code class="reqn">\theta</code> is a
single point in multidimensional parameter space; if <code>FALSE</code>, it
is assumed to be a matrix whose rows correspond to points in parameter
space.
</p>
<p>So if <code class="reqn">\theta</code> is one dimensional, calling
<code>Ez.eqn9.supp()</code> with a vector-valued <code class="reqn">\theta</code> will
fail because the function will assume that <code class="reqn">\theta</code> is a
single, multidimensional, point.  To get round this, use
<code>as.matrix(theta)</code>, which is not a vector; the rows are the (1D)
parameter values.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+tee">tee</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
Ez.eqn9.supp(x=x.toy,  theta=theta.toy, d=d.toy, D1=D1.toy,
         D2=D2.toy, H1=H1.toy,H2=H2.toy, phi=phi.toy)

Ez.eqn9.supp(x=D2.toy, theta=t.vec.toy,  d=d.toy, D1=D1.toy,
         D2=D2.toy, H1=H1.toy,H2=H2.toy, phi=phi.toy)

Ez.eqn9.supp(x=x.vec,  theta=t.vec.toy,  d=d.toy, D1=D1.toy,
         D2=D2.toy, H1=H1.toy,H2=H2.toy, phi=phi.toy)

</code></pre>

<hr>
<h2 id='H.fun'>H function</h2><span id='topic+H.fun'></span>

<h3>Description</h3>

<p>H.  See front page of KOHsupp.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>H.fun(theta, D1, D2, H1, H2, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="H.fun_+3A_theta">theta</code></td>
<td>
<p>parameters</p>
</td></tr>
<tr><td><code id="H.fun_+3A_d1">D1</code></td>
<td>
<p>matrix of code run points</p>
</td></tr>
<tr><td><code id="H.fun_+3A_d2">D2</code></td>
<td>
<p>matrix of observation points</p>
</td></tr>
<tr><td><code id="H.fun_+3A_h1">H1</code></td>
<td>
<p>Regressor function for D1</p>
</td></tr>
<tr><td><code id="H.fun_+3A_h2">H2</code></td>
<td>
<p>Regressor function for D2</p>
</td></tr>
<tr><td><code id="H.fun_+3A_phi">phi</code></td>
<td>
<p>hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
H.fun(theta=theta.toy, D1=D1.toy, D2=D2.toy, H1=H1.toy,
       H2=H2.toy, phi=phi.toy)

H.fun(theta=theta.toy, D1=D1.toy[1,,drop=FALSE], D2=D2.toy,
       H1=H1.toy, H2=H2.toy, phi=phi.toy)

H.fun(theta=theta.toy, D1=D1.toy[1,,drop=FALSE],
       D2=D2.toy[1,,drop=FALSE],
       H1=H1.toy, H2=H2.toy, phi=phi.toy)
</code></pre>

<hr>
<h2 id='h1.toy'>Basis functions</h2><span id='topic+h1.toy'></span><span id='topic+h2.toy'></span>

<h3>Description</h3>

<p>Basis functions for D1 and D2 respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h1.toy(x)
h2.toy(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="h1.toy_+3A_x">x</code></td>
<td>
<p>Vector of lat/long or lat/long and theta</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>h1()</code> operates on a vector: for dataframes, use
<code>H1.toy()</code> which is a wrapper for <code>apply(D1, 1, h1)</code>.
</p>
<p><strong>NB</strong> If the definition of <code>h1.toy()</code> or <code>h2.toy()</code> is
changed, then function <code>hbar.toy()</code> must be changed to match.
This cannot be done automatically, as the form of <code>hbar.toy()</code>
depends on the distribution of <code>X</code>.  The shibboleth is whether
<code>E_X()</code> commutes with <code>h_1()</code>; it does in this case but does
not in general (for example, consider
<code class="reqn">h(x,\theta)=c(1,x,x^2)</code> and <code class="reqn">X\sim
  N(m,V)</code>.  Then <code class="reqn">E_X(h(x,\theta))</code> will
be <code class="reqn">(1,m,m^2+V,\theta)</code>; note the V)
</p>


<h3>Value</h3>

<p>Returns basis functions of a vector; in the toy case, just prepend a
<code>1</code>.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+H1.toy">H1.toy</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
 h1.toy(D1.toy[1,])
</code></pre>

<hr>
<h2 id='H1.toy'>Basis functions for D1 and D2</h2><span id='topic+H1.toy'></span><span id='topic+H2.toy'></span>

<h3>Description</h3>

<p>Applies basis functions to rows of <code>D1</code> and <code>D2</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>H1.toy(D1)
H2.toy(D2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="H1.toy_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="H1.toy_+3A_d2">D2</code></td>
<td>
<p>Matrix of observation points</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix whose rows are the basis functions of the code run
points or observation points.  Function <code>H1.toy()</code> operates on
datasets like <code>D1.toy</code> (latlong and parameters) and function
<code>H2.toy()</code> operates on datasets like <code>D2.toy</code> (latlong only)
</p>


<h3>Note</h3>

<p>See package <span class="pkg">goldstein</span> for a less trivial example of <code>h()</code>.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+D1.toy">D1.toy</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
jj &lt;- extractor.toy(D1.toy)
x.star.toy &lt;- jj$x.star
t.vec.toy &lt;- jj$t.vec

H1.toy(D1=D1.toy)
H1.toy(D1.toy[1,,drop=FALSE])
H1.toy(D1.fun(x.star.toy , theta.toy)[1,,drop=FALSE])
H1.toy(D1.fun(x.star=x.toy,t.vec=theta.toy))
H1.toy(D1.fun(x.star=x.star.toy[1,],t.vec=t.vec.toy[1,]))
H1.toy(D1.fun(x.star=x.star.toy[1,],t.vec=t.vec.toy[1:2,]))

H2.toy(D2.toy)
H2.toy(t(x.toy))
</code></pre>

<hr>
<h2 id='hbar.fun.toy'>Toy example of hbar (section 4.2)</h2><span id='topic+hbar.fun.toy'></span>

<h3>Description</h3>

<p>A toy example of the expectation of h as per section 4.2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hbar.fun.toy(theta, X.dist, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hbar.fun.toy_+3A_theta">theta</code></td>
<td>
<p>Parameter set</p>
</td></tr>
<tr><td><code id="hbar.fun.toy_+3A_x.dist">X.dist</code></td>
<td>
<p>Distribution of variable inputs <code>X</code> as per section 4.2</p>
</td></tr>
<tr><td><code id="hbar.fun.toy_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if <code>h1.toy()</code> or <code>h2.toy()</code> change, then
<code>hbar.fun.toy()</code> will have to change too; see <code>?h1.toy</code> for an
example in which nonlinearity changes the form of <code>E.theta.toy()</code>
</p>


<h3>Value</h3>

<p>Returns a vector as per section 4.2 of KOH2001S
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+h1.toy">h1.toy</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
hbar.fun.toy(theta=theta.toy, X.dist=X.dist.toy, phi=phi.toy)
</code></pre>

<hr>
<h2 id='is.positive.definite'>Is a matrix positive definite?</h2><span id='topic+is.positive.definite'></span>

<h3>Description</h3>

<p>Returns <code>TRUE</code> if and only if a matrix is positive definite.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.positive.definite(a, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is.positive.definite_+3A_a">a</code></td>
<td>
<p>Matrix to be tested</p>
</td></tr>
<tr><td><code id="is.positive.definite_+3A_...">...</code></td>
<td>
<p>Extra arguments passed to <code>eigen()</code>, such as
<code>symmetric</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A wrapper for <code>eigen()</code> (a matrix is positive definite if all its
eigenvalues are positive).  This function is included for convenience only.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.positive.definite(diag(3),sym=TRUE)
is.positive.definite(diag(6)-0.1)
</code></pre>

<hr>
<h2 id='MH'>Very basic implementation of the Metropolis-Hastings algorithm</h2><span id='topic+MH'></span>

<h3>Description</h3>

<p>Very basic implementation of the Metropolis-Hastings algorithm using a
multivariate Gaussian proposal distribution.   Useful for sampling
from <code>p.eqn8.supp()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MH(n, start, sigma, pi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MH_+3A_n">n</code></td>
<td>
<p>Number of samples to take</p>
</td></tr>
<tr><td><code id="MH_+3A_start">start</code></td>
<td>
<p>Start value</p>
</td></tr>
<tr><td><code id="MH_+3A_sigma">sigma</code></td>
<td>
<p>Variance matrix for kernel</p>
</td></tr>
<tr><td><code id="MH_+3A_pi">pi</code></td>
<td>
<p>Functional proportional to the desired sampling pdf</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a <strong>basic</strong> implementation.  The proposal
distribution~<code class="reqn">q(X|Y)</code> is
<code class="reqn">q(\cdot|X)=N(X,\sigma^2)</code>
</p>


<h3>Value</h3>

<p>Returns a matrix whose rows are samples from <code class="reqn">\pi()</code>.  Note
that the first few rows will be &ldquo;burn-in&rdquo;, so should be
ignored
</p>


<h3>Note</h3>

<p>This function is a little slow because it is not vectorized.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li><p> W. R. Gilks et al 1996. <em>Markov Chain Monte Carlo in
practice</em>.  Chapman and Hall, 1996.    ISBN 0-412-05551-1
</p>
</li>
<li><p> N. Metropolis and others 1953. <em>Equation of state
calculations by fast computing machines</em>.  The Journal of Chemical
Physics, volume 21, number 6, pages 1087-1092
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+p.eqn8.supp">p.eqn8.supp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># First, a bivariate Gaussian:
A &lt;- diag(3) + 0.7
quad.form &lt;- function(M,x){drop(crossprod(crossprod(M,x),x))}
pi.gaussian &lt;- function(x){exp(-quad.form(A/2,x))}
x.gauss &lt;- MH(n=1000, start=c(0,0,0),sigma=diag(3),pi=pi.gaussian)
cov(x.gauss)/solve(A) # Should be a matrix of 1s.


# Now something a bit weirder:
pi.triangle &lt;- function(x){
  1*as.numeric( (abs(x[1])&lt;1.0) &amp; (abs(x[2])&lt;1.0) ) +
  5*as.numeric( (abs(x[1])&lt;0.5) &amp; (abs(x[2])&lt;0.5) ) *
    as.numeric(x[1]&gt;x[2])
}
x.tri &lt;- MH(n=100,start=c(0,0),sigma=diag(2),pi=pi.triangle)
plot(x.tri,main="Try with a higher n")


# Now a Gaussian mixture model:
pi.2gauss &lt;- function(x){
  exp(-quad.form(A/2,x)) +
  exp(-quad.form(A/2,x+c(2,2,2)))
}
x.2 &lt;- MH(n=100,start=c(0,0,0),sigma=diag(3),pi=pi.2gauss)
## Not run: p3d(x.2, theta=44,d=1e4,d0=1,main="Try with more points")


</code></pre>

<hr>
<h2 id='p.eqn4.supp'>Apostiori probability of psi1</h2><span id='topic+p.eqn4.supp'></span><span id='topic+p.equationn4.supp'></span>

<h3>Description</h3>

<p>Gives the probability of <code class="reqn">\psi_1</code>, given observations.
Equation 4 of the supplement
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p.eqn4.supp(D1, y, H1, include.prior=TRUE, lognormally.distributed, return.log, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="p.eqn4.supp_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="p.eqn4.supp_+3A_y">y</code></td>
<td>
<p>Vector of code outputs</p>
</td></tr>
<tr><td><code id="p.eqn4.supp_+3A_h1">H1</code></td>
<td>
<p>Regression function</p>
</td></tr>
<tr><td><code id="p.eqn4.supp_+3A_include.prior">include.prior</code></td>
<td>
<p>Boolean with default <code>TRUE</code> meaning to
return the likelihood multiplied by the aprior probability and <code>FALSE</code>
meaning to return the likelihood without the prior.</p>
</td></tr>
<tr><td><code id="p.eqn4.supp_+3A_lognormally.distributed">lognormally.distributed</code></td>
<td>
<p>Boolean; see <code>?prob.theta</code> for
details</p>
</td></tr>
<tr><td><code id="p.eqn4.supp_+3A_return.log">return.log</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return
the probability and <code>TRUE</code> meaning to return the logarithm of
the probability</p>
</td></tr>
<tr><td><code id="p.eqn4.supp_+3A_phi">phi</code></td>
<td>
<p>hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+W1">W1</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
p.eqn4.supp(D1=D1.toy, y=y.toy , H1=H1.toy, lognormally.distributed=TRUE,
phi=phi.toy)
</code></pre>

<hr>
<h2 id='p.eqn8.supp'>A postiori probability of hyperparameters</h2><span id='topic+p.eqn8.supp'></span><span id='topic+p.eqn8.supp.vector'></span>

<h3>Description</h3>

<p>Function to determine the a-postiori probability of hyperparameters
<code class="reqn">\rho</code>, <code class="reqn">\lambda</code> and <code class="reqn">\psi_2</code>,
given observations and <code class="reqn">\psi_1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p.eqn8.supp(theta, D1, D2, H1, H2, d, include.prior=FALSE,
lognormally.distributed=FALSE, return.log=FALSE, phi)
p.eqn8.supp.vector(theta, D1, D2, H1, H2, d, include.prior=FALSE,
lognormally.distributed=FALSE, return.log=FALSE, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="p.eqn8.supp_+3A_theta">theta</code></td>
<td>
<p>Parameters</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_d2">D2</code></td>
<td>
<p>Matrix of observation points</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_h1">H1</code></td>
<td>
<p>Regression function for D1</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_h2">H2</code></td>
<td>
<p>Regression function for D2</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_d">d</code></td>
<td>
<p>Vector of code output values and observations</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_include.prior">include.prior</code></td>
<td>
<p>Boolean, with <code>TRUE</code>
meaning to include the prior PDF for <code class="reqn">\theta</code> and default
<code>FALSE</code> meaning  return the likelihood, multiplied by an
undetermined constant</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_lognormally.distributed">lognormally.distributed</code></td>
<td>
<p>Boolean, with <code>TRUE</code> meaning to
assume prior is lognormal (see <code>prob.theta()</code> for more info)</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_return.log">return.log</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return
the probability; <code>TRUE</code> means to return the (natural) logarithm
of the answer</p>
</td></tr>
<tr><td><code id="p.eqn8.supp_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user should always use <code>p.eqn8.supp()</code>, which is a wrapper
for <code>p.eqn8.supp.vector()</code>.  The forms differ in their treatment
of <code class="reqn">\theta</code>.  In the former, <code class="reqn">\theta</code> must be a
vector; in the latter, <code class="reqn">\theta</code> may be a matrix, in which
case <code>p.eqn8.supp.vector()</code> is applied to the rows
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+W2">W2</a></code>,<code><a href="#topic+stage1">stage1</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
p.eqn8.supp(theta=theta.toy, D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy,
d=d.toy, phi=phi.toy)

## Now try using the true hyperparameters, and data directly drawn from
## the appropriate multivariate distn:

phi.true &lt;- phi.true.toy(phi=phi.toy)
jj &lt;- create.new.toy.datasets(D1.toy , D2.toy)
d.toy &lt;- jj$d.toy
p.eqn8.supp(theta=theta.toy, D1=D1.toy, D2=D2.toy, H1=H1.toy,
     H2=H2.toy, d=d.toy, phi=phi.true)


## Now try p.eqn8.supp() with a vector of possible thetas:
p.eqn8.supp(theta=sample.theta(n=11,phi=phi.true), D1=D1.toy,
     D2=D2.toy, H1=H1.toy, H2=H2.toy,  d=d.toy, phi=phi.true)

</code></pre>

<hr>
<h2 id='p.page4'>A postiori probability of hyperparameters</h2><span id='topic+p.page4'></span>

<h3>Description</h3>

<p>Function to determine a postiori probability of hyperparameters
<code class="reqn">\rho</code>, <code class="reqn">\lambda</code> and <code class="reqn">\psi_2</code>,
given observations and <code class="reqn">\psi_1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p.page4(D1, D2, H1, H2, V, y, z, E.theta, Edash.theta, extractor, include.prior=FALSE,
lognormally.distributed=FALSE, return.log=FALSE, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="p.page4_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="p.page4_+3A_d2">D2</code></td>
<td>
<p>Matrix of observation points</p>
</td></tr>
<tr><td><code id="p.page4_+3A_h1">H1</code></td>
<td>
<p>Basis function (vectorized)</p>
</td></tr>
<tr><td><code id="p.page4_+3A_h2">H2</code></td>
<td>
<p>Regression function for D2</p>
</td></tr>
<tr><td><code id="p.page4_+3A_v">V</code></td>
<td>
<p>Covariance matrix; default value of <code>NULL</code> results in
the function evaluating it (but this takes a long time, so supply
<code>V</code> if known)</p>
</td></tr>
<tr><td><code id="p.page4_+3A_y">y</code></td>
<td>
<p>Vector of code outputs</p>
</td></tr>
<tr><td><code id="p.page4_+3A_z">z</code></td>
<td>
<p>Vector of observation values</p>
</td></tr>
<tr><td><code id="p.page4_+3A_e.theta">E.theta</code></td>
<td>
<p>Expectation over theta</p>
</td></tr>
<tr><td><code id="p.page4_+3A_edash.theta">Edash.theta</code></td>
<td>
<p>Expectation over theta WRT <code class="reqn">E'</code></p>
</td></tr>
<tr><td><code id="p.page4_+3A_extractor">extractor</code></td>
<td>
<p>Function to extract independent variables and
parameters from D1</p>
</td></tr>
<tr><td><code id="p.page4_+3A_include.prior">include.prior</code></td>
<td>
<p>Boolean, with <code>TRUE</code>
meaning to include the prior PDF for <code class="reqn">\theta</code> and default
value of <code>FALSE</code> meaning to return the likelihood multiplied by an
undetermined constant</p>
</td></tr>
<tr><td><code id="p.page4_+3A_lognormally.distributed">lognormally.distributed</code></td>
<td>
<p>Boolean with <code>TRUE</code> meaning to assume
lognormality.  See <code>prob.psi1</code> for details</p>
</td></tr>
<tr><td><code id="p.page4_+3A_return.log">return.log</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return
the probability, and <code>TRUE</code> meaning to return the (natural)
logarithm of the probability (which is useful when considering very
small probabilities)</p>
</td></tr>
<tr><td><code id="p.page4_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+W2">W2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)

p.page4(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, V=NULL, y=y.toy,
z=z.toy,E.theta=E.theta.toy, Edash.theta=Edash.theta.toy, extractor=extractor.toy, phi=phi.toy)

## Now compare the above value with p.page4() calculated with phi
## differing only in psi2:

phi.toy.new &lt;- phi.change(phi.fun=phi.fun.toy, old.phi = phi.toy, psi2=c(8,8,8))

p.page4(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, V=V.toy, y=y.toy, z=z.toy,
E.theta=E.theta.toy, Edash.theta=Edash.theta.toy,
extractor=extractor.toy, phi=phi.toy.new)
## different!

</code></pre>

<hr>
<h2 id='phi.fun.toy'>Functions to create or change hyperparameters</h2><span id='topic+phi.fun.toy'></span><span id='topic+phi.change'></span>

<h3>Description</h3>

<p>Function to create (<code>phi.fun.toy</code>) or modify
(<code>phi.change</code>) toy hyperparameters <code class="reqn">\phi</code>
in a form suitable for passing to the other functions in the library.
</p>
<p>The user should never make <code class="reqn">\phi</code> by hand; always use one of
these functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phi.fun.toy(rho, lambda, psi1, psi1.apriori, psi2, psi2.apriori,
  theta.apriori)
phi.change(phi.fun, old.phi = NULL, rho = NULL, lambda = NULL,
          psi1 = NULL, psi1.apriori=NULL,  psi1.apriori.mean=NULL,
          psi1.apriori.sigma=NULL, psi2 = NULL, psi2.apriori=NULL,
          psi2.apriori.mean=NULL,  psi2.apriori.sigma=NULL,
          theta.apriori=NULL, theta.apriori.mean=NULL,
          theta.apriori.sigma=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phi.fun.toy_+3A_phi.fun">phi.fun</code></td>
<td>
<p>In <code>phi.change()</code>, the name of the function that 
creates the hyperparameters.  Use <code>phi.fun.toy()</code> for the toy
dataset
</p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_old.phi">old.phi</code></td>
<td>
<p>In function <code>phi.change()</code>, the hyperparameter
object <code class="reqn">\phi</code> to be modified
</p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_rho">rho</code></td>
<td>
<p>Correlation hyperparameter appearing in main equation
</p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_lambda">lambda</code></td>
<td>
<p>Noise hyperparameter
</p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi1">psi1</code></td>
<td>
<p>Roughness lengths hyperparameter for design matrix
<code>D1</code>.  Internal function <code>pdm.maker.psi1()</code> takes
<code>psi1</code> as an argument and returns <code>omega_x</code>,
<code>omega_t</code> and <code>sigma1squared</code>.
</p>
<p>Recall that <code class="reqn">\Omega_x</code> and <code class="reqn">Omega_t</code> are
arbitrary functions of <code class="reqn">\psi_1</code>.  In this case,
the values are <code>omega_x=psi1[1:2]</code>, <code>omega_t=psi1[3:4]</code>
and <code>sigma1squared=psi1[6]</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi1.apriori">psi1.apriori</code></td>
<td>
<p>A priori PDF for <code class="reqn">\psi_1</code>.  In the form
of a two element list with first element (<code>mean</code>) the mean and
second element (<code>sigma</code>) the covariance matrix; distribution of
the logarithms is assumed to be multivariate normal.  In the toy
example, the mean is a vector of length six (the first five are
<code class="reqn">\psi_1</code> and the sixth is for
<code class="reqn">\sigma_1^2</code>), and the variance is the
corresponding six-by-six matrix.  Use function <code>prob.psi1()</code> to
calculate the apriori probability density for a particular value of
<code class="reqn">\psi_1</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi1.apriori.mean">psi1.apriori.mean</code></td>
<td>
<p>In function <code>phi.change.toy()</code>, use this
argument to change just the mean of <code>psi1</code> (and leave the value
of <code>sigma</code> unchanged)</p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi1.apriori.sigma">psi1.apriori.sigma</code></td>
<td>
<p>In function <code>phi.change.toy()</code>, use
this argument to change just the variance matrix  of <code>psi1</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi2">psi2</code></td>
<td>
<p>Roughness lengths hyperparameter for <code>D2</code>.
</p>
<p>Internal function <code>pdm.maker.psi2()</code> takes <code>psi2</code> as an
argument and returns <code>omegastar_x</code> and <code>sigma2squared</code>.
In <code>phi.fun.toy()</code>, the values are <code>omegastar_x=psi2[1:2]</code>
and <code>sigma2squared=psi2[3]</code>.
</p>
<p>NB: function <code>stage2()</code> optimizes more than just <code>psi2</code>.
It simultaneously optimizes <code>psi2</code> and <code>lambda</code> and
<code>rho</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi2.apriori">psi2.apriori</code></td>
<td>
<p>A priori PDF for <code class="reqn">\psi_2</code> <strong>and</strong>
hyperparameters <code class="reqn">\rho</code> and <code class="reqn">\lambda</code> (in that
order). 
</p>
<p>As for <code>psi1.apriori</code>, this is in the form of a list with the
first element (<code>mean</code>) the mean and second element
(<code>sigma</code>) the covariance matrix; the logs are multivariate
normal.  In the toy example, the mean is a vector of length five.
The first and second elements of the mean are the apriori mean of
<code class="reqn">\rho</code> and <code class="reqn">\lambda</code> respectively; the third
and fourth elements are the apriori mean of <code class="reqn">\psi_2</code> (that
is, <code>x</code> and <code>y</code> respectively); and the fifth is the mean
of <code class="reqn">\sigma_2^2</code>.
</p>
<p>The second element of <code>phi.toy$psi2.apriori</code>, <code>sigma</code>, is
the corresponding four-by-four variance matrix.  Use function
<code>prob.psi2()</code> to calculate the apriori probability density of a
particular value of <code class="reqn">\psi_2</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi2.apriori.mean">psi2.apriori.mean</code></td>
<td>
<p>In <code>phi.change.toy()</code>, use to change
just the mean of <code>psi2</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_psi2.apriori.sigma">psi2.apriori.sigma</code></td>
<td>
<p>In
<code>phi.change.toy()</code>, use to change just the variance matrix of
<code>psi2</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_theta.apriori">theta.apriori</code></td>
<td>
<p>Apriori PDF for
<code class="reqn">\theta</code>.  As above, in the form of a list with elements
for the mean and covariance.  The distribution is multivariate
normal (NB: The distribution is multivariate normal and NOT
lognormal!  To be explicit: <code class="reqn">\log(\theta)</code> is
lognormally distributed).  Use function <code>prob.theta()</code> to
calculate the apriori probability density of a particular value of
<code class="reqn">\theta</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_theta.apriori.mean">theta.apriori.mean</code></td>
<td>
<p>In <code>phi.change.toy()</code>, use to change
just the mean of <code>theta</code></p>
</td></tr>
<tr><td><code id="phi.fun.toy_+3A_theta.apriori.sigma">theta.apriori.sigma</code></td>
<td>
<p>In <code>phi.change.toy()</code>,
use to change just the variance matrix of <code>theta</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this toy function contains within itself
<code>pdm.maker.toy()</code> which extracts <code>omega_x</code> and
<code>omega_t</code> and <code>sigma1squared</code> from <code>psi1</code>.
This will need to  be changed for real-world applications.
</p>
<p>Earlier versions of the package had <code>pdm.maker.toy()</code>
defined separately.
</p>


<h3>Value</h3>

<p>Returns a list of several elements:
</p>
<table role = "presentation">
<tr><td><code>rho</code></td>
<td>
<p>Correlation hyperparameter</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Noise hyperparameter</p>
</td></tr>   
<tr><td><code>psi1</code></td>
<td>
<p>Roughness lengths hyperparameter for <code>D1</code></p>
</td></tr>
<tr><td><code>psi1.apriori</code></td>
<td>
<p>Apriori mean and variance matrix for <code>psi1</code></p>
</td></tr>
<tr><td><code>psi2</code></td>
<td>
<p>Roughness lengths hyperparameter for <code>D2</code></p>
</td></tr>
<tr><td><code>psi2.apriori</code></td>
<td>
<p>Apriori mean and variance matrix for <code>psi2</code></p>
</td></tr>
<tr><td><code>theta.apriori</code></td>
<td>
<p>Apriori mean and variance matrix for the
parameters</p>
</td></tr>
<tr><td><code>omega_x</code></td>
<td>
<p>Positive definite matrix for the lat/long part of
<code>D1</code>, whose diagonal is <code>psi1[1:2]</code></p>
</td></tr>
<tr><td><code>omega_t</code></td>
<td>
<p>Positive definite matrix for the code parameters theta,
whose diagonal is <code>psi1[3:5]</code></p>
</td></tr>
<tr><td><code>omegastar_x</code></td>
<td>
<p>Positive definite matrix for use in equation 13 of
the supplement; represents distances between rows of <code>D2</code></p>
</td></tr>
<tr><td><code>sigma1squared</code></td>
<td>
<p>variance</p>
</td></tr>
<tr><td><code>sigma2squared</code></td>
<td>
<p>variance</p>
</td></tr>
<tr><td><code>omega_x.upper</code></td>
<td>
<p>Upper triangular Cholesky decomposition for <code>omega_x</code></p>
</td></tr>
<tr><td><code>omega_x.lower</code></td>
<td>
<p>Lower triangular Cholesky decomposition for <code>omega_x</code></p>
</td></tr>
<tr><td><code>omega_t.upper</code></td>
<td>
<p>Upper triangular Cholesky decomposition for <code>omega_t</code></p>
</td></tr>
<tr><td><code>omega_t.lower</code></td>
<td>
<p>Lower triangular Cholesky decomposition for <code>omega_t</code></p>
</td></tr>
<tr><td><code>a</code></td>
<td>
<p>Precalculated matrix for use in
<code>Edash.theta(...,fast.but.opaque=TRUE)</code></p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>Precalculated matrix for use in
<code>Edash.theta(...,fast.but.opaque=TRUE)</code></p>
</td></tr>
<tr><td><code>c</code></td>
<td>
<p>Precalculated scalar for use in
<code>ht.fun(...,fast.but.opaque=TRUE)</code></p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Precalculated scalarfor use in
<code>tt.fun()</code></p>
</td></tr>
<tr><td><code>A.upper</code></td>
<td>
<p>Upper triangular Cholesky decomposition for <code>A</code></p>
</td></tr>
<tr><td><code>A.lower</code></td>
<td>
<p>Lower triangular Cholesky decomposition for <code>A</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+toys">toys</a></code>,
<code><a href="#topic+H1.toy">H1.toy</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
phi.fun.toy(100,101,1:6,list(mean=rep(1,6),sigma=1+diag(6)),50:55,
list(mean=rep(0,4),sigma=0.1+diag(4)),
list(mean=0.1+(1:3),sigma=2.1+diag(3)))

phi.fun.toy(rho=1, lambda=1,
    psi1 = structure(c(1.1, 1.2, 1.3, 1.4, 1.5, 0.7),
            .Names = c("x", "y", "A","B", "C","s1sq")),
    psi1.apriori  = list(
             mean=rep(0,6), sigma=0.4+diag(6)),
             psi2=structure(c(2.1, 2.2), .Names = c("x","y")),
             psi2.apriori  = list(mean=rep(0,5),sigma=0.2+diag(5)),
             theta.apriori = list(mean=0.1+(1:3),sigma=2.1+diag(3))
)

data(toys)
phi.change(phi.fun=phi.fun.toy, old.phi = phi.toy, rho = 100)
phi.change(phi.fun=phi.fun.toy, old.phi = phi.toy,
     theta.apriori.sigma = 4*diag(3))

identical(phi.toy, phi.change(phi.fun=phi.fun.toy, old.phi=phi.toy))
</code></pre>

<hr>
<h2 id='prob.psi1'>A priori probability of psi1, psi2, and theta</h2><span id='topic+prob.psi1'></span><span id='topic+prob.psi2'></span><span id='topic+prob.theta'></span><span id='topic+sample.theta'></span>

<h3>Description</h3>

<p>Function to determine the a-priori probability of <code class="reqn">\psi_1</code>
and <code class="reqn">\psi_2</code> of the hyperparameters, and <code class="reqn">\theta</code>,
given the apriori means  and standard deviations.
</p>
<p>Function <code>sample.theta()</code> samples <code class="reqn">\theta</code> from its prior distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prob.psi1(phi,lognormally.distributed=TRUE)
prob.psi2(phi,lognormally.distributed=TRUE)
prob.theta(theta,phi,lognormally.distributed=FALSE)
sample.theta(n=1,phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prob.psi1_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
<tr><td><code id="prob.psi1_+3A_theta">theta</code></td>
<td>
<p>Parameters</p>
</td></tr>
<tr><td><code id="prob.psi1_+3A_lognormally.distributed">lognormally.distributed</code></td>
<td>
<p>Boolean variable with 
<code>FALSE</code> meaning to assume a Gaussian distribution and <code>TRUE</code>
meaning to use a lognormal distribution.</p>
</td></tr>
<tr><td><code id="prob.psi1_+3A_n">n</code></td>
<td>
<p>In function <code>sample.theta()</code>, the number of observations
to take</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions use package <code>mvtnorm</code> to calculate the
probability density under the assumption that the PDF is lognormal.
One implication would be that <code>phi$psi2.apriori$mean</code>
and <code>phi$psi1.apriori$mean</code> are the means of the
<strong>logarithms</strong> of the elements of <code>psi1</code> and <code>psi2</code>
(which are thus assumed to be positive).  The <code>sigma</code> matrix is
the covariance matrix of the logarithms as well.
</p>
<p>In these functions, interpretation of argument <code>phi</code> depends on
the value of Boolean argument <code>lognormally.distributed</code>.  Take
<code>prob.theta()</code> as an example.  If <code>lognormally.distributed</code>
is <code>TRUE</code>, then <code>log(theta)</code> is normally distributed with
mean <code>phi$theta.aprior$mean</code> and variance
<code>phi$theta.apriori$sigma</code>.  If <code>FALSE</code>, <code>theta</code> is
normally distributed with mean <code>phi$theta.aprior$mean</code> and
variance <code>phi$theta.apriori$sigma</code>.
</p>
<p>Interpretation of <code>phi$theta.aprior$mean</code> depends on the value of
<code>lognormally.distributed</code>: if <code>TRUE</code> it is the expected
value of <code>log(theta)</code>; if <code>FALSE</code>, it is the expectation of
<code>theta</code>.
</p>
<p>The reason that <code>prob.theta</code> has a different default value for
<code>lognormally.distributed</code> is that some elements of <code>theta</code>
might be negative, contraindicating a lognormal distribution
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+p.eqn4.supp">p.eqn4.supp</a></code>, <code><a href="#topic+stage1">stage1</a></code>, <code><a href="#topic+p.eqn8.supp">p.eqn8.supp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
prob.psi1(phi=phi.toy)
prob.psi2(phi=phi.toy)

prob.theta(theta=theta.toy,phi=phi.toy)

sample.theta(n=4,phi=phi.toy)

</code></pre>

<hr>
<h2 id='reality'>Reality</h2><span id='topic+reality'></span><span id='topic+computer.model'></span><span id='topic+model.inadequacy'></span><span id='topic+phi.true.toy'></span><span id='topic+phi.true'></span>

<h3>Description</h3>

  
<p>Function to compute reality, gratis <em>deus ex machina</em>.  Includes a
simple computer model that substitutes for a complex climate model,
and a simple function that substitutes for the base system, in this
case the climate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.inadequacy(X, set.seed.to.zero=TRUE, draw.from.prior=FALSE,
     export.true.hyperparameters=FALSE,phi=NULL)
computer.model(X, params=NULL, set.seed.to.zero=TRUE,
draw.from.prior=FALSE, export.true.hyperparameters=FALSE,phi=NULL)
phi.true.toy(phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reality_+3A_x">X</code></td>
<td>
<p>Observation point</p>
</td></tr>
<tr><td><code id="reality_+3A_params">params</code></td>
<td>
<p>Parameters needed by <code>computer.model()</code></p>
</td></tr>
<tr><td><code id="reality_+3A_set.seed.to.zero">set.seed.to.zero</code></td>
<td>
<p>Boolean, with the default value of <code>TRUE</code>
meaning to set the RNG seed to zero</p>
</td></tr>
<tr><td><code id="reality_+3A_draw.from.prior">draw.from.prior</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to
generate obsevations from the &ldquo;true&rdquo; values of the
parameters, and <code>TRUE</code> meaning to draw from the relevant
apriori distribution.</p>
</td></tr>
<tr><td><code id="reality_+3A_export.true.hyperparameters">export.true.hyperparameters</code></td>
<td>
<p>Boolean, with default value
of <code>FALSE</code> meaning to return the observed scalar.  Set to
<code>TRUE</code> to exercise omniscience and access the <em>true</em>
values of the parameters and hyperparameters.  Only the omnipotent
should set this variable, and only the omniscient may see its true
value.</p>
</td></tr>
<tr><td><code id="reality_+3A_phi">phi</code></td>
<td>
<p>In function <code>phi.true.toy()</code> the hyperparameters
<code class="reqn">\phi</code>.  Note that apriori distributions are unchanged
(they are irrelevant to omniscient beings).
</p>
<p>In functions <code>reality()</code> and <code>computer.model()</code>, the prior
distributions of the hyperparameters is passed via <code>phi</code> (so it
only elements <code>psi1.apriori</code> and <code>psi2.apriori</code> need to be set).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>reality()</code> provides <em>the</em> scalar value observed at
a point <code>x</code>.  Evaluation expense is zero; there is no overhead.
</p>
<p>(However, it does not compute &ldquo;reality&rdquo;: the function returns a
value subject to observational error <code class="reqn">N(0,\lambda)</code>
as per equation 5.  It might be better to call this function
<code>observation()</code>)
</p>
<p>Function <code>computer.model()</code> returns the output of a simple,
nonlinear computer model.
</p>
<p>Both functions documented here return a random variable drawn from an
appropriate (correlated) multivariate Gaussian distribution, and are
thus Gaussian processes.
</p>
<p>The approach is more explicit in the help pages of the emulator
package.  There, Gaussian processes are generated by directly invoking
<code>rmvnorm()</code> with a suitable correlation matrix
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+computer.model">computer.model</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
  data(toys)


  computer.model(X=D2.toy,params=theta.toy)
  computer.model(D1.toy)
  computer.model(X=x.toy, params=extractor.toy(D1.toy)$t.vec)


  phi.fix &lt;- phi.change(old.phi=phi.toy,
           psi1=c(1, 0.5, 1, 1, 0.5,  0.4),phi.fun=phi.fun.toy)
      #The values come from c(REAL.SCALES,REAL.SIGMA1SQUARED) as
      #seen in the sourcecode for computer.model().

  computer.model(D1.toy)   # use debug(computer.model) and examine
                           # var.matrix directly.  It should match the
                           #  output from V1():


          # first fix phi so that it has the correct values for psi1 (see the
          # section on psi1 in ?phi.fun.toy for how to get this):

   phi.fix &lt;- phi.change(old.phi=phi.toy,psi1=c(1, 0.5, 1.0, 1.0, 0.5,
   0.4), phi.fun=phi.fun.toy)
   V1(D1.toy,phi=phi.fix)





# What are the hyperparameters that were used to create reality?
phi.true.toy(phi=phi.toy)

# 
 computer.model(X=D2.toy,params=theta.toy,draw.from.prior=TRUE,phi=phi.toy)


</code></pre>

<hr>
<h2 id='stage1'>Stage 1,2 and 3 optimization on toy dataset</h2><span id='topic+stage1'></span><span id='topic+stage2'></span><span id='topic+stage3'></span>

<h3>Description</h3>

<p>Perform O'Hagan's three stage optimization on the toy dataset.  Function
<code>stage1()</code> and <code>stage2()</code> find the optimal values for
the hyperparameters and <code>stage3()</code> finds the optimal values for
the three parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stage1(D1, y, H1,  maxit,  trace=100, method="Nelder-Mead",
      directory = ".", do.filewrite=FALSE, do.print=TRUE,
      phi.fun, lognormally.distributed=FALSE, include.prior=TRUE, phi)
stage2(D1, D2, H1, H2, y, z, maxit, trace=100, method = "Nelder-Mead",
      directory = ".", do.filewrite=FALSE, do.print=TRUE,  extractor,
      phi.fun, E.theta, Edash.theta, isotropic=FALSE,
      lognormally.distributed = FALSE, include.prior = TRUE,
      use.standin = FALSE, rho.eq.1 = TRUE, phi) 
stage3(D1, D2, H1, H2, d, maxit, trace=100, method="Nelder-Mead",
      directory = ".", do.filewrite=FALSE, do.print=TRUE,
      include.prior = TRUE, lognormally.distributed=FALSE,
      theta.start=NULL, phi) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stage1_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations as passed to <code>optim()</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_trace">trace</code></td>
<td>
<p>Amount of information displayed, as passed to <code>optim()</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_d1">D1</code></td>
<td>
<p>Matrix whose rows are points at which code output is known</p>
</td></tr>
<tr><td><code id="stage1_+3A_d2">D2</code></td>
<td>
<p>Matrix whose rows are points at which observations were made</p>
</td></tr>
<tr><td><code id="stage1_+3A_h1">H1</code>, <code id="stage1_+3A_h2">H2</code></td>
<td>
<p>Regressor basis functions for <code>D1</code> and <code>D2</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_y">y</code></td>
<td>
<p>Code outputs.  Toy example is <code>y.toy</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_z">z</code></td>
<td>
<p>Observations.  Toy example is <code>z.toy</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_d">d</code></td>
<td>
<p>Data vector consisting of the code runs and observations</p>
</td></tr>
<tr><td><code id="stage1_+3A_extractor">extractor</code></td>
<td>
<p>extractor function for <code>D1</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_e.theta">E.theta</code>, <code id="stage1_+3A_edash.theta">Edash.theta</code></td>
<td>
<p>Expectation WRT theta, and dashed theta.
Toy examples are <code>E.theta.toy()</code> and <code>Edash.theta.toy()</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_phi.fun">phi.fun</code></td>
<td>
<p>Function to create hyperparameters; passed  (in
<code>stage1()</code> and <code>stage2()</code>) to <code>phi.change()</code>.  Toy
version is <code>phi.fun.toy()</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_method">method</code></td>
<td>
<p>Method argument passed to <code>optim()</code>; qv</p>
</td></tr>
<tr><td><code id="stage1_+3A_include.prior">include.prior</code></td>
<td>
<p>Boolean variable with default <code>TRUE</code> meaning
to include the prior distribution in the optimization process and
<code>FALSE</code> meaning to use an uniformative prior (effectively
uniform support).  This variable is passed to <code>p.eqn4.supp()</code>
for <code>stage1()</code>, <code>p.page4()</code> for <code>stage2()</code>, and
<code>p.eqn8.supp()</code>  for <code>stage3()</code></p>
</td></tr> 
<tr><td><code id="stage1_+3A_lognormally.distributed">lognormally.distributed</code></td>
<td>
<p>Boolean with <code>TRUE</code> meaning to use
a lognormal distn.  See <code>prob.theta</code> for details</p>
</td></tr>
<tr><td><code id="stage1_+3A_do.filewrite">do.filewrite</code></td>
<td>
<p>Boolean, with <code>TRUE</code> meaning to
save a <code>load</code>able file <code>stage[123].&lt;date&gt;</code>, containing the interim value of <code>phi</code>
and the corresponding optimand to <code>directory</code> at each evalution
of the optimizer.  If <code>FALSE</code>, don't write the files</p>
</td></tr>
<tr><td><code id="stage1_+3A_directory">directory</code></td>
<td>
<p>The directory to write files to; only matters if
<code>do.filewrite</code> is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="stage1_+3A_isotropic">isotropic</code></td>
<td>
<p>In function <code>stage2()</code>, Boolean with default
<code>FALSE</code> meaning to carry out a full optimization, and
<code>TRUE</code> meaning to restrict the scope to isotroic roughness
matrices.  See details section below</p>
</td></tr>
<tr><td><code id="stage1_+3A_do.print">do.print</code></td>
<td>
<p>Boolean, with default <code>TRUE</code> meaning to print
interim values of <code>phi</code> at each evaluation</p>
</td></tr>
<tr><td><code id="stage1_+3A_use.standin">use.standin</code></td>
<td>
<p>In <code>stage2()</code>, a Boolean argument, with
default <code>FALSE</code> meaning to use the real value for matrix
<code>V.temp</code>, and <code>TRUE</code> meaning to use a standing that is the
same size but contains fictitious values.  The only time to set
<code>use.standin</code> to <code>TRUE</code> is when debugging as it runs
several orders of magnitude faster</p>
</td></tr>
<tr><td><code id="stage1_+3A_rho.eq.1">rho.eq.1</code></td>
<td>
<p>Boolean, with default <code>TRUE</code> meaning to hold the
value of <code>rho</code> constant at one (1)</p>
</td></tr>
<tr><td><code id="stage1_+3A_theta.start">theta.start</code></td>
<td>
<p>In <code>stage3()</code>, the starting point of the
optimization with default <code>NULL</code> meaning to use the maximum
likelihood point of the apriori distribution (ie <code>phi$theta.apriori$mean</code>)</p>
</td></tr>
<tr><td><code id="stage1_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters.  Used as initial values for the
hyperparameters in the optimization routines</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The three functions documented here carry out the multi-stage
optimization detailed in KOH2001 (actually, KOH2001 only defined stage
1 and stage 2, which estimated the hyperparameters.  What is here
called &ldquo;<code>stage3()</code>&rdquo; estimates the true value of
<code class="reqn">\theta</code> given the hyperparameters).
</p>
<p><code>stage1()</code> carries out stage 1 of KOH2001 which is used to
estimate <code class="reqn">\psi_1</code> using optimization.
</p>
<p>In function <code>stage2()</code>, setting argument <code>isotropic</code> to
<code>TRUE</code> will force <code>phi$omegastar_x</code> to be a function of a
length one scalar.  The value of <code>phi$omegastar_x</code> used will
depend on <code>pdm.maker.psi2()</code> (an internal function appearing in
<code>hpa.fun.toy()</code>).  In <code>stage2()</code>, several kludges are made.
The initial conditions are provided by argument <code>phi</code>.  The
relevant part of this is <code>phi$psi2</code>.  
</p>
<p>Function <code>stage2()</code> estimates <code class="reqn">\psi_2</code> <strong>and</strong>
<code class="reqn">\rho</code> <strong>and</strong> <code class="reqn">\lambda</code>, using
optimization.  Note that <code class="reqn">\psi_2</code> includes
<code class="reqn">\sigma_2^2</code> in addition to <code>omegastar_X</code> (in
the toy case, <code class="reqn">\psi_2</code> has three elements: the first two are
the diagonal of <code>omegastar_x</code> and the third is
<code class="reqn">\sigma_2^2</code> <strong>but</strong> this information is
encoded in <code>phi.fun.toy()</code>, which changes from application to
application).
</p>
<p>Function <code>stage3()</code> attempts to find the maximum likelihood
estimate of <code class="reqn">\theta</code>, given hyperparameters and
observations, using optimization
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+toys">toys</a></code>,
<code><a href="#topic+phi.fun.toy">phi.fun.toy</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
stage1(D1=D1.toy,y=y.toy,H1=H1.toy, maxit=5, phi.fun=phi.fun.toy, phi=phi.toy)

##now try with a slightly bigger dataset:
##Examples below take a few minutes to run:

set.seed(0)
data(toys)
jj &lt;- create.new.toy.datasets(D1.toy , D2.toy)
y.toy &lt;- jj$y.toy
z.toy &lt;- jj$z.toy
d.toy &lt;- jj$d.toy

phi.toy.stage1 &lt;- stage1(D1=D1.toy, y=y.toy, H1=H1.toy, maxit=10, phi.fun=phi.fun.toy, phi=phi.toy)

phi.toy.stage2 &lt;- stage2(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy,
 y=y.toy, z=z.toy, extractor=extractor.toy,
phi.fun=phi.fun.toy, E.theta=E.theta.toy, Edash.theta=Edash.theta.toy,
maxit=3, phi=phi.toy.stage1)

stage3(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, d=d.toy, maxit=3, phi=phi.toy.stage2)

# Now try with the true values of the hyperparameters:
phi.true &lt;- phi.true.toy(phi=phi.toy)

stage3(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, d=d.toy, maxit=3, phi=phi.true)

</code></pre>

<hr>
<h2 id='symmetrize'>Symmetrize an upper triangular matrix</h2><span id='topic+symmetrize'></span>

<h3>Description</h3>

<p>Symmetrize an upper triangular matrix by copying the upper triangular
elements into the lower triangular places
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symmetrize(a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="symmetrize_+3A_a">a</code></td>
<td>
<p>Upper triangular matrix to be symmetrized</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Also works for lower triangular matrices
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>Examples</h3>

<pre><code class='language-R'>jj &lt;- matrix(rnorm(50),10,5)
X &lt;- crossprod(jj,jj)    # X has a Wishart distribution (and in
                         # particular is positive definite)

chol(X)
symmetrize(chol(X))
</code></pre>

<hr>
<h2 id='tee'>Auxiliary functions for equation 9 of the supplement</h2><span id='topic+tee'></span><span id='topic+h.fun'></span>

<h3>Description</h3>

<p>Returns a vector whose elements are the &ldquo;distances&rdquo; from a point
to the observations and code run points (<code>tee()</code>); and basis
functions for use in <code>Ez.eqn9.supp()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tee(x, theta, D1, D2, phi)
h.fun(x, theta, H1, H2, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tee_+3A_x">x</code></td>
<td>
<p>Point from which distances are calculated</p>
</td></tr>
<tr><td><code id="tee_+3A_theta">theta</code></td>
<td>
<p>Value of parameters</p>
</td></tr>
<tr><td><code id="tee_+3A_d1">D1</code>, <code id="tee_+3A_d2">D2</code></td>
<td>
<p>Design matrices of code run points and field observation
points respectively (<code>tee()</code>)</p>
</td></tr>
<tr><td><code id="tee_+3A_h1">H1</code>, <code id="tee_+3A_h2">H2</code></td>
<td>
<p>Basis functions for eta and model inadequacy term
respectively (<code>h.fun()</code>)</p>
</td></tr>
<tr><td><code id="tee_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Equation 9 of the supplement is identical to equation 10 of KOH2001.
</p>
<p>Function <code>h.fun()</code> returns the first of the subsidiary equations
in equation 9 of the supplement and function <code>tee()</code> returns the
second (NB: do not confuse this with functions <code>t1bar()</code> and
<code>t2bar()</code> which are internal to <code>EK.eqn10.supp()</code>)
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+Ez.eqn9.supp">Ez.eqn9.supp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
tee(x=x.toy, theta=theta.toy, D1=D1.toy, D2=D2.toy, phi=phi.toy)


# Now some vectorized examples:
jj &lt;- rbind(x.toy , x.toy , x.toy+0.01,x.toy+1,x.toy*10)

tee(x=jj, theta=theta.toy, D1=D1.toy, D2=D2.toy, phi=phi.toy)
h.fun(x=jj, theta=theta.toy, H1=H1.toy, H2=H2.toy, phi=phi.toy)

</code></pre>

<hr>
<h2 id='toys'>Toy datasets</h2><span id='topic+D1.toy'></span><span id='topic+D2.toy'></span><span id='topic+d.toy'></span><span id='topic+phi.toy'></span><span id='topic+theta.toy'></span><span id='topic+t.vec.toy'></span><span id='topic+toys'></span><span id='topic+x.toy'></span><span id='topic+x.toy2'></span><span id='topic+x.vec'></span><span id='topic+y.toy'></span><span id='topic+z.toy'></span><span id='topic+V.toy'></span><span id='topic+X.dist.toy'></span>

<h3>Description</h3>

<p>Toy datasets that illustrate the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(toys)
  D1.toy
  D2.toy
  d.toy
  phi.toy
  theta.toy
  V.toy
  X.dist.toy
</code></pre>


<h3>Format</h3>

<p>The <code>D1.toy</code> matrix is 8 rows of code run points, with five
columns.  The first two columns are the lat and long and the next
three are parameter values.
</p>
<p>The <code>D2.toy</code> matrix is five rows of observations on two
variables, <code>x</code> and <code>y</code> which are styled
&ldquo;latitude and longitude&rdquo;.
</p>
<p><code>d.toy</code> is the &ldquo;data&rdquo; vector consisting of length 13: elements
1-8 are code runs and elements 9-13 are observations.
</p>
<p><code>theta.toy</code> is a vector of length three that is a working example
of <code class="reqn">\theta</code>.  The parameters are designed to work with
<code>computer.model()</code>.
</p>
<p><code>t.vec.toy</code> is a matrix of eight rows and three columns.  Each
row specifies a value for <code class="reqn">\theta</code>.  The eight rows
correspond to  eight code runs.
</p>
<p><code>x.toy</code> and <code>x.toy2</code> are vectors of length two that gives a
sample point at which observations may be made (or the code run).
The gloss of the two elements is latitude and longitude.
</p>
<p><code>x.vec</code> is a matrix whose rows are reasonable x values but
<em>not</em> those in <code>D2.toy</code>.
</p>
<p><code>y.toy</code> is a vector of length eight.  Each element corresponds to
the output from a code run at each of the rows of <code>D1.toy</code>.
</p>
<p><code>z.toy</code> is a vector of length five.  Each element corresponds to
a measurement at each of the rows of <code>D2.toy</code>.
</p>
<p><code>V.toy</code> is a five by five variance-covariance matrix for the toy
datasets.
</p>
<p><code>X.dist.toy</code> is a toy example of a distribution of <code>X</code> for
use in calibrated uncertainty analysis, section 4.2.
</p>
<p><strong>Brief description of toy functions fully documented under their own manpage</strong>
</p>
<p>Function <code>create.new.toy.datasets()</code> creates new toy datasets
with any number of observations and code runs.
</p>
<p>Function <code>E.theta.toy()</code> returns expectation of <code>H(D)</code> with
respect to <code class="reqn">\theta</code>; <code>Edash.theta.toy()</code> returns
expectation with respect to <code class="reqn">E'</code>.
</p>
<p>Function <code>extractor.toy()</code>  extracts <code>x.star.toy</code>
and <code>t.vec.toy</code> from <code>D2</code>; toy example needed because the
extraction differs from case to case.
</p>
<p>Function <code>H1.toy()</code> applies basis functions to rows of <code>D1</code>
and <code>D2</code>
</p>
<p>Function <code>phi.fun.toy()</code> creates a hyperparameter object such as
<code>phi.toy</code> in a form suitable for passing to the other functions
in the library.
</p>
<p>Function <code>phi.change.toy()</code> modifies the hyperparameter object.
</p>
<p><strong>See the helpfiles listed in the &ldquo;see also&rdquo; section
below</strong>
</p>


<h3>Details</h3>

<p>All toy datasets are documented here.  There are also several toy
functions that are needed for a toy problem; these are documented
separately (they are too diverse to document fully in a single
manpage).  Nevertheless a terse summary  for each toy function
is provided on this page.  All toy functions in the package are listed
under &ldquo;See Also&rdquo;.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+create.new.toy.datasets">create.new.toy.datasets</a></code>,
<code><a href="#topic+E.theta.toy">E.theta.toy</a></code>,
<code><a href="#topic+extractor.toy">extractor.toy</a></code>,
<code><a href="#topic+H1.toy">H1.toy</a></code>,
<code><a href="#topic+phi.fun.toy">phi.fun.toy</a></code>,
<code><a href="#topic+stage1">stage1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
D1.toy
extractor.toy(D1.toy)

D2.fun(theta=theta.toy , D2=D2.toy)
D2.fun(theta=theta.toy,D2=D2.toy[1,,drop=FALSE])

library("emulator")
corr.matrix(D1.toy,scales=rep(1,5))
corr.matrix(D1.toy, pos.def.matrix=diag(5))

</code></pre>

<hr>
<h2 id='tt.fun'>Integrals needed in KOH2001</h2><span id='topic+tt.fun'></span><span id='topic+ht.fun'></span><span id='topic+hh.fun'></span><span id='topic+t.fun'></span>

<h3>Description</h3>

<p>Calculates the three integrals needed for <code>V</code>, under the
restrictions specified in the KOH2001 supplement
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tt.fun(D1, extractor, x.i, x.j,  test.for.symmetry=FALSE, method=1, phi)
ht.fun(x.i, x.j, D1, extractor,  Edash.theta,  H1, fast.but.opaque=TRUE,
x.star=NULL, t.vec=NULL, phi) 
hh.fun(x.i, x.j,  H1, E.theta,  phi)
t.fun(x, D1, extractor,  phi) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tt.fun_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_h1">H1</code></td>
<td>
<p>regression basis functions for <code>D1</code></p>
</td></tr>
<tr><td><code id="tt.fun_+3A_extractor">extractor</code></td>
<td>
<p>Function to extract <code>x.star</code> and <code>t.vec</code>
from <code>D1</code></p>
</td></tr>
<tr><td><code id="tt.fun_+3A_x">x</code></td>
<td>
<p>Lat and long of a point in <code>t.fun()</code> (eg <code>D2[1,]</code>)</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_x.i">x.i</code></td>
<td>
<p>Lat and long of first point (eg <code>D2[1,]</code>)</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_x.j">x.j</code></td>
<td>
<p>Lat and long of second point (eg <code>D2[2,]</code>)</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_theta">theta</code></td>
<td>
<p>parameters</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_edash.theta">Edash.theta</code></td>
<td>
<p>Function to return expectation of <code>H</code> with respect
to the alternative distribution of <code class="reqn">\theta</code>;
<code>Edash.theta.toy</code> is the example for the toy dataset</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_e.theta">E.theta</code></td>
<td>
<p>Function to return expectation of <code>H</code> with respect
to <code class="reqn">\theta</code></p>
</td></tr>
<tr><td><code id="tt.fun_+3A_test.for.symmetry">test.for.symmetry</code></td>
<td>
<p>In <code>tt.fun()</code>, Boolean with <code>TRUE</code>
meaning to calculate each element of <code class="reqn">C</code> explicitly.  If
<code>FALSE</code>, then calculate only the elements of <code class="reqn">C</code> that
lie on or over the diagonal and use the fact that <code class="reqn">C</code> is
symmetric to calculate the other matrix elements.  For <code class="reqn">n</code>
observations, this means <code class="reqn">n(n+1)/2</code> evaluations,
compared with <code class="reqn">n^2</code> for the full case.
</p>
<p>Set this argument to <code>TRUE</code> only when debugging, or testing
accuracy.</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_fast.but.opaque">fast.but.opaque</code></td>
<td>
<p>In <code>ht.fun()</code>, Boolean with default
<code>TRUE</code> meaning to pass some precalculated results as
arguments, to save time.  Set this argument to <code>FALSE</code> only
when debugging.</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_x.star">x.star</code></td>
<td>
<p>In <code>ht.fun()</code>, value of <code class="reqn">x^*</code> (required
only if <code>fast.but.opaque</code> is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_t.vec">t.vec</code></td>
<td>
<p>In <code>ht.fun()</code>, value of <code class="reqn">t</code> (required
only if <code>fast.but.opaque</code> is <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_method">method</code></td>
<td>
<p>In <code>tt.fun()</code>, zero means use the old method and
nonzero means use the new method.  The new method is faster, but
the code is harder to understand.  The two methods should give
identical results.</p>
</td></tr>
<tr><td><code id="tt.fun_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The four functions return integrals representing means taken over
<code>theta</code>.  To wit:
</p>

<ul>
<li><p> Function <code>tt.fun()</code> evaluates </p>
<p style="text-align: center;"><code class="reqn">\int
  t(x_j,\theta)t(x_i,\theta)^Tp(\theta)d\theta</code>
</p>
<p>  and is used in
<code>V.fun()</code>.  Note that this function is symmetric in <code class="reqn">x_i</code>
and <code class="reqn">x_j</code>.
</p>
</li>
<li><p> Function <code>ht.fun()</code> evaluates </p>
<p style="text-align: center;"><code class="reqn">\int
  h_1(x_j,\theta)t(x_i,\theta)^Tp(\theta)d\theta</code>
</p>
<p> and is used in
<code>V.fun()</code>.  Note that this function is <strong>not</strong> symmetric in
<code class="reqn">x_i</code> and <code class="reqn">x_j</code>.
</p>
</li>
<li><p> Function
<code>hh.fun()</code> evaluates </p>
<p style="text-align: center;"><code class="reqn">\int
  h_1(x_j,\theta)h_1(x_i,\theta)^Tp(\theta)d\theta</code>
</p>
<p> and is used in
<code>V.fun()</code>.  Note that this function is symmetric in <code class="reqn">x_i</code>
and <code class="reqn">x_j</code>.
</p>
</li>
<li><p> Function <code>t.fun()</code> evaluates
</p>
<p style="text-align: center;"><code class="reqn">\int
  t(x_i,\theta)^Tp(\theta)d\theta=
  \int c_1\left( (x_i,\theta),(x_j^*,t_j)\right)p(\theta)\,d\theta
</code>
</p>

<p>using the formula </p>
<p style="text-align: center;"><code class="reqn">
  \sigma_1^2\left|I+2V_\theta\Omega_x\right|^{-1/2}
  \exp\left\{
  -\left(x_i-x_j^*\right)^T\Omega_x\left(x_i-x_j^*\right)
  \right\}\times
  \exp\left\{
  -\left(m_\theta-t_j\right)^T
  \left(2V_\theta+\Omega_t^{-1}\right)^{-1}
  \left(m_\theta-t_j\right)\right\}.
</code>
</p>

<p>It is used in <code>Ez_eq7.supp()</code>.  NB: do not confuse
this function with <code>tee()</code>, which is different.
</p>
</li></ul>

<p>These functions are not generally of much interest to the end user; they
are called by <code>V.fun()</code>.  They are defined separately as a
debugging aid, and to simplify the structure of <code>V.fun()</code>.
</p>


<h3>Value</h3>

<p>Each function returns a matrix as described in KOH2001
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+V.fun">V.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)

tt.fun(D1=D1.toy, extractor=extractor.toy, x.i=D2.toy[1,],
    x.j=D2.toy[2,],  phi=phi.toy)

ht.fun(x.i=D2.toy[1,], x.j=D2.toy[2,], D1=D1.toy,
    extractor=extractor.toy, 
    Edash.theta=Edash.theta.toy, H1=H1.toy, fast.but.opaque=FALSE, phi=phi.toy)

ht.fun(x.i=D2.toy[1,], x.j=D2.toy[2,], D1=D1.toy,
    extractor=extractor.toy, 
    Edash.theta=Edash.theta.toy, H1=H1.toy, fast.but.opaque=TRUE,
    x.star=extractor.toy(D1.toy)$x.star, t.vec=extractor.toy(D1.toy)$t.vec,
    phi=phi.toy)



hh.fun(x.i=D2.toy[1,], x.j=D2.toy[2,],
    H1=H1.toy, E.theta=E.theta.toy,  phi=phi.toy)

t.fun(x=x.toy, D1=D1.toy, extractor=extractor.toy, phi=phi.toy)
</code></pre>

<hr>
<h2 id='V.fun'>Variance matrix for observations</h2><span id='topic+V.fun'></span>

<h3>Description</h3>

<p>Determines the variance/covariance matrix for the observations and code
run points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>V.fun(D1, D2, H1, H2,  extractor,
E.theta, Edash.theta, give.answers=FALSE, test.for.symmetry=FALSE, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="V.fun_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="V.fun_+3A_d2">D2</code></td>
<td>
<p>Matrix of observation points</p>
</td></tr>
<tr><td><code id="V.fun_+3A_h1">H1</code></td>
<td>
<p>Regression function for <code>D1</code></p>
</td></tr>
<tr><td><code id="V.fun_+3A_h2">H2</code></td>
<td>
<p>Regression function for <code>D2</code></p>
</td></tr>
<tr><td><code id="V.fun_+3A_extractor">extractor</code></td>
<td>
<p>Function to extract <code>x.star</code> and <code>t.vec</code>
from <code>D1</code></p>
</td></tr>
<tr><td><code id="V.fun_+3A_edash.theta">Edash.theta</code></td>
<td>
<p>Function to return expectation of <code>H</code> with respect
to the alternative distribution of <code class="reqn">\theta</code>;
<code>Edash.theta.toy</code> is the example for the toy dataset</p>
</td></tr>
<tr><td><code id="V.fun_+3A_e.theta">E.theta</code></td>
<td>
<p>Expectation of <code>h</code> WRT theta over the apriori
distribution.  Note that this function must be updated if <code>h1()</code> changes.</p>
</td></tr>
<tr><td><code id="V.fun_+3A_give.answers">give.answers</code></td>
<td>
<p>Boolean (defaulting to <code>FALSE</code>) with
<code>TRUE</code> meaning to return a list whose elements are <code>V</code> and
its constituent parts, viz <code>line1</code> to <code>line6</code>.  This
argument is used mainly for debugging.</p>
</td></tr>
<tr><td><code id="V.fun_+3A_test.for.symmetry">test.for.symmetry</code></td>
<td>
<p>Boolean with <code>TRUE</code> meaning to
calculate each element of <code class="reqn">C</code> explicitly, and default
<code>FALSE</code> meaning to calculate only the elements of <code class="reqn">C</code>
that lie on or over the diagonal and use the fact that <code class="reqn">C</code>
is symmetric to calculate the other matrix elements.  For <code class="reqn">n</code>
observations, this means <code class="reqn">n(n+1)/2</code> evaluations, compared with
<code class="reqn">n^2</code> for the full case.  The time saving is considerable, even
for small matrices.
</p>
<p>Set this argument to <code>TRUE</code> only when debugging, or testing
accuracy</p>
</td></tr> 
<tr><td><code id="V.fun_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See KOH2001 for full details on page 3 of the supplement
</p>


<h3>Value</h3>

<p>If <code>give.answers</code> is the default value of <code>FALSE</code>,
returns a matrix of covariances for use in <code>p.page4()</code>.
</p>
<p>If <code>give.answers</code> is <code>TRUE</code>, returns a named list of (currently)
17 elements.  Elements one to six are lines one to six respectively from
page 3 of the supplement; subsequent lines give intermediate steps in
the calculation.  The final element is the matrix is the covariances
as returned when <code>give.answers</code> is <code>FALSE</code>.
</p>


<h3>Note</h3>

<p>This function takes a long time to run</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+tt.fun">tt.fun</a></code>,<code><a href="#topic+p.page4">p.page4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
(jj &lt;-V.fun(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, 
  extractor=extractor.toy, 
  Edash.theta=Edash.theta.toy,
  E.theta=E.theta.toy,  phi=phi.toy))


## Now note that V.fun() changes with the PRIOR used for theta:
phi.different.theta &lt;-  phi.change(old.phi=phi.toy,
     theta.apriori.mean=c(100,100,100),phi.fun=phi.fun.toy)
V.fun(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, 
  extractor=extractor.toy, 
  Edash.theta=Edash.theta.toy,
  E.theta=E.theta.toy,  phi=phi.different.theta)
## different!


## Now compare jj above with V.fun() calculated with
## different phi2:

phi.toy.new &lt;- phi.change(phi.fun=phi.fun.toy, old.phi = phi.toy, psi2=c(8,8,8))

V.fun(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, 
  extractor=extractor.toy, 
  Edash.theta=Edash.theta.toy,
  E.theta=E.theta.toy,  phi=phi.toy.new)

## different!



## Not run: 
data(toys)
set.seed(0)
jj &lt;- create.new.toy.datasets(D1=D1.toy , D2=D2.toy)
y.toy &lt;- jj$y.toy
z.toy &lt;- jj$z.toy
d.toy &lt;- jj$d.toy

v.fun &lt;- function(...){V.fun(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy, 
     extractor=extractor.toy, Edash.theta=Edash.theta.toy,
     E.theta=E.theta.toy, phi=phi.toy, give=TRUE)}

Rprof(file="~/f.txt");ignore &lt;- v.fun();Rprof(file=NULL)
system("cd ; R CMD Rprof ~/f.txt &gt; ~/ff.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='V1'>Distance matrix</h2><span id='topic+V1'></span>

<h3>Description</h3>

<p>Gives the distance matrix between rows of D1 and D1 (or, if supplied,
another matrix)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>V1(D1,  other = NULL, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="V1_+3A_d1">D1</code></td>
<td>
<p>Matrix of code run points</p>
</td></tr>
<tr><td><code id="V1_+3A_other">other</code></td>
<td>
<p>Second matrix to compute distances to.  If <code>NULL</code>,
use the first supplied matrix</p>
</td></tr>
<tr><td><code id="V1_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+V2">V2</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
V1(D1=D1.toy,  other=NULL,   phi=phi.toy)
V1(D1=D1.toy[1,,drop=FALSE], other=NULL, phi=phi.toy)

V1(D1=D1.toy,  other=D1.toy[1:3,],   phi=phi.toy)

V1(D1=D1.toy,other=D1.fun(x.star=x.vec,t.vec=theta.toy),phi=phi.toy)

</code></pre>

<hr>
<h2 id='V2'>distance between observation points</h2><span id='topic+V2'></span>

<h3>Description</h3>

<p>distance between observation points
</p>


<h3>Usage</h3>

<pre><code class='language-R'>V2(x, other = NULL,  phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="V2_+3A_x">x</code></td>
<td>
<p>Matrix whose rows are observation points</p>
</td></tr>
<tr><td><code id="V2_+3A_other">other</code></td>
<td>
<p>Second matrix; if <code>NULL</code>, use x</p>
</td></tr>
<tr><td><code id="V2_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns the variance matrix of observations of the real
process <code class="reqn">z</code> at points
<code class="reqn">D_2=\left\{x_1,\ldots,x_n\right\}</code>.
</p>
<p>It appears in the lower right corner of the variance matrix on the
bottom of page 1 of the supplement, calculated by function
<code>Vd()</code>. 
</p>
<p>It is also used in functions <code>Cov.eqn9.supp()</code> and
<code>V.fun()</code>.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+V1">V1</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
V2(D2.toy,other=NULL, phi=phi.toy)
V2(D2.toy,x.vec,phi=phi.toy)
</code></pre>

<hr>
<h2 id='Vd'>Variance matrix for d</h2><span id='topic+Vd'></span>

<h3>Description</h3>

<p>Variance matrix for d, as per the bottom of page 1 of the supplement
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Vd(D1, D2, theta, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Vd_+3A_d1">D1</code></td>
<td>
<p>matrix of code run points</p>
</td></tr>
<tr><td><code id="Vd_+3A_d2">D2</code></td>
<td>
<p>matrix of observation points</p>
</td></tr>
<tr><td><code id="Vd_+3A_theta">theta</code></td>
<td>
<p>Parameters</p>
</td></tr>
<tr><td><code id="Vd_+3A_phi">phi</code></td>
<td>
<p>hyperparameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+H.fun">H.fun</a></code>,<code><a href="#topic+V1">V1</a></code>,<code><a href="#topic+V2">V2</a></code>,<code><a href="#topic+C1">C1</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
Vd(D1=D1.toy, D2=D2.toy, theta=theta.toy, phi=phi.toy)
</code></pre>

<hr>
<h2 id='W'>covariance matrix for beta</h2><span id='topic+W'></span>

<h3>Description</h3>

<p>Covariance matrix of beta given theta, phi, d
</p>


<h3>Usage</h3>

<pre><code class='language-R'>W(D1, D2, H1, H2, theta, det=FALSE, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="W_+3A_d1">D1</code></td>
<td>
<p>Matrix whose rows are code run points</p>
</td></tr>
<tr><td><code id="W_+3A_d2">D2</code></td>
<td>
<p>Matrix whose rows are  observation points</p>
</td></tr>
<tr><td><code id="W_+3A_h1">H1</code></td>
<td>
<p>regression function</p>
</td></tr>
<tr><td><code id="W_+3A_h2">H2</code></td>
<td>
<p>regression function</p>
</td></tr>
<tr><td><code id="W_+3A_theta">theta</code></td>
<td>
<p>parameters</p>
</td></tr>
<tr><td><code id="W_+3A_det">det</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return the
covariance matrix, and <code>TRUE</code> meaning to return its determinant.</p>
</td></tr>
<tr><td><code id="W_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is defined between equations 2 and 3 of the
supplement.  It is used in functions <code>betahat.fun.koh()</code>,
<code>p.eqn8.supp()</code>, and <code>p.joint()</code>.
</p>
<p>Returns
</p>
<p style="text-align: center;"><code class="reqn">
    {\mathbf W} (\theta)=
    \left(
         {\mathbf H}(\theta)^T {\mathbf V}_d(\theta)^{-1} {\mathbf H}(\theta)
    \right)^{-1}
  </code>
</p>

<p>If only the determinant is required, setting argument <code>det</code> to
<code>TRUE</code> is faster than using <code>det(W(..., det=FALSE))</code>, as the
former avoids an unnecessary use of <code>solve()</code>.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betahat.fun.koh">betahat.fun.koh</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
W(D1=D1.toy, D2=D2.toy, H1=H1.toy, H2=H2.toy,  theta=theta.toy, phi=phi.toy)
</code></pre>

<hr>
<h2 id='W1'>Variance matrix for beta1hat</h2><span id='topic+W1'></span>

<h3>Description</h3>

<p>returns the variance-covariance matrix for the estimate of beta1hat
</p>


<h3>Usage</h3>

<pre><code class='language-R'>W1(D1, H1, det=FALSE, phi)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="W1_+3A_d1">D1</code></td>
<td>
<p>matrix of code points</p>
</td></tr>
<tr><td><code id="W1_+3A_h1">H1</code></td>
<td>
<p>Basis function generator</p>
</td></tr>
<tr><td><code id="W1_+3A_phi">phi</code></td>
<td>
<p>Hyperparameters</p>
</td></tr>
<tr><td><code id="W1_+3A_det">det</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return the
matrix, and <code>TRUE</code> meaning to return its determinant only</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If only the determinant is required, setting argument <code>det</code> to
<code>TRUE</code> is faster than using <code>det(W1(...,det=FALSE))</code>, as the
former avoids an unnecessary use of <code>solve()</code>.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+beta1hat.fun">beta1hat.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
W1(D1=D1.toy, H1=H1.toy,  phi=phi.toy)
</code></pre>

<hr>
<h2 id='W2'>variance matrix for beta2</h2><span id='topic+W2'></span>

<h3>Description</h3>

<p>Variance matrix for beta2 as per page 4 of the supplement
</p>


<h3>Usage</h3>

<pre><code class='language-R'>W2(D2, H2, V, det=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="W2_+3A_d2">D2</code></td>
<td>
<p>matrix of observation points</p>
</td></tr>
<tr><td><code id="W2_+3A_h2">H2</code></td>
<td>
<p>regression function</p>
</td></tr>
<tr><td><code id="W2_+3A_v">V</code></td>
<td>
<p>Overall covariance matrix</p>
</td></tr>
<tr><td><code id="W2_+3A_det">det</code></td>
<td>
<p>Boolean, with default <code>FALSE</code> meaning to return the
matrix, and <code>TRUE</code> meaning to return its determinant only</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If only the determinant is required, setting argument <code>det</code> to
<code>TRUE</code> is faster than using <code>det(W2(...,det=FALSE))</code>, as the
former avoids an unnecessary use of <code>solve()</code>
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>


<ul>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001. <em>Bayesian
calibration of computer models</em>.  Journal of the Royal Statistical
Society B, 63(3) pp425-464
</p>
</li>
<li>
<p>M. C. Kennedy and A. O'Hagan 2001.  <em>Supplementary details on
Bayesian calibration of computer models</em>, Internal report, University
of Sheffield.  Available at
<a href="http://www.tonyohagan.co.uk/academic/ps/calsup.ps">http://www.tonyohagan.co.uk/academic/ps/calsup.ps</a>
</p>
</li>
<li>
<p>R. K. S. Hankin 2005. <em>Introducing BACCO, an R bundle for
Bayesian analysis of computer code output</em>, Journal of Statistical
Software, 14(16)
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+V.fun">V.fun</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toys)
W2(D2=D2.toy, H2=H2.toy, V=V.toy) 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
