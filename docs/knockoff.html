<!DOCTYPE html><html><head><title>Help for package knockoff</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {knockoff}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#create_equicorrelated'><p>Create equicorrelated fixed-X knockoffs.</p></a></li>
<li><a href='#create_sdp'><p>Create SDP fixed-X knockoffs.</p></a></li>
<li><a href='#create.fixed'><p>Fixed-X knockoffs</p></a></li>
<li><a href='#create.gaussian'><p>Model-X Gaussian knockoffs</p></a></li>
<li><a href='#create.second_order'><p>Second-order Gaussian knockoffs</p></a></li>
<li><a href='#create.solve_asdp'><p>Relaxed optimization for fixed-X and Gaussian knockoffs</p></a></li>
<li><a href='#create.solve_equi'><p>Optimization for equi-correlated fixed-X and Gaussian knockoffs</p></a></li>
<li><a href='#create.solve_sdp'><p>Optimization for fixed-X and Gaussian knockoffs</p></a></li>
<li><a href='#create.vectorize_matrix'><p>Vectorize a matrix into the SCS format</p></a></li>
<li><a href='#decompose'><p>Compute the SVD of X and construct an orthogonal matrix U_perp such that U_perp * U = 0.</p></a></li>
<li><a href='#divide.sdp'><p>Approximate a covariance matrix by a block diagonal matrix with blocks</p>
of approximately equal size using Ward's method for hierarchical clustering</a></li>
<li><a href='#fs'><p>Forward selection</p></a></li>
<li><a href='#knockoff'><p>knockoff: A package for controlled variable selection</p></a></li>
<li><a href='#knockoff.filter'><p>The Knockoff Filter</p></a></li>
<li><a href='#knockoff.threshold'><p>Threshold for the knockoff filter</p></a></li>
<li><a href='#lasso_max_lambda'><p>Maximum lambda in lasso model</p></a></li>
<li><a href='#merge.clusters'><p>Merge consecutive clusters of correlated variables while ensuring</p>
that no cluster has size larger than max.size</a></li>
<li><a href='#print.knockoff.result'><p>Print results for the knockoff filter</p></a></li>
<li><a href='#stability_selection_importance'><p>Stability selection</p></a></li>
<li><a href='#stat.forward_selection'><p>Importance statistics based on forward selection</p></a></li>
<li><a href='#stat.glmnet_coefdiff'><p>Importance statistics based on a GLM with cross-validation</p></a></li>
<li><a href='#stat.glmnet_lambdadiff'><p>Importance statistics based on a GLM</p></a></li>
<li><a href='#stat.glmnet_lambdasmax'><p>GLM statistics for knockoff</p></a></li>
<li><a href='#stat.lasso_coefdiff'><p>Importance statistics based the lasso with cross-validation</p></a></li>
<li><a href='#stat.lasso_coefdiff_bin'><p>Importance statistics based on regularized logistic regression with cross-validation</p></a></li>
<li><a href='#stat.lasso_lambdadiff'><p>Importance statistics based on the lasso</p></a></li>
<li><a href='#stat.lasso_lambdadiff_bin'><p>Importance statistics based on regularized logistic regression</p></a></li>
<li><a href='#stat.lasso_lambdasmax'><p>Penalized linear regression statistics for knockoff</p></a></li>
<li><a href='#stat.lasso_lambdasmax_bin'><p>Penalized logistic regression statistics for knockoff</p></a></li>
<li><a href='#stat.random_forest'><p>Importance statistics based on random forests</p></a></li>
<li><a href='#stat.sqrt_lasso'><p>Importance statistics based on the square-root lasso</p></a></li>
<li><a href='#stat.stability_selection'><p>Importance statistics based on stability selection</p></a></li>
<li><a href='#verify_stat_depends'><p>Verify dependencies for chosen statistics</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The Knockoff Filter for Controlled Variable Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-08-12</td>
</tr>
<tr>
<td>Description:</td>
<td>The knockoff filter is a general procedure for controlling the false discovery rate (FDR)
  when performing variable selection. 
  For more information, see the website below and the accompanying paper: Candes et al., 
  "Panning for gold: model-X knockoffs for high-dimensional controlled variable selection", 
  J. R. Statist. Soc. B (2018) 80, 3, pp. 551-577.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://web.stanford.edu/group/candes/knockoffs/index.html">https://web.stanford.edu/group/candes/knockoffs/index.html</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>methods, stats</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rdsdp, Matrix, corpcor, glmnet, RSpectra, gtools, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, testthat, rmarkdown, lars, ranger, stabs, RPtests,
doParallel, parallel</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-12 18:43:32 UTC; msesia</td>
</tr>
<tr>
<td>Author:</td>
<td>Rina Foygel Barber [ctb] (Development of the original Fixed-X
    Knockoffs),
  Emmanuel Candes [ctb] (Development of Model-X Knockoffs and original
    Fixed-X Knockoffs),
  Lucas Janson [ctb] (Development of Model-X Knockoffs),
  Evan Patterson [aut] (Earlier R package for the original Fixed-X
    Knockoffs),
  Matteo Sesia [aut, cre] (R package for Model-X Knockoffs)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matteo Sesia &lt;sesia@marshall.usc.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-15 07:30:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='create_equicorrelated'>Create equicorrelated fixed-X knockoffs.</h2><span id='topic+create_equicorrelated'></span>

<h3>Description</h3>

<p>Create equicorrelated fixed-X knockoffs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_equicorrelated(X, randomize)
</code></pre>

<hr>
<h2 id='create_sdp'>Create SDP fixed-X knockoffs.</h2><span id='topic+create_sdp'></span>

<h3>Description</h3>

<p>Create SDP fixed-X knockoffs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_sdp(X, randomize)
</code></pre>

<hr>
<h2 id='create.fixed'>Fixed-X knockoffs</h2><span id='topic+create.fixed'></span>

<h3>Description</h3>

<p>Creates fixed-X knockoff variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.fixed(
  X,
  method = c("sdp", "equi"),
  sigma = NULL,
  y = NULL,
  randomize = F
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.fixed_+3A_x">X</code></td>
<td>
<p>normalized n-by-p matrix of original variables.(<code class="reqn">n \geq p</code>).</p>
</td></tr>
<tr><td><code id="create.fixed_+3A_method">method</code></td>
<td>
<p>either &quot;equi&quot; or &quot;sdp&quot; (default: &quot;sdp&quot;).
This determines the method that will be used to minimize the correlation between the original variables and the knockoffs.</p>
</td></tr>
<tr><td><code id="create.fixed_+3A_sigma">sigma</code></td>
<td>
<p>the noise level, used to augment the data with extra rows if necessary (default: NULL).</p>
</td></tr>
<tr><td><code id="create.fixed_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the observed responses. 
This is needed to estimate the noise level if the parameter <code>sigma</code> is not provided, 
in case <code class="reqn">p \leq n &lt; 2p</code> (default: NULL).</p>
</td></tr>
<tr><td><code id="create.fixed_+3A_randomize">randomize</code></td>
<td>
<p>whether the knockoffs are constructed deterministically or randomized (default: F).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fixed-X knockoffs assume a homoscedastic linear regression model for <code class="reqn">Y|X</code>. Moreover, they only guarantee
FDR control when used in combination with statistics satisfying the &quot;sufficiency&quot; property. 
In particular, the default statistics based on the cross-validated lasso does not satisfy this 
property and should not be used with fixed-X knockoffs.
</p>


<h3>Value</h3>

<p>An object of class &quot;knockoff.variables&quot;. This is a list 
containing at least the following components:
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>n-by-p matrix of original variables (possibly augmented or transformed).</p>
</td></tr>
<tr><td><code>Xk</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>vector of observed responses (possibly augmented). </p>
</td></tr>
</table>


<h3>References</h3>

<p>Barber and Candes,
Controlling the false discovery rate via knockoffs. 
Ann. Statist. 43 (2015), no. 5, 2055&ndash;2085.
</p>


<h3>See Also</h3>

<p>Other create: 
<code><a href="#topic+create.gaussian">create.gaussian</a>()</code>,
<code><a href="#topic+create.second_order">create.second_order</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=50; n=100; k=15
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 5.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=create.fixed)
print(result$selected)

# Advanced usage with custom arguments
knockoffs = function(X) create.fixed(X, method='equi')
result = knockoff.filter(X, y, knockoffs=knockoffs)
print(result$selected) 

</code></pre>

<hr>
<h2 id='create.gaussian'>Model-X Gaussian knockoffs</h2><span id='topic+create.gaussian'></span>

<h3>Description</h3>

<p>Samples multivariate Gaussian model-X knockoff variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.gaussian(X, mu, Sigma, method = c("asdp", "sdp", "equi"), diag_s = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.gaussian_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="create.gaussian_+3A_mu">mu</code></td>
<td>
<p>vector of length p, indicating the mean parameter of the Gaussian model for <code class="reqn">X</code>.</p>
</td></tr>
<tr><td><code id="create.gaussian_+3A_sigma">Sigma</code></td>
<td>
<p>p-by-p covariance matrix for the Gaussian model of <code class="reqn">X</code>.</p>
</td></tr>
<tr><td><code id="create.gaussian_+3A_method">method</code></td>
<td>
<p>either &quot;equi&quot;, &quot;sdp&quot; or &quot;asdp&quot; (default: &quot;asdp&quot;).
This determines the method that will be used to minimize the correlation between the original variables and the knockoffs.</p>
</td></tr>
<tr><td><code id="create.gaussian_+3A_diag_s">diag_s</code></td>
<td>
<p>vector of length p, containing the pre-computed covariances between the original 
variables and the knockoffs. This will be computed according to <code>method</code>, if not supplied.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A n-by-p matrix of knockoff variables.
</p>


<h3>References</h3>

<p>Candes et al., Panning for Gold: Model-free Knockoffs for High-dimensional Controlled Variable Selection,
arXiv:1610.02351 (2016).
<a href="https://web.stanford.edu/group/candes/knockoffs/index.html">https://web.stanford.edu/group/candes/knockoffs/index.html</a>
</p>


<h3>See Also</h3>

<p>Other create: 
<code><a href="#topic+create.fixed">create.fixed</a>()</code>,
<code><a href="#topic+create.second_order">create.second_order</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=100; n=80; k=15
rho = 0.4
mu = rep(0,p); Sigma = toeplitz(rho^(0:(p-1)))
X = matrix(rnorm(n*p),n) %*% chol(Sigma)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)

# Basic usage with default arguments
knockoffs = function(X) create.gaussian(X, mu, Sigma)
result = knockoff.filter(X, y, knockoffs=knockoffs)
print(result$selected)

# Advanced usage with custom arguments
knockoffs = function(X) create.gaussian(X, mu, Sigma, method='equi')
result = knockoff.filter(X, y, knockoffs=knockoffs)
print(result$selected)

</code></pre>

<hr>
<h2 id='create.second_order'>Second-order Gaussian knockoffs</h2><span id='topic+create.second_order'></span>

<h3>Description</h3>

<p>This function samples second-order multivariate Gaussian knockoff variables.
First, a multivariate Gaussian distribution is fitted to the observations of X.
Then, Gaussian knockoffs are generated according to the estimated model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.second_order(X, method = c("asdp", "equi", "sdp"), shrink = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.second_order_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="create.second_order_+3A_method">method</code></td>
<td>
<p>either &quot;equi&quot;, &quot;sdp&quot; or &quot;asdp&quot; (default: &quot;asdp&quot;).
This determines the method that will be used to minimize the correlation between the original variables and the knockoffs.</p>
</td></tr>
<tr><td><code id="create.second_order_+3A_shrink">shrink</code></td>
<td>
<p>whether to shrink the estimated covariance matrix (default: F).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the argument <code>shrink</code> is set to T, a James-Stein-type shrinkage estimator for
the covariance matrix is used instead of the traditional maximum-likelihood estimate. This option
requires the package <code>corpcor</code>. See <code><a href="corpcor.html#topic+cov.shrink">cov.shrink</a></code> for more details.
</p>
<p>Even if the argument <code>shrink</code> is set to F, in the case that the estimated covariance 
matrix is not positive-definite, this function will apply some shrinkage.
</p>


<h3>Value</h3>

<p>A n-by-p matrix of knockoff variables.
</p>


<h3>References</h3>

<p>Candes et al., Panning for Gold: Model-free Knockoffs for High-dimensional Controlled Variable Selection,
arXiv:1610.02351 (2016).
<a href="https://web.stanford.edu/group/candes/knockoffs/index.html">https://web.stanford.edu/group/candes/knockoffs/index.html</a>
</p>


<h3>See Also</h3>

<p>Other create: 
<code><a href="#topic+create.fixed">create.fixed</a>()</code>,
<code><a href="#topic+create.gaussian">create.gaussian</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=100; n=80; k=15
rho = 0.4
Sigma = toeplitz(rho^(0:(p-1)))
X = matrix(rnorm(n*p),n) %*% chol(Sigma)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=create.second_order)
print(result$selected)

# Advanced usage with custom arguments
knockoffs = function(X) create.second_order(X, method='equi')
result = knockoff.filter(X, y, knockoffs=knockoffs)
print(result$selected)   
  
</code></pre>

<hr>
<h2 id='create.solve_asdp'>Relaxed optimization for fixed-X and Gaussian knockoffs</h2><span id='topic+create.solve_asdp'></span>

<h3>Description</h3>

<p>This function solves the optimization problem needed to create fixed-X and Gaussian SDP knockoffs
on a block-diagonal approximation of the covariance matrix. This will be less
powerful than <code><a href="#topic+create.solve_sdp">create.solve_sdp</a></code>, but more computationally efficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.solve_asdp(
  Sigma,
  max.size = 500,
  gaptol = 1e-06,
  maxit = 1000,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.solve_asdp_+3A_sigma">Sigma</code></td>
<td>
<p>positive-definite p-by-p covariance matrix.</p>
</td></tr>
<tr><td><code id="create.solve_asdp_+3A_max.size">max.size</code></td>
<td>
<p>size of the largest block in the block-diagonal approximation of Sigma (default: 500). See Details.</p>
</td></tr>
<tr><td><code id="create.solve_asdp_+3A_gaptol">gaptol</code></td>
<td>
<p>tolerance for duality gap as a fraction of the value of the objective functions (default: 1e-6).</p>
</td></tr>
<tr><td><code id="create.solve_asdp_+3A_maxit">maxit</code></td>
<td>
<p>the maximum number of iterations for the solver (default: 1000).</p>
</td></tr>
<tr><td><code id="create.solve_asdp_+3A_verbose">verbose</code></td>
<td>
<p>whether to display progress (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves the following two-step semidefinite program:
</p>
<p>(step 1)  </p>
<p style="text-align: center;"><code class="reqn"> \mathrm{maximize}     \; \mathrm{sum}(s) \quad
                   \mathrm{subject} \; \mathrm{to:}  \; 0 \leq s \leq 1, \;
                                         2 \Sigma_{\mathrm{approx}} - \mathrm{diag}(s) \geq 0</code>
</p>

<p>(step 2) </p>
<p style="text-align: center;"><code class="reqn"> \mathrm{maximize}      \; \gamma \quad
                  \mathrm{subject} \; \mathrm{to:}    \; \mathrm{diag}(\gamma s) \leq 2 \Sigma</code>
</p>

<p>Each smaller SDP is solved using the interior-point method implemented in <code><a href="Rdsdp.html#topic+dsdp">dsdp</a></code>.
</p>
<p>The parameter max.size controls the size of the largest semidefinite program that needs to be solved.
A larger value of max.size will increase the computation cost, while yielding a solution closer to
that of the original semidefinite program.
</p>
<p>If the matrix Sigma supplied by the user is a non-scaled covariance matrix 
(i.e. its diagonal entries are not all equal to 1), then the appropriate scaling is applied before
solving the SDP defined above. The result is then scaled back before being returned, as to match 
the original scaling of the covariance matrix supplied by the user.
</p>


<h3>Value</h3>

<p>The solution <code class="reqn">s</code> to the semidefinite program defined above.
</p>


<h3>See Also</h3>

<p>Other optimization: 
<code><a href="#topic+create.solve_equi">create.solve_equi</a>()</code>,
<code><a href="#topic+create.solve_sdp">create.solve_sdp</a>()</code>
</p>

<hr>
<h2 id='create.solve_equi'>Optimization for equi-correlated fixed-X and Gaussian knockoffs</h2><span id='topic+create.solve_equi'></span>

<h3>Description</h3>

<p>This function solves a very simple optimization problem needed to create fixed-X and 
Gaussian SDP knockoffs on the full the covariance matrix. This may be significantly
less powerful than <code><a href="#topic+create.solve_sdp">create.solve_sdp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.solve_equi(Sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.solve_equi_+3A_sigma">Sigma</code></td>
<td>
<p>positive-definite p-by-p covariance matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the closed-form solution to the semidefinite programming problem:
</p>
<p style="text-align: center;"><code class="reqn"> \mathrm{maximize}  \; s \quad
       \mathrm{subject} \; \mathrm{to:}   \; 0 \leq s \leq 1, \;
       2\Sigma - sI \geq 0 </code>
</p>

<p>used to generate equi-correlated knockoffs.
</p>
<p>The closed form-solution to this problem is <code class="reqn">s = 2\lambda_{\mathrm{min}}(\Sigma) \land 1</code>.
</p>


<h3>Value</h3>

<p>The solution <code class="reqn">s</code> to the optimization problem defined above.
</p>


<h3>See Also</h3>

<p>Other optimization: 
<code><a href="#topic+create.solve_asdp">create.solve_asdp</a>()</code>,
<code><a href="#topic+create.solve_sdp">create.solve_sdp</a>()</code>
</p>

<hr>
<h2 id='create.solve_sdp'>Optimization for fixed-X and Gaussian knockoffs</h2><span id='topic+create.solve_sdp'></span>

<h3>Description</h3>

<p>This function solves the optimization problem needed to create fixed-X and Gaussian SDP knockoffs
on the full covariance matrix. This will be more powerful than <code><a href="#topic+create.solve_asdp">create.solve_asdp</a></code>,
but more computationally expensive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.solve_sdp(Sigma, gaptol = 1e-06, maxit = 1000, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.solve_sdp_+3A_sigma">Sigma</code></td>
<td>
<p>positive-definite p-by-p covariance matrix.</p>
</td></tr>
<tr><td><code id="create.solve_sdp_+3A_gaptol">gaptol</code></td>
<td>
<p>tolerance for duality gap as a fraction of the value of the objective functions (default: 1e-6).</p>
</td></tr>
<tr><td><code id="create.solve_sdp_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations for the solver (default: 1000).</p>
</td></tr>
<tr><td><code id="create.solve_sdp_+3A_verbose">verbose</code></td>
<td>
<p>whether to display progress (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Solves the semidefinite programming problem:
</p>
<p style="text-align: center;"><code class="reqn"> \mathrm{maximize}      \; \mathrm{sum}(s) \quad
          \mathrm{subject} \; \mathrm{to}    0 \leq s \leq 1, \;
                                 2\Sigma - \mathrm{diag}(s) \geq 0</code>
</p>

<p>This problem is solved using the interior-point method implemented in <code><a href="Rdsdp.html#topic+dsdp">dsdp</a></code>.
</p>
<p>If the matrix Sigma supplied by the user is a non-scaled covariance matrix 
(i.e. its diagonal entries are not all equal to 1), then the appropriate scaling is applied before
solving the SDP defined above. The result is then scaled back before being returned, as to match 
the original scaling of the covariance matrix supplied by the user.
</p>


<h3>Value</h3>

<p>The solution <code class="reqn">s</code> to the semidefinite programming problem defined above.
</p>


<h3>See Also</h3>

<p>Other optimization: 
<code><a href="#topic+create.solve_asdp">create.solve_asdp</a>()</code>,
<code><a href="#topic+create.solve_equi">create.solve_equi</a>()</code>
</p>

<hr>
<h2 id='create.vectorize_matrix'>Vectorize a matrix into the SCS format</h2><span id='topic+create.vectorize_matrix'></span>

<h3>Description</h3>

<p>Vectorize a matrix into the SCS format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.vectorize_matrix(M)
</code></pre>

<hr>
<h2 id='decompose'>Compute the SVD of X and construct an orthogonal matrix U_perp such that U_perp * U = 0.</h2><span id='topic+decompose'></span>

<h3>Description</h3>

<p>Compute the SVD of X and construct an orthogonal matrix U_perp such that U_perp * U = 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decompose(X, randomize)
</code></pre>

<hr>
<h2 id='divide.sdp'>Approximate a covariance matrix by a block diagonal matrix with blocks
of approximately equal size using Ward's method for hierarchical clustering</h2><span id='topic+divide.sdp'></span>

<h3>Description</h3>

<p>Approximate a covariance matrix by a block diagonal matrix with blocks
of approximately equal size using Ward's method for hierarchical clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divide.sdp(Sigma, max.size)
</code></pre>

<hr>
<h2 id='fs'>Forward selection</h2><span id='topic+fs'></span>

<h3>Description</h3>

<p>Perform forward variable selection with or without OMP
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fs(X, y, omp = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fs_+3A_x">X</code></td>
<td>
<p>matrix of predictors</p>
</td></tr>
<tr><td><code id="fs_+3A_y">y</code></td>
<td>
<p>response vector</p>
</td></tr>
<tr><td><code id="fs_+3A_omp">omp</code></td>
<td>
<p>whether to use orthogonal matching pursuit (OMP)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with jth component the variable added at step j
</p>

<hr>
<h2 id='knockoff'>knockoff: A package for controlled variable selection</h2><span id='topic+knockoff'></span>

<h3>Description</h3>

<p>This package implements the Knockoff Filter, which is a powerful and versatile tool for 
controlled variable selection.
</p>


<h3>Outline</h3>

<p>The procedure is based on the contruction of artificial 'knockoff copies' of the variables 
present in the given statistical model. Then, it selects those variables that are clearly better 
than their corresponding knockoffs, based on some measure of variable importance.
A wide range of statistics and machine learning tools can be exploited to estimate the 
importance of each variable, while guaranteeing finite-sample control of the false
discovery rate (FDR).
</p>
<p>The Knockoff Filter controls the FDR in either of two statistical scenarios:
</p>

<ul>
<li><p>The &quot;model-X&quot; scenario: the response <code class="reqn">Y</code> can depend on the variables <code class="reqn">X=(X_1,\ldots,X_p)</code>
in an arbitrary and unknown fashion, but the distribution of <code class="reqn">X</code> must be known. In thise case
there are no constraints on the dimensions <code class="reqn">n</code> and <code class="reqn">p</code> of the problem.
</p>
</li>
<li><p>The &quot;fixed-X&quot; scenario: the response <code class="reqn">Y</code> depends upon <code class="reqn">X</code> through a 
homoscedastic Gaussian linear model and the problem is low-dimensional (<code class="reqn">n \geq p</code>). 
In this case, no modeling assumptions on <code class="reqn">X</code> are required. 
</p>
</li></ul>

<p>For more information, see the website below and the accompanying paper.
</p>
<p><a href="https://web.stanford.edu/group/candes/knockoffs/index.html">https://web.stanford.edu/group/candes/knockoffs/index.html</a>
</p>

<hr>
<h2 id='knockoff.filter'>The Knockoff Filter</h2><span id='topic+knockoff.filter'></span>

<h3>Description</h3>

<p>This function runs the Knockoffs procedure from start to finish, selecting variables
relevant for predicting the outcome of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knockoff.filter(
  X,
  y,
  knockoffs = create.second_order,
  statistic = stat.glmnet_coefdiff,
  fdr = 0.1,
  offset = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knockoff.filter_+3A_x">X</code></td>
<td>
<p>n-by-p matrix or data frame of predictors.</p>
</td></tr>
<tr><td><code id="knockoff.filter_+3A_y">y</code></td>
<td>
<p>response vector of length n.</p>
</td></tr>
<tr><td><code id="knockoff.filter_+3A_knockoffs">knockoffs</code></td>
<td>
<p>method used to construct knockoffs for the <code class="reqn">X</code> variables.
It must be a function taking a n-by-p matrix as input and returning a n-by-p matrix of knockoff variables. 
By default, approximate model-X Gaussian knockoffs are used.</p>
</td></tr>
<tr><td><code id="knockoff.filter_+3A_statistic">statistic</code></td>
<td>
<p>statistics used to assess variable importance. By default, 
a lasso statistic with cross-validation is used. See the Details section for more information.</p>
</td></tr>
<tr><td><code id="knockoff.filter_+3A_fdr">fdr</code></td>
<td>
<p>target false discovery rate (default: 0.1).</p>
</td></tr>
<tr><td><code id="knockoff.filter_+3A_offset">offset</code></td>
<td>
<p>either 0 or 1 (default: 1). This is the offset used to compute the rejection threshold on the
statistics. The value 1 yields a slightly more conservative procedure (&quot;knockoffs+&quot;) that
controls the false discovery rate (FDR) according to the usual definition, 
while an offset of 0 controls a modified FDR.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates the knockoffs, computes the importance statistics, 
and selects variables. 
It is the main entry point for the knockoff package.
</p>
<p>The parameter <code>knockoffs</code> controls how knockoff variables are created.
By default, the model-X scenario is assumed and a multivariate normal distribution 
is fitted to the original variables <code class="reqn">X</code>. The estimated mean vector and the covariance 
matrix are used to generate second-order approximate Gaussian knockoffs.
In general, the function <code>knockoffs</code> should take a n-by-p matrix of
observed variables <code class="reqn">X</code> as input and return a n-by-p matrix of knockoffs.
Two default functions for creating knockoffs are provided with this package.
</p>
<p>In the model-X scenario, under the assumption that the rows of <code class="reqn">X</code> are distributed 
as a multivariate Gaussian with known parameters, then the function 
<code>create.gaussian</code> can be used to generate Gaussian knockoffs, 
as shown in the examples below.
</p>
<p>In the fixed-X scenario, one can create the knockoffs using the function 
<code>create.fixed</code>. This requires <code class="reqn">n \geq p</code> and it assumes 
that the response <code class="reqn">Y</code> follows a homoscedastic linear regression model.
</p>
<p>For more information about creating knockoffs, type <code>??create</code>.
</p>
<p>The default importance statistic is <a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>.
For a complete list of the statistics provided with this package, 
type <code>??stat</code>.
</p>
<p>It is possible to provide custom functions for the knockoff constructions 
or the importance statistics. Some examples can be found in the vignette.
</p>


<h3>Value</h3>

<p>An object of class &quot;knockoff.result&quot;. This object is a list 
containing at least the following components:
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>matrix of original variables</p>
</td></tr>
<tr><td><code>Xk</code></td>
<td>
<p>matrix of knockoff variables</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>computed test statistics</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>computed selection threshold</p>
</td></tr>
<tr><td><code>selected</code></td>
<td>
<p>named vector of selected variables</p>
</td></tr>
</table>


<h3>References</h3>

<p>Candes et al., Panning for Gold: Model-free Knockoffs for High-dimensional Controlled Variable Selection,
arXiv:1610.02351 (2016).
<a href="https://web.stanford.edu/group/candes/knockoffs/index.html">https://web.stanford.edu/group/candes/knockoffs/index.html</a>
</p>
<p>Barber and Candes,
Controlling the false discovery rate via knockoffs. 
Ann. Statist. 43 (2015), no. 5, 2055&ndash;2085.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=100; n=80; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)

# Basic usage with default arguments
result = knockoff.filter(X, y)
print(result$selected)

# Advanced usage with custom arguments
knockoffs = function(X) create.gaussian(X, mu, Sigma)
k_stat = function(X, Xk, y) stat.glmnet_coefdiff(X, Xk, y, nfolds=5)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)


</code></pre>

<hr>
<h2 id='knockoff.threshold'>Threshold for the knockoff filter</h2><span id='topic+knockoff.threshold'></span>

<h3>Description</h3>

<p>Computes the threshold for the knockoff filter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knockoff.threshold(W, fdr = 0.1, offset = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knockoff.threshold_+3A_w">W</code></td>
<td>
<p>the test statistics</p>
</td></tr>
<tr><td><code id="knockoff.threshold_+3A_fdr">fdr</code></td>
<td>
<p>target false discovery rate (default: 0.1)</p>
</td></tr>
<tr><td><code id="knockoff.threshold_+3A_offset">offset</code></td>
<td>
<p>either 0 or 1 (default: 1). The offset used to compute the rejection threshold on the
statistics. The value 1 yields a slightly more conservative procedure (&quot;knockoffs+&quot;) that
controls the FDR according to the usual definition, while an offset of 0 controls a modified FDR.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The threshold for variable selection.
</p>

<hr>
<h2 id='lasso_max_lambda'>Maximum lambda in lasso model</h2><span id='topic+lasso_max_lambda'></span>

<h3>Description</h3>

<p>Computes the earliest (largest) lambda's for which predictors enter the
lasso model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lasso_max_lambda(X, y, method = c("glmnet", "lars"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lasso_max_lambda_+3A_x">X</code></td>
<td>
<p>matrix of predictors</p>
</td></tr>
<tr><td><code id="lasso_max_lambda_+3A_y">y</code></td>
<td>
<p>response vector</p>
</td></tr>
<tr><td><code id="lasso_max_lambda_+3A_method">method</code></td>
<td>
<p>either 'glmnet' or 'lars'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of maximum lambda's
</p>

<hr>
<h2 id='merge.clusters'>Merge consecutive clusters of correlated variables while ensuring 
that no cluster has size larger than max.size</h2><span id='topic+merge.clusters'></span>

<h3>Description</h3>

<p>Merge consecutive clusters of correlated variables while ensuring 
that no cluster has size larger than max.size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clusters'
merge(clusters, max.size)
</code></pre>

<hr>
<h2 id='print.knockoff.result'>Print results for the knockoff filter</h2><span id='topic+print.knockoff.result'></span>

<h3>Description</h3>

<p>Prints the list of variables selected by the knockoff filter and the corresponding function call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'knockoff.result'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.knockoff.result_+3A_x">x</code></td>
<td>
<p>the output of a call to knockoff.filter</p>
</td></tr>
<tr><td><code id="print.knockoff.result_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>

<hr>
<h2 id='stability_selection_importance'>Stability selection</h2><span id='topic+stability_selection_importance'></span>

<h3>Description</h3>

<p>Perform variable selection with stability selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stability_selection_importance(X, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stability_selection_importance_+3A_x">X</code></td>
<td>
<p>matrix of predictors</p>
</td></tr>
<tr><td><code id="stability_selection_importance_+3A_y">y</code></td>
<td>
<p>response vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with jth component the selection probability of variable j
</p>

<hr>
<h2 id='stat.forward_selection'>Importance statistics based on forward selection</h2><span id='topic+stat.forward_selection'></span>

<h3>Description</h3>

<p>Computes the statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = \max(Z_j, Z_{j+p}) \cdot \mathrm{sgn}(Z_j - Z_{j+p}),</code>
</p>

<p>where <code class="reqn">Z_1,\dots,Z_{2p}</code> give the reverse order in which the 2p
variables (the originals and the knockoffs) enter the forward selection 
model.
See the Details for information about forward selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.forward_selection(X, X_k, y, omp = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.forward_selection_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.forward_selection_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.forward_selection_+3A_y">y</code></td>
<td>
<p>numeric vector of length n, containing the response variables.</p>
</td></tr>
<tr><td><code id="stat.forward_selection_+3A_omp">omp</code></td>
<td>
<p>whether to use orthogonal matching pursuit (default: F).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In <em>forward selection</em>, the variables are chosen iteratively to maximize
the inner product with the residual from the previous step. The initial
residual is always <code>y</code>. In standard forward selection
(<code>stat.forward_selection</code>), the next residual is the remainder after
regressing on the selected variable; when orthogonal matching pursuit
is used, the next residual is the remainder
after regressing on <em>all</em> the previously selected variables.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=100; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs,
                           statistic=stat.forward_selection)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.forward_selection
k_stat = function(X, X_k, y) foo(X, X_k, y, omp=TRUE)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.glmnet_coefdiff'>Importance statistics based on a GLM with cross-validation</h2><span id='topic+stat.glmnet_coefdiff'></span>

<h3>Description</h3>

<p>Fits a generalized linear model via penalized maximum likelihood and cross-validation.
Then, compute the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = |Z_j| - |\tilde{Z}_j|</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the coefficient estimates for the 
jth variable and its knockoff, respectively. The value of the regularization
parameter <code class="reqn">\lambda</code> is selected by cross-validation and computed with <code>glmnet</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.glmnet_coefdiff(X, X_k, y, family = "gaussian", cores = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.glmnet_coefdiff_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.glmnet_coefdiff_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.glmnet_coefdiff_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. Quantitative for family=&quot;gaussian&quot;, 
or family=&quot;poisson&quot; (non-negative counts). For family=&quot;binomial&quot; 
should be either a factor with two levels, or a two-column matrix of counts 
or proportions (the second column is treated as the target class; for a factor, 
the last level in alphabetical order is the target class). For family=&quot;multinomial&quot;, 
can be a nc&gt;=2 level factor, or a matrix with nc columns of counts or proportions. 
For either &quot;binomial&quot; or &quot;multinomial&quot;, if y is presented as a vector, it will 
be coerced into a factor. For family=&quot;cox&quot;, y should be a two-column matrix with 
columns named 'time' and 'status'. The latter is a binary variable, with '1' 
indicating death, and '0' indicating right censored. The function Surv() in 
package survival produces such a matrix. For family=&quot;mgaussian&quot;, y is a matrix 
of quantitative responses.</p>
</td></tr>
<tr><td><code id="stat.glmnet_coefdiff_+3A_family">family</code></td>
<td>
<p>response type (see above).</p>
</td></tr>
<tr><td><code id="stat.glmnet_coefdiff_+3A_cores">cores</code></td>
<td>
<p>Number of cores used to compute the statistics by running cv.glmnet.
Unless otherwise specified, the number of cores is set equal to two (if available).</p>
</td></tr>
<tr><td><code id="stat.glmnet_coefdiff_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>glmnet</code> package to fit a generalized linear model
via penalized maximum likelihood.
</p>
<p>The statistics <code class="reqn">W_j</code> are constructed by taking the difference 
between the coefficient of the j-th variable and its knockoff.
</p>
<p>By default, the value of the regularization parameter is chosen by 10-fold cross-validation.
</p>
<p>The default response family is 'gaussian', for a linear regression model.
Different response families (e.g. 'binomial') can be specified by passing an
optional parameter 'family'.
</p>
<p>The optional <code>nlambda</code> parameter can be used to control the granularity of the 
grid of <code class="reqn">\lambda</code>'s. The default value of <code>nlambda</code> is <code>500</code>,
where <code>p</code> is the number of columns of <code>X</code>.
</p>
<p>If the family is 'binomial' and a lambda sequence is not provided by the user, 
this function generates it on a log-linear scale before calling 'glmnet'.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>
and <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, 
                           statistic=stat.glmnet_coefdiff)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.glmnet_coefdiff
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.glmnet_lambdadiff'>Importance statistics based on a GLM</h2><span id='topic+stat.glmnet_lambdadiff'></span>

<h3>Description</h3>

<p>Fits a generalized linear model via penalized maximum likelihood and
computes the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = Z_j - \tilde{Z}_j</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the maximum values of the 
regularization parameter <code class="reqn">\lambda</code> at which the jth variable 
and its knockoff enter the model, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.glmnet_lambdadiff(X, X_k, y, family = "gaussian", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.glmnet_lambdadiff_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdadiff_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdadiff_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. Quantitative for family=&quot;gaussian&quot;, 
or family=&quot;poisson&quot; (non-negative counts). For family=&quot;binomial&quot; 
should be either a factor with two levels, or a two-column matrix of counts 
or proportions (the second column is treated as the target class; for a factor, 
the last level in alphabetical order is the target class). For family=&quot;multinomial&quot;, 
can be a nc&gt;=2 level factor, or a matrix with nc columns of counts or proportions. 
For either &quot;binomial&quot; or &quot;multinomial&quot;, if y is presented as a vector, it will 
be coerced into a factor. For family=&quot;cox&quot;, y should be a two-column matrix with 
columns named 'time' and 'status'. The latter is a binary variable, with '1' 
indicating death, and '0' indicating right censored. The function Surv() in 
package survival produces such a matrix. For family=&quot;mgaussian&quot;, y is a matrix 
of quantitative responses.</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdadiff_+3A_family">family</code></td>
<td>
<p>response type (see above).</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdadiff_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code>glmnet</code> to compute the regularization path
on a fine grid of <code class="reqn">\lambda</code>'s.
</p>
<p>The <code>nlambda</code> parameter can be used to control the granularity of the 
grid of <code class="reqn">\lambda</code>'s. The default value of <code>nlambda</code> is <code>500</code>.
</p>
<p>If the family is 'binomial' and a lambda sequence is not provided by the user, 
this function generates it on a log-linear scale before calling 'glmnet'.
</p>
<p>The default response family is 'gaussian', for a linear regression model.
Different response families (e.g. 'binomial') can be specified by passing an
optional parameter 'family'.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, 
                           statistic=stat.glmnet_lambdadiff)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.glmnet_lambdadiff
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.glmnet_lambdasmax'>GLM statistics for knockoff</h2><span id='topic+stat.glmnet_lambdasmax'></span>

<h3>Description</h3>

<p>Computes the signed maximum statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = \max(Z_j, \tilde{Z}_j) \cdot \mathrm{sgn}(Z_j - \tilde{Z}_j),</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the maximum values of 
<code class="reqn">\lambda</code> at which the jth variable and its knockoff, respectively,
enter the generalized linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.glmnet_lambdasmax(X, X_k, y, family = "gaussian", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.glmnet_lambdasmax_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdasmax_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdasmax_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. Quantitative for family=&quot;gaussian&quot;, 
or family=&quot;poisson&quot; (non-negative counts). For family=&quot;binomial&quot; 
should be either a factor with two levels, or a two-column matrix of counts 
or proportions (the second column is treated as the target class; for a factor, 
the last level in alphabetical order is the target class). For family=&quot;multinomial&quot;, 
can be a nc&gt;=2 level factor, or a matrix with nc columns of counts or proportions. 
For either &quot;binomial&quot; or &quot;multinomial&quot;, if y is presented as a vector, it will 
be coerced into a factor. For family=&quot;cox&quot;, y should be a two-column matrix with 
columns named 'time' and 'status'. The latter is a binary variable, with '1' 
indicating death, and '0' indicating right censored. The function Surv() in 
package survival produces such a matrix. For family=&quot;mgaussian&quot;, y is a matrix 
of quantitative responses.</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdasmax_+3A_family">family</code></td>
<td>
<p>response type (see above).</p>
</td></tr>
<tr><td><code id="stat.glmnet_lambdasmax_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code>glmnet</code> to compute the regularization path
on a fine grid of <code class="reqn">\lambda</code>'s.
</p>
<p>The additional <code>nlambda</code> 
parameter can be used to control the granularity of the grid of <code class="reqn">\lambda</code> values. 
The default value of <code>nlambda</code> is <code>500</code>.
</p>
<p>If the family is 'binomial' and a lambda sequence is not provided by the user, 
this function generates it on a log-linear scale before calling 'glmnet'.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoff=knockoffs,
                           statistic=stat.glmnet_lambdasmax)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.glmnet_lambdasmax
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.lasso_coefdiff'>Importance statistics based the lasso with cross-validation</h2><span id='topic+stat.lasso_coefdiff'></span>

<h3>Description</h3>

<p>Fits a linear regression model via penalized maximum likelihood and cross-validation.
Then, compute the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = |Z_j| - |\tilde{Z}_j|</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the coefficient estimates for the 
jth variable and its knockoff, respectively. The value of the regularization
parameter <code class="reqn">\lambda</code> is selected by cross-validation and computed with <code>glmnet</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.lasso_coefdiff(X, X_k, y, cores = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.lasso_coefdiff_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. It should be numeric</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_+3A_cores">cores</code></td>
<td>
<p>Number of cores used to compute the statistics by running cv.glmnet.
If not specified, the number of cores is set to approximately half of the number of cores 
detected by the parallel package.</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>glmnet</code> package to fit the lasso path and 
is a wrapper around the more general <a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>.
</p>
<p>The statistics <code class="reqn">W_j</code> are constructed by taking the difference 
between the coefficient of the j-th variable and its knockoff.
</p>
<p>By default, the value of the regularization parameter is chosen by 10-fold cross-validation.
</p>
<p>The optional <code>nlambda</code> parameter can be used to control the granularity of the 
grid of <code class="reqn">\lambda</code>'s. The default value of <code>nlambda</code> is <code>500</code>,
where <code>p</code> is the number of columns of <code>X</code>.
</p>
<p>Unless a lambda sequence is provided by the user, this function generates it on a 
log-linear scale before calling 'glmnet' (default 'nlambda': 500).
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>
and <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, 
                           statistic=stat.lasso_coefdiff)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.lasso_coefdiff
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.lasso_coefdiff_bin'>Importance statistics based on regularized logistic regression with cross-validation</h2><span id='topic+stat.lasso_coefdiff_bin'></span>

<h3>Description</h3>

<p>Fits a logistic regression model via penalized maximum likelihood and cross-validation.
Then, compute the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = |Z_j| - |\tilde{Z}_j|</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the coefficient estimates for the 
jth variable and its knockoff, respectively. The value of the regularization
parameter <code class="reqn">\lambda</code> is selected by cross-validation and computed with <code>glmnet</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.lasso_coefdiff_bin(X, X_k, y, cores = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.lasso_coefdiff_bin_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables..</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_bin_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_bin_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. It should be either a factor with two levels, 
or a two-column matrix of counts or proportions 
(the second column is treated as the target class; for a factor, the last level 
in alphabetical order is the target class). If y is presented as a vector, 
it will be coerced into a factor.</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_bin_+3A_cores">cores</code></td>
<td>
<p>Number of cores used to compute the statistics by running cv.glmnet.
If not specified, the number of cores is set to approximately half of the number of cores 
detected by the parallel package.</p>
</td></tr>
<tr><td><code id="stat.lasso_coefdiff_bin_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>glmnet</code> package to fit the penalized logistic regression path
and is a wrapper around the more general <code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a></code>.
</p>
<p>The statistics <code class="reqn">W_j</code> are constructed by taking the difference 
between the coefficient of the j-th variable and its knockoff.
</p>
<p>By default, the value of the regularization parameter is chosen by 10-fold cross-validation.
</p>
<p>The optional <code>nlambda</code> parameter can be used to control the granularity of the 
grid of <code class="reqn">\lambda</code>'s. The default value of <code>nlambda</code> is <code>500</code>,
where <code>p</code> is the number of columns of <code>X</code>.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>
and <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
pr = 1/(1+exp(-X %*% beta))
y = rbinom(n,1,pr)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, 
                           statistic=stat.lasso_coefdiff_bin)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.lasso_coefdiff_bin
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.lasso_lambdadiff'>Importance statistics based on the lasso</h2><span id='topic+stat.lasso_lambdadiff'></span>

<h3>Description</h3>

<p>Fit the lasso path and computes the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = Z_j - \tilde{Z}_j</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the maximum values of the 
regularization parameter <code class="reqn">\lambda</code> at which the jth variable 
and its knockoff enter the penalized linear regression model, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.lasso_lambdadiff(X, X_k, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.lasso_lambdadiff_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdadiff_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdadiff_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. It should be numeric.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdadiff_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code>glmnet</code> to compute the lasso path
on a fine grid of <code class="reqn">\lambda</code>'s and is a wrapper around the more general
<a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>.
</p>
<p>The <code>nlambda</code> parameter can be used to control the granularity of the 
grid of <code class="reqn">\lambda</code>'s. The default value of <code>nlambda</code> is <code>500</code>.
</p>
<p>Unless a lambda sequence is provided by the user, this function generates it on a 
log-linear scale before calling <code>glmnet</code> (default 'nlambda': 500).
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
or <code><a href="lars.html#topic+lars">lars</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, 
                           statistic=stat.lasso_lambdadiff)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.lasso_lambdadiff
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.lasso_lambdadiff_bin'>Importance statistics based on regularized logistic regression</h2><span id='topic+stat.lasso_lambdadiff_bin'></span>

<h3>Description</h3>

<p>Fit the lasso path and computes the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = Z_j - \tilde{Z}_j</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the maximum values of the 
regularization parameter <code class="reqn">\lambda</code> at which the jth variable 
and its knockoff enter the penalized logistic regression model, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.lasso_lambdadiff_bin(X, X_k, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.lasso_lambdadiff_bin_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdadiff_bin_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdadiff_bin_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. It should be either a factor with two levels, 
or a two-column matrix of counts or proportions 
(the second column is treated as the target class; for a factor, the last level 
in alphabetical order is the target class). If y is presented as a vector, 
it will be coerced into a factor.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdadiff_bin_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code>glmnet</code> to compute the lasso path
on a fine grid of <code class="reqn">\lambda</code>'s.
</p>
<p>The <code>nlambda</code> parameter can be used to control the granularity of the 
grid of <code class="reqn">\lambda</code>'s. The default value of <code>nlambda</code> is <code>500</code>.
</p>
<p>This function is a wrapper around the more general <code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a></code>.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
or <code><a href="lars.html#topic+lars">lars</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
pr = 1/(1+exp(-X %*% beta))
y = rbinom(n,1,pr)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, 
                           statistic=stat.lasso_lambdadiff_bin)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.lasso_lambdadiff_bin
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.lasso_lambdasmax'>Penalized linear regression statistics for knockoff</h2><span id='topic+stat.lasso_lambdasmax'></span>

<h3>Description</h3>

<p>Computes the signed maximum statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = \max(Z_j, \tilde{Z}_j) \cdot \mathrm{sgn}(Z_j - \tilde{Z}_j),</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the maximum values of 
<code class="reqn">\lambda</code> at which the jth variable and its knockoff, respectively,
enter the penalized linear regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.lasso_lambdasmax(X, X_k, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.lasso_lambdasmax_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdasmax_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdasmax_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. It should be numeric.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdasmax_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> or <code>lars</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code>glmnet</code> to compute the regularization path
on a fine grid of <code class="reqn">\lambda</code>'s.
</p>
<p>The additional <code>nlambda</code> 
parameter can be used to control the granularity of the grid of <code class="reqn">\lambda</code> values. 
The default value of <code>nlambda</code> is <code>500</code>.
</p>
<p>Unless a lambda sequence is provided by the user, this function generates it on a 
log-linear scale before calling <code>glmnet</code> (default 'nlambda': 500).
</p>
<p>This function is a wrapper around the more general 
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a></code>.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoff=knockoffs,
                           statistic=stat.lasso_lambdasmax)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.lasso_lambdasmax
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.lasso_lambdasmax_bin'>Penalized logistic regression statistics for knockoff</h2><span id='topic+stat.lasso_lambdasmax_bin'></span>

<h3>Description</h3>

<p>Computes the signed maximum statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = \max(Z_j, \tilde{Z}_j) \cdot \mathrm{sgn}(Z_j - \tilde{Z}_j),</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the maximum values of 
<code class="reqn">\lambda</code> at which the jth variable and its knockoff, respectively,
enter the penalized logistic regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.lasso_lambdasmax_bin(X, X_k, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.lasso_lambdasmax_bin_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdasmax_bin_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdasmax_bin_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. It should be either a factor with two levels, 
or a two-column matrix of counts or proportions 
(the second column is treated as the target class; for a factor, the last level 
in alphabetical order is the target class). If y is presented as a vector, 
it will be coerced into a factor.</p>
</td></tr>
<tr><td><code id="stat.lasso_lambdasmax_bin_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>glmnet</code> or <code>lars</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code>glmnet</code> to compute the regularization path
on a fine grid of <code class="reqn">\lambda</code>'s.
</p>
<p>The additional <code>nlambda</code> 
parameter can be used to control the granularity of the grid of <code class="reqn">\lambda</code> values. 
The default value of <code>nlambda</code> is <code>500</code>.
</p>
<p>This function is a wrapper around the more general 
<a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
pr = 1/(1+exp(-X %*% beta))
y = rbinom(n,1,pr)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoff=knockoffs,
                           statistic=stat.lasso_lambdasmax_bin)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.lasso_lambdasmax_bin
k_stat = function(X, X_k, y) foo(X, X_k, y, nlambda=200)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.random_forest'>Importance statistics based on random forests</h2><span id='topic+stat.random_forest'></span>

<h3>Description</h3>

<p>Computes the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = |Z_j| - |\tilde{Z}_j|</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the random forest feature importances
of the jth variable and its knockoff, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.random_forest(X, X_k, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.random_forest_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.random_forest_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.random_forest_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables. If a factor, classification is assumed, 
otherwise regression is assumed.</p>
</td></tr>
<tr><td><code id="stat.random_forest_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>ranger</code> (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>ranger</code> package to compute variable 
importance measures. The importance of a variable is measured as the total decrease
in node impurities from splitting on that variable, averaged over all trees. 
For regression, the node impurity is measured by residual sum of squares.
For classification, it is measured by the Gini index.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="ranger.html#topic+ranger">ranger</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=200; n=100; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, 
                           statistic=stat.random_forest)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.random_forest
k_stat = function(X, X_k, y) foo(X, X_k, y, nodesize=5)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.sqrt_lasso'>Importance statistics based on the square-root lasso</h2><span id='topic+stat.sqrt_lasso'></span>

<h3>Description</h3>

<p>Computes the signed maximum statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = \max(Z_j, \tilde{Z}_j) \cdot \mathrm{sgn}(Z_j - \tilde{Z}_j),</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are the maximum values of 
<code class="reqn">\lambda</code> at which the jth variable and its knockoff, respectively,
enter the SQRT lasso model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.sqrt_lasso(X, X_k, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.sqrt_lasso_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.sqrt_lasso_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.sqrt_lasso_+3A_y">y</code></td>
<td>
<p>vector of length n, containing the response variables of numeric type.</p>
</td></tr>
<tr><td><code id="stat.sqrt_lasso_+3A_...">...</code></td>
<td>
<p>additional arguments specific to <code>slim</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With default parameters, this function uses the package <code>RPtests</code>
to run the SQRT lasso. By specifying the appropriate optional parameters, 
one can use different Lasso variants including Dantzig Selector, LAD Lasso,
SQRT Lasso and Lq Lasso for estimating high dimensional sparse linear models.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="RPtests.html#topic+sqrt_lasso">sqrt_lasso</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.stability_selection">stat.stability_selection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=50; n=50; k=10
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=stat.sqrt_lasso)
print(result$selected)

# Advanced usage with custom arguments
foo = stat.sqrt_lasso
k_stat = function(X, X_k, y) foo(X, X_k, y, q=0.5)
result = knockoff.filter(X, y, knockoffs=knockoffs, statistic=k_stat)
print(result$selected)

</code></pre>

<hr>
<h2 id='stat.stability_selection'>Importance statistics based on stability selection</h2><span id='topic+stat.stability_selection'></span>

<h3>Description</h3>

<p>Computes the difference statistic
</p>
<p style="text-align: center;"><code class="reqn">W_j = |Z_j| - |\tilde{Z}_j|</code>
</p>

<p>where <code class="reqn">Z_j</code> and <code class="reqn">\tilde{Z}_j</code> are measure the importance
of the jth variable and its knockoff, respectively, based on the 
stability of their selection upon subsampling of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stat.stability_selection(X, X_k, y, fitfun = stabs::lars.lasso, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stat.stability_selection_+3A_x">X</code></td>
<td>
<p>n-by-p matrix of original variables.</p>
</td></tr>
<tr><td><code id="stat.stability_selection_+3A_x_k">X_k</code></td>
<td>
<p>n-by-p matrix of knockoff variables.</p>
</td></tr>
<tr><td><code id="stat.stability_selection_+3A_y">y</code></td>
<td>
<p>response vector (length n)</p>
</td></tr>
<tr><td><code id="stat.stability_selection_+3A_fitfun">fitfun</code></td>
<td>
<p>fitfun a function that takes the arguments x, y as above, 
and additionally the number of variables to include in each model q. 
The function then needs to fit the model and to return a logical vector 
that indicates which variable was selected (among the q selected variables).
The name of the function should be prefixed by 'stabs::'.</p>
</td></tr>
<tr><td><code id="stat.stability_selection_+3A_...">...</code></td>
<td>
<p>additional arguments specific to 'stabs' (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>stabs</code> package to compute
variable selection stability. The selection stability of the j-th 
variable is defined as its probability of being selected upon random
subsampling of the data. The default method for selecting variables 
in each subsampled dataset is <code><a href="stabs.html#topic+lars.lasso">lars.lasso</a></code>.
</p>
<p>For a complete list of the available additional arguments, see <code><a href="stabs.html#topic+stabsel">stabsel</a></code>.
</p>


<h3>Value</h3>

<p>A vector of statistics <code class="reqn">W</code> of length p.
</p>


<h3>See Also</h3>

<p>Other statistics: 
<code><a href="#topic+stat.forward_selection">stat.forward_selection</a>()</code>,
<code><a href="#topic+stat.glmnet_coefdiff">stat.glmnet_coefdiff</a>()</code>,
<code><a href="#topic+stat.glmnet_lambdadiff">stat.glmnet_lambdadiff</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff_bin">stat.lasso_coefdiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_coefdiff">stat.lasso_coefdiff</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff_bin">stat.lasso_lambdadiff_bin</a>()</code>,
<code><a href="#topic+stat.lasso_lambdadiff">stat.lasso_lambdadiff</a>()</code>,
<code><a href="#topic+stat.random_forest">stat.random_forest</a>()</code>,
<code><a href="#topic+stat.sqrt_lasso">stat.sqrt_lasso</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2022)
p=50; n=50; k=15
mu = rep(0,p); Sigma = diag(p)
X = matrix(rnorm(n*p),n)
nonzero = sample(p, k)
beta = 3.5 * (1:p %in% nonzero)
y = X %*% beta + rnorm(n)
knockoffs = function(X) create.gaussian(X, mu, Sigma)

# Basic usage with default arguments
result = knockoff.filter(X, y, knockoffs=knockoffs,
                         statistic=stat.stability_selection)
print(result$selected)


</code></pre>

<hr>
<h2 id='verify_stat_depends'>Verify dependencies for chosen statistics</h2><span id='topic+verify_stat_depends'></span>

<h3>Description</h3>

<p>Verify dependencies for chosen statistics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verify_stat_depends(statistic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="verify_stat_depends_+3A_statistic">statistic</code></td>
<td>
<p>the statistic chosen by the user</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
