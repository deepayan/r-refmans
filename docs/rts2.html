<!DOCTYPE html><html><head><title>Help for package rts2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rts2}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#birmingham_crime'><p>Birmingham crime data</p></a></li>
<li><a href='#boundary'><p>Boundary polygon for Birmingham, UK</p></a></li>
<li><a href='#coef.rtsFit'><p>Extracts coefficients from a mcml object</p></a></li>
<li><a href='#covariance.parameters'><p>Extracts the estimates of the covariance parameters</p></a></li>
<li><a href='#create_points'><p>Create sf object from point location data</p></a></li>
<li><a href='#example_points'><p>Simulated point data for running single-period examples</p></a></li>
<li><a href='#fixed.effects'><p>Extracts the fixed effect estimates</p></a></li>
<li><a href='#grid'><p>An rts grid object</p></a></li>
<li><a href='#logLik.rtsFit'><p>Extracts the log-likelihood from an mcml object</p></a></li>
<li><a href='#print.rtsFit'><p>Prints an rtsFit fit output</p></a></li>
<li><a href='#print.rtsFitSummary'><p>Prints an rtsFitSummary fit output</p></a></li>
<li><a href='#progress_bar'><p>Generates a progress bar</p></a></li>
<li><a href='#random.effects'><p>Extracts the random effect estimates</p></a></li>
<li><a href='#rts2-package'><p>The 'rts2' package.</p></a></li>
<li><a href='#summary.rtsFit'><p>Summary method for class &quot;rtsFit&quot;</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Real-Time Disease Surveillance</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-07</td>
</tr>
<tr>
<td>Description:</td>
<td>Supports modelling real-time case data to facilitate the real-time
    surveillance of infectious diseases and other point phenomena. The package provides automated computational grid generation over
    an area of interest with methods to map covariates between geographies, model fitting including spatially aggregated case counts, 
    and predictions and visualisation. Both Bayesian and maximum likelihood methods are provided. Log-Gaussian Cox Processes are described by 
    Diggle et al. (2013) &lt;<a href="https://doi.org/10.1214%2F13-STS441">doi:10.1214/13-STS441</a>&gt; and we provide both the low-rank approximation for Gaussian processes 
    described by Solin and Särkkä (2020) &lt;<a href="https://doi.org/10.1007%2Fs11222-019-09886-w">doi:10.1007/s11222-019-09886-w</a>&gt; and Riutort-Mayol et al (2020) &lt;<a href="https://arxiv.org/abs/2004.11408">arXiv:2004.11408</a>&gt; and the
    nearest neighbour Gaussian process described by Datta et al (2016) &lt;<a href="https://doi.org/10.1080%2F01621459.2015.1044091">doi:10.1080/01621459.2015.1044091</a>&gt;. 'cmdstanr' can be downloaded at <a href="https://mc-stan.org/cmdstanr/">https://mc-stan.org/cmdstanr/</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), sf (&ge; 1.0-14)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, R6, Rcpp (&ge; 0.12.0), RcppParallel (&ge; 5.0.1), rstan
(&ge; 2.26.0), rstantools (&ge; 2.1.1), lubridate</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cmdstanr (&ge; 0.4.0), testthat</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH (&ge; 1.66.0), Rcpp (&ge; 0.12.0), RcppEigen (&ge; 0.3.3.3.0),
RcppParallel (&ge; 5.0.1), rstan (&ge; 2.26.0), StanHeaders (&ge;
2.32.0), glmmrBase (&ge; 0.7.1), SparseChol (&ge; 0.2.2)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-07 16:42:42 UTC; samue</td>
</tr>
<tr>
<td>Author:</td>
<td>Sam Watson <a href="https://orcid.org/0000-0002-8972-769X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sam Watson &lt;s.i.watson@bham.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-08 09:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='birmingham_crime'>Birmingham crime data</h2><span id='topic+birmingham_crime'></span>

<h3>Description</h3>

<p>Counts of burglaries for the months of 2022 for the city of Birmingham, UK at the
Middle-Layer Super Output Area.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>birmingham_crime
</code></pre>


<h3>Format</h3>

<p>An object of class <code>sf</code> (inherits from <code>data.frame</code>) with 132 rows and 21 columns.
</p>

<hr>
<h2 id='boundary'>Boundary polygon for Birmingham, UK</h2><span id='topic+boundary'></span>

<h3>Description</h3>

<p>A Boundary polygon describing the border of the city of Birmingham, UK.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boundary
</code></pre>


<h3>Format</h3>

<p>An object of class <code>sf</code> (inherits from <code>data.frame</code>) with 1 rows and 2 columns.
</p>

<hr>
<h2 id='coef.rtsFit'>Extracts coefficients from a mcml object</h2><span id='topic+coef.rtsFit'></span>

<h3>Description</h3>

<p>Extracts the coefficients from an <code>mcml</code> object returned from a call of <code>MCML</code> or <code>LA</code> in the <a href="glmmrBase.html#topic+Model">Model</a> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rtsFit'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.rtsFit_+3A_object">object</code></td>
<td>
<p>An <code>mcml</code> model fit.</p>
</td></tr>
<tr><td><code id="coef.rtsFit_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame summarising the parameters including the random effects.
</p>

<hr>
<h2 id='covariance.parameters'>Extracts the estimates of the covariance parameters</h2><span id='topic+covariance.parameters'></span>

<h3>Description</h3>

<p>Extracts the estimates of the covariance parameters an <code style="white-space: pre;">&#8288;rtsFit object&#8288;</code> returned from call of <code>lgcp_ml()</code> or <code>lgcp_bayes()</code> in the <a href="#topic+grid">grid</a> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covariance.parameters(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covariance.parameters_+3A_object">object</code></td>
<td>
<p>An <code>mcml</code> model fit.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of dimension (number of fixed effects ) x (number of MCMC samples). For Laplace approximation, the number of &quot;samples&quot; equals one.
</p>

<hr>
<h2 id='create_points'>Create sf object from point location data</h2><span id='topic+create_points'></span>

<h3>Description</h3>

<p>Produces an sf object with location and time of cases from a data frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_points(
  data,
  pos_vars = c("lat", "long"),
  t_var,
  format = "%Y-%m-%d",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_points_+3A_data">data</code></td>
<td>
<p>data.frame with the x- and y-coordinate of case locations and the date
of the case.</p>
</td></tr>
<tr><td><code id="create_points_+3A_pos_vars">pos_vars</code></td>
<td>
<p>vector of length two with the names of the columns
containing the y and x coordinates, respectively.</p>
</td></tr>
<tr><td><code id="create_points_+3A_t_var">t_var</code></td>
<td>
<p>character string with the name of the column with the date of the case. If single-period
analysis then set t_var to NULL.</p>
</td></tr>
<tr><td><code id="create_points_+3A_format">format</code></td>
<td>
<p>character string with the format of the date specified by t_var. See
<a href="base.html#topic+strptime">strptime</a></p>
</td></tr>
<tr><td><code id="create_points_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether to print information</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a data frame containing the point location and date of cases, the function
will return an sf object of the points with the date information.
</p>


<h3>Value</h3>

<p>An sf object of the same size as <code>data</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
</code></pre>

<hr>
<h2 id='example_points'>Simulated point data for running single-period examples</h2><span id='topic+example_points'></span>

<h3>Description</h3>

<p>A set of 261 points simulated within the boundary of the city Birmingham, UK
from a log-Gaussian Cox process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example_points
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 261 rows and 3 columns.
</p>

<hr>
<h2 id='fixed.effects'>Extracts the fixed effect estimates</h2><span id='topic+fixed.effects'></span>

<h3>Description</h3>

<p>Extracts the fixed effect estimates from an <code style="white-space: pre;">&#8288;rtsFit object&#8288;</code> returned from call of <code>lgcp_ml()</code> or <code>lgcp_bayes()</code> in the <a href="#topic+grid">grid</a> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixed.effects(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixed.effects_+3A_object">object</code></td>
<td>
<p>An <code>mcml</code> model fit.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named, numeric vector of fixed-effects estimates.
</p>

<hr>
<h2 id='grid'>An rts grid object</h2><span id='topic+grid'></span>

<h3>Description</h3>

<p>An rts grid object
</p>
<p>An rts grid object
</p>


<h3>Details</h3>

<p>An rts grid object is an R6 class holding the spatial data with data, model fitting, and analysis functions.
</p>
<p><strong>INTRODUCTION</strong>
</p>
<p>The various methods of the class include examples and details of their implementation. The <span class="pkg">sf</span> package is used for
all spatial data. A typical workflow with this class would
be:
</p>

<ol>
<li><p> Create a new grid object. The class is initialized with either a single polygon describing the area of interest or a collection
of polygons if spatially aggregated data are used.
</p>
</li>
<li><p> If the location (and times) of cases are available (i.e. the data are not spatially aggregated), then we map the points to the computational
grid. The function <a href="#topic+create_points">create_points</a> can generate point data in the correct <span class="pkg">sf</span> format. The member function <code>points_to_grid</code> will then
map these data to the grid. Counts can also be manually added to grid data. For region data, since the counts are assumed to be already aggregated, these
must be manually provided by the user. The case counts must appear in columns with specific names. If there is only a single time period then the counts
must be in a column named <code>y</code>. If there are multiple time periods then the counts must be in columns names <code>t1</code>, <code>t2</code>, <code>t3</code>,... Associated columns labelled
<code>date1</code>, <code>date2</code>, etc. will permit use of some functionality regarding specific time intervals.
</p>
</li>
<li><p> If any covariates are to be used for the modelling, then these can be mapped to the compuational grid using the function <code>add_covariates()</code>. Other
functions, <code>add_time_indicators()</code> and <code>get_dow()</code> will also generate relevant temporal indicators where required. At a minimum we would recommend including
a measure of population density.
</p>
</li>
<li><p> Fit a model. There are multiple methods for model fitting, which are available through the member functions <code>lgcp_ml()</code> and <code>lgcp_bayes()</code> for maximum likelihood
and Bayesian approaches, respectively. The results are stored internally and optionally returned as a <code>rtsFit</code> object.
</p>
</li>
<li><p> Summarise the output. The main functions for summarising the output are <code>extract_preds()</code>, which will generate predictions of relative risk, incidence rate
ratios, and predicted incidence, and <code>hotspots()</code>, which will estimate probabilities that these statistics exceed given thresholds. For spatially-aggregated data models,
the relative risk applies to the grid, whereas rate ratios and predicted incidence applies to the areas.
</p>
</li>
<li><p> Predictions can be visualised or aggregated to relevant geographies with the <code>plot()</code> and <code>aggregate()</code> functions.
</p>
</li></ol>

<p>Specific details of the implementation of each of these functions along with examples appear below.
</p>
<p><strong>PLOTTING</strong>
</p>
<p>If <code>zcol</code> is not specified then only the geometry is plotted, otherwise the covariates specified will be plotted.
The user can also use sf plotting functions on self$grid_data and self$region_data directly.
</p>
<p><strong>POINTS TO GRID</strong>
</p>
<p>Given the sf object with the point locations and date output from
<code>create_points()</code>, the functions will add columns to <code>grid_data</code> indicating
the case count in each cell in each time period.
</p>
<p>Case counts are generated for each grid cell for each time period. The user
can specify the length of each time period; currently <code>day</code>, <code>week</code>, and <code>month</code>
are supported.
</p>
<p>The user must also specify the number of time periods to include with the
<code>laglength</code> argument. The total number of time periods is the specified lag
length counting back from the most recent case. The columns in the output
will be named <code>t1</code>, <code>t2</code>,... up to the lag length, where the highest number
is the most recent period.
</p>
<p><strong>ADDING COVARIATES</strong>
</p>
<p><em>Spatially-varying data only</em>
</p>
<p><code>cov_data</code> is an sf object describing covariate
values for a set of polygons over the area of interest. The values are mapped
onto <code>grid_data</code>. For each grid cell in <code>grid_data</code> a weighted
average of each covariate listed in <code>zcols</code> is generated with weights either
equal to the area of intersection of the grid cell and the polygons in
<code>cov_data</code> (<code>weight_type="area"</code>), or this area multiplied by the population
density of the polygon for population weighted (<code>weight_type="pop"</code>). Columns
with the names in <code>zcols</code> are added to the output.
</p>
<p><em>Temporally-varying only data</em>
</p>
<p><code>cov_data</code> is a data frame with number of rows
equal to the number of time periods. One of the columns must be called <code>t</code> and
have values from 1 to the number of time periods. The other columns of the data
frame have the values of the covariates for each time period. See
<code>get_dow()</code> for day of week data. A total of
length(zcols)*(number of time periods) columns are added to the output: for each
covariate there will be columns appended with each time period number. For example,
<code>dayMon1</code>, <code>dayMon2</code>, etc.
</p>
<p><em>Spatially and temporally varying data</em>
</p>
<p>There are two ways to add data that
vary both spatially and temporally. The final output for use in analysis must
have a column for each covariate and each time period with the same name appended
by the time period number, e.g. <code>covariateA1</code>,<code>covariateA2</code>,... If the covariate
values for different time periods are in separate sf objects, one can follow
the method for spatially-varying only data above and append the time period number
using the argument <code>t_label</code>. If the values for different time periods are in the same
sf object then they should be named as described above and then can be added
as for spatially-varying covariates, e.g. <code>zcols=c("covariateA1","covariateA2")</code>.
</p>
<p><strong>BAYESIAN MODEL FITTING</strong>
</p>
<p>The grid data must contain columns <code style="white-space: pre;">&#8288;t*&#8288;</code>, giving the case
count in each time period (see <code>points_to_grid</code>), as well as any covariates to include in the model
(see <code>add_covariates</code>) and the population density. Otherwise, if the data are regional data, then the outcome
counts must be in self$region_data
</p>
<p>Our statistical model is a Log Gaussian cox process,
whose realisation is observed on the Cartesian area of interest
A and time period T. The resulting data are relaisations of an inhomogeneous
Poisson process with stochastic intensity function <code class="reqn">\{\lambda{s,t}:s\in A, t \in T\}</code>.
We specify a log-linear model for the intensity:
</p>
<p style="text-align: center;"><code class="reqn">\lambda(s,t) = r(s,t)exp(X(s,t)'\gamma + Z(s,t))</code>
</p>

<p>where r(s,t) is a spatio-temporally varying Poisson offset.
X(s,t) is a length Q vector of covariates including an intercept and
Z(s,t) is a latent field. We use an auto-regressive specification for the
latent field, with spatial innovation in each field specified as a spatial
Gaussian process.
</p>
<p>The argument <code>approx</code> specifies whether to use a full LGCP model (<code>approx='none'</code>) or whether
to use either a nearest neighbour approximation (<code>approx='nngp'</code>) or a &quot;Hilbert space&quot; approximation
(<code>approx='hsgp'</code>). For full details of NNGPs see XX and for Hilbert space approximations see references (1) and (2).
</p>
<p><em>Priors</em>
</p>
<p>For Bayesian model fitting, the priors should be provided as a list to the griddata object:
</p>
<div class="sourceCode"><pre>griddata$priors &lt;- list(
  prior_lscale=c(0,0.5),
  prior_var=c(0,0.5),
  prior_linpred_mean=c(-5,rep(0,7)),
  prior_linpred_sd=c(3,rep(1,7))
)
</pre></div>
<p>where these refer to the priors:
<code>prior_lscale</code>: the length scale parameter has a half-normal prior <code class="reqn">N(a,b^2)I[0,\infty)</code>. The vector is <code>c(a,b)</code>.
<code>prior_var</code>: the standard deviation term has a half normal prior <code class="reqn">\sigma ~ N(a,b^2)I[0,\infty)</code>. The vector is <code>c(a,b)</code>.
<code>prior_linpred_mean</code> and <code>prior_linpred_sd</code>: The parameters of the linear predictor.
If X is the nT x Q matrix of covariates, with the first column as ones for the intercept,
then the linear prediction contains the term <code class="reqn">X'\gamma</code>. Each parameter in <code class="reqn">\gamma</code> has prior
<code class="reqn">\gamma_q ~ N(a_q,b_q^2)</code>.
<code>prior_linpred_mean</code> should be the vector <code style="white-space: pre;">&#8288;(a_1,a_2,...,a_Q)&#8288;</code> and
<code>prior_linpred_sd</code> should be <code style="white-space: pre;">&#8288;(b_1,b_2,...,b_Q)&#8288;</code>.
</p>
<p><strong>MAXIMUM LIKELIHOOD MODEL FITTING</strong>
</p>
<p>The grid data must contain columns <code style="white-space: pre;">&#8288;t*&#8288;</code>, giving the case
count in each time period (see <code>points_to_grid</code>), as well as any covariates to include in the model
(see <code>add_covariates</code>) and the population density. Otherwise, if the data are regional data, then the outcome
counts must be in self$region_data. See <code>lgcp_bayes()</code> for more details on the model.
</p>
<p>The argument <code>approx</code> specifies whether to use a full LGCP model (<code>approx='none'</code>) or whether
to use either a nearest neighbour approximation (<code>approx='nngp'</code>)
</p>
<p>Model fitting uses one of several stochastic maximum likelihood algorithms, which have three steps:
</p>

<ol>
<li><p> Sample random effects using MCMC. Using cmdstanr is recommended as it is much faster. The arguments
<code>mcmc_warmup</code> and <code>mcmc_sampling</code> specify the warmup and sampling iterations for this step.
</p>
</li>
<li><p> Fit fixed effect parameters using expectation maximisation.
</p>
</li>
<li><p> Fit covariance parameters using expectation maximisation. This third step is the slowest. The NNGP approximation
provides some speed improvements. Otherwise this step can be skipped if the covaraince parameters are &quot;known&quot;.
The argument <code>algo</code> specifies the algorithm, the user can select either MCMC maximum likelihood or stochastic approximation
expectation maximisation with or without Ruppert-Polyak averaging. MCMC-ML can be used with or without adaptive MCMC sample sizes
and either a derivative free or quasi-Newton optimiser (depending on the underlying model).
</p>
</li></ol>

<p><strong>EXTRACTING PREDICTIONS</strong>
</p>
<p>Three outputs can be extracted from the model fit, which will be added as columns to <code>grid_data</code>:
</p>
<p>Predicted incidence: If type includes <code>pred</code> then <code>pred_mean_total</code> and
<code>pred_mean_total_sd</code> provide the
predicted mean total incidence and its standard deviation, respectively.
<code>pred_mean_pp</code> and <code>pred_mean_pp_sd</code> provide the predicted population
standardised incidence and its standard deviation.
</p>
<p>Relative risk: if type includes <code>rr</code> then the relative risk is reported in
the columns <code>rr</code> and <code>rr_sd</code>. The relative risk here is the exponential
of the latent field, which describes the relative difference between
expexted mean and predicted mean incidence.
</p>
<p>Incidence risk ratio: if type includes <code>irr</code> then the incidence rate ratio (IRR)
is reported in the columns <code>irr</code> and <code>irr_sd</code>. This is the ratio of the predicted
incidence in the last period (minus <code>t_lag</code>) to the predicted incidence in the
last period minus <code>irr_lag</code> (minus <code>t_lag</code>). For example, if the time period
is in days then setting <code>irr_lag</code> to 7 and leaving <code>t_lag=0</code> then the IRR
is the relative change in incidence in the present period compared to a week
prior.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>grid_data</code></dt><dd><p>sf object specifying the computational grid for the analysis</p>
</dd>
<dt><code>region_data</code></dt><dd><p>sf object specifying an irregular lattice, such as census areas,
within which case counts are aggregated. Only used if polygon data are provided on
class initialisation.</p>
</dd>
<dt><code>priors</code></dt><dd><p>list of prior distributions for the analysis</p>
</dd>
<dt><code>bobyqa_control</code></dt><dd><p>list of control parameters for the BOBYQA algorithm, must contain named
elements any or all of <code>npt</code>, <code>rhobeg</code>, <code>rhoend</code>, <code>covrhobeg</code>, <code>covrhoend</code>.
Only has an effect for the HSGP and NNGP approximations. The latter two parameters control the
covariance parameter optimisation, while the former control the linear predictor.</p>
</dd>
<dt><code>boundary</code></dt><dd><p>sf object showing the boundary of the area of interest</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-grid-new"><code>grid$new()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-print"><code>grid$print()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-plot"><code>grid$plot()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-points_to_grid"><code>grid$points_to_grid()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-add_covariates"><code>grid$add_covariates()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-get_dow"><code>grid$get_dow()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-add_time_indicators"><code>grid$add_time_indicators()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-lgcp_bayes"><code>grid$lgcp_bayes()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-lgcp_ml"><code>grid$lgcp_ml()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-extract_preds"><code>grid$extract_preds()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-hotspots"><code>grid$hotspots()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-aggregate_output"><code>grid$aggregate_output()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-scale_conversion_factor"><code>grid$scale_conversion_factor()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-get_region_data"><code>grid$get_region_data()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-variogram"><code>grid$variogram()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-reorder"><code>grid$reorder()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-data"><code>grid$data()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-get_random_effects"><code>grid$get_random_effects()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-model_fit"><code>grid$model_fit()</code></a>
</p>
</li>
<li> <p><a href="#method-grid-clone"><code>grid$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-grid-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new grid object
</p>
<p>Produces a regular grid over an area of interest as an sf object, see details for information on initialisation.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$new(poly, cellsize, verbose = TRUE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>poly</code></dt><dd><p>An sf object containing either one polygon describing the area of interest or multiple polygons
representing survey or census regions in which the case data counts are aggregated</p>
</dd>
<dt><code>cellsize</code></dt><dd><p>The dimension of the grid cells</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Logical indicating whether to provide feedback to the console.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>NULL
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre># a simple example with a square and a small number of cells
# this same running example is used for the other functions 
b1 = sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)

# an example with multiple polygons
data("birmingham_crime")
g2 &lt;- grid$new(birmingham_crime,cellsize = 1000)
</pre>
</div>


<hr>
<a id="method-grid-print"></a>



<h4>Method <code>print()</code></h4>

<p>Prints this object
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$print()</pre></div>



<h5>Returns</h5>

<p>None. called for effects.
</p>


<hr>
<a id="method-grid-plot"></a>



<h4>Method <code>plot()</code></h4>

<p>Plots the grid data
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$plot(zcol)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>zcol</code></dt><dd><p>Vector of strings specifying names of columns of <code>grid_data</code> to plot</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A plot
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>b1 = sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
g1$plot()

# a plot with covariates - we simulate covariates first
g1$grid_data$cov &lt;- stats::rnorm(nrow(g1$grid_data))
g1$plot("cov")
</pre>
</div>


<hr>
<a id="method-grid-points_to_grid"></a>



<h4>Method <code>points_to_grid()</code></h4>

<p>Generates case counts of points over the grid
</p>
<p>Counts the number of cases in each time period in each grid cell
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$points_to_grid(
  point_data,
  t_win = c("day"),
  laglength = 14,
  verbose = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>point_data</code></dt><dd><p>sf object describing the point location of cases with a column
<code>t</code> of the date of the case in YYYY-MM-DD format. See <a href="#topic+create_points">create_points</a></p>
</dd>
<dt><code>t_win</code></dt><dd><p>character string. One of &quot;day&quot;, &quot;week&quot;, or &quot;month&quot; indicating the
length of the time windows in which to count cases</p>
</dd>
<dt><code>laglength</code></dt><dd><p>integer The number of time periods to include counting back from the most
recent time period</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Logical indicating whether to report detailed output</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>NULL
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
# simulate some points
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20)) 
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
g1$points_to_grid(dp, laglength=5)
</pre>
</div>


<hr>
<a id="method-grid-add_covariates"></a>



<h4>Method <code>add_covariates()</code></h4>

<p>Adds covariate data to the grid
</p>
<p>Maps spatial, temporal, or spatio-temporal covariate data onto the grid.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$add_covariates(
  cov_data,
  zcols,
  weight_type = "area",
  popdens = NULL,
  verbose = TRUE,
  t_label = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>cov_data</code></dt><dd><p>sf object or data.frame. See details.</p>
</dd>
<dt><code>zcols</code></dt><dd><p>vector of character strings with the names of the columns of <code>cov_data</code>
to include</p>
</dd>
<dt><code>weight_type</code></dt><dd><p>character string. Either &quot;area&quot; for area-weighted average or &quot;pop&quot;
for population-weighted average</p>
</dd>
<dt><code>popdens</code></dt><dd><p>character string. The name of the column in <code>cov_data</code> with the
population density. Required if weight_type=&quot;pop&quot;</p>
</dd>
<dt><code>verbose</code></dt><dd><p>logical. Whether to provide a progress bar</p>
</dd>
<dt><code>t_label</code></dt><dd><p>integer. If adding spatio-temporally varying data by time period,
this time label should be appended to the column name. See details.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>NULL
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>b1 &lt;-  sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)

\donttest{
# mapping population data from some other polygons
data("boundary")
data("birmingham_crime")
g2 &lt;- grid$new(boundary,cellsize=0.008)
msoa &lt;- sf::st_transform(birmingham_crime,crs = 4326)
suppressWarnings(sf::st_crs(msoa) &lt;- sf::st_crs(g2$grid_data)) # ensure crs matches
g2$add_covariates(msoa,
                  zcols="pop",
                  weight_type="area",
                  verbose=FALSE)
g2$plot("pop")
}
</pre>
</div>


<hr>
<a id="method-grid-get_dow"></a>



<h4>Method <code>get_dow()</code></h4>

<p>Generate day of week data
</p>
<p>Create data frame with day of week indicators
</p>
<p>Generates a data frame with indicator
variables for each day of the week for use in the <code>add_covariates()</code> function.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$get_dow()</pre></div>



<h5>Returns</h5>

<p>data.frame with columns <code>t</code>, <code>day</code>, and <code>dayMon</code> to <code>daySun</code>
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
g1$points_to_grid(dp, laglength=5)
dow &lt;- g1$get_dow()
g1$add_covariates(dow,zcols = colnames(dow)[3:ncol(dow)])
</pre>
</div>


<hr>
<a id="method-grid-add_time_indicators"></a>



<h4>Method <code>add_time_indicators()</code></h4>

<p>Adds time period indicators to the data
</p>
<p>Adds indicator variables for each time period to the data. To include
these in a model fitting procedure use, for example, <code style="white-space: pre;">&#8288;covs = c("time1i, time2i,...)&#8288;</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$add_time_indicators()</pre></div>



<h5>Returns</h5>

<p>Nothing. Called for effects.
</p>


<hr>
<a id="method-grid-lgcp_bayes"></a>



<h4>Method <code>lgcp_bayes()</code></h4>

<p>Fit an (approximate) log-Gaussian Cox Process model using Bayesian methods
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$lgcp_bayes(
  popdens,
  covs = NULL,
  covs_grid = NULL,
  approx = "nngp",
  m = 10,
  L = 1.5,
  model = "exp",
  known_theta = NULL,
  iter_warmup = 500,
  iter_sampling = 500,
  chains = 3,
  parallel_chains = 3,
  verbose = TRUE,
  vb = FALSE,
  use_cmdstanr = FALSE,
  return_stan_fit = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>popdens</code></dt><dd><p>character string. Name of the population density column</p>
</dd>
<dt><code>covs</code></dt><dd><p>vector of character string. Base names of the covariates to
include. For temporally-varying covariates only the stem is required and not
the individual column names for each time period (e.g. <code>dayMon</code> and not <code>dayMon1</code>,
<code>dayMon2</code>, etc.)</p>
</dd>
<dt><code>covs_grid</code></dt><dd><p>If using a region model, covariates at the level of the grid can also be specified by providing their
names to this argument.</p>
</dd>
<dt><code>approx</code></dt><dd><p>Either &quot;rank&quot; for reduced rank approximation, or &quot;nngp&quot; for nearest
neighbour Gaussian process.</p>
</dd>
<dt><code>m</code></dt><dd><p>integer. Number of basis functions for reduced rank approximation, or
number of nearest neighbours for nearest neighbour Gaussian process. See Details.</p>
</dd>
<dt><code>L</code></dt><dd><p>integer. For reduced rank approximation, boundary condition as proportionate extension of area, e.g.
<code>L=2</code> is a doubling of the analysis area. See Details.</p>
</dd>
<dt><code>model</code></dt><dd><p>Either &quot;exp&quot; for exponential covariance function or &quot;sqexp&quot; for squared exponential
covariance function</p>
</dd>
<dt><code>known_theta</code></dt><dd><p>An optional vector of two values of the covariance parameters. If these are provided
then the covariance parameters are assumed to be known and will not be estimated.</p>
</dd>
<dt><code>iter_warmup</code></dt><dd><p>integer. Number of warmup iterations</p>
</dd>
<dt><code>iter_sampling</code></dt><dd><p>integer. Number of sampling iterations</p>
</dd>
<dt><code>chains</code></dt><dd><p>integer. Number of chains</p>
</dd>
<dt><code>parallel_chains</code></dt><dd><p>integer. Number of parallel chains</p>
</dd>
<dt><code>verbose</code></dt><dd><p>logical. Provide feedback on progress</p>
</dd>
<dt><code>vb</code></dt><dd><p>Logical indicating whether to use variational Bayes (TRUE) or full MCMC sampling (FALSE)</p>
</dd>
<dt><code>use_cmdstanr</code></dt><dd><p>logical. Defaults to false. If true then cmdstanr will be used
instead of rstan.</p>
</dd>
<dt><code>return_stan_fit</code></dt><dd><p>logical. The results of the model fit are stored internally as an <code>rstFit</code> object and
returned in that format. If this argument is set to TRUE, then the fitted stan object will instead be returned,
but the <code>rtsFit</code> object will still be saved.</p>
</dd>
<dt><code>...</code></dt><dd><p>additional options to pass to '$sample()&ldquo;.</p>
</dd>
<dt><code>priors</code></dt><dd><p>list. See Details</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A <a href="rstan.html#topic+stanfit">stanfit</a> or a <code>CmdStanMCMC</code> object
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre># the data are just random simulated points 
b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)
g1$points_to_grid(dp, laglength=5)
g1$priors &lt;- list(
  prior_lscale=c(0,0.5),
  prior_var=c(0,0.5),
  prior_linpred_mean=c(0),
  prior_linpred_sd=c(5)
  )
\donttest{
g1$lgcp_bayes(popdens="cov", approx = "hsgp", parallel_chains = 0)
g1$model_fit()
# we can extract predictions
g1$extract_preds("rr")
g1$plot("rr")
g1$hotspots(rr.threshold = 2)

 # this example uses real aggregated data but will take a relatively long time to run
 data("birmingham_crime")
 example_data &lt;- birmingham_crime[,c(1:8,21)]
 example_data$y &lt;- birmingham_crime$t12
 g2 &lt;- grid$new(example_data,cellsize=1000)
 g2$priors &lt;- list(
  prior_lscale=c(0,0.5),
  prior_var=c(0,0.5),
  prior_linpred_mean=c(-3),
  prior_linpred_sd=c(5)
)
g2$lgcp_bayes(popdens="pop", approx = "hsgp", parallel_chains = 0)
g2$model_fit()
g2$extract_preds("rr")
g2$plot("rr")
g2$hotspots(rr.threshold = 2)
}
</pre>
</div>


<hr>
<a id="method-grid-lgcp_ml"></a>



<h4>Method <code>lgcp_ml()</code></h4>

<p>Fit an (approximate) log-Gaussian Cox Process model using Maximum Likelihood
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$lgcp_ml(
  popdens,
  covs = NULL,
  covs_grid = NULL,
  approx = "nngp",
  m = 10,
  L = 1.5,
  model = "exp",
  known_theta = NULL,
  starting_values = NULL,
  lower_bound = NULL,
  upper_bound = NULL,
  formula_1 = NULL,
  formula_2 = NULL,
  algo = 4,
  alpha = 0.7,
  conv_criterion = 1,
  tol = 0.01,
  max.iter = 30,
  iter_warmup = 100,
  iter_sampling = 250,
  trace = 1,
  use_cmdstanr = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>popdens</code></dt><dd><p>character string. Name of the population density column</p>
</dd>
<dt><code>covs</code></dt><dd><p>vector of strings. Base names of the covariates to
include. For temporally-varying covariates only the stem is required and not
the individual column names for each time period (e.g. <code>dayMon</code> and not <code>dayMon1</code>,
<code>dayMon2</code>, etc.) Alternatively, a formula can be passed to the <code>formula</code> arguments below.</p>
</dd>
<dt><code>covs_grid</code></dt><dd><p>If using a region model, covariates at the level of the grid can also be specified by providing their
names to this argument. Alternatively, a formula can be passed to the <code>formula</code> arguments below.</p>
</dd>
<dt><code>approx</code></dt><dd><p>Either &quot;rank&quot; for reduced rank approximation, or &quot;nngp&quot; for nearest
neighbour Gaussian process.</p>
</dd>
<dt><code>m</code></dt><dd><p>integer. Number of basis functions for reduced rank approximation, or
number of nearest neighbours for nearest neighbour Gaussian process. See Details.</p>
</dd>
<dt><code>L</code></dt><dd><p>integer. For reduced rank approximation, boundary condition as proportionate extension of area, e.g.
<code>L=2</code> is a doubling of the analysis area. See Details.</p>
</dd>
<dt><code>model</code></dt><dd><p>Either &quot;exp&quot; for exponential covariance function or &quot;sqexp&quot; for squared exponential
covariance function</p>
</dd>
<dt><code>known_theta</code></dt><dd><p>An optional vector of two values of the covariance parameters. If these are provided
then the covariance parameters are assumed to be known and will not be estimated.</p>
</dd>
<dt><code>starting_values</code></dt><dd><p>An optional list providing starting values of the model parameters. The list can have named elements
<code>gamma</code> for the linear predictor parameters, <code>theta</code> for the covariance parameters, and <code>ar</code> for the auto-regressive parameter.
If there are covariates for the grid in a region data model then their parameters are <code>gamma_g</code>. The list elements must be a
vector of starting values. If this is not provided then the non-intercept linear predictor parameters are initialised randomly
as N(0,0.1), the covariance parameters as Uniform(0,0.5) and the auto-regressive parameter to 0.1.</p>
</dd>
<dt><code>lower_bound</code></dt><dd><p>Optional. Vector of lower bound values for the fixed effect parameters.</p>
</dd>
<dt><code>upper_bound</code></dt><dd><p>Optional. Vector of upper bound values for the fixed effect parameters.</p>
</dd>
<dt><code>formula_1</code></dt><dd><p>Optional. Instead of providing a list of covariates above (to <code>covs</code>) a formula can be specified here. For a regional model, this
argument specified the regional-level fixed effects model.</p>
</dd>
<dt><code>formula_2</code></dt><dd><p>Optional. Instead of providing a list of covariates above (to <code>covs_grid</code>) a formula can be specified here. For a regional model, this
argument specified the grid-level fixed effects model.</p>
</dd>
<dt><code>algo</code></dt><dd><p>integer. 1 = MCMC ML with L-BFGS for beta and non-approximate covariance parameters,
2 = MCMC ML with BOBYQA for both, 3 = MCMC ML with L-BFGS for beta, BOBYQA for covariance parameters,
4 = SAEM with BOBYQA for both, 5 = SAEM with RP averaging and BOBYQA for both (default), 6-8 = as 1-3 but
with adaptive MCMC sample size that starts at 20 with a max of <code>iter_sampling</code></p>
</dd>
<dt><code>alpha</code></dt><dd><p>Optional. Value for alpha in the SAEM parameter.</p>
</dd>
<dt><code>conv_criterion</code></dt><dd><p>Integer. The convergence criterion for the algorithm. 1 = No improvement in the overall log-likelihood with probability 0.95,
2 = No improvement in the log-likelihood for beta with probability 0.95, 3 = Difference between model parameters is less than <code>tol</code> between iterations.</p>
</dd>
<dt><code>tol</code></dt><dd><p>Scalar indicating the upper bound for the maximum absolute difference between parameter estimates on sucessive iterations, after which the algorithm
terminates.</p>
</dd>
<dt><code>max.iter</code></dt><dd><p>Integer. The maximum number of iterations for the algorithm.</p>
</dd>
<dt><code>iter_warmup</code></dt><dd><p>integer. Number of warmup iterations</p>
</dd>
<dt><code>iter_sampling</code></dt><dd><p>integer. Number of sampling iterations</p>
</dd>
<dt><code>trace</code></dt><dd><p>Integer. Level of detail of information printed to the console. 0 = none, 1 = some (default), 2 = most.</p>
</dd>
<dt><code>use_cmdstanr</code></dt><dd><p>logical. Defaults to false. If true then cmdstanr will be used
instead of rstan.</p>
</dd>
<dt><code>...</code></dt><dd><p>additional options to pass to <code style="white-space: pre;">&#8288;$sample()&#8288;</code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Optionally, an <code>rtsFit</code> model fit object. This fit is stored internally and can be retrieved with <code>model_fit()</code>
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre># a simple example with completely random points
b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)
g1$points_to_grid(dp, laglength=5)
\donttest{
g1$lgcp_ml(popdens="cov",iter_warmup = 100, iter_sampling = 50)
g1$model_fit()
g1$extract_preds("rr")
g1$plot("rr")
g1$hotspots(rr.threshold = 2)

# this example uses real aggregated data but will take a relatively long time to run
 data("birmingham_crime")
 example_data &lt;- birmingham_crime[,c(1:8,21)]
 example_data$y &lt;- birmingham_crime$t12
 g2 &lt;- grid$new(example_data,cellsize=1000)
 g2$lgcp_ml(popdens = "pop",iter_warmup = 100, iter_sampling = 50)
 g2$model_fit()
 g2$extract_preds("rr")
 g2$plot("rr")
 g2$hotspots(rr.threshold = 2) 
}

</pre>
</div>


<hr>
<a id="method-grid-extract_preds"></a>



<h4>Method <code>extract_preds()</code></h4>

<p>Extract predictions
</p>
<p>Extract incidence and relative risk predictions. The predictions will be extracted from the last model fit. If no previous model fit then use either <code>lgcp_ml()</code> or <code>lgcp_bayes()</code>, or see
<code>model_fit()</code> to update the stored model fit.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$extract_preds(
  type = c("pred", "rr", "irr"),
  irr.lag = NULL,
  t.lag = 0,
  popdens = NULL,
  verbose = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>type</code></dt><dd><p>Vector of character strings. Any combination of &quot;pred&quot;, &quot;rr&quot;, and &quot;irr&quot;, which are,
posterior mean incidence (overall and population standardised), relative risk,
and incidence rate ratio, respectively.</p>
</dd>
<dt><code>irr.lag</code></dt><dd><p>integer. If &quot;irr&quot; is requested as <code>type</code> then the number of time
periods lag previous the ratio is in comparison to</p>
</dd>
<dt><code>t.lag</code></dt><dd><p>integer. Extract predictions for previous time periods.</p>
</dd>
<dt><code>popdens</code></dt><dd><p>character string. Name of the column in <code>grid_data</code> with the
population density data</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Logical indicating whether to print messages to the console</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>NULL
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre># See examples for lgcp_bayes() and lgcp_ml()
</pre>
</div>


<hr>
<a id="method-grid-hotspots"></a>



<h4>Method <code>hotspots()</code></h4>

<p>Generate hotspot probabilities
</p>
<p>Generate hotspot probabilities. The last model fit will be used to extract
predictions. If no previous model fit then use either <code>lgcp_ml()</code> or <code>lgcp_bayes()</code>, or see
<code>model_fit()</code> to update the stored model fit.
</p>
<p>Given a definition of a hotspot in terms of threshold(s) for incidence,
relative risk, and/or incidence rate ratio, returns the probabilities
each area is a &quot;hotspot&quot;. See Details of <code>extract_preds</code>. Columns
will be added to <code>grid_data</code>. Note that for incidence threshold, the threshold should
be specified as the per individual incidence.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$hotspots(
  incidence.threshold = NULL,
  irr.threshold = NULL,
  irr.lag = 1,
  rr.threshold = NULL,
  t.lag = 0,
  popdens,
  col_label = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>incidence.threshold</code></dt><dd><p>Numeric. Threshold of population standardised incidence
above which an area is a hotspot</p>
</dd>
<dt><code>irr.threshold</code></dt><dd><p>Numeric. Threshold of incidence rate ratio
above which an area is a hotspot.</p>
</dd>
<dt><code>irr.lag</code></dt><dd><p>integer. Lag of time period to calculate the incidence rate ratio.
Only required if <code>irr.threshold</code> is not <code>NULL</code>.</p>
</dd>
<dt><code>rr.threshold</code></dt><dd><p>numeric. Threshold of local relative risk
above which an area is a hotspot</p>
</dd>
<dt><code>t.lag</code></dt><dd><p>integer. Extract predictions for incidence or relative risk for previous time periods.</p>
</dd>
<dt><code>popdens</code></dt><dd><p>character string. Name of variable in <code>grid_data</code>
specifying the population density. Needed if <code>incidence.threshold</code> is not
<code>NULL</code></p>
</dd>
<dt><code>col_label</code></dt><dd><p>character string. If not NULL then the name of the column
for the hotspot probabilities.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>None, called for effects. Columns are added to grid or region data.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>\dontrun{
# See examples for lgcp_bayes() and lgcp_ml()
}
</pre>
</div>


<hr>
<a id="method-grid-aggregate_output"></a>



<h4>Method <code>aggregate_output()</code></h4>

<p>Aggregate output
</p>
<p>Aggregate <code>lgcp_fit</code> output to another geography
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$aggregate_output(
  new_geom,
  zcols,
  weight_type = "area",
  popdens = NULL,
  verbose = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>new_geom</code></dt><dd><p>sf object. A set of polygons covering the same area as <code>boundary</code></p>
</dd>
<dt><code>zcols</code></dt><dd><p>vector of character strings. Names of the variables in <code>grid_data</code> to
map to the new geography</p>
</dd>
<dt><code>weight_type</code></dt><dd><p>character string, either &quot;area&quot; or &quot;pop&quot; for area-weighted
or population weighted averaging, respectively</p>
</dd>
<dt><code>popdens</code></dt><dd><p>character string. If <code>weight_type</code> is equal to &quot;pop&quot; then the
name of the column in <code>grid_data</code> with population density data</p>
</dd>
<dt><code>verbose</code></dt><dd><p>logical. Whether to provide progress bar.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>An <code>sf</code> object identical to <code>new_geom</code> with additional columns with the
variables specified in <code>zcols</code>
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>\donttest{
b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)
g1$points_to_grid(dp, laglength=5)
g1$priors &lt;- list(
  prior_lscale=c(0,0.5),
  prior_var=c(0,0.5),
  prior_linpred_mean=c(0),
  prior_linpred_sd=c(5)
  )
res &lt;- g1$lgcp_bayes(popdens="cov", parallel_chains = 1)
g1$extract_preds(res,
                 type=c("pred","rr"),
                 popdens="cov")
new1 &lt;- g1$aggregate_output(cov1$grid_data,
                            zcols="rr")
}
</pre>
</div>


<hr>
<a id="method-grid-scale_conversion_factor"></a>



<h4>Method <code>scale_conversion_factor()</code></h4>

<p>Returns scale conversion factor
</p>
<p>Coordinates are scaled to <code style="white-space: pre;">&#8288;[-1,1]&#8288;</code> for LGCP models fit with HSGP. This function
returns the scaling factor for this conversion.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$scale_conversion_factor()</pre></div>



<h5>Returns</h5>

<p>numeric
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>b1 = sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
g1$scale_conversion_factor()
</pre>
</div>


<hr>
<a id="method-grid-get_region_data"></a>



<h4>Method <code>get_region_data()</code></h4>

<p>Returns summary data of the region/grid intersections
</p>
<p>Information on the intersection between the region areas and the computational grid
including the number of cells intersecting each region (<code>n_cell</code>), the indexes of the
cells intersecting each region in order (<code>cell_id</code>), and the proportion of each region's
area covered by each intersecting grid cell (<code>q_weights</code>).
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$get_region_data()</pre></div>



<h5>Returns</h5>

<p>A named list
</p>


<hr>
<a id="method-grid-variogram"></a>



<h4>Method <code>variogram()</code></h4>

<p>Plots the empirical semi-variogram
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$variogram(popdens, yvar, nbins = 20)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>popdens</code></dt><dd><p>String naming the variable in the data specifying the offset. If not
provided then no offset is used.</p>
</dd>
<dt><code>yvar</code></dt><dd><p>String naming the outcome variable to calculate the variogram for. Optional, if
not provided then the outcome count data will be used.</p>
</dd>
<dt><code>nbins</code></dt><dd><p>The number of bins in the empirical semivariogram</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A ggplot plot is printed and optionally returned
</p>


<hr>
<a id="method-grid-reorder"></a>



<h4>Method <code>reorder()</code></h4>

<p>Re-orders the computational grid
</p>
<p>The quality of the nearest neighbour approximation can depend on the ordering of
the grid cells. This function reorders the grid cells. If this is a region data model,
then the intersections are recomputed.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$reorder(option = "y", verbose = TRUE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>option</code></dt><dd><p>Either &quot;y&quot; for order of the y coordinate, &quot;x&quot; for order of the x coordinate,
&quot;minimax&quot;  in which the next observation in the order is the one which maximises the
minimum distance to the previous observations, or &quot;random&quot; which randomly orders them.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>Logical indicating whether to print a progress bar (TRUE) or not (FALSE).</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>No return, used for effects.
</p>


<hr>
<a id="method-grid-data"></a>



<h4>Method <code>data()</code></h4>

<p>A list of prepared data
</p>
<p>The class prepares data for use in the in-built estimation functions. The same data could be used
for alternative models. This is a utility function to facilitate model fitting for custom models.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$data(m, approx, popdens, covs, covs_grid)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>m</code></dt><dd><p>The number of nearest neighbours or basis functions.</p>
</dd>
<dt><code>approx</code></dt><dd><p>Either &quot;rank&quot; for reduced rank approximation, or &quot;nngp&quot; for nearest
neighbour Gaussian process.</p>
</dd>
<dt><code>popdens</code></dt><dd><p>String naming the variable in the data specifying the offset. If not
provided then no offset is used.</p>
</dd>
<dt><code>covs</code></dt><dd><p>An optional vector of covariate names. For regional data models, this is specifically for the region-level covariates.</p>
</dd>
<dt><code>covs_grid</code></dt><dd><p>An optional vector of covariate names for region data models, identifying the covariates at the grid level.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A named list of data items used in model fitting
</p>


<hr>
<a id="method-grid-get_random_effects"></a>



<h4>Method <code>get_random_effects()</code></h4>

<p>Returns the random effects stored in the object (if any) after using ML fitting. It's main use is
if a fitting procedure is stopped, the random effects can still be returned.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$get_random_effects()</pre></div>



<h5>Returns</h5>

<p>A matrix of random effects samples if a MCMCML model has been initialised, otherwise returns FALSE
</p>


<hr>
<a id="method-grid-model_fit"></a>



<h4>Method <code>model_fit()</code></h4>

<p>Either returns the stored last model fit with either <code>lgcp_ml</code> or <code>lgcp_bayes</code>, or updates
the saved model fit if an object is provided.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$model_fit(fit = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>fit</code></dt><dd><p>Optional. A previous <code>rtsFit</code> object. If provided then the function updates the internally stored model fit.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Either a <code>rtsFit</code> object or nothing if no model has been previously fit, or if the fit is updated.
</p>


<hr>
<a id="method-grid-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>grid$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>(1) Solin A, Särkkä S. Hilbert space methods for reduced-rank Gaussian
process regression. Stat Comput. 2020;30:419–46.
doi:10.1007/s11222-019-09886-w.
</p>
<p>(2) Riutort-Mayol G, Bürkner P-C, Andersen MR, Solin A, Vehtari A.
Practical Hilbert space approximate Bayesian Gaussian processes for
probabilistic programming. 2020. http://arxiv.org/abs/2004.11408.
</p>


<h3>See Also</h3>

<p><a href="#topic+create_points">create_points</a>
</p>
<p>points_to_grid, add_covariates
</p>
<p>points_to_grid, add_covariates
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## ------------------------------------------------
## Method `grid$new`
## ------------------------------------------------

# a simple example with a square and a small number of cells
# this same running example is used for the other functions 
b1 = sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)

# an example with multiple polygons
data("birmingham_crime")
g2 &lt;- grid$new(birmingham_crime,cellsize = 1000)

## ------------------------------------------------
## Method `grid$plot`
## ------------------------------------------------

b1 = sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
g1$plot()

# a plot with covariates - we simulate covariates first
g1$grid_data$cov &lt;- stats::rnorm(nrow(g1$grid_data))
g1$plot("cov")

## ------------------------------------------------
## Method `grid$points_to_grid`
## ------------------------------------------------

b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
# simulate some points
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20)) 
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
g1$points_to_grid(dp, laglength=5)

## ------------------------------------------------
## Method `grid$add_covariates`
## ------------------------------------------------

b1 &lt;-  sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)


# mapping population data from some other polygons
data("boundary")
data("birmingham_crime")
g2 &lt;- grid$new(boundary,cellsize=0.008)
msoa &lt;- sf::st_transform(birmingham_crime,crs = 4326)
suppressWarnings(sf::st_crs(msoa) &lt;- sf::st_crs(g2$grid_data)) # ensure crs matches
g2$add_covariates(msoa,
                  zcols="pop",
                  weight_type="area",
                  verbose=FALSE)
g2$plot("pop")


## ------------------------------------------------
## Method `grid$get_dow`
## ------------------------------------------------

b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
g1$points_to_grid(dp, laglength=5)
dow &lt;- g1$get_dow()
g1$add_covariates(dow,zcols = colnames(dow)[3:ncol(dow)])

## ------------------------------------------------
## Method `grid$lgcp_bayes`
## ------------------------------------------------

# the data are just random simulated points 
b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)
g1$points_to_grid(dp, laglength=5)
g1$priors &lt;- list(
  prior_lscale=c(0,0.5),
  prior_var=c(0,0.5),
  prior_linpred_mean=c(0),
  prior_linpred_sd=c(5)
  )

g1$lgcp_bayes(popdens="cov", approx = "hsgp", parallel_chains = 0)
g1$model_fit()
# we can extract predictions
g1$extract_preds("rr")
g1$plot("rr")
g1$hotspots(rr.threshold = 2)

 # this example uses real aggregated data but will take a relatively long time to run
 data("birmingham_crime")
 example_data &lt;- birmingham_crime[,c(1:8,21)]
 example_data$y &lt;- birmingham_crime$t12
 g2 &lt;- grid$new(example_data,cellsize=1000)
 g2$priors &lt;- list(
  prior_lscale=c(0,0.5),
  prior_var=c(0,0.5),
  prior_linpred_mean=c(-3),
  prior_linpred_sd=c(5)
)
g2$lgcp_bayes(popdens="pop", approx = "hsgp", parallel_chains = 0)
g2$model_fit()
g2$extract_preds("rr")
g2$plot("rr")
g2$hotspots(rr.threshold = 2)


## ------------------------------------------------
## Method `grid$lgcp_ml`
## ------------------------------------------------

# a simple example with completely random points
b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)
g1$points_to_grid(dp, laglength=5)

g1$lgcp_ml(popdens="cov",iter_warmup = 100, iter_sampling = 50)
g1$model_fit()
g1$extract_preds("rr")
g1$plot("rr")
g1$hotspots(rr.threshold = 2)

# this example uses real aggregated data but will take a relatively long time to run
 data("birmingham_crime")
 example_data &lt;- birmingham_crime[,c(1:8,21)]
 example_data$y &lt;- birmingham_crime$t12
 g2 &lt;- grid$new(example_data,cellsize=1000)
 g2$lgcp_ml(popdens = "pop",iter_warmup = 100, iter_sampling = 50)
 g2$model_fit()
 g2$extract_preds("rr")
 g2$plot("rr")
 g2$hotspots(rr.threshold = 2) 



## ------------------------------------------------
## Method `grid$extract_preds`
## ------------------------------------------------

# See examples for lgcp_bayes() and lgcp_ml()

## ------------------------------------------------
## Method `grid$hotspots`
## ------------------------------------------------

## Not run: 
# See examples for lgcp_bayes() and lgcp_ml()

## End(Not run)

## ------------------------------------------------
## Method `grid$aggregate_output`
## ------------------------------------------------


b1 &lt;- sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
dp &lt;- data.frame(y=runif(10,0,3),x=runif(10,0,3),date=paste0("2021-01-",11:20))
dp &lt;- create_points(dp,pos_vars = c('y','x'),t_var='date')
cov1 &lt;- grid$new(b1,0.8)
cov1$grid_data$cov &lt;- runif(nrow(cov1$grid_data))
g1$add_covariates(cov1$grid_data,
                  zcols="cov",
                  verbose = FALSE)
g1$points_to_grid(dp, laglength=5)
g1$priors &lt;- list(
  prior_lscale=c(0,0.5),
  prior_var=c(0,0.5),
  prior_linpred_mean=c(0),
  prior_linpred_sd=c(5)
  )
res &lt;- g1$lgcp_bayes(popdens="cov", parallel_chains = 1)
g1$extract_preds(res,
                 type=c("pred","rr"),
                 popdens="cov")
new1 &lt;- g1$aggregate_output(cov1$grid_data,
                            zcols="rr")


## ------------------------------------------------
## Method `grid$scale_conversion_factor`
## ------------------------------------------------

b1 = sf::st_sf(sf::st_sfc(sf::st_polygon(list(cbind(c(0,3,3,0,0),c(0,0,3,3,0))))))
g1 &lt;- grid$new(b1,0.5)
g1$scale_conversion_factor()
</code></pre>

<hr>
<h2 id='logLik.rtsFit'>Extracts the log-likelihood from an mcml object</h2><span id='topic+logLik.rtsFit'></span>

<h3>Description</h3>

<p>Extracts the final log-likelihood value from an mcml object returned from call of <code>MCML</code> or <code>LA</code> in the <a href="glmmrBase.html#topic+Model">Model</a> class. The fitting algorithm estimates
the fixed effects, random effects, and covariance parameters all separately. The log-likelihood is separable in the fixed and covariance parameters, so one can return
the log-likelihood for either component, or the overall log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rtsFit'
logLik(object, fixed = TRUE, covariance = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.rtsFit_+3A_object">object</code></td>
<td>
<p>An <code>mcml</code> model fit.</p>
</td></tr>
<tr><td><code id="logLik.rtsFit_+3A_fixed">fixed</code></td>
<td>
<p>Logical whether to include the log-likelihood value from the fixed effects.</p>
</td></tr>
<tr><td><code id="logLik.rtsFit_+3A_covariance">covariance</code></td>
<td>
<p>Logical whether to include the log-likelihood value from the covariance parameters.</p>
</td></tr>
<tr><td><code id="logLik.rtsFit_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value. If both <code>fixed</code> and <code>covariance</code> are FALSE then it returns NA.
</p>

<hr>
<h2 id='print.rtsFit'>Prints an rtsFit fit output</h2><span id='topic+print.rtsFit'></span>

<h3>Description</h3>

<p>Print method for class &quot;<code>rtsFit</code>&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rtsFit'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.rtsFit_+3A_x">x</code></td>
<td>
<p>an object of class &quot;<code>rtsFit</code>&quot;</p>
</td></tr>
<tr><td><code id="print.rtsFit_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>print.rtsFit</code> tries to replicate the output of other regression functions, such
as <code>lm</code> and <code>lmer</code> reporting parameters, standard errors, and z- and p- statistics for maximum
likelihood esitmates, or posterior means, standard deviations and credible intervals for
Bayesian models.
</p>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>

<hr>
<h2 id='print.rtsFitSummary'>Prints an rtsFitSummary fit output</h2><span id='topic+print.rtsFitSummary'></span>

<h3>Description</h3>

<p>Print method for class &quot;<code>rtsFitSummary</code>&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rtsFitSummary'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.rtsFitSummary_+3A_x">x</code></td>
<td>
<p>an object of class &quot;<code>rtsFitSummary</code>&quot;</p>
</td></tr>
<tr><td><code id="print.rtsFitSummary_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>print.rtsFitSummary</code> prints the summary of an rtsFit, see <a href="#topic+summary.rtsFit">summary.rtsFit</a>
</p>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>

<hr>
<h2 id='progress_bar'>Generates a progress bar</h2><span id='topic+progress_bar'></span>

<h3>Description</h3>

<p>Prints a progress bar
</p>


<h3>Usage</h3>

<pre><code class='language-R'>progress_bar(i, n, len = 30)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="progress_bar_+3A_i">i</code></td>
<td>
<p>integer. The current iteration.</p>
</td></tr>
<tr><td><code id="progress_bar_+3A_n">n</code></td>
<td>
<p>integer. The total number of interations</p>
</td></tr>
<tr><td><code id="progress_bar_+3A_len">len</code></td>
<td>
<p>integer. Length of the progress a number of characters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>progress_bar(10,100)
</code></pre>

<hr>
<h2 id='random.effects'>Extracts the random effect estimates</h2><span id='topic+random.effects'></span>

<h3>Description</h3>

<p>Extracts the random effect estimates or samples from an <code style="white-space: pre;">&#8288;rtsFit object&#8288;</code> returned from call of <code>lgcp_ml()</code> or <code>lgcp_bayes()</code> in the <a href="#topic+grid">grid</a> class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random.effects(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random.effects_+3A_object">object</code></td>
<td>
<p>An <code>mcml</code> model fit.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of dimension (number of fixed effects ) x (number of MCMC samples). For Laplace approximation, the number of &quot;samples&quot; equals one.
</p>

<hr>
<h2 id='rts2-package'>The 'rts2' package.</h2><span id='topic+rts2-package'></span><span id='topic+rts2'></span>

<h3>Description</h3>

<p>A DESCRIPTION OF THE PACKAGE
</p>


<h3>References</h3>

<p>Stan Development Team (2020). RStan: the R interface to Stan. R package version 2.21.2. https://mc-stan.org
</p>

<hr>
<h2 id='summary.rtsFit'>Summary method for class &quot;rtsFit&quot;</h2><span id='topic+summary.rtsFit'></span>

<h3>Description</h3>

<p>Summary method for class &quot;<code>rtsFit</code>&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rtsFit'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rtsFit_+3A_object">object</code></td>
<td>
<p>an object of class &quot;<code>rtsFit</code>&quot; as a result of a call to <code>lgcp_ml()</code> or <code>lgcp_bayes()</code></p>
</td></tr>
<tr><td><code id="summary.rtsFit_+3A_...">...</code></td>
<td>
<p>Further arguments passed from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary methods aims to replicate the output of other regression model fitting functions and reports
central point estimates, relevant test statistics, and uncertainty intervals. In addition, the returned
summary object will also include time period specific relative risk and incidence predictions.
</p>


<h3>Value</h3>

<p>An rtsFitSummary object
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
