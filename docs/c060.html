<!DOCTYPE html><html><head><title>Help for package c060</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {c060}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregation.auc'><p>Determine the area under the ROC curve for a fitted model</p></a></li>
<li><a href='#balancedFolds '><p>   Function producing stratified/ balanced folds for cross validation</p></a></li>
<li><a href='#coef.sum.intsearch'>
<p>Get coefficients for a model</p></a></li>
<li><a href='#complexity.glmnet'><p>Interface for determination of penalty lambda in penalized regression model via cross-validation</p></a></li>
<li><a href='#epsgo'><p>  Efficient Parameter Selection via Global Optimization</p></a></li>
<li><a href='#fit.glmnet'><p>Interface function for fitting a penalized regression model with <code>glmnet</code></p></a></li>
<li><a href='#PLL.coxnet'><p>Predictive partial log-likelihood for glmnet Cox PH model fit</p></a></li>
<li><a href='#Plot.coef.glmnet'>
<p>function to highlight the path of a pre-specified set of variables within the coefficient path</p></a></li>
<li><a href='#Plot.peperr.curves'><p>Plot method for prediction error curves of a peperr object</p></a></li>
<li><a href='#plot.stabpath'>
<p>function to plot a stability path</p></a></li>
<li><a href='#plot.sum.intsearch'>
<p>Plot Summary object for interval search models</p></a></li>
<li><a href='#predictProb.coxnet'><p>Extract predicted survival probabilities from a glmnet fit</p></a></li>
<li><a href='#predictProb.glmnet'><p>Extract predicted survival probabilities from a glmnet fit</p></a></li>
<li><a href='#stabpath'>
<p>Stability path for glmnet models</p></a></li>
<li><a href='#stabsel'>
<p>function to estimate a stable set of variables</p></a></li>
<li><a href='#summary.intsearch'>
<p>Summary method for interval search models</p></a></li>
<li><a href='#tune.glmnet.interval'><p>  Wrapper function for <code>glmnet</code> objects.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.3-0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-23</td>
</tr>
<tr>
<td>Author:</td>
<td>Martin Sill, Thomas Hielscher, Manuela Zucknick, Natalia Becker.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Frederic Bertrand &lt;frederic.bertrand@utt.fr&gt;</td>
</tr>
<tr>
<td>Title:</td>
<td>Extended Inference for Lasso and Elastic-Net Regularized Cox and
Generalized Linear Models</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, survival, parallel, mlegp, tgp, peperr, penalized,
penalizedSVM, lattice, methods</td>
</tr>
<tr>
<td>Description:</td>
<td>The c060 package provides additional functions to perform stability selection, model validation and parameter tuning for glmnet models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/fbertran/c060/">https://github.com/fbertran/c060/</a>,
<a href="https://fbertran.github.io/c060/">https://fbertran.github.io/c060/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/fbertran/c060/issues/">https://github.com/fbertran/c060/issues/</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-23 14:37:26 UTC; fbertran</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-23 15:02:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregation.auc'>Determine the area under the ROC curve for a fitted model</h2><span id='topic+aggregation.auc'></span>

<h3>Description</h3>

<p>Evaluate the area under the ROC curve for a fitted model on new data. To be used as argument <code>aggregation.fun</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregation.auc(full.data=NULL, response, x, model, cplx=NULL,  
type=c("apparent", "noinf"), fullsample.attr = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregation.auc_+3A_full.data">full.data</code></td>
<td>
<p>passed from <code>peperr</code>, but not used for calculation.</p>
</td></tr>
<tr><td><code id="aggregation.auc_+3A_response">response</code></td>
<td>
<p>vector of binary response.</p>
</td></tr>
<tr><td><code id="aggregation.auc_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="aggregation.auc_+3A_model">model</code></td>
<td>
<p>model fitted as returned by a <code>fit.fun</code>, as used in a call to <code>peperr</code>.</p>
</td></tr>
<tr><td><code id="aggregation.auc_+3A_cplx">cplx</code></td>
<td>
<p>passed from <code>peperr</code>, but not necessary for calculation.</p>
</td></tr>
<tr><td><code id="aggregation.auc_+3A_type">type</code></td>
<td>
<p>character.</p>
</td></tr>
<tr><td><code id="aggregation.auc_+3A_fullsample.attr">fullsample.attr</code></td>
<td>
<p>passed from <code>peperr</code>, but not necessary for calculation.</p>
</td></tr>
<tr><td><code id="aggregation.auc_+3A_...">...</code></td>
<td>
<p>additional arguments, passed to <code>predict</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Area under the ROC curve is calculated based on internal <code>glmnet:::auc</code> function from package <code>glmnet</code>.
</p>


<h3>Value</h3>

<p>Scalar, indicating the area under the ROC curve.
</p>


<h3>Author(s)</h3>

<p>Thomas Hielscher \
<a href="mailto:t.hielscher@dkfz.de">t.hielscher@dkfz.de</a>
</p>


<h3>See Also</h3>

<p><code><a href="peperr.html#topic+peperr">peperr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# binomial model - classification

library(c060)
library(gridExtra)
library(ggplot2)

set.seed(0815)
x &lt;- matrix(rnorm(100*20),100,20)
y &lt;- sample(0:1,100,replace=TRUE)

peperr_obj &lt;- peperr(response=y, x=x, fit.fun=fit.glmnet, args.fit=list(family="binomial"),
           complexity=complexity.glmnet, args.complexity=list(nfolds=10, family="binomial"),
           trace=F, RNG="fixed",seed=0815,
#           aggregation.fun=c060:::aggregation.misclass,                  
#           aggregation.fun=c060:::aggregation.brier,                  
           aggregation.fun=c060:::aggregation.auc,                  
           indices=resample.indices(n=nrow(x), sample.n = 100, method = "sub632"))

tmp   &lt;- data.frame(grp="",error=unlist(peperr_obj$sample.error)) 
errs  &lt;- data.frame(error=c(perr(peperr_obj,"resample"),
         perr(peperr_obj,"632p"),perr(peperr_obj,"app"),
         perr(peperr_obj,"nullmodel")), col  = c("red","blue","green","brown"),
         row.names=c("mean\nout-of-bag",".632plus","apparent","null model"))
                 
p     &lt;- ggplot(tmp, aes(grp,error))
pg    &lt;- p + geom_boxplot(outlier.colour = rgb(0,0,0,0), outlier.size=0) +
         geom_jitter(position=position_jitter(width=.1)) + 
         theme_bw() + scale_y_continuous("AUC") +  scale_x_discrete("") +
         geom_hline(aes(yintercept=error, colour=col), data=errs, show_guide=T) + 
         scale_colour_identity("error type", guide = "legend", breaks=errs$col,
         labels=rownames(errs)) +
         ggtitle("AUC \n in bootstrap samples ")                       

p2     &lt;- ggplot(data.frame(complx=peperr_obj$sample.complexity), aes(x=complx))
pg2    &lt;- p2 + geom_histogram(binwidth = 0.02, fill = "white", colour="black") +
          theme_bw()+  xlab(expression(lambda)) +
          ylab("frequency") + 
          geom_vline(xintercept=peperr_obj$selected.complexity, colour="red") + 
          ggtitle("Selected complexity \n in bootstrap samples") +
          ggplot2::annotate("text", x = 0.12, y = -0.5,
          label = "full data", colour="red", size=4)

grid.arrange(pg2, pg, ncol=2)


## End(Not run)</code></pre>

<hr>
<h2 id='balancedFolds+20'>   Function producing stratified/ balanced folds for cross validation      </h2><span id='topic+balancedFolds'></span>

<h3>Description</h3>

<p>Get balanced folds for cross validation,  which are used for tuning penalization parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>balancedFolds(class.column.factor, cross.outer) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="balancedFolds+2B20_+3A_class.column.factor">class.column.factor</code></td>
<td>
<p>class labels of length n  </p>
</td></tr>
<tr><td><code id="balancedFolds+2B20_+3A_cross.outer">cross.outer</code></td>
<td>
<p>  number of folds</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>permutated.cut</code></td>
<td>
<p>vector of length n, indicating the fold belongs to</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p> model list
</p>

<ul>
<li><p> alpha -  optimal alpha
</p>
</li>
<li><p> lambda - optimal lambda
</p>
</li>
<li><p> nfolds - cross-validation's folds
</p>
</li>
<li><p> cvreg -  <code>cv.glmnet</code> object for optimal alpha 
</p>
</li>
<li><p> fit - <code>glmnet</code> object for optimal alpha and optimal lambda 
</p>
</li></ul>
 
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Natalia Becker  natalia.becker at dkfz.de </p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

<p><code><a href="penalizedSVM.html#topic+EPSGO">EPSGO</a></code></p>

<hr>
<h2 id='coef.sum.intsearch'>
Get coefficients for a model 
</h2><span id='topic+coef.sum.intsearch'></span>

<h3>Description</h3>

<p>Get coefficients for a model after applying interval search for tuning parameters 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sum.intsearch'
coef(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.sum.intsearch_+3A_object">object</code></td>
<td>
<p> an object as returned by the function <code>summary.intsearch</code>.</p>
</td></tr>
<tr><td><code id="coef.sum.intsearch_+3A_...">...</code></td>
<td>
<p>additional argument(s)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>named vector of non-zero coeficients for the optimal lambda</p>


<h3>Author(s)</h3>

<p>Natalia Becker  \
<a href="mailto:natalia.becker@dkfz.de">natalia.becker@dkfz.de</a>
</p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

 <p><code><a href="penalizedSVM.html#topic+EPSGO">EPSGO</a></code>, <code><a href="#topic+summary.intsearch">summary.intsearch</a></code>,<code><a href="#topic+plot.sum.intsearch">plot.sum.intsearch</a></code>
</p>

<hr>
<h2 id='complexity.glmnet'>Interface for determination of penalty lambda in penalized regression model via cross-validation</h2><span id='topic+complexity.glmnet'></span>

<h3>Description</h3>

<p>Determines the amount of shrinkage for a penalized regression model fitted by glmnet via cross-validation, conforming to the calling convention required by argument <code>complexity</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complexity.glmnet(response, x, full.data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="complexity.glmnet_+3A_response">response</code></td>
<td>
<p>a survival object (with <code>Surv(time, status)</code>, or a binary vector with entries 0 and 1).</p>
</td></tr>
<tr><td><code id="complexity.glmnet_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="complexity.glmnet_+3A_full.data">full.data</code></td>
<td>
<p>data frame containing response and covariates of the full data set.</p>
</td></tr>
<tr><td><code id="complexity.glmnet_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>cv.glmnet</code> call such as <code>family</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function is basically a wrapper for <code>cv.glmnet</code> of package <code>glmnet</code>. A n-fold cross-validation (default n=10) is performed to determine the optimal penalty lambda.
For Cox PH regression models the deviance based on penalized partial log-likelihood is used as loss function. For binary endpoints other loss functions are available as well (see <code>type.measure</code>). Deviance is default. Calling <code>peperr</code>, the default arguments of <code>cv.glmnet</code> can be changed by passing a named list containing these as argument <code>args.complexity</code>.
Note that only penalized Cox PH (<code>family="cox"</code>) and logistic regression models (<code>family="binomial"</code>) are sensible for prediction error
evaluation with package <code>peperr</code>.
</p>


<h3>Value</h3>

<p>Scalar value giving the optimal lambda.
</p>


<h3>Author(s)</h3>

<p>Thomas Hielscher \
<a href="mailto:t.hielscher@dkfz.de">t.hielscher@dkfz.de</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em>,   <a href="https://web.stanford.edu/~hastie/Papers/glmnet.pdf">https://web.stanford.edu/~hastie/Papers/glmnet.pdf</a><br />
<em>Journal of Statistical Software, Vol. 33(1), 1-22 Feb 2010</em><br />
<a href="https://www.jstatsoft.org/v33/i01/">https://www.jstatsoft.org/v33/i01/</a><br />
Simon, N., Friedman, J., Hastie, T., Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional Hazards Model via
Coordinate Descent, Journal of Statistical Software, Vol. 39(5)
1-13</em><br />
<a href="https://www.jstatsoft.org/v39/i05/">https://www.jstatsoft.org/v39/i05/</a><br />
Porzelius, C., Binder, H., and Schumacher, M. (2009) 
<em>Parallelized prediction error estimation for evaluation of high-dimensional models,
Bioinformatics, Vol. 25(6), 827-829.</em><br />
Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

<p><code><a href="peperr.html#topic+peperr">peperr</a></code>, <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code></p>

<hr>
<h2 id='epsgo'>  Efficient Parameter Selection via Global Optimization  </h2><span id='topic+epsgo'></span>

<h3>Description</h3>

<p>Finds an optimal solution for the Q.func function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epsgo(Q.func, bounds,  round.n=5, parms.coding="none",
  fminlower=0, flag.find.one.min =FALSE,
  show=c("none", "final", "all"), N= NULL, maxevals = 500,
  pdf.name=NULL,  pdf.width=12,  pdf.height=12, my.mfrow=c(1,1),
  verbose=TRUE, seed=123,  ...  )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="epsgo_+3A_q.func">Q.func</code></td>
<td>
<p> name of the function to be  minimized. </p>
</td></tr>
<tr><td><code id="epsgo_+3A_bounds">bounds</code></td>
<td>
<p> bounds for parameters</p>
</td></tr>
<tr><td><code id="epsgo_+3A_round.n">round.n</code></td>
<td>
<p> number of digits after comma, default: 5</p>
</td></tr>           
<tr><td><code id="epsgo_+3A_parms.coding">parms.coding</code></td>
<td>
<p> parmeters coding: none  or log2, default: none.  </p>
</td></tr>
<tr><td><code id="epsgo_+3A_fminlower">fminlower</code></td>
<td>
<p> minimal value for the function Q.func, default is 0.     </p>
</td></tr>
<tr><td><code id="epsgo_+3A_flag.find.one.min">flag.find.one.min</code></td>
<td>
<p>  do you want to find one min value and stop? Default: FALSE </p>
</td></tr>
<tr><td><code id="epsgo_+3A_show">show</code></td>
<td>
<p>  show plots of  DIRECT algorithm:    none, final iteration, all iterations. Default: none  </p>
</td></tr>
<tr><td><code id="epsgo_+3A_n">N</code></td>
<td>
<p> define the number of start points, see details. </p>
</td></tr>
<tr><td><code id="epsgo_+3A_maxevals">maxevals</code></td>
<td>
<p> the maximum number of DIRECT function evaluations, default: 500.   </p>
</td></tr>
<tr><td><code id="epsgo_+3A_pdf.name">pdf.name</code></td>
<td>
<p>pdf name      </p>
</td></tr>   
<tr><td><code id="epsgo_+3A_pdf.width">pdf.width</code></td>
<td>
<p> default: 12 </p>
</td></tr>
<tr><td><code id="epsgo_+3A_pdf.height">pdf.height</code></td>
<td>
<p> default: 12 </p>
</td></tr>
<tr><td><code id="epsgo_+3A_my.mfrow">my.mfrow</code></td>
<td>
<p> default: c(1,1) </p>
</td></tr>
<tr><td><code id="epsgo_+3A_verbose">verbose</code></td>
<td>
<p> verbose? default: TRUE. </p>
</td></tr>
<tr><td><code id="epsgo_+3A_seed">seed</code></td>
<td>
<p> seed </p>
</td></tr>
<tr><td><code id="epsgo_+3A_...">...</code></td>
<td>
<p> additional argument(s) </p>
</td></tr>
</table>


<h3>Details</h3>

<p>if the number of start points (N)  is not defined by the user, it will be defined dependent on the dimensionality of the parameter space.
N=10D+1, where  D is the number of parameters, but for high dimensional parameter space with more than 6 dimensions,  
the initial set is restricted to 65. However for one-dimensional parameter space the N is set to 21 due to stability reasons.
</p>
<p>The idea of EPSGO (Efficient Parameter Selection via Global Optimization): Beginning
from an intial Latin hypercube sampling containing N starting points we train
an Online GP, look for the point with the maximal expected 	improvement, sample there and update the Gaussian Process(GP). Thereby
it is not so important that GP really correctly 	models the error surface of the SVM in parameter space, but
that it can give a us information about potentially interesting 	points in parameter space where we should sample next.
We continue with sampling points until some convergence criterion is met.
</p>
<p>DIRECT is a sampling algorithm which requires no knowledge of the objective function gradient.
Instead, the algorithm samples points in the domain, and uses the information it has obtained to decide where to
search next. The DIRECT algorithm will globally converge to the maximal value of the objective function. The name
DIRECT comes from the shortening of the phrase 'DIviding RECTangles', which describes the way the algorithm moves
towards the optimum.  
</p>
<p>The code source was adopted from MATLAB originals, special thanks to Holger Froehlich.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fmin</code></td>
<td>
<p>minimal value of Q.func on the interval defined by bounds. </p>
</td></tr>
<tr><td><code>xmin</code></td>
<td>
<p>corresponding parameters for the minimum</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations</p>
</td></tr>
<tr><td><code>neval</code></td>
<td>
<p>  number of visited points </p>
</td></tr>
<tr><td><code>maxevals</code></td>
<td>
<p>  the maximum number of DIRECT function evaluations </p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>  seed</p>
</td></tr>
<tr><td><code>bounds</code></td>
<td>
<p> bounds for parameters</p>
</td></tr>
<tr><td><code>Q.func</code></td>
<td>
<p>  name of the function to be  minimized. </p>
</td></tr>
<tr><td><code>points.fmin</code></td>
<td>
<p>  the set of points with the same fmin </p>
</td></tr>
<tr><td><code>Xtrain</code></td>
<td>
<p>  visited points </p>
</td></tr>
<tr><td><code>Ytrain</code></td>
<td>
<p>  the output of Q.func at visited points Xtrain </p>
</td></tr>
<tr><td><code>gp.seed</code></td>
<td>
<p> seed for Gaussian Process </p>
</td></tr>
<tr><td><code>model.list</code></td>
<td>
<p> detailed information of the search process </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Natalia Becker natalia.becker at dkfz.de </p>


<h3>References</h3>

<p>Froehlich, H. and Zell, A. (2005) &quot;Effcient parameter selection for support vector
machines in classification and regression via model-based global optimization&quot;
<em>In Proc. Int. Joint Conf. Neural Networks,  1431-1438 </em>.<br />
</p>
<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1010)
n=1000;p=100
nzc=trunc(p/10)
x=matrix(rnorm(n*p),n,p)
beta=rnorm(nzc)
fx= x[,seq(nzc)] %*% beta
eps=rnorm(n)*5
y=drop(fx+eps)
px=exp(fx)
px=px/(1+px)
ly=rbinom(n=length(px),prob=px,size=1)
set.seed(1011)

 
nfolds = 10
set.seed(1234)
foldid &lt;- balancedFolds(class.column.factor=y.classes, cross.outer=nfolds)

# y - binomial
y.classes&lt;-ifelse(y&gt;= median(y),1, 0)
bounds &lt;- t(data.frame(alpha=c(0, 1)))
colnames(bounds)&lt;-c("lower","upper")
 
fit &lt;- epsgo(Q.func="tune.glmnet.interval", 
             bounds=bounds, 
             parms.coding="none", 
             seed = 1234, 
             show="none",
             fminlower = -100,
             x = x, y = y.classes, family = "binomial", 
             foldid = foldid,
             type.min = "lambda.1se",
             type.measure = "mse")
summary(fit)

# y - multinomial: low - low 25%, middle - (25,75)-quantiles, high - larger 75%.
y.classes&lt;-ifelse(y &lt;= quantile(y,0.25),1, ifelse(y &gt;= quantile(y,0.75),3, 2))
bounds &lt;- t(data.frame(alpha=c(0, 1)))
colnames(bounds)&lt;-c("lower","upper")
 
fit &lt;- epsgo(Q.func="tune.glmnet.interval", 
             bounds=bounds, 
             parms.coding="none", 
             seed = 1234, 
             show="none",
             fminlower = -100,
             x = x, y = y.classes, family = "multinomial", 
             foldid = foldid,
             type.min = "lambda.1se",
             type.measure = "mse")
summary(fit)

##poisson
N=500; p=20
nzc=5
x=matrix(rnorm(N*p),N,p)
beta=rnorm(nzc)
f = x[,seq(nzc)]
mu=exp(f)
y.classes=rpois(N,mu)

nfolds = 10
set.seed(1234)
foldid &lt;- balancedFolds(class.column.factor=y.classes, cross.outer=nfolds)


fit &lt;- epsgo(Q.func="tune.glmnet.interval", 
             bounds=bounds, 
             parms.coding="none", 
             seed = 1234, 
             show="none",
             fminlower = -100,
             x = x, y = y.classes, family = "poisson", 
             foldid = foldid,
             type.min = "lambda.1se",
             type.measure = "mse")
summary(fit)

#gaussian
set.seed(1234)
x=matrix(rnorm(100*1000,0,1),100,1000)
y &lt;- x[1:100,1:1000]%*%c(rep(2,5),rep(-2,5),rep(.1,990))

foldid &lt;- rep(1:10,each=10)

fit &lt;- epsgo(Q.func="tune.glmnet.interval", 
             bounds=bounds, 
             parms.coding="none", 
             seed = 1234, 
             show="none",
             fminlower = -100,
             x = x, y = y, family = "gaussian", 
             foldid = foldid,
             type.min = "lambda.1se",
             type.measure = "mse")
summary(fit)  

# y - cox in vingette

## End(Not run)
</code></pre>

<hr>
<h2 id='fit.glmnet'>Interface function for fitting a penalized regression model with <code>glmnet</code></h2><span id='topic+fit.glmnet'></span>

<h3>Description</h3>

<p>Interface for fitting penalized regression models for binary of survival endpoint using <code>glmnet</code>, conforming to the requirements for argument <code>fit.fun</code> in <code>peperr</code> call. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.glmnet(response, x, cplx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.glmnet_+3A_response">response</code></td>
<td>
<p>a survival object (with <code>Surv(time, status)</code>, or a binary vector with entries 0 and 1).</p>
</td></tr>
<tr><td><code id="fit.glmnet_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="fit.glmnet_+3A_cplx">cplx</code></td>
<td>
<p>lambda penalty value.</p>
</td></tr>
<tr><td><code id="fit.glmnet_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>glmnet</code> call such as <code>family</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function is basically a wrapper for <code>glmnet</code> of package <span class="pkg">glmnet</span>.
Note that only penalized Cox PH (<code>family="cox"</code>) and logistic regression models (<code>family="binomial"</code>) are sensible for prediction error
evaluation with package <code>peperr</code>.
</p>


<h3>Value</h3>

<p>glmnet object
</p>


<h3>Author(s)</h3>

<p>Thomas Hielscher \
<a href="mailto:t.hielscher@dkfz.de">t.hielscher@dkfz.de</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em>,   <a href="https://web.stanford.edu/~hastie/Papers/glmnet.pdf">https://web.stanford.edu/~hastie/Papers/glmnet.pdf</a><br />
<em>Journal of Statistical Software, Vol. 33(1), 1-22 Feb 2010</em><br />
<a href="https://www.jstatsoft.org/v33/i01/">https://www.jstatsoft.org/v33/i01/</a><br />
Simon, N., Friedman, J., Hastie, T., Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional Hazards Model via
Coordinate Descent, Journal of Statistical Software, Vol. 39(5)
1-13</em><br />
<a href="https://www.jstatsoft.org/v39/i05/">https://www.jstatsoft.org/v39/i05/</a><br />
Porzelius, C., Binder, H., and Schumacher, M. (2009) 
<em>Parallelized prediction error estimation for evaluation of high-dimensional models,
Bioinformatics, Vol. 25(6), 827-829.</em><br />
Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

 <p><code><a href="peperr.html#topic+peperr">peperr</a></code>, <code><a href="glmnet.html#topic+glmnet">glmnet</a></code></p>

<hr>
<h2 id='PLL.coxnet'>Predictive partial log-likelihood for glmnet Cox PH model fit</h2><span id='topic+PLL.coxnet'></span>

<h3>Description</h3>

<p>Extracts the predictive partial log-likelihood from a glmnet Cox PH model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coxnet'
PLL(object, newdata, newtime, newstatus, complexity, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLL.coxnet_+3A_object">object</code></td>
<td>
<p>fitted model of class <code>coxnet</code>.</p>
</td></tr>
<tr><td><code id="PLL.coxnet_+3A_newdata">newdata</code></td>
<td>
<p><code>n_new*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="PLL.coxnet_+3A_newtime">newtime</code></td>
<td>
<p><code>n_new</code>-vector of censored survival times.</p>
</td></tr>
<tr><td><code id="PLL.coxnet_+3A_newstatus">newstatus</code></td>
<td>
<p><code>n_new</code>-vector of survival status, coded with 0 and .1</p>
</td></tr>
<tr><td><code id="PLL.coxnet_+3A_complexity">complexity</code></td>
<td>
<p>lambda penalty value.</p>
</td></tr>
<tr><td><code id="PLL.coxnet_+3A_...">...</code></td>
<td>
<p>additional arguments, not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Used by function <code>peperr</code>, if function <code>fit.glmnet</code> and <code>family="cox"</code> is used for model fit, which gives a class <code>coxnet</code> object.
This is basically a wrapper based on the <code>coxnet.deviance</code> function from package <code>glmnet</code>.
</p>


<h3>Value</h3>

<p>Vector of length <code>n_new</code>
</p>


<h3>Author(s)</h3>

<p>Thomas Hielscher \
<a href="mailto:t.hielscher@dkfz.de">t.hielscher@dkfz.de</a>
</p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>

<hr>
<h2 id='Plot.coef.glmnet'>
function to highlight the path of a pre-specified set of variables within the coefficient path
</h2><span id='topic+Plot.coef.glmnet'></span>

<h3>Description</h3>

<p>Creates several plots showing the coefficient path for the final model of a cv.glmnet fit and highlights the path of a pre-specified set of variables within the coefficient path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Plot.coef.glmnet(cvfit, betas)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Plot.coef.glmnet_+3A_cvfit">cvfit</code></td>
<td>
<p>an object of class &quot;cv.glmnet&quot; as returned by the function <code>cv.glmnet</code>.</p>
</td></tr>
<tr><td><code id="Plot.coef.glmnet_+3A_betas">betas</code></td>
<td>
<p>a vector of names of variables; must be a subset of rownames(coef(cvfit)).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of four objects
</p>
<table>
<tr><td><code>stable</code></td>
<td>

<p>a vector giving the positions of the estimated stable variables 
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>the penalization parameter used for the stability selection 
</p>
</td></tr>
<tr><td><code>lpos</code></td>
<td>

<p>the position of the penalization parameter in the regularization path
</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>the desired type I error level w.r.t. to the chosen type I error rate
</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the type I error rate 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuela Zucknick \
<a href="mailto:m.zucknick@dkfz-heidelberg.de">m.zucknick@dkfz-heidelberg.de</a>
</p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1010)
n=1000;p=100
nzc=trunc(p/10)
x=matrix(rnorm(n*p),n,p)
beta=rnorm(nzc)
fx= x[,seq(nzc)] %*% beta
eps=rnorm(n)*5
y=drop(fx+eps)
px=exp(fx)
px=px/(1+px)
ly=rbinom(n=length(px),prob=px,size=1)
set.seed(1011)
cvob1=cv.glmnet(x,y)
Plot.coef.glmnet(cvob1, c("V1","V100"))

## End(Not run)</code></pre>

<hr>
<h2 id='Plot.peperr.curves'>Plot method for prediction error curves of a peperr object</h2><span id='topic+Plot.peperr.curves'></span>

<h3>Description</h3>

<p>Plots individual and aggregated prediction error estimates based on bootstrap samples.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Plot.peperr.curves(x, at.risk=TRUE, allErrors=FALSE, 
bootRuns=FALSE, bootQuants=TRUE, bootQuants.level=0.95, leg.cex=0.7,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Plot.peperr.curves_+3A_x">x</code></td>
<td>
<p><code>peperr</code> object.</p>
</td></tr>
<tr><td><code id="Plot.peperr.curves_+3A_at.risk">at.risk</code></td>
<td>
<p>number at risk to be display. default is TRUE.</p>
</td></tr>
<tr><td><code id="Plot.peperr.curves_+3A_allerrors">allErrors</code></td>
<td>
<p>Display .632, no information and average out-of-bag error in addition. default is FALSE.</p>
</td></tr>
<tr><td><code id="Plot.peperr.curves_+3A_bootruns">bootRuns</code></td>
<td>
<p>Display individual out-of-bag bootstrap samples. default is FALSE.</p>
</td></tr>
<tr><td><code id="Plot.peperr.curves_+3A_bootquants">bootQuants</code></td>
<td>
<p>Display pointwise out-of-bag bootstrap quantiles as shaded area. default is TRUE.</p>
</td></tr>
<tr><td><code id="Plot.peperr.curves_+3A_bootquants.level">bootQuants.level</code></td>
<td>
<p>Quantile probabilities for pointwise out-of-bag bootstrap quantiles. default is 0.95, i.e. 2.5% and 97.5% quantiles.</p>
</td></tr>
<tr><td><code id="Plot.peperr.curves_+3A_leg.cex">leg.cex</code></td>
<td>
<p>size of legend text</p>
</td></tr>
<tr><td><code id="Plot.peperr.curves_+3A_...">...</code></td>
<td>
<p>additional arguments, not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is literally taken from <code>plot.peperr</code> in the <code>peperr</code> package.
The display of prediction error curves is adapted to allow for numbers at risk and pointwise bootstrap quantiles.
</p>


<h3>Author(s)</h3>

<p>Thomas Hielscher 
<a href="mailto:t.hielscher@dkfz.de">t.hielscher@dkfz.de</a>
</p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

<p><code><a href="peperr.html#topic+peperr">peperr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# example from glmnet package
set.seed(10101)
library(glmnet)
library(survival)
library(peperr)

N=1000;p=30
nzc=p/3
x=matrix(rnorm(N*p),N,p)
beta=rnorm(nzc)
fx=x[,seq(nzc)]
hx=exp(fx)
ty=rexp(N,hx)
tcens=rbinom(n=N,prob=.3,size=1)# censoring indicator
y=Surv(ty,1-tcens)

peperr.object &lt;- peperr(response=y, x=x, 
                        fit.fun=fit.glmnet, args.fit=list(family="cox"), 
                        complexity=complexity.glmnet,  
                        args.complexity=list(family="cox",nfolds=10),
                        indices=resample.indices(n=N, method="sub632", sample.n=10))

# pointwise bootstrap quantiles and all error types
Plot.peperr.curves(peperr.object, allErrors=TRUE)

# individual bootstrap runs and selected error types
Plot.peperr.curves(peperr.object, allErrors=FALSE, bootRuns=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.stabpath'>
function to plot a stability path 
</h2><span id='topic+plot.stabpath'></span>

<h3>Description</h3>

<p>Given a desired family-wise error rate (FWER) and a stability path calculated with <code>stability.path</code> the function selects an stable set of features and plots the stability path and the corresponding regularization path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stabpath'
plot(x, error=0.05, type=c("pfer","pcer"), pi_thr=0.6, xvar=c("lambda", "norm", "dev"),
     col.all="black", col.sel="red", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.stabpath_+3A_x">x</code></td>
<td>

<p>an object of class &quot;stabpath&quot; as returned by the function <code>stabpath</code>.
</p>
</td></tr>
<tr><td><code id="plot.stabpath_+3A_error">error</code></td>
<td>

<p>the desired type I error level w.r.t. to the chosen type I error rate.
</p>
</td></tr>
<tr><td><code id="plot.stabpath_+3A_type">type</code></td>
<td>

<p>The type I error rate used for controlling the number falsely selected variables. If <code>type="pfer"</code> the per-family error rate is controlled and <code>error</code> corresponds to the expected number of type I errors.
Selecting <code>type="pfer"</code> and <code>error</code> in the range of 0 &gt; <code>error</code> &lt; 1 will control the family-wise error rate, i.e. the probability that at least one variable in the estimated stable set has been falsely selected.
If <code>type="pcer"</code> the per-comparison error rate is controlled and <code>error</code> corresponds to the expected number of type I errors divided by the number variables. 
</p>
</td></tr>
<tr><td><code id="plot.stabpath_+3A_pi_thr">pi_thr</code></td>
<td>

<p>the threshold used for the stability selection, should be in the range of 0.5 &gt; pi_thr &lt; 1.  
</p>
</td></tr>
<tr><td><code id="plot.stabpath_+3A_xvar">xvar</code></td>
<td>

<p>the variable used for the xaxis, e.g. for &quot;lambda&quot; the selection probabilities are plotted along the log of the penalization parameters,
for &quot;norm&quot; along the L1-norm and for &quot;dev&quot; along the fraction of explained deviance.
</p>
</td></tr>
<tr><td><code id="plot.stabpath_+3A_col.all">col.all</code></td>
<td>

<p>the color used for the variables that are not in the estimated stable set   
</p>
</td></tr>
<tr><td><code id="plot.stabpath_+3A_col.sel">col.sel</code></td>
<td>

<p>the color used for the variables in the estimated stable set
</p>
</td></tr>
<tr><td><code id="plot.stabpath_+3A_...">...</code></td>
<td>

<p>further arguments that are passed to matplot
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of four objects
</p>
<table>
<tr><td><code>stable</code></td>
<td>

<p>a vector giving the positions of the estimated stable variables 
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>the penalization parameter used for the stability selection 
</p>
</td></tr>
<tr><td><code>lpos</code></td>
<td>

<p>the position of the penalization parameter in the regularization path
</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>the desired type I error level w.r.t. to the chosen type I error rate
</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the type I error rate 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Sill \
<a href="mailto:m.sill@dkfz.de">m.sill@dkfz.de</a>
</p>


<h3>References</h3>

<p>Meinshausen N. and Buehlmann P. (2010), Stability Selection, Journal of the Royal Statistical Society: Series B (Statistical Methodology) Volume 72, Issue 4, pages 417-473.<br />
Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+stabsel">stabsel</a>,<a href="#topic+stabpath">stabpath</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#gaussian
set.seed(1234)
x=matrix(rnorm(100*1000,0,1),100,1000)
y &lt;- x[1:100,1:1000]%*%c(rep(2,5),rep(-2,5),rep(.1,990))
res &lt;- stabpath(y,x,weakness=1,mc.cores=2)
plot(res,error=.5,type='pfer')

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.sum.intsearch'>
Plot Summary object for interval search models
</h2><span id='topic+plot.sum.intsearch'></span>

<h3>Description</h3>

<p>Produces a plot for summary object of a fitted interval search model.
Plot 'visited' points against iteration steps. start.N points are initial points selected before interval search starts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sum.intsearch'
plot(x,type="summary",startN=21,... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sum.intsearch_+3A_x">x</code></td>
<td>

<p>an object of class <code>sum.intsearch</code> as returned by the function <code>summary.intsearch</code>.
</p>
</td></tr>
<tr><td><code id="plot.sum.intsearch_+3A_type">type</code></td>
<td>
<p>type of plot to be drawn, <code>type="summary"</code> will plot the partial log likelihood deviance as a function of   both tuning parameters &alpha; and log&lambda;. The final solution will be highlighted by solid red line.
Alternativly, <code>type="points"</code> will draw the distribution of initial and visited points of the interval search plotted in chronological order.</p>
</td></tr>
<tr><td><code id="plot.sum.intsearch_+3A_startn">startN</code></td>
<td>
<p>number of initial points. Needed if <code>type="points"</code></p>
</td></tr>
<tr><td><code id="plot.sum.intsearch_+3A_...">...</code></td>
<td>
<p>additional argument(s)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Natalia Becker  \
<a href="mailto:natalia.becker@dkfz.de">natalia.becker@dkfz.de</a>
</p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

 <p><code><a href="penalizedSVM.html#topic+EPSGO">EPSGO</a></code>, <code><a href="#topic+summary.intsearch">summary.intsearch</a></code>
</p>

<hr>
<h2 id='predictProb.coxnet'>Extract predicted survival probabilities from a glmnet fit</h2><span id='topic+predictProb.coxnet'></span>

<h3>Description</h3>

<p>Extracts predicted survival probabilities from survival model fitted by glmnet, providing an interface as required by <code>pmpec</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coxnet'
predictProb(object, response, x, times, complexity, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictProb.coxnet_+3A_object">object</code></td>
<td>
<p>a fitted model of class <code>glmnet</code></p>
</td></tr>
<tr><td><code id="predictProb.coxnet_+3A_response">response</code></td>
<td>
<p>a two-column matrix with columns named 'time' and 'status'. The latter is a binary variable, with '1' indicating death, and '0' indicating right censored. The function <code>Surv()</code> in package survival produces such a matrix</p>
</td></tr>
<tr><td><code id="predictProb.coxnet_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="predictProb.coxnet_+3A_times">times</code></td>
<td>
<p>vector of evaluation time points.</p>
</td></tr>
<tr><td><code id="predictProb.coxnet_+3A_complexity">complexity</code></td>
<td>
<p>lambda penalty value.</p>
</td></tr>
<tr><td><code id="predictProb.coxnet_+3A_...">...</code></td>
<td>
<p>additional arguments, currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with probabilities for each evaluation time point in <code>times</code> (columns) and each new observation (rows). 
</p>


<h3>Author(s)</h3>

<p>Thomas Hielscher \
<a href="mailto:t.hielscher@dkfz.de">t.hielscher@dkfz.de</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em>,   <a href="https://web.stanford.edu/~hastie/Papers/glmnet.pdf">https://web.stanford.edu/~hastie/Papers/glmnet.pdf</a><br />
<em>Journal of Statistical Software, Vol. 33(1), 1-22 Feb 2010</em><br />
<a href="https://www.jstatsoft.org/v33/i01/">https://www.jstatsoft.org/v33/i01/</a><br />
Simon, N., Friedman, J., Hastie, T., Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional Hazards Model via
Coordinate Descent, Journal of Statistical Software, Vol. 39(5)
1-13</em><br />
<a href="https://www.jstatsoft.org/v39/i05/">https://www.jstatsoft.org/v39/i05/</a><br />
Porzelius, C., Binder, H., and Schumacher, M. (2009) 
<em>Parallelized prediction error estimation for evaluation of high-dimensional models,
Bioinformatics, Vol. 25(6), 827-829.</em><br />
Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predictProb.glmnet">predictProb.glmnet</a></code>,<code><a href="peperr.html#topic+peperr">peperr</a></code>, <code><a href="glmnet.html#topic+glmnet">glmnet</a></code></p>

<hr>
<h2 id='predictProb.glmnet'>Extract predicted survival probabilities from a glmnet fit</h2><span id='topic+predictProb.glmnet'></span>

<h3>Description</h3>

<p>Extracts predicted survival probabilities from survival model fitted by glmnet, providing an interface as required by <code>pmpec</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmnet'
predictProb(object, response, x, times, complexity, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictProb.glmnet_+3A_object">object</code></td>
<td>
<p>a fitted model of class <code>glmnet</code>.</p>
</td></tr>
<tr><td><code id="predictProb.glmnet_+3A_response">response</code></td>
<td>
<p>response variable. Quantitative for <code>family="gaussian"</code>, or <code>family="poisson"</code> (non-negative counts). For <code>family="binomial"</code> should be either a factor with two levels, or a two-column matrix of counts or proportions. For <code>family="multinomial"</code>, can be a nc&gt;=2 level factor, or a matrix with nc columns of counts or proportions. </p>
</td></tr>
<tr><td><code id="predictProb.glmnet_+3A_x">x</code></td>
<td>
<p><code>n*p</code> matrix of covariates.</p>
</td></tr>
<tr><td><code id="predictProb.glmnet_+3A_times">times</code></td>
<td>
<p>vector of evaluation time points.</p>
</td></tr>
<tr><td><code id="predictProb.glmnet_+3A_complexity">complexity</code></td>
<td>
<p>lambda penalty value.</p>
</td></tr>
<tr><td><code id="predictProb.glmnet_+3A_...">...</code></td>
<td>
<p>additional arguments, currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with probabilities for each evaluation time point in <code>times</code> (columns) and each new observation (rows). 
</p>


<h3>Author(s)</h3>

<p>Thomas Hielscher \
<a href="mailto:t.hielscher@dkfz.de">t.hielscher@dkfz.de</a>
</p>


<h3>References</h3>

<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent</em>,   <a href="https://web.stanford.edu/~hastie/Papers/glmnet.pdf">https://web.stanford.edu/~hastie/Papers/glmnet.pdf</a><br />
<em>Journal of Statistical Software, Vol. 33(1), 1-22 Feb 2010</em><br />
<a href="https://www.jstatsoft.org/v33/i01/">https://www.jstatsoft.org/v33/i01/</a><br />
Simon, N., Friedman, J., Hastie, T., Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional Hazards Model via
Coordinate Descent, Journal of Statistical Software, Vol. 39(5)
1-13</em><br />
<a href="https://www.jstatsoft.org/v39/i05/">https://www.jstatsoft.org/v39/i05/</a><br />
Porzelius, C., Binder, H., and Schumacher, M. (2009) 
<em>Parallelized prediction error estimation for evaluation of high-dimensional models,
Bioinformatics, Vol. 25(6), 827-829.</em><br />
Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predictProb.coxnet">predictProb.coxnet</a></code>, <code><a href="peperr.html#topic+peperr">peperr</a></code>, <code><a href="glmnet.html#topic+glmnet">glmnet</a></code></p>

<hr>
<h2 id='stabpath'>
Stability path for glmnet models
</h2><span id='topic+stabpath'></span>

<h3>Description</h3>

<p>The function calculates the stability path for glmnet models, e.g. the selection probabilities of the features along the range of regularization parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stabpath(y,x,size=0.632,steps=100,weakness=1,mc.cores=getOption("mc.cores", 2L),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stabpath_+3A_y">y</code></td>
<td>

<p>response variable. Like for the glment function: Quantitative for <code>family="gaussian"</code> or
<code>family="poisson"</code> (non-negative counts). For
<code>family="binomial"</code> should be either a factor with two
levels, or a two-column matrix of counts or proportions. For
<code>family="multinomial"</code>, can be a <code>nc&gt;=2</code> level factor, or a
matrix with <code>nc</code> columns of counts or proportions. For
<code>family="cox"</code>, <code>y</code> should be a two-column matrix with
columns named 'time' and 'status'. The latter is a binary
variable, with '1' indicating death, and '0' indicating right
censored. The function <code>Surv()</code> in package <code>survival</code>
produces such a matrix
</p>
</td></tr>
<tr><td><code id="stabpath_+3A_x">x</code></td>
<td>

<p>input matrix. Like for the glmnet function:
of dimension nobs x nvars; each row is an
observation vector. Can be in sparse matrix format (inherit
from class <code>"sparseMatrix"</code> as in package <code>Matrix</code>; not yet
available for <code>family="cox"</code>)
</p>
</td></tr>
<tr><td><code id="stabpath_+3A_size">size</code></td>
<td>

<p>proportion of samples drawn in every subsample used for the stability selection.
</p>
</td></tr>
<tr><td><code id="stabpath_+3A_steps">steps</code></td>
<td>

<p>number of subsamples used for the stability selection.
</p>
</td></tr>
<tr><td><code id="stabpath_+3A_weakness">weakness</code></td>
<td>

<p>weakness parameter used for the randomised lasso as described in Meinshausen and B\&quot;uhlmann (2010). 
For each subsample the features are reweighted by a random weight uniformly sampled in [weakness,1].
This additional randomisation leads to a more consistent estimation of the stable set of features.
</p>
</td></tr>
<tr><td><code id="stabpath_+3A_mc.cores">mc.cores</code></td>
<td>

<p>number of cores used for the parallelization. For unix like system the parallelization is done by forking using the function <code>mclapply</code>. For windows systems socket cluster are used. 
</p>
</td></tr>
<tr><td><code id="stabpath_+3A_...">...</code></td>
<td>

<p>further arguments that are passed to the <code>glmnet</code> function. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class &quot;stabpath&quot;, which is a list of three objects
</p>
<table>
<tr><td><code>fit</code></td>
<td>

<p>the fit object of class &quot;glmnet&quot; as returned from the glmnet function when applied to the complete data set.
</p>
</td></tr>
<tr><td><code>stabpath</code></td>
<td>

<p>a matrix which represents the stability path.
</p>
</td></tr>
<tr><td><code>qs</code></td>
<td>

<p>a vector holding the values of the average number of non-zero coefficients w.r.t to the lambdas in the regularization path.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Sill 
<a href="mailto:m.sill@dkfz.de">m.sill@dkfz.de</a>
</p>


<h3>References</h3>

<p>Meinshausen N. and B\&quot;uhlmann P. (2010), <em>Stability Selection, Journal of the Royal Statistical Society: Series B (Statistical Methodology) Volume 72, Issue 4, pages 417&ndash;473.</em><br />
</p>
<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

 <p><code><a href="glmnet.html#topic+glmnet">glmnet</a>,<a href="#topic+stabsel">stabsel</a>,<a href="#topic+plot.stabpath">plot.stabpath</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#gaussian
set.seed(1234)
x &lt;- matrix(rnorm(100*1000,0,1),100,1000)
y &lt;- x[1:100,1:1000]%*% c(rep(2,5),rep(-2,5),rep(.1,990))
res &lt;- stabpath(y,x,weakness=1,mc.cores=2)
plot(res)

#binomial
y=sample(1:2,100,replace=TRUE)
res &lt;- stabpath(y,x,weakness=1,mc.cores=2,family="binomial")
plot(res)
    
#multinomial
y=sample(1:4,100,replace=TRUE)
res &lt;- stabpath(y,x,weakness=1,mc.cores=2,family="multinomial")
plot(res)
    
#poisson
N=100; p=1000
nzc=5
x=matrix(rnorm(N*p),N,p)
beta=rnorm(nzc)
f = x[,seq(nzc)]%*%beta
mu=exp(f)
y=rpois(N,mu)
res &lt;- stabpath(y,x,weakness=1,mc.cores=2,family="poisson")
plot(res)

#Cox
library(survival)
set.seed(10101)
N=100;p=1000
nzc=p/3
x=matrix(rnorm(N*p),N,p)
beta=rnorm(nzc)
fx=x[,seq(nzc)]%*%beta/3
hx=exp(fx)
ty=rexp(N,hx)
tcens=rbinom(n=N,prob=.3,size=1)
y=cbind(time=ty,status=1-tcens)
res &lt;- stabpath(y,x,weakness=1,mc.cores=2,family="cox")
plot(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='stabsel'>
function to estimate a stable set of variables  
</h2><span id='topic+stabsel'></span>

<h3>Description</h3>

<p>Given a desired type I error rate and a stability path calculated with <code>stability.path</code> the function selects a stable set of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stabsel(x,error=0.05,type=c("pfer","pcer"),pi_thr=0.6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stabsel_+3A_x">x</code></td>
<td>

<p>an object of class &quot;stabpath&quot; as returned by the function <code>stabpath</code>.
</p>
</td></tr>
<tr><td><code id="stabsel_+3A_error">error</code></td>
<td>

<p>the desired type I error level w.r.t. to the chosen type I error rate.
</p>
</td></tr>
<tr><td><code id="stabsel_+3A_type">type</code></td>
<td>

<p>The type I error rate used for controlling the number falsely selected variables. If <code>type="pfer"</code> the per-family error rate is controlled and <code>error</code> corresponds to the expected number of type I errors.
Selecting <code>type="pfer"</code> and <code>error</code> in the range of $0 &gt; <code>error</code> &lt; 1$ will control the family-wise error rate, i.e. the probability that at least one variable in the estimated stable set has been falsely selected.
If <code>type="pcer"</code> the per-comparison error rate is controlled and <code>error</code> corresponds to the expected number of type I errors divided by the number variables. 
</p>
</td></tr>
<tr><td><code id="stabsel_+3A_pi_thr">pi_thr</code></td>
<td>

<p>the threshold used for the stability selection, should be in the range of $0.5 &gt; pi_thr &lt; 1$.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of four objects
</p>
<table>
<tr><td><code>stable</code></td>
<td>

<p>a vector giving the positions of the estimated stable variables 
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>the penalization parameter used for the stability selection 
</p>
</td></tr>
<tr><td><code>lpos</code></td>
<td>

<p>the position of the penalization parameter in the regularization path
</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>the desired type I error level w.r.t. to the chosen type I error rate
</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the type I error rate 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Sill \
<a href="mailto:m.sill@dkfz.de">m.sill@dkfz.de</a>
</p>


<h3>References</h3>

<p>Meinshausen N. and B\&quot;uhlmann P. (2010), <em>Stability Selection, Journal of the Royal Statistical Society: Series B (Statistical Methodology) Volume 72, Issue 4, pages 417&ndash;473.</em><br />
</p>
<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.stabpath">plot.stabpath</a>,<a href="#topic+stabpath">stabpath</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#gaussian
set.seed(1234)
x=matrix(rnorm(100*1000,0,1),100,1000)
y &lt;- x[1:100,1:1000]%*%c(rep(2,5),rep(-2,5),rep(.1,990))
res &lt;- stabpath(y,x,weakness=1,mc.cores=2)
stabsel(res,error=0.05,type="pfer")

## End(Not run)</code></pre>

<hr>
<h2 id='summary.intsearch'>
Summary method for interval search models
</h2><span id='topic+summary.intsearch'></span>

<h3>Description</h3>

<p>Produces a summary of a fitted interval search model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'intsearch'
summary(object,digits = max(3, getOption("digits") - 3), verbose=TRUE,first.n=5,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.intsearch_+3A_object">object</code></td>
<td>
<p> an object of class <code>intsearch</code> as returned by the function <code>EPSGO</code>.</p>
</td></tr>
<tr><td><code id="summary.intsearch_+3A_digits">digits</code></td>
<td>
<p> digits after the comma </p>
</td></tr>
<tr><td><code id="summary.intsearch_+3A_verbose">verbose</code></td>
<td>
<p> default set to TRUE.  </p>
</td></tr>
<tr><td><code id="summary.intsearch_+3A_first.n">first.n</code></td>
<td>
<p> show first.n entries , default 5. </p>
</td></tr>
<tr><td><code id="summary.intsearch_+3A_...">...</code></td>
<td>
<p>additional argument(s)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of following elements 
</p>
<table>
<tr><td><code>info</code></td>
<td>

<p>a data frame of four objects for optimal models<br />
</p>
  
<ul>
<li><p> alpha - a vector of alphas 
</p>
</li>
<li><p> lambda - a vector of  penalization parameter lambda
</p>
</li>
<li><p> deviances - a vector of deviances
</p>
</li>
<li><p> n.features -a vector of number of features selected in each optimal model
</p>
</li></ul>

</td></tr>  
<tr><td><code>opt.alpha</code></td>
<td>
<p> an optimal value for alpha</p>
</td></tr>
<tr><td><code>opt.lambda</code></td>
<td>
<p>an optimal value for lambda</p>
</td></tr>
<tr><td><code>opt.error</code></td>
<td>
<p> an optimal value for error, hier minimal diviance</p>
</td></tr>
<tr><td><code>opt.models</code></td>
<td>
<p>  a list of optimal models with the same optimal error</p>
</td></tr>  
</table>


<h3>Author(s)</h3>

<p>Natalia Becker  \
<a href="mailto:natalia.becker@dkfz.de">natalia.becker@dkfz.de</a>
</p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

 <p><code><a href="penalizedSVM.html#topic+EPSGO">EPSGO</a></code>,<code><a href="#topic+plot.sum.intsearch">plot.sum.intsearch</a></code>
</p>

<hr>
<h2 id='tune.glmnet.interval'>  Wrapper function for <code>glmnet</code> objects.    </h2><span id='topic+tune.glmnet.interval'></span>

<h3>Description</h3>

<p>Wrapper function for <code>glmnet</code> objects used by <code>epsgo</code> function.
This function is  mainly used within the function <code><a href="#topic+epsgo">epsgo</a></code>  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tune.glmnet.interval(parms, x, y,
                     weights, 
                     offset = NULL, 
                     lambda = NULL, 
                     type.measure = c("mse", "deviance", "class", "auc", "mae"),
                     seed=12345, 
                     nfolds = 10, 
                     foldid=NULL, 
                     grouped = TRUE, 
                     type.min=c("lambda.min", "lambda.1se"),
                     family,
                     verbose=FALSE,
                     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tune.glmnet.interval_+3A_parms">parms</code></td>
<td>
<p>tuning parameter alpha for <code>glmnet</code> object</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_x">x</code>, <code id="tune.glmnet.interval_+3A_y">y</code></td>
<td>
<p>x is a matrix where each row refers to a sample a each
column refers to a gene; y is a factor which includes the class for
each sample</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_weights">weights</code></td>
<td>
<p>observation weights. Can be total counts if responses are proportion matrices. Default is 1 for each observation</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_offset">offset</code></td>
<td>
<p>A vector of length nobs that is included in the linear predictor (a nobs x nc matrix for the &quot;multinomial&quot; family). Useful for the &quot;poisson&quot; family (e.g. log of exposure time), or for refining a model by starting at a current fit. Default is NULL. If supplied, then values must also be supplied to the predict function.</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence. Typical usage is to have the program compute its own lambda sequence based on nlambda and lambda.min.ratio. Supplying a value of lambda overrides this. WARNING: use with care. Do not supply a single value for lambda (for predictions after CV use predict() instead). Supply instead a decreasing sequence of lambda values. glmnet relies on its warms starts for speed, and its often faster to fit a whole path than compute a single fit.</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_type.measure">type.measure</code></td>
<td>
<p>loss to use for cross-validation. Currently five options, not all available for all models. The default is type.measure=&quot;deviance&quot;, which uses squared-error for gaussian models (a.k.a type.measure=&quot;mse&quot; there), deviance for logistic and poisson regression, and partial-likelihood for the Cox model. type.measure=&quot;class&quot; applies to binomial and multinomial logistic regression only, and gives misclassification error. type.measure=&quot;auc&quot; is for two-class logistic regression only, and gives area under the ROC curve. type.measure=&quot;mse&quot; or type.measure=&quot;mae&quot; (mean absolute error) can be used by all models except the &quot;cox&quot;; they measure the deviation from the fitted mean to the response.</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_seed">seed</code></td>
<td>
<p>seed</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_nfolds">nfolds</code></td>
<td>
<p>number of cross-validation's folds, default 10.</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_foldid">foldid</code></td>
<td>
<p>an optional vector of values between 1 and nfold identifying what fold each observation is in. If supplied, nfold can be missing.</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_grouped">grouped</code></td>
<td>
<p> This is an experimental argument, with default TRUE, and can be ignored by most users. For all models except the &quot;cox&quot;, this refers to computing nfolds separate statistics, and then using their mean and estimated standard error to describe the CV curve. If grouped=FALSE, an error matrix is built up at the observation level from the predictions from the nfold fits, and then summarized (does not apply to type.measure=&quot;auc&quot;). For the &quot;cox&quot; family, grouped=TRUE obtains the CV partial likelihood for the Kth fold by subtraction; by subtracting the log partial likelihood evaluated on the full dataset from that evaluated on the on the (K-1)/K dataset. This makes more efficient use of risk sets. With grouped=FALSE the log partial likelihood is computed only on the Kth fold</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_type.min">type.min</code></td>
<td>
<p>parameter for chosing optimal model: 'lambda.min'- value of lambda that gives minimum mean cross-validated error (cvm).
'lambda.1se' - largest value of lambda such that error is within one standard error of the minimum.</p>
</td></tr>
<tr><td><code id="tune.glmnet.interval_+3A_family">family</code></td>
<td>
<p>family of the model, i.e. cox, glm,...</p>
</td></tr> 
<tr><td><code id="tune.glmnet.interval_+3A_verbose">verbose</code></td>
<td>
<p>verbose</p>
</td></tr>   
<tr><td><code id="tune.glmnet.interval_+3A_...">...</code></td>
<td>
<p>Further parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>q.val</code></td>
<td>
<p>minimal value of Q.func on the interval defined by bounds. Here, q.val is  minimum mean cross-validate               d error (cvm)</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p> model list
</p>

<ul>
<li><p> alpha -  optimal alpha
</p>
</li>
<li><p> lambda - optimal lambda
</p>
</li>
<li><p> nfolds - cross-validation's folds
</p>
</li>
<li><p> cvreg -  <code>cv.glmnet</code> object for optimal alpha 
</p>
</li>
<li><p> fit - <code>glmnet</code> object for optimal alpha and optimal lambda 
</p>
</li></ul>
 
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Natalia Becker  natalia.becker at dkfz.de </p>


<h3>References</h3>

<p>Sill M., Hielscher T., Becker N. and Zucknick M. (2014), <em>c060: Extended Inference with Lasso and Elastic-Net Regularized Cox and Generalized Linear Models, Journal of Statistical Software, Volume 62(5), pages 1&ndash;22.</em>
<a href="https://doi.org/10.18637/jss.v062.i05">doi:10.18637/jss.v062.i05</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epsgo">epsgo</a></code></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
