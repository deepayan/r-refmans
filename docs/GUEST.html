<!DOCTYPE html><html lang="en"><head><title>Help for package GUEST</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GUEST}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#boost.graph'><p>Estimation of precision matrix and detection of graphical structure</p></a></li>
<li><a href='#GUEST_package'>
<p>Graphical Models in Ultrahigh-Dimensional and Error-Prone Data via Boosting Algorithm</p></a></li>
<li><a href='#LDA.boost'><p>Implementation of the linear discriminant function for multi-label classification.</p></a></li>
<li><a href='#MedulloblastomaData'><p>The medulloblastoma dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Graphical Models in Ultrahigh-Dimensional and Error-Prone Data
via Boosting Algorithm</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>We consider the ultrahigh-dimensional and error-prone data. Our goal aims to estimate the precision matrix and identify the graphical structure of the random variables with measurement error corrected. We further adopt the estimated precision matrix to the linear discriminant function to do classification for multi-label classes.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>sna</td>
</tr>
<tr>
<td>Imports:</td>
<td>XICOR, network, GGally</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Author:</td>
<td>Hui-Shan Tsao [aut, cre],
  Li-Pang Chen [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hui-Shan Tsao &lt;n410412@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-30 14:18:16 UTC; user</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-30 14:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='boost.graph'>Estimation of precision matrix and detection of graphical structure</h2><span id='topic+boost.graph'></span>

<h3>Description</h3>

<p>This function first applies the regression calibration to deal with measurement error effects. After that, the feature screening technique is employed to screen out independent pairs of random variables and reduce the dimension of random variables. Finally, we adopt the boosting method to detect informative pairs of random variables and estimate the precision matrix. This function can handle various distributions, such as normal, binomial, and Poisson distributions, as well as nonlinear effects among random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boost.graph(data,ite1,ite2,ite3,thre,select = 0.9,inc = 10^(-3),
sigma_e = 0.6,q = 0.8,lambda = 1,pi = 0.5,rep = 100,cor = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boost.graph_+3A_data">data</code></td>
<td>

<p>An n (observations) times p (variables) matrix of random variables, whose distributions can be continuous, discrete, or mixed.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_ite1">ite1</code></td>
<td>

<p>The number of iterations for continuous variables.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_ite2">ite2</code></td>
<td>

<p>The number of iterations for binary variables.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_ite3">ite3</code></td>
<td>

<p>The number of iterations for count variables.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_thre">thre</code></td>
<td>

<p>The treshold value for feature screening, whose value should be between 0 and 1.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_select">select</code></td>
<td>

<p>The treshold constant in the boosting algorithm, whose value should be between 0 and 1. The default value is 0.9.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_inc">inc</code></td>
<td>

<p>The learning rate of the increment in the boosting algorithm, which shoud be a small value. The default value is 0.001.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_sigma_e">sigma_e</code></td>
<td>

<p>The common value in the diagonal covariance matrix of the error for the classical measurement error model when <code>data</code> are continuous. The default value is 0.6.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_q">q</code></td>
<td>

<p>The common value used to characterize misclassification for binary random variables. The default value is 0.8.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_lambda">lambda</code></td>
<td>

<p>The parameter of the Poisson distribution, which is used to characterize error-prone count random variables. The default value is 1.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_pi">pi</code></td>
<td>

<p>The probability in the Binomial distribution, which is used to characterize error-prone count random variables. The default value is 0.5.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_rep">rep</code></td>
<td>

<p>The number of bootstrapping iterations. The default value is 100.
</p>
</td></tr>
<tr><td><code id="boost.graph_+3A_cor">cor</code></td>
<td>

<p>Measurement error correction when estimating the precision matrix. The default value is TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>w</code></td>
<td>

<p>The estimator of the precision matrix.
</p>
</td></tr>
<tr><td><code>p</code></td>
<td>

<p>The chosen pairs obtained by the feature screening.
</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>

<p>The weights sorted with pairs in <code>p</code>.
</p>
</td></tr>
<tr><td><code>g</code></td>
<td>

<p>The visualization of the estimated network structure determined by <code>w</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hui-Shan Tsao and Li-Pang Chen<br />
Maintainer: Hui-Shan Tsao <a href="mailto:n410412@gmail.com">n410412@gmail.com</a>
</p>


<h3>References</h3>

<p>Hui-Shan Tsao (2024). <em>Estimation of Ultrahigh-Dimensional Graphical Models and Its Application to Dsicriminant Analysis.</em> Master Thesis supervised by Li-Pang Chen, National Chengchi University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MedulloblastomaData)

X &lt;- t(MedulloblastomaData[2:656,]) #covariates
Y &lt;- MedulloblastomaData[1,] #response

X &lt;- matrix(as.numeric(X),nrow=23)

p &lt;- ncol(X)
n &lt;- nrow(X)

#standarization
X_new=data.frame()
for (i in 1:p){
 X_new[1:n,i]=(X[,i]-rep(mean(X[,i]),n))/sd(X[,i])
}
X_new=matrix(unlist(X_new),nrow = n)


#estimate graphical model
result &lt;- boost.graph(data = X_new, thre = 0.2, ite1 = 3, ite2 = 0, ite3 = 0, rep = 1)
theta.hat &lt;- result$w
</code></pre>

<hr>
<h2 id='GUEST_package'>
Graphical Models in Ultrahigh-Dimensional and Error-Prone Data via Boosting Algorithm
</h2><span id='topic+GUEST_package'></span>

<h3>Description</h3>

<p>The package GUEST, referred to Graphical models in Ultrahigh-dimensional and Error-prone data via booSTing algorithm, is used to estimate the precision matrix and detect graphical structure for ultrahigh-dimensional, error-prone, and possibly nonlinear random variables. Given the estimated precision matrix, we further apply it to the linear discriminant function to deal with multi-classification. The precision matrix can be estimated by the function <code>boost.graph</code>, and the classification can be implemented by the function <code>LDA.boost</code>. Finally, we consider the medulloblastoma dataset to demonstrate the implementation of two functions. </p>


<h3>Details</h3>

<p>To estimate the precision matrix and detect the graphical structure under our scenario, the function <code>boost.graph</code> first applies the regression calibration method to deal with measurement error in continuous, binary, or count random variables. After that, the feature screening technique is employed to reduce the dimension of random variable, and we then adopt the boosting algorithm to estimate the precision matrix. The estimated precision matrix also reflects the desired graphical structure. The function <code>LDA.boost</code> implements the linear discriminant function to do classification for multi-label classes, where the precision matrix, also known as the inverse of the covariance matrix, in the linear discriminant function can be estimated by the function <code>boost.graph</code>.
</p>


<h3>Value</h3>

<p>GUEST_package
</p>

<hr>
<h2 id='LDA.boost'>Implementation of the linear discriminant function for multi-label classification.</h2><span id='topic+LDA.boost'></span>

<h3>Description</h3>

<p>This function applies the linear discriminant function to do classification for multi-label responses. The precision matrix, or the inverse of the covariance matrix, in the linear discriminant function can be estimated by <code>w</code> in the function <code>boost.graph</code>. In addition,  error-prone covariates in  the linear discriminant function are addressed by the regression calibration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDA.boost(data, resp, theta, sigma_e = 0.6,q = 0.8,lambda = 1, pi = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LDA.boost_+3A_data">data</code></td>
<td>

<p>An n (observations) times p (variables) matrix of random variables, whose distributions can be continuous, discrete, or mixed.
</p>
</td></tr>
<tr><td><code id="LDA.boost_+3A_resp">resp</code></td>
<td>

<p>An n-dimensional vector of categorical random variables, which is the response in the data.
</p>
</td></tr>
<tr><td><code id="LDA.boost_+3A_theta">theta</code></td>
<td>

<p>The estimator of the precision matrix.
</p>
</td></tr>
<tr><td><code id="LDA.boost_+3A_sigma_e">sigma_e</code></td>
<td>

<p>The common value in the diagonal covariance matrix of the error for the classical measurement error model when <code>data</code> are continuous. The default value is 0.6.
</p>
</td></tr>
<tr><td><code id="LDA.boost_+3A_q">q</code></td>
<td>

<p>The common value used to characterize misclassification for binary random variables. The default value is 0.8.
</p>
</td></tr>
<tr><td><code id="LDA.boost_+3A_lambda">lambda</code></td>
<td>

<p>The parameter of the Poisson distribution, which is used to characterize error-prone count random variables. The default value is 1.
</p>
</td></tr>
<tr><td><code id="LDA.boost_+3A_pi">pi</code></td>
<td>

<p>The probability in the Binomial distribution, which is used to characterize error-prone count random variables. The default value is 0.5.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The linear discriminant function used is as follow: <br />
</p>
<p style="text-align: center;"><code class="reqn">
  \code{score}_{i,j} = \log (\pi _i) - 0.5\ \mu_{i}^\top\  \code{theta}\ \mu _{i} + \code{data}_{j}^\top\ \code{theta}\ \mu_{i},
  </code>
</p>
<p><br />
for the class <code class="reqn">i = 1, \cdots, I</code> with <code class="reqn">I</code> being the number of classes in the dataset and subject <code class="reqn">j = 1, \cdots, n</code>, where <code class="reqn">\pi _i</code> is the proportion of subjects in the class <code class="reqn">i</code>, <code class="reqn">\code{data}_{j}</code> is the vector of covariates for the subject <code class="reqn">j</code>, <code class="reqn">\code{theta}</code> is the precision matrix of the covariates, and <code class="reqn">\mu_{i}</code> is the empirical mean vector of the random variables in the class <code class="reqn">i</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>score</code></td>
<td>

<p>The value of the linear discriminant function (see details) with the estimator of the precision matrix accommodated.
</p>
</td></tr>
<tr><td><code>class</code></td>
<td>

<p>The result of predicted class for subjects.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hui-Shan Tsao and Li-Pang Chen<br />
Maintainer: Hui-Shan Tsao <a href="mailto:n410412@gmail.com">n410412@gmail.com</a>
</p>


<h3>References</h3>

<p>Hui-Shan Tsao (2024). <em>Estimation of Ultrahigh-Dimensional Graphical Models and Its Application to Dsicriminant Analysis.</em> Master Thesis supervised by Li-Pang Chen, National Chengchi University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MedulloblastomaData)

X &lt;- t(MedulloblastomaData[2:655,]) #covariates
Y &lt;- MedulloblastomaData[1,] #response

X &lt;- matrix(as.numeric(X),nrow=23)

p &lt;- ncol(X)
n &lt;- nrow(X)

#standarization
X_new=data.frame()
for (i in 1:p){
 X_new[1:n,i]=(X[,i]-rep(mean(X[,i]),n))/sd(X[,i])
}
X_new=matrix(unlist(X_new),nrow = n)


#estimate graphical model
result &lt;- boost.graph(data = X_new, thre = 0.2, ite1 = 3, ite2 = 0, ite3 = 0, rep = 1)
theta.hat &lt;- result$w

theta.hat[which(theta.hat&lt;0.8)]=0 #keep the highly dependent pairs

#predict
pre &lt;- LDA.boost(data = X_new, resp = Y, theta = theta.hat)
estimated_Y &lt;- pre$class
</code></pre>

<hr>
<h2 id='MedulloblastomaData'>The medulloblastoma dataset
</h2><span id='topic+MedulloblastomaData'></span>

<h3>Description</h3>

<p>The dataset, which is available on https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE468, contains 23 patients with medulloblastoma, and each patient has 2059 gene expression values. The response contains 2 classes: metastatic (M+) or non-metastatic (M0). After removing the missing and duplicate values, the dimension of remaining gene expressions is 655. The dataset is used to illustrate the usage of the <code><a href="#topic+boost.graph">boost.graph</a></code> and <code><a href="#topic+LDA.boost">LDA.boost</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MedulloblastomaData)</code></pre>


<h3>Format</h3>

<p>The dataset has 23 observations and 655 gene expression values.
</p>


<h3>References</h3>

<p>MacDonald, T., Brown, K., LaFleur, B., Peterson K., Lawlor C., Chen Y., Packer RJ., Cogen P., Stephan DA.(2001). <em>Expression profiling of medulloblastoma: PDGFRA and the RAS/MAPK pathway as therapeutic targets for metastatic disease</em>. Nat Genet, 29, 143–152.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- t(MedulloblastomaData[2:655,]) #covariates
Y &lt;- MedulloblastomaData[1,] #response

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
