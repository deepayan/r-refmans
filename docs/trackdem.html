<!DOCTYPE html><html><head><title>Help for package trackdem</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {trackdem}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#trackdem'><p>trackdem - Particle Tracking and Demography</p></a></li>
<li><a href='#createBackground'><p>Background detection</p></a></li>
<li><a href='#createImageSeq'><p>Create image sequence</p></a></li>
<li><a href='#findMaxCost'><p>Find maximum tracking cost</p></a></li>
<li><a href='#findPixelRange'><p>Find pixel range</p></a></li>
<li><a href='#findThreshold'><p>Find threshold</p></a></li>
<li><a href='#identifyParticles'><p>Identify moving particles</p></a></li>
<li><a href='#loadImages'><p>Load .png images</p></a></li>
<li><a href='#manuallySelect'><p>Manually identify true and false positives with a GUI.</p></a></li>
<li><a href='#mergeTracks'><p>Merge track records</p></a></li>
<li><a href='#plot.TrDm'><p><code>plot</code> methods for class 'TrDm'.</p></a></li>
<li><a href='#print.summaryTrDm'><p><code>print</code> methods for class 'TrDm'.</p></a></li>
<li><a href='#print.TrDm'><p><code>print</code> methods for class 'TrDm'.</p></a></li>
<li><a href='#runBatch'><p>Batch analysis</p></a></li>
<li><a href='#simulTrajec'><p>Simulate trajectories and save as png files.</p></a></li>
<li><a href='#subtractBackground'><p>Background subtraction</p></a></li>
<li><a href='#summary.TrDm'><p><code>summary</code> methods for class 'TrDm'.</p></a></li>
<li><a href='#testNN'><p>Train, validate and test artificial</p>
neural networks</a></li>
<li><a href='#trackParticles'><p>Track particles</p></a></li>
<li><a href='#update.particles'><p>Update identified particles.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Particle Tracking and Demography</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-06</td>
</tr>
<tr>
<td>Author:</td>
<td>Marjolein Bruijning, Marco D. Visser, Caspar A. Hallmann, Eelke Jongejans</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marjolein Bruijning &lt;m.bruijning@uva.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Obtain population density and body size structure, using video material or image sequences as input. Functions assist in the creation of image sequences from videos, background detection and subtraction, particle identification and tracking. An artificial neural network can be trained for noise filtering. The goal is to supply accurate estimates of population size, structure and/or individual behavior, for use in  evolutionary and ecological studies.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/marjoleinbruijning/trackdem">https://github.com/marjoleinbruijning/trackdem</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/marjoleinbruijning/trackdem/issues">https://github.com/marjoleinbruijning/trackdem/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>png, neuralnet, raster, Rcpp, MASS, grDevices, graphics,
stats, shiny</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo,</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;=2.7), Libav, ExifTool</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-08 10:20:59 UTC; mbruijn1</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-08 13:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='trackdem'>trackdem - Particle Tracking and Demography</h2><span id='topic+trackdem-package'></span><span id='topic+trackdem'></span>

<h3>Description</h3>

<p>trackdem - Particle Tracking and Demography
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann, Marco D. Visser, Eelke Jongejans
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/marjoleinbruijning/trackdem">https://github.com/marjoleinbruijning/trackdem</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/marjoleinbruijning/trackdem/issues">https://github.com/marjoleinbruijning/trackdem/issues</a>
</p>
</li></ul>


<hr>
<h2 id='createBackground'>Background detection</h2><span id='topic+createBackground'></span>

<h3>Description</h3>

<p><code>createBackground</code> detects the still background,
containing all motionless pixels (non particles). Three different methods
to detect the background can be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createBackground(colorimages, method = "mean")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createBackground_+3A_colorimages">colorimages</code></td>
<td>
<p>Array of class 'TrDm' containing all images, obtained by
<code><a href="#topic+loadImages">loadImages</a></code>.</p>
</td></tr>
<tr><td><code id="createBackground_+3A_method">method</code></td>
<td>
<p>Use <code>method='mean'</code> to calculate the mean value for each
pixel and color.
Use <code>method='powerroot'</code> to deflate dark values (note, this can only be
used for dark particles on a light background). Use <code>method='filter'</code> to
replace pixels in which movement has occurred with the mode of neighboring
values.
Note that <code>method='filter'</code> is computationally more intensive.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Array of class 'TrDm' and 'colorimage' containing detected background.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
plot(stillBack)

## End(Not run)
</code></pre>

<hr>
<h2 id='createImageSeq'>Create image sequence</h2><span id='topic+createImageSeq'></span>

<h3>Description</h3>

<p><code>createImageSeq</code> creates an image sequences (.png) using
video files as input. All movies within a directory will
be converted into an image sequence.
For each movie, a new directory is created containing the recorded date and
name of the movie.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createImageSeq(
  moviepath = "Movies",
  imagepath = "ImageSequences",
  x = 1920,
  y = 1080,
  fps = 15,
  nsec = 2,
  start = NULL,
  stop = NULL,
  ext = "MTS",
  libavpath = "avconv",
  exiftoolpath = "exiftool",
  pythonpath = "python",
  verbose = FALSE,
  logfile = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createImageSeq_+3A_moviepath">moviepath</code></td>
<td>
<p>Path to existing directory containing the video files.
By default, 'Movies' is used.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_imagepath">imagepath</code></td>
<td>
<p>Path to location of a directory in which image
sequences should
be saved. By default, 'ImageSequences' is used (and created if not existing).</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_x">x</code></td>
<td>
<p>Number of pixels in horizontal direction; default is 1920 (HD).</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_y">y</code></td>
<td>
<p>Number of pixels in vertical direction; default is 1080 (HD).</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_fps">fps</code></td>
<td>
<p>Frames per second, default is 15.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_nsec">nsec</code></td>
<td>
<p>Duration of movie that is exported, default is 2 seconds.
When movie length is greater than <code>nsec</code>, the <code>nsec</code> seconds
in the exact middle of the movie are exported.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_start">start</code></td>
<td>
<p>Start time (in seconds) from where the video is converted (optional). By
default, the <code>nsec</code> middle second of the video are used. If a a start
time is specified and no stop time, <code>nsec</code> seconds starting from <code>start</code>
are converted.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_stop">stop</code></td>
<td>
<p>End time (in seconds) from where the video is converted (optional). By
default, the <code>nsec</code> middle second of the video are used. When an end time
but no start time are specified, conversion starts at <code>nsec</code> seconds before
<code>end</code>.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_ext">ext</code></td>
<td>
<p>The extension of the video. Default is <code>'MTS'</code>. All
formats supported by libav are accepted. To convert videos with different
extensions, use for example <code>c('MTS','mp4')</code>.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_libavpath">libavpath</code></td>
<td>
<p>Path to location where the executable file for libav
can be found (named 'avconv.exe'), in case it is not found automatically,
e.g. <code>'C:/Users/libav/usr/bin/avconv.exe'</code>.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_exiftoolpath">exiftoolpath</code></td>
<td>
<p>Path to location where the executable file for
ExifTool can be found, in case it is not found automatically.
For instance, use <code>'exiftool(-k).exe'</code>, if located in the working
directory.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_pythonpath">pythonpath</code></td>
<td>
<p>Path to location where the executable file for
Python 2.7 can be found, in case it is not found automatically. For
instance, use <code>'C:/Python27/python.exe'</code>.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_verbose">verbose</code></td>
<td>
<p>Logical. By default FALSE. Set to TRUE will print additional information.</p>
</td></tr>
<tr><td><code id="createImageSeq_+3A_logfile">logfile</code></td>
<td>
<p>Logical. By default FALSE. Set to TRUE will create a log file in the
working directory.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
createImageSeq(moviepath="Movies",imagepath="ImageSequences",
               nsec=3,ext="AVI")

## End(Not run)
</code></pre>

<hr>
<h2 id='findMaxCost'>Find maximum tracking cost</h2><span id='topic+findMaxCost'></span>

<h3>Description</h3>

<p>This function can help to find a appropriate maximum value for linking
a particle to another particle (parameter L in function <code>trackParticles</code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findMaxCost(particles, frame = 1, colorimages = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findMaxCost_+3A_particles">particles</code></td>
<td>
<p>Object of class 'particles', obtained using <code>identifyParticles</code>.</p>
</td></tr>
<tr><td><code id="findMaxCost_+3A_frame">frame</code></td>
<td>
<p>Number specifying which frame to use. Default is frame 1.</p>
</td></tr>
<tr><td><code id="findMaxCost_+3A_colorimages">colorimages</code></td>
<td>
<p>Array containing original color images. By default,
the original color images are obtained from the global environment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the number that is interactively chosen by the user. Use
this value in <code>trackParticles</code>.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
partIden &lt;- identifyParticles(sbg=allImages,
                              threshold=-0.05)
maxcost &lt;- findMaxCost(partIden,frame=1)
records &lt;- trackParticles(partIden,L=maxcost,R=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='findPixelRange'>Find pixel range</h2><span id='topic+findPixelRange'></span>

<h3>Description</h3>

<p>This function can help to find the minimum and maximum particle size
in pixels, to use in <code>identifyParticles</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findPixelRange(colorimages, frame = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findPixelRange_+3A_colorimages">colorimages</code></td>
<td>
<p>Array containing original color images.</p>
</td></tr>
<tr><td><code id="findPixelRange_+3A_frame">frame</code></td>
<td>
<p>Number specifying which frame to use. Default is frame 1.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marjolein Bruijning
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages)
allImages &lt;- subtractBackground(stillBack)
findPixelRange(allFullImages,frame=10)

## End(Not run)
</code></pre>

<hr>
<h2 id='findThreshold'>Find threshold</h2><span id='topic+findThreshold'></span>

<h3>Description</h3>

<p>This function can help to find a threshold value to distinguish noise from
particles of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findThreshold(images, frame = 1, colorimages = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findThreshold_+3A_images">images</code></td>
<td>
<p>Array containing images containing all moving particles,
as obtained from <code><a href="#topic+subtractBackground">subtractBackground</a></code>.</p>
</td></tr>
<tr><td><code id="findThreshold_+3A_frame">frame</code></td>
<td>
<p>Number specifying which frame to use. Default is frame 1.</p>
</td></tr>
<tr><td><code id="findThreshold_+3A_colorimages">colorimages</code></td>
<td>
<p>Array containing original color images. By default,
the original color images are obtained from the global environment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the number that is interactively chosen by the user. Use
this threshold value in <code>identifyParticles</code>.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
allImages &lt;- subtractBackground(stillBack)
thr &lt;- findThreshold(allImages,frame=10)

## End(Not run)
</code></pre>

<hr>
<h2 id='identifyParticles'>Identify moving particles</h2><span id='topic+identifyParticles'></span>

<h3>Description</h3>

<p><code>identifyParticles</code> identifies moving particles using the
subtracted images obtained from <code><a href="#topic+subtractBackground">subtractBackground</a></code>. Function
uses Connected Component Labeling and obtains particle statistics based on
code developed for the orphaned
package SDMTools (written by Jeremy VanDerWal).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identifyParticles(
  sbg,
  threshold = -0.1,
  pixelRange = NULL,
  qthreshold = NULL,
  select = "dark",
  colorimages = NULL,
  autoThres = FALSE,
  perFrame = FALSE,
  frames = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="identifyParticles_+3A_sbg">sbg</code></td>
<td>
<p>Array containing images containing all moving particles,
as obtained from <code><a href="#topic+subtractBackground">subtractBackground</a></code>.</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_threshold">threshold</code></td>
<td>
<p>Thresholds for including particles. A numeric vector
containing three values; one for each color. Otherwise, supply one value
which is to be used for all three colors. For a chosen quantile
for each frame, use <code>qthreshold</code>. Default is <code>threshold=-0.1</code>,
which works for dark particles on a light background. Alternatively,
set <code>autoThres</code> below for an automatic threshold.</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_pixelrange">pixelRange</code></td>
<td>
<p>Default is <code>NULL</code>. Numeric vector with minimum and
maximum particle size (area), used as a
first filter to identify particles. Use if particle of interest are of a
known size range (in pixels).</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_qthreshold">qthreshold</code></td>
<td>
<p>Default is <code>NULL</code>. Supply a value, to do thresholding
based on quantile. Quantile is calculated for each
frame separately.</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_select">select</code></td>
<td>
<p>Select dark particles (<code>'dark'</code>), light particles
(<code>'light'</code>), or both (<code>'both'</code>), compared to background.
Default is <code>'dark'</code>.</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_colorimages">colorimages</code></td>
<td>
<p>Array containing original color images. By default, the
original color images are obtained from global environment.</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_autothres">autoThres</code></td>
<td>
<p>Logical. <code>TRUE</code> to get an automated threshold for each
color layer. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_perframe">perFrame</code></td>
<td>
<p>Logical. If <code>autoThres=TRUE</code>, set at <code>TRUE</code>
to calculate a threshold for
each frame separately. Default is <code>FALSE</code>. Note that is can be
computationally intensive to calculate a threshold for each frame.</p>
</td></tr>
<tr><td><code id="identifyParticles_+3A_frames">frames</code></td>
<td>
<p>When <code>autoThres=TRUE</code> and <code>allFrames=FALSE</code>, supply a
numeric vector specifying over which frames the automated threshold
should be calculated on (e.g. <code>c(1,3,5,7,9,11)</code> for all odd frames
from 1 to 11).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe of class 'TrDm' and 'particles', containing
particle statistics with identified particles for each frame
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
allImages &lt;- subtractBackground(stillBack)
partIden &lt;- identifyParticles(allImages,threshold=-0.1,
                                   pixelRange=c(3,400))
plot(partIden)
summary(partIden)

## End(Not run)
</code></pre>

<hr>
<h2 id='loadImages'>Load .png images</h2><span id='topic+loadImages'></span>

<h3>Description</h3>

<p><code>loadImages</code> loads png images as three dimensional arrays.
The objects created through the function can be used for image analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadImages(
  dirPictures,
  filenames = NULL,
  nImages = 1:30,
  xranges = NULL,
  yranges = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadImages_+3A_dirpictures">dirPictures</code></td>
<td>
<p>The path of the folder where the images can be found.</p>
</td></tr>
<tr><td><code id="loadImages_+3A_filenames">filenames</code></td>
<td>
<p>Default is <code>NULL</code>, or all files. If all files should
NOT be loaded, here specify which files to use, as a character string.</p>
</td></tr>
<tr><td><code id="loadImages_+3A_nimages">nImages</code></td>
<td>
<p>Numeric vector specifying which images in the directory
should be loaded; default is <code>1:30</code>.</p>
</td></tr>
<tr><td><code id="loadImages_+3A_xranges">xranges</code></td>
<td>
<p>By default the full image is loaded; specify to subset the
number of columns.</p>
</td></tr>
<tr><td><code id="loadImages_+3A_yranges">yranges</code></td>
<td>
<p>By default the full image is loaded; specify to subset the
number of rows.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Array of class 'TrDm' and 'colorimages' containing all loaded images.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
plot(allFullImages)

## End(Not run)
</code></pre>

<hr>
<h2 id='manuallySelect'>Manually identify true and false positives with a GUI.</h2><span id='topic+manuallySelect'></span>

<h3>Description</h3>

<p><code>manuallySelect</code> opens a graphic user interface to create
training data for a neural net by manually selecting true and
false positives (i.e. correctly identified particles and noise, respectively).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>manuallySelect(particles, colorimages = NULL, frames = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="manuallySelect_+3A_particles">particles</code></td>
<td>
<p>A data frame of class 'TrDm' with particle statistics for
each frame, obtained by <code><a href="#topic+identifyParticles">identifyParticles</a></code>.</p>
</td></tr>
<tr><td><code id="manuallySelect_+3A_colorimages">colorimages</code></td>
<td>
<p>An array with the original full color images, in order
to plot on the original images. If <code>NULL</code>, the original color images
are used, obtained from the global environment.</p>
</td></tr>
<tr><td><code id="manuallySelect_+3A_frames">frames</code></td>
<td>
<p>A vector defining the frame(s) that should be used. Default
is <code>NULL</code>; in that case the frame with the maximum number of identified
particles is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing three elements: true positives, false positives,
and the evaluated frame.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain='square',
                    h=0.01,rho=0.9,movingNoise=TRUE,
                    parsMoving = list(density=20, duration=10, size=1,
                                      speed = 10, colRange = c(0,1)),
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
allImages &lt;- subtractBackground(stillBack)
partIden &lt;- identifyParticles(allImages,threshold=-0.1,
                                   pixelRange=c(3,400))
# select the nframes with the most identified particles
nframes &lt;- 3
frames &lt;- order(tapply(partIden$patchID,partIden$frame,length),
                decreasing=TRUE)[1:nframes]
mId &lt;- manuallySelect(particles=partIden,frame=frames)

## End(Not run)
</code></pre>

<hr>
<h2 id='mergeTracks'>Merge track records</h2><span id='topic+mergeTracks'></span>

<h3>Description</h3>

<p><code>mergeTracks</code> attempts to merge to two track objects as obtained by
<code><a href="#topic+trackParticles">trackParticles</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergeTracks(records1, records2, L = NULL, weight = NULL, logsizes = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mergeTracks_+3A_records1">records1</code></td>
<td>
<p>Object of class 'tracked',
obtained using <code><a href="#topic+trackParticles">trackParticles</a></code>.</p>
</td></tr>
<tr><td><code id="mergeTracks_+3A_records2">records2</code></td>
<td>
<p>Object of class 'tracked',
obtained using <code><a href="#topic+trackParticles">trackParticles</a></code> that should be linked to
<code>records1</code>.</p>
</td></tr>
<tr><td><code id="mergeTracks_+3A_l">L</code></td>
<td>
<p>Numeric. Maximum cost for linking a particle to another particle.
When the cost is larger,
particles will be not be linked (resulting in the begin or end of a segment).
If <code>NULL</code>, the same <code>L</code> as used to create
<code>records2</code> is used.</p>
</td></tr>
<tr><td><code id="mergeTracks_+3A_weight">weight</code></td>
<td>
<p>Vector containing 3 weights to calculate costs. Depending
on the study system user may want to value certain elements over others.
Weights are ordered as follows;
first number gives the weight for differences in x and y coordinates;
second number
gives the weight for particle size differences. Note that the
difference between the predicted location and the observed location is
not taken into account in this function. If <code>NULL</code>, the same weights as
used to create <code>records2</code> is used.</p>
</td></tr>
<tr><td><code id="mergeTracks_+3A_logsizes">logsizes</code></td>
<td>
<p>Logical. Default is <code>FALSE</code>. Set to <code>TRUE</code> to take the
natural logarithm of body sizes, when calculating the cost of linking two particles.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class 'TrDm' and 'records'. Use 'summary' and 'plot'.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Create image sequence
dir.create("images")
traj &lt;- simulTrajec(path="images",
                    nframes=60,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,sizes=runif(20,0.004,0.006))
## Analyse first part
dir &lt;- "images"
allFullImages1 &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack1 &lt;- createBackground(allFullImages1)
allImages1 &lt;- subtractBackground(bg=stillBack1)
partIden1 &lt;- identifyParticles(sbg=allImages1,
                              pixelRange=c(1,500),
                              threshold=-0.1)
records1 &lt;- trackParticles(partIden1,L=20,R=2)
## Analyse second part
allFullImages2 &lt;- loadImages (dirPictures=dir,nImages=31:60)
stillBack2 &lt;- createBackground(allFullImages2)
allImages2 &lt;- subtractBackground(bg=stillBack2)
partIden2 &lt;- identifyParticles(sbg=allImages2,
                              pixelRange=c(1,500),
                              threshold=-0.1)
records2 &lt;- trackParticles(partIden2,L=20,R=2)
## Merge tracks
records &lt;- mergeTracks(records1,records2)
plot(records,colorimages=allFullImages1,type="trajectories",incThres=10)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.TrDm'><code>plot</code> methods for class 'TrDm'.</h2><span id='topic+plot.TrDm'></span>

<h3>Description</h3>

<p><code>plot</code> methods for class 'TrDm'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TrDm'
plot(
  x,
  frame = 1,
  type = NULL,
  incThres = NULL,
  colorimages = NULL,
  cl = 1,
  path = NULL,
  name = "animation",
  libavpath = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.TrDm_+3A_x">x</code></td>
<td>
<p>An object of class 'TrDm'.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_frame">frame</code></td>
<td>
<p>Choose which frame to be plotted. By default, <code>frame=1</code>.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_type">type</code></td>
<td>
<p>Only for 'tracked' objects. By default, both trajectories and
size distribution are plotted. Choose
<code>'trajectories'</code> to plot only trajectories on the original color image.
Choose <code>'sizes'</code>
to only plot the particle size distribution. Choose <code>'animation'</code> to
create an .mp4 animation.
Here, images are temporarily saved in <code>path</code>. Set name of file with
argument <code>name</code>.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_incthres">incThres</code></td>
<td>
<p>Minimum length of tracked segments for particles to be included.
By default an automated threshold is calculated. Only for 'tracked' objects.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_colorimages">colorimages</code></td>
<td>
<p>Original color images. By default, original color images
are obtained from the global environment.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_cl">cl</code></td>
<td>
<p>When plotting a subtracted background image, choose which color layer
is plotted. By default, <code>cl=1</code>.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_path">path</code></td>
<td>
<p>When creating an animation, choose directory in which images
are saved temporarily, and where the animation should be saved.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_name">name</code></td>
<td>
<p>of animation; by default <code>'animation'</code>.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_libavpath">libavpath</code></td>
<td>
<p>Path to location where the executable file for libav
can be found (named 'avconv.exe'), in case it is not found automatically,
e.g. <code>'C:/Users/libav/usr/bin/avconv.exe'</code>. Only required when creating
an animation.</p>
</td></tr>
<tr><td><code id="plot.TrDm_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="raster.html#topic+plotRGB">plotRGB</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>

<hr>
<h2 id='print.summaryTrDm'><code>print</code> methods for class 'TrDm'.</h2><span id='topic+print.summaryTrDm'></span>

<h3>Description</h3>

<p><code>print</code> methods for class 'TrDm'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summaryTrDm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summaryTrDm_+3A_x">x</code></td>
<td>
<p>Object of class 'summaryTrDm'.</p>
</td></tr>
<tr><td><code id="print.summaryTrDm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>

<hr>
<h2 id='print.TrDm'><code>print</code> methods for class 'TrDm'.</h2><span id='topic+print.TrDm'></span>

<h3>Description</h3>

<p><code>print</code> methods for class 'TrDm'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TrDm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.TrDm_+3A_x">x</code></td>
<td>
<p>Object of class 'TrDm'.</p>
</td></tr>
<tr><td><code id="print.TrDm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>

<hr>
<h2 id='runBatch'>Batch analysis</h2><span id='topic+runBatch'></span>

<h3>Description</h3>

<p><code>runBatch</code> analyzes all image sequences in a specified
directory. Use this function when settings have been optimized
previously on a single or selection of movies/image sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runBatch(
  path,
  settings = NULL,
  dirnames = NULL,
  nImages = 1:30,
  pixelRange = NULL,
  threshold = -0.1,
  qthreshold = NULL,
  select = "dark",
  nn = NULL,
  incThres = NULL,
  plotOutput = FALSE,
  plotType = "trajectories",
  L = 20,
  R = 2,
  weight = c(1, 1, 1),
  autoThres = FALSE,
  perFrame = FALSE,
  methodBg = "mean",
  frames = NULL,
  saveAll = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runBatch_+3A_path">path</code></td>
<td>
<p>A character vector of path name that contains all directories
with image sequences.</p>
</td></tr>
<tr><td><code id="runBatch_+3A_settings">settings</code></td>
<td>
<p>Object of class 'tracked' containing all optimized settings
in attributes,
as obtained from <code><a href="#topic+trackParticles">trackParticles</a></code>.
Alternatively, settings can be specified using arguments described below.</p>
</td></tr>
<tr><td><code id="runBatch_+3A_dirnames">dirnames</code></td>
<td>
<p>If not all image sequences should be
analyzed, specify which files to use as a character string.</p>
</td></tr>
<tr><td><code id="runBatch_+3A_nimages">nImages</code></td>
<td>
<p>See <code><a href="#topic+loadImages">loadImages</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_pixelrange">pixelRange</code></td>
<td>
<p>See <code><a href="#topic+identifyParticles">identifyParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_threshold">threshold</code></td>
<td>
<p>See <code><a href="#topic+identifyParticles">identifyParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_qthreshold">qthreshold</code></td>
<td>
<p>See <code><a href="#topic+identifyParticles">identifyParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_select">select</code></td>
<td>
<p>See <code><a href="#topic+identifyParticles">identifyParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_nn">nn</code></td>
<td>
<p>Name of artificial neural net if apply it to images. Default
is <code>NULL</code>, resulting in no neural net being applied.</p>
</td></tr>
<tr><td><code id="runBatch_+3A_incthres">incThres</code></td>
<td>
<p>Minimum number of frames that a particle must be
present. By default, automated estimate is used.</p>
</td></tr>
<tr><td><code id="runBatch_+3A_plotoutput">plotOutput</code></td>
<td>
<p>Default is <code>FALSE</code>. Set <code>TRUE</code> to plot results.</p>
</td></tr>
<tr><td><code id="runBatch_+3A_plottype">plotType</code></td>
<td>
<p>Default is 'trajectories'. Other options are 'sizes' and
'animation'.</p>
</td></tr>
<tr><td><code id="runBatch_+3A_l">L</code></td>
<td>
<p>See <code><a href="#topic+trackParticles">trackParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_r">R</code></td>
<td>
<p>See <code><a href="#topic+trackParticles">trackParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_weight">weight</code></td>
<td>
<p>See <code><a href="#topic+trackParticles">trackParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_autothres">autoThres</code></td>
<td>
<p>See <code><a href="#topic+identifyParticles">identifyParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_perframe">perFrame</code></td>
<td>
<p>See <code><a href="#topic+identifyParticles">identifyParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_methodbg">methodBg</code></td>
<td>
<p>See <code><a href="#topic+createBackground">createBackground</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_frames">frames</code></td>
<td>
<p>See <code><a href="#topic+identifyParticles">identifyParticles</a></code></p>
</td></tr>
<tr><td><code id="runBatch_+3A_saveall">saveAll</code></td>
<td>
<p>Logical. Set <code>TRUE</code> to save for each image sequence the
full object obtained from <code><a href="#topic+loadImages">loadImages</a></code>. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dataframe with estimated population size for each image sequence.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>See Also</h3>

<p><code><a href="#topic+loadImages">loadImages</a></code>, <code><a href="#topic+createBackground">createBackground</a></code>,
<code><a href="#topic+subtractBackground">subtractBackground</a></code>, <code><a href="#topic+identifyParticles">identifyParticles</a></code>,
<code><a href="#topic+trackParticles">trackParticles</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Simulate 3 image sequences
wd &lt;- getwd()
folders &lt;- paste0(rep("images",3),1:3)
populations &lt;- c(15,25,50)
dir.create("./batchTest")
setwd("./batchTest")
for(i in 1:length(folders)){
  dir.create(folders[i])
  traj &lt;- simulTrajec(path=folders[i],
                      nframes=30,nIndividuals=populations[i],
                      h=0.01,rho=0.9,
                      sizes=runif(populations[i],0.004,0.006))
}
setwd(wd)
batchpath &lt;- "./batchTest"
results &lt;- runBatch(path=batchpath,
                    nImages=1:30,threshold=-0.1,select='dark',
                    pixelRange=c(1,100),L=50,R=3,
                    incThres=10)
results

## End(Not run)
</code></pre>

<hr>
<h2 id='simulTrajec'>Simulate trajectories and save as png files.</h2><span id='topic+simulTrajec'></span>

<h3>Description</h3>

<p><code>simulTrajec</code> simulates movement trajectories within a
bounded space, movements are set with speed (<code>h</code>) and may be correlated
in direction (<code>rho</code>). Function simulates movement of particles in a video
sequence of certain number of frames (<code>nframes</code>) in length. Images
are saved as png files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulTrajec(
  nframes = 20,
  nIndividuals = 10,
  h = 0.02,
  rho = 0,
  domain = "square",
  correctBoundary = TRUE,
  sizes = stats::runif(nIndividuals) * 0.012 + 0.01,
  staticNoise = FALSE,
  movingNoise = FALSE,
  name = "trajectory",
  path = NULL,
  parsMoving = list(density = 10, duration = 10, size = 1, speed = 10, colRange = c(0,
    1)),
  parsStatic = list(density = 10, blur = TRUE, blurCoef = 0.025, sizes = NULL, col =
    "red"),
  width = 480,
  height = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulTrajec_+3A_nframes">nframes</code></td>
<td>
<p>Number of time frames(steps).</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_nindividuals">nIndividuals</code></td>
<td>
<p>Number of individual trajectories.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_h">h</code></td>
<td>
<p>Displacement speed in pixels.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_rho">rho</code></td>
<td>
<p>Correlation parameter for angle of displacement.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_domain">domain</code></td>
<td>
<p>One of <code>"square"</code> or <code>"circle"</code>, imposing a [0-1,0-1]
rectangle domain, or a circular domain of radius 1, respectively.
correct boundary ensure individual trajectories do not cross the domain</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_correctboundary">correctBoundary</code></td>
<td>
<p>Logical. <code>TRUE</code> to make sure that individuals
cannot leave the image.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_sizes">sizes</code></td>
<td>
<p>Vector of sizes for each simulated particle of length
nIndividuals.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_staticnoise">staticNoise</code></td>
<td>
<p>Logical. If <code>TRUE</code>, static noise is added.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_movingnoise">movingNoise</code></td>
<td>
<p>Logical. If <code>TRUE</code>, moving noise is added.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_name">name</code></td>
<td>
<p>Stem of the filename.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_path">path</code></td>
<td>
<p>to location where the created images should be saved. By default
the working directory is used.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_parsmoving">parsMoving</code></td>
<td>
<p>List of parameters used to generate moving noise
these include the density of noise particles (<code>density</code>), their duration
(in n frames; <code>duration</code>), their size (<code>size=1</code>),
their speed (<code>speed=10</code>) and the range or colors they are randomly
drawn from (<code>colRange=c(0,1)</code>).</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_parsstatic">parsStatic</code></td>
<td>
<p>List of parameters used to generate static noise.
These include the density (per image) of noise particles (<code>density</code>),
whether spots
look blurry (<code>blur=TRUE</code> or <code>blur=FALSE</code>), a blurring coefficient
(<code>blurCoef=0.025</code>), and the size of the spots (with <code>sizes</code>).</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_width">width</code></td>
<td>
<p>of created png image. By default 480.</p>
</td></tr>
<tr><td><code id="simulTrajec_+3A_height">height</code></td>
<td>
<p>of create png image. If <code>NULL</code>, <code>width</code> is used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Caspar A. Hallmann, Marjolein Bruijning &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence and save as png's in the working directory.
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,
                    sizes=runif(20,0.004,0.006))

## End(Not run)
</code></pre>

<hr>
<h2 id='subtractBackground'>Background subtraction</h2><span id='topic+subtractBackground'></span>

<h3>Description</h3>

<p><code>subtractBackground</code> subtracts each image from a
previously created still background.
The objects created through the function contain all changing
pixels (i.e. movement).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subtractBackground(bg, colorimages = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subtractBackground_+3A_bg">bg</code></td>
<td>
<p>Array containing still background, as returned from
<code><a href="#topic+createBackground">createBackground</a></code>.</p>
</td></tr>
<tr><td><code id="subtractBackground_+3A_colorimages">colorimages</code></td>
<td>
<p>Array containing all frames, obtained by
<code><a href="#topic+loadImages">loadImages</a></code>. Default is <code>NULL</code>, in this case the original
images are used from the global environment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns array of class 'TrDm' and 'sbg' with same size as images,
subtracted from background.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
allImages &lt;- subtractBackground(stillBack)
plot(allImages)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.TrDm'><code>summary</code> methods for class 'TrDm'.</h2><span id='topic+summary.TrDm'></span>

<h3>Description</h3>

<p><code>summary</code> methods for class 'TrDm'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TrDm'
summary(object, incThres = NULL, funSize = stats::median, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.TrDm_+3A_object">object</code></td>
<td>
<p>an object of class 'TrDm'.</p>
</td></tr>
<tr><td><code id="summary.TrDm_+3A_incthres">incThres</code></td>
<td>
<p>Minimum length of tracked segments for particles to be
included. By default an automated threshold is calculated. Only for
'tracked' objects.</p>
</td></tr>
<tr><td><code id="summary.TrDm_+3A_funsize">funSize</code></td>
<td>
<p>Statistic to be calculated to obtain particle sizes. By
default <code>median</code> is used.</p>
</td></tr>
<tr><td><code id="summary.TrDm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>

<hr>
<h2 id='testNN'>Train, validate and test artificial
neural networks</h2><span id='topic+testNN'></span>

<h3>Description</h3>

<p>Fits multiple neural networks to
a dataset; data set has been randomly assigned to each
of three categories: train, validate and test.
A final neural net is selected based on a fit statistic
(either precision, recall or the F1-score). All neural networks
are trained to the training dataset. Neural network may vary in
the number of hidden layers. Classification thresholds are selected
based on the validation data, and then the final neural network
is selected based on the test data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testNN(
  dat,
  stat = "F",
  maxH = 5,
  repetitions = 3,
  prop = c(8, 1, 1),
  predictors = NULL,
  pca = TRUE,
  thr = 0.95,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="testNN_+3A_dat">dat</code></td>
<td>
<p>a previously constructed dataset obtained from
<code>manuallySelect</code>.</p>
</td></tr>
<tr><td><code id="testNN_+3A_stat">stat</code></td>
<td>
<p>Fit statistic. May be <code>"precision"</code>, <code>"recall"</code>, or
<code>"F"</code> for the harmonic mean of precision and recall.</p>
</td></tr>
<tr><td><code id="testNN_+3A_maxh">maxH</code></td>
<td>
<p>maximum number of hidden layers to test
note that more layers will require more time to fit.</p>
</td></tr>
<tr><td><code id="testNN_+3A_repetitions">repetitions</code></td>
<td>
<p>the number of repetitions
for the neural network's training.</p>
</td></tr>
<tr><td><code id="testNN_+3A_prop">prop</code></td>
<td>
<p>the proportion or ratio for each class
c(training, validation,test).</p>
</td></tr>
<tr><td><code id="testNN_+3A_predictors">predictors</code></td>
<td>
<p>Optional. A set of custom predictors
for the neural network. Default uses all columns in <code>dat</code>.</p>
</td></tr>
<tr><td><code id="testNN_+3A_pca">pca</code></td>
<td>
<p>Logical. <code>TRUE</code> by default. Should the
set of predictors be compressed to the most informative? In short,
should a principal component analysis be conducted to select axis that
explain at least a fraction <code>thr</code> (see below)
of the variance in the full set of predictors?</p>
</td></tr>
<tr><td><code id="testNN_+3A_thr">thr</code></td>
<td>
<p>Threshold for pca (above).</p>
</td></tr>
<tr><td><code id="testNN_+3A_...">...</code></td>
<td>
<p>additional parameters, passed to neuralnet.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The neural networks may be selected based on precision, recall or
a F1-score (default).
In binary classification, precision is the number of correct positive
results divided by the number of all positive predictions. Recall is
the number of correct positive results divided by the number of positive
results that could have been returned if the algorithm was perfect.
A F1 score (F-score/ F-measure) is a statistical
measure of accuracy. F1 scores considers both the precision
and the recall. A F1 score may be seen as a weighted average
(harmonic mean) of the precision and recall.
Precision, recall and F1 scores are at best 1 and at worst 0.
</p>


<h3>Value</h3>

<p>Returns trained artificial neural net.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain='square',
                    h=0.01,rho=0.9,movingNoise=TRUE,
                    parsMoving = list(density=20, duration=10, size=1,
                                      speed = 10, colRange = c(0,1)),
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
allImages &lt;- subtractBackground(stillBack)
partIden &lt;- identifyParticles(allImages,threshold=-0.1,
                                   pixelRange=c(3,400))
nframes &lt;- 3
frames &lt;- order(tapply(partIden$patchID,partIden$frame,length),
                decreasing=TRUE)[1:nframes]
mId &lt;- manuallySelect(particles=partIden,frame=frames)
finalNN &lt;- testNN(dat=mId,repetitions=10,maxH=4,prop=c(6,2,2))
summary(finalNN)

## End(Not run)
</code></pre>

<hr>
<h2 id='trackParticles'>Track particles</h2><span id='topic+trackParticles'></span>

<h3>Description</h3>

<p><code>trackParticles</code> reconstructs trajectories by linking particles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trackParticles(
  particles,
  L = 50,
  R = 2,
  weight = c(1, 1, 1),
  costconstant = FALSE,
  logsizes = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trackParticles_+3A_particles">particles</code></td>
<td>
<p>Object of class 'particles',
obtained using <code><a href="#topic+identifyParticles">identifyParticles</a></code>.</p>
</td></tr>
<tr><td><code id="trackParticles_+3A_l">L</code></td>
<td>
<p>Numeric. Maximum cost for linking a particle to another particle.
When the cost is larger,
particles will be not be linked (resulting in the begin or end of a segment).
Default set at <code>50</code>.</p>
</td></tr>
<tr><td><code id="trackParticles_+3A_r">R</code></td>
<td>
<p>Integer. Link to how many subsequent frames? Default set
at <code>2</code>.</p>
</td></tr>
<tr><td><code id="trackParticles_+3A_weight">weight</code></td>
<td>
<p>Vector containing 3 weights to calculate costs. Depending
on the study system, users may want to value certain elements over others.
For instance, when individuals can vary in size over frames
(which happens when objects move away or towards a camera)
the &quot;size&quot; weight may be decreased. Weights are ordered as follows;
first number gives the weight for differences in x and y coordinates;
second number
gives the weight for particle size differences; third number gives the
difference between the predicted location and the observed location. The
latter is calculated using the location of the identified particle in the
previous frame.</p>
</td></tr>
<tr><td><code id="trackParticles_+3A_costconstant">costconstant</code></td>
<td>
<p>Logical. Default is <code>FALSE</code>. This increases the maximum
cost L proportional to the number of images in between two frames (when R &gt; 1).
Set to <code>TRUE</code> keeps maximum cost L constant for all 1:R frames.</p>
</td></tr>
<tr><td><code id="trackParticles_+3A_logsizes">logsizes</code></td>
<td>
<p>Logical. Default is <code>FALSE</code>. Set to <code>TRUE</code> to take the
natural logarithm of body sizes, when calculating the cost of linking two particles.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class 'TrDm' and 'records'. Use 'summary' and 'plot'.
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain="square",
                    h=0.01,rho=0.9,
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
allImages &lt;- subtractBackground(stillBack)
partIden &lt;- identifyParticles(allImages,threshold=-0.1,
                                   pixelRange=c(3,400))
records &lt;- trackParticles(particles,L=40,R=2)
summary(records)
plot(records,type="trajectories")

## End(Not run)
</code></pre>

<hr>
<h2 id='update.particles'>Update identified particles.</h2><span id='topic+update.particles'></span>

<h3>Description</h3>

<p>Apply trained artificial neural network to particleStat object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'particles'
update(object, neuralnet, pca = TRUE, colorimages = NULL, sbg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update.particles_+3A_object">object</code></td>
<td>
<p>Object of class 'nnTrackdemObject'.</p>
</td></tr>
<tr><td><code id="update.particles_+3A_neuralnet">neuralnet</code></td>
<td>
<p>Trained neural net obtained from <code><a href="#topic+testNN">testNN</a></code></p>
</td></tr>
<tr><td><code id="update.particles_+3A_pca">pca</code></td>
<td>
<p>Logical. By default <code>TRUE</code>, indicating that a principal
component analysis is performed on the predictors.</p>
</td></tr>
<tr><td><code id="update.particles_+3A_colorimages">colorimages</code></td>
<td>
<p>An array with the original full color images, in order
to plot on the original images, obtained by <code><a href="#topic+loadImages">loadImages</a></code>.
By default the original color images are used.</p>
</td></tr>
<tr><td><code id="update.particles_+3A_sbg">sbg</code></td>
<td>
<p>Images subtracted from background, as obtained by
<code><a href="#topic+subtractBackground">subtractBackground</a></code>. By default, the original subtracted images
are used.</p>
</td></tr>
<tr><td><code id="update.particles_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame class 'particles', containing updated
particle statistics (excluding
particles that have been filtered out by the neural net).
</p>


<h3>Author(s)</h3>

<p>Marjolein Bruijning, Caspar A. Hallmann &amp; Marco D. Visser
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dir.create("images")
## Create image sequence
traj &lt;- simulTrajec(path="images",
                    nframes=30,nIndividuals=20,domain='square',
                    h=0.01,rho=0.9,movingNoise=TRUE,
                    parsMoving = list(density=20, duration=10, size=1,
                                      speed = 10, colRange = c(0,1)),
                    sizes=runif(20,0.004,0.006))
## Load images
dir &lt;- "images"
allFullImages &lt;- loadImages (dirPictures=dir,nImages=1:30)
stillBack &lt;- createBackground(allFullImages,method="mean")
allImages &lt;- subtractBackground(stillBack)
partIden &lt;- identifyParticles(allImages,threshold=-0.1,
                                   pixelRange=c(3,400))
nframes &lt;- 3
frames &lt;- order(tapply(partIden$patchID,partIden$frame,length),
                decreasing=TRUE)[1:nframes]
mId &lt;- manuallySelect(particles=partIden,frame=frames)
finalNN &lt;- testNN(dat=mId,repetitions=10,maxH=4,prop=c(6,2,2))
partIdenNN &lt;- update(particles=partIden,neuralnet=finalNN)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
