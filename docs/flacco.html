<!DOCTYPE html><html><head><title>Help for package flacco</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {flacco}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BBOBImport'><p>Shiny server function for BBOB import page module</p></a></li>
<li><a href='#BBOBImportPage'><p>Shiny UI-Module for Batch Import of BBOB Functions</p></a></li>
<li><a href='#calculateFeatureSet'><p>Calculate Landscape Features</p></a></li>
<li><a href='#computeGridCenters'><p>Compute the Cell Centers of a Cell Mapping Grid</p></a></li>
<li><a href='#convertInitDesignToGrid'><p>Converts an Initial Design into a Cell Mapping Grid</p></a></li>
<li><a href='#createInitialSample'><p>Create Initial Sample</p></a></li>
<li><a href='#featureList'><p>Feature List</p></a></li>
<li><a href='#FeatureObject'><p>Create a Feature Object</p></a></li>
<li><a href='#featureObject_sidebar'><p>Shiny UI-Module for Function Input</p></a></li>
<li><a href='#FeatureSetCalculation'><p>Shiny Server Function for Feature Set Component</p></a></li>
<li><a href='#FeatureSetCalculationComponent'><p>Shiny UI-Module for Calculating and Displaying Feature Sets</p></a></li>
<li><a href='#FeatureSetVisualization'><p>Shiny Server Function for Feature Set Component</p></a></li>
<li><a href='#FeatureSetVisualizationComponent'><p>Shiny Component for Visualizing the Feature Sets</p></a></li>
<li><a href='#findLinearNeighbours'><p>Find Neighbouring Cells</p></a></li>
<li><a href='#findNearestPrototype'><p>Find Nearest Prototype</p></a></li>
<li><a href='#functionInput'><p>Shiny Server Function for Feature Calculation of Function Input</p></a></li>
<li><a href='#ggplotFeatureImportance'><p>Feature Importance Plot</p></a></li>
<li><a href='#listAvailableFeatureSets'><p>List Available Feature Sets</p></a></li>
<li><a href='#measureTime'><p>Measure Runtime of a Feature Computation</p></a></li>
<li><a href='#plotBarrierTree2D'><p>Plot Barrier Tree in 2D</p></a></li>
<li><a href='#plotBarrierTree3D'><p>Plot Barrier Tree in 3D</p></a></li>
<li><a href='#plotCellMapping'><p>Plot Cell Mapping</p></a></li>
<li><a href='#plotInformationContent'><p>Plot Information Content</p></a></li>
<li><a href='#runFlaccoGUI'><p>Run the flacco-GUI based on Shiny</p></a></li>
<li><a href='#SmoofImport'><p>Shiny Server Function for BBOB Import Page Module</p></a></li>
<li><a href='#SmoofImportPage'><p>Shiny UI-Module for Batch Import of Smoof Functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Feature-Based Landscape Analysis of Continuous and Constrained
Optimization Problems</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools and features for "Exploratory Landscape Analysis (ELA)" of
	single-objective continuous optimization problems.
    Those features are able to quantify rather complex properties, such as the
    global structure, separability, etc., of the optimization problems.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kerschke/flacco">https://github.com/kerschke/flacco</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kerschke/flacco/issues">https://github.com/kerschke/flacco/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-2-Clause">BSD_2_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>BBmisc, checkmate, mlr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>devtools, e1071, ggplot2, lhs, MASS, Matrix, mda, mlbench,
numDeriv, parallel, parallelMap, ParamHelpers, plotly, plyr,
RANN, R.rsp, rpart, shape, shiny, smoof, testthat</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.8</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-03-31</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-03-31 18:16:56 UTC; kerschke</td>
</tr>
<tr>
<td>Author:</td>
<td>Pascal Kerschke [aut, cre],
  Christian Hanster [ctb],
  Jan Dagefoerde [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pascal Kerschke &lt;kerschke@uni-muenster.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-03-31 20:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BBOBImport'>Shiny server function for BBOB import page module</h2><span id='topic+BBOBImport'></span>

<h3>Description</h3>

<p><code>BBOBImport</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> server function which will
control all aspects of the <code><a href="#topic+BBOBImportPage">BBOBImportPage</a></code> UI Module. It
will be called with <code><a href="shiny.html#topic+callModule">callModule</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BBOBImport(input, output, session, stringsAsFactors)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BBOBImport_+3A_input">input</code></td>
<td>
<p>[<code>shiny-input</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> input variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="BBOBImport_+3A_output">output</code></td>
<td>
<p>[<code>shiny-output object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> output variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="BBOBImport_+3A_session">session</code></td>
<td>
<p>[<code>shiny-session object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> session variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="BBOBImport_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
How should strings be treated internally?</p>
</td></tr>
</table>

<hr>
<h2 id='BBOBImportPage'>Shiny UI-Module for Batch Import of BBOB Functions</h2><span id='topic+BBOBImportPage'></span>

<h3>Description</h3>

<p><code>BBOBImportPage</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> component which can be added to
your <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> app so that you get a batch import for several BBOB
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BBOBImportPage(id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BBOBImportPage_+3A_id">id</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a>(1)</code>]<br />
Character representing the <code>namespace</code> of the <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> component.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It will load a CSV-file with BBOB parameters (the function ID, instance ID and
problem dimension) and then calculate the selected features for the specific
function(s).
</p>

<hr>
<h2 id='calculateFeatureSet'>Calculate Landscape Features</h2><span id='topic+calculateFeatureSet'></span><span id='topic+calculateFeatures'></span>

<h3>Description</h3>

<p>Performs an Exploratory Landscape Analysis of a continuous function and
computes various features, which quantify the function's landscape.
Currently, the following feature sets are provided:
</p>

<ul>
<li><p>CM: cell mapping features (<code>"cm_angle"</code>, <code>"cm_conv"</code>,
<code>"cm_grad"</code>)
</p>
</li>
<li><p>ELA: classical ELA features (<code>"ela_conv"</code>,
<code>"ela_curv"</code>, <code>"ela_distr"</code>, <code>"ela_level"</code>,
<code>"ela_local"</code>, <code>"ela_meta"</code>)
</p>
</li>
<li><p>GCM: general cell mapping features (<code>"gcm"</code>)
</p>
</li>
<li><p>BT: barrier tree features (<code>"bt"</code>)
</p>
</li>
<li><p>IC: information content features (<code>"ic"</code>)
</p>
</li>
<li><p>Basic: basic features (<code>"basic"</code>)
</p>
</li>
<li><p>Disp: dispersion features (<code>"disp"</code>)
</p>
</li>
<li><p>LiMo: linear model features (<code>"limo"</code>)
</p>
</li>
<li><p>NBC: nearest better clustering features (<code>"nbc"</code>)
</p>
</li>
<li><p>PC: principal component features (<code>"pca"</code>)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>calculateFeatureSet(feat.object, set, control, ...)

calculateFeatures(feat.object, control, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculateFeatureSet_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
<tr><td><code id="calculateFeatureSet_+3A_set">set</code></td>
<td>
<p>[<code>character(1)</code>]<br />
Name of the feature set, which should be computed. All possible feature
sets can be listed using <code><a href="#topic+listAvailableFeatureSets">listAvailableFeatureSets</a></code>.</p>
</td></tr>
<tr><td><code id="calculateFeatureSet_+3A_control">control</code></td>
<td>
<p>[<code>list</code>]<br />
A <code>list</code>, which stores additional control arguments.
For further information, see details.</p>
</td></tr>
<tr><td><code id="calculateFeatureSet_+3A_...">...</code></td>
<td>
<p>[any]<br />
Further arguments, e.g. handled by <code><a href="stats.html#topic+optim">optim</a></code> (within the
computation of the ELA local search features) or <code><a href="stats.html#topic+density">density</a></code>
(within the computation of the ELA y-distribution features).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if you want to speed up the runtime of the features, you might
consider running your feature computation parallelized. For more
information, please refer to the <code>parallelMap</code> package or to
<a href="https://mlr.mlr-org.com/articles/tutorial/parallelization.html">https://mlr.mlr-org.com/articles/tutorial/parallelization.html</a>.
</p>
<p>Furthermore, please consider adapting the feature computation to your
needs. Possible <code>control</code> arguments are:
</p>

<ul>
<li><p>general: </p>

<ul>
<li><p><code>show_progress</code>: Show progress bar when computing the
features? The default is <code>TRUE</code>.
</p>
</li>
<li><p><code>subset</code>: Specify a subset of features that should be
computed. Per default, all features will be computed.
</p>
</li>
<li><p><code>allow_cellmapping</code>: Should cell mapping features be
computed? The default is <code>TRUE</code>.
</p>
</li>
<li><p><code>allow_costs</code>: Should expensive features, i.e. features,
which require additional function evaluations, be computed? The
default is <code>TRUE</code> if the feature object provides a function,
otherwise <code>FALSE</code>.
</p>
</li>
<li><p><code>blacklist</code>: Which features should NOT be computed? The
default is <code>NULL</code>, i.e. none of the features will be excluded.
</p>
</li></ul>

</li>
<li><p>cell mapping angle features: </p>

<ul>
<li><p><code>cm_angle.show_warnings</code>: Should possible warnings about
<code>NAs</code> in the feature computation be shown? The default is
<code>FALSE</code>.
</p>
</li></ul>

</li>
<li><p>cell mapping convexity features: </p>

<ul>
<li><p><code>cm_conv.diag</code>: Should cells, which are located on the
diagonal compared to the current cell, be considered as neighbouring
cells? The default is <code>FALSE</code>, i.e. only cells along the axes
are considered as neighbours.
</p>
</li>
<li><p><code>cm_conv.dist_method</code>: Which distance method should be
used for computing the distance between two observations? All methods
of <code><a href="stats.html#topic+dist">dist</a></code> are possible options with <code>"euclidean"</code>
being the default.
</p>
</li>
<li><p><code>cm_conv.minkowski_p</code>: Value of <code>p</code> in case
<code>dist_meth</code> is <code>"minkowski"</code>. The default is <code>2</code>, i.e.
the euclidean distance.
</p>
</li>
<li><p><code>cm_conv.fast_k</code>: Percentage of elements that should be
considered within the nearest neighbour computation. The default is
<code>0.05</code>.
</p>
</li></ul>

</li>
<li><p>cell mapping gradient homogeneity features: </p>

<ul>
<li><p><code>cm_grad.dist_tie_breaker</code>: How will ties be broken when
different observations have the same distance to an observation?
Possible values are <code>"sample"</code>, <code>"first"</code> and <code>"last"</code>.
The default is <code>"sample"</code>.
</p>
</li>
<li><p><code>cm_grad.dist_method</code>: Which distance method should be
used for computing the distance between two observations? All methods
of <code><a href="stats.html#topic+dist">dist</a></code> are possible options with <code>"euclidean"</code>
being the default.
</p>
</li>
<li><p><code>cm_grad.minkowski_p</code>: Value of <code>p</code> in case
<code>dist_meth</code> is <code>"minkowski"</code>. The default is <code>2</code>, i.e.
the euclidean distance.
</p>
</li>
<li><p><code>cm_grad.show_warnings</code>: Should possible warnings about
(almost) empty cells be shown? The default is <code>FALSE</code>.
</p>
</li></ul>

</li>
<li><p>ELA convexity features: </p>

<ul>
<li><p><code>ela_conv.nsample</code>: Number of samples that are drawn for
calculating the convexity features. The default is <code>1000</code>.
</p>
</li>
<li><p><code>ela_conv.threshold</code>: Threshold of the linearity, i.e. the
tolerance to / deviation from perfect linearity, in order to still be
considered linear. The default is <code>1e-10</code>.
</p>
</li></ul>

</li>
<li><p>ELA curvature features: </p>

<ul>
<li><p><code>ela_curv.sample_size</code>: Number of samples used for
calculating the curvature features. The default is <code>100*d</code>.
</p>
</li>
<li><p><code>ela_curv.{delta, eps, zero_tol, r, v}</code>: Parameters used
by <code><a href="numDeriv.html#topic+grad">grad</a></code> and <code><a href="numDeriv.html#topic+hessian">hessian</a></code> within the
approximation of the gradient and hessian. The default values are
identical to the ones from the corresponding functions. Note that we
slightly modified <code><a href="numDeriv.html#topic+hessian">hessian</a></code> in order to assure
that we do not exceed the boundaries during the estimation of the
Hessian.
</p>
</li></ul>

</li>
<li><p>ELA distribution features: </p>

<ul>
<li><p><code>ela_distr.smoothing_bandwidth</code>: The smoothing bandwidth,
which should be used within the <code><a href="stats.html#topic+density">density</a></code> estimation.
The default is <code>"SJ"</code>.
</p>
</li>
<li><p><code>ela_distr.modemass_threshold</code>: Threshold that is used in
order to classify whether a minimum can be considered as a peak.
The default is <code>0.01</code>.
</p>
</li>
<li><p><code>ela_distr.skewness_type</code>: Algorithm type for computing
the <code><a href="e1071.html#topic+skewness">skewness</a></code>. The default is <code>3</code>.
</p>
</li>
<li><p><code>ela_distr.kurtosis_type</code>: Algorithm type for computing
the <code><a href="e1071.html#topic+kurtosis">kurtosis</a></code>. The default is <code>3</code>.
</p>
</li></ul>

</li>
<li><p>ELA levelset features: </p>

<ul>
<li><p><code>ela_level.quantiles</code>: Cutpoints (quantiles of the
objective values) for splitting the objective space. The default is
<code>c(0.10, 0.25, 0.50)</code>.
</p>
</li>
<li><p><code>ela_level.classif_methods</code>: Methods for classifying
the artificially splitted objective space. The default is
<code>c("lda", "qda", "mda")</code>.
</p>
</li>
<li><p><code>ela_level.resample_method</code>: Resample technique for
training the model, cf. <code><a href="mlr.html#topic+ResampleDesc">ResampleDesc</a></code>. The default
is <code>"CV"</code>.
</p>
</li>
<li><p><code>ela_level.resample_iterations</code>: Number of iterations
of the resampling method. The default is <code>10</code>.
</p>
</li>
<li><p><code>ela_level.resample_info</code>: Should information regarding
the resampling be printed? The default is <code>FALSE</code>.
</p>
</li>
<li><p><code>ela_level.parallelize</code>: Should the levelset features be
computed in parallel? The default is <code>FALSE</code>.
</p>
</li>
<li><p><code>ela_level.parallel.mode</code>: Which mode should be used for
the parallelized computation? Possible options are <code>"local"</code>,
<code>"multicore"</code>, <code>"socket"</code> (default), <code>"mpi"</code> and
<code>"BatchJobs"</code>. Note that in case you are using a windows computer
you can only use the <code>"socket"</code> mode.
</p>
</li>
<li><p><code>ela_level.parallel.cpus</code>: On how many cpus do you want to
compute the features in parallel? Per default, all available cpus are
used.
</p>
</li>
<li><p><code>ela_level.parallel.level</code>: On which level should the
parallel computation be performed? The default is
<code>"mlr.resample"</code>, i.e. the internal resampling (performed using
<code>mlr</code>) will be done in parallel.
</p>
</li>
<li><p><code>ela_level.parallel.logging</code>: Should slave output be
logged? The default is <code>FALSE</code>.
</p>
</li>
<li><p><code>ela_level.parallel.show_info</code>: Should verbose output of
function calls be printed on the console? The default is <code>FALSE</code>.
</p>
</li></ul>

</li>
<li><p>ELA local search features: </p>

<ul>
<li><p><code>ela_local.local_searches</code>: Number of local searches. The
default is <code>50 * d</code> with <code>d</code> being the number of features
(i.e. the dimension).
</p>
</li>
<li><p><code>ela_local.optim_method</code>: Local search algorithm. The
default is <code>"L-BFGS-B"</code>.
</p>
</li>
<li><p><code>ela_local.optim.{lower, upper}</code>: Lower and upper bounds
to be considered by the local search algorithm. Per default, the
boundaries are the same as defined within the feature object
(in case of <code>"L-BFGS-B"</code>) or infinity (for all others).
</p>
</li>
<li><p><code>ela_local.optim_method_control</code>: Control settings of the
local search algorithm. The default is an empty list.
</p>
</li>
<li><p><code>ela_local.sample_seed</code>: Seed, which will be set before
the selection of the initial start points of the local search. The
default is <code>sample(1:1e6, 1)</code>.
</p>
</li>
<li><p><code>ela_local.clust_method</code>: Once the local searches
converge, basins have to be assigned. This is done using hierarchical
clustering methods from <code><a href="stats.html#topic+hclust">hclust</a></code>. The default is
<code>"single"</code>, i.e. <em>single linkage clustering</em>.
</p>
</li>
<li><p><code>ela_local.clust_cut_function</code>: A function of a
hierarchical clustering <code>cl</code>, which defines at which height the
dendrogramm should be splitted into clusters
(cf. <code><a href="stats.html#topic+cutree">cutree</a></code>). The default is
<code>function(cl) as.numeric(quantile(cl$height, 0.1))</code>, i.e. the
<code>10%</code>-quantile of all the distances between clusters.
</p>
</li></ul>

</li>
<li><p>GCM features: </p>

<ul>
<li><p><code>gcm.approaches</code>: Which approach(es) should be used when
computing the representatives of a cell. The default are all three
approaches, i.e. <code>c("min", "mean", "near")</code>.
</p>
</li>
<li><p><code>gcm.cf_power</code>: Theoretically, we need to compute the
canonical form to the power of infinity. However, we use this value
as approximation of infinity. The default is <code>256</code>.
</p>
</li></ul>

</li>
<li><p>barrier tree features: </p>

<ul>
<li><p><code>gcm.approaches</code>: Which approach(es) should be used when
computing the representatives of a cell. The default are all three
approaches, i.e. <code>c("min", "mean", "near")</code>.
</p>
</li>
<li><p><code>gcm.cf_power</code>: Theoretically, we need to compute the
canonical form to the power of infinity. However, we use this value
as approximation of infinity. The default is <code>256</code>.
</p>
</li>
<li><p><code>bt.base</code>: Maximum number of basins, which are joined at a
single breakpoint. The default is <code>4L</code>.
</p>
</li>
<li><p><code>bt.max_depth</code>: Maximum number of levels of the barrier
tree. The default is <code>16L</code>.
</p>
</li></ul>

</li>
<li><p>information content features: </p>

<ul>
<li><p><code>ic.epsilon</code>: Epsilon values as described in section V.A
of Munoz et al. (2015). The default is
<code>c(0, 10^(seq(-5, 15, length.out = 1000))</code>.
</p>
</li>
<li><p><code>ic.sorting</code>: Sorting strategy, which is used to define
the tour through the landscape. Possible values are <code>"nn"</code>
(= default) and <code>"random"</code>.
</p>
</li>
<li><p><code>ic.sample.generate</code>: Should the initial design be created
using a LHS? The default is <code>FALSE</code>, i.e. the initial design from
the feature object will be used.
</p>
</li>
<li><p><code>ic.sample.dimensions</code>: Dimensions of the initial design,
if created using a LHS. The default is <code>feat.object$dimension</code>.
</p>
</li>
<li><p><code>ic.sample.size</code>: Size of the initial design, if created
using a LHS. The default is <code>100 * feat.object$dimension</code>.
</p>
</li>
<li><p><code>ic.sample.lower</code>: Lower bounds of the initial design, if
created with a LHS. The default is <code>100 * feat.object$lower</code>.
</p>
</li>
<li><p><code>ic.sample.upper</code>: Upper bounds of the initial design, if
created with a LHS. The default is <code>100 * feat.object$upper</code>.
</p>
</li>
<li><p><code>ic.aggregate_duplicated</code>: How should observations, which
have duplicates in the decision space, be aggregated? The default is
<code>mean</code>.
</p>
</li>
<li><p><code>ic.show_warnings</code>: Should warnings be shown, when
possible duplicates are removed? The default is <code>FALSE</code>.
</p>
</li>
<li><p><code>ic.seed</code>: Possible seed, which can be used for making
your experiments reproducable. Per default, a random number will be
drawn as seed.
</p>
</li>
<li><p><code>ic.nn.start</code>: Which observation should be used as
starting value, when exploring the landscape with the nearest
neighbour approach. The default is a randomly chosen integer value.
</p>
</li>
<li><p><code>ic.nn.neighborhood</code>: In order to provide a fast
computation of the features, we use <code>RANN::nn2</code> for computing
the nearest neighbors of an observation. Per default, we consider
the <code>20L</code> closest neighbors for finding the nearest
not-yet-visited observation. If all of those neighbors have been
visited already, we compute the distances to the remaining points
separately.
</p>
</li>
<li><p><code>ic.settling_sensitivity</code>: Threshold, which should be
used for computing the &ldquo;settling sensitivity&rdquo;. The default
is <code>0.05</code> (as used in the corresponding paper).
</p>
</li>
<li><p><code>ic.info_sensitivity</code>: Portion of partial information
sensitivity. The default is <code>0.5</code> (as used in the paper).
</p>
</li></ul>

</li>
<li><p>dispersion features: </p>

<ul>
<li><p><code>disp.quantiles</code>: Quantiles, which should be used for
defining the &quot;best&quot; elements of the entire initial design. The default
is <code>c(0.02, 0.05, 0.1, 0.25)</code>.
</p>
</li>
<li><p><code>disp.dist_method</code>: Which distance method should be
used for computing the distance between two observations? All methods
of <code><a href="stats.html#topic+dist">dist</a></code> are possible options with <code>"euclidean"</code>
being the default.
</p>
</li>
<li><p><code>disp.minkowski_p</code>: Value of <code>p</code> in case
<code>dist_meth</code> is <code>"minkowski"</code>. The default is <code>2</code>, i.e.
the euclidean distance.
</p>
</li></ul>

</li>
<li><p>nearest better clustering features: </p>

<ul>
<li><p><code>nbc.dist_method</code>: Which distance method should be
used for computing the distance between two observations? All methods
of <code><a href="stats.html#topic+dist">dist</a></code> are possible options with <code>"euclidean"</code>
being the default.
</p>
</li>
<li><p><code>nbc.minkowski_p</code>: Value of <code>p</code> in case
<code>dist_meth</code> is <code>"minkowski"</code>. The default is <code>2</code>, i.e.
the euclidean distance.
</p>
</li>
<li><p><code>nbc.dist_tie_breaker</code>: How will ties be broken when
different observations have the same distance to an observation?
Possible values are <code>"sample"</code>, <code>"first"</code> and <code>"last"</code>.
The default is <code>"sample"</code>.
</p>
</li>
<li><p><code>nbc.cor_na</code>: How should NA's be handled when computing
correlations? Any method from the argument <code>use</code> of the function
<code><a href="stats.html#topic+cor">cor</a></code> is possible. The default is
<code>"pairwise.complete.obs"</code>.
</p>
</li>
<li><p><code>nbc.fast_k</code>: In case of euclidean distances, the method
can find neighbours faster. This parameter controls the percentage of
observations that should be considered when looking for the nearest
better neighbour, i.e. the nearest neighbour with a better objective
value. The default is <code>0.05</code>, i.e. the 5
</p>
</li></ul>

</li>
<li><p>principal component features: </p>

<ul>
<li><p><code>pca.{cov, cor}_{x, init}</code>: Which proportion of the
variance should be explained by the principal components given a
principal component analysis based on the covariance / correlation
matrix of the decision space (<code>x</code>) or the entire initial
design (<code>init</code>)? The defaults are <code>0.9</code>.
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p><code>list</code> of (<code>numeric</code>) features:
</p>

<ul>
<li><p><code>cm_angle</code> &ndash; angle features (10):<br />
These features are based on the location of the worst and best element
within each cell. To be precise, their distance to the cell center and
the angle between these three elements (at the center) are the
foundation:
</p>

<ul>
<li><p><code>dist_ctr2{best, worst}.{mean, sd}</code>: arithmetic mean and
standard deviation of distances from the cell center to the best /
worst observation within the cell (over all cells)
</p>
</li>
<li><p><code>angle.{mean, sd}</code>: arithmetic mean and standard deviation
of angles (in degree) between worst, center and best element of a cell
(over all cells)
</p>
</li>
<li><p><code>y_ratio_best2worst.{mean, sd}</code>: arithmetic mean and
standard deviation of the ratios between the distance of the worst and
best element within a cell and the worst and best element in the
entire initial design (over all cells);<br />
note that the distances are only measured in the objective space
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>cm_conv</code> &ndash; cell mapping convexity features (6):<br />
Each cell will be represented by an observation (of the initial design),
which is located closest to the cell center. Then, the objectives of three
neighbouring cells are compared:<br />
</p>

<ul>
<li><p><code>{convex, concave}.hard</code>: if the objective of the inner
cell is above / below the two outer cells, there is strong evidence
for convexity / concavity
</p>
</li>
<li><p><code>{convex, concave}.soft</code>: if the objective of the inner
cell is above / below the arithmetic mean of the two outer cells,
there is weak evidence for convexity / concavity
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>cm_grad</code> &ndash; gradient homogeneity features (4):<br />
Within a cell of the initial grid, the gradients between each
observation and its nearest neighbour observation are computed. Those
gradients are then directed towards the smaller of the two objective
values and afterwards normalized. Then, the length of the sum of all the
directed and normalized gradients within a cell is computed. Based on
those measurements (one per cell) the following features are computed:<br />
</p>

<ul>
<li><p><code>{mean, sd}</code>: arithmetic mean and standard deviation of
the aforementioned lengths
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>ela_conv</code> &ndash; ELA convexity features (6):<br />
Two observations are chosen randomly from the initial design. Then, a
linear (convex) combination of those observations is calculated &ndash; based
on a random weight from [0, 1]. The corresponding objective value will be
compared to the linear combination of the objectives from the two
original observations. This process is replicated <code>convex.nsample</code>
(per default <code>1000</code>) times and will then be aggregated:<br />
</p>

<ul>
<li><p><code>{convex_p, linear_p}</code>: percentage of convexity / linearity
</p>
</li>
<li><p><code>linear_dev.{orig, abs}</code>: average (original / absolute)
deviation between the linear combination of the objectives and the
objective of the linear combination of the observations
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>ela_curv</code> &ndash; ELA curvature features (26):<br />
Given a feature object, <code>curv.sample_size</code> samples (per default
<code>100 * d</code> with <code>d</code> being the number of features) are randomly
chosen. Then, the gradient and hessian of the function are estimated
based on those points and the following features are computed:<br />
</p>

<ul>
<li><p><code>grad_norm.{min, lq, mean, median, uq, max, sd, nas}</code>:
aggregations (minimum, lower quartile, arithmetic mean, median, upper
quartile, maximum, standard deviation and percentage of NAs) of the
gradients' lengths
</p>
</li>
<li><p><code>grad_scale.{min, lq, mean, median, uq, max, sd, nas}</code>:
aggregations of the ratios between biggest and smallest (absolute)
gradient directions
</p>
</li>
<li><p><code>hessian_cond.{min, lq, mean, median, uq, max, sd, nas}</code>:
aggregations of the ratios of biggest and smallest eigenvalue of the
hessian matrices
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>ela_distr</code> &ndash; ELA y-distribution features (5):<br />
</p>

<ul>
<li><p><code>skewness</code>: skewness of the objective values
</p>
</li>
<li><p><code>kurtosis</code>: kurtosis of the objective values
</p>
</li>
<li><p><code>number_of_peaks</code>: number of peaks based on an estimation
of the density of the objective values
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>ela_level</code> &ndash; ELA levelset features (20):<br />
</p>

<ul>
<li><p><code>mmce_{methods}_{quantiles}</code>: mean misclassification error
of each pair of classification method and quantile
</p>
</li>
<li><p><code>{method1}_{method2}_{quantiles}</code>: ratio of all pairs of
classification methods for all quantiles
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>ela_local</code> &ndash; ELA local search features (16):<br />
Based on some randomly chosen points from the initial design, a
pre-defined number of local searches (<code>ela_local.local_searches</code>)
are executed. Their optima are then clustered (using hierarchical
clustering), assuming that local optima that are located close to each
other, likely belong to the same basin. Given those basins, the
following features are computed:<br />
</p>

<ul>
<li><p><code>n_loc_opt.{abs, rel}</code>: the absolute / relative amount of
local optima
</p>
</li>
<li><p><code>best2mean_contr.orig</code>: each cluster is represented by its
center; this feature is the ratio of the objective values of the best
and average cluster
</p>
</li>
<li><p><code>best2mean_contr.ratio</code>: each cluster is represented by its
center; this feature is the ratio of the differences in the objective
values of average to best and worst to best cluster
</p>
</li>
<li><p><code>basin_sizes.avg_{best, non_best, worst}</code>: average basin
size of the best / non-best / worst cluster(s)
</p>
</li>
<li><p><code>fun_evals.{min, lq, mean, median, uq, max, sd}</code>:
aggregations of the performed local searches
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>ela_meta</code> &ndash; ELA meta model features (11):<br />
Given an initial design, linear and quadratic models of the form
<code>objective ~ features</code> are created. Both versions are created
with and without simple interactions (e.g., <code>x1:x2</code>). Based on
those models, the following features are computed:<br />
</p>

<ul>
<li><p><code>lin_simple.{adj_r2, intercept}</code>: adjusted R^2 (i.e. model
fit) and intercept of a simple linear model
</p>
</li>
<li><p><code>lin_simple.coef.{min, max, max_by_min}</code>: smallest and
biggest (non-intercept) absolute coefficients of the simple linear
model, and their ratio
</p>
</li>
<li><p><code>{lin_w_interact, quad_simple, quad_w_interact}.adj_r2</code>:
adjusted R^2 (i.e. the model fit) of a linear model with interactions,
and a quadratic model with and without interactions
</p>
</li>
<li><p><code>quad_simple.cond</code>: condition of a simple quadratic model
(without interactions), i.e. the ratio of its (absolute) biggest and
smallest coefficients
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>gcm</code> &ndash; general cell mapping (GCM) features (75):<br />
Computes general cell mapping features based on the Generalized Cell
Mapping (GCM) approach, which interpretes the cells as absorbing Markov
chains. Computations are performed based on three different approaches:
taking the best (<code>min</code>) or average (<code>mean</code>) objective value of
a cell or the closest observation (<code>near</code>) to a cell as
representative. For each of these approaches the following 25 features
are computed:<br />
</p>

<ul>
<li><p><code>attractors, pcells, tcells, uncertain</code>: relative amount
of attractor, periodic, transient and uncertain cells
</p>
</li>
<li><p><code>basin_prob.{min, mean, median, max, sd}</code>: aggregations
of the probabilities of each basin of attraction
</p>
</li>
<li><p><code>basin_certain.{min, mean, median, max, sd}</code>: aggregations
of the (relative) size of each basin of attraction, in case only
certain cells are considered (i.e. cells, which only point towards one
attractor)
</p>
</li>
<li><p><code>basin_uncertain.{min, mean, median, max, sd}</code>:
aggregations of the (relative) size of each basin of attraction, in
case uncertain cells are considered (i.e. a cell, which points to
multiple attractors contributes to each of its basins)
</p>
</li>
<li><p><code>best_attr.{prob, no}</code>: probability of finding the
attractor with the best objective value and the (relative) amount of
those attractors (i.e. the ratio of the number of attractors with the
best objective value and the total amount of cells)
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>bt</code> &ndash; barrier tree features (90):<br />
Computes barrier tree features, based on a Generalized Cell Mapping
(GCM) approach. Computations are performed based on three different
approaches: taking the best (<code>min</code>) or average (<code>mean</code>)
objective value of a cell or the closest observation (<code>near</code>) to a
cell as representative. For each of these approaches the following 31
features are computed:<br />
</p>

<ul>
<li><p><code>levels</code>: absolute number of levels of the barrier tree
</p>
</li>
<li><p><code>leaves</code>: absolute number of leaves (i.e. local optima)
of the barrier tree
</p>
</li>
<li><p><code>depth</code>: range between highest and lowest node of the tree
</p>
</li>
<li><p><code>depth_levels_ratio</code>: ratio of depth and levels
</p>
</li>
<li><p><code>levels_nodes_ratio</code>: ratio of number of levels and number
of (non-root) nodes of the tree
</p>
</li>
<li><p><code>diffs.{min, mean, median, max, sd}</code>:
aggregations of the height differences between a node and its
predecessor
</p>
</li>
<li><p><code>level_diffs.{min, mean, median, max, sd}</code>:
aggregations of the average height differences per level
</p>
</li>
<li><p><code>attractor_dists.{min, mean, median, max, sd}</code>:
aggregations of the (euclidean) distances between the local and global
best cells (attractors)
</p>
</li>
<li><p><code>basin_ratio.{uncertain, certain, most_likely}</code>:
ratios of maximum and minimum size of the basins of attractions; here,
a cell might belong to different attractors (uncertain), exactly one
attractor (certain) or the attractor with the highest probability
</p>
</li>
<li><p><code>basin_intersection.{min, mean, median, max, sd}</code>:
aggregations of the intersection between the basin of the global best
value and the basins of all local best values
</p>
</li>
<li><p><code>basin_range</code>:
range of a basin (euclidean distance of widest range per dimension)
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>ic</code> &ndash; information content features (7):<br />
Computes features based on the Information Content of Fitness Sequences
(ICoFiS) approach (cf. Munoz et al., 2015). In this approach, the
information content of a continuous landscape, i.e. smoothness,
ruggedness, or neutrality, are quantified. While common analysis methods
were able to calculate the information content of discrete landscapes,
the ICoFiS approach provides an adaptation to continuous landscapes that
accounts e.g. for variable step sizes in random walk sampling:<br />
</p>

<ul>
<li><p><code>h.max</code>: &ldquo;maximum information content&rdquo; (entropy) of
the fitness sequence, cf. equation (5)
</p>
</li>
<li><p><code>eps.s</code>: &ldquo;settling sensitivity&rdquo;, indicating the
epsilon for which the sequence nearly consists of zeros only, cf.
equation (6)
</p>
</li>
<li><p><code>eps.max</code>: similar to <code>eps.s</code>, but in contrast to the
former <code>eps.max</code> guarantees non-missing values; this simply is the
epsilon-value for which H(<code>eps.max</code>) == <code>h.max</code>
</p>
</li>
<li><p><code>eps.ratio</code>: &ldquo;ratio of partial information
sensitivity&rdquo;, cf. equation (8), where the ratio is <code>0.5</code>
</p>
</li>
<li><p><code>m0</code>: &ldquo;initial partial information&rdquo;, cf. equation
(7)
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>basic</code> &ndash; basic features (15):<br />
Very simple features, which can be read from the feature object (without
any computational efforts):<br />
</p>

<ul>
<li><p><code>{dim, observations}</code>: number of features / dimensions and
observations within the initial sample
</p>
</li>
<li><p><code>{lower, upper, objective, blocks}_{min, max}</code>: minimum
and maximum value of all lower and upper bounds, the objective values
and the number of blocks / cells (per dimension)
</p>
</li>
<li><p><code>cells_{filled, total}</code>: number of filled (i.e. non-empty)
cells and total number of cells
</p>
</li>
<li><p><code>{minimize_fun}</code>: logical value, indicating
whether the optimization function should be minimized
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>disp</code> &ndash; dispersion features (18):<br />
Computes features based on the comparison of the dispersion of pairwise
distances among the 'best' elements and the entire initial design:<br />
</p>

<ul>
<li><p><code>{ratio, diff}_{mean, median}_{02, 05, 10, 25}</code>: ratio
and difference of the mean / median distances of the distances of the
'best' objectives vs. 'all' objectives
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>limo</code> &ndash; linear model features (14):<br />
Linear models are computed per cell, provided the decision space is
divided into a grid of cells. Each one of the models has the form
<code>objective ~ features</code>.<br />
</p>

<ul>
<li><p><code>avg_length.{reg, norm}</code>: length of the average
coefficient vector (based on regular and normalized vectors)
</p>
</li>
<li><p><code>length_{mean, sd}</code>: arithmetic mean and standard
deviation of the lengths of all coefficient vectors
</p>
</li>
<li><p><code>cor.{reg, norm}</code>: correlation of all coefficient vectors
(based on regular and normalized vectors)
</p>
</li>
<li><p><code>ratio_{mean, sd}</code>: arithmetic mean and standard deviation
of the ratios of (absolute) maximum and minimum (non-intercept)
coefficients per cell
</p>
</li>
<li><p><code>sd_{ratio, mean}.{reg, norm}</code>: max-by-min-ratio and
arithmetic mean of the standard deviations of the (non-intercept)
coefficients (based on regular and normalized vectors)
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>nbc</code> &ndash; nearest better (clustering) features (7):<br />
Computes features based on the comparison of nearest neighbour and
nearest better neighbour, i.e., the nearest neighbor with a better
performance / objective value value.<br />
</p>

<ul>
<li><p><code>nn_nb.{sd, mean}_ratio</code>: ratio of standard deviations and
arithmetic mean based on the distances among the nearest neighbours
and the nearest better neighbours
</p>
</li>
<li><p><code>nn_nb.cor</code>: correlation between distances of the nearest
neighbours and the distances of the nearest better neighbours
</p>
</li>
<li><p><code>dist_ratio.coeff_var</code>: coefficient of variation of the
distance ratios
</p>
</li>
<li><p><code>nb_fitness.cor</code>: correlation between fitness value and
count of observations to whom the current observation is the nearest
better neighbour (the so-called &ldquo;indegree&rdquo;).
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li>
<li><p><code>pca</code> &ndash; principal component (analysis) features (10):<br />
</p>

<ul>
<li><p><code>expl_var.{cov, cor}_{x, init}</code>: proportion of the
explained variance when applying PCA to the covariance / correlation
matrix of the decision space (<code>x</code>) or the entire initial design
(<code>init</code>)
</p>
</li>
<li><p><code>expl_var_PC1.{cov, cor}_{x, init}</code>: proportion of
variance, which is explained by the first principal component &ndash; when
applying PCA to the covariance / correlation matrix of the decision
space (<code>x</code>) or the entire initial design
</p>
</li>
<li><p><code>costs_{fun_evals, runtime}</code>: number of (additional)
function evaluations and runtime (in seconds), which were needed for
the computation of these features
</p>
</li></ul>

</li></ul>



<h3>References</h3>


<ul>
<li><p>Kerschke, P., and Trautmann, H. (2019):
&ldquo;Comprehensive Feature-Based Landscape Analysis of Continuous
and Constrained Optimization Problems Using the R-package flacco&rdquo;,
in: Applications in Statistical Computing &ndash; From Music Data Analysis
to Industrial Quality Improvement, pp. 93-123, Springer.
(<a href="https://link.springer.com/chapter/10.1007/978-3-030-25147-5_7">https://link.springer.com/chapter/10.1007/978-3-030-25147-5_7</a>).
</p>
</li>
<li><p>Kerschke, P., Preuss, M., Hernandez, C., Schuetze, O., Sun, J.-Q.,
Grimme, C., Rudolph, G., Bischl, B., and Trautmann, H. (2014):
&ldquo;Cell Mapping Techniques for Exploratory Landscape Analysis&rdquo;,
in: EVOLVE &ndash; A Bridge between Probability, Set Oriented Numerics, and
Evolutionary Computation V, pp. 115-131
(<a href="http://dx.doi.org/10.1007/978-3-319-07494-8_9">http://dx.doi.org/10.1007/978-3-319-07494-8_9</a>).
</p>
</li>
<li><p>Kerschke, P., Preuss, M., Wessing, S., and Trautmann, H. (2015):
&ldquo;Detecting Funnel Structures by Means of Exploratory Landscape
Analysis&rdquo;, in: Proceedings of the 17th Annual Conference on Genetic and
Evolutionary Computation (GECCO '15), pp. 265-272
(<a href="http://dx.doi.org/10.1145/2739480.2754642">http://dx.doi.org/10.1145/2739480.2754642</a>).
</p>
</li>
<li><p>Lunacek, M., and Whitley, D. (2006):
&ldquo;The dispersion metric and the CMA evolution strategy&rdquo;, in:
Proceedings of the 8th Annual Conference on Genetic and Evolutionary
Computation (GECCO '06), pp. 477-484
(<a href="http://dx.doi.org/10.1145/1143997.1144085">http://dx.doi.org/10.1145/1143997.1144085</a>).
</p>
</li>
<li><p>Mersmann, O., Bischl, B., Trautmann, H., Preuss, M., Weihs, C.,
and Rudolph, G. (2011): &ldquo;Exploratory Landscape Analysis&rdquo;, in:
Proceedings of the 13th Annual Conference on Genetic and Evolutionary
Computation (GECCO '11), pp. 829-836
(<a href="http://dx.doi.org/10.1145/2001576.2001690">http://dx.doi.org/10.1145/2001576.2001690</a>).
</p>
</li>
<li><p>Munoz, M. A., Kirley, M., and Halgamuge, S. K. (2015):
&ldquo;Exploratory Landscape Analysis of Continuous Space Optimization
Problems Using Information Content&rdquo;, in: IEEE Transactions on
Evolutionary Computation (19:1), pp. 74-87
(<a href="http://dx.doi.org/10.1109/TEVC.2014.2302006">http://dx.doi.org/10.1109/TEVC.2014.2302006</a>).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># (1) create a feature object:
X = t(replicate(n = 2000, expr = runif(n = 5, min = -10, max = 10)))
## Not run: feat.object = createFeatureObject(X = X, fun = function(x) sum(x^2))

# (2) compute all non-cellmapping features
ctrl = list(allow_cellmapping = FALSE)
## Not run: features = calculateFeatures(feat.object, control = ctrl)

# (3) in order to allow the computation of the cell mapping features, one
# has to provide a feature object that has knowledge about the number of
# cells per dimension:
f = function(x) sum(x^2)
feat.object = createFeatureObject(X = X, fun = f, blocks = 3)
## Not run: features = calculateFeatures(feat.object)

# (4) if you want to compute a specific feature set, you can use
# calculateFeatureSet:
features.angle = calculateFeatureSet(feat.object, "cm_angle")

# (5) as noted in the details, it might be useful to compute the levelset
# features parallelized:
## Not run: 
library(parallelMap)
library(parallel)
n.cores = detectCores()
parallelStart(mode = "socket", cpus = n.cores,
  logging = FALSE, show.info = FALSE)
system.time((levelset.par = calculateFeatureSet(feat.object, "ela_level")))
parallelStop()
system.time((levelset.seq = calculateFeatureSet(feat.object, "ela_level")))
## End(Not run)

</code></pre>

<hr>
<h2 id='computeGridCenters'>Compute the Cell Centers of a Cell Mapping Grid</h2><span id='topic+computeGridCenters'></span>

<h3>Description</h3>

<p>Computes the cell centers and the corresponding cell IDs of a cell mapping
grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computeGridCenters(lower, upper, blocks)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computeGridCenters_+3A_lower">lower</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a></code> or <code><a href="base.html#topic+integer">integer</a></code>]<br />
The lower limits per dimension.</p>
</td></tr>
<tr><td><code id="computeGridCenters_+3A_upper">upper</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a></code> or <code><a href="base.html#topic+integer">integer</a></code>]<br />
The upper limits per dimension.</p>
</td></tr>
<tr><td><code id="computeGridCenters_+3A_blocks">blocks</code></td>
<td>
<p>[<code><a href="base.html#topic+integer">integer</a></code>]<br />
The number of blocks per dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="base.html#topic+data.frame">data.frame</a></code>].<br />
A <code>data.frame</code>, which includes the coordinates of the cell centers,
as well as the corresponding cell ID (<code>cell.ID</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>computeGridCenters(lower = -10, upper = 10, blocks = c(10, 5, 8))

</code></pre>

<hr>
<h2 id='convertInitDesignToGrid'>Converts an Initial Design into a Cell Mapping Grid</h2><span id='topic+convertInitDesignToGrid'></span>

<h3>Description</h3>

<p>This function takes an initial design &ndash; with rows being the observations
and columns standing for the dimensions (plus the corresponding objective)
&ndash; and adds an additional column to the <code>data.frame</code>. This additional
column states the cell ID for each observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertInitDesignToGrid(init, lower, upper, blocks)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convertInitDesignToGrid_+3A_init">init</code></td>
<td>
<p>[<code><a href="base.html#topic+data.frame">data.frame</a></code>]<br />
The initial design, consisting of <code>d + 1</code> columns (d dimensions and
one column for the objective value) and one row per observation.</p>
</td></tr>
<tr><td><code id="convertInitDesignToGrid_+3A_lower">lower</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a></code> or <code><a href="base.html#topic+integer">integer</a></code>]<br />
The lower limits per dimension.</p>
</td></tr>
<tr><td><code id="convertInitDesignToGrid_+3A_upper">upper</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a></code> or <code><a href="base.html#topic+integer">integer</a></code>]<br />
The upper limits per dimension.</p>
</td></tr>
<tr><td><code id="convertInitDesignToGrid_+3A_blocks">blocks</code></td>
<td>
<p>[<code><a href="base.html#topic+integer">integer</a></code>]<br />
The number of blocks per dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="base.html#topic+data.frame">data.frame</a></code>].<br />
A <code>data.frame</code>, which includes an additional column (<code>cell.ID</code>)
compared to the initial design (<code>init</code>). The <code>cell.ID</code> will be a
value between 1 and <code>prod(blocks)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># (1) create an initial design:
X = t(replicate(n = 200, expr = runif(n = 5, min = -10, max = 10)))
f = function(x) sum(x^2)
y = apply(X = X, MARGIN = 1, FUN = f)
init = data.frame(X, y = y)

# (2) compute the cell mapping grid
convertInitDesignToGrid(init = init, lower = -10, upper = 10, blocks = 20)

</code></pre>

<hr>
<h2 id='createInitialSample'>Create Initial Sample</h2><span id='topic+createInitialSample'></span>

<h3>Description</h3>

<p>Convenient helper function, which creates an initial sample - either based
on random (uniform) sampling or using latin hypercube sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createInitialSample(n.obs, dim, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createInitialSample_+3A_n.obs">n.obs</code></td>
<td>
<p>[<code>integer(1)</code>]<br />
Number of observations.</p>
</td></tr>
<tr><td><code id="createInitialSample_+3A_dim">dim</code></td>
<td>
<p>[<code>integer(1)</code>]<br />
Number of dimensions.</p>
</td></tr>
<tr><td><code id="createInitialSample_+3A_control">control</code></td>
<td>
<p>[<code>list</code>]<br />
Control argument. For further information refer to the details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Per default, this function will produce <code>n.obs</code> observations of size
<code>dim</code> in the range from 0 to 1. If you want to create a more specific
initial sample, the following control arguments might be helpful:
</p>

<ul>
<li><p><code>init_sample.type</code>: Should the initial sample be created
based on random uniform sampling (<code>"random"</code>) or on a latin hypercube
sample (<code>"lhs"</code>)? The default is <code>"random"</code>.
</p>
</li>
<li><p><code>init_sample.lower</code>: The lower bounds of the initial sample.
Either a vector of size <code>dim</code> or a scalar (if all lower bounds are
identical). The default is <code>0</code>.
</p>
</li>
<li><p><code>init_sample.upper</code>: The upper bounds of the initial sample.
Either a vector of size <code>dim</code> or a scalar (if all upper bounds are
identical). The default is <code>1</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>[<code><a href="base.html#topic+matrix">matrix</a></code>].<br />
A matrix, consisting of <code>n.obs</code> rows of <code>dim</code>-dimensional
observations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># (1) create a simple initial sample:
X = createInitialSample(300, 5)
summary(X)

# (2) create a more specific initial sample:
ctrl = list(init_sample.type = "lhs",
  init_sample.lower = c(-5, 2, 0),
  init_sample.upper = 10)
X = createInitialSample(200, 3, control = ctrl)
summary(X)

</code></pre>

<hr>
<h2 id='featureList'>Feature List</h2><span id='topic+featureList'></span>

<h3>Description</h3>

<p>Contains a list of features. This could be the result of a feature selection
(based on a nested resampling strategy) executed on the
<code><a href="mlbench.html#topic+Glass">Glass</a></code> data.
</p>

<hr>
<h2 id='FeatureObject'>Create a Feature Object</h2><span id='topic+FeatureObject'></span><span id='topic+createFeatureObject'></span>

<h3>Description</h3>

<p>Create a <code><a href="#topic+FeatureObject">FeatureObject</a></code>, which will be used as input for all
the feature computations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createFeatureObject(
  init,
  X,
  y,
  fun,
  minimize,
  lower,
  upper,
  blocks,
  objective,
  force = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FeatureObject_+3A_init">init</code></td>
<td>
<p>[<code><a href="base.html#topic+data.frame">data.frame</a></code>]<br />
A <code>data.frame</code>, which can be used as initial design. If not provided,
it will be created either based on the initial sample <code>X</code> and the
objective values <code>y</code> or <code>X</code> and the function definition <code>fun</code>.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_x">X</code></td>
<td>
<p>[<code><a href="base.html#topic+data.frame">data.frame</a></code> or <code><a href="base.html#topic+matrix">matrix</a></code>]<br />
A <code>data.frame</code> or <code>matrix</code> containing the initial sample. If not
provided, it will be extracted from <code>init</code>.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_y">y</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a></code> or <code><a href="base.html#topic+integer">integer</a></code>]<br />
A vector containing the objective values of the initial design.
If not provided, it will be extracted from <code>init</code>.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_fun">fun</code></td>
<td>
<p>[<code><a href="base.html#topic+function">function</a></code>]<br />
A function, which allows the computation of the objective values. If it is
not provided, features that require additional function evaluations, can't
be computed.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_minimize">minimize</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
Should the objective function be minimized? The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_lower">lower</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a></code> or <code><a href="base.html#topic+integer">integer</a></code>]<br />
The lower limits per dimension.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_upper">upper</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a></code> or <code><a href="base.html#topic+integer">integer</a></code>]<br />
The upper limits per dimension.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_blocks">blocks</code></td>
<td>
<p>[<code><a href="base.html#topic+integer">integer</a></code>]<br />
The number of blocks per dimension.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_objective">objective</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a>(1)</code>]<br />
The name of the feature, which contains the objective values. The
default is <code>"y"</code>.</p>
</td></tr>
<tr><td><code id="FeatureObject_+3A_force">force</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
Only change this parameter IF YOU KNOW WHAT YOU ARE DOING! Per default
(<code>force = FALSE</code>), the function checks whether the total number of
cells that you are trying to generate, is below the (hard-coded) internal
maximum of 25,000 cells. If you set this parameter to <code>TRUE</code>, you
agree that you want to exceed that internal limit.<br />
Note: *Exploratory Landscape Analysis (ELA)* is only useful when you are
limited to a small budget (i.e., a small number of function evaluations)
and in such scenarios, the number of cells should also be kept low!</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>].
</p>


<h3>Examples</h3>

<pre><code class='language-R'># (1a) create a feature object using X and y:
X = createInitialSample(n.obs = 500, dim = 3,
  control = list(init_sample.lower = -10, init_sample.upper = 10))
y = apply(X, 1, function(x) sum(x^2))
feat.object1 = createFeatureObject(X = X, y = y, 
  lower = -10, upper = 10, blocks = c(5, 10, 4))

# (1b) create a feature object using X and fun:
feat.object2 = createFeatureObject(X = X, 
  fun = function(x) sum(sin(x) * x^2),
  lower = -10, upper = 10, blocks = c(5, 10, 4))

# (1c) create a feature object using a data.frame:
feat.object3 = createFeatureObject(iris[,-5], blocks = 5, 
  objective = "Petal.Length")

# (2) have a look at the feature objects:
feat.object1
feat.object2
feat.object3

# (3) now, one could calculate features
calculateFeatureSet(feat.object1, "ela_meta")
calculateFeatureSet(feat.object2, "cm_grad")
library(plyr)
calculateFeatureSet(feat.object3, "cm_angle", control = list(cm_angle.show_warnings = FALSE))

</code></pre>

<hr>
<h2 id='featureObject_sidebar'>Shiny UI-Module for Function Input</h2><span id='topic+featureObject_sidebar'></span>

<h3>Description</h3>

<p><code>featObject_sidebar</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> UI-component which can be
added to your <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> app so that you can easily generate a
feature object by providing all relevant information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>featureObject_sidebar(id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="featureObject_sidebar_+3A_id">id</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a>(1)</code>]<br />
Character representing the <code>namespace</code> of the <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> component.</p>
</td></tr>
</table>

<hr>
<h2 id='FeatureSetCalculation'>Shiny Server Function for Feature Set Component</h2><span id='topic+FeatureSetCalculation'></span>

<h3>Description</h3>

<p><code>FeatureSetCalculation</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> server function
which will control all aspects of the <code>FeatureSetCalculationComponent</code>
UI Module. Will be called with <code><a href="shiny.html#topic+callModule">callModule</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FeatureSetCalculation(input, output, session, stringsAsFactors, feat.object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FeatureSetCalculation_+3A_input">input</code></td>
<td>
<p>[<code>shiny-input</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> input variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="FeatureSetCalculation_+3A_output">output</code></td>
<td>
<p>[<code>shiny-output object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> output variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="FeatureSetCalculation_+3A_session">session</code></td>
<td>
<p>[<code>shiny-session object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> session variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="FeatureSetCalculation_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
How should strings be treated internally?</p>
</td></tr>
<tr><td><code id="FeatureSetCalculation_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It will take the user input and calculate the selected feature set.
In order to calculate a feature set, the function needs a <code><a href="#topic+FeatureObject">FeatureObject</a></code>.
</p>

<hr>
<h2 id='FeatureSetCalculationComponent'>Shiny UI-Module for Calculating and Displaying Feature Sets</h2><span id='topic+FeatureSetCalculationComponent'></span>

<h3>Description</h3>

<p><code>FeatureSetCalculationComponent</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a>
UI-component which can be added to your <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> app so
that you can calculate and display different feature sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FeatureSetCalculationComponent(id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FeatureSetCalculationComponent_+3A_id">id</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a>(1)</code>]<br />
Character representing the <code>namespace</code> of the <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> component.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The component integrates a select-Input for choosing the feature set,
which should be calculated and displayed in a table.
With the download button the calculated features can be exported as CSV-file.
</p>

<hr>
<h2 id='FeatureSetVisualization'>Shiny Server Function for Feature Set Component</h2><span id='topic+FeatureSetVisualization'></span>

<h3>Description</h3>

<p><code>FeatureSetVisualization</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> server function
which will control all aspects of the <code>FeatureSetVisualizationComponent</code>
UI-Module. It will be called with <code><a href="shiny.html#topic+callModule">callModule</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FeatureSetVisualization(input, output, session, stringsAsFactors, feat.object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FeatureSetVisualization_+3A_input">input</code></td>
<td>
<p>[<code>shiny-input</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> input variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="FeatureSetVisualization_+3A_output">output</code></td>
<td>
<p>[<code>shiny-output object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> output variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="FeatureSetVisualization_+3A_session">session</code></td>
<td>
<p>[<code>shiny-session object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> session variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="FeatureSetVisualization_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
How should strings be treated internally?</p>
</td></tr>
<tr><td><code id="FeatureSetVisualization_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It will take the user input and plot the selected visualization. To create a
flacco plot, the function needs a <code><a href="#topic+FeatureObject">FeatureObject</a></code>.
</p>

<hr>
<h2 id='FeatureSetVisualizationComponent'>Shiny Component for Visualizing the Feature Sets</h2><span id='topic+FeatureSetVisualizationComponent'></span>

<h3>Description</h3>

<p><code>FeatureSetVisualizationComponent</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> component
which can be added to your <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> app so that you can display
different feature set plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FeatureSetVisualizationComponent(id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FeatureSetVisualizationComponent_+3A_id">id</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a>(1)</code>]<br />
Character representing the <code>namespace</code> of the <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> component.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It integrates a select input where the user can select the plot which should be created.
</p>

<hr>
<h2 id='findLinearNeighbours'>Find Neighbouring Cells</h2><span id='topic+findLinearNeighbours'></span>

<h3>Description</h3>

<p>Given a vector of cell IDs (<code>cell.ids</code>) and a vector (<code>blocks</code>),
which defines the number of blocks / cells per dimension, a list of all
combinations of (linearly) neighbouring cells around each element of
<code>cell.ids</code> is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findLinearNeighbours(cell.ids, blocks, diag = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findLinearNeighbours_+3A_cell.ids">cell.ids</code></td>
<td>
<p>[<code><a href="base.html#topic+integer">integer</a></code>]<br />
Vector of cell IDs (one number per cell) for which the neighbouring cells
should be computed.</p>
</td></tr>
<tr><td><code id="findLinearNeighbours_+3A_blocks">blocks</code></td>
<td>
<p>[<code><a href="base.html#topic+integer">integer</a></code>]<br />
The number of blocks per dimension.</p>
</td></tr>
<tr><td><code id="findLinearNeighbours_+3A_diag">diag</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
<code>logical</code>, indicating whether only cells that are located parallel to
the axes should be considered (<code>diag = FALSE</code>) as neighbours.
Alternatively, one can also look for neighbours that are located
diagonally to a cell. The default is <code>diag = FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="base.html#topic+list">list</a></code> of <code><a href="base.html#topic+integer">integer</a>(3)</code>].<br />
List of neighbours. Each list element stands for a combination of
predecessing, current and succeeding cell.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cell.ids = c(5, 84, 17, 23)
blocks = c(5, 4, 7)

# (1) Considering diagonal neighbours as well:
findLinearNeighbours(cell.ids = cell.ids, blocks = blocks, diag = TRUE)

# (2) Only consider neighbours which are parellel to the axes:
findLinearNeighbours(cell.ids = cell.ids, blocks = blocks)

</code></pre>

<hr>
<h2 id='findNearestPrototype'>Find Nearest Prototype</h2><span id='topic+findNearestPrototype'></span>

<h3>Description</h3>

<p>For each cell of the initial design, select the closest observation to its
center and use it as a representative for that cell.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findNearestPrototype(feat.object, dist_meth, mink_p, fast_k, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findNearestPrototype_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
<tr><td><code id="findNearestPrototype_+3A_dist_meth">dist_meth</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a>(1)</code>]<br />
Which distance method should be used for computing the distance between
two observations? All methods of <code><a href="stats.html#topic+dist">dist</a></code> are possible options
with <code>"euclidean"</code> being the default.</p>
</td></tr>
<tr><td><code id="findNearestPrototype_+3A_mink_p">mink_p</code></td>
<td>
<p>[<code><a href="base.html#topic+integer">integer</a>(1)</code>]<br />
Value of <code>p</code> in case <code>dist_meth</code> is <code>"minkowski"</code>.
The default is <code>2</code>, i.e. the euclidean distance.</p>
</td></tr>
<tr><td><code id="findNearestPrototype_+3A_fast_k">fast_k</code></td>
<td>
<p>[<code><a href="base.html#topic+numeric">numeric</a>(1)</code>]<br />
Percentage of elements that should be considered within the nearest
neighbour computation. The default is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="findNearestPrototype_+3A_...">...</code></td>
<td>
<p>[any]<br />
Further arguments, which might be used within the distance computation
(<code><a href="stats.html#topic+dist">dist</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="base.html#topic+data.frame">data.frame</a></code>].<br />
A <code>data.frame</code> containing one prototype (i.e. a representative
observation) per cell. Each prototype consists of its values from the
decision space, the corresponding objective value, its own cell ID and the
cell ID of the cell, which it represents.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># (1) create the initial sample and feature object:
X = createInitialSample(n.obs = 1000, dim = 2,
  control = list(init_sample.lower = -10, init_sample.upper = 10))
feat.object = createFeatureObject(X = X, 
  fun = function(x) sum(x^2), blocks = 10)

# (2) find the nearest prototypes of all cells:
findNearestPrototype(feat.object)
</code></pre>

<hr>
<h2 id='functionInput'>Shiny Server Function for Feature Calculation of Function Input</h2><span id='topic+functionInput'></span>

<h3>Description</h3>

<p><code>functionInput</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> server function which controls
all aspects of the <code>FlaccoFunctionInput</code> UI Module. Will be
called with <code><a href="shiny.html#topic+callModule">callModule</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functionInput(input, output, session, stringsAsFactors)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functionInput_+3A_input">input</code></td>
<td>
<p>[<code>shiny-input</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> input variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="functionInput_+3A_output">output</code></td>
<td>
<p>[<code>shiny-output object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> output variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="functionInput_+3A_session">session</code></td>
<td>
<p>[<code>shiny-session object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> session variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="functionInput_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
How should strings be treated internally?</p>
</td></tr>
</table>

<hr>
<h2 id='ggplotFeatureImportance'>Feature Importance Plot</h2><span id='topic+ggplotFeatureImportance'></span><span id='topic+plotFeatureImportance'></span>

<h3>Description</h3>

<p>Creates a feature importance plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggplotFeatureImportance(featureList, control = list(), ...)

plotFeatureImportance(featureList, control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ggplotFeatureImportance_+3A_featurelist">featureList</code></td>
<td>
<p>[<code>list</code>]<br />
List of vectors of features. One list element is expected to belong to
one resampling iteration / fold.</p>
</td></tr>
<tr><td><code id="ggplotFeatureImportance_+3A_control">control</code></td>
<td>
<p>[<code>list</code>]<br />
A list, which stores additional configuration parameters:
</p>

<ul>
<li><p><code>featimp.col_{high/medium/low}</code>: Color of the features, which
are used often, sometimes or only a few times.
</p>
</li>
<li><p><code>featimp.perc_{high/low}</code>: Percentage of the total number of folds,
defining when a features, is used often, sometimes or only a few times.
</p>
</li>
<li><p><code>featimp.las</code>: Alignment of axis labels.
</p>
</li>
<li><p><code>featimp.lab_{feat/resample}</code>: Axis labels (features and resample iterations).
</p>
</li>
<li><p><code>featimp.string_angle</code>: Angle for the features on the x-axis.
</p>
</li>
<li><p><code>featimp.pch_{active/inactive}</code>: Plot symbol of the active and
inactive points.
</p>
</li>
<li><p><code>featimp.col_inactive</code>: Color of the inactive points.
</p>
</li>
<li><p><code>featimp.col_vertical</code>: Color of the vertical lines.
</p>
</li>
<li><p><code>featimp.lab_{title/strip}</code>: Label used for the title and/or strip label.
These parameters are only relevant for <code>ggplotFeatureImportance</code>.
</p>
</li>
<li><p><code>featimp.legend_position</code>: Location of the legend.
This parameter is only relevant for <code>ggplotFeatureImportance</code>.
</p>
</li>
<li><p><code>featimp.flip_axes</code>: Should the axes be flipped?
This parameter is only relevant for <code>ggplotFeatureImportance</code>.
</p>
</li>
<li><p><code>featimp.plot_tiles</code>: Visualize (non-)selected features with tiles?
This parameter is only relevant for <code>ggplotFeatureImportance</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="ggplotFeatureImportance_+3A_...">...</code></td>
<td>
<p>[any]<br />
Further arguments, which can be passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code>plot</code>].<br />
Feature Importance Plot, indicating which feature was used during which iteration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# At the beginning, one needs a list of features, e.g. derived during a
# nested feature selection within mlr (see the following 8 steps):
library(mlr)
library(mlbench)
data(Glass)

# (1) Create a classification task:
classifTask = makeClassifTask(data = Glass, target = "Type")

# (2) Define the model (here, a classification tree):
lrn = makeLearner(cl = "classif.rpart")

# (3) Define the resampling strategy, which is supposed to be used within 
# each inner loop of the nested feature selection:
innerResampling = makeResampleDesc("Holdout")

# (4) What kind of feature selection approach should be used? Here, we use a
# sequential backward strategy, i.e. starting from a model with all features,
# in each step the feature decreasing the performance measure the least is
# removed from the model:
ctrl = makeFeatSelControlSequential(method = "sbs")

# (5) Wrap the original model (see (2)) in order to allow feature selection:
wrappedLearner = makeFeatSelWrapper(learner = lrn,
  resampling = innerResampling, control = ctrl)

# (6) Define a resampling strategy for the outer loop. This is necessary in
# order to assess whether the selected features depend on the underlying
# fold:
outerResampling = makeResampleDesc(method = "CV", iters = 10L)

# (7) Perform the feature selection:
featselResult = resample(learner = wrappedLearner, task = classifTask,
  resampling = outerResampling, models = TRUE)

# (8) Extract the features, which were selected during each iteration of the
# outer loop (i.e. during each of the 10 folds of the cross-validation):
featureList = lapply(featselResult$models, 
  function(mod) getFeatSelResult(mod)$x)
## End(Not run)

########################################################################

# Now, one could inspect the features manually:
featureList

# Alternatively, one might use visual means such as the feature
# importance plot. There exist two versions for the feature importance
# plot. One based on the classical R figures
plotFeatureImportance(featureList)

# and one using ggplot
ggplotFeatureImportance(featureList)

</code></pre>

<hr>
<h2 id='listAvailableFeatureSets'>List Available Feature Sets</h2><span id='topic+listAvailableFeatureSets'></span>

<h3>Description</h3>

<p>Lists all available feature sets w.r.t. certain restrictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listAvailableFeatureSets(
  subset,
  allow.cellmapping,
  allow.additional_costs,
  blacklist
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="listAvailableFeatureSets_+3A_subset">subset</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a></code>]<br />
Vector of feature sets, which should be considered. If not defined, all
features will be considered.</p>
</td></tr>
<tr><td><code id="listAvailableFeatureSets_+3A_allow.cellmapping">allow.cellmapping</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
Should (general) cell mapping features be considered as well? The default is
<code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="listAvailableFeatureSets_+3A_allow.additional_costs">allow.additional_costs</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
Should feature sets be considered, which require additional function
evaluations? The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="listAvailableFeatureSets_+3A_blacklist">blacklist</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a></code>]<br />
Vector of feature sets, which should not be considered. The default is
<code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="base.html#topic+character">character</a></code>].<br />
Feature sets, which could be computed - based on the provided input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sets = listAvailableFeatureSets()
</code></pre>

<hr>
<h2 id='measureTime'>Measure Runtime of a Feature Computation</h2><span id='topic+measureTime'></span>

<h3>Description</h3>

<p>Simple wrapper around <code>proc.time</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>measureTime(expr, prefix, envir = parent.frame())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="measureTime_+3A_expr">expr</code></td>
<td>
<p>[<code>expression</code>]<br />
Expression of which the time should be measured.</p>
</td></tr>
<tr><td><code id="measureTime_+3A_prefix">prefix</code></td>
<td>
<p>[<code>character(1)</code>]<br />
Name of the corresponding feature set. Used as a prefix for the runtime.</p>
</td></tr>
<tr><td><code id="measureTime_+3A_envir">envir</code></td>
<td>
<p>[<code>environment</code>]<br />
Environment in which expr should be evaluated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the value(s) of the evaluated <code>expr</code> and adds two
additional attributes: the number of function evaluations
<code>costs_fun_evals</code> and the runtime <code>costs_runtime</code>, which was
required for evaluating the expression.
</p>

<hr>
<h2 id='plotBarrierTree2D'>Plot Barrier Tree in 2D</h2><span id='topic+plotBarrierTree2D'></span>

<h3>Description</h3>

<p>Creates a 2D image containing the barrier tree of this cell mapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBarrierTree2D(feat.object, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotBarrierTree2D_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
<tr><td><code id="plotBarrierTree2D_+3A_control">control</code></td>
<td>
<p>[<code>list</code>]<br />
A <code>list</code>, which stores additional control arguments.
For further information, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Possible <code>control</code> arguments are:
</p>

<ul>
<li><p>Computation of Cell Mapping: </p>

<ul>
<li><p><code>gcm.approach</code>: Which approach should be used when
computing the representatives of a cell. The default is <code>"min"</code>,
i.e. the observation with the best (minimum) value within per cell.
</p>
</li>
<li><p><code>gcm.cf_power</code>: Theoretically, we need to compute the
canonical form to the power of infinity. However, we use this value
as approximation of infinity. The default is <code>256</code>.
</p>
</li></ul>

</li>
<li><p>Plot Control: </p>

<ul>
<li><p><code>bt.cm_surface</code>: Should the underlying surface be based
on a cell mapping plot (default is <code>TRUE</code>)? Alternatively, the
cells would be coloured in shades of grey - according to their
objective values.
</p>
</li>
<li><p><code>bt.margin</code>: Margins of the plot as used by
<code>par("mar")</code>. The default is <code>c(5, 5, 4, 4)</code>.
</p>
</li>
<li><p><code>bt.color_surface</code>: Color of the surface of the
perspective plot. The default is <code>"lightgrey"</code>.
</p>
</li>
<li><p><code>bt.color_branches</code>: Color used for the branches of the
barrier tree. Per default there will be one color per level.
</p>
</li>
<li><p><code>bt.pch_root</code>: Symbol used for plotting the root.
The default is <code>17</code> (filled triangle).
</p>
</li>
<li><p><code>bt.pch_breakpoint</code>: Symbol used for plotting a
breakpoint. The default is <code>5</code> (non-filled diamond).
</p>
</li>
<li><p><code>bt.pch_basin</code>: Symbol used for plotting the leaf (i.e. a
basin) of the barrier tree. The default is <code>19</code> (filled circle).
</p>
</li>
<li><p><code>bt.col_root</code>: Color of the root symbol. The default is
<code>"red"</code>.
</p>
</li>
<li><p><code>bt.lwd</code>: Width of the lines used for plotting the
branches of a barrier tree. The default is <code>2</code>.
</p>
</li>
<li><p><code>bt.label.{x, y}_coord</code>: Label of the x-/y-coordinate
(below / left side of the plot).
</p>
</li>
<li><p><code>bt.label.{x, y}_id</code>: Label of the x-/y-cell ID (above /
right side of the plot).
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>[<code>plot</code>].<br />
A 2D image, visualizing the barrier tree of this cell mapping.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a feature object
X = createInitialSample(n.obs = 900, dim = 2)
f = smoof::makeAckleyFunction(dimensions = 2)
y = apply(X, 1, f)
feat.object = createFeatureObject(X = X, y = y, fun = f, blocks = c(4, 6))

# plot the corresponing barrier tree
plotBarrierTree2D(feat.object)
</code></pre>

<hr>
<h2 id='plotBarrierTree3D'>Plot Barrier Tree in 3D</h2><span id='topic+plotBarrierTree3D'></span>

<h3>Description</h3>

<p>Creates a 3D surface plot containing the barrier tree of this cell mapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBarrierTree3D(feat.object, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotBarrierTree3D_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
<tr><td><code id="plotBarrierTree3D_+3A_control">control</code></td>
<td>
<p>[<code>list</code>]<br />
A <code>list</code>, which stores additional control arguments.
For further information, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Possible <code>control</code> arguments are:
</p>

<ul>
<li><p>Computation of Cell Mapping: </p>

<ul>
<li><p><code>gcm.approach</code>: Which approach should be used when
computing the representatives of a cell. The default is <code>"min"</code>,
i.e. the observation with the best (minimum) value within per cell.
</p>
</li>
<li><p><code>gcm.cf_power</code>: Theoretically, we need to compute the
canonical form to the power of infinity. However, we use this value
as approximation of infinity. The default is <code>256</code>.
</p>
</li></ul>

</li>
<li><p>Plot Control: </p>

<ul>
<li><p><code>bt.margin</code>: Margins of the plot as used by
<code>par("mar")</code>. The default is <code>c(0.5, 1, 0, 0)</code>.
</p>
</li>
<li><p><code>bt.color_surface</code>: Color of the surface of the
perspective plot. The default is <code>"lightgrey"</code>.
</p>
</li>
<li><p><code>bt.color_branches</code>: Color used for the branches of the
barrier tree. Per default there will be one color per level.
</p>
</li>
<li><p><code>bt.persp_border</code>: Color of the lines / borders around
each facet of the perspective plot. The default is <code>"grey"</code>.
</p>
</li>
<li><p><code>bt.persp_shade</code>: A ratio defining the shade of the
surface. The default is <code>0.35</code>.
</p>
</li>
<li><p><code>bt.persp_{theta, phi}</code>: Angles (in degree) defining the
viewing direction of the perspective plot. <code>theta</code> corresponds to
the azimuthal direction (default: <code>330</code>) and <code>phi</code> to the
colatitude (default: <code>15</code>).
</p>
</li>
<li><p><code>bt.persp_{xlab, ylab, zlab}</code>: Labels of the x-, y- and z-
axis. The defaults are <code>expression(x[1])</code>,
<code>expression(x[2])</code> and <code>expression(f(x[1], x[2]))</code>
</p>
</li>
<li><p><code>bt.persp_ticktype</code>: Should the values of each dimension
be shown in detail (<code>"detailed"</code>) or just via <code>"simple"</code>
arrows in direction of increasement along the axes? The default is
<code>"detailed"</code>.
</p>
</li>
<li><p><code>bt.col_root</code>: Color of the root symbol. The default is
<code>"red"</code>.
</p>
</li>
<li><p><code>bt.pch_root</code>: Symbol used for plotting the root.
The default is <code>17</code> (filled triangle).
</p>
</li>
<li><p><code>bt.pch_breakpoint</code>: Symbol used for plotting a
breakpoint. The default is <code>5</code> (non-filled diamond).
</p>
</li>
<li><p><code>bt.pch_basin</code>: Symbol used for plotting the leaf (i.e. a
basin) of the barrier tree. The default is <code>19</code> (filled circle).
</p>
</li>
<li><p><code>bt.lwd</code>: Width of the lines used for plotting the
branches of a barrier tree. The default is <code>2</code>.
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>[<code>plot</code>].<br />
A 3D-surface plot, visualizing the barrier tree of this cell mapping.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a feature object
X = createInitialSample(n.obs = 900, dim = 2)
f = smoof::makeAckleyFunction(dimensions = 2)
y = apply(X, 1, f)
feat.object = createFeatureObject(X = X, y = y, fun = f, blocks = c(4, 6))

# plot the corresponing barrier tree
plotBarrierTree3D(feat.object)
</code></pre>

<hr>
<h2 id='plotCellMapping'>Plot Cell Mapping</h2><span id='topic+plotCellMapping'></span>

<h3>Description</h3>

<p>Visualizes the transitions among the cells in the General Cell Mapping approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCellMapping(feat.object, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotCellMapping_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
<tr><td><code id="plotCellMapping_+3A_control">control</code></td>
<td>
<p>[<code>list</code>]<br />
A <code>list</code>, which stores additional control arguments.
For further information, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Possible <code>control</code> arguments are:
</p>

<ul>
<li><p>Computation of GCM Features: </p>

<ul>
<li><p><code>gcm.approach</code>: Which approach should be used when
computing the representatives of a cell. The default is <code>"min"</code>,
i.e. the observation with the best (minimum) value within per cell.
</p>
</li>
<li><p><code>gcm.cf_power</code>: Theoretically, we need to compute the
canonical form to the power of infinity. However, we use this value
as approximation of infinity. The default is <code>256</code>.
</p>
</li></ul>

</li>
<li><p>Plot Control: </p>

<ul>
<li><p><code>gcm.margin</code>: The margins of the plot as used by
<code>par("mar")</code>. The default is <code>c(5, 5, 4, 4)</code>.
</p>
</li>
<li><p><code>gcm.color_attractor</code>: Color of the attractors. The
default is <code>"#333333"</code>, i.e. dark grey.
</p>
</li>
<li><p><code>gcm.color_uncertain</code>: Color of the uncertain cells. The
default is <code>"#cccccc"</code>, i.e. grey.
</p>
</li>
<li><p><code>gcm.color_basin</code>: Color of the basins of attraction. This
has to be a function, which computes the colors, depending on the
number of attractors. The default is the color scheme from <code>ggplot2</code>.
</p>
</li>
<li><p><code>gcm.plot_arrows</code>: Should arrows be plotted? The default
is <code>TRUE</code>.
</p>
</li>
<li><p><code>gcm.arrow.length_{x, y}</code>: Scaling factor of the arrow
length in x- and y-direction. The default is <code>0.9</code>, i.e. 90%
of the actual length.
</p>
</li>
<li><p><code>gcm.arrowhead.{length, width}</code>: Scaling factor for the
width and length of the arrowhead. Per default (<code>0.1</code>) the
arrowhead is 10% of the length of the original arrow.
</p>
</li>
<li><p><code>gcm.arrowhead.type</code>: Type of the arrowhead. Possible
options are <code>"simple"</code>, <code>"curved"</code>, <code>"triangle"</code>
(default), <code>"circle"</code>, <code>"ellipse"</code> and <code>"T"</code>.
</p>
</li>
<li><p><code>gcm.color_grid</code>: Color of the grid lines. The default is
<code>"#333333"</code>, i.e. dark grey.
</p>
</li>
<li><p><code>gcm.label.{x, y}_coord</code>: Label of the x-/y-coordinate
(below / left side of the plot).
</p>
</li>
<li><p><code>gcm.label.{x, y}_id</code>: Label of the x-/y-cell ID (above /
right side of the plot).
</p>
</li>
<li><p><code>gcm.plot_{coord, id}_labels</code>: Should the coordinate
(bottom and left) / ID (top and right) labels be plotted? The default
is <code>TRUE</code>.
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>[<code>plot</code>].
</p>


<h3>References</h3>


<ul>
<li><p>Kerschke, P., Preuss, M., Hernandez, C., Schuetze, O., Sun, J.-Q.,
Grimme, C., Rudolph, G., Bischl, B., and Trautmann, H. (2014):
&ldquo;Cell Mapping Techniques for Exploratory Landscape Analysis&rdquo;,
in: EVOLVE &ndash; A Bridge between Probability, Set Oriented Numerics, and
Evolutionary Computation V, pp. 115-131
(<a href="http://dx.doi.org/10.1007/978-3-319-07494-8_9">http://dx.doi.org/10.1007/978-3-319-07494-8_9</a>).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># (1) Define a function:
library(smoof)
f = makeHosakiFunction()

# (2) Create a feature object:
X = cbind(
  x1 = runif(n = 100, min = -32, max = 32),
  x2 = runif(n = 100, min = 0, max = 10)
)
y = apply(X, 1, f)
feat.object = createFeatureObject(X = X, y = y, blocks = c(4, 6))

# (3) Plot the cell mapping:
plotCellMapping(feat.object)
</code></pre>

<hr>
<h2 id='plotInformationContent'>Plot Information Content</h2><span id='topic+plotInformationContent'></span>

<h3>Description</h3>

<p>Creates a plot of the Information Content Features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotInformationContent(feat.object, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotInformationContent_+3A_feat.object">feat.object</code></td>
<td>
<p>[<code><a href="#topic+FeatureObject">FeatureObject</a></code>]<br />
A feature object as created by <code><a href="#topic+createFeatureObject">createFeatureObject</a></code>.</p>
</td></tr>
<tr><td><code id="plotInformationContent_+3A_control">control</code></td>
<td>
<p>[<code>list</code>]<br />
A <code>list</code>, which stores additional control arguments.
For further information, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Possible <code>control</code> arguments are:
</p>

<ul>
<li><p>Computation of Information Content Features: </p>

<ul>
<li><p><code>ic.epsilon</code>: Epsilon values as described in section V.A
of Munoz et al. (2015). The default is
<code>c(0, 10^(seq(-5, 15, length.out = 1000))</code>.
</p>
</li>
<li><p><code>ic.sorting</code>: Sorting strategy, which is used to define
the tour through the landscape. Possible values are <code>"nn"</code>
(= default) and <code>"random"</code>.
</p>
</li>
<li><p><code>ic.sample.generate</code>: Should the initial design be created
using a LHS? The default is <code>FALSE</code>, i.e. the initial design from
the feature object will be used.
</p>
</li>
<li><p><code>ic.sample.dimensions</code>: Dimensions of the initial sample,
if created using a LHS. The default is <code>feat.object$dimension</code>.
</p>
</li>
<li><p><code>ic.sample.size</code>: Size of the initial sample, if created
using a LHS. The default is <code>100 * feat.object$dimension</code>.
</p>
</li>
<li><p><code>ic.sample.lower</code>: Lower bounds of the initial sample, if
created with a LHS. The default is <code>100 * feat.object$lower</code>.
</p>
</li>
<li><p><code>ic.sample.upper</code>: Upper bounds of the initial sample, if
created with a LHS. The default is <code>100 * feat.object$upper</code>.
</p>
</li>
<li><p><code>ic.show_warnings</code>: Should warnings be shown, when
possible duplicates are removed? The default is <code>FALSE</code>.
</p>
</li>
<li><p><code>ic.seed</code>: Possible seed, which can be used for making
your experiments reproducable. Per default, a random number will be
drawn as seed.
</p>
</li>
<li><p><code>ic.nn.start</code>: Which observation should be used as
starting value, when exploring the landscape with the nearest
neighbour approach. The default is a randomly chosen integer value.
</p>
</li>
<li><p><code>ic.nn.neighborhood</code>: In order to provide a fast
computation of the features, we use <code>RANN::nn2</code> for computing
the nearest neighbors of an observation. Per default, we consider
the <code>20L</code> closest neighbors for finding the nearest
not-yet-visited observation. If all of those neighbors have been
visited already, we compute the distances to the remaining points
separately.
</p>
</li>
<li><p><code>ic.settling_sensitivity</code>: Threshold, which should be
used for computing the &ldquo;settling sensitivity&rdquo;. The default
is <code>0.05</code> (as used in the corresponding paper).
</p>
</li>
<li><p><code>ic.info_sensitivity</code>: Portion of partial information
sensitivity. The default is <code>0.5</code> (as used in the paper).
</p>
</li></ul>

</li>
<li><p>Plot Control: </p>

<ul>
<li><p><code>ic.plot.{xlim, ylim, las, xlab, ylab}</code>: Settings of the
plot in general, cf. <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.
</p>
</li>
<li><p><code>ic.plot.{xlab_line, ylab_line}</code>: Position of <code>xlab</code>
and <code>ylab</code>.
</p>
</li>
<li><p><code>ic.plot.ic.{lty, pch, cex, pch_col}</code>: Type, width and colour
of the line visualizing the &ldquo;Information Content&rdquo; <code class="reqn">H(\epsilon)</code>.
</p>
</li>
<li><p><code>ic.plot.max_ic.{lty, pch, lwd, cex, line_col, pch_col}</code>:
Type, size and colour of the line and point referring to the
&ldquo;Maximum Information Content&rdquo; <code class="reqn">H[max]</code>.
</p>
</li>
<li><p><code>ic.plot.settl_sens.{pch, cex, col}</code>:
Type, size and colour of the point referring to the
&ldquo;Settling Sensitivity&rdquo; <code class="reqn">\epsilon[s]</code>.
</p>
</li>
<li><p><code>ic.plot.partial_ic</code>: Should the information of the partial
information content be plotted as well? The default is <code>TRUE</code>.
</p>
</li>
<li><p><code>ic.plot.partial_ic.{lty, pch, lwd, cex, line_col, pch_col}</code>:
Type, size and colour of the line and point referring to the
&ldquo;Initial Partial Information&rdquo; <code class="reqn">M[0]</code> and the
&ldquo;Partial Information Content&rdquo; <code class="reqn">M(\epsilon)</code>.
</p>
</li>
<li><p><code>ic.plot.half_partial.{pch, cex, pch_col}</code>:
Type, size and colour of the point referring to the
&ldquo;Relative Partial Information Sensitivity&rdquo; <code class="reqn">\epsilon[ratio]</code>.
</p>
</li>
<li><p><code>ic.plot.half_partial.{lty, line_col, lwd}_{h, v}</code>:
Type, colour and width of the horizontal and vertical lines referring
to the &ldquo;Relative Partial Information Sensitivity&rdquo; <code class="reqn">\epsilon[ratio]</code>.
</p>
</li>
<li><p><code>ic.plot.half_partial.text_{cex, col}</code>:
Size and colour of the text at the horizontal line of the
&ldquo;Relative Partial Information Sensitivity&rdquo; <code class="reqn">\epsilon[ratio]</code>.
</p>
</li>
<li><p><code>ic.plot.legend_{descr, points, lines, location}</code>:
Description, points, lines and location of the legend.
</p>
</li></ul>

</li></ul>



<h3>Value</h3>

<p>[<code>plot</code>].<br />
A plot visualizing the Information Content Features.
</p>


<h3>References</h3>


<ul>
<li><p>Munoz, M. A., Kirley, M., and Halgamuge, S. K. (2015):
&ldquo;Exploratory Landscape Analysis of Continuous Space Optimization
Problems Using Information Content&rdquo;, in: IEEE Transactions on
Evolutionary Computation (19:1), pp. 74-87
(<a href="http://dx.doi.org/10.1109/TEVC.2014.2302006">http://dx.doi.org/10.1109/TEVC.2014.2302006</a>).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># (1) create a feature object:
X = t(replicate(n = 2000, expr = runif(n = 5, min = -10, max = 10)))
feat.object = createFeatureObject(X = X, fun = function(x) sum(x^2))

# (2) plot its information content features:
plotInformationContent(feat.object)
</code></pre>

<hr>
<h2 id='runFlaccoGUI'>Run the flacco-GUI based on Shiny</h2><span id='topic+runFlaccoGUI'></span>

<h3>Description</h3>

<p><code>runFlaccoGUI</code> starts a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a>
application, which allows the user to compute the flacco features and also visualize
the underlying functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runFlaccoGUI()
</code></pre>


<h3>Details</h3>

<p>A <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> application is a web-app
which can be accessed through a browser.
</p>


<h3>References</h3>


<ul>
<li><p>Hanster, C., and Kerschke, P. (2017):
&ldquo;flaccogui: Exploratory Landscape Analysis for Everyone&rdquo;,
in: Proceedings of the 19th Annual Conference on Genetic an
Evolutionary Computation (GECCO) Companion, pp. 1215-1222, ACM.
(<a href="http://dl.acm.org/citation.cfm?doid=3067695.3082477">http://dl.acm.org/citation.cfm?doid=3067695.3082477</a>).
</p>
</li>
<li><p>Kerschke, P., and Trautmann, H. (2019):
&ldquo;Comprehensive Feature-Based Landscape Analysis of Continuous
and Constrained Optimization Problems Using the R-package flacco&rdquo;,
in: Applications in Statistical Computing &ndash; From Music Data Analysis
to Industrial Quality Improvement, pp. 93-123, Springer.
(<a href="https://link.springer.com/chapter/10.1007/978-3-030-25147-5_7">https://link.springer.com/chapter/10.1007/978-3-030-25147-5_7</a>).
</p>
</li></ul>


<hr>
<h2 id='SmoofImport'>Shiny Server Function for BBOB Import Page Module</h2><span id='topic+SmoofImport'></span>

<h3>Description</h3>

<p><code>SmoofImport</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a>
server function which will control all aspects of the <code>SmoofImportPage</code>-UI Module.
It will be called with <code><a href="shiny.html#topic+callModule">callModule</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SmoofImport(input, output, session, stringsAsFactors)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SmoofImport_+3A_input">input</code></td>
<td>
<p>[<code>shiny-input</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> input variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="SmoofImport_+3A_output">output</code></td>
<td>
<p>[<code>shiny-output object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> output variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="SmoofImport_+3A_session">session</code></td>
<td>
<p>[<code>shiny-session object</code>]<br />
<a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> session variable for the specific UI module.</p>
</td></tr>
<tr><td><code id="SmoofImport_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>[<code><a href="base.html#topic+logical">logical</a>(1)</code>]<br />
How should strings be treated internally?</p>
</td></tr>
</table>

<hr>
<h2 id='SmoofImportPage'>Shiny UI-Module for Batch Import of Smoof Functions</h2><span id='topic+SmoofImportPage'></span>

<h3>Description</h3>

<p><code>SmoofImportPage</code> is a <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> UI-component which can be
added to your <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> app so that you get a batch import for a
specific <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> function but different parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SmoofImportPage(id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SmoofImportPage_+3A_id">id</code></td>
<td>
<p>[<code><a href="base.html#topic+character">character</a>(1)</code>]<br />
Character representing the <code>namespace</code> of the <a href="https://CRAN.R-project.org/package=shiny"><code>shiny</code></a> component.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It will load a CSV-file with parameters for the <a href="https://CRAN.R-project.org/package=smoof"><code>smoof</code></a> function
and calculate the selected features for the specific function.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
