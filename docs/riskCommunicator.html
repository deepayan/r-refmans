<!DOCTYPE html><html><head><title>Help for package riskCommunicator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {riskCommunicator}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cvdd'><p>A subset of the <code>framingham</code> teaching data</p></a></li>
<li><a href='#framingham'><p>The <code>framingham</code> data set</p></a></li>
<li><a href='#gComp'><p>Estimate difference and ratio effects with 95% confidence intervals.</p></a></li>
<li><a href='#get_results_dataframe'><p>Take predicted dataframe and calculate the outcome (risk difference/ratio,</p>
incidence rate difference/ratio, mean difference, and/or number needed to
treat)</a></li>
<li><a href='#make_predict_df'><p>Using <code>glm</code> results, predict outcomes for each individual at each level</p>
of treatment/exposure</a></li>
<li><a href='#plot.gComp'><p>Plot estimates of difference and ratio effects obtained in the bootstrap</p>
computations of the g-computation</a></li>
<li><a href='#pointEstimate'><p>Perform g-computation to estimate difference and ratio effects of an exposure</p></a></li>
<li><a href='#print.gComp'><p>Print estimates of difference and ratio effects obtained in the bootstrap</p>
computations of the g-computation</a></li>
<li><a href='#riskCommunicator'><p>riskCommunicator: Obtaining interpretable epidemiological effect</p>
estimates</a></li>
<li><a href='#summary.gComp'><p>Print a summary of a gComp class object.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>G-Computation to Estimate Interpretable Epidemiological Effects</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>boot, dplyr, ggplot2, ggpubr, magrittr, MASS, methods, purrr,
rlang, stats, tidyr, tidyselect</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimates flexible epidemiological effect measures including both differences and ratios using the parametric G-formula developed as an alternative to inverse probability weighting.  It is useful for estimating the impact of interventions in the presence of treatment-confounder-feedback. G-computation was originally described by Robbins (1986) &lt;<a href="https://doi.org/10.1016%2F0270-0255%2886%2990088-6">doi:10.1016/0270-0255(86)90088-6</a>&gt; and has been described in detail by Ahern, Hubbard, and Galea (2009) &lt;<a href="https://doi.org/10.1093%2Faje%2Fkwp015">doi:10.1093/aje/kwp015</a>&gt;; Snowden, Rose, and Mortimer (2011) &lt;<a href="https://doi.org/10.1093%2Faje%2Fkwq472">doi:10.1093/aje/kwq472</a>&gt;; and Westreich et al. (2012) &lt;<a href="https://doi.org/10.1002%2Fsim.5316">doi:10.1002/sim.5316</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, tidyverse, printr, stringr,
formatR, sandwich</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-31 21:06:05 UTC; JGrembi</td>
</tr>
<tr>
<td>Author:</td>
<td>Jessica Grembi <a href="https://orcid.org/0000-0001-6142-4913"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Elizabeth Rogawski McQuade
    <a href="https://orcid.org/0000-0002-4942-3747"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jessica Grembi &lt;jess.grembi@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-31 23:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cvdd'>A subset of the <code>framingham</code> teaching data</h2><span id='topic+cvdd'></span>

<h3>Description</h3>

<p>A subset of the <code>framingham</code> teaching dataset containing the following changes:
</p>

<ul>
<li><p>removal of all observations where PERIOD == 2 or PERIOD == 3 (i.e. keep only PERIOD == 1)
</p>
</li>
<li><p>removal of all observations where PREVCHD == 1 (i.e. all patients with coronary heart disease at baseline)
</p>
</li>
<li><p>created a new variable, <code>cvd_dth</code> signifying an outcome of cardiovascular disease OR death (i.e. if the patient had either CVD or DEATH, this new variable is 1, otherwise 0)
</p>
</li>
<li><p>created a new variable, <code>timeout</code>, which calculates the number of days from the start of the study to cardiovascular disease, death, or loss to follow-up
</p>
</li>
<li><p>created a new variable, <code>logpdays</code>, which is the log of <code>timeout</code>
</p>
</li>
<li><p>created a new variable, <code>nhosp</code>, which is a simulated number of hospitalizations
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(cvdd)
</code></pre>


<h3>Format</h3>

<p>A data frame with 4240 rows and 31 variables:
</p>

<dl>
<dt>RANDID</dt><dd><p>Unique identification number for each participant.</p>
</dd>
<dt>SEX</dt><dd><p>Participant sex. 0 = Male, 1 = Female.</p>
</dd>
<dt>TOTCHOL</dt><dd><p>Serum Total Cholesterol (mg/dL).</p>
</dd>
<dt>AGE</dt><dd><p>Age at exam (years).</p>
</dd>
<dt>SYSBP</dt><dd><p>Systolic Blood Pressure (mean of last two of three measurements) (mmHg).</p>
</dd>
<dt>DIABP</dt><dd><p>Diastolic Blood Pressure (mean of last two of three measurements) (mmHg).</p>
</dd>
<dt>CURSMOKE</dt><dd><p>Current cigarette smoking at exam. 0 = Not current smoker, 1 = Current smoker.</p>
</dd>
<dt>CIGPDAY</dt><dd><p>Number of cigarettes smoked each day. 0 = Not current smoker.</p>
</dd>
<dt>BMI</dt><dd><p>Body Mass Index, weight in kilograms/height meters squared.</p>
</dd>
<dt>DIABETES</dt><dd><p>Diabetic according to criteria of first exam treated or first exam with casual glucose of 200 mg/dL or more. 0 = Not a diabetic, 1 = Diabetic.</p>
</dd>
<dt>BPMEDS</dt><dd><p>Use of Anti-hypertensive medication at exam. 0 = Not currently used, 1 = Current use.</p>
</dd>
<dt>HEARTRTE</dt><dd><p>Heart rate (Ventricular rate) in beats/min.</p>
</dd>
<dt>GLUCOSE</dt><dd><p>Casual serum glucose (mg/dL).</p>
</dd>
<dt>educ</dt><dd><p>Level of completed education. 1 = 0-11 years, 2 = high school or GED, 3 = some college, 4 = college graduate or higher.</p>
</dd>
<dt>PREVSTRK</dt><dd><p>Prevalent Stroke. 0 = Free of disease, 1 = Prevalent disease.</p>
</dd>
<dt>PREVHYP</dt><dd><p>Prevalent Hypertensive. Subject was defined as hypertensive if treated or if second exam at which mean systolic was &gt;=140 mmHg or mean Diastolic &gt;=90 mmHg. 0 = Free of disease, 1 = Prevalent disease.</p>
</dd>
<dt>DEATH</dt><dd><p>Death from any cause. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>ANGINA</dt><dd><p>Angina Pectoris. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>HOSPMI</dt><dd><p>Hospitalized Myocardial Infarction. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>MI_FCHD</dt><dd><p>Hospitalized Myocardial Infarction or Fatal Coronary Heart Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>ANYCHD</dt><dd><p>Angina Pectoris, Myocardial infarction (Hospitalized and silent or unrecognized), Coronary Insufficiency (Unstable Angina), or Fatal Coronary Heart Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>STROKE</dt><dd><p>Atherothrombotic infarction, Cerebral Embolism, Intracerebral Hemorrhage, or Subarachnoid Hemorrhage or Fatal Cerebrovascular Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>CVD</dt><dd><p>Myocardial infarction (Hospitalized and silent or unrecognized), Fatal Coronary Heart Disease, Atherothrombotic infarction, Cerebral Embolism, Intracerebral Hemorrhage, or Subarachnoid Hemorrhage or Fatal Cerebrovascular Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>HYPERTEN</dt><dd><p>Hypertensive. Defined as the first exam treated for high blood pressure or second exam in which either Systolic is 6 140 mmHg or Diastolic 6 90mmHg. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>cvd_dth</dt><dd><p>Cardiovascular disease OR death. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>timeout</dt><dd><p>Number of days from the start of the study to cardiovascular disease, death, or loss to follow-up.</p>
</dd>
<dt>drop</dt><dd><p>Participant was lost to follow-up before 24 months complete followup. 0 = no, 1 = yes</p>
</dd>
<dt>glucoseyear6</dt><dd><p>Casual serum glucose (mg/dL) after 6 years of follow-up</p>
</dd>
<dt>logpdays</dt><dd><p>Natural log of <code>timeout</code>.</p>
</dd>
<dt>bmicat</dt><dd><p>BMI category. 0 = Normal, 1 = Underweight, 2 = Overweight, 3 = Obese.</p>
</dd>
<dt>nhosp</dt><dd><p>Simulated number of hospitalizations over 24 months, associated with age, sex, BMI, and diabetes (not collected in the Framingham study).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The National Heart, Lung, and Blood Institute of the National Institutes of 
Health developed a longitudinal, epidemiology-focused dataset using the Framingham 
Heart Study. The Framingham Heart Study is a long term prospective study of the 
etiology of cardiovascular disease among a population of free living subjects in 
the community of Framingham, Massachusetts. The Framingham Heart Study was a 
landmark study in epidemiology in that it was the first prospective study of 
cardiovascular disease and identified the concept of risk factors and their joint 
effects. The study began in 1948 and 5,209 subjects were initially enrolled in the 
study. Participants have been examined biennially since the inception of the study 
and all subjects are continuously followed through regular surveillance for 
cardiovascular outcomes. Clinic examination data has included cardiovascular disease 
risk factors and markers of disease such as blood pressure, blood chemistry, lung 
function, smoking history, health behaviors, ECG tracings, Echocardiography, and 
medication use. Through regular surveillance of area hospitals, participant contact, 
and death certificates, the Framingham Heart Study reviews and adjudicates events for 
the occurrence of Angina Pectoris, Myocardial Infarction, Heart Failure, and 
Cerebrovascular disease. This dataset contains three clinic examinations and 20 year 
follow-up data on a large subset of the original Framingham cohort participants.
</p>
<p>NOTE: This is a &quot;teaching&quot; dataset. Specific methods were employed to ensure an 
anonymous dataset that protects patient confidentiality; therefore, this dataset is 
inappropriate for publication purposes.&quot; The use of these data for the purposes of 
this package were approved on 11Mar2019 (request #7161) by NIH/NHLBI.
</p>


<h3>Source</h3>

<p><a href="https://biolincc.nhlbi.nih.gov/teaching/">https://biolincc.nhlbi.nih.gov/teaching/</a>
</p>

<hr>
<h2 id='framingham'>The <code>framingham</code> data set</h2><span id='topic+framingham'></span>

<h3>Description</h3>

<p>The Framingham Heart Study is a long term prospective study of the etiology of 
cardiovascular disease among a population of free living subjects in the community of Framingham, Massachusetts. The Framingham 
Heart Study was a landmark study in epidemiology in that it was the first prospective study of cardiovascular disease and 
identified the concept of risk factors and their joint effects. The study began in 1948 and 5,209 subjects were initially 
enrolled in the study. Participants have been examined biennially since the inception of the study and all subjects are 
continuously followed through regular surveillance for cardiovascular outcomes. Clinic examination data has included 
cardiovascular disease risk factors and markers of disease such as blood pressure, blood chemistry, lung function, smoking 
history, health behaviors, ECG tracings, Echocardiography, and medication use. Through regular surveillance of area hospitals,
participant contact, and death certificates, the Framingham Heart Study reviews and adjudicates events for the occurrence of 
Angina Pectoris, Myocardial Infarction, Heart Failure, and Cerebrovascular disease.
The enclosed dataset is a subset of the data collected as part of the Framingham study and includes laboratory, clinic, 
questionnaire, and adjudicated event data on 4,434 participants. Participant clinic data was collected during three examination 
periods, approximately 6 years apart, from roughly 1956 to 1968. Each participant was followed for a total of 24 years for the 
outcome of the following events: Angina Pectoris, Myocardial Infarction, Atherothrombotic Infarction or Cerebral Hemorrhage 
(Stroke) or death.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(framingham)
</code></pre>


<h3>Format</h3>

<p>A data frame with 11627 rows and 39 variables:
</p>

<dl>
<dt>RANDID</dt><dd><p>Unique identification number for each participant. Values range from 2448-999312.</p>
</dd>
<dt>SEX</dt><dd><p>Participant sex. 1 = Male (n = 5022), 2 = Female (n = 6605).</p>
</dd>
<dt>TOTCHOL</dt><dd><p>Serum Total Cholesterol (mg/dL). Values range from 107-696.</p>
</dd>
<dt>AGE</dt><dd><p>Age at exam (years). Values range from 32-81.</p>
</dd>
<dt>SYSBP</dt><dd><p>Systolic Blood Pressure (mean of last two of three measurements) (mmHg). Values range from 83.5-295. </p>
</dd>
<dt>DIABP</dt><dd><p>Diastolic Blood Pressure (mean of last two of three measurements) (mmHg). Values range from 30-150.</p>
</dd>
<dt>CURSMOKE</dt><dd><p>Current cigarette smoking at exam. 0 = Not current smoker (n = 6598), 1 = Current smoker (n = 5029).</p>
</dd>
<dt>CIGPDAY</dt><dd><p>Number of cigarettes smoked each day. 0 = Not current smoker. Values range from 0-90 cigarettes per day.</p>
</dd>
<dt>BMI</dt><dd><p>Body Mass Index, weight in kilograms/height meters squared. Values range from 14.43-56.8.</p>
</dd>
<dt>DIABETES</dt><dd><p>Diabetic according to criteria of first exam treated or first exam with casual glucose of 200 mg/dL or more. 0 = Not a diabetic (n = 11097), 1 = Diabetic (n = 530)</p>
</dd>
<dt>BPMEDS</dt><dd><p>Use of Anti-hypertensive medication at exam. 0 = Not currently used (n = 10090), 1 = Current use (n = 944).</p>
</dd>
<dt>HEARTRTE</dt><dd><p>Heart rate (Ventricular rate) in beats/min. Values range from 37-220.</p>
</dd>
<dt>GLUCOSE</dt><dd><p>Casual serum glucose (mg/dL). Values range from 39-478.</p>
</dd>
<dt>educ</dt><dd></dd> 
<dt>PREVCHD</dt><dd><p>Prevalent Coronary Heart Disease defined as pre-existing Angina Pectoris, Myocardial Infarction (hospitalized, silent or unrecognized), or Coronary Insufficiency (unstable angina). 0 = Free of disease (n = 10785), 1 = Prevalent disease (n = 842).</p>
</dd>
<dt>PREVAP</dt><dd><p>Prevalent Angina Pectoris at exam. 0 = Free of disease (n = 11000), 1 = Prevalent disease (n = 627).</p>
</dd>
<dt>PREVMI</dt><dd><p>Prevalent Myocardial Infarction. 0 = Free of disease (n = 11253), 1 = Prevalent disease (n = 374).</p>
</dd>
<dt>PREVSTRK</dt><dd><p>Prevalent Stroke. 0 = Free of disease (n = 11475), 1 = Prevalent disease (n = 152).</p>
</dd>
<dt>PREVHYP</dt><dd><p>Prevalent Hypertensive. Subject was defined as hypertensive if treated or if second exam at which mean systolic was &gt;=140 mmHg or mean Diastolic &gt;=90 mmHg. 0 = Free of disease (n = 6283), 1 = Prevalent disease (n = 5344).</p>
</dd>
<dt>TIME</dt><dd><p>Number of days since baseline exam. Values range from 0-4854</p>
</dd>
<dt>PERIOD</dt><dd><p>Examination Cycle. 1 = Period 1 (n = 4434), 2 = Period 2 (n = 3930), 3 = Period 3 (n = 3263)</p>
</dd>
<dt>HDLC</dt><dd><p>High Density Lipoprotein Cholesterol (mg/dL). Available for Period 3 only. Values range from 10-189.</p>
</dd>
<dt>LDLC</dt><dd><p>Low Density Lipoprotein Cholesterol (mg/dL). Available for Period 3 only. Values range from 20-565.</p>
</dd>
<dt>DEATH</dt><dd><p>Death from any cause. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>ANGINA</dt><dd><p>Angina Pectoris. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>HOSPMI</dt><dd><p>Hospitalized Myocardial Infarction. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>MI_FCHD</dt><dd><p>Hospitalized Myocardial Infarction or Fatal Coronary Heart Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>ANYCHD</dt><dd><p>Angina Pectoris, Myocardial infarction (Hospitalized and silent or unrecognized), Coronary Insufficiency (Unstable Angina), or Fatal Coronary Heart Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>STROKE</dt><dd><p>Atherothrombotic infarction, Cerebral Embolism, Intracerebral Hemorrhage, or Subarachnoid Hemorrhage or Fatal Cerebrovascular Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>CVD</dt><dd><p>Myocardial infarction (Hospitalized and silent or unrecognized), Fatal Coronary Heart Disease, Atherothrombotic infarction, Cerebral Embolism, Intracerebral Hemorrhage, or Subarachnoid Hemorrhage or Fatal Cerebrovascular Disease. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>HYPERTEN</dt><dd><p>Hypertensive. Defined as the first exam treated for high blood pressure or second exam in which either Systolic is 6 140 mmHg or Diastolic 6 90mmHg. 0 = Did not occur during followup, 1 = Did occur during followup.</p>
</dd>
<dt>TIMEAP</dt><dd><p>Number of days from Baseline exam to first Angina during the followup or Number of days from Baseline to censor date. Censor date may be end of followup, death or last known contact date if subject is lost to followup.</p>
</dd>
<dt>TIMEMI</dt><dd><p>Number of days from Baseline exam to first HOSPMI event during followup or Number of days from Baseline to censor date. Censor date may be end of followup, death or last known contact date if subject is lost to followup.</p>
</dd>
<dt>TIMEMIFC</dt><dd><p>Number of days from Baseline exam to first MI_FCHD event during followup or Number of days from Baseline to censor date. Censor date may be end of followup, death or last known contact date if subject is lost to followup.</p>
</dd>
<dt>TIMECHD</dt><dd><p>Number of days from Baseline exam to first ANYCHD event during followup or Number of days from Baseline to censor date. Censor date may be end of followup, death or last known contact date if subject is lost to followup.</p>
</dd>
<dt>TIMESTRK</dt><dd><p>Number of days from Baseline exam to first STROKE event during followup or Number of days from Baseline to censor date. Censor date may be end of followup, death or last known contact date if subject is lost to followup.</p>
</dd>
<dt>TIMECVD</dt><dd><p>Number of days from Baseline exam to first CVD event during followup or Number of days from Baseline to censor date. Censor date may be end of followup, death or last known contact date if subject is lost to followup.</p>
</dd>
<dt>TIMEDTH</dt><dd><p>Number of days from Baseline exam to death if occurring during followup or Number of days from Baseline to censor date. Censor date may be end of followup, or last known contact date if subject is lost to followup.</p>
</dd>
<dt>TIMEHYP</dt><dd><p>Number of days from Baseline exam to first HYPERTEN event during followup or Number of days from Baseline to censor date. Censor date may be end of followup, death or last known contact date if subject is lost to followup.</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset is the teaching dataset from the Framingham Heart Study (No. N01-HC-25195), provided with permission from #' the National Heart, Lung, and Blood Institute (NHLBI). The Framingham Heart Study is conducted and supported by the NHLBI in 
collaboration with Boston University. This package was not prepared in collaboration with investigators of the Framingham Heart 
Study and does not necessarily reflect the opinions or views of the Framingham Heart Study, Boston University, or NHLBI.
</p>

<hr>
<h2 id='gComp'>Estimate difference and ratio effects with 95% confidence intervals.</h2><span id='topic+gComp'></span>

<h3>Description</h3>

<p>Obtain a point estimate and 95% confidence interval for
difference and ratio effects comparing exposed and unexposed (or treatment and non-treatment)
groups using g-computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gComp(
  data,
  outcome.type = c("binary", "count", "count_nb", "rate", "rate_nb", "continuous"),
  formula = NULL,
  Y = NULL,
  X = NULL,
  Z = NULL,
  subgroup = NULL,
  offset = NULL,
  rate.multiplier = 1,
  exposure.scalar = 1,
  R = 200,
  clusterID = NULL,
  parallel = "no",
  ncpus = getOption("boot.ncpus", 1L)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gComp_+3A_data">data</code></td>
<td>
<p>(Required) A data.frame containing variables for
<code>Y</code>, <code>X</code>, and <code>Z</code> or with variables matching the model
variables specified in a user-supplied formula. Data set should also
contain variables for the optional <code>subgroup</code> and <code>offset</code>, if
they are specified.</p>
</td></tr>
<tr><td><code id="gComp_+3A_outcome.type">outcome.type</code></td>
<td>
<p>(Required) Character argument to describe the outcome
type. Acceptable responses, and the corresponding error distribution and
link function used in the <code>glm</code>, include: </p>

<dl>
<dt>binary</dt><dd><p>(Default) A binomial distribution with link = 'logit' is
used.</p>
</dd> 
<dt>count</dt><dd><p>A Poisson distribution with link = 'log' is used.</p>
</dd>
<dt>count_nb</dt><dd><p>A negative binomial model with link = 'log' is used, where the theta 
parameter is estimated internally; ideal for over-dispersed count data.</p>
</dd>
<dt>rate</dt><dd><p>A Poisson distribution with link = 'log' is used; ideal for 
events/person-time outcomes.</p>
</dd> 
<dt>rate_nb</dt><dd><p>A negative binomial model with link = 'log' is used, where the theta 
parameter is estimated internally; ideal for over-dispersed events/person-time outcomes.</p>
</dd>
<dt>continuous</dt><dd><p>A gaussian distribution with link = 'identity' is used.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="gComp_+3A_formula">formula</code></td>
<td>
<p>(Optional) Default NULL. An object of class &quot;formula&quot; (or one
that can be coerced to that class) which provides the the complete model
formula, similar to the formula for the glm function in R (e.g. 'Y ~ X + Z1
+ Z2 + Z3'). Can be supplied as a character or formula object. If no
formula is provided, Y and X must be provided.</p>
</td></tr>
<tr><td><code id="gComp_+3A_y">Y</code></td>
<td>
<p>(Optional) Default NULL. Character argument which specifies the
outcome variable. Can optionally provide a formula instead of <code>Y</code> and
<code>X</code> variables.</p>
</td></tr>
<tr><td><code id="gComp_+3A_x">X</code></td>
<td>
<p>(Optional) Default NULL. Character argument which specifies the
exposure variable (or treatment group assignment), which can be binary,
categorical, or continuous. This variable can be supplied as a factor
variable (for binary or categorical exposures) or a continuous variable.
For binary/categorical exposures, <code>X</code> should be supplied as a factor 
with the lowest level set to the desired referent. Numeric variables are 
accepted, but will be centered (see Note). Character variables are not 
accepted and will throw an error. Can optionally provide a formula
instead of <code>Y</code> and <code>X</code> variables.</p>
</td></tr>
<tr><td><code id="gComp_+3A_z">Z</code></td>
<td>
<p>(Optional) Default NULL. List or single character vector which
specifies the names of covariates or other variables to adjust for in the
<code>glm</code> function. All variables should either be factors, continuous, 
or coded 0/1 (i.e. not character variables). Does not allow interaction terms.</p>
</td></tr>
<tr><td><code id="gComp_+3A_subgroup">subgroup</code></td>
<td>
<p>(Optional) Default NULL. Character argument that indicates
subgroups for stratified analysis. Effects will be reported for each
category of the subgroup variable. Variable will be automatically converted
to a factor if not already.</p>
</td></tr>
<tr><td><code id="gComp_+3A_offset">offset</code></td>
<td>
<p>(Optional, only applicable for rate/count outcomes) Default NULL.
Character argument which specifies the variable name to be used as the 
person-time denominator for rate outcomes to be included as an offset in the
Poisson regression model. Numeric variable should be on the linear scale; 
function will take natural log before including in the model.</p>
</td></tr>
<tr><td><code id="gComp_+3A_rate.multiplier">rate.multiplier</code></td>
<td>
<p>(Optional, only applicable for rate/count outcomes). 
Default 1. Numeric variable signifying the person-time value to use in 
predictions; the offset variable will be set to this when predicting under 
the counterfactual conditions. This value should be set to the person-time 
denominator desired for the rate difference measure and must be inputted in 
the units of the original offset variable (e.g. if the offset variable is 
in days and the desired rate difference is the rate per 100 person-years, 
rate.multiplier should be inputted as 365.25*100).</p>
</td></tr>
<tr><td><code id="gComp_+3A_exposure.scalar">exposure.scalar</code></td>
<td>
<p>(Optional, only applicable for continuous exposure)
Default 1. Numeric value to scale effects with a continuous exposure. This 
option facilitates reporting effects for an interpretable contrast (i.e. 
magnitude of difference) within the continuous exposure. For example, if 
the continuous exposure is age in years, a multiplier of 10 would result 
in estimates per 10-year increase in age rather than per a 1-year increase 
in age.</p>
</td></tr>
<tr><td><code id="gComp_+3A_r">R</code></td>
<td>
<p>(Optional) Default 200. The number of data resamples to be conducted
to produce the bootstrap confidence interval of the estimate.</p>
</td></tr>
<tr><td><code id="gComp_+3A_clusterid">clusterID</code></td>
<td>
<p>(Optional) Default NULL. Character argument which specifies
the variable name for the unique identifier for clusters. This option
specifies that clustering should be accounted for in the calculation of
confidence intervals. The <code>clusterID</code> will be used as the level for
resampling in the bootstrap procedure.</p>
</td></tr>
<tr><td><code id="gComp_+3A_parallel">parallel</code></td>
<td>
<p>(Optional) Default &quot;no.&quot; The type of parallel operation to be used. Available 
options (besides the default of no parallel processing) include &quot;multicore&quot; (not available 
for Windows) or &quot;snow.&quot; This argument is passed directly to <code><a href="boot.html#topic+boot">boot</a></code>.
See note below about setting seeds and parallel computing.</p>
</td></tr>
<tr><td><code id="gComp_+3A_ncpus">ncpus</code></td>
<td>
<p>(Optional, only used if parallel is set to &quot;multicore&quot; or &quot;snow&quot;) Default 1. 
Integer argument for the number of CPUs available for parallel processing/ number of 
parallel operations to be used.  This argument is passed directly to <code><a href="boot.html#topic+boot">boot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>gComp</code> function executes the following steps: 
</p>

<ol>
<li><p> Calls the <code><a href="#topic+pointEstimate">pointEstimate</a></code> function on the data to obtain
the appropriate effect estimates (difference, ratio, etc.). 
</p>
</li>
<li><p> Generates <code>R</code> bootstrap resamples of the data, with replacement. If
the resampling is to be done at the cluster level (set using the
<code>clusterID</code> argument), the number of clusters will remain constant but
the total number of observations in each resampled data set might be
different if clusters are not balanced. 
</p>
</li>
<li><p> Calls the <code><a href="#topic+pointEstimate">pointEstimate</a></code> function on each of the resampled data sets.
</p>
</li>
<li><p> Calculates the 95% confidence interval of the difference and ratio
estimates using the results obtained from the <code>R</code> resampled parameter
estimates. </p>
</li></ol>
   
<p>As bootstrap resamples are generated with random sampling, users should
set a seed (<code><a href="base.html#topic+set.seed">set.seed</a></code> for reproducible
confidence intervals.
</p>
<p>While offsets are used to account for differences in follow-up time 
between individuals in the <code>glm</code> model, rate differences are 
calculated assuming equivalent follow-up of all individuals (i.e. 
predictions for each exposure are based on all observations having the 
same offset value). The default is 1 (specifying 1 unit of the original 
offset variable) or the user can specify an offset to be used in the 
predictions with the rate.multiplier argument.
</p>


<h3>Value</h3>

<p>An object of class <code>gComp</code> which is a named list with components:
</p>
<table>
<tr><td><code>$summary</code></td>
<td>
<p>Summary providing parameter estimates and 95% confidence
limits of the outcome difference and ratio (in a print-pretty format)</p>
</td></tr> 
<tr><td><code>$results.df</code></td>
<td>
<p>Data.frame with parameter estimates, 2.5% confidence 
limit, and 97.5% confidence limit each as a column (which can be used for easy 
incorporation into tables for publication)</p>
</td></tr> 
<tr><td><code>$n</code></td>
<td>
<p>Number of unique observations in the original dataset</p>
</td></tr> 
<tr><td><code>$R</code></td>
<td>
<p>Number of bootstrap iterations</p>
</td></tr>
<tr><td><code>$boot.result</code></td>
<td>
<p>Data.frame containing the results of the <code>R</code>
bootstrap iterations of the g-computation</p>
</td></tr> 
<tr><td><code>$contrast</code></td>
<td>
<p>Contrast levels compared</p>
</td></tr> 
<tr><td><code>$family</code></td>
<td>
<p>Error distribution used in the model</p>
</td></tr>
<tr><td><code>$formula</code></td>
<td>
<p>Model formula used to fit the <code>glm</code></p>
</td></tr>
<tr><td><code>$predicted.outcome</code></td>
<td>
<p>A data.frame with the marginal mean predicted outcomes 
(with 95% confidence limits) for each exposure level (i.e. under both exposed 
and unexposed counterfactual predictions)</p>
</td></tr>
<tr><td><code>$glm.result</code></td>
<td>
<p>The <code>glm</code> class object returned from the 
fitted regression of the outcome on the exposure and relevant covariates.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that for a protective exposure (risk difference less than 0), the 
'Number needed to treat/harm' is interpreted as the number needed to treat, 
and for a harmful exposure (risk difference greater than 0), it is 
interpreted as the number needed to harm. Note also that confidence intervals 
are not reported for the number needed to treat/harm. If the confidence 
interval (CI) for the risk difference crosses the null, the construction of 
the CI for the number needed to treat/harm is not well defined. Challenges 
and options for reporting the number needed to treat/harm CI are reviewed 
extensively in Altman 1998, Hutton 2000, and Stang 2010, with a consensus 
that an appropriate interval would have two segments, one bounded at negative 
infinity and the other at positive infinity. Because the number needed to 
treat/harm is most useful as a communication tool and is directly derived 
from the risk difference, which has a CI that provides a more interpretable 
measure of precision, we do not report the CI for the number needed to 
treat/harm. If the CI of the risk difference does not cross the null, the 
number needed to treat/harm CI can be calculated straightforwardly by 
taking the inverse of each confidence bound of the risk difference.
</p>
<p>For continuous exposure variables, the default effects are provided 
for a one unit difference in the exposure at the mean value of the exposure 
variable. Because the underlying parametric model for a binary outcome is 
logistic regression, the risks for a continuous exposure will be estimated 
to be linear on the log-odds (logit) scale, such that the odds ratio for 
any one unit increase in the continuous variable is constant. However, 
the risks will not be linear on the linear (risk difference) or log (risk 
ratio) scales, such that these parameters will not be constant across the 
range of the continuous exposure. Users should be aware that the risk 
difference, risk ratio, number needed to treat/harm (for a binary outcome) 
and the incidence rate difference (for a rate/count outcome) reported with 
a continuous exposure apply specifically at the mean of the continuous 
exposure. The effects do not necessarily apply across the entire range of 
the variable. However, variations in the effect are likely small, 
especially near the mean.
</p>
<p>Interaction terms are not allowed in the model formula. The <code>subgroup</code> 
argument affords interaction between the exposure variable and a single 
covariate (that is forced to categorical if supplied as numeric) to 
estimate effects of the exposure within subgroups defined by the 
interacting covariate. To include additional interaction terms with 
variables other than the exposure, we recommend that users create the 
interaction term as a cross-product of the two interaction variables in  
a data cleaning step prior to running the model.
</p>
<p>The documentation for <code><a href="boot.html#topic+boot">boot</a></code> includes details about 
reproducible seeds when using parallel computing.
</p>


<h3>References</h3>

<p>Ahern J, Hubbard A, Galea S. Estimating the effects of potential public health 
interventions on population disease burden: a step-by-step illustration of 
causal inference methods. Am. J. Epidemiol. 2009;169(9):1140–1147.
<a href="https://doi.org/10.1093/aje/kwp015">doi:10.1093/aje/kwp015</a>
</p>
<p>Altman DG, Deeks JJ, Sackett DL. Odds ratios should be avoided when events 
are common. BMJ. 1998;317(7168):1318. <a href="https://doi.org/10.1136/bmj.317.7168.1318">doi:10.1136/bmj.317.7168.1318</a>
</p>
<p>Hernán MA, Robins JM (2020). Causal Inference: What If. Boca Raton: 
Chapman &amp; Hall/CRC. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">Book link</a>
</p>
<p>Hutton JL. Number needed to treat: properties and problems. Journal of the 
Royal Statistical Society: Series A (Statistics in Society). 2000;163(3):381–402.
<a href="https://doi.org/10.1111/1467-985X.00175">doi:10.1111/1467-985X.00175</a>
</p>
<p>Robins J. A new approach to causal inference in mortality studies with a 
sustained exposure period—application to control of the healthy worker 
survivor effect. Mathematical Modelling. 1986;7(9):1393–1512. <a href="https://doi.org/10.1016/0270-0255%2886%2990088-6">doi:10.1016/0270-0255(86)90088-6</a>
</p>
<p>Snowden JM, Rose S, Mortimer KM. Implementation of G-computation on a 
simulated data set: demonstration of a causal inference technique. 
Am. J. Epidemiol. 2011;173(7):731–738. <a href="https://doi.org/10.1093/aje/kwq472">doi:10.1093/aje/kwq472</a>
</p>
<p>Stang A, Poole C, Bender R. Common problems related to the use of number 
needed to treat. Journal of Clinical Epidemiology. 2010;63(8):820–825. 
<a href="https://doi.org/10.1016/j.jclinepi.2009.08.006">doi:10.1016/j.jclinepi.2009.08.006</a>
</p>
<p>Westreich D, Cole SR, Young JG, et al. The parametric g-formula to 
estimate the effect of highly active antiretroviral therapy on incident 
AIDS or death. Stat Med. 2012;31(18):2000–2009. <a href="https://doi.org/10.1002/sim.5316">doi:10.1002/sim.5316</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pointEstimate">pointEstimate</a></code> <code><a href="boot.html#topic+boot">boot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtain the risk difference and risk ratio for cardiovascular disease or death between
## patients with and without diabetes.
data(cvdd)
set.seed(538)
diabetes &lt;- gComp(cvdd, formula = "cvd_dth ~ DIABETES + AGE + SEX + BMI + CURSMOKE + PREVHYP",
outcome.type = "binary", R = 20)

</code></pre>

<hr>
<h2 id='get_results_dataframe'>Take predicted dataframe and calculate the outcome (risk difference/ratio,
incidence rate difference/ratio, mean difference, and/or number needed to
treat)</h2><span id='topic+get_results_dataframe'></span>

<h3>Description</h3>

<p>Take predicted dataframe and calculate the outcome (risk difference/ratio,
incidence rate difference/ratio, mean difference, and/or number needed to
treat)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_results_dataframe(predict.df, outcome.type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_results_dataframe_+3A_predict.df">predict.df</code></td>
<td>
<p>(Required) A data.frame output from the
<code>make_predict_df</code> function with predicted outcome for each observation
at each level of treatment/exposure.</p>
</td></tr>
<tr><td><code id="get_results_dataframe_+3A_outcome.type">outcome.type</code></td>
<td>
<p>(Required) Character argument to describe the outcome
type. Acceptable responses, and the corresponding error distribution and
link function used in the <code>glm</code>, include: </p>

<dl>
<dt>binary</dt><dd><p>(Default) A binomial distribution with link = 'logit' is
used.</p>
</dd> 
<dt>count</dt><dd><p>A Poisson distribution with link = 'log' is used.</p>
</dd>
<dt>count_nb</dt><dd><p>A negative binomial model with link = 'log' is used, where the theta 
parameter is estimated internally; ideal for over-dispersed count data.</p>
</dd>
<dt>rate</dt><dd><p>A Poisson distribution with link = 'log' is used; ideal for 
events/person-time outcomes.</p>
</dd> 
<dt>rate_nb</dt><dd><p>A negative binomial model with link = 'log' is used, where the theta 
parameter is estimated internally; ideal for over-dispersed events/person-time outcomes.</p>
</dd>
<dt>continuous</dt><dd><p>A gaussian distribution with link = 'identity' is used.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the calculated results for the applicable measures
(based on the outcome.type): Risk Difference, Risk Ratio, Odds Ratio,
Incidence Risk Difference, Incidence Risk Ratio, Mean Difference, Number
Needed to Treat, Average Tx (average predicted outcome of all observations with 
treatment/exposure), and Average noTx (average predicted outcome of all 
observations without treatment/exposure)
</p>

<hr>
<h2 id='make_predict_df'>Using <code>glm</code> results, predict outcomes for each individual at each level
of treatment/exposure</h2><span id='topic+make_predict_df'></span>

<h3>Description</h3>

<p>Using <code>glm</code> results, predict outcomes for each individual at each level
of treatment/exposure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_predict_df(
  glm.res,
  df,
  X,
  subgroup = NULL,
  offset = NULL,
  rate.multiplier = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_predict_df_+3A_glm.res">glm.res</code></td>
<td>
<p>(Required) A fitted object of class inheriting from &quot;glm&quot; that
will be used with new dataset for prediciton.</p>
</td></tr>
<tr><td><code id="make_predict_df_+3A_df">df</code></td>
<td>
<p>(Required) A new data frame in which to look for variables with
which to predict. This is equivalent to the <code>newdata</code> argument in
predict.glm.</p>
</td></tr>
<tr><td><code id="make_predict_df_+3A_x">X</code></td>
<td>
<p>(Required) Character argument which provides variable identifying
exposure/treatment group assignment.</p>
</td></tr>
<tr><td><code id="make_predict_df_+3A_subgroup">subgroup</code></td>
<td>
<p>(Optional) Default NULL. Character argument of the variable
name to use for subgroup analyses. Variable automatically transformed to a
factor within the function if not supplied as such.</p>
</td></tr>
<tr><td><code id="make_predict_df_+3A_offset">offset</code></td>
<td>
<p>(Optional, only applicable for rate/count outcomes) Default NULL.
Character argument which specifies the variable name to be used as the 
person-time denominator for rate outcomes to be included as an offset in the
Poisson regression model. Numeric variable should be on the linear scale; 
function will take natural log before including in the model.</p>
</td></tr>
<tr><td><code id="make_predict_df_+3A_rate.multiplier">rate.multiplier</code></td>
<td>
<p>(Optional, only applicable for rate/count outcomes). 
Default 1 Numeric variable signifying the person-time value to use in 
predictions; the offset variable will be set to this when predicting under 
the counterfactual conditions. This value should be set to the person-time 
denominator desired for the rate difference measure and must be inputted in 
the units of the original offset variable (e.g. if the offset variable is 
in days and the desired rate difference is the rate per 100 person-years, 
rate.multiplier should be inputted as 365.25*100).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame of predicted outcomes for each level of
treatment/exposure.  Additional columns are provided for each subgroup
*x*treatment, if specified.
</p>

<hr>
<h2 id='plot.gComp'>Plot estimates of difference and ratio effects obtained in the bootstrap
computations of the g-computation</h2><span id='topic+plot.gComp'></span>

<h3>Description</h3>

<p>Plot histograms and Q-Q plots for each the difference and ratio
estimates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gComp'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gComp_+3A_x">x</code></td>
<td>
<p>(Required) An object of class <code>gComp</code>.</p>
</td></tr>
<tr><td><code id="plot.gComp_+3A_...">...</code></td>
<td>
<p>(Optional) additional arguments to be supplied to the
'<code>geom_histogram</code> call (e.g. to adjust binwidth for histogram, assign
colors, etc.).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a plot containing histograms and Q-Q plots of the difference and
ratio estimates returned from R bootstrap iterations
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtain the risk difference and risk ratio for cardiovascular disease or death
## between patients with and without diabetes, while controlling for
## age,
## sex,
## BMI,
## whether the individual is currently a smoker, and
## if they have a history of hypertension.
data(cvdd)
set.seed(58)
diabetes.result &lt;- gComp(data = cvdd, Y = "cvd_dth", X = "DIABETES",
Z = c("AGE", "SEX", "BMI", "CURSMOKE", "PREVHYP"), outcome.type = "binary", R = 60)
plot(diabetes.result)

</code></pre>

<hr>
<h2 id='pointEstimate'>Perform g-computation to estimate difference and ratio effects of an exposure</h2><span id='topic+pointEstimate'></span>

<h3>Description</h3>

<p>Generate a point estimate of the outcome difference and ratio
using G-computation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pointEstimate(
  data,
  outcome.type = c("binary", "count", "count_nb", "rate", "rate_nb", "continuous"),
  formula = NULL,
  Y = NULL,
  X = NULL,
  Z = NULL,
  subgroup = NULL,
  offset = NULL,
  rate.multiplier = 1,
  exposure.scalar = 1,
  exposure.center = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pointEstimate_+3A_data">data</code></td>
<td>
<p>(Required) A data.frame containing variables for
<code>Y</code>, <code>X</code>, and <code>Z</code> or with variables matching the model
variables specified in a user-supplied formula. Data set should also
contain variables for the optional <code>subgroup</code> and <code>offset</code>, if
they are specified.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_outcome.type">outcome.type</code></td>
<td>
<p>(Required) Character argument to describe the outcome
type. Acceptable responses, and the corresponding error distribution and
link function used in the <code>glm</code>, include: </p>

<dl>
<dt>binary</dt><dd><p>(Default) A binomial distribution with link = 'logit' is
used.</p>
</dd> 
<dt>count</dt><dd><p>A Poisson distribution with link = 'log' is used.</p>
</dd>
<dt>count_nb</dt><dd><p>A negative binomial model with link = 'log' is used, where the theta 
parameter is estimated internally; ideal for over-dispersed count data.</p>
</dd>
<dt>rate</dt><dd><p>A Poisson distribution with link = 'log' is used; ideal for 
events/person-time outcomes.</p>
</dd> 
<dt>rate_nb</dt><dd><p>A negative binomial model with link = 'log' is used, where the theta 
parameter is estimated internally; ideal for over-dispersed events/person-time outcomes.</p>
</dd>
<dt>continuous</dt><dd><p>A gaussian distribution with link = 'identity' is used.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="pointEstimate_+3A_formula">formula</code></td>
<td>
<p>(Optional) Default NULL. An object of class &quot;formula&quot; (or one
that can be coerced to that class) which provides the the complete model
formula, similar to the formula for the glm function in R (e.g. 'Y ~ X + Z1
+ Z2 + Z3'). Can be supplied as a character or formula object. If no
formula is provided, Y and X must be provided.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_y">Y</code></td>
<td>
<p>(Optional) Default NULL. Character argument which specifies the
outcome variable. Can optionally provide a formula instead of <code>Y</code> and
<code>X</code> variables.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_x">X</code></td>
<td>
<p>(Optional) Default NULL. Character argument which specifies the
exposure variable (or treatment group assignment), which can be binary,
categorical, or continuous. This variable can be supplied as a factor
variable (for binary or categorical exposures) or a continuous variable.
For binary/categorical exposures, <code>X</code> should be supplied as a factor 
with the lowest level set to the desired referent. Numeric variables are 
accepted, but will be centered (see Note). Character variables are not 
accepted and will throw an error. Can optionally provide a formula
instead of <code>Y</code> and <code>X</code> variables.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_z">Z</code></td>
<td>
<p>(Optional) Default NULL. List or single character vector which
specifies the names of covariates or other variables to adjust for in the
<code>glm</code> function. All variables should either be factors, continuous, 
or coded 0/1 (i.e. not character variables). Does not allow interaction terms.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_subgroup">subgroup</code></td>
<td>
<p>(Optional) Default NULL. Character argument that indicates
subgroups for stratified analysis. Effects will be reported for each
category of the subgroup variable. Variable will be automatically converted
to a factor if not already.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_offset">offset</code></td>
<td>
<p>(Optional, only applicable for rate/count outcomes) Default NULL.
Character argument which specifies the variable name to be used as the 
person-time denominator for rate outcomes to be included as an offset in the
Poisson regression model. Numeric variable should be on the linear scale; 
function will take natural log before including in the model.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_rate.multiplier">rate.multiplier</code></td>
<td>
<p>(Optional, only applicable for rate/count outcomes). 
Default 1. Numeric variable signifying the person-time value to use in 
predictions; the offset variable will be set to this when predicting under 
the counterfactual conditions. This value should be set to the person-time 
denominator desired for the rate difference measure and must be inputted in 
the units of the original offset variable (e.g. if the offset variable is 
in days and the desired rate difference is the rate per 100 person-years, 
rate.multiplier should be inputted as 365.25*100).</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_exposure.scalar">exposure.scalar</code></td>
<td>
<p>(Optional, only applicable for continuous exposure)
Default 1. Numeric value to scale effects with a continuous exposure. This 
option facilitates reporting effects for an interpretable contrast (i.e. 
magnitude of difference) within the continuous exposure. For example, if 
the continuous exposure is age in years, a multiplier of 10 would result 
in estimates per 10-year increase in age rather than per a 1-year increase 
in age.</p>
</td></tr>
<tr><td><code id="pointEstimate_+3A_exposure.center">exposure.center</code></td>
<td>
<p>(Optional, only applicable for continuous exposure)
Default TRUE. Logical or numeric value to center a continuous exposure. This
option facilitates reporting effects at the mean value of the exposure 
variable, and allows for a mean value to be provided directly to the function
in cases where bootstrap resampling is being conducted and a standardized 
centering value should be used across all bootstraps. See note below on 
continuous exposure variables for additional details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>pointEstimate</code> function executes the following steps on
the data: 
</p>
 
<ol>
<li><p> Fit a regression of the outcome on the exposure
and relevant covariates, using the provided data set. 
</p>
</li>
<li><p> Using the model fit in step 1, predict counterfactuals (e.g. 
calculate predicted outcomes for each observation in the data set under 
each level of the treatment/exposure). 
</p>
</li>
<li><p> Estimate the marginal difference/ratio of treatment effect by 
taking the difference or ratio of the average of all observations under 
the treatment/no treatment regimes. 
</p>
</li></ol>

<p>As counterfactual predictions are generated with random sampling of the
distribution, users should set a seed (<code><a href="base.html#topic+set.seed">set.seed</a></code>) prior to 
calling the function for reproducible confidence intervals.
</p>


<h3>Value</h3>

<p>A named list containing the following: 
</p>
<table>
<tr><td><code>$parameter.estimates</code></td>
<td>
<p>Point estimates for the risk difference, risk
ratio, odds ratio, incidence rate difference, incidence rate ratio, mean
difference and/or number needed to treat/harm, depending on the outcome.type</p>
</td></tr>
<tr><td><code>$formula</code></td>
<td>
<p>Model formula used to fit the <code>glm</code></p>
</td></tr>    
<tr><td><code>$contrast</code></td>
<td>
<p>Contrast levels compared</p>
</td></tr> 
<tr><td><code>$Y</code></td>
<td>
<p>The response variable</p>
</td></tr> 
<tr><td><code>$covariates</code></td>
<td>
<p>Covariates used in the model</p>
</td></tr> 
<tr><td><code>$n</code></td>
<td>
<p>Number of observations provided to the model</p>
</td></tr> 
<tr><td><code>$family</code></td>
<td>
<p>Error distribution used in the model</p>
</td></tr> 
<tr><td><code>$predicted.data</code></td>
<td>
<p>A data.frame with the predicted values for the exposed 
and unexposed counterfactual predictions for each observation in the original 
dataset (on the log scale)</p>
</td></tr> 
<tr><td><code>$predicted.outcome</code></td>
<td>
<p>A data.frame with the marginal mean
predicted outcomes for each exposure level</p>
</td></tr> 
<tr><td><code>$glm.result</code></td>
<td>
<p>The <code>glm</code> class object returned from the 
fitted regression of the outcome on the exposure and relevant covariates.</p>
</td></tr> 
</table>
<p>formula = formula,
</p>


<h3>Note</h3>

<p>While offsets are used to account for differences in follow-up time 
between individuals in the <code>glm</code> model, rate differences are 
calculated assuming equivalent follow-up of all individuals (i.e. 
predictions for each exposure are based on all observations having the 
same offset value). The default is 1 (specifying 1 unit of the original 
offset variable) or the user can specify an offset to be used in the 
predictions with the rate.multiplier argument.
</p>
<p>Note that for a protective exposure (risk difference less than 0), the 
'Number needed to treat/harm' is interpreted as the number needed to treat, 
and for a harmful exposure (risk difference greater than 0), it is 
interpreted as the number needed to harm.
</p>
<p>For continuous exposure variables, the default effects are provided 
for a one unit difference in the exposure at the mean value of the exposure 
variable. Because the underlying parametric model for a binary outcome is 
logistic regression, the risks for a continuous exposure will be estimated 
to be linear on the log-odds (logit) scale, such that the odds ratio for 
any one unit increase in the continuous variable is constant. However, 
the risks will not be linear on the linear (risk difference) or log (risk 
ratio) scales, such that these parameters will not be constant across the 
range of the continuous exposure. Users should be aware that the risk 
difference, risk ratio, number needed to treat/harm (for a binary outcome) 
and the incidence rate difference (for a rate/count outcome) reported with 
a continuous exposure apply specifically at the mean of the continuous 
exposure. The effects do not necessarily apply across the entire range of 
the variable. However, variations in the effect are likely small, 
especially near the mean.
</p>
<p>@note       
Interaction terms are not allowed in the model formula. The <code>subgroup</code> 
argument affords interaction between the exposure variable and a single 
covariate (that is forced to categorical if supplied as numeric) to 
estimate effects of the exposure within subgroups defined by the 
interacting covariate. To include additional interaction terms with 
variables other than the exposure, we recommend that users create the 
interaction term as a cross-product of the two interaction variables in  
a data cleaning step prior to running the model.
</p>
<p>@note 
For negative binomial models, <code>MASS::glm.nb</code> is used instead of the
standard <code>stats::glm</code> function used for all other models.
</p>


<h3>References</h3>

<p>Ahern J, Hubbard A, Galea S. Estimating the effects of potential public health 
interventions on population disease burden: a step-by-step illustration of 
causal inference methods. Am. J. Epidemiol. 2009;169(9):1140–1147.
<a href="https://doi.org/10.1093/aje/kwp015">doi:10.1093/aje/kwp015</a>
</p>
<p>Altman DG, Deeks JJ, Sackett DL. Odds ratios should be avoided when events 
are common. BMJ. 1998;317(7168):1318. <a href="https://doi.org/10.1136/bmj.317.7168.1318">doi:10.1136/bmj.317.7168.1318</a>
</p>
<p>Hernán MA, Robins JM (2020). Causal Inference: What If. Boca Raton: 
Chapman &amp; Hall/CRC. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">Book link</a>
</p>
<p>Robins J. A new approach to causal inference in mortality studies with a 
sustained exposure period—application to control of the healthy worker 
survivor effect. Mathematical Modelling. 1986;7(9):1393–1512. <a href="https://doi.org/10.1016/0270-0255%2886%2990088-6">doi:10.1016/0270-0255(86)90088-6</a>
</p>
<p>Snowden JM, Rose S, Mortimer KM. Implementation of G-computation on a 
simulated data set: demonstration of a causal inference technique. 
Am. J. Epidemiol. 2011;173(7):731–738. <a href="https://doi.org/10.1093/aje/kwq472">doi:10.1093/aje/kwq472</a>
</p>
<p>Westreich D, Cole SR, Young JG, et al. The parametric g-formula to 
estimate the effect of highly active antiretroviral therapy on incident 
AIDS or death. Stat Med. 2012;31(18):2000–2009. <a href="https://doi.org/10.1002/sim.5316">doi:10.1002/sim.5316</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gComp">gComp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtain the risk difference and risk ratio for cardiovascular disease or death
## between patients with and without diabetes, while controlling for
## age,
## sex,
## BMI,
## whether the individual is currently a smoker, and
## if they have a history of hypertension.
data(cvdd)
ptEstimate &lt;- pointEstimate(data = cvdd, Y = "cvd_dth", X = "DIABETES",
Z = c("AGE", "SEX", "BMI", "CURSMOKE", "PREVHYP"), outcome.type = "binary")

</code></pre>

<hr>
<h2 id='print.gComp'>Print estimates of difference and ratio effects obtained in the bootstrap
computations of the g-computation</h2><span id='topic+print.gComp'></span>

<h3>Description</h3>

<p>Print results from bootstrap computations of the g-computation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gComp'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.gComp_+3A_x">x</code></td>
<td>
<p>(Required) An object of class <code>gComp</code> as produced by <code>gComp()</code>.</p>
</td></tr>
<tr><td><code id="print.gComp_+3A_...">...</code></td>
<td>
<p>(Optional) Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the formula and resulting point estimate and 95% 
confidence intervals of the difference and ratio.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtain the risk difference and risk ratio for cardiovascular disease or 
## death between patients with and without diabetes, while controlling for
## age, sex, BMI, whether the individual is currently a smoker, and 
## if they have a history of hypertension.
data(cvdd)
set.seed(4832)
diabetes.result &lt;- gComp(cvdd, 
   formula = "cvd_dth ~ DIABETES + AGE + SEX + BMI + CURSMOKE + PREVHYP",
   outcome.type = "binary", R = 20)
print(diabetes.result)


</code></pre>

<hr>
<h2 id='riskCommunicator'>riskCommunicator: Obtaining interpretable epidemiological effect
estimates</h2><span id='topic+riskCommunicator'></span>

<h3>Description</h3>

<p><code>riskCommunicator</code> is a package for estimating flexible epidemiological
effect measures including both differences and ratios. The package is based
on the parametric G-formula (g-computation with parametric models) developed
by Robbins et. al. in 1986 as an alternative to inverse probability weighting.  
It is useful for estimating the impact of interventions in the presence of 
treatment-confounder-feedback and is a powerful tool for causal inference, 
but has seen limited success due to lack of software for the computationally 
intensive components. This package provides three main functions.  
The first, <code>pointEstimate</code>, obtains a point estimate of the difference 
and ratio effect estimates. This function is typically called within the 
<code>gComp</code> function, but is available for use in special cases for example 
when the user requires more explicit control over bootstrap resampling 
(e.g. nested clusters). The second function, <code>gComp</code>, is the workhorse 
function that obtains point estimates for difference and ratio effects along 
with their 95/
to visualize the bootstrap results. We provide the <code>framingham</code> dataset, 
which is the teaching dataset from the Framingham Heart Study, as well as a 
subset of that data, <code>cvdd</code> for users.
</p>


<h3>References</h3>

<p>Robins, James. 1986. “A New Approach To Causal Inference in
Mortality Studies with a Sustained Exposure Period - Application To Control
of the Healthy Worker Survivor Effect.” Mathematical Modelling 7: 1393–1512.
doi:10.1016/0270-0255(86)90088-6.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gComp">gComp</a></code>
</p>
<p><code><a href="#topic+pointEstimate">pointEstimate</a></code>
</p>
<p><code><a href="#topic+plot.gComp">plot.gComp</a></code>
</p>

<hr>
<h2 id='summary.gComp'>Print a summary of a gComp class object.</h2><span id='topic+summary.gComp'></span><span id='topic+print.summary.gComp'></span>

<h3>Description</h3>

<p>Takes a <code>gComp</code> object produced by <code>gComp()</code> and 
produces various useful summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gComp'
summary(object, ...)

## S3 method for class 'summary.gComp'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.gComp_+3A_object">object</code></td>
<td>
<p>(Required) An object of class <code>gComp</code> as produced by <code>gComp()</code>.</p>
</td></tr>
<tr><td><code id="summary.gComp_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.gComp_+3A_x">x</code></td>
<td>
<p>(Required) An object of class <code>summary.gComp</code> as produced by <code>summary.gComp()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the formula, family (with link function), contrast evaluated, resulting  
point estimate and 95% confidence intervals of the parameters estimated, and the  
underlying glm used for model predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtain the risk difference and risk ratio for cardiovascular disease or 
## death between patients with and without diabetes, while controlling for
## age, sex, BMI, whether the individual is currently a smoker, and 
## if they have a history of hypertension.
data(cvdd)
set.seed(4832)
diabetes.result &lt;- gComp(cvdd, 
   formula = "cvd_dth ~ DIABETES + AGE + SEX + BMI + CURSMOKE + PREVHYP",
   outcome.type = "binary", R = 20)
summary(diabetes.result)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
