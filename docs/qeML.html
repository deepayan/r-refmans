<!DOCTYPE html><html><head><title>Help for package qeML</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {qeML}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Advanced Plots'><p>Advanced Plots</p></a></li>
<li><a href='#CancerMenopause'>
<p>Swedish breast cancer.</p></a></li>
<li><a href='#courseRecords'>
<p>Records from several offerings of a certain course.</p></a></li>
<li><a href='#currency'>
<p>Pre-Euro Era Currency Fluctuations</p></a></li>
<li><a href='#day,day1'>
<p>Bike sharing data.</p></a></li>
<li><a href='#Double Descent'><p>Double Descent Phenomenon</p></a></li>
<li><a href='#empAttrition'>
<p>Employee Attrition Data</p></a></li>
<li><a href='#english'>
<p>English vocabulary data</p></a></li>
<li><a href='#EPI GrowthData'>
<p>EPI Growth Data</p></a></li>
<li><a href='#Feature Model Select'><p>Feature Selection and Model Building</p></a></li>
<li><a href='#forest500'>
<p>Subset of the Covertype data.</p></a></li>
<li><a href='#iranChurn'>
<p>Iranian Customer Churn Data</p></a></li>
<li><a href='#lsa'>
<p>Law School Admissions Data</p></a></li>
<li><a href='#ltrfreqs'>
<p>Letter Frequencies</p></a></li>
<li><a href='#mlb'>
<p>Major Leage Baseball player data set.</p></a></li>
<li><a href='#mlens'>
<p>MovieLens User Summary Data</p></a></li>
<li><a href='#newadult'>
<p>UCI adult income data set, adapted</p></a></li>
<li><a href='#nyctaxi'>
<p>New York City Taxi Data</p></a></li>
<li><a href='#oliveoils'>
<p>Italian olive oils data set.</p></a></li>
<li><a href='#Prediction with Missing Values'><p>Prediction with Missing Values</p></a></li>
<li><a href='#prgeng'>
<p>Silicon Valley programmers and engineers data</p></a></li>
<li><a href='#qe-Series Predictive Functions'><p>Quick-and-Easy Machine Learning Wrappers</p></a></li>
<li><a href='#quizDocs'>
<p>Course quiz documents</p></a></li>
<li><a href='#R Factor Utilities'><p>R Factor Utilities</p></a></li>
<li><a href='#ThyroidDisease'>
<p>Thyroid Disease</p></a></li>
<li><a href='#Utilities'><p>Utilities</p></a></li>
<li><a href='#Variable Importance Measures'><p>Variable Importance Measures</p></a></li>
<li><a href='#weatherTS'>
<p>Weather Time Series</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Quick and Easy Machine Learning Tools</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Norm Matloff &lt;nsmatloff@ucdavis.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0),regtools (&ge; 0.8.0),gtools,rmarkdown,tufte</td>
</tr>
<tr>
<td>Imports:</td>
<td>grf,gbm,toweranNA,tm,rpart,rpart.plot,partools,FOCI</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr,partykit,randomForest,ranger,e1071,JOUSBoost,lightgbm,
keras,neuralnet,polyreg,glmnet,umap,reticulate,party,pROC,xgboost,ROCR,
autoimage,deepnet,ncvreg,uwot,cdparcoord</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Description:</td>
<td>The letters 'qe' in the package title stand for "quick and
   easy," alluding to the convenience goal of the package. We bring
   together a variety of machine learning (ML) tools from standard R
   packages, providing wrappers with a simple, convenient, 
   and uniform interface.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/matloff/qeML">https://github.com/matloff/qeML</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/matloff/qeML/issues">https://github.com/matloff/qeML/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-26 01:10:13 UTC; normanmatloff</td>
</tr>
<tr>
<td>Author:</td>
<td>Norm Matloff <a href="https://orcid.org/0000-0001-9179-6785"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Advanced+20Plots'>Advanced Plots</h2><span id='topic+plotPairedResids'></span><span id='topic+plotClassesUMAP'></span><span id='topic+qeFreqParcoord'></span>

<h3>Description</h3>

<p>Miscellaneous specialized plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPairedResids(data,qeOut) 
plotClassesUMAP(data,classVar) 
qeFreqParcoord(dataName,k=25,opts=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Advanced+2B20Plots_+3A_data">data</code></td>
<td>
<p>A data frame or equivalent.</p>
</td></tr>
<tr><td><code id="Advanced+2B20Plots_+3A_qeout">qeOut</code></td>
<td>
<p>An object returned from one of the qe-series
predictive functions..</p>
</td></tr>
<tr><td><code id="Advanced+2B20Plots_+3A_classvar">classVar</code></td>
<td>
<p>Name of the column containing class information.</p>
</td></tr>
<tr><td><code id="Advanced+2B20Plots_+3A_dataname">dataName</code></td>
<td>
<p>Quoted name of a data frame.</p>
</td></tr>
<tr><td><code id="Advanced+2B20Plots_+3A_k">k</code></td>
<td>
<p>Number of nearest neighbors.</p>
</td></tr>
<tr><td><code id="Advanced+2B20Plots_+3A_opts">opts</code></td>
<td>
<p>Options to be passed to <code>discparcoord</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plotPairedResids</code> function plots model residuals against pairs
of features, for example for model validation.  Pairs are chosen
randomly.
</p>
<p>The function <code>qeFreqParcoord</code> is a <code>qeML</code> interface to the
<code>cdparcoord</code> package.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(pef)
linout &lt;- qeLin(pef,'wageinc')
plotPairedResids(pef,linout)

## End(Not run)

</code></pre>

<hr>
<h2 id='CancerMenopause'>
Swedish breast cancer.
</h2><span id='topic+CancerMenopause'></span>

<h3>Description</h3>

<p>Data on incidence of breast cancer among women in Sweden.  Goal of the
study was to investigate whether the incidence increases with the onset
of menopause.
</p>
<p>Included here with the permission of Prof. Yudi Pawitan, Karolinska
Institutet, Stockholm.
</p>

<hr>
<h2 id='courseRecords'>
Records from several offerings of a certain course.
</h2><span id='topic+courseRecords'></span>

<h3>Description</h3>

<p>The data are in the form of an R list.  Each element of the list
corresponds to one offering of the course.  Fields are:  Class level;
major (two different computer science majors, LCSI in Letters and
Science and ECSE in engineering); quiz grade average (scale of 4.0, A+
counting as 4.3); homework grade average (same scale); and course letter
grade.
</p>

<hr>
<h2 id='currency'>
Pre-Euro Era Currency Fluctuations
</h2><span id='topic+currency'></span>

<h3>Description</h3>

<p>From Wai Mun Fong and Sam Ouliaris, &quot;Spectral Tests of the Martingale       
Hypothesis for Exchange Rates&quot;, Journal of Applied Econometrics, Vol.
10, No. 3, 1995, pp. 255-271.  Weekly exchange rates against US dollar,
over the period 7 August 1974 to 29 March 1989.        
</p>

<hr>
<h2 id='day+2Cday1'>
Bike sharing data.
</h2><span id='topic+day'></span><span id='topic+day1'></span><span id='topic+day2'></span>

<h3>Description</h3>

<p>This is the Bike Sharing dataset (day records only) from the UC Irvine
Machine Learning Dataset Repository.  Included here with 
permission of Dr. Hadi Fanaee.  
</p>
<p>The <code>day</code> data is as on UCI; <code>day1</code> is modified so that the
numeric weather variables are on their original scale.
</p>
<p>The <code>day2</code> is the same as <code>day1</code>, except that <code>dteday</code>
has been removed, and <code>season</code>, <code>mnth</code>, <code>weekday</code> and
<code>weathersit</code> have been converted to R factors.
</p>
<p>See <a href="https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset">https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset</a>
for details.
</p>

<hr>
<h2 id='Double+20Descent'>Double Descent Phenomenon</h2><span id='topic+doubleD'></span><span id='topic+plot.doubleD'></span>

<h3>Description</h3>

<p>Belkin and others have shown that some machine learning algorithms
exhibit surprising behavior when in overfitting settings.  The classic
U-shape of mean loss plotted against model complexity may be followed by
a surprise second &quot;mini-U.&quot;
</p>
<p>Alternatively, one might keep the model complexity fixed while varying
the number of data points n, including over a region in which n is
smaller than the complexity value of the model.  The surprise here is
that mean loss may actually increase with n in the overfitting region.
</p>
<p>The function <code>doubleD</code> facilitates easy exploration of this
phenomenon.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>doubleD(qeFtnCall,xPts,nReps,makeDummies=NULL,classif=FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Double+2B20Descent_+3A_qeftncall">qeFtnCall</code></td>
<td>
<p>Quoted string; somewhere should include 'xPts[i]'.</p>
</td></tr>
<tr><td><code id="Double+2B20Descent_+3A_xpts">xPts</code></td>
<td>
<p>Range of values to be used in the experiments, e.g.
a vector of degrees for polynomial models.</p>
</td></tr>
<tr><td><code id="Double+2B20Descent_+3A_nreps">nReps</code></td>
<td>
<p>Number of repetitions for each experiment, typically the
number in the holdout set.</p>
</td></tr>
<tr><td><code id="Double+2B20Descent_+3A_makedummies">makeDummies</code></td>
<td>
<p>If non-NULL, call <code>regtools::factorsToDummies</code>
on the dataset of this name.  This avoids the problem of some
levels of a factor appearing in the holdout set but not the
training set.</p>
</td></tr>
<tr><td><code id="Double+2B20Descent_+3A_classif">classif</code></td>
<td>
<p>Set TRUE if this is a classification problem.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will run the code in <code>qeFtnCall</code> <code>nreps</code>
times for each level specified in <code>xPts</code>, recording the test and
training error in each case.  So, for each level, we will have a mean
test and training error.
</p>


<h3>Value</h3>

<p>Each call in <code>xPts</code> results in one line in the return value
of <code>doubleD</code>.  The return matrix can then be plotted, using the
generic <code>plot.doubleD</code>.  Mean test (red) and training (blue) accuracy 
will be plotted against <code>xPts</code>.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   ## Not run: 
      data(mlb1)
      hw &lt;- mlb1[,2:3]
      doubleD('qePolyLin(hw,"Weight",deg=xPts[i])',1:20,250)
   
## End(Not run)
</code></pre>

<hr>
<h2 id='empAttrition'>
Employee Attrition Data
</h2><span id='topic+empAttrition'></span>

<h3>Description</h3>

<p>IBM data from Kaggle,
<a href="https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset">https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(empAttrition)
</code></pre>

<hr>
<h2 id='english'>
English vocabulary data
</h2><span id='topic+english'></span>

<h3>Description</h3>

<p>The Stanford WordBank data on vocabulary acquisition in young children.
The file consists of about 5500 rows. (There are many NA values, though,
and only about 2800 complete cases.) Variables are age, birth order,
sex, mother's education and vocabulary size.
</p>

<hr>
<h2 id='EPI+20GrowthData'>
EPI Growth Data
</h2><span id='topic+EPIWgProduct'></span>

<h3>Description</h3>

<p>US economic growth measures.
</p>
<p>Courtesy of the Economic Policy Institute.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(EPIWgProduct)
</code></pre>

<hr>
<h2 id='Feature+20Model+20Select'>Feature Selection and Model Building</h2><span id='topic+qeText'></span><span id='topic+qeTS'></span><span id='topic+qeCompare'></span><span id='topic+qeFT'></span><span id='topic+predict.qeText'></span><span id='topic+predict.qeTS'></span>

<h3>Description</h3>

<p>Utilties to help build models, both in specific applications such as
time series and text analysis, and in general tools..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qeCompare(data,yName,qeFtnList,nReps,opts=NULL,seed=9999)
qeFT(data,yName,qeftn,pars,nCombs,nTst,nXval,showProgress=TRUE)
qeText(data,yName,kTop=50,stopWords=tm::stopwords("english"),
   qeName,opts=NULL,holdout=floor(min(1000,0.1*nrow(data))))
qeTS(lag,data,qeName,opts=NULL,holdout=floor(min(1000,0.1*length(data))))
## S3 method for class 'qeText'
predict(object,newDocs,...)
## S3 method for class 'qeTS'
predict(object,newx,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_object">object</code></td>
<td>
<p>Object returned by a qe-series function.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_newx">newx</code></td>
<td>
<p>New data to be predicted.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_newdocs">newDocs</code></td>
<td>
<p>Vector of new documents to be predicted.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_lag">lag</code></td>
<td>
<p>number of recent values to use in predicting the next.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_qename">qeName</code></td>
<td>
<p>Name of qe-series predictive function, e.g. 'qeRF'.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_stopwords">stopWords</code></td>
<td>
<p>Stop lists to use.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_ntst">nTst</code></td>
<td>
<p>Number of parameter combinations.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_ktop">kTop</code></td>
<td>
<p>Number of most-frequent words to use.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_data">data</code></td>
<td>
<p>Dataframe, training set. Classification case is signaled
via labels column being an R factor.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_yname">yName</code></td>
<td>
<p>Name of the class labels column.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_holdout">holdout</code></td>
<td>
<p>If not NULL, form a holdout set of the specified size.
After fitting to the remaining data, evaluate accuracy on the test set.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_qeftnlist">qeFtnList</code></td>
<td>
<p>Character vector of <code>qe*</code> function names.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_nreps">nReps</code></td>
<td>
<p>Number of holdout sets to generate.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_opts">opts</code></td>
<td>
<p>R list of optional arguments for none, some or all of th
functions in <code>qeFtnList</code>.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_seed">seed</code></td>
<td>
<p>Seed for random number generation.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_qeftn">qeftn</code></td>
<td>
<p>Quoted string, specifying the name of a qe-series
machine learning method.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_pars">pars</code></td>
<td>
<p>R list of hyperparameter ranges.  See 
<code>regtools::fineTuning</code>.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_ncombs">nCombs</code></td>
<td>
<p>Number of hyperparameter combinations to run.  
See <code>regtools::fineTuning</code>.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_nxval">nXval</code></td>
<td>
<p>Number of cross-validations to run.  
See <code>regtools::fineTuning</code>.</p>
</td></tr>
<tr><td><code id="Feature+2B20Model+2B20Select_+3A_showprogress">showProgress</code></td>
<td>
<p>If TRUE, show results as they arise.  
See <code>regtools::fineTuning</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Overviews of the functions:
</p>

<ul>
<li> <p><code>qeTs</code> is a tool for time series modeling
</p>
</li>
<li> <p><code>qeText</code> is a tool for textual modeling
</p>
</li>
<li> <p><code>qeCompare</code> facilitates comparison among models
</p>
</li>
<li> <p><code>qeFT</code> does a random grid search for optimal hyperparameter
values
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mlb1)
# predict Weight in the mlb1 dataset, using qeKNN, with k = 5 and 25,
# with 10 cross-validations
qeFT(mlb1,'Weight','qeKNN',list(k=c(5,25)),nTst=100,nXval=10)


</code></pre>

<hr>
<h2 id='forest500'>
Subset of the Covertype data.
</h2><span id='topic+forest500'></span>

<h3>Description</h3>

<p>Random subset of 500 records.
</p>
<p><a href="https://archive.ics.uci.edu/ml/datasets/covertype">https://archive.ics.uci.edu/ml/datasets/covertype</a>
</p>

<hr>
<h2 id='iranChurn'>
Iranian Customer Churn Data
</h2><span id='topic+iranChurn'></span>

<h3>Description</h3>

<p>From <a href="https://github.com/sharmaroshan/Churn-Modelling-Dataset">https://github.com/sharmaroshan/Churn-Modelling-Dataset</a>.
</p>
<p>Character variables and bernoulli variables have been converted to
factors.  The first three cols, e.g. customer ID, have been deleted.
</p>
<p>The tenure col is apparently length of time with the firm.
</p>

<hr>
<h2 id='lsa'>
Law School Admissions Data
</h2><span id='topic+lsa'></span>

<h3>Description</h3>

<p>Law School Admissions dataset from the Law School Admissions Council
(LSAC).  The dataset was originally collected for a study called 'LSAC
National Longitudinal Bar Passage Study' by Linda Wightman in 1998.
</p>
<p>Most of the names are self-explanatory, but note that:  The two
decile scores are class standing in the first and third years of law
school, and 'cluster' refers to the reputed quality of the law school.
Two variables of particular interest might be the student's score on the
Law School Admission Test (LSAT) and a logical variable indicating
whether the person passed the bar examination.
</p>
<p>Note that the 'age' variable is apparently birth year, e.g. 69 meaning
1969.
</p>

<hr>
<h2 id='ltrfreqs'>
Letter Frequencies
</h2><span id='topic+ltrfreqs'></span>

<h3>Description</h3>

<p>This is data consists of capital letter frequencies obtained at
https://www.math.cornell.edu/~mec/2003-2004/cryptography/subs/frequencies.h
tml
</p>

<hr>
<h2 id='mlb'>
Major Leage Baseball player data set.
</h2><span id='topic+mlb'></span><span id='topic+mlb1'></span>

<h3>Description</h3>

<p>Heights, weights, ages etc. of major league baseball players.  A new
variable has been added, consolidating positions into Infielders,
Outfielders, Catchers and Pitchers.
</p>
<p>The <code>mlb1</code> version has only Position, Height, Weight and Age.
</p>
<p>Included here with the permission of the UCLA Statistics Department.
</p>

<hr>
<h2 id='mlens'>
MovieLens User Summary Data
</h2><span id='topic+mlens'></span>

<h3>Description</h3>

<p>The MovieLens dataset, <a href="https://grouplens.org/">https://grouplens.org/</a>,
is a standard example in the recommender systems literature.  Here we
give demographic data for each user, plus the mean rating and number of
ratings.  One may explore, for instance, the relation between ratings
and age.
</p>

<hr>
<h2 id='newadult'>
UCI adult income data set, adapted
</h2><span id='topic+newadult'></span><span id='topic+newAdult'></span>

<h3>Description</h3>

<p>This data set is adapted from
the Adult data from the UCI Machine Learning Repository,
which was in turn adapted from Census data on adult incomes and other 
demographic variables.  The UCI data is used here with permission 
from Ronny Kohavi.
</p>
<p>The variables are:
</p>

<ul>
<li> <p><code>gt50</code>, which converts the original <code>&gt;50K</code> variable
to an indicator variable; 1 for income greater than $50,000, else 0
</p>
</li>
<li> <p><code>edu</code>, which converts a set of education levels to
approximate number of years of schooling
</p>
</li>
<li> <p><code>age</code>
</p>
</li>
<li> <p><code>gender</code>, 1 for male, 0 for female
</p>
</li>
<li> <p><code>mar</code>, 1 for married, 0 for single
</p>
</li></ul>

<p>Note that the education variable is now numeric.
</p>

<hr>
<h2 id='nyctaxi'>
New York City Taxi Data
</h2><span id='topic+nyctaxi'></span>

<h3>Description</h3>

<p>10,000 records on five variables, extracted from
<a href="https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq">https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nyctaxi)
</code></pre>

<hr>
<h2 id='oliveoils'>
Italian olive oils data set.
</h2><span id='topic+oliveoils'></span>

<h3>Description</h3>

<p>Italian olive oils data set, as used in <em>Graphics of Large 
Datasets: Visualizing a  Million</em>, by  Antony Unwin, Martin Theus and 
Heike Hofmann, Springer, 2006.  Included here with permission of Dr. 
Martin Theus.  
</p>

<hr>
<h2 id='Prediction+20with+20Missing+20Values'>Prediction with Missing Values</h2><span id='topic+qeLinMV'></span><span id='topic+qeLogitMV'></span><span id='topic+qeKNNMV'></span><span id='topic+predict.qeLinMV'></span><span id='topic+predict.qeLogitMV'></span><span id='topic+predict.qeKNNMV'></span>

<h3>Description</h3>

<p>ML methods for prediction in which features are subject to missing
values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qeLinMV(data,yName)
qeLogitMV(data,yName,yesYVal)
qeKNNMV(data,yName,kmax)
## S3 method for class 'qeLinMV'
predict(object,newx,...)
## S3 method for class 'qeLogitMV'
predict(object,newx,...)
## S3 method for class 'qeKNNMV'
predict(object,newx,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Prediction+2B20with+2B20Missing+2B20Values_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20Missing+2B20Values_+3A_object">object</code></td>
<td>
<p>An object returned by one of the <code>qe*MV</code> functions.</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20Missing+2B20Values_+3A_data">data</code></td>
<td>
<p>Dataframe, training set. Classification case is signaled
via labels column being an R factor.</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20Missing+2B20Values_+3A_yname">yName</code></td>
<td>
<p>Name of the class labels column.</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20Missing+2B20Values_+3A_newx">newx</code></td>
<td>
<p>New data to be predicted.</p>
</td></tr>
<tr><td><code id="Prediction+2B20with+2B20Missing+2B20Values_+3A_kmax">kmax</code></td>
<td>
<p>Number of nearest neighbors in training set.</p>
</td></tr> 
<tr><td><code id="Prediction+2B20with+2B20Missing+2B20Values_+3A_yesyval">yesYVal</code></td>
<td>
<p>Y value to be considered &quot;yes,&quot; to be coded 1 rather than 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are wrappers to the <span class="pkg">toweranNA</span> package.  Linear, logistic and
kNN interfaces are available.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sum(is.na(airquality))  # 44 NAs, good test example
z &lt;- qeKNNMV(airquality,'Ozone',10)
# example of new case, insert an NA in 1st row
aq2 &lt;- airquality[2,-1]
aq2$Wind &lt;- NA
predict(z,aq2)  # 28.1

</code></pre>

<hr>
<h2 id='prgeng'>
Silicon Valley programmers and engineers data
</h2><span id='topic+prgeng'></span><span id='topic+pef'></span><span id='topic+svcensus'></span>

<h3>Description</h3>

<p>This data set is adapted from the 2000 Census (5% sample, person
records).  It is mainly restricted to programmers and engineers in the 
Silicon Valley area.  (Apparently due to errors, there are some from
other ZIP codes.)
</p>
<p>There are three versions:
</p>

<ul>
<li><p><code>prgeng</code>, the original data, with categorical variables,
e.g. Occupation, in their original codes
</p>
</li>
<li><p><code>pef</code>, same as <code>peFactors</code>, but having only columns
for age, education, occupation, gender, wage income and weeks
worked.  The education column has been collapsed to Master's degree,
PhD and other, coded 'z14', 'z16' and 'zzzOther'.  Most cases are in
the latter category.
</p>
</li>
<li><p><code>svcensus</code>, same as <code>pef</code>, but with the column
name 'sex' replaced by 'gender'.
</p>
</li></ul>

<p>The variable codes, e.g. occupational codes, are available from 
<a href="https://usa.ipums.org/usa/volii/occ2000.shtml">https://usa.ipums.org/usa/volii/occ2000.shtml</a>.
(Short code lists are given in the record layout, but longer ones are in
the appendix Code Lists.)
</p>
<p>The variables are:
</p>

<ul>
<li><p><code>age</code>, with a U(0,1) variate added for jitter
</p>
</li>
<li><p><code>cit</code>, citizenship; 1-4 code various categories of
citizens; 5 means noncitizen (including permanent residents)
</p>
</li>
<li><p><code>educ</code>: 01-09 code no college; 10-12 means some college;
13 is a bachelor's degree, 14 a master's, 15 a professional degree and
16 is a doctorate
</p>
</li>
<li><p><code>occ</code>, occupation
</p>
</li>
<li><p><code>birth</code>, place of birth
</p>
</li>
<li><p><code>wageinc</code>, wage income
</p>
</li>
<li><p><code>wkswrkd</code>, number of weeks worked
</p>
</li>
<li><p><code>yrentry</code>, year of entry to the U.S. (0 for natives)
</p>
</li>
<li><p><code>powpuma</code>, location of work 
</p>
</li>
<li><p><code>gender</code>, 1 for male, 2 for female
</p>
</li></ul>


<hr>
<h2 id='qe-Series+20Predictive+20Functions'>Quick-and-Easy Machine Learning Wrappers</h2><span id='topic+qeLogit'></span><span id='topic+qeLin'></span><span id='topic+qeKNN'></span><span id='topic+qeRF'></span><span id='topic+qeRFranger'></span><span id='topic+qeRFgrf'></span><span id='topic+qeSVM'></span><span id='topic+qeGBoost'></span><span id='topic+qeAdaBoost'></span><span id='topic+qeLightGBoost'></span><span id='topic+qeNeural'></span><span id='topic+qeLASSO'></span><span id='topic+qePolyLin'></span><span id='topic+qePolyLog'></span><span id='topic+qePoly'></span><span id='topic+qeIso'></span><span id='topic+qePCA'></span><span id='topic+qeUMAP'></span><span id='topic+qeParallel'></span><span id='topic+qeDT'></span><span id='topic+qeFOCI'></span><span id='topic+qeFOCIrand'></span><span id='topic+qeFOCImult'></span><span id='topic+qeLinKNN'></span><span id='topic+qePolyLASSO'></span><span id='topic+qeROC'></span><span id='topic+qeXGBoost'></span><span id='topic+qeDeepnet'></span><span id='topic+qeNCVregCV'></span><span id='topic+qePolyLinKNN'></span><span id='topic+qeRpart'></span><span id='topic+checkPkgLoaded'></span><span id='topic+predict.qeLogit'></span><span id='topic+predict.qeLin'></span><span id='topic+predict.qeKNN'></span><span id='topic+predict.qeRF'></span><span id='topic+predict.qeRFranger'></span><span id='topic+predict.qeRFgrf'></span><span id='topic+predict.qeSVM'></span><span id='topic+predict.qeGBoost'></span><span id='topic+predict.qeLightGBoost'></span><span id='topic+predict.qeAdaBoost'></span><span id='topic+predict.qeNeural'></span><span id='topic+predict.qeLASSO'></span><span id='topic+predict.qePolyLin'></span><span id='topic+predict.qePolyLog'></span><span id='topic+predict.qeIso'></span><span id='topic+predict.qePCA'></span><span id='topic+predict.qeUMAP'></span><span id='topic+predict.qeDeepnet'></span><span id='topic+predict.qeParallel'></span><span id='topic+predict.qeNCVregCV'></span><span id='topic+predict.qePolyLinKNN'></span><span id='topic+predict.qePoly'></span><span id='topic+predict.qeRpart'></span><span id='topic+plot.qePoly'></span><span id='topic+plot.qeRF'></span><span id='topic+plot.qeLASSO'></span><span id='topic+plot.qeRpart'></span>

<h3>Description</h3>

<p>Quick access to machine learning methods, with a very simple
interface.  &quot;Works right out of the box!&quot;:
Just one call needed to fit, no preliminary
setup of model etc.  The simplicity also makes the series useful
for teaching.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qeLogit(data,yName,holdout=floor(min(1000,0.1*nrow(data))),yesYVal=NULL)
qeLin(data,yName,noBeta0=FALSE,holdout=floor(min(1000,0.1*nrow(data))))
qeKNN(data,yName,k,scaleX=TRUE,smoothingFtn=mean,yesYVal=NULL,
   expandVars=NULL,expandVals =NULL,holdout=floor(min(1000,0.1*nrow(data))))
qeRF(data,yName,nTree=500,minNodeSize=10,mtry=floor(sqrt(ncol(data)))+1,
   holdout=floor(min(1000,0.1*nrow(data))))
qeRFranger(data,yName,nTree=500,minNodeSize=10,
   mtry=floor(sqrt(ncol(data)))+1,deweightPars=NULL,
   holdout=floor(min(1000,0.1*nrow(data))),yesYVal="") 
qeRFgrf(data,yName,nTree=2000,minNodeSize=5,mtry=floor(sqrt(ncol(data)))+1,
   ll=FALSE,lambda=0.1,splitCutoff=sqrt(nrow(data)),
   holdout=floor(min(1000,0.1*nrow(data))))
qeSVM(data,yName,gamma=1.0,cost=1.0,kernel='radial',degree=2,
   allDefaults=FALSE,holdout=floor(min(1000,0.1*nrow(data))))
qeGBoost(data,yName,nTree=100,minNodeSize=10,learnRate=0.1,
   holdout=floor(min(1000,0.1*nrow(data))))
qeAdaBoost(data, yName, treeDepth = 3, nRounds = 100, rpartControl = NULL, 
    holdout = floor(min(1000, 0.1 * nrow(data)))) 
qeLightGBoost(data,yName,nTree=100,minNodeSize=10,learnRate=0.1,
   holdout=floor(min(1000,0.1*nrow(data))))
qeNeural(data,yName,hidden=c(100,100),nEpoch=30,
   acts=rep("relu",length(hidden)),learnRate=0.001,
   conv=NULL,xShape=NULL,
   holdout=floor(min(1000,0.1*nrow(data))))
qeLASSO(data,yName,alpha=1,holdout=floor(min(1000,0.1*nrow(data))))
qePolyLin(data,yName,deg=2,maxInteractDeg = deg,
   holdout=floor(min(1000,0.1*nrow(data))))
qePolyLog(data,yName,deg=2,maxInteractDeg = deg,
   holdout=floor(min(1000,0.1*nrow(data))))
qePCA(data,yName,qeName,opts=NULL,pcaProp,
   holdout=floor(min(1000,0.1*nrow(data))))
qeUMAP(data,yName,qeName,opts=NULL,
   holdout=floor(min(1000,0.1*nrow(data))),scaleX=FALSE,
   nComps=NULL,nNeighbors=NULL)
qeDT(data,yName,alpha=0.05,minsplit=20,minbucket=7,maxdepth=0,mtry=0,
   holdout=floor(min(1000,0.1*nrow(data))))
qeFOCI(data,yName,numCores=1,parPlat="none",
   yesYLevel=NULL)
qeFOCIrand(data,yName,xSetSize,nXSets)
qeFOCImult(data,yName,numCores=1,
   parPlat="none",coalesce='union')
qeLinKNN(data,yName,k=25,scaleX=TRUE,smoothingFtn=mean,
   expandVars=NULL,expandVals=NULL,
   holdout=floor(min(1000,0.1*nrow(data))))
qePolyLASSO(data,yName,deg=2,maxInteractDeg=deg,alpha=0,
   holdout=floor(min(1000,0.1*nrow(data))))
qeROC(dataIn,qeOut,yLevelName)
qeXGBoost(data,yName,nRounds=250,
   params=list(eta=0.3,max_depth=6,alpha=0),
   holdout=floor(min(1000,0.1*nrow(data))))
qeDeepnet(data,yName,hidden=c(10),activationfun="sigm",
   learningrate=0.8,momentum=0.5,learningrate_scale=1,
   numepochs=3,batchsize=100,hidden_dropout=0,yesYVal=NULL,
   holdout=floor(min(1000,0.1*nrow(data))))
qeRpart(data,yName,minBucket=10,holdout=floor(min(1000,
   0.1*nrow(data)))) 
qeParallel(data,yName,qeFtnName,dataName,opts=NULL,cls=1,
   libs=NULL,holdout=NULL)
checkPkgLoaded(pkgName,whereObtain='CRAN') 
## S3 method for class 'qeParallel'
predict(object,newx,...)
## S3 method for class 'qeLogit'
predict(object,newx,...)
## S3 method for class 'qeLin'
predict(object,newx,useTrainRow1=TRUE,...)
## S3 method for class 'qeKNN'
predict(object,newx,newxK=1,...)
## S3 method for class 'qeRF'
predict(object,newx,...)
## S3 method for class 'qeRFranger'
predict(object,newx,...)
## S3 method for class 'qeRFgrf'
predict(object,newx,...)
## S3 method for class 'qeSVM'
predict(object,newx,...)
## S3 method for class 'qeGBoost'
predict(object,newx,newNTree=NULL,...)
## S3 method for class 'qeLightGBoost'
predict(object,newx,...)
## S3 method for class 'qeNeural'
predict(object,newx,k=NULL,...)
## S3 method for class 'qeLASSO'
predict(object,newx,...)
## S3 method for class 'qePoly'
predict(object,newx)
## S3 method for class 'qePCA'
predict(object,newx,...)
## S3 method for class 'qeUMAP'
predict(object,newx,...)
## S3 method for class 'qeDeepnet'
predict(object,newx,...)
## S3 method for class 'qeRpart'
predict(object,newx,...)
## S3 method for class 'qeLASSO'
plot(x,...)
## S3 method for class 'qeRF'
plot(x,...)
## S3 method for class 'qeRpart'
plot(x,boxPalette=c("red","yellow","green","blue"),...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_...">...</code></td>
<td>
<p>Further arguments.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_cls">cls</code></td>
<td>
<p>Cluster in the sense of <span class="pkg">parallel</span> package.  If not of 
class <code>cluster</code>, this is either a positive integer, indicating the
desired number of cores, or a character vector, indicating the
machines on which the cluster is to be formed.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_libs">libs</code></td>
<td>
<p>Character vector listing libraries needed to be loaded for 
<code>qeFtnName</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_dataname">dataName</code></td>
<td>
<p>Name of the <code>data</code> argument.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_hidden_dropout">hidden_dropout</code></td>
<td>
<p>Drop out fraction for hidden layer.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_batchsize">batchsize</code></td>
<td>
<p>Batch size.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_numepochs">numepochs</code></td>
<td>
<p>Number of iterations to conduct.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_learningrate">learningrate</code></td>
<td>
<p>Learning rate.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_momentum">momentum</code></td>
<td>
<p>Momemtum</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_learningrate_scale">learningrate_scale</code></td>
<td>
<p>Learning rate will be multiplied by this at
each iteration, allowing for decay.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_activationfun">activationfun</code></td>
<td>
<p>Can be 'sigm', 'tanh' or 'linear'.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_newntree">newNTree</code></td>
<td>
<p>Number of trees to use in prediction.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_newxk">newxK</code></td>
<td>
<p>If predicting new cases, number of nearest neighbors to
smooth in the object returned by <code>qeKNN</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_usetrainrow1">useTrainRow1</code></td>
<td>
<p>If TRUE, take names in <code>newx</code> from row 1 in
the training data.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_newx">newx</code></td>
<td>
<p>New data to be predicted.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_object">object</code></td>
<td>
<p>An object returned by a qe-series function.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_minsplit">minsplit</code></td>
<td>
<p>Minimum number of data points in a node.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_minbucket">minbucket</code></td>
<td>
<p>Minimum number of data points in a terminal node.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_minbucket">minBucket</code></td>
<td>
<p>Minimum number of data points in a terminal node.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_maxdepth">maxdepth</code></td>
<td>
<p>Maximum number of levels in a tree.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_qename">qeName</code></td>
<td>
<p>Name of qe-series predictive function.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_qeftnname">qeFtnName</code></td>
<td>
<p>Name of qe-series predictive function.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_conv">conv</code></td>
<td>
<p>R list specifying the convolutional layers, if any.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_deweightpars">deweightPars</code></td>
<td>
<p>Values for de-emphasizing variables in a 
tree node split, e.g. 'list(age=0.2,gender=0.5)'.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_alldefaults">allDefaults</code></td>
<td>
<p>Use all default values of the wrapped function.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_expandvars">expandVars</code></td>
<td>
<p>Columns to be emphasized.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_expandvals">expandVals</code></td>
<td>
<p>Emphasis values; a value less than 1 means de-emphasis.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_mtry">mtry</code></td>
<td>
<p>Number of variables randomly tried at each split.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_yesyval">yesYVal</code></td>
<td>
<p>Y value to be considered &quot;yes,&quot; to be coded 1 rather than 0.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_yesylevel">yesYLevel</code></td>
<td>
<p>Y value to be considered &quot;yes,&quot; to be coded 1 rather than 0.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_nobeta0">noBeta0</code></td>
<td>
<p>No intercept term.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_pcaprop">pcaProp</code></td>
<td>
<p>Desired proportion of overall variance for the PCs.'</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_data">data</code></td>
<td>
<p>Dataframe, training set. Classification case is signaled
via labels column being an R factor.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_datain">dataIn</code></td>
<td>
<p>See <code>data</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_qeout">qeOut</code></td>
<td>
<p>Output from a qe-series function.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_yname">yName</code></td>
<td>
<p>Name of the class labels column.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_holdout">holdout</code></td>
<td>
<p>If not NULL, form a holdout set of the specified size.
After fitting to the remaining data, evaluate accuracy on the test set.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_k">k</code></td>
<td>
<p>Number of nearest neighbors. In functions other than
<code>qeKNN</code> for which this is an argument, it is the number of 
neighbors to use in finding conditional probabilities via 
<code>knnCalib</code>.</p>
</td></tr> 
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_smoothingftn">smoothingFtn</code></td>
<td>
<p>As in <code>kNN</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_scalex">scaleX</code></td>
<td>
<p>Scale the features.</p>
</td></tr> 
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_ntree">nTree</code></td>
<td>
<p>Number of trees.</p>
</td></tr> 
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_minnodesize">minNodeSize</code></td>
<td>
<p>Minimum number of data points in a tree node.</p>
</td></tr> 
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_learnrate">learnRate</code></td>
<td>
<p>Learning rate.</p>
</td></tr> 
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_hidden">hidden</code></td>
<td>
<p>Vector of units per hidden layer.  Fractional values
indicated dropout proportions.  Can be specified as a string, e.g.
'100,50', for use with <code>qeFT</code>.</p>
</td></tr> 
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_nepoch">nEpoch</code></td>
<td>
<p>Number of iterations in neural net.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_acts">acts</code></td>
<td>
<p>Vector of names of the activation functions, one per
hidden layer.  Choices inclde 'relu', 'sigmoid', 'tanh', 'softmax',
'elu', 'selu'.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_alpha">alpha</code></td>
<td>
<p>In the case of <code>qeDT</code>, a p-value cutoff criterion.
Otherwise 1 for LASSO, 2 for ridge.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_gamma">gamma</code></td>
<td>
<p>Scale parameter in <code>e1071::svm</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_cost">cost</code></td>
<td>
<p>Cost parameter in <code>e1071::svm</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_kernel">kernel</code></td>
<td>
<p>In the case of <code>qeSVM</code>, this is 
One of 'linear','radial','polynomial' and 'sigmoid'.</p>
</td></tr>  
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_degree">degree</code></td>
<td>
<p>Degree of SVM polynomial kernel, if any.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_opts">opts</code></td>
<td>
<p>R list of optional arguments for none, some or all of th
functions in <code>qeFtnList</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_ncomps">nComps</code></td>
<td>
<p>Number of UMAP components to extract.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_nneighbors">nNeighbors</code></td>
<td>
<p>Number of nearest neighbors to use in UMAP.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_ll">ll</code></td>
<td>
<p>If TRUE, use local linear forest.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_lambda">lambda</code></td>
<td>
<p>Ridge lambda for local linear forest.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_splitcutoff">splitCutoff</code></td>
<td>
<p>For leaves smaller than this value, do not fit
linear model.  Just use the linear model fit to the entire dataset.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_xshape">xShape</code></td>
<td>
<p>Input X data shape, e.g. c(28,28) for 28x28 grayscale
images.  Must be non-NULL if <code>conv</code> is.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_treedepth">treeDepth</code></td>
<td>
<p>Number of levels in each tree.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_nrounds">nRounds</code></td>
<td>
<p>Number of boosting rounds.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_rpartcontrol">rpartControl</code></td>
<td>
<p>An R list specifying properties of fitted trees.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_numcores">numCores</code></td>
<td>
<p>Number of cores to use in parallel computation.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_parplat">parPlat</code></td>
<td>
<p>Parallel platforParallel platform.  Valid values are
'none', 'cluster' (output of <code>parallel::makeCluster</code>), and 
'locThreads' (local cores).</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_xsetsize">xSetSize</code></td>
<td>
<p>Size of subsets of the predictor variables.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_nxsets">nXSets</code></td>
<td>
<p>Number of subsets of the predictor variables.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_coalesce">coalesce</code></td>
<td>
<p>Method for combining variable sets.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_deg">deg</code></td>
<td>
<p>Degree of a polynomial.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_maxinteractdeg">maxInteractDeg</code></td>
<td>
<p>Maximul degree of interaction terms in
a polynomial.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_ylevelname">yLevelName</code></td>
<td>
<p>Name of the class to be considered a positive
response in a classification problem.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_params">params</code></td>
<td>
<p>Tuning parameters for <code>xgboost</code>, e.g. 
<code>params=list(eta=0.1,max_depth=8)</code>.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_boxpalette">boxPalette</code></td>
<td>
<p>Color palette.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_pkgname">pkgName</code></td>
<td>
<p>Name of wrapped package.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_whereobtain">whereObtain</code></td>
<td>
<p>Location.</p>
</td></tr>
<tr><td><code id="qe-Series+2B20Predictive+2B20Functions_+3A_x">x</code></td>
<td>
<p>A qe-series function return object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As noted, these functions are intended for quick, first-level analysis
of regression/machine learning problems.  Emphasis here is
on convenience and simplicity.  
</p>
<p>The idea is that, given a new dataset, the analyst can quickly and
easily try fitting a number of models in succession, say first k-NN,
then random forests: 
</p>
<pre>
# built-in data on major league baseball players
&gt; data(mlb)  
&gt; mlb &lt;- mlb[,3:6]  # position, height, weight, age

# fit models
&gt; knnout &lt;- qeKNN(mlb,'Weight',k=25)
&gt; rfout &lt;- qeRF(mlb,'Weight')

# mean abs. pred. error on holdout set, in pounds
&gt; knnout$testAcc
[1] 11.75644
&gt; rfout$testAcc
[1] 12.6787

# predict a new case
&gt; newx &lt;- data.frame(Position='Catcher',Height=73.5,Age=26)
&gt; predict(knnout,newx)
       [,1]
[1,] 204.04
&gt; predict(rfout,newx)
      11 
199.1714

# many of the functions include algorithm-specific output
&gt; lassout &lt;- qeLASSO(mlb,'Weight')
holdout set has  101 rows
&gt; lassout$testAcc
[1] 14.27337
&gt; lassout$coefs  # sparse result?
10 x 1 sparse Matrix of class "dgCMatrix"
                                    s1
(Intercept)               -109.2909416
Position.Catcher             0.4408752
Position.First_Baseman       4.8308437
Position.Outfielder          .        
Position.Relief_Pitcher      .        
Position.Second_Baseman     -0.7846501
Position.Shortstop          -4.2291338
Position.Starting_Pitcher    .        
Height                       4.0039114
Age                          0.5352793

</pre>
<p>The <code>holdout</code> argument triggers formation of a holdout set
and the corresponding cross-validation evaluation of predictive power.
Note that if a holdout is formed, the return value will consist of the
fit on the training set, not on the full original dataset.
</p>
<p>The <code>qe*</code> functions do model fit.  Each of them has a
<code>predict</code> method, and some also have a <code>plot</code> method.
</p>
<p>Arguments for <code>qe*</code> are at least: 
</p>

<ul>
<li> <p><code>data</code> 
</p>
</li>
<li> <p><code>yName</code> 
</p>
</li>
<li> <p><code>holdout</code>
</p>
</li></ul>

<p>Typically there are also algorithm-specific hyperparameter arguments.
</p>
<p>Arguments for <code>predict</code> are at least:
</p>

<ul>
<li> <p><code>object</code>, the return value from <code>qe*</code>
</p>
</li>
<li> <p><code>newx</code>, a data frame of points to be predicted
</p>
</li></ul>

<p>For both the fitting function and the prediction function, there may be
additional algorithm-specific parameters; default values are provided.
</p>
<p>Some notes on specific functions:
</p>

<ul>
<li><p> The function <code>qeLin</code> handles not only the usual OLS models
but also classification problems as multivariate-outcome linear
models. If one's goal is prediction, it can be much faster than
<code>qeLogit</code>, often with comparable accuracy.
</p>
</li>
<li><p> Regularization in linear/generalized linear models is
implemented in <code>qeLASSO</code> and other functions with names
containing 'LASSO', as well as <code>qeNCVregCV</code>.  The latter,
wrappping the MCP and other regularization methods, wraps the package
of the same name.
</p>
</li>
<li><p> Several functions fit polynomial models.  The <code>qePolyLin</code>
function does polynomial regression of the indicated degree. In the
above example degree 3 means all terms through degree 3, e.g.
<code>Height * Age^2</code>.  Dummy variables are handled properly, e.g.
no powers of a dummy are generatd.  The logistic polynomial
regression version is <code>qePolyLog</code>, and there is a LASSO version,
<code>qePolyLASSO</code>.
</p>
</li>
<li><p> Several random forests implementations are offered:
<code>qeRF</code> wraps <code>randomForest</code> in the package of the same name; 
<code>qeRFranger</code> wraps <code>ranger</code> in the package of the same name; 
<code>qeRFgrf</code> wraps <code>regression_forest</code> and 
<code>ll_regression_forest</code> in <span class="pkg">grf</span> (the latter does local
linear smoothing).  There is also <code>qeDT</code>, using 
the <span class="pkg">party</span> package.
</p>
</li>
<li><p> Several implementations of gradient boosting are offered,
including <code>qeGBoost</code> using the <span class="pkg">gbm</span> package, 
<code>qelightGBoost</code> using <span class="pkg">lightgbm</span>, and <code>qeXGBoost</code>
wrapping <span class="pkg">xgboost</span>.
</p>
</li>
<li><p> Several functions involve dimension reduction/feature
selection.  Pre-mapping to lower-dimensional manifolds can be done via
<code>qePCA</code> and <code>qeUMAP</code>.  For instance, the former will first
extract the specified number of principal components, then fit the
user's desired ML model, say k-NN (<code>qeKNN</code>) or gradient boosting
(<code>qeGBoost</code>).  
</p>
</li>
<li><p> The <code>qeFOCI</code> function does feature selection
in a basically assumption-free manner.  It handles numeric and binary
Y (the latter coded 1,0).  For categorical Y, use <code>qeFOCImult</code>.
The function <code>qeFOCIrand</code> applies FOCI to many subsets of the
input dataset, eventually returning the union of the outputs; this is
useful if the dataset has many NA values.
</p>
</li>
<li><p> Neural network models are implemented by <code>qeNeural</code>
and <code>qeDeepnet</code>, based on <span class="pkg">keras</span> and <span class="pkg">deepnet</span>.
</p>
</li>
<li><p> The <code>qeLinKNN</code> function offers a hybrid approach.  It
first fits a linear model, then applies k-Nearest Neighbors to the
residuals.  The <code>qePolyLinKNN</code> function does the same in with a
polynomial fit.
</p>
</li>
<li><p> The <code>qeIso</code> function is intended mainly for use as a
smoothing method in calibration actions.  
</p>
</li></ul>

<p>In most cases, the full basket of options in the wrapped function is not
reflected.  Use of arguments not presented in the qe function requires
direct use the relevant packages.
</p>


<h3>Value</h3>

<p>The value returned by <code>qe*</code> functions depends on the algorithm, but
with some commonality, e.g. <code>classif</code>, a logical value indicating
whether the problem was of classification type.  
</p>
<p>If a holdout set was requested, an additional returned component will be
<code>testAcc</code>, the accuracy on the holdout set.  This will be Mean
Absolute Prediction Error in the regression case, and proportion of
misclassified cases in the classification case.
</p>
<p>The value returned by the <code>predict</code> functions is an
R list with components as follows:
</p>
<p>Classification case:
</p>

<ul>
<li> <p><code>predClasses</code>:  R factor instance of predicted class labels 
</p>
</li>
<li> <p><code>probs</code>:  vector/matrix of class probabilities; in the 2-class
case, a vector, the probabilities of Y = 1
</p>
</li></ul>

<p>Regression case: vector of predicted values
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# see also 'details' above

## Not run: 

data(peFactors)  
pef &lt;- peFactors[,c(1,3,5,7:9)]  
# most people in the dataset have at least a Bachelor's degree; so let's
# just consider Master's (code 14) and PhD (code 16) as special
pef$educ &lt;- toSubFactor(pef$educ,c('14','16'))  

# predict occupation; 6 classes, 100, 101, 102, 106, 140, 141, using SVM
svmout &lt;- qeSVM(pef,'occ',holdout=NULL) 
# as example of prediction, take the 8th case, but change the gender and
# age to female and 25; note that by setting k to non-null, we are
# requesting that conditional probabilities be calculated, via
# knnCalib(), here using 25 nearest neighbors
newx &lt;- pef[8,-3] 
newx$sex &lt;- '2'
newx$age &lt;- 25
predict(svmout,newx,k=25)
# $predClasses
#   8 
# 100 
# Levels: 100 101 102 106 140 141
# $dvals
#      102/101    102/100   102/141  102/140  102/106    101/100  101/141
# 8 -0.7774038 -0.5132022 0.9997894 1.003251 0.999688 -0.4023077 1.000419
#    101/140   101/106  100/141  100/140  100/106   141/140    141/106   140/106
# 8 1.000474 0.9997371 1.000088 1.000026 1.000126 0.9460703 -0.4974625 -1.035721
# 
# $probs
#       100  101  102  106 140  141
# [1,] 0.24 0.52 0.12 0.08   0 0.04
#
# so, occupation code 100 is predicted, with a 0.36 conditional
# probability

# if holdout evaluation is desired as well, say 1000 cases, seed 9999:
&gt; svmout &lt;- qeSVM(pef,'occ',holdout=c(1000,9999)) 
&gt; svmout$testAcc
[1] 0.622  # 62

# linear
# lm() doesn't like numeric factor levels, so prepend an 'a'
pef$occ &lt;- prepend('a',pef$occ)
lmout &lt;- qeLin(pef,'occ')
predict(lmout,pef[1,-3])  # occ 100, prob 0.3316
lmout &lt;- qeLin(pef,'wageinc')
predict(lmout,pef[1,-5])  # 70857.79


## End(Not run)

</code></pre>

<hr>
<h2 id='quizDocs'>
Course quiz documents
</h2><span id='topic+quizDocs'></span><span id='topic+quizzes'></span>

<h3>Description</h3>

<p>This data is suitable for NLP analysis.  It consists of all the quizzes
I've given in undergraduate courses, 143 quizzes in all.  
</p>
<p>It is available in two forms.  First, <code>quizzes</code> is a data.frame,
143 rows and 2 columns.  Row i consists of a single character vector
comprising the entire quiz i, followed by the course name (as an R
factor).  The second form is an R list, 143 elements.  Each list element
is a character vector, one vector element per line of the quiz.
</p>
<p>The original documents were LaTeX files.  They have been run through the
<code>detex</code> utility to remove most LaTeX commands, as well as removing
the LaTeX preambles separately.
</p>
<p>The names of the list elements are the course names, as follows:
</p>
<p>ECS 50:  a course in machine organization
</p>
<p>ECS 132:  an undergraduate course in probabilistic modeling
</p>
<p>ECS 145:  a course in scripting languages (Python, R)
</p>
<p>ECS 158:  an undergraduate course in parallel computation
</p>
<p>ECS 256:  a graduate course in probabilistic modeling
</p>

<hr>
<h2 id='R+20Factor+20Utilities'>R Factor Utilities</h2><span id='topic+levelCounts'></span><span id='topic+dataToTopLevels'></span><span id='topic+factorToTopLevels'></span><span id='topic+cartesianFactor'></span><span id='topic+qeRareLevels'></span>

<h3>Description</h3>

<p>Utilities to manipulate R factors, extending the ones in <code>regtools.</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>levelCounts(data)
dataToTopLevels(data,lowCountThresholds)
factorToTopLevels(f,lowCountThresh=0)
cartesianFactor(dataName,factorNames,fNameSep = ".")
qeRareLevels(x, yName, yesYVal = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_data">data</code></td>
<td>
<p>A data frame or equivalent.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_f">f</code></td>
<td>
<p>An R factor.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_lowcountthresh">lowCountThresh</code></td>
<td>
<p>Factor levels will counts below this value will
not be used for this factor.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_lowcountthresholds">lowCountThresholds</code></td>
<td>
<p>An R list of column names and their
corresponding values of <code>lowCountThresh</code>.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_dataname">dataName</code></td>
<td>
<p>A quoted name of a data frame or equivalent.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_factornames">factorNames</code></td>
<td>
<p>A vector of R factor names.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_fnamesep">fNameSep</code></td>
<td>
<p>A character to be used as a delimiter in the names of
the levels of the output factor.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_x">x</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_yname">yName</code></td>
<td>
<p>Quoted name of the response variable.</p>
</td></tr>
<tr><td><code id="R+2B20Factor+2B20Utilities_+3A_yesyval">yesYVal</code></td>
<td>
<p>In the case of binary Y, the factor level to 
be considered positive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Often one has an R factor in which one or more levels are rare in the
data.  This could cause problems, say in performing cross-validation; a
level in the test set might be &quot;new,&quot; not having appeared in the
training set.  Toward this end, <code>factorToTopLevels</code> will remove
rare levels from a factor; <code>dataToTopLevels</code> applies this to an
entire data frame.
</p>
<p>Also toward this end, the function <code>levelCounts</code> simply applies
<code>table()</code> to each column of <code>data</code>, returning the result as an
R list. (If more than 10 levels, it returns NA.
</p>
<p>The function <code>cartesianFactor</code> generates a &quot;superfactor&quot; from
individual ones; e.g. if factors f1 and f2 have n1 and n2 levels, the
output is a new factor with n1 * n2 levels.
</p>
<p>The function <code>qeRareLevels</code> checks all columns in a data frame in
terms of being an R factor with rare levels.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(svcensus)
levelCounts(svcensus)  # e.g. finds there are 15182 men, 4908 women
f1 &lt;- svcensus$gender  # 2 levels
f2 &lt;- svcensus$occ  # 6 levels
z &lt;- cartesianFactor('svcensus',c('gender','occ'))
head(z)
# [1] female.102 male.101   female.102 male.100   female.100 male.100  
# 12 Levels: female.100 female.101 female.102 female.106 ... male.141

</code></pre>

<hr>
<h2 id='ThyroidDisease'>
Thyroid Disease
</h2><span id='topic+ThyroidDisease'></span>

<h3>Description</h3>

<p>See OpenML repository,
https://www.openml.org/search?type=data&amp;sort=runs&amp;id=38&amp;status=active.
</p>
<p>&quot;Thyroid disease records supplied by the Garavan Institute
and J. Ross Quinlan, New South Wales Institute, Syndney, Australia.
1987.&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ThyroidDisease)
</code></pre>

<hr>
<h2 id='Utilities'>Utilities</h2><span id='topic+buildQEcall'></span><span id='topic+evalr'></span><span id='topic+newDFRow'></span>

<h3>Description</h3>

<p>Miscellaneous functions, used mainly internally in the package, but of
possible use externally.</p>


<h3>Usage</h3>

<pre><code class='language-R'>buildQEcall(qeFtnName,dataName,yName=NULL,opts=NULL,holdout=NULL,
    holdoutArg=TRUE) 
evalr(toexec) 
newDFRow(dta,yName,x,dtaRowNum=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Utilities_+3A_qeftnname">qeFtnName</code></td>
<td>
<p>Quoted name of a <span class="pkg">qeML</span> predictive function.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_dataname">dataName</code></td>
<td>
<p>Quoted name of a data frame.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_yname">yName</code></td>
<td>
<p>Quoted name of a column to be predicted.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_opts">opts</code></td>
<td>
<p>Non-default arguments for the function specified
in <code>qeFtnName</code>.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_holdout">holdout</code></td>
<td>
<p>Size of holdout set, if any.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_holdoutarg">holdoutArg</code></td>
<td>
<p>A value TRUE means the function specified in 
<code>qeFtnName</code> has an argument 'holdout'.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_toexec">toexec</code></td>
<td>
<p>Quoted string containing an R function call.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_dta">dta</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_x">x</code></td>
<td>
<p>An R list specifying fields to be set.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_dtarownum">dtaRowNum</code></td>
<td>
<p>Row number in 'dta' to be used as a basis.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>qeFtnName</code> does what its name implies:  It assembles
a string consisting of a <span class="pkg">qeML</span> function call.  Typically the latter
is then executed via <a href="#topic+evalr">evalr</a>.  See for instance the source code of
<code>qeLeaveOut1Var</code>.
</p>
<p>R's generic <code>predict</code> function generally required that the input
rows match the original training data in name and class.  The
<code>newDFRow</code> function can be used to construct such a row.
</p>


<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# function to list all the objects loaded by the specified package
lsp &lt;- function(pkg) {
   cmd &lt;- paste('ls(package:',pkg,')')
   evalr(cmd)
}
lsp('regtools')
# outputs 
#  [1] "clusterApply"        "clusterApplyLB"      "clusterCall"        
#  [4] "clusterEvalQ"        "clusterExport"       "clusterMap"         
# ...
</code></pre>

<hr>
<h2 id='Variable+20Importance+20Measures'>Variable Importance Measures</h2><span id='topic+qeLeaveOut1Var'></span>

<h3>Description</h3>

<p>Various approaches to assessing relative importance of one's features.</p>


<h3>Usage</h3>

<pre><code class='language-R'>qeLeaveOut1Var(data,yName,qeFtnName,nReps,opts=list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Variable+2B20Importance+2B20Measures_+3A_data">data</code></td>
<td>
<p>Dataframe, training set. Classification case is signaled
via labels column being an R factor.</p>
</td></tr>
<tr><td><code id="Variable+2B20Importance+2B20Measures_+3A_yname">yName</code></td>
<td>
<p>Name of the class labels column.</p>
</td></tr>
<tr><td><code id="Variable+2B20Importance+2B20Measures_+3A_qeftnname">qeFtnName</code></td>
<td>
<p>Quoted <code>qe*</code> function name.</p>
</td></tr>
<tr><td><code id="Variable+2B20Importance+2B20Measures_+3A_nreps">nReps</code></td>
<td>
<p>Number of holdout sets to generate.</p>
</td></tr>
<tr><td><code id="Variable+2B20Importance+2B20Measures_+3A_opts">opts</code></td>
<td>
<p>R list of optional arguments for none, some or all of th
functions in <code>qeFtnList</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many methods have been developed assessing relative importance of one's
features.  A few that we consider most useful are accessible here.
</p>
<p>As a quick assessment, the <code>qeLeave1VarOut</code> function, with call
form as above, simply compares predictive ability with and without
the given feature.
</p>
<p>Some methods rely on reweighting:
</p>

<ul>
<li> <p><code>qeKNN</code> 
</p>
</li>
<li> <p><code>qeRFranger</code>
</p>
</li></ul>

<p>Others make use of order of entry of a variable into the prediction
model:
</p>

<ul>
<li> <p><code>qeFOCI</code>
</p>
</li>
<li> <p><code>qeLASSO</code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Norm Matloff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(pef)
qeLeaveOut1Var(pef,'wageinc','qeLin',5)
# in order of impact, wkswrkd largest, then education etc.

</code></pre>

<hr>
<h2 id='weatherTS'>
Weather Time Series
</h2><span id='topic+weatherTS'></span>

<h3>Description</h3>

<p>Various measurements on weather variables collected by NASA.  Downloaded
via <code>nasapower</code>; see that package for documentation.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
