<!DOCTYPE html><html><head><title>Help for package DirichletReg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DirichletReg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#anova.DirichletRegModel'><p>Compare Dirichlet Regression Models using an LRT</p></a></li>
<li><a href='#ArcticLake'><p>Arctic Lake Data (Aitchison)</p></a></li>
<li><a href='#BloodSamples'><p>Serum Protein Composition in Blood Samples</p></a></li>
<li><a href='#Dirichlet'><p>The Dirichlet Distribution</p></a></li>
<li><a href='#DirichletReg-package'><p>The <span class="pkg">DirichletReg</span> Package</p></a></li>
<li><a href='#DirichletRegData'><p>Prepare Compositional Data</p></a></li>
<li><a href='#DirichletRegModel'><p>Methods for the Class <code>DirichletRegModel</code></p></a></li>
<li><a href='#DirichReg'><p>Fitting a Dirichlet Regression</p></a></li>
<li><a href='#GlacialTills'>
<p>Glacial Tills</p></a></li>
<li><a href='#plot.DirichletRegData'><p>Plot Dirichlet-Distributed Data</p></a></li>
<li><a href='#Reading Accuracy Data'><p>Pammer and Kevan's Data on Reading Skills</p></a></li>
<li><a href='#Rocks'>
<p>Aitchison's Rock Data</p></a></li>
<li><a href='#Simplex-Transformations'><p>Transform Compositional Data for a Simplex</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-04-29</td>
</tr>
<tr>
<td>Title:</td>
<td>Dirichlet Regression</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements Dirichlet regression models.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), Formula</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics, methods, maxLik</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rgl, knitr, rmarkdown, formatR, testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/maiermarco/DirichletReg">https://github.com/maiermarco/DirichletReg</a>
<a href="https://CRAN.R-project.org/package=DirichletReg">https://CRAN.R-project.org/package=DirichletReg</a></td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>ZipData:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Author:</td>
<td>Marco Johannes Maier
    <a href="https://orcid.org/0000-0002-1715-7456"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre, aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marco Johannes Maier &lt;marco_maier@posteo.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Repository/R-Forge/Project:</td>
<td>dirichletreg</td>
</tr>
<tr>
<td>Repository/R-Forge/Revision:</td>
<td>33</td>
</tr>
<tr>
<td>Repository/R-Forge/DateTimeStamp:</td>
<td>2021-05-18 09:47:56</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-18 10:30:03 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-18 10:12:52 UTC; rforge</td>
</tr>
</table>
<hr>
<h2 id='anova.DirichletRegModel'>Compare Dirichlet Regression Models using an LRT</h2><span id='topic+anova.DirichletRegModel'></span>

<h3>Description</h3>

<p>This function allows for pairwise tests of Dirichlet regression models using a likelihood ratio test (<abbr><span class="acronym">LRT</span></abbr>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DirichletRegModel'
anova(object, ..., sorted = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.DirichletRegModel_+3A_object">object</code></td>
<td>
<p>the model to be compared against those listed in ...</p>
</td></tr>
<tr><td><code id="anova.DirichletRegModel_+3A_...">...</code></td>
<td>
<p>models to be tested against the one specified as <code>object</code></p>
</td></tr>
<tr><td><code id="anova.DirichletRegModel_+3A_sorted">sorted</code></td>
<td>
<p>should the models be sorted according to their numbers or parameters?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic is computed <code class="reqn">LR=-2\left[\log(L_a)-\log(L_b)\right]</code> where <code class="reqn">L_i</code> is the likelihood of model <code class="reqn">i</code> with <code class="reqn">df</code> equal to the difference of the number of parameters in the models.
</p>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>Examples</h3>

<pre><code class='language-R'>ALake &lt;- ArcticLake
ALake$AL &lt;- DR_data(ArcticLake[,1:3])
mod0 &lt;- DirichReg(AL ~ 1, ALake)
mod1 &lt;- DirichReg(AL ~ depth, ALake)
mod2 &lt;- DirichReg(AL ~ depth + I(depth^2), ALake)
anova(mod1, mod0, mod2, sorted = TRUE)
</code></pre>

<hr>
<h2 id='ArcticLake'>Arctic Lake Data (Aitchison)</h2><span id='topic+ArcticLake'></span>

<h3>Description</h3>

<p>These data are taken from Aitchison (2003) and contain information on the relation of sediment composition with depth in an Arctic lake.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ArcticLake</code></pre>


<h3>Format</h3>

<p>A data frame with 39 observations on the following 4 variables:
</p>

<dl>
<dt><code>sand</code>, <code>silt</code>, <code>clay</code></dt><dd><p>relative frequencies of sand, silt, and clay</p>
</dd>
<dt><code>depth</code></dt><dd><p>water depth in meters</p>
</dd>
</dl>



<h3>Source</h3>

<p>Aitchison, J. (2003). <em>The Statistical Analysis of Compositional Data.</em> The Blackburn Press, Caldwell, NJ.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(ArcticLake)
AL &lt;- DR_data(ArcticLake[,1:3])
plot(AL)
summary(AL)
</code></pre>

<hr>
<h2 id='BloodSamples'>Serum Protein Composition in Blood Samples</h2><span id='topic+BloodSamples'></span>

<h3>Description</h3>

<p>These data (Aitchison, 2003) list blood samples' compositions of <em>Albumin</em>, <em>Pre-Albumin</em>, <em>Globulin A</em>, and <em>Globulin B</em> in relation to two types of diseases. 14 patients suffer from disease A, 16 from disease B and 6 are unclassified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BloodSamples</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations on the following 6 variables.
</p>

<dl>
<dt><code>Albumin</code>, <code>Pre.Albumin</code>, <code>Globulin.A</code>, <code>Globulin.B</code></dt><dd><p>the amounts of Albumin, Pre-Albumin, Globulin A, and Globulin B.</p>
</dd>
<dt><code>Disease</code></dt><dd><p>diagnosis of disease <code>A</code>, <code>B</code>, or <code>NA</code> for unclassified observations.</p>
</dd>
<dt><code>New</code></dt><dd><p>a factor indicating whether the observations are old and classified (<code>No</code>) or new and unclassified (<code>Yes</code>).</p>
</dd>
</dl>



<h3>Source</h3>


<p>Aitchison, J. (2003). <em>The Statistical Analysis of Compositional Data.</em> The Blackburn Press, Caldwell, NJ.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(BloodSamples)
Bl &lt;- DR_data(BloodSamples[,1:4])
summary(Bl)
</code></pre>

<hr>
<h2 id='Dirichlet'>The Dirichlet Distribution</h2><span id='topic+rdirichlet'></span><span id='topic+ddirichlet'></span><span id='topic+ddirichlet_R'></span>

<h3>Description</h3>

<p>Density function and random number generation for the Dirichlet distribution</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdirichlet(n, alpha)

ddirichlet(x, alpha, log = FALSE, sum.up = FALSE)

ddirichlet_R(x, alpha, log = FALSE, sum.up = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dirichlet_+3A_n">n</code></td>
<td>
<p>number of random observations to draw</p>
</td></tr>
<tr><td><code id="Dirichlet_+3A_x">x</code></td>
<td>
<p>a matrix containing observations</p>
</td></tr>
<tr><td><code id="Dirichlet_+3A_alpha">alpha</code></td>
<td>
<p>the Dirichlet distribution's parameters. Can be a vector (one set of parameters for all observations) or a matrix (a different set of parameters for each observation), see &ldquo;Details&rdquo;</p>
</td></tr>
<tr><td><code id="Dirichlet_+3A_log">log</code></td>
<td>
<p>if <code>TRUE</code>, logarithmic densities are returned</p>
</td></tr>
<tr><td><code id="Dirichlet_+3A_sum.up">sum.up</code></td>
<td>
<p>if <code>TRUE</code>, the (log-)likelihood is returned</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Dirichlet distribution is a multidimensional generalization of the Beta distribution where each dimension is governed by an <code class="reqn">\alpha</code>-parameter.
Formally this is
</p>
<p style="text-align: center;"><code class="reqn">%
    \mathcal{D}(\alpha_i)=\left[\left.\Gamma(\sum_{i}\alpha_i)\right/\prod_i\Gamma(\alpha_i)\right]\prod_{i}y_i^{\alpha_i-1}%
  </code>
</p>

<p>Usually, <code>alpha</code> is a vector thus the same parameters will be used for all observations.
If <code>alpha</code> is a matrix, a complete set of <code class="reqn">\alpha</code>-parameters must be supplied for each observation.
</p>
<p><code>log</code> returns the logarithm of the densities (therefore the log-likelihood) and <code>sum.up</code> returns the product or sum and thereby the likelihood or log-likelihood.
</p>
<p>Dirichlet (log-)densities are by default computed using C-routines (<code>ddirichlet_log_vector</code> and <code>ddirichlet_log_matrix</code>), a version only using R is provided by <code>ddirichlet_R</code>.
Caution: Although <code>.C()</code> can be used to call the C routines directly, R will crash or produce wrong values, if, e.g., data types are not set properly.
</p>


<h3>Value</h3>

<table>
<tr><td><code>rdirichlet</code></td>
<td>
<p>returns a matrix with random numbers according to the supplied alpha vector or matrix.</p>
</td></tr>
<tr><td><code>ddirichlet</code></td>
<td>
<p>returns a vector of densities (if <code>sum.up = FALSE</code>) or the (log-)likelihood (if <code>sum.up = TRUE</code>) for the given data and alphas. Returns <code>NaN</code> if any element of <code>alpha</code> is <code class="reqn">\leq0</code>.</p>
</td></tr>
<tr><td><code>ddirichlet_R</code></td>
<td>
<p>as <code>ddirichlet</code>, only implemented purely in R.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- rdirichlet(100, c(5, 5, 10))

a.mat &lt;- cbind(1:10, 5, 10:1)
a.mat
X2 &lt;- rdirichlet(10, a.mat)
# note how the probabilities in the first an last column relate to a.mat
round(X2, 2)

ddirichlet(X1, c(5, 5, 10))
ddirichlet(X2, a.mat)

ddirichlet(X2[1:3,], c(1, 2, -1))
ddirichlet(X2[1:3,], c(1, 2, -1), sum.up = TRUE)
</code></pre>

<hr>
<h2 id='DirichletReg-package'>The <span class="pkg">DirichletReg</span> Package</h2><span id='topic+DirichletReg'></span><span id='topic+DirichletReg'></span>

<h3>Description</h3>


<p>This package provides a functions to analyze compositional data using Dirichlet regression methods.
</p>

<table>
<tr>
 <td style="text-align: left;">
Package:</td><td style="text-align: left;">DirichletReg</td>
</tr>
<tr>
 <td style="text-align: left;">
Type:   </td><td style="text-align: left;">Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version:</td><td style="text-align: left;">0.7-1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date:   </td><td style="text-align: left;">2021-04-29</td>
</tr>
<tr>
 <td style="text-align: left;">
License:</td><td style="text-align: left;">GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>Examples</h3>

<pre><code class='language-R'>  example(plot.DirichletRegData)
  example(DirichReg)
</code></pre>

<hr>
<h2 id='DirichletRegData'>Prepare Compositional Data</h2><span id='topic+DirichletRegData'></span><span id='topic+DR_data'></span><span id='topic+print.DirichletRegData'></span><span id='topic+summary.DirichletRegData'></span>

<h3>Description</h3>

<p>This function prepares a matrix with compositional variables for further processing in the <span class="pkg">DirichletReg</span> package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>DR_data(Y, trafo = sqrt(.Machine$double.eps), base = 1,
    norm_tol = sqrt(.Machine$double.eps))

## S3 method for class 'DirichletRegData'
print(x, type = c("processed", "original"), ...)

## S3 method for class 'DirichletRegData'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="DirichletRegData_+3A_y">Y</code></td>
<td>

<p>A <code>matrix</code> or <code>data.frame</code> with nonnegative values of all compositional variables (in some cases, a vector is also permissible, see &ldquo;Details&rdquo;).
</p>
</td></tr>
<tr><td><code id="DirichletRegData_+3A_trafo">trafo</code></td>
<td>

<p>Either a logical or numeric value.
Transformation of variables causes the values to shrink away from extreme values of 0 and 1, see &ldquo;Details&rdquo;.
<br />    
If logical, it will force (<code>TRUE</code>) or suppress (<code>FALSE</code>) transformation.
Suppressing transformation in the presence of extreme values (0 and 1) will result in an error.
<br />
If <code>trafo</code> is numeric it is used as a &ldquo;threshold&rdquo;, so transformation will be applied if values in <code>Y</code> are <code class="reqn">y &lt; \mathtt{trafo}</code> or <code class="reqn">y &gt; \left(1-\mathtt{trafo}\right)</code>.
</p>
</td></tr>
<tr><td><code id="DirichletRegData_+3A_base">base</code></td>
<td>

<p>The &ldquo;base&rdquo; component to use in the reparametrized model
</p>
</td></tr>
<tr><td><code id="DirichletRegData_+3A_norm_tol">norm_tol</code></td>
<td>

<p>Due to numerical precision, row sums of <code class="reqn">\mathbf{Y}</code> may not be <em>exactly</em> equal to 1.
Therefore, <code>norm_tol</code> is a small non-negative value (default: <code>sqrt(.Machine$double.eps)</code>) which represents the tolerance when testing for &ldquo;near equality&rdquo; to 1 (see <code><a href="base.html#topic+all.equal">all.equal</a></code>).
</p>
</td></tr>
<tr><td><code id="DirichletRegData_+3A_x">x</code></td>
<td>

<p>A <code>DirichletRegData</code> object
</p>
</td></tr>
<tr><td><code id="DirichletRegData_+3A_type">type</code></td>
<td>

<p>Displays either the (possibly normalized or transformed) <code>"processed"</code> or <code>"original"</code> data
</p>
</td></tr>
<tr><td><code id="DirichletRegData_+3A_object">object</code></td>
<td>

<p>A <code>DirichletRegData</code> object
</p>
</td></tr>
<tr><td><code id="DirichletRegData_+3A_...">...</code></td>
<td>

<p>Further arguments
</p>
</td></tr>
</table>


<h3>Details</h3>



<h4><code>Y</code></h4>


<p><code>Y</code> is a <code>matrix</code> or <code>data.frame</code> containing compositional variables.
If they do not sum up to 1 for all observations, normalization is forced where each row entry is divided by the row's sum (a warning will be issued that normalization was applied).<br />
In case one row-entry (or more) is <code>NA</code>, the whole row will be returned as <code>NA</code>.
Beta-distributed variables can be supplied as a single vector which, however, has to have values in the interval <code class="reqn">[0,\,1]</code>.
The second variable will be generated (<code>1 - Y</code>) and a <code>matrix</code> consisting of the columns <code>1 - Y</code> and <code>Y</code> will be returned.
A message will be issued that a beta-distributed variable was assumed and that this assumtion needs to be checked.
</p>



<h4><code>trafo</code></h4>


<p>The transformation (done if <code>trafo = TRUE</code>) is a generalization of that proposed by Smithson and Verkuilen (2006) that transforms each component <code class="reqn">y</code> of <code class="reqn">Y</code> by computing <code class="reqn">y^{*}=\frac{y(n-1)+\frac{1}{2}}{n}</code> where <code class="reqn">n</code> is the number of observations in <code class="reqn">Y</code> (this approach is also used in the package <span class="pkg">betareg</span>, see Cribari-Neto &amp; Zeileis, 2010).<br />
For an arbitrary number of dimensions (or variables) <code class="reqn">d</code> the transformation is <code class="reqn">y^{*}=\frac{y(n-1)+\frac{1}{d}}{n}</code>.
</p>



<h4><code>base</code></h4>


<p>To set the base (i.e., omitted) component of <code>Y</code> for the &ldquo;alternative&rdquo; (mean/precision) model, the argument <code>base</code> can be used. This is by default set to the first variable in <code>Y</code> (if a vector is be supplied, the column <code>1 - Y</code> becomes the base component).<br />
Note that the definition can be overruled in <code><a href="#topic+DirichReg">DirichReg</a></code>.
</p>



<h4><code>x</code> and <code>object</code></h4>


<p>Objects created by <code>DR_data</code>.
</p>



<h4><code>type</code></h4>


<p>specifies for the print method whether the original or processed data are displayed.
</p>



<h3>Value</h3>

<p>The function returns a <code>matrix</code> object of class <code>DirichletRegData</code> with the following attributes:
</p>
<table>
<tr><td><code>attr(*</code>, <code>"dimnames")</code></td>
<td>
<p>a list with two entries, row names (by default <code>NULL</code>) and column names.</p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"Y.original")</code></td>
<td>
<p>the original data</p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"dims")</code></td>
<td>
<p>number of dimensions of <code>Y</code> (i.e., number of columns)</p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"dim.names")</code></td>
<td>
<p>the number of components in <code>Y</code></p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"obs")</code></td>
<td>
<p>number of observations of <code>Y</code> (i.e., number of rows)</p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"valid_obs")</code></td>
<td>
<p>number of valid observations</p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"normalized")</code></td>
<td>
<p>a logical value indicating whether the data were normalized</p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"transformed")</code></td>
<td>
<p>a logical value indicating whether the data were transformed</p>
</td></tr>
<tr><td><code>attr(*</code>, <code>"base")</code></td>
<td>
<p>number of the variable used as the base in the reparametrized model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>References</h3>

<p>Smithson, M. &amp; Verkuilen, J. (2006). A Better Lemon Squeezer? Maximum-Likelihood Regression With Beta-Distributed Dependent Variables. <em>Psychological Methods, 11</em>(1), 54&ndash;71.
</p>
<p>Cribari-Neto, F. &amp; Zeileis, A. (2010). Beta Regression in R. <em>Journal of Statistical Software, 34</em>(2), 1&ndash;24.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a DirichletRegData object from the Arctic Lake data
head(ArcticLake[, 1:3])
AL &lt;- DR_data(ArcticLake[, 1:3])
summary(AL)
head(AL)
</code></pre>

<hr>
<h2 id='DirichletRegModel'>Methods for the Class <code>DirichletRegModel</code></h2><span id='topic+print.DirichletRegModel'></span><span id='topic+summary.DirichletRegModel'></span><span id='topic+fitted.DirichletRegModel'></span><span id='topic+predict.DirichletRegModel'></span><span id='topic+residuals.DirichletRegModel'></span><span id='topic+logLik.DirichletRegModel'></span><span id='topic+AIC.DirichletRegModel'></span><span id='topic+BIC.DirichletRegModel'></span><span id='topic+nobs.DirichletRegModel'></span><span id='topic+vcov.DirichletRegModel'></span><span id='topic+update.DirichletRegModel'></span><span id='topic+confint.DirichletRegModel'></span><span id='topic+drop1.DirichletRegModel'></span><span id='topic+print.DirichletRegConfint'></span>

<h3>Description</h3>

<p>These are available methods for the results of Dirichlet regression models and objects of class <code>DirichletRegModel</code>.
These methods contain functions for <code>print</code> and <code>summary</code> of the data, generate <code>fitted</code> values and predicting new values using <code>predict</code>.
Various types of <code>residuals</code> are implemented and <code>confint</code> can be used to compute confidence intervals of the parameters.
Furthermore <code>logLik</code> extracts the log-likelihood of the model and <code>vcov</code> extracts the covariance matrix of the parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DirichletRegModel'
print(x, digits = max(3, getOption("digits") - 3), ...)

## S3 method for class 'DirichletRegModel'
summary(object, ...)

## S3 method for class 'DirichletRegModel'
fitted(object, mu = TRUE, alpha = FALSE, phi = FALSE, ...)

## S3 method for class 'DirichletRegModel'
predict(object, newdata, mu = TRUE, alpha = FALSE, phi = FALSE, ...)

## S3 method for class 'DirichletRegModel'
residuals(object, type = c("standardized", "composite", "raw"), ...)

## S3 method for class 'DirichletRegModel'
confint(object, parm, level, ..., type=c("all", "beta", "gamma"), exp = FALSE)

## S3 method for class 'DirichletRegConfint'
print(x, digits = 3, ...)

## S3 method for class 'DirichletRegModel'
logLik(object, ...)

## S3 method for class 'DirichletRegModel'
AIC(object, ..., k = 2)

## S3 method for class 'DirichletRegModel'
BIC(object, ...)

## S3 method for class 'DirichletRegModel'
nobs(object, ...)

## S3 method for class 'DirichletRegModel'
vcov(object, ...)

## S3 method for class 'DirichletRegModel'
update(object, formula., ..., evaluate = TRUE)

## S3 method for class 'DirichletRegModel'
drop1(object, scope, test = c("LRT", "none"), k = 2, sort = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DirichletRegModel_+3A_x">x</code></td>
<td>
<p>an object of class <code>DirichletRegModel</code></p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_object">object</code></td>
<td>
<p>an object of class <code>DirichletRegModel</code> or <code>DirichletRegConfint</code> for printing an object obtained by <code>confint.DirichletRegModel</code></p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_alpha">alpha</code></td>
<td>
<p>logical; returns alpha values</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_mu">mu</code></td>
<td>
<p>logical; returns expected values</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_phi">phi</code></td>
<td>
<p>logical; returns precision values</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_type">type</code></td>
<td>
<p>for <code>residuals</code>: defines the type of residuals to be computed <code>"standardized"</code> (i.e., Pearson), <code>"composite"</code>, or <code>"raw"</code>
</p>
<p>for <code>confint</code>: defines the type of parameter (<code>"all"</code>, <code>"beta"</code>, or <code>"gamma"</code>) for which confidence values are returned</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_newdata">newdata</code></td>
<td>
<p>a <code>data.frame</code> containing new observations</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_k">k</code></td>
<td>
<p>number for the weighting of parameters</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_parm">parm</code></td>
<td>
<p>a vector containing names of the parameters to print</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_level">level</code></td>
<td>
<p>(a vector of) confidence level(s), defaults to <code>.95</code></p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_exp">exp</code></td>
<td>
<p>logical; returns parameters in exponentiated form</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_digits">digits</code></td>
<td>
<p>the number of digits in the output</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_formula.">formula.</code></td>
<td>
<p>the new formula to be updated, see <code><a href="stats.html#topic+update.formula">update.formula</a></code> and <code><a href="Formula.html#topic+update.Formula">update.Formula</a></code></p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_evaluate">evaluate</code></td>
<td>
<p>if <code>FALSE</code> the updated call will be returned, but not evaluated</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_scope">scope</code></td>
<td>
<p>defines the scope of variables to be dropped, see <code><a href="stats.html#topic+drop1">drop1</a></code></p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_test">test</code></td>
<td>
<p>defines the type of test for <code>drop1</code></p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_sort">sort</code></td>
<td>
<p>if <code>TRUE</code>, p-values will be sorted in decreasing order.</p>
</td></tr>
<tr><td><code id="DirichletRegModel_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>Examples</h3>

<pre><code class='language-R'>ALake &lt;- ArcticLake
ALake$AL &lt;- DR_data(ArcticLake[, 1:3])

mod1 &lt;- DirichReg(AL ~ depth + I(depth^2) | depth, data = ALake, model="alternative")

update(mod1, . ~ . | . + I(depth^2), evaluate = FALSE)
mod1

drop1(mod1)   ### issues a caveat when used for the first time in an R session

summary(mod1)

head(fitted(mod1))

predict(mod1, newdata = data.frame("depth" = seq(10, 100, 10)))

head(residuals(mod1))

confint(mod1)
confint(mod1, exp = TRUE)

logLik(mod1)
round(vcov(mod1), 5)
</code></pre>

<hr>
<h2 id='DirichReg'>Fitting a Dirichlet Regression</h2><span id='topic+DirichReg'></span>

<h3>Description</h3>

<p>This function allows for fitting Dirichlet regression models using two different parametrizations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DirichReg(formula, data, model = c("common", "alternative"),
          subset, sub.comp, base, weights, control, verbosity = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DirichReg_+3A_formula">formula</code></td>
<td>
<p>the model formula (for different specifications see &ldquo;Details&rdquo;)</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> containing independent <strong>and</strong> dependent variables</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_model">model</code></td>
<td>
<p>specifies whether the <code>"common"</code> (<code class="reqn">\alpha\mathrm{s}</code>) or <code>"alternative"</code> (<code class="reqn">\mu/\phi</code>) parametrization is employed (see &ldquo;Details&rdquo;)</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_subset">subset</code></td>
<td>
<p>estimates the model for a subset of the data</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_sub.comp">sub.comp</code></td>
<td>
<p>analyze a subcomposition by selecting specific components (see &ldquo;Details&rdquo;)</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_base">base</code></td>
<td>
<p>redefine the base variable</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_weights">weights</code></td>
<td>
<p>frequency weights</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_control">control</code></td>
<td>
<p>a list containing control parameters used for the optimization</p>
</td></tr>
<tr><td><code id="DirichReg_+3A_verbosity">verbosity</code></td>
<td>
<p>prints information about the function's progress, see Details</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Formula Specification and Models</h4>

<p><code>formula</code> determines the used predictors.
The responses <strong>must</strong> be prepared by <code><a href="#topic+DR_data">DR_data</a></code> and can be optionally stored in the object containing all covariates which is then specified as the argument <code>data</code>.
(Although &ldquo;on-the-fly&rdquo; processing of <code>DR_data</code> in a formula works, it is only intended for testing purposes and may be removed at any time &ndash; use at your own risk.)
</p>
<p>There are two different parametrization (controlled by the argument <code>model</code>, see below):
</p>

<ul>
<li><p> the <em>&ldquo;common&rdquo;</em> param. that models each <code class="reqn">\alpha</code> by an (possibly individual) set of predictors, and
</p>
</li>
<li><p> the <em>&ldquo;alternative&rdquo;</em> param. that models expected values (<code class="reqn">\mu</code>; as in multinomial logistic regression) and precision parameters (<code class="reqn">\phi</code>) with two sets of predictors.
</p>
</li></ul>

<p>As the two models offer different modeling strategies, the specification of their formulae differ:
</p>


<h5>Formulae for the &ldquo;Common&rdquo; Model</h5>

<p>The simplest possible model here is to include only an intercept for all components.
If <code>DV</code> is the <em>&lsquo;dependent variable&rsquo;</em> (i.e., compositional data) with three components, we can request this null-model by <code>DV ~ 1</code>.
We always have at least two dependent variables, so simple formulae as the one given above will be expanded to <code>DV ~ 1 | 1 | 1</code>, because <code>DV</code> hast three components.
Likewise, it is possible to specify a common set of predictors for all components, as in <code>DV ~ p1 * p2</code>, where <code>p1</code> and <code>p2</code> are predictors.
</p>
<p>If the covariates of the components shall differ, one has to set up a complete formula for each subcomposition, using <code>|</code> as separators between the components, for example, <code>DV ~ p1 | p1 + p2 | p1 * p2</code> will lead to a model where the first response in <code>DV</code> will be modeled using <code>p1</code>, the second will be predicted by <code>p1 + p2</code> and the third by <code>p1 * p2</code>.
Note that if you use the latter approach, the predictors have to be stated
explicitly for all response variables.
</p>



<h5>Formulae for the &ldquo;Alternative&rdquo; Model</h5>

<p>The simplest possible model here is to include an intercept for all components (except the base) and an intercept for precision. This can be achieved by <code>DV ~ 1</code>, which is expanded to <code>DV ~ 1 | 1</code>. The part modeling the &lsquo;mean&rsquo; (first element on the right-hand side) is mandatory, if no specification for precision is included, an intercept will be added. Note that you need to set <code>model = "alternative"</code> to use this parametrization!
</p>
<p>The alternative parametrization consists of two parts: modeled expected values (<code class="reqn">\mu</code>) and their &lsquo;precision&rsquo; (<code class="reqn">\phi</code>). 
As in multinomial logistic regression, one response variable is omitted (by default the first, but this can be changed by the <code>base</code> argument in <code><a href="#topic+DR_data">DR_data</a></code> or <code>DirichReg</code>) and for the rest a set of predictors is used with a multinomial logit-link.
For precisions, a different set of predictors can be set up using a log-link.
</p>
<p><code>DV ~ p1 * p2 | p1 + p2</code> will set up a model where the expected values are predicted by <code>p1 * p2</code> and precision are modeled using <code>p1 + p2</code>.
</p>




<h4>Data Preparation</h4>

<p>The <code>data</code> argument accepts a <code>data.frame</code> that <strong>must</strong> include the dependent variable as a named element (see examples how to do this).
</p>



<h4>Changing the Base Component and Analyzing Subcompositions</h4>

<p>The base-component (i.e., omitted component) is initially set during the stage of data preparation <code><a href="#topic+DR_data">DR_data</a></code>, but can easily be changed using the argument <code>base</code> which takes integer values from 1 to the maximum number of components.
</p>
<p>If a data set contains a large number of components, of which only a few are relevant, the latter can be &lsquo;sorted out&rsquo; and the irrelevant (i.e., not selected) components will be aggregated into a single variable (row sums) that automatically becomes the base category for the model, unless specified otherwise by <code>base</code>. The positioning of variables will necessarily change: the aggregated variable takes the first column and the others are appended in their order of selection.
</p>



<h4>Subsets and Weights</h4>

<p>Using <code>subset</code>, the model can be fitted only to a part of the data, for more information about this functionality, see <code><a href="base.html#topic+subset">subset</a></code>.<br />
Note that, unlike in <code><a href="stats.html#topic+glm">glm</a></code>, <code>weights</code> are <strong>not</strong> treated as prior weights, but as frequency weights!
</p>



<h4>Optimization and Verbosity</h4>

<p>Using the <code>control</code> argument, the settings passed to the optimizers can be altered.
This argument takes a named list.
To supply user-defined starting values, use <code>control = list(sv=c(...))</code> and supply a vector containing initial values for all parameters.
Optimizer-specific options include the number of iterations (<code>iterlim = 1000</code>) and convergence criteria for the BFGS- and NR-optimization ((<code>tol1 = 1e-5</code>) and (<code>tol2 = 1e-10</code>)).
</p>
<p>Verbosity takes integer values from <code>0</code> to <code>4</code>.
<code>0</code>, no information is printed (default).
<code>1</code> prints information about 3 stages (preparation, starting values, estimation).
<code>2</code> prints little information about optimization (<code>verbosity</code> values greater than one are passed to <code>print.default = verbosity - 1</code> of <code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code> and <code><a href="maxLik.html#topic+maxNR">maxNR</a></code>).
<code>3</code> prints more information about optimization.
<code>4</code> prints all information about optimization.
</p>



<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>[<code>language</code>] function call</p>
</td></tr>
<tr><td><code>parametrization</code></td>
<td>
<p>[<code>character</code>] used parametrization</p>
</td></tr>
<tr><td><code>varnames</code></td>
<td>
<p>[<code>character</code>] components' names</p>
</td></tr>
<tr><td><code>n.vars</code></td>
<td>
<p>[<code>numeric</code>] vector with the number of parameters per set of predictors</p>
</td></tr>
<tr><td><code>dims</code></td>
<td>
<p>[<code>numeric</code>] number of components</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>[<code>numeric</code>] used components</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>[<code>numeric list</code>] sets of predictors</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>[<code>numeric list</code>] sets of predictors (only for the alternative parametrization)</p>
</td></tr>

<tr><td><code>sub.comp</code></td>
<td>
<p>[<code>numeric</code>] vector of single components</p>
</td></tr>
<tr><td><code>base</code></td>
<td>
<p>[<code>numeric</code>] base (only for the alternative parametrization)</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>[<code>numeric</code>] vector of frequency weights</p>
</td></tr>
<tr><td><code>orig.resp</code></td>
<td>
<p>[<code>DirichletRegData</code>] the original response</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>[<code>data.frame</code>] original data</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>[<code>data.frame</code>] used data</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>[<code>Formula</code>] expanded formula</p>
</td></tr>
<tr><td><code>mf_formula</code></td>
<td>
<p>[<code>language</code>] expression for generating the model frame</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>[<code>numeric</code>] number of parameters</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>[<code>numeric</code>] named vector of parameters</p>
</td></tr>
<tr><td><code>coefnames</code></td>
<td>
<p>[<code>character</code>] names of the parameters</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>[<code>list of matrices</code>] list containing alpha's, mu's, phi's for the observations</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>[<code>numeric</code>] the log-likelihood</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>[<code>matrix</code>] covariance-matrix of parameter estimates</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>[<code>matrix</code>] (observed) Hessian</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>[<code>numeric</code>] vector of standard errors</p>
</td></tr>
<tr><td><code>optimization</code></td>
<td>
<p>[<code>list</code>] contains details about the optimization process provided by <code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code> and <code><a href="maxLik.html#topic+maxNR">maxNR</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>Examples</h3>

<pre><code class='language-R'>ALake &lt;- ArcticLake
ALake$Y &lt;- DR_data(ALake[,1:3])

# fit a quadratic Dirichlet regression models ("common")
res1 &lt;- DirichReg(Y ~ depth + I(depth^2), ALake)

# fit a Dirichlet regression with quadratic predictor for the mean and
# a linear predictor for precision ("alternative")
res2 &lt;- DirichReg(Y ~ depth + I(depth^2) | depth, ALake, model="alternative")

# test both models
anova(res1, res2)

res1
summary(res2)
</code></pre>

<hr>
<h2 id='GlacialTills'>
Glacial Tills
</h2><span id='topic+GlacialTills'></span>

<h3>Description</h3>

<p>Data from Aitchison (2003)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GlacialTills</code></pre>


<h3>Format</h3>

<p>A data frame with 92 observations on the following 5 variables.
</p>

<dl>
<dt><code>Red.Sandstone</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Gray.Sandstone</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Crystalline</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Miscellaneous</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Pcount</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Aitchison, J. (2003). <em>The Statistical Analysis of Compositional Data.</em>
The Blackburn Press, Caldwell, NJ.
</p>

<hr>
<h2 id='plot.DirichletRegData'>Plot Dirichlet-Distributed Data</h2><span id='topic+plot.DirichletRegData'></span><span id='topic+lines.DirichletRegData'></span>

<h3>Description</h3>

<p>With this function you can plot Dirichlet-distributed data in 2, 3 and 4 dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DirichletRegData'
plot(x, dims, ticks = TRUE, ref.lines = NULL, dim.labels, a2d = list(colored =
  TRUE, c.grid = TRUE, col.scheme = c("dims", "entropy"), entropy.contours =
  FALSE, entropy.colors = FALSE), a3d = list(rgl = TRUE, ...), rug = TRUE,
  reset_par = TRUE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.DirichletRegData_+3A_x">x</code></td>
<td>
<p>data prepared with <code><a href="#topic+DR_data">DR_data</a></code></p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_dims">dims</code></td>
<td>
<p>select two, three, or four Dimensions of your data <code>x</code> to plot</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_ticks">ticks</code></td>
<td>
<p>display ticks?</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_ref.lines">ref.lines</code></td>
<td>
<p>.</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_dim.labels">dim.labels</code></td>
<td>
<p>a character vector giving labels for the dimensions/variables</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_a2d">a2d</code></td>
<td>
<p>a named list of settings for ternary plots (3 variables), see Details</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_a3d">a3d</code></td>
<td>
<p>a named list of settings for quaternary plots (4 variables), see Details</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_rug">rug</code></td>
<td>
<p>display a rug for a one-dimensional plot (2 variables)</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_reset_par">reset_par</code></td>
<td>
<p>reset graphical parameters of <code><a href="#topic+DR_data">DR_data</a></code> after creating a two-dimensional plot (2 variables), see Details</p>
</td></tr>
<tr><td><code id="plot.DirichletRegData_+3A_...">...</code></td>
<td>
<p>further graphical arguments as <code>col</code>, <code>pch</code>, <code>cex</code>, ...</p>
</td></tr>




</table>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>Examples</h3>

<pre><code class='language-R'># plot of "Sand" in the Arctic Lake data set
plot(DR_data(ReadingSkills[, 1]), main="Reading Accuracy")

# ternary plot of Arctic Lake data
plot(DR_data(ArcticLake[, 1:3]), a2d = list(colored = FALSE))
</code></pre>

<hr>
<h2 id='Reading+20Accuracy+20Data'>Pammer and Kevan's Data on Reading Skills</h2><span id='topic+ReadingSkills'></span>

<h3>Description</h3>

<p>These data provide transformed reading accuracy scores predicted by <abbr><span class="acronym">IQ</span></abbr> and diagnosed dyslexia.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadingSkills</code></pre>


<h3>Format</h3>

<p>A data frame containing 44 observations on 3 variables.
</p>

<dl>
<dt><code>accuracy</code></dt><dd><p>reading accuracy score transformed to fit into <code class="reqn">(0,\,1)</code></p>
</dd>
<dt><code>dyslexia</code></dt><dd><p>a factor with the diagnosis of dyslexia (&ldquo;yes&rdquo; or &ldquo;no&rdquo;)</p>
</dd>
<dt><code>iq</code></dt><dd><p>non-verbal <abbr><span class="acronym">IQ</span></abbr> (<code class="reqn">z</code>-scores; <code class="reqn">\mu=0</code>, <code class="reqn">\sigma^2=1</code>)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Example 3 from <a href="http://www.michaelsmithson.online/stats/betareg/betareg.html">http://www.michaelsmithson.online/stats/betareg/betareg.html</a></p>

<hr>
<h2 id='Rocks'>
Aitchison's Rock Data
</h2><span id='topic+Rocks'></span>

<h3>Description</h3>

<p>A compilation of four datasets listed in Aitchison (2003)
</p>
<p>Each type of rock has 25 observations &ndash; to use only a certain type of rock, see &ldquo;Details&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rocks</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations on the following 8 variables.
</p>

<dl>
<dt><code>Albite</code>, <code>Blandite</code>, <code>Cornite</code>, <code>Daubite</code>, <code>Endite</code></dt><dd><p>numeric vectors</p>
</dd>
<dt><code>depth</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>porosity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>type</code></dt><dd><p>a factor with levels <code>Boxite</code> <code>Coxite</code> <code>Hongite</code> <code>Kongite</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Aitchison, J. (2003). <em>The Statistical Analysis of Compositional Data.</em> The Blackburn Press, Caldwell, NJ.
</p>

<hr>
<h2 id='Simplex-Transformations'>Transform Compositional Data for a Simplex</h2><span id='topic+toQuaternary'></span><span id='topic+toQuaternaryVectors'></span><span id='topic+toTernary'></span><span id='topic+toTernaryVectors'></span><span id='topic+toSimplex'></span>

<h3>Description</h3>

<p>These functions transform a matrix with three or four components to fit into a two- or three-dimensional simplex (triangle or tetrahedron).</p>


<h3>Usage</h3>

<pre><code class='language-R'>toSimplex(x)

toTernary(abc)
toTernaryVectors(c1, c2, c3)

toQuaternary(abcd)
toQuaternaryVectors(c1, c2, c3, c4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Simplex-Transformations_+3A_x">x</code></td>
<td>
<p>a matrix-like object with 3 or 4 columns.</p>
</td></tr>
<tr><td><code id="Simplex-Transformations_+3A_abc">abc</code></td>
<td>
<p>a matrix-like object with 3 columns.</p>
</td></tr>
<tr><td><code id="Simplex-Transformations_+3A_abcd">abcd</code></td>
<td>
<p>a matrix-like object with 4 columns.</p>
</td></tr>
<tr><td><code id="Simplex-Transformations_+3A_c1">c1</code></td>
<td>
<p>a numeric vector with values of the first component.</p>
</td></tr>
<tr><td><code id="Simplex-Transformations_+3A_c2">c2</code></td>
<td>
<p>a numeric vector with values of the second component.</p>
</td></tr>
<tr><td><code id="Simplex-Transformations_+3A_c3">c3</code></td>
<td>
<p>a numeric vector with values of the third component.</p>
</td></tr>
<tr><td><code id="Simplex-Transformations_+3A_c4">c4</code></td>
<td>
<p>a numeric vector with values of the fourth component.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of these functions are only used internally, but sometimes it might be useful to plot &ldquo;custom&rdquo; ternary or quaternary graphics.
</p>
<p>Note that, apart from <code>toSimplex()</code>, functions do not have <em>any</em> checks, so it is advisable to use this function if elements are added to plots or own graphics are created.
</p>


<h3>Value</h3>

<p>The function returns a <code>matrix</code> object with coordinates in two or three dimensions</p>


<h3>Note</h3>

<p>In prior versions (up to 0.5-0), an unexported function <code>coord.trafo()</code> was used internally and could also be accessed via <code>DirichletReg:::coord.trafo()</code>.
</p>
<p>If you have used this in your code, you will get a message that the function is now deprecated and will become defunct in the future.
Use <code>toSimplex()</code> instead.
</p>


<h3>Author(s)</h3>

<p>Marco J. Maier</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a DirichletRegData object from the Arctic Lake data
"to be added"
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
