<!DOCTYPE html><html><head><title>Help for package otsad</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {otsad}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ambient_temperature_system_failure'><p>ambient_temperature_system_failure.</p></a></li>
<li><a href='#art_daily_flatmiddle'><p>art_daily_flatmiddle.</p></a></li>
<li><a href='#art_daily_jumpsdown'><p>art_daily_jumpsdown</p></a></li>
<li><a href='#art_daily_jumpsup'><p>art_daily_jumpsup</p></a></li>
<li><a href='#art_daily_nojump'><p>art_daily_nojump</p></a></li>
<li><a href='#art_increase_spike_density'><p>art_increase_spike_density</p></a></li>
<li><a href='#art_load_balancer_spikes'><p>art_load_balancer_spikes.</p></a></li>
<li><a href='#ContextualAnomalyDetector'><p>Contextual Anomaly Detector - Open Source (CAD)</p></a></li>
<li><a href='#CpKnnCad'><p>Classic processing KNN based Conformal Anomaly Detector (KNN-CAD)</p></a></li>
<li><a href='#CpPewma'><p>Classic Processing Probabilistic-EWMA (PEWMA).</p></a></li>
<li><a href='#CpSdEwma'><p>Classic Processing Shift-Detection based on EWMA (SD-EWMA).</p></a></li>
<li><a href='#CpTsSdEwma'><p>Classic Processing Two-Stage Shift-Detection based on EWMA</p></a></li>
<li><a href='#cpu_utilization_asg_misconfiguration'><p>cpu_utilization_asg_misconfiguration.</p></a></li>
<li><a href='#ec2_cpu_utilization_24ae8d'><p>ec2_cpu_utilization_24ae8d.</p></a></li>
<li><a href='#ec2_cpu_utilization_53ea38'><p>ec2_cpu_utilization_53ea38.</p></a></li>
<li><a href='#ec2_cpu_utilization_5f5533'><p>ec2_cpu_utilization_5f5533.</p></a></li>
<li><a href='#ec2_cpu_utilization_77c1ca'><p>ec2_cpu_utilization_77c1ca.</p></a></li>
<li><a href='#ec2_cpu_utilization_825cc2'><p>ec2_cpu_utilization_825cc2.</p></a></li>
<li><a href='#ec2_cpu_utilization_ac20cd'><p>ec2_cpu_utilization_ac20cd.</p></a></li>
<li><a href='#ec2_cpu_utilization_fe7f93'><p>ec2_cpu_utilization_fe7f93.</p></a></li>
<li><a href='#ec2_disk_write_bytes_1ef3de'><p>ec2_disk_write_bytes_1ef3de.</p></a></li>
<li><a href='#ec2_disk_write_bytes_c0d644'><p>ec2_disk_write_bytes_c0d644.</p></a></li>
<li><a href='#ec2_network_in_257a54'><p>ec2_network_in_257a54.</p></a></li>
<li><a href='#ec2_network_in_5abac7'><p>ec2_network_in_5abac7.</p></a></li>
<li><a href='#ec2_request_latency_system_failure'><p>ec2_request_latency_system_failure.</p></a></li>
<li><a href='#elb_request_count_8c0756'><p>elb_request_count_8c0756.</p></a></li>
<li><a href='#exchange_2_cpc_results'><p>exchange_2_cpc_results.</p></a></li>
<li><a href='#exchange_2_cpm_results'><p>exchange_2_cpm_results.</p></a></li>
<li><a href='#exchange_3_cpc_results'><p>exchange_3_cpc_results.</p></a></li>
<li><a href='#exchange_3_cpm_results'><p>exchange_3_cpm_results.</p></a></li>
<li><a href='#exchange_4_cpc_results'><p>exchange_4_cpc_results.</p></a></li>
<li><a href='#exchange_4_cpm_results'><p>exchange_4_cpm_results.</p></a></li>
<li><a href='#GetDetectorScore'><p>Get detector score</p></a></li>
<li><a href='#GetLabels'><p>Get Lables</p></a></li>
<li><a href='#GetNullAndPerfectScores'><p>Get Null And Perfect Scores</p></a></li>
<li><a href='#GetNumTrainingValues'><p>Get Number of Training Values</p></a></li>
<li><a href='#GetWindowLength'><p>Get Window Length</p></a></li>
<li><a href='#GetWindowsLimits'><p>Get windows limits</p></a></li>
<li><a href='#grok_asg_anomaly'><p>grok_asg_anomaly.</p></a></li>
<li><a href='#iio_us_east1_i_a2eb1cd9_NetworkIn'><p>iio_us_east1_i_a2eb1cd9_NetworkIn.</p></a></li>
<li><a href='#IpKnnCad'><p>Incremental processing KNN based Conformal Anomaly Detector (KNN-CAD).</p></a></li>
<li><a href='#IpPewma'><p>Incremental Processing Probabilistic-EWMA (PEWMA).</p></a></li>
<li><a href='#IpSdEwma'><p>Incremental Processing Shift-Detection based on EWMA (SD-EWMA).</p></a></li>
<li><a href='#IpTsSdEwma'><p>Incremental Processing Two-Stage Shift-Detection based on EWMA</p></a></li>
<li><a href='#machine_temperature_system_failure'><p>machine_temperature_system_failure.</p></a></li>
<li><a href='#NormalizeScore'><p>Normalize Score using Max and Min normalization</p></a></li>
<li><a href='#nyc_taxi'><p>nyc_taxi.</p></a></li>
<li><a href='#occupancy_6005'><p>occupancy_6005.</p></a></li>
<li><a href='#occupancy_t4013'><p>occupancy_t4013.</p></a></li>
<li><a href='#OcpPewma'><p>Optimized Classic Processing Probabilistic-EWMA (PEWMA).</p></a></li>
<li><a href='#OcpSdEwma'><p>Optimized Classic Processing Shift-Detection based on EWMA (SD-EWMA).</p></a></li>
<li><a href='#OcpTsSdEwma'><p>Optimized Classic Processing Two-Stage Shift-Detection based on EWMA</p></a></li>
<li><a href='#OipPewma'><p>Optimized Incremental Processing Probabilistic-EWMA (PEWMA).</p></a></li>
<li><a href='#OipSdEwma'><p>Optimized Incremental Processing Shift-Detection based on EWMA (SD-EWMA).</p></a></li>
<li><a href='#OipTsSdEwma'><p>Optimized Incremental Processing Two-Stage Shift-Detection based on EWMA</p></a></li>
<li><a href='#PlotDetections'><p>PLOT DETECTIONS</p></a></li>
<li><a href='#rds_cpu_utilization_cc0c53'><p>rds_cpu_utilization_cc0c53.</p></a></li>
<li><a href='#rds_cpu_utilization_e47b3b'><p>rds_cpu_utilization_e47b3b.</p></a></li>
<li><a href='#ReduceAnomalies'><p>Reduce Anomalies</p></a></li>
<li><a href='#rogue_agent_key_hold'><p>rogue_agent_key_hold.</p></a></li>
<li><a href='#rogue_agent_key_updown'><p>rogue_agent_key_updown.</p></a></li>
<li><a href='#speed_6005'><p>speed_6005.</p></a></li>
<li><a href='#speed_7578'><p>speed_7578.</p></a></li>
<li><a href='#speed_t4013'><p>speed_t4013.</p></a></li>
<li><a href='#TravelTime_387'><p>TravelTime_387.</p></a></li>
<li><a href='#TravelTime_451'><p>TravelTime_451.</p></a></li>
<li><a href='#Twitter_volume_AAPL'><p>Twitter_volume_AAPL.</p></a></li>
<li><a href='#Twitter_volume_AMZN'><p>Twitter_volume_AMZN.</p></a></li>
<li><a href='#Twitter_volume_CRM'><p>Twitter_volume_CRM.</p></a></li>
<li><a href='#Twitter_volume_CVS'><p>Twitter_volume_CVS.</p></a></li>
<li><a href='#Twitter_volume_FB'><p>Twitter_volume_FB.</p></a></li>
<li><a href='#Twitter_volume_GOOG'><p>Twitter_volume_GOOG.</p></a></li>
<li><a href='#Twitter_volume_IBM'><p>Twitter_volume_IBM.</p></a></li>
<li><a href='#Twitter_volume_KO'><p>Twitter_volume_KO.</p></a></li>
<li><a href='#Twitter_volume_PFE'><p>Twitter_volume_PFE.</p></a></li>
<li><a href='#Twitter_volume_UPS'><p>Twitter_volume_UPS.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Online Time Series Anomaly Detectors</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements a set of online fault detectors for time-series, called: PEWMA see M. Carter
             et al. (2012) &lt;<a href="https://doi.org/10.1109%2FSSP.2012.6319708">doi:10.1109/SSP.2012.6319708</a>&gt;, SD-EWMA and TSSD-EWMA see H. Raza et al. 
             (2015) &lt;<a href="https://doi.org/10.1016%2Fj.patcog.2014.07.028">doi:10.1016/j.patcog.2014.07.028</a>&gt;, KNN-CAD see E. Burnaev et al. (2016)
             &lt;<a href="https://doi.org/10.48550/arXiv.1608.04585">doi:10.48550/arXiv.1608.04585</a>&gt;, KNN-LDCD see V. Ishimtsev et al. (2017) &lt;<a href="https://doi.org/10.48550/arXiv.1706.03412">doi:10.48550/arXiv.1706.03412</a>&gt; and 
             CAD-OSE see M. Smirnov (2018) <a href="https://github.com/smirmik/CAD">https://github.com/smirmik/CAD</a>. The first three 
             algorithms belong to prediction-based techniques and the last three belong to 
             window-based techniques. In addition, the SD-EWMA and PEWMA algorithms are algorithms 
             designed to work in stationary environments, while the other four 
             are algorithms designed to work in non-stationary environments.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;= 3.0.1); bencode-python3 (1.0.2)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/AGPL-3">AGPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/alaineiturria/otsad">https://github.com/alaineiturria/otsad</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/alaineiturria/otsad/issues">https://github.com/alaineiturria/otsad/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, stream, knitr, rmarkdown</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, ggplot2, plotly, sigmoid, reticulate</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-05 17:21:13 UTC; aiturria</td>
</tr>
<tr>
<td>Author:</td>
<td>Alaiñe Iturria [aut, cre],
  Jacinto Carrasco [aut],
  Francisco Herrera [aut],
  Santiago Charramendieta [aut],
  Karmele Intxausti [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alaiñe Iturria &lt;aiturria@ikerlan.es&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-06 09:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ambient_temperature_system_failure'>ambient_temperature_system_failure.</h2><span id='topic+ambient_temperature_system_failure'></span>

<h3>Description</h3>

<p>The ambient temperature in an office setting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ambient_temperature_system_failure
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='art_daily_flatmiddle'>art_daily_flatmiddle.</h2><span id='topic+art_daily_flatmiddle'></span>

<h3>Description</h3>

<p>Artificially-generated data with varying types of anomalies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>art_daily_flatmiddle
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='art_daily_jumpsdown'>art_daily_jumpsdown</h2><span id='topic+art_daily_jumpsdown'></span>

<h3>Description</h3>

<p>Artificially-generated data with varying types of anomalies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>art_daily_jumpsdown
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='art_daily_jumpsup'>art_daily_jumpsup</h2><span id='topic+art_daily_jumpsup'></span>

<h3>Description</h3>

<p>Artificially-generated data with varying types of anomalies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>art_daily_jumpsup
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='art_daily_nojump'>art_daily_nojump</h2><span id='topic+art_daily_nojump'></span>

<h3>Description</h3>

<p>Artificially-generated data with varying types of anomalies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>art_daily_nojump
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='art_increase_spike_density'>art_increase_spike_density</h2><span id='topic+art_increase_spike_density'></span>

<h3>Description</h3>

<p>Artificially-generated data with varying types of anomalies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>art_increase_spike_density
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='art_load_balancer_spikes'>art_load_balancer_spikes.</h2><span id='topic+art_load_balancer_spikes'></span>

<h3>Description</h3>

<p>Artificially-generated data with varying types of anomalies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>art_load_balancer_spikes
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ContextualAnomalyDetector'>Contextual Anomaly Detector - Open Source (CAD)</h2><span id='topic+ContextualAnomalyDetector'></span>

<h3>Description</h3>

<p><code>ContextualAnomalyDetector</code> calculates the anomaly score of a
dataset using the notion of contexts conformed by facts and provides
probabilistic abnormality scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ContextualAnomalyDetector(data, rest.period = max(min(150,
  round(length(data) * 0.03), 1)), max.left.semicontexts = 7,
  max.active.neurons = 15, num.norm.value.bits = 3,
  base.threshold = 0.75, min.value = min(data, na.rm = T),
  max.value = max(data, na.rm = T), python.object = NULL, lib = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ContextualAnomalyDetector_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_rest.period">rest.period</code></td>
<td>
<p>Training period after an anomaly.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_max.left.semicontexts">max.left.semicontexts</code></td>
<td>
<p>Number of semicontexts that should be maintained in memory.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_max.active.neurons">max.active.neurons</code></td>
<td>
<p>Number of neurons of the model.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_num.norm.value.bits">num.norm.value.bits</code></td>
<td>
<p>Granularity of the transformation into discrete values</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_base.threshold">base.threshold</code></td>
<td>
<p>Threshold to be considered an anomaly.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_min.value">min.value</code></td>
<td>
<p>Minimum expected value.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_max.value">max.value</code></td>
<td>
<p>Maximum expected value.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_python.object">python.object</code></td>
<td>
<p>Python object for incremental processing.</p>
</td></tr>
<tr><td><code id="ContextualAnomalyDetector_+3A_lib">lib</code></td>
<td>
<p>0 to run the original python script, 1 to get the same results on all operating
systems.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1. If the anomaly
score obtained for an observation is greater than the <code>threshold</code>, the
observation will be considered abnormal. Requires hashlib (included in python installation)
and bencode-python3 (which can be installed using pip) python libraries.
</p>


<h3>Value</h3>

<p>List
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>Data frame with <code>anomaly.score</code> and <code>is.anomaly</code> comparing the anomaly
score with <code>base.threshold</code>.</p>
</td></tr>
<tr><td><code>python.object</code></td>
<td>
<p>ContextualAnomalyDetector Python object used in online anomaly detection</p>
</td></tr>
</table>


<h3>References</h3>

<p>Smirnov, M. (2018). CAD: Contextual Anomaly
Detector. https://github.com/smirmik/CAD
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 200
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies

   result &lt;- ContextualAnomalyDetector(data = df$value, rest.period = 10, base.threshold = 0.9)

   ## Plot results
   res &lt;- cbind(df, result$result)
   PlotDetections(res, title = "CAD_OSE ANOMALY DETECTOR")



</code></pre>

<hr>
<h2 id='CpKnnCad'>Classic processing KNN based Conformal Anomaly Detector (KNN-CAD)</h2><span id='topic+CpKnnCad'></span>

<h3>Description</h3>

<p><code>CpKnnCad</code> calculates the anomalies of a dataset using classical
processing based on the KNN-CAD algorithm. KNN-CAD is a model-free anomaly
detection method for univariate time-series which adapts itself to
non-stationarity in the data stream and provides probabilistic abnormality
scores based on the conformal prediction paradigm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CpKnnCad(data, n.train, threshold = 1, l = 19, k = 27,
  ncm.type = "ICAD", reducefp = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CpKnnCad_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="CpKnnCad_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the training set.</p>
</td></tr>
<tr><td><code id="CpKnnCad_+3A_threshold">threshold</code></td>
<td>
<p>Anomaly threshold.</p>
</td></tr>
<tr><td><code id="CpKnnCad_+3A_l">l</code></td>
<td>
<p>Window length.</p>
</td></tr>
<tr><td><code id="CpKnnCad_+3A_k">k</code></td>
<td>
<p>Number of neighbours to take into account.</p>
</td></tr>
<tr><td><code id="CpKnnCad_+3A_ncm.type">ncm.type</code></td>
<td>
<p>Non Conformity Measure to use &quot;ICAD&quot; or &quot;LDCD&quot;</p>
</td></tr>
<tr><td><code id="CpKnnCad_+3A_reducefp">reducefp</code></td>
<td>
<p>If TRUE reduces false positives.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1. If the anomaly
score obtained for an observation is greater than the <code>threshold</code>, the
observation will be considered abnormal. <code>l</code> must be a numerical value
between 1 and 1/<code>n</code>; <code>n</code> being the length of the training data.
Take into account that the value of l has a direct impact on the
computational cost, so very high values will make the execution time longer.
<code>k</code> parameter must be a numerical value less than the <code>n.train</code>
value. <code>ncm.type</code> determines the non-conformity measurement to be used.
ICAD calculates dissimilarity as the sum of the distances of the nearest k
neighbours and LDCD as the average.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous, 0 otherwise.</p>
</td></tr>
<tr><td><code>anomaly.score</code></td>
<td>
<p>Probability of anomaly.</p>
</td></tr>
</table>


<h3>References</h3>

<p>V. Ishimtsev, I. Nazarov, A. Bernstein and E. Burnaev. Conformal
k-NN Anomaly Detector for Univariate Data Streams. ArXiv e-prints, jun. 2017.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 350
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Set parameters
params.KNN &lt;- list(threshold = 1, n.train = 50, l = 19, k = 17)

## Calculate anomalies
result &lt;- CpKnnCad(
  data = df$value,
  n.train = params.KNN$n.train,
  threshold = params.KNN$threshold,
  l = params.KNN$l,
  k = params.KNN$k,
  ncm.type = "ICAD",
  reducefp = TRUE
)

## Plot results
res &lt;- cbind(df, result)
PlotDetections(res, title = "KNN-CAD ANOMALY DETECTOR")

</code></pre>

<hr>
<h2 id='CpPewma'>Classic Processing Probabilistic-EWMA (PEWMA).</h2><span id='topic+CpPewma'></span>

<h3>Description</h3>

<p><code>CpPewma</code> calculates the anomalies of a dataset using
classical processing based on the PEWMA algorithm. This algorithm is
a probabilistic method of EWMA which dynamically adjusts the parameterization
based on the probability of the given observation. This method produces
dynamic, data-driven anomaly thresholds which are robust to abrupt transient
changes, yet quickly adjust to long-term distributional shifts. See also
<code><a href="#topic+OcpPewma">OcpPewma</a></code>, the optimized and faster function of the this
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CpPewma(data, n.train = 5, alpha0 = 0.8, beta = 0.3, l = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CpPewma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="CpPewma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="CpPewma_+3A_alpha0">alpha0</code></td>
<td>
<p>Maximal weighting parameter.</p>
</td></tr>
<tr><td><code id="CpPewma_+3A_beta">beta</code></td>
<td>
<p>Weight placed on the probability of the given observation.</p>
</td></tr>
<tr><td><code id="CpPewma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>alpha0</code> must be a numeric value where 0 &lt; <code>alpha0</code> &lt; 1. If a
faster adjustment to the initial shift is desirable, simply lowering
<code>alpha0</code> will suffice. <code>beta</code> is the weight placed on the
probability of the given observation. It must be a numeric value where
0 &lt;= <code>beta</code> &lt;= 1. Note that if <code>beta</code> equals 0, PEWMA converges to
a standard EWMA. Finally <code>l</code> is the parameter that determines the
control limits. By default, 3 is used.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous 0, otherwise.</p>
</td></tr>
<tr><td><code>ucl</code></td>
<td>
<p>Upper control limit.</p>
</td></tr>
<tr><td><code>lcl</code></td>
<td>
<p>Lower control limit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>M. Carter, Kevin y W. Streilein. Probabilistic reasoning for
streaming anomaly detection. 2012 IEEE Statistical Signal Processing Workshop
(SSP), pp. 377-380, Aug 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- CpPewma(
  data = df$value,
  n.train = 5,
  alpha0 = 0.8,
  beta = 0.1,
  l = 3
)

## Plot results
res &lt;- cbind(df, result)
PlotDetections(res, title = "PEWMA ANOMALY DETECTOR")
</code></pre>

<hr>
<h2 id='CpSdEwma'>Classic Processing Shift-Detection based on EWMA (SD-EWMA).</h2><span id='topic+CpSdEwma'></span>

<h3>Description</h3>

<p><code>CpSdEwma</code> calculates the anomalies of a dataset using
classical processing based on the SD-EWMA algorithm. This algorithm is a
novel method for covariate shift-detection tests based on a two-stage
structure for univariate time-series. It works in an online mode and it uses
an exponentially weighted moving average (EWMA) model based control chart to
detect the covariate shift-point in non-stationary time-series. See also
<code><a href="#topic+OcpSdEwma">OcpSdEwma</a></code>, the optimized and faster function of this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CpSdEwma(data, n.train, threshold = 0.01, l = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CpSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="CpSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the training set.</p>
</td></tr>
<tr><td><code id="CpSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="CpSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1.
It is recommended to use low values such as 0.01 or 0.05. By default, 0.01 is
used. Finally, <code>l</code> is the parameter that determines the control limits.
By default, 3 is used.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous 0, otherwise.</p>
</td></tr>
<tr><td><code>ucl</code></td>
<td>
<p>Upper control limit.</p>
</td></tr>
<tr><td><code>lcl</code></td>
<td>
<p>Lower control limit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- CpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result)

## Plot results
PlotDetections(res, title = "KNN-CAD ANOMALY DETECTOR")
</code></pre>

<hr>
<h2 id='CpTsSdEwma'>Classic Processing Two-Stage Shift-Detection based on EWMA</h2><span id='topic+CpTsSdEwma'></span>

<h3>Description</h3>

<p><code>CpTsSdEwma</code> calculates the anomalies of a dataset using
classical processing based on the SD-EWMA algorithm. This algorithm is a
novel method for covariate shift-detection tests based on a two-stage
structure for univariate time-series. This algorithm works in two phases. In
the first phase, it detects anomalies using the SD-EWMA
<code><a href="#topic+CpSdEwma">CpSdEwma</a></code> algorithm. In the second phase, it checks the veracity
of the anomalies using the Kolmogorov-Simirnov test to reduce false alarms.
See also <code><a href="#topic+OcpTsSdEwma">OcpTsSdEwma</a></code>, the optimized and faster function of this
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CpTsSdEwma(data, n.train, threshold = 0.01, l = 3, m = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CpTsSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="CpTsSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the training set.</p>
</td></tr>
<tr><td><code id="CpTsSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="CpTsSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="CpTsSdEwma_+3A_m">m</code></td>
<td>
<p>Length of the subsequences for applying the Kolmogorov-Smirnov test.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1.
It is recommended to use low values such as 0.01 or 0.05. By default, 0.01 is
used. Finally, <code>l</code> is the parameter that determines the control limits.
By default, 3 is used. <code>m</code> is the length of the subsequences for
applying the Kolmogorov-Smirnov test. By default, 5 is used. It should be
noted that the last <code>m</code> values will not been verified because another
<code>m</code> values are needed to be able to perform the verification.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous, 0 otherwise.</p>
</td></tr>
<tr><td><code>ucl</code></td>
<td>
<p>Upper control limit.</p>
</td></tr>
<tr><td><code>lcl</code></td>
<td>
<p>Lower control limit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- CpTsSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3,
  m = 20
)
res &lt;- cbind(df, result)

## Plot results
PlotDetections(res, title = "TSSD_EWMA ANOMALY DETECTOR")
</code></pre>

<hr>
<h2 id='cpu_utilization_asg_misconfiguration'>cpu_utilization_asg_misconfiguration.</h2><span id='topic+cpu_utilization_asg_misconfiguration'></span>

<h3>Description</h3>

<p>From Amazon Web Services (AWS) monitoring CPU usage – i.e. average CPU usage across a
given cluster. When usage is high, AWS spins up a new machine, and uses fewer
machines when usage is low.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpu_utilization_asg_misconfiguration
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_cpu_utilization_24ae8d'>ec2_cpu_utilization_24ae8d.</h2><span id='topic+ec2_cpu_utilization_24ae8d'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_cpu_utilization_24ae8d
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_cpu_utilization_53ea38'>ec2_cpu_utilization_53ea38.</h2><span id='topic+ec2_cpu_utilization_53ea38'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_cpu_utilization_53ea38
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_cpu_utilization_5f5533'>ec2_cpu_utilization_5f5533.</h2><span id='topic+ec2_cpu_utilization_5f5533'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_cpu_utilization_5f5533
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_cpu_utilization_77c1ca'>ec2_cpu_utilization_77c1ca.</h2><span id='topic+ec2_cpu_utilization_77c1ca'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_cpu_utilization_77c1ca
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_cpu_utilization_825cc2'>ec2_cpu_utilization_825cc2.</h2><span id='topic+ec2_cpu_utilization_825cc2'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_cpu_utilization_825cc2
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_cpu_utilization_ac20cd'>ec2_cpu_utilization_ac20cd.</h2><span id='topic+ec2_cpu_utilization_ac20cd'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_cpu_utilization_ac20cd
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_cpu_utilization_fe7f93'>ec2_cpu_utilization_fe7f93.</h2><span id='topic+ec2_cpu_utilization_fe7f93'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_cpu_utilization_fe7f93
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_disk_write_bytes_1ef3de'>ec2_disk_write_bytes_1ef3de.</h2><span id='topic+ec2_disk_write_bytes_1ef3de'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_disk_write_bytes_1ef3de
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_disk_write_bytes_c0d644'>ec2_disk_write_bytes_c0d644.</h2><span id='topic+ec2_disk_write_bytes_c0d644'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_disk_write_bytes_c0d644
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_network_in_257a54'>ec2_network_in_257a54.</h2><span id='topic+ec2_network_in_257a54'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_network_in_257a54
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_network_in_5abac7'>ec2_network_in_5abac7.</h2><span id='topic+ec2_network_in_5abac7'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_network_in_5abac7
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ec2_request_latency_system_failure'>ec2_request_latency_system_failure.</h2><span id='topic+ec2_request_latency_system_failure'></span>

<h3>Description</h3>

<p>CPU usage data from a server in Amazon's East Coast datacenter. The dataset ends
with complete system failure resulting from a documented failure of AWS API
servers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ec2_request_latency_system_failure
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='elb_request_count_8c0756'>elb_request_count_8c0756.</h2><span id='topic+elb_request_count_8c0756'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>
<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elb_request_count_8c0756

elb_request_count_8c0756
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='exchange_2_cpc_results'>exchange_2_cpc_results.</h2><span id='topic+exchange_2_cpc_results'></span>

<h3>Description</h3>

<p>Online advertisement clicking rates, where the metrics are cost-per-click (CPC) and cost
per thousand impressions (CPM). One of the files is normal, without anomalies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exchange_2_cpc_results
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='exchange_2_cpm_results'>exchange_2_cpm_results.</h2><span id='topic+exchange_2_cpm_results'></span>

<h3>Description</h3>

<p>Online advertisement clicking rates, where the metrics are cost-per-click (CPC) and cost
per thousand impressions (CPM). One of the files is normal, without anomalies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exchange_2_cpm_results
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='exchange_3_cpc_results'>exchange_3_cpc_results.</h2><span id='topic+exchange_3_cpc_results'></span>

<h3>Description</h3>

<p>Online advertisement clicking rates, where the metrics are cost-per-click (CPC) and cost
per thousand impressions (CPM). One of the files is normal, without anomalies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exchange_3_cpc_results
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='exchange_3_cpm_results'>exchange_3_cpm_results.</h2><span id='topic+exchange_3_cpm_results'></span>

<h3>Description</h3>

<p>Online advertisement clicking rates, where the metrics are cost-per-click (CPC) and cost
per thousand impressions (CPM). One of the files is normal, without anomalies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exchange_3_cpm_results
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='exchange_4_cpc_results'>exchange_4_cpc_results.</h2><span id='topic+exchange_4_cpc_results'></span>

<h3>Description</h3>

<p>Online advertisement clicking rates, where the metrics are cost-per-click (CPC) and cost
per thousand impressions (CPM). One of the files is normal, without anomalies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exchange_4_cpc_results
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='exchange_4_cpm_results'>exchange_4_cpm_results.</h2><span id='topic+exchange_4_cpm_results'></span>

<h3>Description</h3>

<p>Online advertisement clicking rates, where the metrics are cost-per-click (CPC) and cost
per thousand impressions (CPM). One of the files is normal, without anomalies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exchange_4_cpm_results
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='GetDetectorScore'>Get detector score</h2><span id='topic+GetDetectorScore'></span>

<h3>Description</h3>

<p><code>GetDetectorScore</code> Calculates the start and end positions of each window that
are focused on the real anomalies. This windows can be used to know if the detected anomaly is a
true positive or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetDetectorScore(data, print = FALSE, title = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetDetectorScore_+3A_data">data</code></td>
<td>
<p>All dataset with training and test datasets and with at least <code>timestamp</code>,
<code>value</code>, <code>is.anomaly</code> and <code>is.real.anomaly</code> columns.</p>
</td></tr>
<tr><td><code id="GetDetectorScore_+3A_print">print</code></td>
<td>
<p>If TRUE shows a graph with results.</p>
</td></tr>
<tr><td><code id="GetDetectorScore_+3A_title">title</code></td>
<td>
<p>Title of the graph.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a data.frame with  <code>timestamp</code>, <code>value</code>, <code>is.anomaly</code>
and <code>is.real.anomaly</code> columns. <code>timestamp</code> column can be numeric, of type POSIXct, or a
character type date convertible to POSIXct.
</p>
<p>This function calculates the scores based on three different profiles. Each label tp, fp, tn,
fn is associated with a weight to give a more realistic score.
For the standard profile weights are tp = 1, tn = 1, fp, = 0.11, and fn = 1.
For the reward_low_FP_rate profile weights are tp = 1, tn = 1, fp, = 0.22, and fn = 1.
For the reward_low_FN_rate profile weights are tp = 1, tn = 1, fp, = 0.11, and fn = 2.
</p>


<h3>Value</h3>

<p>List conformed by the following items:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Same data set with additional columns such as <code>label</code>, <code>start.limit</code>,
<code>end.limit</code>, <code>standard.score</code> and etc.</p>
</td></tr>
<tr><td><code>standard</code></td>
<td>
<p>Total score obtained by the detector using the weights of the
standard profile.</p>
</td></tr>
<tr><td><code>low_FP_rate</code></td>
<td>
<p>Total score obtained by the detector using the weights of the
reward_low_FP_rate profile.</p>
</td></tr>
<tr><td><code>low_FN_rate</code></td>
<td>
<p>Total score obtained by the detector using the weights of the
reward_low_FN_rate profile.</p>
</td></tr>
<tr><td><code>tp</code></td>
<td>
<p>Number of true positives</p>
</td></tr>
<tr><td><code>tn</code></td>
<td>
<p>Number of true negatives</p>
</td></tr>
<tr><td><code>fp</code></td>
<td>
<p>Number of false positives</p>
</td></tr>
<tr><td><code>fn</code></td>
<td>
<p>Number of false negatives</p>
</td></tr>
</table>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA’15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

# Add is.real.anomaly column
df$is.real.anomaly &lt;- 0
df[c(25,80,150), "is.real.anomaly"] &lt;- 1

## Calculate anomalies
result &lt;- CpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result)

# Get detector score
GetDetectorScore(res, print = FALSE, title = "")
</code></pre>

<hr>
<h2 id='GetLabels'>Get Lables</h2><span id='topic+GetLabels'></span>

<h3>Description</h3>

<p><code>GetLabels</code> Calculates the start and end positions of each window that
are focused on the real anomalies. This windows can be used to know if the detected anomaly is a
true positive or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetLabels(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetLabels_+3A_data">data</code></td>
<td>
<p>All dataset with training and test datasets with at least <code>timestamp</code>,
<code>value</code>, <code>is.anomaly</code>, <code>is.real.anomaly</code>, <code>start.limit</code> and
<code>end.limit</code> columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a data.frame with  <code>timestamp</code>, <code>value</code>, <code>is.anomaly</code>
and <code>is.real.anomaly</code> columns. <code>timestamp</code> column can be numeric, of type POSIXct, or a
character type date convertible to POSIXct. see  <code><a href="#topic+GetWindowsLimits">GetWindowsLimits</a></code> to know more
about how to get <code>start.limit</code> and <code>end.limit</code> columns.
</p>


<h3>Value</h3>

<p>Same data set with two additional columns <code>label</code> and <code>first.tp</code>.
<code>first.tp</code> indicates for each window Which is the position of first true positive.
<code>label</code> indicates for each detection if it is a TP, FP, TN or FN.
</p>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA’15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

# Add is.real.anomaly column
df$is.real.anomaly &lt;- 0
df[c(25,80,150), "is.real.anomaly"] &lt;- 1

## Calculate anomalies
result &lt;- CpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result)

# Get Window Limits
data &lt;- GetWindowsLimits(res)
data[data$is.real.anomaly == 1,]

# Get labels
data &lt;- GetLabels(data)
data[data$is.real.anomaly == 1 | data$is.anomaly == 1,]

# Plot results
PlotDetections(res, print.real.anomaly = TRUE, print.time.window = TRUE)
</code></pre>

<hr>
<h2 id='GetNullAndPerfectScores'>Get Null And Perfect Scores</h2><span id='topic+GetNullAndPerfectScores'></span>

<h3>Description</h3>

<p><code>GetNullAndPerfectScores</code> Calculates the score of Perfect and Null
detectors scores. Perfect detector is one that outputs all true positives and no false
positives. And Null detector is one that outputs no anomaly detections.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetNullAndPerfectScores(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetNullAndPerfectScores_+3A_data">data</code></td>
<td>
<p>All dataset with training and test datasets and with at least <code>timestamp</code>,
<code>value</code> and <code>is.real.anomaly</code> columns.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the scores based on three different profiles. Each tp,
fp, tn, fn label is associated with a weight to give a more realistic score.
For the standard profile weights are tp = 1, tn = 1, fp, = 0.11, and fn = 1.
For the reward_low_FP_rate profile weights are tp = 1, tn = 1, fp, = 0.22, and fn = 1.
For the reward_low_FN_rate profile weights are tp = 1, tn = 1, fp, = 0.11, and fn = 2.
</p>


<h3>Value</h3>

<p>data.frame with null and perfect detectors scores for each profile.
</p>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA’15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

# Add is.real.anomaly column
df$is.real.anomaly &lt;- 0
df[c(25,80,150), "is.real.anomaly"] &lt;- 1

# Get null and perfect scores
GetNullAndPerfectScores(df)
</code></pre>

<hr>
<h2 id='GetNumTrainingValues'>Get Number of Training Values</h2><span id='topic+GetNumTrainingValues'></span>

<h3>Description</h3>

<p><code>GetNumTrainingValues</code> Calculates the number of values to be used as a
training set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetNumTrainingValues(n.row, prob.percent = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetNumTrainingValues_+3A_n.row">n.row</code></td>
<td>
<p>Number of rows of the all dataset with training and test values.</p>
</td></tr>
<tr><td><code id="GetNumTrainingValues_+3A_prob.percent">prob.percent</code></td>
<td>
<p>Percentage of training values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the number of values to be used as a training set is calculated as a minimum
between 15% of the number of rows in the dataset and 15% of 5000.
</p>


<h3>Value</h3>

<p>Number of training values.
</p>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA’15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

# Get number of instances to train phase
GetNumTrainingValues(nrow(df))
</code></pre>

<hr>
<h2 id='GetWindowLength'>Get Window Length</h2><span id='topic+GetWindowLength'></span>

<h3>Description</h3>

<p><code>GetWindowLength</code> Calculates the size of the window. This window focuses on
the real anomaly and it can be used to know if the detected anomaly is a true positive or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetWindowLength(data.length, num.real.anomaly, window.length.perc = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetWindowLength_+3A_data.length">data.length</code></td>
<td>
<p>Dataset length.</p>
</td></tr>
<tr><td><code id="GetWindowLength_+3A_num.real.anomaly">num.real.anomaly</code></td>
<td>
<p>Number of real anomalies contained in the data set.</p>
</td></tr>
<tr><td><code id="GetWindowLength_+3A_window.length.perc">window.length.perc</code></td>
<td>
<p>Window length in percentage of the total data</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nrow.data</code> and <code>num.real.anomaly</code> must be numeric. Window length is
calculated by default as 10% of the length of the data set divided by the number of real
anomalies contained in it.
</p>


<h3>Value</h3>

<p>Window length as numeric.
</p>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA 15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

# Add is.real.anomaly column
df$is.real.anomaly &lt;- 0
df[c(25,80,150), "is.real.anomaly"] &lt;- 1

# Get window length
GetWindowLength(data.length = nrow(df), num.real.anomaly = 3)
</code></pre>

<hr>
<h2 id='GetWindowsLimits'>Get windows limits</h2><span id='topic+GetWindowsLimits'></span>

<h3>Description</h3>

<p><code>GetWindowsLimits</code> Calculates the start and end positions of each window that
are focused on the real anomalies. This windows can be used to know if the detected anomaly is a
true positive or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetWindowsLimits(data, windowLength = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetWindowsLimits_+3A_data">data</code></td>
<td>
<p>All dataset with training and test datasets and with at least <code>timestamp</code>,
<code>value</code> and <code>is.real.anomaly</code> columns.</p>
</td></tr>
<tr><td><code id="GetWindowsLimits_+3A_windowlength">windowLength</code></td>
<td>
<p>Window length. See <code><a href="#topic+GetWindowLength">GetWindowLength</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a data.frame with  <code>timestamp</code>, <code>value</code>, <code>is.anomaly</code>
and <code>is.real.anomaly</code> columns. <code>timestamp</code> column can be numeric, of type POSIXct, or a
character type date convertible to POSIXct. <code>windowLength</code> must be numeric value.
</p>


<h3>Value</h3>

<p>Same data set with two additional columns <code>start.limit</code> and <code>end.limit</code> where
for each is.real.anomaly equal to 1 is indicated the position in the data set where each window
starts and ends. If two anomalies fall within the same window, the start and end positions
are only indicated on the first of them.
</p>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA’15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

# Add is.real.anomaly column
df$is.real.anomaly &lt;- 0
df[c(25,80,150), "is.real.anomaly"] &lt;- 1

# Get Window Limits
data &lt;- GetWindowsLimits(df)
data[data$is.real.anomaly == 1,]
</code></pre>

<hr>
<h2 id='grok_asg_anomaly'>grok_asg_anomaly.</h2><span id='topic+grok_asg_anomaly'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grok_asg_anomaly
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='iio_us_east1_i_a2eb1cd9_NetworkIn'>iio_us_east1_i_a2eb1cd9_NetworkIn.</h2><span id='topic+iio_us_east1_i_a2eb1cd9_NetworkIn'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iio_us_east1_i_a2eb1cd9_NetworkIn
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='IpKnnCad'>Incremental processing KNN based Conformal Anomaly Detector (KNN-CAD).</h2><span id='topic+IpKnnCad'></span>

<h3>Description</h3>

<p><code>IpKnnCad</code> allows the calculation of anomalies using SD-EWMA in an
incremental processing mode. KNN-CAD is a model-free anomaly
detection method for univariate time-series which adapts itself to
non-stationarity in the data stream and provides probabilistic abnormality
scores based on the conformal prediction paradigm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IpKnnCad(data, n.train, threshold = 1, l = 19, k = 27,
  ncm.type = "ICAD", reducefp = TRUE, to.next.iteration = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IpKnnCad_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="IpKnnCad_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="IpKnnCad_+3A_threshold">threshold</code></td>
<td>
<p>Anomaly threshold.</p>
</td></tr>
<tr><td><code id="IpKnnCad_+3A_l">l</code></td>
<td>
<p>Window length.</p>
</td></tr>
<tr><td><code id="IpKnnCad_+3A_k">k</code></td>
<td>
<p>Number of neighbours to take into account.</p>
</td></tr>
<tr><td><code id="IpKnnCad_+3A_ncm.type">ncm.type</code></td>
<td>
<p>Non Conformity Measure to use &quot;ICAD&quot; or &quot;LDCD&quot;</p>
</td></tr>
<tr><td><code id="IpKnnCad_+3A_reducefp">reducefp</code></td>
<td>
<p>If TRUE reduces false positives.</p>
</td></tr>
<tr><td><code id="IpKnnCad_+3A_to.next.iteration">to.next.iteration</code></td>
<td>
<p>list with the necessary parameters to execute in
the next iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1. If the anomaly
score obtained for an observation is greater than the <code>threshold</code>, the
observation will be considered abnormal. <code>l</code> must be a numerical value
between 1 and 1/<code>n</code>; <code>n</code> being the length of the training data.
Take into account that the value of l has a direct impact on the
computational cost, so very high values will make the execution time longer.
<code>k</code> parameter must be a numerical value less than the <code>n.train</code>
value. <code>ncm.type</code> determines the non-conformity measurement to be used.
ICAD calculates dissimilarity as the sum of the distances of the nearest k
neighbours and LDCD as the average. <code>to.next.iteration</code>
is the last result returned by some previous execution of this algorithm.
The first time the algorithm is executed its value is NULL. However, to run a
new batch of data without having to include it in the old dataset and restart
the process, this parameter returned by the last run is only needed.
</p>
<p>This algorithm can be used for both classical and incremental processing.
It should be noted that in case of having a finite dataset, the
<code><a href="#topic+CpKnnCad">CpKnnCad</a></code> algorithm is faster.
Incremental processing can be used in two ways. 1) Processing all available
data and saving <code>calibration.alpha</code> and <code>last.data</code> for future runs
with new data. 2) Using the
<a href="https://CRAN.R-project.org/package=stream">stream</a> library for when
there is much data and it does not fit into the memory. An example has been
made for this use case.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous 0, otherwise.</p>
</td></tr>
<tr><td><code>anomaly.score</code></td>
<td>
<p>Probability of anomaly.</p>
</td></tr>
<tr><td><code>to.next.iteration</code></td>
<td>
<p>Last result returned by the algorithm. It is a list
containing the following items.</p>
</td></tr>
</table>

<ul>
<li> <p><code>training.set</code> Last training set values used
in the previous iteration and required for the next run.
</p>
</li>
<li> <p><code>calibration.set</code> Last calibration set values used
in the previous iteration and required for the next run.
</p>
</li>
<li> <p><code>sigma</code> Last covariance matrix calculated in the previous
iteration and required for the next run.
</p>
</li>
<li> <p><code>alphas</code> Last calibration alpha values calculated
in the previous iteration and required for the next run.
</p>
</li>
<li> <p><code>last.data</code> Last values of the dataset converted into
multi-dimensional vectors..
</p>
</li>
<li> <p><code>pred</code> Parameter that is used to reduce false positives. Only
necessary in case of reducefp is TRUE.
</p>
</li>
<li> <p><code>record.count</code> Number of observations that have been
processed up to the last iteration.
</p>
</li></ul>



<h3>References</h3>

<p>V. Ishimtsev, I. Nazarov, A. Bernstein and E. Burnaev. Conformal
k-NN Anomaly Detector for Univariate Data Streams. ArXiv e-prints, jun. 2017.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: ----------------------
## It can be used in the same way as with CpKnnCad passing the whole dataset as
## an argument.

## Generate data
set.seed(100)
n &lt;- 500
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Set parameters
params.KNN &lt;- list(threshold = 1, n.train = 50, l = 19, k = 17)

## Calculate anomalies
result &lt;- IpKnnCad(
  data = df$value,
  n.train = params.KNN$n.train,
  threshold = params.KNN$threshold,
  l = params.KNN$l,
  k = params.KNN$k,
  ncm.type = "ICAD",
  reducefp = TRUE
)

## Plot results
res &lt;- cbind(df, is.anomaly = result$is.anomaly)
PlotDetections(res, print.time.window = FALSE, title = "KNN-CAD ANOMALY DETECTOR")

## EXAMPLE 2: ----------------------
## You can use it in an incremental way. This is an example using the stream
## library. This library allows the simulation of streaming operation.

# install.packages("stream")
library("stream")

## Generate data
set.seed(100)
n &lt;- 500
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)
dsd_df &lt;- DSD_Memory(df)

## Initialize parameters for the loop
last.res &lt;- NULL
res &lt;- NULL
nread &lt;- 100
numIter &lt;- n%/%nread

## Set parameters
params.KNN &lt;- list(threshold = 1, n.train = 50, l = 19, k = 17)

## Calculate anomalies
for(i in 1:numIter) {
  # read new data
  newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
  # calculate if it's an anomaly
  last.res &lt;- IpKnnCad(
    data = newRow$value,
    n.train = params.KNN$n.train,
    threshold = params.KNN$threshold,
    l = params.KNN$l,
    k = params.KNN$k,
    ncm.type = "ICAD",
    reducefp = TRUE,
    to.next.iteration = last.res$to.next.iteration
  )
  # prepare the result
  if(!is.null(last.res$is.anomaly)){
    res &lt;- rbind(res, cbind(newRow, is.anomaly = last.res$is.anomaly))
  }
}

## Plot results
PlotDetections(res, title = "KNN-CAD ANOMALY DETECTOR")



</code></pre>

<hr>
<h2 id='IpPewma'>Incremental Processing Probabilistic-EWMA (PEWMA).</h2><span id='topic+IpPewma'></span>

<h3>Description</h3>

<p><code>IpPewma</code> allows the calculation of anomalies using PEWMA
in an incremental processing mode. See also <code><a href="#topic+OipPewma">OipPewma</a></code>, the
optimized and faster function of this function This algorithm is a
probabilistic method of EWMA which dynamically adjusts the parameterization
based on the probability of the given observation. This method produces
dynamic, data-driven anomaly thresholds which are robust to abrupt transient
changes, yet quickly adjust to long-term distributional shifts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IpPewma(data, n.train = 5, alpha0 = 0.8, beta = 0, l = 3,
  last.res = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IpPewma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="IpPewma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="IpPewma_+3A_alpha0">alpha0</code></td>
<td>
<p>Maximal weighting parameter.</p>
</td></tr>
<tr><td><code id="IpPewma_+3A_beta">beta</code></td>
<td>
<p>Weight placed on the probability of the given observation.</p>
</td></tr>
<tr><td><code id="IpPewma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="IpPewma_+3A_last.res">last.res</code></td>
<td>
<p>Last result returned by the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>alpha0</code> must be a numeric value where 0 &lt; <code>alpha0</code> &lt; 1. If a
faster adjustment to the initial shift is desirable, simply lowering
<code>alpha0</code> will suffice. <code>beta</code> is the weight placed on the
probability of the given observation. it must be a numeric value where
0 &lt;= <code>beta</code> &lt;= 1. Note that <code>beta</code> equals 0, PEWMA converges to a
standard EWMA. Finally <code>l</code> is the parameter that determines the control
limits. By default, 3 is used. <code>last.res</code> is the last result returned
by some previous execution of this algorithm. The first time the algorithm
is executed its value is NULL. However, to run a new batch
of data without having to include it in the old dataset and restart the
process, the two parameters returned by the last run are only needed.
</p>
<p>This algorithm can be used for both classical and incremental processing. It
should be noted that in case of having a finite dataset the
<code><a href="#topic+CpPewma">CpPewma</a></code> or <code><a href="#topic+OcpPewma">OcpPewma</a></code> algorithms are faster.
Incremental processing can be used in two ways. 1) Processing all available
data and saving <code>last.res</code> for future runs in which there is new data.
2) Using the <a href="https://CRAN.R-project.org/package=stream">stream</a> library
for when there is too much data and it does not fit into the memory.
An example has been made for this use case.
</p>


<h3>Value</h3>

<p>A list of the following items.
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>dataset conformed by the following columns.</p>
</td></tr>
</table>

<ul>
<li> <p><code>is.anomaly</code> 1 if the value is anomalous 0, otherwise.
</p>
</li>
<li> <p><code>ucl</code> Upper control limit.
</p>
</li>
<li> <p><code>lcl</code> Lower control limit.
</p>
</li></ul>

<table>
<tr><td><code>last.res</code></td>
<td>
<p>Last result returned by the algorithm. Is a dataset
containing the parameters calculated in the last iteration and necessary
for the next one.</p>
</td></tr>
</table>


<h3>References</h3>

<p>M. Carter, Kevin y W. Streilein. Probabilistic reasoning for
streaming anomaly detection. 2012 IEEE Statistical Signal Processing Workshop
(SSP), pp. 377-380, Aug 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: ----------------------
## It can be used in the same way as with CpPewma passing the whole dataset as
## an argument.

## Generate data
set.seed(100)
n &lt;- 350
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n,value = x)

## Calculate anomalies
result &lt;- IpPewma(
  data = df$value,
  alpha0 = 0.8,
  beta = 0.1,
  n.train = 5,
  l = 3,
  last.res = NULL
)
res &lt;- cbind(df, result$result)

## Plot results
PlotDetections(res, title = "PEWMA ANOMALY DETECTOR")

## EXAMPLE 2: ----------------------
## You can use it in an incremental way. This is an example using the stream
## library. This library allows the simulation of streaming operation.

# install.packages("stream")
library("stream")

## Generate data
set.seed(100)
n &lt;- 500
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)
dsd_df &lt;- DSD_Memory(df)

## Initialize parameters for the loop
last.res &lt;- NULL
res &lt;- NULL
nread &lt;- 100
numIter &lt;- n%/%nread

## Calculate anomalies
for(i in 1:numIter) {
  # read new data
  newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
  # calculate if it's an anomaly
  last.res &lt;- IpPewma(
    data = newRow$value,
    n.train = 5,
    alpha0 = 0.8,
    beta = 0.1,
    l = 3,
    last.res = last.res$last.res
  )
  # prepare the result
  if(!is.null(last.res$result)){
    res &lt;- rbind(res, cbind(newRow, last.res$result))
  }
}

## Plot results
PlotDetections(res, title = "PEWMA ANOMALY DETECTOR")



</code></pre>

<hr>
<h2 id='IpSdEwma'>Incremental Processing Shift-Detection based on EWMA (SD-EWMA).</h2><span id='topic+IpSdEwma'></span>

<h3>Description</h3>

<p><code>IpSdEwma</code> allows the calculation of anomalies
using SD-EWMA in an incremental processing mode. See also
<code><a href="#topic+OipSdEwma">OipSdEwma</a></code>, the optimized and faster function of this function
SD-EWMA algorithm is a novel method for covariate shift-detection tests
based on a two-stage structure for univariate time-series. It works in an
online mode and it uses an exponentially weighted moving average (EWMA)
model based control chart to detect the covariate shift-point in
non-stationary time-series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IpSdEwma(data, n.train, threshold = 0.01, l = 3, last.res = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IpSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="IpSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="IpSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="IpSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="IpSdEwma_+3A_last.res">last.res</code></td>
<td>
<p>Last result returned by the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1. It is recommended
to use low values such as 0.01 or 0.05. By default, 0.01 is used. <code>l</code> is
the parameter that determines the control limits. By default, 3 is used.
Finally <code>last.res</code> is the last result returned by some previous
execution of this algorithm. The first time the algorithm is executed its
value is NULL. However, to run a new batch
of data without having to include it in the old dataset and restart the
process, the two parameters returned by the last run are only needed.
</p>
<p>This algorithm can be used for both classical and incremental processing. It
should be noted that in case of having a finite dataset the
<code><a href="#topic+CpSdEwma">CpSdEwma</a></code> or <code><a href="#topic+OcpSdEwma">OcpSdEwma</a></code> algorithms are faster.
Incremental processing can be used in two ways. 1) Processing all available
data and saving <code>last.res</code> for future runs in which there is new data.
2) Using the <a href="https://CRAN.R-project.org/package=stream">stream</a> library
for when there is too much data and it does not fit into memory. An example
has been made for this use case.
</p>


<h3>Value</h3>

<p>A list of the following items.
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>dataset conformed by the following columns.</p>
</td></tr>
</table>

<ul>
<li> <p><code>is.anomaly</code> 1 if the value is anomalous 0 otherwise.
</p>
</li>
<li> <p><code>ucl</code> Upper control limit.
</p>
</li>
<li> <p><code>lcl</code> Lower control limit.
</p>
</li></ul>

<table>
<tr><td><code>last.res</code></td>
<td>
<p>Last result returned by the algorithm. Is a dataset
containing the parameters calculated in the last iteration and necessary
for the next one.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: ----------------------
## It can be used in the same way as with CpSdEwma passing the whole dataset as
## an argument.

## Generate data
set.seed(100)
n &lt;- 200
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- IpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result$result)

## Plot results
PlotDetections(res, title = "SD-EWMA ANOMALY DETECTOR")

## EXAMPLE 2: ----------------------
## You can use it in an incremental way. This is an example using the stream
## library. This library allows the simulation of streaming operation.

# install.packages("stream")
library("stream")

## Generate data
set.seed(100)
n &lt;- 350
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)
dsd_df &lt;- DSD_Memory(df)

## Initialize parameters for the loop
last.res &lt;- NULL
res &lt;- NULL
nread &lt;- 100
numIter &lt;- n%/%nread

## Calculate anomalies
for(i in 1:numIter) {
  # read new data
  newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
  # calculate if it's an anomaly
  last.res &lt;- IpSdEwma(
    data = newRow$value,
    n.train = 5,
    threshold = 0.01,
    l = 3,
    last.res = last.res$last.res
  )
  # prepare the result
  if(!is.null(last.res$result)){
    res &lt;- rbind(res, cbind(newRow, last.res$result))
  }
}

## Plot results
PlotDetections(res, title = "SD-EWMA ANOMALY DETECTOR")


</code></pre>

<hr>
<h2 id='IpTsSdEwma'>Incremental Processing Two-Stage Shift-Detection based on EWMA</h2><span id='topic+IpTsSdEwma'></span>

<h3>Description</h3>

<p><code>IpTsSdEwma</code> allows the calculation of anomalies using
TSSD-EWMA in an incremental processing mode. See also
<code><a href="#topic+OipTsSdEwma">OipTsSdEwma</a></code>, the optimized and faster function of this
function. This algorithm is a novel method for covariate shift-detection
tests based on a two-stage structure for univariate time-series. TSSD-EWMA
works in two phases. In the first phase, it detects anomalies using the
SD-EWMA <code><a href="#topic+CpSdEwma">CpSdEwma</a></code> algorithm. In the second phase, it checks the
veracity of the anomalies using the Kolmogorov-Simirnov test to reduce false
alarms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IpTsSdEwma(data, n.train, threshold, l = 3, m = 5,
  to.next.iteration = list(last.res = NULL, to.check = NULL, last.m =
  NULL))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IpTsSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="IpTsSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="IpTsSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="IpTsSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="IpTsSdEwma_+3A_m">m</code></td>
<td>
<p>Length of the subsequences for applying the Kolmogorov-Smirnov test.</p>
</td></tr>
<tr><td><code id="IpTsSdEwma_+3A_to.next.iteration">to.next.iteration</code></td>
<td>
<p>list with the necessary parameters to execute in
the next iteration</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1.
It is recommended to use low values such as 0.01 or 0.05. By default, 0.01 is
used. Finally, <code>l</code> is the parameter that determines the control limits.
By default, 3 is used. <code>m</code> is the length of the subsequences for
applying the Kolmogorov-Smirnov test. By default, 5 is used. It should be
noted that the last m values have not been verified because you need other m
values to be able to perform the verification. Finally
<code>to.next.iteration</code> is the last result returned by some previous
execution of this algorithm. The first time the algorithm is executed its
value is NULL. However, to run a new batch of data without having to include
it in the old dataset and restart the process, the two parameters returned by
the last run are only needed.
</p>


<h3>Value</h3>

<p>A list of the following items.
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>Dataset conformed by the following columns:</p>
</td></tr>
</table>

<ul>
<li> <p><code>is.anomaly</code> 1 if the value is anomalous 0 otherwise.
</p>
</li>
<li> <p><code>ucl</code> Upper control limit.
</p>
</li>
<li> <p><code>lcl</code> Lower control limit.
</p>
</li>
<li> <p><code>i</code> row id or index
</p>
</li></ul>

<table>
<tr><td><code>last.data.checked</code></td>
<td>
<p>Data frame with checked anomalies. <code>i</code> column is the id or
index and <code>is.anomaly</code> is its new is.anomaly value.</p>
</td></tr>
<tr><td><code>to.next.iteration</code></td>
<td>
<p>Last result returned by the algorithm. It is a list
containing the following items.</p>
</td></tr>
</table>

<ul>
<li> <p><code>last.res</code> Last result returned by the aplicaction of
SD-EWMA function with the calculations of the parameters of the last run
. These are necessary for the next run.
</p>
</li>
<li> <p><code>to.check</code> Subsequence of the last remaining unchecked
values to be checked in the next iterations.
</p>
</li>
<li> <p><code>last.m</code> Subsequence of the last m values.
</p>
</li></ul>



<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: ----------------------
## It can be used in the same way as with CpTsSdEwma passing the whole dataset
## as an argument.

## Generate data
set.seed(100)
n &lt;- 200
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- IpTsSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3,
  m = 20,
  to.next.iteration = NULL
)
res &lt;- cbind(df, result$result)

## Plot results
PlotDetections(res, print.time.window = FALSE, title = "TSSD-EWMA ANOMALY DETECTOR")

## EXAMPLE 2: ----------------------
## You can use it in an incremental way. This is an example using the stream
## library. This library allows the simulation of streaming operation.

# install.packages("stream")
library("stream")

## Generate data
set.seed(100)
n &lt;- 500
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)
dsd_df &lt;- DSD_Memory(df)

## Initialize parameters for the loop
last.res &lt;- NULL
res &lt;- NULL
nread &lt;- 50
numIter &lt;- n%/%nread
m &lt;- 20
dsd_df &lt;- DSD_Memory(df)

## Calculate anomalies
for(i in 1:numIter) {
  # read new data
  newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
  # calculate if it's an anomaly
  last.res &lt;- IpTsSdEwma(
    data = newRow$value,
    n.train = 5,
    threshold = 0.01,
    l = 3,
    m = 20,
    to.next.iteration = last.res$to.next.iteration
  )
  # prepare result
  res &lt;- rbind(res, cbind(newRow, last.res$result))
  if (!is.null(last.res$last.data.checked)) {
    res[res$i %in% last.res$last.data.checked$i, "is.anomaly"] &lt;-
      last.res$last.data.checked$is.anomaly
  }
}

## Plot results
PlotDetections(res, title = "TSSD-EWMA ANOMALY DETECTOR")

</code></pre>

<hr>
<h2 id='machine_temperature_system_failure'>machine_temperature_system_failure.</h2><span id='topic+machine_temperature_system_failure'></span>

<h3>Description</h3>

<p>Temperature sensor data of an internal component of a large, industrial mahcine.
The first anomaly is a planned shutdown of the machine. The second anomaly is
difficult to detect and directly led to the third anomaly, a catastrophic failure
of the machine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>machine_temperature_system_failure
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='NormalizeScore'>Normalize Score using Max and Min normalization</h2><span id='topic+NormalizeScore'></span>

<h3>Description</h3>

<p><code>ReduceAnomalies</code> It reduces the number of detected anomalies. This function is
designed to reduce the number of false positives keeping only the first detection of all those
that are close to each other. This proximity distance is defined by a window
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NormalizeScore(real.score, perfect.score, null.score)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NormalizeScore_+3A_real.score">real.score</code></td>
<td>
<p>Detector score. See <code><a href="#topic+GetDetectorScore">GetDetectorScore</a></code>.</p>
</td></tr>
<tr><td><code id="NormalizeScore_+3A_perfect.score">perfect.score</code></td>
<td>
<p>Perfect detector score; one that outputs all true positives and no false
positives. See <code><a href="#topic+GetNullAndPerfectScores">GetNullAndPerfectScores</a></code>.</p>
</td></tr>
<tr><td><code id="NormalizeScore_+3A_null.score">null.score</code></td>
<td>
<p>Perfect detector score; one that outputs all true positives and no false
positives. See <code><a href="#topic+GetNullAndPerfectScores">GetNullAndPerfectScores</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Normalized score.
</p>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA’15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

# Add is.real.anomaly column
df$is.real.anomaly &lt;- 0
df[c(25,80,150), "is.real.anomaly"] &lt;- 1

## Calculate anomalies
result &lt;- CpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result)

# Get null and perfect scores
np.scores &lt;- GetNullAndPerfectScores(df)
np.standard &lt;- np.scores[1,]
np.fp &lt;- np.scores[2,]
np.fn &lt;- np.scores[3,]

# Get detector score
scores &lt;- GetDetectorScore(res, print = FALSE, title = "")

# Normalize standard score
NormalizeScore(scores$standard, np.standard$perfect.score, np.standard$null.score)

# Normalize low_FP_rate score
NormalizeScore(scores$low_FP_rate, np.fp$perfect.score, np.fp$null.score)

# Normalize low_FN_rate score
NormalizeScore(scores$low_FN_rate, np.fn$perfect.score, np.fn$null.score)
</code></pre>

<hr>
<h2 id='nyc_taxi'>nyc_taxi.</h2><span id='topic+nyc_taxi'></span>

<h3>Description</h3>

<p>Number of NYC taxi passengers, where the five anomalies occur during the NYC
marathon, Thanksgiving, Christmas, New Years day, and a snow storm. The raw
data is from the NYC Taxi and Limousine Commission. The data file included
here consists of aggregating the total number of taxi passengers into 30
minute buckets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nyc_taxi
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='occupancy_6005'>occupancy_6005.</h2><span id='topic+occupancy_6005'></span>

<h3>Description</h3>

<p>Real time traffic data from the Twin Cities Metro area in Minnesota, collected
by the Minnesota Department of Transportation. Included metrics include
occupancy, speed, and travel time from specific sensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occupancy_6005
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='occupancy_t4013'>occupancy_t4013.</h2><span id='topic+occupancy_t4013'></span>

<h3>Description</h3>

<p>Real time traffic data from the Twin Cities Metro area in Minnesota, collected
by the Minnesota Department of Transportation. Included metrics include
occupancy, speed, and travel time from specific sensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>occupancy_t4013
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='OcpPewma'>Optimized Classic Processing Probabilistic-EWMA (PEWMA).</h2><span id='topic+OcpPewma'></span>

<h3>Description</h3>

<p><code>OcpPewma</code> calculates the anomalies of a dataset using
an optimized version of classical processing Probabilistic-EWMA algorithm.
It Is an optimized implementation of the <code><a href="#topic+CpPewma">CpPewma</a></code> algorithm
using environmental variables. It has been shown that in long datasets it can
reduce runtime by up to 50%. TThis algorithm is a probabilistic method of
EWMA which dynamically adjusts the parameterization based on the probability
of the given observation. This method produces dynamic, data-driven anomaly
thresholds which are robust to abrupt transient changes, yet quickly adjust
to long-term distributional shifts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OcpPewma(data, alpha0 = 0.2, beta = 0, n.train = 5, l = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OcpPewma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test datasets.</p>
</td></tr>
<tr><td><code id="OcpPewma_+3A_alpha0">alpha0</code></td>
<td>
<p>Maximal weighting parameter.</p>
</td></tr>
<tr><td><code id="OcpPewma_+3A_beta">beta</code></td>
<td>
<p>Weight placed on the probability of the given observation.</p>
</td></tr>
<tr><td><code id="OcpPewma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="OcpPewma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>alpha0</code> must be a numeric value where 0 &lt; <code>alpha0</code> &lt; 1. If a
faster adjustment to the initial shift is desirable, simply lowering
<code>alpha0</code> will suffice. <code>beta</code> is the weight placed on the
probability of the given observation. It must be a numeric value where
0 &lt;= <code>beta</code> &lt;= 1. Note that if <code>beta</code> equals 0, PEWMA converges to
a standard EWMA. Finally <code>l</code> is the parameter that determines the
control limits. By default, 3 is used.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous 0, otherwise.</p>
</td></tr>
<tr><td><code>ucl</code></td>
<td>
<p>Upper control limit.</p>
</td></tr>
<tr><td><code>lcl</code></td>
<td>
<p>Lower control limit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>M. Carter, Kevin y W. Streilein. Probabilistic reasoning for
streaming anomaly detection. 2012 IEEE Statistical Signal Processing Workshop
(SSP), pp. 377-380, Aug 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- OcpPewma(
  data = df$value,
  n.train = 5,
  alpha0 = 0.8,
  beta = 0.1,
  l = 3
)

## Plot results
res &lt;- cbind(df, result)
PlotDetections(res, title = "PEWMA ANOMALY DETECTOR")
</code></pre>

<hr>
<h2 id='OcpSdEwma'>Optimized Classic Processing Shift-Detection based on EWMA (SD-EWMA).</h2><span id='topic+OcpSdEwma'></span>

<h3>Description</h3>

<p><code>OcpSdEwma</code> calculates the anomalies of a dataset using an
optimized version of classical processing based on the SD-EWMA algorithm.
It is an optimized implementation of the <code><a href="#topic+CpSdEwma">CpSdEwma</a></code> algorithm
using environment variables. It has been shown that in long datasets it can
reduce runtime by up to 50%. SD-EWMA algorithm is a novel method for
covariate shift-detection tests based on a two-stage structure for univariate
time-series. It works in an online mode and it uses an exponentially weighted
moving average (EWMA) model based control chart to detect the covariate
shift-point in non-stationary time-series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OcpSdEwma(data, n.train, threshold, l = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OcpSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="OcpSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the training set.</p>
</td></tr>
<tr><td><code id="OcpSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="OcpSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1.
It is recommended to use low values such as 0.01 or 0.05. By default, 0.01 is
used. Finally, <code>l</code> is the parameter that determines the control limits.
By default, 3 is used.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous 0, otherwise.</p>
</td></tr>
<tr><td><code>ucl</code></td>
<td>
<p>Upper control limit.</p>
</td></tr>
<tr><td><code>lcl</code></td>
<td>
<p>Lower control limit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 200
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- OcpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result)

## Plot results
PlotDetections(res, title = "SD-EWMA ANOMALY DETECTOR")
</code></pre>

<hr>
<h2 id='OcpTsSdEwma'>Optimized Classic Processing Two-Stage Shift-Detection based on EWMA</h2><span id='topic+OcpTsSdEwma'></span>

<h3>Description</h3>

<p><code>OcpTsSdEwma</code> calculates the anomalies of a dataset using
an optimized verision of classical processing based on the SD-EWMA
algorithm. It is an optimized implementation of the <code><a href="#topic+CpTsSdEwma">CpTsSdEwma</a></code>
algorithm using environment variables. It has been shown that in long
datasets it can reduce runtime by up to 50%. This algorithm is a
novel method for covariate shift-detection tests based on a two-stage
structure for univariate time-series. This algorithm works in two phases. In
the first phase, it detects anomalies using the SD-EWMA
<code><a href="#topic+CpSdEwma">CpSdEwma</a></code> algorithm. In the second phase, it checks the veracity
of the anomalies using the Kolmogorov-Simirnov test to reduce false alarms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OcpTsSdEwma(data, n.train, threshold, l = 3, m = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OcpTsSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="OcpTsSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the training set.</p>
</td></tr>
<tr><td><code id="OcpTsSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="OcpTsSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="OcpTsSdEwma_+3A_m">m</code></td>
<td>
<p>Length of the subsequences for applying the Kolmogorov-Smirnov test.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1.
It is recommended to use low values such as 0.01 or 0.05. By default, 0.01 is
used. Finally, <code>l</code> is the parameter that determines the control limits.
By default, 3 is used. <code>m</code> is the length of the subsequences for
applying the Kolmogorov-Smirnov test. By default, 5 is used. It should be
noted that the last <code>m</code> values will not been verified because another
<code>m</code> values are needed to be able to perform the verification.
</p>


<h3>Value</h3>

<p>dataset conformed by the following columns:
</p>
<table>
<tr><td><code>is.anomaly</code></td>
<td>
<p>1 if the value is anomalous 0, otherwise.</p>
</td></tr>
<tr><td><code>ucl</code></td>
<td>
<p>Upper control limit.</p>
</td></tr>
<tr><td><code>lcl</code></td>
<td>
<p>Lower control limit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- OcpTsSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3,
  m = 20
)
res &lt;- cbind(df, result)

## Plot results
PlotDetections(res, title = "TSSD-EWMA ANOMALY DETECTOR")
</code></pre>

<hr>
<h2 id='OipPewma'>Optimized Incremental Processing Probabilistic-EWMA (PEWMA).</h2><span id='topic+OipPewma'></span>

<h3>Description</h3>

<p><code>OipPewma</code> is the optimized implementation of the
<code>IpPewma</code> function using environmental variables. It has been shown that
in long datasets it can reduce runtime by up to 50%. This function allows
the calculation of anomalies using PEWMA in an incremental processing mode.
This algorithm is a probabilistic method of EWMA which dynamically adjusts the
parameterization based on the probability of the given observation. This
method produces dynamic, data-driven anomaly thresholds which are robust to
abrupt transient changes, yet quickly adjust to long-term distributional
shifts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OipPewma(data, alpha0 = 0.2, beta = 0, n.train = 5, l = 3,
  last.res = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OipPewma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="OipPewma_+3A_alpha0">alpha0</code></td>
<td>
<p>Maximal weighting parameter.</p>
</td></tr>
<tr><td><code id="OipPewma_+3A_beta">beta</code></td>
<td>
<p>Weight placed on the probability of the given observation.</p>
</td></tr>
<tr><td><code id="OipPewma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="OipPewma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="OipPewma_+3A_last.res">last.res</code></td>
<td>
<p>Last result returned by the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>alpha0</code> must be a numeric value where 0 &lt; <code>alpha0</code> &lt; 1. If a
faster adjustment to the initial shift is desirable, simply lowering
<code>alpha0</code> will suffice. <code>beta</code> is the weight placed on the
probability of the given observation. it must be a numeric value where
0 &lt;= <code>beta</code> &lt;= 1. Note that <code>beta</code> equals 0, PEWMA converges to a
standard EWMA. Finally <code>l</code> is the parameter that determines the control
limits. By default, 3 is used. <code>last.res</code> is the last result returned
by some previous execution of this algorithm. The first time the algorithm
is executed its value is NULL. However, to run a new batch
of data without having to include it in the old dataset and restart the
process, the two parameters returned by the last run are only needed.
</p>
<p>This algorithm can be used for both classical and incremental processing. It
should be noted that in case of having a finite dataset the
<code><a href="#topic+CpPewma">CpPewma</a></code> or <code><a href="#topic+OcpPewma">OcpPewma</a></code> algorithms are faster.
Incremental processing can be used in two ways. 1) Processing all available
data and saving <code>last.res</code> for future runs in which there is new data.
2) Using the <a href="https://CRAN.R-project.org/package=stream">stream</a> library
for when there is too much data and it does not fit into the memory.
An example has been made for this use case.
</p>


<h3>Value</h3>

<p>A list of the following items.
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>dataset conformed by the following columns.</p>
</td></tr>
</table>

<ul>
<li> <p><code>is.anomaly</code> 1 if the value is anomalous 0, otherwise.
</p>
</li>
<li> <p><code>ucl</code> Upper control limit.
</p>
</li>
<li> <p><code>lcl</code> Lower control limit.
</p>
</li></ul>

<table>
<tr><td><code>last.res</code></td>
<td>
<p>Last result returned by the algorithm. Is a dataset
containing the parameters calculated in the last iteration and necessary
for the next one.</p>
</td></tr>
</table>


<h3>References</h3>

<p>M. Carter, Kevin y W. Streilein. Probabilistic reasoning for
streaming anomaly detection. 2012 IEEE Statistical Signal Processing Workshop
(SSP), pp. 377-380, Aug 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: ----------------------
## It can be used in the same way as with OcpPewma passing the whole dataset as
## an argument.

## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- OipPewma(
  data = df$value,
  alpha0 = 0.8,
  beta = 0.1,
  n.train = 5,
  l = 3,
  last.res = NULL
)
res &lt;- cbind(df, result$result)

## Plot results
PlotDetections(res, title = "PEWMA ANOMALY DETECTOR")

## EXAMPLE 2: ----------------------
## You can use it in an incremental way. This is an example using the stream
## library. This library allows the simulation of streaming operation.

# install.packages("stream")
library("stream")

## Generate data
set.seed(100)
n &lt;- 500
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)
dsd_df &lt;- DSD_Memory(df)

## Initialize parameters for the loop
last.res &lt;- NULL
res &lt;- NULL
nread &lt;- 100
numIter &lt;- n%/%nread

## Calculate anomalies
for(i in 1:numIter) {
  # read new data
  newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
  # calculate if it's an anomaly
  last.res &lt;- OipPewma(
    data = newRow$value,
    n.train = 5,
    alpha0 = 0.8,
    beta = 0.1,
    l = 3,
    last.res = last.res$last.res
  )
  # prepare the result
  if(!is.null(last.res$result)){
    res &lt;- rbind(res, cbind(newRow, last.res$result))
  }
}

## Plot results
PlotDetections(res, print.time.window = FALSE, title = "PEWMA ANOMALY DETECTOR")



</code></pre>

<hr>
<h2 id='OipSdEwma'>Optimized Incremental Processing Shift-Detection based on EWMA (SD-EWMA).</h2><span id='topic+OipSdEwma'></span>

<h3>Description</h3>

<p><code>OipSdEwma</code> is the optimized implementation of the
<code>IpSdEwma</code> function using environmental variables. This function  allows
the calculation of anomalies using SD-EWMA alogrithm in an incremental
processing mode. It has been shown that in long datasets it can reduce
runtime by up to 50%. SD-EWMA algorithm is a novel method for covariate
shift-detection tests based on a two-stage structure for univariate
time-series. It works in an online mode and it uses an exponentially weighted
moving average (EWMA) model based control chart to detect the covariate
shift-point in non-stationary time-series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OipSdEwma(data, n.train, threshold, l = 3, last.res = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OipSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test datasets.</p>
</td></tr>
<tr><td><code id="OipSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="OipSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="OipSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="OipSdEwma_+3A_last.res">last.res</code></td>
<td>
<p>Last result returned by the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1. It is recommended
to use low values such as 0.01 or 0.05. By default, 0.01 is used. <code>l</code> is
the parameter that determines the control limits. By default, 3 is used.
Finally <code>last.res</code> is the last result returned by some previous
execution of this algorithm. The first time the algorithm is executed its
value is NULL. However, to run a new batch
of data without having to include it in the old dataset and restart the
process, the two parameters returned by the last run are only needed.
</p>
<p>This algorithm can be used for both classical and incremental processing. It
should be noted that in case of having a finite dataset the
<code><a href="#topic+CpSdEwma">CpSdEwma</a></code> or <code><a href="#topic+OcpSdEwma">OcpSdEwma</a></code> algorithms are faster.
Incremental processing can be used in two ways. 1) Processing all available
data and saving <code>last.res</code> for future runs in which there is new data.
2) Using the <a href="https://CRAN.R-project.org/package=stream">stream</a> library
for when there is too much data and it does not fit into memory. An example
has been made for this use case.
</p>


<h3>Value</h3>

<p>A list of the following items.
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>dataset conformed by the following columns.</p>
</td></tr>
</table>

<ul>
<li> <p><code>is.anomaly</code> 1 if the value is anomalous 0, otherwise.
</p>
</li>
<li> <p><code>ucl</code> Upper control limit.
</p>
</li>
<li> <p><code>lcl</code> Lower control limit.
</p>
</li></ul>

<table>
<tr><td><code>last.res</code></td>
<td>
<p>Last result returned by the algorithm. Is a dataset
containing the parameters calculated in the last iteration and necessary
for the next one.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: ----------------------
## It can be used in the same way as with OcpSdEwma passing the whole dataset as
## an argument.

## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- OipSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result$result)

## Plot results
PlotDetections(res, print.time.window = FALSE, title = "SD-EWMA ANOMALY DETECTOR")

## EXAMPLE 2: ----------------------
## You can use it in an incremental way. This is an example using the stream
## library. This library allows the simulation of streaming operation.

# install.packages("stream")
library("stream")

## Generate data
set.seed(100)
n &lt;- 500
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)
dsd_df &lt;- DSD_Memory(df)

## Initialize parameters for the loop
last.res &lt;- NULL
res &lt;- NULL
nread &lt;- 100
numIter &lt;- n%/%nread

## Calculate anomalies
for(i in 1:numIter) {
  # read new data
  newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
  # calculate if it's an anomaly
  last.res &lt;- OipSdEwma(
    data = newRow$value,
    n.train = 5,
    threshold = 0.01,
    l = 3,
    last.res = last.res$last.res
  )
  # prepare the result
  if(!is.null(last.res$result)){
    res &lt;- rbind(res, cbind(newRow, last.res$result))
  }
}

# plot
PlotDetections(res, title = "SD-EWMA ANOMALY DETECTOR")


</code></pre>

<hr>
<h2 id='OipTsSdEwma'>Optimized Incremental Processing Two-Stage Shift-Detection based on EWMA</h2><span id='topic+OipTsSdEwma'></span>

<h3>Description</h3>

<p><code>OipTsSdEwma</code> is the optimized implementation of the
<code>IpTsSdEwma</code> function using environmental variables. This function
allows the calculation of anomalies using TSSD-EWMA in an incremental
processing mode. It has been shown that in long datasets it can reduce
runtime by up to 50%. This algorithm is a novel method for covariate
shift-detection tests based on a two-stage structure for univariate
time-series. TSSD-EWMA works in two phases. In the first phase, it detects
anomalies using the SD-EWMA <code><a href="#topic+CpSdEwma">CpSdEwma</a></code> algorithm. In the second
phase, it checks the veracity of the anomalies using the Kolmogorov-Simirnov
test to reduce false alarms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OipTsSdEwma(data, n.train, threshold, l = 3, m = 5,
  to.next.iteration = list(last.res = NULL, to.check = NULL, last.m =
  NULL))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OipTsSdEwma_+3A_data">data</code></td>
<td>
<p>Numerical vector with training and test dataset.</p>
</td></tr>
<tr><td><code id="OipTsSdEwma_+3A_n.train">n.train</code></td>
<td>
<p>Number of points of the dataset that correspond to the
training set.</p>
</td></tr>
<tr><td><code id="OipTsSdEwma_+3A_threshold">threshold</code></td>
<td>
<p>Error smoothing constant.</p>
</td></tr>
<tr><td><code id="OipTsSdEwma_+3A_l">l</code></td>
<td>
<p>Control limit multiplier.</p>
</td></tr>
<tr><td><code id="OipTsSdEwma_+3A_m">m</code></td>
<td>
<p>Length of the subsequences for applying the Kolmogorov-Smirnov test.</p>
</td></tr>
<tr><td><code id="OipTsSdEwma_+3A_to.next.iteration">to.next.iteration</code></td>
<td>
<p>list with the necessary parameters to execute in
the next iteration</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a numerical vector without NA values.
<code>threshold</code> must be a numeric value between 0 and 1.
It is recommended to use low values such as 0.01 or 0.05. By default, 0.01 is
used. Finally, <code>l</code> is the parameter that determines the control limits.
By default, 3 is used. <code>m</code> is the length of the subsequences for
applying the Kolmogorov-Smirnov test. By default, 5 is used. It should be
noted that the last m values have not been verified because you need other m
values to be able to perform the verification. Finally
<code>to.next.iteration</code> is the last result returned by some previous
execution of this algorithm. The first time the algorithm is executed its
value is NULL. However, to run a new batch of data without having to include
it in the old dataset and restart the process, the two parameters returned by
the last run are only needed.
</p>


<h3>Value</h3>

<p>A list of the following items.
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>Dataset conformed by the following columns:</p>
</td></tr>
</table>

<ul>
<li> <p><code>is.anomaly</code> 1 if the value is anomalous 0 otherwise.
</p>
</li>
<li> <p><code>ucl</code> Upper control limit.
</p>
</li>
<li> <p><code>lcl</code> Lower control limit.
</p>
</li>
<li> <p><code>i</code> row id or index
</p>
</li></ul>

<table>
<tr><td><code>last.data.checked</code></td>
<td>
<p>Data frame with checked anomalies. <code>i</code> column is the id or
index and <code>is.anomaly</code> is its new is.anomaly value.</p>
</td></tr>
<tr><td><code>to.next.iteration</code></td>
<td>
<p>Last result returned by the algorithm. It is a list
containing the following items.</p>
</td></tr>
</table>

<ul>
<li> <p><code>last.res</code> Last result returned by the aplicaction of
SD-EWMA function with the calculations of the parameters of the last run
. These are necessary for the next run.
</p>
</li>
<li> <p><code>to.check</code> Subsequence of the last remaining unchecked
values to be checked in the next iterations.
</p>
</li>
<li> <p><code>last.m</code> Subsequence of the last m values.
</p>
</li></ul>



<h3>References</h3>

<p>Raza, H., Prasad, G., &amp; Li, Y. (03 de 2015). EWMA model based
shift-detection methods for detecting covariate shifts in non-stationary
environments. Pattern Recognition, 48(3), 659-669.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: ----------------------
## It can be used in the same way as with OcpTsSdEwma passing the whole dataset
## as an argument.

## Generate data
set.seed(100)
n &lt;- 200
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- OipTsSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3,
  m = 20,
  to.next.iteration = NULL
)
res &lt;- cbind(df, result$result)

## Plot results
PlotDetections(res, print.time.window = FALSE, title = "TSSD-EWMA ANOMALY DETECTOR")

## EXAMPLE 2: ----------------------
## You can use it in an incremental way. This is an example using the stream
## library. This library allows the simulation of streaming operation.

# install.packages("stream")
library("stream")


## Generate data
set.seed(100)
n &lt;- 500
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)
dsd_df &lt;- DSD_Memory(df)

## Initialize parameters for the loop
last.res &lt;- NULL
res &lt;- NULL
nread &lt;- 50
numIter &lt;- n%/%nread
m &lt;- 20
dsd_df &lt;- DSD_Memory(df)

## Calculate anomalies
for(i in 1:numIter) {
  # read new data
  newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
  # calculate if it's an anomaly
  last.res &lt;- OipTsSdEwma(
    data = newRow$value,
    n.train = 5,
    threshold = 0.01,
    l = 3,
    m = 20,
    to.next.iteration = last.res$to.next.iteration
  )
  # prepare result
  res &lt;- rbind(res, cbind(newRow, last.res$result))
  if (!is.null(last.res$last.data.checked)) {
    res[res$i %in% last.res$last.data.checked$i, "is.anomaly"] &lt;-
      last.res$last.data.checked$is.anomaly
  }
}

## Plot results
PlotDetections(res, title = "TSSD-EWMA ANOMALY DETECTOR")

</code></pre>

<hr>
<h2 id='PlotDetections'>PLOT DETECTIONS</h2><span id='topic+PlotDetections'></span>

<h3>Description</h3>

<p><code>PlotDetections</code> shows in a graph the results obtained after the application
of one of the anomaly detectors included in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotDetections(data, print.real.anomaly = FALSE,
  print.time.window = FALSE, title = "", xlab = "Time",
  ylab = "Value", return.ggplot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotDetections_+3A_data">data</code></td>
<td>
<p>data.frame composed of at least one column called timestamp and another column
called value. You can also include other columns such as is.anomaly, is.real.anomaly, ucl, lcl,
anomaly.score. Any of these columns except is.real.anomaly that are included in the dataset will
be shown in the graph automatically.</p>
</td></tr>
<tr><td><code id="PlotDetections_+3A_print.real.anomaly">print.real.anomaly</code></td>
<td>
<p>If TRUE adds the real anomalies to the graph.</p>
</td></tr>
<tr><td><code id="PlotDetections_+3A_print.time.window">print.time.window</code></td>
<td>
<p>If TRUE shows a time band centered on the real anomaly. According to the
article shown in the reference, if the detected anomaly remains within it would be considered a
true positive.</p>
</td></tr>
<tr><td><code id="PlotDetections_+3A_title">title</code></td>
<td>
<p>Title of the graph.</p>
</td></tr>
<tr><td><code id="PlotDetections_+3A_xlab">xlab</code></td>
<td>
<p>X Axis Name.</p>
</td></tr>
<tr><td><code id="PlotDetections_+3A_ylab">ylab</code></td>
<td>
<p>Y Axis Name.</p>
</td></tr>
<tr><td><code id="PlotDetections_+3A_return.ggplot">return.ggplot</code></td>
<td>
<p>If TRUE the function returns a ggplot object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>data</code> must be a data.frame. The <code>timestamp</code> column can be numeric, of type POSIXlt,
or a character type date convertible  to POSIXlt. The <code>value</code> column must be numeric.
<code>is.anomaly</code>, <code>is.real.anomaly</code>, <code>ucl</code>, <code>lcl</code>, <code>anomaly.score</code> are
some of the variables returned by the algorithms included in this package and must be numeric
or boolean in the case of columns is.anomaly, is.real.anomaly .
</p>


<h3>Value</h3>

<p>plotly object.
</p>


<h3>References</h3>

<p>A. Lavin and S. Ahmad, “Evaluating Real-time Anomaly Detection Algorithms – the
Numenta Anomaly Benchmark,” in 14th International Conference on Machine Learning and
Applications (IEEE ICMLA’15), 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(100)
n &lt;- 180
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[150] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- CpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 3
)
res &lt;- cbind(df, result)

## Plot results
PlotDetections(res, title = "KNN-CAD ANOMALY DETECTOR")
</code></pre>

<hr>
<h2 id='rds_cpu_utilization_cc0c53'>rds_cpu_utilization_cc0c53.</h2><span id='topic+rds_cpu_utilization_cc0c53'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rds_cpu_utilization_cc0c53
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='rds_cpu_utilization_e47b3b'>rds_cpu_utilization_e47b3b.</h2><span id='topic+rds_cpu_utilization_e47b3b'></span>

<h3>Description</h3>

<p>AWS server metrics as collected by the AmazonCloudwatch service. Example metrics include
CPU Utilization, Network Bytes In, and Disk Read Bytes..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rds_cpu_utilization_e47b3b
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='ReduceAnomalies'>Reduce Anomalies</h2><span id='topic+ReduceAnomalies'></span>

<h3>Description</h3>

<p><code>ReduceAnomalies</code> It reduces the number of detected anomalies. This function is
designed to reduce the number of false positives keeping only the first detection of all those
that are close to each other. This proximity distance is defined by a window
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReduceAnomalies(data, windowLength, incremental = FALSE,
  last.res = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReduceAnomalies_+3A_data">data</code></td>
<td>
<p>Numerical vector with anomaly labels.</p>
</td></tr>
<tr><td><code id="ReduceAnomalies_+3A_windowlength">windowLength</code></td>
<td>
<p>Window length.</p>
</td></tr>
<tr><td><code id="ReduceAnomalies_+3A_incremental">incremental</code></td>
<td>
<p>TRUE for incremental processing and FALSE for classic processing</p>
</td></tr>
<tr><td><code id="ReduceAnomalies_+3A_last.res">last.res</code></td>
<td>
<p>Last result returned by the algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>incremental</code> = FALSE,  new Numerical vector with reduced anomaly labels. Else,
a list of the following items.
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>New Numerical vector with reduced anomaly labels.</p>
</td></tr>
<tr><td><code>last.res</code></td>
<td>
<p>Last result returned by the algorithm. It is a list with <code>pointer</code>,
the index of the last anomaly and <code>index</code>, the index number of the last point in the data</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE 1: Classic Processing ----------------------

## Generate data
set.seed(100)
n &lt;- 350
x &lt;- sample(1:100, n, replace = TRUE)
x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
x[25] &lt;- 200
x[320] &lt;- 170
df &lt;- data.frame(timestamp = 1:n, value = x)

## Calculate anomalies
result &lt;- IpSdEwma(
  data = df$value,
  n.train = 5,
  threshold = 0.01,
  l = 2
)
res &lt;- cbind(df, result$result)

## Plot results
PlotDetections(res, title = "SD-EWMA ANOMALY DETECTOR")

## Reduce anomalies
res$is.anomaly &lt;- ReduceAnomalies(res$is.anomaly, windowLength = 5)

## Plot results
PlotDetections(res, title = "SD-EWMA ANOMALY DETECTOR")


## EXAMPLE 2: Incremental Processing ----------------------


  # install.packages("stream")
  library("stream")

  # Generate data
  set.seed(100)
  n &lt;- 350
  x &lt;- sample(1:100, n, replace = TRUE)
  x[70:90] &lt;- sample(110:115, 21, replace = TRUE)
  x[25] &lt;- 200
  x[320] &lt;- 170
  df &lt;- data.frame(timestamp = 1:n, value = x)
  dsd_df &lt;- DSD_Memory(df)

  # Initialize parameters for the loop
  last.res &lt;- NULL
  red.res &lt;- NULL
  res &lt;- NULL
  nread &lt;- 100
  numIter &lt;- ceiling(n/nread)

  # Calculate anomalies
  for(i in 1:numIter) {
    # read new data
    newRow &lt;- get_points(dsd_df, n = nread, outofpoints = "ignore")
    # calculate if it's an anomaly
    last.res &lt;- IpSdEwma(
      data = newRow$value,
      n.train = 5,
      threshold = 0.01,
      l = 2,
      last.res = last.res$last.res
    )

    if(!is.null(last.res$result)){
      # reduce anomalies
      red.res &lt;- ReduceAnomalies(last.res$result$is.anomaly,
                                 windowLength = 5, incremental = TRUE, last.res = red.res$last.res)
      last.res$result$is.anomaly &lt;- red.res$result

      # prepare the result
      res &lt;- rbind(res, cbind(newRow, last.res$result))
    }
  }

  # Plot results
  PlotDetections(res, title = "SD-EWMA ANOMALY DETECTOR")

</code></pre>

<hr>
<h2 id='rogue_agent_key_hold'>rogue_agent_key_hold.</h2><span id='topic+rogue_agent_key_hold'></span>

<h3>Description</h3>

<p>Timing the key holds for several users of a computer, where the anomalies
represent a change in the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rogue_agent_key_hold
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='rogue_agent_key_updown'>rogue_agent_key_updown.</h2><span id='topic+rogue_agent_key_updown'></span>

<h3>Description</h3>

<p>Timing the key strokes for several users of a computer, where the anomalies
represent a change in the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rogue_agent_key_updown
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='speed_6005'>speed_6005.</h2><span id='topic+speed_6005'></span>

<h3>Description</h3>

<p>Real time traffic data from the Twin Cities Metro area in Minnesota, collected
by the Minnesota Department of Transportation. Included metrics include
occupancy, speed, and travel time from specific sensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>speed_6005
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='speed_7578'>speed_7578.</h2><span id='topic+speed_7578'></span>

<h3>Description</h3>

<p>Real time traffic data from the Twin Cities Metro area in Minnesota, collected
by the Minnesota Department of Transportation. Included metrics include
occupancy, speed, and travel time from specific sensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>speed_7578
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='speed_t4013'>speed_t4013.</h2><span id='topic+speed_t4013'></span>

<h3>Description</h3>

<p>Real time traffic data from the Twin Cities Metro area in Minnesota, collected
by the Minnesota Department of Transportation. Included metrics include
occupancy, speed, and travel time from specific sensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>speed_t4013
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='TravelTime_387'>TravelTime_387.</h2><span id='topic+TravelTime_387'></span>

<h3>Description</h3>

<p>Real time traffic data from the Twin Cities Metro area in Minnesota, collected
by the Minnesota Department of Transportation. Included metrics include
occupancy, speed, and travel time from specific sensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TravelTime_387
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='TravelTime_451'>TravelTime_451.</h2><span id='topic+TravelTime_451'></span>

<h3>Description</h3>

<p>Real time traffic data from the Twin Cities Metro area in Minnesota, collected
by the Minnesota Department of Transportation. Included metrics include
occupancy, speed, and travel time from specific sensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TravelTime_451
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_AAPL'>Twitter_volume_AAPL.</h2><span id='topic+Twitter_volume_AAPL'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_AAPL
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_AMZN'>Twitter_volume_AMZN.</h2><span id='topic+Twitter_volume_AMZN'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_AMZN
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_CRM'>Twitter_volume_CRM.</h2><span id='topic+Twitter_volume_CRM'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_CRM
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_CVS'>Twitter_volume_CVS.</h2><span id='topic+Twitter_volume_CVS'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_CVS
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_FB'>Twitter_volume_FB.</h2><span id='topic+Twitter_volume_FB'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_FB
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_GOOG'>Twitter_volume_GOOG.</h2><span id='topic+Twitter_volume_GOOG'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_GOOG
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_IBM'>Twitter_volume_IBM.</h2><span id='topic+Twitter_volume_IBM'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_IBM
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_KO'>Twitter_volume_KO.</h2><span id='topic+Twitter_volume_KO'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_KO
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_PFE'>Twitter_volume_PFE.</h2><span id='topic+Twitter_volume_PFE'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_PFE
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

<hr>
<h2 id='Twitter_volume_UPS'>Twitter_volume_UPS.</h2><span id='topic+Twitter_volume_UPS'></span>

<h3>Description</h3>

<p>A collection of Twitter mentions of large publicly-traded companies such
as Google and IBM. The metric value represents the number of mentions for
a given ticker symbol every 5 minutes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Twitter_volume_UPS
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: <code>timestamp</code>, <code>value</code>,
<code>is.real.anomaly</code>.
</p>
<p>For further details, see <a href="https://github.com/numenta/NAB/blob/master/data/README.md">https://github.com/numenta/NAB/blob/master/data/README.md</a></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
