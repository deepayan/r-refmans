<!DOCTYPE html><html><head><title>Help for package rqPen</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rqPen}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#rqPen'><p>rqPen: A package for estimating quantile regression models using penalized objective functions.</p></a></li>
<li><a href='#beta_plots'><p>Plots of coefficients by lambda for cv.rq.group.pen and cv.rq.pen</p></a></li>
<li><a href='#bytau.plot'><p>Plot of how coefficients change with tau</p></a></li>
<li><a href='#bytau.plot.rq.pen.seq'><p>Plot of how coefficients change with tau.</p></a></li>
<li><a href='#bytau.plot.rq.pen.seq.cv'><p>Plot of coefficients varying by quantiles for rq.pen.seq.cv object</p></a></li>
<li><a href='#coef.cv.rq.group.pen'><p>Coefficients from a cv.rq.group.pen object</p></a></li>
<li><a href='#coef.cv.rq.pen'><p>Returns Coefficients of a cv.rq.pen object</p></a></li>
<li><a href='#coef.rq.pen.seq'><p>Returns coefficients of a rq.pen.seq object</p></a></li>
<li><a href='#coef.rq.pen.seq.cv'><p>Returns coefficients from a rq.pen.seq.cv object.</p></a></li>
<li><a href='#cv_plots'><p>Plots of cross validation results as a function of lambda.</p></a></li>
<li><a href='#cv.rq.group.pen'><p>Old cross validation function for group penalty</p></a></li>
<li><a href='#plot.cv.rq.group.pen'><p>Cross validation plot for cv.rq.group.pen object</p></a></li>
<li><a href='#plot.rq.pen.seq'><p>Plot of coefficients of rq.pen.seq object as a function of lambda</p></a></li>
<li><a href='#plot.rq.pen.seq.cv'><p>Plots cross validation results from a rq.pen.seq.cv object</p></a></li>
<li><a href='#predict.cv.rq.pen'><p>Prediction for a cv.rq.pen object</p></a></li>
<li><a href='#predict.qic.select'><p>Predictions from a qic.select object</p></a></li>
<li><a href='#predict.rq.pen'><p>Prediction for a rq.pen object</p></a></li>
<li><a href='#predict.rq.pen.seq'><p>Predictions from rq.pen.seq object</p></a></li>
<li><a href='#predict.rq.pen.seq.cv'><p>Predictions from rq.pen.seq.cv object</p></a></li>
<li><a href='#print.qic.select'><p>Print a qic.select object</p></a></li>
<li><a href='#print.rq.pen.seq'><p>Print a rq.pen.seq object</p></a></li>
<li><a href='#print.rq.pen.seq.cv'><p>Prints a rq.pen.seq.cv object</p></a></li>
<li><a href='#qic'><p>Calculate information criterion for penalized quantile regression models. Currently not exported.</p></a></li>
<li><a href='#qic.select'><p>Select tuning parameters using IC</p></a></li>
<li><a href='#qic.select.rq.pen.seq'><p>Select tuning parameters using IC</p></a></li>
<li><a href='#qic.select.rq.pen.seq.cv'><p>Select tuning parameters using IC</p></a></li>
<li><a href='#rq.gq.pen'><p>Title Quantile regression estimation and consistent variable selection across multiple quantiles</p></a></li>
<li><a href='#rq.gq.pen.cv'><p>Title Cross validation for consistent variable selection across multiple quantiles.</p></a></li>
<li><a href='#rq.group.fit'><p>Estimates a quantile regression model with a group penalized objective function.</p></a></li>
<li><a href='#rq.group.pen'><p>Fits quantile regression models using a group penalized objective function.</p></a></li>
<li><a href='#rq.group.pen.cv'><p>Performs cross validation for a group penalty.</p></a></li>
<li><a href='#rq.lasso.fit'><p>Estimates a quantile regression model with a lasso penalized quanitle loss function.</p></a></li>
<li><a href='#rq.nc.fit'><p>Non-convex penalized quantile regression</p></a></li>
<li><a href='#rq.pen'><p>Fit a quantile regression model using a penalized quantile loss function.</p></a></li>
<li><a href='#rq.pen.cv'><p>Does k-folds cross validation for rq.pen. If multiple values of a are specified then does a grid based search for best value of <code class="reqn">\lambda</code> and a.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Penalized Quantile Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>4.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-31</td>
</tr>
<tr>
<td>Author:</td>
<td>Ben Sherwood [aut, cre], Adam Maidman [aut], Shaobo Li [aut] </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, quantreg, hqreg, hrqglas, data.table, Rdpack,
lifecycle, plyr, Matrix, Rcpp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>splines, knitr</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ben Sherwood &lt;ben.sherwood@ku.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs penalized quantile regression with LASSO, elastic net, SCAD and MCP penalty functions including group penalties. In addition, offers a group penalty that provides consistent variable selection across quantiles. Provides a function that automatically generates lambdas and evaluates different models with cross validation or BIC, including a large p version of BIC. Below URL provides a link to a work in progress vignette. </td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bssherwood/rqpen/blob/master/ignore/rqPenArticle.pdf">https://github.com/bssherwood/rqpen/blob/master/ignore/rqPenArticle.pdf</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-31 15:23:59 UTC; b157s966</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-04 13:30:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='rqPen'>rqPen: A package for estimating quantile regression models using penalized objective functions.</h2><span id='topic+rqPen'></span><span id='topic+rqPen-package'></span>

<h3>Description</h3>

<p>The package estimates a quantile regression model using LASSO, Adaptive LASSO, SCAD, MCP, elastic net, 
and their group counterparts, with the exception of elastic net for which there is no group penalty implementation.
</p>


<h3>rqPen functions</h3>

<p>The most important functions are rq.pen(), rq.group.pen(), rq.pen.cv() and rq.group.pen.cv(). These functions 
fit quantile regression models with individual or group penalties. The cv functions automate the cross-validation process for selection of tuning parameters.
</p>

<hr>
<h2 id='beta_plots'>Plots of coefficients by lambda for cv.rq.group.pen and cv.rq.pen</h2><span id='topic+beta_plots'></span>

<h3>Description</h3>

<p>Warning: this function is no longer exported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beta_plots(model, voi = NULL, logLambda = TRUE, loi = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beta_plots_+3A_model">model</code></td>
<td>
<p>cv.rq.pen or cv.rq.group.pen object</p>
</td></tr>
<tr><td><code id="beta_plots_+3A_voi">voi</code></td>
<td>
<p>Index of betas to include. Default is all of them.</p>
</td></tr>
<tr><td><code id="beta_plots_+3A_loglambda">logLambda</code></td>
<td>
<p>Plot of lambdas is on the log scale.</p>
</td></tr>
<tr><td><code id="beta_plots_+3A_loi">loi</code></td>
<td>
<p>Index of lambdas to use, default is all of them.</p>
</td></tr>
<tr><td><code id="beta_plots_+3A_...">...</code></td>
<td>
<p>Additional arguments to be sent to plot()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plot of how beta estimates change with lambda.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  set.seed(1)
  x &lt;- matrix(rnorm(800),nrow=100)
  y &lt;- 1 + x[,1] - 3*x[,5] + rnorm(100)
  lassoModels &lt;- cv.rq.pen(x,y)
  b_plot &lt;- beta_plots(lassoModels)

## End(Not run)
</code></pre>

<hr>
<h2 id='bytau.plot'>Plot of how coefficients change with tau</h2><span id='topic+bytau.plot'></span>

<h3>Description</h3>

<p>Plot of how coefficients change with tau
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bytau.plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bytau.plot_+3A_x">x</code></td>
<td>
<p>A rq.pen.seq or rq.pen.seq.cv object.</p>
</td></tr>
<tr><td><code id="bytau.plot_+3A_...">...</code></td>
<td>
<p>Additional arguments see bytau.plot.rq.pen.seq() or bytau.plot.rq.pen.seq.cv() for more information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the plot of how coefficients change with tau.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>

<hr>
<h2 id='bytau.plot.rq.pen.seq'>Plot of how coefficients change with tau.</h2><span id='topic+bytau.plot.rq.pen.seq'></span>

<h3>Description</h3>

<p>Plot of how coefficients change with tau.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq'
bytau.plot(x, a = NULL, lambda = NULL, lambdaIndex = NULL, vars = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bytau.plot.rq.pen.seq_+3A_x">x</code></td>
<td>
<p>An rq.pen.seq object</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq_+3A_a">a</code></td>
<td>
<p>The tuning parameter a of interest</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq_+3A_lambda">lambda</code></td>
<td>
<p>The lambda value of interest.</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq_+3A_lambdaindex">lambdaIndex</code></td>
<td>
<p>The lambda index of interest. Only specify lambdaIndex or lambda, not both.</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq_+3A_vars">vars</code></td>
<td>
<p>Index of the variables to plot with 1 being the intercept, 2 being the first predictor, etc. Default is to include all variables.</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq_+3A_...">...</code></td>
<td>
<p>Additional parameters sent to coef()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of coefficient values by tau.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(1)
  x &lt;- matrix(rnorm(800),nrow=100)
  y &lt;- 1 + x[,1] - 3*x[,5] + rnorm(100)
  lassoModels &lt;- rq.pen(x,y,tau=seq(.1,.9,.1))
  bytau.plot(lassoModels,lambda=lassoModels$lambda[5])
</code></pre>

<hr>
<h2 id='bytau.plot.rq.pen.seq.cv'>Plot of coefficients varying by quantiles for rq.pen.seq.cv object</h2><span id='topic+bytau.plot.rq.pen.seq.cv'></span>

<h3>Description</h3>

<p>Produces plots of how coefficient estimates vary by quantile for models selected by using cross validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq.cv'
bytau.plot(
  x,
  septau = ifelse(x$fit$penalty != "gq", TRUE, FALSE),
  cvmin = TRUE,
  useDefaults = TRUE,
  vars = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bytau.plot.rq.pen.seq.cv_+3A_x">x</code></td>
<td>
<p>An rq.pen.seq.cv object</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq.cv_+3A_septau">septau</code></td>
<td>
<p>Whether optimal tuning parameters are estimated separately for each quantile.</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq.cv_+3A_cvmin">cvmin</code></td>
<td>
<p>Whether the minimum cv error should be used or the one standard error rule.</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq.cv_+3A_usedefaults">useDefaults</code></td>
<td>
<p>Set to FALSE if you want to use something besides minimum cv or 1se.</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq.cv_+3A_vars">vars</code></td>
<td>
<p>Index of the variables to plot with 1 being the intercept, 2 being the first predictor, etc. Default is to include all variables.</p>
</td></tr>
<tr><td><code id="bytau.plot.rq.pen.seq.cv_+3A_...">...</code></td>
<td>
<p>Additional parameters sent to coef()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns plots of coefficient estimates varying by quantile.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> set.seed(1)
 x &lt;- matrix(runif(800),nrow=100)
 y &lt;- 1 + x[,1] - 3*x[,5] + (1+x[,4])*rnorm(100)
 lmcv &lt;- rq.pen.cv(x,y,tau=seq(.1,.9,.1))
 bytau.plot(lmcv)
</code></pre>

<hr>
<h2 id='coef.cv.rq.group.pen'>Coefficients from a cv.rq.group.pen object</h2><span id='topic+coef.cv.rq.group.pen'></span>

<h3>Description</h3>

<p>Coefficients from a cv.rq.group.pen object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.rq.group.pen'
coef(object, lambda = "min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.cv.rq.group.pen_+3A_object">object</code></td>
<td>
<p>A cv.rq.group.pen object.</p>
</td></tr>
<tr><td><code id="coef.cv.rq.group.pen_+3A_lambda">lambda</code></td>
<td>
<p>The lambda value, default is to use the one associated with the minimum cv error.</p>
</td></tr>
<tr><td><code id="coef.cv.rq.group.pen_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of coefficients.
</p>

<hr>
<h2 id='coef.cv.rq.pen'>Returns Coefficients of a cv.rq.pen object</h2><span id='topic+coef.cv.rq.pen'></span>

<h3>Description</h3>

<p>Warning: this function is no longer exported, due to the switch from cv.rq.pen() to rq.pen.cv().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.rq.pen'
coef(object, lambda = "min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.cv.rq.pen_+3A_object">object</code></td>
<td>
<p>cv.rq.pen object</p>
</td></tr>
<tr><td><code id="coef.cv.rq.pen_+3A_lambda">lambda</code></td>
<td>
<p>Value of lambda, default is to use the minimum value.</p>
</td></tr>
<tr><td><code id="coef.cv.rq.pen_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Coefficients for a given lambda, or the lambda associated with the minimum cv value.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>

<hr>
<h2 id='coef.rq.pen.seq'>Returns coefficients of a rq.pen.seq object</h2><span id='topic+coef.rq.pen.seq'></span>

<h3>Description</h3>

<p>Returns coefficients of a rq.pen.seq object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq'
coef(
  object,
  tau = NULL,
  a = NULL,
  lambda = NULL,
  modelsIndex = NULL,
  lambdaIndex = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.rq.pen.seq_+3A_object">object</code></td>
<td>
<p>rq.pen.seq object</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq_+3A_tau">tau</code></td>
<td>
<p>Quantile of interest. Default is NULL, which will return all quantiles. Should not be specified if modelsIndex is used.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq_+3A_a">a</code></td>
<td>
<p>Tuning parameter of a. Default is NULL, which returns coefficients for all values of a. Should not be specified if modelsIndex is used.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq_+3A_lambda">lambda</code></td>
<td>
<p>Tuning parameter of <code class="reqn">\lambda</code>. Default is NULL, which returns coefficients for all values of <code class="reqn">\lambda</code>.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq_+3A_modelsindex">modelsIndex</code></td>
<td>
<p>Index of the models for which coefficients should be returned. Does not need to be specified if tau or a are specified.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq_+3A_lambdaindex">lambdaIndex</code></td>
<td>
<p>Index of the lambda values for which coefficients should be returned. Does not need to be specified if lambda is specified.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of a matrix of coefficients for each tau and a combination
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
m1 &lt;- rq.pen(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.75),lambda=c(.1,.05,.01))
allCoefs &lt;- coef(m1)
targetCoefs &lt;- coef(m1,tau=.25,a=.5,lambda=.1)
idxApproach &lt;- coef(m1,modelsIndex=2)
bothIdxApproach &lt;- coef(m1,modelsIndex=2,lambdaIndex=1)
</code></pre>

<hr>
<h2 id='coef.rq.pen.seq.cv'>Returns coefficients from a rq.pen.seq.cv object.</h2><span id='topic+coef.rq.pen.seq.cv'></span>

<h3>Description</h3>

<p>Returns coefficients from a rq.pen.seq.cv object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq.cv'
coef(
  object,
  septau = ifelse(object$fit$penalty != "gq", TRUE, FALSE),
  cvmin = TRUE,
  useDefaults = TRUE,
  tau = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.rq.pen.seq.cv_+3A_object">object</code></td>
<td>
<p>An rq.pen.seq.cv object.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq.cv_+3A_septau">septau</code></td>
<td>
<p>Whether tuning parameter should be optimized separately for each quantile.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq.cv_+3A_cvmin">cvmin</code></td>
<td>
<p>If TRUE then minimum error is used, if FALSE then one standard error rule is used.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq.cv_+3A_usedefaults">useDefaults</code></td>
<td>
<p>Whether the default results are used. Set to FALSE if you you want to specify specific models and lambda values.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq.cv_+3A_tau">tau</code></td>
<td>
<p>Quantiles of interest.</p>
</td></tr>
<tr><td><code id="coef.rq.pen.seq.cv_+3A_...">...</code></td>
<td>
<p>Additional parameters sent to coef.rq.pen.seq()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns coefficients
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
 set.seed(1)
 x &lt;- matrix(rnorm(800),nrow=100)
 y &lt;- 1 + x[,1] - 3*x[,5] + rnorm(100)
 lassoModels &lt;- rq.pen.cv(x,y,tau=seq(.1,.9,.1))
 coefficients(lassoModels,septau=FALSE)
 coefficients(lassoModels,cvmin=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='cv_plots'>Plots of cross validation results as a function of lambda.</h2><span id='topic+cv_plots'></span>

<h3>Description</h3>

<p>Plots of cross validation results as a function of lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_plots(model, logLambda = TRUE, loi = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_plots_+3A_model">model</code></td>
<td>
<p>A cv.rq.pen() object.</p>
</td></tr>
<tr><td><code id="cv_plots_+3A_loglambda">logLambda</code></td>
<td>
<p>Whether lambda values should be logged or not.</p>
</td></tr>
<tr><td><code id="cv_plots_+3A_loi">loi</code></td>
<td>
<p>Lambda indexes of interest, if null all lambda values will be used.</p>
</td></tr>
<tr><td><code id="cv_plots_+3A_...">...</code></td>
<td>
<p>Additional parameters sent to plot function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a cross validation plot
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>

<hr>
<h2 id='cv.rq.group.pen'>Old cross validation function for group penalty</h2><span id='topic+cv.rq.group.pen'></span>

<h3>Description</h3>

<p>This function is no longer exported. Recommend using rq.group.pen.cv() instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.rq.group.pen(
  x,
  y,
  groups,
  tau = 0.5,
  lambda = NULL,
  penalty = "SCAD",
  intercept = TRUE,
  criteria = "CV",
  cvFunc = "check",
  nfolds = 10,
  foldid = NULL,
  nlambda = 100,
  eps = 1e-04,
  init.lambda = 1,
  alg = "huber",
  penGroups = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.rq.group.pen_+3A_x">x</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_y">y</code></td>
<td>
<p>Vector of responses.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_groups">groups</code></td>
<td>
<p>Vector of groups.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_tau">tau</code></td>
<td>
<p>Quantile being modeled.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_lambda">lambda</code></td>
<td>
<p>Vector of lambdas. Default is for lambdas to be automatically generated.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_penalty">penalty</code></td>
<td>
<p>Type of penalty: &quot;LASSO&quot;, &quot;SCAD&quot; or &quot;MCP&quot;.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_intercept">intercept</code></td>
<td>
<p>Whether model should include an intercept. Constant does not need to be included in &quot;x&quot;.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_criteria">criteria</code></td>
<td>
<p>How models will be evaluated. Either cross-validation &quot;CV&quot;, BIC &quot;BIC&quot; or large P BIC &quot;PBIC&quot;.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_cvfunc">cvFunc</code></td>
<td>
<p>If cross-validation is used how errors are evaluated. Check function &quot;check&quot;, &quot;SqErr&quot; (Squared Error) or &quot;AE&quot; (Absolute Value).</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_nfolds">nfolds</code></td>
<td>
<p>K for K-folds cross-validation.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_foldid">foldid</code></td>
<td>
<p>Group id for cross-validation. Function will randomly generate groups if not specified.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_nlambda">nlambda</code></td>
<td>
<p>Number of lambdas for which models are fit.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_eps">eps</code></td>
<td>
<p>Multiple of lambda max for Smallest lambda used.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_init.lambda">init.lambda</code></td>
<td>
<p>Initial lambda used to find the maximum lambda. Not needed if lambda values are set.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_alg">alg</code></td>
<td>
<p>Algorithm used for fit. Only &quot;LP&quot;, &quot;QICD&quot; is no longer available.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_pengroups">penGroups</code></td>
<td>
<p>Specify which groups will be penalized. Default is to penalize all groups.</p>
</td></tr>
<tr><td><code id="cv.rq.group.pen_+3A_...">...</code></td>
<td>
<p>Additional arguments to be sent to rq.group.fit</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the following: 
</p>

<dl>
<dt>beta</dt><dd><p> Matrix of coefficients for different values of lambda</p>
</dd>
<dt>residuals</dt><dd><p> Matrix of residuals for different values of lambda.</p>
</dd>
<dt>rho</dt><dd><p>Vector of rho, unpenalized portion of the objective function, for different values of lambda.</p>
</dd>
<dt>cv</dt><dd><p> Data frame with &quot;lambda&quot; and second column is the evaluation based on the criteria selected.</p>
</dd>
<dt>lambda.min</dt><dd><p> Lambda which provides the smallest statistic for the selected criteria.</p>
</dd>
<dt>penalty</dt><dd><p> Penalty selected.</p>
</dd> 
<dt>intercept</dt><dd><p>Whether intercept was included in model.</p>
</dd>
<dt>groups</dt><dd><p>Group structure for penalty function.</p>
</dd>
</dl>



<h3>References</h3>


<ul>
<li><p> Yuan, M. and Lin, Y. (2006). Model selection and estimation in regression with grouped variables. <em>J. R. Statist. Soc. B</em>, <b>68</b>, 49-67.
</p>
</li>
<li><p> Peng, B. and Wang, L. (2015). An Iterative Coordinate Descent Algorithm for High-Dimensional Nonconvex Penalized Quantile Regression. <em>Journal of Computational and Graphical Statistics</em>, <b>24</b>, 676-694.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- matrix(rnorm(800),nrow=100)
y &lt;- 1 + x[,1] - 3*x[,5] + rnorm(100)
cv_model &lt;- cv.rq.group.pen(x,y,groups=c(rep(1,4),rep(2,4)),criteria="BIC")

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.cv.rq.group.pen'>Cross validation plot for cv.rq.group.pen object</h2><span id='topic+plot.cv.rq.group.pen'></span>

<h3>Description</h3>

<p>Cross validation plot for cv.rq.group.pen object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.rq.group.pen'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.rq.group.pen_+3A_x">x</code></td>
<td>
<p>A cv.rq.group.pen object</p>
</td></tr>
<tr><td><code id="plot.cv.rq.group.pen_+3A_...">...</code></td>
<td>
<p>Additional parameters for plot function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cross validation plot.
</p>

<hr>
<h2 id='plot.rq.pen.seq'>Plot of coefficients of rq.pen.seq object as a function of lambda</h2><span id='topic+plot.rq.pen.seq'></span>

<h3>Description</h3>

<p>Plot of coefficients of rq.pen.seq object as a function of lambda
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq'
plot(
  x,
  vars = NULL,
  logLambda = TRUE,
  tau = NULL,
  a = NULL,
  lambda = NULL,
  modelsIndex = NULL,
  lambdaIndex = NULL,
  main = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rq.pen.seq_+3A_x">x</code></td>
<td>
<p>rq.pen.seq object</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_vars">vars</code></td>
<td>
<p>Variables of interest</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_loglambda">logLambda</code></td>
<td>
<p>Whether lambda should be reported on the log scale</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_tau">tau</code></td>
<td>
<p>Quantiles of interest</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_a">a</code></td>
<td>
<p>Tuning parameter a values of interest.</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_lambda">lambda</code></td>
<td>
<p>Values of lambda of interest.</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_modelsindex">modelsIndex</code></td>
<td>
<p>Specific models of interest.</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_lambdaindex">lambdaIndex</code></td>
<td>
<p>Specific lambda values of interest.</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_main">main</code></td>
<td>
<p>Title of the plots. Can be a vector of multiple titles if multiple plots are created.</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq_+3A_...">...</code></td>
<td>
<p>Additional arguments sent to plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns plot(s) of coefficients as they change with lambda.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(rnorm(100*8,sd=10),ncol=8)
y &lt;- 1 + x[,1] + 3*x[,3] - x[,8] + rt(100,3)
m1 &lt;- rq.pen(x,y,tau=c(.1,.5,.7),penalty="SCAD",a=c(3,4))
plot(m1,a=3,tau=.7)
plot(m1)
mlist &lt;- list()
for(i in 1:6){
mlist[[i]] &lt;- paste("Plot",i)
}
plot(m1,main=mlist)
</code></pre>

<hr>
<h2 id='plot.rq.pen.seq.cv'>Plots cross validation results from a rq.pen.seq.cv object</h2><span id='topic+plot.rq.pen.seq.cv'></span>

<h3>Description</h3>

<p>Provides plots of cross-validation results by lambda. If septau is set to TRUE then plots the cross-validation results for each quantile. If septau is set to FALSE
then provides one plot for cross-validation results across all quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq.cv'
plot(
  x,
  septau = ifelse(x$fit$penalty != "gq", TRUE, FALSE),
  tau = NULL,
  logLambda = TRUE,
  main = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rq.pen.seq.cv_+3A_x">x</code></td>
<td>
<p>The rq.pen.seq.cv object</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq.cv_+3A_septau">septau</code></td>
<td>
<p>If set to true then optimal tuning parameters are selected seperately for each quantile and there will be a different plot for each quanitle.</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq.cv_+3A_tau">tau</code></td>
<td>
<p>Quantiles of interest.</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq.cv_+3A_loglambda">logLambda</code></td>
<td>
<p>Whether log(lambda) is used for the x-axis</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq.cv_+3A_main">main</code></td>
<td>
<p>Title to the plot</p>
</td></tr>
<tr><td><code id="plot.rq.pen.seq.cv_+3A_...">...</code></td>
<td>
<p>Additional parameters sent to the plot function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plots of the cross validation results by lambda.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(rnorm(100*8,sd=1),ncol=8)
y &lt;- 1 + x[,1] + 3*x[,3] - x[,8] + rt(100,3)
m1 &lt;- rq.pen.cv(x,y,tau=c(.1,.3,.7))
plot(m1)
plot(m1,septau=FALSE)
</code></pre>

<hr>
<h2 id='predict.cv.rq.pen'>Prediction for a cv.rq.pen object</h2><span id='topic+predict.cv.rq.pen'></span>

<h3>Description</h3>

<p>This function is no longer exported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.rq.pen'
predict(object, newx, lambda = "lambda.min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.rq.pen_+3A_object">object</code></td>
<td>
<p>A cv.rq.pen object.</p>
</td></tr>
<tr><td><code id="predict.cv.rq.pen_+3A_newx">newx</code></td>
<td>
<p>Matrix of new data to make predictions with.</p>
</td></tr>
<tr><td><code id="predict.cv.rq.pen_+3A_lambda">lambda</code></td>
<td>
<p>Lambda value used, default is the value associated with the minimum cross validation result.</p>
</td></tr>
<tr><td><code id="predict.cv.rq.pen_+3A_...">...</code></td>
<td>
<p>Additional parameters that are currenlty ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predictions.
</p>

<hr>
<h2 id='predict.qic.select'>Predictions from a qic.select object</h2><span id='topic+predict.qic.select'></span>

<h3>Description</h3>

<p>Predictions from a qic.select object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qic.select'
predict(object, newx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.qic.select_+3A_object">object</code></td>
<td>
<p>qic.select object</p>
</td></tr>
<tr><td><code id="predict.qic.select_+3A_newx">newx</code></td>
<td>
<p>Data matrix to make predictions from.</p>
</td></tr>
<tr><td><code id="predict.qic.select_+3A_...">...</code></td>
<td>
<p>optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predicted values.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
m1 &lt;- rq.pen(x,y,tau=c(.25,.75))
q1 &lt;- qic.select(m1)
newx &lt;- matrix(runif(80),ncol=8)
preds &lt;- predict(q1,newx)
</code></pre>

<hr>
<h2 id='predict.rq.pen'>Prediction for a rq.pen object</h2><span id='topic+predict.rq.pen'></span>

<h3>Description</h3>

<p>This function is no longer exported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen'
predict(object, newx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.rq.pen_+3A_object">object</code></td>
<td>
<p>An rq.pen object.</p>
</td></tr>
<tr><td><code id="predict.rq.pen_+3A_newx">newx</code></td>
<td>
<p>Matrix of new data to make predictions with.</p>
</td></tr>
<tr><td><code id="predict.rq.pen_+3A_...">...</code></td>
<td>
<p>Additional parameters that are currenlty ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predictions.
</p>

<hr>
<h2 id='predict.rq.pen.seq'>Predictions from rq.pen.seq object</h2><span id='topic+predict.rq.pen.seq'></span>

<h3>Description</h3>

<p>Predictions from rq.pen.seq object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq'
predict(
  object,
  newx,
  tau = NULL,
  a = NULL,
  lambda = NULL,
  modelsIndex = NULL,
  lambdaIndex = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.rq.pen.seq_+3A_object">object</code></td>
<td>
<p>rq.pen.seq object</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq_+3A_newx">newx</code></td>
<td>
<p>Matrix of predictors</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq_+3A_tau">tau</code></td>
<td>
<p>Quantile of interest. Default is NULL, which will return all quantiles. Should not be specified if modelsIndex is used.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq_+3A_a">a</code></td>
<td>
<p>Tuning parameter of a. Default is NULL, which returns coefficients for all values of a. Should not be specified if modelsIndex is used.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq_+3A_lambda">lambda</code></td>
<td>
<p>Tuning parameter of <code class="reqn">\lambda</code>. Default is NULL, which returns coefficients for all values of <code class="reqn">\lambda</code>.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq_+3A_modelsindex">modelsIndex</code></td>
<td>
<p>Index of the models for which coefficients should be returned. Does not need to be specified if tau or a are specified.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq_+3A_lambdaindex">lambdaIndex</code></td>
<td>
<p>Index of the lambda values for which coefficients should be returned. Does not need to be specified if lambda is specified.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to coef.rq.pen.seq()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions for each tau and a combination
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
m1 &lt;- rq.pen(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.75),lambda=c(.1,.05,.01))
newx &lt;- matrix(runif(80),ncol=8)
allCoefs &lt;- predict(m1,newx)
targetCoefs &lt;- predict(m1,newx,tau=.25,a=.5,lambda=.1)
idxApproach &lt;- predict(m1,newx,modelsIndex=2)
bothIdxApproach &lt;- predict(m1,newx,modelsIndex=2,lambdaIndex=1)
</code></pre>

<hr>
<h2 id='predict.rq.pen.seq.cv'>Predictions from rq.pen.seq.cv object</h2><span id='topic+predict.rq.pen.seq.cv'></span>

<h3>Description</h3>

<p>Predictions from rq.pen.seq.cv object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq.cv'
predict(
  object,
  newx,
  tau = NULL,
  septau = ifelse(object$fit$penalty != "gq", TRUE, FALSE),
  cvmin = TRUE,
  useDefaults = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.rq.pen.seq.cv_+3A_object">object</code></td>
<td>
<p>rq.pen.seq.cv object</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq.cv_+3A_newx">newx</code></td>
<td>
<p>Matrix of predictors</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq.cv_+3A_tau">tau</code></td>
<td>
<p>Quantile of interest. Default is NULL, which will return all quantiles. Should not be specified if modelsIndex is used.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq.cv_+3A_septau">septau</code></td>
<td>
<p>Whether tuning parameter should be optimized separately for each quantile.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq.cv_+3A_cvmin">cvmin</code></td>
<td>
<p>If TRUE then minimum error is used, if FALSE then one standard error rule is used.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq.cv_+3A_usedefaults">useDefaults</code></td>
<td>
<p>Whether the default results are used. Set to FALSE if you you want to specify specific models and lambda values.</p>
</td></tr>
<tr><td><code id="predict.rq.pen.seq.cv_+3A_...">...</code></td>
<td>
<p>Additional parameters sent to coef.rq.pen.seq.cv().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions for each tau and a combination
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(runif(1600),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(200)
m1 &lt;- rq.pen.cv(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.75),lambda=c(.1,.05,.01))
newx &lt;- matrix(runif(80),ncol=8)
cvpreds &lt;- predict(m1,newx)
</code></pre>

<hr>
<h2 id='print.qic.select'>Print a qic.select object</h2><span id='topic+print.qic.select'></span>

<h3>Description</h3>

<p>Print a qic.select object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qic.select'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.qic.select_+3A_x">x</code></td>
<td>
<p>qic.select object</p>
</td></tr>
<tr><td><code id="print.qic.select_+3A_...">...</code></td>
<td>
<p>optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints the coefficients of the qic.select object
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>

<hr>
<h2 id='print.rq.pen.seq'>Print a rq.pen.seq object</h2><span id='topic+print.rq.pen.seq'></span>

<h3>Description</h3>

<p>Print a rq.pen.seq object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.rq.pen.seq_+3A_x">x</code></td>
<td>
<p>rq.pen.seq object</p>
</td></tr>
<tr><td><code id="print.rq.pen.seq_+3A_...">...</code></td>
<td>
<p>optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If only one model, prints a data.frame of the number of nonzero coefficients and lambda. Otherwise prints information about the quantiles being modeled and choices for a.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>

<hr>
<h2 id='print.rq.pen.seq.cv'>Prints a rq.pen.seq.cv object</h2><span id='topic+print.rq.pen.seq.cv'></span>

<h3>Description</h3>

<p>Prints a rq.pen.seq.cv object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq.cv'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.rq.pen.seq.cv_+3A_x">x</code></td>
<td>
<p>A req.pen.seq.cv object.</p>
</td></tr>
<tr><td><code id="print.rq.pen.seq.cv_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Print of btr and gtr from a rq.pen.seq.cv object. If only one quantile is modeled then only btr is returned.
</p>

<hr>
<h2 id='qic'>Calculate information criterion for penalized quantile regression models. Currently not exported.</h2><span id='topic+qic'></span>

<h3>Description</h3>

<p>Calculate information criterion for penalized quantile regression models. Currently not exported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qic(model, n, method = c("BIC", "AIC", "PBIC"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qic_+3A_model">model</code></td>
<td>
<p>model from a rq.pen.seq() object</p>
</td></tr>
<tr><td><code id="qic_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="qic_+3A_method">method</code></td>
<td>
<p>Choice of BIC, AIC or PBIC, a large p BIC.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Let <code class="reqn">\hat{\beta}</code> be the coefficient vectors for the estimated model. Function returns the value 
</p>
<p style="text-align: center;"><code class="reqn">\log(\sum_{i=1}^n w_i \rho_\tau(y_i-x_i^\top\hat{\beta})) + d*b/(2n),</code>
</p>
<p> where d is the number of nonzero coefficients and b depends on the method used. For AIC <code class="reqn">b=2</code>,
for BIC <code class="reqn">b=log(n)</code> and for PBIC <code class="reqn">d=log(n)*log(p)</code> where p is the dimension of <code class="reqn">\hat{\beta}</code>. The values of w_i default to one and are set using weights when fitting the models. Returns this value for each coefficient vector in the model, so one
for every value of <code class="reqn">\lambda</code>.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>References</h3>

<p>Lee ER, Noh H, Park BU (2014).
&ldquo;Model Selection via Bayesian Information Criterion for Quantile Regression Models.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>109</b>(505), 216&ndash;229.
ISSN 01621459.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1)
x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
m1 &lt;- rq.pen(x,y,tau=c(.25,.75))
# returns the IC values for tau=.25
qic(m1$models[[1]],m1$n) 
# returns the IC values for tau=.75
qic(m1$models[[2]],m1$n)

## End(Not run) 
</code></pre>

<hr>
<h2 id='qic.select'>Select tuning parameters using IC</h2><span id='topic+qic.select'></span>

<h3>Description</h3>

<p>Selects tuning parameter <code class="reqn">\lambda</code> and a according to information criterion of choice. For a given <code class="reqn">\hat{\beta}</code> the information criterion is calculated
as
</p>
<p style="text-align: center;"><code class="reqn">\log(\sum_{i=1}^n w_i \rho_\tau(y_i-x_i^\top\hat{\beta})) + d*b/(2n),</code>
</p>
<p> where d is the number of nonzero coefficients and b depends on the method used. For AIC <code class="reqn">b=2</code>,
for BIC <code class="reqn">b=log(n)</code> and for PBIC <code class="reqn">d=log(n)*log(p)</code> where p is the dimension of <code class="reqn">\hat{\beta}</code>.
If septau set to FALSE then calculations are made across the quantiles. Let <code class="reqn">\hat{\beta}^q</code> be the coefficient vector for the qth quantile of Q quantiles. In addition let <code class="reqn">d_q</code> and <code class="reqn">b_q</code> 
be d and b values from the qth quantile model. Note, for all of these we are assuming eqn and a are the same. Then the summary across all quantiles is 
</p>
<p style="text-align: center;"><code class="reqn">\sum_{q=1}^Q w_q[ \log(\sum_{i=1}^n m_i \rho_\tau(y_i-x_i^\top\hat{\beta}^q)) + d_q*b_q/(2n)],</code>
</p>

<p>where <code class="reqn">w_q</code> is the weight assigned for the qth quantile model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qic.select(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qic.select_+3A_obj">obj</code></td>
<td>
<p>A rq.pen.seq or rq.pen.seq.cv object.</p>
</td></tr>
<tr><td><code id="qic.select_+3A_...">...</code></td>
<td>
<p>Additional arguments see qic.select.rq.pen.seq() or qic.select.rq.pen.seq.cv() for more information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a qic.select object.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>References</h3>

<p>Lee ER, Noh H, Park BU (2014).
&ldquo;Model Selection via Bayesian Information Criterion for Quantile Regression Models.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>109</b>(505), 216&ndash;229.
ISSN 01621459.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
m1 &lt;- rq.pen(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.75))
qic.select(m1)
</code></pre>

<hr>
<h2 id='qic.select.rq.pen.seq'>Select tuning parameters using IC</h2><span id='topic+qic.select.rq.pen.seq'></span>

<h3>Description</h3>

<p>Selects tuning parameter <code class="reqn">\lambda</code> and a according to information criterion of choice. For a given <code class="reqn">\hat{\beta}</code> the information criterion is calculated
as
</p>
<p style="text-align: center;"><code class="reqn">\log(\sum_{i=1}^n w_i \rho_\tau(y_i-x_i^\top\hat{\beta})) + d*b/(2n),</code>
</p>
<p> where d is the number of nonzero coefficients and b depends on the method used. For AIC <code class="reqn">b=2</code>,
for BIC <code class="reqn">b=log(n)</code> and for PBIC <code class="reqn">d=log(n)*log(p)</code> where p is the dimension of <code class="reqn">\hat{\beta}</code>.
If septau set to FALSE then calculations are made across the quantiles. Let <code class="reqn">\hat{\beta}^q</code> be the coefficient vector for the qth quantile of Q quantiles. In addition let <code class="reqn">d_q</code> and <code class="reqn">b_q</code> 
be d and b values from the qth quantile model. Note, for all of these we are assuming eqn and a are the same. Then the summary across all quantiles is 
</p>
<p style="text-align: center;"><code class="reqn">\sum_{q=1}^Q w_q[ \log(\sum_{i=1}^n m_i \rho_\tau(y_i-x_i^\top\hat{\beta}^q)) + d_q*b_q/(2n)],</code>
</p>

<p>where <code class="reqn">w_q</code> is the weight assigned for the qth quantile model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq'
qic.select(
  obj,
  method = c("BIC", "AIC", "PBIC"),
  septau = ifelse(obj$penalty != "gq", TRUE, FALSE),
  tauWeights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qic.select.rq.pen.seq_+3A_obj">obj</code></td>
<td>
<p>A rq.pen.seq or rq.pen.seq.cv object.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq_+3A_method">method</code></td>
<td>
<p>Choice of BIC, AIC or PBIC, a large p BIC.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq_+3A_septau">septau</code></td>
<td>
<p>If optimal values of <code class="reqn">\lambda</code> and a can vary with <code class="reqn">\tau</code>. Default is TRUE.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq_+3A_tauweights">tauWeights</code></td>
<td>
<p>Weights for each quantile. Useful if you set septau to FALSE but want different weights for the different quantiles. If not specified default is to have <code class="reqn">w_q=1</code> for all quantiles.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>coefficients</dt><dd><p>Coefficients of the selected models.</p>
</dd>
<dt>ic</dt><dd><p>Information criterion values for all considered models.</p>
</dd>
<dt>modelsInfo</dt><dd><p>Model info for the selected models related to the original object obj.</p>
</dd>
<dt>gic</dt><dd><p>Information criterion summarized across all quantiles. Only returned if septau set to FALSE</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>References</h3>

<p>Lee ER, Noh H, Park BU (2014).
&ldquo;Model Selection via Bayesian Information Criterion for Quantile Regression Models.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>109</b>(505), 216&ndash;229.
ISSN 01621459.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
m1 &lt;- rq.pen(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.75))
qic.select(m1)
</code></pre>

<hr>
<h2 id='qic.select.rq.pen.seq.cv'>Select tuning parameters using IC</h2><span id='topic+qic.select.rq.pen.seq.cv'></span>

<h3>Description</h3>

<p>Selects tuning parameter <code class="reqn">\lambda</code> and a according to information criterion of choice. For a given <code class="reqn">\hat{\beta}</code> the information criterion is calculated
as
</p>
<p style="text-align: center;"><code class="reqn">\log(\sum_{i=1}^n w_i \rho_\tau(y_i-x_i^\top\hat{\beta})) + d*b/(2n),</code>
</p>
<p> where d is the number of nonzero coefficients and b depends on the method used. For AIC <code class="reqn">b=2</code>,
for BIC <code class="reqn">b=log(n)</code> and for PBIC <code class="reqn">d=log(n)*log(p)</code> where p is the dimension of <code class="reqn">\hat{\beta}</code>.
If septau set to FALSE then calculations are made across the quantiles. Let <code class="reqn">\hat{\beta}^q</code> be the coefficient vector for the qth quantile of Q quantiles. In addition let <code class="reqn">d_q</code> and <code class="reqn">b_q</code> 
be d and b values from the qth quantile model. Note, for all of these we are assuming eqn and a are the same. Then the summary across all quantiles is 
</p>
<p style="text-align: center;"><code class="reqn">\sum_{q=1}^Q w_q[ \log(\sum_{i=1}^n  \rho_\tau(y_i-x_i^\top\hat{\beta}^q)) + d_q*b_q/(2n)],</code>
</p>

<p>where <code class="reqn">w_q</code> is the weight assigned for the qth quantile model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.pen.seq.cv'
qic.select(
  obj,
  method = c("BIC", "AIC", "PBIC"),
  septau = ifelse(obj$fit$penalty != "gq", TRUE, FALSE),
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qic.select.rq.pen.seq.cv_+3A_obj">obj</code></td>
<td>
<p>A rq.pen.seq.cv object.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq.cv_+3A_method">method</code></td>
<td>
<p>Choice of BIC, AIC or PBIC, a large p BIC.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq.cv_+3A_septau">septau</code></td>
<td>
<p>If optimal values of <code class="reqn">\lambda</code> and a can vary with <code class="reqn">\tau</code>. Default is TRUE.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq.cv_+3A_weights">weights</code></td>
<td>
<p>Weights for each quantile. Useful if you set septau to FALSE but want different weights for the different quantiles. If not specified default is to have <code class="reqn">w_q=1</code> for all quantiles.</p>
</td></tr>
<tr><td><code id="qic.select.rq.pen.seq.cv_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>coefficients</dt><dd><p>Coefficients of the selected models.</p>
</dd>
<dt>ic</dt><dd><p>Information criterion values for all considered models.</p>
</dd>
<dt>modelsInfo</dt><dd><p>Model info for the selected models related to the original object obj.</p>
</dd>
<dt>gic</dt><dd><p>Information criterion summarized across all quantiles. Only returned if septau set to FALSE</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>References</h3>

<p>Lee ER, Noh H, Park BU (2014).
&ldquo;Model Selection via Bayesian Information Criterion for Quantile Regression Models.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>109</b>(505), 216&ndash;229.
ISSN 01621459.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
m1 &lt;- rq.pen.cv(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.75))
qic.select(m1)
</code></pre>

<hr>
<h2 id='rq.gq.pen'>Title Quantile regression estimation and consistent variable selection across multiple quantiles</h2><span id='topic+rq.gq.pen'></span>

<h3>Description</h3>

<p>Uses the group lasso penalty across the quantiles to provide consistent selection across all, K, modeled quantiles. Let <code class="reqn">\beta^q</code>
be the coefficients for the kth quantiles, <code class="reqn">\beta_j</code> be the Q-dimensional vector of the jth coefficient for each quantile, and
<code class="reqn">\rho_\tau(u)</code> is the quantile loss function. The method minimizes
</p>
<p style="text-align: center;"><code class="reqn">\sum_{q=1}^Q \frac{1}{n} \sum_{i=1}^n m_i \rho_\tau(y_i-x_i^\top\beta^q) + \lambda \sum_{j=1}^p ||\beta_j||_{2,w}  .</code>
</p>

<p>Uses a Huber approximation in the fitting of model, as presented in Sherwood and Li (2022). Where,
</p>
<p style="text-align: center;"><code class="reqn">||\beta_j||_{2,w} = \sqrt{\sum_{k=1}^K w_kv_j\beta_{kj}^2},</code>
</p>
<p> where <code class="reqn">w_k</code> is a quantile weight 
that can be specified by <code>tau.penalty.factor</code>, <code class="reqn">v_j</code> is a predictor weight that can be assigned by <code>penalty.factor</code>, 
and <code class="reqn">m_i</code> is an observation weight that can be set by <code>weights</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.gq.pen(
  x,
  y,
  tau,
  lambda = NULL,
  nlambda = 100,
  eps = ifelse(nrow(x) &lt; ncol(x), 0.01, 0.001),
  weights = NULL,
  penalty.factor = NULL,
  scalex = TRUE,
  tau.penalty.factor = NULL,
  gmma = 0.2,
  max.iter = 200,
  lambda.discard = TRUE,
  converge.eps = 1e-04,
  beta0 = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.gq.pen_+3A_x">x</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_y">y</code></td>
<td>
<p>a univariate response variable</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_tau">tau</code></td>
<td>
<p>a sequence of quantiles to be modeled, must be of at least length 3.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_lambda">lambda</code></td>
<td>
<p>shrinkage parameter. Default is NULL, and the algorithm provides a solution path.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_nlambda">nlambda</code></td>
<td>
<p>Number of lambda values to be considered.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_eps">eps</code></td>
<td>
<p>If not pre-specified the lambda vector will be from lambda_max to lambda_max times eps</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_weights">weights</code></td>
<td>
<p>observation weights. Default is NULL, which means equal weights.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>weights for the shrinkage parameter for each covariate. Default is equal weight.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_scalex">scalex</code></td>
<td>
<p>Whether x should be scaled before fitting the model. Coefficients are returned on the original scale.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_tau.penalty.factor">tau.penalty.factor</code></td>
<td>
<p>weights for different quantiles. Default is equal weight.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_gmma">gmma</code></td>
<td>
<p>tuning parameter for the Huber loss</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iteration. Default is 200.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_lambda.discard">lambda.discard</code></td>
<td>
<p>Default is TRUE, meaning that the solution path stops if the relative deviance changes sufficiently small. It usually happens near the end of solution path. However, the program returns at least 70 models along the solution path.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_converge.eps">converge.eps</code></td>
<td>
<p>The epsilon level convergence. Default is 1e-4.</p>
</td></tr>
<tr><td><code id="rq.gq.pen_+3A_beta0">beta0</code></td>
<td>
<p>Initial estimates. Default is NULL, and the algorithm starts with the intercepts being the quantiles of response variable and other coefficients being zeros.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An rq.pen.seq object. 
</p>

<dl>
<dt>models: </dt><dd><p> A list of each model fit for each tau and a combination.</p>
</dd>
<dt>n:</dt><dd><p> Sample size.</p>
</dd>
<dt>p:</dt><dd><p> Number of predictors.</p>
</dd>
<dt>alg:</dt><dd><p> Algorithm used. Options are &quot;huber&quot; or any method implemented in rq(), such as &quot;br&quot;. </p>
</dd>
<dt>tau:</dt><dd><p> Quantiles modeled.</p>
</dd>
<dt>a:</dt><dd><p> Tuning parameters a used.</p>
</dd>
<dt>modelsInfo:</dt><dd><p> Information about the quantile and a value for each model.</p>
</dd>
<dt>lambda:</dt><dd><p> Lambda values used for all models. If a model has fewer coefficients than lambda, say k. Then it used the first k values of lambda. Setting lambda.discard to TRUE will gurantee all values use the same lambdas, but may increase computational time noticeably and for little gain.</p>
</dd>
<dt>penalty:</dt><dd><p> Penalty used.</p>
</dd>
<dt>call:</dt><dd><p> Original call.</p>
</dd>
</dl>

<p>Each model in the models list has the following values. 
</p>

<dl>
<dt>coefficients:</dt><dd><p> Coefficients for each value of lambda.</p>
</dd>
<dt>rho:</dt><dd><p> The unpenalized objective function for each value of lambda.</p>
</dd>
<dt>PenRho:</dt><dd><p> The penalized objective function for each value of lambda.</p>
</dd>
<dt>nzero:</dt><dd><p> The number of nonzero coefficients for each value of lambda.</p>
</dd>
<dt>tau:</dt><dd><p> Quantile of the model.</p>
</dd>
<dt>a:</dt><dd><p> Value of a for the penalized loss function.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Shaobo Li and Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>References</h3>

<p>Wang M, Kang X, Liang J, Wang K, Wu Y (2024).
&ldquo;Heteroscedasticity identification and variable selection via multiple quantile regression.&rdquo;
<em>Journal of Statistical Computation and Simulation</em>, <b>94</b>(2), 297-314.
</p>
<p>Sherwood B, Li S (2022).
&ldquo;Quantile regression feature selection and estimation with grouped variables using Huber approximation.&rdquo;
<em>Statistics and Computing</em>, <b>32</b>(5), 75.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
n&lt;- 200
p&lt;- 10
X&lt;- matrix(rnorm(n*p),n,p)
y&lt;- -2+X[,1]+0.5*X[,2]-X[,3]-0.5*X[,7]+X[,8]-0.2*X[,9]+rt(n,2)
taus &lt;- seq(0.1, 0.9, 0.2)
fit&lt;- rq.gq.pen(X, y, taus)
#use IC to select best model, see rq.gq.pen.cv() for a cross-validation approach
qfit &lt;- qic.select(fit)

## End(Not run)
</code></pre>

<hr>
<h2 id='rq.gq.pen.cv'>Title Cross validation for consistent variable selection across multiple quantiles.</h2><span id='topic+rq.gq.pen.cv'></span>

<h3>Description</h3>

<p>Title Cross validation for consistent variable selection across multiple quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.gq.pen.cv(
  x = NULL,
  y = NULL,
  tau = NULL,
  lambda = NULL,
  nfolds = 10,
  cvFunc = c("rq", "se"),
  tauWeights = NULL,
  foldid = NULL,
  printProgress = FALSE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.gq.pen.cv_+3A_x">x</code></td>
<td>
<p>covariate matrix. Not needed if <code>model_obj</code> is supplied.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_y">y</code></td>
<td>
<p>univariate response. Not needed if <code>model_obj</code> is supplied.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_tau">tau</code></td>
<td>
<p>a sequence of tau to be modeled, must be at least of length 3.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_lambda">lambda</code></td>
<td>
<p>Values of <code class="reqn">\lambda</code>. Default will automatically select the <code class="reqn">\lambda</code> values.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_cvfunc">cvFunc</code></td>
<td>
<p>loss function to be evaluated for cross-validation. Supported loss functions include quantile (&quot;rq&quot;) and squared loss(&quot;se&quot;). Default is the quantile loss.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_tauweights">tauWeights</code></td>
<td>
<p>weights for different quantiles in calculating the cv error. Default is equal weight.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_foldid">foldid</code></td>
<td>
<p>indices of pre-split testing obervations</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_printprogress">printProgress</code></td>
<td>
<p>If set to TRUE prints which partition is being worked on.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_weights">weights</code></td>
<td>
<p>Weights for the quantile loss objective function.</p>
</td></tr>
<tr><td><code id="rq.gq.pen.cv_+3A_...">...</code></td>
<td>
<p>other arguments for <code>rq.gq.pen.cv</code> sent to <code>rq.gq.pen</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">y_{b,i}</code> and <code class="reqn">x_{b,i}</code> index the observations in 
fold b. Let <code class="reqn">\hat{\beta}_{\tau,a,\lambda}^{-b}</code> be the estimator for a given quantile and tuning parameters that did not use the bth fold. Let <code class="reqn">n_b</code> be the number of observations in fold
b. Then the cross validation error for fold b is 
</p>
<p style="text-align: center;"><code class="reqn">\mbox{CV}(b,\tau) = \sum_{q=1}^Q \frac{1}{n_b} \sum_{i=1}^{n_b} m_{b,i}v_q \rho_\tau(y_{b,i}-x_{b,i}^\top\hat{\beta}_{\tau_q,a,\lambda}^{-b}).</code>
</p>

<p>Where, <code class="reqn">m_{b,i}</code> is the weight for the ith observation in fold b and <code class="reqn">v_q</code> is a quantile specific weight. Note that <code class="reqn">\rho_\tau()</code> can be replaced squared error loss. Provides results about how the average of the cross-validation error changes with <code class="reqn">\lambda</code>. Uses a
Huber approximation in the fitting of model, as presented in Sherwood and Li (2022).
</p>


<h3>Value</h3>

<p>An rq.pen.seq.cv object. 
</p>

<dl>
<dt>cverr:</dt><dd><p> Matrix of cvSummary function, default is average, cross-validation error for each model, tau and a combination, and lambda.</p>
</dd>
<dt>cvse:</dt><dd><p> Matrix of the standard error of cverr foreach model, tau and a combination, and lambda.</p>
</dd>
<dt>fit:</dt><dd><p> The rq.pen.seq object fit to the full data.</p>
</dd>
<dt>btr:</dt><dd><p> Let blank, unlike rq.pen.seq.cv() or rq.group.pen.cv(), because optmizes the quantiles individually does not make sense with this penalty.</p>
</dd>
<dt>gtr:</dt><dd><p> A data.table for the combination of a and lambda that minimize the cross validation error across all tau.</p>
</dd>
<dt>gcve:</dt><dd><p> Group, across all quantiles, cross-validation error results for each value of a and lambda.</p>
</dd>
<dt>call:</dt><dd><p> Original call to the function.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Shaobo Li and Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>References</h3>

<p>Wang M, Kang X, Liang J, Wang K, Wu Y (2024).
&ldquo;Heteroscedasticity identification and variable selection via multiple quantile regression.&rdquo;
<em>Journal of Statistical Computation and Simulation</em>, <b>94</b>(2), 297-314.
</p>
<p>Sherwood B, Li S (2022).
&ldquo;Quantile regression feature selection and estimation with grouped variables using Huber approximation.&rdquo;
<em>Statistics and Computing</em>, <b>32</b>(5), 75.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
n&lt;- 200
p&lt;- 10
X&lt;- matrix(rnorm(n*p),n,p)
y&lt;- -2+X[,1]+0.5*X[,2]-X[,3]-0.5*X[,7]+X[,8]-0.2*X[,9]+rt(n,2)
taus &lt;- seq(0.1, 0.9, 0.2)
cvfit&lt;- rq.gq.pen.cv(x=X, y=y, tau=taus)
cvCoefs &lt;- coefficients(cvfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='rq.group.fit'>Estimates a quantile regression model with a group penalized objective function.</h2><span id='topic+rq.group.fit'></span>

<h3>Description</h3>

<p>Warning: function is no longer exported. Recommend using rq.group.pen() instead. 
Similar to cv.rq.pen function, but uses group penalty. Group penalties use the L1 norm instead of L2 for computational convenience. 
As a result of this the group lasso penalty is the same as the typical lasso penalty and thus you should only use a SCAD or MCP penalty. 
Only the SCAD and MCP penalties incorporate the group structure into the penalty. The group lasso penalty is implemented because it is 
needed for the SCAD and MCP algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.group.fit(
  x,
  y,
  groups,
  tau = 0.5,
  lambda,
  intercept = TRUE,
  penalty = "SCAD",
  alg = "LP",
  a = 3.7,
  penGroups = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.group.fit_+3A_x">x</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_y">y</code></td>
<td>
<p>Vector of responses.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_groups">groups</code></td>
<td>
<p>Vector of group assignments.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_tau">tau</code></td>
<td>
<p>Single quantile to be modeled.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_lambda">lambda</code></td>
<td>
<p>Single value or seperate value for each group.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_intercept">intercept</code></td>
<td>
<p>Whether intercept should be included in the model or not.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_penalty">penalty</code></td>
<td>
<p>Type of penalty used: SCAD, MCP or LASSO.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_alg">alg</code></td>
<td>
<p>Only LP, QICD no longer available</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_a">a</code></td>
<td>
<p>Additional tuning parameter for SCAD and MCP.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_pengroups">penGroups</code></td>
<td>
<p>Vector of TRUE and FALSE entries for each group determing if they should be penalized. Default is TRUE for all groups.</p>
</td></tr>
<tr><td><code id="rq.group.fit_+3A_...">...</code></td>
<td>
<p>Additional arguments sent to rq.group.lin.prog()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the following:    
</p>
  
<dl>
<dt>coefficients</dt><dd><p>Coefficients of the model.</p>
</dd>
<dt>residuals</dt><dd><p> Residuals from the fitted model.</p>
</dd>
<dt>rho</dt><dd><p>Unpenalized portion of the objective function.</p>
</dd>
<dt>tau</dt><dd><p> Quantile being modeled.</p>
</dd>
<dt>n</dt><dd><p>Sample size.</p>
</dd>
<dt>intercept</dt><dd><p>Whether intercept was included in model.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a> and Adam Maidman
</p>


<h3>References</h3>


<ul>
<li><p> Yuan, M. and Lin, Y. (2006). Model selection and estimation in regression with grouped variables. <em>J. R. Statist. Soc. B</em>, <b>68</b>, 49-67.
</p>
</li>
<li><p> Peng, B. and Wang, L. (2015). An Iterative Coordinate Descent Algorithm for High-Dimensional Nonconvex Penalized Quantile Regression. <em>Journal of Computational and Graphical Statistics</em>, <b>24</b>, 676-694.
</p>
</li></ul>


<hr>
<h2 id='rq.group.pen'>Fits quantile regression models using a group penalized objective function.</h2><span id='topic+rq.group.pen'></span>

<h3>Description</h3>

<p>Let the predictors be divided into G groups with G corresponding vectors of coefficients, <code class="reqn">\beta_1,\ldots,\beta_G</code>. 
Let <code class="reqn">\rho_\tau(a) = a[\tau-I(a&lt;0)]</code>. Fits quantile regression models for Q quantiles by minimizing the penalized objective function of
</p>
<p style="text-align: center;"><code class="reqn">\sum_{q=1}^Q \frac{1}{n} \sum_{i=1}^n m_i \rho_\tau(y_i-x_i^\top\beta^q) + \sum_{q=1}^Q  \sum_{g=1}^G P(||\beta^q_g||_k,w_q*v_j*\lambda,a).</code>
</p>

<p>Where <code class="reqn">w_q</code> and <code class="reqn">v_j</code> are designated by penalty.factor and tau.penalty.factor respectively and <code class="reqn">m_i</code> can be set by weights. The value of <code class="reqn">k</code> is chosen by <code>norm</code>.
Value of P() depends on the penalty. Briefly, but see references or vignette for more details,
</p>

<dl>
<dt>Group LASSO (gLASSO)</dt><dd><p><code class="reqn">P(||\beta||_k,\lambda,a)=\lambda||\beta||_k</code></p>
</dd>
<dt>Group SCAD</dt><dd><p><code class="reqn">P(||\beta||_k,\lambda,a)=SCAD(||\beta||_k,\lambda,a)</code></p>
</dd>
<dt>Group MCP</dt><dd><p><code class="reqn">P(||\beta||_k,\lambda,a)=MCP(||\beta||_k,\lambda,a)</code></p>
</dd>
<dt>Group Adaptive LASSO</dt><dd><p><code class="reqn">P(||\beta||_k,\lambda,a)=\frac{\lambda ||\beta||_k}{|\beta_0|^a}</code></p>
</dd>
</dl>

<p>Note if <code class="reqn">k=1</code> and the group lasso penalty is used then this is identical to the regular lasso and thus function will stop and
suggest that you use rq.pen() instead. For Adaptive LASSO the values of <code class="reqn">\beta_0</code> come from a Ridge solution with the same value of <code class="reqn">\lambda</code>.
If the Huber algorithm is used than <code class="reqn">\rho_\tau(y_i-x_i^\top\beta)</code> is replaced by a Huber-type approximation. Specifically, it is replaced by <code class="reqn">h^\tau_\gamma(y_i-x_i^\top\beta)/2</code> where 
</p>
<p style="text-align: center;"><code class="reqn">h^\tau_\gamma(a) = a^2/(2\gamma)I(|a| \leq \gamma) + (|a|-\gamma/2)I(|a|&gt;\gamma)+(2\tau-1)a.</code>
</p>

<p>Where if <code class="reqn">\tau=.5</code>, we get the usual Huber loss function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.group.pen(
  x,
  y,
  tau = 0.5,
  groups = 1:ncol(x),
  penalty = c("gLASSO", "gAdLASSO", "gSCAD", "gMCP"),
  lambda = NULL,
  nlambda = 100,
  eps = ifelse(nrow(x) &lt; ncol(x), 0.05, 0.01),
  alg = c("huber", "br"),
  a = NULL,
  norm = 2,
  group.pen.factor = NULL,
  tau.penalty.factor = rep(1, length(tau)),
  scalex = TRUE,
  coef.cutoff = 1e-08,
  max.iter = 500,
  converge.eps = 1e-04,
  gamma = IQR(y)/10,
  lambda.discard = TRUE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.group.pen_+3A_x">x</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_y">y</code></td>
<td>
<p>Vector of responses.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_tau">tau</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_groups">groups</code></td>
<td>
<p>Vector of group assignments for predictors.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_penalty">penalty</code></td>
<td>
<p>Penalty used, choices are group lasso (&quot;gLASSO&quot;), group adaptive lasso (&quot;gAdLASSO&quot;), group SCAD (&quot;gSCAD&quot;) and group MCP (&quot;gMCP&quot;)</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_lambda">lambda</code></td>
<td>
<p>Vector of lambda tuning parameters. Will be autmoatically generated if it is not set.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda tuning parameters.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_eps">eps</code></td>
<td>
<p>The value to be multiplied by the largest lambda value to determine the smallest lambda value.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_alg">alg</code></td>
<td>
<p>Algorithm used. Choices are Huber approximation (&quot;huber&quot;) or linear programming (&quot;lp&quot;).</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_a">a</code></td>
<td>
<p>The additional tuning parameter for adaptive lasso, SCAD and MCP.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_norm">norm</code></td>
<td>
<p>Whether a L1 or L2 norm is used for the grouped coefficients.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_group.pen.factor">group.pen.factor</code></td>
<td>
<p>Penalty factor for each group. Default is 1 for all groups if norm=1 and square root of group size if norm=2.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_tau.penalty.factor">tau.penalty.factor</code></td>
<td>
<p>Penalty factor for each quantile.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_scalex">scalex</code></td>
<td>
<p>Whether X should be centered and scaled so that the columns have mean zero and standard deviation of one. If set to TRUE, the coefficients will be returned to the original scale of the data.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_coef.cutoff">coef.cutoff</code></td>
<td>
<p>Coefficient cutoff where any value below this number is set to zero. Useful for the lp algorithm, which are prone to finding almost, but not quite, sparse solutions.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_max.iter">max.iter</code></td>
<td>
<p>The maximum number of iterations for the algorithm.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_converge.eps">converge.eps</code></td>
<td>
<p>The convergence criteria for the algorithms.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_gamma">gamma</code></td>
<td>
<p>The tuning parameter for the Huber loss.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_lambda.discard">lambda.discard</code></td>
<td>
<p>Whether lambdas should be discarded if for small values of lambda there is very little change in the solutions.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_weights">weights</code></td>
<td>
<p>Weights used in the quanitle loss objective function.</p>
</td></tr>
<tr><td><code id="rq.group.pen_+3A_...">...</code></td>
<td>
<p>Additional parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An rq.pen.seq object. 
</p>

<dl>
<dt>models</dt><dd><p>A list of each model fit for each tau and a combination.</p>
</dd>
<dt>n</dt><dd><p>Sample size.</p>
</dd>
<dt>p</dt><dd><p>Number of predictors.</p>
</dd>
<dt>alg</dt><dd><p>Algorithm used.</p>
</dd>
<dt>tau</dt><dd><p>Quantiles modeled.</p>
</dd>
<dt>penalty</dt><dd><p>Penalty used.</p>
</dd>
<dt>a</dt><dd><p>Tuning parameters a used.</p>
</dd>
<dt>lambda</dt><dd><p>Lambda values used for all models. If a model has fewer coefficients than lambda, say k. Then it used the first k values of lambda. Setting lambda.discard to TRUE will gurantee all values use the same lambdas, but may increase computational time noticeably and for little gain.</p>
</dd>
<dt>modelsInfo</dt><dd><p>Information about the quantile and a value for each model.</p>
</dd>
<dt>call</dt><dd><p>Original call.</p>
</dd>
</dl>

<p>Each model in the models list has the following values. 
</p>

<dl>
<dt>coefficients</dt><dd><p>Coefficients for each value of lambda.</p>
</dd>
<dt>rho</dt><dd><p>The unpenalized objective function for each value of lambda.</p>
</dd>
<dt>PenRho</dt><dd><p>The penalized objective function for each value of lambda.</p>
</dd>
<dt>nzero</dt><dd><p>The number of nonzero coefficients for each value of lambda.</p>
</dd>
<dt>tau</dt><dd><p>Quantile of the model.</p>
</dd>
<dt>a</dt><dd><p>Value of a for the penalized loss function.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>, Shaobo Li <a href="mailto:shaobo.li@ku.edu">shaobo.li@ku.edu</a> and Adam Maidman
</p>


<h3>References</h3>

<p>Peng B, Wang L (2015).
&ldquo;An iterative coordinate descent algorithm for high-dimensional nonconvex penalized quantile regression.&rdquo;
<em>J. Comput. Graph. Statist.</em>, <b>24</b>(3), 676-694.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
set.seed(1)
x &lt;- matrix(rnorm(200*8,sd=1),ncol=8)
y &lt;- 1 + x[,1] + 3*x[,3] - x[,8] + rt(200,3)
g &lt;- c(1,1,1,2,2,2,3,3)
tvals &lt;- c(.25,.75)
r1 &lt;- rq.group.pen(x,y,groups=g)
r5 &lt;- rq.group.pen(x,y,groups=g,tau=tvals)
#Linear programming approach with group SCAD penalty and L1-norm
m2 &lt;- rq.group.pen(x,y,groups=g,alg="br",penalty="gSCAD",norm=1,a=seq(3,4))
# No penalty for the first group
m3 &lt;- rq.group.pen(x,y,groups=g,group.pen.factor=c(0,rep(1,2)))
# Smaller penalty for the median
m4 &lt;- rq.group.pen(x,y,groups=g,tau=c(.25,.5,.75),tau.penalty.factor=c(1,.25,1))

## End(Not run)
</code></pre>

<hr>
<h2 id='rq.group.pen.cv'>Performs cross validation for a group penalty.</h2><span id='topic+rq.group.pen.cv'></span>

<h3>Description</h3>

<p>Performs cross validation for a group penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.group.pen.cv(
  x,
  y,
  tau = 0.5,
  groups = 1:ncol(x),
  lambda = NULL,
  a = NULL,
  cvFunc = NULL,
  nfolds = 10,
  foldid = NULL,
  groupError = TRUE,
  cvSummary = mean,
  tauWeights = rep(1, length(tau)),
  printProgress = FALSE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.group.pen.cv_+3A_x">x</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_y">y</code></td>
<td>
<p>Vector of responses.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_tau">tau</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_groups">groups</code></td>
<td>
<p>Vector of group assignments for the predictors.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_lambda">lambda</code></td>
<td>
<p>Vector of lambda values, if set to NULL they will be generated automatically.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_a">a</code></td>
<td>
<p>Vector of the other tuning parameter values.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_cvfunc">cvFunc</code></td>
<td>
<p>Function used for cross-validation error, default is quantile loss.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds used for cross validation.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_foldid">foldid</code></td>
<td>
<p>Fold assignments, if not set this will be randomly created.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_grouperror">groupError</code></td>
<td>
<p>If errors are to be reported as a group or as the average for each fold.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_cvsummary">cvSummary</code></td>
<td>
<p>The</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_tauweights">tauWeights</code></td>
<td>
<p>Weights for the tau penalty only used in group tau results (gtr).</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_printprogress">printProgress</code></td>
<td>
<p>If set to TRUE will print which fold the process is working on.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_weights">weights</code></td>
<td>
<p>Weights for the quantile loss function. Used in both model fitting and cross-validation.</p>
</td></tr>
<tr><td><code id="rq.group.pen.cv_+3A_...">...</code></td>
<td>
<p>Additional parameters that will be sent to rq.group.pen().</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two cross validation results are returned. One that considers the best combination of a and lambda for each quantile. The second considers the best combination of the tuning 
parameters for all quantiles. Let <code class="reqn">y_{b,i}</code>, <code class="reqn">x_{b,i}</code>, and <code class="reqn">m_{b,i}</code> index the response, predictors, and weights of observations in 
fold b. Let <code class="reqn">\hat{\beta}_{\tau,a,\lambda}^{-b}</code> be the estimator for a given quantile and tuning parameters that did not use the bth fold. Let <code class="reqn">n_b</code> be the number of observations in fold
b. Then the cross validation error for fold b is 
</p>
<p style="text-align: center;"><code class="reqn">\mbox{CV}(b,\tau) = \frac{1}{n_b} \sum_{i=1}^{n_b} m_{b,i} \rho_\tau(y_{b,i}-x_{b,i}^\top\hat{\beta}_{\tau,a,\lambda}^{-b}).</code>
</p>

<p>Note that <code class="reqn">\rho_\tau()</code> can be replaced by a different function by setting the cvFunc parameter. The function returns two different cross-validation summaries. The first is btr, by tau results. 
It provides the values of <code>lambda</code> and <code>a</code> that minimize the average, or whatever function is used for <code>cvSummary</code>, of <code class="reqn">\mbox{CV}(b)</code>. In addition it provides the 
sparsest solution that is within one standard error of the minimum results. 
</p>
<p>The other approach is the group tau results, gtr. Consider the case of estimating Q quantiles of <code class="reqn">\tau_1,\ldots,\tau_Q</code> with quantile (tauWeights) of <code class="reqn">v_q</code>. The gtr returns the values of <code>lambda</code> and <code>a</code> that minimizes the average, or again whatever function is used for <code>cvSummary</code>, of 
</p>
<p style="text-align: center;"><code class="reqn">\sum_{q=1}^Q v_q\mbox{CV}(b,\tau_q).</code>
</p>
<p> If only one quantile is modeled then the gtr results can be ignored as they provide the same minimum solution as btr.
</p>


<h3>Value</h3>

<p>An rq.pen.seq.cv object. 
</p>

<dl>
<dt>cverr</dt><dd><p>Matrix of cvSummary function, default is average, cross-validation error for each model, tau and a combination, and lambda.</p>
</dd>
<dt>cvse</dt><dd><p>Matrix of the standard error of cverr foreach model, tau and a combination, and lambda.</p>
</dd>
<dt>fit</dt><dd><p>The rq.pen.seq object fit to the full data.</p>
</dd>
<dt>btr</dt><dd><p>A data.table of the values of a and lambda that are best as determined by the minimum cross validation error and the one standard error rule, which fixes a. In btr the values of lambda and a are selected seperately for each quantile.</p>
</dd>
<dt>gtr</dt><dd><p>A data.table for the combination of a and lambda that minimize the cross validation error across all tau.</p>
</dd>
<dt>gcve</dt><dd><p>Group, across all quantiles, cross-validation error results for each value of a and lambda.</p>
</dd>
<dt>call</dt><dd><p>Original call to the function.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a> and Shaobo Li <a href="mailto:shaobo.li@ku.edu">shaobo.li@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- matrix(rnorm(100*8,sd=1),ncol=8)
y &lt;- 1 + x[,1] + 3*x[,3] - x[,8] + rt(100,3)
g &lt;- c(1,1,1,1,2,2,3,3)
tvals &lt;- c(.25,.75)
## Not run: 
m1 &lt;- rq.group.pen.cv(x,y,tau=c(.1,.3,.7),groups=g)
m2 &lt;- rq.group.pen.cv(x,y,penalty="gAdLASSO",tau=c(.1,.3,.7),groups=g)
m3 &lt;- rq.group.pen.cv(x,y,penalty="gSCAD",tau=c(.1,.3,.7),a=c(3,4,5),groups=g)
m4 &lt;- rq.group.pen.cv(x,y,penalty="gMCP",tau=c(.1,.3,.7),a=c(3,4,5),groups=g)

## End(Not run)
</code></pre>

<hr>
<h2 id='rq.lasso.fit'>Estimates a quantile regression model with a lasso penalized quanitle loss function.</h2><span id='topic+rq.lasso.fit'></span>

<h3>Description</h3>

<p>Fits a quantile regression model with the LASSO penalty. Uses the augmented data approach similar to the proposal in Sherwood and Wang (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.lasso.fit(
  x,
  y,
  tau = 0.5,
  lambda = NULL,
  weights = NULL,
  intercept = TRUE,
  coef.cutoff = 1e-08,
  method = "br",
  penVars = NULL,
  scalex = TRUE,
  lambda.discard = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.lasso.fit_+3A_x">x</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_y">y</code></td>
<td>
<p>Vector of responses.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_tau">tau</code></td>
<td>
<p>Quantile of interest.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_lambda">lambda</code></td>
<td>
<p>Tuning parameter.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_weights">weights</code></td>
<td>
<p>Weights for the objective function.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_intercept">intercept</code></td>
<td>
<p>Whether model should include an intercept. Constant does not need to be included in &quot;x&quot;.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_coef.cutoff">coef.cutoff</code></td>
<td>
<p>Coefficients below this value will be set to zero.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_method">method</code></td>
<td>
<p>Use method &quot;br&quot; or &quot;fn&quot; as outlined in quantreg package. We have found &quot;br&quot; to be more stable for penalized regression problems.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_penvars">penVars</code></td>
<td>
<p>Variables that should be penalized. With default value of NULL all variables are penalized.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_scalex">scalex</code></td>
<td>
<p>If set to true the predictors will be scaled to have mean zero and standard deviation of one before fitting the model. The output returned will be on the original scale of the data.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_lambda.discard">lambda.discard</code></td>
<td>
<p>If TRUE lambda sequence will stop early if for small values of lambda the estimates do not change much.</p>
</td></tr>
<tr><td><code id="rq.lasso.fit_+3A_...">...</code></td>
<td>
<p>Additional items to be sent to rq. Note this will have to be done carefully as rq is run on the augmented data to account for penalization and could provide strange results if this is not taken into account.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the following:
</p>

<dl>
<dt>coefficients</dt><dd><p> Coefficients from the penalized model.</p>
</dd> 
<dt>PenRho</dt><dd><p> Penalized objective function value.</p>
</dd>
<dt>residuals</dt><dd><p> Residuals from the model.</p>
</dd>
<dt>rho</dt><dd><p> Objective function evaluation without the penalty.</p>
</dd>
<dt>tau</dt><dd><p> Conditional quantile being modeled.</p>
</dd>
<dt>n</dt><dd><p> Sample size.</p>
</dd>  
</dl>



<h3>References</h3>


<ul>
<li><p> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. <em>Journal of the Royal Statistical Society. Series B</em>, <b>58</b>, 267&ndash;288.
</p>
</li>
<li><p> Wu, Y. and Liu, Y. (2009). Variable selection in quantile regression. <em>Statistica Sinica</em>, <b>19</b>, 801&ndash;817.  
</p>
</li>
<li><p> Sherwood, B. and Wang, L. (2016) Partially linear additive quantile regression in ultra-high dimension. <em>Annals of Statistics</em> <b>44</b>, 288&ndash;317. 
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- matrix(rnorm(800),nrow=100)
y &lt;- 1 + x[,1] - 3*x[,5] + rnorm(100)
lassoModel &lt;- rq.lasso.fit(x,y,lambda=.1)

## End(Not run)
</code></pre>

<hr>
<h2 id='rq.nc.fit'>Non-convex penalized quantile regression</h2><span id='topic+rq.nc.fit'></span>

<h3>Description</h3>

<p>Warning: this function is no longer exported. Produces penalized quantile regression models for a range of lambdas and penalty of choice. If lambda is unselected than an iterative algorithm is used to 
find a maximum lambda such that the penalty is large enough to produce an intercept only model. Then range of lambdas goes from the maximum lambda found to &quot;eps&quot; on the 
log scale. Local linear approximation approach used by Wang, Wu and Li to extend LLA as proposed by Zou and Li (2008) to the quantile regression setting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.nc.fit(
  x,
  y,
  tau = 0.5,
  lambda = NULL,
  weights = NULL,
  intercept = TRUE,
  penalty = "SCAD",
  a = 3.7,
  iterations = 1,
  converge_criteria = 1e-06,
  alg = "LP",
  penVars = NULL,
  internal = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.nc.fit_+3A_x">x</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_y">y</code></td>
<td>
<p>Vector of response values.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_tau">tau</code></td>
<td>
<p>Conditional quantile being modelled.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_lambda">lambda</code></td>
<td>
<p>Vector of lambdas. Default is for lambdas to be automatically generated.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_weights">weights</code></td>
<td>
<p>Weights for the objective function.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_intercept">intercept</code></td>
<td>
<p>Whether model should include an intercept. Constant does not need to be included in &quot;x&quot;.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_penalty">penalty</code></td>
<td>
<p>Type of penalty: &quot;LASSO&quot;, &quot;SCAD&quot; or &quot;MCP&quot;.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_a">a</code></td>
<td>
<p>Additional tuning parameter for SCAD and MCP</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations to be done for iterative LLA algorithm.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_converge_criteria">converge_criteria</code></td>
<td>
<p>Difference in betas from iteration process that would satisfy convergence.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_alg">alg</code></td>
<td>
<p>Defaults for small p to linear programming (LP), see Wang, Wu and Li (2012) for details. QICD is no longer available.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_penvars">penVars</code></td>
<td>
<p>Variables that should be penalized. With default value of NULL all variables are penalized.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_internal">internal</code></td>
<td>
<p>Whether call to this function has been made internally or not.</p>
</td></tr>
<tr><td><code id="rq.nc.fit_+3A_...">...</code></td>
<td>
<p>Additional items to be sent to rq.lasso.fit.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the following:
</p>

<dl>
<dt>coefficients</dt><dd><p>Coefficients from the penalized model.</p>
</dd>
<dt>PenRho</dt><dd><p>Penalized objective function value.</p>
</dd>
<dt>residuals</dt><dd><p> Residuals from the model.</p>
</dd>
<dt>rho</dt><dd><p> Objective function evaluation without the penalty.</p>
</dd>
<dt>coefficients</dt><dd><p> Coefficients from the penalized model.</p>
</dd> 
<dt>tau</dt><dd><p> Conditional quantile being modeled.</p>
</dd>
<dt>n</dt><dd><p> Sample size.</p>
</dd>  
<dt>penalty</dt><dd><p> Penalty used, SCAD or MCP.</p>
</dd> 
<dt>penalty</dt><dd><p>Penalty selected.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a> and Adam Maidman.
</p>


<h3>References</h3>


<ul>
<li><p> Wang, L., Wu, Y. and Li, R. (2012). Quantile regression of analyzing heterogeneity in ultra-high dimension. <em>J. Am. Statist. Ass</em>, <b>107</b>, 214&ndash;222.
</p>
</li>
<li><p> Wu, Y. and Liu, Y. (2009). Variable selection in quantile regression. <em>Statistica Sinica</em>, <b>19</b>, 801&ndash;817.
</p>
</li>
<li><p> Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models. <em>Ann. Statist.</em>, <b>36</b>, 1509&ndash;1533.
</p>
</li>
<li><p> Peng, B. and Wang, L. (2015). An iterative coordinate-descent algorithm for high-dimensional nonconvex penalized quantile regression. <em>J. Comp. Graph.</em>, <b>24</b>, 676&ndash;694.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- matrix(rnorm(800),nrow=100)
y &lt;- 1 + x[,1] - 3*x[,5] + rnorm(100)
scadModel &lt;- rq.nc.fit(x,y,lambda=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='rq.pen'>Fit a quantile regression model using a penalized quantile loss function.</h2><span id='topic+rq.pen'></span>

<h3>Description</h3>

<p>Let q index the Q quantiles of interest. Let <code class="reqn">\rho_\tau(a) = a[\tau-I(a&lt;0)]</code>. Fits quantile regression models by minimizing the penalized objective function of
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \sum_{q=1}^Q \sum_{i=1}^n m_i \rho_\tau(y_i-x_i^\top\beta^q) + \sum_{q=1}^Q  \sum_{j=1}^p P(\beta^q_p,w_q*v_j*\lambda,a).</code>
</p>

<p>Where <code class="reqn">w_q</code> and <code class="reqn">v_j</code> are designated by penalty.factor and tau.penalty.factor respectively, and <code class="reqn">m_i</code> is designated by weights. Value of <code class="reqn">P()</code> depends on the penalty. See references or vignette for more details,
</p>

<dl>
<dt>LASSO:</dt><dd> <p><code class="reqn">P(\beta,\lambda,a)=\lambda|\beta|</code></p>
</dd>
<dt>SCAD:</dt><dd> <p><code class="reqn">P(\beta,\lambda,a)=SCAD(\beta,\lambda,a)</code></p>
</dd>
<dt>MCP:</dt><dd> <p><code class="reqn">P(\beta,\lambda,a)=MCP(\beta,\lambda,a)</code></p>
</dd>
<dt>Ridge:</dt><dd> <p><code class="reqn">P(\beta,\lambda,a)=\lambda\beta^2</code></p>
</dd>
<dt>Elastic Net:</dt><dd> <p><code class="reqn">P(\beta,\lambda,a)=a*\lambda|\beta|+(1-a)*\lambda*\beta^2</code></p>
</dd>
<dt>Adaptive LASSO:</dt><dd> <p><code class="reqn">P(\beta,\lambda,a)=\frac{\lambda |\beta|}{|\beta_0|^a}</code></p>
</dd>
</dl>

<p>For Adaptive LASSO the values of <code class="reqn">\beta_0</code> come from a Ridge solution with the same value of <code class="reqn">\lambda</code>. Three different algorithms are implemented
</p>

<dl>
<dt>huber:</dt><dd><p> Uses a Huber approximation of the quantile loss function. See Yi and Huang 2017 for more details.</p>
</dd>
<dt>br:</dt><dd><p> Solution is found by re-formulating the problem so it can be solved with the rq() function from quantreg with the br algorithm.</p>
</dd> 
</dl>

<p>The huber algorithm offers substantial speed advantages without much, if any, loss in performance. However, it should be noted that it solves an approximation of the quantile loss function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.pen(
  x,
  y,
  tau = 0.5,
  lambda = NULL,
  penalty = c("LASSO", "Ridge", "ENet", "aLASSO", "SCAD", "MCP"),
  a = NULL,
  nlambda = 100,
  eps = ifelse(nrow(x) &lt; ncol(x), 0.05, 0.01),
  penalty.factor = rep(1, ncol(x)),
  alg = c("huber", "br", "QICD", "fn"),
  scalex = TRUE,
  tau.penalty.factor = rep(1, length(tau)),
  coef.cutoff = 1e-08,
  max.iter = 10000,
  converge.eps = 1e-07,
  lambda.discard = TRUE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.pen_+3A_x">x</code></td>
<td>
<p>matrix of predictors</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_y">y</code></td>
<td>
<p>vector of responses</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_tau">tau</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_lambda">lambda</code></td>
<td>
<p>vector of lambda, if not set will be generated automatically</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_penalty">penalty</code></td>
<td>
<p>choice of penalty</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_a">a</code></td>
<td>
<p>Additional tuning parameter, not used for lasso or ridge penalties. However, will be set to the elastic net values of 1 and 0 respectively. Defaults are ENet(0), aLASSO(1), SCAD(3.7) and MCP(3).</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_nlambda">nlambda</code></td>
<td>
<p>number of lambda, ignored if lambda is set</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_eps">eps</code></td>
<td>
<p>If not pre-specified the lambda vector will be from lambda_max to lambda_max times eps</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>penalty factor for the predictors</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_alg">alg</code></td>
<td>
<p>Algorithm used.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_scalex">scalex</code></td>
<td>
<p>Whether x should be scaled before fitting the model. Coefficients are returned on the original scale.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_tau.penalty.factor">tau.penalty.factor</code></td>
<td>
<p>A penalty factor for each quantile.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_coef.cutoff">coef.cutoff</code></td>
<td>
<p>Some of the linear programs will provide very small, but not sparse solutions. Estimates below this number will be set to zero. This is ignored if a non-linear programming algorithm is used.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations of non-linear programming algorithms.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_converge.eps">converge.eps</code></td>
<td>
<p>Convergence threshold for non-linear programming algorithms.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_lambda.discard">lambda.discard</code></td>
<td>
<p>Algorithm may stop for small values of lambda if the coefficient estimates are not changing drastically. One example of this is it is possible for the LLA weights of the non-convex functions to all become zero and smaller values of lambda are extremely likely to produce the same zero weights.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_weights">weights</code></td>
<td>
<p>Weights for the quantile objective function.</p>
</td></tr>
<tr><td><code id="rq.pen_+3A_...">...</code></td>
<td>
<p>Extra parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An rq.pen.seq object. 
</p>

<dl>
<dt>models: </dt><dd><p> A list of each model fit for each tau and a combination.</p>
</dd>
<dt>n:</dt><dd><p> Sample size.</p>
</dd>
<dt>p:</dt><dd><p> Number of predictors.</p>
</dd>
<dt>alg:</dt><dd><p> Algorithm used. Options are &quot;huber&quot; or any method implemented in rq(), such as &quot;br&quot;. </p>
</dd>
<dt>tau:</dt><dd><p> Quantiles modeled.</p>
</dd>
<dt>a:</dt><dd><p> Tuning parameters a used.</p>
</dd>
<dt>modelsInfo:</dt><dd><p> Information about the quantile and a value for each model.</p>
</dd>
<dt>lambda:</dt><dd><p> Lambda values used for all models. If a model has fewer coefficients than lambda, say k. Then it used the first k values of lambda. Setting lambda.discard to TRUE will gurantee all values use the same lambdas, but may increase computational time noticeably and for little gain.</p>
</dd>
<dt>penalty:</dt><dd><p> Penalty used.</p>
</dd>
<dt>call:</dt><dd><p> Original call.</p>
</dd>
</dl>

<p>Each model in the models list has the following values. 
</p>

<dl>
<dt>coefficients:</dt><dd><p> Coefficients for each value of lambda.</p>
</dd>
<dt>rho:</dt><dd><p> The unpenalized objective function for each value of lambda.</p>
</dd>
<dt>PenRho:</dt><dd><p> The penalized objective function for each value of lambda.</p>
</dd>
<dt>nzero:</dt><dd><p> The number of nonzero coefficients for each value of lambda.</p>
</dd>
<dt>tau:</dt><dd><p> Quantile of the model.</p>
</dd>
<dt>a:</dt><dd><p> Value of a for the penalized loss function.</p>
</dd>
</dl>

<p>If the Huber algorithm is used than <code class="reqn">\rho_\tau(y_i-x_i^\top\beta)</code> is replaced by a Huber-type approximation. Specifically, it is replaced by <code class="reqn">h^\tau_\gamma(y_i-x_i^\top\beta)/2</code> where 
</p>
<p style="text-align: center;"><code class="reqn">h^\tau_\gamma(a) = a^2/(2\gamma)I(|a| \leq \gamma) + (|a|-\gamma/2)I(|a|&gt;\gamma)+(2\tau-1)a.</code>
</p>

<p>Where if <code class="reqn">\tau=.5</code>, we get the usual Huber loss function. The Huber implementation calls the package hqreg which implements the methods of Yi and Huang (2017) 
for Huber loss with elastic net penalties. For non-elastic net penalties the LLA algorithm of Zou and Li (2008) is used to approximate those loss functions
with a lasso penalty with different weights for each predictor.
</p>


<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>, Shaobo Li, and Adam Maidman
</p>


<h3>References</h3>

<p>Zou H, Li R (2008).
&ldquo;One-step sparse estimates in nonconcave penalized likelihood models.&rdquo;
<em>Ann. Statist.</em>, <b>36</b>(4), 1509-1533.
</p>
<p>Yi C, Huang J (2017).
&ldquo;Semismooth Newton Coordinate Descent Algorithm for Elastic-Net Penalized Huber Loss Regression and Quantile Regression.&rdquo;
<em>J. Comput. Graph. Statist.</em>, <b>26</b>(3), 547-557.
</p>
<p>Belloni A, Chernozhukov V (2011).
&ldquo;L1-Penalized quantile regression in high-dimensional sparse models.&rdquo;
<em>Ann. Statist.</em>, <b>39</b>(1), 82-130.
</p>
<p>Peng B, Wang L (2015).
&ldquo;An iterative coordinate descent algorithm for high-dimensional nonconvex penalized quantile regression.&rdquo;
<em>J. Comput. Graph. Statist.</em>, <b>24</b>(3), 676-694.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
p &lt;- 8
x &lt;- matrix(runif(n*p),ncol=p)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(n)
r1 &lt;- rq.pen(x,y) #Lasso fit for median
# Lasso for multiple quantiles
r2 &lt;- rq.pen(x,y,tau=c(.25,.5,.75))
# Elastic net fit for multiple quantiles, which must use Huber algorithm
r3 &lt;- rq.pen(x,y,penalty="ENet",a=c(0,.5,1),alg="huber")
# First variable is not penalized
r4 &lt;- rq.pen(x,y,penalty.factor=c(0,rep(1,7)))
tvals &lt;- c(.1,.2,.3,.4,.5)
#Similar to penalty proposed by Belloni and Chernouzhukov. 
#To be exact you would divide the tau.penalty.factor by n. 
r5 &lt;- rq.pen(x,y,tau=tvals, tau.penalty.factor=sqrt(tvals*(1-tvals)))
</code></pre>

<hr>
<h2 id='rq.pen.cv'>Does k-folds cross validation for rq.pen. If multiple values of a are specified then does a grid based search for best value of <code class="reqn">\lambda</code> and a.</h2><span id='topic+rq.pen.cv'></span>

<h3>Description</h3>

<p>Does k-folds cross validation for rq.pen. If multiple values of a are specified then does a grid based search for best value of <code class="reqn">\lambda</code> and a.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.pen.cv(
  x,
  y,
  tau = 0.5,
  lambda = NULL,
  penalty = c("LASSO", "Ridge", "ENet", "aLASSO", "SCAD", "MCP"),
  a = NULL,
  cvFunc = NULL,
  nfolds = 10,
  foldid = NULL,
  nlambda = 100,
  groupError = TRUE,
  cvSummary = mean,
  tauWeights = rep(1, length(tau)),
  printProgress = FALSE,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.pen.cv_+3A_x">x</code></td>
<td>
<p>Matrix of predictors.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_y">y</code></td>
<td>
<p>Vector of responses.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_tau">tau</code></td>
<td>
<p>Quantiles to be modeled.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_lambda">lambda</code></td>
<td>
<p>Values of <code class="reqn">\lambda</code>. Default will automatically select the <code class="reqn">\lambda</code> values.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_penalty">penalty</code></td>
<td>
<p>Choice of penalty between LASSO, Ridge, Elastic Net (ENet), Adaptive Lasso (aLASSO), SCAD and MCP.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_a">a</code></td>
<td>
<p>Tuning parameter of a. LASSO and Ridge has no second tuning parameter, but for notation is set to 1 or 0 respectively, the values for elastic net. Defaults are Ridge ()</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_cvfunc">cvFunc</code></td>
<td>
<p>Loss function for cross-validation. Defaults to quantile loss, but user can specify their own function.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_foldid">foldid</code></td>
<td>
<p>Ids for folds. If set will override nfolds.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_nlambda">nlambda</code></td>
<td>
<p>Number of lambda, ignored if lambda is set.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_grouperror">groupError</code></td>
<td>
<p>If set to false then reported error is the sum of all errors, not the sum of error for each fold.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_cvsummary">cvSummary</code></td>
<td>
<p>Function to summarize the errors across the folds, default is mean. User can specify another function, such as median.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_tauweights">tauWeights</code></td>
<td>
<p>Weights for the different tau models. Only used in group tau results (gtr).</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_printprogress">printProgress</code></td>
<td>
<p>If set to TRUE prints which partition is being worked on.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_weights">weights</code></td>
<td>
<p>Weights for the quantile loss objective function.</p>
</td></tr>
<tr><td><code id="rq.pen.cv_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to rq.pen()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two cross validation results are returned. One that considers the best combination of a and lambda for each quantile. The second considers the best combination of the tuning 
parameters for all quantiles. Let <code class="reqn">y_{b,i}</code>, <code class="reqn">x_{b,i}</code>, and <code class="reqn">m_{b,i}</code> index the response, predictors, and weights of observations in 
fold b. Let <code class="reqn">\hat{\beta}_{\tau,a,\lambda}^{-b}</code> be the estimator for a given quantile and tuning parameters that did not use the bth fold. Let <code class="reqn">n_b</code> be the number of observations in fold
b. Then the cross validation error for fold b is 
</p>
<p style="text-align: center;"><code class="reqn">\mbox{CV}(b,\tau) = \frac{1}{n_b} \sum_{i=1}^{n_b} m_{b,i} \rho_\tau(y_{b,i}-x_{b,i}^\top\hat{\beta}_{\tau,a,\lambda}^{-b}).</code>
</p>

<p>Note that <code class="reqn">\rho_\tau()</code> can be replaced by a different function by setting the cvFunc parameter. The function returns two different cross-validation summaries. The first is btr, by tau results. 
It provides the values of <code>lambda</code> and <code>a</code> that minimize the average, or whatever function is used for <code>cvSummary</code>, of <code class="reqn">\mbox{CV}(b)</code>. In addition it provides the 
sparsest solution that is within one standard error of the minimum results. 
</p>
<p>The other approach is the group tau results, gtr. Consider the case of estimating Q quantiles of <code class="reqn">\tau_1,\ldots,\tau_Q</code> with quantile (tauWeights) of <code class="reqn">v_q</code>. The gtr returns the values of <code>lambda</code> and <code>a</code> that minimizes the average, or again whatever function is used for <code>cvSummary</code>, of 
</p>
<p style="text-align: center;"><code class="reqn">\sum_{q=1}^Q v_q\mbox{CV}(b,\tau_q).</code>
</p>
<p> If only one quantile is modeled then the gtr results can be ignored as they provide the same minimum solution as btr.
</p>


<h3>Value</h3>

<p>An rq.pen.seq.cv object. 
</p>

<dl>
<dt>cverr:</dt><dd><p> Matrix of cvSummary function, default is average, cross-validation error for each model, tau and a combination, and lambda.</p>
</dd>
<dt>cvse:</dt><dd><p> Matrix of the standard error of cverr foreach model, tau and a combination, and lambda.</p>
</dd>
<dt>fit:</dt><dd><p> The rq.pen.seq object fit to the full data.</p>
</dd>
<dt>btr:</dt><dd><p> A data.table of the values of a and lambda that are best as determined by the minimum cross validation error and the one standard error rule, which fixes a. In btr the values of lambda and a are selected seperately for each quantile.</p>
</dd>
<dt>gtr:</dt><dd><p> A data.table for the combination of a and lambda that minimize the cross validation error across all tau.</p>
</dd>
<dt>gcve:</dt><dd><p> Group, across all quantiles, cross-validation error results for each value of a and lambda.</p>
</dd>
<dt>call:</dt><dd><p> Original call to the function.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ben Sherwood, <a href="mailto:ben.sherwood@ku.edu">ben.sherwood@ku.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- matrix(runif(800),ncol=8)
y &lt;- 1 + x[,1] + x[,8] + (1+.5*x[,3])*rnorm(100)
r1 &lt;- rq.pen.cv(x,y) #lasso fit for median
# Elastic net fit for multiple values of a and tau
r2 &lt;- rq.pen.cv(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.5,.75)) 
#same as above but more weight given to median when calculating group cross validation error. 
r3 &lt;- rq.pen.cv(x,y,penalty="ENet",a=c(0,.5,1),tau=c(.25,.5,.75),tauWeights=c(.25,.5,.25))
# uses median cross-validation error instead of mean.
r4 &lt;- rq.pen.cv(x,y,cvSummary=median)  
#Cross-validation with no penalty on the first variable.
r5 &lt;- rq.pen.cv(x,y,penalty.factor=c(0,rep(1,7)))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
