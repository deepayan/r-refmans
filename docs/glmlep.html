<!DOCTYPE html><html><head><title>Help for package glmlep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {glmlep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.glmlep'>
<p>Cross-validation for <code>glmlep</code>.</p></a></li>
<li><a href='#glmlep'>
<p>Fit a GLM wit LEP regularization</p></a></li>
<li><a href='#glmlep-package'>
<p>Regularization paths for LEP-penalized regression models</p></a></li>
<li><a href='#loglike'>
<p>Internal glmlep functions</p></a></li>
<li><a href='#SetLambda'>
<p>Internal glmlep functions</p></a></li>
<li><a href='#soft'>
<p>Internal glmlep functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fit GLM with LEP-Based Penalized Maximum Likelihood</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-03-06</td>
</tr>
<tr>
<td>Author:</td>
<td>Canhong Wen, Hao Lin, Xueqin Wang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Canhong Wen &lt;wencanhong@gmail.com&gt;</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mvtnorm</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient algorithms for fitting regularization paths for
        linear or logistic regression models penalized by LEP.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-03-08 08:55:54 UTC; quanshijief</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-03-08 15:10:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.glmlep'>
Cross-validation for <code>glmlep</code>.
</h2><span id='topic+cv.glmlep'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for <code>glmlep</code>, produces a plot, and returns a value for <code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.glmlep(x, y, family = c("gaussian", "binomial"), lambda = NULL, 
lambda.min = ifelse(n &lt; p, 0.05, 0.001), nlambda = 100, lambda2 = 0, 
kappa = ifelse(n &lt; p, 0.1, 0.05), pen.fac = rep(1, p), tol = 1e-06, 
max.ite = 1000, foldid, nfolds = 5, cv.seed = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.glmlep_+3A_x">x</code></td>
<td>

<p>The design matrix, without an intercept.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_y">y</code></td>
<td>

<p>The response vector. Quantitative for family=&quot;gaussian&quot;. For family=&quot;binomial&quot; should be a vector with two levels.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_family">family</code></td>
<td>

<p>Response type (see above)
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_lambda">lambda</code></td>
<td>

<p>A user supplied lambda sequence. Typical usage is to have the program compute its own lambda sequence based on nlambda and lambda.min.ratio. Supplying a value of lambda overrides this. WARNING: use with care. Do not supply a single value for lambda. Supply instead a decreasing sequence of lambda values. glmnet relies on its warms starts for speed, and its often faster to fit a whole path than compute a single fit.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_lambda.min">lambda.min</code></td>
<td>

<p>Smallest value for lambda, as a fraction of lambda.max, the (data derived) entry value (i.e. the smallest value for which all coefficients are zero). The default depends on the sample size nobs relative to the number of variables nvars. If nobs &gt; nvars, the default is 0.001, close to zero. If nobs &lt; nvars, the default is 0.05. 
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_nlambda">nlambda</code></td>
<td>

<p>The number of <code>lambda</code> values; default is 100.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_lambda2">lambda2</code></td>
<td>

<p>The tuning parameter for additional L_2 penalty. Use for better grouping effect. The default is 0.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_kappa">kappa</code></td>
<td>

<p>The scale tuning parameter of the LEP penalty. One can specify it to get the desired estimates because of the homotopy of LEP function to the L_0 function. If nobs &gt; nvars, the default is 0.05, close to zero. If nobs &lt; nvars, the default is 0.1.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_pen.fac">pen.fac</code></td>
<td>

<p>Separate penalty factors can be applied to each coefficient. This is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some variables, which implies no shrinkage, and that variable is always included in the model. Default is 1 for all variables (and implicitly infinity for variables listed in exclude). Note: the penalty factors are internally rescaled to sum to nobs, and the lambda sequence will reflect this change.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_tol">tol</code></td>
<td>

<p>Convergence tolerance for MCD. Each inner MCD loop continues until the change in the estimates is less than <code>tol</code>. default is 1E-6.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_max.ite">max.ite</code></td>
<td>

<p>Maximum number of passes over the data for all lambda values; default is 10^3.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_foldid">foldid</code></td>
<td>

<p>An optional vector of values between 1 and <code>nfold</code> identifying what fold each observation is in. If supplied, nfold can be missing.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_nfolds">nfolds</code></td>
<td>

<p>Number of folds - default is 5.
</p>
</td></tr>
<tr><td><code id="cv.glmlep_+3A_cv.seed">cv.seed</code></td>
<td>

<p>The seed for cross-validation. This could be used for simulation replicability.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs glmlep nfolds+1 times; the first to get the lambda sequence and the final estimate, and then the remainder to compute the fit with each of the folds omitted. The loss is accumulated, and the average loss over the folds is computed. Note that cv.glmlep does NOT search for values for <code>kappa</code>. A specific value should be supplied, else <code>kappa</code>=0.05 is assumed by default. If users would like to cross-validate <code>kappa</code> as well, they should call cv.glmlep with a pre-computed vector foldid, and then use this same fold vector in separate calls to cv.glmlep with different values of <code>kappa</code>. Note that <code>n</code> is the sample size and <code>p</code> is the dimension of variables.
</p>


<h3>Value</h3>

<p>An object of class &quot;cv.glmlep&quot; is returned, which is a list with the ingredients of the cross-validation fit.
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A nrow(x) x length(<code>lambda</code>) matrix of estimated coefficient.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of regularization parameter values used</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The degree of freedom for each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>The -2*log-likelihood value for each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>The value of lambda with the minimum EBIC.</p>
</td></tr>
<tr><td><code>beta.min</code></td>
<td>
<p>The coefficient with the minimum EBIC.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produces this object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Canhong Wen, Hao Lin, Shaoli Wang and Xueqin Wang.
</p>
<p>Maintainer: Canhong Wen &lt;wencanhong@gmail.com&gt;
</p>


<h3>References</h3>

<p>Wen, C., Wang, X., &amp; Wang, S. (2013). Laplace Error Penalty based variable selection in ultra high-dimension. In press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate data from multivariate normal distribution
require(mvtnorm)
n = 100;
beta &lt;- c(3,1.5,0,0,2,0,0,0)

set.seed(100)
p=length(beta);
corr_data=diag(rep(1,p));
x=as.matrix(rmvnorm(n,rep(0,p),corr_data))
noise=rnorm(n);

## Gaussian
y &lt;- tcrossprod(x,t(beta)) + noise;
fit &lt;- cv.glmlep(x,y,family="gaussian")


</code></pre>

<hr>
<h2 id='glmlep'>
Fit a GLM wit LEP regularization
</h2><span id='topic+glmlep'></span>

<h3>Description</h3>

<p>Fit a generalized linear model via penalized maximum likelihood. The regularization path is computed for the LEP penalty at a grid of values for the regularization parameter lambda. Fits linear, logistic and Cox regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmlep(x, y, family = c("gaussian", "binomial"), lambda = NULL, 
lambda.min = ifelse(n &lt; p, 0.05, 0.001), nlambda = 100, lambda2 = 0, 
kappa = ifelse(n &lt; p, 0.1, 0.05), pen.fac = rep(1, p), tol = 1e-06, 
max.ite = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmlep_+3A_x">x</code></td>
<td>

<p>The design matrix, without an intercept.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_y">y</code></td>
<td>

<p>The response vector. Quantitative for family=&quot;gaussian&quot;. For family=&quot;binomial&quot; should be a vector with two levels.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_family">family</code></td>
<td>

<p>Response type (see above)
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_lambda">lambda</code></td>
<td>

<p>A user supplied lambda sequence. Typical usage is to have the program compute its own lambda sequence based on nlambda and lambda.min.ratio. Supplying a value of lambda overrides this. WARNING: use with care. Do not supply a single value for lambda. Supply instead a decreasing sequence of lambda values. glmnet relies on its warms starts for speed, and its often faster to fit a whole path than compute a single fit.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_lambda.min">lambda.min</code></td>
<td>

<p>Smallest value for lambda, as a fraction of lambda.max, the (data derived) entry value (i.e. the smallest value for which all coefficients are zero). The default depends on the sample size nobs relative to the number of variables nvars. If nobs &gt; nvars, the default is 0.001, close to zero. If nobs &lt; nvars, the default is 0.05. 
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_nlambda">nlambda</code></td>
<td>

<p>The number of <code>lambda</code> values; default is 100.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_lambda2">lambda2</code></td>
<td>

<p>The tuning parameter for additional L_2 penalty. Use for better grouping effect. The default is 0.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_kappa">kappa</code></td>
<td>

<p>The scale tuning parameter of the LEP penalty. One can specify it to get the desired estimates because of the homotopy of LEP function to the L_0 function. If nobs &gt; nvars, the default is 0.05, close to zero. If nobs &lt; nvars, the default is 0.1.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_pen.fac">pen.fac</code></td>
<td>

<p>Separate penalty factors can be applied to each coefficient. This is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some variables, which implies no shrinkage, and that variable is always included in the model. Default is 1 for all variables (and implicitly infinity for variables listed in exclude). Note: the penalty factors are internally rescaled to sum to nobs, and the lambda sequence will reflect this change.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_tol">tol</code></td>
<td>

<p>Convergence tolerance for MCD. Each inner MCD loop continues until the change in the estimates is less than <code>tol</code>. default is 1E-6.
</p>
</td></tr>
<tr><td><code id="glmlep_+3A_max.ite">max.ite</code></td>
<td>

<p>Maximum number of passes over the data for all lambda values; default is 10^3.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models implied by lambda is fit by a modified version of coordinate descent (MCD), see reference below.  Note that <code>n</code> is the sample size and <code>p</code> is the dimension of variables.
</p>


<h3>Value</h3>

<p>An object of class &quot;glmlep&quot;, &quot;*&quot;, where &quot;*&quot; is &quot;gaulep&quot; or &quot;binlep&quot; for the two types of models.
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A nrow(x) x length(<code>lambda</code>) matrix of estimated coefficient.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of regularization parameter values used</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The degree of freedom for each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>The -2*log-likelihood value for each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>EBIC</code></td>
<td>
<p>The EBIC value for each value of <code>lambda</code>. Note tha the EBIC value is defined as</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>The value of lambda with the minimum EBIC.</p>
</td></tr>
<tr><td><code>beta.min</code></td>
<td>
<p>The coefficient with the minimum EBIC.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The call that produces this object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Canhong Wen, Hao Lin. <a href="mailto:wencanhong@gmail.com">wencanhong@gmail.com</a>
</p>
<p>Maintainer: Canhong Wen &lt;wencanhong@gmail.com&gt;
</p>


<h3>References</h3>

<p>Wen, C., Wang, X., &amp; Wang, S. (2013). Laplace Error Penalty based variable selection in ultra high-dimension. In press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate data
require(mvtnorm)
n = 100;
beta &lt;- c(3,1.5,0,0,2,0,0,0)

set.seed(100)
p=length(beta);
corr_data=diag(rep(1,p));

x=as.matrix(rmvnorm(n,rep(0,p),corr_data))
noise=rnorm(n);

## Gaussian
y &lt;- tcrossprod(x,t(beta)) + noise;
fit &lt;- glmlep(x,y,family="gaussian")

</code></pre>

<hr>
<h2 id='glmlep-package'>
Regularization paths for LEP-penalized regression models
</h2><span id='topic+glmlep-package'></span>

<h3>Description</h3>

<p>Efficient algorithms for fitting regularization paths for linear or logistic regression models penalized by LEP.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> glmlep</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2013-06-05</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Accepts a design matrix X and vector of responses y, produces the regularization path over a grid of values for the tuning parameter lambda. Also provides methods for plotting and for determining locally convex regions of the coefficients paths.
</p>


<h3>Author(s)</h3>

<p>Canhong Wen, Hao Lin, Shaoli Wang and Xueqin Wang.
</p>
<p>Maintainer: Canhong Wen &lt;wencanhong@gmail.com&gt;
</p>


<h3>References</h3>

<p>Wen, C., Wang, X., &amp; Wang, S. (2013). Laplace Error Penalty based variable selection in ultra high-dimension. In press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate data
require(mvtnorm)
n &lt;- 100;
beta &lt;- c(3,1.5,0,0,2,0,0,0)

set.seed(100)
p &lt;- length(beta);
corr_data &lt;- diag(rep(1,p));

x &lt;- as.matrix(rmvnorm(n,rep(0,p),corr_data))
noise &lt;- rnorm(n)

y &lt;- tcrossprod(x,t(beta)) + noise;
fit &lt;- glmlep(x,y,family="gaussian")
</code></pre>

<hr>
<h2 id='loglike'>
Internal glmlep functions
</h2><span id='topic+loglike'></span>

<h3>Description</h3>

<p>Internal glmlep functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglike(x, y, beta, family = c("gaussian", "binomial"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglike_+3A_x">x</code></td>
<td>

<p>The design matrix, without an intercept.
</p>
</td></tr>
<tr><td><code id="loglike_+3A_y">y</code></td>
<td>

<p>The response vector. Quantitative for family=&quot;gaussian&quot;. For family=&quot;binomial&quot; should be a vector with two levels.
</p>
</td></tr>
<tr><td><code id="loglike_+3A_beta">beta</code></td>
<td>

<p>The estimated coefficients.
</p>
</td></tr>
<tr><td><code id="loglike_+3A_family">family</code></td>
<td>

<p>Response type (see above)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are not intended for use by users.</p>


<h3>Author(s)</h3>

<p>Canhong Wen, Hao Lin, Shaoli Wang and Xueqin Wang.
</p>
<p>Maintainer: Canhong Wen &lt;wencanhong@gmail.com&gt;
</p>

<hr>
<h2 id='SetLambda'>
Internal glmlep functions
</h2><span id='topic+SetLambda'></span>

<h3>Description</h3>

<p>Internal glmlep functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SetLambda(x, y, lambda.min, nlambda, penalty.factor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SetLambda_+3A_x">x</code></td>
<td>

<p>The design matrix, without an intercept.
</p>
</td></tr>
<tr><td><code id="SetLambda_+3A_y">y</code></td>
<td>

<p>The response vector. Quantitative for family=&quot;gaussian&quot;. For family=&quot;binomial&quot; should be a vector with two levels.
</p>
</td></tr>
<tr><td><code id="SetLambda_+3A_lambda.min">lambda.min</code></td>
<td>

<p>Smallest value for lambda, as a fraction of lambda.max, the (data derived) entry value (i.e. the smallest value for which all coefficients are zero). The default depends on the sample size nobs relative to the number of variables nvars. If nobs &gt; nvars, the default is 0.001, close to zero. If nobs &lt; nvars, the default is 0.05. 
</p>
</td></tr>
<tr><td><code id="SetLambda_+3A_nlambda">nlambda</code></td>
<td>

<p>The number of <code>lambda</code> values; default is 100.
</p>
</td></tr>
<tr><td><code id="SetLambda_+3A_penalty.factor">penalty.factor</code></td>
<td>

<p>Separate penalty factors can be applied to each coefficient. This is a number that multiplies lambda to allow differential shrinkage. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are not intended for use by users.
</p>


<h3>Author(s)</h3>

<p>Canhong Wen, Hao Lin, Shaoli Wang and Xueqin Wang.
</p>
<p>Maintainer: Canhong Wen &lt;wencanhong@gmail.com&gt;
</p>

<hr>
<h2 id='soft'>
Internal glmlep functions
</h2><span id='topic+soft'></span>

<h3>Description</h3>

<p>Internal glmlep functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>soft(z, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="soft_+3A_z">z</code></td>
<td>

<p>The partial least square estimate.
</p>
</td></tr>
<tr><td><code id="soft_+3A_lambda">lambda</code></td>
<td>

<p>The tuning parameter.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are not intended for use by users.
</p>


<h3>Author(s)</h3>

<p>Canhong Wen, Hao Lin, Shaoli Wang and Xueqin Wang.
</p>
<p>Maintainer: Canhong Wen &lt;wencanhong@gmail.com&gt;
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
