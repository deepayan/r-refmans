<!DOCTYPE html><html><head><title>Help for package mpt</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mpt}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#citysize'><p>City-Size Paired-Comparison Task</p></a></li>
<li><a href='#logLik.mpt'><p>Log-Likelihood of an mpt Object</p></a></li>
<li><a href='#moraldilemma'><p>Moral Dilemma Judgment</p></a></li>
<li><a href='#mpt'><p>Multinomial Processing Tree (MPT) Models</p></a></li>
<li><a href='#mptEM'><p>EM Algorithm for Multinomial Processing Tree Models</p></a></li>
<li><a href='#mptspec'><p>Specify a Multinomial Processing Tree (MPT) Model</p></a></li>
<li><a href='#plot.mpt'><p>Diagnostic Plot for MPT Models</p></a></li>
<li><a href='#proact'><p>Recall Frequencies for DaPolito's Experiment on Proactive Inhibition</p></a></li>
<li><a href='#prospecMemory'><p>Prospective Memory and Task Importance</p></a></li>
<li><a href='#recogROC'><p>Recognition Receiver Operating Characteristics</p></a></li>
<li><a href='#retroact'><p>Recall Frequencies in Retroactive Inhibition</p></a></li>
<li><a href='#selectiontask'><p>Wason Selection Task (WST) and Helpful Hints</p></a></li>
<li><a href='#simulate.mpt'><p>Simulate Responses from MPT Models</p></a></li>
<li><a href='#valence'><p>World Valence and Source Memory for Vertical Position</p></a></li>
<li><a href='#vcov.mpt'><p>Covariance and Information Matrix for MPT Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.8-0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-03-22</td>
</tr>
<tr>
<td>Title:</td>
<td>Multinomial Processing Tree Models</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), stats</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, utils</td>
</tr>
<tr>
<td>Description:</td>
<td>Fitting and testing multinomial processing tree (MPT) models, a
  class of nonlinear models for categorical data.  The parameters are the
  link probabilities of a tree-like graph and represent the latent cognitive
  processing steps executed to arrive at observable response categories
  (Batchelder &amp; Riefer, 1999 &lt;<a href="https://doi.org/10.3758%2Fbf03210812">doi:10.3758/bf03210812</a>&gt;; Erdfelder et al., 2009
  &lt;<a href="https://doi.org/10.1027%2F0044-3409.217.3.108">doi:10.1027/0044-3409.217.3.108</a>&gt;; Riefer &amp; Batchelder, 1988
  &lt;<a href="https://doi.org/10.1037%2F0033-295x.95.3.318">doi:10.1037/0033-295x.95.3.318</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.mathpsy.uni-tuebingen.de/wickelmaier/">http://www.mathpsy.uni-tuebingen.de/wickelmaier/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-03-22 14:26:57 UTC; siifw01</td>
</tr>
<tr>
<td>Author:</td>
<td>Florian Wickelmaier [aut, cre],
  Achim Zeileis <a href="https://orcid.org/0000-0003-0918-3766"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Florian Wickelmaier &lt;wickelmaier@web.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-03-23 07:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='citysize'>City-Size Paired-Comparison Task</h2><span id='topic+citysize'></span><span id='topic+WorldCities'></span><span id='topic+ItalianCities'></span>

<h3>Description</h3>

<p>In a city-size paired-comparison task on each trial, participants judge
which of two cities is more populous. After the paired comparisons,
participants indicate for each city if they recognize its name.
Hilbig, Erdfelder, and Pohl (2010) report a series of experiments to
evaluate their model of recognition heuristic use at this task.
</p>
<p>The <code>WorldCities</code> data are from a study designed to be similar to
Hilbig et al.'s Experiment 6.  The 17 cities were (in order of population;
Wikipedia, 2016): Shanghai, Tianjin, Tokyo, Seoul, London, Bangkok,
Chongqing, Wuhan, Santiago, Rangun, Ankara, Harbin, Kano, Busan, Durban,
Ibadan, Montreal.
</p>
<p>The <code>ItalianCities</code> data are from a study designed to be similar to
Hilbig et al.'s Experiment 7.  The 14 cities were: Milan, Naples, Turin,
Palermo, Venice, Padua, Taranto, Prato, Reggio Emilia, Perugia, Cagliari,
Foggia, Salerno, Ferrara.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(citysize)</code></pre>


<h3>Format</h3>

<p><code>WorldCities</code> A data frame containing 37 observations of six
variables:
</p>

<dl>
<dt><code>gender</code></dt><dd><p>factor. Participant gender.</p>
</dd>
<dt><code>age</code></dt><dd><p>participant age.</p>
</dd>
<dt><code>rt</code></dt><dd><p>median response time (in seconds) across paired
comparisons.</p>
</dd>
<dt><code>group</code></dt><dd><p>factor. The control group (<code>CG</code>) received
standard instructions, the experimental group (<code>EG</code>) was instructed
to choose the city they recognized whenever possible.</p>
</dd>
<dt><code>country</code></dt><dd><p>number of cities whose country was correctly
identified.</p>
</dd>
<dt><code>y</code></dt><dd><p>a matrix of aggregate response frequencies per
participant. The column names indicate each of eight response
categories: correct/false responses when both cities were recognized
(<code>KC</code>, <code>KF</code>), when both were unrecognized (<code>GC</code>,
<code>GF</code>), when only one was recognized and the recognized city was
chosen (<code>RC</code>, <code>RF</code>), and when only one was recognized and the
unrecognized city was chosen (<code>UF</code>, <code>UC</code>).</p>
</dd>
</dl>

<p><code>ItalianCities</code> A data frame containing 64 observations of six
variables:
</p>

<dl>
<dt><code>gender</code>, <code>age</code>, <code>rt</code>, <code>y</code></dt><dd><p>see above.</p>
</dd>
<dt><code>group</code></dt><dd><p>factor. The control group (<code>CG</code>) received
standard instructions, the experimental group (<code>EG</code>) was asked
to compare the cities with respect to their elevation above sea level.</p>
</dd>
<dt><code>knowRH</code></dt><dd><p>factor. Does the participant have any knowledge about
the recognition heuristic (RH)?</p>
</dd>
</dl>



<h3>Source</h3>

<p>The <code>WorldCities</code> data were collected at the Department of Psychology,
University of Tuebingen, in June/July 2016. The <code>ItalianCities</code> data
are from Rettich (2020). The original data are from Castela et al. (2014).
</p>


<h3>References</h3>

<p>Hilbig, B.E., Erdfelder, E., &amp; Pohl, R.F. (2010).
One-reason decision-making unveiled: A measurement model of the recognition
heuristic.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>36</b>(1), 123&ndash;134.
doi: <a href="https://doi.org/10.1037/a0017518">10.1037/a0017518</a>
</p>
<p>Castela, M., Kellen, D., Erdfelder, E., &amp; Hilbig, B.E. (2014).
The impact of subjective recognition experiences on recognition heuristic
use: A multinomial processing tree approach.
<em>Psychonomic Bulletin &amp; Review</em>,
<b>21</b>(5), 1131&ndash;1138.
doi: <a href="https://doi.org/10.3758/s13423-014-0587-4">10.3758/s13423-014-0587-4</a>
</p>
<p>Rettich, A. (2020).
<em>Application of the recognition heuristic: An experimental validation
of the r-model</em>.
Bachelor thesis. University of Tuebingen, Germany.
<a href="https://osf.io/mz47y/">https://osf.io/mz47y/</a>
</p>
<p>Wikipedia. (2016). List of cities proper by population. Retrieved Jun 16
from <a href="https://en.wikipedia.org/wiki/List_of_cities_proper_by_population">https://en.wikipedia.org/wiki/List_of_cities_proper_by_population</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(citysize)

## Fit r-model separately for each instruction type
mpt(mptspec("rmodel"), unname(WorldCities[WorldCities$group == "CG",  "y"]))
mpt(mptspec("rmodel"), unname(WorldCities[WorldCities$group == "EG", "y"]))

## Test instruction effect on r parameter
city.agg &lt;- aggregate(y ~ group, WorldCities, sum)
y &lt;- as.vector(t(city.agg[, -1]))

m1 &lt;- mpt(mptspec("rmodel", .replicates = 2), y)
m2 &lt;- mpt(update(m1$spec, .restr = list(r2=r1)), y)
anova(m2, m1)  # more use of RH with recognition instruction

## Fit r-model separately for each task type
mpt(mptspec("rmodel"),
    unname(ItalianCities[ItalianCities$group == "CG",  "y"]))
mpt(mptspec("rmodel"),
    unname(ItalianCities[ItalianCities$group == "EG", "y"]))

## Test task effect on r parameter
city.agg &lt;- aggregate(y ~ group, ItalianCities, sum)
y &lt;- as.vector(t(city.agg[, -1]))

m3 &lt;- mpt(mptspec("rmodel", .replicates = 2), y)
m4 &lt;- mpt(update(m1$spec, .restr = list(r2=r1)), y)
anova(m4, m3)  # less use of RH with elevation task

## Plot parameter estimates
par(mfrow = 1:2)
dotchart(coef(m1)[c(4, 1:3)], xlim=0:1, labels=c("a", "b", "g", "r"),
         xlab="", main="by instruction type")
points(coef(m1)[c(8, 5:7)], 1:4, pch=16)
legend(0, 1, c("none", "recognition"), pch=c(1, 16),
       title="Instruction", bty="n")
dotchart(coef(m3)[c(4, 1:3)], xlim=0:1, labels=c("a", "b", "g", "r"),
         xlab="", main="by task type")
points(coef(m3)[c(8, 5:7)], 1:4, pch=16)
legend(0, 1, c("population", "elevation"), pch=c(1, 16),
       title="Task", bty="n")
title("Recognition heuristic use", outer=TRUE, line=-1)
mtext("Parameter estimate (r-model)", side=1, outer=TRUE, line=-2)

## Compare with original results
Hilbig2010 &lt;- rbind(
    WorldCities.CG = c(462, 204, 290, 272, 740, 205, 77, 62),
    WorldCities.EG = c(500, 307, 279, 264, 902, 235, 68, 29),
  ItalianCities.CG = c(232, 78, 135, 136, 465, 65, 56, 16),
  ItalianCities.EG = c(245, 176, 154, 150, 228, 160, 112, 140)
)
apply(Hilbig2010, 1, mpt, spec = mptspec("rmodel"))
</code></pre>

<hr>
<h2 id='logLik.mpt'>Log-Likelihood of an mpt Object</h2><span id='topic+logLik.mpt'></span><span id='topic+nobs.mpt'></span><span id='topic+deviance.mpt'></span><span id='topic+AIC.mpt'></span><span id='topic+BIC.mpt'></span>

<h3>Description</h3>

<p>Returns the log-likelihood value of the (joint) multinomial processing
tree model represented by <code>object</code> evaluated at the estimated
parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpt'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.mpt_+3A_object">object</code></td>
<td>
<p>an object inheriting from class <code>mpt</code>, representing
a fitted multinomial processing tree model.</p>
</td></tr>
<tr><td><code id="logLik.mpt_+3A_...">...</code></td>
<td>
<p>some methods for this generic require additional
arguments.  None are used in this method.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>The log-likelihood of the model represented by <code>object</code> evaluated at
the estimated parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>, <code><a href="stats.html#topic+logLik.lm">logLik.lm</a></code>, <code><a href="stats.html#topic+AIC">AIC</a></code>,
<code><a href="stats.html#topic+deviance">deviance</a></code>, <code><a href="stats.html#topic+nobs">nobs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- mpt(mptspec("SR2"), c(243, 64, 58, 55))  # from Riefer et al. (2002)
logLik(m)
deviance(m)
AIC(m)
AIC(m, k = log(sum(m$y)))  # BIC w/total number of data points
BIC(m)                     # BIC using nobs()
nobs(m)                    # number of non-redundant response categories
</code></pre>

<hr>
<h2 id='moraldilemma'>Moral Dilemma Judgment</h2><span id='topic+moraldilemma'></span><span id='topic+MDHennig2020'></span><span id='topic+MDreplication'></span>

<h3>Description</h3>

<p>Hennig and Huetter (2020) proposed a multinomial model of moral dilemma
judgment and evaluated the model in a series of experiments. Participants
were presented with hypothetical scenarios that required a decision whether
or not to break a moral norm.
</p>
<p>Berentelg (2020) conducted a replication study that was designed to be
similar to Experiment 2b in Hennig and Huetter (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(moraldilemma)</code></pre>


<h3>Format</h3>

<p><code>MDHennig2020</code> A data frame consisting of seven variables:
</p>

<dl>
<dt><code>selfrel</code></dt><dd><p>factor. Instructions about self-relevant
consequences of the decision where either (<code>absent</code>) or
(<code>present</code>).</p>
</dd>
<dt><code>congrcy</code></dt><dd><p>factor. Endorsement of consequences and
norm endorsement lead to different decisions (<code>incongruent</code>) or to
the same decision (<code>congruent</code>).</p>
</dd>
<dt><code>default</code></dt><dd><p>factor. The norm may be adhered to by continuing
(<code>inaction</code> default state) or by changing (<code>action</code> default
state) an ongoing behavior.</p>
</dd>
<dt><code>breaknorm</code></dt><dd><p>factor. Decision to break the norm.</p>
</dd>
<dt><code>exp1</code>, <code>exp2b</code></dt><dd><p>the aggregate response frequencies for
Experiment 1 and 2b, respectively.</p>
</dd>
<dt><code>treeid</code></dt><dd><p>an identifier for the single trees of the joint
multinomial model.</p>
</dd>
</dl>

<p><code>MDreplication</code> A data frame containing 751 observations of five
variables:
</p>

<dl>
<dt><code>selfrel</code></dt><dd><p>factor. See above.</p>
</dd>
<dt><code>gender</code></dt><dd><p>factor. Participant gender.</p>
</dd>
<dt><code>age</code></dt><dd><p>participant age.</p>
</dd>
<dt><code>rt</code></dt><dd><p>median response time (in seconds) across scenarios.</p>
</dd>
<dt><code>y</code></dt><dd><p>a matrix of response frequencies per participant. Each
column represents a combination of the factors <code>congrcy</code>,
<code>default</code>, and <code>breaknorm</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hennig, M., &amp; Huetter, M. (2020).
Revisiting the divide between deontology and utilitarianism in moral
dilemma judgment: A multinomial modeling approach.
<em>Journal of Personality and Social Psychology</em>
<b>118</b>(1), 22&ndash;56.
doi: <a href="https://doi.org/10.1037/pspa0000173">10.1037/pspa0000173</a>
</p>
<p>Berentelg, M. (2020).
<em>Multinomial modeling of moral dilemma judgment: A replication
study</em>.
Bachelor thesis. University of Tuebingen, Germany.
<a href="https://osf.io/mb32t/">https://osf.io/mb32t/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(moraldilemma)

## Exp. 1: proCNI and process dissociation (PD) model
s &lt;- mptspec("proCNI")
exp1 &lt;- subset(MDHennig2020, selfrel == "absent")
mpt(update(s, .restr = list(J=I)),      data = exp1, freqvar = "exp1")
mpt(update(s, .restr = list(I=0, J=1)), data = exp1, freqvar = "exp1")

## Exp. 2b: self-relevant consequences and norm endorsement
s &lt;- mptspec("proCNI", .replicates = 2, .restr = list(J1=I1, J2=I2))
m1 &lt;- mpt(s, data = MDHennig2020, freqvar = "exp2b")
m2 &lt;- mpt(update(m1$spec, .restr = list(N1=N2)), data = m1$y)
anova(m2, m1)

## Replication of Exp. 2b
md.agg &lt;- aggregate(y ~ selfrel, MDreplication, sum)
y &lt;- as.vector(t(md.agg[, -1]))

m3 &lt;- mpt(s, data = y)
m4 &lt;- mpt(update(s, .restr = list(N1=N2)), data = y)
anova(m4, m3)

coefs &lt;- c(diff(coef(m3)[c("N2", "N1")]),
           diff(coef(m1)[c("N2", "N1")]))
names(coefs) &lt;- c("Replication", "Hennig &amp; Huetter\n(2020, Exp. 2b)")
ci &lt;- coefs + rbind(
  qnorm(c(.025, .975))*sqrt(sum(diag(vcov(m3))[c("N2", "N1")])),
  qnorm(c(.025, .975))*sqrt(sum(diag(vcov(m1))[c("N2", "N1")]))
)
dotchart(coefs, pch = 16, xlim = c(-.2, 1),
  xlab = expression(N[absent] - N[present]~"(proCNI model, 95% CI)"),
  main = paste("Self-relevant consequences and norm endorsement",
               "in moral dilemma judgment", sep = "\n"))
abline(v = 0, col = "gray")
arrows(ci[, 1], 1:2, ci[, 2], 1:2, .05, 90, 3)
</code></pre>

<hr>
<h2 id='mpt'>Multinomial Processing Tree (MPT) Models</h2><span id='topic+mpt'></span><span id='topic+anova.mpt'></span><span id='topic+coef.mpt'></span><span id='topic+confint.mpt'></span><span id='topic+predict.mpt'></span><span id='topic+print.mpt'></span><span id='topic+summary.mpt'></span><span id='topic+print.summary.mpt'></span>

<h3>Description</h3>

<p>Fits a (joint) multinomial processing tree (MPT) model specified
by a symbolic description via <code><a href="#topic+mptspec">mptspec</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mpt(spec, data, start = NULL, method = c("BFGS", "EM"), treeid = "treeid",
    freqvar = "freq", optimargs = 
      if(method == "BFGS") list(control =
        list(reltol = .Machine$double.eps^(1/1.2), maxit = 1000))
      else list())

## S3 method for class 'mpt'
anova(object, ..., test = c("Chisq", "none"))

## S3 method for class 'mpt'
coef(object, logit = FALSE, ...)

## S3 method for class 'mpt'
confint(object, parm, level = 0.95, logit = TRUE, ...)

## S3 method for class 'mpt'
predict(object, newdata = NULL, type = c("freq", "prob"), ...)

## S3 method for class 'mpt'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mpt_+3A_spec">spec</code></td>
<td>
<p>an object of class <code>mptspec</code>: typically result of a call to
<code><a href="#topic+mptspec">mptspec</a></code>. A symbolic description of the model to be
fitted. (See Details and Examples.)</p>
</td></tr>
<tr><td><code id="mpt_+3A_data">data</code></td>
<td>
<p>a data frame consisting at least of one variable that contains
the absolute response frequencies. Alternatively, a (named) vector or
matrix of frequencies.</p>
</td></tr>
<tr><td><code id="mpt_+3A_start">start</code></td>
<td>
<p>a vector of starting values for the parameter estimates between
zero and one.</p>
</td></tr>
<tr><td><code id="mpt_+3A_method">method</code></td>
<td>
<p>optimization method. Implemented are
<code>optim(..., method = "BFGS")</code> and the EM algorithm.</p>
</td></tr>
<tr><td><code id="mpt_+3A_treeid">treeid</code></td>
<td>
<p>name of the variable that identifies the processing trees
of a joint multinomial model. Alternatively, a factor that identifies each
tree.</p>
</td></tr>
<tr><td><code id="mpt_+3A_freqvar">freqvar</code></td>
<td>
<p>if <code>data</code> is a data frame, name of the variable that
holds the response frequencies; else ignored.</p>
</td></tr>
<tr><td><code id="mpt_+3A_logit">logit</code></td>
<td>
<p>logical. Parameter estimates on logit or probability scale.</p>
</td></tr>
<tr><td><code id="mpt_+3A_optimargs">optimargs</code></td>
<td>
<p>a list of arguments passed to the optimization function,
either <code><a href="stats.html#topic+optim">optim</a></code> or <code><a href="#topic+mptEM">mptEM</a></code>.</p>
</td></tr>
<tr><td><code id="mpt_+3A_object">object</code></td>
<td>
<p>an object of class <code>mpt</code>, typically the result of a
call to <code>mpt</code>.</p>
</td></tr>
<tr><td><code id="mpt_+3A_test">test</code></td>
<td>
<p>should the p-values of the chi-square distributions be
reported?</p>
</td></tr>
<tr><td><code id="mpt_+3A_parm">parm</code>, <code id="mpt_+3A_level">level</code></td>
<td>
<p>See <code><a href="stats.html#topic+confint.default">confint.default</a></code>.</p>
</td></tr>
<tr><td><code id="mpt_+3A_newdata">newdata</code></td>
<td>
<p>a vector of response frequencies.</p>
</td></tr>
<tr><td><code id="mpt_+3A_type">type</code></td>
<td>
<p>predicted frequencies or probabilities.</p>
</td></tr>
<tr><td><code id="mpt_+3A_...">...</code></td>
<td>
<p>additional arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multinomial processing tree models (Batchelder &amp; Riefer, 1999; Erdfelder et
al., 2009; Riefer &amp; Batchelder, 1988) seek to represent the categorical
responses of a group of subjects by a small number of latent
(psychological) parameters.  These models have a tree-like graph, the links
being the parameters, the leaves being the response categories.  The path
from the root to one of the leaves represents the cognitive processing
steps executed to arrive at a given response.
</p>
<p>If <code>data</code> is a data frame, each row corresponds to one response
category.  If <code>data</code> is a vector or matrix, each element or column
corresponds to one response category.  The order of response categories and
of model equations specified in <code><a href="#topic+mptspec">mptspec</a></code> should match.
</p>
<p>Joint (or product) multinomial models consist of more than one processing
tree.  The <code>treeid</code> should uniquely identify each tree.
</p>
<p>Per default, parameter estimation is carried out by <code><a href="stats.html#topic+optim">optim</a></code>'s
BFGS method on the logit scale with analytical gradients; it can be switched
to <code><a href="#topic+mptEM">mptEM</a></code> which implements the EM algorithm.
</p>


<h3>Value</h3>

<p>An object of class <code>mpt</code> containing the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a vector of parameter estimates. For extraction, the
<code>coef</code> function is preferred.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>the log-likelihood of the fitted model.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>the number of nonredundant response categories.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>the fitted response frequencies.</p>
</td></tr>
<tr><td><code>goodness.of.fit</code></td>
<td>
<p>the goodness of fit statistic including the
likelihood ratio fitted vs. saturated model (G2), the degrees of
freedom, and the p-value of the corresponding chi-square distribution.</p>
</td></tr>
<tr><td><code>ntrees</code></td>
<td>
<p>the number of trees in a joint multinomial model.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the total number of observations per tree.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the vector of response frequencies.</p>
</td></tr>
<tr><td><code>pcat</code></td>
<td>
<p>the predicted probabilities for each response category.</p>
</td></tr>
<tr><td><code>treeid</code></td>
<td>
<p>a factor that identifies each tree.</p>
</td></tr>
<tr><td><code>a</code>, <code>b</code>, <code>c</code></td>
<td>
<p>structural constants passed to <code><a href="#topic+mptEM">mptEM</a></code>.</p>
</td></tr>
<tr><td><code>spec</code></td>
<td>
<p>the MPT model specification returned by <code><a href="#topic+mptspec">mptspec</a></code>.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the optimization method used.</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>the return value of the optimization function.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Batchelder, W.H., &amp; Riefer, D.M. (1999).
Theoretical and empirical review of multinomial process tree modeling.
<em>Psychonomic Bulletin &amp; Review</em>, <b>6</b>(1), 57&ndash;86.
doi: <a href="https://doi.org/10.3758/bf03210812">10.3758/bf03210812</a>
</p>
<p>Erdfelder, E., Auer, T., Hilbig, B.E., Assfalg, A., Moshagen, M., &amp;
Nadarevic, L. (2009).
Multinomial processing tree models: A review of the literature.
<em>Zeitschrift fuer Psychologie</em>, <b>217</b>(3), 108&ndash;124.
doi: <a href="https://doi.org/10.1027/0044-3409.217.3.108">10.1027/0044-3409.217.3.108</a>
</p>
<p>Riefer, D.M., &amp; Batchelder, W.H. (1988).
Multinomial modeling and the measurement of cognitive processes.
<em>Psychological Review</em>, <b>95</b>(3), 318&ndash;339.
doi: <a href="https://doi.org/10.1037/0033-295x.95.3.318">10.1037/0033-295x.95.3.318</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mptEM">mptEM</a></code>, <code><a href="#topic+mptspec">mptspec</a></code>, <code><a href="#topic+simulate.mpt">simulate.mpt</a></code>,
<code><a href="#topic+plot.mpt">plot.mpt</a></code>, <code><a href="#topic+residuals.mpt">residuals.mpt</a></code>,
<code><a href="#topic+logLik.mpt">logLik.mpt</a></code>, <code><a href="#topic+vcov.mpt">vcov.mpt</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Storage-retrieval model for pair clustering (Riefer &amp; Batchelder, 1988)
data(retroact)

spec &lt;- mptspec(
  c*r,
  (1 - c)*u^2,
  2*(1 - c)*u*(1 - u),
  c*(1 - r) + (1 - c)*(1 - u)^2,
  u,
  1 - u
)
m &lt;- mpt(spec, retroact[retroact$lists == 0, ])

summary(m)  # parameter estimates, goodness of fit
plot(m)     # residuals versus predicted values
confint(m)  # approximate confidence intervals

plot(coef(m), axes = FALSE, ylim = 0:1, pch = 16, xlab = "",
     ylab="Parameter estimate (MPT model, 95% CI)")
axis(1, 1:3, names(coef(m))); axis(2)
arrows(1:3, plogis(confint(m))[, 1], 1:3, plogis(confint(m))[, 2],
       .05, 90, 3)

## See data(package = "mpt") for application examples.
</code></pre>

<hr>
<h2 id='mptEM'>EM Algorithm for Multinomial Processing Tree Models</h2><span id='topic+mptEM'></span>

<h3>Description</h3>

<p>Applies the EM algorithm to fit a multinomial processing tree
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mptEM(theta, data, a, b, c, maxit = 1000, tolerance = 1e-8, 
      stepsize = 1, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mptEM_+3A_theta">theta</code></td>
<td>
<p>a vector of starting values for the parameter estimates.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_data">data</code></td>
<td>
<p>a vector of absolute response frequencies.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_a">a</code></td>
<td>
<p>a three-dimensional array representing the model structure.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_b">b</code></td>
<td>
<p>a three-dimensional array representing the model structure.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_c">c</code></td>
<td>
<p>a matrix of structural constants.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_maxit">maxit</code></td>
<td>
<p>the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_tolerance">tolerance</code></td>
<td>
<p>the convergence criterion; the iterations converge when
<code class="reqn">logLik - logLik.old &lt; tolerance</code>.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_stepsize">stepsize</code></td>
<td>
<p>the step size defaulting to 1; slightly larger values may
speed up convergence, but may also give errors; use with care.</p>
</td></tr>
<tr><td><code id="mptEM_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if output should be produced for each
iteration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Usually, <code>mptEM</code> is automatically called by <code><a href="#topic+mpt">mpt</a></code>.
</p>
<p>A prerequisite for the application of the EM algorithm is that the
probabilities of the i-th branch leading to the j-th category take the form
</p>
<p style="text-align: center;"><code class="reqn">p_{ij}(\Theta) =
    c_{ij} \prod_{s = 1}^S \vartheta_s^{a_{ijs}} (1 - \vartheta_s)^{b_{ijs}},</code>
</p>

<p>where <code class="reqn">\Theta = (\vartheta_s)</code> is the parameter vector, <code class="reqn">a_{ijs}</code>
and <code class="reqn">b_{ijs}</code> count the occurrences of <code class="reqn">\vartheta_s</code> and
<code class="reqn">1 - \vartheta_s</code> in a branch, respectively, and <code class="reqn">c_{kj}</code> is a
nonnegative real number.  The branch probabilities sum up to the total
probability of a given category, <code class="reqn">p_j = p_{1j} + \dots + p_{Ij}</code>.  This
is the structural restriction of the class of MPT models that can be
represented by binary trees.  Other model types have to be suitably
reparameterized for the algorithm to apply.
</p>
<p>See Hu and Batchelder (1994) and Hu (1999) for details on the algorithm.
</p>


<h3>Value</h3>

<table>
<tr><td><code>theta</code></td>
<td>
<p>the vector of parameter estimates.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>the log-likelihood at termination of the algorithm.</p>
</td></tr>
<tr><td><code>pcat</code></td>
<td>
<p>a vector of predicted probabilities for each response category.</p>
</td></tr>
<tr><td><code>pbranch</code></td>
<td>
<p>a vector of predicted branch probabilities.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of iterations of the algorithm.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hu, X. (1999).
Multinomial processing tree models: An implementation.
<em>Behavior Research Methods, Instruments, &amp; Computers</em>,
<b>31</b>(4), 689&ndash;695.
doi: <a href="https://doi.org/10.3758/BF03200747">10.3758/BF03200747</a>
</p>
<p>Hu, X., &amp; Batchelder, W.H. (1994).
The statistical analysis of general processing tree models with the EM
algorithm.
<em>Psychometrika</em>,
<b>59</b>(1), 21&ndash;47.
doi: <a href="https://doi.org/10.1007/bf02294263">10.1007/bf02294263</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit storage-retrieval model to data in Riefer et al. (2002)
mpt(mptspec("SR2"), c(243, 64, 58, 55), method = "EM")
</code></pre>

<hr>
<h2 id='mptspec'>Specify a Multinomial Processing Tree (MPT) Model</h2><span id='topic+mptspec'></span><span id='topic+print.mptspec'></span><span id='topic+update.mptspec'></span>

<h3>Description</h3>

<p>Returns the specification of an MPT model object for fitting with
<code><a href="#topic+mpt">mpt</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>mptspec(..., .replicates = NULL, .restr = NULL)

## S3 method for class 'mptspec'
update(object, .replicates = NULL, .restr = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mptspec_+3A_...">...</code></td>
<td>
<p>(named) expressions or a character string specifying the model.
See Details.</p>
</td></tr>
<tr><td><code id="mptspec_+3A_.replicates">.replicates</code></td>
<td>
<p>the number of replicates of the model equations.
See Details.</p>
</td></tr>
<tr><td><code id="mptspec_+3A_.restr">.restr</code></td>
<td>
<p>a named list of parameter restrictions.  See Details.</p>
</td></tr>
<tr><td><code id="mptspec_+3A_object">object</code></td>
<td>
<p>an object of class <code>mptspec</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>...</code> is used to symbolically specify the MPT model equations by
suitable expressions, for example, they could look like this
</p>
<p><code>r + (1 - r)*b, (1 - r)*(1 - b), b, 1 - b</code>
</p>
<p>where each expression represents the probability of a response in the
corresponding category (link probabilities are multiplied, branch
probabilities are added).  Thus, there usually are as many expressions as
response categories.
</p>
<p>Joint (or product) multinomial models consist of more than a single
processing tree.  To identify the trees in such a model, expressions may
have optional names.  Canonically, these names are of the form <code>x.y</code>,
where <code>x</code> is the tree identifier (<code>treeid</code>) and <code>y</code> specifies
the response category within a tree.
</p>
<p>Alternatively, <code>...</code> may be a character string identifying one out of
a list of pre-specified MPT models.  Currently accessible are the following
models (other models have to be specified by explicit expressions as
described above):
</p>
<p><code>1HT</code>: the one-high-threshold model (Blackwell, 1963; Swets, 1961).
</p>
<p><code>2HT</code>: the two-high-threshold model (Snodgrass &amp; Corwin, 1988; see also
Broeder &amp; Schuetz, 2009).
</p>
<p><code>PairAsso</code>: the paired-associate learning model (Riefer &amp; Batchelder,
1988).
</p>
<p><code>proCNI</code>: the CNI model of moral dilemma judgment for proscriptive
norms (Hennig &amp; Huetter, 2020).  The general formula includes the process
dissociation (PD) model (Conway &amp; Gawronski, 2013) as a special case.
</p>
<p><code>prospec</code>: the event-based prospective memory model (Smith &amp; Bayen,
2004).
</p>
<p><code>rmodel</code>: the r-model of recognition heuristic use (Hilbig, Erdfelder,
&amp; Pohl, 2010).
</p>
<p><code>SourceMon</code>: the source-monitoring model (Batchelder &amp; Riefer, 1990).
</p>
<p><code>SR</code>, <code>SR2</code>: the storage-retrieval model for pair clustering
(Batchelder &amp; Riefer, 1986). <code>SR2</code> is the model without singleton
items.
</p>
<p><code>WST</code>: the inference-guessing model with relaxed assumptions (Klauer,
Stahl, &amp; Erdfelder, 2007) for the Wason selection task.
</p>
<p>The intended use of <code>.replicates</code> is to specify the number of
replicates of the model equations, for example, when the same model is
repeatedly applied in several experimental conditions.  Accordingly,
parameter names are augmented by numbers to make them unique.
</p>
<p>Parameter restrictions included in <code>.restr</code> may be of the form
<code>b = r</code> or <code>b = 0.5</code> etc. Depending on the fitting algorithm
employed in <code><a href="#topic+mpt">mpt</a></code> (<code>BFGS</code>, but not <code>EM</code>), mathematical
functions are permissible, for example, <code>b = sqrt(r)</code>.
</p>
<p>The <code>update</code> method is used to add parameter restrictions or replicates
to an existing <code>mptspec</code> object.
</p>


<h3>Value</h3>

<p>An object of class <code>mptspec</code> that serves as input to <code><a href="#topic+mpt">mpt</a></code>
which fits the model to data. It consists of the following components:
</p>
<table>
<tr><td><code>par2prob</code></td>
<td>
<p>a function that takes a vector of parameter values and
computes the response probabilities.</p>
</td></tr>
<tr><td><code>par2deriv</code></td>
<td>
<p>a function that takes a vector of parameter values and
computes first and second derivatives of the model equations.</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>a list containing expressions of the model equations.</p>
</td></tr>
<tr><td><code>deriv</code></td>
<td>
<p>a list containing expressions of the first and second
derivatives of the model equations.</p>
</td></tr>
<tr><td><code>par</code></td>
<td>
<p>a named vector of parameter values.</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>the number of replicates of the model equations.</p>
</td></tr>
<tr><td><code>restr</code></td>
<td>
<p>a list containing expressions of parameter restrictions.</p>
</td></tr>
<tr><td><code>treeid</code></td>
<td>
<p>a factor that identifies each tree.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Batchelder, W.H., &amp; Riefer, D.M. (1986).
The statistical analysis of a model for storage and retrieval processes in
human memory.
<em>British Journal of Mathematical and Statistical Psychology</em>,
<b>39</b>(2), 129&ndash;149.
doi: <a href="https://doi.org/10.1111/j.2044-8317.1986.tb00852.x">10.1111/j.2044-8317.1986.tb00852.x</a>
</p>
<p>Batchelder, W.H., &amp; Riefer, D.M. (1990).
Multinomial processing models of source monitoring.
<em>Psychological Review</em>,
<b>97</b>(4), 548&ndash;564.
doi: <a href="https://doi.org/10.1037/0033-295x.97.4.548">10.1037/0033-295x.97.4.548</a>
</p>
<p>Blackwell, H.R. (1963).
Neural theories of simple visual discriminations.
<em>Journal of the Optical Society of America</em>,
<b>53</b>(1), 129&ndash;160.
doi: <a href="https://doi.org/10.1364/JOSA.53.000129">10.1364/JOSA.53.000129</a>
</p>
<p>Broeder, A., &amp; Schuetz, J. (2009).
Recognition ROCs are curvilinear&ndash;or are they? On premature arguments
against the two-high-threshold model of recognition.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>35</b>(3), 587&ndash;606.
doi: <a href="https://doi.org/10.1037/a0015279">10.1037/a0015279</a>
</p>
<p>Conway, P., &amp; Gawronski, B. (2013).
Deontological and utilitarian inclinations in moral decision making:
A process dissociation approach.
<em>Journal of Personality and Social Psychology</em>,
<b>104</b>(2), 216&ndash;235.
doi: <a href="https://doi.org/10.1037/a0031021">10.1037/a0031021</a>
</p>
<p>Hennig, M., &amp; Huetter, M. (2020).
Revisiting the divide between deontology and utilitarianism in moral
dilemma judgment: A multinomial modeling approach.
<em>Journal of Personality and Social Psychology</em>
<b>118</b>(1), 22&ndash;56.
doi: <a href="https://doi.org/10.1037/pspa0000173">10.1037/pspa0000173</a>
</p>
<p>Hilbig, B.E., Erdfelder, E., &amp; Pohl, R.F. (2010).
One-reason decision-making unveiled: A measurement model of the recognition
heuristic.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>36</b>(1), 123&ndash;134.
doi: <a href="https://doi.org/10.1037/a0017518">10.1037/a0017518</a>
</p>
<p>Klauer, K.C., Stahl, C., &amp; Erdfelder, E. (2007).
The abstract selection task: New data and an almost comprehensive model.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>33</b>(4), 680&ndash;703.
doi: <a href="https://doi.org/10.1037/0278-7393.33.4.680">10.1037/0278-7393.33.4.680</a>
</p>
<p>Riefer, D.M., &amp; Batchelder, W.H. (1988).
Multinomial modeling and the measurement of cognitive processes.
<em>Psychological Review</em>,
<b>95</b>(3), 318&ndash;339.
doi: <a href="https://doi.org/10.1037/0033-295x.95.3.318">10.1037/0033-295x.95.3.318</a>
</p>
<p>Smith, R.E., &amp; Bayen, U.J. (2004).
A multinomial model of event-based prospective memory.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>30</b>(4), 756&ndash;777.
doi: <a href="https://doi.org/10.1037/0278-7393.30.4.756">10.1037/0278-7393.30.4.756</a>
</p>
<p>Snodgrass, J.G., &amp; Corwin, J. (1988).
Pragmatics of measuring recognition memory: Applications to dementia and
amnesia.
<em>Journal of Experimental Psychology: General</em>,
<b>117</b>(1), 34&ndash;50.
doi: <a href="https://doi.org/10.1037/0096-3445.117.1.34">10.1037/0096-3445.117.1.34</a>
</p>
<p>Swets, J. A. (1961).
Is there a sensory threshold?
<em>Science</em>,
<b>134</b>(3473), 168&ndash;177.
doi: <a href="https://doi.org/10.1126/science.134.3473.168">10.1126/science.134.3473.168</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Specify storage-retrieval model for pairs
spec1 &lt;- mptspec(
  c*r,
  (1 - c)*u^2,
  2*(1 - c)*u*(1 - u),
  c*(1 - r) + (1 - c)*(1 - u)^2
)

## Specify storage-retrieval model with parameter restrictions
spec2 &lt;- mptspec(
  c*r,
  (1 - c)*u^2,
  2*(1 - c)*u*(1 - u),
  c*(1 - r) + (1 - c)*(1 - u)^2,
  .restr = list(c = r/2, u = 0.3)
)

## Optional names identifying trees in joint MPT model
spec3 &lt;- mptspec(
      Target.Hit  = r + (1 - r)*b,
      Target.Miss = (1 - r)*(1 - b),
  Distractor.FA   = b,
  Distractor.CR   = 1 - b,
  .replicates = 3,
  .restr = list(r1 = r, r2 = r, r3 = r)
)

## Pre-specified one-high-threshold model
spec4 &lt;- mptspec("1HT")

## Fit to data in Broeder and Schuetz (2009)
m &lt;- mpt(spec4, c(55, 35, 45, 765))

## Working with the mptspec object
spec4$par2prob(c(0.5, 0.1))     # response probabilities
spec4$par2deriv(coef(m))$deriv  # Jacobian matrix at ML estimate

## See data(package = "mpt") for application examples.
</code></pre>

<hr>
<h2 id='plot.mpt'>Diagnostic Plot for MPT Models</h2><span id='topic+plot.mpt'></span><span id='topic+residuals.mpt'></span>

<h3>Description</h3>

<p>Plots MPT residuals against fitted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpt'
plot(x, showNames = TRUE,
     xlab = "Predicted response probabilities", ylab = "Deviance residuals",
     ...)

## S3 method for class 'mpt'
residuals(object, type = c("deviance", "pearson"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mpt_+3A_x">x</code>, <code id="plot.mpt_+3A_object">object</code></td>
<td>
<p>an object of class <code>mpt</code>, typically the result of a
call to <code><a href="#topic+mpt">mpt</a></code>.</p>
</td></tr>
<tr><td><code id="plot.mpt_+3A_shownames">showNames</code></td>
<td>
<p>logical. Should the names of the residuals be plotted?
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.mpt_+3A_xlab">xlab</code>, <code id="plot.mpt_+3A_ylab">ylab</code></td>
<td>
<p>graphical parameters passed to plot.</p>
</td></tr>
<tr><td><code id="plot.mpt_+3A_type">type</code></td>
<td>
<p>the type of residuals which should be returned; the alternatives
are: <code>"deviance"</code> (default) and <code>"pearson"</code>.</p>
</td></tr>
<tr><td><code id="plot.mpt_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The deviance residuals are plotted against the predicted response
probabilities.  If <code>showNames</code> is true, plotting symbols are the
names of the residuals.
</p>


<h3>Value</h3>

<p>For <code>residuals</code>, a named vector of residuals having as many elements as
response categories.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>, <code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compare two constrained MPT models
data(proact)

spec &lt;- mptspec(
  p1*q1*r1,
  p1*q1*(1 - r1),
  p1*(1 - q1)*r1,
  (1 - p1) + p1*(1 - q1)*(1 - r1),

  p2*q2*r2,
  p2*q2*(1 - r2),
  p2*(1 - q2)*r2,
  (1 - p2) + p2*(1 - q2)*(1 - r2),

  p3*q3*r3,
  p3*q3*(1 - r3),
  p3*(1 - q3)*r3,
  (1 - p3) + p3*(1 - q3)*(1 - r3)
)
m1 &lt;- mpt(update(spec, .restr = list(p2=p1, p3=p1)),
          proact[proact$test == 1, ])
m2 &lt;- mpt(update(spec, .restr = list(q2=q1, q3=q1)), m1$y)

par(mfrow = c(1, 2))                 # residuals versus fitted values
plot(m1, main = "p constrained", ylim = c(-3, 3.5))  # good fit
plot(m2, main = "q constrained", ylim = c(-3, 3.5))  # bad fit

sum( resid(m1)^2 )                   # likelihood ratio G2
sum( resid(m1, "pearson")^2 )        # Pearson X2
</code></pre>

<hr>
<h2 id='proact'>Recall Frequencies for DaPolito's Experiment on Proactive Inhibition</h2><span id='topic+proact'></span>

<h3>Description</h3>

<p>In DaPolito's experiment (Greeno, James, DaPolito, &amp; Polson, 1978), 60
subjects were presented with lists of stimulus-response associates to be
learned, followed by a test in which only the stimuli were presented and
the responses had to be recalled.  Stimuli consisted of three-letter
syllables, responses of the numbers from 1 to 30, so list items looked
like, say, ESI-12, JOK-3, MAL-8, etc.  Part of the items had two responses
(A-B, A-C), the control items had only a single correct response.  If the
recall of C responses is poorer than that of control items, then proactive
inhibition has occurred, that is interference with the recall by
information that has been learned earlier.
</p>
<p>Riefer and Batchelder (1988) analyzed only the A-B and A-C items.  They
investigated how repeated A-B presentation affects the B and C recall,
respectively.  The responses were classified into four categories and
pooled across subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(proact)</code></pre>


<h3>Format</h3>

<p>A data frame consisting of five variables:
</p>

<dl>
<dt><code>test</code></dt><dd><p>first or second test.</p>
</dd>
<dt><code>abpres</code></dt><dd><p>the number of A-B presentations.</p>
</dd>
<dt><code>resp</code></dt><dd><p>a factor giving the response category; <code>BC</code>
both B and C responses are correctly recalled, <code>Bc</code> only B is
recalled, <code>bC</code> only C is recalled, <code>bc</code> neither response is
recalled.</p>
</dd>
<dt><code>freq</code></dt><dd><p>the aggregate recall frequencies per condition.</p>
</dd>
<dt><code>treeid</code></dt><dd><p>an identifier for the single trees of the joint
multinomial model.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Greeno, J.G., James, C.T., DaPolito, F, &amp; Polson, P.G. (1978).
<em>Associative learning: A cognitive analysis</em>.
Englewood Cliffs, NJ: Prentice-Hall.
</p>
<p>Riefer, D.M., &amp; Batchelder, W.H. (1988).
Multinomial modeling and the measurement of cognitive processes.
<em>Psychological Review</em>, <b>95</b>(3), 318&ndash;339.
doi: <a href="https://doi.org/10.1037/0033-295x.95.3.318">10.1037/0033-295x.95.3.318</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(proact)

## Testing effects of repeated A-B presentations
spec &lt;- mptspec(
  .BC = p*q*r,
  .Bc = p*q*(1 - r),
  .bC = p*(1 - q)*r,
  .bc = (1 - p) + p*(1 - q)*(1 - r),
  .replicates = 6
)
m1 &lt;- mpt(spec, proact)
m2 &lt;- mpt(update(spec, .restr = list(q2=q1, q3=q1, q5=q4, q6=q4)), proact)
m3 &lt;- mpt(update(spec, .restr = list(r2=r1, r3=r1, r5=r4, r6=r4)), proact)

anova(m2, m1)  # q increases with number of A-B presentations
anova(m3, m1)  # r remains constant
</code></pre>

<hr>
<h2 id='prospecMemory'>Prospective Memory and Task Importance</h2><span id='topic+prospecMemory'></span><span id='topic+PMSmithBayen'></span><span id='topic+PMreplication'></span>

<h3>Description</h3>

<p>Smith and Bayen (2004) tested the performance of 64 participants in an
event-based prospective memory task that was embedded in a color-matching
task.  On each trial, participants were presented with four colored
rectangles followed by a colored word.  Their task was to press a key to
indicate whether the color of the word matched one of the rectangles.
Interspersed among these nontarget words were six target words for which
subjects had to remember to press a special key (prospective memory
response) regardless of the color.  Participants received two different
instruction types either stressing the importance of the color-matching 
(CMI) or of the prospective-memory task (PMI).
</p>
<p>In a replication study, the performance of 72 German-speaking participants
was tested; this study was designed to be similar to Experiment 1 in Smith
and Bayen (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prospecMemory)</code></pre>


<h3>Format</h3>

<p><code>PMSmithBayen</code> A data frame consisting of five variables:
</p>

<dl>
<dt><code>instruction</code></dt><dd><p>instruction type, either color-matching
importance (<code>cmi</code>) or prospective memory importance (<code>pmi</code>).</p>
</dd>
<dt><code>item</code></dt><dd><p>a factor specifying one of four item types: either a
target word that did or did not match the color of the rectangles, or
a nontarget word that did or did not match.</p>
</dd>
<dt><code>resp</code></dt><dd><p>a factor giving the response categories: <code>match</code>,
<code>nonmatch</code>, or the prospective memory response (<code>prospec</code>).</p>
</dd>
<dt><code>freq</code></dt><dd><p>the aggregate response frequencies per condition.</p>
</dd>
<dt><code>treeid</code></dt><dd><p>an identifier for the single trees of the joint
multinomial model.</p>
</dd>
</dl>

<p><code>PMreplication</code> A data frame containing 72 observations of five
variables:
</p>

<dl>
<dt><code>gender</code></dt><dd><p>factor. Participant gender.</p>
</dd>
<dt><code>age</code></dt><dd><p>participant age.</p>
</dd>
<dt><code>instr</code></dt><dd><p>factor. Instruction type.</p>
</dd>
<dt><code>rtdiff</code></dt><dd><p>average response time difference (in milliseconds)
between color-matching and prospective-memory task.</p>
</dd>
<dt><code>y</code></dt><dd><p>a matrix of aggregate response frequencies per
participant. The column names indicate each of twelve response
categories: match, nonmatch, prospective memory response for targets in
matching (<code>tmm</code>, <code>tmn</code>, <code>tmp</code>) or in nonmatching
condition (<code>tnm</code>, <code>tnn</code>, <code>tnp</code>), and again for nontargets
(<code>nmm</code>, <code>nmn</code>, <code>nmp</code> vs. <code>nnm</code>, <code>nnn</code>,
<code>nnp</code>).</p>
</dd>
</dl>



<h3>Source</h3>

<p>Smith, R.E., &amp; Bayen, U.J. (2004).
A multinomial model of event-based prospective memory.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>30</b>(4), 756&ndash;777.
doi: <a href="https://doi.org/10.1037/0278-7393.30.4.756">10.1037/0278-7393.30.4.756</a>
</p>
<p>For the replication study, data were collected at the Department of
Psychology, University of Tuebingen, between December 2018 and January 2019.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Prospective memory model: identifiability
qr(mptspec("prospec",
   .restr = list(M1=M, M2=M))$par2deriv(runif(6))$deriv)$rank
qr(mptspec("prospec",
   .restr = list(M1=M, M2=M, g=.1, c=.5))$par2deriv(runif(4))$deriv)$rank

## Prospective memory model: goodness of fit
data(prospecMemory)
cmi &lt;- PMSmithBayen[PMSmithBayen$instruction == "cmi", ]
m2 &lt;- mpt(mptspec("prospec", .restr = list(M1=M, M2=M, g=.1, c=.5)), cmi)
m1 &lt;- mpt(update(m2$spec, .restr = list(C2=C1)), cmi)
anova(m1, m2)

pmi &lt;- PMSmithBayen[PMSmithBayen$instruction == "pmi", ]
anova(mpt(m1$spec, pmi), mpt(m2$spec, pmi))

## Testing P_cmi = P_pmi and M_cmi = M_pmi

## Smith and Bayen
m2 &lt;- mpt(mptspec("prospec", .replicates = 2,
                  .restr = list(M11=M1, M21=M1, g1=.1, c1=.5,
                                M12=M2, M22=M2, g2=.1, c2=.5)),
          data = PMSmithBayen)
m1 &lt;- mpt(update(m2$spec, .restr = list(P2=P1)), PMSmithBayen)
m0 &lt;- mpt(update(m2$spec, .restr = list(M2=M1)), PMSmithBayen)
anova(m1, m2)
anova(m0, m2)

## Replication
pm.agg &lt;- aggregate(y ~ instr, PMreplication, sum)
y &lt;- as.vector(t(pm.agg[2:1, -1]))

m3 &lt;- mpt(m2$spec, y)
m1 &lt;- mpt(update(m3$spec, .restr = list(P2=P1)), y)
m0 &lt;- mpt(update(m3$spec, .restr = list(M2=M1)), y)
anova(m1, m3)
anova(m0, m3)

par(mfrow = 1:2)
dotchart(coef(m2)[c("C12", "C22", "P2", "M2")], xlim=0:1, xlab="",
  labels=c("C1", "C2", "P", "M"), main="Smith and Bayen (2004, Exp. 1)")
points(coef(m2)[c("C11", "C21", "P1", "M1")], 1:4, pch=16)
legend("bottomleft", c("CMI", "PMI"), pch=c(1, 16), title="Instruction",
       title.adj=1, bty="n")

dotchart(coef(m3)[c("C12", "C22", "P2", "M2")], xlim=0:1, xlab="",
  labels=c("C1", "C2", "P", "M"), main="Replication study")
points(coef(m3)[c("C11", "C21", "P1", "M1")], 1:4, pch=16)
mtext("Parameter estimate (prospective memory model)", side=1,
      line=-2, outer=TRUE)
</code></pre>

<hr>
<h2 id='recogROC'>Recognition Receiver Operating Characteristics</h2><span id='topic+recogROC'></span><span id='topic+ROCBroeder2009'></span><span id='topic+ROCreplication'></span>

<h3>Description</h3>

<p>In a series of experiments, Broeder and Schuetz (2009) tested the shape of
recognition receiver operating characteristics.  Participants studied a list
of items.  In a recognition test, old items intermixed with new ones were
presented, and participants had to classify them as old or new.  The
percentage of old items varied in order to manipulate the response bias.
</p>
<p>Wellingerhof (2019) conducted a replication study that was designed to be
similar to Experiment 3 in Broeder and Schuetz (2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(recogROC)</code></pre>


<h3>Format</h3>

<p><code>ROCBroeder2009</code> A data frame consisting of seven variables:
</p>

<dl>
<dt><code>item</code></dt><dd><p>factor. Target (old) or distractor (new) item.</p>
</dd>
<dt><code>resp</code></dt><dd><p>a factor giving the response category, <code>old</code>
or <code>new</code>.</p>
</dd>
<dt><code>treeid</code></dt><dd><p>an identifier for the single trees of the joint
multinomial model.</p>
</dd>
<dt><code>ptarget1</code>, <code>ptarget3</code></dt><dd><p>percentage of target (old)
items in Experiment 1 and 3, respectively.</p>
</dd>
<dt><code>exp1</code>, <code>exp3</code></dt><dd><p>the aggregate response frequencies.</p>
</dd>
</dl>

<p><code>ROCreplication</code> A data frame containing 48 observations of five
variables:
</p>

<dl>
<dt><code>gender</code></dt><dd><p>factor. Participant gender.</p>
</dd>
<dt><code>age</code></dt><dd><p>participant age.</p>
</dd>
<dt><code>arith</code></dt><dd><p>number of mental-arithmetic problems solved.</p>
</dd>
<dt><code>lexical</code></dt><dd><p>number of correct trials in lexical selection task.</p>
</dd>
<dt><code>y</code></dt><dd><p>a matrix of aggregate response frequencies per
participant. The column names indicate each of 4 x 5 response
categories: <code>h</code>it, <code>m</code>iss, <code>f</code>alse alarm, and
<code>c</code>orrect rejection in the five bias conditions.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Broeder, A., &amp; Schuetz, J. (2009).
Recognition ROCs are curvilinear&ndash;or are they? On premature arguments
against the two-high-threshold model of recognition.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>35</b>(3), 587&ndash;606.
doi: <a href="https://doi.org/10.1037/a0015279">10.1037/a0015279</a>
</p>
<p>Wellingerhof, P. (2019).
<em>Signal detection theory vs. 2-high-threshold model in recognition
memory: A preregistered replication study</em>.
Bachelor thesis. University of Tuebingen, Germany.
<a href="https://osf.io/hvg4p/">https://osf.io/hvg4p/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(recogROC)

## Two-high-threshold model
s &lt;- mptspec("2HT", .replicates = 5,
                    .restr = list(r1=r, r2=r, r3=r, r4=r, r5=r,
                                  d1=d, d2=d, d3=d, d4=d, d5=d))
m1 &lt;- mpt(s, data = ROCBroeder2009, freqvar = "exp3")
m2 &lt;- mpt(s, data = unname(ROCreplication$y))

## Table 4
rbind(Broeder2009 = c(deviance(m1), coef(m1)),
      Replication = c(deviance(m2), coef(m2)))

## Hit rate and false alarm rate
i.hit &lt;- with(ROCBroeder2009, item == "target" &amp; resp == "old")
i.fa  &lt;- with(ROCBroeder2009, item == "distractor" &amp; resp == "old")

hrfa &lt;- data.frame(
   study = rep(c("Broeder2009", "Replication"), each=5),
   obshr = c((m1$y/m1$n)[i.hit], (m2$y/m2$n)[i.hit]),
   obsfa = c((m1$y/m1$n)[i.fa],  (m2$y/m2$n)[i.fa]),
  predhr = c(m1$pcat[i.hit],     m2$pcat[i.hit]),
  predfa = c(m1$pcat[i.fa],      m2$pcat[i.fa])
)

## ROC, Figure 7
plot(obshr ~ obsfa, hrfa[hrfa$study == "Broeder2009", ],
     xlim=0:1, ylim=0:1, pch=16,
     main="Linear recognition ROCs?",
     ylab="Hit rate", xlab="False alarm rate")
abline(0, 1, lty=2)
lines(predhr ~ predfa, hrfa[hrfa$study == "Broeder2009", ])
points(obshr ~ obsfa, hrfa[hrfa$study == "Replication", ], col = "blue")
lines(predhr ~ predfa, hrfa[hrfa$study == "Replication", ],
      col = "blue")
text(0.45, 0.93, "Replication", col = "blue")
text(0.59, 0.82, "Broeder and Schuetz\n(2009, Exp. 3)")
</code></pre>

<hr>
<h2 id='retroact'>Recall Frequencies in Retroactive Inhibition</h2><span id='topic+retroact'></span>

<h3>Description</h3>

<p>Riefer and Batchelder (1988) presented each of 75 participants with either
one, two, three, four, or five successive lists of words (15 subjects per
group).  These words were shown in random order on a computer screen, one
word at a time, at a rate of 5 s per word.  Each list contained 25 words,
consisting of 10 categories (with 2 associate words per category) and five
singletons.  Subjects were given 1.5 min to recall in writing the 25 words
from each individual list.  After all of the lists had been presented, a
final free-recall test was given in which subjects attempted to recall the
words from all of the previous lists.  Subjects were given up to 5 min for
this final written recall.
</p>
<p>The focus here is on the recall of the first-list words during the final
recall task.  The responses were classified into six categories and pooled
across subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(retroact)</code></pre>


<h3>Format</h3>

<p>A data frame consisting of four variables:
</p>

<dl>
<dt><code>lists</code></dt><dd><p>the number of interpolated lists.</p>
</dd>
<dt><code>treeid</code></dt><dd><p>an identifier for the single trees of the joint
multinomial model.</p>
</dd>
<dt><code>resp</code></dt><dd><p>a factor giving the response category; <code>E1</code>
pair is recalled adjacently, <code>E2</code> pair is recalled non-adjacently,
<code>E3</code> one word in a pair is recalled, <code>E4</code> neither word in a
pair is recalled, <code>F1</code> recall of a singleton, <code>F2</code> non-recall
of a singleton.</p>
</dd>
<dt><code>freq</code></dt><dd><p>the aggregate recall frequencies per condition.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Riefer, D.M., &amp; Batchelder, W.H. (1988).
Multinomial modeling and the measurement of cognitive processes.
<em>Psychological Review</em>, <b>95</b>(3), 318&ndash;339.
doi: <a href="https://doi.org/10.1037/0033-295x.95.3.318">10.1037/0033-295x.95.3.318</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(retroact)

## Fitting individual storage-retrieval models per condition
spec &lt;- mptspec(
  c*r,
  (1 - c)*u^2,
  2*(1 - c)*u*(1 - u),
  c*(1 - r) + (1 - c)*(1 - u)^2,
  u,
  1 - u
)
pars &lt;- sapply(0:4,
  function(x) coef(mpt(spec, retroact[retroact$lists == x, ])))

## Figure 3 in Riefer &amp; Batchelder (1988)
plot(pars["c", ] ~ I(0:4), pch=16, type="b", ylim=c(.3, 1),
     xlab="Number of interpolated lists, j",
     ylab="Parameter estimate (Storage-retrieval model)",
     main="Riefer and Batchelder (1988)")
points(pars["r", ] ~ I(0:4), type="b", lty=2)
text(3, .89, expression("Storage of clusters," ~ hat(c)[j]))
text(3, .46, expression("Retrieval of clusters," ~ hat(r)[j]))

## Testing effects of interpolated lists
spec &lt;- mptspec(
  c0*r0,
  (1 - c0)*u0^2,
  2*(1 - c0)*u0*(1 - u0),
  c0*(1 - r0) + (1 - c0)*(1 - u0)^2,
  u0,
  1 - u0,

  c1*r1,
  (1 - c1)*u1^2,
  2*(1 - c1)*u1*(1 - u1),
  c1*(1 - r1) + (1 - c1)*(1 - u1)^2,
  u1,
  1 - u1,

  c2*r2,
  (1 - c2)*u2^2,
  2*(1 - c2)*u2*(1 - u2),
  c2*(1 - r2) + (1 - c2)*(1 - u2)^2,
  u2,
  1 - u2,

  c3*r3,
  (1 - c3)*u3^2,
  2*(1 - c3)*u3*(1 - u3),
  c3*(1 - r3) + (1 - c3)*(1 - u3)^2,
  u3,
  1 - u3,

  c4*r4,
  (1 - c4)*u4^2,
  2*(1 - c4)*u4*(1 - u4),
  c4*(1 - r4) + (1 - c4)*(1 - u4)^2,
  u4,
  1 - u4
)
m1 &lt;- mpt(spec, retroact)
m2 &lt;- mpt(update(spec, .restr=list(r0=r, r1=r, r2=r, r3=r, r4=r)),
          retroact)
m3 &lt;- mpt(update(spec, .restr=list(c0=c, c1=c, c2=c, c3=c, c4=c)),
          retroact)

anova(m2, m1)  # r decreases the more lists have been interpolated
anova(m3, m1)  # c remains constant
</code></pre>

<hr>
<h2 id='selectiontask'>Wason Selection Task (WST) and Helpful Hints</h2><span id='topic+selectiontask'></span><span id='topic+WSTKlauer2007'></span><span id='topic+WSTreplication'></span>

<h3>Description</h3>

<p>In the Wason selection task, a participant is presented with four cards,
each one having a letter side and a number side, e.g., A B 3 4.  The task is
to select the card(s) that have to be turned around in order to test the
rule &quot;If there is an A on the letter side then there is a 3 on the number
side.&quot;  Klauer, Stahl, and Erdfelder (2007) report a series of experiments
to test their WST model using the aggregate frequencies of the 16 possible
response patterns.
</p>
<p>Bauder (2020) conducted a replication study that was designed to be
similar to Experiment 1 in Klauer et al. (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(selectiontask)</code></pre>


<h3>Format</h3>

<p><code>WSTKlauer2007</code> A data frame consisting of four variables:
</p>

<dl>
<dt><code>group</code></dt><dd><p>factor. The control group (<code>CG</code>) received
standard instructions, the experimental group (<code>EG</code>) got
additional helpful hints.</p>
</dd>
<dt><code>pattern</code></dt><dd><p>character. Response pattern indicating which card(s)
were selected (<code>1</code>) or not selected (<code>0</code>).</p>
</dd>
<dt><code>exp1</code>, <code>exp2</code></dt><dd><p>the aggregate response frequencies for
Experiment 1 and 2, respectively.</p>
</dd>
</dl>

<p><code>WSTreplication</code> A data frame containing 1118 observations of eight
variables:
</p>

<dl>
<dt><code>status</code></dt><dd><p>factor. Was the participant excluded?</p>
</dd>
<dt><code>group</code></dt><dd><p>factor. The experimental group.</p>
</dd>
<dt><code>gender</code></dt><dd><p>factor. Participant gender.</p>
</dd>
<dt><code>age</code></dt><dd><p>participant age.</p>
</dd>
<dt><code>education</code></dt><dd><p>years of education.</p>
</dd>
<dt><code>logic</code></dt><dd><p>factor. Familiarity with formal logic.</p>
</dd>
<dt><code>time</code></dt><dd><p>seconds spent on the web page.</p>
</dd>
<dt><code>y</code></dt><dd><p>a participant by response pattern indicator matrix.</p>
</dd>
</dl>



<h3>Note</h3>

<p>In the original analyses (Klauer et al., 2007), a constant of one was added
to all frequencies.
</p>


<h3>Source</h3>

<p>Klauer, K.C., Stahl, C., &amp; Erdfelder, E. (2007).
The abstract selection task: New data and an almost comprehensive model.
<em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>,
<b>33</b>(4), 680&ndash;703.
doi: <a href="https://doi.org/10.1037/0278-7393.33.4.680">10.1037/0278-7393.33.4.680</a>
</p>
<p>Bauder, D. (2020).
<em>Die Modellierung der abstrakten Auswahlaufgabe von Wason - eine
Replikationsstudie</em>.
Bachelor thesis. University of Tuebingen, Germany.
<a href="https://osf.io/3z7ux/">https://osf.io/3z7ux/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(selectiontask)

## Inference-guessing model with relaxed assumptions
s &lt;- mptspec("WST", .replicates = 2)
m1 &lt;- mpt(s, data = WSTKlauer2007$exp1, method = "EM")

## Inference-guessing model
m2 &lt;- mpt(update(s, .restr = list(sf1=s1, sb1=s1, sfb1=s1,
                                  sf2=s2, sb2=s2, sfb2=s2)),
          data = m1$y, method = "EM")

## Effect of hint on i parameter (Exp. 1)
m3 &lt;- mpt(update(m2$spec, .restr = list(i2=i1)), data = m1$y,
          method = "EM")

## Independence model
m4 &lt;- mpt(update(m2$spec,
                 .restr = list(a1=0, c1=0, x1=0, d1=0, s1=0, i1=0,
                               a2=0, c2=0, x2=0, d2=0, s2=0, i2=0)),
          data = m1$y, method = "EM")

anova(m4, m3, m2, m1)
plogis(confint(m2))
AIC(m2)
BIC(m2)  # BIC w/number of non-redundant response categories
AIC(m2, k = log(sum(m2$y)))  # BIC w/total number of data points

## Effect of hint on c parameter (Exp. 2)
m5 &lt;- mpt(m2$spec, data = WSTKlauer2007$exp2, method = "EM")
m6 &lt;- mpt(update(m5$spec, .restr = list(c2=c1)), data = m5$y,
          method = "EM")
anova(m6, m5)

## Replication of Exp. 1
wst.agg &lt;- aggregate(y ~ group, WSTreplication,
                     subset = status == "select", sum)
y &lt;- as.vector(t(wst.agg[, -1]))

set.seed(1503)
m7 &lt;- mpt(m2$spec, data = y, start = runif(20), method = "EM")

idx &lt;- c("P", "p", "Q", "q", "a", "c", "x", "d", "s", "i")
par(mfrow = 1:2)
dotchart(coef(m2)[paste0(idx, 1)], xlim=c(0, 1), labels=idx,
         main="Klauer et al. (2007, Exp. 1)", xlab="")
points(coef(m2)[paste0(idx, 2)], 1:10, pch=16)
legend(0, 11, c("standard", "hints"), pch=c(1, 16),
       title="Instruction", bty="n")
dotchart(coef(m7)[paste0(idx, 1)], xlim=c(0, 1), labels=idx,
         main="Replication study", xlab="")
points(coef(m7)[paste0(idx, 2)], 1:10, pch=16)
mtext("Parameter estimate (inference-guessing model)", side=1,
      outer=TRUE, line=-2)
</code></pre>

<hr>
<h2 id='simulate.mpt'>Simulate Responses from MPT Models</h2><span id='topic+simulate.mpt'></span>

<h3>Description</h3>

<p>Simulates responses from the distribution corresponding to a fitted
<code>mpt</code> model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpt'
simulate(object, nsim, seed, pool = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate.mpt_+3A_object">object</code></td>
<td>
<p>an object of class <code>mpt</code>, typically the result of a
call to <code><a href="#topic+mpt">mpt</a></code>.</p>
</td></tr>
<tr><td><code id="simulate.mpt_+3A_nsim">nsim</code>, <code id="simulate.mpt_+3A_seed">seed</code></td>
<td>
<p>currently not used.</p>
</td></tr>
<tr><td><code id="simulate.mpt_+3A_pool">pool</code></td>
<td>
<p>logical, if <code>TRUE</code> (default), pooled responses (summed
across respondents) are returned.</p>
</td></tr>
<tr><td><code id="simulate.mpt_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
None are used in this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Responses are simulated by (repeatedly) applying <code><a href="stats.html#topic+rmultinom">rmultinom</a></code>
with sizes taken from the original sample and probabilities computed from
the model object.
</p>


<h3>Value</h3>

<p>A named vector of (pooled) responses. Names identify the tree from which
responses were simulated.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>, <code><a href="stats.html#topic+rmultinom">rmultinom</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(retroact)
 
m &lt;- mpt(mptspec(
  c*r,
  (1 - c)*u^2,
  2*(1 - c)*u*(1 - u),
  c*(1 - r) + (1 - c)*(1 - u)^2,
  u,
  1 - u
), retroact[retroact$lists == 1, ])

simulate(m)

## Parametric bootstrap of goodness-of-fit test
LR.stat &lt;- replicate(200, deviance(mpt(m$spec, simulate(m))))

hist(LR.stat, border="white", freq=FALSE, breaks=20,
     main="Parametric bootstrap")
curve(dchisq(x, df=1), add=TRUE)
abline(v=deviance(m), lty=2)
</code></pre>

<hr>
<h2 id='valence'>World Valence and Source Memory for Vertical Position</h2><span id='topic+valence'></span>

<h3>Description</h3>

<p>Sixty-four participants studied words with positive, negative, or neutral
valence displayed at the top or bottom part of a computer screen.  Later,
these words were presented intermixed with new words, and participants had
to classify them as &quot;top,&quot; &quot;bottom,&quot; or &quot;new.&quot;  It was of interest if memory
is improved in congruent trials, in which word valence and vertical
position match (positive-top, negative-bottom), as opposed to incongruent
trials.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(valence)</code></pre>


<h3>Format</h3>

<p>A data frame consisting of five components:
</p>

<dl>
<dt><code>id</code></dt><dd><p>factor. Participant ID.</p>
</dd>
<dt><code>gender</code></dt><dd><p>factor. Participant gender.</p>
</dd>
<dt><code>age</code></dt><dd><p>participant age.</p>
</dd>
<dt><code>condition</code></dt><dd><p>factor. In <code>congruent</code> trials, positive words
were presented at the top, negative words at the bottom, and vice versa
for <code>incongruent</code> trials.</p>
</dd>
<dt><code>y</code></dt><dd><p>a matrix of aggregate response frequencies per participant
and condition. The column names indicate each of nine response
categories, for example, <code>top.bottom</code> means that words were
presented at the top, but participant responded &quot;bottom.&quot;</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data were collected at the Department of Psychology, University of
Tuebingen, in 2010.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(valence)

## Fit source-monitoring model to subsets of data
spec &lt;- mptspec("SourceMon", .restr=list(d1=d, d2=d))
names(spec$prob) &lt;- colnames(valence$y)

mpt(spec, valence[valence$condition == "congruent" &amp;
                  valence$gender == "female", "y"])
mpt(spec, valence[valence$condition == "incongruent" &amp;
                  valence$gender == "female", "y"])

## Test the congruency effect
val.agg &lt;- aggregate(y ~ gender + condition, valence, sum)
y &lt;- as.vector(t(val.agg[, -(1:2)]))

spec &lt;- mptspec("SourceMon", .replicates=4,
                .restr=list(d11=d1, d21=d1, d12=d2, d22=d2,
                            d13=d3, d23=d3, d14=d4, d24=d4))
m1 &lt;- mpt(spec, y)
m2 &lt;- mpt(update(spec, .restr=list(d1=d.f, d3=d.f, d2=d.m, d4=d.m)), y)
anova(m2, m1)  # better discrimination in congruent trials

## Plot parameter estimates
mat &lt;- matrix(coef(m1), 5)
rownames(mat) &lt;- c("D1", "d",  "g",  "b",  "D2")
mat &lt;- mat[c("D1", "D2", "d", "b", "g"), ]
matplot(mat, type="b", axes=FALSE, ylab="MPT model parameter estimate",
        main="Word valence and source monitoring", ylim=0:1, pch=1:4)
axis(1, 1:5, rownames(mat)); axis(2)
legend("bottomleft", c("female, congruent", "male, congruent",
       "female, incongruent", "male, incongruent"), pch=1:4, bty="n")
</code></pre>

<hr>
<h2 id='vcov.mpt'>Covariance and Information Matrix for MPT Models</h2><span id='topic+vcov.mpt'></span>

<h3>Description</h3>

<p>Returns the covariance matrix or the Fisher information matrix of a fitted
<code>mpt</code> model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mpt'
vcov(object, logit = FALSE, what = c("vcov", "fisher"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov.mpt_+3A_object">object</code></td>
<td>
<p>an object of class <code>mpt</code>, typically the result of a
call to <code><a href="#topic+mpt">mpt</a></code>.</p>
</td></tr>
<tr><td><code id="vcov.mpt_+3A_logit">logit</code></td>
<td>
<p>logical. Switch between logit and probability scale.</p>
</td></tr>
<tr><td><code id="vcov.mpt_+3A_what">what</code></td>
<td>
<p>character. If <code>vcov</code> (default), the covariance matrix is
returned; if <code>fisher</code>, the Fisher information matrix is returned.</p>
</td></tr>
<tr><td><code id="vcov.mpt_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
None are used in this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>logit</code> is false, the covariance matrix is based on the observed
Fisher information matrix of the ML estimator on the probability scale.
This is equivalent to the equations for the covariance matrix given in Hu
and Batchelder (1994) and Hu (1999), although the implementation here is
different.
</p>
<p>If <code>logit</code> is true, the covariance matrix and the estimated information
matrix (Elandt-Johnson, 1971) of the ML estimator on the logit scale are
obtained by the multivariate delta method (Bishop, Fienberg, and Holland,
1975; Grizzle, Starmer, and Koch, 1969).
</p>


<h3>Value</h3>

<p>A (named) square matrix.
</p>


<h3>References</h3>

<p>Bishop, Y.M.M., Fienberg, S.E., &amp; Holland, P.W. (1975).
<em>Discrete multivariate analysis: Theory and practice</em>.
Cambridge: MIT Press.
</p>
<p>Elandt-Johnson, R. C. (1971).
<em>Probability models and statistical methods in genetics</em>.
New York: Wiley.
</p>
<p>Grizzle, J.E., Starmer, C.F., &amp; Koch, G. (1969).
Analysis of categorical data by linear models.
<em>Biometrics</em>,
<b>25</b>(3), 489&ndash;504.
doi: <a href="https://doi.org/10.2307/2528901">10.2307/2528901</a>
</p>
<p>Hu, X. (1999).
Multinomial processing tree models: An implementation.
<em>Behavior Research Methods, Instruments, &amp; Computers</em>,
<b>31</b>(4), 689&ndash;695.
doi: <a href="https://doi.org/10.3758/BF03200747">10.3758/BF03200747</a>
</p>
<p>Hu, X., &amp; Batchelder, W.H. (1994).
The statistical analysis of general processing tree models with the EM
algorithm.
<em>Psychometrika</em>,
<b>59</b>(1), 21&ndash;47.
doi: <a href="https://doi.org/10.1007/bf02294263">10.1007/bf02294263</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mpt">mpt</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(retroact)
m &lt;- mpt(mptspec("SR"), retroact[retroact$lists == 1, ])

vcov(m)                   # covariance matrix (probability scale)
vcov(m, logit = TRUE)     # covariance matrix (logit scale)
vcov(m, what = "fisher")  # Fisher information
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
