<!DOCTYPE html><html><head><title>Help for package semEff</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {semEff}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#semEff-package'><p>semEff: Automatic Calculation of Effects for Piecewise Structural Equation Models</p></a></li>
<li><a href='#avgEst'><p>Weighted Average of Model Estimates</p></a></li>
<li><a href='#bootCI'><p>Bootstrap Confidence Intervals</p></a></li>
<li><a href='#bootEff'><p>Bootstrap Effects</p></a></li>
<li><a href='#getData'><p>Get Model Data</p></a></li>
<li><a href='#getEff'><p>Get SEM Effects</p></a></li>
<li><a href='#getX'><p>Get Model Design Matrix</p></a></li>
<li><a href='#getY'><p>Get Model Response Variable</p></a></li>
<li><a href='#glt'><p>Generalised Link Transformation</p></a></li>
<li><a href='#Object.Type'><p>Object Types</p></a></li>
<li><a href='#Param.Type'><p>Parameter Types</p></a></li>
<li><a href='#predEff'><p>Predict Effects</p></a></li>
<li><a href='#print.bootCI'><p>Print <code>"bootCI"</code> Objects</p></a></li>
<li><a href='#print.semEff'><p>Print <code>"semEff"</code> Objects</p></a></li>
<li><a href='#pSapply'><p>Parallel <code>sapply()</code></p></a></li>
<li><a href='#R2'><p>R-squared</p></a></li>
<li><a href='#rMapply'><p>Recursive <code>mapply()</code></p></a></li>
<li><a href='#RVIF'><p>Root Variance Inflation Factors</p></a></li>
<li><a href='#sdW'><p>Weighted Standard Deviation</p></a></li>
<li><a href='#semEff'><p>SEM Effects</p></a></li>
<li><a href='#shipley'><p>Simulated Data from Shipley (2009)</p></a></li>
<li><a href='#shipley.growth'><p>Candidate Model Set from Shipley 'Growth' Model</p></a></li>
<li><a href='#shipley.sem'><p>Hypothesised SEM from Shipley (2009)</p></a></li>
<li><a href='#shipley.sem.boot'><p>Bootstrapped Estimates for Shipley SEM</p></a></li>
<li><a href='#shipley.sem.eff'><p>Effects for Shipley SEM</p></a></li>
<li><a href='#stdEff'><p>Standardised Effects</p></a></li>
<li><a href='#summary.semEff'><p>Summarise SEM Effects</p></a></li>
<li><a href='#varW'><p>Weighted Variance</p></a></li>
<li><a href='#VIF'><p>Generalised Variance Inflation Factors</p></a></li>
<li><a href='#xNam'><p>Get Model Term Names</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Automatic Calculation of Effects for Piecewise Structural
Equation Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Automatically calculate direct, indirect, and total effects for 
    piecewise structural equation models, comprising lists of fitted models 
    representing structured equations (Lefcheck, 2016 &lt;<a href="https://doi.org/10%2Ff8s8rb">doi:10/f8s8rb</a>&gt;). 
    Confidence intervals are provided via bootstrapping.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://murphymv.github.io/semEff/">https://murphymv.github.io/semEff/</a>,
<a href="https://github.com/murphymv/semEff">https://github.com/murphymv/semEff</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/murphymv/semEff/issues">https://github.com/murphymv/semEff/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>boot, gsl, lme4, parallel, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, knitr, markdown, piecewiseSEM, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>xz</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-20 21:45:10 UTC; murph</td>
</tr>
<tr>
<td>Author:</td>
<td>Mark V. Murphy [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mark V. Murphy &lt;murphymv@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-22 07:50:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='semEff-package'>semEff: Automatic Calculation of Effects for Piecewise Structural Equation Models</h2><span id='topic+semEff-package'></span><span id='topic+_PACKAGE'></span>

<h3>Description</h3>

<p>Automatically calculate direct, indirect, and total effects for piecewise structural equation models, comprising lists of fitted models representing structured equations (Lefcheck, 2016 <a href="https://doi.org/10/f8s8rb">doi:10/f8s8rb</a>). Confidence intervals are provided via bootstrapping.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Mark V. Murphy <a href="mailto:murphymv@gmail.com">murphymv@gmail.com</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://murphymv.github.io/semEff/">https://murphymv.github.io/semEff/</a>
</p>
</li>
<li> <p><a href="https://github.com/murphymv/semEff">https://github.com/murphymv/semEff</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/murphymv/semEff/issues">https://github.com/murphymv/semEff/issues</a>
</p>
</li></ul>


<hr>
<h2 id='avgEst'>Weighted Average of Model Estimates</h2><span id='topic+avgEst'></span>

<h3>Description</h3>

<p>Calculate a weighted average of model estimates (e.g. effects,
fitted values, residuals) for a set of models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avgEst(est, weights = "equal", est.names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="avgEst_+3A_est">est</code></td>
<td>
<p>A list or nested list of numeric vectors, comprising the model
estimates. In the latter case, these should correspond to estimates for
candidate models for each of a set of different response variables.</p>
</td></tr>
<tr><td><code id="avgEst_+3A_weights">weights</code></td>
<td>
<p>An optional numeric vector of weights to use for model
averaging, or a named list of such vectors. The former should be supplied
when <code>est</code> is a list, and the latter when it is a nested list (with
matching list names). If <code>weights = "equal"</code> (default), a simple average is
calculated instead.</p>
</td></tr>
<tr><td><code id="avgEst_+3A_est.names">est.names</code></td>
<td>
<p>An optional vector of names used to extract and/or sort
estimates from the output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used to calculate a weighted average of model
estimates such as effects, fitted values, or residuals, where models are
typically competing candidate models fit to the same response variable.
Weights are typically a 'weight of evidence' type metric such as Akaike
model weights (Burnham &amp; Anderson, 2002; Burnham et al., 2011), which can
be conveniently calculated in <em>R</em> using packages such as
<a href="https://cran.r-project.org/package=MuMIn">MuMIn</a> or
<a href="https://cran.r-project.org/package=AICcmodavg">AICcmodavg</a>. However,
numeric weights of any sort can be used. If none are supplied, a simple
average is calculated instead.
</p>
<p>Averaging is performed via the 'full'/'zero' rather than
'subset'/'conditional'/'natural' method, meaning that zero is substituted
for estimates for any 'missing' parameters (e.g. effects) prior to
calculations. This provides a form of shrinkage and thus reduces <a href="https://stackoverflow.com/questions/53055050/predicted-values-with-mumin-throwing-error-when-full-false">estimate bias</a>
(Burnham &amp; Anderson, 2002; Grueber et al., 2011).
</p>


<h3>Value</h3>

<p>A numeric vector of the model-averaged estimates, or a list of such
vectors.
</p>


<h3>References</h3>

<p>Burnham, K. P., &amp; Anderson, D. R. (2002). <em>Model Selection and
Multimodel Inference: A Practical Information-Theoretic Approach</em> (2nd
ed.). Springer-Verlag. <a href="https://link.springer.com/book/10.1007/b97636">https://link.springer.com/book/10.1007/b97636</a>
</p>
<p>Burnham, K. P., Anderson, D. R., &amp; Huyvaert, K. P. (2011). AIC model
selection and multimodel inference in behavioral ecology: some background,
observations, and comparisons. <em>Behavioral Ecology and Sociobiology</em>,
<em>65</em>(1), 23-35. <a href="https://doi.org/10/c4mrns">doi:10/c4mrns</a>
</p>
<p>Dormann, C. F., Calabrese, J. M., Guillera‐Arroita, G., Matechou, E., Bahn,
V., Bartoń, K., Beale, C. M., Ciuti, S., Elith, J., Gerstner, K., Guelat,
J., Keil, P., Lahoz‐Monfort, J. J., Pollock, L. J., Reineking, B., Roberts,
D. R., Schröder, B., Thuiller, W., Warton, D. I., … Hartig, F. (2018).
Model averaging in ecology: A review of Bayesian, information-theoretic,
and tactical approaches for predictive inference. <em>Ecological Monographs</em>,
<em>88</em>(4), 485–504. <a href="https://doi.org/10/gfgwrv">doi:10/gfgwrv</a>
</p>
<p>Grueber, C. E., Nakagawa, S., Laws, R. J., &amp; Jamieson, I. G. (2011).
Multimodel inference in ecology and evolution: challenges and solutions.
<em>Journal of Evolutionary Biology</em>, <em>24</em>(4), 699-711. <a href="https://doi.org/10/b7b5d4">doi:10/b7b5d4</a>
</p>
<p>Walker, J. A. (2019). Model-averaged regression coefficients have a
straightforward interpretation using causal conditioning. <em>BioRxiv</em>,
133785. <a href="https://doi.org/10/c8zt">doi:10/c8zt</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Model-averaged effects (coefficients)
m &lt;- shipley.growth  # candidate models
e &lt;- lapply(m, function(i) coef(summary(i))[, 1])
avgEst(e)

# Using weights
w &lt;- runif(length(e), 0, 1)
avgEst(e, w)

# Model-averaged predictions
f &lt;- lapply(m, predict)
head(avgEst(f, w))
</code></pre>

<hr>
<h2 id='bootCI'>Bootstrap Confidence Intervals</h2><span id='topic+bootCI'></span>

<h3>Description</h3>

<p>Calculate confidence intervals from bootstrapped model effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootCI(mod, conf = 0.95, type = "bca", digits = 3, bci.arg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootCI_+3A_mod">mod</code></td>
<td>
<p>A fitted model object. Alternatively, a boot object (class
<code>"boot"</code>), containing bootstrapped model effects. Can also be a list or
nested list of such objects.</p>
</td></tr>
<tr><td><code id="bootCI_+3A_conf">conf</code></td>
<td>
<p>A numeric value specifying the confidence level for the
intervals.</p>
</td></tr>
<tr><td><code id="bootCI_+3A_type">type</code></td>
<td>
<p>The type of confidence interval to return (defaults to <code>"bca"</code> –
see Details). See <code><a href="boot.html#topic+boot.ci">boot.ci()</a></code> for further options.</p>
</td></tr>
<tr><td><code id="bootCI_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits to return for numeric values.</p>
</td></tr>
<tr><td><code id="bootCI_+3A_bci.arg">bci.arg</code></td>
<td>
<p>A named list of any additional arguments to <code><a href="boot.html#topic+boot.ci">boot.ci()</a></code>,
excepting argument <code>index</code>.</p>
</td></tr>
<tr><td><code id="bootCI_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="#topic+bootEff">bootEff()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>bootCI()</code> uses <code><a href="boot.html#topic+boot.ci">boot::boot.ci()</a></code> to calculate confidence intervals
of the specified type and level calculated from bootstrapped model effects.
If a model or models is supplied, bootstrapping will first be performed via
<code><a href="#topic+bootEff">bootEff()</a></code>.
</p>
<p>Nonparametric bias-corrected and accelerated confidence intervals (BC<em>a</em>;
Efron, 1987) are calculated by default, which should provide the most
accurate coverage across a range of bootstrap sampling distributions (Puth
et al., 2015). They will, however, be
<a href="https://stackoverflow.com/questions/7588388/adjusted-bootstrap-confidence-intervals-bca-with-parametric-bootstrap-in-boot">inappropriate</a>
for parametric resampling – in which case the default will be set to the
bootstrap percentile method instead (<code>"perc"</code>).
</p>
<p>Effects and confidence intervals are returned in a summary table, along
with the bootstrap standard errors (standard deviations of the samples) and
the bootstrap biases (sample means minus original estimates). Effects for
which the confidence intervals do not contain zero are highlighted with a
star (i.e. 'significant' at the <code>conf</code> level).
</p>


<h3>Value</h3>

<p>A summary table of the effects and bootstrapped confidence intervals
(data frame), or a list or nested list of same.
</p>


<h3>Note</h3>

<p>All bootstrapped confidence intervals will tend to underestimate the
true nominal coverage to some extent when sample size is small (Chernick &amp;
Labudde, 2009), so the appropriate caution should be exercised in
interpretation in such cases. Comparison of different interval types may be
informative. For example, normal-theory based intervals may outperform
bootstrap percentile methods when n &lt; 34 (Hesterberg, 2015). Ultimately
however, the bootstrap is <a href="https://stats.stackexchange.com/questions/112147/can-bootstrap-be-seen-as-a-cure-for-the-small-sample-size">not a solution to small sample size</a>.
</p>


<h3>References</h3>

<p>Chernick, M. R., &amp; Labudde, R. A. (2009). Revisiting Qualms about
Bootstrap Confidence Intervals. <em>American Journal of Mathematical and
Management Sciences</em>, <em>29</em>(3–4), 437–456. <a href="https://doi.org/10/c8zv">doi:10/c8zv</a>
</p>
<p>Efron, B. (1987). Better Bootstrap Confidence Intervals. <em>Journal of the
American Statistical Association</em>, <em>82</em>(397), 171–185. <a href="https://doi.org/10/gfww2z">doi:10/gfww2z</a>
</p>
<p>Hesterberg, T. C. (2015). What Teachers Should Know About the Bootstrap:
Resampling in the Undergraduate Statistics Curriculum. <em>The American
Statistician</em>, <em>69</em>(4), 371–386. <a href="https://doi.org/10/gd85v5">doi:10/gd85v5</a>
</p>
<p>Puth, M.-T., Neuhäuser, M., &amp; Ruxton, G. D. (2015). On the variety of
methods for calculating confidence intervals by bootstrapping. <em>Journal of
Animal Ecology</em>, <em>84</em>(4), 892–897. <a href="https://doi.org/10/f8n9rq">doi:10/f8n9rq</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># CIs calculated from bootstrapped SEM
(shipley.sem.ci &lt;- bootCI(shipley.sem.boot))

# From original SEM (models)
# (not typically recommended – better to use saved boot objects)
# system.time(
#   shipley.sem.ci &lt;- bootCI(shipley.sem, R = 1000, seed = 13,
#                            ran.eff = "site")
# )
</code></pre>

<hr>
<h2 id='bootEff'>Bootstrap Effects</h2><span id='topic+bootEff'></span>

<h3>Description</h3>

<p>Bootstrap model effects (standardised coefficients) and optional
SEM correlated errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootEff(
  mod,
  R,
  seed = NULL,
  type = c("nonparametric", "parametric", "semiparametric"),
  ran.eff = NULL,
  cor.err = NULL,
  catch.err = TRUE,
  parallel = c("snow", "multicore", "no"),
  ncpus = NULL,
  cl = NULL,
  bM.arg = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootEff_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.
Alternatively, a <code>"psem"</code> object from
<a href="https://rdrr.io/cran/piecewiseSEM/man/psem.html"><code>piecewiseSEM::psem()</code></a>.
If model lists are unnamed, response variable names will be used.</p>
</td></tr>
<tr><td><code id="bootEff_+3A_r">R</code></td>
<td>
<p>Number of bootstrap resamples to generate.</p>
</td></tr>
<tr><td><code id="bootEff_+3A_seed">seed</code></td>
<td>
<p>Seed for the random number generator. If not provided, a random
five-digit integer is used (see Details).</p>
</td></tr>
<tr><td><code id="bootEff_+3A_type">type</code></td>
<td>
<p>The type of bootstrapping to perform. Can be <code>"nonparametric"</code>
(default), <code>"parametric"</code>, or <code>"semiparametric"</code> (the last two currently
only for mixed models, via <code><a href="lme4.html#topic+bootMer">bootMer()</a></code>).</p>
</td></tr>
<tr><td><code id="bootEff_+3A_ran.eff">ran.eff</code></td>
<td>
<p>For nonparametric bootstrapping of mixed models, the name of
the (highest-level) random effect to resample (see Details).</p>
</td></tr>
<tr><td><code id="bootEff_+3A_cor.err">cor.err</code></td>
<td>
<p>Optional, names of SEM correlated errors to be bootstrapped
(ignored if <code>mod</code> is a <code>"psem"</code> object). Should be of the form: <code>c("var1 ~~ var2", "var3 ~~ var4", ...)</code> (spaces optional), using model/response
variable names.</p>
</td></tr>
<tr><td><code id="bootEff_+3A_catch.err">catch.err</code></td>
<td>
<p>Logical, should errors generated during model fitting or
estimation be caught and <code>NA</code> returned for estimates? If <code>FALSE</code>, any such
errors will cause the function to exit.</p>
</td></tr>
<tr><td><code id="bootEff_+3A_parallel">parallel</code></td>
<td>
<p>The type of parallel processing to use. Can be one of
<code>"snow"</code>, <code>"multicore"</code>, or <code>"no"</code> (for none).</p>
</td></tr>
<tr><td><code id="bootEff_+3A_ncpus">ncpus</code></td>
<td>
<p>Number of system cores to use for parallel processing. If <code>NULL</code>
(default), all available cores are used.</p>
</td></tr>
<tr><td><code id="bootEff_+3A_cl">cl</code></td>
<td>
<p>Optional cluster to use if <code>parallel = "snow"</code>. If <code>NULL</code>
(default), a local cluster is created using the specified number of cores.</p>
</td></tr>
<tr><td><code id="bootEff_+3A_bm.arg">bM.arg</code></td>
<td>
<p>A named list of any additional arguments to <code><a href="lme4.html#topic+bootMer">bootMer()</a></code>.</p>
</td></tr>
<tr><td><code id="bootEff_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="#topic+stdEff">stdEff()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>bootEff()</code> uses <code><a href="boot.html#topic+boot">boot::boot()</a></code> (primarily) to bootstrap
standardised effects from a fitted model or list of models (calculated
using <code><a href="#topic+stdEff">stdEff()</a></code>). Bootstrapping is typically nonparametric, i.e. model
effects are calculated from data where the rows have been randomly sampled
with replacement. 10,000 such resamples should provide accurate coverage
for confidence intervals in most situations, with fewer sufficing in some
cases. To ensure that data is resampled in the same way across individual
bootstrap operations within the same run (e.g. models in a list), the same
seed is set per operation, with the value saved as an attribute to the
matrix of bootstrapped values (for reproducibility). The seed can either be
user-supplied or a randomly-generated five-digit number (default), and is
always re-initialised on exit (i.e. <code>set.seed(NULL)</code>).
</p>
<p>Where <code>weights</code> are specified, bootstrapped effects will be a weighted
average across the set of candidate models for each response variable,
calculated after each model is first refit to the resampled dataset
(specifying <code>weights = "equal"</code> will use a simple average instead – see
<code><a href="#topic+avgEst">avgEst()</a></code>). If no weights are specified and <code>mod</code> is a nested list of
models, the function will throw an error, as it will be expecting weights
for a presumed model averaging scenario. If instead the user wishes to
bootstrap each individual model, they should recursively apply the function
using <code><a href="#topic+rMapply">rMapply()</a></code> (remember to set a seed).
</p>
<p>Where names of response variables with correlated errors are specified to
<code>cor.err</code>, the function will also return bootstrapped Pearson correlated
errors (weighted residuals) for those models. If <code>weights</code> are supplied and
<code>mod</code> is a nested list, residuals will first be averaged across candidate
models. If any two models (or candidate sets) with correlated errors were
fit to different subsets of data observations, both models/sets are first
refit to data containing only the observations in common.
</p>
<p>For nonparametric bootstrapping of mixed models, resampling should occur at
the group-level, as individual observations are not independent. The name
of the random effect to resample must be supplied to <code>ran.eff</code>. For nested
random effects, this should be the highest-level group (Davison &amp; Hinkley,
1997; Ren et al., 2010). This form of resampling will result in datasets of
different sizes if observations are unbalanced across groups; however this
should not generally be an issue, as the number of independent units
(groups), and hence the 'degrees of freedom', remains
<a href="https://stats.stackexchange.com/questions/46965/bootstrapping-unbalanced-clustered-data-non-parametric-bootstrap">unchanged</a>.
</p>
<p>For mixed models with <a href="https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified">non-nested random effects</a>,
nonparametric resampling will not be appropriate. In these cases,
parametric or semiparametric bootstrapping can be performed instead via
<code><a href="lme4.html#topic+bootMer">lme4::bootMer()</a></code> (with additional arguments passed to that function as
necessary). NOTE: As <code><a href="lme4.html#topic+bootMer">bootMer()</a></code> takes only a fitted model as its first
argument (i.e. no lists), any model averaging is calculated 'post-hoc'
using the estimates in boot objects for each candidate model, rather than
during the bootstrapping process itself (i.e. the default procedure via
<code><a href="boot.html#topic+boot">boot()</a></code>). Results are then returned in a new boot object for each response
variable or correlated error estimate.
</p>
<p>If supplied a list containing both mixed and non-mixed models, <code><a href="#topic+bootEff">bootEff()</a></code>
with nonparametric bootstrapping will still work and will treat all models
as mixed models for resampling (with a warning). This is likely a
relatively rare scenario, but may occur where the user decides that
non-mixed models perform similarly and/or cause less fitting issues than
their mixed counterparts for at least some response variables (e.g. where
random effect variance estimates are at or near zero). The data will be
resampled on the supplied random effect for all models. If nonparametric
bootstrapping is not used in this scenario however, an error will occur, as
<code><a href="lme4.html#topic+bootMer">bootMer()</a></code> will only accept mixed models.
</p>
<p>Parallel processing is used by default via the <a href="parallel.html#topic+parallel">parallel</a> package and
option <code>parallel = "snow"</code> (and is generally recommended), but users can
specify the type of parallel processing to use, or none. If <code>"snow"</code>, a
cluster of workers is created using <code><a href="parallel.html#topic+makeCluster">makeCluster()</a></code>, and the user can
specify the number of system cores to incorporate in the cluster (defaults
to all available). <code><a href="#topic+bootEff">bootEff()</a></code> then exports all required objects and
functions to this cluster using <code><a href="parallel.html#topic+clusterExport">clusterExport()</a></code>, after performing a
(rough) match of all objects and functions in the current global
environment to those referenced in the model call(s). Users should load any
required external packages prior to calling the function.
</p>


<h3>Value</h3>

<p>An object of class <code>"boot"</code> containing the bootstrapped effects, or a
(named) list/nested list of such objects.
</p>


<h3>Note</h3>

<p>Bootstrapping mixed (or indeed any other) models may take a very long
time when the number of replicates, observations, parameters, and/or models
is high. To decrease processing time, it may be worth trying different
optimisers and/or other options to generate faster estimates (always check
results).
</p>


<h3>References</h3>

<p>Burnham, K. P., &amp; Anderson, D. R. (2002). <em>Model Selection and
Multimodel Inference: A Practical Information-Theoretic Approach</em> (2nd
ed.). Springer-Verlag. <a href="https://link.springer.com/book/10.1007/b97636">https://link.springer.com/book/10.1007/b97636</a>
</p>
<p>Davison, A. C., &amp; Hinkley, D. V. (1997). <em>Bootstrap Methods and their
Application</em>. Cambridge University Press.
</p>
<p>Ren, S., Lai, H., Tong, W., Aminzadeh, M., Hou, X., &amp; Lai, S. (2010).
Nonparametric bootstrapping for hierarchical data. <em>Journal of Applied
Statistics</em>, <em>37</em>(9), 1487–1498. <a href="https://doi.org/10/dvfzcn">doi:10/dvfzcn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Bootstrap Shipley SEM (test – 1 rep)
# (set 'site' as group for resampling – highest-level random effect)
bootEff(shipley.sem, R = 1, ran.eff = "site", parallel = "no")

# Check estimates (use saved boot object – 1000 reps)
lapply(shipley.sem.boot, "[[", 1)  # original
lapply(shipley.sem.boot, function(i) head(i$t))  # bootstrapped
</code></pre>

<hr>
<h2 id='getData'>Get Model Data</h2><span id='topic+getData'></span>

<h3>Description</h3>

<p>Extract the data used to fit a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getData(mod, subset = FALSE, merge = FALSE, env = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getData_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.</p>
</td></tr>
<tr><td><code id="getData_+3A_subset">subset</code></td>
<td>
<p>Logical. If <code>TRUE</code>, only observations used to fit the model(s)
are returned (i.e. missing observations (<code>NA</code>) or those with zero weight
are removed).</p>
</td></tr>
<tr><td><code id="getData_+3A_merge">merge</code></td>
<td>
<p>Logical. If <code>TRUE</code>, and <code>mod</code> is a list or nested list, a single
dataset containing all variables used to fit models is returned (variables
must be the same length).</p>
</td></tr>
<tr><td><code id="getData_+3A_env">env</code></td>
<td>
<p>Environment in which to look for data (passed to <code><a href="base.html#topic+eval">eval()</a></code>).
Defaults to the <code><a href="stats.html#topic+formula">formula()</a></code> environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a simple convenience function to return the data used to fit
a model, by evaluating the 'data' slot of the model call object. If the
'data' argument of the model call was not specified, or is not a data frame
(or coercible to such) containing all variables referenced in the model
formula, an error will be thrown – this restriction is largely to ensure
that a single coherent dataset of all model variables can be made available
for resampling purposes.
</p>
<p>If <code>mod</code> is a list of models and <code>merge = TRUE</code>, all (unique) variables
used to fit models are merged into a single data frame. This will return an
error if <code>subset = TRUE</code> results in datasets with different numbers of
observations (rows).
</p>


<h3>Value</h3>

<p>A data frame of the variables used to fit the model(s), or a list or
nested list of same.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+getCall">getCall()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get data used to fit SEM from Shipley (2009)
head(getData(shipley.sem[[1]]))  # from single model
lapply(getData(shipley.sem), head)  # from SEM (list)
head(getData(shipley.sem, merge = TRUE))  # from SEM (single dataset)
</code></pre>

<hr>
<h2 id='getEff'>Get SEM Effects</h2><span id='topic+getEff'></span><span id='topic+getDirEff'></span><span id='topic+getIndEff'></span><span id='topic+getTotEff'></span><span id='topic+getMedEff'></span><span id='topic+getAllInd'></span>

<h3>Description</h3>

<p>Extract SEM effects from an object of class <code>"semEff"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEff(eff, responses = NULL, type = c("orig", "boot"))

getDirEff(...)

getIndEff(...)

getTotEff(...)

getMedEff(...)

getAllInd(eff, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getEff_+3A_eff">eff</code></td>
<td>
<p>An object of class <code>"semEff"</code>.</p>
</td></tr>
<tr><td><code id="getEff_+3A_responses">responses</code></td>
<td>
<p>An optional character vector, the names of one or more SEM
response variables for which to return effects. Can also be a numeric
vector of indices of <code>eff</code>. If <code>NULL</code> (default), all effects are returned.</p>
</td></tr>
<tr><td><code id="getEff_+3A_type">type</code></td>
<td>
<p>The type of effects to return. Can be <code>"orig"</code> (default) or
<code>"boot"</code> (for bootstrapped).</p>
</td></tr>
<tr><td><code id="getEff_+3A_...">...</code></td>
<td>
<p>Arguments (above) to be passed to <code>getEff()</code> from the other
extractor functions (<code>type = "boot"</code> is not available for <code>getAllInd()</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are simple extractor functions for effects calculated using
<code><a href="#topic+semEff">semEff()</a></code>, intended for convenience (e.g. for use with <code><a href="#topic+predEff">predEff()</a></code>).
</p>


<h3>Value</h3>

<p>A list containing the original or bootstrapped effects for each
response variable, as numeric vectors or matrices (respectively).
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>getEff()</code>: Extract effects.
</p>
</li>
<li> <p><code>getDirEff()</code>: Extract direct effects.
</p>
</li>
<li> <p><code>getIndEff()</code>: Extract indirect effects.
</p>
</li>
<li> <p><code>getTotEff()</code>: Extract total effects.
</p>
</li>
<li> <p><code>getMedEff()</code>: Extract mediator effects.
</p>
</li>
<li> <p><code>getAllInd()</code>: Extract all indirect effects.
</p>
</li></ul>

<hr>
<h2 id='getX'>Get Model Design Matrix</h2><span id='topic+getX'></span>

<h3>Description</h3>

<p>Return the design matrix for a fitted model, with some
additional options.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getX(
  mod,
  data = NULL,
  contrasts = NULL,
  add.data = FALSE,
  centre = FALSE,
  scale = FALSE,
  as.df = FALSE,
  merge = FALSE,
  env = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getX_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.
Can also be a model formula(s) or character vector(s) of term names (in
which case <code>data</code> must be supplied).</p>
</td></tr>
<tr><td><code id="getX_+3A_data">data</code></td>
<td>
<p>An optional dataset, used to refit the model(s) and/or construct
the design matrix.</p>
</td></tr>
<tr><td><code id="getX_+3A_contrasts">contrasts</code></td>
<td>
<p>Optional, a named list of contrasts to apply to factors (see
the <code>contrasts.arg</code> argument of <code><a href="stats.html#topic+model.matrix">model.matrix()</a></code> for specification). These
will override any existing contrasts in the data or model call.</p>
</td></tr>
<tr><td><code id="getX_+3A_add.data">add.data</code></td>
<td>
<p>Logical, whether to append data not specified in the model
formula (with factors converted to dummy variables).</p>
</td></tr>
<tr><td><code id="getX_+3A_centre">centre</code>, <code id="getX_+3A_scale">scale</code></td>
<td>
<p>Logical, whether to mean-centre and/or scale terms by
standard deviations (for interactions, this is carried out prior to
construction of product terms). Alternatively, a numeric vector of
means/standard deviations (or other statistics) can be supplied, whose
names must match term names.</p>
</td></tr>
<tr><td><code id="getX_+3A_as.df">as.df</code></td>
<td>
<p>Logical, whether to return the matrix as a data frame (without
modifying names).</p>
</td></tr>
<tr><td><code id="getX_+3A_merge">merge</code></td>
<td>
<p>Logical. If <code>TRUE</code>, and <code>mod</code> is a list or nested list, a single
matrix containing all terms is returned (variables must be the same
length).</p>
</td></tr>
<tr><td><code id="getX_+3A_env">env</code></td>
<td>
<p>Environment in which to look for model data (if none supplied).
Defaults to the <code><a href="stats.html#topic+formula">formula()</a></code> environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is primarily a convenience function to enable more flexible
construction of design matrices, usually for internal use and for further
processing. Use cases include processing and/or return of terms which may
not be present in a typical design matrix (e.g. constituents of product
terms, dummy variables).
</p>


<h3>Value</h3>

<p>A matrix or data frame of model(s) terms, or a list or nested list of
same.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+model.matrix">model.matrix()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Model design matrix (original)
m &lt;- shipley.growth[[3]]
x1 &lt;- model.matrix(m)
x2 &lt;- getX(m)
stopifnot(all.equal(x1, x2, check.attributes = FALSE))

# Using formula or term names (supply data)
d &lt;- shipley
x1 &lt;- getX(formula(m), data = d)
x2 &lt;- getX(names(lme4::fixef(m)), data = d)
stopifnot(all.equal(x1, x2))

# Scaled terms
head(getX(m, centre = TRUE, scale = TRUE))

# Combined matrix for SEM
head(getX(shipley.sem, merge = TRUE))
head(getX(shipley.sem, merge = TRUE, add.data = TRUE))  # add other variables
</code></pre>

<hr>
<h2 id='getY'>Get Model Response Variable</h2><span id='topic+getY'></span>

<h3>Description</h3>

<p>Extract the response variable from a fitted model on the
original or link scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getY(mod, data = NULL, link = FALSE, offset = FALSE, env = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getY_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.</p>
</td></tr>
<tr><td><code id="getY_+3A_data">data</code></td>
<td>
<p>An optional dataset, used to first refit the model(s).</p>
</td></tr>
<tr><td><code id="getY_+3A_link">link</code></td>
<td>
<p>Logical. If <code>TRUE</code>, return the GLM response variable on the link
scale (see Details).</p>
</td></tr>
<tr><td><code id="getY_+3A_offset">offset</code></td>
<td>
<p>Logical. If <code>TRUE</code>, include model offset(s) in the response.</p>
</td></tr>
<tr><td><code id="getY_+3A_env">env</code></td>
<td>
<p>Environment in which to look for model data (if none supplied).
Defaults to the <code><a href="stats.html#topic+formula">formula()</a></code> environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>getY()</code> will return the response variable from a model by summing
the fitted values and the response residuals. If <code>link = TRUE</code> and the
model is a GLM, the response is transformed to the link scale. If this
results in undefined values, an estimate based on the 'working' response
variable of the GLM is returned instead (see <code><a href="#topic+glt">glt()</a></code>).
</p>
<p>Any offset variables are subtracted from the response by default. This
means that, for example, rates rather than raw counts will be returned for
poisson GLMs (where applicable).
</p>


<h3>Value</h3>

<p>A numeric vector comprising the response variable on the original or
link scale, or an array, list of vectors/arrays, or nested list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># All SEM responses (original scale)
head(getY(shipley.sem))

# Estimated response in link scale from binomial model
head(getY(shipley.sem$Live, link = TRUE))
</code></pre>

<hr>
<h2 id='glt'>Generalised Link Transformation</h2><span id='topic+glt'></span>

<h3>Description</h3>

<p>Transform a numeric variable using a GLM link function, or
return an estimate of same.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glt(x, family = NULL, force.est = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glt_+3A_x">x</code></td>
<td>
<p>a positive numeric vector, corresponding to a variable to be
transformed. Can also be a list or nested list of such vectors.</p>
</td></tr>
<tr><td><code id="glt_+3A_family">family</code></td>
<td>
<p>Optional, the error distribution family containing the link
function which will be used to transform <code>x</code> (see <code><a href="stats.html#topic+family">family()</a></code> for
specification details). If not supplied, it is determined from <code>x</code> (see
Details).</p>
</td></tr>
<tr><td><code id="glt_+3A_force.est">force.est</code></td>
<td>
<p>Logical, whether to force the return of the estimated rather
than direct transformation, where the latter is available (i.e. does not
contain undefined values).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>glt()</code> can be used to provide a 'generalised' transformation of a
numeric variable, using the link function from a generalised linear model
(GLM) fit to the variable. The transformation is generalised in the sense
that it can extend even to cases where a standard link transformation would
produce undefined values. It achieves this by using an estimate based on
the 'working' response variable of the GLM (see below). If the error
distribution <code>family</code> is not specified (default), then it is determined
(roughly) from <code>x</code>, with <code>binomial(link = "logit")</code> used when all x &lt;= 1
and <code>poisson(link = "log")</code> otherwise. Although the function is generally
intended for variables with a binomial or Poisson distribution, any
variable which can be fit using <code><a href="stats.html#topic+glm">glm()</a></code> can be supplied. One of the key
purposes of <code>glt()</code> is to allow the calculation of fully standardised
effects (coefficients) for GLMs (in which case <code>x</code> = the response
variable), while it can also facilitate the proper calculation of SEM
indirect effects (see below).
</p>
<p><strong>Estimating the direct link transformation</strong>
</p>
<p>A key challenge in generating fully standardised effects for a GLM with a
non-gaussian link function is the difficulty in calculating appropriate
standardised ranges (typically the standard deviation) for the response
variable in the link scale. This is because a direct transformation of the
response will often produce undefined values. Although methods for
circumventing this issue by indirectly estimating the variance of the
response on the link scale have been proposed – including a
latent-theoretic approach for binomial models (McKelvey &amp; Zavoina, 1975)
and a more general variance-based method using pseudo R-squared (Menard,
2011) – here an alternative approach is used. Where transformed values are
undefined, the function will instead return the synthetic 'working'
response from the iteratively reweighted least squares (IRLS) algorithm of
the GLM (McCullagh &amp; Nelder, 1989). This is reconstructed as the sum of the
linear predictor and the working residuals – with the latter comprising the
error of the model on the link scale. The advantage of this approach is
that a relatively straightforward 'transformation' of any non-gaussian
response is readily attainable in all cases. The standard deviation (or
other relevant range) can then be calculated using values of the
transformed response and used to scale the effects. An additional benefit
for piecewise SEMs is that the transformed rather than original response
can be specified as a predictor in other models, ensuring that standardised
indirect and total effects are calculated correctly (i.e. using the same
units).
</p>
<p>To ensure a high level of 'accuracy' in the working response – in the sense
that the inverse-transformation is practically indistinguishable from the
original response variable – the function uses the following iterative
fitting procedure to calculate a 'final' working response:
</p>

<ol>
<li><p> A new GLM of the same error family is fit with the original response
variable as both predictor and response, and using a single IRLS iteration.
</p>
</li>
<li><p> The working response is reconstructed from this model.
</p>
</li>
<li><p> The inverse transformation of the working response is calculated.
</p>
</li>
<li><p> If the inverse transformation is 'effectively equal' to the original
response (tested using <code><a href="base.html#topic+all.equal">all.equal()</a></code> with the default tolerance of
<code>1.5e-8</code>), the working response is returned; otherwise, the GLM is refit
with the working response now as the predictor, and steps 2-4 are repeated
– each time with an additional IRLS iteration.
</p>
</li></ol>

<p>This approach will generate a very reasonable transformation of the
response variable, which will also be practically indistinguishable from
the direct transformation, where this can be compared (see Examples). It
also ensures that the transformed values, and hence the standard deviation,
are the same for any GLM fitting the same response (provided it uses the
same link function) – facilitating model comparisons, selection, and
averaging.
</p>


<h3>Value</h3>

<p>A numeric vector of the transformed values, or an array, list of
vectors/arrays, or nested list.
</p>


<h3>Note</h3>

<p>As we often cannot directly observe the GLM response variable on the
link scale, any method estimating its values or statistics will be wrong to
some degree. The heuristic approach described here aims to reduce this
error as far as (reasonably) possible, while also generating standardised
effects whose interpretation most closely resembles those of the ordinary
linear model. The solution of using the working response from the GLM to
scale effects is a practical, but reasonable one, and one that takes
advantage of modern computing power to minimise error through iterative
model fitting. An added bonus is that the estimated variance is constant
across models fit to the same response variable, which cannot be said of
previous methods (Menard, 2011). The overall approach would be classed as
'observed-empirical' by Grace et al. (2018), as it utilises model error
variance (the estimated working residuals) rather than theoretical
distribution-specific variance.
</p>


<h3>References</h3>

<p>Grace, J. B., Johnson, D. J., Lefcheck, J. S., &amp; Byrnes, J. E. K.
(2018). Quantifying relative importance: computing standardized effects in
models with binary outcomes. <em>Ecosphere</em>, <em>9</em>, e02283. <a href="https://doi.org/10/gdm5bj">doi:10/gdm5bj</a>
</p>
<p>McCullagh P., &amp; Nelder, J. A. (1989). <em>Generalized Linear Models</em> (2nd
Edition). Chapman and Hall.
</p>
<p>McKelvey, R. D., &amp; Zavoina, W. (1975). A statistical model for the analysis
of ordinal level dependent variables. <em>The Journal of Mathematical
Sociology</em>, <em>4</em>(1), 103-120. <a href="https://doi.org/10/dqfhpp">doi:10/dqfhpp</a>
</p>
<p>Menard, S. (2011). Standards for Standardized Logistic Regression
Coefficients. <em>Social Forces</em>, <em>89</em>, 1409-1428. <a href="https://doi.org/10/bvxb6s">doi:10/bvxb6s</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compare estimate with a direct link transformation
# (test with a poisson variable, log link)
set.seed(13)
y &lt;- rpois(30, lambda = 10)
yl &lt;- unname(glt(y, force.est = TRUE))

# Effectively equal?
all.equal(log(y), yl)
# TRUE

# Actual difference...
all.equal(log(y), yl, tolerance = .Machine$double.eps)
# "Mean relative difference: 2.489317e-10"
</code></pre>

<hr>
<h2 id='Object.Type'>Object Types</h2><span id='topic+Object.Type'></span><span id='topic+isList'></span><span id='topic+isBoot'></span><span id='topic+isMod'></span><span id='topic+isGlm'></span><span id='topic+isMer'></span><span id='topic+isGls'></span><span id='topic+isBet'></span>

<h3>Description</h3>

<p>Functions to determine the 'type' of an R object using classes.
Intended largely for convenience and internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isList(x)

isBoot(x)

isMod(x)

isGlm(x)

isMer(x)

isGls(x)

isBet(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Object.Type_+3A_x">x</code></td>
<td>
<p>An R object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical value.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>isList()</code>: Is object a list (class <code>"list"</code> only)?
</p>
</li>
<li> <p><code>isBoot()</code>: Is object a boot object (class <code>"boot"</code>)?
</p>
</li>
<li> <p><code>isMod()</code>: Is object a fitted model?
</p>
</li>
<li> <p><code>isGlm()</code>: Is object a generalised linear model (i.e. uses a
link function)?
</p>
</li>
<li> <p><code>isMer()</code>: Is object a mixed model (class <code>"merMod"</code>)?
</p>
</li>
<li> <p><code>isGls()</code>: Is object a generalised least squares model (class
<code>"gls"</code>)?
</p>
</li>
<li> <p><code>isBet()</code>: Is object a beta regression model (class
<code>"betareg"</code>)?
</p>
</li></ul>

<hr>
<h2 id='Param.Type'>Parameter Types</h2><span id='topic+Param.Type'></span><span id='topic+isInt'></span><span id='topic+isInx'></span><span id='topic+isPhi'></span><span id='topic+isR2'></span><span id='topic+isRaw'></span>

<h3>Description</h3>

<p>Functions to determine the presence/absence of certain model
parameter types using their names. Intended largely for convenience and
internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isInt(x)

isInx(x)

isPhi(x)

isR2(x)

isRaw(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Param.Type_+3A_x">x</code></td>
<td>
<p>A character vector of parameter names (e.g. names of coefficients
from <code><a href="stats.html#topic+coef">coef()</a></code> or <code><a href="#topic+stdEff">stdEff()</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector of the same length as <code>x</code>.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>isInt()</code>: Is parameter an intercept?
</p>
</li>
<li> <p><code>isInx()</code>: Is parameter a variable interaction (product term)?
</p>
</li>
<li> <p><code>isPhi()</code>: Is parameter a beta regression precision coefficient?
</p>
</li>
<li> <p><code>isR2()</code>: Is parameter an R-squared value?
</p>
</li>
<li> <p><code>isRaw()</code>: Is parameter a raw (unstandardised) coefficient?
</p>
</li></ul>

<hr>
<h2 id='predEff'>Predict Effects</h2><span id='topic+predEff'></span>

<h3>Description</h3>

<p>Generate predicted values for SEM direct, indirect, or total
effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predEff(
  mod,
  newdata = NULL,
  effects = NULL,
  eff.boot = NULL,
  re.form = NA,
  type = c("link", "response"),
  interaction = NULL,
  use.raw = FALSE,
  ci.conf = 0.95,
  ci.type = "bca",
  digits = 3,
  bci.arg = NULL,
  parallel = "no",
  ncpus = NULL,
  cl = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predEff_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.</p>
</td></tr>
<tr><td><code id="predEff_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame of new values to predict, which should
contain all the variables named in <code>effects</code> or all those used to fit
<code>mod</code>.</p>
</td></tr>
<tr><td><code id="predEff_+3A_effects">effects</code></td>
<td>
<p>A numeric vector of effects to predict, or a list or nested
list of such vectors. These will typically have been calculated using
<code><a href="#topic+semEff">semEff()</a></code>, <code><a href="#topic+bootEff">bootEff()</a></code>, or <code><a href="#topic+stdEff">stdEff()</a></code>. Alternatively, a boot object
produced by <code><a href="#topic+bootEff">bootEff()</a></code> can be supplied.</p>
</td></tr>
<tr><td><code id="predEff_+3A_eff.boot">eff.boot</code></td>
<td>
<p>A matrix of bootstrapped effects used to calculate confidence
intervals for predictions, or a list or nested list of such matrices. These
will have been calculated using <code><a href="#topic+semEff">semEff()</a></code> or <code><a href="#topic+bootEff">bootEff()</a></code>.</p>
</td></tr>
<tr><td><code id="predEff_+3A_re.form">re.form</code></td>
<td>
<p>For mixed models of class <code>"merMod"</code>, the formula for random
effects to condition on when predicting effects. Defaults to <code>NA</code>, meaning
random effects are averaged over. See <code><a href="lme4.html#topic+predict.merMod">predict.merMod()</a></code> for further
specification details.</p>
</td></tr>
<tr><td><code id="predEff_+3A_type">type</code></td>
<td>
<p>The type of prediction to return (for GLMs). Can be either
<code>"link"</code> (default) or <code>"response"</code>.</p>
</td></tr>
<tr><td><code id="predEff_+3A_interaction">interaction</code></td>
<td>
<p>An optional name of an interactive effect, for which to
return standardised effects for a 'main' continuous variable across
different values or levels of interacting variables (see Details).</p>
</td></tr>
<tr><td><code id="predEff_+3A_use.raw">use.raw</code></td>
<td>
<p>Logical, whether to use raw (unstandardised) effects for all
calculations (if present).</p>
</td></tr>
<tr><td><code id="predEff_+3A_ci.conf">ci.conf</code></td>
<td>
<p>A numeric value specifying the confidence level for confidence
intervals on predictions (and any interactive effects).</p>
</td></tr>
<tr><td><code id="predEff_+3A_ci.type">ci.type</code></td>
<td>
<p>The type of confidence interval to return (defaults to <code>"bca"</code>
– see Details). See <code><a href="boot.html#topic+boot.ci">boot.ci()</a></code> for further specification details.</p>
</td></tr>
<tr><td><code id="predEff_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits to return for interactive
effects.</p>
</td></tr>
<tr><td><code id="predEff_+3A_bci.arg">bci.arg</code></td>
<td>
<p>A named list of any additional arguments to <code><a href="boot.html#topic+boot.ci">boot.ci()</a></code>,
excepting argument <code>index</code>.</p>
</td></tr>
<tr><td><code id="predEff_+3A_parallel">parallel</code></td>
<td>
<p>The type of parallel processing to use for calculating
confidence intervals on predictions. Can be one of <code>"snow"</code>, <code>"multicore"</code>,
or <code>"no"</code> (for none – the default).</p>
</td></tr>
<tr><td><code id="predEff_+3A_ncpus">ncpus</code></td>
<td>
<p>Number of system cores to use for parallel processing. If <code>NULL</code>
(default), all available cores are used.</p>
</td></tr>
<tr><td><code id="predEff_+3A_cl">cl</code></td>
<td>
<p>Optional cluster to use if <code>parallel = "snow"</code>. If <code>NULL</code>
(default), a local cluster is created using the specified number of cores.</p>
</td></tr>
<tr><td><code id="predEff_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="#topic+stdEff">stdEff()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generate predicted values for SEM direct, indirect, or total effects
on a response variable, which should be supplied to <code>effects</code>. These are
used in place of model coefficients in the standard prediction formula,
with values for predictors drawn either from the data used to fit the
original model(s) (<code>mod</code>) or from <code>newdata</code>. It is assumed that effects are
fully standardised; however, if this is not the case, then the same
centring and scaling options originally specified to <code><a href="#topic+stdEff">stdEff()</a></code> should be
re-specified – which will then be used to standardise the data. If no
effects are supplied, standardised (direct) effects will be calculated from
the model and used to generate predictions. These predictions will equal
the model(s) fitted values if <code>newdata = NULL</code>, <code>unique.eff = FALSE</code>, and
<code>re.form = NULL</code> (where applicable).
</p>
<p>Model-averaged predictions can be generated if averaged <code>effects</code> are
supplied to the model in <code>mod</code>, or, alternatively, if <code>weights</code> are
specified (passed to <code><a href="#topic+stdEff">stdEff()</a></code>) and <code>mod</code> is a list of candidate models
(<code>effects</code> can also be passed using this latter method). For mixed model
predictions where random effects are included (e.g. <code>re.form = NULL</code>), the
latter approach should be used, otherwise the contribution of random
effects will be taken from the single model instead of (correctly) being
averaged over a candidate set.
</p>
<p>If bootstrapped effects are supplied to <code>eff.boot</code> (or to <code>effects</code>, as
part of a boot object), bootstrapped predictions are calculated by
predicting from each effect. Confidence intervals can then be returned via
<code><a href="#topic+bootCI">bootCI()</a></code>, for which the <code>type</code> should be appropriate for the original
form of bootstrap sampling (defaults to <code>"bca"</code>). If the number of
observations to predict is very large, parallel processing (via
<code><a href="#topic+pSapply">pSapply()</a></code>) may speed up the calculation of intervals.
</p>
<p>Predictions are always returned in the original (typically unstandardised)
units of the (link-transformed) response variable. For GLMs, they can be
returned in the response scale if <code>type = "response"</code>.
</p>
<p>Additionally, if the name of an interactive effect is supplied to
<code>interaction</code>, standardised effects (and confidence intervals) can be
returned for effects of a continuous 'main' variable across different
values or levels of interacting variable(s). The name should be of the form
<code>"x1:x2..."</code>, containing all the variables involved and matching the name
of an interactive effect in the model(s) terms or in <code>effects</code>. The values
for all variables should be supplied in <code>newdata</code>, with the main continuous
variable being automatically identified as that having the most unique
values.
</p>


<h3>Value</h3>

<p>A numeric vector of the predictions, or, if bootstrapped effects are
supplied, a list containing the predictions and the upper and lower
confidence intervals. Optional interactive effects may also be appended.
Predictions may also be returned in a list or nested list, depending on the
structure of <code>mod</code> (and other arguments).
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+predict">predict()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Predict effects (direct, total)
m &lt;- shipley.sem
e &lt;- shipley.sem.eff
dir &lt;- getDirEff(e)
tot &lt;- getTotEff(e)
f.dir &lt;- predEff(m, effects = dir, type = "response")
f.tot &lt;- predEff(m, effects = tot, type = "response")
f.dir$Live[1:10]
f.tot$Live[1:10]

# Using new data for predictors
d &lt;- na.omit(shipley)
xn &lt;- c("lat", "DD", "Date", "Growth")
seq100 &lt;- function(x) seq(min(x), max(x), length = 100)
nd &lt;- data.frame(sapply(d[xn], seq100))
f.dir &lt;- predEff(m, nd, dir, type = "response")
f.tot &lt;- predEff(m, nd, tot, type = "response")
f.dir$Live[1:10]
f.tot$Live[1:10]
# Add CIs
# dir.b &lt;- getDirEff(e, "boot")
# tot.b &lt;- getTotEff(e, "boot")
# f.dir &lt;- predEff(m, nd, dir, dir.b, type = "response")
# f.tot &lt;- predEff(m, nd, tot, tot.b, type = "response")

# Predict an interactive effect (e.g. Live ~ Growth * DD)
xn &lt;- c("Growth", "DD")
d[xn] &lt;- scale(d[xn])  # scale predictors (improves fit)
m &lt;- lme4::glmer(Live ~ Growth * DD + (1 | site) + (1 | tree),
                 family = binomial, data = d)
nd &lt;- with(d, expand.grid(
  Growth = seq100(Growth),
  DD = mean(DD) + c(-sd(DD), sd(DD))  # two levels for DD
))
f &lt;- predEff(m, nd, type = "response", interaction = "Growth:DD")
f$fit[1:10]
f$interaction
# Add CIs (need to bootstrap model...)
# system.time(B &lt;- bootEff(m, R = 1000, ran.eff = "site"))
# f &lt;- predEff(m, nd, B, type = "response", interaction = "Growth:DD")

# Model-averaged predictions (several approaches)
m &lt;- shipley.growth  # candidate models (list)
w &lt;- runif(length(m), 0, 1)  # weights
e &lt;- stdEff(m, w)  # averaged effects
f1 &lt;- predEff(m[[1]], effects = e)  # pass avg. effects
f2 &lt;- predEff(m, weights = w)  # pass weights argument
f3 &lt;- avgEst(predEff(m), w)  # use avgEst function
stopifnot(all.equal(f1, f2))
stopifnot(all.equal(f2, f3))

# Compare model fitted values: predEff() vs. fitted()
m &lt;- shipley.sem$Live
f1 &lt;- predEff(m, unique.eff = FALSE, re.form = NULL, type = "response")
f2 &lt;- fitted(m)
stopifnot(all.equal(f1, f2))

# Compare predictions using standardised vs. raw effects (same)
f1 &lt;- predEff(m)
f2 &lt;- predEff(m, use.raw = TRUE)
stopifnot(all.equal(f1, f2))
</code></pre>

<hr>
<h2 id='print.bootCI'>Print <code>"bootCI"</code> Objects</h2><span id='topic+print.bootCI'></span>

<h3>Description</h3>

<p>A <code><a href="base.html#topic+print">print()</a></code> method for an object of class <code>"bootCI"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bootCI'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bootCI_+3A_x">x</code></td>
<td>
<p>An object of class <code>"bootCI"</code>.</p>
</td></tr>
<tr><td><code id="print.bootCI_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. Not currently
used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary table of the effects and bootstrapped confidence intervals
(data frame).
</p>

<hr>
<h2 id='print.semEff'>Print <code>"semEff"</code> Objects</h2><span id='topic+print.semEff'></span>

<h3>Description</h3>

<p>A <code><a href="base.html#topic+print">print()</a></code> method for an object of class <code>"semEff"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'semEff'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.semEff_+3A_x">x</code></td>
<td>
<p>An object of class <code>"semEff"</code>.</p>
</td></tr>
<tr><td><code id="print.semEff_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. Not currently
used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This print method returns a summary table for the SEM variables,
giving their status as exogenous or endogenous and as predictor, mediator
and/or response. It also gives the number of direct vs. indirect paths
leading to each variable, and the number of correlated errors (if
applicable).
</p>
<p>Printing of summary tables uses a custom version of <code>print.data.frame()</code>,
facilitating correct rendering of unicode characters by bypassing
<code><a href="base.html#topic+format.data.frame">format.data.frame()</a></code> (<a href="https://stat.ethz.ch/pipermail/r-devel/2015-May/071252.html">bug details</a>,
workaround adapted from
<a href="https://stat.ethz.ch/pipermail/r-devel/2015-May/071259.html">here</a>). Row
names (numbers) are also suppressed by default.
</p>


<h3>Value</h3>

<p>A summary table for the SEM variables (data frame).
</p>

<hr>
<h2 id='pSapply'>Parallel <code><a href="base.html#topic+sapply">sapply()</a></code></h2><span id='topic+pSapply'></span>

<h3>Description</h3>

<p>Apply a function to a vector using parallel processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pSapply(
  X,
  FUN,
  parallel = c("snow", "multicore", "no"),
  ncpus = NULL,
  cl = NULL,
  add.obj = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pSapply_+3A_x">X</code></td>
<td>
<p>A vector object (numeric, character, or list).</p>
</td></tr>
<tr><td><code id="pSapply_+3A_fun">FUN</code></td>
<td>
<p>Function to apply to the elements of <code>X</code>.</p>
</td></tr>
<tr><td><code id="pSapply_+3A_parallel">parallel</code></td>
<td>
<p>The type of parallel processing to use. Can be one of
<code>"snow"</code> (default), <code>"multicore"</code> (not available on Windows), or <code>"no"</code>
(for none). See Details.</p>
</td></tr>
<tr><td><code id="pSapply_+3A_ncpus">ncpus</code></td>
<td>
<p>Number of system cores to use for parallel processing. If <code>NULL</code>
(default), all available cores are used.</p>
</td></tr>
<tr><td><code id="pSapply_+3A_cl">cl</code></td>
<td>
<p>Optional cluster to use if <code>parallel = "snow"</code>. If <code>NULL</code>
(default), a local cluster is created using the specified number of cores.</p>
</td></tr>
<tr><td><code id="pSapply_+3A_add.obj">add.obj</code></td>
<td>
<p>A character vector of any additional object names to be
exported to the cluster. Use if a required object or function cannot be
found.</p>
</td></tr>
<tr><td><code id="pSapply_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="parallel.html#topic+parSapply">parSapply()</a></code>,
<a href="https://rdrr.io/r/parallel/unix/mclapply.html"><code>mcmapply()</code></a>, or
<code><a href="base.html#topic+sapply">sapply()</a></code> (note: arguments <code>"simplify"</code> and <code>"SIMPLIFY"</code> are both
allowed).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a wrapper for <code><a href="parallel.html#topic+clusterApply">parallel::parSapply()</a></code> (<code>"snow"</code>) or
<a href="https://rdrr.io/r/parallel/unix/mclapply.html"><code>parallel::mcmapply()</code></a>
(<code>"multicore"</code>), enabling (potentially) faster processing of a function
over a vector of objects. If <code>parallel = "no"</code>, <code><a href="base.html#topic+sapply">sapply()</a></code> is used instead.
</p>
<p>Parallel processing via option <code>"snow"</code> (default) is carried out using a
cluster of workers, which is automatically set up via <code><a href="parallel.html#topic+makeCluster">makeCluster()</a></code> using
all available system cores or a user supplied number of cores. The function
then exports the required objects and functions to this cluster using
<code><a href="parallel.html#topic+clusterExport">clusterExport()</a></code>, after performing a (rough) match of all objects and
functions in the current global environment to those referenced in the call
to <code>FUN</code> (and also any calls in <code>X</code>). Any additional required object names
can be supplied using <code>add.obj</code>.
</p>


<h3>Value</h3>

<p>The output of <code>FUN</code> in a list, or simplified to a vector or array.
</p>

<hr>
<h2 id='R2'>R-squared</h2><span id='topic+R2'></span>

<h3>Description</h3>

<p>Calculate (Pseudo) R-squared for a fitted model, defined here as
the squared multiple correlation between the observed and fitted values for
the response variable. 'Adjusted' and 'Predicted' versions are also
calculated (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R2(
  mod,
  data = NULL,
  adj = TRUE,
  pred = TRUE,
  offset = FALSE,
  re.form = NULL,
  type = c("pearson", "spearman"),
  adj.type = c("olkin-pratt", "ezekiel"),
  positive.only = TRUE,
  env = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R2_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.</p>
</td></tr>
<tr><td><code id="R2_+3A_data">data</code></td>
<td>
<p>An optional dataset, used to first refit the model(s).</p>
</td></tr>
<tr><td><code id="R2_+3A_adj">adj</code>, <code id="R2_+3A_pred">pred</code></td>
<td>
<p>Logical. If <code>TRUE</code> (default), adjusted and/or predicted
R-squared are also returned (the latter is not available for all model
types).</p>
</td></tr>
<tr><td><code id="R2_+3A_offset">offset</code></td>
<td>
<p>Logical. If <code>TRUE</code>, include model offset(s) in the calculations
(i.e. in the response variable and fitted values).</p>
</td></tr>
<tr><td><code id="R2_+3A_re.form">re.form</code></td>
<td>
<p>For mixed models of class <code>"merMod"</code>, the formula for random
effects to condition on when generating fitted values used in the
calculation of R-squared. Defaults to <code>NULL</code>, meaning all random effects
are included. See <code><a href="lme4.html#topic+predict.merMod">predict.merMod()</a></code> for further specification details.</p>
</td></tr>
<tr><td><code id="R2_+3A_type">type</code></td>
<td>
<p>The type of correlation coefficient to use. Can be <code>"pearson"</code>
(default) or <code>"spearman"</code>.</p>
</td></tr>
<tr><td><code id="R2_+3A_adj.type">adj.type</code></td>
<td>
<p>The type of adjusted R-squared estimator to use. Can be
<code>"olkin-pratt"</code> (default) or <code>"ezekiel"</code>. See Details.</p>
</td></tr>
<tr><td><code id="R2_+3A_positive.only">positive.only</code></td>
<td>
<p>Logical, whether to return only positive values for
R-squared (negative values replaced with zero).</p>
</td></tr>
<tr><td><code id="R2_+3A_env">env</code></td>
<td>
<p>Environment in which to look for model data (if none supplied).
Defaults to the <code><a href="stats.html#topic+formula">formula()</a></code> environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Various approaches to the calculation of a goodness of fit measure
for GLMs analogous to R-squared in the ordinary linear model have been
proposed. Generally termed 'pseudo R-squared' measures, they include
variance-based, likelihood-based, and distribution-specific approaches.
Here however, a more straightforward definition is used, which can be
applied to any model for which fitted values of the response variable are
generated: R-squared is calculated as the squared (weighted) correlation
between the observed and fitted values of the response (in the original
units). This is simply the squared version of the correlation measure
advocated by Zheng &amp; Agresti (2000), itself an intuitive measure of
goodness of fit describing the predictive power of a model. As the measure
does not depend on any specific error distribution or model estimating
procedure, it is also generally comparable across many different types of
model (Kvalseth, 1985). In the case of the ordinary linear model, the
measure is exactly equal to the traditional R-squared based on sums of
squares.
</p>
<p>If <code>adj = TRUE</code> (default), the 'adjusted' R-squared value is also returned,
which provides an estimate of the population – as opposed to sample –
R-squared. This is achieved via an analytical formula which adjusts
R-squared using the 'degrees of freedom' of the model (i.e. the ratio of
observations to parameters), helping to counter multiple R-squared's
positive bias and guard against overfitting of the model to noise in the
original sample. By default, this is calculated via the exact 'Olkin-Pratt'
estimator, shown in recent simulations to be the optimal unbiased
population R-squared estimator across a range of estimators and
specification scenarios (Karch, 2020), and thus a good general first
choice, even for smaller sample sizes. Setting <code>adj.type = "ezekiel"</code>
however will use the simpler and more common 'Ezekiel' formula, which can
be more appropriate where minimising the mean squared error (MSE) of the
estimate is more important than strict unbiasedness (Hittner, 2019; Karch,
2020).
</p>
<p>If <code>pred = TRUE</code> (default), a 'predicted' R-squared is also returned, which
is calculated via the same formula as for R-squared but using
cross-validated, rather than original, fitted values. These are obtained by
dividing the model residuals (in the response scale) by the complement of
the observation leverages (diagonals of the hat matrix), then subtracting
these inflated 'predicted' residuals from the response variable. This is
essentially a short cut to obtaining 'out-of-sample' predictions, normally
arising via a 'leave-one-out' cross-validation procedure (they are not
exactly equal for GLMs). The resulting R-squared is an estimate of the
R-squared that would result were the model fit to new data, and will be
lower than the original – and likely also the adjusted – R-squared,
highlighting the loss of explanatory power due to sample noise. Predicted
R-squared <a href="https://stats.stackexchange.com/questions/242770/difference-between-adjusted-r-squared-and-predicted-r-squared">may be a more powerful and general indicator of overfitting than adjusted R-squared</a>,
as it provides a true out-of-sample test. This measure is a variant of an
<a href="https://www.r-bloggers.com/2014/05/can-we-do-better-than-r-squared/">existing one</a>,
calculated by substituting the 'PRESS' statistic, i.e. the sum of squares
of the predicted residuals (Allen, 1974), for the residual sum of squares
in the classic R-squared formula. It is not calculated here for GLMMs, as
the interpretation of the hat matrix is not reliable (see
<code><a href="lme4.html#topic+hatvalues.merMod">hatvalues.merMod()</a></code>).
</p>
<p>For models fitted with one or more offsets, these will be removed by
default from the response variable and fitted values prior to calculations.
Thus R-squared will measure goodness of fit only for the predictors with
estimated, rather than fixed, coefficients. This is likely to be the
intended behaviour in most circumstances, though if users wish to include
variation due to the offset(s) they can set <code>offset = TRUE</code>.
</p>
<p>For mixed models, the function will, by default, calculate all R-squared
measures using fitted values incorporating both the fixed and random
effects, thus encompassing all variation captured by the model. This is
equivalent to the 'conditional' R-squared of Nakagawa et al. (2017) (though
see that reference for a more advanced approach to R-squared for mixed
models). To include only some or no random effects, simply set the
appropriate formula using the argument <code>re.form</code>, which is passed directly
to <code><a href="lme4.html#topic+predict.merMod">predict.merMod()</a></code>. If <code>re.form = NA</code>, R-squared is calculated for the
fixed effects only, i.e. the 'marginal' R-squared of Nakagawa et al.
(2017).
</p>
<p>As R-squared is calculated here as a squared correlation, the <code>type</code> of
correlation coefficient can also be specified. Setting this to <code>"spearman"</code>
may be desirable in some cases, such as where the relationship between
response and fitted values is not necessarily bivariate normal or linear,
and a correlation of the ranks may be more informative and/or general. This
purely monotonic R-squared can also be considered a <a href="https://stats.stackexchange.com/questions/44268/reporting-coefficient-of-determination-using-spearmans-rho">useful goodness of fit measure</a>,
and may be more appropriate for comparisons between GLMs and ordinary
linear models in some scenarios.
</p>
<p>R-squared values produced by this function will by default be in the range
0-1, meaning that any negative values arising from calculations will be
converted to zero. Negative values essentially mean that the fit is 'worse'
than the null expectation of no relationship between the variables, which
can be difficult to interpret in practice and in any case usually only
occurs in rare situations, such as where the intercept is suppressed or
where a low value of R-squared is adjusted downwards via an analytic
estimator. Such values are also 'impossible' in practice, given that
R-squared is a strictly positive measure (as generally known). Hence, for
simplicity and ease of interpretation, values less than zero are presented
as a complete lack of model fit. This is also recommended by Shieh (2008),
who shows for adjusted R-squared that such 'positive-part' estimators have
lower MSE in estimating the population R-squared (though higher bias). To
allow return of negative values however, set <code>positive.only = FALSE</code>. This
may be desirable for simulation purposes, and/or where strict unbiasedness
is prioritised.
</p>


<h3>Value</h3>

<p>A numeric vector of the R-squared value(s), or an array, list of
vectors/arrays, or nested list.
</p>


<h3>Note</h3>

<p>Caution must be exercised in interpreting the values of any pseudo
R-squared measure calculated for a GLM or mixed model (including those
produced by this function), as such measures do not hold all the properties
of R-squared in the ordinary linear model and as such may not always behave
as expected. Care must also be taken in comparing the measures to their
equivalents from ordinary linear models, particularly the adjusted and
predicted versions, as assumptions and/or calculations may not generalise
well. With that being said, the value of standardised R-squared measures
for even 'rough' model fit assessment and comparison may outweigh such
reservations, and the adjusted and predicted versions in particular may aid
the user in diagnosing and preventing overfitting. They should NOT,
however, replace other measures such as AIC or BIC for formally comparing
and/or ranking competing models fit to the same response variable.
</p>


<h3>References</h3>

<p>Allen, D. M. (1974). The Relationship Between Variable Selection
and Data Augmentation and a Method for Prediction. <em>Technometrics</em>,
<em>16</em>(1), 125-127. <a href="https://doi.org/10/gfgv57">doi:10/gfgv57</a>
</p>
<p>Hittner, J. B. (2019). Ezekiel’s classic estimator of the population
squared multiple correlation coefficient: Monte Carlo-based extensions and
refinements. <em>The Journal of General Psychology</em>, <em>147</em>(3), 213–227.
<a href="https://doi.org/10/gk53wb">doi:10/gk53wb</a>
</p>
<p>Karch, J. (2020). Improving on Adjusted R-Squared. <em>Collabra: Psychology</em>,
<em>6</em>(1). <a href="https://doi.org/10/gkgk2v">doi:10/gkgk2v</a>
</p>
<p>Kvalseth, T. O. (1985). Cautionary Note about R2. <em>The American
Statistician</em>, <em>39</em>(4), 279-285. <a href="https://doi.org/10/b8b782">doi:10/b8b782</a>
</p>
<p>Nakagawa, S., Johnson, P. C. D., &amp; Schielzeth, H. (2017). The coefficient
of determination R2 and intra-class correlation coefficient from
generalized linear mixed-effects models revisited and expanded. <em>Journal of
the Royal Society Interface</em>, <em>14</em>(134). <a href="https://doi.org/10/gddpnq">doi:10/gddpnq</a>
</p>
<p>Shieh, G. (2008). Improved Shrinkage Estimation of Squared Multiple
Correlation Coefficient and Squared Cross-Validity Coefficient.
<em>Organizational Research Methods</em>, <em>11</em>(2), 387–407. <a href="https://doi.org/10/bcwqf3">doi:10/bcwqf3</a>
</p>
<p>Zheng, B., &amp; Agresti, A. (2000). Summarizing the predictive power of a
generalized linear model. <em>Statistics in Medicine</em>, <em>19</em>(13), 1771-1781.
<a href="https://doi.org/10/db7rfv">doi:10/db7rfv</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Pseudo R-squared for mixed models
R2(shipley.sem)  # fixed + random ('conditional')
R2(shipley.sem, re.form = ~ (1 | tree))  # fixed + 'tree'
R2(shipley.sem, re.form = ~ (1 | site))  # fixed + 'site'
R2(shipley.sem, re.form = NA)  # fixed only ('marginal')
R2(shipley.sem, re.form = NA, type = "spearman")  # using Spearman's Rho

# Predicted R-squared: compare cross-validated predictions calculated/
# approximated via the hat matrix to standard method (leave-one-out)

# Fit test models using Shipley data – compare lm vs glm
d &lt;- na.omit(shipley)
m &lt;- lm(Live ~ Date + DD + lat, d)
# m &lt;- glm(Live ~ Date + DD + lat, binomial, d)

# Manual CV predictions (leave-one-out)
cvf1 &lt;- sapply(1:nrow(d), function(i) {
  m.ni &lt;- update(m, data = d[-i, ])
  predict(m.ni, d[i, ], type = "response")
})

# Short-cut via the hat matrix
y &lt;- getY(m)
f &lt;- fitted(m)
cvf2 &lt;- y - (y - f) / (1 - hatvalues(m))

# Compare predictions (not exactly equal for GLMs)
all.equal(cvf1, cvf2)
# lm: TRUE; glm: "Mean relative difference: 1.977725e-06"
cor(cvf1, cvf2)
# lm: 1; glm: 0.9999987

# NOTE: comparison not tested here for mixed models, as hierarchical data can
# complicate the choice of an appropriate leave-one-out procedure. However,
# there is no obvious reason why use of the leverage values (diagonals of the
# hat matrix) to estimate CV predictions shouldn't generalise, roughly, to
# the mixed model case (at least for LMMs). In any case, users should
# exercise the appropriate caution in interpretation.
</code></pre>

<hr>
<h2 id='rMapply'>Recursive <code><a href="base.html#topic+mapply">mapply()</a></code></h2><span id='topic+rMapply'></span>

<h3>Description</h3>

<p>Recursively apply a function to a list or lists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rMapply(FUN, ..., MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rMapply_+3A_fun">FUN</code></td>
<td>
<p>Function to apply.</p>
</td></tr>
<tr><td><code id="rMapply_+3A_...">...</code></td>
<td>
<p>Object(s) to which <code>FUN</code> can be applied, or lists of such objects
to iterate over (defined narrowly, as of class <code>"list"</code>).</p>
</td></tr>
<tr><td><code id="rMapply_+3A_moreargs">MoreArgs</code></td>
<td>
<p>A list of additional arguments to <code>FUN</code>.</p>
</td></tr>
<tr><td><code id="rMapply_+3A_simplify">SIMPLIFY</code></td>
<td>
<p>Logical, whether to simplify the results to a vector or
array.</p>
</td></tr>
<tr><td><code id="rMapply_+3A_use.names">USE.NAMES</code></td>
<td>
<p>Logical, whether to use the names of the first list object
in <code>...</code> for the output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rMapply()</code> recursively applies <code>FUN</code> to the elements of the lists
in <code>...</code> via <code><a href="base.html#topic+mapply">mapply()</a></code>. If only a single list is supplied, the function
acts like a recursive version of <code><a href="base.html#topic+sapply">sapply()</a></code>. The particular condition that
determines if the function should stop recursing is if either the first or
second objects in <code>...</code> are not of class <code>"list"</code>. Thus, unlike <code><a href="base.html#topic+mapply">mapply()</a></code>,
it will not iterate over non-list elements in these objects, but instead
returns the output of <code>FUN(...)</code>.
</p>
<p>This is primarily a convenience function used internally to enable
recursive application of functions to lists or nested lists. Its particular
stop condition for recursing is also designed to either <em>a)</em> act as a
wrapper for <code>FUN</code> if the first object in <code>...</code> is not a list, or <em>b)</em> apply
a weighted averaging operation if the first object is a list and the second
object is a numeric vector of weights.
</p>


<h3>Value</h3>

<p>The output of <code>FUN</code> in a list or nested list, or simplified to a
vector or array (or list of arrays).
</p>

<hr>
<h2 id='RVIF'>Root Variance Inflation Factors</h2><span id='topic+RVIF'></span>

<h3>Description</h3>

<p>Calculate root variance inflation factors (RVIF) for terms in a
fitted model(s), i.e. the square root of the (generalised) VIFs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RVIF(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RVIF_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="#topic+VIF">VIF()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RVIFs quantify the inflation of estimate standard errors due to
multicollinearity among predictors, and also of estimates themselves
compared to the 'unique' (residualised) effects. RVIFs may often be more
practical than VIFs for assessing multicollinearity, relating more directly
to the parameters of interest.
</p>


<h3>Value</h3>

<p>A numeric vector of the RVIFs, or an array, list of vectors/arrays,
or nested list.
</p>

<hr>
<h2 id='sdW'>Weighted Standard Deviation</h2><span id='topic+sdW'></span>

<h3>Description</h3>

<p>Calculate the weighted standard deviation of <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdW(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdW_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="#topic+varW">varW()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is simply a wrapper for <code><a href="#topic+varW">varW()</a></code>, applying the square root to
the output.
</p>


<h3>Value</h3>

<p>A numeric value, the weighted standard deviation of <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+sd">sd()</a></code>
</p>

<hr>
<h2 id='semEff'>SEM Effects</h2><span id='topic+semEff'></span>

<h3>Description</h3>

<p>Automatically calculate direct, indirect, total, and mediator
effects for endogenous (response) variables in a 'piecewise' structural
equation model (SEM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semEff(
  sem,
  predictors = NULL,
  mediators = NULL,
  use.raw = FALSE,
  ci.conf = 0.95,
  ci.type = "bca",
  digits = 3,
  bci.arg = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="semEff_+3A_sem">sem</code></td>
<td>
<p>A piecewise SEM, comprising a list of fitted model objects or of
boot objects (containing bootstrapped model effects). Alternatively, a
<code>"psem"</code> object from
<a href="https://rdrr.io/cran/piecewiseSEM/man/psem.html"><code>piecewiseSEM::psem()</code></a>.
If list is unnamed, response variable names will be used.</p>
</td></tr>
<tr><td><code id="semEff_+3A_predictors">predictors</code>, <code id="semEff_+3A_mediators">mediators</code></td>
<td>
<p>Names of variables for/through which to calculate
effects. If <code>NULL</code> (default), all predictors/mediators in the SEM will be
used.</p>
</td></tr>
<tr><td><code id="semEff_+3A_use.raw">use.raw</code></td>
<td>
<p>Logical, whether to use 'raw' (unstandardised) effects for all
calculations (if present in <code>sem</code>).</p>
</td></tr>
<tr><td><code id="semEff_+3A_ci.conf">ci.conf</code></td>
<td>
<p>A numeric value specifying the confidence level for confidence
intervals on effects.</p>
</td></tr>
<tr><td><code id="semEff_+3A_ci.type">ci.type</code></td>
<td>
<p>The type of confidence interval to return (defaults to <code>"bca"</code>
– see Details). See <code><a href="boot.html#topic+boot.ci">boot.ci()</a></code> for further specification details.</p>
</td></tr>
<tr><td><code id="semEff_+3A_digits">digits</code></td>
<td>
<p>The number of significant digits to return for numeric values
(for summary tables).</p>
</td></tr>
<tr><td><code id="semEff_+3A_bci.arg">bci.arg</code></td>
<td>
<p>A named list of any additional arguments to <code><a href="boot.html#topic+boot.ci">boot.ci()</a></code>,
excepting argument <code>index</code>.</p>
</td></tr>
<tr><td><code id="semEff_+3A_...">...</code></td>
<td>
<p>Arguments to <code><a href="#topic+bootEff">bootEff()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The eponymous function of this package calculates all direct,
indirect, total, and mediator effects for a 'piecewise' structural equation
model (SEM), that is, one where parameter estimation is local rather than
global (Lefcheck, 2016; Shipley, 2000, 2009). The SEM simply takes the form
of a list of fitted models, or bootstrapped estimates from such models,
describing hypothesised causal pathways from predictors to response
('endogenous') variables. These are either direct, or operate indirectly
via other response variables ('mediators'). This list should represent a
directed ('acyclic') causal model, which should be named exactly for each
response variable and ordered from 'upstream' or 'causal' variables through
to 'downstream' (i.e. those at the end of the pathway). If <code>sem</code> is a list
of fitted models, effects will first be bootstrapped using <code><a href="#topic+bootEff">bootEff()</a></code>
(this may take a while!).
</p>
<p>Direct effects are calculated as fully standardised model coefficients for
each response variable (see <code><a href="#topic+stdEff">stdEff()</a></code> for details), while indirect effects
are the product of these direct effects operating along causal pathways in
the SEM. The total effects of any given predictor on a response are then
the sum of its direct and (all) its indirect effects. 'Mediator' effects
are also calculated, as the sum of all indirect paths which operate through
each individual mediator – useful to assess the relative importance of
different mediators in affecting the response. All of these effect types
can be calculated automatically for all (default) or for a specified subset
of predictors and/or mediators in the SEM. As indirect, total, and mediator
effects are not directly bootstrapped using the fitted models for response
variables (i.e. via <code><a href="#topic+bootEff">bootEff()</a></code>), their equivalent 'bootstrapped' estimates
are calculated instead using each bootstrapped direct effect.
</p>
<p>Confidence intervals for all effects are returned in summary tables for
each response (see <code><a href="#topic+bootCI">bootCI()</a></code>), with BC<em>a</em> intervals calculated by default
using the bootstrapped estimates for each effect type (Cheung, 2009; Hayes
&amp; Scharkow, 2013; MacKinnon et al., 2004). Effects for which the confidence
intervals do not contain zero are highlighted with a star (i.e.
'significant' at the <code>ci.conf</code> level). Bootstrap standard errors (standard
deviations of the samples) and biases (sample means minus original
estimates) are also included. Correlated errors (and confidence intervals)
are also returned if their bootstrapped values are present in <code>sem</code>, or if
they are specified to argument <code>cor.err</code> or as part of a <code>"psem"</code> object
(see <code><a href="#topic+bootEff">bootEff()</a></code>). These represent residual relationships among response
variables, unaccounted for by the hypothesised SEM paths. Use <code>summary()</code>
for effect summary tables and <code>print()</code> to return a table of variable names
and associated details.
</p>
<p>All calculated effects and bootstrapped effects are also returned in lists
for each response variable, with all except mediator effects also including
the model intercept(s) – required for prediction (these will be zero for
ordinary linear models with fully standardised effects). Effects can be
conveniently extracted with <code><a href="#topic+getEff">getEff()</a></code> and related functions.
</p>


<h3>Value</h3>

<p>A list object of class <code>"semEff"</code> for which several methods and
extractor functions exist. Contains:
</p>

<ol>
<li><p> Summary tables of effects and confidence intervals
</p>
</li>
<li><p> All effects
</p>
</li>
<li><p> All bootstrapped effects
</p>
</li>
<li><p> All indirect effects (individual, not summed)
</p>
</li></ol>



<h3>References</h3>

<p>Cheung, M. W. L. (2009). Comparison of methods for constructing
confidence intervals of standardized indirect effects. <em>Behavior Research
Methods</em>, <em>41</em>(2), 425-438. <a href="https://doi.org/10/fnx7xk">doi:10/fnx7xk</a>
</p>
<p>Hayes, A. F., &amp; Scharkow, M. (2013). The Relative Trustworthiness of
Inferential Tests of the Indirect Effect in Statistical Mediation Analysis:
Does Method Really Matter? <em>Psychological Science</em>, <em>24</em>(10), 1918-1927.
<a href="https://doi.org/10/bbhr">doi:10/bbhr</a>
</p>
<p>Lefcheck, J. S. (2016). piecewiseSEM: Piecewise structural equation
modelling in <code>R</code> for ecology, evolution, and systematics. <em>Methods in
Ecology and Evolution</em>, <em>7</em>(5), 573-579. <a href="https://doi.org/10/f8s8rb">doi:10/f8s8rb</a>
</p>
<p>MacKinnon, D. P., Lockwood, C. M., &amp; Williams, J. (2004). Confidence Limits
for the Indirect Effect: Distribution of the Product and Resampling
Methods. <em>Multivariate Behavioral Research</em>, <em>39</em>(1), 99. <a href="https://doi.org/10/chqcnx">doi:10/chqcnx</a>
</p>
<p>Shipley, B. (2000). A New Inferential Test for Path Models Based on
Directed Acyclic Graphs. <em>Structural Equation Modeling: A Multidisciplinary
Journal</em>, <em>7</em>(2), 206-218. <a href="https://doi.org/10/cqm32d">doi:10/cqm32d</a>
</p>
<p>Shipley, B. (2009). Confirmatory path analysis in a generalized multilevel
context. <em>Ecology</em>, <em>90</em>(2), 363-368. <a href="https://doi.org/10/bqd43d">doi:10/bqd43d</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># SEM effects
(shipley.sem.eff &lt;- semEff(shipley.sem.boot))
summary(shipley.sem.eff)

# Effects for selected variables
summary(shipley.sem.eff, response = "Live")
# summary(semEff(shipley.sem.boot, predictor = "lat"))
# summary(semEff(shipley.sem.boot, mediator = "DD"))

# Effects calculated using original SEM (models)
# (not typically recommended – better to use saved boot objects)
# system.time(
#  shipley.sem.eff &lt;- semEff(shipley.sem, R = 1000, seed = 13,
#                            ran.eff = "site")
# )
</code></pre>

<hr>
<h2 id='shipley'>Simulated Data from Shipley (2009)</h2><span id='topic+shipley'></span>

<h3>Description</h3>

<p>Simulated Data from Shipley (2009)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shipley
</code></pre>


<h3>Format</h3>

<p>A data frame with 1900 observations and 9 variables:
</p>

<dl>
<dt>site</dt><dd><p>a numeric code giving the site from which the observation comes</p>
</dd>
<dt>tree</dt><dd><p>a numeric code giving the tree from which the observation comes</p>
</dd>
<dt>lat</dt><dd><p>the latitude of the site</p>
</dd>
<dt>year</dt><dd><p>the year in which the observation was taken</p>
</dd>
<dt>Date</dt><dd><p>the Julian date when the bud burst occurs</p>
</dd>
<dt>DD</dt><dd><p>the number of degree days when bud burst occurs</p>
</dd>
<dt>Growth</dt><dd><p>the increase in diameter growth of the tree</p>
</dd>
<dt>Survival</dt><dd><p>the probability of survival until the next year (used only
for the simulation)</p>
</dd>
<dt>Live</dt><dd><p>a binary value (1 = tree lived the following winter, 0 = tree
died the following winter)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://doi.org/10/c886">doi:10/c886</a>
</p>


<h3>References</h3>

<p>Shipley, B. (2009). Confirmatory path analysis in a generalized
multilevel context. <em>Ecology</em>, <em>90</em>(2), 363-368. <a href="https://doi.org/10/bqd43d">doi:10/bqd43d</a>
</p>

<hr>
<h2 id='shipley.growth'>Candidate Model Set from Shipley 'Growth' Model</h2><span id='topic+shipley.growth'></span>

<h3>Description</h3>

<p>A set of hypothetical competing models fit to the same response
variable ('Growth') using the simulated data in Shipley (2009), for which
model estimates can be compared and/or averaged.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shipley.growth
</code></pre>


<h3>Format</h3>

<p>A list of mixed models of class <code>"lmer"</code> and <code>"glmer"</code>, fit to the
same response variable.
</p>


<h3>References</h3>

<p>Shipley, B. (2009). Confirmatory path analysis in a generalized
multilevel context. <em>Ecology</em>, <em>90</em>(2), 363-368. <a href="https://doi.org/10/bqd43d">doi:10/bqd43d</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specification
# shipley.growth &lt;- list(
#   lme4::lmer(Growth ~ Date + (1 | site) + (1 | tree), data = shipley),
#   lme4::lmer(Growth ~ Date + DD + (1 | site) + (1 | tree), data = shipley),
#   lme4::lmer(Growth ~ Date + DD + lat + (1 | site) + (1 | tree),
#              data = shipley)
# )
</code></pre>

<hr>
<h2 id='shipley.sem'>Hypothesised SEM from Shipley (2009)</h2><span id='topic+shipley.sem'></span>

<h3>Description</h3>

<p>Hypothesised SEM from Shipley (2009)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shipley.sem
</code></pre>


<h3>Format</h3>

<p>A list of fitted mixed models of class <code>"lmer"</code> and <code>"glmer"</code>,
representing structured equations.
</p>


<h3>References</h3>

<p>Shipley, B. (2009). Confirmatory path analysis in a generalized
multilevel context. <em>Ecology</em>, <em>90</em>(2), 363-368. <a href="https://doi.org/10/bqd43d">doi:10/bqd43d</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specification
# shipley.sem &lt;- list(
#   DD = lme4::lmer(DD ~ lat + (1 | site) + (1 | tree), data = shipley),
#   Date = lme4::lmer(Date ~ DD + (1 | site) + (1 | tree), data = shipley),
#   Growth = lme4::lmer(Growth ~ Date + (1 | site) + (1 | tree),
#                       data = shipley),
#   Live = lme4::glmer(Live ~ Growth + (1 | site) + (1 | tree), binomial,
#                      data = shipley)
# )
</code></pre>

<hr>
<h2 id='shipley.sem.boot'>Bootstrapped Estimates for Shipley SEM</h2><span id='topic+shipley.sem.boot'></span>

<h3>Description</h3>

<p>Bootstrapped estimates generated from the hypothesised SEM from
Shipley (2009), using <code><a href="#topic+bootEff">bootEff()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shipley.sem.boot
</code></pre>


<h3>Format</h3>

<p>A list of objects of class <code>"boot"</code>, representing bootstrapped
estimates from fitted mixed models.
</p>


<h3>References</h3>

<p>Shipley, B. (2009). Confirmatory path analysis in a generalized
multilevel context. <em>Ecology</em>, <em>90</em>(2), 363-368. <a href="https://doi.org/10/bqd43d">doi:10/bqd43d</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specification
# shipley.sem.boot &lt;- bootEff(shipley.sem, R = 1000, seed = 13,
#                             ran.eff = "site")
</code></pre>

<hr>
<h2 id='shipley.sem.eff'>Effects for Shipley SEM</h2><span id='topic+shipley.sem.eff'></span>

<h3>Description</h3>

<p>SEM effects calculated from bootstrapped estimates of the
hypothesised SEM from Shipley (2009), using <code><a href="#topic+semEff">semEff()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shipley.sem.eff
</code></pre>


<h3>Format</h3>

<p>A list object of class <code>"semEff"</code>, containing SEM effects and summary
tables.
</p>


<h3>References</h3>

<p>Shipley, B. (2009). Confirmatory path analysis in a generalized
multilevel context. <em>Ecology</em>, <em>90</em>(2), 363-368. <a href="https://doi.org/10/bqd43d">doi:10/bqd43d</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specification
# shipley.sem.eff &lt;- semEff(shipley.sem.boot)
</code></pre>

<hr>
<h2 id='stdEff'>Standardised Effects</h2><span id='topic+stdEff'></span>

<h3>Description</h3>

<p>Calculate fully standardised effects (model coefficients) in
standard deviation units, adjusted for multicollinearity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stdEff(
  mod,
  weights = NULL,
  data = NULL,
  term.names = NULL,
  unique.eff = TRUE,
  cen.x = TRUE,
  cen.y = TRUE,
  std.x = TRUE,
  std.y = TRUE,
  refit.x = TRUE,
  incl.raw = FALSE,
  R.squared = FALSE,
  R2.arg = NULL,
  env = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stdEff_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.</p>
</td></tr>
<tr><td><code id="stdEff_+3A_weights">weights</code></td>
<td>
<p>An optional numeric vector of weights to use for model
averaging, or a named list of such vectors. The former should be supplied
when <code>mod</code> is a list, and the latter when it is a nested list (with
matching list names). If set to <code>"equal"</code>, a simple average is calculated
instead.</p>
</td></tr>
<tr><td><code id="stdEff_+3A_data">data</code></td>
<td>
<p>An optional dataset, used to first refit the model(s).</p>
</td></tr>
<tr><td><code id="stdEff_+3A_term.names">term.names</code></td>
<td>
<p>An optional vector of names used to extract and/or sort
effects from the output.</p>
</td></tr>
<tr><td><code id="stdEff_+3A_unique.eff">unique.eff</code></td>
<td>
<p>Logical, whether unique effects should be calculated
(adjusted for multicollinearity among predictors).</p>
</td></tr>
<tr><td><code id="stdEff_+3A_cen.x">cen.x</code>, <code id="stdEff_+3A_cen.y">cen.y</code></td>
<td>
<p>Logical, whether effects should be calculated as if from
mean-centred variables.</p>
</td></tr>
<tr><td><code id="stdEff_+3A_std.x">std.x</code>, <code id="stdEff_+3A_std.y">std.y</code></td>
<td>
<p>Logical, whether effects should be scaled by the standard
deviations of variables.</p>
</td></tr>
<tr><td><code id="stdEff_+3A_refit.x">refit.x</code></td>
<td>
<p>Logical, whether the model should be refit with mean-centred
predictor variables (see Details).</p>
</td></tr>
<tr><td><code id="stdEff_+3A_incl.raw">incl.raw</code></td>
<td>
<p>Logical, whether to append the raw (unstandardised) effects
to the output.</p>
</td></tr>
<tr><td><code id="stdEff_+3A_r.squared">R.squared</code></td>
<td>
<p>Logical, whether R-squared values should also be calculated
(via <code><a href="#topic+R2">R2()</a></code>).</p>
</td></tr>
<tr><td><code id="stdEff_+3A_r2.arg">R2.arg</code></td>
<td>
<p>A named list of additional arguments to <code><a href="#topic+R2">R2()</a></code> (where
applicable), excepting argument <code>env</code>. Ignored if <code>R.squared = FALSE</code>.</p>
</td></tr>
<tr><td><code id="stdEff_+3A_env">env</code></td>
<td>
<p>Environment in which to look for model data (if none supplied).
Defaults to the <code><a href="stats.html#topic+formula">formula()</a></code> environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>stdEff()</code> will calculate fully standardised effects (coefficients)
in standard deviation units for a fitted model or list of models. It
achieves this via adjusting the 'raw' model coefficients, so no
standardisation of input variables is required beforehand. Users can simply
specify the model with all variables in their original units and the
function will do the rest. However, the user is free to scale and/or centre
any input variables should they choose, which should not affect the outcome
of standardisation (provided any scaling is by standard deviations). This
may be desirable in some cases, such as to increase numerical stability
during model fitting when variables are on widely different scales.
</p>
<p>If arguments <code>cen.x</code> or <code>cen.y</code> are <code>TRUE</code>, effects will be calculated as
if all predictors (x) and/or the response variable (y) were mean-centred
prior to model-fitting (including any dummy variables arising from
categorical predictors). Thus, for an ordinary linear model where centring
of x and y is specified, the intercept will be zero – the mean (or weighted
mean) of y. In addition, if <code>cen.x = TRUE</code> and there are interacting terms
in the model, all effects for lower order terms of the interaction are
adjusted using an expression which ensures that each main effect or lower
order term is estimated at the mean values of the terms they interact with
(zero in a 'centred' model) – typically improving the interpretation of
effects. The expression used comprises a weighted sum of all the effects
that contain the lower order term, with the weight for the term itself
being zero and those for 'containing' terms being the product of the means
of the other variables involved in that term (i.e. those not in the lower
order term itself). For example, for a three-way interaction (x1 * x2 *
x3), the expression for main effect <code class="reqn">\beta1</code> would be:
</p>
<p style="text-align: center;"><code class="reqn">\beta_{1} + \beta_{12}\bar{x}_{2} + \beta_{13}\bar{x}_{3} +
  \beta_{123}\bar{x}_{2}\bar{x}_{3}</code>
</p>
<p> (adapted from
<a href="https://stats.stackexchange.com/questions/65898/why-could-centering-independent-variables-change-the-main-effects-with-moderatio">here</a>)
</p>
<p>In addition, if <code>std.x = TRUE</code> or <code>unique.eff = TRUE</code> (see below), product
terms for interactive effects will be recalculated using mean-centred
variables, to ensure that standard deviations and variance inflation
factors (VIF) for predictors are calculated correctly (the model must be
refit for this latter purpose, to recalculate the variance-covariance
matrix).
</p>
<p>If <code>std.x = TRUE</code>, effects are scaled by multiplying by the standard
deviations of predictor variables (or terms), while if <code>std.y = TRUE</code> they
are divided by the standard deviation of the response variable (minus any
offsets). If the model is a GLM, this latter is calculated using the
link-transformed response (or an estimate of same) generated using the
function <code><a href="#topic+glt">glt()</a></code>. If both arguments are true, the effects are regarded as
'fully' standardised in the traditional sense, often referred to as
'betas'.
</p>
<p>If <code>unique.eff = TRUE</code> (default), effects are adjusted for
multicollinearity among predictors by dividing by the square root of the
VIFs (Dudgeon, 2016; Thompson et al., 2017; <code><a href="#topic+RVIF">RVIF()</a></code>). If they have also
been scaled by the standard deviations of x and y, this converts them to
semipartial correlations, i.e. the correlation between the unique
components of predictors (residualised on other predictors) and the
response variable. This measure of effect size is arguably much more
interpretable and useful than the traditional standardised coefficient, as
it always represents the unique effects of predictors and so can more
readily be compared both within and across models. Values range from zero
to +/- one rather than +/- infinity (as in the case of betas) – putting
them on the same scale as the bivariate correlation between predictor and
response. In the case of GLMs however, the measure is analogous but not
exactly equal to the semipartial correlation, so its values may not always
be bound between +/- one (such cases are likely rare). Importantly, for
ordinary linear models, the square of the semipartial correlation equals
the increase in R-squared when that variable is included last in the model
– directly linking the measure to unique variance explained. See
<a href="https://www.daviddisabato.com/blog/2016/4/8/on-effect-sizes-in-multiple-regression">here</a>
for additional arguments in favour of the use of semipartial correlations.
</p>
<p>If <code>refit.x</code>, <code>cen.x</code>, and <code>unique.eff</code> are <code>TRUE</code> and there are
interaction terms in the model, the model will be refit with any
(newly-)centred continuous predictors, in order to calculate correct VIFs
from the variance-covariance matrix. However, refitting may not be
necessary in some circumstances, for example where predictors have already
been mean-centred, and whose values will not subsequently be resampled
(e.g. parametric bootstrap). Setting <code>refit.x = FALSE</code> in such cases will
save time, especially with larger/more complex models and/or bootstrap
runs.
</p>
<p>If <code>incl.raw = TRUE</code>, raw (unstandardised) effects can also be appended,
i.e. those with all centring and scaling options set to <code>FALSE</code> (though
still adjusted for multicollinearity, where applicable). These may be of
interest in some cases, for example to compare their bootstrapped
distributions with those of standardised effects.
</p>
<p>If <code>R.squared = TRUE</code>, model R-squared values are appended to effects via
the <code><a href="#topic+R2">R2()</a></code> function, with any additional arguments passed via <code>R2.arg</code>.
</p>
<p>Finally, if <code>weights</code> are specified, the function calculates a weighted
average of standardised effects across a set (or sets) of different
candidate models for a particular response variable(s) (Burnham &amp; Anderson,
2002), via the <code><a href="#topic+avgEst">avgEst()</a></code> function.
</p>


<h3>Value</h3>

<p>A numeric vector of the standardised effects, or a list or nested
list of such vectors.
</p>


<h3>References</h3>

<p>Burnham, K. P., &amp; Anderson, D. R. (2002). <em>Model Selection and
Multimodel Inference: A Practical Information-Theoretic Approach</em> (2nd
ed.). Springer-Verlag. <a href="https://link.springer.com/book/10.1007/b97636">https://link.springer.com/book/10.1007/b97636</a>
</p>
<p>Dudgeon, P. (2016). A Comparative Investigation of Confidence Intervals for
Independent Variables in Linear Regression. <em>Multivariate Behavioral
Research</em>, <em>51</em>(2-3), 139-153. <a href="https://doi.org/10/gfww3f">doi:10/gfww3f</a>
</p>
<p>Thompson, C. G., Kim, R. S., Aloe, A. M., &amp; Becker, B. J. (2017).
Extracting the Variance Inflation Factor and Other Multicollinearity
Diagnostics from Typical Regression Results. <em>Basic and Applied Social
Psychology</em>, <em>39</em>(2), 81-90. <a href="https://doi.org/10/gfww2w">doi:10/gfww2w</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lme4)

# Standardised (direct) effects for SEM
m &lt;- shipley.sem
stdEff(m)
stdEff(m, cen.y = FALSE, std.y = FALSE)  # x-only
stdEff(m, std.x = FALSE, std.y = FALSE)  # centred only
stdEff(m, cen.x = FALSE, cen.y = FALSE)  # scaled only
stdEff(m, unique.eff = FALSE)  # include multicollinearity
stdEff(m, R.squared = TRUE)  # add R-squared
stdEff(m, incl.raw = TRUE)  # add unstandardised

# Demonstrate equality with effects from manually-standardised variables
# (gaussian models only)
m &lt;- shipley.growth[[3]]
d &lt;- data.frame(scale(na.omit(shipley)))
e1 &lt;- stdEff(m, unique.eff = FALSE)
e2 &lt;- coef(summary(update(m, data = d)))[, 1]
stopifnot(all.equal(e1, e2))

# Demonstrate equality with square root of increment in R-squared
# (ordinary linear models only)
m &lt;- lm(Growth ~ Date + DD + lat, data = shipley)
r2 &lt;- summary(m)$r.squared
e1 &lt;- stdEff(m)[-1]
en &lt;- names(e1)
e2 &lt;- sapply(en, function(i) {
  f &lt;- reformulate(en[!en %in% i])
  r2i &lt;- summary(update(m, f))$r.squared
  sqrt(r2 - r2i)
})
stopifnot(all.equal(e1, e2))

# Model-averaged standardised effects
m &lt;- shipley.growth  # candidate models
w &lt;- runif(length(m), 0, 1)  # weights
stdEff(m, w)
</code></pre>

<hr>
<h2 id='summary.semEff'>Summarise SEM Effects</h2><span id='topic+summary.semEff'></span>

<h3>Description</h3>

<p>A <code><a href="base.html#topic+summary">summary()</a></code> method for an object of class <code>"semEff"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'semEff'
summary(object, responses = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.semEff_+3A_object">object</code></td>
<td>
<p>An object of class <code>"semEff"</code>.</p>
</td></tr>
<tr><td><code id="summary.semEff_+3A_responses">responses</code></td>
<td>
<p>An optional character vector, the names of one or more SEM
response variables for which to return summaries (and/or <code>"Correlated Errors"</code>, where applicable). Can also be a numeric vector of indices of
<code>object</code>. If <code>NULL</code> (default), all summaries are returned.</p>
</td></tr>
<tr><td><code id="summary.semEff_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. Not currently
used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This summary method prints tables of effects and confidence
intervals for SEM endogenous (response) variables.
</p>


<h3>Value</h3>

<p>A summary table or tables of effects for the endogenous variables
(data frames).
</p>

<hr>
<h2 id='varW'>Weighted Variance</h2><span id='topic+varW'></span>

<h3>Description</h3>

<p>Calculate the weighted variance of <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varW(x, w = NULL, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varW_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="varW_+3A_w">w</code></td>
<td>
<p>A numeric vector of weights of the same length as <code>x</code>.</p>
</td></tr>
<tr><td><code id="varW_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, whether NAs in <code>x</code> should be removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculate the weighted variance of <code>x</code> via the weighted covariance
matrix (<code><a href="stats.html#topic+cov.wt">cov.wt()</a></code>). If no weights are supplied, the simple variance is
returned instead. As in <code><a href="stats.html#topic+weighted.mean">weighted.mean()</a></code>, <code>NA</code>s in <code>w</code> are not handled
specially and will return <code>NA</code> as result.
</p>


<h3>Value</h3>

<p>A numeric value, the weighted variance of <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+var">var()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Weighted variance
x &lt;- rnorm(30)
w &lt;- runif(30, 0, 1)
varW(x, w)

# Simple variance
varW(x)
stopifnot(varW(x) == var(x))

# NA handling
varW(c(x[1:29], NA), w, na.rm = TRUE)  # NA in x (removed)
varW(c(x[1:29], NA), w, na.rm = FALSE)  # NA in x (NA returned)
varW(x[1:29], w = c(w[1:29], NA))  # NA in w (NA returned)
</code></pre>

<hr>
<h2 id='VIF'>Generalised Variance Inflation Factors</h2><span id='topic+VIF'></span>

<h3>Description</h3>

<p>Calculate generalised variance inflation factors for terms in a
fitted model(s) via the variance-covariance matrix of coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VIF(mod, data = NULL, env = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VIF_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.</p>
</td></tr>
<tr><td><code id="VIF_+3A_data">data</code></td>
<td>
<p>An optional dataset, used to first refit the model(s).</p>
</td></tr>
<tr><td><code id="VIF_+3A_env">env</code></td>
<td>
<p>Environment in which to look for model data (if none supplied).
Defaults to the <code><a href="stats.html#topic+formula">formula()</a></code> environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>VIF()</code> calculates generalised variance inflation factors (GVIF) as
described in Fox &amp; Monette (1992), and also implemented in
<a href="https://rdrr.io/cran/car/man/vif.html"><code>car::vif()</code></a>. However, whereas
<code>vif()</code> returns both GVIF and GVIF^(1/(2*Df)) values, <code>VIF()</code> simply
returns the squared result of the latter measure, which equals the standard
VIF for single-coefficient terms and is the equivalent measure for
multi-coefficient terms (e.g. categorical or polynomial). Also, while
<code>vif()</code> returns values per model term (i.e. predictor variable), <code>VIF()</code>
returns values per coefficient, meaning that the same value will be
returned per coefficient for multi-coefficient terms. Finally, <code>NA</code> is
returned for any terms which could not be estimated in the model (e.g.
aliased).
</p>


<h3>Value</h3>

<p>A numeric vector of the VIFs, or an array, list of vectors/arrays, or
nested list.
</p>


<h3>References</h3>

<p>Fox, J., &amp; Monette, G. (1992). Generalized Collinearity
Diagnostics. <em>Journal of the American Statistical Association</em>, <em>87</em>,
178-183. <a href="https://doi.org/10/dm9wbw">doi:10/dm9wbw</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Model with two correlated terms
m &lt;- shipley.growth[[3]]
VIF(m)  # Date &amp; DD somewhat correlated
VIF(update(m, . ~ . - DD))  # drop DD

# Model with different types of predictor (some multi-coefficient terms)
d &lt;- data.frame(
  y = rnorm(100),
  x1 = rnorm(100),
  x2 = as.factor(rep(c("a", "b", "c", "d"), each = 25)),
  x3 = rep(1, 100)
)
m &lt;- lm(y ~ poly(x1, 2) + x2 + x3, data = d)
VIF(m)
</code></pre>

<hr>
<h2 id='xNam'>Get Model Term Names</h2><span id='topic+xNam'></span>

<h3>Description</h3>

<p>Extract term names from a fitted model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xNam(mod, intercept = TRUE, aliased = TRUE, list = FALSE, env = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xNam_+3A_mod">mod</code></td>
<td>
<p>A fitted model object, or a list or nested list of such objects.</p>
</td></tr>
<tr><td><code id="xNam_+3A_intercept">intercept</code></td>
<td>
<p>Logical, whether the intercept should be included.</p>
</td></tr>
<tr><td><code id="xNam_+3A_aliased">aliased</code></td>
<td>
<p>Logical, whether names of aliased terms should be included
(see Details).</p>
</td></tr>
<tr><td><code id="xNam_+3A_list">list</code></td>
<td>
<p>Logical, whether names should be returned as a list, with all
multi-coefficient terms grouped under their main term names.</p>
</td></tr>
<tr><td><code id="xNam_+3A_env">env</code></td>
<td>
<p>Environment in which to look for model data (used to construct the
model frame). Defaults to the <code><a href="stats.html#topic+formula">formula()</a></code> environment.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extract term names from a fitted model. Names of terms for which
coefficients cannot be estimated are also included if <code>aliased = TRUE</code>
(default). These may be terms which are perfectly correlated with other
terms in the model, so that the model design matrix is rank deficient.
</p>


<h3>Value</h3>

<p>A character vector or list/nested list of term names.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Term names from Shipley SEM
m &lt;- shipley.sem
xNam(m)
xNam(m, intercept = FALSE)

# Model with different types of predictor (some multi-coefficient terms)
d &lt;- data.frame(
  y = rnorm(100),
  x1 = rnorm(100),
  x2 = as.factor(rep(c("a", "b", "c", "d"), each = 25)),
  x3 = rep(1, 100)
)
m &lt;- lm(y ~ poly(x1, 2) + x2 + x3, data = d)
xNam(m)
xNam(m, aliased = FALSE)  # drop term that cannot be estimated (x3)
xNam(m, aliased = FALSE, list = TRUE)  # names as list
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
