<!DOCTYPE html><html lang="en"><head><title>Help for package textir</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {textir}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#congress109'><p> Ideology in Political Speeches</p></a></li>
<li><a href='#corr'><p>2nd momments of sparse matrices</p></a></li>
<li><a href='#pls'><p> Partial Least Squares</p></a></li>
<li><a href='#srproj'>
<p>Multinomial Inverse Regression (MNIR)</p></a></li>
<li><a href='#tfidf'><p>tf-idf</p></a></li>
<li><a href='#we8there'><p> On-Line Restaurant Reviews</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Inverse Regression for Text Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0-5</td>
</tr>
<tr>
<td>Author:</td>
<td>Matt Taddy &lt;mataddy@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15), distrom, gamlr, Matrix, stats, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS</td>
</tr>
<tr>
<td>Description:</td>
<td>Multinomial (inverse) regression inference for text documents and associated attributes.  For details see: Taddy (2013 JASA) Multinomial Inverse Regression for Text Analysis &lt;<a href="https://doi.org/10.48550/arXiv.1012.2098">doi:10.48550/arXiv.1012.2098</a>&gt; and Taddy (2015, AoAS), Distributed Multinomial Regression, &lt;<a href="https://doi.org/10.48550/arXiv.1311.6139">doi:10.48550/arXiv.1311.6139</a>&gt;. A minimalist partial least squares routine is also included.  Note that the topic modeling capability of earlier 'textir' is now a separate package, 'maptpx'.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matt Taddy &lt;mataddy@gmail.com&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://taddylab.com">http://taddylab.com</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-02-11 17:05:54 UTC; Matt</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-02-11 20:55:45 UTC</td>
</tr>
</table>
<hr>
<h2 id='congress109'> Ideology in Political Speeches </h2><span id='topic+congress109'></span><span id='topic+congress109Ideology'></span><span id='topic+congress109Counts'></span>

<h3>Description</h3>

<p> Phrase counts and ideology scores by speaker for members of the 109th US congress. </p>


<h3>Details</h3>

<p> This data originally appear in Gentzkow and Shapiro
(GS; 2010) and considers text of the 2005 Congressional Record,
containing all speeches in that year for members of the United States
House and Senate. In particular, GS record the number times each of
529 legislators used terms in a list of 1000 phrases (i.e., each
document is a year of transcripts for a single speaker). Associated
sentiments are repshare &ndash; the two-party vote-share from each
speaker's constituency (congressional district for representatives;
state for senators) obtained by George W. Bush in the 2004
presidential election &ndash; and the speaker's first and second
common-score values (from http://voteview.com). Full
parsing and sentiment details are in Taddy (2013; Section 2.1). </p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>congress109Counts</code></td>
<td>
<p> A <code>dgCMatrix</code> of phrase counts indexed by speaker-rows and phrase-columns.</p>
</td></tr>
<tr><td><code>congress109Ideology</code></td>
<td>
<p> A <code>data.frame</code> containing the associated <code>repshare</code> and common scores <code>[cs1,cs2]</code>, as well as speaker
characteristics: <code>party</code> (&lsquo;R&rsquo;epublican, &lsquo;D&rsquo;emocrat, or &lsquo;I&rsquo;ndependent), <code>state</code>, and <code>chamber</code> (&lsquo;H&rsquo;ouse or &lsquo;S&rsquo;enate). </p>
</td></tr>
</table>


<h3>Author(s)</h3>

 
<p>Matt Taddy, <a href="mailto:mataddy@gmail.com">mataddy@gmail.com</a>
</p>


<h3>References</h3>

 
<p>Gentzkow, M. and J. Shapiro (2010), <em>What drives media slant? Evidence from U.S. daily newspapers</em>. Econometrica 78, 35-7.  The full dataset is at <a href="http://dx.doi.org/10.3886/ICPSR26242">http://dx.doi.org/10.3886/ICPSR26242</a>.
</p>
<p>Taddy (2013), <em>Multinomial Inverse Regression for Text Analysis</em>.
<a href="http://arxiv.org/abs/1012.2098">http://arxiv.org/abs/1012.2098</a>
</p>


<h3>See Also</h3>

<p> srproj, pls, dmr, we8there </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(congress109)

## Bivariate sentiment factors (roll-call vote common scores)
covars &lt;- data.frame(gop=congress109Ideology$party=="R",
					cscore=congress109Ideology$cs1)
covars$cscore &lt;- covars$cscore - 
	tapply(covars$cscore,covars$gop,mean)[covars$gop+1]
rownames(covars) &lt;- rownames(congress109Ideology)

## cl=NULL implies a serial run. 
## To use a parallel library fork cluster, 
## uncomment the relevant lines below. 
## Forking is unix only; use PSOCK for windows
cl &lt;- NULL
# cl &lt;- makeCluster(detectCores(), type="FORK")
## small nlambda for a fast example
fitCS &lt;- dmr(cl, covars, congress109Counts, gamma=1, nlambda=10)
# stopCluster(cl)

## plot the fit
par(mfrow=c(1,2))
for(j in c("estate.tax","death.tax")){
	plot(fitCS[[j]], col=c("red","green"))
	mtext(j,line=2) }
legend("topright",bty="n",fill=c("red","green"),legend=names(covars))


## plot the IR sufficient reduction space
Z &lt;- srproj(fitCS, congress109Counts)
par(mfrow=c(1,1))
plot(Z, pch=21, bg=c(4,3,2)[congress109Ideology$party], main="SR projections")
## two pols
Z[c(68,388),]
</code></pre>

<hr>
<h2 id='corr'>2nd momments of sparse matrices</h2><span id='topic+corr'></span><span id='topic+sdev'></span>

<h3>Description</h3>

<p>Correlation and deviation in sparse matrices.</p>


<h3>Usage</h3>

<pre><code class='language-R'>corr(x, y)
sdev(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="corr_+3A_x">x</code></td>
<td>
<p>A <code>dgCMatrix</code> or <code>matrix</code> of counts. </p>
</td></tr>
<tr><td><code id="corr_+3A_y">y</code></td>
<td>
<p>A <code>matrix</code> with <code>nrow(y)=nrow(x)</code>. </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>corr</code> returns the <code>ncol(x)</code> by <code>ncol(y)</code> matrix of correlation between x and y, and <code>sdev</code> returns the column standard deviations.
</p>


<h3>Author(s)</h3>

<p>Matt Taddy <a href="mailto:taddy@chicagobooth.edu">taddy@chicagobooth.edu</a>
</p>


<h3>See Also</h3>

<p> pls, congress109 </p>


<h3>Examples</h3>

<pre><code class='language-R'># some congress examples
data(congress109)
r &lt;- corr(congress109Counts, congress109Ideology$repshare)
## 20 terms for Democrats
sort(r[,1])[1:20]
## 20 terms for Republicans
sort(r[,1], decreasing=TRUE)[1:20]
## 20 high variance terms
colnames(congress109Counts)[
	order(-sdev(congress109Counts))[1:20]]
 
 </code></pre>

<hr>
<h2 id='pls'> Partial Least Squares </h2><span id='topic+pls'></span><span id='topic+predict.pls'></span><span id='topic+summary.pls'></span><span id='topic+print.pls'></span><span id='topic+plot.pls'></span>

<h3>Description</h3>

<p> A simple partial least squares procedure. </p>


<h3>Usage</h3>

<pre><code class='language-R'>pls(x, y, K=1, scale=TRUE, verb=TRUE) 

## S3 method for class 'pls'
predict( object, newdata, type="response", ... )

## S3 method for class 'pls'
summary( object, ... )

## S3 method for class 'pls'
print(x, ... )

## S3 method for class 'pls'
plot(x, K=NULL, xlab="response", ylab=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pls_+3A_x">x</code></td>
<td>
<p> The covariate matrix, in either <code>dgCMatrix</code> or <code>matrix</code> format.   For <code>plot</code> and <code>print</code>: a <code>pls</code> output object. </p>
</td></tr>
<tr><td><code id="pls_+3A_y">y</code></td>
<td>
<p> The response vector.  </p>
</td></tr>
<tr><td><code id="pls_+3A_k">K</code></td>
<td>
<p> The number of desired PLS directions. In plotting, this can be a vector of directions to draw, otherwise directions <code>1:fit$K</code> are plotted.  </p>
</td></tr>
<tr><td><code id="pls_+3A_scale">scale</code></td>
<td>
<p> An indicator for whether to scale <code>x</code>; usually a good idea. 
If <code>scale=TRUE</code>, model is fit with x scaled to have variance-one columns.   </p>
</td></tr>
<tr><td><code id="pls_+3A_verb">verb</code></td>
<td>
<p> Whether or not to print a small progress script. </p>
</td></tr>
<tr><td><code id="pls_+3A_object">object</code></td>
<td>
<p>  For <code>predict</code> and <code>summary</code>: a <code>pls</code> output object.</p>
</td></tr>
<tr><td><code id="pls_+3A_newdata">newdata</code></td>
<td>
<p>   For <code>predict</code>, an <code>ncol(x)</code>-column matrix of 
new observations. Can be either a simple <code>matrix</code> or a <code>simple_triplet_matrix</code>.   </p>
</td></tr>
<tr><td><code id="pls_+3A_type">type</code></td>
<td>
<p>  For <code>predict</code>, a choice between output types: predictions scaled to the original response for <code>"response"</code>, fitted partial least squares directions for <code>"reduction"</code>. </p>
</td></tr>
<tr><td><code id="pls_+3A_xlab">xlab</code></td>
<td>
<p> For <code>plot</code>, the x-axis label. </p>
</td></tr>
<tr><td><code id="pls_+3A_ylab">ylab</code></td>
<td>
<p> For <code>plot</code>, the y-axis label. If null, will be set to &lsquo;pls(k) fitted values&rsquo; for each k.</p>
</td></tr>
<tr><td><code id="pls_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 <p><code>pls</code> fits the Partial Least Squares algorithm described in Taddy (2012; Appendix A.1). 
In particular, 	we obtain loadings <code>loadings[,k]</code> as the correlation between
<code>X</code> and factors <code>factors[,k]</code>, where <code>factors[,1]</code> is initialized      
at <code>scale(as.numeric(y))</code> and subsequent factors are orthogonal to
to the k'th pls direction, an ortho-normal transformation of <code>x%*%loadings[,k]</code>.
</p>
<p><code>predict.pls</code> returns predictions from the <code>object$fwdmod</code>
forward regression <code class="reqn">\alpha + \beta*z</code> for projections <code>z = x*loadings -
shift</code> derived from new covariates, or if <code>type="reduction"</code> it just returns these projections.
<code>summary.pls</code> prints dimension details and a quick summary of the 
corresponding forward regression. <code>plot.pls</code> draws response
versus fitted values for least-squares fit onto the K pls directions. </p>


<h3>Value</h3>

<p> Output from <code>pls</code> is a list with the following entries
</p>
<table role = "presentation">
<tr><td><code>y</code></td>
<td>
<p>The response vector. </p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The unchanged covariate matrix. </p>
</td></tr>
<tr><td><code>directions</code></td>
<td>
<p>The pls directions: <code>x%*%loadings - shift</code>. </p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>The pls loadings. </p>
</td></tr>
<tr><td><code>shift</code></td>
<td>
<p> Shift applied after projection to center the PLS directions.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p><code>K</code> columns of fitted <code>y</code> values for each number of directions. </p>
</td></tr>
<tr><td><code>fwdmod</code></td>
<td>
<p> The <code>lm</code> object from forward regression <code>lm(as.numeric(y)~directions)</code>. </p>
</td></tr>
</table>
<p><code>predict.pls</code> outputs either a vector of predicted resonse or an <code>nrow(newcounts)</code> by <code>ncol(object$loadings)</code> matrix of pls directions for each new observation. Summary and plot produce return nothing.
</p>


<h3>Author(s)</h3>

<p> Matt Taddy <a href="mailto:taddy@chicagobooth.edu">taddy@chicagobooth.edu</a> </p>


<h3>References</h3>

<p>Taddy (2013), <em>Multinomial Inverse Regression for Text Analysis</em>.
Journal of the American Statistical Association 108.
</p>
<p>Wold, H. (1975), <em>Soft modeling by latent variables: The nonlinear iterative partial least squares approach</em>. 
In Perspectives in Probability and Statistics, Papers in Honour of M.S. Bartlett.
</p>


<h3>See Also</h3>

<p>normalize, sdev, corr, congress109
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(congress109)
x &lt;- t( t(congress109Counts)/rowSums(congress109Counts) )
summary( fit &lt;- pls(x, congress109Ideology$repshare, K=3) )
plot(fit, pch=21, bg=c(4,3,2)[congress109Ideology$party])
predict(fit, newdata=x[c(68,388),])
</code></pre>

<hr>
<h2 id='srproj'>
Multinomial Inverse Regression (MNIR)</h2><span id='topic+mnlm'></span><span id='topic+srproj'></span>

<h3>Description</h3>

<p>Estimation of MNIR sufficient reduction projections.   Note that <code>mnlm</code> is just a call to <code>dmr</code> from the <code>distrom</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>srproj(obj, counts, dir=1:K, ...)
mnlm(cl, covars, counts, mu=NULL, bins=NULL, verb=0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="srproj_+3A_cl">cl</code></td>
<td>
<p>A <code>parallel</code> library socket cluster.  See the same argument in <code>help(dmr)</code> for details. </p>
</td></tr>
<tr><td><code id="srproj_+3A_covars">covars</code></td>
<td>
<p>A dense <code>matrix</code> 
or sparse <code>Matrix</code> of covariates.
This should not include the intercept.  See the same argument in <code>help(dmr)</code> for details.  </p>
</td></tr>
<tr><td><code id="srproj_+3A_counts">counts</code></td>
<td>
<p>A dense <code>matrix</code> 
or sparse <code>Matrix</code> of
response counts (e.g., token counts in text mining). 
See the same argument in <code>help(dmr)</code> for details. For <code>srproj</code>,
this must have the same number of columns as the response dimensions (vocabulary size) in <code>obj</code>.</p>
</td></tr>
<tr><td><code id="srproj_+3A_mu">mu</code></td>
<td>

<p>Pre-specified fixed effects for each observation in the Poisson regression linear equation.  See the same argument in <code>help(dmr)</code> for details.  </p>
</td></tr>
<tr><td><code id="srproj_+3A_bins">bins</code></td>
<td>
<p>Number of bins into which we will attempt to collapse each column of <code>covars</code>.  <code>bins=NULL</code>
does no collapsing. See the same argument in <code>help(dmr)</code> for details.</p>
</td></tr>
<tr><td><code id="srproj_+3A_verb">verb</code></td>
<td>
<p>Whether to print some info.  See the same argument in <code>help(dmr)</code> for details.</p>
</td></tr>
<tr><td><code id="srproj_+3A_obj">obj</code></td>
<td>
<p>Either a <code>dmr</code> object, as returned from <code>mnlm</code>, or the <code>dmrcoef</code> object obtained by calling <code>coef</code> on the output of <code>mnlm</code> or <code>dmr</code>.  The latter will be faster, since <code>coef.dmr</code> is called inside <code>srproj</code> otherwise.</p>
</td></tr>
<tr><td><code id="srproj_+3A_dir">dir</code></td>
<td>
<p>The attribute (<code>covar</code>) dimensions onto which you want to project.  
The default is all dimensions: <code>1:K</code>, where <code>K</code> is the number of columns in the <code>covars</code> argument to mnlm.</p>
</td></tr>
<tr><td><code id="srproj_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code>gamlr</code> from <code>dmr</code> (or <code>mnlm</code>), and to <code>coef.dmr</code> from <code>srproj</code>.  See <code>help(gamlr)</code> and <code>help(dmr)</code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions provide the first two steps of multinomial inverse regression (see MNIR paper).
</p>
<p><code>mnlm</code> fits multinomial logistic regression
parameters under gamma lasso penalization on a factorized Poisson likelihood.  The <code>mnlm</code> function, which remains in this package for backwards compatability only, is just call to the <code>dmr</code> function of the <code>distrom</code> library (see DMR paper).  For simplicity, we recommend using <code>dmr</code> instead of <code>mnlm</code>. For model selection, coefficients, prediction, and plotting see the relevant functions in <code>help(dmr)</code>.
</p>
<p><code>srproj</code> calculates the MNIR  Sufficient Reduction projection from text <code>counts</code> on to the attribute dimensions of interest (<code>covars</code> in <code>mnlm</code> or <code>dmr</code>).  In particular, for counts <code class="reqn">C</code>, with row sums <code class="reqn">m</code>, and <code>mnlm</code>/<code>dmr</code> coefficients <code class="reqn">\phi_j</code> corresponding to attribute <code class="reqn">j</code>,
<code class="reqn">z_j = C'\phi_j/m</code> is the SR projection in the direction of <code class="reqn">j</code>.  The MNIR paper explains how <code class="reqn">V=[v_1 ... v_K]</code>, your original covariates/attributes, are independent of text counts <code class="reqn">C</code> given SR projections <code class="reqn">Z=[z_1 ... z_K]</code>.  
</p>
<p>The final step of MNIR is &lsquo;forward regression&rsquo; for any element of <code class="reqn">V</code> onto <code class="reqn">Z</code> and the remaining elements of <code class="reqn">V</code>.  We do not provide a function for this because you are free to use whatever you want; see the MNIR and DMR papers for linear, logistic, and random forest forward regression examples.
</p>
<p>Note that if you were previously using <code>textir</code> not for inverse regression, but rather just as fast code for multinomial logistic regression, you probably want to work directly with the <code>gamlr</code> (binary response) or <code>dmr</code> (multinomial response) packages.
</p>


<h3>Value</h3>

<p><code>srproj</code> returns a matrix with columns corresponding to directions <code>dir</code>, plus an additional column <code>m</code> holding the row totals of <code>counts</code>.
<code>mnlm</code> returns a <code>dmr</code> s3 object.  See <code>help(dmr)</code> for details.
</p>


<h3>Author(s)</h3>

<p>Matt Taddy <a href="mailto:mataddy@gmail.com">mataddy@gmail.com</a>
</p>


<h3>References</h3>

<p>Taddy (2013, JASA), <em>Multinomial Inverse Regression for Text Analysis</em> (MNIR).
</p>
<p>Taddy (2015, AoAS), <em>Distributed Multinomial Regression</em> (DMR).  
</p>
<p>Taddy (2016, JCGS), <em>The Gamma Lasso</em> (GL). 
</p>


<h3>See Also</h3>

<p>congress109, we8there, dmr
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Ripley's Cushing Data; see help(Cushings) ###
library(MASS)
data(Cushings)
Cushings[,1:2] &lt;- log(Cushings[,1:2])
train &lt;- Cushings[Cushings$Type!="u",]
newdata &lt;- as.matrix(Cushings[Cushings$Type == "u", 1:2])

## fit, coefficients, predict, and plot

# you could replace 'mnlm' with 'dmr' here.
fit &lt;- mnlm(NULL, 
  covars=train[,1:2], 
  counts=factor(train$Type))

## dmr applies corrected AICc selection by default
round(coef(fit),1) 
round(predict(fit, newdata, type="response"),1)
par(mfrow=c(1,3))
for(j in c("a","b","c")){ 
  plot(fit[[j]]); mtext(j,line=2) }

## see we8there and congress109 for MNIR and srproj examples
 
</code></pre>

<hr>
<h2 id='tfidf'>tf-idf</h2><span id='topic+tfidf'></span>

<h3>Description</h3>

<p>term frequency, inverse document frequency</p>


<h3>Usage</h3>

<pre><code class='language-R'>tfidf(x,normalize=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tfidf_+3A_x">x</code></td>
<td>
<p>A <code>dgCMatrix</code> or <code>matrix</code> of counts. </p>
</td></tr>
<tr><td><code id="tfidf_+3A_normalize">normalize</code></td>
<td>
<p>Whether to normalize term frequency by document totals.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of the same type as <code>x</code>, with values replaced by the tf-idf
</p>
<p style="text-align: center;"><code class="reqn"> f_{ij} * \log[n/(d_j+1)], </code>
</p>

<p>where <code class="reqn">f_{ij}</code> is <code class="reqn">x_{ij}/m_i</code> or <code class="reqn">x_{ij}</code>, depending on <code>normalize</code>,
and <code class="reqn">d_j</code> is the number of documents containing token <code class="reqn">j</code>.
</p>


<h3>Author(s)</h3>

<p>Matt Taddy <a href="mailto:taddy@chicagobooth.edu">taddy@chicagobooth.edu</a>
</p>


<h3>See Also</h3>

<p> pls, we8there </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(we8there)
## 20 high-variance tf-idf terms
colnames(we8thereCounts)[
	order(-sdev(tfidf(we8thereCounts)))[1:20]]
 
 </code></pre>

<hr>
<h2 id='we8there'> On-Line Restaurant Reviews </h2><span id='topic+we8there'></span><span id='topic+we8thereRatings'></span><span id='topic+we8thereCounts'></span>

<h3>Description</h3>

<p>Counts for 2804 bigrams in 6175 restaurant reviews from the site www.we8there.com. </p>


<h3>Details</h3>

<p> The short user-submitted reviews are accompanied by a five-star rating on four specific aspects of restaurant quality - food, service, value, and atmosphere - as well as the overall experience.  The reviews originally appear in Maua and Cozman (2009), and the parsing details behind these specific counts are in Taddy (MNIR; 2013). </p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>we8thereCounts</code></td>
<td>
<p> A <code>dgCMatrix</code> of phrase counts indexed by review-rows and bigram-columns.</p>
</td></tr>
<tr><td><code>we8thereRatings</code></td>
<td>
<p> A <code>matrix</code> containing the associated review ratings. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

 
<p>Matt Taddy, <a href="mailto:mataddy@gmail.com">mataddy@gmail.com</a>
</p>


<h3>References</h3>

 
<p>Maua, D.D. and Cozman, F.G. (2009), <em>Representing and classifying user reviews</em>. In ENIA '09: VIII Enconro Nacional de Inteligencia Artificial, Brazil.
</p>
<p>Taddy (2013, JASA), <em>Multinomial Inverse Regression for Text Analysis</em>.
</p>
<p>Taddy (2013, AoAS), <em>Distributed Multinomial Regression</em>.
</p>


<h3>See Also</h3>

<p> dmr, srproj </p>


<h3>Examples</h3>

<pre><code class='language-R'>## some multinomial inverse regression
## we'll regress counts onto 5-star overall rating
data(we8there)

## cl=NULL implies a serial run. 
## To use a parallel library fork cluster, 
## uncomment the relevant lines below. 
## Forking is unix only; use PSOCK for windows
cl &lt;- NULL
# cl &lt;- makeCluster(detectCores(), type="FORK")
## small nlambda for a fast example
fits &lt;- dmr(cl, we8thereRatings[,'Overall',drop=FALSE], 
			we8thereCounts, bins=5, gamma=1, nlambda=10)
# stopCluster(cl)

## plot fits for a few individual terms
terms &lt;- c("first date","chicken wing",
			"ate here", "good food",
			"food fabul","terribl servic")
par(mfrow=c(3,2))
for(j in terms)
{ 	plot(fits[[j]]); mtext(j,font=2,line=2) }
 
## extract coefficients
B &lt;- coef(fits)
mean(B[2,]==0) # sparsity in loadings
## some big loadings in IR
B[2,order(B[2,])[1:10]]
B[2,order(-B[2,])[1:10]]

## do MNIR projection onto factors
z &lt;- srproj(B,we8thereCounts) 

## fit a fwd model to the factors
summary(fwd &lt;- lm(we8thereRatings$Overall ~ z)) 

## truncate the fwd predictions to our known range
fwd$fitted[fwd$fitted&lt;1] &lt;- 1
fwd$fitted[fwd$fitted&gt;5] &lt;- 5
## plot the fitted rating by true rating
par(mfrow=c(1,1))
plot(fwd$fitted ~ factor(we8thereRatings$Overall), 
	varwidth=TRUE, col="lightslategrey")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
