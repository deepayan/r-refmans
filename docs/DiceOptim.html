<!DOCTYPE html><html><head><title>Help for package DiceOptim</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DiceOptim}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AEI'><p>Augmented Expected Improvement</p></a></li>
<li><a href='#AEI.grad'><p>AEI's Gradient</p></a></li>
<li><a href='#AKG'><p>Approximate Knowledge Gradient (AKG)</p></a></li>
<li><a href='#AKG.grad'><p>AKG's Gradient</p></a></li>
<li><a href='#branin2'><p>2D test function</p></a></li>
<li><a href='#checkPredict'><p>Prevention of numerical instability for a new observation</p></a></li>
<li><a href='#crit_AL'><p>Expected Augmented Lagrangian Improvement</p></a></li>
<li><a href='#crit_EFI'><p>Expected Feasible Improvement</p></a></li>
<li><a href='#crit_SUR_cst'><p>Stepwise Uncertainty Reduction criterion</p></a></li>
<li><a href='#critcst_optimizer'><p>Maximization of constrained Expected Improvement criteria</p></a></li>
<li><a href='#DiceOptim-package'><p>Kriging-based optimization methods for computer experiments</p></a></li>
<li><a href='#easyEGO'><p>User-friendly wrapper of the functions <code>fastEGO.nsteps</code> and <code>TREGO.nsteps</code>.</p>
Generates initial DOEs and kriging models (objects of class <code>km</code>),
and executes <code>nsteps</code> iterations of either EGO or TREGO.</a></li>
<li><a href='#easyEGO.cst'><p>EGO algorithm with constraints</p></a></li>
<li><a href='#EGO.cst'><p>Sequential constrained Expected Improvement maximization and model re-estimation,</p>
with a number of iterations fixed in advance by the user</a></li>
<li><a href='#EGO.nsteps'><p>Sequential EI maximization and model re-estimation, with a number of</p>
iterations fixed in advance by the user</a></li>
<li><a href='#EI'><p>Analytical expression of the Expected Improvement criterion</p></a></li>
<li><a href='#EI.grad'><p>Analytical gradient of the Expected Improvement criterion</p></a></li>
<li><a href='#EQI'><p>Expected Quantile Improvement</p></a></li>
<li><a href='#EQI.grad'><p>EQI's Gradient</p></a></li>
<li><a href='#fastEGO.nsteps'><p>Sequential EI maximization and model re-estimation, with a number of</p>
iterations fixed in advance by the user</a></li>
<li><a href='#fastfun'><p>Fastfun function</p></a></li>
<li><a href='#fastfun-class'><p>Class for fast to compute objective.</p></a></li>
<li><a href='#goldsteinprice'><p>2D test function</p></a></li>
<li><a href='#hartman4'><p>4D test function</p></a></li>
<li><a href='#integration_design_cst'><p>Generic function to build integration points (for the SUR criterion)</p></a></li>
<li><a href='#kriging.quantile'><p>Kriging quantile</p></a></li>
<li><a href='#kriging.quantile.grad'><p>Analytical gradient of the Kriging quantile of level beta</p></a></li>
<li><a href='#max_AEI'><p>Maximizer of the Augmented Expected Improvement criterion function</p></a></li>
<li><a href='#max_AKG'><p>Maximizer of the Expected Quantile Improvement criterion function</p></a></li>
<li><a href='#max_crit'><p>Maximization of the Expected Improvement criterion</p></a></li>
<li><a href='#max_EI'><p>Maximization of the Expected Improvement criterion</p></a></li>
<li><a href='#max_EQI'><p>Maximizer of the Expected Quantile Improvement criterion function</p></a></li>
<li><a href='#max_qEI'><p>Maximization of multipoint expected improvement criterion (qEI)</p></a></li>
<li><a href='#min_quantile'><p>Minimization of the Kriging quantile.</p></a></li>
<li><a href='#noisy.optimizer'><p>Optimization of homogenously noisy functions based on Kriging</p></a></li>
<li><a href='#ParrConstraint'><p>2D constraint function</p></a></li>
<li><a href='#qEGO.nsteps'><p>Sequential multipoint Expected improvement (qEI) maximizations and model</p>
re-estimation</a></li>
<li><a href='#qEI'><p>Analytical expression of the multipoint expected improvement (qEI)</p>
criterion</a></li>
<li><a href='#qEI.grad'><p>Gradient of the multipoint expected improvement (qEI) criterion</p></a></li>
<li><a href='#rosenbrock4'><p>4D test function</p></a></li>
<li><a href='#sampleFromEI'><p>Sampling points according to the expected improvement criterion</p></a></li>
<li><a href='#sphere6'><p>6D sphere function</p></a></li>
<li><a href='#test_feas_vec'><p>Test constraints violation (vectorized)</p></a></li>
<li><a href='#TREGO.nsteps'><p>Trust-region based EGO algorithm.</p></a></li>
<li><a href='#update_km_noisyEGO'><p>Update of one or two Kriging models when adding new observation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.1.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Kriging-Based Optimization for Computer Experiments</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-01-29</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient Global Optimization (EGO) algorithm as described in "Roustant et al. (2012)" &lt;<a href="https://doi.org/10.18637%2Fjss.v051.i01">doi:10.18637/jss.v051.i01</a>&gt; and adaptations for problems with noise ("Picheny and Ginsbourger, 2012") &lt;<a href="https://doi.org/10.1016%2Fj.csda.2013.03.018">doi:10.1016/j.csda.2013.03.018</a>&gt;, parallel infill, and problems with constraints.</td>
</tr>
<tr>
<td>Depends:</td>
<td>DiceKriging (&ge; 1.2), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>randtoolbox, pbivnorm, rgenoud, mnormt, DiceDesign, parallel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>KrigInv, GPareto</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://dice.emse.fr/">http://dice.emse.fr/</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-02-01 08:25:48 UTC; victor</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-02-02 00:10:23 UTC</td>
</tr>
<tr>
<td>Author:</td>
<td>Victor Picheny [aut, cre],
  David Ginsbourger Green [aut],
  Olivier Roustant [aut],
  Mickael Binois [ctb],
  Sebastien Marmin [ctb],
  Tobias Wagner [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Victor Picheny &lt;victor.picheny@toulouse.inra.fr&gt;</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
</table>
<hr>
<h2 id='AEI'>Augmented Expected Improvement</h2><span id='topic+AEI'></span>

<h3>Description</h3>

<p>Evaluation of the Augmented Expected Improvement (AEI) criterion, which is
a modification of the classical EI criterion for noisy functions.  The AEI
consists of the regular EI multiplied by a penalization function that
accounts for the disminishing payoff of observation replicates. The current
minimum y.min is chosen as the kriging predictor of the observation with
smallest kriging quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AEI(x, model, new.noise.var = 0, y.min = NULL, type = "UK", envir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AEI_+3A_x">x</code></td>
<td>
<p>the input vector at which one wants to evaluate the criterion</p>
</td></tr>
<tr><td><code id="AEI_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="AEI_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>the (scalar) noise variance of the future observation.</p>
</td></tr>
<tr><td><code id="AEI_+3A_y.min">y.min</code></td>
<td>
<p>The kriging predictor at the current best point (point with
smallest kriging quantile).  If not provided, this quantity is evaluated.</p>
</td></tr>
<tr><td><code id="AEI_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="AEI_+3A_envir">envir</code></td>
<td>
<p>environment for saving intermediate calculations and reusing
them within AEI.grad</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Augmented Expected Improvement
</p>


<h3>Author(s)</h3>

<p>Victor Picheny  
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>D. Huang, T.T. Allen, W.I. Notz, and N. Zeng (2006), Global Optimization of
Stochastic Black-Box Systems via Sequential Kriging Meta-Models,
<em>Journal of Global Optimization</em>, 34, 441-466.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

##########################################################################
###    AEI SURFACE ASSOCIATED WITH AN ORDINARY KRIGING MODEL        ####
### OF THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################

set.seed(421)

# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
            covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
	    lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)
crit.grid &lt;- rep(0,1,nt)
func.grid &lt;- rep(0,1,nt)

crit.grid &lt;- apply(design.grid, 1, AEI, model=model, new.noise.var=noise.var)
func.grid &lt;- apply(design.grid, 1, test.function)

# Compute kriging mean and variance on a grid
names(design.grid) &lt;- c("V1","V2")
pred &lt;- predict.km(model, newdata=design.grid, type="UK")
mk.grid &lt;- pred$m
sk.grid &lt;- pred$sd

# Plot actual function
z.grid &lt;- matrix(func.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Actual function");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot Kriging mean
z.grid &lt;- matrix(mk.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Kriging mean");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot Kriging variance
z.grid &lt;- matrix(sk.grid^2, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Kriging variance");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot AEI criterion
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("AEI");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

</code></pre>

<hr>
<h2 id='AEI.grad'>AEI's Gradient</h2><span id='topic+AEI.grad'></span>

<h3>Description</h3>

<p>Analytical gradient of the Augmented Expected Improvement (AEI) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AEI.grad(x, model, new.noise.var = 0, y.min = NULL, type = "UK", envir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AEI.grad_+3A_x">x</code></td>
<td>
<p>the input vector at which one wants to evaluate the criterion</p>
</td></tr>
<tr><td><code id="AEI.grad_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="AEI.grad_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>the (scalar) noise variance of the new observation.</p>
</td></tr>
<tr><td><code id="AEI.grad_+3A_y.min">y.min</code></td>
<td>
<p>The kriging predictor at the current best point (point with
smallest kriging quantile). If not provided, this quantity is evaluated.</p>
</td></tr>
<tr><td><code id="AEI.grad_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="AEI.grad_+3A_envir">envir</code></td>
<td>
<p>environment for inheriting intermediate calculations from AEI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gradient of the Augmented Expected Improvement
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(421)

# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
        covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
	lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 8 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)

crit.grid &lt;- apply(design.grid, 1, AEI, model=model, new.noise.var=noise.var)
crit.grad &lt;- t(apply(design.grid, 1, AEI.grad, model=model, new.noise.var=noise.var))

z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
contour(x.grid,y.grid, z.grid, 30)
title("AEI and its gradient")
points(model@X[,1],model@X[,2],pch=17,col="blue")

for (i in 1:nt)
{
 x &lt;- design.grid[i,]
 suppressWarnings(arrows(x$Var1,x$Var2, x$Var1+crit.grad[i,1]*.6,x$Var2+crit.grad[i,2]*.6,
length=0.04,code=2,col="orange",lwd=2))
}

</code></pre>

<hr>
<h2 id='AKG'>Approximate Knowledge Gradient (AKG)</h2><span id='topic+AKG'></span>

<h3>Description</h3>

<p>Evaluation of the Approximate Knowledge Gradient (AKG) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AKG(x, model, new.noise.var = 0, type = "UK", envir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AKG_+3A_x">x</code></td>
<td>
<p>the input vector at which one wants to evaluate the criterion</p>
</td></tr>
<tr><td><code id="AKG_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="AKG_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>(scalar) noise variance of the future observation.
Default value is 0 (noise-free observation).</p>
</td></tr>
<tr><td><code id="AKG_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="AKG_+3A_envir">envir</code></td>
<td>
<p>environment for saving intermediate calculations and reusing
them within AKG.grad</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Approximate Knowledge Gradient
</p>


<h3>Author(s)</h3>

<p>Victor Picheny  
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>Scott, W., Frazier, P., Powell, W. (2011). 
The correlated knowledge gradient for simulation optimization of continuous parameters using gaussian process regression. 
<em>SIAM Journal on Optimization</em>, 21(3), 996-1026.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##########################################################################
###    AKG SURFACE ASSOCIATED WITH AN ORDINARY KRIGING MODEL          ####
### OF THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################
set.seed(421)
# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
  y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
            covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
            lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)

crit.grid &lt;- apply(design.grid, 1, AKG, model=model, new.noise.var=noise.var)
func.grid &lt;- apply(design.grid, 1, test.function)

# Compute kriging mean and variance on a grid
names(design.grid) &lt;- c("V1","V2")
pred &lt;- predict.km(model, newdata=design.grid, type="UK")
mk.grid &lt;- pred$m
sk.grid &lt;- pred$sd

# Plot actual function
z.grid &lt;- matrix(func.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
               plot.axes = {title("Actual function");
                            points(model@X[,1],model@X[,2],pch=17,col="blue"); 
                            axis(1); axis(2)})

# Plot Kriging mean
z.grid &lt;- matrix(mk.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
               plot.axes = {title("Kriging mean");
                            points(model@X[,1],model@X[,2],pch=17,col="blue"); 
                            axis(1); axis(2)})

# Plot Kriging variance
z.grid &lt;- matrix(sk.grid^2, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
               plot.axes = {title("Kriging variance");
                            points(model@X[,1],model@X[,2],pch=17,col="blue"); 
                            axis(1); axis(2)})

# Plot AKG criterion
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
               plot.axes = {title("AKG");
                            points(model@X[,1],model@X[,2],pch=17,col="blue"); 
                            axis(1); axis(2)})

</code></pre>

<hr>
<h2 id='AKG.grad'>AKG's Gradient</h2><span id='topic+AKG.grad'></span>

<h3>Description</h3>

<p>Gradient of the Approximate Knowledge Gradient (AKG) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AKG.grad(x, model, new.noise.var = 0, type = "UK", envir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AKG.grad_+3A_x">x</code></td>
<td>
<p>the input vector at which one wants to evaluate the criterion</p>
</td></tr>
<tr><td><code id="AKG.grad_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="AKG.grad_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>(scalar) noise variance of the future observation.
Default value is 0 (noise-free observation).</p>
</td></tr>
<tr><td><code id="AKG.grad_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="AKG.grad_+3A_envir">envir</code></td>
<td>
<p>optional: environment for reusing intermediate calculations
from AKG</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gradient of the Approximate Knowledge Gradient
</p>


<h3>Author(s)</h3>

<p>Victor Picheny
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########################################################################
###    AKG SURFACE AND ITS GRADIENT ASSOCIATED WITH AN ORDINARY       ####
###                                            KRIGING MODEL          ####
### OF THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################
set.seed(421)

# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
        covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
	lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 9 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)

crit.grid &lt;- apply(design.grid, 1, AKG, model=model, new.noise.var=noise.var)
crit.grad &lt;- t(apply(design.grid, 1, AKG.grad, model=model, new.noise.var=noise.var))

z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
contour(x.grid,y.grid, z.grid, 30)
title("AKG and its gradient")
points(model@X[,1],model@X[,2],pch=17,col="blue")

for (i in 1:nt)
{
 x &lt;- design.grid[i,]
 suppressWarnings(arrows(x$Var1,x$Var2, x$Var1+crit.grad[i,1]*.2,x$Var2+crit.grad[i,2]*.2,
length=0.04,code=2,col="orange",lwd=2))
}
</code></pre>

<hr>
<h2 id='branin2'>2D test function</h2><span id='topic+branin2'></span>

<h3>Description</h3>

<p>Branin 2-dimensional test function (standardized version).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>branin2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="branin2_+3A_x">x</code></td>
<td>
<p>a 2-dimensional vector specifying the location where the function
is to be evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The branin2 (standardized version) function is defined over the domain
<code>[0,1]^2</code>. It has 3 global minimizers : x*,1 = c(0.1239, 0.8183), x*,2
= c(0.5428, 0.1517), x*.3 = c(0.9617, 0.1650), with minimum f(x*,i) =
-1.047410
</p>


<h3>Value</h3>

<p>A real number equal to the branin2 function values at <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Tobias Wagner 
</p>
<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
design &lt;- matrix(runif(200), 200, 2)
response &lt;- apply(design, 1, branin2)

</code></pre>

<hr>
<h2 id='checkPredict'>Prevention of numerical instability for a new observation</h2><span id='topic+checkPredict'></span>

<h3>Description</h3>

<p>Check that the new point is not too close to already known observations to avoid numerical issues.
Closeness can be estimated with several distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkPredict(x, model, threshold = 1e-04, distance = "covdist", type = "UK")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkPredict_+3A_x">x</code></td>
<td>
<p>a vector representing the input to check,</p>
</td></tr>
<tr><td><code id="checkPredict_+3A_model">model</code></td>
<td>
<p>list of objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>, one for each objective functions,</p>
</td></tr>
<tr><td><code id="checkPredict_+3A_threshold">threshold</code></td>
<td>
<p>optional value for the minimal distance to an existing observation, default to <code>1e-4</code>,</p>
</td></tr>
<tr><td><code id="checkPredict_+3A_distance">distance</code></td>
<td>
<p>selection of the distance between new observations, between &quot;<code>euclidean</code>&quot;,
&quot;<code>covdist</code>&quot; (default) and &quot;<code>covratio</code>&quot;, see details,</p>
</td></tr>
<tr><td><code id="checkPredict_+3A_type">type</code></td>
<td>
<p>&quot;<code>SK</code>&quot; or &quot;<code>UK</code>&quot; (default), depending whether uncertainty related to trend estimation has to be taken into account.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the distance between <code>x</code> and the closest observations in <code>model</code> is below
<code>threshold</code>, <code>x</code> should not be evaluated to avoid numerical instabilities.
The distance can simply be the Euclidean distance or the canonical distance associated with the kriging covariance k: 
</p>
<p style="text-align: center;"><code class="reqn">d(x,y) = \sqrt{k(x,x) - 2k(x,y) + k(y,y)}.</code>
</p>
 
<p>The last solution is the ratio between the prediction variance at <code>x</code> and the variance of the process.
</p>


<h3>Value</h3>

<p><code>TRUE</code> if the point should not be tested.
</p>


<h3>Author(s)</h3>

<p>Mickael Binois
</p>

<hr>
<h2 id='crit_AL'>Expected Augmented Lagrangian Improvement</h2><span id='topic+crit_AL'></span>

<h3>Description</h3>

<p>Computes the Expected Augmented Lagrangian Improvement at current location, with our without slack variables. Depending on the cases,
the computation is either analytical (very fast), based on MC integration (slow) or on the CDF of a weighted sum of non-central
chi-square (WNCS) variates (intermediate)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crit_AL(
  x,
  model.fun,
  model.constraint,
  equality = FALSE,
  critcontrol = NULL,
  type = "UK"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crit_AL_+3A_x">x</code></td>
<td>
<p>either a vector representing the design or the design AND slack variables (see details)</p>
</td></tr>
<tr><td><code id="crit_AL_+3A_model.fun">model.fun</code></td>
<td>
<p>object of class <code><a href="DiceKriging.html#topic+km">km</a></code> correspostnding to the objective function,
or, if the objective function is fast-to-evaluate, a <code><a href="#topic+fastfun">fastfun</a></code> object,</p>
</td></tr>
<tr><td><code id="crit_AL_+3A_model.constraint">model.constraint</code></td>
<td>
<p>either one or a list of objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>, one for each constraint function,</p>
</td></tr>
<tr><td><code id="crit_AL_+3A_equality">equality</code></td>
<td>
<p>either <code>FALSE</code> if all constraints are for inequalities, or a vector of Booleans indicating which are equalities</p>
</td></tr>
<tr><td><code id="crit_AL_+3A_critcontrol">critcontrol</code></td>
<td>
<p>optional list with the following arguments:
</p>

<ul>
<li><p><code>slack</code>: logical. If TRUE, slack variables are used for inequality constraints (see Details)
</p>
</li>
<li><p><code>rho</code>: penalty term (scalar),
</p>
</li>
<li><p><code>lambda</code>: Lagrange multipliers (vector of size the number of constraints),
</p>
</li>
<li><p><code>elit</code>: logical. If TRUE, sets the criterion to zero for all x's not improving the objective function
</p>
</li>
<li><p><code>n.mc</code>: number of Monte-Carlo drawings used to evaluate the criterion (see Details)
</p>
</li>
<li><p><code>nt</code>: number of discretization points for the WNCS distribution (see Details)
</p>
</li>
<li> <p><code>tolConstraints</code>, an optional vector giving a tolerance (&gt; 0) for each of the constraints (equality or inequality).
It is highly recommended to use it when there are equality constraints since the default tolerance of 0.05 in such case might not be suited.
</p>
</li></ul>

<p>Options for the <code><a href="#topic+checkPredict">checkPredict</a></code> function: <code>threshold</code> (<code>1e-4</code>) and <code>distance</code> (<code>covdist</code>) 
are used to avoid numerical issues occuring when adding points too close to the existing ones.</p>
</td></tr>
<tr><td><code id="crit_AL_+3A_type">type</code></td>
<td>
<p>&quot;<code>SK</code>&quot; or &quot;<code>UK</code>&quot; (by default), depending whether uncertainty related to trend estimation 
has to be taken into account.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AL can be used with or without the help of slack variables for the inequality constraints. 
If <code>critcontrol$slack=FALSE</code>:
With a single constraint (inequality or equality) and a fast objective, a very fast formula is
used to compute the criterion (recommended setting). 
Otherwise, an MC estimator of the criterion is used, which is much more costly. The argument 
<code>critcontrol$n.mc</code> tunes the precision of the estimator.
On both cases <code>x</code> must be of size <code>d</code>.
</p>
<p>If <code>critcontrol$slack=TRUE</code>:
Slack variables are used to handle the inequality constraints. 
They can be provided directly through <code>x</code>, which should be of size <code>d+</code> the number of inequality constraints.
The last values of <code>x</code> are slack variables scaled to [0,1].
</p>
<p>If <code>x</code> is of size <code>d</code>, estimates of optimal slack variable are used.<br />
</p>


<h3>Value</h3>

<p>The Expected Augmented Lagrangian Improvement at <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>Mickael Binois
</p>


<h3>References</h3>

<p>R.B. Gramacy, G.A. Gray, S. Le Digabel, H.K.H Lee, P. Ranjan, G. Wells, Garth, and S.M. Wild (2014+),
Modeling an augmented Lagrangian for improved blackbox constrained optimization,
<em>arXiv preprint arXiv:1403.4890</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code> from package DiceOptim, <code><a href="#topic+crit_EFI">crit_EFI</a></code>, <code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#---------------------------------------------------------------------------
# Expected Augmented Lagrangian Improvement surface with one inequality constraint,
# fast objective
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun.obj &lt;- goldsteinprice
fun.cst &lt;- function(x){return(-branin(x) + 25)}
n.grid &lt;- 31
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun.obj)
cst.grid &lt;- apply(test.grid, 1, fun.cst)
n.init &lt;- 15 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n.init, n_var, seed = 42)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun.obj)
cst.init &lt;- apply(design.grid, 1, fun.cst)
model.constraint &lt;- km(~., design = design.grid, response = cst.init)
model.fun &lt;- fastfun(fun.obj, design.grid)
AL_grid &lt;- apply(test.grid, 1, crit_AL, model.fun = model.fun,
                  model.constraint = model.constraint)

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(AL_grid, n.grid), main = "Expected AL Improvement",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10,
                                   add=TRUE,drawlabels=TRUE, col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cst.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "red")
                            }
              )

#---------------------------------------------------------------------------
# Expected AL Improvement surface with one inequality and one equality constraint,
# using slack variables
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun.obj &lt;- goldsteinprice
fun.cstineq &lt;- function(x){return(3/2 - x[1] - 2*x[2] - .5*sin(2*pi*(x[1]^2 - 2*x[2])))}
fun.csteq &lt;- function(x){return(branin(x) - 25)}
n.grid &lt;- 51
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun.obj)
cstineq.grid &lt;- apply(test.grid, 1, fun.cstineq)
csteq.grid &lt;- apply(test.grid, 1, fun.csteq)
n.init &lt;- 25 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n.init, n_var, seed = 42)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun.obj)
cstineq.init &lt;- apply(design.grid, 1, fun.cstineq)
csteq.init &lt;- apply(design.grid, 1, fun.csteq)
model.fun &lt;- km(~., design = design.grid, response = obj.init)
model.constraintineq &lt;- km(~., design = design.grid, response = cstineq.init)
model.constrainteq &lt;- km(~., design = design.grid, response = csteq.init)

models.cst &lt;- list(model.constraintineq, model.constrainteq)
 
AL_grid &lt;- apply(test.grid, 1, crit_AL, model.fun = model.fun, model.constraint = models.cst,
                  equality = c(FALSE, TRUE), critcontrol = list(tolConstraints = c(0.05, 3),
                  slack=TRUE))

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(AL_grid, n.grid), main = "Expected AL Improvement",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10,
                                   add=TRUE,drawlabels=TRUE, col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cstineq.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "red")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid),
                            matrix(csteq.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "orange")
                            }
              )

</code></pre>

<hr>
<h2 id='crit_EFI'>Expected Feasible Improvement</h2><span id='topic+crit_EFI'></span>

<h3>Description</h3>

<p>Computes the Expected Feasible Improvement at current location. 
The current feasible minimum of the observations can be replaced by an arbitrary value (plugin), which is usefull in particular in noisy frameworks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crit_EFI(
  x,
  model.fun,
  model.constraint,
  equality = FALSE,
  critcontrol = NULL,
  plugin = NULL,
  type = "UK"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crit_EFI_+3A_x">x</code></td>
<td>
<p>a vector representing the input for which one wishes to calculate <code>EFI</code>,</p>
</td></tr>
<tr><td><code id="crit_EFI_+3A_model.fun">model.fun</code></td>
<td>
<p>object of class <code><a href="DiceKriging.html#topic+km">km</a></code> corresponding to the objective function,
or, if the objective function is fast-to-evaluate, a <code><a href="#topic+fastfun">fastfun</a></code> object,</p>
</td></tr>
<tr><td><code id="crit_EFI_+3A_model.constraint">model.constraint</code></td>
<td>
<p>either one or a list of objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>, one for each constraint function,</p>
</td></tr>
<tr><td><code id="crit_EFI_+3A_equality">equality</code></td>
<td>
<p>either <code>FALSE</code> if all constraints are for inequalities, else a vector of boolean indicating which are equalities,</p>
</td></tr>
<tr><td><code id="crit_EFI_+3A_critcontrol">critcontrol</code></td>
<td>
<p>optional list with argument <code>tolConstraints</code>, an optional vector giving a tolerance (&gt; 0) for each of the constraints (equality or inequality).
It is highly recommended to use it when there are equality constraints since the default tolerance of 0.05 in such case might not be suited.<br />
</p>
<p>Options for the <code><a href="#topic+checkPredict">checkPredict</a></code> function: <code>threshold</code> (<code>1e-4</code>) and <code>distance</code> (<code>covdist</code>) are used to avoid numerical issues occuring when adding points too close to the existing ones.</p>
</td></tr>
<tr><td><code id="crit_EFI_+3A_plugin">plugin</code></td>
<td>
<p>optional scalar: if provided, it replaces the feasible minimum of the current observations.
If set to <code>Inf</code>, e.g. when their is no feasible solution, then the criterion is equal to the probability of feasibility,</p>
</td></tr>
<tr><td><code id="crit_EFI_+3A_type">type</code></td>
<td>
<p>&quot;<code>SK</code>&quot; or &quot;<code>UK</code>&quot; (by default), depending whether uncertainty related to trend estimation 
has to be taken into account.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Expected Feasible Improvement at <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>Mickael Binois
</p>


<h3>References</h3>

<p>M. Schonlau, W.J. Welch, and D.R. Jones (1998),
Global versus local search in constrained optimization of computer models,
<em>Lecture Notes-Monograph Series</em>, 11-25.
</p>
<p>M.J. Sasena, P. Papalambros, and P.Goovaerts (2002),
Exploration of metamodeling sampling criteria for constrained global optimization,
<em>Engineering optimization</em>, 34, 263-278.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code> from package DiceOptim, <code><a href="#topic+crit_AL">crit_AL</a></code>, <code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#---------------------------------------------------------------------------
# Expected Feasible Improvement surface with one inequality constraint
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun.obj &lt;- goldsteinprice
fun.cst &lt;- function(x){return(-branin(x) + 25)}
n.grid &lt;- 51
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun.obj)
cst.grid &lt;- apply(test.grid, 1, fun.cst)
n.init &lt;- 15 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n.init, n_var, seed = 42)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun.obj)
cst.init &lt;- apply(design.grid, 1, fun.cst)
model.fun &lt;- km(~., design = design.grid, response = obj.init)
model.constraint &lt;- km(~., design = design.grid, response = cst.init)

EFI_grid &lt;- apply(test.grid, 1, crit_EFI, model.fun = model.fun,
                  model.constraint = model.constraint)

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(EFI_grid, n.grid), main = "Expected Feasible Improvement",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10,
                                   add=TRUE,drawlabels=TRUE, col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cst.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "red")
                            }
              )

#---------------------------------------------------------------------------
# Expected Feasible Improvement surface with one inequality and one equality constraint
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun.obj &lt;- goldsteinprice
fun.cstineq &lt;- function(x){return(3/2 - x[1] - 2*x[2] - .5*sin(2*pi*(x[1]^2 - 2*x[2])))}
fun.csteq &lt;- function(x){return(branin(x) - 25)}
n.grid &lt;- 51
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun.obj)
cstineq.grid &lt;- apply(test.grid, 1, fun.cstineq)
csteq.grid &lt;- apply(test.grid, 1, fun.csteq)
n.init &lt;- 25 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n.init, n_var, seed = 42)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun.obj)
cstineq.init &lt;- apply(design.grid, 1, fun.cstineq)
csteq.init &lt;- apply(design.grid, 1, fun.csteq)
model.fun &lt;- km(~., design = design.grid, response = obj.init)
model.constraintineq &lt;- km(~., design = design.grid, response = cstineq.init)
model.constrainteq &lt;- km(~., design = design.grid, response = csteq.init)

models.cst &lt;- list(model.constraintineq, model.constrainteq)
 
EFI_grid &lt;- apply(test.grid, 1, crit_EFI, model.fun = model.fun, model.constraint = models.cst,
                  equality = c(FALSE, TRUE), critcontrol = list(tolConstraints = c(0.05, 3)))

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(EFI_grid, n.grid), main = "Expected Feasible Improvement",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10,
                                   add=TRUE,drawlabels=TRUE, col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cstineq.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "red")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid),
                            matrix(csteq.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "orange")
                            }
              )

</code></pre>

<hr>
<h2 id='crit_SUR_cst'>Stepwise Uncertainty Reduction criterion</h2><span id='topic+crit_SUR_cst'></span>

<h3>Description</h3>

<p>Computes the Stepwise Uncertainty Reduction (SUR) criterion at current location
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crit_SUR_cst(
  x,
  model.fun,
  model.constraint,
  equality = FALSE,
  critcontrol = NULL,
  type = "UK"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crit_SUR_cst_+3A_x">x</code></td>
<td>
<p>a vector representing the input for which one wishes to calculate <code>SUR</code>,</p>
</td></tr>
<tr><td><code id="crit_SUR_cst_+3A_model.fun">model.fun</code></td>
<td>
<p>object of class <code><a href="DiceKriging.html#topic+km">km</a></code> corresponding to the objective function,
or, if the objective function is fast-to-evaluate, a <code><a href="#topic+fastfun">fastfun</a></code> object,</p>
</td></tr>
<tr><td><code id="crit_SUR_cst_+3A_model.constraint">model.constraint</code></td>
<td>
<p>either one or a list of objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>, one for each constraint function,</p>
</td></tr>
<tr><td><code id="crit_SUR_cst_+3A_equality">equality</code></td>
<td>
<p>either <code>FALSE</code> if all constraints are for inequalities, else a vector of boolean indicating which are equalities</p>
</td></tr>
<tr><td><code id="crit_SUR_cst_+3A_critcontrol">critcontrol</code></td>
<td>
<p>optional list with arguments:
</p>

<ul>
<li> <p><code>tolConstraints</code> optional vector giving a tolerance (&gt; 0) for each of the constraints (equality or inequality).
It is highly recommended to use it when there are equality constraints since the default tolerance of 0.05 in such case might not be suited;
</p>
</li>
<li> <p><code>integration.points</code> and <code>integration.weights</code>: optional matrix and vector of integration points;
</p>
</li>
<li> <p><code>precalc.data.cst, precalc.data.obj, mn.X.cst, sn.X.cst, mn.X.obj, sn.X.obj</code>: useful quantities for the 
fast evaluation of the criterion. 
</p>
</li>
<li><p> Options for the <code><a href="#topic+checkPredict">checkPredict</a></code> function: <code>threshold</code> (<code>1e-4</code>) and <code>distance</code> (<code>covdist</code>) 
are used to avoid numerical issues occuring when adding points too close to the existing ones.
</p>
</li></ul>
</td></tr>
<tr><td><code id="crit_SUR_cst_+3A_type">type</code></td>
<td>
<p>&quot;<code>SK</code>&quot; or &quot;<code>UK</code>&quot; (by default), depending whether uncertainty related to trend estimation 
has to be taken into account.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Stepwise Uncertainty Reduction criterion at <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>Mickael Binois
</p>


<h3>References</h3>

<p>V. Picheny (2014),
A stepwise uncertainty reduction approach to constrained global optimization,
<em>Proceedings of the 17th International Conference on Artificial Intelligence and Statistics</em>, JMLR W&amp;CP 33, 787-795.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code> from package DiceOptim, <code><a href="#topic+crit_EFI">crit_EFI</a></code>, <code><a href="#topic+crit_AL">crit_AL</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#---------------------------------------------------------------------------
# Stepwise Uncertainty Reduction criterion surface with one inequality constraint
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun.obj &lt;- goldsteinprice
fun.cst &lt;- function(x){return(-branin(x) + 25)}
n.grid &lt;- 21
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun.obj)
cst.grid &lt;- apply(test.grid, 1, fun.cst)

n_appr &lt;- 15 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n_appr, n_var, seed = 42)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun.obj)
cst.init &lt;- apply(design.grid, 1, fun.cst)
model.fun &lt;- km(~., design = design.grid, response = obj.init)
model.constraint &lt;- km(~., design = design.grid, response = cst.init)

integration.param &lt;- integration_design_cst(integcontrol =list(integration.points = test.grid),
                                            lower = rep(0, n_var), upper = rep(1, n_var))

SUR_grid &lt;- apply(test.grid, 1, crit_SUR_cst, model.fun = model.fun,
                  model.constraint = model.constraint, critcontrol=integration.param)

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(SUR_grid, n.grid), main = "SUR criterion",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10,
                                   add=TRUE,drawlabels=TRUE, col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cst.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "red")
                            }
              )

#---------------------------------------------------------------------------
# SUR with one inequality and one equality constraint
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun.obj &lt;- goldsteinprice
fun.cstineq &lt;- function(x){return(3/2 - x[1] - 2*x[2] - .5*sin(2*pi*(x[1]^2 - 2*x[2])))}
fun.csteq &lt;- function(x){return(branin(x) - 25)}
n.grid &lt;- 21
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun.obj)
cstineq.grid &lt;- apply(test.grid, 1, fun.cstineq)
csteq.grid &lt;- apply(test.grid, 1, fun.csteq)
n_appr &lt;- 25 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n_appr, n_var, seed = 42)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun.obj)
cstineq.init &lt;- apply(design.grid, 1, fun.cstineq)
csteq.init &lt;- apply(design.grid, 1, fun.csteq)
model.fun &lt;- km(~., design = design.grid, response = obj.init)
model.constraintineq &lt;- km(~., design = design.grid, response = cstineq.init)
model.constrainteq &lt;- km(~., design = design.grid, response = csteq.init)

models.cst &lt;- list(model.constraintineq, model.constrainteq)
 
SUR_grid &lt;- apply(test.grid, 1, crit_SUR_cst, model.fun = model.fun, model.constraint = models.cst,
                  equality = c(FALSE, TRUE), critcontrol = list(tolConstraints = c(0.05, 3), 
                  integration.points=integration.param$integration.points))

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(SUR_grid, n.grid), main = "SUR criterion",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10,
                                   add=TRUE,drawlabels=TRUE, col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cstineq.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "red")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid),
                            matrix(csteq.grid, n.grid), level = 0, add=TRUE,
                                   drawlabels=FALSE,lwd=1.5, col = "orange")
                            }
              )


</code></pre>

<hr>
<h2 id='critcst_optimizer'>Maximization of constrained Expected Improvement criteria</h2><span id='topic+critcst_optimizer'></span>

<h3>Description</h3>

<p>Given objects of class <code><a href="DiceKriging.html#topic+km">km</a></code> for the objective and constraints,
and a set of tuning parameters (<code>lower, upper and critcontrol</code>), <code>critcst_optimizer</code> performs
the maximization of a constrained Expected Improvement or SUR criterion and delivers
the next point to be visited in an EGO-like procedure. <br /> <br />
The latter maximization relies either on a genetic algorithm using derivatives,
<code><a href="rgenoud.html#topic+genoud">genoud</a></code> or exhaustive search at pre-specified points. 
It is important to remark that the information
needed about the objective and constraint functions reduces here to the vector of response values
embedded in the models (no call to the objective/constraint functions or simulators (except possibly for the objective)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>critcst_optimizer(
  crit = "EFI",
  model.fun,
  model.constraint,
  equality = FALSE,
  lower,
  upper,
  type = "UK",
  critcontrol = NULL,
  optimcontrol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="critcst_optimizer_+3A_crit">crit</code></td>
<td>
<p>sampling criterion. Three choices are available : &quot;<code>EFI</code>&quot;, &quot;<code>AL</code>&quot; and &quot;<code>SUR</code>&quot;,</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_model.fun">model.fun</code></td>
<td>
<p>object of class <code><a href="DiceKriging.html#topic+km">km</a></code> corresponding to the objective function,
or, if the objective function is fast-to-evaluate, either the objective function to be minimized or a 
<code><a href="#topic+fastfun">fastfun</a></code> object, see details and examples below,</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_model.constraint">model.constraint</code></td>
<td>
<p>either one or a list of models of class <code><a href="DiceKriging.html#topic+km">km</a></code>, one for each constraint,</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_equality">equality</code></td>
<td>
<p>either <code>FALSE</code> if all constraints are inequalities, or a Boolean vector indicating which are equalities,</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_type">type</code></td>
<td>
<p>&quot;<code>SK</code>&quot; or &quot;<code>UK</code>&quot; (default), depending whether uncertainty related to trend estimation has to be taken into account.</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_critcontrol">critcontrol</code></td>
<td>
<p>optional list of control parameters for criterion <code>crit</code>, see details.<br />
Options for the <code><a href="#topic+checkPredict">checkPredict</a></code> function: <code>threshold</code> (<code>1e-4</code>) and <code>distance</code> (<code>covdist</code>) are used to avoid numerical issues occuring when adding points too close to the existing ones.</p>
</td></tr>
<tr><td><code id="critcst_optimizer_+3A_optimcontrol">optimcontrol</code></td>
<td>
<p>optional list of control parameters for optimization of the selected infill criterion. 
&quot;<code>method</code>&quot; set the optimization method; one can 
choose between &quot;<code>discrete</code>&quot; and &quot;<code>genoud</code>&quot;. For each method, further parameters can be set.<br /> 
For &quot;<code>discrete</code>&quot;, one has to provide the argument &quot;<code>candidate.points</code>&quot;. <br />
For &quot;<code>genoud</code>&quot;, one can control, among others, &quot;<code>pop.size</code>&quot; (default :  <code>[N = 3*2^dim</code> for <code>dim &lt; 6</code> and  <code>N = 32*dim</code> otherwise]),
&quot;<code>max.generations</code>&quot; (<code>12</code>), &quot;<code>wait.generations</code>&quot; (<code>2</code>)),
see <code><a href="rgenoud.html#topic+genoud">genoud</a></code>. Numbers into brackets are the default values.
@return A list with components: 
</p>

<ul>
<li><p><code>par</code>: The best set of parameters found,
</p>
</li>
<li><p><code>value</code>: The value of expected improvement at <code>par</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Extension of the function <code><a href="#topic+max_EI">max_EI</a></code> for constrained optimization.<br />
</p>
<p>Available infill criteria with <code>crit</code> are : <br />
</p>

<ul>
<li><p> Expected Probability of Feasibily (<code>EFI</code>) <code><a href="#topic+crit_EFI">crit_EFI</a></code>,
</p>
</li>
<li><p> Augmented Lagrangian (<code>AL</code>) <code><a href="#topic+crit_AL">crit_AL</a></code>,
</p>
</li>
<li><p> Stepwise Uncertainty Reduction of the excursion volume (<code>SUR</code>) <code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>.
</p>
</li></ul>

<p>Depending on the selected criterion, parameters  can be given with <code>critcontrol</code>.
Also options for <code><a href="#topic+checkPredict">checkPredict</a></code> are available.
More precisions are given in the corresponding help pages. <br />
</p>
<p>If the objective function to minimize is inexpensive, i.e. no need of a kriging model,
then one can provide it in <code>model.obj</code>, which is handled next with class <code><a href="#topic+fastfun">fastfun</a></code> (or directly as a <code><a href="#topic+fastfun">fastfun</a></code> object). 
See example below.
</p>
<p>In the case of equality constraints, it is possible to define them with <code>equality</code>.
Additionally, one can modify the tolerance on the constraints using the <code>tolConstraints</code> component of <code>critcontrol</code>:
an optional vector giving a tolerance for each of the constraints (equality or inequality). 
It is highly recommended to use it when there are equality constraints since the default tolerance of 0.05 (resp. 0 for inequality constraints) 
in such case might not be suited.<br />
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>Mickael Binois
</p>


<h3>References</h3>

<p>W.R. Jr. Mebane and J.S. Sekhon (2011), Genetic optimization using derivatives: The rgenoud package for R, <em>Journal of Statistical Software</em>, 42(11), 1-26 <br />
</p>
<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global optimization of expensive black-box functions, <em>Journal of Global Optimization</em>, 13, 455-492.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+critcst_optimizer">critcst_optimizer</a></code>, <code><a href="#topic+crit_EFI">crit_EFI</a></code>, <code><a href="#topic+crit_AL">crit_AL</a></code>,
<code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#---------------------------------------------------------------------------
# 2D objective function, 2 cases
#---------------------------------------------------------------------------

set.seed(2546)
library(DiceDesign)

n_var &lt;- 2
fun &lt;- branin

fun1.cst &lt;- function(x){return(goldsteinprice(x)+.5)}
fun2.cst &lt;- function(x){return(3/2 - x[1] - 2*x[2] - .5*sin(2*pi*(x[1]^2 - 2*x[2])))}

# Constraint function with vectorial output
cstfun &lt;- function(x){return(c(fun1.cst(x), fun2.cst(x)))}

n.grid &lt;- 31
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun)
cst1.grid &lt;- apply(test.grid, 1, fun1.cst)
cst2.grid &lt;- apply(test.grid, 1, fun2.cst)

n_appr &lt;- 12 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n_appr, n_var, seed = 2)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun)
cst1.init &lt;- apply(design.grid, 1, fun1.cst)
cst2.init &lt;- apply(design.grid, 1, fun2.cst)
model.fun &lt;- km(~., design = design.grid, response = obj.init)
model.constraint1 &lt;- km(~., design = design.grid, response = cst1.init, lower=c(.2,.2))
model.constraint2 &lt;- km(~., design = design.grid, response = cst2.init, lower=c(.2,.2))
models.cst &lt;- list(model.constraint1, model.constraint2)

lower &lt;- rep(0, n_var)
upper &lt;- rep(1, n_var)

#---------------------------------------------------------------------------
# Augmented Lagrangian Improvement, fast objective function, two ineq constraints,
# optimization with genoud
#---------------------------------------------------------------------------
critcontrol &lt;- list(lambda=c(.5,2), rho=.5)
optimcontrol &lt;- list(method = "genoud", max.generations=10, pop.size=20)

AL_grid &lt;- apply(test.grid, 1, crit_AL, model.fun = fastfun(fun, design.grid),
                 model.constraint = models.cst, critcontrol=critcontrol)

cstEGO1 &lt;- critcst_optimizer(crit = "AL", model.fun = fun,
                             model.constraint = models.cst, equality = FALSE,
                             lower = lower, upper = upper, 
                             optimcontrol = optimcontrol, critcontrol=critcontrol)

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(AL_grid, n.grid), main = "AL map and its maximizer (blue)",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10, add=TRUE,drawlabels=TRUE,
                                   col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cst1.grid, n.grid), level = 0, add=TRUE,drawlabels=FALSE,
                                   lwd=1.5, col = "red")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cst2.grid, n.grid), level = 0, add=TRUE,drawlabels=FALSE,
                                   lwd=1.5, col = "red")
                            points(cstEGO1$par, col = "blue", pch = 4, lwd = 2)
                            }
              )
#---------------------------------------------------------------------------
# SUR, expensive objective function, one equality constraint,
# optimization with genoud, integration on a regular grid
#---------------------------------------------------------------------------
optimcontrol &lt;- list(method = "genoud", s = 40, maxit = 40)
critcontrol  &lt;- list(tolConstraints = .15, integration.points=as.matrix(test.grid))

SUR_grid &lt;- apply(test.grid, 1, crit_SUR_cst, model.fun = model.fun,
                  model.constraint = model.constraint1, equality = TRUE, critcontrol = critcontrol)

cstEGO2 &lt;- critcst_optimizer(crit = "SUR", model.fun = model.fun,
                             model.constraint = model.constraint1, equality = TRUE,
                             lower = lower, upper = upper, 
                             optimcontrol = optimcontrol, critcontrol = critcontrol)

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(SUR_grid, n.grid), main = "SUR map and its maximizer (blue)",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(obj.grid, n.grid), nlevels = 10, add=TRUE,
                            drawlabels=TRUE, col = "black")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                            matrix(cst1.grid, n.grid), level = c(-critcontrol$tolConstraints,
                            critcontrol$tolConstraints), 
                            add=TRUE, drawlabels=FALSE,lwd=1.5, col = "orange")
                            points(cstEGO2$par, col = "blue", pch = 4, lwd = 2)
                            }
              )

</code></pre>

<hr>
<h2 id='DiceOptim-package'>Kriging-based optimization methods for computer experiments</h2><span id='topic+DiceOptim-package'></span><span id='topic+DiceOptim'></span>

<h3>Description</h3>

<p>Sequential and parallel Kriging-based optimization methods relying on
expected improvement criteria.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;"> Package: </td><td style="text-align: left;"> DiceOptim</td>
</tr>
<tr>
 <td style="text-align: left;"> Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;"> Version:
</td><td style="text-align: left;"> 2.0 </td>
</tr>
<tr>
 <td style="text-align: left;"> Date: </td><td style="text-align: left;"> July 2016</td>
</tr>
<tr>
 <td style="text-align: left;"> License: </td><td style="text-align: left;"> GPL-2 | GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Note</h3>

<p>This work is a follow-up of DiceOptim 1.0, which was produced within
the frame of the DICE (Deep Inside Computer Experiments) Consortium between
ARMINES, Renault, EDF, IRSN, ONERA and TOTAL S.A.
</p>
<p>The authors would like to thank Yves Deville for his precious advice in R
programming and packaging, as well as the DICE members for useful
feedbacks, and especially Yann Richet (IRSN) for numerous discussions
concerning the user-friendliness of this package.
</p>
<p>Package <code>rgenoud</code> &gt;=5.3.3. is recommended.
</p>
<p>Important functions or methods: </p>

<table>
<tr>
 <td style="text-align: left;"> <code>EGO.nsteps</code> </td><td style="text-align: left;"> Standard Efficient Global Optimization algorithm with a fixed number of iterations (nsteps) </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;">---with model updates including re-estimation of covariance hyperparameters </td>
</tr>
<tr>
 <td style="text-align: left;">

<code>EI</code> </td><td style="text-align: left;"> Expected Improvement criterion (single infill point, noise-free, constraint free problems)</td>
</tr>
<tr>
 <td style="text-align: left;">

<code>max_EI</code> </td><td style="text-align: left;"> Maximization of the EI criterion. No need to specify any objective function </td>
</tr>
<tr>
 <td style="text-align: left;">

<code>qEI.nsteps</code> </td><td style="text-align: left;"> EGO algorithm with batch-sequential (parallel) infill strategy </td>
</tr>
<tr>
 <td style="text-align: left;">

<code>noisy.optimizer</code> </td><td style="text-align: left;"> EGO algorithm for noisy objective functions </td>
</tr>
<tr>
 <td style="text-align: left;">

<code>EGO.cst</code> </td><td style="text-align: left;"> EGO algorithm for (non-linear) constrained problems </td>
</tr>
<tr>
 <td style="text-align: left;">

<code>easyEGO.cst</code> </td><td style="text-align: left;"> User-friendly wrapper for <code>EGO.cst</code></td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Victor Picheny (INRA, Castanet-Tolosan, France)
</p>
<p>David Ginsbourger (Idiap Research Institute and University of Bern, Switzerland)
</p>
<p>Olivier Roustant (Mines Saint-Etienne, France).
</p>
<p>with contributions by M. Binois, C. Chevalier, S. Marmin and T. Wagner
</p>


<h3>References</h3>

<p>N.A.C. Cressie (1993), <em>Statistics for spatial data</em>,
Wiley series in probability and mathematical statistics.
</p>
<p>D. Ginsbourger (2009), <em>Multiples metamodeles pour l'approximation et
l'optimisation de fonctions numeriques multivariables</em>, Ph.D. thesis, Ecole
Nationale Superieure des Mines de Saint-Etienne, 2009.
<a href="https://tel.archives-ouvertes.fr/tel-00772384">https://tel.archives-ouvertes.fr/tel-00772384</a>
</p>
<p>D. Ginsbourger, R. Le Riche, and L. Carraro (2010), chapter &quot;Kriging is
well-suited to parallelize optimization&quot;, in <em>Computational
Intelligence in Expensive Optimization Problems</em>, Studies in Evolutionary
Learning and Optimization, Springer.
</p>
<p>D.R. Jones (2001), A taxonomy of global optimization methods based on
response surfaces, <em>Journal of Global Optimization</em>, 21, 345-383.
</p>
<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>
<p>W.R. Jr. Mebane and J.S. Sekhon (2011), Genetic optimization
using derivatives: The rgenoud package for R, <em>Journal of Statistical
Software</em>, <b>51</b>(1), 1-55, <a href="https://www.jstatsoft.org/v51/i01/">https://www.jstatsoft.org/v51/i01/</a>.
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>V. Picheny and D. Ginsbourger (2013), Noisy kriging-based optimization
methods: A unified implementation within the DiceOptim package,
<em>Computational Statistics &amp; Data Analysis</em>, 71, 1035-1053. 
</p>
<p>C.E. Rasmussen and C.K.I. Williams (2006), <em>Gaussian Processes for
Machine Learning</em>, the MIT Press, <a href="http://www.gaussianprocess.org/gpml/">http://www.gaussianprocess.org/gpml/</a>
</p>
<p>B.D. Ripley (1987), <em>Stochastic Simulation</em>, Wiley.
</p>
<p>O. Roustant, D. Ginsbourger and Yves Deville (2012), DiceKriging,
DiceOptim: Two R Packages for the Analysis of Computer Experiments by
Kriging-Based Metamodeling and Optimization, <em>Journal of Statistical
Software</em>, <b>42</b>(11), 1&ndash;26, <a href="https://www.jstatsoft.org/article/view/v042i11">https://www.jstatsoft.org/article/view/v042i11</a>.
</p>
<p>T.J. Santner, B.J. Williams, and W.J. Notz (2003), <em>The design and
analysis of computer experiments</em>, Springer.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
set.seed(123)

###############################################################
###	2D optimization USING EGO.nsteps and qEGO.nsteps   ########
###############################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- data.frame(apply(design.fact, 1, branin))
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

### EGO, 5 steps ##################
library(rgenoud)
nsteps &lt;- 5
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)     
oEGO &lt;- EGO.nsteps(model=fitted.model1, fun=branin, nsteps=nsteps, 
lower=lower, upper=upper, control=list(pop.size=20, BFGSburnin=2))
print(oEGO$par)
print(oEGO$value)

# graphics
n.grid &lt;- 15
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, branin)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid, y.grid, z.grid, 40)
title("EGO")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par, pch=19, col="red")
text(oEGO$par[,1], oEGO$par[,2], labels=1:nsteps, pos=3)

### Parallel EGO, 3 steps with batches of 3 ##############
nsteps &lt;- 3
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)
npoints &lt;- 3 # The batchsize
oEGO &lt;- qEGO.nsteps(model = fitted.model1, branin, npoints = npoints, nsteps = nsteps,
crit="exact", lower, upper, optimcontrol = NULL)
print(oEGO$par)
print(oEGO$value)

# graphics
contour(x.grid, y.grid, z.grid, 40)
title("qEGO")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par, pch=19, col="red")
text(oEGO$par[,1], oEGO$par[,2], labels=c(tcrossprod(rep(1,npoints),1:nsteps)), pos=3)

##########################################################################
### 2D OPTIMIZATION, NOISY OBJECTIVE                                   ###
##########################################################################

set.seed(10)
library(DiceDesign)
# Set test problem parameters
doe.size &lt;- 9
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.1

# Build noisy simulator
funnoise &lt;- function(x)
{     f.new &lt;- test.function(x) + sqrt(noise.var)*rnorm(n=1)
      return(f.new)}

# Generate DOE and response
doe &lt;- as.data.frame(lhsDesign(doe.size, dim)$design)
y.tilde &lt;- funnoise(doe)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
     covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
     lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Optimisation with noisy.optimizer
optim.param &lt;- list()
optim.param$quantile &lt;- .7
optim.result &lt;- noisy.optimizer(optim.crit="EQI", optim.param=optim.param, model=model,
		n.ite=5, noise.var=noise.var, funnoise=funnoise, lower=lower, upper=upper,
		NoiseReEstimate=FALSE, CovReEstimate=FALSE)

print(optim.result$best.x)

##########################################################################
### 2D OPTIMIZATION, 2 INEQUALITY CONSTRAINTS                          ###
##########################################################################
set.seed(25468)
library(DiceDesign)

fun &lt;- goldsteinprice
fun1.cst &lt;- function(x){return(-branin(x) + 25)}
fun2.cst &lt;- function(x){return(3/2 - x[1] - 2*x[2] - .5*sin(2*pi*(x[1]^2 - 2*x[2])))}
constraint &lt;- function(x){return(c(fun1.cst(x), fun2.cst(x)))}

lower &lt;- rep(0, 2)
upper &lt;- rep(1, 2)

## Optimization using the Expected Feasible Improvement criterion
res &lt;- easyEGO.cst(fun=fun, constraint=constraint, n.cst=2, lower=lower, upper=upper, budget=10, 
                   control=list(method="EFI", inneroptim="genoud", maxit=20))

cat("best design found:", res$par, "\n")
cat("corresponding objective and constraints:", res$value, "\n")

# Objective function in colour, constraint boundaries in red
# Initial DoE: white circles, added points: blue crosses, best solution: red cross

n.grid &lt;- 15
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun)
cst1.grid &lt;- apply(test.grid, 1, fun1.cst)
cst2.grid &lt;- apply(test.grid, 1, fun2.cst)
filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(obj.grid, n.grid), main = "Two inequality constraints",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst1.grid, n.grid), level = 0, add=TRUE,
                                    drawlabels=FALSE, lwd=1.5, col = "red")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst2.grid, n.grid), level = 0, add=TRUE,drawlabels=FALSE,
                                    lwd=1.5, col = "red")
                            points(res$history$X, col = "blue", pch = 4, lwd = 2)       
                            points(res$par[1], res$par[2], col = "red", pch = 4, lwd = 2, cex=2) 
               }
)
</code></pre>

<hr>
<h2 id='easyEGO'>User-friendly wrapper of the functions <code><a href="#topic+fastEGO.nsteps">fastEGO.nsteps</a></code> and <code><a href="#topic+TREGO.nsteps">TREGO.nsteps</a></code>.
Generates initial DOEs and kriging models (objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>), 
and executes <code>nsteps</code> iterations of either EGO or TREGO.</h2><span id='topic+easyEGO'></span>

<h3>Description</h3>

<p>User-friendly wrapper of the functions <code><a href="#topic+fastEGO.nsteps">fastEGO.nsteps</a></code> and <code><a href="#topic+TREGO.nsteps">TREGO.nsteps</a></code>.
Generates initial DOEs and kriging models (objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>), 
and executes <code>nsteps</code> iterations of either EGO or TREGO.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>easyEGO(
  fun,
  budget,
  lower,
  upper,
  X = NULL,
  y = NULL,
  control = list(trace = 1, seed = 42),
  n.cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="easyEGO_+3A_fun">fun</code></td>
<td>
<p>scalar function to be minimized,</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_budget">budget</code></td>
<td>
<p>total number of calls to the objective and constraint functions,</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_x">X</code></td>
<td>
<p>initial design of experiments. If not provided, X is taken as a maximin LHD with budget/3 points</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_y">y</code></td>
<td>
<p>initial set of objective observations <code class="reqn">f(X)</code>. Computed if not provided.</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_control">control</code></td>
<td>
<p>an optional list of control parameters. See &quot;Details&quot;.</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_n.cores">n.cores</code></td>
<td>
<p>number of cores for parallel computation</p>
</td></tr>
<tr><td><code id="easyEGO_+3A_...">...</code></td>
<td>
<p>additional parameters to be given to <code>fun</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Does not require knowledge on kriging models (objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>)  <br />
The <code>control</code> argument is a list that can supply any of the following components: <br />
</p>

<ul>
<li> <p><code>trace</code>: between -1 and 3
</p>
</li>
<li> <p><code>seed</code>: to fix the seed of the run
</p>
</li>
<li> <p><code>cov.reestim</code>: Boolean, if TRUE (default) the covariance parameters are re-estimated at each iteration
</p>
</li>
<li> <p><code>model.trend</code>: trend for the GP model
</p>
</li>
<li> <p><code>lb, ub</code>: lower and upper bounds for the GP covariance ranges
</p>
</li>
<li> <p><code>nugget</code>: optional nugget effect
</p>
</li>
<li> <p><code>covtype</code>: covariance of the GP model (default &quot;matern5_2&quot;)
</p>
</li>
<li> <p><code>optim.method</code>: optimisation of the GP hyperparameters (default &quot;BFGS&quot;)
</p>
</li>
<li> <p><code>multistart</code>: number of restarts of BFGS
</p>
</li>
<li> <p><code>gpmean.trick, gpmean.freq</code>: Boolean and integer, resp., for the gpmean trick
</p>
</li>
<li> <p><code>scaling</code>: Boolean, activates input scaling
</p>
</li>
<li> <p><code>warping</code>: Boolean, activates output warping
</p>
</li>
<li> <p><code>TR</code>: Boolean, activates TREGO instead of EGO
</p>
</li>
<li> <p><code>trcontrol</code>: list of parameters of the trust region, see <code><a href="#topic+TREGO.nsteps">TREGO.nsteps</a></code>
</p>
</li>
<li> <p><code>always.sample</code>: Boolean, activates force observation even if it leads to poor conditioning
</p>
</li></ul>



<h3>Value</h3>

<p>A list with components:
</p>

<ul>
<li><p><code>par</code>: the best feasible point
</p>
</li>
<li><p><code>values</code>: a vector of the objective and constraints at the point given in <code>par</code>,
</p>
</li>
<li><p><code>history</code>: a list containing all the points visited by the algorithm (<code>X</code>) and their corresponding objectives (<code>y</code>).
</p>
</li>
<li><p><code>model</code>: the last GP model, class <code><a href="DiceKriging.html#topic+km">km</a></code>
</p>
</li>
<li><p><code>control</code>: full list of control values, see &quot;Details&quot;
</p>
</li>
<li><p><code>res</code>: the output of either <code><a href="#topic+fastEGO.nsteps">fastEGO.nsteps</a></code> or <code><a href="#topic+TREGO.nsteps">TREGO.nsteps</a></code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Victor Picheny
</p>


<h3>References</h3>

<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parallel)
library(DiceOptim)
set.seed(123)

#########################################################
### 	10 ITERATIONS OF TREGO ON THE BRANIN FUNCTION, ####
###	 STARTING FROM A 9-POINTS FACTORIAL DESIGN       ####
########################################################

# a 9-points factorial design, and the corresponding response
ylim=NULL
fun &lt;- branin; d &lt;- 2
budget &lt;- 5*d
lower &lt;- rep(0,d)
upper &lt;- rep(1,d)
n.init &lt;- 2*d

control &lt;- list(n.init=2*d, TR=TRUE, nugget=1e-5, trcontrol=list(algo="TREGO"), multistart=1)

res1 &lt;- easyEGO(fun=fun, budget=budget, lower=lower, upper=upper, control=control, n.cores=1)

par(mfrow=c(3,1))
y &lt;- res1$history$y
steps &lt;- res1$res$all.steps
success &lt;- res1$res$all.success
sigma &lt;- res1$res$all.sigma
ymin &lt;- cummin(y)
pch &lt;- rep(1, length(sigma))
col &lt;- rep("red", length(sigma))
pch[which(!steps)] &lt;- 2
col[which(success)] &lt;- "darkgreen"

pch2 &lt;- c(rep(3, n.init), pch)
col2 &lt;- c(rep("black", n.init), col)
plot(y, col=col2, ylim=ylim, pch=pch2, lwd=2, xlim=c(0, budget))
lines(ymin, col="darkgreen")
abline(v=n.init+.5)

plot(n.init + (1:length(sigma)), sigma, xlim=c(0, budget), ylim=c(0, max(sigma)), 
pch=pch, col=col, lwd=2, main="TR size") 
lines(n.init + (1:length(sigma)), sigma, xlim=c(0, budget)) 
abline(v=n.init+.5)

plot(NA, xlim=c(0, budget), ylim=c(0, 1), main="x0 (coordinates)")
for (i in 1:d) {
  lines(n.init + (1:nrow(res1$res$all.x0)), res1$res$all.x0[,i]) 
  points(n.init + (1:nrow(res1$res$all.x0)), res1$res$all.x0[,i], pch=pch, col=col, lwd=2) 
}
abline(v=n.init+.5)

par(mfrow=c(1,1))
pairs(res1$model@X, pch=pch2, col=col2)

</code></pre>

<hr>
<h2 id='easyEGO.cst'>EGO algorithm with constraints</h2><span id='topic+easyEGO.cst'></span>

<h3>Description</h3>

<p>User-friendly wrapper of the function <code><a href="#topic+EGO.cst">EGO.cst</a></code>
Generates initial DOEs and kriging models (objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>), 
and executes <code>nsteps</code> iterations of EGO methods integrating constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>easyEGO.cst(
  fun,
  constraint,
  n.cst = 1,
  budget,
  lower,
  upper,
  cheapfun = FALSE,
  equality = FALSE,
  X = NULL,
  y = NULL,
  C = NULL,
  control = list(method = "EFI", trace = 1, inneroptim = "genoud", maxit = 100, seed =
    42),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="easyEGO.cst_+3A_fun">fun</code></td>
<td>
<p>scalar function to be minimized,</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_constraint">constraint</code></td>
<td>
<p>vectorial function corresponding to the constraints, see details below,</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_n.cst">n.cst</code></td>
<td>
<p>number of constraints,</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_budget">budget</code></td>
<td>
<p>total number of calls to the objective and constraint functions,</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_cheapfun">cheapfun</code></td>
<td>
<p>optional boolean, <code>TRUE</code> if the objective is a fast-to-evaluate function that does not need a kriging model</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_equality">equality</code></td>
<td>
<p>either <code>FALSE</code> if all constraints are inequalities, else a Boolean vector indicating which are equalities</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_x">X</code></td>
<td>
<p>initial design of experiments. If not provided, X is taken as a maximin LHD with budget/3 points</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_y">y</code></td>
<td>
<p>initial set of objective observations <code class="reqn">f(X)</code>. Computed if not provided.</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_c">C</code></td>
<td>
<p>initial set of constraint observations <code class="reqn">g(X)</code>. Computed if not provided.</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_control">control</code></td>
<td>
<p>an optional list of control parameters. See &quot;Details&quot;.</p>
</td></tr>
<tr><td><code id="easyEGO.cst_+3A_...">...</code></td>
<td>
<p>additional parameters to be given to BOTH the objective <code>fun</code> and <code>constraints</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Does not require knowledge on kriging models (objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>)  <br />
</p>
<p>The problem considered is of the form: <code class="reqn">min f(x)</code> s.t. <code class="reqn">g(x) \le 0</code>, 
<code class="reqn">g</code> having a vectorial output. 
By default all its components are supposed to be inequalities, but one can use a Boolean vector in <code>equality</code> 
to specify which are equality constraints, hence of the type <code class="reqn">g(x) = 0</code>.
The <code>control</code> argument is a list that can supply any of the following components: <br />
</p>

<ul>
<li> <p><code>method</code>: choice of constrained improvement function: &quot;<code>AL</code>&quot;, &quot;<code>EFI</code>&quot; or &quot;<code>SUR</code>&quot; 
(see <code><a href="#topic+crit_EFI">crit_EFI</a></code>, <code><a href="#topic+crit_AL">crit_AL</a></code>, <code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>)
</p>
</li>
<li> <p><code>trace</code>:  if positive, tracing information on the progress of the optimization is produced.
</p>
</li>
<li> <p><code>inneroptim</code>: choice of the inner optimization algorithm: &quot;<code>genoud</code>&quot; or &quot;<code>random</code>&quot;
(see <code><a href="rgenoud.html#topic+genoud">genoud</a></code>).
</p>
</li>
<li> <p><code>maxit</code>: maximum number of iterations of the inner loop. 
</p>
</li>
<li> <p><code>seed</code>: to fix the random variable generator
</p>
</li></ul>

<p>For additional details, see <code><a href="#topic+EGO.cst">EGO.cst</a></code>.
</p>


<h3>Value</h3>

<p>A list with components:
</p>

<ul>
<li><p><code>par</code>: the best feasible point
</p>
</li>
<li><p><code>values</code>: a vector of the objective and constraints at the point given in <code>par</code>,
</p>
</li>
<li><p><code>history</code>: a list containing all the points visited by the algorithm (<code>X</code>) and their corresponding objectives (<code>y</code>) and constraints (<code>C</code>) <br /> <br />
If no feasible point is found, <code>par</code> returns the most feasible point (in the least square sense).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>Mickael Binois
</p>


<h3>References</h3>

<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>
<p>M. Schonlau, W.J. Welch, and D.R. Jones (1998),
Global versus local search in constrained optimization of computer models,
<em>Lecture Notes-Monograph Series</em>, 11-25.
</p>
<p>M.J. Sasena, P. Papalambros, and P.Goovaerts (2002),
Exploration of metamodeling sampling criteria for constrained global optimization,
<em>Engineering optimization</em>, 34, 263-278.
</p>
<p>R.B. Gramacy, G.A. Gray, S. Le Digabel, H.K.H Lee, P. Ranjan, G. Wells, Garth, and S.M. Wild (2014+),
Modeling an augmented Lagrangian for improved blackbox constrained optimization,
<em>arXiv preprint arXiv:1403.4890</em>.
</p>
<p>J.M. Parr (2012),
<em>Improvement criteria for constraint handling and multiobjective optimization</em>,
University of Southampton.
</p>
<p>V. Picheny (2014),
A stepwise uncertainty reduction approach to constrained global optimization,
<em>Proceedings of the 17th International Conference on Artificial Intelligence and Statistics</em>,  JMLR W&amp;CP 33, 787-795.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#---------------------------------------------------------------------------
# 2D objective function, 3 cases
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun &lt;- goldsteinprice
fun1.cst &lt;- function(x){return(-branin(x) + 25)}
fun2.cst &lt;- function(x){return(3/2 - x[1] - 2*x[2] - .5*sin(2*pi*(x[1]^2 - 2*x[2])))}

# Constraint function with vectorial output
constraint &lt;- function(x){return(c(fun1.cst(x), fun2.cst(x)))}

# For illustration purposes
n.grid &lt;- 31
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun)
cst1.grid &lt;- apply(test.grid, 1, fun1.cst)
cst2.grid &lt;- apply(test.grid, 1, fun2.cst)

lower &lt;- rep(0, n_var)
upper &lt;- rep(1, n_var)

#---------------------------------------------------------------------------
# 1- Expected Feasible Improvement criterion, expensive objective function,
# two inequality constraints, 15 observations budget, using genoud
#---------------------------------------------------------------------------
res &lt;- easyEGO.cst(fun=fun, constraint=constraint, n.cst=2, lower=lower, upper=upper, budget=15, 
                   control=list(method="EFI", inneroptim="genoud", maxit=20))

cat("best design found:", res$par, "\n")
cat("corresponding objective and constraints:", res$value, "\n")

# Objective function in colour, constraint boundaries in red
# Initial DoE: white circles, added points: blue crosses, best solution: red cross

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(obj.grid, n.grid), main = "Two inequality constraints",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst1.grid, n.grid), level = 0, add=TRUE,
                                    drawlabels=FALSE, lwd=1.5, col = "red")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst2.grid, n.grid), level = 0, add=TRUE,drawlabels=FALSE,
                                    lwd=1.5, col = "red")
                            points(res$history$X, col = "blue", pch = 4, lwd = 2)       
                            points(res$par[1], res$par[2], col = "red", pch = 4, lwd = 2, cex=2) 
               }
)

#---------------------------------------------------------------------------
# 2- Augmented Lagrangian Improvement criterion, expensive objective function,
# one inequality and one equality constraint, 25 observations budget, using random search
#---------------------------------------------------------------------------
res2 &lt;- easyEGO.cst(fun=fun, constraint=constraint, n.cst=2, lower=lower, upper=upper, budget=25,
                   equality = c(TRUE, FALSE),
                   control=list(method="AL", inneroptim="random", maxit=100))

cat("best design found:", res2$par, "\n")
cat("corresponding objective and constraints:", res2$value, "\n")

# Objective function in colour, inequality constraint boundary in red, equality
# constraint in orange
# Initial DoE: white circles, added points: blue crosses, best solution: red cross

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(obj.grid, n.grid), xlab = expression(x[1]), ylab = expression(x[2]),
               main = "Inequality (red) and equality (orange) constraints", color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst1.grid, n.grid), level = 0, add=TRUE,
                                    drawlabels=FALSE,lwd=1.5, col = "orange")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid),
                                    matrix(cst2.grid, n.grid), level = 0, add=TRUE,
                                    drawlabels=FALSE,lwd=1.5, col = "red")
                            points(res2$history$X, col = "blue", pch = 4, lwd = 2)
                            points(res2$par[1], res2$par[2], col = "red", pch = 4, lwd = 2, cex=2) 
               }
)

#---------------------------------------------------------------------------
# 3- Stepwise Uncertainty Reduction criterion, fast objective function,
# single inequality constraint, with initial DOE given + 10 observations,
# using genoud
#---------------------------------------------------------------------------
n.init &lt;- 12 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n.init, n_var, seed = 42)$design)$design, 1)
cst2.init &lt;- apply(design.grid, 1, fun2.cst)

res3 &lt;- easyEGO.cst(fun=fun, constraint=fun2.cst, n.cst=1, lower=lower, upper=upper, budget=10,
                    X=design.grid, C=cst2.init,
                   cheapfun=TRUE, control=list(method="SUR", inneroptim="genoud", maxit=20))
        
cat("best design found:", res3$par, "\n")
cat("corresponding objective and constraint:", res3$value, "\n")

# Objective function in colour, inequality constraint boundary in red
# Initial DoE: white circles, added points: blue crosses, best solution: red cross
                            
filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(obj.grid, n.grid), main = "Single constraint, fast objective",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(obj.grid, n.grid), nlevels = 10, add = TRUE,
                                    drawlabels = TRUE)
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst2.grid, n.grid), level = 0, add = TRUE,
                                    drawlabels = FALSE,lwd = 1.5, col = "red")
                            points(res3$history$X, col = "blue", pch = 4, lwd = 2)
                            points(res3$par[1], res3$par[2], col = "red", pch = 4, lwd = 2, cex=2) 
                                           }
                )


</code></pre>

<hr>
<h2 id='EGO.cst'>Sequential constrained Expected Improvement maximization and model re-estimation,
with a number of iterations fixed in advance by the user</h2><span id='topic+EGO.cst'></span>

<h3>Description</h3>

<p>Executes <code>nsteps</code> iterations of EGO methods integrating constraints, based on objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>.
At each step, kriging models are re-estimated (including covariance parameters re-estimation)
based on the initial design points plus the points visited during all previous iterations;
then a new point is obtained by maximizing one of the constrained Expected Improvement criteria available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EGO.cst(
  model.fun = NULL,
  fun,
  cheapfun = NULL,
  model.constraint,
  constraint,
  equality = FALSE,
  crit = "EFI",
  nsteps,
  lower,
  upper,
  type = "UK",
  cov.reestim = TRUE,
  critcontrol = NULL,
  optimcontrol = list(method = "genoud", threshold = 1e-05, distance = "euclidean",
    notrace = FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EGO.cst_+3A_model.fun">model.fun</code></td>
<td>
<p>object of class <code><a href="DiceKriging.html#topic+km">km</a></code> corresponding to the objective function,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_fun">fun</code></td>
<td>
<p>scalar function to be minimized, corresponding to <code>model.fun</code> found by a call to <code><a href="base.html#topic+match.fun">match.fun</a></code>,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_cheapfun">cheapfun</code></td>
<td>
<p>optional scalar function to use if the objective is a fast-to-evaluate function (handled next with class <code><a href="#topic+fastfun">fastfun</a></code>,
through the use of <code><a href="base.html#topic+match.fun">match.fun</a></code>), 
which does not need a kriging model, see details below,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_model.constraint">model.constraint</code></td>
<td>
<p>either one or a list of models of class <code><a href="DiceKriging.html#topic+km">km</a></code>, one per constraint,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_constraint">constraint</code></td>
<td>
<p>vectorial function corresponding to the constraints, see details below,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_equality">equality</code></td>
<td>
<p>either <code>FALSE</code> if all constraints are for inequalities, else a vector of boolean indicating which are equalities</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_crit">crit</code></td>
<td>
<p>choice of constrained improvement function: &quot;<code>AL</code>&quot;, &quot;<code>EFI</code>&quot; or &quot;<code>SUR</code>&quot;,
see details below,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_nsteps">nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_type">type</code></td>
<td>
<p>&quot;<code>SK</code>&quot; or &quot;<code>UK</code>&quot; (by default), depending whether uncertainty related to trend estimation has to be taken into account,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_cov.reestim">cov.reestim</code></td>
<td>
<p>optional boolean specifying if the kriging hyperparameters should be re-estimated at each iteration,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_critcontrol">critcontrol</code></td>
<td>
<p>optional list of parameters for criterion <code>crit</code>, see details,</p>
</td></tr>
<tr><td><code id="EGO.cst_+3A_optimcontrol">optimcontrol</code></td>
<td>
<p>an optional list of control parameters for optimization of the selected infill criterion:
</p>

<ul>
<li><p><code>method</code> can be set to &quot;<code>discrete</code>&quot; or &quot;<code>genoud</code>&quot;. For &quot;<code>discrete</code>&quot;, a matrix <code>candidate.points</code> must be given,
For &quot;<code>genoud</code>&quot;, specific parameters to the chosen method can also be specified  (see <code><a href="rgenoud.html#topic+genoud">genoud</a></code>).
</p>
</li>
<li><p>Options for the <code><a href="#topic+checkPredict">checkPredict</a></code> function: <code>threshold</code> (<code>1e-4</code>) and <code>distance</code> (<code>covdist</code>) are used to avoid 
numerical issues occuring when adding points too close to the existing ones.
</p>
</li>
<li><p><code>notrace</code> can be set to <code>TRUE</code> to suppress printing of the optimization progresses.
</p>
</li></ul>
</td></tr>
<tr><td><code id="EGO.cst_+3A_...">...</code></td>
<td>
<p>additional parameters to be given to the objective <code>fun</code> and <code>constraint</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extension of the function <code><a href="#topic+EGO.nsteps">EGO.nsteps</a></code> to constrained optimization.<br />
</p>
<p>The problem considered is of the form: <code class="reqn">min f(x)</code> s.t. <code class="reqn">g(x) \le 0</code>, 
<code class="reqn">g</code> having a vectorial output. 
By default all its components are supposed to be inequalities, but one can use a boolean vector in <code>equality</code> to specify which are equality constraints.
In this case one can modify the tolerance on the constraints using the <code>tolConstraints</code> component of <code>critcontrol</code>:
an optional vector giving a tolerance for each of the constraints (equality or inequality). 
It is highly recommended to use it when there are equality constraints since the default tolerance of <code>0.05</code> in such case might not be suited.<br />
</p>
<p>Available infill criteria with <code>crit</code> are: <br />
</p>

<ul>
<li><p> Expected Probability of Feasibily (<code>EFI</code>) <code><a href="#topic+crit_EFI">crit_EFI</a></code>,
</p>
</li>
<li><p> Augmented Lagrangian (<code>AL</code>) <code><a href="#topic+crit_AL">crit_AL</a></code>,
</p>
</li>
<li><p> Stepwise Uncertainty Reduction of the excursion volume (<code>SUR</code>) <code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>.
</p>
</li></ul>

<p>Depending on the selected criterion, various parameters are available.
More precisions are given in the corresponding help pages.<br /> 
</p>
<p>It is possible to consider a cheap to evaluate objective function submitted to expensive constraints. 
In this case, provide only a function in <code>cheapfun</code>, with both <code>model.fun</code> and <code>fun</code> to NULL, see examples below.
</p>


<h3>Value</h3>

<p>A list with components:
</p>

<ul>
<li><p><code>par</code>: a matrix representing the additional points visited during the algorithm,
</p>
</li>
<li><p><code>values</code>: a vector representing the response (objective) values at the points given in <code>par</code>,
</p>
</li>
<li><p><code>constraint</code>: a matrix representing the constraints values at the points given in <code>par</code>,
</p>
</li>
<li><p><code>feasibility</code>: a boolean vector saying if points given in <code>par</code> respect the constraints,
</p>
</li>
<li><p><code>nsteps</code>: an integer representing the desired number of iterations (given in argument),
</p>
</li>
<li><p><code>lastmodel.fun</code>: an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> corresponding to the objective function,
</p>
</li>
<li><p><code>lastmodel.constraint</code>: one or a list of objects of class <code><a href="DiceKriging.html#topic+km">km</a></code> corresponding to the last kriging models fitted to the constraints.<br /> <br />
If a problem occurs during either model updates or criterion maximization, the last working model and corresponding values are returned.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>Mickael Binois
</p>


<h3>References</h3>

<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>
<p>M. Schonlau, W.J. Welch, and D.R. Jones (1998),
Global versus local search in constrained optimization of computer models,
<em>Lecture Notes-Monograph Series</em>, 11-25.
</p>
<p>M.J. Sasena, P. Papalambros, and P.Goovaerts (2002),
Exploration of metamodeling sampling criteria for constrained global optimization,
<em>Engineering optimization</em>, 34, 263-278.
</p>
<p>R.B. Gramacy, G.A. Gray, S. Le Digabel, H.K.H Lee, P. Ranjan, G. Wells, Garth, and S.M. Wild (2014+),
Modeling an augmented Lagrangian for improved blackbox constrained optimization,
<em>arXiv preprint arXiv:1403.4890</em>.
</p>
<p>J.M. Parr (2012),
<em>Improvement criteria for constraint handling and multiobjective optimization</em>,
University of Southampton.
</p>
<p>V. Picheny (2014),
A stepwise uncertainty reduction approach to constrained global optimization,
<em>Proceedings of the 17th International Conference on Artificial Intelligence and Statistics</em>,  JMLR W&amp;CP 33, 787-795.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+critcst_optimizer">critcst_optimizer</a></code>, <code><a href="#topic+crit_EFI">crit_EFI</a></code>, <code><a href="#topic+crit_AL">crit_AL</a></code>,
<code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>, <code><a href="#topic+easyEGO.cst">easyEGO.cst</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#---------------------------------------------------------------------------
# 2D objective function, 3 cases
#---------------------------------------------------------------------------

set.seed(25468)
library(DiceDesign)

n_var &lt;- 2 
fun &lt;- goldsteinprice
fun1.cst &lt;- function(x){return(-branin(x) + 25)}
fun2.cst &lt;- function(x){return(3/2 - x[1] - 2*x[2] - .5*sin(2*pi*(x[1]^2 - 2*x[2])))}

# Constraint function with vectorial output
cstfun &lt;- function(x){
  return(c(fun1.cst(x), fun2.cst(x)))
}

# For illustration purposes
n.grid &lt;- 31
test.grid &lt;- expand.grid(X1 = seq(0, 1, length.out = n.grid), X2 = seq(0, 1, length.out = n.grid))
obj.grid &lt;- apply(test.grid, 1, fun)
cst1.grid &lt;- apply(test.grid, 1, fun1.cst)
cst2.grid &lt;- apply(test.grid, 1, fun2.cst)

# Initial set of observations and models
n.init &lt;- 12 
design.grid &lt;- round(maximinESE_LHS(lhsDesign(n.init, n_var, seed = 42)$design)$design, 1)
obj.init &lt;- apply(design.grid, 1, fun)
cst1.init &lt;- apply(design.grid, 1, fun1.cst)
cst2.init &lt;- apply(design.grid, 1, fun2.cst)
model.fun &lt;- km(~., design = design.grid, response = obj.init)
model.constraint1 &lt;- km(~., design = design.grid, response = cst1.init, lower=c(.2,.2))
model.constraint2 &lt;- km(~., design = design.grid, response = cst2.init, lower=c(.2,.2))
model.constraint &lt;- list(model.constraint1, model.constraint2)

lower &lt;- rep(0, n_var)
upper &lt;- rep(1, n_var)

#---------------------------------------------------------------------------
# 1- Expected Feasible Improvement criterion, expensive objective function,
# two inequality constraints, 5 iterations, using genoud
#---------------------------------------------------------------------------

cstEGO &lt;- EGO.cst(model.fun = model.fun, fun = fun, model.constraint = model.constraint,
                  crit = "EFI", constraint = cstfun, equality = FALSE, lower = lower, 
                  upper = upper, nsteps = 5, optimcontrol = list(method = "genoud", maxit = 20))

# Plots: objective function in colour, constraint boundaries in red
# Initial DoE: white circles, added points: blue crosses, best solution: red cross

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(obj.grid, n.grid), main = "Two inequality constraints",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst1.grid, n.grid), level = 0, add=TRUE,drawlabels=FALSE,
                                    lwd=1.5, col = "red")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst2.grid, n.grid), level = 0, add=TRUE,drawlabels=FALSE,
                                    lwd=1.5, col = "red")
                            points(cstEGO$par, col = "blue", pch = 4, lwd = 2)
               }
)

#---------------------------------------------------------------------------
# 2- Augmented Lagrangian Improvement criterion, expensive objective function,
# one inequality and one equality constraint, using a discrete set of candidates (grid)
#---------------------------------------------------------------------------
cstEGO2 &lt;- EGO.cst(model.fun = model.fun, fun = fun, model.constraint = model.constraint,
                   crit = "AL", constraint = cstfun, equality = c(TRUE, FALSE), lower = lower,  
                   upper = upper, nsteps = 10,
                   critcontrol = list(tolConstraints = c(2, 0), always.update=TRUE),
                   optimcontrol=list(method="discrete", candidate.points=as.matrix(test.grid)))

# Plots: objective function in colour, inequality constraint boundary in red,
# equality constraint in orange
# Initial DoE: white circles, added points: blue crosses, best solution: red cross

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(obj.grid, n.grid),
               main = "Inequality (red) and equality (orange) constraints",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst1.grid, n.grid), level = 0, add=TRUE,
                                    drawlabels=FALSE,lwd=1.5, col = "orange")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid),
                                    matrix(cst2.grid, n.grid), level = 0, add=TRUE,
                                    drawlabels=FALSE,lwd=1.5, col = "red")
                            points(cstEGO2$par, col = "blue", pch = 4, lwd = 2)
               }
)

#---------------------------------------------------------------------------
# 3- Stepwise Uncertainty Reduction criterion, fast objective function,
# single inequality constraint, 5 steps, importance sampling scheme
#---------------------------------------------------------------------------

cstEGO3 &lt;- EGO.cst(model.fun = NULL, fun = NULL, cheapfun = fun,
                   model.constraint = model.constraint2, constraint = fun2.cst,
                   crit = "SUR", lower = lower, upper = upper,
                   nsteps =5, critcontrol=list(distrib="SUR"))

# Plots: objective function in colour, inequality constraint boundary in red,
# Initial DoE: white circles, added points: blue crosses, best solution: red cross

filled.contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), nlevels = 50,
               matrix(obj.grid, n.grid), main = "Single constraint, fast objective",
               xlab = expression(x[1]), ylab = expression(x[2]), color = terrain.colors, 
               plot.axes = {axis(1); axis(2);
                            points(design.grid[,1], design.grid[,2], pch = 21, bg = "white")
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(obj.grid, n.grid), nlevels = 10, add = TRUE,
                                    drawlabels = TRUE)
                            contour(seq(0, 1, length.out = n.grid), seq(0, 1, length.out = n.grid), 
                                    matrix(cst2.grid, n.grid), level = 0, add=TRUE,
                                    drawlabels=FALSE,lwd=1.5, col = "black")
                            points(cstEGO3$par, col = "blue", pch = 4, lwd = 2)
                                           }
                )


</code></pre>

<hr>
<h2 id='EGO.nsteps'>Sequential EI maximization and model re-estimation, with a number of
iterations fixed in advance by the user</h2><span id='topic+EGO.nsteps'></span>

<h3>Description</h3>

<p>Executes <em>nsteps</em> iterations of the EGO method to an object of class
<code><a href="DiceKriging.html#topic+km">km</a></code>.  At each step, a kriging model is
re-estimated (including covariance parameters re-estimation) based on the
initial design points plus the points visited during all previous
iterations; then a new point is obtained by maximizing the Expected
Improvement criterion (<code><a href="#topic+EI">EI</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EGO.nsteps(
  model,
  fun,
  nsteps,
  lower,
  upper,
  parinit = NULL,
  control = NULL,
  kmcontrol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EGO.nsteps_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> ,</p>
</td></tr>
<tr><td><code id="EGO.nsteps_+3A_fun">fun</code></td>
<td>
<p>the objective function to be minimized,</p>
</td></tr>
<tr><td><code id="EGO.nsteps_+3A_nsteps">nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations,</p>
</td></tr>
<tr><td><code id="EGO.nsteps_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="EGO.nsteps_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="EGO.nsteps_+3A_parinit">parinit</code></td>
<td>
<p>optional vector of initial values for the variables to be
optimized over,</p>
</td></tr>
<tr><td><code id="EGO.nsteps_+3A_control">control</code></td>
<td>
<p>an optional list of control parameters for optimization. One
can control
</p>
<p><code>"pop.size"</code> (default : [4+3*log(nb of variables)]),
</p>
<p><code>"max.generations"</code> (default :5),
</p>
<p><code>"wait.generations"</code> (default :2),
</p>
<p><code>"BFGSburnin"</code> (default :0),
</p>
<p>of the function <code><a href="rgenoud.html#topic+genoud">genoud</a></code>.</p>
</td></tr>
<tr><td><code id="EGO.nsteps_+3A_kmcontrol">kmcontrol</code></td>
<td>
<p>an optional list representing the control variables for
the re-estimation of the kriging model.  The items are the same as in
<code><a href="DiceKriging.html#topic+km">km</a></code> :
</p>
<p><code>penalty</code>, <code>optim.method</code>, <code>parinit</code>, <code>control</code>.
</p>
<p>The default values are those contained in <code>model</code>, typically
corresponding to the variables used in <code><a href="DiceKriging.html#topic+km">km</a></code> to
estimate a kriging model from the initial design points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>a data frame representing the additional points visited during
the algorithm,</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>a data frame representing the response values at the points
given in <code>par</code>,</p>
</td></tr>
<tr><td><code>npoints</code></td>
<td>
<p>an integer representing the number of parallel computations
(=1 here),</p>
</td></tr>
<tr><td><code>nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations
(given in argument),</p>
</td></tr>
<tr><td><code>lastmodel</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>
corresponding to the last kriging model fitted.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Most EGO-like methods (EI algorithms) usually work with Ordinary
Kriging (constant trend), by maximization of the expected improvement.
Here, the EI maximization is also possible with any linear trend. However,
note that the optimization may perform much faster and better when the
trend is a constant since it is the only case where the analytical gradient
is available.
</p>
<p>For more details on <code>kmcontrol</code>, see the documentation of
<code><a href="DiceKriging.html#topic+km">km</a></code>.
</p>


<h3>Author(s)</h3>

<p>David Ginsbourger 
</p>
<p>Olivier Roustant
</p>


<h3>References</h3>

<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>T.J. Santner, B.J. Williams, and W.J. Notz (2003), <em>The design and
analysis of computer experiments</em>, Springer.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code>, <code><a href="#topic+max_EI">max_EI</a></code>, <code><a href="#topic+EI.grad">EI.grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(123)
###############################################################
### 	10 ITERATIONS OF EGO ON THE BRANIN FUNCTION, 	   ####
###	 STARTING FROM A 9-POINTS FACTORIAL DESIGN         ####
###############################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# EGO n steps
library(rgenoud)
nsteps &lt;- 5 # Was 10, reduced to 5 for speeding up compilation
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)     
oEGO &lt;- EGO.nsteps(model=fitted.model1, fun=branin, nsteps=nsteps, 
lower=lower, upper=upper, control=list(pop.size=20, BFGSburnin=2))
print(oEGO$par)
print(oEGO$value)

# graphics
n.grid &lt;- 15 # Was 20, reduced to 15 for speeding up compilation
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, branin)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid, y.grid, z.grid, 40)
title("Branin function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par, pch=19, col="red")
text(oEGO$par[,1], oEGO$par[,2], labels=1:nsteps, pos=3)


###############################################################
### 	20 ITERATIONS OF EGO ON THE GOLDSTEIN-PRICE,  	   ####
###	 STARTING FROM A 9-POINTS FACTORIAL DESIGN   	   ####
###############################################################
## Not run: 
# a 9-points factorial design, and the corresponding response
d &lt;- 2 
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.goldsteinPrice &lt;- apply(design.fact, 1, goldsteinPrice)
response.goldsteinPrice &lt;- data.frame(response.goldsteinPrice) 
names(response.goldsteinPrice) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.goldsteinPrice, 
covtype="gauss", control=list(pop.size=50, max.generations=50, 
wait.generations=5, BFGSburnin=10,trace=FALSE), parinit=c(0.5, 0.5), optim.method="BFGS")

# EGO n steps
library(rgenoud)
nsteps &lt;- 10 # Was 20, reduced to 10 for speeding up compilation
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)     
oEGO &lt;- EGO.nsteps(model=fitted.model1, fun=goldsteinPrice, nsteps=nsteps, 
lower, upper, control=list(pop.size=20, BFGSburnin=2))
print(oEGO$par)
print(oEGO$value)

# graphics
n.grid &lt;- 15 # Was 20, reduced to 15 for speeding up compilation
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, goldsteinPrice)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid, y.grid, z.grid, 40)
title("Goldstein-Price Function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par, pch=19, col="red")
text(oEGO$par[,1], oEGO$par[,2], labels=1:nsteps, pos=3)

## End(Not run)

#######################################################################
### 	nsteps ITERATIONS OF EGO ON THE HARTMAN6 FUNCTION,  	   ####
###	  STARTING FROM A 10-POINTS UNIFORM DESIGN      	   ####
#######################################################################

## Not run: 
fonction&lt;-hartman6
data(mydata)
a &lt;- mydata
nb&lt;-10
nsteps &lt;- 3 # Maybe be changed to a larger value 
x1&lt;-a[[1]][1:nb];x2&lt;-a[[2]][1:nb];x3&lt;-a[[3]][1:nb]
x4&lt;-a[[4]][1:nb];x5&lt;-a[[5]][1:nb];x6&lt;-a[[6]][1:nb]
design &lt;- data.frame(cbind(x1,x2,x3,x4,x5,x6)) 
names(design)&lt;-c("x1", "x2","x3","x4","x5","x6")
n &lt;- nrow(design)

response &lt;- data.frame(q=apply(design,1,fonction)) 
names(response) &lt;- "y" 
fitted.model1 &lt;- km(~1, design=design, response=response, covtype="gauss", 
control=list(pop.size=50, max.generations=20, wait.generations=5, BFGSburnin=5,
trace=FALSE), optim.method="gen", parinit=rep(0.8,6))

res.nsteps &lt;- EGO.nsteps(model=fitted.model1, fun=fonction, nsteps=nsteps, 
lower=rep(0,6), upper=rep(1,6), parinit=rep(0.5,6), control=list(pop.size=50, 
max.generations=20, wait.generations=5, BFGSburnin=5), kmcontrol=NULL)
print(res.nsteps)
plot(res.nsteps$value,type="l")

## End(Not run)

</code></pre>

<hr>
<h2 id='EI'>Analytical expression of the Expected Improvement criterion</h2><span id='topic+EI'></span>

<h3>Description</h3>

<p>Computes the Expected Improvement at current location. The current minimum
of the observations can be replaced by an arbitrary value (plugin), which
is usefull in particular in noisy frameworks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EI(
  x,
  model,
  plugin = NULL,
  type = "UK",
  minimization = TRUE,
  envir = NULL,
  proxy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EI_+3A_x">x</code></td>
<td>
<p>a vector representing the input for which one wishes to calculate
EI,</p>
</td></tr>
<tr><td><code id="EI_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>,</p>
</td></tr>
<tr><td><code id="EI_+3A_plugin">plugin</code></td>
<td>
<p>optional scalar: if provided, it replaces the minimum of the
current observations,</p>
</td></tr>
<tr><td><code id="EI_+3A_type">type</code></td>
<td>
<p>&quot;SK&quot; or &quot;UK&quot; (by default), depending whether uncertainty
related to trend estimation has to be taken into account,</p>
</td></tr>
<tr><td><code id="EI_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td></tr>
<tr><td><code id="EI_+3A_envir">envir</code></td>
<td>
<p>an optional environment specifying where to assign
intermediate values for future gradient calculations. Default is NULL.</p>
</td></tr>
<tr><td><code id="EI_+3A_proxy">proxy</code></td>
<td>
<p>an optional Boolean, if TRUE EI is replaced by the kriging mean (to minimize)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The expected improvement, defined as </p>
<p style="text-align: center;"><code class="reqn">EI(x) := E[( min(Y(X)) -
Y(x))^{+} | Y(X)=y(X)],</code>
</p>
<p> where X is the current design of experiments and Y
is the random process assumed to have generated the objective function y.
If a plugin is specified, it replaces </p>
<p style="text-align: center;"><code class="reqn">min(Y(X))</code>
</p>
<p> in the previous
formula.
</p>


<h3>Author(s)</h3>

<p>David Ginsbourger 
</p>
<p>Olivier Roustant 
</p>
<p>Victor Picheny
</p>


<h3>References</h3>

<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>T.J. Santner, B.J. Williams, and W.J. Notz (2003), <em>The design and
analysis of computer experiments</em>, Springer.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+max_EI">max_EI</a></code>, <code><a href="#topic+EGO.nsteps">EGO.nsteps</a></code>, <code><a href="#topic+qEI">qEI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
##########################################################################
### 	  EI SURFACE ASSOCIATED WITH AN ORDINARY KRIGING MODEL        ####
###    OF THE BRANIN FUNCTION KNOWN AT A 9-POINTS FACTORIAL DESIGN    ####
##########################################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2; n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3))
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# graphics
n.grid &lt;- 12
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
#response.grid &lt;- apply(design.grid, 1, branin)
EI.grid &lt;- apply(design.grid, 1, EI,fitted.model1)
z.grid &lt;- matrix(EI.grid, n.grid, n.grid)
contour(x.grid,y.grid,z.grid,25)
title("Expected Improvement for the Branin function known at 9 points")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")

</code></pre>

<hr>
<h2 id='EI.grad'>Analytical gradient of the Expected Improvement criterion</h2><span id='topic+EI.grad'></span>

<h3>Description</h3>

<p>Computes the gradient of the Expected Improvement at the current location.
The current minimum of the observations can be replaced by an arbitrary
value (plugin), which is usefull in particular in noisy frameworks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EI.grad(
  x,
  model,
  plugin = NULL,
  type = "UK",
  minimization = TRUE,
  envir = NULL,
  proxy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EI.grad_+3A_x">x</code></td>
<td>
<p>a vector representing the input for which one wishes to calculate
<code><a href="#topic+EI">EI</a></code>.</p>
</td></tr>
<tr><td><code id="EI.grad_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>.</p>
</td></tr>
<tr><td><code id="EI.grad_+3A_plugin">plugin</code></td>
<td>
<p>optional scalar: if provided, it replaces the minimum of the
current observations,</p>
</td></tr>
<tr><td><code id="EI.grad_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="EI.grad_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td></tr>
<tr><td><code id="EI.grad_+3A_envir">envir</code></td>
<td>
<p>an optional environment specifying where to get intermediate
values calculated in <code><a href="#topic+EI">EI</a></code>.</p>
</td></tr>
<tr><td><code id="EI.grad_+3A_proxy">proxy</code></td>
<td>
<p>an optional Boolean, if TRUE EI is replaced by the kriging mean (to minimize)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gradient of the expected improvement criterion with respect to
x.  Returns 0 at design points (where the gradient does not exist).
</p>


<h3>Author(s)</h3>

<p>David Ginsbourger 
</p>
<p>Olivier Roustant 
</p>
<p>Victor Picheny
</p>


<h3>References</h3>

<p>D. Ginsbourger (2009), <em>Multiples metamodeles pour l'approximation et
l'optimisation de fonctions numeriques multivariables</em>, Ph.D. thesis, Ecole
Nationale Superieure des Mines de Saint-Etienne, 2009.
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>T.J. Santner, B.J. Williams, and W.J. Notz (2003), <em>The design and
analysis of computer experiments</em>, Springer.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# a 9-points factorial design, and the corresponding response
d &lt;- 2; n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# graphics
n.grid &lt;- 9  # Increase to 50 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
#response.grid &lt;- apply(design.grid, 1, branin)
EI.grid &lt;- apply(design.grid, 1, EI,fitted.model1)
#EI.grid &lt;- apply(design.grid, 1, EI.plot,fitted.model1, gr=TRUE)

z.grid &lt;- matrix(EI.grid, n.grid, n.grid)

contour(x.grid,y.grid,z.grid,20)
title("Expected Improvement for the Branin function known at 9 points")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")

# graphics
n.gridx &lt;- 5  # increase to 15 for nicer picture
n.gridy &lt;- 5  # increase to 15 for nicer picture
x.grid2 &lt;- seq(0,1,length=n.gridx) 
y.grid2 &lt;- seq(0,1,length=n.gridy) 
design.grid2 &lt;- expand.grid(x.grid2, y.grid2)

EI.envir &lt;- new.env()	
	environment(EI) &lt;- environment(EI.grad) &lt;- EI.envir 

for(i in seq(1, nrow(design.grid2)) )
{
	x &lt;- design.grid2[i,]
	ei &lt;- EI(x, model=fitted.model1, envir=EI.envir)
	eigrad &lt;- EI.grad(x , model=fitted.model1, envir=EI.envir)
	if(!(is.null(ei)))
	{
	suppressWarnings(arrows(x$Var1,x$Var2,
	x$Var1 + eigrad[1]*2.2*10e-5, x$Var2 + eigrad[2]*2.2*10e-5, 
	length = 0.04, code=2, col="orange", lwd=2))
	}
}

</code></pre>

<hr>
<h2 id='EQI'>Expected Quantile Improvement</h2><span id='topic+EQI'></span>

<h3>Description</h3>

<p>Evaluation of the Expected Quantile Improvement (EQI) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQI(
  x,
  model,
  new.noise.var = 0,
  beta = 0.9,
  q.min = NULL,
  type = "UK",
  envir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EQI_+3A_x">x</code></td>
<td>
<p>the input vector at which one wants to evaluate the criterion</p>
</td></tr>
<tr><td><code id="EQI_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="EQI_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>(scalar) noise variance of the future observation.
Default value is 0 (noise-free observation).</p>
</td></tr>
<tr><td><code id="EQI_+3A_beta">beta</code></td>
<td>
<p>Quantile level (default value is 0.9)</p>
</td></tr>
<tr><td><code id="EQI_+3A_q.min">q.min</code></td>
<td>
<p>Best kriging quantile. If not provided, this quantity is
evaluated.</p>
</td></tr>
<tr><td><code id="EQI_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="EQI_+3A_envir">envir</code></td>
<td>
<p>environment for saving intermediate calculations and reusing
them within EQI.grad</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Expected Quantile Improvement
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>Picheny, V., Ginsbourger, D., Richet, Y., Caplin, G. (2013). 
Quantile-based optimization of noisy computer experiments with tunable precision. 
<em>Technometrics</em>, 55(1), 2-13.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

##########################################################################
###    EQI SURFACE ASSOCIATED WITH AN ORDINARY KRIGING MODEL        ####
### OF THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################

set.seed(421)

# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
            covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
	    lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)

crit.grid &lt;- apply(design.grid, 1, EQI, model=model, new.noise.var=noise.var, beta=.9)
func.grid &lt;- apply(design.grid, 1, test.function)

# Compute kriging mean and variance on a grid
names(design.grid) &lt;- c("V1","V2")
pred &lt;- predict(model, newdata=design.grid, type="UK", checkNames = FALSE)
mk.grid &lt;- pred$m
sk.grid &lt;- pred$sd

# Plot actual function
z.grid &lt;- matrix(func.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Actual function");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot Kriging mean
z.grid &lt;- matrix(mk.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Kriging mean");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot Kriging variance
z.grid &lt;- matrix(sk.grid^2, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Kriging variance");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot EQI criterion
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("EQI");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

</code></pre>

<hr>
<h2 id='EQI.grad'>EQI's Gradient</h2><span id='topic+EQI.grad'></span>

<h3>Description</h3>

<p>Analytical gradient of the Expected Quantile Improvement (EQI) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EQI.grad(
  x,
  model,
  new.noise.var = 0,
  beta = 0.9,
  q.min = NULL,
  type = "UK",
  envir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EQI.grad_+3A_x">x</code></td>
<td>
<p>the input vector at which one wants to evaluate the criterion</p>
</td></tr>
<tr><td><code id="EQI.grad_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="EQI.grad_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>(scalar) noise variance of the future observation.
Default value is 0 (noise-free observation).</p>
</td></tr>
<tr><td><code id="EQI.grad_+3A_beta">beta</code></td>
<td>
<p>Quantile level (default value is 0.9)</p>
</td></tr>
<tr><td><code id="EQI.grad_+3A_q.min">q.min</code></td>
<td>
<p>Best kriging quantile. If not provided, this quantity is
evaluated.</p>
</td></tr>
<tr><td><code id="EQI.grad_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="EQI.grad_+3A_envir">envir</code></td>
<td>
<p>environment for inheriting intermediate calculations from EQI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gradient of the Expected Quantile Improvement
</p>


<h3>Author(s)</h3>

<p>Victor Picheny  
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(421)

# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
        covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
	lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 9  # change to 21 for nicer visuals
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)

crit.grid &lt;- apply(design.grid, 1, EQI, model=model, new.noise.var=noise.var, beta=.9)
crit.grad &lt;- t(apply(design.grid, 1, EQI.grad, model=model, new.noise.var=noise.var, beta=.9))

z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
contour(x.grid,y.grid, z.grid, 30)
title("EQI and its gradient")
points(model@X[,1],model@X[,2],pch=17,col="blue")

for (i in 1:nt)
{
 x &lt;- design.grid[i,]
 suppressWarnings(arrows(x$Var1,x$Var2, x$Var1+crit.grad[i,1]*.2,x$Var2+crit.grad[i,2]*.2,
length=0.04,code=2,col="orange",lwd=2))
}

</code></pre>

<hr>
<h2 id='fastEGO.nsteps'>Sequential EI maximization and model re-estimation, with a number of
iterations fixed in advance by the user</h2><span id='topic+fastEGO.nsteps'></span>

<h3>Description</h3>

<p>Executes <em>nsteps</em> iterations of the EGO method to an object of class
<code><a href="DiceKriging.html#topic+km">km</a></code>.  At each step, a kriging model is
re-estimated (including covariance parameters re-estimation) based on the
initial design points plus the points visited during all previous
iterations; then a new point is obtained by maximizing the Expected
Improvement criterion (<code><a href="#topic+EI">EI</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastEGO.nsteps(
  model,
  fun,
  nsteps,
  lower,
  upper,
  control = NULL,
  trace = 0,
  n.cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastEGO.nsteps_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> ,</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_fun">fun</code></td>
<td>
<p>the objective function to be minimized,</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_nsteps">nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations,</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_control">control</code></td>
<td>
<p>an optional list of control parameters for EGO. One
can control
</p>
<p><code>"warping"</code> whether or not a warping is applied to the outputs (default FALSE)
</p>
<p><code>"cov.reestim"</code> whether or not the covariance parameters are estimated at
each step (default TRUE)
<code>"gpmean.trick"</code> whether or not EI should be replaced periodically by the GP mean
(default FALSE)
</p>
<p><code>"gpmean.freq"</code> frequency at which EI is replaced by the GP mean (default 1e4)
</p>
<p><code>"always.sample"</code> if TRUE, forces observation even if it creates poor conditioning</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_trace">trace</code></td>
<td>
<p>between -1 (no trace) and 3 (full messages)</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_n.cores">n.cores</code></td>
<td>
<p>number of cores used for EI maximisation</p>
</td></tr>
<tr><td><code id="fastEGO.nsteps_+3A_...">...</code></td>
<td>
<p>additional parameters to be given to <code>fun</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>a data frame representing the additional points visited during
the algorithm,</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>a data frame representing the response values at the points
given in <code>par</code>,</p>
</td></tr>
<tr><td><code>npoints</code></td>
<td>
<p>an integer representing the number of parallel computations
(=1 here),</p>
</td></tr>
<tr><td><code>nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations
(given in argument),</p>
</td></tr>
<tr><td><code>lastmodel</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>
corresponding to the last kriging model fitted. If warping is true, 
<code>y</code> values are normalized (warped) and will not match <code>value</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny
</p>


<h3>References</h3>

<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>T.J. Santner, B.J. Williams, and W.J. Notz (2003), <em>The design and
analysis of computer experiments</em>, Springer.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code>, <code><a href="#topic+max_crit">max_crit</a></code>, <code><a href="#topic+EI.grad">EI.grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
###############################################################
### 	10 ITERATIONS OF EGO ON THE BRANIN FUNCTION, 	   ####
###	 STARTING FROM A 9-POINTS FACTORIAL DESIGN         ####
###############################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# EGO n steps
nsteps &lt;- 5 
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)     
oEGO &lt;- fastEGO.nsteps(model=fitted.model1, fun=branin, nsteps=nsteps, lower=lower, upper=upper)
print(oEGO$par)
print(oEGO$value)

# graphics
n.grid &lt;- 15 # Was 20, reduced to 15 for speeding up compilation
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, branin)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid, y.grid, z.grid, 40)
title("Branin function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par, pch=19, col="red")
text(oEGO$par[,1], oEGO$par[,2], labels=1:nsteps, pos=3)

</code></pre>

<hr>
<h2 id='fastfun'>Fastfun function</h2><span id='topic+fastfun'></span>

<h3>Description</h3>

<p>Modification of an R function to be used as with methods <code>predict</code> and <code>update</code> (similar to a <code><a href="DiceKriging.html#topic+km">km</a></code> object). 
It creates an S4 object which contains the values corresponding to evaluations of other costly observations.
It is useful when an objective can be evaluated fast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastfun(fn, design, response = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastfun_+3A_fn">fn</code></td>
<td>
<p>the evaluator function, found by a call to <code><a href="base.html#topic+match.fun">match.fun</a></code>,</p>
</td></tr>
<tr><td><code id="fastfun_+3A_design">design</code></td>
<td>
<p>a data frame representing the design of experiments.
The ith row contains the values of the d input variables corresponding to the ith evaluation.</p>
</td></tr>
<tr><td><code id="fastfun_+3A_response">response</code></td>
<td>
<p>optional vector (or 1-column matrix or data frame) containing the values of the 1-dimensional output given by the objective function at the design points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class  <code><a href="#topic+fastfun-class">fastfun-class</a></code>.
</p>

<hr>
<h2 id='fastfun-class'>Class for fast to compute objective.</h2><span id='topic+fastfun-class'></span><span id='topic+predict+2Cfastfun-method'></span><span id='topic+update+2Cfastfun-method'></span><span id='topic+simulate+2Cfastfun-method'></span>

<h3>Description</h3>

<p>Class for fast to compute objective.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'fastfun'
predict(object, newdata, ...)

## S4 method for signature 'fastfun'
update(object, newX, newy, ...)

## S4 method for signature 'fastfun'
simulate(object, nsim, seed, newdata, cond, nugget.sim, checkNames, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastfun-class_+3A_object">object</code></td>
<td>
<p><code><a href="#topic+fastfun">fastfun</a></code> object</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_newdata">newdata</code></td>
<td>
<p>an optional vector, matrix or data frame containing the points where to perform predictions.
Default is <code>NULL</code>: simulation is performed at design points specified in <code>object</code>.</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_...">...</code></td>
<td>
<p>further arguments (not used)</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_newx">newX</code></td>
<td>
<p>Matrix of the new location for the design</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_newy">newy</code></td>
<td>
<p>Matrix of the responses at <code>newX</code></p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_nsim">nsim</code></td>
<td>
<p>an optional number specifying the number of response vectors to simulate. Default is 1.</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_seed">seed</code></td>
<td>
<p>usual seed argument of method simulate. Not used.</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_cond">cond</code></td>
<td>
<p>an optional boolean indicating the type of simulations. Not used.</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_nugget.sim">nugget.sim</code></td>
<td>
<p>an optional number corresponding to a numerical nugget effect. Not used.</p>
</td></tr>
<tr><td><code id="fastfun-class_+3A_checknames">checkNames</code></td>
<td>
<p>an optional boolean. Not used.</p>
</td></tr>
</table>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>predict</code>: Predict(by evaluating <code>fun</code>) the result at a new observation.
</p>
</li>
<li> <p><code>update</code>: Update the <code>X</code> and <code>y</code> slots with a new design and observation.
</p>
</li>
<li> <p><code>simulate</code>: Simulate responses values (for compatibility with methods using <code>DiceKriging simulate</code>)
</p>
</li></ul>


<h3>Slots</h3>


<dl>
<dt><code>d</code></dt><dd><p>spatial dimension,</p>
</dd>
<dt><code>n</code></dt><dd><p>observations number,</p>
</dd>
<dt><code>X</code></dt><dd><p>the design of experiments, size <code>n x d</code>,</p>
</dd>
<dt><code>y</code></dt><dd><p>the observations, size <code>n x 1</code>,</p>
</dd>
<dt><code>fun</code></dt><dd><p>the evaluator function.</p>
</dd>
</dl>


<h3>Objects from the Class </h3>

<p>To create a <code>fastfun</code> object, use <code><a href="#topic+fastfun">fastfun</a></code>. See also this function for more details and examples.
</p>

<hr>
<h2 id='goldsteinprice'>2D test function</h2><span id='topic+goldsteinprice'></span>

<h3>Description</h3>

<p>Goldstein-Price 2-dimensional test function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goldsteinprice(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="goldsteinprice_+3A_x">x</code></td>
<td>
<p>a 2-dimensional vector specifying the location where the function
is to be evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The goldsteinprice (standardized version) function is defined over the
domain <code>[0,1]^2</code>. It has 1 global minimizer : x* = c(0.5, 0.25), with
minimum f(x*) = -3.129172, and 3 local minima x*,2 = c(0.35, 0.4), x*,3 =
c(0.95, 0.55), x*,4 = c(0.8 , 0.7), with respective minima f(x*,2) =
-2.180396, f(x*,3) = -1.756143, f(x*,4) = -0.807367.
</p>


<h3>Value</h3>

<p>A real number equal to the goldsteinprice function values at
<code>x</code>
</p>


<h3>Author(s)</h3>

<p>Tobias Wagner  
</p>
<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
design &lt;- matrix(runif(200), 200, 2)
response &lt;- apply(design, 1, goldsteinprice)

</code></pre>

<hr>
<h2 id='hartman4'>4D test function</h2><span id='topic+hartman4'></span>

<h3>Description</h3>

<p>Hartman 4-dimensional test function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hartman4(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hartman4_+3A_x">x</code></td>
<td>
<p>a 4-dimensional vector specifying the location where the function
is to be evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The hartman4 (standardized version) function is defined over the domain
<code>[0,1]^4</code>. It has 1 global minimizer : x* = c(0.1873, 0.1906, 0.5566,
0.2647), with minimum f(x*) = -3.135474
</p>


<h3>Value</h3>

<p>A real number equal to the hartman4 function values at <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Tobias Wagner  
</p>
<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
design &lt;- matrix(runif(400), 100, 4)
response &lt;- apply(design, 1, hartman4)

</code></pre>

<hr>
<h2 id='integration_design_cst'>Generic function to build integration points (for the SUR criterion)</h2><span id='topic+integration_design_cst'></span>

<h3>Description</h3>

<p>Modification of the function  <code><a href="KrigInv.html#topic+integration_design">integration_design</a></code> from the package <code>KrigInv</code> to 
be usable for SUR-based optimization with constraints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integration_design_cst(
  integcontrol = NULL,
  lower,
  upper,
  model.fun = NULL,
  model.constraint = NULL,
  equality = FALSE,
  critcontrol = NULL,
  min.prob = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integration_design_cst_+3A_integcontrol">integcontrol</code></td>
<td>
<p>Optional list specifying the procedure to build the integration points and weights. 
Many options are possible.<br /> 
A) If nothing is specified, 100*d points are chosen using the Sobol sequence. <br />
B) One can directly set the field <code>integration.points</code> (p * d matrix) for prespecified integration points. 
In this case these integration points and the corresponding vector <code>integration.weights</code> will be used 
for all the iterations of the algorithm. <br />
C) If the field <code>integration.points</code> is not set then the integration points are renewed at each iteration. 
In that case one can control the number of integration points <code>n.points</code> (default: 100*d) and a specific 
distribution <code>distrib</code>. Possible values for distrib are: &quot;<code>sobol</code>&quot;, &quot;<code>MC</code>&quot; and &quot;<code>SUR</code>&quot;
(default: &quot;<code>sobol</code>&quot;). <br />
C.1) The choice &quot;<code>sobol</code>&quot; corresponds to integration points chosen with the Sobol sequence in dimension d (uniform weight). <br />
C.2) The choice &quot;<code>MC</code>&quot; corresponds to points chosen randomly, uniformly on the domain. <br />
C.3) The choice &quot;<code>SUR</code>&quot; corresponds to importance sampling distributions (unequal weights). <br />
When important sampling procedures are chosen, <code>n.points</code> points are chosen using importance sampling among a discrete 
set of <code>n.candidates</code> points (default: <code>n.points</code>*10) which are distributed according to a distribution <code>init.distrib</code> 
(default: &quot;<code>sobol</code>&quot;). Possible values for <code>init.distrib</code> are the space filling distributions &quot;<code>sobol</code>&quot; and &quot;<code>MC</code>&quot; 
or an user defined distribution &quot;<code>spec</code>&quot;. The &quot;<code>sobol</code>&quot; and &quot;<code>MC</code>&quot; choices correspond to quasi random and random points 
in the domain. If the &quot;<code>spec</code>&quot; value is chosen the user must fill in manually the field <code>init.distrib.spec</code> to specify 
himself a n.candidates * d matrix of points in dimension d.</p>
</td></tr>
<tr><td><code id="integration_design_cst_+3A_lower">lower</code></td>
<td>
<p>Vector containing the lower bounds of the design space.</p>
</td></tr>
<tr><td><code id="integration_design_cst_+3A_upper">upper</code></td>
<td>
<p>Vector containing the upper bounds of the design space.</p>
</td></tr>
<tr><td><code id="integration_design_cst_+3A_model.fun">model.fun</code></td>
<td>
<p>object of class <code><a href="DiceKriging.html#topic+km">km</a></code> corresponding to the objective functions,
or, if the objective function is fast-to-evaluate, a <code><a href="#topic+fastfun">fastfun</a></code> object,</p>
</td></tr>
<tr><td><code id="integration_design_cst_+3A_model.constraint">model.constraint</code></td>
<td>
<p>either one or a list of objects of class <code><a href="DiceKriging.html#topic+km">km</a></code>, one for each constraint function,</p>
</td></tr>
<tr><td><code id="integration_design_cst_+3A_equality">equality</code></td>
<td>
<p>either <code>FALSE</code> if all constraints are for inequalities, else a vector of boolean indicating which are equalities</p>
</td></tr>
<tr><td><code id="integration_design_cst_+3A_critcontrol">critcontrol</code></td>
<td>
<p>optional list of parameters (see <code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code>); here only the component <code>tolConstraints</code> is used.</p>
</td></tr>
<tr><td><code id="integration_design_cst_+3A_min.prob">min.prob</code></td>
<td>
<p>This argument applies only when importance sampling distributions are chosen. 
For numerical reasons we give a minimum probability for a point to
belong to the importance sample. This avoids probabilities equal to zero and importance sampling
weights equal to infinity. In an importance sample of M points, the maximum weight becomes 
<code>1/min.prob * 1/M</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components:
</p>

<ul>
<li><p><code>integration.points</code> p x d matrix of p points used for the numerical calculation of integrals
</p>
</li>
<li><p><code>integration.weights</code> a vector of size p corresponding to the weight of each point. If all the points are equally 
weighted, integration.weights is set to NULL
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>Mickael Binois
</p>


<h3>References</h3>

<p>Chevalier C., Picheny V., Ginsbourger D. (2012), 
The KrigInv package: An efficient and user-friendly R implementation of Kriging-based inversion algorithms, 
<em>Computational Statistics and Data Analysis</em>, 71, 1021-1034.
</p>
<p>Chevalier C., Bect J., Ginsbourger D., Vazquez E., Picheny V., Richet Y. (2011), 
Fast parallel kriging-based stepwise uncertainty reduction with application to the identification of an excursion set,
<em>Technometrics</em>, 56(4), 455-465.
</p>
<p>V. Picheny (2014),
A stepwise uncertainty reduction approach to constrained global optimization,
<em>Proceedings of the 17th International Conference on Artificial Intelligence and Statistics</em>, JMLR W&amp;CP 33, 787-795.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crit_SUR_cst">crit_SUR_cst</a></code> <code>KrigInv integration_design</code>
</p>

<hr>
<h2 id='kriging.quantile'>Kriging quantile</h2><span id='topic+kriging.quantile'></span>

<h3>Description</h3>

<p>Evaluation of a kriging quantile a a new point. To be used in an
optimization loop.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kriging.quantile(x, model, beta = 0.1, type = "UK", envir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kriging.quantile_+3A_x">x</code></td>
<td>
<p>the input vector at which one wants to evaluate the criterion</p>
</td></tr>
<tr><td><code id="kriging.quantile_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="kriging.quantile_+3A_beta">beta</code></td>
<td>
<p>Quantile level (default value is 0.1)</p>
</td></tr>
<tr><td><code id="kriging.quantile_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="kriging.quantile_+3A_envir">envir</code></td>
<td>
<p>an optional environment specifying where to assign
intermediate values for future gradient calculations. Default is NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Kriging quantile
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

##########################################################################
###    KRIGING QUANTILE SURFACE                                       ####
### OF THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################

set.seed(421)

# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
            covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
	    lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)

crit.grid &lt;- apply(design.grid, 1, kriging.quantile, model=model, beta=.1)
func.grid &lt;- apply(design.grid, 1, test.function)

# Compute kriging mean and variance on a grid
names(design.grid) &lt;- c("V1","V2")
pred &lt;- predict(model, newdata=design.grid, type="UK", checkNames = FALSE)
mk.grid &lt;- pred$m
sk.grid &lt;- pred$sd

# Plot actual function
z.grid &lt;- matrix(func.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Actual function");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot Kriging mean
z.grid &lt;- matrix(mk.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Kriging mean");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot Kriging variance
z.grid &lt;- matrix(sk.grid^2, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("Kriging variance");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

# Plot kriging.quantile criterion
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title("kriging.quantile");
points(model@X[,1],model@X[,2],pch=17,col="blue"); 
axis(1); axis(2)})

</code></pre>

<hr>
<h2 id='kriging.quantile.grad'>Analytical gradient of the Kriging quantile of level beta</h2><span id='topic+kriging.quantile.grad'></span>

<h3>Description</h3>

<p>Computes the gradient of the Kriging quantile of level beta at the current
location. Only available for Universal Kriging with constant trend
(Ordinary Kriging).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kriging.quantile.grad(x, model, beta = 0.1, type = "UK", envir = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kriging.quantile.grad_+3A_x">x</code></td>
<td>
<p>a vector representing the input for which one wishes to calculate
kriging.quantile.grad.</p>
</td></tr>
<tr><td><code id="kriging.quantile.grad_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>.</p>
</td></tr>
<tr><td><code id="kriging.quantile.grad_+3A_beta">beta</code></td>
<td>
<p>A quantile level (between 0 and 1)</p>
</td></tr>
<tr><td><code id="kriging.quantile.grad_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="kriging.quantile.grad_+3A_envir">envir</code></td>
<td>
<p>environment for inheriting intermediate calculations from
<code>"kriging.quantile"</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gradient of the Kriging mean predictor with respect to x.  
Returns 0 at design points (where the gradient does not exist).
</p>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>O. Roustant, D. Ginsbourger, Y. Deville, <em>DiceKriging, DiceOptim: Two
R packages for the analysis of computer experiments by kriging-based
metamodeling and optimization</em>, J. Stat. Soft., 2010.
<a href="https://www.jstatsoft.org/article/view/v051i01">https://www.jstatsoft.org/article/view/v051i01</a>
</p>
<p>D. Ginsbourger (2009), <em>Multiples metamodeles pour l'approximation et
l'optimisation de fonctions numeriques multivariables</em>, Ph.D. thesis, Ecole
Nationale Superieure des Mines de Saint-Etienne, 2009.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI.grad">EI.grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##########################################################################
###    KRIGING QUANTILE SURFACE AND ITS GRADIENT FOR                  ####
###    THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################
set.seed(421)

# Set test problem parameters
doe.size &lt;- 12
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {
y.tilde[i] &lt;- test.function(doe[i,]) + sqrt(noise.var)*rnorm(n=1)
}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
        covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
	lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Compute actual function and criterion on a grid
n.grid &lt;- 9 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
nt &lt;- nrow(design.grid)

crit.grid &lt;- apply(design.grid, 1, kriging.quantile, model=model, beta=.1)
crit.grad &lt;- t(apply(design.grid, 1, kriging.quantile.grad, model=model, beta=.1))

z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
contour(x.grid,y.grid, z.grid, 30)
title("kriging.quantile and its gradient")
points(model@X[,1],model@X[,2],pch=17,col="blue")

for (i in 1:nt)
{
 x &lt;- design.grid[i,]
 arrows(x$Var1,x$Var2, x$Var1+crit.grad[i,1]*.01,x$Var2+crit.grad[i,2]*.01, 
length=0.04,code=2,col="orange",lwd=2)
}

</code></pre>

<hr>
<h2 id='max_AEI'>Maximizer of the Augmented Expected Improvement criterion function</h2><span id='topic+max_AEI'></span>

<h3>Description</h3>

<p>Maximization, based on the package rgenoud of the Augmented Expected
Improvement (AEI) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_AEI(
  model,
  new.noise.var = 0,
  y.min = NULL,
  type = "UK",
  lower,
  upper,
  parinit = NULL,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_AEI_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="max_AEI_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>the (scalar) noise variance of the new observation.</p>
</td></tr>
<tr><td><code id="max_AEI_+3A_y.min">y.min</code></td>
<td>
<p>The kriging mean prediction at the current best point (point
with smallest kriging quantile).  If not provided, this quantity is
evaluated inside the AEI function (may increase computational time).</p>
</td></tr>
<tr><td><code id="max_AEI_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="max_AEI_+3A_lower">lower</code></td>
<td>
<p>vector containing the lower bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="max_AEI_+3A_upper">upper</code></td>
<td>
<p>optional vector containing the upper bounds of the variables
to be optimized over</p>
</td></tr>
<tr><td><code id="max_AEI_+3A_parinit">parinit</code></td>
<td>
<p>optional vector containing the initial values for the
variables to be optimized over</p>
</td></tr>
<tr><td><code id="max_AEI_+3A_control">control</code></td>
<td>
<p>optional list of control parameters for optimization.  One
can control <code>"pop.size"</code> (default : [N=3*2^dim for dim&lt;6 and N=32*dim
otherwise]), <code>"max.generations"</code> (12), <code>"wait.generations"</code> (2)
and <code>"BFGSburnin"</code> (2) of function <code>"genoud"</code> (see
<code><a href="rgenoud.html#topic+genoud">genoud</a></code>).  Numbers into brackets are the default
values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: </p>
<table>
<tr><td><code>par</code></td>
<td>
<p>the best set of parameters
found.</p>
</td></tr> <tr><td><code>value</code></td>
<td>
<p>the value AEI at par.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(DiceDesign)
set.seed(100)

# Set test problem parameters
doe.size &lt;- 10
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(lhsDesign(doe.size, dim)$design)
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {y.tilde[i] &lt;- test.function(doe[i,]) 
+ sqrt(noise.var)*rnorm(n=1)}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
     covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
     lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Optimisation using max_AEI
res &lt;- max_AEI(model, new.noise.var=noise.var, type = "UK", 
lower=c(0,0), upper=c(1,1)) 
X.genoud &lt;- res$par

# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
names(design.grid) &lt;- c("V1","V2")
nt &lt;- nrow(design.grid)
crit.grid &lt;- apply(design.grid, 1, AEI, model=model, new.noise.var=noise.var)

## Not run: 
# # 2D plots
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
tit &lt;- "Green: best point found by optimizer"
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title(tit);points(model@X[,1],model@X[,2],pch=17,col="blue"); 
points(X.genoud[1],X.genoud[2],pch=17,col="green");
axis(1); axis(2)})

## End(Not run)

</code></pre>

<hr>
<h2 id='max_AKG'>Maximizer of the Expected Quantile Improvement criterion function</h2><span id='topic+max_AKG'></span>

<h3>Description</h3>

<p>Maximization, based on the package rgenoud of the Expected Quantile
Improvement (AKG) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_AKG(
  model,
  new.noise.var = 0,
  type = "UK",
  lower,
  upper,
  parinit = NULL,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_AKG_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="max_AKG_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>the (scalar) noise variance of an observation. Default
value is 0 (noise-free observation).</p>
</td></tr>
<tr><td><code id="max_AKG_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="max_AKG_+3A_lower">lower</code></td>
<td>
<p>vector containing the lower bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="max_AKG_+3A_upper">upper</code></td>
<td>
<p>vector containing the upper bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="max_AKG_+3A_parinit">parinit</code></td>
<td>
<p>optional vector containing the initial values for the
variables to be optimized over</p>
</td></tr>
<tr><td><code id="max_AKG_+3A_control">control</code></td>
<td>
<p>optional list of control parameters for optimization.  One
can control <code>"pop.size"</code> (default : [N=3*2^dim for dim&lt;6 and N=32*dim
otherwise]), <code>"max.generations"</code> (12), <code>"wait.generations"</code> (2)
and <code>"BFGSburnin"</code> (2) of function <code>"genoud"</code> (see
<code><a href="rgenoud.html#topic+genoud">genoud</a></code>).  Numbers into brackets are the default
values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: </p>
<table>
<tr><td><code>par</code></td>
<td>
<p>the best set of parameters
found.</p>
</td></tr> <tr><td><code>value</code></td>
<td>
<p>the value AKG at par.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##########################################################################
###    AKG SURFACE AND OPTIMIZATION PERFORMED BY GENOUD               ####
###    FOR AN ORDINARY KRIGING MODEL                                  ####
### OF THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################
set.seed(10)

# Set test problem parameters
doe.size &lt;- 10
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
library(DiceDesign)
doe &lt;- as.data.frame(lhsDesign(doe.size, dim)$design)
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {y.tilde[i] &lt;- test.function(doe[i,]) 
+ sqrt(noise.var)*rnorm(n=1)}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
     covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
     lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Optimisation using max_AKG
res &lt;- max_AKG(model, new.noise.var=noise.var, type = "UK", 
lower=c(0,0), upper=c(1,1)) 
X.genoud &lt;- res$par

## Not run: 
# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
names(design.grid) &lt;- c("V1","V2")
nt &lt;- nrow(design.grid)
crit.grid &lt;- apply(design.grid, 1, AKG, model=model, new.noise.var=noise.var)

# # 2D plots
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
tit &lt;- "Green: best point found by optimizer"
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
plot.axes = {title(tit);points(model@X[,1],model@X[,2],pch=17,col="blue"); 
points(X.genoud[1],X.genoud[2],pch=17,col="green");
axis(1); axis(2)})

## End(Not run)

</code></pre>

<hr>
<h2 id='max_crit'>Maximization of the Expected Improvement criterion</h2><span id='topic+max_crit'></span>

<h3>Description</h3>

<p>For a number of <code>control$restarts</code>, generates a large number of random samples,
then picks the one with best EI value to start L-BFGS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_crit(
  model,
  type = "UK",
  lower,
  upper,
  minimization = TRUE,
  control = NULL,
  proxy = FALSE,
  trcontrol = NULL,
  n.cores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_crit_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> ,</p>
</td></tr>
<tr><td><code id="max_crit_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="max_crit_+3A_lower">lower</code>, <code id="max_crit_+3A_upper">upper</code></td>
<td>
<p>vectors of lower and upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="max_crit_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td></tr>
<tr><td><code id="max_crit_+3A_control">control</code></td>
<td>
<p>optional list of control parameters for optimization. For now only the number of <code>restarts</code> can be set.</p>
</td></tr>
<tr><td><code id="max_crit_+3A_proxy">proxy</code></td>
<td>
<p>Boolean, if TRUE, then EI maximization is replaced by the minimization of the kriging mean.</p>
</td></tr>
<tr><td><code id="max_crit_+3A_trcontrol">trcontrol</code></td>
<td>
<p>an optional list to activate the Trust-region management (see <code><a href="#topic+TREGO.nsteps">TREGO.nsteps</a></code>)</p>
</td></tr>
<tr><td><code id="max_crit_+3A_n.cores">n.cores</code></td>
<td>
<p>Number of cores if parallel computation is used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>The best set of parameters found.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of expected improvement at par.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
library(parallel)
##########################################################
### "ONE-SHOT" EI-MAXIMIZATION OF THE BRANIN FUNCTION ####
### 	KNOWN AT A 9-POINTS FACTORIAL DESIGN          ####
##########################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2 
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact) &lt;- c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact) &lt;- c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# EGO one step
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)     # domain for Branin function
oEGO &lt;- max_crit(fitted.model1, lower=lower, upper=upper)
print(oEGO)

# graphics
n.grid &lt;- 20
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, branin)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid,y.grid,z.grid,40)
title("Branin Function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par[1], oEGO$par[2], pch=19, col="red")
</code></pre>

<hr>
<h2 id='max_EI'>Maximization of the Expected Improvement criterion</h2><span id='topic+max_EI'></span>

<h3>Description</h3>

<p>Given an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> and a set of tuning
parameters (<code>lower</code>,<code>upper</code>,<code>parinit</code>, and <code>control</code>),
<code>max_EI</code> performs the maximization of the Expected Improvement
criterion and delivers the next point to be visited in an EGO-like
procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_EI(
  model,
  plugin = NULL,
  type = "UK",
  lower,
  upper,
  parinit = NULL,
  minimization = TRUE,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_EI_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> ,</p>
</td></tr>
<tr><td><code id="max_EI_+3A_plugin">plugin</code></td>
<td>
<p>optional scalar: if provided, it replaces the minimum of the
current observations,</p>
</td></tr>
<tr><td><code id="max_EI_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="max_EI_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="max_EI_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="max_EI_+3A_parinit">parinit</code></td>
<td>
<p>optional vector of initial values for the variables to be
optimized over,</p>
</td></tr>
<tr><td><code id="max_EI_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td></tr>
<tr><td><code id="max_EI_+3A_control">control</code></td>
<td>
<p>optional list of control parameters for optimization.  One
can control <code>"pop.size"</code> (default : [N=3*2^dim for dim&lt;6 and N=32*dim
otherwise]), <code>"max.generations"</code> (12), <code>"wait.generations"</code> (2)
and <code>"BFGSburnin"</code> (2) of function <code>"genoud"</code> (see
<code><a href="rgenoud.html#topic+genoud">genoud</a></code>).  Numbers into brackets are the default
values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The latter maximization relies on a genetic algorithm using derivatives,
<code><a href="rgenoud.html#topic+genoud">genoud</a></code>. This function plays a central role in the
package since it is in constant use in the proposed algorithms. It is
important to remark that the information needed about the objective
function reduces here to the vector of response values embedded in
<code>model</code> (no call to the objective function or simulator).
</p>
<p>The current minimum of the observations can be replaced by an arbitrary
value (plugin), which is usefull in particular in noisy frameworks.
</p>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>The best set of parameters found.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of expected improvement at par.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David Ginsbourger 
</p>
<p>Olivier Roustant
</p>
<p>Victor Picheny
</p>


<h3>References</h3>

<p>D. Ginsbourger (2009), <em>Multiples metamodeles pour l'approximation et
l'optimisation de fonctions numeriques multivariables</em>, Ph.D. thesis, Ecole
Nationale Superieure des Mines de Saint-Etienne, 2009.
</p>
<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>
<p>W.R. Jr. Mebane and J.S. Sekhon (2009), in press, Genetic optimization
using derivatives: The rgenoud package for R, <em>Journal of Statistical
Software</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
##########################################################
### "ONE-SHOT" EI-MAXIMIZATION OF THE BRANIN FUNCTION ####
### 	KNOWN AT A 9-POINTS FACTORIAL DESIGN          ####
##########################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2 
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact) &lt;- c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact) &lt;- c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# EGO one step
library(rgenoud)
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)     # domain for Branin function
oEGO &lt;- max_EI(fitted.model1, lower=lower, upper=upper, 
control=list(pop.size=20, BFGSburnin=2))
print(oEGO)

# graphics
n.grid &lt;- 20
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, branin)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid,y.grid,z.grid,40)
title("Branin Function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par[1], oEGO$par[2], pch=19, col="red")


#############################################################
### "ONE-SHOT" EI-MAXIMIZATION OF THE CAMELBACK FUNCTION ####
###	KNOWN AT A 16-POINTS FACTORIAL DESIGN            ####
#############################################################
## Not run: 
# a 16-points factorial design, and the corresponding response
d &lt;- 2 
n &lt;- 16
design.fact &lt;- expand.grid(seq(0,1,length=4), seq(0,1,length=4)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact) &lt;- c("x1", "x2")
response.camelback &lt;- apply(design.fact, 1, camelback)
response.camelback &lt;- data.frame(response.camelback) 
names(response.camelback) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.camelback, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# EI maximization
library(rgenoud)
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)   
oEGO &lt;- max_EI(fitted.model1, lower=lower, upper=upper, 
control=list(pop.size=20, BFGSburnin=2))
print(oEGO)

# graphics
n.grid &lt;- 20
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, camelback)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid,y.grid,z.grid,40)
title("Camelback Function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par[1], oEGO$par[2], pch=19, col="red")

## End(Not run)

####################################################################
### "ONE-SHOT" EI-MAXIMIZATION OF THE GOLDSTEIN-PRICE FUNCTION #####
### 	     KNOWN AT A 9-POINTS FACTORIAL DESIGN              #####
####################################################################

## Not run: 
# a 9-points factorial design, and the corresponding response
d &lt;- 2 
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.goldsteinPrice &lt;- apply(design.fact, 1, goldsteinPrice)
response.goldsteinPrice &lt;- data.frame(response.goldsteinPrice) 
names(response.goldsteinPrice) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.goldsteinPrice, 
covtype="gauss", control=list(pop.size=50, max.generations=50, 
wait.generations=5, BFGSburnin=10, trace=FALSE), parinit=c(0.5, 0.5), optim.method="gen")

# EI maximization
library(rgenoud)
lower &lt;- rep(0,d); upper &lt;- rep(1,d);     # domain for Branin function
oEGO &lt;- max_EI(fitted.model1, lower=lower, upper=upper, control
=list(pop.size=50, max.generations=50, wait.generations=5, BFGSburnin=10))
print(oEGO)

# graphics
n.grid &lt;- 20
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, goldsteinPrice)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid,y.grid,z.grid,40)
title("Goldstein-Price Function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par[1], oEGO$par[2], pch=19, col="red")

## End(Not run)

</code></pre>

<hr>
<h2 id='max_EQI'>Maximizer of the Expected Quantile Improvement criterion function</h2><span id='topic+max_EQI'></span>

<h3>Description</h3>

<p>Maximization, based on the package rgenoud of the Expected Quantile
Improvement (EQI) criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_EQI(
  model,
  new.noise.var = 0,
  beta = 0.9,
  q.min = NULL,
  type = "UK",
  lower,
  upper,
  parinit = NULL,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_EQI_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_new.noise.var">new.noise.var</code></td>
<td>
<p>the (scalar) noise variance of an observation. Default
value is 0 (noise-free observation).</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_beta">beta</code></td>
<td>
<p>Quantile level (default value is 0.9)</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_q.min">q.min</code></td>
<td>
<p>The current best kriging quantile. If not provided, this
quantity is evaluated inside the EQI function (may increase computational
time).</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_lower">lower</code></td>
<td>
<p>vector containing the lower bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_upper">upper</code></td>
<td>
<p>optional vector containing the upper bounds of the variables
to be optimized over</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_parinit">parinit</code></td>
<td>
<p>optional vector containing the initial values for the
variables to be optimized over</p>
</td></tr>
<tr><td><code id="max_EQI_+3A_control">control</code></td>
<td>
<p>optional list of control parameters for optimization.  One
can control <code>"pop.size"</code> (default : [N=3*2^dim for dim&lt;6 and N=32*dim
otherwise]), <code>"max.generations"</code> (12), <code>"wait.generations"</code> (2)
and <code>"BFGSburnin"</code> (2) of function <code>"genoud"</code> (see
<code><a href="rgenoud.html#topic+genoud">genoud</a></code>).  Numbers into brackets are the default
values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: </p>
<table>
<tr><td><code>par</code></td>
<td>
<p>the best set of parameters
found.</p>
</td></tr> <tr><td><code>value</code></td>
<td>
<p>the value EQI at par.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(10)

# Set test problem parameters
doe.size &lt;- 10
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {y.tilde[i] &lt;- test.function(doe[i,]) 
+ sqrt(noise.var)*rnorm(n=1)}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
     covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
     lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Optimisation using max_EQI
res &lt;- max_EQI(model, new.noise.var=noise.var, type = "UK", 
lower=c(0,0), upper=c(1,1)) 
X.genoud &lt;- res$par

## Not run: 
# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
names(design.grid) &lt;- c("V1","V2")
nt &lt;- nrow(design.grid)
crit.grid &lt;- apply(design.grid, 1, EQI, model=model, new.noise.var=noise.var, beta=.9)

# # 2D plots
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
tit &lt;- "Green: best point found by optimizer"
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = rainbow,
plot.axes = {title(tit);points(model@X[,1],model@X[,2],pch=17,col="blue"); 
points(X.genoud[1],X.genoud[2],pch=17,col="green");
axis(1); axis(2)})

## End(Not run)

</code></pre>

<hr>
<h2 id='max_qEI'>Maximization of multipoint expected improvement criterion (qEI)</h2><span id='topic+max_qEI'></span>

<h3>Description</h3>

<p>Maximization of the <code><a href="#topic+qEI">qEI</a></code> criterion. Two options are available
: Constant Liar (CL), and brute force qEI maximization with
Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm, or GENetic Optimization
Using Derivative (genoud) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>max_qEI(
  model,
  npoints,
  lower,
  upper,
  crit = "exact",
  minimization = TRUE,
  optimcontrol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="max_qEI_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> ,</p>
</td></tr>
<tr><td><code id="max_qEI_+3A_npoints">npoints</code></td>
<td>
<p>an integer representing the desired number of iterations,</p>
</td></tr>
<tr><td><code id="max_qEI_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds,</p>
</td></tr>
<tr><td><code id="max_qEI_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds,</p>
</td></tr>
<tr><td><code id="max_qEI_+3A_crit">crit</code></td>
<td>
<p>&quot;exact&quot;, &quot;CL&quot; : a string specifying the criterion used. &quot;exact&quot;
triggers the maximization of the multipoint expected improvement at each
iteration (see <code><a href="#topic+max_qEI">max_qEI</a></code>), &quot;CL&quot; applies the Constant Liar
heuristic,</p>
</td></tr>
<tr><td><code id="max_qEI_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if the qEI to be maximized is used
in minimiziation or in maximization,</p>
</td></tr>
<tr><td><code id="max_qEI_+3A_optimcontrol">optimcontrol</code></td>
<td>
<p>an optional list of control parameters for
optimization. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>- CL is a heuristic method. First, the regular Expected Improvement EI is
maximized (<code><a href="#topic+max_EI">max_EI</a></code>). Then, for the next points, the Expected
Improvement is maximized again, but with an artificially updated Kriging
model. Since the response values corresponding to the last best point
obtained are not available, the idea of CL is to replace them by an
arbitrary constant value L (a &quot;lie&quot;) set by the user (default is the
minimum of all currently available observations).
</p>
<p>- The BFGS algorithm is implemented in the standard function
<code><a href="stats.html#topic+optim">optim</a></code>. Analytical formulae of <code><a href="#topic+qEI">qEI</a></code> and its
gradient <code><a href="#topic+qEI.grad">qEI.grad</a></code> are used. The <code>nStarts</code> starting
points are by default sampled with respect to the regular EI
(<code><a href="#topic+sampleFromEI">sampleFromEI</a></code>) criterion.
</p>
<p>- The &quot;genoud&quot; method calls the function <code><a href="rgenoud.html#topic+genoud">genoud</a></code> using
analytical formulae of <code><a href="#topic+qEI">qEI</a></code> and its gradient
<code><a href="#topic+qEI.grad">qEI.grad</a></code>.
</p>
<p>The parameters of list <code>optimcontrol</code> are :
</p>
<p>- <code>optimcontrol$method</code> : &quot;BFGS&quot; (default), &quot;genoud&quot; ; a string
specifying the method used to maximize the criterion (irrelevant when
<code>crit</code> is &quot;CL&quot; because this method always uses genoud),
</p>
<p>- when <code>crit="CL"</code> :
</p>
<p>+ <code>optimcontrol$parinit</code> : optional matrix of initial values (must
have model@d columns, the number of rows is not constrained),
</p>
<p>+ <code>optimcontrol$L</code> : &quot;max&quot;, &quot;min&quot;, &quot;mean&quot; or a scalar value specifying
the liar ; &quot;min&quot; takes <code>model@min</code>, &quot;max&quot; takes <code>model@max</code>,
&quot;mean&quot; takes the prediction of the model ; When L is <code>NULL</code>, &quot;min&quot; is
taken if <code>minimization==TRUE</code>, else it is &quot;max&quot;.
</p>
<p>+ The parameters of function <code><a href="rgenoud.html#topic+genoud">genoud</a></code>. Main parameters are :
<code>"pop.size"</code> (default : [N=3*2^model@d for dim&lt;6 and N=32*model@d
otherwise]), <code>"max.generations"</code> (default : 12),
<code>"wait.generations"</code> (default : 2) and <code>"BFGSburnin"</code> (default :
2).
</p>
<p>- when <code>optimcontrol$method = "BFGS"</code> :
</p>
<p>+ <code>optimcontrol$nStarts</code> (default : 4),
</p>
<p>+ <code>optimcontrol$fastCompute</code> : if TRUE (default), a fast approximation
method based on a semi-analytic formula is used, see [Marmin 2014] for
details,
</p>
<p>+ <code>optimcontrol$samplingFun</code> : a function which sample a batch of
starting point (default : <code><a href="#topic+sampleFromEI">sampleFromEI</a></code>),
</p>
<p>+ <code>optimcontrol$parinit</code> : optional 3d-array of initial (or candidate)
batches (for all <code>k</code>, parinit[,,k] is a matrix of size
<code>npoints*model@d</code> representing one batch). The number of initial
batches (length(parinit[1,1,])) is not contrained and does not have to be
equal to <code>nStarts</code>. If there is too few initial batches for
<code>nStarts</code>, missing batches are drawn with <code>samplingFun</code> (default
: <code>NULL</code>),
</p>
<p>- when <code>optimcontrol$method = "genoud"</code> :
</p>
<p>+ <code>optimcontrol$fastCompute</code> : if TRUE (default), a fast approximation
method based on a semi-analytic formula is used, see [Marmin 2014] for
details,
</p>
<p>+ <code>optimcontrol$parinit</code> : optional matrix of candidate starting
points (one row corresponds to one point),
</p>
<p>+ The parameters of the <code><a href="rgenoud.html#topic+genoud">genoud</a></code> function. Main parameters are
<code>"pop.size"</code> (default : <code>[50*(model@d)*(npoints)]</code>),
<code>"max.generations"</code> (default : 5), <code>"wait.generations"</code> (default
: 2), <code>"BFGSburnin"</code> (default : 2).
</p>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>A matrix containing the <code>npoints</code> input vectors found.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>A value giving the qEI computed in <code>par</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastien Marmin 
</p>
<p>Clement Chevalier 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>C. Chevalier and D. Ginsbourger (2014) Learning and Intelligent
Optimization - 7th International Conference, Lion 7, Catania, Italy,
January 7-11, 2013, Revised Selected Papers, chapter Fast computation of
the multipoint Expected Improvement with applications in batch selection,
pages 59-69, Springer.
</p>
<p>D. Ginsbourger, R. Le Riche, L. Carraro (2007), A Multipoint Criterion for
Deterministic Parallel Global Optimization based on Kriging. The
International Conference on Non Convex Programming, 2007.
</p>
<p>D. Ginsbourger, R. Le Riche, and L. Carraro. Kriging is well-suited to
parallelize optimization (2010), In Lim Meng Hiot, Yew Soon Ong, Yoel
Tenne, and Chi-Keong Goh, editors, <em>Computational Intelligence in
Expensive Optimization Problems</em>, Adaptation Learning and Optimization,
pages 131-162. Springer Berlin Heidelberg.
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qEI">qEI</a></code>, <code><a href="#topic+qEI.grad">qEI.grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


set.seed(000)
# 3-points EI maximization.
# 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 
lower &lt;- c(0,0)
upper &lt;- c(1,1)

# number of point in the bacth
batchSize &lt;- 3

# model identification
fitted.model &lt;- km(~1, design=design.fact, response=response.branin, 
                   covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# maximization of qEI

# With a multistarted BFGS algorithm
maxBFGS &lt;- max_qEI(model = fitted.model, npoints = batchSize, lower = lower, upper = upper, 
crit = "exact",optimcontrol=list(nStarts=3,method = "BFGS"))

# comparison
print(maxBFGS$value)
## Not run: 
# With a genetic algorithme using derivatives
maxGen  &lt;- max_qEI(model = fitted.model, npoints = batchSize, lower = lower, upper = upper, 
crit = "exact", optimcontrol=list(nStarts=3,method = "genoud",pop.size=100,max.generations = 15))
# With the constant liar heuristic
maxCL   &lt;- max_qEI(model = fitted.model, npoints = batchSize, lower = lower, upper = upper, 
crit = "CL",optimcontrol=list(pop.size=20))
print(maxGen$value)
print(maxCL$value)

## End(Not run)


</code></pre>

<hr>
<h2 id='min_quantile'>Minimization of the Kriging quantile.</h2><span id='topic+min_quantile'></span>

<h3>Description</h3>

<p>Minimization, based on the package rgenoud of the kriging quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>min_quantile(
  model,
  beta = 0.1,
  type = "UK",
  lower,
  upper,
  parinit = NULL,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="min_quantile_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="min_quantile_+3A_beta">beta</code></td>
<td>
<p>Quantile level (default value is 0.1)</p>
</td></tr>
<tr><td><code id="min_quantile_+3A_type">type</code></td>
<td>
<p>Kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="min_quantile_+3A_lower">lower</code></td>
<td>
<p>vector containing the lower bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="min_quantile_+3A_upper">upper</code></td>
<td>
<p>vector containing the upper bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="min_quantile_+3A_parinit">parinit</code></td>
<td>
<p>optional vector containing the initial values for the
variables to be optimized over</p>
</td></tr>
<tr><td><code id="min_quantile_+3A_control">control</code></td>
<td>
<p>optional list of control parameters for optimization.  One
can control <code>"pop.size"</code> (default : [N=3*2^dim for dim&lt;6 and N=32*dim
otherwise]), <code>"max.generations"</code> (12), <code>"wait.generations"</code> (2)
and <code>"BFGSburnin"</code> (2) of function <code>"genoud"</code> (see
<code><a href="rgenoud.html#topic+genoud">genoud</a></code>).  Numbers into brackets are the default
values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: </p>
<table>
<tr><td><code>par</code></td>
<td>
<p>the best set of parameters
found.</p>
</td></tr> <tr><td><code>value</code></td>
<td>
<p>the value of the krigign quantile at par.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

##########################################################################
###    KRIGING QUANTILE SURFACE AND OPTIMIZATION PERFORMED BY GENOUD  ####
###    FOR AN ORDINARY KRIGING MODEL                                  ####
### OF THE BRANIN FUNCTION KNOWN AT A 12-POINT LATIN HYPERCUBE DESIGN ####
##########################################################################
set.seed(10)

# Set test problem parameters
doe.size &lt;- 10
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.2

# Generate DOE and response
doe &lt;- as.data.frame(matrix(runif(doe.size*dim),doe.size))
y.tilde &lt;- rep(0, 1, doe.size)
for (i in 1:doe.size)  {y.tilde[i] &lt;- test.function(doe[i,]) 
+ sqrt(noise.var)*rnorm(n=1)}
y.tilde &lt;- as.numeric(y.tilde)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
     covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
     lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Optimisation using max_kriging.quantile
res &lt;- min_quantile(model, beta=0.1, type = "UK", lower=c(0,0), upper=c(1,1)) 
X.genoud &lt;- res$par

# Compute actual function and criterion on a grid
n.grid &lt;- 12 # Change to 21 for a nicer picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
names(design.grid) &lt;- c("V1","V2")
nt &lt;- nrow(design.grid)
crit.grid &lt;- apply(design.grid, 1, kriging.quantile, model=model, beta=.1)

# # 2D plots
z.grid &lt;- matrix(crit.grid, n.grid, n.grid)
tit &lt;- "Green: best point found by optimizer"
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
plot.axes = {title(tit);points(model@X[,1],model@X[,2],pch=17,col="blue"); 
points(X.genoud[1],X.genoud[2],pch=17,col="green");
axis(1); axis(2)})

</code></pre>

<hr>
<h2 id='noisy.optimizer'>Optimization of homogenously noisy functions based on Kriging</h2><span id='topic+noisy.optimizer'></span>

<h3>Description</h3>

<p>Sequential optimization of kriging-based criterion conditional on noisy
observations, with model update after each evaluation.  Eight criteria are
proposed to choose the next observation: random search, sequential
parameter optimization (SPO), reinterpolation, Expected Improvement (EI)
with plugin, Expected Quantile Improvement (EQI), quantile minimization,
Augmented Expected Improvement (AEI) and Approximate Knowledge Gradient
(AKG). The criterion optimization is based on the package rgenoud.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>noisy.optimizer(
  optim.crit,
  optim.param = NULL,
  model,
  n.ite,
  noise.var = NULL,
  funnoise,
  lower,
  upper,
  parinit = NULL,
  control = NULL,
  CovReEstimate = TRUE,
  NoiseReEstimate = FALSE,
  nugget.LB = 1e-05,
  estim.model = NULL,
  type = "UK"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="noisy.optimizer_+3A_optim.crit">optim.crit</code></td>
<td>
<p>String defining the criterion to be optimized at each
iteration. Possible values are: &quot;random.search&quot;, &quot;SPO&quot;, &quot;reinterpolation&quot;,
&quot;EI.plugin&quot;, &quot;EQI&quot;, &quot;min.quantile&quot;, &quot;AEI&quot;, &quot;AKG&quot;.</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_optim.param">optim.param</code></td>
<td>
<p>List of parameters for the chosen criterion.  For
&quot;EI.plugin&quot;: optim.param$plugin.type is a string defining which plugin is
to be used. Possible values are &quot;ytilde&quot;, &quot;quantile&quot; and &quot;other&quot;.  If
&quot;quantile&quot; is chosen, optim.param$quantile defines the quantile level.  If
&quot;other&quot; is chosen, optim.param$plugin directly sets the plugin value.
</p>
<p>For &quot;EQI&quot;: optim.param$quantile defines the quantile level. If not
provided, default value is 0.9.
</p>
<p>For &quot;min.quantile&quot;: optim.param$quantile defines the quantile level. If not
provided, default value is 0.1.
</p>
<p>For &quot;AEI&quot;: optim.param$quantile defines the quantile level to choose the
current best point. If not provided, default value is 0.75.</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_n.ite">n.ite</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_noise.var">noise.var</code></td>
<td>
<p>Noise variance (scalar). If noiseReEstimate=TRUE, it is an
initial guess for the unknown variance (used in optimization).</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_funnoise">funnoise</code></td>
<td>
<p>objective (noisy) function</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_lower">lower</code></td>
<td>
<p>vector containing the lower bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_upper">upper</code></td>
<td>
<p>vector containing the upper bounds of the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_parinit">parinit</code></td>
<td>
<p>optional vector of initial values for the variables to be
optimized over</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_control">control</code></td>
<td>
<p>optional list of control parameters for optimization.  One
can control <code>"pop.size"</code> (default : [N=3*2^dim for dim&lt;6 and N=32*dim
otherwise]]), <code>"max.generations"</code> (N), <code>"wait.generations"</code> (2)
and <code>"BFGSburnin"</code> (0) of function <code>"genoud"</code> (see
<code><a href="rgenoud.html#topic+genoud">genoud</a></code>).  Numbers into brackets are the default
values</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_covreestimate">CovReEstimate</code></td>
<td>
<p>optional boolean specfiying if the covariance
parameters should be re-estimated at every iteration (default value = TRUE)</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_noisereestimate">NoiseReEstimate</code></td>
<td>
<p>optional boolean specfiying if the noise variance
should be re-estimated at every iteration (default value = FALSE)</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_nugget.lb">nugget.LB</code></td>
<td>
<p>optional scalar of minimal value for the estimated noise
variance. Default value is 1e-5.</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_estim.model">estim.model</code></td>
<td>
<p>optional kriging model of &quot;km&quot; class with homogeneous
nugget effect (no noise.var). Required if noise variance is reestimated and
the initial &quot;model&quot; has heterogenenous noise variances.</p>
</td></tr>
<tr><td><code id="noisy.optimizer_+3A_type">type</code></td>
<td>
<p>&quot;SK&quot; or &quot;UK&quot; for Kriging with known or estimated trend</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: </p>
<table>
<tr><td><code>model</code></td>
<td>
<p>the current (last) kriging
model of &quot;km&quot; class</p>
</td></tr> <tr><td><code>best.x</code></td>
<td>
<p> The best design found</p>
</td></tr>
<tr><td><code>best.y</code></td>
<td>
<p>The objective function value at best.x</p>
</td></tr> <tr><td><code>best.index</code></td>
<td>
<p>The
index of best.x in the design of experiments</p>
</td></tr>
<tr><td><code>history.x</code></td>
<td>
<p> The added observations</p>
</td></tr> <tr><td><code>history.y</code></td>
<td>
<p>The added
observation values</p>
</td></tr> <tr><td><code>history.hyperparam</code></td>
<td>
<p>The history of the kriging
parameters</p>
</td></tr>
<tr><td><code>estim.model</code></td>
<td>
<p>If noiseReEstimate=TRUE, the current (last) kriging
model of &quot;km&quot; class for estimating the noise variance.</p>
</td></tr>
<tr><td><code>history.noise.var</code></td>
<td>
<p>If noiseReEstimate=TRUE, the history of the noise
variance estimate.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny
</p>


<h3>References</h3>

<p>V. Picheny and D. Ginsbourger (2013), Noisy kriging-based optimization
methods: A unified implementation within the DiceOptim package,
<em>Computational Statistics &amp; Data Analysis</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##########################################################################
### EXAMPLE 1: 3 OPTIMIZATION STEPS USING EQI WITH KNOWN NOISE         ###
### AND KNOWN COVARIANCE PARAMETERS FOR THE BRANIN FUNCTION            ###
##########################################################################

set.seed(10)
library(DiceDesign)
# Set test problem parameters
doe.size &lt;- 9
dim &lt;- 2
test.function &lt;- get("branin2")
lower &lt;- rep(0,1,dim)
upper &lt;- rep(1,1,dim)
noise.var &lt;- 0.1

# Build noisy simulator
funnoise &lt;- function(x)
{     f.new &lt;- test.function(x) + sqrt(noise.var)*rnorm(n=1)
      return(f.new)}

# Generate DOE and response
doe &lt;- as.data.frame(lhsDesign(doe.size, dim)$design)
y.tilde &lt;- funnoise(doe)

# Create kriging model
model &lt;- km(y~1, design=doe, response=data.frame(y=y.tilde),
     covtype="gauss", noise.var=rep(noise.var,1,doe.size), 
     lower=rep(.1,dim), upper=rep(1,dim), control=list(trace=FALSE))

# Optimisation with noisy.optimizer (n.ite can be increased)
n.ite &lt;- 2 
optim.param &lt;- list()
optim.param$quantile &lt;- .9
optim.result &lt;- noisy.optimizer(optim.crit="EQI", optim.param=optim.param, model=model,
		n.ite=n.ite, noise.var=noise.var, funnoise=funnoise, lower=lower, upper=upper,
		NoiseReEstimate=FALSE, CovReEstimate=FALSE)

new.model &lt;- optim.result$model
best.x    &lt;- optim.result$best.x
new.doe   &lt;- optim.result$history.x

## Not run: 
##### DRAW RESULTS #####
# Compute actual function on a grid
n.grid &lt;- 12
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
names(design.grid) &lt;- c("V1","V2")
nt &lt;- nrow(design.grid)
func.grid &lt;- rep(0,1,nt)

for (i in 1:nt)
{ func.grid[i] &lt;- test.function(x=design.grid[i,])}

# Compute initial and final kriging on a grid
pred &lt;- predict(object=model, newdata=design.grid, type="UK", checkNames = FALSE)
mk.grid1 &lt;- pred$m
sk.grid1 &lt;- pred$sd

pred &lt;- predict(object=new.model, newdata=design.grid, type="UK", checkNames = FALSE)
mk.grid2 &lt;- pred$m
sk.grid2 &lt;- pred$sd

# Plot initial kriging mean
z.grid &lt;- matrix(mk.grid1, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
plot.axes = {title("Initial kriging mean");
points(model@X[,1],model@X[,2],pch=17,col="black"); 
axis(1); axis(2)})

# Plot initial kriging variance
z.grid &lt;- matrix(sk.grid1^2, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
plot.axes = {title("Initial kriging variance");
points(model@X[,1],model@X[,2],pch=17,col="black"); 
axis(1); axis(2)})

# Plot final kriging mean
z.grid &lt;- matrix(mk.grid2, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
plot.axes = {title("Final kriging mean");
points(new.model@X[,1],new.model@X[,2],pch=17,col="black"); 
axis(1); axis(2)})

# Plot final kriging variance
z.grid &lt;- matrix(sk.grid2^2, n.grid, n.grid)
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
plot.axes = {title("Final kriging variance");
points(new.model@X[,1],new.model@X[,2],pch=17,col="black"); 
axis(1); axis(2)})

# Plot actual function and observations
z.grid &lt;- matrix(func.grid, n.grid, n.grid)
tit &lt;- "Actual function - Black: initial points; red: added points"
filled.contour(x.grid,y.grid, z.grid, nlevels=50, color = topo.colors,
plot.axes = {title(tit);points(model@X[,1],model@X[,2],pch=17,col="black"); 
points(new.doe[1,],new.doe[2,],pch=15,col="red");
axis(1); axis(2)})

## End(Not run)

##########################################################################
### EXAMPLE 2: 3 OPTIMIZATION STEPS USING EQI WITH UNKNOWN NOISE       ###
### AND UNKNOWN COVARIANCE PARAMETERS FOR THE BRANIN FUNCTION          ###
##########################################################################
# Same initial model and parameters as for example 1
n.ite &lt;- 2 # May be changed to a larger value 
res &lt;- noisy.optimizer(optim.crit="min.quantile", 
optim.param=list(type="quantile",quantile=0.01),
model=model, n.ite=n.ite, noise.var=noise.var, funnoise=funnoise, 
lower=lower, upper=upper, 
control=list(print.level=0),CovReEstimate=TRUE, NoiseReEstimate=TRUE)

# Plot actual function and observations
plot(model@X[,1], model@X[,2], pch=17,xlim=c(0,1),ylim=c(0,1))
points(res$history.x[1,], res$history.x[2,], col="blue")

# Restart: requires the output estim.model of the previous run
# to deal with potential repetitions
res2 &lt;- noisy.optimizer(optim.crit="min.quantile", 
optim.param=list(type="quantile",quantile=0.01), 
model=res$model, n.ite=n.ite, noise.var=noise.var, funnoise=funnoise, 
lower=lower, upper=upper, estim.model=res$estim.model,
control=list(print.level=0),CovReEstimate=TRUE, NoiseReEstimate=TRUE)

# Plot new observations
points(res2$history.x[1,], res2$history.x[2,], col="red")


</code></pre>

<hr>
<h2 id='ParrConstraint'>2D constraint function</h2><span id='topic+ParrConstraint'></span>

<h3>Description</h3>

<p>Strongly multimdoal constraint function from Parr et al. (standardized version)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParrConstraint(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ParrConstraint_+3A_x">x</code></td>
<td>
<p>a 2-dimensional vector or a two-column matrix specifying the location(s) where the function
is to be evaluated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scalar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n.grid &lt;- 20
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, ParrConstraint)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid,y.grid,z.grid,40)
title("Parr constraint function")

</code></pre>

<hr>
<h2 id='qEGO.nsteps'>Sequential multipoint Expected improvement (qEI) maximizations and model
re-estimation</h2><span id='topic+qEGO.nsteps'></span>

<h3>Description</h3>

<p>Executes <code>nsteps</code> iterations of the multipoint EGO method to an object
of class <code><a href="DiceKriging.html#topic+km">km</a></code>.  At each step, a kriging model
(including covariance parameters) is re-estimated based on the initial
design points plus the points visited during all previous iterations; then
a new batch of points is obtained by maximizing the multipoint Expected
Improvement criterion (<code><a href="#topic+qEI">qEI</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qEGO.nsteps(
  fun,
  model,
  npoints,
  nsteps,
  lower = rep(0, model@d),
  upper = rep(1, model@d),
  crit = "exact",
  minimization = TRUE,
  optimcontrol = NULL,
  cov.reestim = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qEGO.nsteps_+3A_fun">fun</code></td>
<td>
<p>the objective function to be optimized,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code> ,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_npoints">npoints</code></td>
<td>
<p>an integer repesenting the desired batchsize,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_nsteps">nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_crit">crit</code></td>
<td>
<p>&quot;exact&quot;, &quot;CL&quot; : a string specifying the criterion used. &quot;exact&quot;
triggers the maximization of the multipoint expected improvement at each
iteration (see <code><a href="#topic+max_qEI">max_qEI</a></code>), &quot;CL&quot; applies the Constant Liar
heuristic,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if we want to minimize or maximize
<code>fun</code>,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_optimcontrol">optimcontrol</code></td>
<td>
<p>an optional list of control parameters for the qEI
optimization (see details or <code><a href="#topic+max_qEI">max_qEI</a></code>),</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_cov.reestim">cov.reestim</code></td>
<td>
<p>optional boolean specifying if the kriging
hyperparameters should be re-estimated at each iteration,</p>
</td></tr>
<tr><td><code id="qEGO.nsteps_+3A_...">...</code></td>
<td>
<p>optional arguments for <code>fun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters of list <code>optimcontrol</code> are :
</p>
<p>- <code>optimcontrol$method</code> : &quot;BFGS&quot; (default), &quot;genoud&quot; ; a string
specifying the method used to maximize the criterion (irrelevant when
<code>crit</code> is &quot;CL&quot; because this method always uses genoud),
</p>
<p>- when <code>crit="CL"</code> :
</p>
<p>+ <code>optimcontrol$parinit</code> : optional matrix of initial values (must
have model@d columns, the number of rows is not constrained),
</p>
<p>+ <code>optimcontrol$L</code> : &quot;max&quot;, &quot;min&quot;, &quot;mean&quot; or a scalar value specifying
the liar ; &quot;min&quot; takes <code>model@min</code>, &quot;max&quot; takes <code>model@max</code>,
&quot;mean&quot; takes the prediction of the model ; When L is <code>NULL</code>, &quot;min&quot; is
taken if <code>minimization==TRUE</code>, else it is &quot;max&quot;.
</p>
<p>+ The parameters of function <code><a href="rgenoud.html#topic+genoud">genoud</a></code>. Main parameters are :
<code>"pop.size"</code> (default : [N=3*2^model@d for dim&lt;6 and N=32*model@d
otherwise]), <code>"max.generations"</code> (default : 12),
<code>"wait.generations"</code> (default : 2) and <code>"BFGSburnin"</code> (default :
2).
</p>
<p>- when <code>optimcontrol$method = "BFGS"</code> :
</p>
<p>+ <code>optimcontrol$nStarts</code> (default : 4),
</p>
<p>+ <code>optimcontrol$fastCompute</code> : if TRUE (default), a fast approximation
method based on a semi-analytic formula is used, see [Marmin 2014] for
details,
</p>
<p>+ <code>optimcontrol$samplingFun</code> : a function which sample a batch of
starting point (default : <code><a href="#topic+sampleFromEI">sampleFromEI</a></code>),
</p>
<p>+ <code>optimcontrol$parinit</code> : optional 3d-array of initial (or candidate)
batches (for all <code>k</code>, parinit[,,k] is a matrix of size
<code>npoints*model@d</code> representing one batch). The number of initial
batches (length(parinit[1,1,])) is not contrained and does not have to be
equal to <code>nStarts</code>. If there is too few initial batches for
<code>nStarts</code>, missing batches are drawn with <code>samplingFun</code> (default
: <code>NULL</code>),
</p>
<p>- when <code>optimcontrol$method = "genoud"</code> :
</p>
<p>+ <code>optimcontrol$fastCompute</code> : if TRUE (default), a fast approximation
method based on a semi-analytic formula is used, see [Marmin 2014] for
details,
</p>
<p>+ <code>optimcontrol$parinit</code> : optional matrix of candidate starting
points (one row corresponds to one point),
</p>
<p>+ The parameters of the <code><a href="rgenoud.html#topic+genoud">genoud</a></code> function. Main parameters are
<code>"pop.size"</code> (default : <code>[50*(model@d)*(npoints)]</code>),
<code>"max.generations"</code> (default : 5), <code>"wait.generations"</code> (default
: 2), <code>"BFGSburnin"</code> (default : 2).
</p>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>a data frame representing the additional points visited during
the algorithm,</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>a data frame representing the response values at the points
given in <code>par</code>,</p>
</td></tr>
<tr><td><code>npoints</code></td>
<td>
<p>an integer representing the number of parallel
computations,</p>
</td></tr>
<tr><td><code>nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations
(given in argument),</p>
</td></tr>
<tr><td><code>lastmodel</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>
corresponding to the last kriging model fitted,</p>
</td></tr>
<tr><td><code>history</code></td>
<td>
<p>a vector of size <code>nsteps</code> representing the current
known optimum at each step.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sebastien Marmin 
</p>
<p>Clement Chevalier 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>C. Chevalier and D. Ginsbourger (2014) Learning and Intelligent
Optimization - 7th International Conference, Lion 7, Catania, Italy,
January 7-11, 2013, Revised Selected Papers, chapter Fast computation of
the multipoint Expected Improvement with applications in batch selection,
pages 59-69, Springer.
</p>
<p>D. Ginsbourger, R. Le Riche, L. Carraro (2007), A Multipoint Criterion for
Deterministic Parallel Global Optimization based on Kriging. The
International Conference on Non Convex Programming, 2007.
</p>
<p>D. Ginsbourger, R. Le Riche, and L. Carraro. Kriging is well-suited to
parallelize optimization (2010), In Lim Meng Hiot, Yew Soon Ong, Yoel
Tenne, and Chi-Keong Goh, editors, <em>Computational Intelligence in
Expensive Optimization Problems</em>, Adaptation Learning and Optimization,
pages 131-162. Springer Berlin Heidelberg.
</p>
<p>S. Marmin. Developpements pour l'evaluation et la maximisation du critere
d'amelioration esperee multipoint en optimisation globale (2014). Master's
thesis, Mines Saint-Etienne (France) and University of Bern (Switzerland).
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qEI">qEI</a></code>, <code><a href="#topic+max_qEI">max_qEI</a></code>, <code><a href="#topic+qEI.grad">qEI.grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(123)
#####################################################
### 2 ITERATIONS OF EGO ON THE BRANIN FUNCTION,   ###
### STARTING FROM A 9-POINTS FACTORIAL DESIGN     ###
#####################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# EGO n steps
library(rgenoud)
nsteps &lt;- 2 # increase to 10 for a more meaningful example
lower &lt;- rep(0,d) 
upper &lt;- rep(1,d)
npoints &lt;- 3 # The batchsize
oEGO &lt;- qEGO.nsteps(model = fitted.model1, branin, npoints = npoints, nsteps = nsteps,
crit="exact", lower, upper, optimcontrol = NULL)
print(oEGO$par)
print(oEGO$value)
plot(c(1:nsteps),oEGO$history,xlab='step',ylab='Current known minimum')

## Not run: 
# graphics
n.grid &lt;- 15 # increase to 21 for better picture
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, branin)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid, y.grid, z.grid, 40)
title("Branin function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par, pch=19, col="red")
text(oEGO$par[,1], oEGO$par[,2], labels=c(tcrossprod(rep(1,npoints),1:nsteps)), pos=3)

## End(Not run)

</code></pre>

<hr>
<h2 id='qEI'>Analytical expression of the multipoint expected improvement (qEI)
criterion</h2><span id='topic+qEI'></span>

<h3>Description</h3>

<p>Computes the multipoint expected improvement criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qEI(
  x,
  model,
  plugin = NULL,
  type = "UK",
  minimization = TRUE,
  fastCompute = TRUE,
  eps = 10^(-5),
  envir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qEI_+3A_x">x</code></td>
<td>
<p>a matrix representing the set of input points (one row corresponds
to one point) where to evaluate the qEI criterion,</p>
</td></tr>
<tr><td><code id="qEI_+3A_model">model</code></td>
<td>
<p>an object of class <code>km</code>,</p>
</td></tr>
<tr><td><code id="qEI_+3A_plugin">plugin</code></td>
<td>
<p>optional scalar: if provided, it replaces the minimum of the
current observations,</p>
</td></tr>
<tr><td><code id="qEI_+3A_type">type</code></td>
<td>
<p>&quot;SK&quot; or &quot;UK&quot; (by default), depending whether uncertainty
related to trend estimation has to be taken into account,</p>
</td></tr>
<tr><td><code id="qEI_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td></tr>
<tr><td><code id="qEI_+3A_fastcompute">fastCompute</code></td>
<td>
<p>if TRUE, a fast approximation method based on a
semi-analytic formula is used (see [Marmin 2014] for details),</p>
</td></tr>
<tr><td><code id="qEI_+3A_eps">eps</code></td>
<td>
<p>the value of <em>epsilon</em> of the fast computation trick.
Relevant only if <code>fastComputation</code> is TRUE,</p>
</td></tr>
<tr><td><code id="qEI_+3A_envir">envir</code></td>
<td>
<p>an optional environment specifying where to get intermediate
values calculated in <code><a href="#topic+qEI">qEI</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The multipoint Expected Improvement, defined as </p>
<p style="text-align: center;"><code class="reqn">qEI(X_{new})
:= E[ ( min(Y(X)) - min(Y( X_{new} )) )_{+} | Y(X)=y(X)],</code>
</p>

<p>where <code class="reqn">X</code> is the current design of experiments, <code class="reqn"> X_{new} </code> is a
new candidate design, and <code class="reqn">Y</code> is a random process assumed to have
generated the objective function <code class="reqn">y</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastien Marmin 
</p>
<p>Clement Chevalier 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>C. Chevalier and D. Ginsbourger (2014) Learning and Intelligent
Optimization - 7th International Conference, Lion 7, Catania, Italy,
January 7-11, 2013, Revised Selected Papers, chapter Fast computation of
the multipoint Expected Improvement with applications in batch selection,
pages 59-69, Springer.
</p>
<p>D. Ginsbourger, R. Le Riche, L. Carraro (2007), A Multipoint Criterion for
Deterministic Parallel Global Optimization based on Kriging. The
International Conference on Non Convex Programming, 2007.
</p>
<p>S. Marmin. Developpements pour l'evaluation et la maximisation du critere
d'amelioration esperee multipoint en optimisation globale (2014). Master's
thesis, Mines Saint-Etienne (France) and University of Bern (Switzerland).
</p>
<p>D. Ginsbourger, R. Le Riche, and L. Carraro. Kriging is well-suited to
parallelize optimization (2010), 
In Lim Meng Hiot, Yew Soon Ong, Yoel
Tenne, and Chi-Keong Goh, editors, <em>Computational Intelligence in
Expensive Optimization Problems</em>, Adaptation Learning and Optimization,
pages 131-162. Springer Berlin Heidelberg.
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(007)

# Monte-Carlo validation

# a 4-d, 81-points grid design, and the corresponding response
d &lt;- 4; n &lt;- 3^d
design &lt;- do.call(expand.grid,rep(list(seq(0,1,length=3)),d))
names(design) &lt;- paste("x",1:d,sep="")
y &lt;- data.frame(apply(design, 1, hartman4))
names(y) &lt;- "y"

# learning
model &lt;- km(~1, design=design, response=y, control=list(trace=FALSE))

# pick up 10 points sampled from the 1-point expected improvement
q &lt;- 10
X &lt;- sampleFromEI(model,n=q)
# simulation of the minimum of the kriging random vector at X
t1 &lt;- proc.time()
newdata &lt;- as.data.frame(X)
colnames(newdata) &lt;- colnames(model@X)

krig  &lt;- predict(object=model, newdata=newdata,type="UK",se.compute=TRUE, cov.compute=TRUE)
mk &lt;- krig$mean
Sigma.q &lt;- krig$cov
mychol &lt;- chol(Sigma.q)
nsim &lt;- 300000
white.noise &lt;- rnorm(n=nsim*q)
minYsim &lt;- apply(crossprod(mychol,matrix(white.noise,nrow=q)) + mk,2,min)
# simulation of the improvement (minimization)
qImprovement &lt;- (min(model@y)-minYsim)*((min(model@y)-minYsim) &gt; 0)

# empirical expectation of the improvement and confident interval (95%)
eiMC &lt;- mean(qImprovement)
confInterv &lt;- c(eiMC - 1.96*sd(qImprovement)*1/sqrt(nsim),eiMC + 1.96*sd(qImprovement)*1/sqrt(nsim))

# MC estimation of the qEI
print(eiMC) 
t2 &lt;- proc.time()
# qEI with analytical formula
qEI(X,model,fastCompute= FALSE)
t3 &lt;- proc.time()
# qEI with fast computation trick
qEI(X,model)
t4 &lt;- proc.time()
t2-t1  # Time of MC computation
t3-t2  # Time of normal computation
t4-t3  # Time of fast computation


</code></pre>

<hr>
<h2 id='qEI.grad'>Gradient of the multipoint expected improvement (qEI) criterion</h2><span id='topic+qEI.grad'></span>

<h3>Description</h3>

<p>Computes an exact or approximate gradient of the multipoint expected
improvement criterion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qEI.grad(
  x,
  model,
  plugin = NULL,
  type = "UK",
  minimization = TRUE,
  fastCompute = TRUE,
  eps = 10^(-6),
  envir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qEI.grad_+3A_x">x</code></td>
<td>
<p>a matrix representing the set of input points (one row corresponds
to one point) where to evaluate the gradient,</p>
</td></tr>
<tr><td><code id="qEI.grad_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>,</p>
</td></tr>
<tr><td><code id="qEI.grad_+3A_plugin">plugin</code></td>
<td>
<p>optional scalar: if provided, it replaces the minimum of the
current observations,</p>
</td></tr>
<tr><td><code id="qEI.grad_+3A_type">type</code></td>
<td>
<p>&quot;SK&quot; or &quot;UK&quot; (by default), depending whether uncertainty
related to trend estimation has to be taken into account,</p>
</td></tr>
<tr><td><code id="qEI.grad_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td></tr>
<tr><td><code id="qEI.grad_+3A_fastcompute">fastCompute</code></td>
<td>
<p>if TRUE, a fast approximation method based on a
semi-analytic formula is used (see [Marmin 2014] for details),</p>
</td></tr>
<tr><td><code id="qEI.grad_+3A_eps">eps</code></td>
<td>
<p>the value of <em>epsilon</em> of the fast computation trick.
Relevant only if <code>fastComputation</code> is TRUE,</p>
</td></tr>
<tr><td><code id="qEI.grad_+3A_envir">envir</code></td>
<td>
<p>an optional environment specifying where to get intermediate
values calculated in <code><a href="#topic+qEI">qEI</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The gradient of the multipoint expected improvement criterion with
respect to x. A 0-matrix is returned if the batch of input points contains
twice the same point or a point from the design experiment of the km object
(the gradient does not exist in these cases).
</p>


<h3>Author(s)</h3>

<p>Sebastien Marmin 
</p>
<p>Clement Chevalier 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>C. Chevalier and D. Ginsbourger (2014) Learning and Intelligent
Optimization - 7th International Conference, Lion 7, Catania, Italy,
January 7-11, 2013, Revised Selected Papers, chapter Fast computation of
the multipoint Expected Improvement with applications in batch selection,
pages 59-69, Springer.
</p>
<p>D. Ginsbourger, R. Le Riche, L. Carraro (2007), A Multipoint Criterion for
Deterministic Parallel Global Optimization based on Kriging. The
International Conference on Non Convex Programming, 2007.
</p>
<p>D. Ginsbourger, R. Le Riche, and L. Carraro. Kriging is well-suited to
parallelize optimization (2010), In Lim Meng Hiot, Yew Soon Ong, Yoel
Tenne, and Chi-Keong Goh, editors, <em>Computational Intelligence in
Expensive Optimization Problems</em>, Adaptation Learning and Optimization,
pages 131-162. Springer Berlin Heidelberg.
</p>
<p>S. Marmin. Developpements pour l'evaluation et la maximisation du critere
d'amelioration esperee multipoint en optimisation globale (2014). Master's
thesis, Mines Saint-Etienne (France) and University of Bern (Switzerland).
</p>
<p>J. Mockus (1988), <em>Bayesian Approach to Global Optimization</em>. Kluwer
academic publishers.
</p>
<p>M. Schonlau (1997), <em>Computer experiments and global optimization</em>,
Ph.D. thesis, University of Waterloo.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qEI">qEI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(15)
# Example 1 - validation by comparison to finite difference approximations

# a 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design)&lt;-c("x1", "x2")
design &lt;- data.frame(design) 
names(design)&lt;-c("x1", "x2")
y &lt;- apply(design, 1, branin)
y &lt;- data.frame(y) 
names(y) &lt;- "y" 

# learning
model &lt;- km(~1, design=design, response=y)

# pick up 2 points sampled from the simple expected improvement
q &lt;- 2  # increase to 4 for a more meaningful test
X &lt;- sampleFromEI(model,n=q)

# compute the gradient at the 4-point batch
grad.analytic &lt;- qEI.grad(X,model)
# numerically compute the gradient
grad.numeric &lt;- matrix(NaN,q,d)
eps &lt;- 10^(-6)
EPS &lt;- matrix(0,q,d)
for (i in 1:q) {
  for (j in 1:d) {
    EPS[i,j] &lt;- eps
    grad.numeric[i,j] &lt;- 1/eps*(qEI(X+EPS,model,fastCompute=FALSE)-qEI(X,model,fastCompute=FALSE))
    EPS[i,j] &lt;- 0
  }  
}
print(grad.numeric)
print(grad.analytic)

## Not run: 
# graphics: displays the EI criterion, the design points in black, 
# the batch points in red and the gradient in blue.
nGrid &lt;- 15
gridAxe1 &lt;- seq(lower[1],upper[1],length=nGrid)
gridAxe2 &lt;- seq(lower[2],upper[2],length=nGrid)
grid &lt;- expand.grid(gridAxe1,gridAxe2)
aa &lt;- apply(grid,1,EI,model=model)
myMat &lt;- matrix(aa,nrow=nGrid)
image(x = gridAxe1, y = gridAxe2, z = myMat, 
      col = colorRampPalette(c("darkgray","white"))(5*10), 
      ylab = names(design)[1], xlab=names(design)[2], 
      main = "qEI-gradient of a batch of 4 points", axes = TRUE, 
      zlim = c(min(myMat), max(myMat)))
contour(x = gridAxe1, y = gridAxe2, z = myMat, 
        add = TRUE, nlevels = 10)
points(X[,1],X[,2],pch=19,col='red')
points(model@X[,1],model@X[,2],pch=19)
arrows(X[,1],X[,2],X[,1]+0.012*grad.analytic[,1],X[,2]+0.012*grad.analytic[,2],col='blue')

## End(Not run)

</code></pre>

<hr>
<h2 id='rosenbrock4'>4D test function</h2><span id='topic+rosenbrock4'></span>

<h3>Description</h3>

<p>Rosenbrock 4-dimensional test function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rosenbrock4(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rosenbrock4_+3A_x">x</code></td>
<td>
<p>a 4-dimensional vector specifying the location where the function
is to be evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rosenbrock4 (standardized version) function is defined over the domain
<code>[0,1]^4</code>. It has 1 global minimizer : x* = c(0.4,0.4,0.4,0.4), with
minimum f(x*) = -1.019701, and an additional local minimizer, x*,2 =
c(0.26667,0.4,0.4,0.4), with minimum f(x*,2) = -1.019691.
</p>


<h3>Value</h3>

<p>A real number equal to the rosenbrock4 function values at <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Tobias Wagner  
</p>
<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
design &lt;- matrix(runif(400), 100, 4)
response &lt;- apply(design, 1, rosenbrock4)

</code></pre>

<hr>
<h2 id='sampleFromEI'>Sampling points according to the expected improvement criterion</h2><span id='topic+sampleFromEI'></span>

<h3>Description</h3>

<p>Samples <code>n</code> points from a distribution proportional to the expected
improvement (EI) computed from a <code>km</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleFromEI(
  model,
  minimization = TRUE,
  n = 1,
  initdistrib = NULL,
  lower = rep(0, model@d),
  upper = rep(1, model@d),
  T = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleFromEI_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>,</p>
</td></tr>
<tr><td><code id="sampleFromEI_+3A_minimization">minimization</code></td>
<td>
<p>logical specifying if EI is used in minimiziation or in
maximization,</p>
</td></tr>
<tr><td><code id="sampleFromEI_+3A_n">n</code></td>
<td>
<p>number of points to be sampled,</p>
</td></tr>
<tr><td><code id="sampleFromEI_+3A_initdistrib">initdistrib</code></td>
<td>
<p>matrix of candidate points.</p>
</td></tr>
<tr><td><code id="sampleFromEI_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds,</p>
</td></tr>
<tr><td><code id="sampleFromEI_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds,</p>
</td></tr>
<tr><td><code id="sampleFromEI_+3A_t">T</code></td>
<td>
<p>optional scalar : if provided, it replaces the current minimum (or
maximum) of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>n*d</code> matrix containing the sampled points. If <code>NULL</code>, <code>1000*d</code> points 
are obtained by latin hypercube sampling,
</p>


<h3>Author(s)</h3>

<p>Sebastien Marmin 
</p>
<p>Clement Chevalier 
</p>
<p>David Ginsbourger
</p>


<h3>References</h3>

<p>D.R. Jones, M. Schonlau, and W.J. Welch (1998), Efficient global
optimization of expensive black-box functions, <em>Journal of Global
Optimization</em>, 13, 455-492.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code>, <code><a href="DiceKriging.html#topic+km">km</a></code>, <code><a href="#topic+qEI">qEI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>



set.seed(004)

# a 9-points factorial design, and the corresponding responses
d &lt;- 2
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
lower &lt;- c(0,0)
upper &lt;- c(1,1)
names(response.branin) &lt;- "y" 


# model identification
fitted.model &lt;- km(~1, design=design.fact, response=response.branin, 
                   covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# sample a 30 point batch
batchSize &lt;- 30
x &lt;- sampleFromEI(model = fitted.model, n = batchSize, lower = lower, upper = upper)

# graphics 
# displays the EI criterion, the design points in black and the EI-sampled points in red.
nGrid &lt;- 15
gridAxe1 &lt;- seq(lower[1],upper[1],length=nGrid)
gridAxe2 &lt;- seq(lower[2],upper[2],length=nGrid)
grid &lt;- expand.grid(gridAxe1,gridAxe2)
aa &lt;- apply(grid,1,EI,model=fitted.model)
myMat &lt;- matrix(aa,nrow=nGrid)
image(x = gridAxe1, y = gridAxe2, z = myMat, 
      col = colorRampPalette(c("darkgray","white"))(5*10), 
      ylab = names(design.fact)[1], xlab=names(design.fact)[2], 
      main = "Sampling from the expected improvement criterion", 
      axes = TRUE, zlim = c(min(myMat), max(myMat)))
contour(x = gridAxe1, y = gridAxe2, z = myMat, 
        add = TRUE, nlevels = 10)
points(x[,1],x[,2],pch=19,col='red')
points(fitted.model@X[,1],fitted.model@X[,2],pch=19)


</code></pre>

<hr>
<h2 id='sphere6'>6D sphere function</h2><span id='topic+sphere6'></span>

<h3>Description</h3>

<p>6D Shifted and rotated weighted sphere test function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sphere6(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sphere6_+3A_x">x</code></td>
<td>
<p>a 6-dimensional vector specifying the location where the function
is to be evaluated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 6D Shifted and rotated weighted sphere (standardized version) function
is here defined over the domain <code>[0,1]^6</code>. It has 1 global minimizer :
x* = c(1,0.8,0.6,0.4,0.2,0), ), with minimum f(x*) = -1.941389. It has no
further local minima.
</p>


<h3>Value</h3>

<p>A real number equal to the sphere6 function values at <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Tobias Wagner  
</p>
<p>Victor Picheny 
</p>
<p>David Ginsbourger
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
design &lt;- matrix(runif(400), 100, 4)
response &lt;- apply(design, 1, sphere6)

</code></pre>

<hr>
<h2 id='test_feas_vec'>Test constraints violation (vectorized)</h2><span id='topic+test_feas_vec'></span>

<h3>Description</h3>

<p>Test whether a set of constraints are violated or not, depending on their nature (equality or inequality) and tolerance parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_feas_vec(cst, equality = FALSE, tolConstraints = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test_feas_vec_+3A_cst">cst</code></td>
<td>
<p>matrix of constraints (one column for each constraint function)</p>
</td></tr>
<tr><td><code id="test_feas_vec_+3A_equality">equality</code></td>
<td>
<p>either FALSE or a Boolean vector defining which constraints are treated as equalities</p>
</td></tr>
<tr><td><code id="test_feas_vec_+3A_tolconstraints">tolConstraints</code></td>
<td>
<p>tolerance (vector) for all constraints. If not provided, set to zero for inequalities and 0.05 for equalities</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Boolean vector, TRUE if the point if feasible, FALSE if at least one constraint is violated
</p>


<h3>Author(s)</h3>

<p>Mickael Binois 
</p>
<p>Victor Picheny
</p>

<hr>
<h2 id='TREGO.nsteps'>Trust-region based EGO algorithm.</h2><span id='topic+TREGO.nsteps'></span>

<h3>Description</h3>

<p>Executes <em>nsteps</em> iterations of the TREGO method to an object of class
<code><a href="DiceKriging.html#topic+km">km</a></code>.  At each step, a kriging model is
re-estimated (including covariance parameters re-estimation) based on the
initial design points plus the points visited during all previous
iterations; then a new point is obtained by maximizing the Expected
Improvement criterion (<code><a href="#topic+EI">EI</a></code>) over either the entire search space
or restricted to a trust region. The trust region is updated at each iteration
based on a sufficient decrease condition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TREGO.nsteps(
  model,
  fun,
  nsteps,
  lower,
  upper,
  control = NULL,
  kmcontrol = NULL,
  trcontrol = NULL,
  trace = 0,
  n.cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TREGO.nsteps_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>,</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_fun">fun</code></td>
<td>
<p>the objective function to be minimized,</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_nsteps">nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations,</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_lower">lower</code>, <code id="TREGO.nsteps_+3A_upper">upper</code></td>
<td>
<p>vector of lower and upper bounds for the variables to be optimized over,</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_control">control</code></td>
<td>
<p>an optional list of control parameters for optimization.
For now only the number of <code>restarts</code> can be set.</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_kmcontrol">kmcontrol</code></td>
<td>
<p>an optional list representing the control variables for
the re-estimation of the kriging model.</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_trcontrol">trcontrol</code></td>
<td>
<p>an optional list of control parameters for the trust-region scheme: 
<code>sigma</code> the initial size of the trust region,
<code>x0</code> its initial center, 
<code>beta</code> the contraction factor,
<code>alpha</code> its dilatation factor, 
<code>kappa</code> the forcing factor, 
<code>crit</code> the criterion used inside the TR (either &quot;EI&quot; or &quot;gpmean&quot;),
<code>GLratio</code> number of consecutive global and local steps,
<code>algo</code> either &quot;TREGO&quot; or &quot;TRIKE&quot;,
<code>minsigma</code> minimal sigma value,
<code>maxsigma</code> maximal sigma value,
<code>minEI</code> stopping criterion for TRIKE,
<code>local.model</code> Boolean; if TRUE, a local model is used within the trust region,
<code>local.trend, local.covtype</code> trend and covariance for the local model,
<code>n.local.min</code> minimal number of points used to build the local model,</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_trace">trace</code></td>
<td>
<p>between -1 (no trace) and 3 (full messages)</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_n.cores">n.cores</code></td>
<td>
<p>number of cores used for EI maximisation</p>
</td></tr>
<tr><td><code id="TREGO.nsteps_+3A_...">...</code></td>
<td>
<p>additional parameters to be given to <code>fun</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>a data frame representing the additional points visited during
the algorithm,</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>a data frame representing the response values at the points
given in <code>par</code>,</p>
</td></tr>
<tr><td><code>npoints</code></td>
<td>
<p>an integer representing the number of parallel computations
(=1 here),</p>
</td></tr>
<tr><td><code>nsteps</code></td>
<td>
<p>an integer representing the desired number of iterations
(given in argument),</p>
</td></tr>
<tr><td><code>lastmodel</code></td>
<td>
<p>an object of class <code><a href="DiceKriging.html#topic+km">km</a></code>
corresponding to the last kriging model fitted. If warping is true, 
<code>y</code> values are normalized (warped) and will not match <code>value</code>.</p>
</td></tr>
<tr><td><code>all.success</code></td>
<td>
<p> a vector of Boolean indicating the successful steps according
to the sufficient decrease condtion</p>
</td></tr>
<tr><td><code>all.steps</code></td>
<td>
<p> a vector of Boolean indicating which steps were global</p>
</td></tr>
<tr><td><code>all.sigma</code></td>
<td>
<p> history of trust region size</p>
</td></tr>
<tr><td><code>all.x0</code></td>
<td>
<p> history of trust region centers</p>
</td></tr>
<tr><td><code>local.model</code></td>
<td>
<p> if trcontrol$local.model=TRUE, the latest local model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny
</p>


<h3>References</h3>

<p>Diouane, Picheny, Le Riche, Scotto Di Perrotolo (2021),
<em>TREGO: a Trust-Region Framework for Efficient Global Optimization</em>, ArXiv
</p>


<h3>See Also</h3>

<p><code><a href="#topic+EI">EI</a></code>, <code><a href="#topic+max_crit">max_crit</a></code>, <code><a href="#topic+EI.grad">EI.grad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(123)
###############################################################
### 	10 ITERATIONS OF TREGO ON THE BRANIN FUNCTION, 	 ####
###	 STARTING FROM A 9-POINTS FACTORIAL DESIGN         ####
###############################################################

# a 9-points factorial design, and the corresponding response
d &lt;- 2
n &lt;- 9
design.fact &lt;- expand.grid(seq(0,1,length=3), seq(0,1,length=3)) 
names(design.fact)&lt;-c("x1", "x2")
design.fact &lt;- data.frame(design.fact) 
names(design.fact)&lt;-c("x1", "x2")
response.branin &lt;- apply(design.fact, 1, branin)
response.branin &lt;- data.frame(response.branin) 
names(response.branin) &lt;- "y" 

# model identification
fitted.model1 &lt;- km(~1, design=design.fact, response=response.branin, 
covtype="gauss", control=list(pop.size=50,trace=FALSE), parinit=c(0.5, 0.5))

# TREGO n steps
nsteps &lt;- 5
lower &lt;- rep(0, d) 
upper &lt;- rep(1, d)     
oEGO &lt;- TREGO.nsteps(model=fitted.model1, fun=branin, nsteps=nsteps, 
lower=lower, upper=upper)
print(oEGO$par)
print(oEGO$value)

# graphics
n.grid &lt;- 15 # Was 20, reduced to 15 for speeding up compilation
x.grid &lt;- y.grid &lt;- seq(0,1,length=n.grid)
design.grid &lt;- expand.grid(x.grid, y.grid)
response.grid &lt;- apply(design.grid, 1, branin)
z.grid &lt;- matrix(response.grid, n.grid, n.grid)
contour(x.grid, y.grid, z.grid, 40)
title("Branin function")
points(design.fact[,1], design.fact[,2], pch=17, col="blue")
points(oEGO$par, pch=19, col="red")
text(oEGO$par[,1], oEGO$par[,2], labels=1:nsteps, pos=3)
</code></pre>

<hr>
<h2 id='update_km_noisyEGO'>Update of one or two Kriging models when adding new observation</h2><span id='topic+update_km_noisyEGO'></span>

<h3>Description</h3>

<p>Update of a noisy Kriging model when adding new observation, with or
without covariance parameter re-estimation.  When the noise level is
unkown, a twin model &quot;estim.model&quot; is also updated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_km_noisyEGO(
  model,
  x.new,
  y.new,
  noise.var = 0,
  type = "UK",
  add.obs = TRUE,
  index.in.DOE = NULL,
  CovReEstimate = TRUE,
  NoiseReEstimate = FALSE,
  estim.model = NULL,
  nugget.LB = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_km_noisyEGO_+3A_model">model</code></td>
<td>
<p>a Kriging model of &quot;km&quot; class</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_x.new">x.new</code></td>
<td>
<p>a matrix containing the new points of experiments</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_y.new">y.new</code></td>
<td>
<p>a matrix containing the function values on the points NewX</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_noise.var">noise.var</code></td>
<td>
<p>scalar: noise variance</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_type">type</code></td>
<td>
<p>kriging type: &quot;SK&quot; or &quot;UK&quot;</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_add.obs">add.obs</code></td>
<td>
<p>boolean: if TRUE, the new point does not exist already in
the design of experiment model@X</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_index.in.doe">index.in.DOE</code></td>
<td>
<p>optional integer: if add.obs=TRUE, it specifies the
index of the observation in model@X corresponding to x.new</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_covreestimate">CovReEstimate</code></td>
<td>
<p>optional boolean specfiying if the covariance
parameters should be re-estimated (default value = TRUE)</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_noisereestimate">NoiseReEstimate</code></td>
<td>
<p>optional boolean specfiying if the noise variance
should be re-estimated (default value = TRUE)</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_estim.model">estim.model</code></td>
<td>
<p>optional input of &quot;km&quot; class. Required if
NoiseReEstimate=TRUE, in order to deal with repetitions.</p>
</td></tr>
<tr><td><code id="update_km_noisyEGO_+3A_nugget.lb">nugget.LB</code></td>
<td>
<p>optional scalar: is used to define a lower bound on the
noise variance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing: </p>
<table>
<tr><td><code>model</code></td>
<td>
<p> The updated Kriging model </p>
</td></tr>
<tr><td><code>estim.model</code></td>
<td>
<p>If NoiseReEstimate=TRUE, the updated estim.model</p>
</td></tr>
<tr><td><code>noise.var</code></td>
<td>
<p>If NoiseReEstimate=TRUE, the re-estimated noise variance</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Victor Picheny
</p>


<h3>References</h3>

<p>V. Picheny and D. Ginsbourger (2013), Noisy kriging-based optimization
methods: A unified implementation within the DiceOptim package,
<em>Computational Statistics &amp; Data Analysis</em>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
