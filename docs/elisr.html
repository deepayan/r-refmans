<!DOCTYPE html><html><head><title>Help for package elisr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {elisr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checks'><p>Miscellaneous input validation</p></a></li>
<li><a href='#disjoint'><p>Multiple scaling &ndash; the disjoint way</p></a></li>
<li><a href='#msdf'><p>Create and test for a multiple scaled data frame</p></a></li>
<li><a href='#overlap'><p>Multiple scaling &ndash; the overlapping way</p></a></li>
<li><a href='#print.msdf'><p>Print method for a multiple scaled data frame</p></a></li>
<li><a href='#trust'><p>German General Social Survey's Trust Items</p></a></li>
<li><a href='#utilities'><p>Miscellaneous utility functions</p></a></li>
<li><a href='#workhorses'><p>elisr's quadriga</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Exploratory Likert Scaling</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>An alternative to Exploratory Factor Analysis (EFA) for
    metrical data in R. Drawing on characteristics of classical test
    theory, Exploratory Likert Scaling (ELiS) supports the user exploring
    multiple one-dimensional data structures. In common research practice,
    however, EFA remains the go-to method to uncover the (underlying)
    structure of a data set. Orthogonal dimensions and the potential of
    overextraction are often accepted as side effects. As described in
    Müller-Schneider (2001) &lt;<a href="https://doi.org/10.1515%2Fzfsoz-2001-0404">doi:10.1515/zfsoz-2001-0404</a>&gt;), ELiS confronts
    these problems. As a result, 'elisr' provides the platform to fully
    exploit the exploratory potential of the multiple scaling approach
    itself.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/sbissantz/elisr">https://github.com/sbissantz/elisr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/sbissantz/elisr/issues">https://github.com/sbissantz/elisr/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, devtools, knitr, pkgdown, psych, rmarkdown, testthat
(&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en, de</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-13 11:56:16 UTC; steven</td>
</tr>
<tr>
<td>Author:</td>
<td>Steven Bißantz [aut, cre],
  Thomas Müller-Schneider [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Steven Bißantz &lt;steven.bissantz@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-15 22:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='checks'>Miscellaneous input validation</h2><span id='topic+checks'></span><span id='topic+check_df'></span><span id='topic+check_sclvals'></span><span id='topic+compare_sclvals'></span><span id='topic+check_mrit'></span><span id='topic+check_ovlp'></span><span id='topic+check_msdf'></span><span id='topic+check_neg'></span><span id='topic+check_comp'></span>

<h3>Description</h3>

<p>A set of test functions to ensure valid input and give helpful
advice if it is not.
</p>
<p><code>check_df()</code> guarantees that <code>x</code> is an appropriate
data frame for the analysis. That means: It verifies that <code>x</code> has less
than two variables (a single item can't build a core), <code>x</code> has column
names (used to pre-build <code>scls</code> in the overlapping process), if the
column names are unique, and not of type <code>NA</code>. It throws an error if
any of these requirements are not met. Additionally, it warns the user if
the provided <code>colnames</code> are not unique or <code>NA</code>.
</p>
<p><code>check_sclvals()</code> tests whether <code>x</code> is a two element
vector and throws an error if not. Integers are coerced to be of type
<code>double</code>. Additionally, the function ensures that the first value is
smaller than the second. Remember that checking for a two element vector
implicitly secures that <code>x</code> is not <code>NULL</code> (because <code>NULL</code> is
a logical constant of length '0').
</p>
<p><code>compare_sclvals()</code> makes sure that the <code>sclvals</code> set
with <code>overlap()</code> are equal to those set with <code>disjoint()</code>. It
throws an error if not.
</p>
<p><code>check_mrit()</code> guarantees that the input is a double vector
of length one. Moreover, the function secures that the lower bound is
unique and ranges between '0' and '1' (it throws an error if not). In
addition, it warns a user pre-determining a fragment.
</p>
<p><code>check_ovlp()</code> safeguards that <code>x</code> is a character
vector of length '1'. That means, it throws an error if not. Note that
<code>switch()</code> within <code>disjoint()</code> and <code>overlap()</code> takes care
of the input string itself. It throws an error when the given character
doesn't match any available option.
</p>
<p><code>check_msdf()</code> guards against inputs that are not of type
'msdf'. It throws an error if not.
</p>
<p><code>check_neg()</code> verifies that the input is a logical constant of length 1
and not a missing value (this is necessary because objects of type <code>NA</code>
are logical constants of length 1, too).
</p>
<p><code>check_comp()</code> examines the correlation matrix,
<code>cor(df)</code>. It complains (throws an error) if no correlation in
<code>cor(df)</code> is greater than the specified <code>mrit_min</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_df(x)

check_sclvals(x)

compare_sclvals(x, x_attr)

check_mrit(x)

check_ovlp(x)

check_msdf(x)

check_neg(x)

check_comp(x, mrit_min, use)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checks_+3A_x">x</code></td>
<td>
<p>some arbitrary input to be checked.</p>
</td></tr>
<tr><td><code id="checks_+3A_x_attr">x_attr</code></td>
<td>
<p>a numeric vector of length 2 indicating the start- and endpoint
of a scale.</p>
</td></tr>
<tr><td><code id="checks_+3A_mrit_min">mrit_min</code></td>
<td>
<p>a numeric constant of length 1 to specify the marginal
corrected item-total correlation.</p>
</td></tr>
<tr><td><code id="checks_+3A_use">use</code></td>
<td>
<p>an optional string to specify how missing values enter the
analysis. See <code>use</code> in <code><a href="stats.html#topic+cor">cor</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All functions are internal functions.
</p>


<h3>Value</h3>

<p>All functions are called for their side effects. If there are no
errors or warnings, no value is returned.
</p>

<hr>
<h2 id='disjoint'>Multiple scaling &ndash; the disjoint way</h2><span id='topic+disjoint'></span>

<h3>Description</h3>

<p><code>disjoint()</code> returns a multiple, disjointedly scaled
version of the specified data frame. This so called <code>msdf</code> sets up the
building block for further analysis with <code>overlap()</code> (type
<code>?overlap</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disjoint(
  df,
  mrit_min = 0.3,
  negative_too = FALSE,
  sclvals = NULL,
  use = "pairwise.complete.obs"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disjoint_+3A_df">df</code></td>
<td>
<p>a data frame (with more than two items and unique, non-<code>NA</code>
column names).</p>
</td></tr>
<tr><td><code id="disjoint_+3A_mrit_min">mrit_min</code></td>
<td>
<p>a numeric constant of length 1 to specify the marginal
corrected item-total correlation. Its value is in the range of 0-1. The
default is set to <code>.3</code>.</p>
</td></tr>
<tr><td><code id="disjoint_+3A_negative_too">negative_too</code></td>
<td>
<p>a logical constant indicating whether reversed items are
included in the analysis. The default is set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="disjoint_+3A_sclvals">sclvals</code></td>
<td>
<p>a numeric vector of length 2 indicating the start- and
endpoint of a scale. Use something like <code>c(min,max)</code>.</p>
</td></tr>
<tr><td><code id="disjoint_+3A_use">use</code></td>
<td>
<p>an optional string to specify how missing values enter the
analysis. See <code>use</code> in <code><a href="stats.html#topic+cor">cor</a></code> for details. The
default is set to <code>pairwise.complete.obs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>use</code> clarifies how to set up a correlation matrix in the
presence of missing values. In a typical scaling process this happens at
least twice. First, when determining the core items (the two items in the
correlation matrix with the highest linear relationship). Second, when an
item is proposed for an emerging scale.
</p>
<p>Note that <code>disjoint()</code> uses <code><a href="stats.html#topic+cor">cor</a></code>'s default method
<code>pearson</code>.
</p>


<h3>Value</h3>

<p>A multiple scaled data frame (<code>msdf</code>).
</p>


<h3>References</h3>

<p>Müller-Schneider, T. (2001). Multiple Skalierung nach dem
Kristallisationsprinzip / Multiple Scaling According to the Principle of
Crystallization. Zeitschrift für Soziologie, 30(4), 305-315.
https://doi.org/10.1515/zfsoz-2001-0404
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use only positive correlations
disjoint(mtcars, mrit_min = .4)

# Include negative correlations
disjoint(mtcars, mrit_min = .4, negative_too = TRUE, sclvals = c(1,7))

# Change the treatment of missing values
disjoint(mtcars, mrit_min = .4, use = "all.obs")
</code></pre>

<hr>
<h2 id='msdf'>Create and test for a multiple scaled data frame</h2><span id='topic+msdf'></span><span id='topic+new_msdf'></span><span id='topic+is.msdf'></span>

<h3>Description</h3>

<p><code>new_msdf()</code> creates a multiple scaled data frame
(<code>msdf</code>).
</p>
<p><code>is.msdf()</code> tests if an object is a multiple scaled data
frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>new_msdf(x = list(), method, mrit_min, negative_too, sclvals = NULL, df)

is.msdf(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msdf_+3A_x">x</code></td>
<td>
<p>either a multiple scaled data frame (<code>new_msdf()</code>) or an
arbitrary object to test (<code>is_msdf()</code>).</p>
</td></tr>
<tr><td><code id="msdf_+3A_method">method</code></td>
<td>
<p>the method used to produce the multiple scaled data frame
(either <code>disjoint()</code> or <code>overlap()</code>).</p>
</td></tr>
<tr><td><code id="msdf_+3A_mrit_min">mrit_min</code></td>
<td>
<p>a numeric constant of length one to specify the marginal
corrected item-total correlation. Its value is in the range of 0-1.</p>
</td></tr>
<tr><td><code id="msdf_+3A_negative_too">negative_too</code></td>
<td>
<p>a logical constant indicating whether reversed items are
included in the analysis. The default is set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="msdf_+3A_sclvals">sclvals</code></td>
<td>
<p>a numeric vector of length two indicating the start- and
endpoint of a scale.</p>
</td></tr>
<tr><td><code id="msdf_+3A_df">df</code></td>
<td>
<p>the data frame to analyze.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Objects of type 'msdf' are for internal use only.
</p>


<h3>Value</h3>

<p><code>new_msdf()</code> returns a list of data frames with a few
attributes that partially summarize the scaling process.
</p>
<p><code>is.msdf()</code> returns a logical vector of length one. <code>TRUE</code>
indicates that the object is of type <code>msdf</code>.
</p>

<hr>
<h2 id='overlap'>Multiple scaling &ndash; the overlapping way</h2><span id='topic+overlap'></span>

<h3>Description</h3>

<p><code>overlap()</code> returns a overlapped version (either extended,
or reversed, or both) of the specified <code>msdf</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overlap(
  msdf,
  mrit_min = NULL,
  negative_too = FALSE,
  overlap_with = "fragment",
  sclvals = NULL,
  use = "pairwise.complete.obs"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="overlap_+3A_msdf">msdf</code></td>
<td>
<p>a multiple scaled data frame (built with <code>disjoint()</code>).</p>
</td></tr>
<tr><td><code id="overlap_+3A_mrit_min">mrit_min</code></td>
<td>
<p>a numeric constant of length 1 to specify the marginal
corrected item-total correlation. Its value is in the range of 0-1. The
default is set to <code>.3</code>.</p>
</td></tr>
<tr><td><code id="overlap_+3A_negative_too">negative_too</code></td>
<td>
<p>a logical constant indicating whether reversed items are
included in the analysis. The default is set to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="overlap_+3A_overlap_with">overlap_with</code></td>
<td>
<p>a string telling <code>overlap()</code> the set of items for
the extension. To build up on all variables of a fragment use
<code>fragment</code>, for the core-only option type <code>core</code>. The default is
set to &quot;fragment&quot;.</p>
</td></tr>
<tr><td><code id="overlap_+3A_sclvals">sclvals</code></td>
<td>
<p>a numeric vector of length 2 indicating the start- and
endpoint of a scale. Use something like <code>c(min,max)</code>.</p>
</td></tr>
<tr><td><code id="overlap_+3A_use">use</code></td>
<td>
<p>an optional string to specify how missing values enter the
analysis. See <code>use</code> in <code><a href="stats.html#topic+cor">cor</a></code> for details. The
default is set to <code>pairwise.complete.obs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>use</code> clarifies how to set up a correlation matrix in the
presence of missing values. In a typical scaling process this happens at
least twice. First, when determining the core items (the two items in the
correlation matrix with the highest linear relationship). Second, when an
item is proposed for an emerging scale.
</p>
<p>Note that <code>overlap()</code> uses <code><a href="stats.html#topic+cor">cor</a></code>'s default
method <code>pearson</code>.
</p>


<h3>Value</h3>

<p>A multiple scaled data frame (<code>msdf</code>).
</p>


<h3>References</h3>

<p>Müller-Schneider, T. (2001). Multiple Skalierung nach dem
Kristallisationsprinzip / Multiple Scaling According to the Principle of
Crystallization. Zeitschrift für Soziologie, 30(4), 305-315.
https://doi.org/10.1515/zfsoz-2001-0404
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Build a msdf
msdf &lt;- disjoint(mtcars, mrit_min = .4)

# Use positive correlations (extend on fragments)
overlap(msdf, mrit_min = .6)

# Use positive correlations (extend on cores)
overlap(msdf, mrit_min = .6, overlap_with = "core")

# Include negative correlations
overlap(msdf, mrit_min = .7, negative_too = TRUE, sclvals = c(-3,3))

# Change the treatment of missing values
overlap(msdf, mrit_min = .6, use = "all.obs")

</code></pre>

<hr>
<h2 id='print.msdf'>Print method for a multiple scaled data frame</h2><span id='topic+print.msdf'></span>

<h3>Description</h3>

<p>The print method for a multiple scaled data frame. It summarizes
the <code>msdf</code> using values of classical test theory. Note that every line
in the output tags a new stage in the development process of each gradually
emerging scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'msdf'
print(x, digits = 2, use = "pairwise.complete.obs", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.msdf_+3A_x">x</code></td>
<td>
<p>a multiple scaled data frame (built with either
<code>disjoint()</code> or <code>overlap()</code>).</p>
</td></tr>
<tr><td><code id="print.msdf_+3A_digits">digits</code></td>
<td>
<p>an integer constant to determine the number of printed digits.
See <code>digits</code> in <code><a href="base.html#topic+options">options</a></code> for details.</p>
</td></tr>
<tr><td><code id="print.msdf_+3A_use">use</code></td>
<td>
<p>an optional string to specify how missing values enter the
analysis. See <code>use</code> in <code><a href="stats.html#topic+cor">cor</a></code> for details. The
default is set to <code>pairwise.complete.obs</code>.</p>
</td></tr>
<tr><td><code id="print.msdf_+3A_...">...</code></td>
<td>
<p>Additional arguments to the method which will be ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>use</code> clarifies how to set up a correlation matrix in the
presence of missing values. In a typical scaling process this happens at
least twice. First, when determining the core items (the two items in the
correlation matrix with the highest linear relationship). Second, when an
item is proposed for an emerging scale.
</p>


<h3>Value</h3>

<p>A list of summary statistics: the marginal corrected item-total
correlation (<code>mrit</code>), Cronbach's alpha (<code>alpha</code>), and the average
correlation (<code>rbar</code>).
</p>


<h3>References</h3>

<p>Müller-Schneider, T. (2001). Multiple Skalierung nach dem
Kristallisationsprinzip / Multiple Scaling According to the Principle of
Crystallization. Zeitschrift für Soziologie, 30(4), 305-315.
https://doi.org/10.1515/zfsoz-2001-0404
</p>

<hr>
<h2 id='trust'>German General Social Survey's Trust Items</h2><span id='topic+trust'></span>

<h3>Description</h3>

<p>A subset of the German General Social Survey (ALLBUS) 2018
containing its trust items (F018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trust
</code></pre>


<h3>Format</h3>

<p>Participants were asked about their trust in public institutions and
organizations. '1' means they have absolutely no trust at all, whereas '7'
represents a great deal of trust. The data frame has 3477 rows and 13
variables:
</p>

<dl>
<dt>healserv</dt><dd><p>Health service</p>
</dd>
<dt>fccourt</dt><dd><p>German constitutional court</p>
</dd>
<dt>bundtag</dt><dd><p>German Parliament</p>
</dd>
<dt>munadmin</dt><dd><p>Municipal administration</p>
</dd>
<dt>judsyst</dt><dd><p>Judicial system</p>
</dd>
<dt>tv</dt><dd><p>Television</p>
</dd>
<dt>newsppr</dt><dd><p>Newspapers</p>
</dd>
<dt>uni</dt><dd><p>Universities and other institutes of higher education</p>
</dd>
<dt>fedgovt</dt><dd><p>German government</p>
</dd>
<dt>police</dt><dd><p>Police</p>
</dd>
<dt>polpati</dt><dd><p>Political parties</p>
</dd>
<dt>eucomisn</dt><dd><p>European Commission</p>
</dd>
<dt>eupalmnt</dt><dd><p>European Parliament</p>
</dd>
</dl>



<h3>Details</h3>

<p>Please note that in comparison to the original data set participant
order has been randomly rearranged to further ensure anonymity. This might
lead to differences when trying to reproduce the results of the analysis
with the original data set (mentioned below).
</p>


<h3>References</h3>

<p>GESIS - Leibniz-Institut für Sozialwissenschaften (2019). German
General Social Survey - ALLBUS 2018. GESIS Datenarchiv, Köln. ZA5272
Datenfile Version 1.0.0, https://doi.org/10.4232/1.13325.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use trust with disjoint
disjoint(trust, mrit_min = .4)
</code></pre>

<hr>
<h2 id='utilities'>Miscellaneous utility functions</h2><span id='topic+utilities'></span><span id='topic+calc_rit'></span><span id='topic+calc_rbar'></span><span id='topic+calc_alpha'></span><span id='topic+rvrs_var'></span><span id='topic+rvrs_note'></span><span id='topic+extr_core'></span><span id='topic+extr_core_nms'></span><span id='topic+extreb_itms'></span><span id='topic+nme_msdf'></span>

<h3>Description</h3>

<p>A set of utility functions to calculate characteristic values of
classical test theory, reverse a variable, and extract the relevant bits
from various objects.
</p>
<p><code>calc_rit()</code> calculates the corrected item-total
correlation of a scale or fragment using a part-whole correction. Thus, the
item itself is excluded in the calculation process.
</p>
<p><code>calc_rbar()</code> calculates the average correlation of a
fragment or scale.
</p>
<p><code>calc_alpha()</code> calculates the internal consistency of a
scale or fragment using Cronbach's alpha.
</p>
<p><code>rvrs_var()</code> reverses an item using the specified scaling values. It
handles the following types of scales:
</p>

<ul>
<li><p>  ...-3 -2 -1 0 1 2 3..., e.g., <code>sclvals = c(-3, 3)</code>
</p>
</li>
<li><p>  0 1 2 3 4 5 6..., e.g.,  <code>sclvals = c(0, 7)</code>
</p>
</li>
<li><p>  1 2 3 4 5 6 7..., e.g., <code>sclcals = c(1, 7)</code>
</p>
</li></ul>

<p><code>rvrs_note()</code> gets the full report of reversed variables
and reports a unique list of them.
</p>
<p><code>extr_core()</code> is used to extract all pairs of core items from a
fragment.
</p>
<p><code>extr_core_nms()</code> is used to extract the names of all pairs
of core items from a given fragment.
</p>
<p><code>extreb_itms()</code> builds the counterpart of a fragment from
the given item names. Therefore, the counterpart includes all variables
that are not part of a fragment but which are mentioned in the specified
data set.
</p>
<p><code>nme_msdf()</code> renames the components of a multiple scaled
data frame. The naming scheme is <code>scl_n</code>. <code>scl</code> stands for
'scale' and <code>n</code> specifies the number of fragments or scales. For
example, the first component is called <code>scl_1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_rit(scl, use)

calc_rbar(scl, use)

calc_alpha(scl, use)

rvrs_var(var, sclvals)

rvrs_note(msg, applicant)

extr_core(scl)

extr_core_nms(scl)

extreb_itms(df, itm_nms)

nme_msdf(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="utilities_+3A_scl">scl</code></td>
<td>
<p>a scale within a multiple scaled data frame.</p>
</td></tr>
<tr><td><code id="utilities_+3A_use">use</code></td>
<td>
<p>an optional string indicating how to deal with missing values, See
<code>use</code> in <code><a href="stats.html#topic+cor">cor</a></code> for details.</p>
</td></tr>
<tr><td><code id="utilities_+3A_var">var</code></td>
<td>
<p>a variable or item (often a column from a data frame).</p>
</td></tr>
<tr><td><code id="utilities_+3A_sclvals">sclvals</code></td>
<td>
<p>the start- and end point of a scale (specify:
<code>c(sp,ep)</code>).</p>
</td></tr>
<tr><td><code id="utilities_+3A_msg">msg</code></td>
<td>
<p>a reverse message sent from either <code>disjoint()</code> or
<code>overlap()</code>.</p>
</td></tr>
<tr><td><code id="utilities_+3A_applicant">applicant</code></td>
<td>
<p>the function which wants to leave messages <code>disjoint()</code>
or <code>overlap()</code>.</p>
</td></tr>
<tr><td><code id="utilities_+3A_df">df</code></td>
<td>
<p>a data frame object.</p>
</td></tr>
<tr><td><code id="utilities_+3A_itm_nms">itm_nms</code></td>
<td>
<p>the names of an item from a scale.</p>
</td></tr>
<tr><td><code id="utilities_+3A_x">x</code></td>
<td>
<p>a multiple scaled data frame.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All functions are internal functions.
</p>


<h3>Value</h3>

<p><code>calc_rit()</code> returns a numeric vector of length one. It is used
to examine the coherence between item and overall score.
</p>
<p><code>calc_rbar()</code> returns a numeric vector of length one that
reports the inter-item correlation.
</p>
<p><code>calc_alpha()</code> returns a numeric vector of length one which is
used to assess the internal consistency of a scale.
</p>
<p><code>rvrs_var()</code> returns the reversed numeric vector using the above
reversing scheme.
</p>
<p><code>rvrs_note()</code> is called for its side effects. It leaves a
message when an item is reversed.
</p>
<p><code>extr_core()</code> returns a numeric vector of length two, which
contains the two items with the highest correlation in a fragment or scale.
</p>
<p><code>extr_core_nms()</code> returns character vector of length two, which
contains the names of the two items with the highest correlation in a
fragment or scale.
</p>
<p><code>extrev_itms()</code> returns vector of length m minus two, where 'm'
specifies the number of variables in a given data set. It contains the
items of a scale's counterpart.
</p>
<p><code>nme_msdf()</code> returns a character vector that numbers each
element of its input according to the above naming scheme.
</p>

<hr>
<h2 id='workhorses'>elisr's quadriga</h2><span id='topic+workhorses'></span><span id='topic+disj_pci'></span><span id='topic+disj_nci'></span><span id='topic+ovlp_pci'></span><span id='topic+ovlp_nci'></span>

<h3>Description</h3>

<p>The four workhorses inside <code>elisr</code>'s user functions
<code>disjoint()</code> and <code>overlap()</code>.
</p>
<p><code>disj_pci()</code> is a loop which runs through the following
steps: (1) Set up a (first) scale. (2) Find the two items with the highest
positive correlation in the data set. (3) If the absolute value of this
correlation is greater than the pre-specified lower bound
(<code>mrit_min</code>), add up the two items to build the core of the emerging
scale. (4) As long as the value of the correlation between the sum-score
and a remaining item in the data frame is greater than <code>mrit_min</code>,
flavor the scale with the appropriate item. (5) If there are at least two
leftovers in the data frame that meet the inclusion criterion, start over
again.
</p>
<p><code>disj_nci()</code> is almost identical to <code>disj_pci()</code>,
though step (4) varies slightly from above. To take negative correlations
into account, <code>disj_nci()</code> flavors the scale with appropriate item as
long as the <em>absolute</em> value of the correlation between the sum-score
and a remaining items in the data frame is greater than <code>mrit_min</code>.
</p>
<p><code>ovlp_pci()</code> takes a disjointedly built scale fragment and
tries to extend it with those items in the data set, which are not yet
built into the fragment (aka., its counterpart). Because <code>ovlp_pci()</code>
does this for every disjointedly built scale fragment it is a multiple
one-dimensional extension of <code>disj_pci()</code>.
</p>
<p>The only difference to <code>ovlp_pci()</code> is that
<code>ovlp_nci()</code> can handle reversed items. The extension algorithm
remains almost the same; <code>ovlp_nci()</code> flavors <em>each</em> scale
fragment with appropriate items from its counterpart as long as the
<em>absolute</em> value of the correlation between the sum-score and a
remaining item is greater than <code>mrit_min</code>. Thus, it is a multiple
one-dimensional extension of <code>disj_nci()</code>:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disj_pci(df, mrit_min, use)

disj_nci(df, mrit_min, sclvals, use)

ovlp_pci(msdf, mrit_min, overlap_with, use)

ovlp_nci(msdf, mrit_min, overlap_with, sclvals, use)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="workhorses_+3A_df">df</code></td>
<td>
<p>a data frame object.</p>
</td></tr>
<tr><td><code id="workhorses_+3A_mrit_min">mrit_min</code></td>
<td>
<p>a numerical constant to specify the marginal corrected item
total correlation. The value must be in the range of 0-1.</p>
</td></tr>
<tr><td><code id="workhorses_+3A_use">use</code></td>
<td>
<p>an optional string to specify how missing values will enter the
analysis. See <code>use</code> in <code><a href="stats.html#topic+cor">cor</a></code> for details.</p>
</td></tr>
<tr><td><code id="workhorses_+3A_sclvals">sclvals</code></td>
<td>
<p>a numerical vector of length 2 indicating the start- and
endpoint of a scale.</p>
</td></tr>
<tr><td><code id="workhorses_+3A_msdf">msdf</code></td>
<td>
<p>a multiple scaled data frame (built with <code>disjoint()</code>).</p>
</td></tr>
<tr><td><code id="workhorses_+3A_overlap_with">overlap_with</code></td>
<td>
<p>a string telling <code>overlap()</code> the set of items for
the extension. To build up on all variables of a fragment use
<code>fragment</code>, for the core-only option type <code>core</code>. The default is
set to &quot;fragment&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All functions are internal functions.
</p>
<p>The <code>use</code> argument specifies how to set up a correlation matrix in the
presence of missing values. In a typical scaling process this happens at
least twice. First, when determining the core items (the two items in the
correlation matrix with the highest linear relationship). Second, when an
item is proposed for an emerging scale.
</p>
<p>Note that all functions use <code><a href="stats.html#topic+cor">cor</a></code>'s default method
<code>pearson</code>.
</p>


<h3>Value</h3>

<p><code>disj_pci()</code> and <code>disj_nci()</code> both return a list of data
frames which result from applying the above-mentioned algorithm.
</p>
<p><code>ovlp_pci()</code> and <code>ovlp_nci()</code> often return an
<em>extended</em> a list of data frames.
</p>


<h3>References</h3>

<p>Müller-Schneider, T. (2001). Multiple Skalierung nach dem
Kristallisationsprinzip / Multiple Scaling According to the Principle of
Crystallization. Zeitschrift für Soziologie, 30(4), 305-315.
https://doi.org/10.1515/zfsoz-2001-0404
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
