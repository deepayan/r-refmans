<!DOCTYPE html><html><head><title>Help for package GGMridge</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GGMridge}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EM.mixture'><p>Estimation of the mixture distribution using EM algorithm</p></a></li>
<li><a href='#getEfronp'><p>Estimation of empirical null distribution.</p></a></li>
<li><a href='#ksStat'><p>The Kolmogorov-Smirnov Statistic for p-Values</p></a></li>
<li><a href='#lambda.cv'><p>Choose the Tuning Parameter of the Ridge Inverse</p></a></li>
<li><a href='#lambda.pcut.cv'><p>Choose the Tuning Parameter of the Ridge Inverse and</p>
Thresholding Level of the Empirical p-Values</a></li>
<li><a href='#lambda.pcut.cv1'><p>Choose the Tuning Parameter of the Ridge Inverse and</p>
Thresholding Level of the Empirical p-Values.
</p>
<p>Calculate total prediction error for test data after fitting partial</p>
correlations from train data for all values of lambda and pcut.</a></li>
<li><a href='#lambda.TargetD'><p>Shrinkage Estimation of a Covariance Matrix Toward an Identity Matrix</p></a></li>
<li><a href='#ne.lambda.cv'><p>Choose the Tuning Parameter of a Ridge Regression Using Cross-Validation</p></a></li>
<li><a href='#R.separate.ridge'><p>Estimation of Partial Correlation Matrix Using p Separate Ridge Regressions.</p></a></li>
<li><a href='#scaledMat'><p>Scale a square matrix</p></a></li>
<li><a href='#simulateData'><p>Generate Simulation Data from a Random Network.</p></a></li>
<li><a href='#structuredEstimate'><p>Estimation of Partial Correlation Matrix Given Zero Structure.</p></a></li>
<li><a href='#transFisher'><p>Fisher's Z-Transformation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Gaussian Graphical Models Using Ridge Penalty Followed by
Thresholding and Reestimation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-24</td>
</tr>
<tr>
<td>Author:</td>
<td>Min Jin Ha [aut, cre], Shannon T. Holloway [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Shannon T. Holloway &lt;shannon.t.holloway@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>mvtnorm, MASS, stats, graphics</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimation of partial correlation matrix using ridge penalty 
    followed by thresholding and reestimation. Under multivariate Gaussian 
    assumption, the matrix constitutes an Gaussian graphical model (GGM).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Collate:</td>
<td>'EM.mixture.R' 'scaledMat.R' 'svdFunc.R' 'splitSets.R'
'ne.lambda.cv.R' 'R.separate.ridge.R' 'StructuredEstimate.R'
'ksStat.R' 'getEfronp.R' 'lambda.TargetD.R' 'lambda.cv.R'
'transFisher.R' 'lambda.pcut.cv1.R' 'lambda.pcut.cv.R'
'simulateData.R'</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-24 17:07:31 UTC; 19194</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-24 22:20:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='EM.mixture'>Estimation of the mixture distribution using EM algorithm</h2><span id='topic+EM.mixture'></span>

<h3>Description</h3>

<p>Estimation of the parameters, null proportion, and 
degrees of freedom of the exact null density in the 
mixture distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EM.mixture(p, eta0, df, tol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EM.mixture_+3A_p">p</code></td>
<td>
<p>A numeric vector representing partial correlation coefficients.</p>
</td></tr>
<tr><td><code id="EM.mixture_+3A_eta0">eta0</code></td>
<td>
<p>An initial value for the null proportion; 1-eta0 is the non-null 
proportion.</p>
</td></tr>
<tr><td><code id="EM.mixture_+3A_df">df</code></td>
<td>
<p>An initial value for the degrees of freedom of the exact null 
density.</p>
</td></tr>
<tr><td><code id="EM.mixture_+3A_tol">tol</code></td>
<td>
<p>The tolerance level for convergence.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list object containing
</p>
<table>
<tr><td><code>df</code></td>
<td>
<p>Estimated degrees of freedom of the null density.</p>
</td></tr>
<tr><td><code>eta0</code></td>
<td>
<p>Estimated null proportion.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iterations required to reach convergence.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Schafer, J. and Strimmer, K. 
(2005). 
An empirical Bayes approach to inferring large-scale gene association 
networks. 
Bioinformatics, 21, 754&ndash;764.
</p>

<hr>
<h2 id='getEfronp'>Estimation of empirical null distribution.</h2><span id='topic+getEfronp'></span>

<h3>Description</h3>

<p>Estimation of empirical null distribution using Efron's central matching.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEfronp(
  z,
  bins = 120L,
  maxQ = 9,
  pct = 0,
  pct0 = 0.25,
  cc = 1.2,
  plotIt = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getEfronp_+3A_z">z</code></td>
<td>
<p>A numeric vector of z values following the theoretical normal null 
distribution.</p>
</td></tr>
<tr><td><code id="getEfronp_+3A_bins">bins</code></td>
<td>
<p>The number of intervals for density estimation of the marginal 
density of z.</p>
</td></tr>
<tr><td><code id="getEfronp_+3A_maxq">maxQ</code></td>
<td>
<p>The maximum degree of the polynomial to be considered for density
estimation of the marginal density of z.</p>
</td></tr>
<tr><td><code id="getEfronp_+3A_pct">pct</code></td>
<td>
<p>Low and top (pct*100)
f(z).</p>
</td></tr>
<tr><td><code id="getEfronp_+3A_pct0">pct0</code></td>
<td>
<p>Low and top (pct0*100)
estimate f0(z).</p>
</td></tr>
<tr><td><code id="getEfronp_+3A_cc">cc</code></td>
<td>
<p>The central parts 
</p>
<p style="text-align: center;"><code class="reqn">(\mu - \sigma cc, \mu + \sigma cc)</code>
</p>

<p>of the empirical distribution z are used for an estimate of the null 
proportion (eta).</p>
</td></tr>
<tr><td><code id="getEfronp_+3A_plotit">plotIt</code></td>
<td>
<p>TRUE if density plot is to be produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing
</p>
<table>
<tr><td><code>correctz</code></td>
<td>
<p>The corrected z values to follow empirically 
standard normal distribution.</p>
</td></tr>
<tr><td><code>correctp</code></td>
<td>
<p>The corrected p values using the correct z values.</p>
</td></tr>
<tr><td><code>q</code></td>
<td>
<p>The chosen degree of polynomial for the estimated 
marginal density.</p>
</td></tr>
<tr><td><code>mu0hat</code></td>
<td>
<p>The location parameter for the normal null 
distribution.</p>
</td></tr>
<tr><td><code>sigma0hat</code></td>
<td>
<p>The scale parameter for the normal null 
distribution.</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>The estimated null proportion.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Efron, B. 
(2004). 
Large-scale simultaneous hypothesis testing. 
Journal of the American Statistical Association, 99, 96&ndash;104.
</p>
<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty 
followed by thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p &lt;- 100 # number of variables
 n &lt;- 50 # sample size

 ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = p, etaA = 0.02, n = n, r = 1)
 data &lt;- simulation$data[[1]]
 stddata &lt;- scale(x = data, center = TRUE, scale = TRUE)
   
 ###############################
 # estimate ridge parameter
 ###############################
 lambda.array &lt;- seq(from = 0.1, to = 20, by = 0.1) * (n - 1.0)
 fit &lt;- lambda.cv(x = stddata, lambda = lambda.array, fold = 10L)
 lambda &lt;- fit$lambda[which.min(fit$spe)] / (n - 1.0)
   
 ###############################
 # calculate partial correlation
 # using ridge inverse
 ###############################
 w.upper &lt;- which(upper.tri(diag(p)))
 partial &lt;- solve(lambda * diag(p) + cor(data))
 partial &lt;- (-scaledMat(x = partial))[w.upper]
   
 ###############################
 # get p-values from empirical 
 # null distribution 
 ###############################
 efron.fit &lt;- getEfronp(z = transFisher(x = partial))
 
</code></pre>

<hr>
<h2 id='ksStat'>The Kolmogorov-Smirnov Statistic for p-Values</h2><span id='topic+ksStat'></span>

<h3>Description</h3>

<p>Calculates the Kolmogorov-Smirnov statistic for p-values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ksStat(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ksStat_+3A_p">p</code></td>
<td>
<p>A numeric vector with p-values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Kolmogorov-Smirnov statistic
</p>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p &lt;- stats::runif(100)
 ksStat(p = p)
 ks.test(p, y = "punif") # compare with ks.test
 
</code></pre>

<hr>
<h2 id='lambda.cv'>Choose the Tuning Parameter of the Ridge Inverse</h2><span id='topic+lambda.cv'></span>

<h3>Description</h3>

<p>Choose the tuning parameter of the ridge inverse by minimizing cross 
validation estimates of the total prediction errors of the p separate 
ridge regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda.cv(x, lambda, fold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda.cv_+3A_x">x</code></td>
<td>
<p>An n by p data matrix.</p>
</td></tr>
<tr><td><code id="lambda.cv_+3A_lambda">lambda</code></td>
<td>
<p>A numeric vector of candidate tuning parameters.</p>
</td></tr>
<tr><td><code id="lambda.cv_+3A_fold">fold</code></td>
<td>
<p>fold-cross validation is performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>The selected tuning parameter, which minimizes the 
total prediction errors. </p>
</td></tr>
<tr><td><code>spe</code></td>
<td>
<p>The total prediction error for all the candidate 
lambda values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty followed 
by thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p &lt;- 100 # number of variables
 n &lt;- 50 # sample size
 
 ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = p, etaA = 0.02, n = n, r = 1)
 data &lt;- simulation$data[[1L]]
 stddata &lt;- scale(x = data, center = TRUE, scale = TRUE)
 
 ###############################
 # estimate ridge parameter
 ###############################
 lambda.array &lt;- seq(from = 0.1, to = 20, by = 0.1) * (n - 1.0)
 fit &lt;- lambda.cv(x = stddata, lambda = lambda.array, fold = 10L)
 lambda &lt;- fit$lambda[which.min(fit$spe)] / (n - 1.0)
 
 ###############################
 # calculate partial correlation 
 # using ridge inverse
 ###############################
 partial &lt;- solve(lambda*diag(p) + cor(data))
 partial &lt;- -scaledMat(x = partial)

</code></pre>

<hr>
<h2 id='lambda.pcut.cv'>Choose the Tuning Parameter of the Ridge Inverse and 
Thresholding Level of the Empirical p-Values</h2><span id='topic+lambda.pcut.cv'></span>

<h3>Description</h3>

<p>Choose the tuning parameter of the ridge inverse and p-value cutoff by 
minimizing cross validation estimates of the total prediction errors of 
the p separate ridge regressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda.pcut.cv(x, lambda, pcut, fold = 10L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda.pcut.cv_+3A_x">x</code></td>
<td>
<p>n by p data matrix.</p>
</td></tr>
<tr><td><code id="lambda.pcut.cv_+3A_lambda">lambda</code></td>
<td>
<p>A vector of candidate tuning parameters.</p>
</td></tr>
<tr><td><code id="lambda.pcut.cv_+3A_pcut">pcut</code></td>
<td>
<p>A vector of candidate cutoffs of pvalues.</p>
</td></tr>
<tr><td><code id="lambda.pcut.cv_+3A_fold">fold</code></td>
<td>
<p>fold-cross validation is performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The total prediction errors for all lambda (row-wise) and pcut 
(column-wise)
</p>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty followed by 
thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p &lt;- 100 # number of variables
 n &lt;- 50 # sample size
 
 ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = p, etaA = 0.02, n = n, r = 1)
 data &lt;- simulation$data[[1L]]
 stddata &lt;- scale(x = data, center = TRUE, scale = TRUE)
 
 ###############################
 # Selection of a lambda and a 
 # p-value cutoff
 ###############################
 lambda.array &lt;- seq(from = 0.1, to = 5, length = 10) * (n-1.0)
 pcut.array &lt;- seq(from = 0.01, to = 0.05, by = 0.01)
 tpe &lt;- lambda.pcut.cv(x = stddata,
                       lambda = lambda.array,
                       pcut = pcut.array,
                       fold = 3L)
 w.mintpe &lt;- which(tpe == min(tpe), arr.ind = TRUE)
 lambda &lt;- lambda.array[w.mintpe[1L]]
 alpha &lt;- pcut.array[w.mintpe[2L]]
 
</code></pre>

<hr>
<h2 id='lambda.pcut.cv1'>Choose the Tuning Parameter of the Ridge Inverse and 
Thresholding Level of the Empirical p-Values.
Calculate total prediction error for test data after fitting partial 
correlations from train data for all values of lambda and pcut.</h2><span id='topic+lambda.pcut.cv1'></span>

<h3>Description</h3>

<p>Choose the Tuning Parameter of the Ridge Inverse and 
Thresholding Level of the Empirical p-Values.
</p>
<p>Calculate total prediction error for test data after fitting partial 
correlations from train data for all values of lambda and pcut.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda.pcut.cv1(train, test, lambda, pcut)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda.pcut.cv1_+3A_train">train</code></td>
<td>
<p>An n x p data matrix from which the model is fitted.</p>
</td></tr>
<tr><td><code id="lambda.pcut.cv1_+3A_test">test</code></td>
<td>
<p>An m x p data matrix from which the model is evaluated.</p>
</td></tr>
<tr><td><code id="lambda.pcut.cv1_+3A_lambda">lambda</code></td>
<td>
<p>A vector of candidate tuning parameters.</p>
</td></tr>
<tr><td><code id="lambda.pcut.cv1_+3A_pcut">pcut</code></td>
<td>
<p>A vector of candidate cutoffs of pvalues.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Total prediction error for all the candidate lambda and pvalue 
cutoff values.
</p>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty followed 
by thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p &lt;- 100 # number of variables
 n &lt;- 50 # sample size
 
 ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = p, etaA = 0.02, n = n, r = 1)
 data &lt;- simulation$data[[1L]]
 
 ###############################
 # Split into train/test sets
 ###############################
 testindex &lt;- sample(1L:n, 10L)
 
 train &lt;- data[-testindex,,drop = FALSE]
 stdTrain &lt;- scale(x = train, center = TRUE, scale = TRUE)
 
 test &lt;- data[testindex,,drop = FALSE]
 stdTest &lt;- scale(x = test, center = TRUE, scale = TRUE)
 
 ###############################
 # Calculate total prediction 
 # errors for all candidate 
 # lambda and p-value cutoffs
 ###############################
 lambda.array &lt;- seq(from = 0.1, to = 5, length = 10) * (n - 1.0)
 pcut.array &lt;- seq(from = 0.01, to = 0.05, by = 0.01)
 tpe &lt;- lambda.pcut.cv1(train = stdTrain,
                        test = stdTest,
                        lambda = lambda.array,
                        pcut = pcut.array)
  
</code></pre>

<hr>
<h2 id='lambda.TargetD'>Shrinkage Estimation of a Covariance Matrix Toward an Identity Matrix</h2><span id='topic+lambda.TargetD'></span>

<h3>Description</h3>

<p>Estimation of a weighted average of a sample covariance (correlation) matrix 
and an identity matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda.TargetD(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda.TargetD_+3A_x">x</code></td>
<td>
<p>Centered data for covariance shrinkage and standardized data for 
correlation shrinkage.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An analytical approach to the estimate ridge parameter.
</p>


<h3>Value</h3>

<p>The estimates of shrinkage intensity.
</p>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Schafer, J. and Strimmer, K.
(2005). 
A shrinkage approach to large-scale covariance matrix estimation 
and implications for functional genomics. 
Statistical Applications in Genetics and Molecular Biology, 4, 32.
</p>
<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty followed 
by thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = 100, etaA = 0.02, n = 50, r = 10)
 dat &lt;- simulation$data[[1L]]
 stddat &lt;- scale(x = dat, center = TRUE, scale = TRUE)
 
 shrinkage.lambda &lt;- lambda.TargetD(x = stddat)
 
 ###############################
 # the ridge parameter
 ###############################
 ridge.lambda &lt;- shrinkage.lambda / (1.0 - shrinkage.lambda)
 
 ###############################
 # partial correlation matrix
 ###############################
 partial &lt;- solve(cor(dat) + ridge.lambda * diag(ncol(dat)))
 partial &lt;- -scaledMat(x = partial)
 
</code></pre>

<hr>
<h2 id='ne.lambda.cv'>Choose the Tuning Parameter of a Ridge Regression Using Cross-Validation</h2><span id='topic+ne.lambda.cv'></span>

<h3>Description</h3>

<p>Choose the tuning parameter of a ridge regression using cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ne.lambda.cv(y, x, lambda, fold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ne.lambda.cv_+3A_y">y</code></td>
<td>
<p>Length n response vector.</p>
</td></tr>
<tr><td><code id="ne.lambda.cv_+3A_x">x</code></td>
<td>
<p>n x p matrix for covariates with p variables and n sample size.</p>
</td></tr>
<tr><td><code id="ne.lambda.cv_+3A_lambda">lambda</code></td>
<td>
<p>A numeric vector for candidate tuning parameters for a ridge 
regression.</p>
</td></tr>
<tr><td><code id="ne.lambda.cv_+3A_fold">fold</code></td>
<td>
<p>fold-cross validation used to choose the tuning parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>The selected tuning parameter, which minimizes 
the prediction error. </p>
</td></tr>
<tr><td><code>spe</code></td>
<td>
<p>The prediction error for all of the candidate 
lambda values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty followed 
by thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p &lt;- 100 # number of variables
 n &lt;- 50 # sample size
 
 ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = p, etaA = 0.02, n = n, r = 1)
 data &lt;- simulation$data[[1L]]
 stddat &lt;- scale(x = data, center = TRUE, scale = TRUE)
 
 X &lt;- stddat[,-1L,drop = FALSE]
 y &lt;- stddat[,1L]
 
 fit.lambda &lt;- ne.lambda.cv(y = y,
                            x = X,
                            lambda = seq(from = 0.01, to = 1,by = 0.1),
                            fold = 10L)  
 
 lambda &lt;- fit.lambda$lambda[which.min(fit.lambda$spe)] 

</code></pre>

<hr>
<h2 id='R.separate.ridge'>Estimation of Partial Correlation Matrix Using p Separate Ridge Regressions.</h2><span id='topic+R.separate.ridge'></span>

<h3>Description</h3>

<p>The partial correlation matrix is estimated by p separate ridge regressions 
with the parameters selected by cross validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R.separate.ridge(x, fold, lambda, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R.separate.ridge_+3A_x">x</code></td>
<td>
<p>n x p data matrix; n is the # of samples and p is the # of variables.</p>
</td></tr>
<tr><td><code id="R.separate.ridge_+3A_fold">fold</code></td>
<td>
<p>Ridge parameters are selected by fold-cross validations 
separately for each regression.</p>
</td></tr>
<tr><td><code id="R.separate.ridge_+3A_lambda">lambda</code></td>
<td>
<p>The candidate ridge parameters for all p ridge regressions.</p>
</td></tr>
<tr><td><code id="R.separate.ridge_+3A_verbose">verbose</code></td>
<td>
<p>TRUE/FALSE; if TRUE, print the procedure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing
</p>
<table>
<tr><td><code>R</code></td>
<td>
<p> The partial correlation matrix.</p>
</td></tr>
<tr><td><code>lambda.sel</code></td>
<td>
<p> The selected tuning parameters for p ridge regressions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty followed 
by thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>   p &lt;- 100 # number of variables
   n &lt;- 50 # sample size
   
   ###############################
   # Simulate data
   ###############################
   simulation &lt;- simulateData(G = p, etaA = 0.02, n = n, r = 1)
   data &lt;- simulation$data[[1L]]
   stddata &lt;- scale(x = data, center = TRUE, scale = FALSE)
   
   ###############################
   # estimate ridge parameter
   ###############################
   w.upper &lt;- which(upper.tri(diag(p)))
   
   lambda.array &lt;- seq(from = 0.1, to = 20, by=0.1) * (n-1.0)
   partial.sep &lt;-  R.separate.ridge(x = stddata,
                                    lambda = lambda.array,
                                    fold = 5L,
                                    verbose = TRUE)$R[w.upper]
 
</code></pre>

<hr>
<h2 id='scaledMat'>Scale a square matrix</h2><span id='topic+scaledMat'></span>

<h3>Description</h3>

<p>Scale a square matrix to have unit diagonal elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaledMat(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaledMat_+3A_x">x</code></td>
<td>
<p>A square matrix with positive diagonal elements</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Scaled matrix of x.
</p>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = 100, etaA = 0.02, n = 50, r = 10)
 dat &lt;- simulation$data[[1L]]
 correlation &lt;- scaledMat(x = stats::cov(dat))

</code></pre>

<hr>
<h2 id='simulateData'>Generate Simulation Data from a Random Network.</h2><span id='topic+simulateData'></span>

<h3>Description</h3>

<p>Generate a random network where both the network structure and the partial 
correlation coefficients are random. The data matrices are generated from 
multivariate normal distribution with the covariance matrix corresponding 
to the network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateData(G, etaA, n, r, dist = "mvnorm")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulateData_+3A_g">G</code></td>
<td>
<p>The number of variables (vertices).</p>
</td></tr>
<tr><td><code id="simulateData_+3A_etaa">etaA</code></td>
<td>
<p>The proportion of non-null edges among all the G(G-1)/2 edges.</p>
</td></tr>
<tr><td><code id="simulateData_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code id="simulateData_+3A_r">r</code></td>
<td>
<p>The number of replicated G by N data matrices.</p>
</td></tr>
<tr><td><code id="simulateData_+3A_dist">dist</code></td>
<td>
<p>A function which indicates the distribution of sample. 
&quot;mvnorm&quot; is multivariate normal distribution and 
&quot;mvt&quot; is multivariate t distribution with df=2. 
The default is set by &quot;mvnorm&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p> a list, each element containing an n X G matrix of 
simulated data.</p>
</td></tr>
<tr><td><code>true.partialcor</code></td>
<td>
<p> The partial correlation matrix which the 
datasets are generated from.</p>
</td></tr>
<tr><td><code>truecor.scaled</code></td>
<td>
<p> The covariance matrix calculted from the 
partial correlation matrix.</p>
</td></tr>
<tr><td><code>sig.node</code></td>
<td>
<p> The indices of nonzero upper triangle 
elements of partial correlation matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Schafer, J. and Strimmer, K. 
(2005). 
An empirical Bayes approach to inferring large-scale gene 
association networks. 
Bioinformatics, 21, 754&ndash;764.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> simulation &lt;- simulateData(G = 100, etaA = 0.02, n = 50, r = 10)

</code></pre>

<hr>
<h2 id='structuredEstimate'>Estimation of Partial Correlation Matrix Given Zero Structure.</h2><span id='topic+structuredEstimate'></span>

<h3>Description</h3>

<p>Estimation of nonzero entries of the partial correlation matrix given zero 
structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>structuredEstimate(x, E)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="structuredEstimate_+3A_x">x</code></td>
<td>
<p>n by p data matrix with the number of variables p and sample size n.</p>
</td></tr>
<tr><td><code id="structuredEstimate_+3A_e">E</code></td>
<td>
<p>The row and column indices of zero entries of the partial 
correlation matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing
</p>
<table>
<tr><td><code>R</code></td>
<td>
<p>The partial correlation matrix.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>The inverse covariance matrix.</p>
</td></tr>
<tr><td><code>RSS</code></td>
<td>
<p>The residual sum of squares.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>References</h3>

<p>Ha, M. J. and Sun, W. 
(2014).
Partial correlation matrix estimation using ridge penalty followed 
by thresholding and re-estimation.
Biometrics, 70, 762&ndash;770.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p &lt;- 100 # number of variables
 n &lt;- 50 # sample size
 
 ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = p, etaA = 0.02, n = n, r = 1)
 data &lt;- simulation$data[[1L]]
 stddata &lt;- scale(x = data, center = TRUE, scale = TRUE)
 
 ###############################
 # estimate ridge parameter
 ###############################
 lambda.array &lt;- seq(from = 0.1, to = 20, by = 0.1) * (n-1.0)
 fit &lt;- lambda.cv(x = stddata, lambda = lambda.array, fold = 10L)
 lambda &lt;- fit$lambda[which.min(fit$spe)]/(n-1)
 
 ###############################
 # calculate partial correlation 
 # using ridge inverse
 ###############################
 w.upper &lt;- which(upper.tri(diag(p)))
 
 partial &lt;- solve(lambda * diag(p) + cor(data))
 partial &lt;- (-scaledMat(x = partial))[w.upper]
 
 ###############################
 # get p-values from empirical 
 # null distribution 
 ###############################
 efron.fit &lt;- getEfronp(z = transFisher(x = partial), 
                        bins = 50L, 
                        maxQ = 13)
 
 ###############################
 # estimate the edge set of 
 # partial correlation graph with 
 # FDR control at level 0.01
 ###############################
 w.array &lt;- which(upper.tri(diag(p)),arr.ind=TRUE)
 th &lt;- 0.01
 wsig &lt;- which(p.adjust(efron.fit$correctp, method="BH") &lt; th )
 E &lt;- w.array[wsig,]
 dim(E)
 
 ###############################
 # structured estimation
 ###############################
 fit &lt;- structuredEstimate(x = stddata, E = E)
 th.partial &lt;- fit$R

</code></pre>

<hr>
<h2 id='transFisher'>Fisher's Z-Transformation</h2><span id='topic+transFisher'></span>

<h3>Description</h3>

<p>Fisher's Z-transformation of (partial) correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transFisher(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transFisher_+3A_x">x</code></td>
<td>
<p>A vector having entries between -1 and 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Fisher's Z-transformed values.
</p>


<h3>Author(s)</h3>

<p>Min Jin Ha
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ###############################
 # Simulate data
 ###############################
 simulation &lt;- simulateData(G = 100, etaA = 0.02, n = 50, r = 1)
 dat &lt;- simulation$data[[1L]]
 stddat &lt;- scale(x = dat, center = TRUE, scale = TRUE)

 shrinkage.lambda &lt;- lambda.TargetD(x = stddat)

 ###############################
 # the ridge parameter
 ###############################
 ridge.lambda &lt;- shrinkage.lambda / (1.0 - shrinkage.lambda)

 ###############################
 # partial correlation matrix
 ###############################
 partial &lt;- solve(cor(dat) + ridge.lambda * diag(ncol(dat)))
 partial &lt;- -scaledMat(x = partial)

 ###############################
 # Fisher's Z transformation of 
 # upper diagonal of the partial 
 # correlation matrix
 ###############################
 w.upper &lt;- which(upper.tri(diag(nrow(dat))))
 psi &lt;- transFisher(x = partial[w.upper])
 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
