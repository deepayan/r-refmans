<!DOCTYPE html><html lang="en"><head><title>Help for package mvMORPH</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mvMORPH}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mvMORPH-package'>
<p>Multivariate Comparative Methods for Fitting Evolutionary Models to Morphometric Data</p></a></li>
<li><a href='#aicw'>
<p>Akaike weights</p></a></li>
<li><a href='#ancestral'>
<p>Estimation of traits ancestral states.</p></a></li>
<li><a href='#coef'>
<p>Extract multivariate gls (or ols) model coefficients</p></a></li>
<li><a href='#dfaShape'>
<p>Projection of 2D and 3D shapes (from geometric morphometric datasets) on Discriminant axes</p></a></li>
<li><a href='#effectsize'>
<p>Multivariate measure of association/effect size for objects of class &quot;manova.gls&quot;</p></a></li>
<li><a href='#EIC'>
<p>Extended Information Criterion (EIC) to compare models fit with <code>mvgls</code> (or <code>mvols</code>) by Maximum Likelihood (ML) or Penalized Likelihood (PL)</p></a></li>
<li><a href='#estim'>
<p>Ancestral states reconstructions and missing value imputation with phylogenetic/time-series models</p></a></li>
<li><a href='#fitted'>
<p>Extract multivariate gls (or ols) model fitted values</p></a></li>
<li><a href='#GIC'>
<p>Generalized Information Criterion (GIC) to compare models fit with <code>mvgls</code> (or <code>mvols</code>) by Maximum Likelihood (ML) or Penalized Likelihood (PL)</p></a></li>
<li><a href='#halflife'>
<p>The phylogenetic half-life for an Ornstein-Uhlenbeck process</p></a></li>
<li><a href='#LRT'>
<p>Likelihood Ratio Test</p></a></li>
<li><a href='#manova.gls'>
<p>Multivariate Analysis of Variance</p></a></li>
<li><a href='#mv.Precalc'>
<p>Model parameterization for the various mvMORPH functions</p></a></li>
<li><a href='#mvBM'>
<p>Multivariate Brownian Motion models of continuous traits evolution</p></a></li>
<li><a href='#mvEB'>
<p>Multivariate Early Burst model of continuous traits evolution</p></a></li>
<li><a href='#mvgls'>
<p>Fit linear model using Generalized Least Squares to multivariate (high-dimensional) data sets</p></a></li>
<li><a href='#mvgls.dfa'>
<p>Discriminant Function Analysis (DFA) - also called Linear Discriminant Analysis (LDA) or Canonical Variate Analysis (CVA) - based on multivariate GLS (or OLS) model fit</p></a></li>
<li><a href='#mvgls.pca'>
<p>Principal Component Analysis (PCA) based on GLS (or OLS) estimate of the traits variance-covariance matrix (possibly regularized)</p></a></li>
<li><a href='#mvLL'>
<p>Multivariate (and univariate) algorithms for log-likelihood estimation of arbitrary covariance matrix/trees</p></a></li>
<li><a href='#mvols'>
<p>Fit linear model using Ordinary Least Squares to multivariate (high-dimensional) data sets</p></a></li>
<li><a href='#mvOU'>
<p>Multivariate Ornstein-Uhlenbeck model of continuous traits evolution</p></a></li>
<li><a href='#mvOUTS'>
<p>Multivariate continuous trait evolution for a stationary time series (Ornstein-Uhlenbeck model)</p></a></li>
<li><a href='#mvqqplot'>
<p>Quantile-Quantile plots for multivariate models fit with <code>mvgls</code> or <code>mvols</code></p></a></li>
<li><a href='#mvRWTS'>
<p>Multivariate Brownian motion / Random Walk model of continuous traits evolution on time series</p></a></li>
<li><a href='#mvSHIFT'>
<p>Multivariate change in mode of continuous trait evolution</p></a></li>
<li><a href='#mvSIM'>
<p>Simulation of (multivariate) continuous traits on a phylogeny</p></a></li>
<li><a href='#pairwise.contrasts'>
<p>Pairwise contrasts</p></a></li>
<li><a href='#pairwise.glh'>
<p>Pairwise multivariate tests between levels of a factor</p></a></li>
<li><a href='#pcaShape'>
<p>Projection of 2D and 3D shapes (from geometric morphometric datasets) on Principal Component Axes (PCA)</p></a></li>
<li><a href='#phyllostomid'>
<p>Phylogeny and trait data for a sample of Phyllostomid bats</p></a></li>
<li><a href='#predict'>
<p>Predictions from (multivariate) gls or ols model fit</p></a></li>
<li><a href='#predict.mvgls.dfa'>
<p>Predictions from Discriminant analysis conducted with a mvgls model fit</p></a></li>
<li><a href='#pruning'>
<p>Pruning algorithm to compute the square root of the phylogenetic covariance matrix and its determinant.</p></a></li>
<li><a href='#residuals'>
<p>Extract gls (or ols) model residuals</p></a></li>
<li><a href='#stationary'>
<p>The stationary variance of an Ornstein-Uhlenbeck process</p></a></li>
<li><a href='#vcov'>
<p>Calculate variance-covariance matrix for a fitted object of class 'mvgls'</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multivariate Comparative Tools for Fitting Evolutionary Models
to Morphometric Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-08-28</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Julien Clavel &lt;julien.clavel@hotmail.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits multivariate (Brownian Motion, Early Burst, ACDC, Ornstein-Uhlenbeck and Shifts) models of continuous traits evolution on trees and time series. 'mvMORPH' also proposes high-dimensional multivariate comparative tools (linear models using Generalized Least Squares and multivariate tests) based on penalized likelihood.  See
    Clavel et al. (2015) &lt;<a href="https://doi.org/10.1111%2F2041-210X.12420">doi:10.1111/2041-210X.12420</a>&gt;, Clavel et al. (2019) &lt;<a href="https://doi.org/10.1093%2Fsysbio%2Fsyy045">doi:10.1093/sysbio/syy045</a>&gt;, and Clavel &amp; Morlon (2020) &lt;<a href="https://doi.org/10.1093%2Fsysbio%2Fsyaa010">doi:10.1093/sysbio/syaa010</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), phytools, ape, corpcor, subplex</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, spam, graphics, glassoFast, parallel, pbmcapply</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, car</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/JClavel/mvMORPH">https://github.com/JClavel/mvMORPH</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-08-28 16:00:13 UTC; julic5</td>
</tr>
<tr>
<td>Author:</td>
<td>Julien Clavel [aut, cre],
  with contributions from Aaron King [aut],
  Emmanuel Paradis [aut]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-28 23:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mvMORPH-package'>
Multivariate Comparative Methods for Fitting Evolutionary Models to Morphometric Data
</h2><span id='topic+mvMORPH-package'></span><span id='topic+mvMORPH'></span>

<h3>Description</h3>

<p>Fit of multivariate evolutionary models on trees (with one or multiple selective regimes) and time-series dedicated to morphometrics or biometric continuous data with covariation. Testing for a phylogenetic signal in a multivariate dataset (including fossil and/or extant taxa), fitting linear models to high-dimensional multivariate comparative data, changes in rate or mode of evolution of continuous traits, simulating multivariate traits evolution, computing the likelihood of multivariate models, accounts for measurement errors and missing data, and other things...
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> mvMORPH</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.2.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2013-07-22</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=2.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Julien Clavel
</p>
<p>Maintainer: Julien Clavel &lt;julien.clavel@hotmail.fr&gt;
</p>


<h3>References</h3>

<p>Clavel et al. (2015). mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods in Ecology and Evolution, 6(11):1311-1319. doi: 10.1111/2041-210X.12420.
</p>
<p>Clavel et al. (2019). A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116. doi: 10.1093/sysbio/syy045.
</p>
<p>Clavel &amp; Morlon (2020). Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in Phyllostomid bats. Systematic Biology 69(5): 927-943. doi: 10.1093/sysbio/syaa010
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvols">mvols</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvgls.pca">mvgls.pca</a></code>
<code><a href="#topic+mvgls.dfa">mvgls.dfa</a></code>
<code><a href="#topic+manova.gls">manova.gls</a></code>
<code><a href="#topic+pairwise.glh">pairwise.glh</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvOUTS">mvOUTS</a></code>
<code><a href="#topic+mvRWTS">mvRWTS</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
<code><a href="#topic+mvLL">mvLL</a></code>
<code><a href="#topic+LRT">LRT</a></code>
<code><a href="#topic+halflife">halflife</a></code>
<code><a href="#topic+stationary">stationary</a></code>
<code><a href="#topic+estim">estim</a></code>
<code><a href="#topic+aicw">aicw</a></code>
<code><a href="#topic+GIC">GIC</a></code>
<code><a href="#topic+EIC">EIC</a></code>
<code><a href="#topic+mvqqplot">mvqqplot</a></code>
</p>

<hr>
<h2 id='aicw'>
Akaike weights
</h2><span id='topic+aicw'></span>

<h3>Description</h3>

<p>This function return the Akaike weights for a set of fitted models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aicw(x,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aicw_+3A_x">x</code></td>
<td>

<p>A list with the fitted objects or a list/vector of AIC
</p>
</td></tr>
<tr><td><code id="aicw_+3A_...">...</code></td>
<td>

<p>Options to be passed through; e.g. aicc=TRUE when a list of fitted objects is provided.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function compute the Akaike weights for a set of model AIC or AICc. Akaike weights can be used for model comparison and model averaging.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>models</code></td>
<td>
<p>List of models</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion</p>
</td></tr>
<tr><td><code>diff</code></td>
<td>
<p>AIC difference with the best fit model</p>
</td></tr>
<tr><td><code>wi</code></td>
<td>
<p>Absolute weight</p>
</td></tr>
<tr><td><code>aicweights</code></td>
<td>
<p>Akaike weights (relative weights)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Burnham K.P., Anderson D.R. 2002. Model selection and multi-model inference: a practical information-theoric approach. New York: Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+AIC">AIC</a></code>
<code><a href="#topic+mvMORPH">mvMORPH</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
# Generating a random tree
tree&lt;-pbtree(n=50)

#simulate the traits
sigma &lt;- matrix(c(0.01,0.005,0.003,0.005,0.01,0.003,0.003,0.003,0.01),3)
theta&lt;-c(0,0,0)
data&lt;-mvSIM(tree, model="BM1", nsim=1, param=list(sigma=sigma, theta=theta))

## Fitting the models
# BM1 - General structure
fit1 &lt;- mvBM(tree, data, model="BM1", method="pic")

# BM1 - No covariations
fit2 &lt;- mvBM(tree, data, model="BM1", method="pic", param=list(constraint="diagonal"))

# BM1 - Equal variances/rates
fit3 &lt;- mvBM(tree, data, model="BM1", method="pic", param=list(constraint="equal"))

results &lt;- list(fit1,fit2,fit3)

# or
# results &lt;- c(AIC(fit1), AIC(fit2), AIC(fit3))

# Akaike weights
aicw(results)

# AICc weights
aicw(results, aicc=TRUE)

# we can compare the MSE...
# mean((fit1$sigma-sigma)^2)
# mean((fit3$sigma-sigma)^2)

</code></pre>

<hr>
<h2 id='ancestral'>
Estimation of traits ancestral states.
</h2><span id='topic+ancestral'></span>

<h3>Description</h3>

<p>Reconstruct the ancestral states at each node of a phylogenetic tree from models fit obtained using the <code>mvgls</code> function. For models of the class <code>mvXX</code> this is a wrapper to the function <code>estim</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>
ancestral(object, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ancestral_+3A_object">object</code></td>
<td>

<p>A model fit object obtained by the <code>mvgls</code> function.
</p>
</td></tr>
<tr><td><code id="ancestral_+3A_...">...</code></td>
<td>

<p>Further options to be passed through. For instance, if a regression model is used, values for the predictor(s) at each node of the tree should be given in a matrix to the <code>newdata</code> argument. If a model of the type <code>mvXX</code> is used, the argument <code>tree</code> and <code>data</code> should be provided like in <code>estim</code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ancestral</code> is an S3 method that reconstruct the ancestral states at each nodes of a phylogenetic tree from the models fit obtained by the <code>mvgls</code> function (Clavel et al. 2019). Ancestral states are estimated using generalized least squares (GLS; Martins &amp; Hansen 1997, Cunningham et al. 1998 ). Note that when a regression model (rather than an intercept only model of the form Y~1) is provided, an argument &quot;newdata&quot; with a matrix of regressor values for each node should be provided (similar to what is done in the &quot;predict&quot; function). 
</p>


<h3>Value</h3>

<p>a matrix of reconstructed ancestral states for each node (note that the numerotation of the ancestral states starts at &quot;N+1&quot; [for the root], where N is the number of species in the tree)
</p>


<h3>Note</h3>

<p>The function is similar to the one used with <code>fit_t_pl</code> from the RPANDA package (Clavel et al. 2019).</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Syst. Biol. 68: 93-116.
</p>
<p>Cunningham C.W., Omland K.E., Oakley T.H. 1998. Reconstructing ancestral character states: a critical reappraisal. Trends Ecol. Evol. 13:361-366.
</p>
<p>Martins E.P., Hansen T.F. 1997. Phylogenies and the comparative method: a general approach to incorporating phylogenetic information into the analysis of interspecific data. Am. Nat. 149:646-667.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>, 
<code><a href="#topic+estim">estim</a></code>,
<code><a href="#topic+predict.mvgls">predict.mvgls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(1)
n &lt;- 32 # number of species
p &lt;- 5 # number of traits

tree &lt;- pbtree(n=n, scale=1) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p), ncol=p)) # a random covariance matrix
# simulate a BM dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R, theta=rep(0,p))) 
data=list(Y=Y)

fit &lt;- mvgls(Y~1, data=data, tree, model="BM", method="LL")

# Perform the ancestral states reconstruction
anc &lt;- ancestral(fit)

# retrieve the ancestral states
head(anc)


</code></pre>

<hr>
<h2 id='coef'>
Extract multivariate gls (or ols) model coefficients
</h2><span id='topic+coef.mvgls'></span>

<h3>Description</h3>

<p>Returns the coefficients of a linear model fit of class 'mvgls' or 'mvols'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'mvgls'
coef(object, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef_+3A_object">object</code></td>
<td>

<p>an object of class 'mvgls' obtained from a <code>mvgls</code> or <code>mvols</code> fit.
</p>
</td></tr>
<tr><td><code id="coef_+3A_...">...</code></td>
<td>

<p>other arguments (not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients extracted from the model fit.
</p>


<h3>Note</h3>

<p>For an intercept only model with phylogenetic structure this correspond to the ancestral states.
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>See Also</h3>

<p><code><a href="#topic+vcov.mvgls">vcov.mvgls</a></code> 
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+fitted.mvgls">fitted.mvgls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
</p>

<hr>
<h2 id='dfaShape'>
Projection of 2D and 3D shapes (from geometric morphometric datasets) on Discriminant axes
</h2><span id='topic+dfaShape'></span>

<h3>Description</h3>

<p>The function extracts the shape changes along discriminant axes computed by a DFA (<code>mvgls.dfa</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dfaShape(object, reference, axis=1, ndim=3, spp=NULL, scaling=1, plot=FALSE, ...)  

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dfaShape_+3A_object">object</code></td>
<td>

<p>A discriminant analysis obtained by the <code>mvgls.dfa</code> function.
</p>
</td></tr>
<tr><td><code id="dfaShape_+3A_reference">reference</code></td>
<td>

<p>The reference shape used to compare the deformations. Usually the mean shape.</p>
</td></tr>
<tr><td><code id="dfaShape_+3A_axis">axis</code></td>
<td>

<p>The discriminant axis on which morphological changes are projected.</p>
</td></tr>
<tr><td><code id="dfaShape_+3A_ndim">ndim</code></td>
<td>

<p>The number of dimensions of the GMM data set (2 for 2D and 3 for 3D).</p>
</td></tr>
<tr><td><code id="dfaShape_+3A_spp">spp</code></td>
<td>

<p>Names of the species (should match names in the dataset) shape to project onto the PC axis. If null, the two extreme shapes along <code>axis</code> are reported.  
</p>
</td></tr>
<tr><td><code id="dfaShape_+3A_scaling">scaling</code></td>
<td>

<p>An arbitrary factor used to multiply the effects (for better visualization)  
</p>
</td></tr>
<tr><td><code id="dfaShape_+3A_plot">plot</code></td>
<td>

<p>Should the projected landmarks be plotted?  
</p>
</td></tr>
<tr><td><code id="dfaShape_+3A_...">...</code></td>
<td>

<p>Further options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will project the shape changes along discriminant axes obtained from a DFA by <code>mvgls.dfa</code>.  This can be used to display morphological changes (for 2D and 3D geometric morphometric data) that best separate individuals from distinct groups.
</p>


<h3>Value</h3>

<p>a list with 2D or 3D coordinates for the shape projected on the selected PC axis.
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Claude, J., 2008. Morphometrics with R. Springer Science.
</p>
<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+mvgls.dfa">mvgls.dfa</a></code>
<code><a href="#topic+pcaShape">pcaShape</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(phyllostomid)

# Fit a linear model by PL
fit &lt;- mvgls(mandible[,-1]~grp1, data=phyllostomid, phyllostomid$tree, model="lambda", method="PL") 

# Discriminant analysis
da &lt;- mvgls.dfa(fit)

# Project the mandible shape extremes on the first discriminant axe
proj_shape &lt;- dfaShape(da, reference=coef(fit), axis=1, ndim=2, plot=TRUE)

polygon(proj_shape$min)
polygon(proj_shape$max, border="red")


</code></pre>

<hr>
<h2 id='effectsize'>
Multivariate measure of association/effect size for objects of class &quot;manova.gls&quot;
</h2><span id='topic+effectsize'></span>

<h3>Description</h3>

<p>This function estimate the multivariate effectsize for all the outcomes variables of a multivariate analysis of variance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effectsize(x,...)
</code></pre>


<h3>Arguments</h3>

 
<table role = "presentation">
<tr><td><code id="effectsize_+3A_x">x</code></td>
<td>

<p>An object of class &quot;manova.gls&quot;
</p>
</td></tr>
<tr><td><code id="effectsize_+3A_...">...</code></td>
<td>

<p>One can specify <code>adjusted=TRUE</code> to obtain Serlin' adjustment to Pillai trace effect size, or Tatsuoka' adjustment for Wilks' lambda. These adjustments are correcting positive bias with increasing number of variables.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows estimating multivariate effect size for the four multivariate statistics implemented in <code>manova.gls</code> (Pillai, Wilks, Roy, Hotelling-Lawley). For models fit by PL, a multivariate measure of effect size is estimated from the permuted data. Interpret only relatively.
</p>


<h3>Value</h3>

<p>Return the effect size for all the terms of the MANOVA or pairwise tests.
</p>


<h3>Note</h3>

<p>This function is still under development.</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manova.gls">manova.gls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
<code><a href="#topic+pairwise.glh">pairwise.glh</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n &lt;- 32 # number of species
p &lt;- 3  # number of traits
tree &lt;- pbtree(n=n) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p),p))  # a random symmetric matrix (covariance)

# simulate a dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R))
X &lt;- rnorm(n) # continuous
grp &lt;- rep(1:2, each=n/2)
dataset &lt;- list(y=Y, x=X, grp=as.factor(grp))

# Model fit
model1 &lt;- mvgls(y~x+grp, data=dataset, tree=tree, model="BM", method="LL")

# Multivariate test
(multivariate_test &lt;- manova.gls(model1, test="Pillai"))
effectsize(multivariate_test)
</code></pre>

<hr>
<h2 id='EIC'>
Extended Information Criterion (EIC) to compare models fit with <code>mvgls</code> (or <code>mvols</code>) by Maximum Likelihood (ML) or Penalized Likelihood (PL)
</h2><span id='topic+EIC'></span>

<h3>Description</h3>

<p>The EIC (Ishiguro et al. 1997, Kitagawa &amp; Konishi 2010), uses bootstrap to estimate the bias term of the Extended Information Criterion. This criterion allows comparing models fit by Maximum Likelihood (ML) or Penalized Likelihood (PL).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
EIC(object, nboot=100L, nbcores=1L, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EIC_+3A_object">object</code></td>
<td>

<p>An object of class 'mvgls'. See <code>?mvgls</code> or <code>?mvols</code></p>
</td></tr>
<tr><td><code id="EIC_+3A_nboot">nboot</code></td>
<td>

<p>The number of boostrap replicates used for estimating the EIC.</p>
</td></tr>
<tr><td><code id="EIC_+3A_nbcores">nbcores</code></td>
<td>

<p>The number of cores used to speed-up the computations (uses the 'parallel' package)</p>
</td></tr>
<tr><td><code id="EIC_+3A_...">...</code></td>
<td>

<p>Options to be passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Extended Information Criterion (<code>EIC</code>) allows comparing the fit of various models estimated by Penalized Likelihood or Maximum Likelihood (see ?<code>mvgls</code>). Similar to the GIC or the more common AIC, the EIC has the form:
</p>
<p style="text-align: center;"><code class="reqn">EIC = -2*(Likelihood) + 2*bias</code>
</p>

<p>Where <em>Likelihood</em> corresponds to either the full or the restricted likelihood (see the note below), and the bias term is estimated by (semi-parametric) bootstrap simulations rather than by using analytical or approximate solutions (see for instance ?<code>GIC</code>). The smaller the EIC, the better is the model. With small sample sizes, the variability around the bootstrap estimate is expected to be high, and one must increase the number of bootstrap replicates. Parallel computation (argument <code>nbcores</code>) allows to speed-up the computations.
</p>
<p>Note: for models estimated by REML, it is generally not possible to compare the restricted likelihoods when the models fit have different fixed effects. However, it is possible to compare models with different fixed effects by using the full likelihood evaluated at the REML estimates (see e.g. Yafune et al. 2006, Verbyla 2019). Both options - evaluating the restricted likelihood or the full likelihood with parameters estimated by REML - are available through the <code>REML</code> argument in the <code>EIC</code> function. The default has been set to <code>REML=FALSE</code> to allow the comparison of models with different fixed effects using the full likelihood evaluated with the REML estimates (see Verbyla 2019).
</p>


<h3>Value</h3>

<p>a list with the following components
</p>
<table role = "presentation">
<tr><td><code>LogLikelihood</code></td>
<td>
<p>the log-likelihood estimated for the model with estimated parameters</p>
</td></tr>
<tr><td><code>EIC</code></td>
<td>
<p>the EIC criterion</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>the standard error of the bias term estimated by bootstrap</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>the values of the bias term estimated from the boostrapped replicates to compute the EIC</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel J., Aristide L., Morlon H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Syst. Biol. 68:93-116.
</p>
<p>Ishiguro M., Sakamoto Y., Kitagawa G., 1997. Bootstrapping log likelihood and EIC, an extension of AIC. Ann. Inst. Statist. Math. 49:411-434.
</p>
<p>Kitagawa G., Konishi S., 2010. Bias and variance reduction techniques for bootstrap information criterion. Ann. Inst. Stat. Math. 62:209-234.
</p>
<p>Konishi S., Kitagawa G., 1996. Generalised information criteria in model selection. Biometrika. 83:875-890.
</p>
<p>Verbyla A. P., 2019. A note on model selection using information criteria for general linear models estimated using REML. Aust. N. Z. J. Stat. 61:39-50.
</p>
<p>Yafune A., Funatogawa T., Ishiguro M., 2005. Extended information criterion (EIC) approach for linear mixed effects models under restricted maximum likelihood (REML) estimation. Statist. Med. 24:3417-3429.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GIC">GIC</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
<code><a href="#topic+manova.gls">manova.gls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(1)
n &lt;- 32 # number of species
p &lt;- 50 # number of traits

tree &lt;- pbtree(n=n) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p), ncol=p)) # a random symmetric matrix (covariance)
# simulate a dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R))

fit1 &lt;- mvgls(Y~1, tree=tree, model="BM", method="H&amp;L")
fit2 &lt;- mvgls(Y~1, tree=tree, model="OU", method="H&amp;L")


EIC(fit1); EIC(fit2)

# We can improve accuracy by increasing the number of bootstrap samples
# EIC(fit1, nboot=5000, nbcores=8L)
# EIC(fit2, nboot=5000, nbcores=8L)

</code></pre>

<hr>
<h2 id='estim'>
Ancestral states reconstructions and missing value imputation with phylogenetic/time-series models
</h2><span id='topic+estim'></span>

<h3>Description</h3>

<p>This function imputes the missing cases (NA values) according to a given phylogenetic model (object of class &quot;mvmorph&quot;); it can also do ancestral state reconstruction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim(tree, data, object, error=NULL, asr=FALSE)
</code></pre>


<h3>Arguments</h3>

 
<table role = "presentation">
<tr><td><code id="estim_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree (an object of class &quot;phylo&quot; or &quot;simmap&quot;) or a time-series.
</p>
</td></tr>
<tr><td><code id="estim_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits with missing cases (NA values) in columns (preferentially with names and in the same order than in the tree).
</p>
</td></tr>
<tr><td><code id="estim_+3A_object">object</code></td>
<td>

<p>A fitted object from an mvMORPH model (class &quot;mvmorph&quot;).
</p>
</td></tr>
<tr><td><code id="estim_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="estim_+3A_asr">asr</code></td>
<td>

<p>If asr=TRUE, the ancestral states are estimated instead of the missing cases.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Missing observations for species in a phylogenetic tree are estimated according to a given evolutionary model (and parameters). Multivariate models are useful to recover the variance and covariance structure of the dataset to be imputed.
</p>
<p>When <em>asr=TRUE</em>, the estimates, their variances and standard errors are those of the ancestral states at each node of the tree (this option is not available for the time-series). Note that if there are missing cases, they are first imputed before estimating the ancestral states.
</p>
<p>Estimation of missing cases and ancestral states is performed using GLS (Generalized Least Squares) solution (See Cunningham et al. 1998).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>estimates</code></td>
<td>
<p>The imputed dataset </p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>Variance of the estimates</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Standard error of the estimates</p>
</td></tr>
<tr><td><code>NA_index</code></td>
<td>
<p>Position of the missing cases in the dataset</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Clavel J., Merceron G., Escarguel G. 2014. Missing Data Estimation in Morphometrics: How Much is Too Much? Syst. Biol. 63:203-218.
</p>
<p>Cunningham C.W., Omland K.E., Oakley T.H. 1998. Reconstructing ancestral character states: a critical reappraisal. Trends Ecol. Evol. 13:361-366.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)

# Setting the regime states of tip species
sta&lt;-as.vector(c(rep("Forest",20),rep("Savannah",30))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate two correlated traits evolving along the phylogeny
traits&lt;-mvSIM(tree,nsim=1, model="BMM", param=list(sigma=list(matrix(c(2,1,1,1.5),2,2),
         matrix(c(4,1,1,4),2,2)), names_traits=c("head.size","mouth.size")))

# Introduce some missing cases (NA values)
data&lt;-traits
data[8,2]&lt;-NA
data[25,1]&lt;-NA

# Fit of model 1
fit&lt;-mvBM(tree,data,model="BMM")

# Estimate the missing cases
imp&lt;-estim(tree, data, fit)

# Check the imputed data
imp$estim[1:10,]

## We want the ancestral states values at each nodes:
nodelabels() # To see where the nodes are situated

imp2&lt;-estim(tree, data, fit, asr=TRUE)

# Check the 10 firsts ancestral states
imp2$estim[1:10,]
</code></pre>

<hr>
<h2 id='fitted'>
Extract multivariate gls (or ols) model fitted values
</h2><span id='topic+fitted.mvgls'></span>

<h3>Description</h3>

<p>Returns the fitted values of a linear model of class 'mvgls'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'mvgls'
fitted(object, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted_+3A_object">object</code></td>
<td>

<p>an object of class 'mvgls' obtained from a <code>mvgls</code> or <code>mvols</code> fit.
</p>
</td></tr>
<tr><td><code id="fitted_+3A_...">...</code></td>
<td>

<p>other arguments (not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The fitted values extracted from the model.
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>See Also</h3>

<p><code><a href="#topic+vcov.mvgls">vcov.mvgls</a></code> 
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+coef.mvgls">coef.mvgls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
</p>

<hr>
<h2 id='GIC'>
Generalized Information Criterion (GIC) to compare models fit with <code>mvgls</code> (or <code>mvols</code>) by Maximum Likelihood (ML) or Penalized Likelihood (PL)
</h2><span id='topic+GIC'></span>

<h3>Description</h3>

<p>The GIC (Konishi &amp; Kitagawa 1996) allows comparing models fit by Maximum Likelihood (ML) or Penalized Likelihood (PL).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>

GIC(object, ...)
  
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GIC_+3A_object">object</code></td>
<td>

<p>An object of class 'mvgls'. See ?mvgls or ?mvols</p>
</td></tr>
<tr><td><code id="GIC_+3A_...">...</code></td>
<td>

<p>Options to be passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Generalized Information Criterion (<code>GIC</code>) allows comparing the fit of various models estimated by Penalized Likelihood (see ?<code>mvgls</code> or ?<code>mvols</code>). See also the <code>gic_criterion</code> function in the RPANDA package. Under maximum likelihood (<code>method="LL"</code> in <code>mvgls</code> or <code>mvols</code>) and on large sample sizes, the GIC should converges to the classical AIC (Akaike Information Criterion).
Note that the current implementation of the criterion has not been tested for multiple predictors comparison (especially under REML). Prefer simulation based comparisons or the <code>EIC</code> criterion instead.
</p>


<h3>Value</h3>

<p>a list with the following components
</p>
<table role = "presentation">
<tr><td><code>LogLikelihood</code></td>
<td>
<p>the log-likelihood estimated for the model with estimated parameters</p>
</td></tr>
<tr><td><code>GIC</code></td>
<td>
<p>the GIC criterion</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>the value of the bias term estimated to compute the GIC</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Konishi S., Kitagawa G. 1996. Generalised information criteria in model selection. Biometrika. 83:875-890.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
<code><a href="#topic+manova.gls">manova.gls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(1)
n &lt;- 32 # number of species
p &lt;- 50 # number of traits

tree &lt;- pbtree(n=n) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p), ncol=p)) # a random symmetric matrix (covariance)
# simulate a dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R))

fit1 &lt;- mvgls(Y~1, tree=tree, model="BM", method="H&amp;L")
fit2 &lt;- mvgls(Y~1, tree=tree, model="OU", method="H&amp;L")


GIC(fit1); GIC(fit2)

</code></pre>

<hr>
<h2 id='halflife'>
The phylogenetic half-life for an Ornstein-Uhlenbeck process
</h2><span id='topic+halflife'></span>

<h3>Description</h3>

<p>This function returns the phylogenetic half-life for an Ornstein-Uhlenbeck process (object of class &quot;ou&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>halflife(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="halflife_+3A_object">object</code></td>
<td>

<p>Object fitted with the &quot;mvOU&quot; function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The phylogenetic half-life describes the time to move halfway from the ancestral state to the primary optimum (Hansen, 1997).
The multivariate counterpart is computed on the eigenvalues of the &quot;selection&quot; matrix (Bartoszek et al. 2012).
</p>


<h3>Value</h3>

<p>The phylogenetic half-life computed from each eigenvalues (or alpha for the univariate case)
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Bartoszek K., Pienaar J., Mostad P., Andersson S., Hansen T.F. 2012. A phylogenetic comparative method for studying multivariate adaptation. J. Theor. Biol. 314:204-215.
</p>
<p>Hansen T.F. 1997. Stabilizing selection and the comparative analysis of adaptation. Evolution. 51:1341-1351.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+stationary">stationary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)

# Setting the regime states of tip species
sta&lt;-as.vector(c(rep("Forest",20),rep("Savannah",30))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate the traits
alpha&lt;-matrix(c(2,0.5,0.5,1),2)
sigma&lt;-matrix(c(0.1,0.05,0.05,0.1),2)
theta&lt;-c(2,3,1,1.3)
data&lt;-mvSIM(tree, param=list(sigma=sigma, alpha=alpha, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size")), model="OUM", nsim=1)

## Fitting the models
# OUM - Analysis with multiple optima
result&lt;-mvOU(tree, data)

halflife(result)

</code></pre>

<hr>
<h2 id='LRT'>
Likelihood Ratio Test
</h2><span id='topic+LRT'></span>

<h3>Description</h3>

<p>This function compares the fit of two nested models of trait evolution with a loglikelihood-ratio statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRT(model1, model2, echo = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRT_+3A_model1">model1</code></td>
<td>

<p>The most parameterized model. A fitted object from an mvMORPH model.
</p>
</td></tr>
<tr><td><code id="LRT_+3A_model2">model2</code></td>
<td>

<p>The second model under comparison (fitted object).
</p>
</td></tr>
<tr><td><code id="LRT_+3A_echo">echo</code></td>
<td>

<p>Whether to return the result or not.
</p>
</td></tr>
<tr><td><code id="LRT_+3A_...">...</code></td>
<td>

<p>Options to be passed through. (Not yet available)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LRT function extracts the log-likelihood of two nested models to compute the loglikelihood-ratio statistic which is compared to a Chi-square distribution. Note that if the models are not nested, the LRT is not an appropriate test and you should rely instead on Information criteria, evidence ratios, or simulated distributions (e.g., Lewis et al. 2011).
This can be achieved using the <code>simulate</code> function (see examples below).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>pval</code></td>
<td>
<p>The p-value of the LRT test (comparison with Chi-square distribution).</p>
</td></tr>
<tr><td><code>ratio</code></td>
<td>
<p>The LRT (Loglikelihood-ratio test) statistic.</p>
</td></tr>
<tr><td><code>ddf</code></td>
<td>
<p>The number of degrees of freedom between the two models.</p>
</td></tr>
<tr><td><code>model1</code></td>
<td>
<p>Name of the first model.</p>
</td></tr>
<tr><td><code>model2</code></td>
<td>
<p>Name of the second model.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>When comparing BM models to OU models, the LRT test might not be at it's nominal level. You should prefer a simulations based test.</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Neyman J., Pearson E.S. 1933. On the problem of the most efficient tests of statistical hypotheses. Philos. Trans. R. Soc. A. 231:289-337.
</p>
<p>Lewis F., Butler A., Gilbert L. 2011. A unified approach to model selection using the likelihood ratio test. Meth. Ecol. Evol. 2:155-162.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)

# Setting the regime states of tip species
sta&lt;-as.vector(c(rep("Forest",20),rep("Savannah",30))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate two correlated traits evolving along the phylogeny
traits&lt;-mvSIM(tree,nsim=1, model="BMM", param=list(sigma=list(matrix(c(2,1,1,1.5),2,2),
         matrix(c(4,1,1,4),2,2)), ntraits=2, names_traits=c("head.size","mouth.size")))

# Fit of model 1
mod1&lt;-mvBM(tree,traits,model="BMM")

# Fit of model 2
mod2&lt;-mvBM(tree,traits,model="BM1")

# comparing the fit using LRT...
LRT(mod1,mod2)



# Simulation based test
nsim = 500
boot &lt;- simulate(mod2, tree=tree, nsim=nsim)
simulations &lt;- sapply(1:nsim, function(i){
  mod1boot&lt;-mvBM(tree, boot[[i]], model="BMM", diagnostic=FALSE, echo=FALSE)
  mod2boot&lt;-mvBM(tree, boot[[i]], model="BM1", diagnostic=FALSE, echo=FALSE, method="pic")
  2*(mod1boot$LogLik-mod2boot$LogLik)
})

# Compute the p-value
LRT_stat&lt;-(2*((mod1$LogLik-mod2$LogLik)))
mean(simulations&gt;=LRT_stat)

plot(density(simulations), main="Non-parametric LRT");
abline(v=LRT_stat, col="red")


</code></pre>

<hr>
<h2 id='manova.gls'>
Multivariate Analysis of Variance
</h2><span id='topic+manova.gls'></span>

<h3>Description</h3>

<p>Performs a Multivariate Analysis of Variance (MANOVA) on an object fitted by the <code>mvgls</code> or the <code>mvols</code> function. With the regularized methods by penalized likelihood implemented in <code>mvgls</code> and <code>mvols</code> (ridgeArch penalty), this function can be used to compare model fit on high-dimensional datasets (where the number of variables is larger than the number of observations). When model fit is performed by maximum likelihood (<code>method="LL"</code>), both parametric and permutation tests are possible.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
manova.gls(object, test=c("Pillai", "Wilks", "Hotelling-Lawley", "Roy"),
            type=c("I","II","III"), nperm=1000L, L=NULL, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="manova.gls_+3A_object">object</code></td>
<td>

<p>A model fit obtained by the <code>mvgls</code> or <code>mvols</code> function.</p>
</td></tr>
<tr><td><code id="manova.gls_+3A_test">test</code></td>
<td>

<p>The multivariate test statistic to compute - &quot;Wilks&quot;, &quot;Pillai&quot;, &quot;Hotelling-Lawley&quot;, or &quot;Roy&quot;</p>
</td></tr>
<tr><td><code id="manova.gls_+3A_type">type</code></td>
<td>

<p>The type of test (sums of squares and cross-products) - &quot;I&quot;, &quot;II&quot;, or &quot;III&quot;</p>
</td></tr>
<tr><td><code id="manova.gls_+3A_nperm">nperm</code></td>
<td>

<p>The number of permutations used for building the null distribution of the chosen statistic. Permutation is the only available approach for high-dimensional PL models, but either permutations or parametric tests can be used with maximum likelihood (method &quot;LL&quot; in <code>mvgls</code> and <code>mvols</code>)</p>
</td></tr>
<tr><td><code id="manova.gls_+3A_l">L</code></td>
<td>

<p>A (contrasts) matrix or a vector giving linear combinations of the coefficients rows.</p>
</td></tr>
<tr><td><code id="manova.gls_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed through. (e.g., <code>nbcores=2L</code> to provide the number of cores used for parallel calculus; <code>parametric=FALSE</code> to obtain permutation instead of parametric tests for maximum likelihood fit; <code>verbose=TRUE</code> to display a progress bar during permutations; <code>rhs=0</code> the &quot;right-hand-side&quot; vector for general linear hypothesis testing; <code>P</code> can be used to specify a matrix of contrasts giving linear combinations of the coefficient columns. See details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>manova.gls</code> allows performing multivariate tests (e.g. Pillai's, Wilks, Hotelling-Lawley and Roy largest root) on generalized least squares (GLS) linear model (objects of class &quot;mvgls&quot;, or OLS with objects of class &quot;mvols&quot;) fit by either maximum likelihood (<code>method="LL"</code>) or penalized likelihood (<code>method="PL-LOO"</code>) using the <code>mvgls</code> or <code>mvols</code> function.
</p>
<p>General Linear Hypothesis of the form:
</p>
<p style="text-align: center;"><code class="reqn">\bold{LB=O}</code>
</p>
<p> or </p>
<p style="text-align: center;"><code class="reqn">\bold{LBP=O}</code>
</p>

<p>Where <b>L</b> is a matrix specifying linear combinations of the model coefficients (<b>B</b>) can be provided through the argument <code>L</code>. This type of &quot;contrasts&quot; matrix allows testing specific hypotheses (for instance pairwise differences - see <code>?pairwise.contrasts</code> and <code>?pairwise.glh</code>). The right-hand-side matrix <b>O</b> is a constant matrix (of zeros by default) that can be provided through the argument <code>rhs</code>. <b>P</b> is a matrix specifying linear combinations of the model coefficients (<b>B</b>) estimated for each responses (usually used in repeated measures designs or for testing linear, quadratic, etc. relationships between successive responses).
</p>
<p>Permutations on high-dimensional datasets is time consuming. You can use the option <code>nbcores</code> to parallelize the calculus over several cores using forking in UNIX platforms (default is <code>nbcores=1L</code>. Estimated time to completion is displayed when <code>verbose=TRUE</code>.
</p>


<h3>Value</h3>

<p>An object of class 'manova.mvgls' which is usually printed. It contains a list including the following components:
</p>
<table role = "presentation">
<tr><td><code>test</code></td>
<td>
<p>the multivariate test statistic used</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>the type of tests used to compute the SSCP matrices</p>
</td></tr>
<tr><td><code>stat</code></td>
<td>
<p>the statistic calculated for each terms in the model</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>the pvalues calculated for each terms in the model</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For PL methods, only the &quot;RidgeArch&quot; penalty is allowed for now.
A tutorial is available from Dryad: https://doi.org/10.5061/dryad.jsxksn052
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Clavel, J., Morlon, H. 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+pairwise.glh">pairwise.glh</a></code>,
<code><a href="#topic+GIC">GIC</a></code>,
<code><a href="#topic+EIC">EIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# ---------------------------------------------------- #
# Multivariate regression tests (continuous predictor) #
# ---------------------------------------------------- #

set.seed(1)
n &lt;- 32 # number of species
p &lt;- 30 # number of traits

tree &lt;- pbtree(n=n) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p),p))  # a random symmetric matrix (covariance)

# simulate a dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R))
X &lt;- rnorm(n) # continuous
grp &lt;- rep(1:2, each=n/2)
dataset &lt;- list(y=Y, x=X, grp=as.factor(grp))

# Model fit
model1 &lt;- mvgls(y~x, data=dataset, tree=tree, model="BM", method="LOO")

# Multivariate test
(multivariate_test &lt;- manova.gls(model1, nperm=999, test="Pillai"))

# ---------------------------------------------------- #
# Multivariate regression tests (discrete predictor)   #
# ---------------------------------------------------- #

# MANOVA on a binary predictor
model2 &lt;- mvgls(y~grp, data=dataset, tree=tree, model="lambda", method="LOO")

# Multivariate test
(multivariate_test &lt;- manova.gls(model2, nperm=999, test="Pillai", verbose=TRUE))

# ---------------------------------------------------- #
# Parametric MANOVA tests                              #
# ---------------------------------------------------- #

# When p&lt;n we can use non-penalized approaches and parametric tests
model2b &lt;- mvgls(y[,1:2]~grp, data=dataset, tree=tree, model="lambda", method="LL")
(multivariate_test2b &lt;- manova.gls(model2b, test="Pillai"))

# ---------------------------------------------------- #
# Multivariate contrasts tests                         #
# ---------------------------------------------------- #

# Multivariate contrasts allow testing specific hypotheses 
# (see also ?pairwise.glh and ?pairwise.contrasts)

# We can replicate the above result by testing if the
# group means are different using the following contrast:
L = matrix(c(0,1), ncol=2)
(manova.gls(model2b, test="Pillai", L=L))

# ---------------------------------------------------- #
# Repeated measures design tests                       #
# ---------------------------------------------------- #

# Contrasts can be used also to test if there's differences
# between repeated measures (responses variables)
# For instance, for comparing y[,1] and y[,2], define the contrast:
P = matrix(c(1,-1), nrow=2)
(manova.gls(model2b, test="Pillai", P=P, L=L))


</code></pre>

<hr>
<h2 id='mv.Precalc'>
Model parameterization for the various mvMORPH functions
</h2><span id='topic+mv.Precalc'></span>

<h3>Description</h3>

<p>This function allows computing the fixed parameters or objects needed by the mvMORPH functions. This could be useful for bootstrap-like computations (see exemple)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mv.Precalc(tree, nb.traits = 1, scale.height = FALSE, param = list(pivot = "MMD",
            method = c("sparse"), smean = TRUE, model = "OUM"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mv.Precalc_+3A_tree">tree</code></td>
<td>

<p>A &quot;phylo&quot; (or SIMMAP like) object representing the tree for which we want to precalculate parameters.
</p>
</td></tr>
<tr><td><code id="mv.Precalc_+3A_nb.traits">nb.traits</code></td>
<td>

<p>The number of traits involved in the subsequent analysis.
</p>
</td></tr>
<tr><td><code id="mv.Precalc_+3A_scale.height">scale.height</code></td>
<td>

<p>Whether the tree should be scaled to unit length or not.
</p>
</td></tr>
<tr><td><code id="mv.Precalc_+3A_param">param</code></td>
<td>

<p>A list of parameters used in the computations (see details)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mv.Precalc function allows the pre-computation of the fixed parameters required by the different mvMORPH models (e.g., the design matrix, the vcv matrix, the sparsity structure...).
In the &quot;param&quot; list you should provide the details about the model fit:
</p>
<p>-model name (e.g., &quot;OUM&quot;, &quot;OU1&quot;)
</p>
<p>-method (which kind of algorithm is used for computing the log-likelihood).
</p>
<p>-smean (whether there is one ancestral state per trait or per selective regimes - for mvBM only).
</p>
<p>Additional parameters can be fixed:
</p>
<p>-root (estimation of the ancestral state for the Ornstein-Uhlenbeck model; see ?mvOU).
</p>
<p>-pivot (pivot method used by the &quot;sparse&quot; matrix method for computing the log-likelihood; see ?spam).
</p>


<h3>Value</h3>

<p>An object of class &quot;mvmorph.precalc&quot; which can be used in the &quot;precalc&quot; argument of the various mvMORPH functions.
</p>


<h3>Note</h3>

<p>This function is mainly used internally; it is still in development. A misuse of this functions can result in a crash of the R session.
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvLL">mvLL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)

# Simulate two correlated traits evolving along the phylogeny according to a
# Ornstein-Uhlenbeck process
alpha&lt;-matrix(c(2,1,1,1.3),2,2)
sigma&lt;-matrix(c(1,0.5,0.5,0.8),2,2)
theta&lt;-c(3,1)
nsim&lt;-50
simul&lt;-mvSIM(tree,param=list(sigma=sigma, alpha=alpha, ntraits=2, theta=theta,
             names_traits=c("head.size","mouth.size")), model="OU1", nsim=nsim)

# Do the pre-calculations
precal&lt;-mv.Precalc(tree,nb.traits=2, param=list(method="sparse",model="OU1", root=FALSE))

mvOU(tree, simul[[1]], method="sparse", model="OU1", precalc=precal,
    param=list(decomp="cholesky"))

### Bootstrap

# Fit the model to the "nsim" simulated datasets
 results&lt;-lapply(1:nsim,function(x){
 mvOU(tree, simul[[x]], method="sparse", model="OU1", precalc=precal,
    param=list(decomp="cholesky"),
    echo=FALSE, diagnostic=FALSE)
 })

### Use parallel package
 library(parallel)
if(.Platform$OS.type == "unix"){
  number_of_cores&lt;-2L # Only working on Unix systems
}else{
  number_of_cores&lt;-1L
} 

 results&lt;-mclapply(simul, function(x){
    mvOU(tree, x, method="sparse", model="OU1", precalc=precal,
       param=list(decomp="cholesky"), echo=FALSE, diagnostic=FALSE)
 }, mc.cores = getOption("mc.cores", number_of_cores))


# Summarize (we use the generic S3 method "logLik" to extract the log-likelihood)
loglik&lt;-sapply(results,logLik)
hist(loglik)
	
</code></pre>

<hr>
<h2 id='mvBM'>
Multivariate Brownian Motion models of continuous traits evolution
</h2><span id='topic+mvBM'></span>

<h3>Description</h3>

<p>This function allows the fitting of multivariate multiple rates of evolution under a Brownian Motion model. This function can also fit constrained models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvBM(tree, data, error = NULL, model = c("BMM", "BM1"), 
    param = list(constraint = FALSE, smean = TRUE, trend=FALSE), 
    method = c("rpf", "pic", "sparse", "inverse", "pseudoinverse"),
    scale.height = FALSE, optimization = c("L-BFGS-B", "Nelder-Mead", "subplex"),
    control = list(maxit = 20000), precalc = NULL, diagnostic = TRUE, echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvBM_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree in SIMMAP format by default. A &quot;phylo&quot; object can also be used with the &quot;BM1&quot; model.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits in columns (preferentially with names and in the same order than in the tree). NA values are allowed with the &quot;rpf&quot;, &quot;inverse&quot;, and &quot;pseudoinverse&quot; methods.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous trait sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_model">model</code></td>
<td>

<p>&quot;BMM&quot; for multi-rate and multi-selective regimes, and &quot;BM1&quot; for a unique rate of evolution per trait.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_param">param</code></td>
<td>

<p>List of arguments to be passed to the function. See details.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_method">method</code></td>
<td>

<p>Choose between &quot;rpf&quot;, &quot;sparse&quot;, &quot;inverse&quot;, &quot;pseudoinverse&quot;, or &quot;pic&quot; for log-likelihood computation during the fitting process. See details.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_scale.height">scale.height</code></td>
<td>

<p>Whether the tree should be scaled to unit length or not.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_optimization">optimization</code></td>
<td>

<p>Methods used by the optimization routines (see ?optim and ?subplex for details). The &quot;fixed&quot; method returns the log-likelihood function only.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_control">control</code></td>
<td>

<p>Max. bound for the number of iteration of the optimizer; other options can be fixed in the list (see ?optim or ?subplex).
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_precalc">precalc</code></td>
<td>

<p>Optional. Precalculation of fixed parameters. See ?mvmorph.Precalc.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_diagnostic">diagnostic</code></td>
<td>

<p>Whether the diagnostics of convergence should be returned or not.
</p>
</td></tr>
<tr><td><code id="mvBM_+3A_echo">echo</code></td>
<td>

<p>Whether the results must be returned or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mvBM function fits a homogeneous multivariate Brownian Motion (BM) process:
</p>
<p style="text-align: center;"><code class="reqn">dX(t) = \Sigma^{1/2}dW(t)</code>
</p>

<p>With possibly multiple rates (<code class="reqn">\Sigma_i</code>) in different parts (&quot;i&quot; selective regimes) of the tree (see O'Meara et al., 2006; Revell and Collar, 2009, see also details of the implementation in Clavel et al. 2015). Note that the function uses the non-censored approach of O'Meara et al. (2006) by default (i.e., a common ancestral state is assumed for the different regimes), but it is possible to specify multiple ancestral states (i.e., one for each regime) through the &quot;smean&quot; parameter (smean=FALSE) in the &quot;param&quot; list.
</p>
<p>The &quot;method&quot; argument allows the user to try different algorithms for computing the log-likelihood. The <code>"rpf"</code> and <code>"sparse"</code> methods use fast GLS algorithms based on factorization for avoiding the computation of the inverse of the variance-covariance matrix and its determinant involved in the log-likelihood estimation. The <code>"inverse"</code> approach uses the &quot;stable&quot; standard explicit computation of the inverse and determinant of the matrix and is therefore slower. The <code>"pseudoinverse"</code> method uses a generalized inverse that is safer for matrix near singularity but highly time consuming. The <code>"pic"</code> method uses a very fast algorithm based on independent contrasts. It should be used with strictly dichotomic trees (i.e., no polytomies) and is currently not available for the multivariate &quot;BMM&quot; model. See ?mvLL for more details on these computational methods.
</p>
<p>The <b>&quot;param&quot;</b> <code>list</code> arguments:
</p>
<p><b>&quot;constraint&quot;</b> - The &quot;constraint&quot; argument in the &quot;param&quot; list allows the user to compute the joint likelihood for each trait by assuming they evolved independently (<b> constraint=&quot;diagonal&quot;</b>, or <b> constraint=&quot;equaldiagonal&quot;</b>). If <b> constraint=&quot;equal&quot;</b>, the sigma values are constrained to be the same for each studied trait using the constrained Cholesky decomposition proposed by Adams (2013) or a separation strategy based on spherical parameterization (when p&gt;2) because of an unstable behavior observed for the constrained Cholesky (Clavel et al. 2015).
</p>
<p>This approach is extended here to the multi-rate case by specifying that the rates must be the same in different parts of the tree (common selective regime). It's also possible to constraint the rate matrices in the &quot;BMM&quot; model to share the same eigen-vectors (<code>constraint="shared"</code>); the same variance but different covariances (<code> constraint="variance"</code>); the same correlation but different variances (<code> constraint="correlation"</code>); or to fit a model with different but proportional rates matrices (<code>constraint="proportional"</code>).
</p>
<p>Finally, user-defined constrained models can be specified through a numeric matrix (square and symmetric) with integer values taken as indices of the parameters. For instance, for three traits:
</p>
<p><code>constraint=matrix(c(1,3,3,3,2,3,3,3,2),3)</code>. 
</p>
<p>Covariances constrained to be zero are introduced by NA values, e.g., 
</p>
<p><code>constraint=matrix(c(1,4,4,4,2,NA,4,NA,3),3)</code>.
</p>
<p>Difference between two nested fitted models can be assessed using the &quot;LRT&quot; function. See example below and ?LRT.
</p>
<p><b> &quot;decomp&quot;</b> - For the general case (unconstrained models), the sigma matrix is parameterized by various methods to ensure its positive definiteness (Pinheiro and Bates, 1996). These methods are the &quot;cholesky&quot;, &quot;eigen+&quot;, and &quot;spherical&quot; parameterizations.
</p>
<p><b>&quot;smean&quot;</b> - Default set to TRUE. If FALSE, the ancestral state for each selective regime is estimated (e.g., Thomas et al., 2006).
</p>
<p><b>&quot;trend&quot;</b> - Default set to FALSE. If TRUE, the ancestral state is allowed to drift linearly with time. This model is identifiable only with non-ultrametric trees. Note that it is possible to provide a vector of integer indices to constrain the estimated trends (see the vignettes).
</p>
<p><b>&quot;sigma&quot;</b> - Starting values for the likelihood estimation. By default the theoretical expected values are used as starting values for the likelihood optimization (for measurement errors, multiple rates,...). The user can specify starting values with a list() object for the &quot;BMM&quot; model (e.g., two objects in the list for a two-regime analysis), or a simple vector of values for the &quot;BM1&quot; model. The parameterization is done using various factorizations for symmetric matrices (e.g., for the &quot;decomp&quot; argument; Pinheiro &amp; Bates, 1996). Thus, you should provide p*(p+1)/2 values, with p the number of traits (e.g., random numbers or the values from the cholesky factor of a symmetric positive definite sigma matrix; see example below). If a constrained model is used, the number of starting values is (p*(p-1)/2)+1.
</p>
<p>If no selective regime is specified the function works only with the model &quot;BM1&quot;.
</p>
<p>N.B.: Mapping of ancestral states can be done using the &quot;make.simmap&quot;, &quot;make.era.map&quot; or &quot;paintSubTree&quot; functions from the &quot;phytools&quot; package.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>LogLik</code></td>
<td>
<p>The log-likelihood of the optimal model.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion for the optimal model.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>Sample size-corrected AIC.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated ancestral states.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Evolutionary rate matrix for each selective regime.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence status of the optimizing function; &quot;0&quot; indicates convergence (See ?optim for details).</p>
</td></tr>
<tr><td><code>hess.values</code></td>
<td>
<p>Reliability of the likelihood estimates calculated through the eigen-decomposition of the hessian matrix. &quot;0&quot; means that a reliable estimate has been reached. (See ?mvOU).</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>List of model fit parameters (optimization, method, model, number of parameters...).</p>
</td></tr>
<tr><td><code>llik</code></td>
<td>
<p>The log-likelihood function evaluated in the model fit &quot;$llik(par, root.mle=TRUE)&quot;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The &quot;pic&quot; method is not yet implemented for the multivariate &quot;BMM&quot; model.
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Adams D.C. 2013. Comparing evolutionary rates for different phenotypic traits on a phylogeny using likelihood. Syst. Biol. 62:181-192.
</p>
<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods Ecol. Evol. 6(11):1311-1319.
</p>
<p>O'Meara B.C., Ane C., Sanderson M.J., Wainwright P.C. 2006. Testing for different rates of continuous trait evolution. Evolution. 60:922-933.
</p>
<p>Revell L.J. 2012. phytools: An R package for phylogenetic comparative biology (and other things). Methods Ecol. Evol. 3:217-223.
</p>
<p>Revell L.J., Collar D.C. 2009. Phylogenetic analysis of the evolutionary correlation using likelihood. Evolution. 63:1090-1100.
</p>
<p>Thomas G.H., Freckleton R.P., Szekely T. 2006. Comparative analyses of the influence of developmental mode on phenotypic diversification rates in shorebirds. Proc. R. Soc. B. 273:1619-1624.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvOUTS">mvOUTS</a></code>
<code><a href="#topic+mvRWTS">mvRWTS</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
<code><a href="#topic+LRT">LRT</a></code>
<code><a href="stats.html#topic+optim">optim</a></code>
<code><a href="phytools.html#topic+brownie.lite">brownie.lite</a></code>
<code><a href="phytools.html#topic+evol.vcv">evol.vcv</a></code>
<code><a href="phytools.html#topic+make.simmap">make.simmap</a></code>
<code><a href="phytools.html#topic+make.era.map">make.era.map</a></code>
<code><a href="phytools.html#topic+paintSubTree">paintSubTree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)

# Setting the regime states of tip species
sta&lt;-as.vector(c(rep("Forest",20),rep("Savannah",30))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate the traits
sigma&lt;-matrix(c(0.1,0.05,0.05,0.1),2)
theta&lt;-c(0,0)
data&lt;-mvSIM(tree, param=list(sigma=sigma, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size")), model="BM1", nsim=1)

## Fitting the models
# BMM - Analysis with multiple rates
mvBM(tree, data)

# BM1 - Analysis with a unique rate matrix
fit1&lt;-mvBM(tree, data, model="BM1", method="pic")

# BM1 constrained
fit2&lt;-mvBM(tree, data, model="BM1", method="pic", param=list(constraint="equal"))

# Comparison with LRT test
LRT(fit1,fit2)

# Random starting values
mvBM(tree, data, model="BMM", method="sparse", param=list(sigma=list(runif(3), runif(3))))

# Specified starting values (from the Cholesky factor)
chol_factor&lt;-chol(sigma)
starting_values&lt;-chol_factor[upper.tri(chol_factor,TRUE)]
mvBM(tree, data, model="BMM", method="sparse",
    param=list( sigma=list(starting_values, starting_values)))


# Multiple mean
mvBM(tree, data, model="BMM", method="sparse", param=list(smean=FALSE))


# Introduce some missing cases (NA values)
data2&lt;-data
data2[8,2]&lt;-NA
data2[25,1]&lt;-NA

mvBM(tree, data2, model="BM1")


## FAST FOR THE UNIVARIATE CASE!!

 set.seed(14)
 tree2&lt;-pbtree(n=5416) # Number of Mammal species
# Setting the regime states of tip species
 sta&lt;-as.vector(c(rep("group_1",2000),rep("group_2",3416))); names(sta)&lt;-tree2$tip.label

# Making the simmap tree with mapped states
 tree2&lt;-make.simmap(tree2,sta , model="ER", nsim=1)
 col&lt;-c("blue","orange"); names(col)&lt;-c("Group_1","Group_2")
 plotSimmap(tree2,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate a trait evolving by brownian motion on the tree
 trait&lt;-rTraitCont(tree2)

# Fitting the models
 mvBM(tree2, trait, model="BMM", method="pic")
 mvBM(tree2, trait, model="BM1", method="pic")


</code></pre>

<hr>
<h2 id='mvEB'>
Multivariate Early Burst model of continuous traits evolution
</h2><span id='topic+mvEB'></span>

<h3>Description</h3>

<p>This function fits to a multivariate dataset of continuous traits a multivariate Early Burst (EB) or ACDC models of evolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvEB(tree, data, error = NULL, param = list(up = 0), method = 
	c("rpf", "sparse", "inverse", "pseudoinverse", "pic"), scale.height =
	 FALSE, optimization = c("Nelder-Mead", "L-BFGS-B", "subplex"), 
	 control = list(maxit = 20000), precalc = NULL, diagnostic = TRUE, 
	 echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvEB_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree (phylo object).
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits in columns (preferentially with names and in the same order than in the tree). NA values are allowed with the &quot;rpf&quot;, &quot;inverse&quot;, and &quot;pseudoinverse&quot; methods.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous trait sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_param">param</code></td>
<td>

<p>List of arguments to be passed to the function. See details.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_method">method</code></td>
<td>

<p>Choose between &quot;rpf&quot;, &quot;sparse&quot;, &quot;inverse&quot;, &quot;pseudoinverse&quot;, or &quot;pic&quot; for computing the log-likelihood during the fitting process. See details.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_scale.height">scale.height</code></td>
<td>

<p>Whether the tree should be scaled to unit length or not.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_optimization">optimization</code></td>
<td>

<p>Methods used by the optimization routines (see ?optim and ?subplex for details). The &quot;fixed&quot; method returns the log-likelihood function only.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_control">control</code></td>
<td>

<p>Max. bound for the number of iteration of the optimizer; other options can be fixed in the list (see ?optim or ?subplex for details).
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_precalc">precalc</code></td>
<td>

<p>Optional. Precalculation of fixed parameters. See ?mvmorph.Precalc for details.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_diagnostic">diagnostic</code></td>
<td>

<p>Whether the diagnostics of convergence should be returned or not.
</p>
</td></tr>
<tr><td><code id="mvEB_+3A_echo">echo</code></td>
<td>

<p>Whether the results must be returned or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Early Burst model (Harmon et al. 2010) is a special case of the ACDC model of Blomberg et al. (2003). Using an upper bound larger than zero transform the EB model to the accelerating rates of character evolution of Blomberg et al. (2003).
</p>
<p>The &quot;method&quot; argument allows the user to try different algorithms for computing the log-likelihood. The &quot;rpf&quot; and &quot;sparse&quot; methods use fast GLS algorithms based on factorization for avoiding the computation of the inverse of the variance-covariance matrix and its determinant for the log-likelihood estimation. The &quot;inverse&quot; approach uses the &quot;stable&quot; standard explicit computation of the inverse and determinant of the matrix and is therefore slower. The &quot;pseudoinverse&quot; method uses a generalized inverse that is safer for matrix near singularity but highly time consuming. The &quot;pic&quot; method uses a very fast algorithm based on independent contrasts. See ?mvLL for more details on these computational methods.
</p>
<p>The &quot;param&quot; list can be used to set the lower (low) and upper (up, default value is 0 - i.e., Early Burst model) bounds for the estimation of the exponential rate (beta). The default lower bound for decelerating rates (as assumed in Early Burst) is fixed as log(min.rate) / T, where T is the depth of the tree and min.rate is the minimum rate that could be assumed for the model (following Slater and Pennell, 2014; log(10^-5)/T). Bounds may need to be adjusted by the user for specific cases.
</p>
<p>Starting values for &quot;sigma&quot; and &quot;beta&quot; could also be provided through the &quot;param&quot; list.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>LogLik</code></td>
<td>
<p>The log-likelihood of the optimal model.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion for the optimal model.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>Sample size-corrected AIC.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated ancestral states.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Exponent rate (of decay or increase).</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Evolutionary rate matrix for each selective regimes.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence status of the optimizing function; &quot;0&quot; indicates convergence (see ?optim for details).</p>
</td></tr>
<tr><td><code>hess.values</code></td>
<td>
<p>Reliability of the likelihood estimates calculated through the eigen-decomposition of the hessian matrix. &quot;0&quot; means that a reliable estimate has been reached. (see ?mvOU for details).</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>List of model fit parameters (optimization, method, model, number of parameters...).</p>
</td></tr>
<tr><td><code>llik</code></td>
<td>
<p>The log-likelihood function evaluated in the model fit &quot;$llik(par, root.mle=TRUE)&quot;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The derivative-free &quot;Nelder-Mead&quot; optimization method is used as default setting instead of &quot;L-BFGS-B&quot;.
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Blomberg S.P., Garland T.J., Ives A.R. 2003. Testing for phylogenetic signal in comparative data: behavioral traits are more labile. Evolution. 57:717-745.
</p>
<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods Ecol. Evol. 6(11):1311-1319.
</p>
<p>Harmon L.J., Losos J.B., Davies J.T., Gillespie R.G., Gittleman J.L., Jennings B.W., Kozak K.H., McPeek M.A., Moreno-Roark F., Near T.J., Purvis A., Ricklefs R.E., Schluter D., Schulte II J.A., Seehausen O., Sidlauskas B.L., Torres-Carvajal O., Weir J.T., Mooers A.O. 2010. Early bursts of body size and shape evolution are rare in comparative data. Evolution. 64:2385-2396.
</p>
<p>Slater G.J., Pennell M. 2014. Robust regression and posterior predictive simulation increase power to detect early bursts of trait evolution. Syst. Biol. 63: 293-308.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvOUTS">mvOUTS</a></code>
<code><a href="#topic+mvRWTS">mvRWTS</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
<code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50, scale=10)

# Simulate the traits
sigma&lt;-matrix(c(0.1,0.05,0.05,0.1),2)
theta&lt;-c(0,0)
beta&lt;- -0.34 # 5 phylogenetic half-life ( log(2)/ (10/5) )
data&lt;-mvSIM(tree, param=list(sigma=sigma, beta=beta, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size")), model="EB", nsim=1)

## Fitting the models
mvEB(tree, data)
mvEB(tree, data, method="pic")
mvEB(tree, data, method="pic", param=list(low=log(10^-5)/10)) # avoid internal estimation

# ACDC
# Note that the AC model is not differentiable from an OU model on ultrametric trees.
beta&lt;- 0.34
data&lt;-mvSIM(tree, param=list(sigma=sigma, beta=beta, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size")), model="EB", nsim=1)

fit&lt;-mvEB(tree, data, method="pic", param=list(up=2, low=-2))

logLik(fit)
AIC(fit)
summary(fit)

</code></pre>

<hr>
<h2 id='mvgls'>
Fit linear model using Generalized Least Squares to multivariate (high-dimensional) data sets
</h2><span id='topic+mvgls'></span>

<h3>Description</h3>

<p>This function uses maximum likelihood (or restricted likelihood) and penalized likelihood approaches to fit linear models where the errors are allowed to be correlated (i.e. a GLS model for serially correlated phylogenetic and time-series data). <code>mvgls</code> uses a penalized-likelihood (PL) approach (see descriptions in Clavel et al. 2019) to fit linear models to high-dimensional data sets (where the number of variables <em>p</em> is approaching or is larger than the number of observations <em>n</em>). The PL approach generally provides improved estimates compared to ML.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvgls(formula, data, tree, model, method=c("PL-LOOCV","LL"),
      REML=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

 
<table role = "presentation">
<tr><td><code id="mvgls_+3A_formula">formula</code></td>
<td>

<p>An object of class &quot;<code>formula</code>&quot; (a two-sided linear formula describing the model to be fitted. See for instance ?<code>lm</code>)
</p>
</td></tr>
<tr><td><code id="mvgls_+3A_data">data</code></td>
<td>

<p>An optional list, data.frame or environment containing the variables in the model. If not found in <em>data</em> the variables are taken from the current environment. Prefer <code>list</code> for blocks of multivariate responses unless you're specifying the response variables by their names using <code>cbind</code> with data.frame.
</p>
</td></tr>
<tr><td><code id="mvgls_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree (an object of class &quot;<code>phylo</code>&quot;) or a time-series object (not yet available).
</p>
</td></tr>
<tr><td><code id="mvgls_+3A_model">model</code></td>
<td>

<p>The evolutionary model: &quot;BM&quot; is Brownian Motion, &quot;OU&quot; is Ornstein-Uhlenbeck, &quot;EB&quot; is Early Burst, &quot;lambda&quot; is Pagel's lambda transformation, and &quot;BMM&quot; is a multi-rates Brownian motion (needs a tree of class &quot;simmap&quot;).
</p>
</td></tr>
<tr><td><code id="mvgls_+3A_method">method</code></td>
<td>

<p>The method used to fit the model. &quot;PL-LOOCV&quot; (or equivalently just &quot;LOOCV&quot;) is the nominal leave one out cross-validation of the penalized log-likelihood, &quot;LL&quot; is the log-likelihood (used in the conventional ML and REML estimation). Two approximated LOOCV methods are also available: &quot;H&amp;L&quot; and &quot;Mahalanobis&quot;. The method &quot;H&amp;L&quot; is a fast LOOCV approach based on Hoffbeck and Landgrebe (1996) tricks, and &quot;Mahalanobis&quot; is an approximation of the LOOCV score proposed by Theiler (2012). Both &quot;H&amp;L&quot; and &quot;Mahalanobis&quot; work only with the &quot;RidgeArch&quot; penalty and for intercept only models (i.e. of the form Y~1, see also details). In such a situation, we recommend the use of &quot;H&amp;L&quot;&quot; (which will coincide with &quot;PL-LOOCV&quot;) over the &quot;Mahalanobis&quot; approach.
</p>
</td></tr>
<tr><td><code id="mvgls_+3A_reml">REML</code></td>
<td>

<p>Use REML (default) or ML for estimating the parameters.
</p>
</td></tr>
<tr><td><code id="mvgls_+3A_...">...</code></td>
<td>

<p>Options to be passed through. For instance the type of penalization: 
<code>penalty="RidgeArch"</code> (default), <code>penalty="RidgeAlt"</code>, or <code>penalty="LASSO"</code>. The target matrices used by &quot;RidgeArch&quot; and &quot;RidgeAlt&quot; penalizations: <code>target="unitVariance"</code>, <code>target="Variance"</code> or <code>target="null"</code>... etc. (see details)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mvgls</code> allows fitting various multivariate linear models to multivariate (possibly high-dimensional, i.e. where the number of variables <em>p</em> is larger than <em>n</em>) datasets for which the residuals have a correlated structure (e.g. evolutionary models such as BM and OU). Models estimated using penalized likelihood (e.g., method=&quot;PL-LOOCV&quot;) are generally more accurate than those estimated by maximum likelihood methods (method=&quot;LL&quot;) when the number of traits approach the number of species. PL is the only solution when <em>p</em>&gt;<em>n</em>.  Models fit can be compared using the GIC or EIC criterion (see ?<code>GIC</code> and ?<code>EIC</code>) and hypothesis testing can be performed using the <code>manova.gls</code> function.
</p>
<p>The tree is assumed to be fully dichotomic and in &quot;postorder&quot;, otherwise the functions <code>multi2di</code> and <code>reorder.phylo</code> are used internally. Note that for the &quot;BMM&quot; model, a tree of class &quot;simmap&quot; must be provided to scale the BM variance-covariance matrix in different parts of the tree (see also <code>mvBM</code>).
</p>
<p>To fit an ordinary multivariate linear model (possibly regularized), one can uses the <code>mvols</code> function instead.
</p>
<p>The various <em>arguments</em> that can be passed through <b>&quot;...&quot;</b>:
</p>
<p><b>&quot;penalty&quot;</b> - The &quot;penalty&quot; argument allows specifying the type of penalization used for regularization (described in Clavel et al. 2019). The various penalizations are: <code>penalty="RidgeArch"</code> (the default), <code>penalty="RidgeAlt"</code> and <code>penalty="LASSO"</code>. The &quot;RidgeArch&quot; penalization shrink linearly the &quot;sample&quot;&quot; covariance matrix toward a given target matrix with a specific structure (see below for <code>target</code>). This penalization is generally fast and the tuning parameter is bounded between 0 and 1 (see van Wieringen &amp; Peeters 2016, Clavel et al. 2019). The &quot;RidgeAlt&quot; penalization scheme uses a quadratic ridge penalty to shrink the covariance matrix toward a specified target matrix (see <code>target</code> below and also see van Wieringen &amp; Peeters 2016). Finally, the &quot;LASSO&quot; regularize the covariance matrix by estimating a sparse estimate of its inverse - the precision matrix (Friedman et al. 2008). Solving the LASSO penalization is computationally intensive. Moreover, this penalization scheme is not invariant to arbitrary rotations of the data.
</p>
<p><b>&quot;target&quot;</b> - This argument allows specifying the target matrix toward which the covariance matrix is shrunk for &quot;Ridge&quot; penalties. <code>target="unitVariance"</code> (for a diagonal target matrix proportional to the identity) and <code>target="Variance"</code> (for a diagonal matrix with unequal variance) can be used with both &quot;RidgeArch&quot; and &quot;RidgeAlt&quot; penalties. <code>target="null"</code> (a null target matrix) is only available for &quot;RidgeAlt&quot;. Penalization with the &quot;Variance&quot; target shrinks the eigenvectors of the covariance matrix and is therefore not rotation invariant. See details on the various target properties in Clavel et al. (2019).
</p>
<p><b>&quot;error&quot;</b> - If <code>TRUE</code> the measurement error (or intra-specific variance) is estimated from the data as a nuisance parameter (like in mixed models). It should probably be systematically used with empirical data. See also Housworth et al. 2004 and Clavel et al. 2019 for details on the proposed implementation.
</p>
<p><b>&quot;scale.height&quot;</b> - Whether the tree should be scaled to unit height or not.
</p>
<p><b>&quot;echo&quot;</b> - Whether the results must be returned or not.
</p>
<p><b>&quot;grid_search&quot;</b> - A logical indicating whether or not a preliminary grid search must be performed to find the best starting values for optimizing the log-likelihood (or penalized log-likelihood). User-specified starting values can be provided through the <b>start</b> argument. Default is <code>TRUE</code>.
</p>
<p><b>&quot;upper&quot;</b> - The upper bound for the parameter search with the &quot;<code>L-BFGS-B</code>&quot; method. See <code>optim</code> for details.
</p>
<p><b>&quot;lower&quot;</b> - The lower bound for the parameter search with the &quot;<code>L-BFGS-B</code>&quot; method. See <code>optim</code> for details.
</p>
<p><b>&quot;tol&quot;</b> - Minimum value for the regularization parameter. Singularities can occur with a zero value in high-dimensional cases. (default is <code>NULL</code>)
</p>


<h3>Value</h3>

<p>An object of class '<code>mvgls</code>'. It contains a list including the following components:
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>a named vector of coefficients</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals (&quot;raw&quot;) of the model. That is response minus fitted values. Use the <code>residuals(x, type="normalized")</code> function to obtain the normalized residuals.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>the fitted values</p>
</td></tr>
<tr><td><code>variables</code></td>
<td>
<p>the variables used for model fit</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the estimated covariance (Pinv) and precision (P) matrix, as well as the sample estimate (S)</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the evolutionary model. But more generally, the model used to specify the structure within the residuals</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>either the (negative) log-likelihood when <code>method="LL"</code> or the cross-validated penalized likelihood</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>the (evolutionary) model parameter estimates. For &quot;BMM&quot; this corresponds to the average rate (mean of the diagonal elements of the covariance matrix (Pinv)).</p>
</td></tr>
<tr><td><code>tuning</code></td>
<td>
<p>the regularization/tuning parameter estimated for the penalized likelihood</p>
</td></tr>
<tr><td><code>mserr</code></td>
<td>
<p>the estimated standard error when <code>error=TRUE</code></p>
</td></tr>
<tr><td><code>start_values</code></td>
<td>
<p>the starting parameters used for the optimization of the LL or PL</p>
</td></tr>
<tr><td><code>corrSt</code></td>
<td>
<p>a list including the transformed tree, the determinant obtained from its covariance matrix and the normalized variables (by the inverse square root of the covariance matrix of the phylogenetic tree or the time-series)</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>the penalty used for the penalized likelihood approach</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>the target used with the &quot;RidgeArch&quot; or &quot;RidgeAlt&quot; penalized likelihood approaches</p>
</td></tr>
<tr><td><code>REML</code></td>
<td>
<p>logical indicating if the REML (<code>TRUE</code>) or ML (<code>FALSE</code>) method has been used</p>
</td></tr>
<tr><td><code>opt</code></td>
<td>
<p>optimizing function output. See <code>optim</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Clavel, J., Morlon, H. 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>
<p>Friedman J., Hastie T., Tibshirani R. 2008. Sparse inverse covariance estimation with the graphical lasso. Biostatistics. 9:432-441.
</p>
<p>Hoffbeck J.P., Landgrebe D.A. 1996. Covariance matrix estimation and classification with limited training data. IEEE Trans. Pattern Anal. Mach. Intell. 18:763-767.
</p>
<p>Housworth E.A., Martins E.P., LynchM. 2004. The phylogenetic mixed model. Am. Nat. 163:84-96.
</p>
<p>Theiler J. 2012. The incredible shrinking covariance estimator. In: Automatic Target Recognition XXII. Proc. SPIE 8391, Baltimore, p. 83910P.
</p>
<p>van Wieringen W.N., Peeters C.F.W. 2016. Ridge estimation of inverse covariance matrices from high-dimensional data. Comput. Stat. Data Anal. 103:284-303.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+manova.gls">manova.gls</a></code>
<code><a href="#topic+EIC">EIC</a></code>
<code><a href="#topic+GIC">GIC</a></code>
<code><a href="#topic+mvgls.pca">mvgls.pca</a></code>
<code><a href="#topic+fitted.mvgls">fitted.mvgls</a></code>
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+coef.mvgls">coef.mvgls</a></code>
<code><a href="#topic+vcov.mvgls">vcov.mvgls</a></code>
<code><a href="#topic+predict.mvgls">predict.mvgls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# --------------------------- #
# Model fit and comparison    #
# --------------------------- #

set.seed(1)
n &lt;- 32 # number of species
p &lt;- 50 # number of traits (p&gt;n)

tree &lt;- pbtree(n=n, scale=1) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p), ncol=p)) # a random covariance matrix
# simulate a BM dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R, theta=rep(0,p))) 
data=list(Y=Y)

# Fit the 'BM', 'OU', and 'EB' models to 'Y'
fit1 &lt;- mvgls(Y~1, data=data, tree, model="BM", penalty="RidgeArch")
fit2 &lt;- mvgls(Y~1, data=data, tree, model="OU", penalty="RidgeArch")
fit3 &lt;- mvgls(Y~1, data=data, tree, model="EB", penalty="RidgeArch")

GIC(fit1); GIC(fit2); GIC(fit3) # BM have the lowest GIC value

# Testing for phylogenetic signal with model fit
signal &lt;- mvgls(Y~1, data=data, tree, model="lambda", penalty="RidgeArch")
summary(signal)

# --------------------------- #
# Model fit by ML             #
# --------------------------- #

# Fit a model by Maximum Likelihood (rather than Penalized likelihood) when p&lt;&lt;n
fit_ml &lt;- mvgls(Y[,1:2]~1, data=data, tree, model="BM", method="LL")
summary(fit_ml)

# --------------------------- #
# Fit a regression model      #
# --------------------------- #

# simulate a 'fake' predictor for illustrative purpose
X &lt;- rTraitCont(tree)

# we can add the predictors to the previous 'data' list
data=list(Y=Y, X=X)

fit_ml &lt;- mvgls(Y~X, data=data, tree, model="lambda")
summary(fit_ml)

# --------------------------- #
# A High-dimensional dataset  #
# --------------------------- #
p &lt;- 200 # number of traits (p&gt;n)

R &lt;- crossprod(matrix(runif(p*p), ncol=p)) # a random symmetric matrix (covariance)
# simulate a BM dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R, theta=rep(0,p))) 
data=list(Y=Y)

# Fast LOOCV using "H&amp;L" with RidgeArch penalization
summary(mvgls(Y~1, data=data, tree, model="BM", penalty="RidgeArch", method="H&amp;L"))





</code></pre>

<hr>
<h2 id='mvgls.dfa'>
Discriminant Function Analysis (DFA) - also called Linear Discriminant Analysis (LDA) or Canonical Variate Analysis (CVA) - based on multivariate GLS (or OLS) model fit 
</h2><span id='topic+mvgls.dfa'></span>

<h3>Description</h3>

<p>Performs a discriminant analysis (DFA) on a regularized variance-covariance matrix obtained using either the <code>mvgls</code> or <code>mvols</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
mvgls.dfa(object, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvgls.dfa_+3A_object">object</code></td>
<td>

<p>A model fit obtained by the <code>mvgls</code> or the <code>mvols</code> function.
</p>
</td></tr>
<tr><td><code id="mvgls.dfa_+3A_...">...</code></td>
<td>

<p>Options to be passed through. (e.g., <code>term="the term corresponding to the factor of interest"</code>, <code>type="I"</code> for the type of decomposition of the hypothesis matrix (see also manova.gls) , etc.)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mvgls.dfa</code> allows computing a discriminant analysis based on GLS (or OLS) estimates from a regression model (see <code>mvgls</code> and <code>mvols</code>). Discriminant functions can be used for dimensionality reduction, to follow up a MANOVA analysis to describe group separation, or for group prediction.
</p>


<h3>Value</h3>

<p>a list with the following components
</p>
<table role = "presentation">
<tr><td><code>coeffs</code></td>
<td>
<p>a matrix containing the raw discriminants</p>
</td></tr>
<tr><td><code>coeffs.std</code></td>
<td>
<p>a matrix containing the standardized discriminants</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>a matrix containing the discriminant scores [residuals X coeffs]</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the centered [with GLS or OLS] response variables</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>the hypothesis (or between group model matrix)</p>
</td></tr>
<tr><td><code>E</code></td>
<td>
<p>the error (or residual model matrix)</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>the rank of <code class="reqn">HE^{-1}</code></p>
</td></tr>
<tr><td><code>pct</code></td>
<td>
<p>the percentage of the discriminant functions</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Still in development, may not handle special designs. </p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Clavel, J., Morlon, H., 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in Phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+manova.gls">manova.gls</a></code>,
<code><a href="#topic+mvgls.pca">mvgls.pca</a></code>,
<code><a href="#topic+predict.mvgls.dfa">predict.mvgls.dfa</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mvMORPH)
n=64
p=4

tree &lt;- pbtree(n=n)
sigma &lt;- crossprod(matrix(runif(p*p),p,p))
resid &lt;- mvSIM(tree, model="BM1", param=list(sigma=sigma))
Y &lt;- rep(c(0,1.5), each=n/2) + resid
grp &lt;- as.factor(rep(c("gp1","gp2"),each=n/2))
names(grp) = rownames(Y)
data &lt;- list(Y=Y, grp=grp)
mod &lt;- mvgls(Y~grp, data=data, tree=tree, model="BM")

# fda
da1 &lt;- mvgls.dfa(mod)

plot(da1)

</code></pre>

<hr>
<h2 id='mvgls.pca'>
Principal Component Analysis (PCA) based on GLS (or OLS) estimate of the traits variance-covariance matrix (possibly regularized)
</h2><span id='topic+mvgls.pca'></span>

<h3>Description</h3>

<p>Performs a principal component analysis (PCA) on a regularized variance-covariance matrix obtained using the <code>mvgls</code> or the <code>mvols</code> function. With &quot;evolutionary&quot; models in <code>mvgls</code>, this performs the so-called phylogenetic PCA.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
mvgls.pca(object, plot=TRUE, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvgls.pca_+3A_object">object</code></td>
<td>

<p>A model fit obtained by the <code>mvgls</code> or <code>mvols</code> function.
</p>
</td></tr>
<tr><td><code id="mvgls.pca_+3A_plot">plot</code></td>
<td>

<p>Plot of the PC's axes. Default is TRUE (see details).'</p>
</td></tr>
<tr><td><code id="mvgls.pca_+3A_...">...</code></td>
<td>

<p>Options to be passed through. (e.g., <code>axes=c(1,2)</code>, <code>col</code>, <code>pch</code>, <code>cex</code>, <code>mode="cov"</code> or <code>"corr"</code>, etc.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mvgls.pca</code> allows computing a principal component analysis based on a GLS (or OLS) estimate of the covariance matrix (see <code>mvgls</code> and <code>mvols</code>). The phylogenetic PCA (following Revell 2009) is a special case obtained from the (possibly regularized) evolutionary variance-covariance matrix (see also the <code>phyl.pca_pl</code> function in RPANDA). In the high-dimensional case the contribution of the firsts PC axes tend to be overestimated with traditional maximum likelihood approaches. Penalized/regularized model fit reduce this bias and allow incorporating various residuals structures (see Clavel et al. 2019).
Plotting options, the number of axes to display (<code>axes=c(1,2)</code> is the default), and whether the covariance (<code>mode="cov"</code>) or correlation (<code>mode="corr"</code>) should be used can be specified through the ellipsis &quot;<code>...</code>&quot; argument.
</p>


<h3>Value</h3>

<p>a list with the following components
</p>
<table role = "presentation">
<tr><td><code>scores</code></td>
<td>
<p>the PC scores</p>
</td></tr>
<tr><td><code>values</code></td>
<td>
<p>the eigenvalues of the variance-covariance matrix estimated by mvgls or mvols</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>
<p>the eigenvectors of the variance-covariance matrix estimated by mvgls or mvols</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>the rank of the estimated variance-covariance matrix</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Contrary to conventional PCA (for instance using <code>mvols</code> with &quot;LL&quot; method), the principal axes of the gls PCA are not orthogonal, they represent the main axes of independent (according to a given phylogenetic or time-series model) evolutionary changes.</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Revell, L.J., 2009. Size-correction and principal components for intraspecific comparative studies. Evolution, 63:3258-3268.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+GIC">GIC</a></code>,
<code><a href="#topic+EIC">EIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
n &lt;- 32 # number of species
p &lt;- 30 # number of traits

tree &lt;- pbtree(n=n) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p),p))  # a random symmetric matrix (covariance)

# simulate a dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R))

# The conventional phylogenetic PCA
phylo_pca &lt;- mvgls(Y~1, tree=tree, model="BM", method="LL")
mvgls.pca(phylo_pca, plot=TRUE) 




# fit a multivariate Pagel lambda model with Penalized likelihood
fit &lt;- mvgls(Y~1, tree=tree, model="lambda", method="LOO", penalty="RidgeAlt")

# Perform a regularized phylogenetic PCA using the model fit (Pagel lambda model)
pca_results &lt;- mvgls.pca(fit, plot=TRUE) 

# retrieve the scores
head(pca_results$scores)

</code></pre>

<hr>
<h2 id='mvLL'>
Multivariate (and univariate) algorithms for log-likelihood estimation of arbitrary covariance matrix/trees
</h2><span id='topic+mvLL'></span>

<h3>Description</h3>

<p>This function allows computing the log-likelihood and estimating ancestral states of an arbitrary tree or variance-covariance matrix with differents algorithms based on GLS (Generalized Least Squares) or Independent Contrasts. Works for univariate or multivariate models. Can be wrapped for maximizing the log-likelihood of user-defined models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvLL(tree, data, error = NULL, method = c("pic", "rpf", "sparse", "inverse",
    "pseudoinverse"), param = list(estim = TRUE, mu = 0, sigma = 0, D = NULL,
    check = TRUE), precalc = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvLL_+3A_tree">tree</code></td>
<td>

<p>A phylogenetic tree of class &quot;phylo&quot; or a variance-covariance matrix (vcv) of that tree (or time-series).
</p>
</td></tr>
<tr><td><code id="mvLL_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits in columns. NA values are allowed with the &quot;rpf&quot;, &quot;inverse&quot; and &quot;pseudoinverse&quot; methods.
</p>
</td></tr>
<tr><td><code id="mvLL_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous trait sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="mvLL_+3A_method">method</code></td>
<td>

<p>Method used for computing the log-likelihood. Could be &quot;pic&quot;, &quot;sparse&quot;, &quot;rpf&quot;, &quot;inverse&quot;, or &quot;pseudoinverse&quot;. See details below.
</p>
</td></tr>
<tr><td><code id="mvLL_+3A_param">param</code></td>
<td>

<p>List of additional arguments to be passed through the function. The &quot;estim&quot;, &quot;mu&quot; and &quot;sigma&quot; arguments are only used with the &quot;pic&quot; method. The &quot;D&quot; argument is used with the others to specify the design matrix. See details below.
</p>
</td></tr>
<tr><td><code id="mvLL_+3A_precalc">precalc</code></td>
<td>

<p>Optional. Object of class &quot;precalc.mvmorph&quot;. See ?mv.Precalc for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mvLL function computes the log-likelihood and the ancestral states (mean at the root-theta) for an arbitrary variance-covariance matrix (or trees for the prunning algorithm based on independent contrasts &quot;pic&quot;) provided by the user. This function can be wrapped for optimizing various multivariate models of trait evolution (by transforming the branch lengths of a tree for the &quot;pic&quot; method, or feeding it with variance-covariance and design matrices for the other methods).
</p>
<p>Five methods are proposed to compute the log-likelihood:
</p>
<p>-&quot;pic&quot; is a very fast prunning algorithm based on independent contrasts which should be used with strictly dichotomic trees (i.e., no polytomies). This method can neither be used with measurement errors nor for multiple ancestral states estimation (theta values).
</p>
<p>-&quot;rpf&quot; is a GLS algorithm using the rectangular packed format Cholesky factorization for solving the linear system without computing the inverse of the variance-covariance matrix and its determinant (normally used in the loglikelihood estimation). This algorithm uses fast BLAS 3 routines with half storage in packed format for computing the Cholesky upper factor. This method is more efficient than the &quot;inverse&quot; method and can be used with dense matrices (no zero entries).
</p>
<p>-&quot;sparse&quot; is a GLS algorithm using Cholesky factorization for sparse matrices (including zero entries). The matrices are stored in the &quot;old Yale sparse format&quot; internally. Depending on the sparsity structure of the variance-covariance matrix this algorithm can be more efficient than the &quot;rpf&quot; method.
</p>
<p>-&quot;inverse&quot; is a GLS algorithm that uses explicit inversion of the variance-covariance matrix (through QR decomposition) as well as computation of its determinant in the log-likelihood estimation. This is the &quot;textbook&quot; method, that is computationally more intensive than the previous approaches.
</p>
<p>-&quot;pseudoinverse&quot; is a GLS method that uses a generalized inverse (through SVD) for computing the log-likelihood. This method is safer when the matrix is near singularity, but it is the most time-consuming.
</p>
<p>The user must provide a variance-covariance matrix (e.g., vcv.phylo(tree)) or a multivariate variance-covariance matrix (e.g., kronecker(matrix(c(2,1,1,1.5),2),vcv.phylo(tree)) as well as a design matrix (or multivariate design matrix) with the &quot;rpf&quot;, &quot;sparse&quot;, &quot;inverse&quot;, and &quot;pseudoinverse&quot; methods.
</p>
<p>Use the &quot;param&quot; list of arguments to define whether or not the brownian rate should be estimated and returned (estim=TRUE) with the &quot;pic&quot; method. Otherwise, the rate parameter (also called sigma) is fixed to 1. The arguments &quot;mu&quot; and &quot;sigma&quot; can be used to specify (e.g., in a MCMC setting) the mean at the root and the (squared) brownian rate, respectively.
</p>
<p>You can choose to provide differently scaled trees for multivariate data with the &quot;pic&quot; method. In such a case, the trees (one per trait) should be embedded within a list() object. See example below.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>logl</code></td>
<td>
<p>Estimated log-likelihood for the data with the given matrix/tree.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated ancestral states at the root. They are defined by the design matrix (D) for all the methods but &quot;pic&quot;.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Estimated (squared) rate parameters. Only when param$estim=TRUE with the &quot;pic&quot; method.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Andersen B. S., Wasniewski J., Gustavson F. G. 2001. A recursive formulation of Cholesky
factorization of a matrix in packed storage. ACM Trans. Math. Soft. 27:214-244.
</p>
<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods Ecol. Evol. 6(11):1311-1319.
</p>
<p>Freckleton R.P. 2012. Fast likelihood calculations for comparative analyses. Methods Ecol. Evol. 3:940-947.
</p>
<p>Golub G.H., Van Loan C.F. 2013. Matrix computations. Baltimore: The John Hopkins University Press.
</p>
<p>Gustavson, F.G., Wasniewski, J., Dongarra, J.J., Langou, J. 2010. Rectangular full packed format for Cholesky's algorithm: factorization, solution and inversion. ACM Trans. Math. Soft., 37:1-33.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simulated dataset
set.seed(14)
# Generating a random tree with 50 tips
n=50
tree&lt;-pbtree(n=n)

# Simulated trait
data=rTraitCont(tree)

# Design matrix
D=matrix(rep(1,n),ncol=1)

## Compute the log-likelihood
# Inverse
mvLL(vcv.phylo(tree),data,method="inverse",param=list(D=D))

# Pseudoinverse
mvLL(vcv.phylo(tree),data,method="pseudoinverse",param=list(D=D))

# Sparse
mvLL(vcv.phylo(tree),data,method="sparse",param=list(D=D))

# RPF
mvLL(vcv.phylo(tree),data,method="rpf",param=list(D=D))

# Pic
mvLL(tree,data,method="pic",param=list(estim=TRUE))

# Pic with arbitrary values
mvLL(tree,data,method="pic",param=list(estim=FALSE, mu=0, sigma=1))
mvLL(tree,data,method="pic",param=list(estim=FALSE))
mvLL(tree,data,method="pic",param=list(estim=FALSE, sigma=1)) # similar to mu=NULL

# Arbitrary value for mu with other methods (similar to mu=0 and sigma=1 with "pic")
mvLL(vcv.phylo(tree),data,method="rpf",param=list(D=D, estim=FALSE, mu=0)) 

## Multivariate cases
# Simulate traits
data2&lt;-mvSIM(tree,nsim=1,model="BM1",param=list(sigma=diag(2),theta=c(0,0),ntraits=2))
# Design matrix
D&lt;-cbind(rep(c(1,0),each=50),rep(c(0,1),each=50))

# RPF
mvLL(kronecker(diag(2),vcv.phylo(tree)),data2,method="rpf", param=list(D=D))

# Inverse (with default design matrix if not provided)
mvLL(kronecker(diag(2),vcv.phylo(tree)),data2,method="inverse")

# Pic
mvLL(tree,data2,method="pic")
# NB: The trees in the list could be differently scaled for each traits...
mvLL(list(tree,tree),data2,method="pic")

## VERY FAST COMPUTATION FOR LARGE TREES (take few seconds)



# Big tree (1,000,000 species) - It's the time consuming part...
 tree2&lt;-rtree(1000000)
# Simulate trait with a Brownian motion process
 trait&lt;-rTraitCont(tree2)
 system.time(mvLL(tree2,trait,method="pic",param=list(estim=FALSE, sigma=1)))

 precal&lt;-mv.Precalc(tree2,nb.traits=1, param=list(method="pic"))
 system.time(mvLL(tree2,trait,method="pic",param=list(estim=FALSE, sigma=1),
   precalc=precal))

# Check=FALSE !! Your tree should be in post-order !!
 tr2&lt;-reorder(tree2,"postorder")
 system.time(mvLL(tr2,trait,method="pic",param=list(estim=FALSE, sigma=1, check=FALSE)))

</code></pre>

<hr>
<h2 id='mvols'>
Fit linear model using Ordinary Least Squares to multivariate (high-dimensional) data sets
</h2><span id='topic+mvols'></span>

<h3>Description</h3>

<p>This function uses maximum likelihood (or restricted likelihood) and penalized likelihood approaches to fit linear models with independent observations (this is the multivariate (and penalized) counterpart to the base <code>lm</code> function). <code>mvols</code> uses a penalized-likelihood (PL) approach (see descriptions in Clavel et al. 2019) to fit linear models to high-dimensional data sets (where the number of variables <em>p</em> is approaching or is larger than the number of observations <em>n</em>). The PL approach generally provides improved estimates compared to ML. OLS is a special case  of GLS linear models (and a wrapper of <code>mvgls</code>) and can be used with all the package functions working on <code>mvgls</code> class objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvols(formula, data, method=c("PL-LOOCV","LL"),
      REML=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

 
<table role = "presentation">
<tr><td><code id="mvols_+3A_formula">formula</code></td>
<td>

<p>An object of class &quot;<code>formula</code>&quot; (a two-sided linear formula describing the model to be fitted. See for instance ?<code>lm</code>)
</p>
</td></tr>
<tr><td><code id="mvols_+3A_data">data</code></td>
<td>

<p>An optional list, data.frame or environment containing the variables in the model. If not found in <em>data</em> the variables are taken from the current environment. Prefer <code>list</code> for blocks of multivariate responses unless you're specifying the response variables by their names using <code>cbind</code> with data.frame.
</p>
</td></tr>
<tr><td><code id="mvols_+3A_method">method</code></td>
<td>

<p>The method used to fit the model. &quot;PL-LOOCV&quot; (or equivalently just &quot;LOOCV&quot;) is the nominal leave one out cross-validation of the penalized log-likelihood, &quot;LL&quot; is the log-likelihood (used in the conventional ML and REML estimation). Two approximated LOOCV methods are also available: &quot;H&amp;L&quot; and &quot;Mahalanobis&quot;. The method &quot;H&amp;L&quot; is a fast LOOCV approach based on Hoffbeck and Landgrebe (1996) tricks, and &quot;Mahalanobis&quot; is an approximation of the LOOCV score proposed by Theiler (2012). Both &quot;H&amp;L&quot; and &quot;Mahalanobis&quot; work only with the &quot;RidgeArch&quot; penalty and for intercept only models (i.e. of the form Y~1, see also details).
</p>
</td></tr>
<tr><td><code id="mvols_+3A_reml">REML</code></td>
<td>

<p>Use REML (default) or ML for estimating the parameters.
</p>
</td></tr>
<tr><td><code id="mvols_+3A_...">...</code></td>
<td>

<p>Options to be passed through. For instance the type of penalization: 
<code>penalty="RidgeArch"</code> (default), <code>penalty="RidgeAlt"</code>, or <code>penalty="LASSO"</code>. The target matrices used by &quot;RidgeArch&quot; and &quot;RidgeAlt&quot; penalizations: <code>target="unitVariance"</code>, <code>target="Variance"</code> or <code>target="null"</code>... etc. (see details). One can also define contrasts options as for the <code>lm</code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mvols</code> allows fitting multivariate linear models to multivariate (possibly high-dimensional, i.e. where the number of variables <em>p</em> is larger than <em>n</em>) datasets. Models estimated using penalized likelihood (e.g., method=&quot;PL-LOOCV&quot;) are generally more accurate than those estimated by maximum likelihood methods (method=&quot;LL&quot;) when the number of traits approach the number of observations. PL is the only solution when <em>p</em>&gt;<em>n</em>.  Models fit can be compared using the GIC or EIC criterion (see ?<code>GIC</code> and ?<code>EIC</code>) and hypothesis testing can be performed using the <code>manova.gls</code> function.
</p>
<p>The various <em>arguments</em> that can be passed through <b>&quot;...&quot;</b>:
</p>
<p><b>&quot;penalty&quot;</b> - The &quot;penalty&quot; argument allows specifying the type of penalization used for regularization (described in Clavel et al. 2019). The various penalizations are: <code>penalty="RidgeArch"</code> (the default), <code>penalty="RidgeAlt"</code> and <code>penalty="LASSO"</code>. The &quot;RidgeArch&quot; penalization shrink linearly the &quot;sample&quot;&quot; covariance matrix toward a given target matrix with a specific structure (see below for <code>target</code>). This penalization is generally fast and the tuning parameter is bounded between 0 and 1 (see van Wieringen &amp; Peeters 2016, Clavel et al. 2019). The &quot;RidgeAlt&quot; penalization scheme uses a quadratic ridge penalty to shrink the covariance matrix toward a specified target matrix (see <code>target</code> below and also see van Wieringen &amp; Peeters 2016). Finally, the &quot;LASSO&quot; regularize the covariance matrix by estimating a sparse estimate of its inverse - the precision matrix (Friedman et al. 2008). Solving the LASSO penalization is computationally intensive. Moreover, this penalization scheme is not invariant to arbitrary rotations of the data.
</p>
<p><b>&quot;target&quot;</b> - This argument allows specifying the target matrix toward which the covariance matrix is shrunk for &quot;Ridge&quot; penalties. <code>target="unitVariance"</code> (for a diagonal target matrix proportional to the identity) and <code>target="Variance"</code> (for a diagonal matrix with unequal variance) can be used with both &quot;RidgeArch&quot; and &quot;RidgeAlt&quot; penalties. <code>target="null"</code> (a null target matrix) is only available for &quot;RidgeAlt&quot;. Penalization with the &quot;Variance&quot; target shrinks the eigenvectors of the covariance matrix and is therefore not rotation invariant. See details on the various target properties in Clavel et al. (2019).
</p>
<p><b>&quot;weights&quot;</b> - A (named) vector of weights (variances) for all the observations. If provided, a weighted least squares (WLS) rather than OLS fit is performed.
</p>
<p><b>&quot;echo&quot;</b> - Whether the results must be returned or not.
</p>
<p><b>&quot;grid_search&quot;</b> - A logical indicating whether or not a preliminary grid search must be performed to find the best starting values for optimizing the log-likelihood (or penalized log-likelihood). User-specified starting values can be provided through the <b>start</b> argument. Default is <code>TRUE</code>.
</p>
<p><b>&quot;tol&quot;</b> - Minimum value for the regularization parameter. Singularities can occur with a zero value in high-dimensional cases. (default is <code>NULL</code>)
</p>


<h3>Value</h3>

<p>An object of class '<code>mvols</code>'. It contains a list including the same components as the <code>mvgls</code> function (see ?mvgls).
</p>


<h3>Note</h3>

<p>This function is a wrapper to the <code>mvgls</code> function (it uses gls with a diagonal covariance). For these reasons, the function can be used with all the methods working with <code>mvgls</code> class objects.
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Clavel, J., Morlon, H. 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>
<p>Friedman J., Hastie T., Tibshirani R. 2008. Sparse inverse covariance estimation with the graphical lasso. Biostatistics. 9:432-441.
</p>
<p>Hoffbeck J.P., Landgrebe D.A. 1996. Covariance matrix estimation and classification with limited training data. IEEE Trans. Pattern Anal. Mach. Intell. 18:763-767.
</p>
<p>Theiler J. 2012. The incredible shrinking covariance estimator. In: Automatic Target Recognition XXII. Proc. SPIE 8391, Baltimore, p. 83910P.
</p>
<p>van Wieringen W.N., Peeters C.F.W. 2016. Ridge estimation of inverse covariance matrices from high-dimensional data. Comput. Stat. Data Anal. 103:284-303.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+manova.gls">manova.gls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+EIC">EIC</a></code>
<code><a href="#topic+GIC">GIC</a></code>
<code><a href="#topic+mvgls.pca">mvgls.pca</a></code>
<code><a href="#topic+fitted.mvgls">fitted.mvgls</a></code>
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+coef.mvgls">coef.mvgls</a></code>
<code><a href="#topic+vcov.mvgls">vcov.mvgls</a></code>
<code><a href="#topic+predict.mvgls">predict.mvgls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
n &lt;- 32 # number of species
p &lt;- 50 # number of traits (p&gt;n)

tree &lt;- pbtree(n=n, scale=1) # phylogenetic tree
R &lt;- crossprod(matrix(runif(p*p), ncol=p)) # a random covariance matrix
# simulate a BM dataset
Y &lt;- mvSIM(tree, model="BM1", nsim=1, param=list(sigma=R, theta=rep(0,p))) 
data=list(Y=Y)

fit1 &lt;- mvgls(Y~1, data=data, tree, model="BM", penalty="RidgeArch")

# compare to OLS?
fit2 &lt;- mvols(Y~1, data=data, penalty="RidgeArch")

GIC(fit1); GIC(fit2); 

## Fit a model by Maximum Likelihood (rather than Penalized likelihood) when p&lt;&lt;n
fit_ml &lt;- mvols(Y[,1:2]~1, data=data, method="LL")
summary(fit_ml)




</code></pre>

<hr>
<h2 id='mvOU'>
Multivariate Ornstein-Uhlenbeck model of continuous traits evolution
</h2><span id='topic+mvOU'></span>

<h3>Description</h3>

<p>This function allows the fitting of a multivariate Ornstein-Uhlenbeck (OU1) model with possibly multiple optima (OUM) for different &quot;selective regimes&quot;. A &quot;phylo&quot; object with SIMMAP-like mapping of ancestral states is required to subdivise the tree (or branches) into &quot;selective regimes&quot;.
Species measurement errors or dispersions can also be included in the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvOU(tree, data, error = NULL, model = c("OUM", "OU1"), param = list(sigma = NULL,
    alpha = NULL, vcv = "fixedRoot", decomp = c("cholesky","spherical","eigen","qr",
    "diagonal","upper","lower")), method = c("rpf", "sparse", "inverse",
    "pseudoinverse", "univarpf"), scale.height = FALSE, optimization = c("L-BFGS-B",
    "Nelder-Mead", "subplex"), control = list(maxit = 20000), precalc = NULL, 
    diagnostic = TRUE, echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvOU_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree with mapped ancestral states in phytools' SIMMAP format for &quot;OUM&quot; model.
(See make.simmap, paintBranches, paintSubTree, and make.era.map functions from the phytools package). A &quot;phylo&quot; object can be used with model &quot;OU1&quot;.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits in columns. NA values are allowed with the &quot;rpf&quot;, &quot;inverse&quot;, and &quot;pseudoinverse&quot; methods.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous trait sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_model">model</code></td>
<td>

<p>Choose between &quot;OUM&quot; for a multiple selective regime model, or &quot;OU1&quot; for a unique selective regime for the whole tree.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_param">param</code></td>
<td>

<p>List of arguments to be passed to the function. See details below.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_method">method</code></td>
<td>

<p>Choose between &quot;rpf&quot;, &quot;sparse&quot;, &quot;inverse&quot;, &quot;pseudoinverse&quot;, or &quot;univarpf&quot; for computing the log-likelihood during the fitting process. See details below.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_scale.height">scale.height</code></td>
<td>

<p>Whether the tree should be scaled to unit length or not.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_optimization">optimization</code></td>
<td>

<p>Methods used by the optimization routines (see ?optim and ?subplex for details). The &quot;fixed&quot; method returns the log-likelihood function only.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_control">control</code></td>
<td>

<p>Max. bound for the number of iteration of the optimizer; other options can be fixed in the list. (See ?optim or ?subplex for details).
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_precalc">precalc</code></td>
<td>

<p>Optional. Precalculation of fixed parameters. See ?mvmorph.Precalc for details.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_diagnostic">diagnostic</code></td>
<td>

<p>Whether the convergence diagnostics should be returned or not.
</p>
</td></tr>
<tr><td><code id="mvOU_+3A_echo">echo</code></td>
<td>

<p>Whether the results must be returned or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mvOU function fits a multivariate model of evolution according to an Ornstein-Uhlenbeck process:
</p>
<p style="text-align: center;"><code class="reqn">dX(t) = A(\Theta - X(t))dt + \Sigma^{1/2}dW(t)</code>
</p>

<p>The user can incorporate measurement errors and uses SIMMAP-like mapping of ancestral states (phytools objects of class &quot;simmap&quot;). SIMMAP mapping allows one to assign parts of branches to different selective regimes for estimating regime-specific evolutionary optima. See the package vignette: browseVignettes(&quot;mvMORPH&quot;).
</p>
<p>Mapping of ancestral states can be done using the &quot;make.simmap&quot;, &quot;make.era.map&quot; or &quot;paintSubTree&quot; functions from the &quot;phytools&quot; package.
</p>
<p>The &quot;method&quot; argument allows the user to try different algorithms for computing the log-likelihood. The <code>"rpf"</code>, <code>"univarpf"</code> (for univariate analysis) and <code>"sparse"</code> methods use fast GLS algorithms based on factorization to avoid explicit computation of the inverse of the variance-covariance matrix and its determinant during log-likelihood estimation. The <code>"inverse"</code> approach uses a &quot;stable&quot; (based on QR decomposition) explicit computation of the inverse and determinant of the matrix and is therefore slower. The <code>"pseudoinverse"</code> method uses a generalized inverse that is safer for matrix near singularity but highly time consuming. See ?mvLL for details.
</p>
<p>Arguments in the <b>&quot;param&quot;</b> <code>list</code> are:
</p>
<p><b>&quot;sigma&quot;</b> or <b>&quot;alpha&quot;</b> - Starting values for the likelihood search can be specified through the &quot;alpha&quot; and &quot;sigma&quot; arguments in the param list. It is also possible to test for the significance of the off-diagonal sigma (scatter) and alpha (drift) matrix in the full model by making comparison with a constrained model (using sigma=&quot;constraint&quot;, or alpha=&quot;constraint&quot;) in the &quot;param&quot; argument list. You can also provide starting values for the constrained model. For instance, for two traits use sigma=list(&quot;constraint&quot;, c(0.5,0.5))  (or alpha=list(&quot;constraint&quot;, c(0.5,0.5))).
</p>
<p><b>&quot;decomp&quot;</b> - You can further constrain the alpha matrix by specifying the decomposition of the matrix through the &quot;decomp&quot; argument in the &quot;param&quot; list. The multivariate Ornstein-Uhlenbeck model is described by the spectral decomposition of the alpha matrix. It is possible to parameterize the alpha matrix to be decomposable using various parameterizations (e.g., on its eigenvalues with different biological interpretations; Sy et al. 1997, Bartoszek et al. 2012; Clavel et al. 2015). For a symmetric matrix parameterization, the user can choose the <code>"cholesky"</code>, <code>"eigen"</code>, or <code>"spherical"</code> option. 
</p>
<p>For general square (non-symmetric) matrices the <code>"svd"</code>, <code>"qr"</code> and <code>"schur"</code> parameterizations can be used. The <code>"schur"</code> parameterization constrains the eigenvalues of the alpha matrix to be real numbers. The <code>"svd+"</code>, <code>"qr+"</code> or <code>"eigen+"</code> options force the eigenvalues to be positives by taking their logarithm. It is also possible to specify <code>"diagonal"</code> which is similar to the use of the &quot;constraint&quot; argument for &quot;alpha&quot; argument, or to use <code>"equal"</code> and <code>"equaldiagonal"</code>. Finally, one can specify that the alpha matrix is <code>"upper"</code> or <code>"lower"</code> triangular (i.e., one process affect the other unilateraly). Details can be found in the package vignette: browseVignettes(&quot;mvMORPH&quot;) and on Clavel et al. 2015.
</p>
<p><b>&quot;decompSigma&quot;</b> - The sigma matrix is parameterized by various methods to ensure its positive definiteness (Pinheiro and Bates, 1996). These methods can be accessed through the &quot;decompSigma&quot; argument and are the <code>"cholesky"</code>, <code>"eigen+"</code>, and <code>"spherical"</code> parameterization. The sigma matrix can also be forced to be diagonal using <code>"diagonal"</code> or <code>"equaldiagonal"</code> and forced to have the same variances using <code>"equal"</code>. Details can be found in the package vignette: browseVignettes(&quot;mvMORPH&quot;).
</p>
<p><b>&quot;vcv&quot;</b> - It is possible to specify in the &quot;param&quot; list what kind of variance-covariance matrix to use with the &quot;vcv&quot; argument, depending on how the root is treated. 
The <code>vcv="randomRoot"</code> option assumes that the value at the root is a random variable with the stationary distribution of the process. It cannot be used with the &quot;sparse&quot; method to speed up the computations. The <code>vcv="fixedRoot"</code> option assumes that the root is a fixed parameter. On ultrametric trees both approaches should converge on the same results when the OU process is stationary.
</p>
<p><b>&quot;root&quot;</b> - This argument allows the user to specify if the ancestral state at the root (theta 0) should be estimated (<code>root=TRUE</code>), or assumed to be at the oldest regime state stationary distribution (<code>root=FALSE</code>). An alternative is to follow Beaulieu et al. (2012) and explicitly drop the root state influence (<code>root="stationary"</code>). The first option should be used with non-ultrametric trees (i.e., with fossil species; e.g., Hansen 1997) where information on the ancestral state is directly available from the data. Note that estimating shifts from the ancestral state to the optimum(s) from extant species can be problematic and it can be preferable to assume each regime optimum(s) to be at the stationary distribution.
</p>
<p>For the <b>&quot;decomp&quot;</b> and <b>&quot;decompSigma</b> arguments, a user-defined matrix with integer values taken as indices of the parameters to be estimated can be provided. See ?mvBM and ?mvRWTS.
</p>
<p>Note on the returned Hessian matrix in the result list (param$opt$hessian):
</p>
<p>The hessian is the matrix of second order partial derivatives of the likelihood function with respect to the maximum likelihood parameter values. This matrix provides a measure of the steepness of the likelihood surface in the vicinity of the optimum. The eigen-decomposition of the hessian matrix allows assessing the reliability of the model fit (even if the optimizer has converged).
When the optimization function does not converge on a stable result, the user may consider increasing the &quot;maxit&quot; argument in the &quot;control&quot; option, or try a simpler model with fewer parameters to estimate. Changing the starting values (&quot;alpha&quot; and &quot;sigma&quot; options in the param list) as well as the optimizing method (&quot;optimization&quot; option) may helps sometimes (e.g., alpha=runif(3) for a two-trait analysis with random starting values - i.e., the lower triangular alpha matrix). Note that the number of starting values to provide depends on the matrix decomposition chosen for the alpha parameter (p*(p+1)/2 values for symmetric alpha matrix, but p*p values for non-symmetric ones - with p the number of traits).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>LogLik</code></td>
<td>
<p>The log-likelihood of the optimal model.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion for the optimal model.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>Sample size-corrected AIC.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated ancestral states.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Matrix of estimated alpha values (strength of selection).</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Evolutionary rate matrix (drift).</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence status of the optimizing function; &quot;0&quot; indicates convergence. (see ?optim for details).</p>
</td></tr>
<tr><td><code>hess.values</code></td>
<td>
<p>Reliability of the likelihood estimates calculated through the eigen-decomposition of the hessian matrix. &quot;0&quot; means that a reliable estimate has been reached. See details above.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>List of model fit parameters (optimization, method, model, number of parameters...).</p>
</td></tr>
<tr><td><code>llik</code></td>
<td>
<p>The log-likelihood function evaluated in the model fit &quot;$llik(par, root.mle=TRUE)&quot;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function partly uses a modified version of the C code from the &quot;OUCH&quot; package built by Aaron King, as well as a C code which is part of the &quot;ape&quot; package by Emmanuel Paradis.  I kindly thank those authors for sharing their sources.
Note that Bartoszek et al. (2012) proposed the mvSLOUCH package also dedicated to multivariate Ornstein-Uhlenbeck processes, which allows fitting regression models with randomly evolving predictor variables.
</p>
<p>The &quot;symmetric&quot;, &quot;nsymmetric&quot;, &quot;symmetricPositive&quot;, and &quot;nsymPositive&quot; options for the &quot;decomp&quot; argument are deprecated.
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Bartoszek K., Pienaar J., Mostad P., Andersson S., Hansen T.F. 2012. A phylogenetic comparative method for studying multivariate adaptation. J. Theor. Biol. 314:204-215.
</p>
<p>Beaulieu J.M., Jhwueng D.-C., Boettiger C., O'Meara B.C. 2012. Modeling stabilizing selection: Expanding the Ornstein-Uhlenbeck model of adaptive evolution. Evolution. 66:2369-2389.
</p>
<p>Butler M.A., King A.A. 2004. Phylogenetic comparative analysis: a modeling approach for adaptive evolution. Am. Nat. 164:683-695.
</p>
<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods Ecol. Evol. 6(11):1311-1319.
</p>
<p>Hansen T.F. 1997. Stabilizing selection and the comparative analysis of adaptation. Evolution. 51:1341-1351.
</p>
<p>Pinheiro J.C., Bates D.M. 1996. Unconstrained parameterizations for variance-covariance matrices. Stat. Comput. 6:289-296.
</p>
<p>Sy J.P., Taylor J.M.G., Cumberland W.G. 1997. A stochastic model for the analysis of bivariate longitudinal AIDS data. Biometrics. 53:542-555.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+halflife">halflife</a></code>
<code><a href="#topic+stationary">stationary</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvOUTS">mvOUTS</a></code>
<code><a href="#topic+mvRWTS">mvRWTS</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
<code><a href="#topic+LRT">LRT</a></code>
<code><a href="stats.html#topic+optim">optim</a></code>
<code><a href="phytools.html#topic+make.simmap">make.simmap</a></code>
<code><a href="phytools.html#topic+make.era.map">make.era.map</a></code>
<code><a href="phytools.html#topic+paintSubTree">paintSubTree</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)

# Setting the regime states of tip species
sta&lt;-as.vector(c(rep("Forest",20),rep("Savannah",30))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate the traits
alpha&lt;-matrix(c(2,0.5,0.5,1),2)
sigma&lt;-matrix(c(0.1,0.05,0.05,0.1),2)
theta&lt;-c(2,3,1,1.3)
data&lt;-mvSIM(tree, param=list(sigma=sigma, alpha=alpha, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size")), model="OUM", nsim=1)

## Fitting the models

# OUM - Analysis with multiple optima
 mvOU(tree, data)

# OU1 - Analysis with a unique optimum
 mvOU(tree, data, model="OU1", method="sparse")

# various options
mvOU(tree, data, model="OUM", method="sparse", scale.height=FALSE,
    param=list(decomp="svd", root="stationary"))# non-symmetric alpha
mvOU(tree, data, model="OUM", method="sparse", scale.height=FALSE,
    param=list(decomp="qr", root=TRUE)) # non-symmetric alpha
mvOU(tree, data, model="OUM", method="sparse", scale.height=FALSE,
    param=list(decomp="cholesky", root=TRUE)) # symmetric-positive
# OUCH setting
mvOU(tree, data, model="OUM", method="rpf", scale.height=FALSE,
    param=list(decomp="cholesky", root=FALSE, vcv="ouch"))

## Univariate case - FAST with RPF
 set.seed(14)
 tree&lt;-pbtree(n=500)

# Setting the regime states of tip species
 sta&lt;-as.vector(c(rep("Forest",200),rep("Savannah",300))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
 tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
 col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
 plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Parameters
 alpha&lt;-2.5
 sigma&lt;-0.1
 theta&lt;-c(0,2)
 data&lt;-mvSIM(tree, param=list(sigma=sigma, alpha=alpha, ntraits=1, theta=theta,
             names_traits=c("body_size")), model="OUM", nsim=1)

# Fit the model
 system.time(mvOU(tree, data, model="OUM", method="univarpf",
                param=list(root="stationary")))
 system.time(mvOU(tree, data, model="OU1", method="univarpf",
                param=list(root="stationary")))

# Add measurement error
 error=rnorm(500,sd=0.1)
 mvOU(tree, data+error, error=rep(0.1^2,500), model="OUM", method="univarpf",
    param=list(root="stationary"))

	
</code></pre>

<hr>
<h2 id='mvOUTS'>
Multivariate continuous trait evolution for a stationary time series (Ornstein-Uhlenbeck model)
</h2><span id='topic+mvOUTS'></span>

<h3>Description</h3>

<p>This function allows the fitting of a multivariate Ornstein-Uhlenbeck (OU) model to a time series.
Species measurement errors or dispersions can also be included in the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvOUTS(times, data, error = NULL, param = list(sigma = NULL, alpha = NULL,
    vcv = "randomRoot", decomp = c("cholesky","spherical","eigen","qr",
    "diagonal","upper","lower")), method = c("rpf", "inverse", "pseudoinverse",
    "univarpf"), scale.height = FALSE, optimization = c("L-BFGS-B", "Nelder-Mead", 
    "subplex"), control = list(maxit = 20000), precalc = NULL, diagnostic = TRUE, 
    echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvOUTS_+3A_times">times</code></td>
<td>

<p>Time series - vector of sample ages.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits in columns. NA values are allowed.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous trait sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_param">param</code></td>
<td>

<p>List of arguments to be passed to the function. See details below.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_method">method</code></td>
<td>

<p>Choose between &quot;rpf&quot;, &quot;inverse&quot;, &quot;pseudoinverse&quot;, or &quot;univarpf&quot; for computing the log-likelihood during the fitting process. See details below.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_scale.height">scale.height</code></td>
<td>

<p>Whether the time series should be scaled to unit length or not.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_optimization">optimization</code></td>
<td>

<p>Methods used by the optimization routines (see ?optim and ?subplex for details). The &quot;fixed&quot; method returns the log-likelihood function only.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_control">control</code></td>
<td>

<p>Max. bound for the number of iteration of the optimizer; other options can be fixed in the list (see ?optim or ?subplex).
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_precalc">precalc</code></td>
<td>

<p>Optional. Precalculation of fixed parameters. See ?mvmorph.Precalc for details.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_diagnostic">diagnostic</code></td>
<td>

<p>Whether the convergence diagnostics should be returned or not.
</p>
</td></tr>
<tr><td><code id="mvOUTS_+3A_echo">echo</code></td>
<td>

<p>Whether the results must be returned or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mvOUTS function fits a multivariate model of trait evolution on a time series according to an Ornstein-Uhlenbeck process. The user can include measurement errors to the analyzed dataset.
</p>
<p>The &quot;method&quot; argument allows the user to try different algorithms for computing the log-likelihood. The <em>&quot;rpf&quot;</em>, <em>&quot;univarpf&quot;</em> (for univariate analysis) methods use fast GLS algorithms based on factorization for avoiding the computation of the inverse of the variance-covariance matrix and its determinant for the log-likelihood estimation. The <em>&quot;inverse&quot;</em> approach uses the <em>&quot;stable&quot;</em> standard explicit computation of the inverse and determinant of the matrix and is therefore slower. The <em>&quot;pseudoinverse&quot;</em> method uses a generalized inverse that is safer for matrix near singularity but highly time consuming. See ?mvLL for details.
</p>
<p>Arguments in the <b>&quot;param&quot;</b> <em>list</em> are:
</p>
<p><b>&quot;sigma&quot;</b> or <b>&quot;alpha&quot;</b> - Starting values for the likelihood search can be specified through the &quot;alpha&quot; and &quot;sigma&quot; arguments in the param list. It is also possible to test for the significance of the off-diagonal sigma (scatter) and alpha (drift) matrix in the full model by making comparison with a constrained model (using sigma=&quot;constraint&quot;, or alpha=&quot;constraint&quot;) in the &quot;param&quot; argument list. You can also provide starting values for the constrained model. For instance, for two traits use sigma=list(&quot;constraint&quot;, c(0.5,0.5))  (or alpha=list(&quot;constraint&quot;, c(0.5,0.5))).
</p>
<p><b>&quot;decomp&quot;</b> - You can further constrain the alpha matrix by specifying the decomposition of the matrix through the &quot;decomp&quot; argument in the &quot;param&quot; list. Indeed, the multivariate Ornstein-Uhlenbeck model is described by the spectral decomposition of the alpha matrix. Thus it is possible to parameterize the alpha matrix to be decomposable using various parameterizations (e.g., on its eigenvalues with different biological interpretations; Sy et al. 1997, Bartoszek et al. 2012). For a symmetric matrix parameterization the user can choose the <em>&quot;cholesky&quot;</em>, <em>&quot;eigen&quot;</em>, or <em>&quot;spherical&quot;</em> option. 
For general square (non-symmetric) matrices the <em>&quot;svd&quot;</em>, <em>&quot;qr&quot;</em> and <em>&quot;schur&quot;</em> parameterizations can be used. The <em>&quot;schur&quot;</em> parameterization constrains the eigenvalues of the alpha matrix to be real numbers. The <em>&quot;svd+&quot;</em>, <em>&quot;qr+&quot;</em> or <em>&quot;eigen+&quot;</em> options forces the eigenvalues to be positives by taking their logarithm. It is also possible to specify <em>&quot;diagonal&quot;</em> which is similar to the use of the &quot;constraint&quot; argument for the &quot;alpha&quot; argument, or to use <em>&quot;equal&quot;</em> and <em>&quot;equaldiagonal&quot;</em>. Finally, one can specify that the alpha matrix is <em>&quot;upper&quot;</em> or <em>&quot;lower&quot;</em> triangular (i.e., one process affect the other unilateraly). Details can be found in the package vignette: browseVignettes(&quot;mvMORPH&quot;).
</p>
<p><b>&quot;decompSigma&quot;</b> - The sigma matrix is parameterized by various methods to ensure its positive definiteness (Pinheiro and Bates, 1996). These methods can be accessed through the &quot;decompSigma&quot; argument and are the <em>&quot;cholesky&quot;</em>, <em>&quot;eigen+&quot;</em>, and <em>&quot;spherical&quot;</em> parameterization. The sigma matrix can also be forced to be diagonal using <em>&quot;diagonal&quot;</em> or <em>&quot;equaldiagonal&quot;</em> and forced to have the same variances using <em>&quot;equal&quot;</em>. Details can be found in the package vignette: browseVignettes(&quot;mvMORPH&quot;).
</p>
<p><b>&quot;vcv&quot;</b> - It is possible to specify in the &quot;param&quot; list what kind of variance-covariance matrix to use with the &quot;vcv&quot; argument, depending on how the root is treated. 
The <em>vcv=&quot;randomRoot&quot;</em> option assumes that the value at the root is a random variable with the stationary distribution of the process. The <em>vcv=&quot;fixedRoot&quot;</em> option assumes that the root is a fixed parameter.
</p>
<p><b>&quot;root&quot;</b> - If root=TRUE, the ancestral state and the optimum (stationary mean) are estimated, otherwise (root=FALSE) the ancestral (initial) state and the optimum (long-term expectation) are assumed to be the same.
</p>
<p>Note: for the <b>&quot;decomp&quot;</b> and <b>&quot;decompSigma</b> arguments, an user-defined matrix with integer values taken as indices of the parameters to be estimated can be provided. See ?mvBM and ?mvRWTS.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>LogLik</code></td>
<td>
<p>The log-likelihood of the optimal model.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion for the optimal model.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>Sample size-corrected AIC.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated ancestral states.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Matrix of estimated alpha values (strength of selection, drift matrix).</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Evolutionary rate matrix (scatter).</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence status of the optimizing function; &quot;0&quot; indicates convergence. (See ?optim for details).</p>
</td></tr>
<tr><td><code>hess.values</code></td>
<td>
<p>Reliability of the likelihood estimates calculated through the eigen-decomposition of the hessian matrix. &quot;0&quot; means that a reliable estimate has been reached. See details on ?mvOU.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>List of model fit parameters (optimization, method, model, number of parameters...).</p>
</td></tr>
<tr><td><code>llik</code></td>
<td>
<p>The log-likelihood function evaluated in the model fit &quot;$llik(par, root.mle=TRUE)&quot;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Bartoszek K., Pienaar J., Mostad P., Andersson S., Hansen T.F. 2012. A phylogenetic comparative method for studying multivariate adaptation. J. Theor. Biol. 314:204-215.
</p>
<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods Ecol. Evol. 6(11):1311-1319.
</p>
<p>Hunt G., Bell M.A., Travis M.P. 2008. Evolution toward a new adaptive optimum: phenotypic evolution in a fossil stickleback lineage. Evolution 62(3):700-710.
</p>
<p>Pinheiro J.C., Bates D.M. 1996. Unconstrained parameterizations for variance-covariance matrices. Stat. Comput. 6:289-296.
</p>
<p>Sy J.P., Taylor J.M.G., Cumberland W.G. 1997. A stochastic model for the analysis of bivariate longitudinal AIDS data. Biometrics. 53:542-555.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+halflife">halflife</a></code>
<code><a href="#topic+stationary">stationary</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvRWTS">mvRWTS</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
<code><a href="#topic+LRT">LRT</a></code>
<code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate the time series
set.seed(14)
timeseries &lt;- 0:49
# Parameters with general alpha matrix on two competitive species (or two traits)
# asymetric (drift) matrix with intervention from the lowest layer
alpha &lt;- matrix(c(0.15,0,0.1,0.1),2,2) 
# scatter matrix
sigma &lt;- matrix(c(0.01,0.005,0.005,0.01),2)
# ancestral states and long term optimum expectation
theta &lt;- matrix(c(0,1,0,.5),2) # columns=traits

# Simulate the data
traits &lt;- mvSIM(timeseries, model="OUTS", param=list(theta=theta, alpha=alpha, sigma=sigma))

# Plot the time series
matplot(traits,type="o",pch=1,  xlab="Time (relative)")

fit1 &lt;- mvOUTS(timeseries, traits, param=list(decomp="qr"))

fit2 &lt;- mvOUTS(timeseries, traits, param=list(decomp="eigen"))

fit3 &lt;- mvOUTS(timeseries, traits, param=list(decomp="diagonal"))

results &lt;- list(fit1,fit2,fit3)
aicw(results)

# Simulate under the MLE
traits2 &lt;- simulate(fit1,tree=timeseries)
matplot(traits2, type="o", pch=1, xlab="Time (relative)")

mvOUTS(timeseries, traits2, param=list(decomp="eigen"))
mvOUTS(timeseries, traits2, param=list(decomp="diagonal"))
mvOUTS(timeseries, traits2, param=list(decomp="upper"))
mvOUTS(timeseries, traits2, param=list(decomp="lower"))


# try user defined constraints
set.seed(100)
ts &lt;- 49
timeseries &lt;- 1:ts

sigma &lt;- matrix(c(0.01,0.005,0.003,0.005,0.01,0.003,0.003,0.003,0.01),3)
# upper triangular matrix with effect of trait 2 on trait 1.
alpha &lt;- matrix(c(0.4,0,0,-0.5,0.3,0,0,0,0.2),3,3) 
theta &lt;- matrix(c(0,0,0,1,0.5,0.5),byrow=TRUE, ncol=3); root=TRUE

data &lt;- mvSIM(timeseries, model="OUTS", param=list(alpha=alpha, 
              sigma=sigma, theta=theta, root=root, 
              names_traits=c("sp 1", "sp 2", "sp 3")))

# plot
matplot(data, type="o", pch=1, xlab="Time (relative)")
legend("bottomright", inset=.05, legend=colnames(data), pch=19, col=c(1,2,3), horiz=TRUE)

# define an user constrained drift matrix
indice &lt;- matrix(NA,3,3)
diag(indice) &lt;- c(1,2,3)
indice[1,2] &lt;- 4

# fit the model
fit_1 &lt;- mvOUTS(timeseries, data, param=list(vcv="fixedRoot", decomp=indice))
fit_2 &lt;- mvOUTS(timeseries, data, param=list(vcv="fixedRoot", decomp="diagonal"))

LRT(fit_1, fit_2)




</code></pre>

<hr>
<h2 id='mvqqplot'>
Quantile-Quantile plots for multivariate models fit with <code>mvgls</code> or <code>mvols</code>
</h2><span id='topic+mvqqplot'></span>

<h3>Description</h3>

<p>The quantile-quantile plots of the Chi square distribution is used to assess multivariate normality and detect outliers using the squared Mahalanobis distances from the models residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
mvqqplot(object, conf=0.95, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvqqplot_+3A_object">object</code></td>
<td>

<p>A model fit obtained by the <code>mvgls</code> or <code>mvols</code> function.
</p>
</td></tr>
<tr><td><code id="mvqqplot_+3A_conf">conf</code></td>
<td>

<p>Confidence interval for the approximate envelope. Default is 0.95.</p>
</td></tr>
<tr><td><code id="mvqqplot_+3A_...">...</code></td>
<td>

<p>Graphical options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical quantiles of standardized Mahalanobis distances (Caroni 1987) estimated from models fit by <code>mvgls</code> (or <code>mvols</code>) are compared to the quantiles of a Chi square distribution with 'p' degrees of freedom (where 'p' is the number of dimensions) when models are fit by maximum likelihood (<code>method='LL'</code>). For penalized likelihood model fit (regularized covariance), a matching moments method is used to map the standardized Mahalanobis distances to the Chi square distribution (Clavel, in prep.). This last option is experimental and still under development.
</p>


<h3>Value</h3>

<p>a list with components
</p>
<table role = "presentation">
<tr><td><code>squared_dist</code></td>
<td>
<p>the squared Mahalanobis distances (standardized)</p>
</td></tr>
<tr><td><code>chi2q</code></td>
<td>
<p>the chi squared quantiles</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Chi square Q-Q plots may be outperformed by F based Q-Q plots for identifying outliers (Hardin &amp; Rocke 2005). The function is still under development.</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Caroni, C. 1987. Residuals and Influence in the multivariate linear model. Journal of the Royal Statistical Society 36(4): 365-370.
</p>
<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Clavel, J., Morlon, H. 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+manova.gls">manova.gls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(phyllostomid)

# Fit a linear model by PL
fit &lt;- mvgls(mandible~grp1, data=phyllostomid, phyllostomid$tree, model="lambda", method="PL") 

# QQ plots
mvqqplot(fit, lty=2, conf=0.99)

</code></pre>

<hr>
<h2 id='mvRWTS'>
Multivariate Brownian motion / Random Walk model of continuous traits evolution on time series
</h2><span id='topic+mvRWTS'></span>

<h3>Description</h3>

<p>This function allows the fitting of multivariate Brownian motion/Random walk model on time-series. This function can also fit constrained models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvRWTS(times, data, error = NULL, param =
    list(sigma=NULL, trend=FALSE, decomp="cholesky"), method = c("rpf",
    "inverse", "pseudoinverse"), scale.height = FALSE,
    optimization = c("L-BFGS-B", "Nelder-Mead", "subplex"),
    control = list(maxit = 20000), precalc = NULL, diagnostic = TRUE,
    echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvRWTS_+3A_times">times</code></td>
<td>

<p>Time series - vector of sample ages.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species/sampled points in rows and continuous traits in columns
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species/sampled points in rows and continuous traits sampling variance (squared standard error) in columns.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_param">param</code></td>
<td>

<p>List of arguments to be passed to the function. See details below.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_method">method</code></td>
<td>

<p>Choose between &quot;rpf&quot;, &quot;inverse&quot;, or &quot;pseudoinverse&quot; for log-likelihood computation during the fitting process. See details below.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_scale.height">scale.height</code></td>
<td>

<p>Whether the time series should be scaled to unit length or not.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_optimization">optimization</code></td>
<td>

<p>Methods used by the optimization routines (see ?optim and ?subplex for details). The &quot;fixed&quot; method returns the log-likelihood function only.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_control">control</code></td>
<td>

<p>Max. bound for the number of iteration of the optimizer; other options can be fixed in the list (see ?optim or ?subplex).
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_precalc">precalc</code></td>
<td>

<p>Optional. Precalculation of fixed parameters. See ?mvmorph.Precalc.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_diagnostic">diagnostic</code></td>
<td>

<p>Whether the diagnostics of convergence should be returned or not.
</p>
</td></tr>
<tr><td><code id="mvRWTS_+3A_echo">echo</code></td>
<td>

<p>Whether the results must be returned or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mvRWTS function fits a multivariate Random Walk (RW; i.e., the time series counterpart of the Brownian motion process).
</p>
<p>The &quot;method&quot; argument allows the user to try different algorithms for computing the log-likelihood. The &quot;rpf&quot; and &quot;sparse&quot; methods use fast GLS algorithms based on factorization for avoiding the computation of the inverse of the variance-covariance matrix and its determinant involved in the log-likelihood estimation. The &quot;inverse&quot; approach uses the &quot;stable&quot; standard explicit computation of the inverse and determinant of the matrix and is therefore slower. The &quot;pseudoinverse&quot; method uses a generalized inverse that is safer for matrix near singularity but highly time consuming. See ?mvLL for more details on these computational methods.
</p>
<p>Arguments in the <b> &quot;param&quot;</b> <em>list</em> are:
</p>
<p><b> &quot;constraint&quot;</b> - The &quot;constraint&quot; argument in the &quot;param&quot; list allows the user to compute the joint likelihood for each trait by assuming they evolved independently (<code> constraint="diagonal"</code>, or <code> constraint="equaldiagonal"</code>). If <code> constraint="equal"</code>, the sigma values are constrained to be the same for each trait using the constrained Cholesky decomposition proposed by Adams (2013) or a separation strategy based on spherical parameterization when p&gt;2 (Clavel et al. 2015).
</p>
<p>User-defined constraints can be specified through a numeric matrix (square and symmetric) with integer values taken as indices of the parameters. 
</p>
<p>For instance, for three traits:
</p>
<p><code>constraint=matrix(c(1, 3, 3, 3, 2, 3, 3, 3, 2), 3)</code>. 
</p>
<p>Covariances constrained to be zero are introduced by NA values, e.g., 
</p>
<p><code>constraint=matrix(c(1, 4, 4, 4, 2, NA, 4, NA, 3), 3)</code>. 
</p>
<p>Difference between two nested fitted models can be assessed using the &quot;<code>LRT</code>&quot; function. See example below and ?<code>LRT</code>.
</p>
<p><b> &quot;decomp&quot;</b> - For the general case (unconstrained models), the sigma matrix is parameterized by various methods to ensure its positive definiteness (Pinheiro and Bates, 1996). These methods are the <code>"cholesky"</code>, <code>"eigen+"</code>, and <code>"spherical"</code> parameterizations.
</p>
<p><b> &quot;trend&quot;</b> - Default set to FALSE. If TRUE, the ancestral state is allowed to drift leading to a directional random walk. Note that it is possible to provide a vector of integer indices to constraint the estimated trends when p&gt;1 (see the vignettes).
</p>
<p><b> &quot;sigma&quot;</b> - Starting values for the likelihood estimation. By default the trait covariances are used as starting values for the likelihood optimization. The user can specify starting values as square symmetric matrices or a simple vector of values for the upper factor of the sigma matrix. The parameterization is done using the factorization determined through the &quot;decomp&quot; argument (Pinheiro and Bates, 1996). Thus, you should provide p*(p+1)/2 values, with p the number of traits (e.g., random numbers or the values from the cholesky factor of a symmetric positive definite sigma matrix; see example below). If a constrained model is used, the number of starting values is (p*(p-1)/2)+1.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>LogLik</code></td>
<td>
<p>The log-likelihood of the optimal model.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion for the optimal model.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>Sample size-corrected AIC.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated ancestral states.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Evolutionary rate matrix for each selective regime.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence status of the optimizing function; &quot;0&quot; indicates convergence (see ?optim for details).</p>
</td></tr>
<tr><td><code>hess.values</code></td>
<td>
<p>Reliability of the likelihood estimates calculated through the eigen-decomposition of the hessian matrix. &quot;0&quot; means that a reliable estimate has been reached (see ?mvOU).</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>List of model fit parameters (optimization, method, model, number of parameters...).</p>
</td></tr>
<tr><td><code>llik</code></td>
<td>
<p>The log-likelihood function evaluated in the model fit &quot;$llik(par, root.mle=TRUE)&quot;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Adams D.C. 2013. Comparing evolutionary rates for different phenotypic traits on a phylogeny using likelihood. Syst. Biol. 62:181-192.
</p>
<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods Ecol. Evol., 6(11):1311-1319.
</p>
<p>Hunt G. (2012). Measuring rates of phenotypic evolution and the inseparability of tempo and mode. Paleobiology, 38(3):351-373.
</p>
<p>Revell L.J. 2012. phytools: An R package for phylogenetic comparative biology (and other things). Methods Ecol. Evol. 3:217-223.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
<code><a href="#topic+mvOUTS">mvOUTS</a></code>
<code><a href="#topic+LRT">LRT</a></code>
<code><a href="stats.html#topic+optim">optim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
# Simulate the time series
timeseries &lt;- 0:49

# Simulate the traits
sigma &lt;- matrix(c(0.01,0.005,0.005,0.01),2)
theta &lt;- c(0,1)
error &lt;- matrix(0,ncol=2,nrow=50);error[1,]=0.001
data&lt;-mvSIM(timeseries, error=error, 
            param=list(sigma=sigma, theta=theta), model="RWTS", nsim=1)

# plot the time series
matplot(data, type="o", pch=1, xlab="Time (relative)")

# model fit
mvRWTS(timeseries, data, error=error, param=list(decomp="diagonal"))
mvRWTS(timeseries, data, error=error, param=list(decomp="equal"))
mvRWTS(timeseries, data, error=error, param=list(decomp="cholesky"))

# Random walk with trend
set.seed(1)
trend &lt;- c(0.02,0.02)
data&lt;-mvSIM(timeseries, error=error, 
            param=list(sigma=sigma, theta=theta, trend=trend), model="RWTS", nsim=1)

# plot the time serie
matplot(data, type="o", pch=1, xlab="Time (relative)")

# model fit
mvRWTS(timeseries, data, error=error, param=list(trend=TRUE))

# we can specify a vector of indices
mvRWTS(timeseries, data, error=error, param=list(trend=c(1,1)))

</code></pre>

<hr>
<h2 id='mvSHIFT'>
Multivariate change in mode of continuous trait evolution
</h2><span id='topic+mvSHIFT'></span>

<h3>Description</h3>

<p>This function fits different models of evolution after a fixed point. This allows fitting models of change in mode of evolution following a given event.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvSHIFT(tree, data, error = NULL, param = list(age = NULL, sigma = NULL,
        alpha = NULL, sig = NULL, beta = NULL), model = c("ER", "RR", "EC",
        "RC", "SR", "EBOU", "OUEB", "EBBM", "BMEB"), method = c("rpf",
        "sparse", "inverse", "pseudoinverse"), scale.height = FALSE,
        optimization = c("L-BFGS-B", "Nelder-Mead", "subplex"), control =
        list(maxit = 20000), precalc = NULL, diagnostic = TRUE, echo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvSHIFT_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree with a shift mapped (see &quot;make.era.map&quot; function from &quot;phytools&quot; package). A &quot;phylo&quot; object can be used if the &quot;age&quot; argument is provided in the &quot;param&quot; list.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_data">data</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous traits in columns. NA values are allowed with the &quot;rpf&quot;, &quot;inverse&quot;, and &quot;pseudoinverse&quot; methods.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous trait sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_param">param</code></td>
<td>

<p>List of arguments to be passed to the function. See details.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_model">model</code></td>
<td>

<p>Choose between the different models &quot;OUBM&quot;, &quot;BMOU&quot;, &quot;EBOU&quot;, &quot;OUEB&quot;, &quot;BMEB&quot;, &quot;EBBM&quot;... See details below.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_method">method</code></td>
<td>

<p>Choose between &quot;rpf&quot;, &quot;sparse&quot;, &quot;inverse&quot;, or &quot;pseudoinverse&quot; for computing the log-likelihood during the fitting process. See details below.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_scale.height">scale.height</code></td>
<td>

<p>Whether the tree should be scaled to unit length or not.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_optimization">optimization</code></td>
<td>

<p>Methods used by the optimization routines (see ?optim and ?subplex for details). The &quot;fixed&quot; method returns the log-likelihood function only.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_control">control</code></td>
<td>

<p>Max. bound for the number of iteration of the optimizer; other options can be fixed in the list (see ?optim and ?subplex for details).
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_precalc">precalc</code></td>
<td>

<p>Optional. Precalculation of fixed parameters. See ?mvmorph.Precalc for details.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_diagnostic">diagnostic</code></td>
<td>

<p>Whether the diagnostics of convergence should be returned or not.
</p>
</td></tr>
<tr><td><code id="mvSHIFT_+3A_echo">echo</code></td>
<td>

<p>Whether the results must be returned or not.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mvSHIFT function fits a shift in mode or rate of evolution at a fixed point in time, as previously proposed by some authors (O'Meara et al. 2006; O'Meara, 2012; Slater, 2013). Shift in mode of evolution can be mapped on a modified &quot;phylo&quot; object using the &quot;make.era.map&quot; function from the &quot;phytools&quot; package.
Note that only one shift is allowed by the current version of mvMORPH. The age of the shift can be otherwise directly provided (in unit of times of the tree) in the function by the &quot;age&quot; argument in the &quot;param&quot; list.
</p>
<p>The function allows fitting model with shift from an Orstein-Uhlenbeck to a Brownian motion process and vice-versa (&quot;OUBM&quot; and &quot;BMOU&quot;), shifts from a Brownian motion to/from an Early Burst (ACDC) model (&quot;BMEB&quot; and &quot;EBBM&quot;), or shifts from an Orstein-Uhlenbeck to/from an Early Burst (ACDC) model (&quot;OUEB&quot; and &quot;EBOU&quot;). Note that the shift models with OU process are relevant only if you use fossil species.
</p>
<p>In all these cases it is possible to allow the drift parameter to vary after the fixed point by specifying &quot;i&quot; (for independent) after the model name. For instance, to fit models of &quot;ecological release&quot; or &quot;ecological release and radiate&quot; following Slater (2013), one can use  &quot;OUBM&quot; or &quot;OUBMi&quot;, respectively.
</p>
<p>Alternatively it is also possible to use the shortcuts &quot;ER&quot; or &quot;RR&quot; to fit models of &quot;ecological release&quot; and &quot;ecological release and radiate&quot; respectively, and &quot;EC&quot; for a model of &quot;constrained ecology&quot; (e.g., after invasion of a competitive species in a given ecosystem) where traits are constrained in an Ornstein-Uhlenbeck process after a fixed point in time (&quot;RC&quot; is the same model but assumes an independent rate during the early radiative phase). The &quot;SR&quot; model allows fitting different (Brownian) rates/drift before and after the shift point (note that this model could also be fitted using the mvBM function).
</p>
<p>The &quot;param&quot; list can be used to provide lower and upper bounds for the exponential rate parameter of the Early-Burst/ACDC model. See ?mvEB for details.
</p>
<p>The &quot;method&quot; argument allows the user to try different algorithms for computing the log-likelihood. The &quot;rpf&quot; and &quot;sparse&quot; methods use fast GLS algorithms based on factorization for avoiding the computation of the inverse of the variance-covariance matrix and its determinant involved in the log-likelihood estimation. The &quot;inverse&quot; approach uses the &quot;stable&quot; standard explicit computation of the inverse and determinant of the matrix and is therefore slower. The &quot;pseudoinverse&quot; method uses a generalized inverse that is safer for matrix near singularity but highly time consuming. See ?mvLL for details.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>LogLik</code></td>
<td>
<p>The log-likelihood of the optimal model.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion for the optimal model.</p>
</td></tr>
<tr><td><code>AICc</code></td>
<td>
<p>Sample size-corrected AIC.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated ancestral states.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Matrix of estimated alpha values (strength of selection).</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Exponent rate (of decay or increase) for the ACDC/Early-Burst model.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Evolutionary rate matrix (drift) for the BM process before the shift.</p>
</td></tr>
<tr><td><code>sig</code></td>
<td>
<p>Evolutionary rate matrix (drift) for the BM process after the shift (only for &quot;i&quot; models).</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence status of the optimizing function; &quot;0&quot; indicates convergence (see ?optim for details).</p>
</td></tr>
<tr><td><code>hess.values</code></td>
<td>
<p>Reliability of the likelihood estimates calculated through the eigen-decomposition of the hessian matrix. &quot;0&quot; means that a reliable estimate has been reached (see ?mvOU for details).</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>List of model fit parameters (optimization, method, model, number of parameters...).</p>
</td></tr>
<tr><td><code>llik</code></td>
<td>
<p>The log-likelihood function evaluated in the model fit &quot;$llik(par, root.mle=TRUE)&quot;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Changes in rate of evolution and optima can also be fitted using the mvBM and mvOU functions using a 'make.era.map' transformed tree.
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an R package for fitting multivariate evolutionary models to morphometric data. Methods in Ecology and Evolution, 6(11):1311-1319.
</p>
<p>O'Meara B.C. 2012. Evolutionary inferences from phylogenies: a review of methods. Annu. Rev. Ecol. Evol. Syst. 43:267-285.
</p>
<p>O'Meara B.C., Ane C., Sanderson M.J., Wainwright P.C. 2006. Testing for different rates of continuous trait evolution. Evolution. 60:922-933.
</p>
<p>Slater G.J. 2013. Phylogenetic evidence for a shift in the mode of mammalian body size evolution at the Cretaceous-Palaeogene boundary. Methods Ecol. Evol. 4:734-744.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvOUTS">mvOUTS</a></code>
<code><a href="#topic+mvRWTS">mvRWTS</a></code>
<code><a href="#topic+mvSIM">mvSIM</a></code>
<code><a href="stats.html#topic+optim">optim</a></code>
<code><a href="subplex.html#topic+subplex">subplex</a></code>
<code><a href="phytools.html#topic+paintSubTree">paintSubTree</a></code>
<code><a href="phytools.html#topic+make.era.map">make.era.map</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-rtree(50)

# Providing a tree whith the shift mapped on
tot&lt;-max(nodeHeights(tree))
age=tot-3    # The shift occured 3 Ma ago
tree&lt;-make.era.map(tree,c(0,age))

# Plot of the phylogeny for illustration
plotSimmap(tree,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate the traits
alpha&lt;-matrix(c(2,0.5,0.5,1),2)
sigma&lt;-matrix(c(0.1,0.05,0.05,0.1),2)
theta&lt;-c(2,3)
data&lt;-mvSIM(tree, param=list(sigma=sigma, alpha=alpha, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size")), model="ER", nsim=1)


## Fitting the models
# "Ecological release model"
mvSHIFT(tree, data, model="OUBM") # similar to mvSHIFT(tree, data, model="ER")

# "Release and radiate model"

 mvSHIFT(tree, data, model="RR", method="sparse")
# similar to mvSHIFT(tree, data, model="OUBMi")

# More generally...

# OU to/from BM
 mvSHIFT(tree, data, model="OUBM", method="sparse")
 mvSHIFT(tree, data, model="BMOU", method="sparse")
 mvSHIFT(tree, data, model="OUBMi", method="sparse")
 mvSHIFT(tree, data, model="BMOUi", method="sparse")

# BM to/from EB
 mvSHIFT(tree, data, model="BMEB", method="sparse")
 mvSHIFT(tree, data, model="EBBM", method="sparse")
 mvSHIFT(tree, data, model="BMEBi", method="sparse")
 mvSHIFT(tree, data, model="EBBMi", method="sparse")

# OU to/from EB
 mvSHIFT(tree, data, model="OUEB", method="sparse")
 mvSHIFT(tree, data, model="OUEBi", method="sparse")
 mvSHIFT(tree, data, model="EBOU", method="sparse")
 mvSHIFT(tree, data, model="EBOUi", method="sparse")


## Without providing mapped tree
# The shift occured 3Ma ago (param$age=3)
 set.seed(14)
 tree&lt;-rtree(50)
 data&lt;-mvSIM(tree, param=list(sigma=sigma, alpha=alpha, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size"), age=3), model="ER", nsim=1)

## Fitting the models without mapped tree but by specifying the age in the param list.
 mvSHIFT(tree, data, model="OUBM", param=list(age=3))

</code></pre>

<hr>
<h2 id='mvSIM'>
Simulation of (multivariate) continuous traits on a phylogeny
</h2><span id='topic+mvSIM'></span>

<h3>Description</h3>

<p>This function allows simulating multivariate (as well as univariate) continuous traits evolving according to a BM (Brownian Motion), OU (Ornstein-Uhlenbeck), ACDC (Accelerating rates and Decelerating rates/Early bursts), or SHIFT models of phenotypic evolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvSIM(tree, nsim = 1, error = NULL, model = c("BM1", "BMM", "OU1", "OUM", "EB"),
                        param = list(theta = 0, sigma = 0.1, alpha = 1, beta = 0))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvSIM_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree with mapped ancestral states in SIMMAP format (see make.simmap function from phytools package) or a standard &quot;phylo&quot; object (ape). Or a time-series
</p>
</td></tr>
<tr><td><code id="mvSIM_+3A_nsim">nsim</code></td>
<td>

<p>The number of simulated traits (or datasets for multivariate analysis).
</p>
</td></tr>
<tr><td><code id="mvSIM_+3A_error">error</code></td>
<td>

<p>Matrix or data frame with species in rows and continuous trait sampling variance (squared standard errors) in columns.
</p>
</td></tr>
<tr><td><code id="mvSIM_+3A_model">model</code></td>
<td>

<p>The model of trait evolution for the simulations. Could be any of the models used by the mvBM, mvEB, mvOU and mvSHIFT functions.
</p>
</td></tr>
<tr><td><code id="mvSIM_+3A_param">param</code></td>
<td>

<p>List of parameter arguments used for the simulations. You should provide the sigma (values or matrix), alpha (for OU and SHIFT models), beta (EB and SHIFT), theta (ancestral states), ntraits (the number of traits) or others param arguments used in the models.
Alternatively you can provide a fitted object of class &quot;mvmorph&quot;. See details below.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simulates multivariate (as well as univariate) continuous traits evolving along a given phylogenetic tree or time series according to a BM/RW (Brownian Motion/Random walk), OU (Ornstein-Uhlenbeck), ACDC (Accelerating rates and Decelerating rates/Early Bursts), and SHIFT models of phenotypic evolution. The traits are simulated by random sampling from a Multivariate Normal Distribution (Paradis, 2012).
</p>
<p>The mvSIM function allows simulating continuous trait (univariate or multivariate) evolution along a phylogeny (or a time-series) with user specified parameters or parameters estimated from a previous fit.
</p>
<p>The &quot;simulate&quot; wrapper can also be used with a fitted object of class &quot;mvmorph&quot;:
simulate(object, nsim=1, tree=tree). See example below.
</p>
<p>If parameter values are not provided, the default values are fixed to 1 (sigma, sig, alpha, beta) or to 0 for the mean at the root (ancestral state).
</p>
<p>For the &quot;BMM&quot; model were different parts of the tree have their own rate, a list with one rate (or matrix of rates) per selective regime must be provided.
</p>
<p>For the &quot;OU1&quot; and &quot;OUM&quot; models, the user can specify if the ancestral state (theta0) should be computed (param$root=TRUE), assumed to be at the oldest regime state (param$root=FALSE), or if there is no root and each regimes is at the stationary point (param$root=&quot;stationary&quot;; see also ?mvOU).
</p>
<p>For the &quot;BM1&quot;, &quot;BMM&quot;, and &quot;RWTS&quot; models, a trend can be simulated by providing values to the &quot;trend&quot; argument in the &quot;param&quot; list.
</p>
<p>Traits names can be provided with the &quot;names_traits&quot; argument in the &quot;param&quot; list.
For all the shift models, if the tree is not mapped the age of the shift should be directly provided (in unit of times of the tree) using the &quot;age&quot; argument in the &quot;param&quot; list.
</p>


<h3>Value</h3>

<p>A matrix with simulated traits (columns) for the univariate case, or a list of matrix for the multivariate case (nsim&gt;1).
</p>


<h3>Note</h3>

<p>Ancestral states for Ornstein-Uhlenbeck processes (param$root=TRUE) should be used with non-ultrametric trees.
As this method uses Multivariate Normal distribution (MVN) for simulating the traits, it is advised to avoid its use with very large datasets/trees and rely instead on recursive algorithms (see, e.g., ?rTraitCont from &quot;ape&quot;).
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Paradis E. 2012. Analysis of Phylogenetics and Evolution with R. New York: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+mvEB">mvEB</a></code>
<code><a href="#topic+mvBM">mvBM</a></code>
<code><a href="#topic+mvSHIFT">mvSHIFT</a></code>
<code><a href="#topic+mvRWTS">mvRWTS</a></code>
<code><a href="#topic+mvOUTS">mvOUTS</a></code>
<code><a href="#topic+mvLL">mvLL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simulated dataset
set.seed(14)
# Generating a random tree with 50 species
tree&lt;-pbtree(n=50)

# Setting the regime states of tip species
sta&lt;-as.vector(c(rep("Forest",20),rep("Savannah",30))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

## Simulate trait evolution according to a bivariate "BMM" model
# Number of traits
ntraits&lt;-2
# Number of simulated (pairs of) traits
nsim&lt;-10
# Rates matrices for the "Forest" and the "Savannah" regimes
sigma&lt;-list(Forest=matrix(c(2,0.5,0.5,1),2), Savannah=matrix(c(5,3,3,4),2))
# ancestral states for each traits
theta&lt;-c(0,0)

# Simulate
simul&lt;-mvSIM(tree,nsim=nsim, model="BMM",param=list(ntraits=ntraits,sigma=sigma,theta=theta))

# Try to fit a "BM1" model to the first simulated dataset
model_fit&lt;-mvBM(tree,simul[[1]],model="BM1")

# Use the estimated parameters to simulate new traits!
simul2&lt;-mvSIM(tree,nsim=nsim,param=model_fit)

# or try with generic "simulate" function
simul3&lt;-simulate(model_fit,nsim=nsim,tree=tree)

## Just-for-fun :Comparing parameters

 simul4&lt;-simulate(model_fit,nsim=100,tree=tree)
 
 results&lt;-lapply(simul4,function(x){
    mvBM(tree,x,model="BM1",method="pic", echo=FALSE,diagnostic=FALSE)
    })

 sigma_simul&lt;-sapply(results,function(x){x$sigma})

# comparison between the simulated (black) and the observed (red) multivariate rates
 layout(matrix(1:4, ncol=2))
 for(i in 1:4){
	  hist(sigma_simul[i,], main=paste("Estimated sigma on simulated traits"),
  	xlab="estimated sigma for 100 replicates");abline(v=mean(sigma_simul[i,]),lwd=2);
  	abline(v=model_fit$sigma[i],col="red",lwd=2)
 }
	
</code></pre>

<hr>
<h2 id='pairwise.contrasts'>
Pairwise contrasts
</h2><span id='topic+pairwise.contrasts'></span>

<h3>Description</h3>

<p>Generates pairwise contrasts (for factor levels) from an object fitted by the <code>mvgls</code> or <code>mvols</code> function. This function is used internally in <code>pairwise.glh</code> for the generalized linear hypothesis tests (see also ?manova.gls).</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pairwise.contrasts(object, term=1, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairwise.contrasts_+3A_object">object</code></td>
<td>

<p>A model fit obtained by the <code>mvgls</code> or <code>mvols</code> function.
</p>
</td></tr>
<tr><td><code id="pairwise.contrasts_+3A_term">term</code></td>
<td>

<p>The factor term in the &quot;object&quot; model fit for which all the pairwise contrasts are built.
</p>
</td></tr>
<tr><td><code id="pairwise.contrasts_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed through. Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix of contrasts for all the pairwise comparisons between levels of &quot;term&quot;.
</p>


<h3>Note</h3>

<p>The function assumes &quot;effect&quot; dummy coding for the factor levels (see ?contr.treatment)</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel, J., Morlon, H. 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+manova.gls">manova.gls</a></code>,
<code><a href="#topic+pairwise.glh">pairwise.glh</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("phyllostomid")

# model fit with mandible~"grp2"
fit &lt;- mvgls(mandible~grp2, data=phyllostomid, phyllostomid$tree, model="lambda", method="PL") 

# pairwise tests - note that the first group in lexicographic order (the "intercept") is
# considered as the baseline in R
pairwise.contrasts(fit, term="grp2") 

# We can explicitly estimate each mean (rather than deviations to the baseline)
fitb &lt;- mvgls(mandible~grp2 + 0, data=phyllostomid, phyllostomid$tree, model="lambda", method="PL") 
pairwise.contrasts(fitb, term="grp2") 

</code></pre>

<hr>
<h2 id='pairwise.glh'>
Pairwise multivariate tests between levels of a factor
</h2><span id='topic+pairwise.glh'></span>

<h3>Description</h3>

<p>Performs pairwise multivariate tests (e.g. &quot;Pillai&quot;) on levels of a factor in a model fitted by the <code>mvgls</code> or <code>mvols</code> function. This is achieved by evaluating all the pairwise contrasts using generalized linear hypothesis tests (see also ?manova.gls).</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pairwise.glh(object, term=1, test=c("Pillai", "Wilks", "Hotelling-Lawley", "Roy"),
            adjust="holm", nperm=1000L, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairwise.glh_+3A_object">object</code></td>
<td>

<p>A model fit obtained by the <code>mvgls</code> or <code>mvols</code> function.
</p>
</td></tr>
<tr><td><code id="pairwise.glh_+3A_term">term</code></td>
<td>

<p>The factor term in the &quot;object&quot; model fit on which the pairwise tests should be evaluated.
</p>
</td></tr>
<tr><td><code id="pairwise.glh_+3A_test">test</code></td>
<td>

<p>The multivariate test statistic to compute - &quot;Wilks&quot;, &quot;Pillai&quot;, &quot;Hotelling-Lawley&quot;, or &quot;Roy&quot;</p>
</td></tr>
<tr><td><code id="pairwise.glh_+3A_adjust">adjust</code></td>
<td>

<p>The multiple comparison adjustment. See <code>?p.adjust</code>.</p>
</td></tr>
<tr><td><code id="pairwise.glh_+3A_nperm">nperm</code></td>
<td>

<p>The number of permutations used for building the null distribution of the chosen statistic. Permutation is the only available approach for high-dimensional PL models, but either permutations or parametric tests can be used with maximum likelihood (method &quot;LL&quot; in <code>mvgls</code> and <code>mvols</code>)</p>
</td></tr>
<tr><td><code id="pairwise.glh_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed through. (e.g., <code>nbcores=2L</code> to provide the number of cores used for parallel calculus; <code>parametric=FALSE</code> to obtain permutation instead of parametric tests for maximum likelihood fit; <code>verbose=TRUE</code> to display a progress bar during permutations; <code>rhs=0</code> the &quot;right-hand-side&quot; vector for general linear hypothesis testing. See details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pairwise.glh</code> allows performing multivariate tests (e.g. Pillai's, Wilks, Hotelling-Lawley and Roy largest root) on generalized least squares (GLS) linear model (objects of class &quot;mvgls&quot;) fit by either maximum likelihood (<code>method="LL"</code>) or penalized likelihood (<code>method="PL-LOO"</code>) using the <code>mvgls</code> or <code>mvols</code> function. 
</p>
<p>General Linear Hypothesis of the form:
</p>
<p style="text-align: center;"><code class="reqn">\bold{LB=O}</code>
</p>

<p>is used internally with an <b>L</b> matrix specifying linear combinations (&quot;contrasts&quot;) of the model coefficients (<b>B</b>) for each pairwise comparisons. The right-hand-side matrix <b>O</b> is a constant matrix (of zeros by default) that can be provided through the argument <code>rhs</code> (to test specific values for instance).
</p>
<p>Permutations on high-dimensional datasets is time consuming. You can use the option <code>nbcores</code> to parallelize the computations over several cores using forking in UNIX platforms (default is <code>nbcores=1L</code>). Estimated time to completion is displayed when <code>verbose=TRUE</code>.
</p>


<h3>Value</h3>

<p>An object of class 'pairs.mvgls' which is usually printed. It contains a list including the following components:
</p>
<table role = "presentation">
<tr><td><code>test</code></td>
<td>
<p>the multivariate test statistic used</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>the contrasts used for all the pairwise tests</p>
</td></tr>
<tr><td><code>stat</code></td>
<td>
<p>the statistic calculated for each pairwise comparisons</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>the p-values calculated for each pairwise comparisons</p>
</td></tr>
<tr><td><code>adjust</code></td>
<td>
<p>the adjusted (for multiple comparisons) p-values calculated for each pairwise comparisons</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For PL methods, only the &quot;RidgeArch&quot; penalty is allowed for now. Due to corrections for multiple comparisons, one should ensure that the number of permutations is large enough.</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>
<p>Clavel, J., Morlon, H. 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+pairwise.contrasts">pairwise.contrasts</a></code>,
<code><a href="#topic+manova.gls">manova.gls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("phyllostomid")

# model fit with mandible~"grp2"
fit &lt;- mvgls(mandible~grp2, data=phyllostomid, phyllostomid$tree, model="lambda", method="PL") 

# pairwise tests 
pairwise.glh(fit, term="grp2", test="Pillai", adjust="holm", nperm=1000, verbose=TRUE)

# fit the model by ML (p&lt;n) and use parametric tests
fitb &lt;- mvgls(mandible[,1:5]~grp2, data=phyllostomid, 
              phyllostomid$tree, model="lambda", method="LL") 
pairwise.glh(fitb, term="grp2", test="Pillai", adjust="holm", verbose=TRUE)

# use permutations on ML fit
pairwise.glh(fitb, term="grp2", test="Pillai", adjust="holm", nperm=1000,  parametric=FALSE)

</code></pre>

<hr>
<h2 id='pcaShape'>
Projection of 2D and 3D shapes (from geometric morphometric datasets) on Principal Component Axes (PCA)
</h2><span id='topic+pcaShape'></span>

<h3>Description</h3>

<p>The function extracts the shape changes along PCA (or phylogenetic PCA) axes computed from a linear model obtained by <code>mvgls</code> or <code>mvols</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
pcaShape(object, axis=1, ndim=3, spp=NULL, plot=FALSE, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcaShape_+3A_object">object</code></td>
<td>

<p>A model fit obtained by the <code>mvgls</code> or <code>mvols</code> function.
</p>
</td></tr>
<tr><td><code id="pcaShape_+3A_axis">axis</code></td>
<td>

<p>PC axis on which the shape data will be projected.</p>
</td></tr>
<tr><td><code id="pcaShape_+3A_ndim">ndim</code></td>
<td>

<p>The number of dimensions of the GMM data set (2 for 2D and 3 for 3D).
</p>
</td></tr>
<tr><td><code id="pcaShape_+3A_spp">spp</code></td>
<td>

<p>Names of the species (should match names in the dataset) shape to project onto the PC axis. If null, the two extreme shapes along <code>axis</code> are reported. 
</p>
</td></tr>
<tr><td><code id="pcaShape_+3A_plot">plot</code></td>
<td>

<p>Should the projected landmarks be plotted?
</p>
</td></tr>
<tr><td><code id="pcaShape_+3A_...">...</code></td>
<td>

<p>Further options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will project the shape changes along PC axes obtained from models fit by <code>mvgls</code> (or <code>mvols</code>).  This can be used to display main (evolutionary) morphological changes for 2D and 3D geometric morphometric data. See for instance Clavel et al. 2019.
</p>


<h3>Value</h3>

<p>a list with 2D or 3D coordinates for the shape projected on the selected PC axis.
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Claude, J., 2008. Morphometrics with R. Springer Science.
</p>
<p>Clavel, J., Aristide, L., Morlon, H., 2019. A Penalized Likelihood framework for high-dimensional phylogenetic comparative methods and an application to new-world monkeys brain evolution. Systematic Biology 68(1): 93-116.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls">mvgls</a></code>,
<code><a href="#topic+mvols">mvols</a></code>,
<code><a href="#topic+mvgls.pca">mvgls.pca</a></code>
<code><a href="#topic+dfaShape">dfaShape</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(phyllostomid)

# Fit a linear model by PL
fit &lt;- mvgls(mandible[,-1]~grp1, data=phyllostomid, phyllostomid$tree, model="lambda", method="PL") 

# Project the mandible shape of Ametrida bat genus 
proj_shape &lt;- pcaShape(fit, axis=1, ndim=2, spp="Ametrida", plot=TRUE)

polygon(proj_shape$Ametrida)


</code></pre>

<hr>
<h2 id='phyllostomid'>
Phylogeny and trait data for a sample of Phyllostomid bats
</h2><span id='topic+phyllostomid'></span>

<h3>Description</h3>

<p>Phylogeny, diet, and morphological variables for 49 species of Phyllostomid bats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("phyllostomid")</code></pre>


<h3>Details</h3>

<p>Illustrative phylogeny (<em>phyllostomid$tree</em>) and morphological data (<em>phyllostomid$mandible</em> - 73 variables composed of the superimposed procrustes 2D-coordinates for the mandible and the condylobasal length) of 49 species of Phyllostomid bats from Monteiro &amp; Nogueira (2011). The firsts 22 coordinates represent anatomical landmarks and the last 50 coordinates are semilandmarks.
</p>
<p>The four grouping factor variables (e.g., <em>phyllostomid$grp1</em>, <em>phyllostomid$grp2</em>, ...) are the adaptive regime models for association between mandible morphology and diet considered in Monteiro &amp; Nogueira (2011).
</p>


<h3>References</h3>

<p>Monteiro L.R., Nogueira M.R. 2011. Evolutionary patterns and processes in the radiation of phyllostomid bats. BMC Evolutionary Biology. 11:1-23.
</p>
<p>Clavel, J., Morlon, H. 2020. Reliable phylogenetic regressions for multivariate comparative data: illustration with the MANOVA and application to the effect of diet on mandible morphology in phyllostomid bats. Systematic Biology 69(5): 927-943.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(phyllostomid)
plot(phyllostomid$tree)
head(phyllostomid$mandible)


# Fit a linear model by PL
fit1 &lt;- mvgls(mandible~grp1, data=phyllostomid, phyllostomid$tree, model="lambda", method="LOO") 

# regularized MANOVA test
(manova.gls(fit1, test="Wilks", verbose=TRUE))

</code></pre>

<hr>
<h2 id='predict'>
Predictions from (multivariate) gls or ols model fit
</h2><span id='topic+predict.mvgls'></span>

<h3>Description</h3>

<p>Returns the prediction(s) of a linear model of class 'mvgls'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'mvgls'
predict(object, newdata, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_+3A_object">object</code></td>
<td>

<p>an object of class 'mvgls' obtained from a <code>mvgls</code> or <code>mvols</code> fit.
</p>
</td></tr>
<tr><td><code id="predict_+3A_newdata">newdata</code></td>
<td>

<p>a dataframe with new observation(s). The column names must match the names of the predictors in the model fit object. The type (e.g. factors, numeric) must also match the type of the predictors in the model fit object.
Note: the fitted values are simply returned if &quot;newdata&quot; is not provided.
</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>

<p>further arguments for this generic function. For models fit by <code>mvgls</code>, if <code>tree</code> is provided (with tip name(s) matching rowname(s) in newdata and in the training (model fit) dataset), then the best unbiased linear prediction (BLUP) for the model is returned. Otherwise the GLS coefficients are used to predict &quot;newdata&quot;.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the predictions for the linear model fitted by <code>mvgls</code> or <code>mvols</code>.
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitted.mvgls">fitted.mvgls</a></code> 
<code><a href="#topic+vcov.mvgls">vcov.mvgls</a></code> 
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+coef.mvgls">coef.mvgls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
</p>

<hr>
<h2 id='predict.mvgls.dfa'>
Predictions from Discriminant analysis conducted with a mvgls model fit
</h2><span id='topic+predict.mvgls.dfa'></span>

<h3>Description</h3>

<p>Returns the prediction(s) of DFA of class 'mvgls.dfa'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'mvgls.dfa'
predict(object, newdata, prior, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.mvgls.dfa_+3A_object">object</code></td>
<td>

<p>an object of class 'mvgls' obtained from a <code>mvgls</code> or <code>mvols</code> fit.
</p>
</td></tr>
<tr><td><code id="predict.mvgls.dfa_+3A_newdata">newdata</code></td>
<td>

<p>a matrix with new observation(s) for the response variables. 
Note: the predictions are performed on fitted values if &quot;newdata&quot; is not provided.
</p>
</td></tr>
<tr><td><code id="predict.mvgls.dfa_+3A_prior">prior</code></td>
<td>

<p>the group priors. If not provided, assumes equal prior.
</p>
</td></tr>
<tr><td><code id="predict.mvgls.dfa_+3A_...">...</code></td>
<td>

<p>further arguments for this generic function. If <code>tree</code> is provided (with tip name(s) matching rownames in newdata and in the training sample (model fit)), then the best unbiased linear prediction (BLUP) for the model is returned. Otherwise the GLS coefficients are used to predict &quot;newdata&quot;, in this condition classification might be less optimal than performing a regular DFA (see <code>lda</code> from MASS or mvgls.dfa on a <code>mvols</code> fit).
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>class</code></td>
<td>
<p>The class assigned to each new observations</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>The posterior probabilities used to classify each new observations</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>The prior used to classify each new observations to each categories</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>References</h3>

<p>Duhamel A. et al. in prep.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvgls.dfa">mvgls.dfa</a></code> 
<code><a href="#topic+predict.mvgls">predict.mvgls</a></code> 
<code><a href="#topic+fitted.mvgls">fitted.mvgls</a></code> 
<code><a href="#topic+vcov.mvgls">vcov.mvgls</a></code> 
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+coef.mvgls">coef.mvgls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mvMORPH)
n=64
p=4

tree &lt;- pbtree(n=n)
sigma &lt;- crossprod(matrix(runif(p*p),p,p))
resid &lt;- mvSIM(tree, model="BM1", param=list(sigma=sigma))
Y &lt;- rep(c(0,1.5), each=n/2) + resid
grp &lt;- as.factor(rep(c("gp1","gp2"),each=n/2))
names(grp) = rownames(Y)
data &lt;- list(Y=Y, grp=grp)
mod &lt;- mvgls(Y~grp, data=data, tree=tree, model="BM")

# fda
da1 &lt;- mvgls.dfa(mod)


</code></pre>

<hr>
<h2 id='pruning'>
Pruning algorithm to compute the square root of the phylogenetic covariance matrix and its determinant.
</h2><span id='topic+pruning'></span>

<h3>Description</h3>

<p>This function uses the pruning algorithm (Felsenstein 1973) to efficiently compute the determinant of the phylogenetic covariance matrix as well as the square root of this matrix (or its inverse; Stone 2011, Khabbazian et al. 2016). This algorithm is faster than using &quot;eigen&quot; or &quot;cholesky&quot; function to compute the determinant or the square root (see e.g., Clavel et al. 2015) and can be used to compute independent contrasts scores and the log-likelihood of a model in linear time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pruning(tree, inv=TRUE, scaled=TRUE, trans=TRUE, check=TRUE)
</code></pre>


<h3>Arguments</h3>

 
<table role = "presentation">
<tr><td><code id="pruning_+3A_tree">tree</code></td>
<td>

<p>Phylogenetic tree (an object of class &quot;phylo&quot; or &quot;simmap&quot;).
</p>
</td></tr>
<tr><td><code id="pruning_+3A_inv">inv</code></td>
<td>

<p>Return the matrix square root of either the covariance matrix (inv=FALSE) or its inverse (inv=TRUE, the default). This matrix is a &quot;contrasts&quot; matrix.
</p>
</td></tr>
<tr><td><code id="pruning_+3A_scaled">scaled</code></td>
<td>

<p>Indicates whether the contrasts should be scaled with their expected variances (default to TRUE).
</p>
</td></tr>
<tr><td><code id="pruning_+3A_trans">trans</code></td>
<td>

<p>Return the transpose (trans=TRUE) of the matrix square root/contrasts matrix.
(by default - i.e., trans=TRUE - it returns a matrix equivalent to the upper triangular Cholesky factor)
</p>
</td></tr>
<tr><td><code id="pruning_+3A_check">check</code></td>
<td>

<p>Check if the input tree is dichotomous and in &quot;postorder&quot; (see ?is.binary.tree and ?reorder.phylo).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tree is assumed to be fully dichotomic and in &quot;postorder&quot;, otherwise the functions <em>multi2di</em> and <em>reorder.phylo</em> are used internally when <em>check=TRUE</em>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>sqrtMat</code></td>
<td>
<p>The matrix square root (contrasts matrix) </p>
</td></tr>
<tr><td><code>varNode</code></td>
<td>
<p>Variance associated to each node values (similar to &quot;contrasts&quot; variance)</p>
</td></tr>
<tr><td><code>varRoot</code></td>
<td>
<p>Variance associated to the root value (similar to the ancestral state variance)</p>
</td></tr>
<tr><td><code>det</code></td>
<td>
<p>Log-determinant of the phylogenetic covariance of the tree</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Clavel J., Escarguel G., Merceron G. 2015. mvMORPH: an r package for fitting multivariate evolutionary models to morphometric data. Methods Ecol. Evol. 6:1311-1319.
</p>
<p>Felsenstein J. 1973. Maximum-likelihood estimation of evolutionary trees from continuous characters. Am. J. Hum. Genet. 25:471-492.
</p>
<p>Khabbazian M., Kriebel R., Rohe K., Ane C. 2016. Fast and accurate detection of evolutionary shifts in Ornstein-Uhlenbeck models. Methods Ecol. Evol. 7:811-824.
</p>
<p>Stone E.A. 2011. Why the phylogenetic regression appears robust to tree misspecification. Syst. Biol. 60:245-260
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvLL">mvLL</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)
Y &lt;- mvSIM(tree, model="BM1", param=list(sigma=1, theta=0)) # trait
X &lt;- matrix(1, nrow=Ntip(tree), ncol=1) # design matrix

## Use the GLS trick
# Compute the matrix square root
C &lt;- vcv.phylo(tree)
D &lt;- chol(C)
Cinv &lt;- solve(C)
Di &lt;- chol(Cinv)

# transform the traits
Xi &lt;- Di%*%X
Yi &lt;- Di%*%Y

# Compute the GLS estimate and determinant (see Clavel et al. 2015)
# GLS estimate for the root
print(pseudoinverse(Xi)%*%Yi)

# Determinant of the phylogenetic covariance matrix
print(sum(log(diag(D)^2)))    


## Use the pruning algorithm (much faster)

M &lt;- pruning(tree, inv=TRUE)

Xi &lt;- M$sqrtMat%*%X
Yi &lt;- M$sqrtMat%*%Y

# GLS estimate
print(pseudoinverse(Xi)%*%Yi)

# determinant
print(M$det)

## REML determinant (without variance of the root state; see Felsenstein 1973)
# full REML
log(det(C)) + log(det(t(X)%*%Cinv%*%X))

# pruning REML
sum(log(M$varNode))

</code></pre>

<hr>
<h2 id='residuals'>
Extract gls (or ols) model residuals
</h2><span id='topic+residuals.mvgls'></span>

<h3>Description</h3>

<p>Returns the residuals of a linear model of class 'mvgls'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'mvgls'
residuals(object, type, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residuals_+3A_object">object</code></td>
<td>

<p>an object of class 'mvgls' obtained from a <code>mvgls</code> or <code>mvols</code> fit.
</p>
</td></tr>
<tr><td><code id="residuals_+3A_type">type</code></td>
<td>

<p>an optional character string specifying the type of residuals to be used. To match conventions used in the <em>nlme</em> package: if &quot;<code>response</code>&quot;, the &quot;raw&quot; residuals (observed-fitted) are used; else, if &quot;normalized&quot;, the normalized residuals (the residuals pre-multiplied by the inverse square-root factor of the estimated (between observations) covariance matrix) are used. Note however that there is still between variables correlations with both types.
</p>
</td></tr>
<tr><td><code id="residuals_+3A_...">...</code></td>
<td>

<p>other arguments for this generic function (not used).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the residuals for the linear model fitted by <code>mvgls</code> or <code>mvols</code>.
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>See Also</h3>

<p><code><a href="#topic+vcov.mvgls">vcov.mvgls</a></code> 
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+coef.mvgls">coef.mvgls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
</p>

<hr>
<h2 id='stationary'>
The stationary variance of an Ornstein-Uhlenbeck process
</h2><span id='topic+stationary'></span>

<h3>Description</h3>

<p>This function returns the stationary variance for an Ornstein-Uhlenbeck process (object of class &quot;ou&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stationary(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stationary_+3A_object">object</code></td>
<td>

<p>Object fitted with the &quot;mvOU&quot; function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the dispersion parameter of the Ornstein-Uhlenbeck process (i.e., the expected variance when the process is stationary).
The multivariate normal stationary distribution of the Ornstein-Uhlenbeck process is computed following Bartoszek et al. (2012).
</p>


<h3>Value</h3>

<p>The stationary variance-covariance matrix of the OU process
</p>


<h3>Author(s)</h3>

<p>Julien Clavel
</p>


<h3>References</h3>

<p>Bartoszek K., Pienaar J., Mostad P., Andersson S., Hansen T.F. 2012. A phylogenetic comparative method for studying multivariate adaptation. J. Theor. Biol. 314:204-215.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mvMORPH">mvMORPH</a></code>
<code><a href="#topic+mvOU">mvOU</a></code>
<code><a href="#topic+halflife">halflife</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated dataset
set.seed(14)
# Generating a random tree
tree&lt;-pbtree(n=50)

# Setting the regime states of tip species
sta&lt;-as.vector(c(rep("Forest",20),rep("Savannah",30))); names(sta)&lt;-tree$tip.label

# Making the simmap tree with mapped states
tree&lt;-make.simmap(tree,sta , model="ER", nsim=1)
col&lt;-c("blue","orange"); names(col)&lt;-c("Forest","Savannah")

# Plot of the phylogeny for illustration
plotSimmap(tree,col,fsize=0.6,node.numbers=FALSE,lwd=3, pts=FALSE)

# Simulate the traits
alpha&lt;-matrix(c(2,0.5,0.5,1),2)
sigma&lt;-matrix(c(0.1,0.05,0.05,0.1),2)
theta&lt;-c(2,3,1,1.3)
data&lt;-mvSIM(tree, param=list(sigma=sigma, alpha=alpha, ntraits=2, theta=theta,
            names_traits=c("head.size","mouth.size")), model="OUM", nsim=1)

## Fitting the models
# OUM - Analysis with multiple optima
result&lt;-mvOU(tree, data)

stationary(result)

# Expected values when the process is stationary
expected&lt;-list(alpha=alpha,sigma=sigma)
class(expected)&lt;-c("mvmorph","mvmorph.ou")
stationary(expected)

</code></pre>

<hr>
<h2 id='vcov'>
Calculate variance-covariance matrix for a fitted object of class 'mvgls'
</h2><span id='topic+vcov.mvgls'></span>

<h3>Description</h3>

<p>Returns the variance-covariance matrix of the coefficients or the traits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'mvgls'
vcov(object, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vcov_+3A_object">object</code></td>
<td>

<p>an object of class 'mvgls' obtained from a <code>mvgls</code> or <code>mvols</code> fit.
</p>
</td></tr>
<tr><td><code id="vcov_+3A_...">...</code></td>
<td>

<p>additional arguments for methods function. See <em>details</em> below.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>vcov</code> function returns by default the variance-covariance matrix of the main parameters of a fitted model object. The main parameters are the coefficients (this correspond to the argument <code>type="coef"</code>; see also <code>coef.mvgls</code>). With <code>type="covariance"</code>, the <code>vcov.mvgls</code> function returns the estimated traits covariance matrix (possibly regularized for PL approaches) while <code>type="precision"</code> return the precision matrix (i.e. the inverse of the covariance).
</p>


<h3>Value</h3>

<p>A matrix of the estimated covariances between the parameter estimates (of type &quot;coef&quot;, &quot;covariance&quot;, or &quot;precision&quot;).
</p>


<h3>Author(s)</h3>

<p>J. Clavel</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.mvgls">coef.mvgls</a></code> 
<code><a href="#topic+residuals.mvgls">residuals.mvgls</a></code>
<code><a href="#topic+fitted.mvgls">fitted.mvgls</a></code>
<code><a href="#topic+mvgls">mvgls</a></code>
<code><a href="#topic+mvols">mvols</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
