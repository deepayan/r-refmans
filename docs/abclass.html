<!DOCTYPE html><html><head><title>Help for package abclass</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {abclass}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abclass-package'><p>Multi-Category Angle-Based Large-Margin Classifiers</p></a></li>
<li><a href='#abclass'><p>Multi-Category Angle-Based Classification</p></a></li>
<li><a href='#coef.abclass'><p>Coefficient Estimates of A Trained Angle-Based Classifier</p></a></li>
<li><a href='#coef.supclass'><p>Coefficient Estimates of A Trained Sup-Norm Classifier</p></a></li>
<li><a href='#cv.abclass'><p>Tune Angle-Based Classifiers by Cross-Validation</p></a></li>
<li><a href='#cv.supclass'><p>Tune Sup-Norm Classifiers by Cross-Validation</p></a></li>
<li><a href='#et.abclass'><p>Tune Angle-Based Classifiers by ET-Lasso</p></a></li>
<li><a href='#predict.abclass'><p>Prediction by A Trained Angle-Based Classifier</p></a></li>
<li><a href='#predict.supclass'><p>Predictions from A Trained Sup-Norm Classifier</p></a></li>
<li><a href='#supclass'><p>Multi-Category Classifiers with Sup-Norm Regularization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Angle-Based Large-Margin Classifiers</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Multi-category angle-based large-margin classifiers.
    See Zhang and Liu (2014) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasu017">doi:10.1093/biomet/asu017</a>&gt; for details.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, parallel, stats</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Matrix, Rglpk, qpmadr, tinytest</td>
</tr>
<tr>
<td>Copyright:</td>
<td>Eli Lilly and Company</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://wwenjie.org/abclass">https://wwenjie.org/abclass</a>,
<a href="https://github.com/wenjie2wang/abclass">https://github.com/wenjie2wang/abclass</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/wenjie2wang/abclass/issues">https://github.com/wenjie2wang/abclass/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-18 04:01:22 UTC; wenjie</td>
</tr>
<tr>
<td>Author:</td>
<td>Wenjie Wang <a href="https://orcid.org/0000-0003-0363-3180"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Eli Lilly and Company [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Wenjie Wang &lt;wang@wwenjie.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-18 04:36:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='abclass-package'>Multi-Category Angle-Based Large-Margin Classifiers</h2><span id='topic+abclass-package'></span>

<h3>Description</h3>

<p>This package provides implementations of the multi-category angle-based
classifiers (Zhang &amp; Liu, 2014) with the large-margin unified machines (Liu,
et al., 2011) for high-dimensional data.
</p>


<h3>References</h3>

<p>Zhang, C., &amp; Liu, Y. (2014). Multicategory Angle-Based Large-Margin
Classification. <em>Biometrika</em>, 101(3), 625&ndash;640.
</p>
<p>Liu, Y., Zhang, H. H., &amp; Wu, Y. (2011). Hard or soft classification?
large-margin unified machines. <em>Journal of the American Statistical
Association</em>, 106(493), 166&ndash;177.
</p>

<hr>
<h2 id='abclass'>Multi-Category Angle-Based Classification</h2><span id='topic+abclass'></span><span id='topic+abclass.control'></span>

<h3>Description</h3>

<p>Multi-category angle-based large-margin classifiers with regularization by
the elastic-net or groupwise penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abclass(
  x,
  y,
  intercept = TRUE,
  weight = NULL,
  loss = c("logistic", "boost", "hinge-boost", "lum"),
  control = list(),
  ...
)

abclass.control(
  lambda = NULL,
  alpha = 1,
  nlambda = 50L,
  lambda_min_ratio = NULL,
  grouped = TRUE,
  group_weight = NULL,
  group_penalty = c("lasso", "scad", "mcp"),
  dgamma = 1,
  lum_a = 1,
  lum_c = 1,
  boost_umin = -5,
  maxit = 100000L,
  epsilon = 1e-04,
  standardize = TRUE,
  varying_active_set = TRUE,
  verbose = 0L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abclass_+3A_x">x</code></td>
<td>
<p>A numeric matrix representing the design matrix.  No missing valus
are allowed.  The coefficient estimates for constant columns will be
zero.  Thus, one should set the argument <code>intercept</code> to <code>TRUE</code>
to include an intercept term instead of adding an all-one column to
<code>x</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_y">y</code></td>
<td>
<p>An integer vector, a character vector, or a factor vector
representing the response label.</p>
</td></tr>
<tr><td><code id="abclass_+3A_intercept">intercept</code></td>
<td>
<p>A logical value indicating if an intercept should be
considered in the model.  The default value is <code>TRUE</code> and the
intercept is excluded from regularization.</p>
</td></tr>
<tr><td><code id="abclass_+3A_weight">weight</code></td>
<td>
<p>A numeric vector for nonnegative observation weights. Equal
observation weights are used by default.</p>
</td></tr>
<tr><td><code id="abclass_+3A_loss">loss</code></td>
<td>
<p>A character value specifying the loss function.  The available
options are <code>"logistic"</code> for the logistic deviance loss,
<code>"boost"</code> for the exponential loss approximating Boosting machines,
<code>"hinge-boost"</code> for hybrid of SVM and AdaBoost machine, and
<code>"lum"</code> for largin-margin unified machines (LUM).  See Liu, et
al. (2011) for details.</p>
</td></tr>
<tr><td><code id="abclass_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See <code>abclass.control()</code>
for details.</p>
</td></tr>
<tr><td><code id="abclass_+3A_...">...</code></td>
<td>
<p>Other control parameters passed to <code>abclass.control()</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_lambda">lambda</code></td>
<td>
<p>A numeric vector specifying the tuning parameter
<em>lambda</em>.  A data-driven <em>lambda</em> sequence will be generated
and used according to specified <code>alpha</code>, <code>nlambda</code> and
<code>lambda_min_ratio</code> if this argument is left as <code>NULL</code> by
default.  The specified <code>lambda</code> will be sorted in decreasing order
internally and only the unique values will be kept.</p>
</td></tr>
<tr><td><code id="abclass_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value in [0, 1] representing the mixing parameter
<em>alpha</em>.  The default value is <code>1.0</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_nlambda">nlambda</code></td>
<td>
<p>A positive integer specifying the length of the internally
generated <em>lambda</em> sequence.  This argument will be ignored if a
valid <code>lambda</code> is specified.  The default value is <code>50</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_lambda_min_ratio">lambda_min_ratio</code></td>
<td>
<p>A positive number specifying the ratio of the
smallest lambda parameter to the largest lambda parameter.  The default
value is set to <code>1e-4</code> if the sample size is larger than the number
of predictors, and <code>1e-2</code> otherwise.</p>
</td></tr>
<tr><td><code id="abclass_+3A_grouped">grouped</code></td>
<td>
<p>A logicial value.  Experimental flag to apply group
penalties.</p>
</td></tr>
<tr><td><code id="abclass_+3A_group_weight">group_weight</code></td>
<td>
<p>A numerical vector with nonnegative values representing
the adaptive penalty factors for the specified group penalty.</p>
</td></tr>
<tr><td><code id="abclass_+3A_group_penalty">group_penalty</code></td>
<td>
<p>A character vector specifying the name of the group
penalty.</p>
</td></tr>
<tr><td><code id="abclass_+3A_dgamma">dgamma</code></td>
<td>
<p>A positive number specifying the increment to the minimal
gamma parameter for group SCAD or group MCP.</p>
</td></tr>
<tr><td><code id="abclass_+3A_lum_a">lum_a</code></td>
<td>
<p>A positive number greater than one representing the parameter
<em>a</em> in LUM, which will be used only if <code>loss = "lum"</code>.  The
default value is <code>1.0</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_lum_c">lum_c</code></td>
<td>
<p>A nonnegative number specifying the parameter <em>c</em> in LUM,
which will be used only if <code>loss = "hinge-boost"</code> or <code>loss =
"lum"</code>.  The default value is <code>1.0</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_boost_umin">boost_umin</code></td>
<td>
<p>A negative number for adjusting the boosting loss for the
internal majorization procedure.</p>
</td></tr>
<tr><td><code id="abclass_+3A_maxit">maxit</code></td>
<td>
<p>A positive integer specifying the maximum number of iteration.
The default value is <code>10^5</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_epsilon">epsilon</code></td>
<td>
<p>A positive number specifying the relative tolerance that
determines convergence.  The default value is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="abclass_+3A_standardize">standardize</code></td>
<td>
<p>A logical value indicating if each column of the design
matrix should be standardized internally to have mean zero and standard
deviation equal to the sample size.  The default value is <code>TRUE</code>.
Notice that the coefficient estimates are always returned on the
original scale.</p>
</td></tr>
<tr><td><code id="abclass_+3A_varying_active_set">varying_active_set</code></td>
<td>
<p>A logical value indicating if the active set
should be updated after each cycle of coordinate-majorization-descent
algorithm.  The default value is <code>TRUE</code> for usually more efficient
estimation procedure.</p>
</td></tr>
<tr><td><code id="abclass_+3A_verbose">verbose</code></td>
<td>
<p>A nonnegative integer specifying if the estimation procedure
is allowed to print out intermediate steps/results.  The default value
is <code>0</code> for silent estimation procedure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>abclass()</code> returns an object of class
<code>abclass</code> representing a trained classifier; The function
<code>abclass.control()</code> returns an object of class abclass.control
representing a list of control parameters.
</p>


<h3>References</h3>

<p>Zhang, C., &amp; Liu, Y. (2014). Multicategory Angle-Based Large-Margin
Classification. <em>Biometrika</em>, 101(3), 625&ndash;640.
</p>
<p>Liu, Y., Zhang, H. H., &amp; Wu, Y. (2011). Hard or soft classification?
large-margin unified machines. <em>Journal of the American Statistical
Association</em>, 106(493), 166&ndash;177.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(abclass)
set.seed(123)

## toy examples for demonstration purpose
## reference: example 1 in Zhang and Liu (2014)
ntrain &lt;- 100 # size of training set
ntest &lt;- 100  # size of testing set
p0 &lt;- 5       # number of actual predictors
p1 &lt;- 5       # number of random predictors
k &lt;- 5        # number of categories

n &lt;- ntrain + ntest; p &lt;- p0 + p1
train_idx &lt;- seq_len(ntrain)
y &lt;- sample(k, size = n, replace = TRUE)         # response
mu &lt;- matrix(rnorm(p0 * k), nrow = k, ncol = p0) # mean vector
## normalize the mean vector so that they are distributed on the unit circle
mu &lt;- mu / apply(mu, 1, function(a) sqrt(sum(a ^ 2)))
x0 &lt;- t(sapply(y, function(i) rnorm(p0, mean = mu[i, ], sd = 0.25)))
x1 &lt;- matrix(rnorm(p1 * n, sd = 0.3), nrow = n, ncol = p1)
x &lt;- cbind(x0, x1)
train_x &lt;- x[train_idx, ]
test_x &lt;- x[- train_idx, ]
y &lt;- factor(paste0("label_", y))
train_y &lt;- y[train_idx]
test_y &lt;- y[- train_idx]

## Regularization through ridge penalty
control1 &lt;- abclass.control(nlambda = 5, lambda_min_ratio = 1e-3,
                            alpha = 1, grouped = FALSE)
model1 &lt;- abclass(train_x, train_y, loss = "logistic",
                  control = control1)
pred1 &lt;- predict(model1, test_x, s = 5)
table(test_y, pred1)
mean(test_y == pred1) # accuracy

## groupwise regularization via group lasso
model2 &lt;- abclass(train_x, train_y, loss = "boost",
                  grouped = TRUE, nlambda = 5)
pred2 &lt;- predict(model2, test_x, s = 5)
table(test_y, pred2)
mean(test_y == pred2) # accuracy
</code></pre>

<hr>
<h2 id='coef.abclass'>Coefficient Estimates of A Trained Angle-Based Classifier</h2><span id='topic+coef.abclass'></span>

<h3>Description</h3>

<p>Extract coefficient estimates from an <code>abclass</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abclass'
coef(object, selection = c("cv_1se", "cv_min", "all"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.abclass_+3A_object">object</code></td>
<td>
<p>An object of class <code>abclass</code>.</p>
</td></tr>
<tr><td><code id="coef.abclass_+3A_selection">selection</code></td>
<td>
<p>An integer vector for the indices of solution path or a
character value specifying how to select a particular set of coefficient
estimates from the entire solution path.  If the specified
<code>abclass</code> object contains the cross-validation results, one may set
<code>selection</code> to <code>"cv_min"</code> (or <code>"cv_1se"</code>) for the
estimates giving the smallest cross-validation error (or the set of
estimates resulted from the largest <em>lambda</em> within one standard
error of the smallest cross-validation error).  The entire solution path
will be returned in an array if <code>selection = "all"</code> or no
cross-validation results are available in the specified <code>abclass</code>
object.</p>
</td></tr>
<tr><td><code id="coef.abclass_+3A_...">...</code></td>
<td>
<p>Other arguments not used now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix representing the coefficient estimates or an array
representing all the selected solutions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples of `abclass()`.

</code></pre>

<hr>
<h2 id='coef.supclass'>Coefficient Estimates of A Trained Sup-Norm Classifier</h2><span id='topic+coef.supclass'></span>

<h3>Description</h3>

<p>Extract coefficient estimates from an <code>supclass</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'supclass'
coef(object, selection = c("cv_1se", "cv_min", "all"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.supclass_+3A_object">object</code></td>
<td>
<p>An object of class <code>supclass</code>.</p>
</td></tr>
<tr><td><code id="coef.supclass_+3A_selection">selection</code></td>
<td>
<p>An integer vector for the indices of solution or a
character value specifying how to select a particular set of coefficient
estimates from the entire solution path.  If the specified
<code>supclass</code> object contains the cross-validation results, one may
set <code>selection</code> to <code>"cv_min"</code> (or <code>"cv_1se"</code>) for the
estimates giving the smallest cross-validation error (or the set of
estimates resulted from the largest <em>lambda</em> within one standard
error of the smallest cross-validation error).  The entire solution path
will be returned in an array if <code>selection = "all"</code> or no
cross-validation results are available in the specified <code>supclass</code>
object.</p>
</td></tr>
<tr><td><code id="coef.supclass_+3A_...">...</code></td>
<td>
<p>Other arguments not used now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix representing the coefficient estimates or an array
representing all the selected solutions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples of `supclass()`.

</code></pre>

<hr>
<h2 id='cv.abclass'>Tune Angle-Based Classifiers by Cross-Validation</h2><span id='topic+cv.abclass'></span>

<h3>Description</h3>

<p>Tune the regularization parameter for an angle-based large-margin classifier
by cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.abclass(
  x,
  y,
  intercept = TRUE,
  weight = NULL,
  loss = c("logistic", "boost", "hinge-boost", "lum"),
  control = list(),
  nfolds = 5L,
  stratified = TRUE,
  alignment = c("fraction", "lambda"),
  refit = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.abclass_+3A_x">x</code></td>
<td>
<p>A numeric matrix representing the design matrix.  No missing valus
are allowed.  The coefficient estimates for constant columns will be
zero.  Thus, one should set the argument <code>intercept</code> to <code>TRUE</code>
to include an intercept term instead of adding an all-one column to
<code>x</code>.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_y">y</code></td>
<td>
<p>An integer vector, a character vector, or a factor vector
representing the response label.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_intercept">intercept</code></td>
<td>
<p>A logical value indicating if an intercept should be
considered in the model.  The default value is <code>TRUE</code> and the
intercept is excluded from regularization.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_weight">weight</code></td>
<td>
<p>A numeric vector for nonnegative observation weights. Equal
observation weights are used by default.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_loss">loss</code></td>
<td>
<p>A character value specifying the loss function.  The available
options are <code>"logistic"</code> for the logistic deviance loss,
<code>"boost"</code> for the exponential loss approximating Boosting machines,
<code>"hinge-boost"</code> for hybrid of SVM and AdaBoost machine, and
<code>"lum"</code> for largin-margin unified machines (LUM).  See Liu, et
al. (2011) for details.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See <code>abclass.control()</code>
for details.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_nfolds">nfolds</code></td>
<td>
<p>A positive integer specifying the number of folds for
cross-validation.  Five-folds cross-validation will be used by default.
An error will be thrown out if the <code>nfolds</code> is specified to be less
than 2.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_stratified">stratified</code></td>
<td>
<p>A logical value indicating if the cross-validation
procedure should be stratified by the response label. The default value
is <code>TRUE</code> to ensure the same number of categories be used in
validation and training.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_alignment">alignment</code></td>
<td>
<p>A character vector specifying how to align the lambda
sequence used in the main fit with the cross-validation fits.  The
available options are <code>"fraction"</code> for allowing cross-validation
fits to have their own lambda sequences and <code>"lambda"</code> for using
the same lambda sequence of the main fit.  The option <code>"lambda"</code>
will be applied if a meaningful <code>lambda</code> is specified.  The default
value is <code>"fraction"</code>.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_refit">refit</code></td>
<td>
<p>A logical value or a named list specifying if and how a refit
for those selected predictors should be performed.  The default valie is
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cv.abclass_+3A_...">...</code></td>
<td>
<p>Other control parameters passed to <code>abclass.control()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>cv.abclass</code>.
</p>

<hr>
<h2 id='cv.supclass'>Tune Sup-Norm Classifiers by Cross-Validation</h2><span id='topic+cv.supclass'></span>

<h3>Description</h3>

<p>Tune the regularization parameter lambda for a sup-norm classifier by
cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.supclass(
  x,
  y,
  model = c("logistic", "psvm", "svm"),
  penalty = c("lasso", "scad"),
  start = NULL,
  control = list(),
  nfolds = 5L,
  stratified = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.supclass_+3A_x">x</code></td>
<td>
<p>A numeric matrix representing the design matrix.  No missing valus
are allowed.  The coefficient estimates for constant columns will be
zero.  Thus, one should set the argument <code>intercept</code> to <code>TRUE</code>
to include an intercept term instead of adding an all-one column to
<code>x</code>.</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_y">y</code></td>
<td>
<p>An integer vector, a character vector, or a factor vector
representing the response label.</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_model">model</code></td>
<td>
<p>A charactor vector specifying the classification model.  The
available options are <code>"logistic"</code> for multi-nomial logistic
regression model, <code>"psvm"</code> for proximal support vector machine
(PSVM), <code>"svm"</code> for multi-category support vector machine.</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_penalty">penalty</code></td>
<td>
<p>A charactor vector specifying the penalty function for the
sup-norms.  The available options are <code>"lasso"</code> for sup-norm
regularization proposed by Zhang et al. (2008) and <code>"scad"</code> for
supSCAD regularization proposed by Li &amp; Zhang (2021).</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_start">start</code></td>
<td>
<p>A numeric matrix representing the starting values for the
quadratic approximation procedure behind the scene.</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_control">control</code></td>
<td>
<p>A list with named elements.</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_nfolds">nfolds</code></td>
<td>
<p>A positive integer specifying the number of folds for
cross-validation.  Five-folds cross-validation will be used by default.
An error will be thrown out if the <code>nfolds</code> is specified to be less
than 2.</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_stratified">stratified</code></td>
<td>
<p>A logical value indicating if the cross-validation
procedure should be stratified by the response label. The default value
is <code>TRUE</code> to ensure the same number of categories be used in
validation and training.</p>
</td></tr>
<tr><td><code id="cv.supclass_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>supclass</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An S3 object of class <code>cv.supclass</code>.
</p>

<hr>
<h2 id='et.abclass'>Tune Angle-Based Classifiers by ET-Lasso</h2><span id='topic+et.abclass'></span>

<h3>Description</h3>

<p>Tune the regularization parameter for an angle-based large-margin classifier
by the ET-Lasso method (Yang, et al., 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>et.abclass(
  x,
  y,
  intercept = TRUE,
  weight = NULL,
  loss = c("logistic", "boost", "hinge-boost", "lum"),
  control = list(),
  nstages = 2,
  refit = list(lambda = 1e-06),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="et.abclass_+3A_x">x</code></td>
<td>
<p>A numeric matrix representing the design matrix.  No missing valus
are allowed.  The coefficient estimates for constant columns will be
zero.  Thus, one should set the argument <code>intercept</code> to <code>TRUE</code>
to include an intercept term instead of adding an all-one column to
<code>x</code>.</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_y">y</code></td>
<td>
<p>An integer vector, a character vector, or a factor vector
representing the response label.</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_intercept">intercept</code></td>
<td>
<p>A logical value indicating if an intercept should be
considered in the model.  The default value is <code>TRUE</code> and the
intercept is excluded from regularization.</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_weight">weight</code></td>
<td>
<p>A numeric vector for nonnegative observation weights. Equal
observation weights are used by default.</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_loss">loss</code></td>
<td>
<p>A character value specifying the loss function.  The available
options are <code>"logistic"</code> for the logistic deviance loss,
<code>"boost"</code> for the exponential loss approximating Boosting machines,
<code>"hinge-boost"</code> for hybrid of SVM and AdaBoost machine, and
<code>"lum"</code> for largin-margin unified machines (LUM).  See Liu, et
al. (2011) for details.</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See <code>abclass.control()</code>
for details.</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_nstages">nstages</code></td>
<td>
<p>A positive integer specifying for the number of stages in the
ET-Lasso procedure.  By default, two rounds of tuning by random
permutations will be performed as suggested in Yang, et al. (2019).</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_refit">refit</code></td>
<td>
<p>A logical value indicating if a new classifier should be
trained using the selected predictors.  This argument can also be a list
with named elements, which will be passed to <code>abclass.control()</code> to
specify how the new classifier should be trained.</p>
</td></tr>
<tr><td><code id="et.abclass_+3A_...">...</code></td>
<td>
<p>Other control parameters passed to <code>abclass.control()</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yang, S., Wen, J., Zhan, X., &amp; Kifer, D. (2019). ET-Lasso: A new efficient
tuning of lasso-type regularization for high-dimensional data. In
<em>Proceedings of the 25th ACM SIGKDD International Conference on
Knowledge Discovery &amp; Data Mining</em> (pp. 607&ndash;616).
</p>

<hr>
<h2 id='predict.abclass'>Prediction by A Trained Angle-Based Classifier</h2><span id='topic+predict.abclass'></span>

<h3>Description</h3>

<p>Predict class labels or estimate conditional probabilities for the specified
new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abclass'
predict(
  object,
  newx,
  type = c("class", "probability"),
  selection = c("cv_1se", "cv_min", "all"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.abclass_+3A_object">object</code></td>
<td>
<p>An object of class <code>abclass</code>.</p>
</td></tr>
<tr><td><code id="predict.abclass_+3A_newx">newx</code></td>
<td>
<p>A numeric matrix representing the design matrix for predictions.</p>
</td></tr>
<tr><td><code id="predict.abclass_+3A_type">type</code></td>
<td>
<p>A character value specifying the desired type of predictions.
The available options are <code>"class"</code> for predicted labels and
<code>"probability"</code> for class conditional probability estimates.</p>
</td></tr>
<tr><td><code id="predict.abclass_+3A_selection">selection</code></td>
<td>
<p>An integer vector for the solution indices or a character
value specifying how to select a particular set of coefficient estimates
from the entire solution path for prediction. If the specified
<code>object</code> contains the cross-validation results, one may set
<code>selection</code> to <code>"cv_min"</code> (or <code>"cv_1se"</code>) for using the
estimates giving the smallest cross-validation error (or the set of
estimates resulted from the largest <em>lambda</em> within one standard
error of the smallest cross-validation error) or prediction.  The
prediction for the entire solution path will be returned in a list if
<code>selection = "all"</code> or no cross-validation results are available in
the specified <code>object</code>.</p>
</td></tr>
<tr><td><code id="predict.abclass_+3A_...">...</code></td>
<td>
<p>Other arguments not used now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector representing the predictions or a list containing the
predictions for each set of estimates along the solution path.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples of `abclass()`.

</code></pre>

<hr>
<h2 id='predict.supclass'>Predictions from A Trained Sup-Norm Classifier</h2><span id='topic+predict.supclass'></span>

<h3>Description</h3>

<p>Predict class labels or estimate conditional probabilities for the specified
new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'supclass'
predict(
  object,
  newx,
  type = c("class", "probability"),
  selection = c("cv_1se", "cv_min", "all"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.supclass_+3A_object">object</code></td>
<td>
<p>An object of class <code>abclass</code>.</p>
</td></tr>
<tr><td><code id="predict.supclass_+3A_newx">newx</code></td>
<td>
<p>A numeric matrix representing the design matrix for predictions.</p>
</td></tr>
<tr><td><code id="predict.supclass_+3A_type">type</code></td>
<td>
<p>A character value specifying the desired type of predictions.
The available options are <code>"class"</code> for predicted labels and
<code>"probability"</code> for class conditional probability estimates.</p>
</td></tr>
<tr><td><code id="predict.supclass_+3A_selection">selection</code></td>
<td>
<p>An integer vector for the solution indices or a character
value specifying how to select a particular set of coefficient estimates
from the entire solution path for prediction. If the specified
<code>object</code> contains the cross-validation results, one may set
<code>selection</code> to <code>"cv_min"</code> (or <code>"cv_1se"</code>) for using the
estimates giving the smallest cross-validation error (or the set of
estimates resulted from the largest <em>lambda</em> within one standard
error of the smallest cross-validation error) or prediction.  The
prediction for the entire solution path will be returned in a list if
<code>selection = "all"</code> or no cross-validation results are available in
the specified <code>object</code>.</p>
</td></tr>
<tr><td><code id="predict.supclass_+3A_...">...</code></td>
<td>
<p>Other arguments not used now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector representing the predictions or a list containing the
predictions for each set of estimates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples of `supclass()`.

</code></pre>

<hr>
<h2 id='supclass'>Multi-Category Classifiers with Sup-Norm Regularization</h2><span id='topic+supclass'></span><span id='topic+supclass.control'></span>

<h3>Description</h3>

<p>Experimental implementations of multi-category classifiers with sup-norm
penalties proposed by Zhang, et al. (2008) and Li &amp; Zhang (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>supclass(
  x,
  y,
  model = c("logistic", "psvm", "svm"),
  penalty = c("lasso", "scad"),
  start = NULL,
  control = list(),
  ...
)

supclass.control(
  lambda = 0.1,
  adaptive_weight = NULL,
  scad_a = 3.7,
  maxit = 50,
  epsilon = 1e-04,
  shrinkage = 1e-04,
  warm_start = TRUE,
  standardize = TRUE,
  verbose = 0L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="supclass_+3A_x">x</code></td>
<td>
<p>A numeric matrix representing the design matrix.  No missing valus
are allowed.  The coefficient estimates for constant columns will be
zero.  Thus, one should set the argument <code>intercept</code> to <code>TRUE</code>
to include an intercept term instead of adding an all-one column to
<code>x</code>.</p>
</td></tr>
<tr><td><code id="supclass_+3A_y">y</code></td>
<td>
<p>An integer vector, a character vector, or a factor vector
representing the response label.</p>
</td></tr>
<tr><td><code id="supclass_+3A_model">model</code></td>
<td>
<p>A charactor vector specifying the classification model.  The
available options are <code>"logistic"</code> for multi-nomial logistic
regression model, <code>"psvm"</code> for proximal support vector machine
(PSVM), <code>"svm"</code> for multi-category support vector machine.</p>
</td></tr>
<tr><td><code id="supclass_+3A_penalty">penalty</code></td>
<td>
<p>A charactor vector specifying the penalty function for the
sup-norms.  The available options are <code>"lasso"</code> for sup-norm
regularization proposed by Zhang et al. (2008) and <code>"scad"</code> for
supSCAD regularization proposed by Li &amp; Zhang (2021).</p>
</td></tr>
<tr><td><code id="supclass_+3A_start">start</code></td>
<td>
<p>A numeric matrix representing the starting values for the
quadratic approximation procedure behind the scene.</p>
</td></tr>
<tr><td><code id="supclass_+3A_control">control</code></td>
<td>
<p>A list with named elements.</p>
</td></tr>
<tr><td><code id="supclass_+3A_...">...</code></td>
<td>
<p>Optional control parameters passed to the
<code>supclass.control()</code>.</p>
</td></tr>
<tr><td><code id="supclass_+3A_lambda">lambda</code></td>
<td>
<p>A numeric vector specifying the tuning parameter
<em>lambda</em>.  The default value is <code>0.1</code>.  Users should tune this
parameter for a better model fit.  The specified lambda will be sorted
in decreasing order internally and only the unique values will be kept.</p>
</td></tr>
<tr><td><code id="supclass_+3A_adaptive_weight">adaptive_weight</code></td>
<td>
<p>A numeric vector or matrix representing the adaptive
penalty weights.  The default value is <code>NULL</code> for equal weights.
Zhang, et al. (2008) proposed two ways to employ the adaptive weights.
The first approach applies the weights to the sup-norm of coefficient
estimates, while the second approach applies element-wise multiplication
to the weights and coefficient estimates inside the sup-norms.  The
first or second approach will be applied if a numeric vector or matrix
is specified, respectively.  The adaptive weights are supported for
lasso penalty only.</p>
</td></tr>
<tr><td><code id="supclass_+3A_scad_a">scad_a</code></td>
<td>
<p>A positive number specifying the tuning parameter <em>a</em> in
the SCAD penalty.</p>
</td></tr>
<tr><td><code id="supclass_+3A_maxit">maxit</code></td>
<td>
<p>A positive integer specifying the maximum number of iteration.
The default value is <code>50</code> as suggested in Li &amp; Zhang (2021).</p>
</td></tr>
<tr><td><code id="supclass_+3A_epsilon">epsilon</code></td>
<td>
<p>A positive number specifying the relative tolerance that
determines convergence.  The default value is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="supclass_+3A_shrinkage">shrinkage</code></td>
<td>
<p>A nonnegative tolerance to shrink estimates with sup-norm
close enough to zero (within the specified tolerance) to zeros.  The
default value is <code>1e-4</code>.  ## @param ridge_lambda The tuning
parameter lambda of the ridge penalty used to ## set the (first set of)
starting values.</p>
</td></tr>
<tr><td><code id="supclass_+3A_warm_start">warm_start</code></td>
<td>
<p>A logical value indicating if the estimates from last
lambda should be used as the starting values for the next lambda.  If
<code>FALSE</code>, the user-specified starting values will be used instead.</p>
</td></tr>
<tr><td><code id="supclass_+3A_standardize">standardize</code></td>
<td>
<p>A logical value indicating if a standardization procedure
should be performed so that each column of the design matrix has mean
zero and standardization</p>
</td></tr>
<tr><td><code id="supclass_+3A_verbose">verbose</code></td>
<td>
<p>A nonnegative integer specifying if the estimation procedure
is allowed to print out intermediate steps/results.  The default value
is <code>0</code> for silent estimation procedure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the multinomial logistic model or the proximal SVM model, this function
utilizes the function <code>quadprog::solve.QP()</code> to solve the equivalent
quadratic problem; For the multi-class SVM, this function utilizes GNU GLPK
to solve the equivalent linear programming problem via the package Rglpk.
It is recommended to use a recent version of GLPK.
</p>


<h3>References</h3>

<p>Zhang, H. H., Liu, Y., Wu, Y., &amp; Zhu, J. (2008). Variable selection for the
multicategory SVM via adaptive sup-norm regularization. <em>Electronic
Journal of Statistics</em>, 2, 149&ndash;167.
</p>
<p>Li, N., &amp; Zhang, H. H. (2021). Sparse learning with non-convex penalty in
multi-classification. <em>Journal of Data Science</em>, 19(1), 56&ndash;74.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(abclass)
set.seed(123)

## toy examples for demonstration purpose
## reference: example 1 in Zhang and Liu (2014)
ntrain &lt;- 100 # size of training set
ntest &lt;- 1000 # size of testing set
p0 &lt;- 2       # number of actual predictors
p1 &lt;- 2       # number of random predictors
k &lt;- 3        # number of categories

n &lt;- ntrain + ntest; p &lt;- p0 + p1
train_idx &lt;- seq_len(ntrain)
y &lt;- sample(k, size = n, replace = TRUE)         # response
mu &lt;- matrix(rnorm(p0 * k), nrow = k, ncol = p0) # mean vector
## normalize the mean vector so that they are distributed on the unit circle
mu &lt;- mu / apply(mu, 1, function(a) sqrt(sum(a ^ 2)))
x0 &lt;- t(sapply(y, function(i) rnorm(p0, mean = mu[i, ], sd = 0.25)))
x1 &lt;- matrix(rnorm(p1 * n, sd = 0.3), nrow = n, ncol = p1)
x &lt;- cbind(x0, x1)
train_x &lt;- x[train_idx, ]
test_x &lt;- x[- train_idx, ]
y &lt;- factor(paste0("label_", y))
train_y &lt;- y[train_idx]
test_y &lt;- y[- train_idx]

## regularization with the supnorm lasso penalty
options("mc.cores" = 1)
model &lt;- supclass(train_x, train_y, model = "psvm", penalty = "lasso")
pred &lt;- predict(model, test_x)
table(test_y, pred)
mean(test_y == pred) # accuracy
</code></pre>

</main>


</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
