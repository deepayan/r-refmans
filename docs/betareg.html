<!DOCTYPE html><html><head><title>Help for package betareg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {betareg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#beta01'><p>The Zero- and/or One-Inflated Beta Distribution in Regression Parameterization</p></a></li>
<li><a href='#Beta01'><p>Create a Zero- and/or One-Inflated Beta Distribution</p></a></li>
<li><a href='#beta4'><p>The 4-Parameter Beta Distribution in Regression Parameterization</p></a></li>
<li><a href='#Beta4'><p>Create a 4-Parameter Beta Distribution</p></a></li>
<li><a href='#betamix'><p>Finite Mixtures of Beta Regression for Rates and Proportions</p></a></li>
<li><a href='#betar'><p>The Beta Distribution in Regression Parameterization</p></a></li>
<li><a href='#BetaR'><p>Create a Beta Regression Distribution</p></a></li>
<li><a href='#betareg'><p>Beta Regression for Rates and Proportions</p></a></li>
<li><a href='#betareg.control'><p>Control Parameters for Beta Regression</p></a></li>
<li><a href='#betatree'><p>Beta Regression Trees</p></a></li>
<li><a href='#CarTask'>
<p>Partition-primed Probability Judgement Task for Car Dealership</p></a></li>
<li><a href='#FoodExpenditure'><p>Proportion of Household Income Spent on Food</p></a></li>
<li><a href='#GasolineYield'><p>Estimation of Gasoline Yields from Crude Oil</p></a></li>
<li><a href='#gleverage'><p>Generalized Leverage Values</p></a></li>
<li><a href='#ImpreciseTask'>
<p>Imprecise Probabilities for Sunday Weather and Boeing Stock Task</p></a></li>
<li><a href='#LossAversion'><p>(No) Myopic Loss Aversion in Adolescents</p></a></li>
<li><a href='#MockJurors'><p>Confidence of Mock Jurors in Their Verdicts</p></a></li>
<li><a href='#plot.betareg'><p>Diagnostic Plots for betareg Objects</p></a></li>
<li><a href='#predict.betareg'><p>Prediction Method for betareg Objects</p></a></li>
<li><a href='#ReadingSkills'><p>Dyslexia and IQ Predicting Reading Accuracy</p></a></li>
<li><a href='#residuals.betareg'><p>Residuals Method for betareg Objects</p></a></li>
<li><a href='#StressAnxiety'><p>Dependency of Anxiety on Stress</p></a></li>
<li><a href='#summary.betareg'><p>Methods for betareg Objects</p></a></li>
<li><a href='#WeatherTask'>
<p>Weather Task With Priming and Precise and Imprecise Probabilities</p></a></li>
<li><a href='#xbeta'><p>The Extended-Support Beta Distribution</p></a></li>
<li><a href='#XBeta'><p>Create an Extended-Support Beta Distribution</p></a></li>
<li><a href='#xbetax'><p>The Extended-Support Beta Mixture Distribution</p></a></li>
<li><a href='#XBetaX'><p>Create an Extended-Support Beta Mixture Distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>3.2-0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-07-05</td>
</tr>
<tr>
<td>Title:</td>
<td>Beta Regression</td>
</tr>
<tr>
<td>Description:</td>
<td>Beta regression for modeling beta-distributed dependent variables on the open unit interval (0, 1),
  e.g., rates and proportions, see Cribari-Neto and Zeileis (2010) &lt;<a href="https://doi.org/10.18637%2Fjss.v034.i02">doi:10.18637/jss.v034.i02</a>&gt;.
  Moreover, extended-support beta regression models can accommodate dependent variables with
  boundary observations at 0 and/or 1. For the classical beta regression model, alternative specifications are
  provided: Bias-corrected and bias-reduced estimation, finite mixture models, and recursive partitioning for
  beta regression, see Grün, Kosmidis, and Zeileis (2012) &lt;<a href="https://doi.org/10.18637%2Fjss.v048.i11">doi:10.18637/jss.v048.i11</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, methods, stats, flexmix, Formula, lmtest,
modeltools, sandwich</td>
</tr>
<tr>
<td>Suggests:</td>
<td>car, distributions3 (&ge; 0.2.1), lattice, numDeriv, partykit,
statmod, strucchange</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://betareg.R-Forge.R-project.org/">https://betareg.R-Forge.R-project.org/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://betareg.R-Forge.R-project.org/contact.html">https://betareg.R-Forge.R-project.org/contact.html</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-07 08:53:53 UTC; zeileis</td>
</tr>
<tr>
<td>Author:</td>
<td>Achim Zeileis <a href="https://orcid.org/0000-0003-0918-3766"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Francisco Cribari-Neto
    <a href="https://orcid.org/0000-0002-5909-6698"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Bettina Grün <a href="https://orcid.org/0000-0001-7265-4773"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Ioannis Kosmidis <a href="https://orcid.org/0000-0003-1556-0302"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Alexandre B. Simas [ctb] (earlier version by),
  Andrea V. Rocha [ctb] (earlier version by)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Achim Zeileis &lt;Achim.Zeileis@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-07 10:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='beta01'>The Zero- and/or One-Inflated Beta Distribution in Regression Parameterization</h2><span id='topic+dbeta01'></span><span id='topic+pbeta01'></span><span id='topic+qbeta01'></span><span id='topic+rbeta01'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation
for the zero- and/or one-inflated beta distribution in regression parameterization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbeta01(x, mu, phi, p0 = 0, p1 = 0, log = FALSE)

pbeta01(q, mu, phi, p0 = 0, p1 = 0, lower.tail = TRUE, log.p = FALSE)

qbeta01(p, mu, phi, p0 = 0, p1 = 0, lower.tail = TRUE, log.p = FALSE)

rbeta01(n, mu, phi, p0 = 0, p1 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beta01_+3A_x">x</code>, <code id="beta01_+3A_q">q</code></td>
<td>
<p>numeric. Vector of quantiles.</p>
</td></tr>
<tr><td><code id="beta01_+3A_p">p</code></td>
<td>
<p>numeric. Vector of probabilities.</p>
</td></tr>
<tr><td><code id="beta01_+3A_n">n</code></td>
<td>
<p>numeric. Number of observations. If <code>length(n) &gt; 1</code>, the length is
taken to be the number required.</p>
</td></tr>
<tr><td><code id="beta01_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the beta distribution (on the open unit interval).</p>
</td></tr>
<tr><td><code id="beta01_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the beta distribution.</p>
</td></tr>
<tr><td><code id="beta01_+3A_p0">p0</code></td>
<td>
<p>numeric. The probability for an observation of zero (often referred
to as zero inflation).</p>
</td></tr>
<tr><td><code id="beta01_+3A_p1">p1</code></td>
<td>
<p>numeric. The probability for an observation of one (often referred
to as one inflation).</p>
</td></tr>
<tr><td><code id="beta01_+3A_log">log</code>, <code id="beta01_+3A_log.p">log.p</code></td>
<td>
<p>logical. If TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="beta01_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical. If TRUE (default), probabilities are P[X &lt;= x]
otherwise, P[X &gt; x].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The zero- and/or one-inflated beta distribution is obtained by adding point
masses at zero and/or one to a standard beta distribution. 
</p>
<p>Note that the support of the standard beta distribution is the open unit
interval where values of exactly zero or one cannot occur. Thus, the inflation
jargon is rather misleading as there is no probability that could be inflated.
It is rather a hurdle or two-part (or three-part) model.
</p>


<h3>Value</h3>

<p><code>dbeta01</code> gives the density, <code>pbeta01</code> gives the distribution
function, <code>qbeta01</code> gives the quantile function, and <code>rbeta01</code>
generates random deviates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbetar">dbetar</a></code>, <code><a href="#topic+Beta01">Beta01</a></code></p>

<hr>
<h2 id='Beta01'>Create a Zero- and/or One-Inflated Beta Distribution</h2><span id='topic+Beta01'></span><span id='topic+mean.Beta01'></span><span id='topic+variance.Beta01'></span><span id='topic+skewness.Beta01'></span><span id='topic+kurtosis.Beta01'></span><span id='topic+pdf.Beta01'></span><span id='topic+log_pdf.Beta01'></span><span id='topic+cdf.Beta01'></span><span id='topic+quantile.Beta01'></span><span id='topic+random.Beta01'></span><span id='topic+support.Beta01'></span><span id='topic+is_discrete.Beta01'></span><span id='topic+is_continuous.Beta01'></span>

<h3>Description</h3>

<p>Class and methods for zero- and/or one-inflated beta distributions in regression specification
using the workflow from the <span class="pkg">distributions3</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta01(mu, phi, p0 = 0, p1 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta01_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the beta distribution (on the open unit interval).</p>
</td></tr>
<tr><td><code id="Beta01_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the beta distribution.</p>
</td></tr>
<tr><td><code id="Beta01_+3A_p0">p0</code></td>
<td>
<p>numeric. The probability for an observation of zero (often referred
to as zero inflation).</p>
</td></tr>
<tr><td><code id="Beta01_+3A_p1">p1</code></td>
<td>
<p>numeric. The probability for an observation of one (often referred
to as one inflation).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The zero- and/or one-inflated beta distribution is obtained by adding point
masses at zero and/or one to a standard beta distribution. 
</p>
<p>Note that the support of the standard beta distribution is the open unit
interval where values of exactly zero or one cannot occur. Thus, the inflation
jargon is rather misleading as there is no probability that could be inflated.
It is rather a hurdle or two-part (or three-part) model.
</p>


<h3>Value</h3>

<p>A <code>Beta01</code> distribution object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbeta01">dbeta01</a></code>, <code><a href="#topic+BetaR">BetaR</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## package and random seed
library("distributions3")
set.seed(6020)

## three beta distributions
X &lt;- Beta01(
  mu  = c(0.25, 0.50, 0.75),
  phi = c(1, 1, 2),
  p0 = c(0.1, 0, 0),
  p1 = c(0, 0, 0.3)
)

X

## compute moments of the distribution
mean(X)
variance(X)

## support interval (minimum and maximum)
support(X)

## simulate random variables
random(X, 5)

## histograms of 1,000 simulated observations
x &lt;- random(X, 1000)
hist(x[1, ])
hist(x[2, ])
hist(x[3, ])

## probability density function (PDF) and log-density (or log-likelihood)
x &lt;- c(0.25, 0.5, 0.75)
pdf(X, x)
pdf(X, x, log = TRUE)
log_pdf(X, x)

## cumulative distribution function (CDF)
cdf(X, x)

## quantiles
quantile(X, 0.5)

## cdf() and quantile() are inverses
cdf(X, quantile(X, 0.5))
quantile(X, cdf(X, 1))

## point mass probabilities (if any) on boundary
cdf(X, 0, lower.tail = TRUE)
cdf(X, 1, lower.tail = FALSE)

## all methods above can either be applied elementwise or for
## all combinations of X and x, if length(X) = length(x),
## also the result can be assured to be a matrix via drop = FALSE
p &lt;- c(0.05, 0.5, 0.95)
quantile(X, p, elementwise = FALSE)
quantile(X, p, elementwise = TRUE)
quantile(X, p, elementwise = TRUE, drop = FALSE)

## compare theoretical and empirical mean from 1,000 simulated observations
cbind(
  "theoretical" = mean(X),
  "empirical" = rowMeans(random(X, 1000))
)

</code></pre>

<hr>
<h2 id='beta4'>The 4-Parameter Beta Distribution in Regression Parameterization</h2><span id='topic+dbeta4'></span><span id='topic+pbeta4'></span><span id='topic+qbeta4'></span><span id='topic+rbeta4'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation
for the 4-parameter beta distribution in regression parameterization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbeta4(x, mu, phi, theta1 = 0, theta2 = 1 - theta1, log = FALSE)

pbeta4(q, mu, phi, theta1 = 0, theta2 = 1 - theta1, lower.tail = TRUE, log.p = FALSE)

qbeta4(p, mu, phi, theta1 = 0, theta2 = 1 - theta1, lower.tail = TRUE, log.p = FALSE)

rbeta4(n, mu, phi, theta1 = 0, theta2 = 1 - theta1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="beta4_+3A_x">x</code>, <code id="beta4_+3A_q">q</code></td>
<td>
<p>numeric. Vector of quantiles.</p>
</td></tr>
<tr><td><code id="beta4_+3A_p">p</code></td>
<td>
<p>numeric. Vector of probabilities.</p>
</td></tr>
<tr><td><code id="beta4_+3A_n">n</code></td>
<td>
<p>numeric. Number of observations. If <code>length(n) &gt; 1</code>, the length is
taken to be the number required.</p>
</td></tr>
<tr><td><code id="beta4_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the beta distribution that is extended to
support [theta1, theta2].</p>
</td></tr>
<tr><td><code id="beta4_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the beta distribution that is
extended to support [theta1, theta2].</p>
</td></tr>
<tr><td><code id="beta4_+3A_theta1">theta1</code>, <code id="beta4_+3A_theta2">theta2</code></td>
<td>
<p>numeric. The minimum and maximum, respectively,
of the 4-parameter beta distribution. By default a symmetric support is
chosen by <code>theta2 = 1 - theta1</code> which reduces to the classic
beta distribution because of the default <code>theta1 = 0</code>.</p>
</td></tr>
<tr><td><code id="beta4_+3A_log">log</code>, <code id="beta4_+3A_log.p">log.p</code></td>
<td>
<p>logical. If TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="beta4_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical. If TRUE (default), probabilities are P[X &lt;= x]
otherwise, P[X &gt; x].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distribution is obtained by a linear transformation of a beta-distributed
random variable with intercept <code>theta1</code> and slope <code>theta2 - theta1</code>.
</p>


<h3>Value</h3>

<p><code>dbeta4</code> gives the density, <code>pbeta4</code> gives the distribution
function, <code>qbeta4</code> gives the quantile function, and <code>rbeta4</code>
generates random deviates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbetar">dbetar</a></code>, <code><a href="#topic+Beta4">Beta4</a></code></p>

<hr>
<h2 id='Beta4'>Create a 4-Parameter Beta Distribution</h2><span id='topic+Beta4'></span><span id='topic+mean.Beta4'></span><span id='topic+variance.Beta4'></span><span id='topic+skewness.Beta4'></span><span id='topic+kurtosis.Beta4'></span><span id='topic+pdf.Beta4'></span><span id='topic+log_pdf.Beta4'></span><span id='topic+cdf.Beta4'></span><span id='topic+quantile.Beta4'></span><span id='topic+random.Beta4'></span><span id='topic+support.Beta4'></span><span id='topic+is_discrete.Beta4'></span><span id='topic+is_continuous.Beta4'></span>

<h3>Description</h3>

<p>Class and methods for 4-parameter beta distributions in regression specification
using the workflow from the <span class="pkg">distributions3</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beta4(mu, phi, theta1 = 0, theta2 = 1 - theta1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beta4_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the beta distribution that is extended to
support [theta1, theta2].</p>
</td></tr>
<tr><td><code id="Beta4_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the beta distribution that is
extended to support [theta1, theta2].</p>
</td></tr>
<tr><td><code id="Beta4_+3A_theta1">theta1</code>, <code id="Beta4_+3A_theta2">theta2</code></td>
<td>
<p>numeric. The minimum and maximum, respectively,
of the 4-parameter beta distribution. By default a symmetric support is
chosen by <code>theta2 = 1 - theta1</code> which reduces to the classic
beta distribution because of the default <code>theta1 = 0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distribution is obtained by a linear transformation of a beta-distributed
random variable with intercept <code>theta1</code> and slope <code>theta2 - theta1</code>.
</p>


<h3>Value</h3>

<p>A <code>Beta4</code> distribution object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbeta4">dbeta4</a></code>, <code><a href="#topic+BetaR">BetaR</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## package and random seed
library("distributions3")
set.seed(6020)

## three beta distributions
X &lt;- Beta4(
  mu  = c(0.25, 0.50, 0.75),
  phi = c(1, 1, 2),
  theta1 = c(0, -0.1, -0.1),
  theta2 = c(1, 1.1, 1.5)
)

X

## compute moments of the distribution
mean(X)
variance(X)

## support interval (minimum and maximum)
support(X)

## simulate random variables
random(X, 5)

## histograms of 1,000 simulated observations
x &lt;- random(X, 1000)
hist(x[1, ])
hist(x[2, ])
hist(x[3, ])

## probability density function (PDF) and log-density (or log-likelihood)
x &lt;- c(0.25, 0.5, 0.75)
pdf(X, x)
pdf(X, x, log = TRUE)
log_pdf(X, x)

## cumulative distribution function (CDF)
cdf(X, x)

## quantiles
quantile(X, 0.5)

## cdf() and quantile() are inverses
cdf(X, quantile(X, 0.5))
quantile(X, cdf(X, 1))

## all methods above can either be applied elementwise or for
## all combinations of X and x, if length(X) = length(x),
## also the result can be assured to be a matrix via drop = FALSE
p &lt;- c(0.05, 0.5, 0.95)
quantile(X, p, elementwise = FALSE)
quantile(X, p, elementwise = TRUE)
quantile(X, p, elementwise = TRUE, drop = FALSE)

## compare theoretical and empirical mean from 1,000 simulated observations
cbind(
  "theoretical" = mean(X),
  "empirical" = rowMeans(random(X, 1000))
)

</code></pre>

<hr>
<h2 id='betamix'>Finite Mixtures of Beta Regression for Rates and Proportions</h2><span id='topic+betamix'></span><span id='topic+extraComponent'></span><span id='topic+fitted+2CFLXMRbeta-method'></span><span id='topic+fitted+2Cbetamix-method'></span><span id='topic+posterior+2Cbetamix+2CANY-method'></span><span id='topic+clusters+2Cbetamix+2CANY-method'></span><span id='topic+predict+2CFLXMRbeta-method'></span><span id='topic+predict+2CFLXMRbetafix-method'></span><span id='topic+predict+2Cbetamix-method'></span>

<h3>Description</h3>

<p>Fit finite mixtures of beta regression models for rates and
proportions via maximum likelihood with the EM algorithm using a
parametrization with mean (depending through a link function on the
covariates) and precision parameter (called phi).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betamix(formula, data, k, subset, na.action, weights, offset,
  link = c("logit", "probit", "cloglog", "cauchit", "log",
    "loglog"), link.phi = "log",
  control = betareg.control(...), cluster = NULL,
  FLXconcomitant = NULL, FLXcontrol = list(), verbose = FALSE,
  nstart = if (is.null(cluster)) 3 else 1, which = "BIC", 
  ID, fixed, extra_components, ...)

extraComponent(type = c("uniform", "betareg"), coef, delta,
  link = "logit", link.phi = "log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betamix_+3A_formula">formula</code></td>
<td>
<p>symbolic description of the model (of type <code>y ~ x</code>
or <code>y ~ x | z</code>; for details see <code><a href="#topic+betareg">betareg</a></code>).</p>
</td></tr>
<tr><td><code id="betamix_+3A_data">data</code>, <code id="betamix_+3A_subset">subset</code>, <code id="betamix_+3A_na.action">na.action</code></td>
<td>
<p>arguments controlling formula processing
via <code><a href="stats.html#topic+model.frame">model.frame</a></code>.</p>
</td></tr>
<tr><td><code id="betamix_+3A_weights">weights</code></td>
<td>
<p>optional numeric vector of integer case weights.</p>
</td></tr>
<tr><td><code id="betamix_+3A_offset">offset</code></td>
<td>
<p>optional numeric vector with an a priori known component to be
included in the linear predictor for the mean.</p>
</td></tr>
<tr><td><code id="betamix_+3A_k">k</code></td>
<td>
<p>a vector of integers indicating the number of components of
the finite mixture; passed in turn to the <code>k</code> argument
of <code><a href="flexmix.html#topic+stepFlexmix">stepFlexmix</a></code>.</p>
</td></tr>
<tr><td><code id="betamix_+3A_link">link</code></td>
<td>
<p>character specification of the link function in
the mean model (mu). Currently, <code>"logit"</code>, <code>"probit"</code>,
<code>"cloglog"</code>, <code>"cauchit"</code>, <code>"log"</code>, <code>"loglog"</code> are supported.
Alternatively, an object of class <code>"link-glm"</code> can be supplied.</p>
</td></tr>
<tr><td><code id="betamix_+3A_link.phi">link.phi</code></td>
<td>
<p>character specification of the link function in
the precision model (phi). Currently, <code>"identity"</code>,
<code>"log"</code>, <code>"sqrt"</code> are supported. The default is <code>"log"</code>
unless <code>formula</code> is of type <code>y ~ x</code> where the default is
<code>"identity"</code> (for backward compatibility).
Alternatively, an object of class <code>"link-glm"</code> can be supplied.</p>
</td></tr>
<tr><td><code id="betamix_+3A_control">control</code></td>
<td>
<p>a list of control arguments specified via
<code><a href="#topic+betareg.control">betareg.control</a></code>.</p>
</td></tr>
<tr><td><code id="betamix_+3A_cluster">cluster</code></td>
<td>
<p>Either a matrix with <code>k</code> columns of initial
cluster membership probabilities for each observation; or a factor
or integer vector with the initial cluster
assignments of observations at the start of the EM
algorithm. Default is random assignment into <code>k</code>
clusters.</p>
</td></tr>
<tr><td><code id="betamix_+3A_flxconcomitant">FLXconcomitant</code></td>
<td>
<p>concomitant variable model; object of class
<code>FLXP</code>. Default is the object returned by calling
<code><a href="flexmix.html#topic+FLXPconstant">FLXPconstant</a></code>.
The argument <code>FLXconcomitant</code> can be omitted if <code>formula</code>
is a three-part formula of type <code>y ~ x | z | w</code>, where <code>w</code>
specificies the concomitant variables.</p>
</td></tr>
<tr><td><code id="betamix_+3A_flxcontrol">FLXcontrol</code></td>
<td>
<p>object of class <code>"FLXcontrol"</code> or a named list;
controls the EM algorithm and passed in turn to the <code>control</code>
argument of <code><a href="flexmix.html#topic+flexmix">flexmix</a></code>.</p>
</td></tr>
<tr><td><code id="betamix_+3A_verbose">verbose</code></td>
<td>
<p>a logical; if <code>TRUE</code> progress information is shown
for different starts of the EM algorithm.</p>
</td></tr>
<tr><td><code id="betamix_+3A_nstart">nstart</code></td>
<td>
<p>for each value of <code>k</code> run
<code><a href="flexmix.html#topic+stepFlexmix">stepFlexmix</a></code> <code>nstart</code> times and keep only
the solution with maximum likelihood.</p>
</td></tr>
<tr><td><code id="betamix_+3A_which">which</code></td>
<td>
<p>number of model to get if <code>k</code> is a vector of
integers longer than one. If character, interpreted as
number of components or name of an information criterion.</p>
</td></tr>
<tr><td><code id="betamix_+3A_id">ID</code></td>
<td>
<p>grouping variable indicating if observations are from the same
individual, i.e. the component membership is restricted to be the
same for these observations.</p>
</td></tr>
<tr><td><code id="betamix_+3A_fixed">fixed</code></td>
<td>
<p>symbolic description of the model for the parameters
fixed over components (of type <code>~ x | z</code>).</p>
</td></tr>
<tr><td><code id="betamix_+3A_extra_components">extra_components</code></td>
<td>
<p>a list containing objects returned by
<code>extraComponent()</code>.</p>
</td></tr>
<tr><td><code id="betamix_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="#topic+betareg.control">betareg.control</a></code>.</p>
</td></tr>
<tr><td><code id="betamix_+3A_type">type</code></td>
<td>
<p>specifies if the component follows a uniform distribution
or a beta regression model.</p>
</td></tr>
<tr><td><code id="betamix_+3A_coef">coef</code></td>
<td>
<p>a vector with the coefficients to determine the midpoint
of the uniform distribution or names list with the coefficients for
the mean and precision of the beta regression model.</p>
</td></tr>
<tr><td><code id="betamix_+3A_delta">delta</code></td>
<td>
<p>numeric; half-length of the interval of the uniform
distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments and the model specification are similar to
<code><a href="#topic+betareg">betareg</a></code>. Internally <code><a href="flexmix.html#topic+stepFlexmix">stepFlexmix</a></code>
is called with suitable arguments to fit the finite mixture model with
the EM algorithm. See Grün et al. (2012) for more details.
</p>
<p><code>extra_components</code> is a list where each element corresponds to a
component where the parameters are fixed a-priori.
</p>


<h3>Value</h3>

<p>An object of class <code>"flexmix"</code> containing the best model with
respect to the log likelihood or the one selected according to
<code>which</code> if <code>k</code> is a vector of integers longer than 1.
</p>


<h3>Author(s)</h3>

<p>Bettina Grün and Achim Zeileis
</p>


<h3>References</h3>

<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Grün, B., Kosmidis, I., and Zeileis, A. (2012).
Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned.
<em>Journal of Statistical Software</em>, <b>48</b>(11), 1&ndash;25.
<a href="https://doi.org/10.18637/jss.v048.i11">doi:10.18637/jss.v048.i11</a>
</p>
<p>Grün, B., and Leisch, F. (2008). FlexMix Version 2: Finite Mixtures
with Concomitant Variables and Varying and Constant Parameters.
<em>Journal of Statistical Software</em>, <b>28</b>(4), 1&ndash;35.
<a href="https://doi.org/10.18637/jss.v028.i04">doi:10.18637/jss.v028.i04</a>
</p>
<p>Leisch, F. (2004). FlexMix: A General Framework for Finite Mixture
Models and Latent Class Regression in R.
<em>Journal of Statistical Software</em>, <b>11</b>(8), 1&ndash;18.
<a href="https://doi.org/10.18637/jss.v011.i08">doi:10.18637/jss.v011.i08</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code>, <code><a href="flexmix.html#topic+flexmix">flexmix</a></code>,
<code><a href="flexmix.html#topic+stepFlexmix">stepFlexmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)

## data with two groups of dyslexic and non-dyslexic children
data("ReadingSkills", package = "betareg")

suppressWarnings(RNGversion("3.5.0"))
set.seed(4040)
## try to capture accuracy ~ iq relationship (without using dyslexia
## information) using two beta regression components and one additional
## extra component for a perfect reading score
rs_mix &lt;- betamix(accuracy ~ iq, data = ReadingSkills, k = 3,
  nstart = 10, extra_components = extraComponent(type = "uniform",
  coef = 0.99, delta = 0.01))

## visualize result
## intensities based on posterior probabilities
prob &lt;- 2 * (posterior(rs_mix)[cbind(1:nrow(ReadingSkills),
   clusters(rs_mix))] - 0.5)
## associated HCL colors
col0 &lt;- hcl(c(260, 0, 130), 65, 45, fixup = FALSE)
col1 &lt;- col0[clusters(rs_mix)]
col2 &lt;- hcl(c(260, 0, 130)[clusters(rs_mix)], 65 * abs(prob)^1.5,
   95 - 50 * abs(prob)^1.5, fixup = FALSE)
## scatter plot
plot(accuracy ~ iq, data = ReadingSkills, col = col2, pch = 19,
   cex = 1.5, xlim = c(-2, 2))
points(accuracy ~ iq, data = ReadingSkills, cex = 1.5, pch = 1,
   col = col1)
## fitted lines
iq &lt;- -30:30/10
cf &lt;- rbind(coef(rs_mix, model = "mean", component = 1:2),
   c(qlogis(0.99), 0))
for(i in 1:3)
   lines(iq, plogis(cf[i, 1] + cf[i, 2] * iq), lwd = 2,
         col = col0[i])

## refit the model including a concomitant variable model using the
## dyslexia information with some noise to avoid complete separation
## between concomitant variable and component memberships
set.seed(4040)
w &lt;- rnorm(nrow(ReadingSkills), 
           c(-1, 1)[as.integer(ReadingSkills$dyslexia)])

## The argument FLXconcomitant can be omitted when specifying
## the model via a three part formula given by
## accuracy ~ iq | 1 | w
## The posteriors from the previously fitted model are used
## for initialization.
library("flexmix")
rs_mix2 &lt;- betamix(accuracy ~ iq, data = ReadingSkills,
  extra_components = extraComponent(type = "uniform",
  coef = 0.99, delta = 0.01), cluster = posterior(rs_mix),
  FLXconcomitant = FLXPmultinom(~w))
coef(rs_mix2, which = "concomitant")
summary(rs_mix2, which = "concomitant")
</code></pre>

<hr>
<h2 id='betar'>The Beta Distribution in Regression Parameterization</h2><span id='topic+dbetar'></span><span id='topic+pbetar'></span><span id='topic+qbetar'></span><span id='topic+rbetar'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation
for the beta distribution in regression parameterization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbetar(x, mu, phi, log = FALSE)

pbetar(q, mu, phi, lower.tail = TRUE, log.p = FALSE)

qbetar(p, mu, phi, lower.tail = TRUE, log.p = FALSE)

rbetar(n, mu, phi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betar_+3A_x">x</code>, <code id="betar_+3A_q">q</code></td>
<td>
<p>numeric. Vector of quantiles.</p>
</td></tr>
<tr><td><code id="betar_+3A_p">p</code></td>
<td>
<p>numeric. Vector of probabilities.</p>
</td></tr>
<tr><td><code id="betar_+3A_n">n</code></td>
<td>
<p>numeric. Number of observations. If <code>length(n) &gt; 1</code>, the length is
taken to be the number required.</p>
</td></tr>
<tr><td><code id="betar_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the beta distribution.</p>
</td></tr>
<tr><td><code id="betar_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the beta distribution.</p>
</td></tr>
<tr><td><code id="betar_+3A_log">log</code>, <code id="betar_+3A_log.p">log.p</code></td>
<td>
<p>logical. If TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="betar_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical. If TRUE (default), probabilities are P[X &lt;= x]
otherwise, P[X &gt; x].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the reparameterization of the beta distribution with mean <code>mu</code>
and precision <code>phi</code>, as employed in beta regression. The classic
parameterization of the beta distribution is obtained by setting
<code>shape1 = mu * phi</code> and <code>shape2 = (1 - mu) * phi</code>,
respectively.
</p>


<h3>Value</h3>

<p><code>dbetar</code> gives the density, <code>pbetar</code> gives the distribution
function, <code>qbetar</code> gives the quantile function, and <code>rbetar</code>
generates random deviates.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dbeta">dbeta</a></code>, <code><a href="#topic+BetaR">BetaR</a></code></p>

<hr>
<h2 id='BetaR'>Create a Beta Regression Distribution</h2><span id='topic+BetaR'></span><span id='topic+mean.BetaR'></span><span id='topic+variance.BetaR'></span><span id='topic+skewness.BetaR'></span><span id='topic+kurtosis.BetaR'></span><span id='topic+pdf.BetaR'></span><span id='topic+log_pdf.BetaR'></span><span id='topic+cdf.BetaR'></span><span id='topic+quantile.BetaR'></span><span id='topic+random.BetaR'></span><span id='topic+support.BetaR'></span><span id='topic+is_discrete.BetaR'></span><span id='topic+is_continuous.BetaR'></span>

<h3>Description</h3>

<p>Class and methods for beta distributions in regression specification
using the workflow from the <span class="pkg">distributions3</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BetaR(mu, phi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BetaR_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the beta distribution.</p>
</td></tr>
<tr><td><code id="BetaR_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the beta distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Alternative parameterization of the classic beta distribution in
terms of its mean <code>mu</code> and precision parameter <code>phi</code>.
Thus, the distribution provided by <code>BetaR</code> is equivalent to
the <code><a href="distributions3.html#topic+Beta">Beta</a></code> distribution with parameters
<code>alpha = mu * phi</code> and <code>beta = (1 - mu) * phi</code>.
</p>


<h3>Value</h3>

<p>A <code>BetaR</code> distribution object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbetar">dbetar</a></code>, <code><a href="distributions3.html#topic+Beta">Beta</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## package and random seed
library("distributions3")
set.seed(6020)

## three beta distributions
X &lt;- BetaR(
  mu  = c(0.25, 0.50, 0.75),
  phi = c(1, 1, 2)
)

X

## compute moments of the distribution
mean(X)
variance(X)
skewness(X)
kurtosis(X)

## support interval (minimum and maximum)
support(X)

## simulate random variables
random(X, 5)

## histograms of 1,000 simulated observations
x &lt;- random(X, 1000)
hist(x[1, ])
hist(x[2, ])
hist(x[3, ])

## probability density function (PDF) and log-density (or log-likelihood)
x &lt;- c(0.25, 0.5, 0.75)
pdf(X, x)
pdf(X, x, log = TRUE)
log_pdf(X, x)

## cumulative distribution function (CDF)
cdf(X, x)

## quantiles
quantile(X, 0.5)

## cdf() and quantile() are inverses (except at censoring points)
cdf(X, quantile(X, 0.5))
quantile(X, cdf(X, 1))

## all methods above can either be applied elementwise or for
## all combinations of X and x, if length(X) = length(x),
## also the result can be assured to be a matrix via drop = FALSE
p &lt;- c(0.05, 0.5, 0.95)
quantile(X, p, elementwise = FALSE)
quantile(X, p, elementwise = TRUE)
quantile(X, p, elementwise = TRUE, drop = FALSE)

## compare theoretical and empirical mean from 1,000 simulated observations
cbind(
  "theoretical" = mean(X),
  "empirical" = rowMeans(random(X, 1000))
)

</code></pre>

<hr>
<h2 id='betareg'>Beta Regression for Rates and Proportions</h2><span id='topic+betareg'></span><span id='topic+betareg.fit'></span>

<h3>Description</h3>

<p>Fit beta regression models for rates and proportions via maximum likelihood
using a parametrization with mean (depending through a link function on the
covariates) and precision parameter (called phi).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betareg(formula, data, subset, na.action, weights, offset,
  link = c("logit", "probit", "cloglog", "cauchit", "log", "loglog"),
  link.phi = NULL, type = c("ML", "BC", "BR"), dist = NULL, nu = NULL,
  control = betareg.control(...), model = TRUE,
  y = TRUE, x = FALSE, ...)

betareg.fit(x, y, z = NULL, weights = NULL, offset = NULL,
  link = "logit", link.phi = "log", type = "ML", control = betareg.control(),
  dist = NULL, nu = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betareg_+3A_formula">formula</code></td>
<td>
<p>symbolic description of the model, either of type <code>y ~ x</code>
(mean submodel, constant precision) or <code>y ~ x | z</code> (submodels for both
mean and precision); for details see below.</p>
</td></tr>
<tr><td><code id="betareg_+3A_data">data</code>, <code id="betareg_+3A_subset">subset</code>, <code id="betareg_+3A_na.action">na.action</code></td>
<td>
<p>arguments controlling formula processing
via <code><a href="stats.html#topic+model.frame">model.frame</a></code>.</p>
</td></tr>
<tr><td><code id="betareg_+3A_weights">weights</code></td>
<td>
<p>optional numeric vector of case weights.</p>
</td></tr>
<tr><td><code id="betareg_+3A_offset">offset</code></td>
<td>
<p>optional numeric vector with an a priori known component to be
included in the linear predictor for the mean. In <code>betareg.fit</code>,
<code>offset</code> may also be a list of two offsets for the mean and precision
equation, respectively.</p>
</td></tr>
<tr><td><code id="betareg_+3A_link">link</code></td>
<td>
<p>character specification of the link function in
the mean model (mu). Currently, <code>"logit"</code>, <code>"probit"</code>,
<code>"cloglog"</code>, <code>"cauchit"</code>, <code>"log"</code>, <code>"loglog"</code> are supported.
Alternatively, an object of class <code>"link-glm"</code> can be supplied.</p>
</td></tr>
<tr><td><code id="betareg_+3A_link.phi">link.phi</code></td>
<td>
<p>character specification of the link function in
the precision model (phi). Currently, <code>"identity"</code>,
<code>"log"</code>, <code>"sqrt"</code> are supported. The default is <code>"log"</code>
unless <code>formula</code> is of type <code>y ~ x</code> where the default is
<code>"identity"</code> (for backward compatibility).
Alternatively, an object of class <code>"link-glm"</code> can be supplied.</p>
</td></tr>
<tr><td><code id="betareg_+3A_type">type</code></td>
<td>
<p>character specification of the type of estimator. Currently,
maximum likelihood (<code>"ML"</code>), ML with bias correction (<code>"BC"</code>),
and ML with bias reduction (<code>"BR"</code>) are supported.</p>
</td></tr>
<tr><td><code id="betareg_+3A_dist">dist</code></td>
<td>
<p>character specification of the response distribution.
Usually, this does not have to be set by the user because by default
the classical <code>"beta"</code> distribution is used when all observations
for the dependent variable are in (0, 1). In the presence of boundary
observations (0 or 1, which cannot be accomodated by <code>"beta"</code>) the
extended-support beta mixture distribution (<code>"xbetax"</code>) is used.
Additionally, <code>dist = "xbeta"</code> can be used with fixed exceedence
parameter <code>nu</code>, mostly for testing and debugging purposes.</p>
</td></tr>
<tr><td><code id="betareg_+3A_nu">nu</code></td>
<td>
<p>numeric. The fixed value of the expected exceedence parameter <code>nu</code> 
in case the extended-support beta mixture distribution is used. By default,
<code>nu</code> does not need to be specified and is estimated if needed. So
setting <code>nu</code> is mostly for profiling and debugging.</p>
</td></tr>
<tr><td><code id="betareg_+3A_control">control</code></td>
<td>
<p>a list of control arguments specified via
<code><a href="#topic+betareg.control">betareg.control</a></code>.</p>
</td></tr>
<tr><td><code id="betareg_+3A_model">model</code>, <code id="betareg_+3A_y">y</code>, <code id="betareg_+3A_x">x</code></td>
<td>
<p>logicals. If <code>TRUE</code> the corresponding components
of the fit (model frame, response, model matrix) are returned.
For <code>betareg.fit</code>, <code>x</code> should be a numeric regressor matrix
and <code>y</code> should be the numeric response vector (with values in (0,1)).</p>
</td></tr>
<tr><td><code id="betareg_+3A_z">z</code></td>
<td>
<p>numeric matrix. Regressor matrix for the precision model, defaulting
to an intercept only.</p>
</td></tr>
<tr><td><code id="betareg_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="#topic+betareg.control">betareg.control</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Beta regression as suggested by Ferrari and Cribari-Neto (2004) and extended
by Simas, Barreto-Souza, and Rocha (2010) is implemented in <code>betareg</code>.
It is useful in situations where the dependent variable is continuous and restricted to
the unit interval (0, 1), e.g., resulting from rates or proportions. It is modeled to be
beta-distributed with parametrization using mean and precision parameter (called mu and
phi, respectively). The mean mu is linked, as in generalized linear models (GLMs), to the
explanatory variables through a link function and a linear predictor. Additionally, the
precision parameter phi can be linked to another (potentially overlapping) set of
regressors through a second link function, resulting in a model with variable dispersion
(see Cribari-Neto and Zeileis 2010).
Estimation is performed by default using maximum likelihood (ML) via <code><a href="stats.html#topic+optim">optim</a></code> with
analytical gradients and starting values from an auxiliary linear regression
of the transformed response. Subsequently, the <code>optim</code> result may be enhanced
by an additional Fisher scoring iteration using analytical gradients and expected information.
Alternative estimation methods are bias-corrected (BC) or bias-reduced (BR)
maximum likelihood (see Grün, Kosmidis, and Zeileis 2012). For ML and BC the Fisher
scoring is just a refinement to move the gradients even closer to zero and can be
disabled by setting <code>fsmaxit = 0</code> in the control arguments. For BR the Fisher scoring
is needed to solve the bias-adjusted estimating equations.
</p>
<p>In the beta regression as introduced by Ferrari and Cribari-Neto (2004), the mean of
the response is linked to a linear predictor described by <code>y ~ x1 + x2</code> using
a <code>link</code> function while the precision parameter phi is assumed to be
constant. Simas et al. (2009) suggest to extend this model by linking phi to an
additional set of regressors (<code>z1 + z2</code>, say): In <code>betareg</code> this can be
specified in a formula of type <code>y ~ x1 + x2 | z1 + z2</code> where the regressors
in the two parts can be overlapping. In the precision model (for phi), the link
function <code>link.phi</code> is used. The default is a <code>"log"</code> link unless no
precision model is specified. In the latter case (i.e., when the formula is of type
<code>y ~ x1 + x2</code>), the <code>"identity"</code> link is used by default for backward
compatibility.
</p>
<p>Kosmidis and Zeileis (2024) introduce a generalization of the classic beta regression
model with extended support [0, 1].
Specifically, the extended-support beta distribution (<code>"xbeta"</code>) leverages an underlying
symmetric four-parameter beta distribution with exceedence parameter nu
to obtain support [-nu, 1 + nu] that is subsequently censored to [0, 1] in order
to obtain point masses at the boundary values 0 and 1. The extended-support
beta mixture distribution (<code>"xbetax"</code>) is a continuous mixture of extended-support
beta distributions where the exceedence parameter follows an exponential distribution
with mean nu (rather than a fixed value of nu). The latter <code>"xbetax"</code>
specification is used by default in case of boundary observations at 0 and/or 1.
The <code>"xbeta"</code> specification with fixed nu is mostly for testing and
debugging purposes.
</p>
<p>A set of standard extractor functions for fitted model objects is available for
objects of class <code>"betareg"</code>, including methods to the generic functions
<code><a href="base.html#topic+print">print</a></code>, <code><a href="base.html#topic+summary">summary</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>, 
<code><a href="stats.html#topic+vcov">vcov</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="stats.html#topic+residuals">residuals</a></code>, 
<code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="stats.html#topic+terms">terms</a></code>,
<code><a href="stats.html#topic+model.frame">model.frame</a></code>, <code><a href="stats.html#topic+model.matrix">model.matrix</a></code>,
<code>cooks.distance</code> and <code>hatvalues</code> (see <code><a href="stats.html#topic+influence.measures">influence.measures</a></code>),
<code><a href="#topic+gleverage">gleverage</a></code> (new generic), <code><a href="sandwich.html#topic+estfun">estfun</a></code> and
<code><a href="sandwich.html#topic+bread">bread</a></code> (from the <span class="pkg">sandwich</span> package), and
<code><a href="lmtest.html#topic+coeftest">coeftest</a></code> (from the <span class="pkg">lmtest</span> package).
</p>
<p>See <code><a href="#topic+predict.betareg">predict.betareg</a></code>, <code><a href="#topic+residuals.betareg">residuals.betareg</a></code>, <code><a href="#topic+plot.betareg">plot.betareg</a></code>,
and <code><a href="#topic+summary.betareg">summary.betareg</a></code> for more details on all methods.
</p>
<p>The main parameters of interest are the coefficients in the linear predictor of the mean
model. The additional parameters in the precision model (phi) can either
be treated as full model parameters (default) or as nuisance parameters. In the latter case
the estimation does not change, only the reported information in output from <code>print</code>,
<code>summary</code>, or <code>coef</code> (among others) will be different. See also <code><a href="#topic+betareg.control">betareg.control</a></code>.
</p>
<p>The implemented algorithms for bias correction/reduction follow Kosmidis and Firth (2010).
Technical note: In case, either bias correction or reduction is requested,
the second derivative of the inverse link function is required for <code>link</code> and
<code>link.phi</code>. If the two links are specified by their names (as done by default
in <code>betareg</code>), then the <code>"link-glm"</code> objects are enhanced automatically
by the required additional <code>d2mu.deta</code> function. However, if a <code>"link-glm"</code>
object is supplied directly by the user, it needs to have the <code>d2mu.deta</code>
function or, for backward compatibility, <code>dmu.deta</code>.
</p>
<p>The original version of the package was written by Alexandre B. Simas and Andrea V. Rocha
(up to version 1.2). Starting from version 2.0-0 the code was rewritten by Achim Zeileis.
</p>


<h3>Value</h3>

<p><code>betareg</code> returns an object of class <code>"betareg"</code>, i.e., a list with components as follows.
For classic beta regressions (<code>dist = "beta"</code>) several elements are lists with the names <code>"mean"</code>
and <code>"precision"</code> for the information from the respective submodels. For extended-support
beta regressions (<code>dist = "xbetax"</code> or <code>"xbeta"</code>), the corresponding names are
<code>"mu"</code> and <code>"phi"</code> because they are not exactly the mean and precision due to the
censoring in the response variable.
</p>
<p><code>betareg.fit</code> returns an unclassed list with components up to <code>converged</code>.
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a list with elements <code>"mean"</code> (or <code>"mu"</code>) and <code>"precision"</code> (or <code>"phi"</code>)
containing the coefficients from the respective submodels and for extended-support beta regressions
an additional element <code>"nu"</code>,</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>a vector of raw residuals (observed - fitted),</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>a vector of fitted means,</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>output from the <code>optim</code> call for maximizing the log-likelihood(s),</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the method argument passed to the <code>optim</code> call,</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the control arguments passed to the <code>optim</code> call,</p>
</td></tr>
<tr><td><code>start</code></td>
<td>
<p>the starting values for the parameters passed to the <code>optim</code> call,</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the weights used (if any),</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>a list of offset vectors used (if any),</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observations,</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>number of observations with non-zero weights,</p>
</td></tr>
<tr><td><code>df.null</code></td>
<td>
<p>residual degrees of freedom in the null model (constant mean and dispersion),
i.e., <code>n - 2</code>,</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>residual degrees of freedom in the fitted model,</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>logical indicating whether the precision (phi) coefficients will be
treated as full model parameters or nuisance parameters in subsequent calls to
<code>print</code>, <code>summary</code>, <code>coef</code> etc.,</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the fitted model,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>covariance matrix of all parameters in the model,</p>
</td></tr>
<tr><td><code>pseudo.r.squared</code></td>
<td>
<p>pseudo R-squared value (squared correlation of linear predictor
and link-transformed response),</p>
</td></tr>
<tr><td><code>link</code></td>
<td>
<p>a list with elements <code>"mean"</code> (or <code>"mu"</code>) and <code>"precision"</code> (or <code>"phi"</code>)
containing the link objects for the respective submodels,</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>logical indicating successful convergence of <code>optim</code>,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the original function call,</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the original formula,</p>
</td></tr>  
<tr><td><code>terms</code></td>
<td>
<p>a list with elements <code>"mean"</code> (or <code>"mu"</code>), <code>"precision"</code> (or <code>"phi"</code>) and
<code>"full"</code> containing the terms objects for the respective models,</p>
</td></tr>
<tr><td><code>levels</code></td>
<td>
<p>a list with elements <code>"mean"</code> (or <code>"mu"</code>), <code>"precision"</code> (or <code>"phi"</code>) and
<code>"full"</code> containing the levels of the categorical regressors,</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>a list with elements <code>"mean"</code> (or <code>"mu"</code>) and <code>"precision"</code> (or <code>"phi"</code>)
containing the contrasts corresponding to <code>levels</code> from the
respective models,</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full model frame (if <code>model = TRUE</code>),</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response proportion vector (if <code>y = TRUE</code>),</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>a list with elements <code>"mean"</code> (or <code>"mu"</code>) and <code>"precision"</code> (or <code>"phi"</code>)
containing the model matrices from the respective models
(if <code>x = TRUE</code>).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cribari-Neto F, Zeileis A (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Ferrari SLP, Cribari-Neto F (2004).
Beta Regression for Modeling Rates and Proportions.
<em>Journal of Applied Statistics</em>, <b>31</b>(7), 799&ndash;815.
</p>
<p>Grün B, Kosmidis I, Zeileis A (2012).
Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned.
<em>Journal of Statistical Software</em>, <b>48</b>(11), 1&ndash;25.
<a href="https://doi.org/10.18637/jss.v048.i11">doi:10.18637/jss.v048.i11</a>
</p>
<p>Kosmidis I, Firth D (2010).
A Generic Algorithm for Reducing Bias in Parametric Estimation.
<em>Electronic Journal of Statistics</em>, <b>4</b>, 1097&ndash;1112.
</p>
<p>Kosmidis I, Zeileis A (2024).
Extended-Support Beta Regression for [0, 1] Responses.
<em>Unpublished manuscript</em>.
</p>
<p>Simas AB, Barreto-Souza W, Rocha AV (2010).
Improved Estimators for a General Class of Beta Regression Models.
<em>Computational Statistics &amp; Data Analysis</em>, <b>54</b>(2), 348&ndash;366.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.betareg">summary.betareg</a></code>, <code><a href="#topic+predict.betareg">predict.betareg</a></code>, <code><a href="#topic+residuals.betareg">residuals.betareg</a></code>,
<code><a href="Formula.html#topic+Formula">Formula</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)

## Section 4 from Ferrari and Cribari-Neto (2004)
data("GasolineYield", package = "betareg")
data("FoodExpenditure", package = "betareg")

## Table 1
gy &lt;- betareg(yield ~ batch + temp, data = GasolineYield)
summary(gy)

## Table 2
fe_lin &lt;- lm(I(food/income) ~ income + persons, data = FoodExpenditure)
library("lmtest")
bptest(fe_lin)
fe_beta &lt;- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)
summary(fe_beta)

## nested model comparisons via Wald and LR tests
fe_beta2 &lt;- betareg(I(food/income) ~ income, data = FoodExpenditure)
lrtest(fe_beta, fe_beta2)
waldtest(fe_beta, fe_beta2)


## Section 3 from online supplements to Simas et al. (2010)
## mean model as in gy above
## precision model with regressor temp
gy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)

## MLE column in Table 19
summary(gy2)

## LRT row in Table 18
lrtest(gy, gy2)
</code></pre>

<hr>
<h2 id='betareg.control'>Control Parameters for Beta Regression</h2><span id='topic+betareg.control'></span>

<h3>Description</h3>

<p>Various parameters that control fitting of beta regression models
using <code><a href="#topic+betareg">betareg</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betareg.control(phi = TRUE, method = "BFGS", maxit = 5000,
  gradient = NULL, hessian = FALSE, trace = FALSE, start = NULL,
  fsmaxit = 200, fstol = 1e-8, quad = 20, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betareg.control_+3A_phi">phi</code></td>
<td>
<p>logical indicating whether the precision parameter
phi should be treated as a full model parameter (<code>TRUE</code>, default)
or as a nuisance parameter.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_method">method</code></td>
<td>
<p>characters string specifying the <code>method</code> argument
passed to <code><a href="stats.html#topic+optim">optim</a></code>. Additionally, <code>method = "nlminb"</code>
can be used to employ <code><a href="stats.html#topic+nlminb">nlminb</a></code>, instead.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_maxit">maxit</code></td>
<td>
<p>integer specifying the <code>maxit</code> argument (maximal number
of iterations) passed to <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_trace">trace</code></td>
<td>
<p>logical or integer controlling whether tracing information on  
the progress of the optimization should be produced (passed to <code><a href="stats.html#topic+optim">optim</a></code>).</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_gradient">gradient</code></td>
<td>
<p>logical. Should the analytical gradient be used for optimizing
the log-likelihood? If set to <code>FALSE</code> a finite-difference approximation
is used instead. The default of <code>NULL</code> signals that analytical gradients
are only used for the classical <code>"beta"</code> distribution but not for
<code>"xbetax"</code> or <code>"xbeta"</code>.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_hessian">hessian</code></td>
<td>
<p>logical. Should the numerical Hessian matrix from the <code>optim</code> output
be used for estimation of the covariance matrix? By default the analytical solution is employed.
For details see below.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_start">start</code></td>
<td>
<p>an optional vector with starting values for all parameters (including phi).</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_fsmaxit">fsmaxit</code></td>
<td>
<p>integer specifying maximal number of additional (quasi) Fisher scoring
iterations. For details see below.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_fstol">fstol</code></td>
<td>
<p>numeric tolerance for convergence in (quasi) Fisher scoring.
For details see below.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_quad">quad</code></td>
<td>
<p>numeric. The number of quadrature points for numeric
integration in case of <code>dist = "xbetax"</code> is used in the beta regression.</p>
</td></tr>
<tr><td><code id="betareg.control_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All parameters in <code><a href="#topic+betareg">betareg</a></code> are estimated by maximum likelihood
using <code><a href="stats.html#topic+optim">optim</a></code> with control options set in <code><a href="#topic+betareg.control">betareg.control</a></code>.
Most arguments are passed on directly to <code>optim</code>, and <code>start</code> controls
how <code>optim</code> is called.
</p>
<p>After the <code>optim</code> maximization, an additional (quasi) Fisher scoring
can be perfomed to further enhance the result or to perform additional bias reduction.
If <code>fsmaxit</code> is greater than zero, this additional optimization is
performed and it converges if the threshold <code>fstol</code> is attained
for the cross-product of the step size.
</p>
<p>Starting values can be supplied via <code>start</code> or estimated by
<code><a href="stats.html#topic+lmfit">lm.wfit</a></code>, using the link-transformed response.
Covariances are in general derived analytically. Only if <code>type = "ML"</code> and
<code>hessian = TRUE</code>, they are determined numerically using the Hessian matrix
returned by <code>optim</code>. In the latter case no Fisher scoring iterations are
performed.
</p>
<p>The main parameters of interest are the coefficients in the linear predictor of the
model and the additional precision parameter phi which can either
be treated as a full model parameter (default) or as a nuisance parameter. In the latter case
the estimation does not change, only the reported information in output from <code>print</code>,
<code>summary</code>, or <code>coef</code> (among others) will be different. See also examples.
</p>


<h3>Value</h3>

<p>A list with the arguments specified.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)

data("GasolineYield", package = "betareg")

## regression with phi as full model parameter
gy1 &lt;- betareg(yield ~ batch + temp, data = GasolineYield)
gy1

## regression with phi as nuisance parameter
gy2 &lt;- betareg(yield ~ batch + temp, data = GasolineYield, phi = FALSE)
gy2

## compare reported output
coef(gy1)
coef(gy2)
summary(gy1)
summary(gy2)
</code></pre>

<hr>
<h2 id='betatree'>Beta Regression Trees</h2><span id='topic+betatree'></span><span id='topic+plot.betatree'></span><span id='topic+print.betatree'></span><span id='topic+predict.betatree'></span><span id='topic+sctest.betatree'></span>

<h3>Description</h3>

<p>Fit beta regression trees via model-based recursive partitioning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betatree(formula, partition,
  data, subset = NULL, na.action = na.omit, weights, offset, cluster,
  link = "logit", link.phi = "log", control = betareg.control(),
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="betatree_+3A_formula">formula</code></td>
<td>
<p>symbolic description of the model of type <code>y ~ x</code>
or <code>y ~ x | z</code>, specifying the variables influencing mean
and precision of <code>y</code>, respectively. For details see <code><a href="#topic+betareg">betareg</a></code>.</p>
</td></tr>
<tr><td><code id="betatree_+3A_partition">partition</code></td>
<td>
<p>symbolic description of the partitioning variables,
e.g., <code>~ p1 + p2</code>. The argument <code>partition</code> can be omitted
if <code>formula</code> is a three-part formula of type <code>y ~ x | z | p1 + p2</code>.</p>
</td></tr>  
<tr><td><code id="betatree_+3A_data">data</code>, <code id="betatree_+3A_subset">subset</code>, <code id="betatree_+3A_na.action">na.action</code>, <code id="betatree_+3A_weights">weights</code>, <code id="betatree_+3A_offset">offset</code>, <code id="betatree_+3A_cluster">cluster</code></td>
<td>
<p>arguments controlling
data/model processing passed to <code><a href="partykit.html#topic+mob">mob</a></code>.</p>
</td></tr>
<tr><td><code id="betatree_+3A_link">link</code></td>
<td>
<p>character specification of the link function in
the mean model (mu). Currently, <code>"logit"</code>, <code>"probit"</code>,
<code>"cloglog"</code>, <code>"cauchit"</code>, <code>"log"</code>, <code>"loglog"</code> are supported.
Alternatively, an object of class <code>"link-glm"</code> can be supplied.</p>
</td></tr>
<tr><td><code id="betatree_+3A_link.phi">link.phi</code></td>
<td>
<p>character specification of the link function in
the precision model (phi). Currently, <code>"identity"</code>,
<code>"log"</code>, <code>"sqrt"</code> are supported.
Alternatively, an object of class <code>"link-glm"</code> can be supplied.</p>
</td></tr>
<tr><td><code id="betatree_+3A_control">control</code></td>
<td>
<p>a list of control arguments for the beta regression specified via
<code><a href="#topic+betareg.control">betareg.control</a></code>.</p>
</td></tr>
<tr><td><code id="betatree_+3A_...">...</code></td>
<td>
<p>further control arguments for the recursive partitioning
passed to <code><a href="partykit.html#topic+mob_control">mob_control</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Beta regression trees are an application of model-based recursive partitioning
(implemented in <code><a href="partykit.html#topic+mob">mob</a></code>, see Zeileis et al. 2008) to
beta regression (implemented in <code><a href="#topic+betareg">betareg</a></code>, see Cribari-Neto
and Zeileis 2010). See also Grün at al. (2012) for more details.
</p>
<p>Various methods are provided for <code>"betatree"</code> objects, most of them
inherit their behavior from <code>"mob"</code> objects (e.g., <code>print</code>, <code>summary</code>,
<code>coef</code>, etc.). The <code>plot</code> method employs the <code><a href="partykit.html#topic+node_bivplot">node_bivplot</a></code>
panel-generating function.
</p>


<h3>Value</h3>

<p><code>betatree()</code> returns an object of S3 class <code>"betatree"</code> which
inherits from <code>"modelparty"</code>.
</p>


<h3>References</h3>

<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Grün, B., Kosmidis, I., and Zeileis, A. (2012).
Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned.
<em>Journal of Statistical Software</em>, <b>48</b>(11), 1&ndash;25.
<a href="https://doi.org/10.18637/jss.v048.i11">doi:10.18637/jss.v048.i11</a>
</p>
<p>Zeileis, A., Hothorn, T., and Hornik K. (2008).
Model-Based Recursive Partitioning.
<em>Journal of Computational and Graphical Statistics</em>, 
<b>17</b>(2), 492&ndash;514.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code>, <code><a href="#topic+betareg.fit">betareg.fit</a></code>, <code><a href="partykit.html#topic+mob">mob</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)
suppressWarnings(RNGversion("3.5.0"))

## data with two groups of dyslexic and non-dyslexic children
data("ReadingSkills", package = "betareg")
## additional random noise (not associated with reading scores)
set.seed(1071)
ReadingSkills$x1 &lt;- rnorm(nrow(ReadingSkills))
ReadingSkills$x2 &lt;- runif(nrow(ReadingSkills))
ReadingSkills$x3 &lt;- factor(rnorm(nrow(ReadingSkills)) &gt; 0)

## fit beta regression tree: in each node
##   - accurcay's mean and precision depends on iq
##   - partitioning is done by dyslexia and the noise variables x1, x2, x3
## only dyslexia is correctly selected for splitting
bt &lt;- betatree(accuracy ~ iq | iq, ~ dyslexia + x1 + x2 + x3,
  data = ReadingSkills, minsize = 10)
plot(bt)

## inspect result
coef(bt)
if(require("strucchange")) sctest(bt)
## IGNORE_RDIFF_BEGIN
summary(bt, node = 2)
summary(bt, node = 3)
## IGNORE_RDIFF_END

## add a numerical variable with relevant information for splitting
ReadingSkills$x4 &lt;- rnorm(nrow(ReadingSkills), c(-1.5, 1.5)[ReadingSkills$dyslexia])

bt2 &lt;- betatree(accuracy ~ iq | iq, ~ x1 + x2 + x3 + x4,
  data = ReadingSkills, minsize = 10)
plot(bt2)

## inspect result
coef(bt2)
if(require("strucchange")) sctest(bt2)
## IGNORE_RDIFF_BEGIN
summary(bt2, node = 2)
summary(bt2, node = 3)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='CarTask'>
Partition-primed Probability Judgement Task for Car Dealership
</h2><span id='topic+CarTask'></span>

<h3>Description</h3>

<p>In this study participants were asked to judge how likely it is that a
customer trades in a coupe or that a customer buys a car form a
specific salesperson out of four possible salespersons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("CarTask", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame with 155 observations on the following 3 variables.
</p>

<dl>
<dt><code>task</code></dt><dd><p>a factor with levels <code>Car</code> and
<code>Salesperson</code> indicating the condition.</p>
</dd>
<dt><code>probability</code></dt><dd><p>a numeric vector of the estimated probability.</p>
</dd>
<dt><code>NFCCscale</code></dt><dd><p>a numeric vector of the NFCC scale.</p>
</dd>
</dl>



<h3>Details</h3>

<p>All participants in the study were undergraduate students at The
Australian National University, some of whom obtained course credit in
first-year Psychology for their participation in the study.
</p>
<p>The NFCC scale is a combined scale of the Need for Closure and Need
for Certainty scales which are strongly correlated.
</p>
<p>For <code>task</code> the questions were:
</p>

<dl>
<dt>Car</dt><dd><p>What is the probability that a customer trades in a coupe?</p>
</dd>
<dt>Salesperson</dt><dd><p>What is the probability that a customer buys a
car from Carlos?</p>
</dd>
</dl>



<h3>Source</h3>

<p>Taken from Smithson et al. (2011) supplements.
</p>


<h3>References</h3>

<p>Smithson, M., Merkle, E.C., and Verkuilen, J. (2011). Beta
Regression Finite Mixture Models of Polarization and Priming.
<em>Journal of Educational and Behavioral Statistics</em>, <b>36</b>(6), 804&ndash;831.
<a href="https://doi.org/10.3102/1076998610396893">doi:10.3102/1076998610396893</a>
</p>
<p>Smithson, M., and Segale, C. (2009). Partition Priming in Judgments of
Imprecise Probabilities. <em>Journal of Statistical Theory and
Practice</em>, <b>3</b>(1), 169&ndash;181.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("CarTask", package = "betareg")
library("flexmix")
car_betamix &lt;- betamix(probability ~ 1, data = CarTask, k = 3,
  extra_components = list(extraComponent(type = "uniform", coef = 1/2,
  delta = 0.01), extraComponent(type = "uniform", coef = 1/4, delta = 0.01)),
  FLXconcomitant = FLXPmultinom(~ task))
</code></pre>

<hr>
<h2 id='FoodExpenditure'>Proportion of Household Income Spent on Food</h2><span id='topic+FoodExpenditure'></span>

<h3>Description</h3>

<p>Data on proportion of income spent on food for a random sample of 38 households in a large US city.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("FoodExpenditure", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame containing 38 observations on 3 variables.
</p>

<dl>
<dt>food</dt><dd><p>household expenditures for food.</p>
</dd>
<dt>income</dt><dd><p>household income.</p>
</dd>
<dt>persons</dt><dd><p>number of persons living in household.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Taken from Griffiths et al. (1993, Table 15.4).
</p>


<h3>References</h3>

<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Ferrari, S.L.P., and Cribari-Neto, F. (2004).
Beta Regression for Modeling Rates and Proportions.
<em>Journal of Applied Statistics</em>, <b>31</b>(7), 799&ndash;815.
</p>
<p>Griffiths, W.E., Hill, R.C., and Judge, G.G. (1993).
<em>Learning and Practicing Econometrics</em>
New York: John Wiley and Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("FoodExpenditure", package = "betareg")

## Ferrari and Cribari-Neto (2004)
## Section 4
fe_lin &lt;- lm(I(food/income) ~ income + persons, data = FoodExpenditure)
library("lmtest")
bptest(fe_lin)

## Table 2
fe_beta &lt;- betareg(I(food/income) ~ income + persons, data = FoodExpenditure)
summary(fe_beta)
</code></pre>

<hr>
<h2 id='GasolineYield'>Estimation of Gasoline Yields from Crude Oil</h2><span id='topic+GasolineYield'></span>

<h3>Description</h3>

<p>Operational data of the proportion of crude oil converted to gasoline after
distillation and fractionation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("GasolineYield", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame containing 32 observations on 6 variables.
</p>

<dl>
<dt>yield</dt><dd><p>proportion of crude oil converted to gasoline after distillation and fractionation.</p>
</dd>
<dt>gravity</dt><dd><p>crude oil gravity (degrees API).</p>
</dd>
<dt>pressure</dt><dd><p>vapor pressure of crude oil (lbf/in2).</p>
</dd>
<dt>temp10</dt><dd><p>temperature (degrees F) at which 10 percent of crude oil has vaporized.</p>
</dd>
<dt>temp</dt><dd><p>temperature (degrees F) at which all gasoline has vaporized.</p>
</dd>
<dt>batch</dt><dd><p>factor indicating unique batch of conditions <code>gravity</code>,
<code>pressure</code>, and <code>temp10</code>.</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset was collected by Prater (1956), its dependent variable is the
proportion of crude oil after distillation and fractionation. This dataset was
analyzed by Atkinson (1985), who used the linear regression model and noted that
there is &ldquo;indication that the error distribution is not quite symmetrical,
giving rise to some unduly large and small residuals&rdquo; (p. 60).
</p>
<p>The dataset contains 32 observations on the response and on the independent
variables. It has been noted (Daniel and Wood, 1971, Chapter 8) that there are only
ten sets of values of the first three explanatory variables which correspond to
ten different crudes and were subjected to experimentally controlled distillation
conditions. These conditions are captured in variable <code>batch</code> and
the data were ordered according to the ascending order of <code>temp10</code>.
</p>


<h3>Source</h3>

<p>Taken from Prater (1956).
</p>


<h3>References</h3>

<p>Atkinson, A.C. (1985).
<em>Plots, Transformations and Regression: An Introduction to Graphical Methods of Diagnostic Regression Analysis</em>.
New York: Oxford University Press.
</p>
<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Daniel, C., and Wood, F.S. (1971).
<em>Fitting Equations to Data</em>.
New York: John Wiley and Sons.
</p>
<p>Ferrari, S.L.P., and Cribari-Neto, F. (2004).
Beta Regression for Modeling Rates and Proportions.
<em>Journal of Applied Statistics</em>, <b>31</b>(7), 799&ndash;815.
</p>
<p>Prater, N.H. (1956).
Estimate Gasoline Yields from Crudes.
<em>Petroleum Refiner</em>, <b>35</b>(5), 236&ndash;238.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
data("GasolineYield", package = "betareg")

gy1 &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)
summary(gy1)

## Ferrari and Cribari-Neto (2004)
gy2 &lt;- betareg(yield ~ batch + temp, data = GasolineYield)
## Table 1
summary(gy2)
## Figure 2
par(mfrow = c(3, 2))
plot(gy2, which = 1, type = "pearson", sub.caption = "")
plot(gy2, which = 1, type = "deviance", sub.caption = "")
plot(gy2, which = 5, type = "deviance", sub.caption = "")
plot(gy2, which = 4, type = "pearson", sub.caption = "")
plot(gy2, which = 2:3)
par(mfrow = c(1, 1))

## exclude 4th observation
gy2a &lt;- update(gy2, subset = -4)
gy2a
summary(gy2a)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='gleverage'>Generalized Leverage Values</h2><span id='topic+gleverage'></span><span id='topic+gleverage.betareg'></span>

<h3>Description</h3>

<p>Compute the generalized leverages values for fitted models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gleverage(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gleverage_+3A_model">model</code></td>
<td>
<p>a model object.</p>
</td></tr>
<tr><td><code id="gleverage_+3A_...">...</code></td>
<td>
<p>further arguments passed to methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>gleverage</code> is a new generic for computing generalized leverage values as suggested by
Wei, Hu, and Fung (1998). Currently, there is only a method for <code>betareg</code> models, implementing
the formulas from Rocha and Simas (2011) which are consistent with the formulas from
Ferrari and Cribari-Neto (2004) for the fixed dispersion case.
</p>
<p>Currently, the vector of generalized leverages requires computations and
storage of order <code class="reqn">n \times n</code>.
</p>


<h3>References</h3>

<p>Ferrari, S.L.P., and Cribari-Neto, F. (2004).
Beta Regression for Modeling Rates and Proportions.
<em>Journal of Applied Statistics</em>, <b>31</b>(7), 799&ndash;815.
</p>
<p>Rocha, A.V., and Simas,  A.B. (2011).
Influence Diagnostics in a General Class of Beta Regression Models.
<em>Test</em>, <b>20</b>(1), 95&ndash;119.
<a href="https://doi.org/10.1007/s11749-010-0189-z">doi:10.1007/s11749-010-0189-z</a>
</p>
<p>Wei, B.-C., and Hu, Y.-Q., and Fung, W.-K. (1998).
Generalized Leverage and Its Applications.
<em>Scandinavian Journal of Statistics</em>, <b>25</b>, 25&ndash;37.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)
data("GasolineYield", package = "betareg")
gy &lt;- betareg(yield ~ batch + temp, data = GasolineYield)
gleverage(gy)
</code></pre>

<hr>
<h2 id='ImpreciseTask'>
Imprecise Probabilities for Sunday Weather and Boeing Stock Task
</h2><span id='topic+ImpreciseTask'></span>

<h3>Description</h3>

<p>In this study participants were asked to estimate upper and lower
probabilities for event to occur and not to occur.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ImpreciseTask", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame with 242 observations on the following 3 variables.
</p>

<dl>
<dt><code>task</code></dt><dd><p>a factor with levels <code>Boeing stock</code> and <code>Sunday weather</code>.</p>
</dd>
<dt><code>location</code></dt><dd><p>a numeric vector of the average of the lower
estimate for the event not to occur and the upper estimate for the
event to occur.</p>
</dd>
<dt><code>difference</code></dt><dd><p>a numeric vector of the differences of the
lower and upper estimate for the event to occur.</p>
</dd>
</dl>



<h3>Details</h3>

<p>All participants in the study were either first- or second-year
undergraduate students in psychology, none of whom had a strong
background in probability or were familiar with imprecise probability
theories. 
</p>
<p>For the sunday weather task see <code><a href="#topic+WeatherTask">WeatherTask</a></code>. For the Boeing
stock task participants were asked to estimate the probability that
Boeing's stock would rise more than those in a list of 30 companies.
</p>
<p>For each task participants were asked to provide lower and upper
estimates for the event to occur and not to occur.  
</p>


<h3>Source</h3>

<p>Taken from Smithson et al. (2011) supplements.
</p>


<h3>References</h3>

<p>Smithson, M., Merkle, E.C., and Verkuilen, J. (2011). Beta
Regression Finite Mixture Models of Polarization and Priming.
<em>Journal of Educational and Behavioral Statistics</em>, <b>36</b>(6), 804&ndash;831.
<a href="https://doi.org/10.3102/1076998610396893">doi:10.3102/1076998610396893</a>
</p>
<p>Smithson, M., and Segale, C. (2009). Partition Priming in Judgments of
Imprecise Probabilities. <em>Journal of Statistical Theory and
Practice</em>, <b>3</b>(1), 169&ndash;181.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("ImpreciseTask", package = "betareg")
library("flexmix")
wt_betamix &lt;- betamix(location ~ difference * task, data = ImpreciseTask, k = 2,
  extra_components = extraComponent(type = "betareg", coef =
    list(mean = 0, precision = 8)),
  FLXconcomitant = FLXPmultinom(~ task))
</code></pre>

<hr>
<h2 id='LossAversion'>(No) Myopic Loss Aversion in Adolescents</h2><span id='topic+LossAversion'></span>

<h3>Description</h3>

<p>Data for assessing the extent of myopic loss aversion among
adolescents (mostly aged 11 to 19).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("LossAversion", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame containing 570 observations on 7 variables.
</p>

<dl>
<dt>invest</dt><dd><p>numeric. Average proportion of points invested across
all 9 rounds.</p>
</dd>
<dt>gender</dt><dd><p>factor. Gender of the player (or team of players).</p>
</dd>
<dt>male</dt><dd><p>factor. Was (at least one of) the player(s) male (in the team)?</p>
</dd>
<dt>age</dt><dd><p>numeric. Age in years (averaged for teams).</p>
</dd>
<dt>treatment</dt><dd><p>factor. Type of treatment: long vs. short.</p>
</dd>
<dt>grade</dt><dd><p>factor. School grades: 6-8 (11-14 years) vs. 10-12 (15-18 years).</p>
</dd>
<dt>arrangement</dt><dd><p>factor. Is the player a single player or team of two?</p>
</dd>
</dl>



<h3>Details</h3>

<p>Myopic loss aversion is a phenomenon in behavioral economics,
where individuals do not behave economically rationally when making short-term
decisions under uncertainty. Example: In lotteries with positive expected payouts
investments are lower than the maximum possible (loss aversion). This effect
is enhanced for short-term investments (myopia or short-sightedness).
</p>
<p>The data in <code>LossAversion</code> were collected by Matthias Sutter and
Daniela Glätzle-Rützler (Universität Innsbruck) in an experiment with
high-school students in Tyrol, Austria (Schwaz and Innsbruck). The students
could invest X points (0-100) in each of 9 rounds in a lottery. The payouts
were 100 + 2.5 * X points with probability 1/3 and 100 - X points with
probability 2/3. Thus, the expected payouts were 100 + 1/6 * X points.
Depending on the treatment in the experiment, the investments could either be
modified in each round (treatment: &quot;short&quot;) or only in round 1, 4, 7
(treatment &quot;long&quot;). Decisions were either made alone or in teams of two. The
points were converted to monetary payouts using a conversion of
EUR 0.5 per 100 points for lower grades (Unterstufe, 6-8) or EUR 1.0 per 100
points for upper grades (Oberstufe, 10-12).
</p>
<p>From the myopic loss aversion literature (on adults) one would expect that the
investments of the players (either single players or teams of two) would
depend on all factors: Investments should be </p>

<ul>
<li><p> lower in the short treatment (which would indicate myopia),
</p>
</li>
<li><p> higher for teams (indicating a reduction in loss aversion),
</p>
</li>
<li><p> higher for (teams with) male players,
</p>
</li>
<li><p> increase with age/grade.
</p>
</li></ul>

<p>See Glätzle-Rützler et al. (2015) for more details and references to the
literature. In their original analysis, the investments are analyzes using
a panel structure (i.e., 9 separate investments for each team). Here, the
data are averaged across rounds for each player, leading to qualitatively
similar results. The full data along with replication materials are available
in the Harvard Dataverse.
</p>


<h3>Source</h3>

<p>Glätzle-Rützler D, Sutter M, Zeileis A (2020).
Replication Data for: No Myopic Loss Aversion in Adolescents? - An Experimental Note.
<em>Harvard Dataverse</em>, UNF:6:6hVtbHavJAFYfL7dDl7jqA==.
<a href="https://doi.org/10.7910/DVN/IHFZAK">doi:10.7910/DVN/IHFZAK</a>
</p>


<h3>References</h3>

<p>Glätzle-Rützler D, Sutter M, Zeileis A (2015).
No Myopic Loss Aversion in Adolescents? - An Experimental Note.
<em>Journal of Economic Behavior &amp; Organization</em>, <b>111</b>, 169-176.
<a href="https://doi.org/10.1016/j.jebo.2014.12.021">doi:10.1016/j.jebo.2014.12.021</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)

## data and add ad-hoc scaling (a la Smithson &amp; Verkuilen)
data("LossAversion", package = "betareg")
LossAversion &lt;- transform(LossAversion,
  invests = (invest * (nrow(LossAversion) - 1) + 0.5)/nrow(LossAversion))


## models: normal (with constant variance), beta, extended-support beta mixture
la_n &lt;- lm(invest ~ grade * (arrangement + age) + male, data = LossAversion)
summary(la_n)


la_b &lt;- betareg(invests ~ grade * (arrangement + age) + male | arrangement + male + grade,
  data = LossAversion)
summary(la_b)

la_xbx &lt;- betareg(invest ~ grade * (arrangement + age) + male | arrangement + male + grade,
  data = LossAversion)
summary(la_xbx)

## coefficients in XBX are typically somewhat shrunken compared to beta
cbind(XBX = coef(la_xbx), Beta = c(coef(la_b), NA))


## predictions on subset: (at least one) male players, higher grades, around age 16
la &lt;- subset(LossAversion, male == "yes" &amp; grade == "10-12" &amp; age &gt;= 15 &amp;  age &lt;= 17)
la_nd &lt;- data.frame(arrangement = c("single", "team"), male = "yes", age = 16, grade = "10-12")

## empirical vs fitted E(Y)
la_nd$mean_emp &lt;- aggregate(invest ~ arrangement, data = la, FUN = mean)$invest 
la_nd$mean_n &lt;- predict(la_n, la_nd)
la_nd$mean_b &lt;- predict(la_b, la_nd)
la_nd$mean_xbx &lt;- predict(la_xbx, la_nd)
la_nd

## visualization: all means rather similar
la_mod &lt;- c("Emp", "N", "B", "XBX")
la_col &lt;- unname(palette.colors())[c(1, 2, 4, 4)]
la_lty &lt;- c(1, 5, 5, 1)
matplot(la_nd[, paste0("mean_", tolower(la_mod))], type = "l",
  col = la_col, lty = la_lty, lwd = 2, ylab = "E(Y)", main = "E(Y)", xaxt = "n")
axis(1, at = 1:2, labels = la_nd$arrangement)
legend("topleft", la_mod, col = la_col, lty = la_lty, lwd = 2, bty = "n")


## empirical vs. fitted P(Y &gt; 0.95)
la_nd$prob_emp &lt;- aggregate(invest &gt;= 0.95 ~ arrangement, data = la, FUN = mean)$invest
la_nd$prob_n &lt;- pnorm(0.95, mean = la_nd$mean_n, sd = summary(la_n)$sigma, lower.tail = FALSE)
la_nd$prob_b &lt;- 1 - predict(la_b, la_nd, type = "probability", at = 0.95)
la_nd$prob_xbx &lt;- 1 - predict(la_xbx, la_nd, type = "probability", at = 0.95)
la_nd[, -(5:8)]

## visualization: only XBX works well
matplot(la_nd[, paste0("prob_", tolower(la_mod))], type = "l",
  col = la_col, lty = la_lty, lwd = 2, ylab = "P(Y &gt; 0.95)", main = "P(Y &gt; 0.95)", xaxt = "n")
axis(1, at = 1:2, labels = la_nd$arrangement)
legend("topleft", la_mod, col = la_col, lty = la_lty, lwd = 2, bty = "n")

</code></pre>

<hr>
<h2 id='MockJurors'>Confidence of Mock Jurors in Their Verdicts</h2><span id='topic+MockJurors'></span>

<h3>Description</h3>

<p>Data with responses of naive mock jurors to the conventional
conventional two-option verdict (guilt vs. acquittal) versus a
three-option verdict setup (the third option was the Scottish
'not proven' alternative), in the presence/absence of conflicting
testimonial evidence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("MockJurors", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame containing 104 observations on 3 variables.
</p>

<dl>
<dt>verdict</dt><dd><p>factor indicating whether a two-option or
three-option verdict is requested. (A sum contrast rather
than treatment contrast is employed.)</p>
</dd>
<dt>conflict</dt><dd><p>factor. Is there conflicting testimonial evidence?
(A sum contrast rather than treatment contrast is employed.)</p>
</dd>
<dt>confidence</dt><dd><p>jurors degree of confidence in his/her verdict,
scaled to the open unit interval (see below).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data were collected by Daily (2004) among first-year psychology
students at Australian National University. Smithson and Verkuilen (2006)
employed the data scaling the original confidence (on a scale 0&ndash;100)
to the open unit interval: <code>((original_confidence/100) * 103 - 0.5) / 104</code>.
</p>
<p>The original coding of <code>conflict</code> in the data provided from Smithson's
homepage is -1/1 which Smithson and Verkuilen (2006) describe to mean
no/yes. However, all their results (sample statistics, histograms, etc.)
suggest that it actually means yes/no which was employed in <code>MockJurors</code>.
</p>


<h3>Source</h3>

<p>Example 1 from Smithson and Verkuilen (2006) supplements.
</p>


<h3>References</h3>

<p>Deady, S. (2004).
The Psychological Third Verdict: 'Not Proven' or 'Not Willing to Make a Decision'?
<em>Unpublished honors thesis</em>, The Australian National University, Canberra.
</p>
<p>Smithson, M., and Verkuilen, J. (2006).
A Better Lemon Squeezer? Maximum-Likelihood Regression with
Beta-Distributed Dependent Variables.
<em>Psychological Methods</em>, <b>11</b>(7), 54&ndash;71.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code>, <code><a href="#topic+ReadingSkills">ReadingSkills</a></code>, <code><a href="#topic+StressAnxiety">StressAnxiety</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("MockJurors", package = "betareg")
library("lmtest")

## Smithson &amp; Verkuilen (2006, Table 1)
## variable dispersion model
## (NOTE: numerical rather than analytical Hessian is used for replication,
##  Smithson &amp; Verkuilen erroneously compute one-sided p-values)
mj_vd &lt;- betareg(confidence ~ verdict * conflict | verdict * conflict,
  data = MockJurors, hessian = TRUE)
summary(mj_vd)

## model selection for beta regression: null model, fixed dispersion model (p. 61)
mj_null &lt;- betareg(confidence ~ 1 | 1, data = MockJurors)
mj_fd &lt;-   betareg(confidence ~ verdict * conflict | 1, data = MockJurors)
lrtest(mj_null, mj_fd)
lrtest(mj_null, mj_vd)
## McFadden's pseudo-R-squared
1 - as.vector(logLik(mj_null)/logLik(mj_vd))

## visualization
if(require("lattice")) {
  histogram(~ confidence | conflict + verdict, data = MockJurors,
    col = "lightgray", breaks = 0:10/10, type = "density")
}

## see demo("SmithsonVerkuilen2006", package = "betareg") for more details
</code></pre>

<hr>
<h2 id='plot.betareg'>Diagnostic Plots for betareg Objects</h2><span id='topic+plot.betareg'></span>

<h3>Description</h3>

<p>Various types of standard diagnostic plots can be produced, involving various types of
residuals, influence measures etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'betareg'
plot(x, which = 1:4,
  caption = c("Residuals vs indices of obs.", "Cook's distance plot",
    "Generalized leverage vs predicted values", "Residuals vs linear predictor", 
    "Half-normal plot of residuals", "Predicted vs observed values"),
    sub.caption = paste(deparse(x$call), collapse = "\n"), main = "", 
    ask = prod(par("mfcol")) &lt; length(which) &amp;&amp; dev.interactive(), 
    ..., type = "quantile", nsim = 100, level = 0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.betareg_+3A_x">x</code></td>
<td>
<p>fitted model object of class <code>"betareg"</code>.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_which">which</code></td>
<td>
<p>numeric. If a subset of the plots is required, specify a subset of the numbers <code>1:6</code>.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_caption">caption</code></td>
<td>
<p>character. Captions to appear above the plots.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_sub.caption">sub.caption</code></td>
<td>
<p>character. Common title-above figures if there are multiple.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_main">main</code></td>
<td>
<p>character. Title to each plot in addition to the above <code>caption</code>.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_ask">ask</code></td>
<td>
<p>logical. If <code>TRUE</code>, the user is asked before each plot.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_type">type</code></td>
<td>
<p>character indicating type of residual to be used, see <code><a href="#topic+residuals.betareg">residuals.betareg</a></code>.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_nsim">nsim</code></td>
<td>
<p>numeric. Number of simulations in half-normal plots.</p>
</td></tr>
<tr><td><code id="plot.betareg_+3A_level">level</code></td>
<td>
<p>numeric. Confidence level in half-normal plots.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot</code> method for <code><a href="#topic+betareg">betareg</a></code> objects produces various types
of diagnostic plots. Most of these are standard for regression models and involve
various types of residuals, influence measures etc. See Ferrari and Cribari-Neto (2004)
for a discussion of some of these displays.
</p>
<p>The <code>which</code> argument can be used to select a subset of currently six supported
types of displays. The corresponding element of <code>caption</code> contains a brief
description. In some more detail, the displays are: Residuals (as selected by
<code>type</code>) vs indices of observations (<code>which = 1</code>). Cook's distances
vs indices of observations (<code>which = 2</code>). Generalized leverage vs
predicted values (<code>which = 3</code>). Residuals vs linear predictor  (<code>which = 4</code>).
Half-normal plot of residuals (<code>which = 5</code>), which is obtained using a simulation
approach. Predicted vs observed values (<code>which = 6</code>).
</p>


<h3>References</h3>

<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Ferrari, S.L.P., and Cribari-Neto, F. (2004).
Beta Regression for Modeling Rates and Proportions.
<em>Journal of Applied Statistics</em>, <b>31</b>(7), 799&ndash;815.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("GasolineYield", package = "betareg")

gy &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)

par(mfrow = c(3, 2))
plot(gy, which = 1:6)
par(mfrow = c(1, 1))
</code></pre>

<hr>
<h2 id='predict.betareg'>Prediction Method for betareg Objects</h2><span id='topic+predict.betareg'></span><span id='topic+pit.betareg'></span><span id='topic+rootogram.betareg'></span>

<h3>Description</h3>

<p>Extract various types of predictions from beta regression models:
either on the scale of responses in (0, 1) or the scale of
the linear predictor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'betareg'
predict(object, newdata = NULL,
  type = c("response", "link", "precision", "variance", "parameters",
    "density", "probability", "quantile"),
  na.action = na.pass, at = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.betareg_+3A_object">object</code></td>
<td>
<p>fitted model object of class <code>"betareg"</code>.</p>
</td></tr>
<tr><td><code id="predict.betareg_+3A_newdata">newdata</code></td>
<td>
<p>optionally, a data frame in which to look for variables with
which to predict. If omitted, the original observations are used.</p>
</td></tr>
<tr><td><code id="predict.betareg_+3A_type">type</code></td>
<td>
<p>character indicating type of predictions: fitted means of response (<code>"response"</code>),
corresponding linear predictor (<code>"link"</code>), fitted precision parameter
phi (<code>"precision"</code>), fitted variances of response (<code>"variance"</code>),
or fitted quantile(s) of the response distribution (<code>"quantile"</code>).</p>
</td></tr>
<tr><td><code id="predict.betareg_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing values
in <code>newdata</code>. The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="predict.betareg_+3A_at">at</code></td>
<td>
<p>numeric vector indicating the level(s) at which quantiles
should be predicted (only if <code>type = "quantile"</code>), defaulting
to the median <code>at = 0.5</code>.</p>
</td></tr>
<tr><td><code id="predict.betareg_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FIXME: Update to extended type and at processing.
</p>
<p>FIXME: Add comments about pit and rootogram.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)

data("GasolineYield", package = "betareg")

gy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)

cbind(
  predict(gy2, type = "response"),
  predict(gy2, type = "link"),
  predict(gy2, type = "precision"),
  predict(gy2, type = "variance"),
  predict(gy2, type = "quantile", at = c(0.25, 0.5, 0.75))
)

## evaluate cumulative _p_robabilities for (small) new data set
gyd &lt;- GasolineYield[c(1, 5, 10), ]
## CDF at 0.1 for each observation
predict(gy2, newdata = gyd, type = "probability", at = 0.1)
## CDF at each combination of 0.1/0.2 and observations
predict(gy2, newdata = gyd, type = "probability", at = c(0.1, 0.2))
## CDF at pairwise combinations of 0.1/0.2/0.3 and observations
predict(gy2, newdata = gyd, type = "probability", at = c(0.1, 0.2, 0.3))
## CDF at all combinations of 0.1/0.2/0.3 and observations
predict(gy2, newdata = gyd, type = "probability", at = rbind(c(0.1, 0.2, 0.3)))
</code></pre>

<hr>
<h2 id='ReadingSkills'>Dyslexia and IQ Predicting Reading Accuracy</h2><span id='topic+ReadingSkills'></span>

<h3>Description</h3>

<p>Data for assessing the contribution of non-verbal IQ to
children's reading skills in dyslexic and non-dyslexic children.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ReadingSkills", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame containing 44 observations on 3 variables.
</p>

<dl>
<dt>accuracy</dt><dd><p>numeric. Reading score with maximum restricted to be
0.99 rather than 1 (see below).</p>
</dd>
<dt>dyslexia</dt><dd><p>factor. Is the child dyslexic? (A sum contrast rather
than treatment contrast is employed.)</p>
</dd>
<dt>iq</dt><dd><p>numeric. Non-verbal intelligence quotient transformed to z-scores.</p>
</dd>
<dt>accuracy1</dt><dd><p>numeric. Unrestricted reading score with a maximum of 1
(see below).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data were collected by Pammer and Kevan (2004) and employed by
Smithson and Verkuilen (2006). The original reading accuracy score was transformed
by Smithson and Verkuilen (2006) so that <code>accuracy</code> is in the open unit
interval (0, 1) and beta regression can be employed. First, the original accuracy
was scaled using the minimal and maximal score (<code>a</code> and <code>b</code>, respectively)
that can be obtained in the test: <code>accuracy1 = (original_accuracy - a) / (b - a)</code>
(<code>a</code> and <code>b</code> are not provided). Subsequently, <code>accuracy</code> was obtained
from <code>accuracy1</code> by replacing all observations with a value of 1 with 0.99.
</p>
<p>Kosmidis and Zeileis (2024) propose to investigate the original unrestricted
<code>accuracy1</code> variable using their extended-support beta mixture regression.
</p>


<h3>Source</h3>

<p>Example 3 from Smithson and Verkuilen (2006) supplements.
</p>


<h3>References</h3>

<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Grün, B., Kosmidis, I., and Zeileis, A. (2012).
Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned.
<em>Journal of Statistical Software</em>, <b>48</b>(11), 1&ndash;25.
<a href="https://doi.org/10.18637/jss.v048.i11">doi:10.18637/jss.v048.i11</a>
</p>
<p>Kosmidis I, Zeileis A (2024).
Extended-Support Beta Regression for [0, 1] Responses.
<em>Unpublished manuscript</em>.
</p>
<p>Pammer, K., and Kevan, A. (2004).
The Contribution of Visual Sensitivity, Phonological Processing
and Non-Verbal IQ to Children's Reading.
<em>Unpublished manuscript</em>, The Australian National University, Canberra.
</p>
<p>Smithson, M., and Verkuilen, J. (2006).
A Better Lemon Squeezer? Maximum-Likelihood Regression with
Beta-Distributed Dependent Variables.
<em>Psychological Methods</em>, <b>11</b>(7), 54&ndash;71.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code>, <code><a href="#topic+MockJurors">MockJurors</a></code>, <code><a href="#topic+StressAnxiety">StressAnxiety</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)
data("ReadingSkills", package = "betareg")

## Smithson &amp; Verkuilen (2006, Table 5)
## OLS regression
## (Note: typo in iq coefficient: 0.3954 instead of 0.3594)
rs_ols &lt;- lm(qlogis(accuracy) ~ dyslexia * iq, data = ReadingSkills)
summary(rs_ols)
## Beta regression (with numerical rather than analytic standard errors)
## (Note: Smithson &amp; Verkuilen erroneously compute one-sided p-values)
rs_beta &lt;- betareg(accuracy ~ dyslexia * iq | dyslexia + iq,
  data = ReadingSkills, hessian = TRUE)
summary(rs_beta)

## Extended-support beta mixture regression (Kosmidis &amp; Zeileis 2024)
rs_xbx &lt;- betareg(accuracy1 ~ dyslexia * iq | dyslexia + iq, data = ReadingSkills)
summary(rs_xbx)

## Coefficients in XBX are typically somewhat shrunken compared to beta
cbind(XBX = coef(rs_xbx), Beta = c(coef(rs_beta), NA))

## Visualization
plot(accuracy1 ~ iq, data = ReadingSkills, col = c(4, 2)[dyslexia], pch = 19)
nd &lt;- data.frame(dyslexia = "no", iq = -30:30/10)
lines(nd$iq, predict(rs_xbx, nd), col = 4)
lines(nd$iq, predict(rs_beta, nd), col = 4, lty = 5)
lines(nd$iq, plogis(predict(rs_ols, nd)), col = 4, lty = 3)
nd &lt;- data.frame(dyslexia = "yes", iq = -30:30/10)
lines(nd$iq, predict(rs_xbx, nd), col = 2)
lines(nd$iq, predict(rs_beta, nd), col = 2, lty = 5)
lines(nd$iq, plogis(predict(rs_ols, nd)), col = 2, lty = 3)
legend("topleft", c("Dyslexia: no", "Dyslexia: yes", "OLS", "XBX", "Beta"),
  lty = c(0, 0, 3, 1, 5), pch = c(19, 19, NA, NA, NA), col = c(4, 2, 1, 1, 1), bty = "n")

## see demo("SmithsonVerkuilen2006", package = "betareg") for further details
</code></pre>

<hr>
<h2 id='residuals.betareg'>Residuals Method for betareg Objects</h2><span id='topic+residuals.betareg'></span>

<h3>Description</h3>

<p>Extract various types of residuals from beta regression models:
raw response residuals (observed - fitted), Pearson residuals (raw residuals scaled by
square root of variance function), deviance residuals (scaled log-likelihood contributions),
and different kinds of weighted residuals suggested by Espinheira et al. (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'betareg'
residuals(object, type = c("quantile",
  "deviance", "pearson", "response", "weighted", "sweighted", "sweighted2"),
  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.betareg_+3A_object">object</code></td>
<td>
<p>fitted model object of class <code>"betareg"</code>.</p>
</td></tr>
<tr><td><code id="residuals.betareg_+3A_type">type</code></td>
<td>
<p>character indicating type of residuals.</p>
</td></tr>
<tr><td><code id="residuals.betareg_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default residuals (starting from version 3.2-0) are quantile residuals
as proposed by Dunn and Smyth (1996) and explored in the context of beta
regression by Pereira (2017). In case of extended support beta regression
with boundary observations at 0 and/or 1, the quantile residuals for the
boundary observations are randomized.
</p>
<p>The definitions of all other residuals are provided in Espinheira et al. (2008):
Equation 2 for <code>"pearson"</code>, last equation on page 409 for <code>"deviance"</code>,
Equation 6 for <code>"weighted"</code>, Equation 7 for <code>"sweighted"</code>, and
Equation 8 for <code>"sweighted2"</code>.
</p>
<p>Espinheira et al. (2008) recommend to use <code>"sweighted2"</code>, hence this was 
the default prior to version 3.2-0. However, these are rather burdensome to
compute because they require operations of <code class="reqn">O(n^2)</code> and hence are typically
prohibitively costly in large sample. Also they are not available for
extended support beta regression. Finally, Pereira (2017) found quantile
residuals to have better distributional properties.
</p>


<h3>References</h3>

<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Dunn, P.K., and Smyth, G.K. (1996). Randomized Quantile Residuals.
<em>Journal of Computational and Graphical Statistics</em>, <b>5</b>(3), 236&ndash;244.
<a href="https://doi.org/10.2307/1390802">doi:10.2307/1390802</a>
</p>
<p>Espinheira, P.L., Ferrari, S.L.P., and Cribari-Neto, F. (2008).
On Beta Regression Residuals.
<em>Journal of Applied Statistics</em>, <b>35</b>(4), 407&ndash;419.
<a href="https://doi.org/10.1080/02664760701834931">doi:10.1080/02664760701834931</a>
</p>
<p>Ferrari, S.L.P., and Cribari-Neto, F. (2004).
Beta Regression for Modeling Rates and Proportions.
<em>Journal of Applied Statistics</em>, <b>31</b>(7), 799&ndash;815.
<a href="https://doi.org/10.1080/0266476042000214501">doi:10.1080/0266476042000214501</a>
</p>
<p>Pereira, G.H.A. (2017). On Quantile Residuals in Beta Regression.
<em>Communications in Statistics &ndash; Simulation and Computation</em>, <b>48</b>(1), 302&ndash;316.
<a href="https://doi.org/10.1080/03610918.2017.1381740">doi:10.1080/03610918.2017.1381740</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)

data("GasolineYield", package = "betareg")

gy &lt;- betareg(yield ~ gravity + pressure + temp10 + temp, data = GasolineYield)

gy_res &lt;- cbind(
  "quantile"   = residuals(gy, type = "quantile"),
  "pearson"    = residuals(gy, type = "pearson"),
  "deviance"   = residuals(gy, type = "deviance"),
  "response"   = residuals(gy, type = "response"),
  "weighted"   = residuals(gy, type = "weighted"),
  "sweighted"  = residuals(gy, type = "sweighted"),
  "sweighted2" = residuals(gy, type = "sweighted2")
)
pairs(gy_res)

cor(gy_res)
</code></pre>

<hr>
<h2 id='StressAnxiety'>Dependency of Anxiety on Stress</h2><span id='topic+StressAnxiety'></span>

<h3>Description</h3>

<p>Stress and anxiety among nonclinical women in Townsville, Queensland, Australia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("StressAnxiety", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame containing 166 observations on 2 variables.
</p>

<dl>
<dt>stress</dt><dd><p>score, linearly transformed to the open unit
interval (see below).</p>
</dd>
<dt>anxiety</dt><dd><p>score, linearly transformed to the open unit
interval (see below).</p>
</dd>
</dl>



<h3>Details</h3>

<p>Both variables were assess on the Depression Anxiety Stress Scales, ranging
from 0 to 42. Smithson and Verkuilen (2006) transformed these to the open
unit interval (without providing details about this transformation).
</p>


<h3>Source</h3>

<p>Example 2 from Smithson and Verkuilen (2006) supplements.
</p>


<h3>References</h3>

<p>Smithson, M., and Verkuilen, J. (2006).
A Better Lemon Squeezer? Maximum-Likelihood Regression with
Beta-Distributed Dependent Variables.
<em>Psychological Methods</em>, <b>11</b>(7), 54&ndash;71.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code>, <code><a href="#topic+MockJurors">MockJurors</a></code>, <code><a href="#topic+ReadingSkills">ReadingSkills</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("StressAnxiety", package = "betareg")
StressAnxiety &lt;- StressAnxiety[order(StressAnxiety$stress),]

## Smithson &amp; Verkuilen (2006, Table 4)
sa_null &lt;- betareg(anxiety ~ 1 | 1,
  data = StressAnxiety, hessian = TRUE)
sa_stress &lt;- betareg(anxiety ~ stress | stress,
  data = StressAnxiety, hessian = TRUE)
summary(sa_null)
summary(sa_stress)
AIC(sa_null, sa_stress)
1 - as.vector(logLik(sa_null)/logLik(sa_stress))

## visualization
attach(StressAnxiety)
plot(jitter(anxiety) ~ jitter(stress),
  xlab = "Stress", ylab = "Anxiety",
  xlim = c(0, 1), ylim = c(0, 1))
lines(lowess(anxiety ~ stress))
lines(fitted(sa_stress) ~ stress, lty = 2)
lines(fitted(lm(anxiety ~ stress)) ~ stress, lty = 3)
legend("topleft", c("lowess", "betareg", "lm"), lty = 1:3, bty = "n")
detach(StressAnxiety)

## see demo("SmithsonVerkuilen2006", package = "betareg") for more details
</code></pre>

<hr>
<h2 id='summary.betareg'>Methods for betareg Objects</h2><span id='topic+print.betareg'></span><span id='topic+summary.betareg'></span><span id='topic+print.summary.betareg'></span><span id='topic+coef.betareg'></span><span id='topic+vcov.betareg'></span><span id='topic+bread.betareg'></span><span id='topic+estfun.betareg'></span><span id='topic+coeftest.betareg'></span><span id='topic+logLik.betareg'></span><span id='topic+terms.betareg'></span><span id='topic+model.frame.betareg'></span><span id='topic+model.matrix.betareg'></span><span id='topic+cooks.distance.betareg'></span><span id='topic+hatvalues.betareg'></span>

<h3>Description</h3>

<p>Methods for extracting information from fitted beta
regression model objects of class <code>"betareg"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'betareg'
summary(object, phi = NULL, type = "quantile", ...)

## S3 method for class 'betareg'
coef(object, model = c("full", "mean", "precision"), phi = NULL, ...)
## S3 method for class 'betareg'
vcov(object, model = c("full", "mean", "precision"), phi = NULL, ...)
## S3 method for class 'betareg'
bread(x, phi = NULL, ...)
## S3 method for class 'betareg'
estfun(x, phi = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.betareg_+3A_object">object</code>, <code id="summary.betareg_+3A_x">x</code></td>
<td>
<p>fitted model object of class <code>"betareg"</code>.</p>
</td></tr>
<tr><td><code id="summary.betareg_+3A_phi">phi</code></td>
<td>
<p>logical indicating whether the parameters in the precision model
(for phi) should be reported as full model parameters (<code>TRUE</code>) or
nuisance parameters (<code>FALSE</code>). The default is taken from
<code>object$phi</code>.</p>
</td></tr>
<tr><td><code id="summary.betareg_+3A_type">type</code></td>
<td>
<p>character specifying type of residuals to be included in the
summary output, see <code><a href="#topic+residuals.betareg">residuals.betareg</a></code>.</p>
</td></tr>
<tr><td><code id="summary.betareg_+3A_model">model</code></td>
<td>
<p>character specifying for which component of the model coefficients/covariance
should be extracted. (Only used if <code>phi</code> is <code>NULL</code>.)</p>
</td></tr>
<tr><td><code id="summary.betareg_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A set of standard extractor functions for fitted model objects is available for
objects of class <code>"betareg"</code>, including methods to the generic functions
<code><a href="base.html#topic+print">print</a></code> and <code><a href="base.html#topic+summary">summary</a></code> which print the estimated
coefficients along with some further information. The <code>summary</code> in particular
supplies partial Wald tests based on the coefficients and the covariance matrix.
As usual, the <code>summary</code> method returns an object of class <code>"summary.betareg"</code>
containing the relevant summary statistics which can subsequently be printed
using the associated <code>print</code> method.
</p>
<p>A <code><a href="stats.html#topic+logLik">logLik</a></code> method is provided, hence <code><a href="stats.html#topic+AIC">AIC</a></code>
can be called to compute information criteria.
</p>


<h3>References</h3>

<p>Cribari-Neto, F., and Zeileis, A. (2010). Beta Regression in R.
<em>Journal of Statistical Software</em>, <b>34</b>(2), 1&ndash;24.
<a href="https://doi.org/10.18637/jss.v034.i02">doi:10.18637/jss.v034.i02</a>
</p>
<p>Ferrari, S.L.P., and Cribari-Neto, F. (2004).
Beta Regression for Modeling Rates and Proportions.
<em>Journal of Applied Statistics</em>, <b>31</b>(7), 799&ndash;815.
</p>
<p>Simas, A.B., and Barreto-Souza, W., and Rocha, A.V. (2010).
Improved Estimators for a General Class of Beta Regression Models.
<em>Computational Statistics &amp; Data Analysis</em>, <b>54</b>(2), 348&ndash;366.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+betareg">betareg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>options(digits = 4)

data("GasolineYield", package = "betareg")

gy2 &lt;- betareg(yield ~ batch + temp | temp, data = GasolineYield)

summary(gy2)
coef(gy2)
vcov(gy2)
logLik(gy2)
AIC(gy2)

coef(gy2, model = "mean")
coef(gy2, model = "precision")
summary(gy2, phi = FALSE)
</code></pre>

<hr>
<h2 id='WeatherTask'>
Weather Task With Priming and Precise and Imprecise Probabilities 
</h2><span id='topic+WeatherTask'></span>

<h3>Description</h3>

<p>In this study participants were asked to judge how likely Sunday is to
be the hottest day of the week.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("WeatherTask", package = "betareg")</code></pre>


<h3>Format</h3>

<p>A data frame with 345 observations on the following 3 variables.
</p>

<dl>
<dt><code>priming</code></dt><dd><p>a factor with levels <code>two-fold</code> (case
prime) and <code>seven-fold</code> (class prime).</p>
</dd>
<dt><code>eliciting</code></dt><dd><p>a factor with levels <code>precise</code> and
<code>imprecise</code> (lower and upper limit).</p>
</dd>
<dt><code>agreement</code></dt><dd><p>a numeric vector, probability indicated by
participants or the average between minimum and maximum
probability indicated.</p>
</dd>
</dl>



<h3>Details</h3>

<p>All participants in the study were either first- or second-year
undergraduate students in psychology, none of whom had a strong
background in probability or were familiar with imprecise probability
theories. 
</p>
<p>For <code>priming</code> the questions were:
</p>

<dl>
<dt>two-fold</dt><dd><p>[What is the probability that] the temperature at
Canberra airport on Sunday will be higher than every other day
next week?</p>
</dd>
<dt>seven-fold</dt><dd><p>[What is the probability that] the highest
temperature of the week at Canberra airport will occur on Sunday?</p>
</dd>
</dl>

<p>For <code>eliciting</code> the instructions were if
</p>

<dl>
<dt>precise</dt><dd><p>to assign a probability estimate,</p>
</dd>
<dt>imprecise</dt><dd><p>to assign a lower and upper probability estimate.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Taken from Smithson et al. (2011) supplements.
</p>


<h3>References</h3>

<p>Smithson, M., Merkle, E.C., and Verkuilen, J. (2011). Beta
Regression Finite Mixture Models of Polarization and Priming.
<em>Journal of Educational and Behavioral Statistics</em>, <b>36</b>(6), 804&ndash;831.
<a href="https://doi.org/10.3102/1076998610396893">doi:10.3102/1076998610396893</a>
</p>
<p>Smithson, M., and Segale, C. (2009). Partition Priming in Judgments of
Imprecise Probabilities. <em>Journal of Statistical Theory and
Practice</em>, <b>3</b>(1), 169&ndash;181.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("WeatherTask", package = "betareg")
library("flexmix")
wt_betamix &lt;- betamix(agreement ~ 1, data = WeatherTask, k = 2,
  extra_components = extraComponent(type = "betareg", coef =
    list(mean = 0, precision = 2)),
  FLXconcomitant = FLXPmultinom(~ priming + eliciting))
</code></pre>

<hr>
<h2 id='xbeta'>The Extended-Support Beta Distribution</h2><span id='topic+dxbeta'></span><span id='topic+pxbeta'></span><span id='topic+qxbeta'></span><span id='topic+rxbeta'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation
for the extended-support beta distribution (in regression parameterization)
on [0, 1].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dxbeta(x, mu, phi, nu = 0, log = FALSE)

pxbeta(q, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE)

qxbeta(p, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE)

rxbeta(n, mu, phi, nu = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xbeta_+3A_x">x</code>, <code id="xbeta_+3A_q">q</code></td>
<td>
<p>numeric. Vector of quantiles.</p>
</td></tr>
<tr><td><code id="xbeta_+3A_p">p</code></td>
<td>
<p>numeric. Vector of probabilities.</p>
</td></tr>
<tr><td><code id="xbeta_+3A_n">n</code></td>
<td>
<p>numeric. Number of observations. If <code>length(n) &gt; 1</code>, the length is
taken to be the number required.</p>
</td></tr>
<tr><td><code id="xbeta_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the underlying beta distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="xbeta_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the underlying beta
distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="xbeta_+3A_nu">nu</code></td>
<td>
<p>numeric. Exceedence parameter for the support of the underlying
beta distribution on [-nu, 1 + nu] that is censored to [0, 1].</p>
</td></tr>
<tr><td><code id="xbeta_+3A_log">log</code>, <code id="xbeta_+3A_log.p">log.p</code></td>
<td>
<p>logical. If TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="xbeta_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical. If TRUE (default), probabilities are P[X &lt;= x]
otherwise, P[X &gt; x].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to obtain an extended-support beta distribution on [0, 1]
an additional exceedence parameter <code>nu</code> is introduced. If <code>nu &gt; 0</code>,
this scales the underlying beta distribution to the interval [-nu, 1 + nu]
where the tails are subsequently censored to the unit interval [0, 1] with
point masses on the boundaries 0 and 1. Thus, <code>nu</code> controls how likely
boundary observations are and for <code>nu = 0</code> (the default), the distribution
reduces to the classic beta distribution (in regression parameterization)
without boundary observations.
</p>


<h3>Value</h3>

<p><code>dxbeta</code> gives the density, <code>pxbeta</code> gives the distribution
function, <code>qxbeta</code> gives the quantile function, and <code>rxbeta</code>
generates random deviates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbetar">dbetar</a></code>, <code><a href="#topic+XBeta">XBeta</a></code></p>

<hr>
<h2 id='XBeta'>Create an Extended-Support Beta Distribution</h2><span id='topic+XBeta'></span><span id='topic+mean.XBeta'></span><span id='topic+variance.XBeta'></span><span id='topic+skewness.XBeta'></span><span id='topic+kurtosis.XBeta'></span><span id='topic+pdf.XBeta'></span><span id='topic+log_pdf.XBeta'></span><span id='topic+cdf.XBeta'></span><span id='topic+quantile.XBeta'></span><span id='topic+random.XBeta'></span><span id='topic+support.XBeta'></span><span id='topic+is_discrete.XBeta'></span><span id='topic+is_continuous.XBeta'></span>

<h3>Description</h3>

<p>Class and methods for extended-support beta distributions
using the workflow from the <span class="pkg">distributions3</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XBeta(mu, phi, nu = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XBeta_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the underlying beta distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="XBeta_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the underlying beta
distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="XBeta_+3A_nu">nu</code></td>
<td>
<p>numeric. Exceedence parameter for the support of the underlying
beta distribution on [-nu, 1 + nu] that is censored to [0, 1].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to obtain an extended-support beta distribution on [0, 1]
an additional exceedence parameter <code>nu</code> is introduced. If <code>nu &gt; 0</code>,
this scales the underlying beta distribution to the interval [-nu, 1 + nu]
where the tails are subsequently censored to the unit interval [0, 1] with
point masses on the boundaries 0 and 1. Thus, <code>nu</code> controls how likely
boundary observations are and for <code>nu = 0</code> (the default), the distribution
reduces to the classic beta distribution (in regression parameterization)
without boundary observations.
</p>


<h3>Value</h3>

<p>A <code>XBeta</code> distribution object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dxbeta">dxbeta</a></code>, <code><a href="#topic+BetaR">BetaR</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## package and random seed
library("distributions3")
set.seed(6020)

## three beta distributions
X &lt;- XBeta(
  mu  = c(0.25, 0.50, 0.75),
  phi = c(1, 1, 2),
  nu = c(0, 0.1, 0.2)
)

X

## compute moments of the distribution
mean(X)
variance(X)

## support interval (minimum and maximum)
support(X)

## it is only continuous when there are no point masses on the boundary
is_continuous(X)
cdf(X, 0)
cdf(X, 1, lower.tail = FALSE)

## simulate random variables
random(X, 5)

## histograms of 1,000 simulated observations
x &lt;- random(X, 1000)
hist(x[1, ])
hist(x[2, ])
hist(x[3, ])

## probability density function (PDF) and log-density (or log-likelihood)
x &lt;- c(0.25, 0.5, 0.75)
pdf(X, x)
pdf(X, x, log = TRUE)
log_pdf(X, x)

## cumulative distribution function (CDF)
cdf(X, x)

## quantiles
quantile(X, 0.5)

## cdf() and quantile() are inverses (except at censoring points)
cdf(X, quantile(X, 0.5))
quantile(X, cdf(X, 1))

## all methods above can either be applied elementwise or for
## all combinations of X and x, if length(X) = length(x),
## also the result can be assured to be a matrix via drop = FALSE
p &lt;- c(0.05, 0.5, 0.95)
quantile(X, p, elementwise = FALSE)
quantile(X, p, elementwise = TRUE)
quantile(X, p, elementwise = TRUE, drop = FALSE)

## compare theoretical and empirical mean from 1,000 simulated observations
cbind(
  "theoretical" = mean(X),
  "empirical" = rowMeans(random(X, 1000))
)

</code></pre>

<hr>
<h2 id='xbetax'>The Extended-Support Beta Mixture Distribution</h2><span id='topic+dxbetax'></span><span id='topic+pxbetax'></span><span id='topic+qxbetax'></span><span id='topic+rxbetax'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation
for the extended-support beta mixture distribution (in regression parameterization)
on [0, 1].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dxbetax(x, mu, phi, nu = 0, log = FALSE, quad = 20)

pxbetax(q, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE, quad = 20)

qxbetax(p, mu, phi, nu = 0, lower.tail = TRUE, log.p = FALSE, quad = 20,
  tol = .Machine$double.eps^0.7)

rxbetax(n, mu, phi, nu = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xbetax_+3A_x">x</code>, <code id="xbetax_+3A_q">q</code></td>
<td>
<p>numeric. Vector of quantiles.</p>
</td></tr>
<tr><td><code id="xbetax_+3A_p">p</code></td>
<td>
<p>numeric. Vector of probabilities.</p>
</td></tr>
<tr><td><code id="xbetax_+3A_n">n</code></td>
<td>
<p>numeric. Number of observations. If <code>length(n) &gt; 1</code>, the length is
taken to be the number required.</p>
</td></tr>
<tr><td><code id="xbetax_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the underlying beta distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="xbetax_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the underlying beta
distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="xbetax_+3A_nu">nu</code></td>
<td>
<p>numeric. Mean of the exponentially-distributed exceedence parameter
for the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].</p>
</td></tr>
<tr><td><code id="xbetax_+3A_log">log</code>, <code id="xbetax_+3A_log.p">log.p</code></td>
<td>
<p>logical. If TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="xbetax_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical. If TRUE (default), probabilities are P[X &lt;= x]
otherwise, P[X &gt; x].</p>
</td></tr>
<tr><td><code id="xbetax_+3A_quad">quad</code></td>
<td>
<p>numeric. The number of quadrature points for numeric
integration of the continuous mixture. Alternatively, a matrix with nodes
and weights for the quadrature points can be specified.</p>
</td></tr>
<tr><td><code id="xbetax_+3A_tol">tol</code></td>
<td>
<p>numeric. Accuracy (convergence tolerance) for numerically
determining quantiles based on <code><a href="stats.html#topic+uniroot">uniroot</a></code> and <code>pxbetax</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extended-support beta mixture distribution is a continuous mixture of
extended-support beta distributions on [0, 1] where the underlying exceedence
parameter is exponentially distributed with mean <code>nu</code>. Thus, if <code>nu &gt; 0</code>,
the resulting distribution has point masses on the boundaries 0 and 1 with larger
values of <code>nu</code> leading to higher boundary probabilities. For <code>nu = 0</code>
(the default), the distribution reduces to the classic beta distribution (in
regression parameterization) without boundary observations.
</p>


<h3>Value</h3>

<p><code>dxbetax</code> gives the density, <code>pxbetax</code> gives the distribution
function, <code>qxbetax</code> gives the quantile function, and <code>rxbetax</code>
generates random deviates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dxbeta">dxbeta</a></code>, <code><a href="#topic+XBetaX">XBetaX</a></code></p>

<hr>
<h2 id='XBetaX'>Create an Extended-Support Beta Mixture Distribution</h2><span id='topic+XBetaX'></span><span id='topic+mean.XBetaX'></span><span id='topic+variance.XBetaX'></span><span id='topic+skewness.XBetaX'></span><span id='topic+kurtosis.XBetaX'></span><span id='topic+pdf.XBetaX'></span><span id='topic+log_pdf.XBetaX'></span><span id='topic+cdf.XBetaX'></span><span id='topic+quantile.XBetaX'></span><span id='topic+random.XBetaX'></span><span id='topic+support.XBetaX'></span><span id='topic+is_discrete.XBetaX'></span><span id='topic+is_continuous.XBetaX'></span>

<h3>Description</h3>

<p>Class and methods for extended-support beta distributions
using the workflow from the <span class="pkg">distributions3</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XBetaX(mu, phi, nu = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XBetaX_+3A_mu">mu</code></td>
<td>
<p>numeric. The mean of the underlying beta distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="XBetaX_+3A_phi">phi</code></td>
<td>
<p>numeric. The precision parameter of the underlying beta
distribution on [-nu, 1 + nu].</p>
</td></tr>
<tr><td><code id="XBetaX_+3A_nu">nu</code></td>
<td>
<p>numeric. Mean of the exponentially-distributed exceedence parameter
for the underlying beta distribution on [-nu, 1 + nu] that is censored to [0, 1].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extended-support beta mixture distribution is a continuous mixture of
extended-support beta distributions on [0, 1] where the underlying exceedence
parameter is exponentially distributed with mean <code>nu</code>. Thus, if <code>nu &gt; 0</code>,
the resulting distribution has point masses on the boundaries 0 and 1 with larger
values of <code>nu</code> leading to higher boundary probabilities. For <code>nu = 0</code>
(the default), the distribution reduces to the classic beta distribution (in
regression parameterization) without boundary observations.
</p>


<h3>Value</h3>

<p>A <code>XBetaX</code> distribution object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dxbetax">dxbetax</a></code>, <code><a href="#topic+XBeta">XBeta</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## package and random seed
library("distributions3")
set.seed(6020)

## three beta distributions
X &lt;- XBetaX(
  mu  = c(0.25, 0.50, 0.75),
  phi = c(1, 1, 2),
  nu = c(0, 0.1, 0.2)
)

X

## compute moments of the distribution
mean(X)
variance(X)

## support interval (minimum and maximum)
support(X)

## it is only continuous when there are no point masses on the boundary
is_continuous(X)
cdf(X, 0)
cdf(X, 1, lower.tail = FALSE)

## simulate random variables
random(X, 5)

## histograms of 1,000 simulated observations
x &lt;- random(X, 1000)
hist(x[1, ])
hist(x[2, ])
hist(x[3, ])

## probability density function (PDF) and log-density (or log-likelihood)
x &lt;- c(0.25, 0.5, 0.75)
pdf(X, x)
pdf(X, x, log = TRUE)
log_pdf(X, x)

## cumulative distribution function (CDF)
cdf(X, x)

## quantiles
quantile(X, 0.5)

## cdf() and quantile() are inverses (except at censoring points)
cdf(X, quantile(X, 0.5))
quantile(X, cdf(X, 1))

## all methods above can either be applied elementwise or for
## all combinations of X and x, if length(X) = length(x),
## also the result can be assured to be a matrix via drop = FALSE
p &lt;- c(0.05, 0.5, 0.95)
quantile(X, p, elementwise = FALSE)
quantile(X, p, elementwise = TRUE)
quantile(X, p, elementwise = TRUE, drop = FALSE)

## compare theoretical and empirical mean from 1,000 simulated observations
cbind(
  "theoretical" = mean(X),
  "empirical" = rowMeans(random(X, 1000))
)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
