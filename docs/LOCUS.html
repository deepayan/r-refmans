<!DOCTYPE html><html lang="en"><head><title>Help for package LOCUS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LOCUS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#LOCUS'>
<p>LOCUS: Low-rank decomposition of brain connectivity matrices with uniform sparsity</p></a></li>
<li><a href='#LOCUS_BIC_selection'>
<p>BIC-based Hyper-parameters selection for LOCUS</p></a></li>
<li><a href='#Ltrans'>
<p>Map a symmetric matrix into its upper triangle part.</p></a></li>
<li><a href='#Ltrinv'>
<p>Inverse function of <code>Ltrans</code> to map back a vector into a symmetric matrix.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Low-Rank Decomposition of Brain Connectivity Matrices with
Uniform Sparsity</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-08-28</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jialu Ran &lt;jialuran422@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), ica, MASS, far</td>
</tr>
<tr>
<td>Description:</td>
<td>To decompose symmetric matrices such as brain connectivity matrices so that one can extract sparse latent component matrices and also estimate mixing coefficients, a blind source separation (BSS) method named LOCUS was proposed in Wang and Guo (2023) &lt;<a href="https://doi.org/10.48550/arXiv.2008.08915">doi:10.48550/arXiv.2008.08915</a>&gt;. For brain connectivity matrices, the outputs correspond to sparse latent connectivity traits and individual-level trait loadings. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-15 14:18:07 UTC; scarlett</td>
</tr>
<tr>
<td>Author:</td>
<td>Yikai Wang [aut, cph],
  Jialu Ran [aut, cre],
  Ying Guo [aut, ths]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-04 07:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='LOCUS'>
LOCUS: Low-rank decomposition of brain connectivity matrices with uniform sparsity
</h2><span id='topic+LOCUS'></span>

<h3>Description</h3>

<p>This is the main function in the package. It conducts the LOCUS approach for decomposing brain connectivity data into subnetworks. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LOCUS(Y, q, V, MaxIteration=100, penalty="SCAD", phi = 0.9, approximation=TRUE, 
preprocess=TRUE, espli1=0.001, espli2=0.001, rho=0.95, silent=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LOCUS_+3A_y">Y</code></td>
<td>
<p>Group-level connectivity data from N subjects, which is of dimension N x p, where p is number of edges. Each row of Y represents a subject's vectorized connectivity matrix by <code>Ltrans</code> function.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_q">q</code></td>
<td>
<p>Number of ICs/subnetworks to extract.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_v">V</code></td>
<td>
<p>Number of nodes in the network. Note: p should be equal to V(V-1)/2. </p>
</td></tr>
<tr><td><code id="LOCUS_+3A_maxiteration">MaxIteration</code></td>
<td>
<p>Maximum number of iteractions.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_penalty">penalty</code></td>
<td>
<p>The penalization approach for uniform sparsity, which can be <code>NULL</code>, <code>SCAD</code>, and <code>L1</code>.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_phi">phi</code></td>
<td>
<p><code class="reqn">\phi</code>: tuning parameter for uniform sparse penalty.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_approximation">approximation</code></td>
<td>
<p>Whether to use an approximated algorithm to speed up the algorithm.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_preprocess">preprocess</code></td>
<td>
<p>Whether to preprocess the data, which reduces the data dimension to <code>q</code> and whiten the data.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_espli1">espli1</code></td>
<td>
<p>Toleration for convergence on mixing coefficient matrix, i.e. A.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_espli2">espli2</code></td>
<td>
<p>Toleration for convergence on latent sources, i.e. S.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_rho">rho</code></td>
<td>
<p><code class="reqn">\rho</code>: tuning parameter for selecting number of ranks in each subnetwork's decomposition.</p>
</td></tr>
<tr><td><code id="LOCUS_+3A_silent">silent</code></td>
<td>
<p>Whether to print intermediate steps.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the main function for LOCUS decomposition of brain connectivity matrices, which is to minimize the following objective function:
</p>
<p style="text-align: center;"><code class="reqn">\sum_{i=1}^N\|y_i - \sum_{l=1}^q a_{il} s_l\|_2^2 + \phi \sum_{l=1}^q\|s_l\|_*,</code>
</p>

<p>where <code class="reqn">y_i</code> is the transpose of <code class="reqn">i</code>th row in <code class="reqn">Y</code>, <code class="reqn">s_l = L(X_l D_l X_l')</code> represents the <code class="reqn">l</code>th vectorized latent source/subnetwork with low-rank decomposition, <code class="reqn">L</code> is <code>Ltrans</code> function, <code class="reqn">\|\cdot\|_*</code> represents the penalty which can either be NULL, L1, or SCAD (Fan &amp; Li, 2001).
</p>
<p>If user want to do BIC parameter selection of <code class="reqn">\phi, \rho</code> before calling LOCUS main function, one can use <code>LOCUS_BIC_selection</code> to find the best parameter set. Further details can be found in the LOCUS paper.  
</p>


<h3>Value</h3>

<p>An R list from Locus containing the following terms:
</p>
<table role = "presentation">
<tr><td><code>Conver</code></td>
<td>
<p>Whether the algorithm is converaged.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Mixing matrix <code class="reqn">\{a_{il}\}</code> of dimension N by q.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>Subnetworks of dimension q by p, where each row represents a vectorized subnetwork based on <code>Ltrans</code> function.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>A list of length q, where <code>theta[[i]]</code> contains the symmetric low-rank decomposition of <code>i</code>th subnetwork. </p>
</td></tr>
</table>


<h3>References</h3>

<p>Wang, Y. and Guo, Y. (2023). <em>LOCUS: A novel signal decomposition method for brain network connectivity matrices using low-rank structure with uniform sparsity.</em> Annals of Applied Statistics.
</p>
<p>Fan, J., &amp; Li, R. (2001).  <em>Variable selection via nonconcave penalized likelihood and its oracle properties.</em> Journal of the American statistical Association, 96(456), 1348-1360.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulated the data to use. 
V = 50
S1 = S2 = S3 = matrix(0,ncol = V,nrow = V)
S1[5:20,5:20] = 4;S1[23:37,23:37] = 3;S1[40:48,40:48] = 3
S2[15:20,] = -3;S2[,15:20] = -3
S3[15:25,36:45] = 3; S3[36:45,15:25] = 3
Struth = rbind(Ltrans(S1,FALSE) , Ltrans(S2,FALSE), Ltrans(S3,FALSE))
set.seed(100)
Atruth = matrix(rnorm(100*3),nrow=100,ncol=3)
Residual = matrix(rnorm(100*dim(Struth)[2]),nrow=100)
Yraw = Atruth%*%Struth + Residual

##### Run Locus on the data ##### 
Locus_result = LOCUS(Yraw,3,V)

oldpar = par(mfrow=c(2,3))
for(i in 1:dim(Struth)[1]){image(Ltrinv(Struth[i,],V,FALSE))}
for(i in 1:dim(Locus_result$S)[1]){image(Ltrinv(Locus_result$S[i,],V,FALSE))}
par(oldpar)
</code></pre>

<hr>
<h2 id='LOCUS_BIC_selection'>
BIC-based Hyper-parameters selection for LOCUS</h2><span id='topic+LOCUS_BIC_selection'></span>

<h3>Description</h3>

<p>This function is to conduct the BIC-based hyper-parameters selection for LOCUS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LOCUS_BIC_selection(Y, q, V, MaxIteration=50, penalty="SCAD", 
phi_grid_search=seq(0.2, 1, 0.2), rho_grid_search=c(0.95), 
espli1=0.001, espli2=0.001, save_LOCUS_output=TRUE, 
preprocess=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LOCUS_BIC_selection_+3A_y">Y</code></td>
<td>
<p>Group-level connectivity data from N subjects, which is of dimension N x p, where p is number of edges. Each row of Y represents a subject's vectorized connectivity matrix by <code>Ltrans</code> function. </p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_q">q</code></td>
<td>
<p>Number of ICs/subnetworks to extract.</p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_v">V</code></td>
<td>
<p>Number of nodes in the network. Note: p should be equal to V(V-1)/2. </p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_maxiteration">MaxIteration</code></td>
<td>
<p>Maximum number of iteractions.</p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_penalty">penalty</code></td>
<td>
<p>The penalization approach for uniform sparsity, which can be <code>NULL</code>, <code>SCAD</code>, <code>L1</code>, <code>Hardthreshold</code>. </p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_phi_grid_search">phi_grid_search</code></td>
<td>
<p>Grid search candidates for tuning parameter of uniform sparse penalty.</p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_espli1">espli1</code></td>
<td>
<p>Toleration for convergence on mixing coefficient matrix, i.e. A.</p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_espli2">espli2</code></td>
<td>
<p>Toleration for convergence on latent sources, i.e. S.</p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_rho_grid_search">rho_grid_search</code></td>
<td>
<p>Grid search candidates for tuning parameter for selecting number of ranks in each subnetwork's decomposition. </p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_save_locus_output">save_LOCUS_output</code></td>
<td>
<p>Whether to save LOCUS output from each grid search.</p>
</td></tr>
<tr><td><code id="LOCUS_BIC_selection_+3A_preprocess">preprocess</code></td>
<td>
<p>Whether to preprocess the data, which reduces the data dimension to <code>q</code> and whiten the data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Wang, Y. and Guo, Y. (2023), the tuning parameters for learning the LOCUS model include <code class="reqn">\phi, \rho</code>. The BIC-type criterion is proposed to select those parameters. 
</p>
<p style="text-align: center;"><code class="reqn">BIC =  -2 \sum_{i=1}^N log \{g(y_i; \sum_{l=1}^{q} \hat{a}_{il} \hat{s}_l, \hat{\sigma}^2 I_p)\} + log(N) \sum_{l=1}^{q}\|\hat{s}_l\|_0</code>
</p>

<p>where <code class="reqn">g</code> denotes the pdf of a multivariate Gaussian distribution, <code class="reqn">\hat{\sigma}^2 = \frac{1}{Np}\sum_i \|y_i-\sum_{l=1}^{q}\hat{a}_{il}\hat{s}_{l}\|_2^2</code>, <code class="reqn">\|\cdot\|_0</code> denotes the <code class="reqn">L_0</code> norm . This criterion balances between model fitting and model sparsity. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>bic_tab</code></td>
<td>
<p>BIC values per phi and rho.</p>
</td></tr>
<tr><td><code>LOCUS_results</code></td>
<td>
<p>LOCUS output, if save_LOCUS_output is TRUE. </p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulated the data to use. 
V = 50
S1 = S2 = S3 = matrix(0,ncol = V,nrow = V)
S1[5:20,5:20] = 4;S1[23:37,23:37] = 3;S1[40:48,40:48] = 3
S2[15:20,] = -3;S2[,15:20] = -3
S3[15:25,36:45] = 3; S3[36:45,15:25] = 3
Struth = rbind(Ltrans(S1,FALSE) , Ltrans(S2,FALSE), Ltrans(S3,FALSE))
set.seed(100)
Atruth = matrix(rnorm(100*3),nrow=100,ncol=3)
Residual = matrix(rnorm(100*dim(Struth)[2]),nrow=100)
Yraw = Atruth%*%Struth + Residual

##### Run Locus on the data ##### 
Locus_bic_result = LOCUS_BIC_selection(Yraw,3,V)
print(Locus_bic_result$bic_tab)
# line plot
plot(Locus_bic_result$bic_tab[,2], Locus_bic_result$bic_tab[,3], type = "b",
     xlab = "phi", ylab = "BIC")
     
# visualize the best result based on BIC
idx = which.min(Locus_bic_result$bic_tab[,3])
oldpar = par(mfrow=c(2,3))
for(i in 1:3){image(Ltrinv(Struth[i,], V, FALSE))}
for(i in 1:3){image(Ltrinv(Locus_bic_result$LOCUS_results[[idx]]$LOCUS$S[i,], 
V, FALSE))}
par(oldpar)
</code></pre>

<hr>
<h2 id='Ltrans'>
Map a symmetric matrix into its upper triangle part. </h2><span id='topic+Ltrans'></span>

<h3>Description</h3>

<p>This function is to map the upper triganle part of a symmetric matrix into a vector. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ltrans(X, d = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ltrans_+3A_x">X</code></td>
<td>
<p>A symmetric matrix of dimentional V by V. </p>
</td></tr>
<tr><td><code id="Ltrans_+3A_d">d</code></td>
<td>
<p>Whether to include the diagonal part of <code>X</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the upper triganle part of <code>X</code>. 
</p>

<hr>
<h2 id='Ltrinv'>
Inverse function of <code>Ltrans</code> to map back a vector into a symmetric matrix. </h2><span id='topic+Ltrinv'></span>

<h3>Description</h3>

<p>This function is the inverse function of <code>Ltrans</code>, which is to map a vector back to a symmetric matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ltrinv(x, V, d = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Ltrinv_+3A_x">x</code></td>
<td>
<p>A vector to convert to a matrix, which is of length p. </p>
</td></tr>
<tr><td><code id="Ltrinv_+3A_v">V</code></td>
<td>
<p>Dimension of the matrix which <code>x</code> is converted to. </p>
</td></tr>
<tr><td><code id="Ltrinv_+3A_d">d</code></td>
<td>
<p>Whether diagonal is kept in <code>x</code> or not. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A symmetric matrix whose upper triangle part is <code>x</code>. 
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
