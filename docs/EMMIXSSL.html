<!DOCTYPE html><html><head><title>Help for package EMMIXSSL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EMMIXSSL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Classifier_Bayes'><p>Classifier based on Bayes rule</p></a></li>
<li><a href='#cov2vec'><p>Transform a variance matrix into a vector</p></a></li>
<li><a href='#discriminant_beta'><p>Discriminant function</p></a></li>
<li><a href='#EMMIXSSL'><p>Fitting Gaussian mixture models</p></a></li>
<li><a href='#errorrate'><p>Error rate of the Bayes rule for two-class Gaussian homoscedastic model</p></a></li>
<li><a href='#gastro_label_binary'><p>Gastrointestinal binary labels</p></a></li>
<li><a href='#gastro_label_trinary'><p>Gastrointestinal trinary labels</p></a></li>
<li><a href='#gastrodata'><p>Gastrointestinal dataset</p></a></li>
<li><a href='#get_clusterprobs'><p>Posterior probability</p></a></li>
<li><a href='#get_entropy'><p>Shannon entropy</p></a></li>
<li><a href='#initialvalue'><p>Initial values for ECM</p></a></li>
<li><a href='#list2par'><p>Transfer a list into a vector</p></a></li>
<li><a href='#loglk_full'><p>Full log-likelihood function</p></a></li>
<li><a href='#loglk_ig'><p>Log likelihood for partially classified data with ingoring the missing mechanism</p></a></li>
<li><a href='#loglk_miss'><p>Log likelihood function formed on the basis of the missing-label indicator</p></a></li>
<li><a href='#logsumexp'><p>log summation of exponential function</p></a></li>
<li><a href='#makelabelmatrix'><p>Label matrix</p></a></li>
<li><a href='#neg_objective_function'><p>Negative objective function for EMMIXSSL</p></a></li>
<li><a href='#normalise_logprob'><p>Normalize log-probability</p></a></li>
<li><a href='#par2list'><p>Transfer a vector into a list</p></a></li>
<li><a href='#pro2vec'><p>Transfer a probability vector into a vector</p></a></li>
<li><a href='#rlabel'><p>Generation of a missing-data indicator</p></a></li>
<li><a href='#rmix'><p>Normal mixture model generator.</p></a></li>
<li><a href='#vec2cov'><p>Transform a vector into a matrix</p></a></li>
<li><a href='#vec2pro'><p>Transfer an informative vector to a probability vector</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Semi-Supervised Gaussian Mixture Model with a Missing-Data
Mechanism</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Ziyang Lyu, Daniel Ahfock, Geoffrey J. McLachlan</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ziyang Lyu &lt;ziyang.lyu@unsw.edu.au&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The algorithm of semi-supervised learning based on finite Gaussian mixture models with a missing-data mechanism is designed for a fitting g-class Gaussian mixture model via maximum likelihood (ML). It is proposed to treat the labels of the unclassified features as missing-data and to introduce a framework for their missing as in the pioneering work of Rubin (1976) for missing in incomplete data analysis. This dependency in the missingness pattern can be leveraged to provide additional information about the optimal classifier as specified by Bayesâ€™ rule. </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0), mvtnorm,stats</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-18 09:32:54 UTC; lyu</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-18 12:17:58 UTC</td>
</tr>
</table>
<hr>
<h2 id='Classifier_Bayes'>Classifier based on Bayes rule</h2><span id='topic+Classifier_Bayes'></span>

<h3>Description</h3>

<p>A classifier based on Bayes rule, that is maximum a posterior probabilities of class membership
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Classifier_Bayes(dat, n, p, g, pi, mu, sigma, ncov = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Classifier_Bayes_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="Classifier_Bayes_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="Classifier_Bayes_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="Classifier_Bayes_+3A_g">g</code></td>
<td>
<p>Number of classes.</p>
</td></tr>
<tr><td><code id="Classifier_Bayes_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="Classifier_Bayes_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="Classifier_Bayes_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="Classifier_Bayes_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The posterior probability can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
\tau_i(y_j;\theta)=Prob\{z_{ij}=1|y_j\}=\frac{\pi_i\phi(y_j;\mu_i,\Sigma_i)}{\sum_{h=1}^g\pi_h\phi(y_j;\mu_h,\Sigma_h) },
</code>
</p>

<p>where <code class="reqn">\phi</code> is a normal probability function with mean <code class="reqn">\mu_i</code> and covariance matrix <code class="reqn">\Sigma_i</code>,
and <code class="reqn">z_{ij}</code> is is a zero-one indicator variable denoting the class of origin.
The Bayes' Classifier of allocation assigns an entity with feature vector <code class="reqn">y_j</code> to Class <code class="reqn">C_k</code> if
</p>
<p style="text-align: center;"><code class="reqn">
k= arg max_i \tau_i(y_j;\theta).
</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>cluster</code></td>
<td>
<p>A vector of the class membership.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma,ncov=2)
cluster&lt;-Classifier_Bayes(dat=dat$Y,n=150,p=3,g=4,mu=mu,sigma=sigma,pi=pi,ncov=2)
</code></pre>

<hr>
<h2 id='cov2vec'>Transform a variance matrix into a vector</h2><span id='topic+cov2vec'></span>

<h3>Description</h3>

<p>Transform a variance matrix into a vector i.e., Sigma=R^T*R
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov2vec(sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cov2vec_+3A_sigma">sigma</code></td>
<td>
<p>A variance matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance matrix is decomposed by computing the Choleski factorization of a real symmetric positive-definite square matrix.
Then, storing the upper triangular factor of the Choleski decomposition into a vector.
</p>


<h3>Value</h3>

<p>par A vector representing a variance matrix
</p>

<hr>
<h2 id='discriminant_beta'>Discriminant function</h2><span id='topic+discriminant_beta'></span>

<h3>Description</h3>

<p>Discriminant function in the particular case of g=2 classes with an equal-covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discriminant_beta(pi, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discriminant_beta_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="discriminant_beta_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="discriminant_beta_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Discriminant function in the particular case of g=2 classes with an equal-covariance matrix can be expressed
</p>
<p style="text-align: center;"><code class="reqn">d(y_i,\beta)=\beta_0+\beta_1 y_i,</code>
</p>

<p>where <code class="reqn">\beta_0=\log\frac{\pi_1}{\pi_2}-\frac{1}{2}\frac{\mu_1^2-\mu_2^2}{\sigma^2}</code> and <code class="reqn">\beta_1=\frac{\mu_1-\mu_2}{\sigma^2}</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>beta0</code></td>
<td>
<p>An intercept of discriminant function</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A coefficient of discriminant function</p>
</td></tr>
</table>

<hr>
<h2 id='EMMIXSSL'>Fitting Gaussian mixture models</h2><span id='topic+EMMIXSSL'></span>

<h3>Description</h3>

<p>Fitting Gaussian mixture model to a complete classified dataset or a incomplete classified dataset with/without the missing-data mechanism.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMMIXSSL(
  dat,
  zm,
  pi,
  mu,
  sigma,
  ncov,
  xi = NULL,
  type,
  iter.max = 500,
  eval.max = 500,
  rel.tol = 1e-06,
  sing.tol = 1e-20
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EMMIXSSL_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_type">type</code></td>
<td>
<p>Three types of Gaussian mixture models, 'ign' indicates fitting the model to a partially classified sample on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates fitting the model to a partially classified sample on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate fitting the model to a completed classified sample.</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_iter.max">iter.max</code></td>
<td>
<p>Maximum number of iterations allowed. Defaults to 500</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_eval.max">eval.max</code></td>
<td>
<p>Maximum number of evaluations of the objective function allowed. Defaults to 500</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_rel.tol">rel.tol</code></td>
<td>
<p>Relative tolerance. Defaults to 1e-15</p>
</td></tr>
<tr><td><code id="EMMIXSSL_+3A_sing.tol">sing.tol</code></td>
<td>
<p>Singular convergence tolerance; defaults to 1e-20.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>objective</code></td>
<td>
<p>Value of objective likelihood</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Value of convergence</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>
<p>Number of iteration</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>Estimated vector of the mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>Estimated matrix of the location parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>Estimated covariance matrix</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>
<p>Estimated  coefficient vector for a logistic function of the Shannon entropy</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma,ncov=2)
xi&lt;-c(-0.5,1)
m&lt;-rlabel(dat=dat$Y,pi=pi,mu=mu,sigma=sigma,xi=xi,ncov=2)
zm&lt;-dat$clust
zm[m==1]&lt;-NA
inits&lt;-initialvalue(g=4,zm=zm,dat=dat$Y,ncov=2)
## Not run: 
fit_pc&lt;-EMMIXSSL(dat=dat$Y,zm=zm,pi=inits$pi,mu=inits$mu,sigma=inits$sigma,xi=xi,type='full',ncov=2)

## End(Not run)

</code></pre>

<hr>
<h2 id='errorrate'>Error rate of the Bayes rule for two-class Gaussian homoscedastic model</h2><span id='topic+errorrate'></span>

<h3>Description</h3>

<p>The optimal error rate of Bayes rule for two-class Gaussian homoscedastic model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorrate(beta0, beta, pi, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="errorrate_+3A_beta0">beta0</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="errorrate_+3A_beta">beta</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="errorrate_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="errorrate_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="errorrate_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimal error rate of Bayes rule for two-class Gaussian homoscedastic model can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
err(y_j;\theta)=\pi_1\phi\{-\frac{\beta_0+\beta_1^T\mu_1}{(\beta_1^T\Sigma\beta_1)^{\frac{1}{2}}}\}+\pi_2\phi\{\frac{\beta_0+\beta_1^T\mu_2}{(\beta_1^T\Sigma\beta_1)^{\frac{1}{2}}}\}
</code>
</p>

<p>where <code class="reqn">\phi</code> is a normal probability function with mean <code class="reqn">\mu_i</code> and covariance matrix <code class="reqn">\Sigma_i</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>errval</code></td>
<td>
<p>A vector of error rate.</p>
</td></tr>
</table>

<hr>
<h2 id='gastro_label_binary'>Gastrointestinal binary labels</h2><span id='topic+gastro_label_binary'></span>

<h3>Description</h3>

<p>A panel of seven endoscopists viewed the videos and determined which patient needs resection (malignant) or no-resection  (benign).
</p>


<h3>References</h3>

<p><a href="http://www.depeca.uah.es/colonoscopy_dataset/">http://www.depeca.uah.es/colonoscopy_dataset/</a>
</p>

<hr>
<h2 id='gastro_label_trinary'>Gastrointestinal trinary labels</h2><span id='topic+gastro_label_trinary'></span>

<h3>Description</h3>

<p>Gastrointestinal trinary ground truth (Adenoma,  Serrated, and Hyperplastic)
</p>


<h3>References</h3>

<p><a href="http://www.depeca.uah.es/colonoscopy_dataset/">http://www.depeca.uah.es/colonoscopy_dataset/</a>
</p>

<hr>
<h2 id='gastrodata'>Gastrointestinal dataset</h2><span id='topic+gastrodata'></span>

<h3>Description</h3>

<p>The collected dataset is composed of 76 colonoscopic videos (recorded with both White Light (WL) and Narrow Band Imaging (NBI)), the histology (classification ground truth), and  the endoscopist's opinion (including 4 experts and 3 beginners). There are $n=76$ observations, and each observation consists of 698 features extracted from colonoscopic videos on patients with gastrointestinal lesions.
</p>


<h3>References</h3>

<p><a href="http://www.depeca.uah.es/colonoscopy_dataset/">http://www.depeca.uah.es/colonoscopy_dataset/</a>
</p>

<hr>
<h2 id='get_clusterprobs'>Posterior probability</h2><span id='topic+get_clusterprobs'></span>

<h3>Description</h3>

<p>Get posterior probabilities of class membership
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_clusterprobs(dat, n, p, g, pi, mu, sigma, ncov = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_clusterprobs_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="get_clusterprobs_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The posterior probability can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
\tau_i(y_j;\theta)=Prob\{z_{ij}=1|y_j\}=\frac{\pi_i\phi(y_j;\mu_i,\Sigma_i)}{\sum_{h=1}^g\pi_h\phi(y_j;\mu_h,\Sigma_h) },
</code>
</p>

<p>where <code class="reqn">\phi</code> is a normal probability function with mean <code class="reqn">\mu_i</code> and covariance matrix <code class="reqn">\Sigma_i</code>,
and <code class="reqn">z_{ij}</code> is is a zero-one indicator variable denoting the class of origin.
</p>


<h3>Value</h3>

<table>
<tr><td><code>clusprobs</code></td>
<td>
<p>Posterior probabilities of class membership for the ith entity</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma,ncov=2)
tau&lt;-get_clusterprobs(dat=dat$Y,n=150,p=3,g=4,mu=mu,sigma=sigma,pi=pi,ncov=2)
</code></pre>

<hr>
<h2 id='get_entropy'>Shannon entropy</h2><span id='topic+get_entropy'></span>

<h3>Description</h3>

<p>Shannon entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_entropy(dat, n, p, g, pi, mu, sigma, ncov = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_entropy_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="get_entropy_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concept of information entropy was introduced by <cite>shannon1948mathematical</cite>.
The entropy of <code class="reqn">y_j</code> is formally defined as
</p>
<p style="text-align: center;"><code class="reqn">e_j( y_j; \theta)=-\sum_{i=1}^g \tau_i( y_j; \theta) \log\tau_i(y_j;\theta).</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>clusprobs</code></td>
<td>
<p>The posterior probabilities of the i-th entity that belongs to the j-th group.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma,ncov=2)
en&lt;-get_entropy(dat=dat$Y,n=150,p=3,g=4,mu=mu,sigma=sigma,pi=pi,ncov=2)
</code></pre>

<hr>
<h2 id='initialvalue'>Initial values for ECM</h2><span id='topic+initialvalue'></span>

<h3>Description</h3>

<p>Inittial values for claculating the estimates based on solely on the classified features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initialvalue(dat, zm, g, ncov = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initialvalue_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="initialvalue_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="initialvalue_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="initialvalue_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>pi</code></td>
<td>
<p>A g-dimensional  initial vector of the mixing proportions.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A initial  <code class="reqn">p \times g</code> matrix of the location parameters.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma,ncov=2)
xi&lt;-c(-0.5,1)
m&lt;-rlabel(dat=dat$Y,pi=pi,mu=mu,sigma=sigma,xi=xi,ncov=2)
zm&lt;-dat$clust
zm[m==1]&lt;-NA
inits&lt;-initialvalue(g=4,zm=zm,dat=dat$Y,ncov=2)



</code></pre>

<hr>
<h2 id='list2par'>Transfer a list into a vector</h2><span id='topic+list2par'></span>

<h3>Description</h3>

<p>Transfer a list into a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list2par(
  p,
  g,
  pi,
  mu,
  sigma,
  ncov = 2,
  xi = NULL,
  type = c("ign", "full", "com")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="list2par_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="list2par_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="list2par_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="list2par_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="list2par_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="list2par_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
<tr><td><code id="list2par_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
<tr><td><code id="list2par_+3A_type">type</code></td>
<td>
<p>Three types to fit to the model, 'ign' indicates fitting the model on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates that the model to be fitted on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate that the model to be fitted to a completed classified sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>par</code></td>
<td>
<p>a vector including all list information</p>
</td></tr>
</table>

<hr>
<h2 id='loglk_full'>Full log-likelihood function</h2><span id='topic+loglk_full'></span>

<h3>Description</h3>

<p>Full log-likelihood function with both terms of ignoring and missing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglk_full(dat, zm, pi, mu, sigma, ncov = 2, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglk_full_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
<tr><td><code id="loglk_full_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The full log-likelihood function can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
\log L_{PC}^{({full})}(\boldsymbol{\Psi})=\log L_{PC}^{({ig})}(\theta)+\log L_{PC}^{({miss})}(\theta,\boldsymbol{\xi}),</code>
</p>

<p>where<code class="reqn">\log L_{PC}^{({ig})}(\theta)</code>is the log likelihood function formed ignoring the missing in the label of the unclassified features,
and <code class="reqn">\log L_{PC}^{({miss})}(\theta,\boldsymbol{\xi})</code> is the log likelihood function formed on the basis of the missing-label indicator.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lk</code></td>
<td>
<p>Log-likelihood value</p>
</td></tr>
</table>

<hr>
<h2 id='loglk_ig'>Log likelihood for partially classified data with ingoring the missing mechanism</h2><span id='topic+loglk_ig'></span>

<h3>Description</h3>

<p>Log likelihood for partially classified data with ingoring the missing mechanism
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglk_ig(dat, zm, pi, mu, sigma, ncov = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglk_ig_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="loglk_ig_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-likelihood function for  partially classified data with ingoring the missing mechanism can be expressed as
</p>
<p style="text-align: center;"><code class="reqn">
 \log L_{PC}^{({ig})}(\theta)=\sum_{j=1}^n  \left[
(1-m_j)\sum_{i=1}^g z_{ij}\left\lbrace \log\pi_i+\log  f_i(y_j;\omega_i)\right\rbrace +m_j\log \left\lbrace  \sum_{i=1}^g\pi_i  f_i(y_j;\omega_i)\right\rbrace  \right],
 </code>
</p>

<p>where <code class="reqn">m_j</code> is a missing label indicator, <code class="reqn">z_{ij}</code> is a zero-one indicator variable defining the known group of origin of each,
and <code class="reqn">f_i(y_j;\omega_i)</code> is a probability density function with parameters <code class="reqn">\omega_i</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lk</code></td>
<td>
<p>Log-likelihood value.</p>
</td></tr>
</table>

<hr>
<h2 id='loglk_miss'>Log likelihood function formed on the basis of the missing-label indicator</h2><span id='topic+loglk_miss'></span>

<h3>Description</h3>

<p>Log likelihood for partially classified data based on the missing mechanism with the Shanon entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglk_miss(dat, zm, pi, mu, sigma, ncov = 2, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglk_miss_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector containing the class labels including the missing-label denoted as NA.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
<tr><td><code id="loglk_miss_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional vector containing the initial values of the coefficients in the logistic function of the Shannon entropy.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-likelihood function  formed on the basis of the missing-label indicator can be expressed by
</p>
<p style="text-align: center;"><code class="reqn">
\log L_{PC}^{({miss})}(\theta,\boldsymbol{\xi})=\sum_{j=1}^n\big[ (1-m_j)\log\left\lbrace 1-q(y_j;\theta,\boldsymbol{\xi})\right\rbrace +m_j\log q(y_j;\theta,\boldsymbol{\xi})\big],
</code>
</p>

<p>where <code class="reqn">q(y_j;\theta,\boldsymbol{\xi})</code> is a logistic function of the Shannon entropy <code class="reqn">e_j(y_j;\theta)</code>,
and  <code class="reqn">m_j</code> is a missing label indicator.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lk</code></td>
<td>
<p>loglikelihood value</p>
</td></tr>
</table>

<hr>
<h2 id='logsumexp'>log summation of exponential function</h2><span id='topic+logsumexp'></span>

<h3>Description</h3>

<p>log summation of exponential variable vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logsumexp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logsumexp_+3A_x">x</code></td>
<td>
<p>A variable vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>val</code></td>
<td>
<p>log summation of exponential variable vector.</p>
</td></tr>
</table>

<hr>
<h2 id='makelabelmatrix'>Label matrix</h2><span id='topic+makelabelmatrix'></span>

<h3>Description</h3>

<p>Convert class indicator into a label maxtrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makelabelmatrix(clust)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makelabelmatrix_+3A_clust">clust</code></td>
<td>
<p>An n-dimensional vector of class partition.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Z</code></td>
<td>
<p> A matrix of class indicator.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>cluster&lt;-c(1,1,2,2,3,3)
label_maxtrix&lt;-makelabelmatrix(cluster)
</code></pre>

<hr>
<h2 id='neg_objective_function'>Negative objective function for EMMIXSSL</h2><span id='topic+neg_objective_function'></span>

<h3>Description</h3>

<p>Negative objective function for EMMIXSSL
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg_objective_function(
  dat,
  zm,
  g,
  par,
  ncov = 2,
  type = c("ign", "full", "com")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg_objective_function_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_zm">zm</code></td>
<td>
<p>An n-dimensional vector of group partition including the missing-label, denoted as NA.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_g">g</code></td>
<td>
<p>Number of multivariate Gaussian groups.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_par">par</code></td>
<td>
<p>An informative vector including <code>mu</code>, <code>pi</code>,<code>sigma</code> and <code>xi</code>.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
<tr><td><code id="neg_objective_function_+3A_type">type</code></td>
<td>
<p>Three types to fit to the model, 'ign' indicates fitting the model on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates that the model to be fitted on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate that the model to be fitted to a completed classified sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>val</code></td>
<td>
<p>Value of negatvie objective function.</p>
</td></tr>
</table>

<hr>
<h2 id='normalise_logprob'>Normalize log-probability</h2><span id='topic+normalise_logprob'></span>

<h3>Description</h3>

<p>Normalize log-probability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalise_logprob(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalise_logprob_+3A_x">x</code></td>
<td>
<p>A variable vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>val</code></td>
<td>
<p>A normalize log probability of variable vector.</p>
</td></tr>
</table>

<hr>
<h2 id='par2list'>Transfer a vector into a list</h2><span id='topic+par2list'></span>

<h3>Description</h3>

<p>Transfer a vector into a list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2list(par, g, p, ncov = 2, type = c("ign", "full"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2list_+3A_par">par</code></td>
<td>
<p>A vector with list information.</p>
</td></tr>
<tr><td><code id="par2list_+3A_g">g</code></td>
<td>
<p>Number of multivariate normal classes.</p>
</td></tr>
<tr><td><code id="par2list_+3A_p">p</code></td>
<td>
<p>Dimension of observation vecor.</p>
</td></tr>
<tr><td><code id="par2list_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix that <code>sigma</code> is a <code class="reqn">p\times p</code> matrix.
<code>ncov</code> = 2 for the unequal  covariance/scale matrices that
<code>sigma</code> represents a list of g matrices with dimension <code class="reqn">p\times p \times g</code>.</p>
</td></tr>
<tr><td><code id="par2list_+3A_type">type</code></td>
<td>
<p>Three types to fit to the model, 'ign' indicates fitting the model on the basis of the likelihood that ignores the missing label mechanism,
'full' indicates that the model to be fitted on the basis of the full likelihood, taking into account the missing-label mechanism,
and 'com' indicate that the model to be fitted to a completed classified sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>parlist</code></td>
<td>
<p>Return a list including <code>mu</code>, <code>pi</code>, <code>sigma</code> and <code>xi</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='pro2vec'>Transfer a probability vector into a vector</h2><span id='topic+pro2vec'></span>

<h3>Description</h3>

<p>Transfer a probability vector into an informative vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pro2vec(pro)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pro2vec_+3A_pro">pro</code></td>
<td>
<p>An propability vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>y An informative vector
</p>

<hr>
<h2 id='rlabel'>Generation of a missing-data indicator</h2><span id='topic+rlabel'></span>

<h3>Description</h3>

<p>Generate the missing label indicator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlabel(dat, pi, mu, sigma, ncov = 2, xi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlabel_+3A_dat">dat</code></td>
<td>
<p>An <code class="reqn">n\times p</code> matrix where each row represents an individual observation.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
<tr><td><code id="rlabel_+3A_xi">xi</code></td>
<td>
<p>A 2-dimensional coefficient vector for a logistic function of the Shannon entropy.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>m</code></td>
<td>
<p>A n-dimensional vector of missing label indicator. The element of  outputs <code>m</code> represents its label indicator is missing if m equals 1, otherwise its label indicator is available if m equals to 0.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma,ncov=2)
xi&lt;-c(-0.5,1)
m&lt;-rlabel(dat=dat$Y,pi=pi,mu=mu,sigma=sigma,xi=xi,ncov=2)
</code></pre>

<hr>
<h2 id='rmix'>Normal mixture model generator.</h2><span id='topic+rmix'></span>

<h3>Description</h3>

<p>Generate random observations from the normal mixture distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmix(n, pi, mu, sigma, ncov = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmix_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="rmix_+3A_pi">pi</code></td>
<td>
<p>A g-dimensional vector for the initial values of the mixing proportions.</p>
</td></tr>
<tr><td><code id="rmix_+3A_mu">mu</code></td>
<td>
<p>A <code class="reqn">p \times g</code> matrix for the initial values of the location parameters.</p>
</td></tr>
<tr><td><code id="rmix_+3A_sigma">sigma</code></td>
<td>
<p>A <code class="reqn">p\times p</code> covariance matrix if <code>ncov=1</code>, or a list of g covariance matrices with dimension <code class="reqn">p\times p \times g</code> if <code>ncov=2</code>.</p>
</td></tr>
<tr><td><code id="rmix_+3A_ncov">ncov</code></td>
<td>
<p>Options of structure of sigma matrix;  the default value is 2;
<code>ncov</code> = 1 for a common covariance matrix;
<code>ncov</code> = 2 for the unequal  covariance/scale matrices.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Y</code></td>
<td>
<p>An <code class="reqn">n\times p</code> numeric matrix with samples drawn in rows.</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p> An <code class="reqn">n\times g</code> numeric matrix; each row represents zero-one indicator variables defining the known class of origin of each.</p>
</td></tr>
<tr><td><code>clust</code></td>
<td>
<p>An n-dimensional vector of class partition.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-150
pi&lt;-c(0.25,0.25,0.25,0.25)
sigma&lt;-array(0,dim=c(3,3,4))
sigma[,,1]&lt;-diag(1,3)
sigma[,,2]&lt;-diag(2,3)
sigma[,,3]&lt;-diag(3,3)
sigma[,,4]&lt;-diag(4,3)
mu&lt;-matrix(c(0.2,0.3,0.4,0.2,0.7,0.6,0.1,0.7,1.6,0.2,1.7,0.6),3,4)
dat&lt;-rmix(n=n,pi=pi,mu=mu,sigma=sigma,ncov=2)
</code></pre>

<hr>
<h2 id='vec2cov'>Transform a vector into a matrix</h2><span id='topic+vec2cov'></span>

<h3>Description</h3>

<p>Transform a vector into a matrix i.e., Sigma=R^T*R
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2cov(par)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2cov_+3A_par">par</code></td>
<td>
<p>A vector representing a variance matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance matrix is decomposed by computing the Choleski factorization of a real symmetric positive-definite square matrix.
Then, storing the upper triangular factor of the Choleski decomposition into a vector.
</p>


<h3>Value</h3>

<p>sigma A variance matrix
</p>

<hr>
<h2 id='vec2pro'>Transfer an informative vector to a probability vector</h2><span id='topic+vec2pro'></span>

<h3>Description</h3>

<p>Transfer an informative vector to a probability vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2pro(vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2pro_+3A_vec">vec</code></td>
<td>
<p>An informative vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>pro A probability vector
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
