<!DOCTYPE html><html><head><title>Help for package predicts</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {predicts}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#predicts-package'>
<p>Spatial prediction</p></a></li>
<li><a href='#backgroundSample'>
<p>Random points</p></a></li>
<li><a href='#biovars'><p>bioclimatic variables</p></a></li>
<li><a href='#divide_polygons'>
<p>Divide polygons into equal area parts</p></a></li>
<li><a href='#envelope'><p>Fit a (climate) envelope model and make predictions</p></a></li>
<li><a href='#folds'>
<p>Make folds for k-fold partitioning</p></a></li>
<li><a href='#hullModel'><p>hull model</p></a></li>
<li><a href='#MaxEnt'><p>MaxEnt</p></a></li>
<li><a href='#mess'><p>Multivariate environmental similarity surfaces (MESS)</p></a></li>
<li><a href='#pa_evaluate'><p>Presence/absence Model evaluation</p></a></li>
<li><a href='#partialResponse'>
<p>Get partial response data</p></a></li>
<li><a href='#plot'>
<p>Plot predictor values</p></a></li>
<li><a href='#predict'><p>Spatial model predictions</p></a></li>
<li><a href='#pwd_sample'><p>Pair-wise distance sampling</p></a></li>
<li><a href='#pycnophy'>
<p>Pycnophylactic interpolation.</p></a></li>
<li><a href='#RMSE'>
<p>Root Mean Square Error</p></a></li>
<li><a href='#SDM'><p>Class &quot;SDM&quot;</p></a></li>
<li><a href='#threshold'><p> Find a threshold</p></a></li>
<li><a href='#varImportance'>
<p>Get variable importance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Spatial Prediction Tools</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for spatial predictive modeling, especially for spatial distribution models. This includes algorithms for model fitting and prediction, as well as methods for model evaluation. </td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-11</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-12</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), methods, terra</td>
</tr>
<tr>
<td>Suggests:</td>
<td>disdat, rJava</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Robert J. Hijmans &lt;r.hijmans@gmail.com&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://rspatial.org/sdm/">https://rspatial.org/sdm/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rspatial/predicts/issues/">https://github.com/rspatial/predicts/issues/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-12 15:07:42 UTC; rhijm</td>
</tr>
<tr>
<td>Author:</td>
<td>Robert J. Hijmans <a href="https://orcid.org/0000-0001-5872-2872"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Steven Phillips [ctb],
  Chris Brunsdon [ctb],
  Barry Rowlingson [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-12 15:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='predicts-package'>
Spatial prediction
</h2><span id='topic+predicts-package'></span><span id='topic+predicts'></span>

<h3>Description</h3>

<p>This package implements functions for spatial predictions methods, especially spatial (species) distribution models, including an R link to the 'maxent' model.
</p>


<h3>Author(s)</h3>

<p>Robert J. Hijmans
</p>

<hr>
<h2 id='backgroundSample'>
Random points
</h2><span id='topic+backgroundSample'></span>

<h3>Description</h3>

<p>Generate random points that can be used to extract background values (&quot;random-absence&quot;). The points are sampled (without replacement) from the cells that are not '<code>NA</code>' in raster '<code>mask</code>'. 
</p>
<p>If the coordinate reference system (of <code>mask</code>) is longitude/latitude, sampling is weighted by the size of the cells. That is, because cells close to the equator are larger than cells closer to the poles, equatorial cells have a higher probability of being selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backgroundSample(mask, n, p, ext=NULL, extf=1.1, excludep=TRUE, 
             cellnumbers=FALSE, tryf=3, warn=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backgroundSample_+3A_mask">mask</code></td>
<td>
<p>SpatRaster. If the object has cell values, cells with <code>NA</code> are excluded (of the first layer of the object if there are multiple layers)</p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_n">n</code></td>
<td>
<p>integer. Number of points</p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_p">p</code></td>
<td>
<p>Presence points (if provided, random points won't be in the same cells (as defined by mask)</p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_ext">ext</code></td>
<td>
<p>SpatExtent. Can be used to restrict sampling to a spatial extent</p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_extf">extf</code></td>
<td>
<p>numeric. Multiplyer to adjust the size of extent 'ext'. The default increases of 1.1 increases the extent a little (5% at each side of the extent)</p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_excludep">excludep</code></td>
<td>
<p>logical. If <code>TRUE</code>, presence points are exluded from background</p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_cellnumbers">cellnumbers</code></td>
<td>
<p>logical. If <code>TRUE</code>, cell numbers for <code>mask</code> are returned rather than coordinates </p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_tryf">tryf</code></td>
<td>
<p>numeric &gt; 1. Multiplyer used for initial sample size from which the requested sample size is extracted after removing NA points (outside of mask) </p>
</td></tr>
<tr><td><code id="backgroundSample_+3A_warn">warn</code></td>
<td>
<p>integer. 2 or higher gives most warnings. 0 or lower gives no warnings if sample size <code>n</code> is not reached </p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix with coordinates, or, if <code>cellnumbers=TRUE</code>, a vector with cell numbers.
</p>

<hr>
<h2 id='biovars'>bioclimatic variables</h2><span id='topic+bcvars'></span><span id='topic+bcvars+2Cmatrix+2Cmatrix+2Cmatrix-method'></span><span id='topic+bcvars+2CSpatRaster+2CSpatRaster+2CSpatRaster-method'></span><span id='topic+bcvars+2Cnumeric+2Cnumeric+2Cnumeric-method'></span>

<h3>Description</h3>

<p>Function to create 'bioclimatic variables' from monthly climate data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SpatRaster,SpatRaster,SpatRaster'
bcvars(prec, tmin, tmax, filename="", ...)

## S4 method for signature 'numeric,numeric,numeric'
bcvars(prec, tmin, tmax)

## S4 method for signature 'matrix,matrix,matrix'
bcvars(prec, tmin, tmax)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biovars_+3A_prec">prec</code></td>
<td>
<p>numeric vector (12 values), matrix (12 columns), or SpatRaster with monthly (12 layers) precipitation data</p>
</td></tr>
<tr><td><code id="biovars_+3A_tmin">tmin</code></td>
<td>
<p>same as <code>prec</code></p>
</td></tr>
<tr><td><code id="biovars_+3A_tmax">tmax</code></td>
<td>
<p>same as <code>prec</code></p>
</td></tr>
<tr><td><code id="biovars_+3A_filename">filename</code></td>
<td>
<p>character. Output filename</p>
</td></tr>
<tr><td><code id="biovars_+3A_...">...</code></td>
<td>
<p>additional arguments for writing files as in <code><a href="terra.html#topic+writeRaster">writeRaster</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input data is normally monthly. I.e. there should be 12 values (layers) for each variable, but the function should also work for e.g. weekly data (with some changes in the meaning of the output variables. E.g. #8 would then not be for a quarter (3 months), but for a 3 week period). 
</p>


<h3>Value</h3>

<p>Same class as input, but 19 values/variables
</p>
<p>bio1 = Mean annual temperature
</p>
<p>bio2 = Mean diurnal range (mean of max temp - min temp)
</p>
<p>bio3 = Isothermality (bio2/bio7) (* 100)
</p>
<p>bio4 = Temperature seasonality (standard deviation *100)
</p>
<p>bio5 = Max temperature of warmest month
</p>
<p>bio6 = Min temperature of coldest month
</p>
<p>bio7 = Temperature annual range (bio5-bio6)
</p>
<p>bio8 = Mean temperature of the wettest quarter
</p>
<p>bio9 = Mean temperature of driest quarter 
</p>
<p>bio10 = Mean temperature of warmest quarter
</p>
<p>bio11 = Mean temperature of coldest quarter
</p>
<p>bio12 = Total (annual) precipitation
</p>
<p>bio13 = Precipitation of wettest month
</p>
<p>bio14 = Precipitation of driest month
</p>
<p>bio15 = Precipitation seasonality (coefficient of variation)
</p>
<p>bio16 = Precipitation of wettest quarter
</p>
<p>bio17 = Precipitation of driest quarter
</p>
<p>bio18 = Precipitation of warmest quarter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmin &lt;- c(10,12,14,16,18,20,22,21,19,17,15,12)
tmax &lt;- tmin + 5
prec &lt;- c(0,2,10,30,80,160,80,20,40,60,20,0)
bcvars(prec, tmin, tmax)

tmn &lt;- tmx &lt;- prc &lt;- rast(nrow=1, ncol=1, nlyr=12)
values(tmn) &lt;- t(matrix(c(10,12,14,16,18,20,22,21,19,17,15,12)))
tmx &lt;- tmn + 5
values(prc) &lt;- t(matrix(c(0,2,10,30,80,160,80,20,40,60,20,0)))
b &lt;- bcvars(prc, tmn, tmx)
as.matrix(b)
</code></pre>

<hr>
<h2 id='divide_polygons'>
Divide polygons into equal area parts
</h2><span id='topic+divider'></span><span id='topic+stripper'></span>

<h3>Description</h3>

<p><code>stripper</code> divides polygons into horizontal or vertical strips of a specified relative size.
</p>
<p><code>divider</code> divides a <code>SpatVector</code> of polygons into <code>n</code> compact and approximately equal area parts. The results are not deterministic so you should use <code><a href="base.html#topic+set.seed">set.seed</a></code> to be able to reproduce your results. If you get a warning about non-convergence, you can increase the number of iterations used with additional argument <code>iter.max</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divider(x, n, env=NULL, alpha=1, ...)
stripper(x, f=c(1/3, 2/3), vertical=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="divide_polygons_+3A_x">x</code></td>
<td>
<p>SpatVector of polygons</p>
</td></tr>
<tr><td><code id="divide_polygons_+3A_n">n</code></td>
<td>
<p>positive integer. The number of parts requested</p>
</td></tr>
<tr><td><code id="divide_polygons_+3A_env">env</code></td>
<td>
<p>SpatRaster with environmental data</p>
</td></tr>
<tr><td><code id="divide_polygons_+3A_alpha">alpha</code></td>
<td>
<p>numeric. One or two numbers that act as weights for the x and y coordinates</p>
</td></tr>
<tr><td><code id="divide_polygons_+3A_...">...</code></td>
<td>
<p>additional arguments such as <code>iter.max</code> passed on to <code><a href="stats.html#topic+kmeans">kmeans</a></code></p>
</td></tr>
<tr><td><code id="divide_polygons_+3A_f">f</code></td>
<td>
<p>numeric vector of fractions. These must be &gt; 0 and &lt; 1, and in ascending order</p>
</td></tr>
<tr><td><code id="divide_polygons_+3A_vertical">vertical</code></td>
<td>
<p>logical. If <code>TRUE</code> the strips are vertical</p>
</td></tr>
</table>


<h3>Value</h3>

<p>SpatVector 
</p>


<h3>Author(s)</h3>

<p>stripper was derived from a function by Barry Rowlingson</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- system.file("ex/lux.shp", package="terra")
v &lt;- aggregate(vect(f))
set.seed(33)
d1 &lt;- divider(v, 10)
plot(d1)

d2 &lt;- divider(v, 100)
boxplot(expanse(d2, "km"))

x &lt;- stripper(v, seq(0.1, 0.9, 0.1))
round(expanse(x,"km"), 1)
plot(x, col=rainbow(12))

</code></pre>

<hr>
<h2 id='envelope'>Fit a (climate) envelope model and make predictions</h2><span id='topic+envelope'></span><span id='topic+envelope+2CSpatRaster-method'></span><span id='topic+envelope+2Cmatrix-method'></span><span id='topic+envelope+2Cdata.frame-method'></span><span id='topic+envelope_model-class'></span>

<h3>Description</h3>

<p>The envelope algorithm has been extensively used for species distribution modeling under the name &quot;bioclim model&quot;. This is the classic 'climate-envelope-model' that started what was later called species distribution modeling and ecological niche modeling. Although it generally does not perform as good as some other methods (Elith et al. 2006) and is unsuited for predicting climate change effects (Hijmans and Graham, 2006). It may be useful in certain cases, among other reasons because the algorithm is easy to understand and thus useful in teaching species distribution modeling. 
</p>
<p>The algorithm computes the similarity of a location by comparing the values of environmental variables at any location to a percentile distribution of the values at known locations of occurrence ('training sites'). The closer to the 50th percentile (the median), the more suitable the location is. The tails of the distribution are not distinguished, that is, 10 percentile is treated as equivalent to 90 percentile. 
</p>
<p>In this R implementation, percentile scores are between 0 and 1, but predicted values larger than 0.5 are subtracted from 1. Then, the minimum percentile score across all the environmental variables is computed (i.e. this is like Liebig's law of the minimum, except that high values can also be limiting factors). The final value is subtracted from 1 and multiplied with 2 so that the results are between 0 and 1. The reason for this transformation is that the results become more like that of other distribution modeling methods and are thus easier to interpret. The value 1 will rarely be observed as it would require a location that has the median value of the training data for all the variables considered. The value 0 is very common as it is assigned to all cells with a value of an environmental variable that is outside the percentile distribution (the range of the training data) for at least one of the variables. 
</p>
<p>When using the <a href="#topic+predict">predict</a> function you can choose to ignore one of the tails of the distribution (for example, to make low rainfall a limiting factor, but not high rainfall).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>envelope(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="envelope_+3A_x">x</code></td>
<td>
<p>matrix or data.frame where each column is an environmental variable and each row an occurrence</p>
</td></tr>
<tr><td><code id="envelope_+3A_...">...</code></td>
<td>
<p> Additional arguments </p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class 'envelope_model'
</p>


<h3>Author(s)</h3>

<p>Robert J. Hijmans
</p>


<h3>References</h3>

<p>Nix, H.A., 1986. A biogeographic analysis of Australian elapid snakes. In: Atlas of Elapid Snakes of Australia. (Ed.) R. Longmore, pp. 4-15. Australian Flora and Fauna Series Number 7. Australian Government Publishing Service: Canberra.
</p>
<p>Booth, T.H., H.A. Nix, J.R. Busby and M.F. Hutchinson, 2014. BIOCLIM: the first species distribution modelling package, its early applications and relevance to most current MAXENT studies. Diversity and Distributions 20: 1-9
</p>
<p>Elith, J., C.H. Graham, R.P. Anderson, M. Dudik, S. Ferrier, A. Guisan, R.J. Hijmans, F. Huettmann, J. Leathwick, A. Lehmann, J. Li, L.G. Lohmann, B. Loiselle, G. Manion, C. Moritz, M. Nakamura, Y. Nakazawa, J. McC. Overton, A.T. Peterson, S. Phillips, K. Richardson, R. Scachetti-Pereira, R. Schapire, J. Soberon, S. Williams, M. Wisz and N. Zimmerman, 2006. Novel methods improve prediction of species' distributions from occurrence data. Ecography 29: 129-151. <a href="https://doi.org/10.1111/j.2006.0906-7590.04596.x">doi:10.1111/j.2006.0906-7590.04596.x</a>
</p>
<p>Hijmans R.J., and C.H. Graham, 2006. Testing the ability of climate envelope models to predict the effect of climate change on species distributions. Global change biology 12: 2272-2281. <a href="https://doi.org/10.1111/j.1365-2486.2006.01256.x">doi:10.1111/j.1365-2486.2006.01256.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict">predict</a>, <a href="#topic+maxent">maxent</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># file with presence points
fsp &lt;- system.file("/ex/bradypus.csv", package="predicts")
occ &lt;- read.csv(fsp)[,-1]

#predictors
f &lt;- system.file("ex/bio.tif", package="predicts")
preds &lt;- rast(f)[[c(1,7,9)]]

v &lt;- extract(preds, occ)
bc &lt;- envelope(v[,-1])

d &lt;- preds[18324:18374]
predict(bc, d)

p1 &lt;- predict(bc, preds)
p2 &lt;- predict(bc, preds, tails=c("both", "low", "high"))

</code></pre>

<hr>
<h2 id='folds'>
Make folds for k-fold partitioning
</h2><span id='topic+folds'></span>

<h3>Description</h3>

<p>k-fold partitioning of a data set for model testing purposes. Each record in a matrix (or similar data structure) is randomly assigned to a group. Group numbers are between 1 and <code>k</code>. The function assures that each fold has the same size (or as close to that as possible).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>folds(x, k=5, by)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="folds_+3A_x">x</code></td>
<td>
<p>a vector, matrix, data.frame, or Spatial object</p>
</td></tr>
<tr><td><code id="folds_+3A_k">k</code></td>
<td>
<p>number of groups</p>
</td></tr>
<tr><td><code id="folds_+3A_by">by</code></td>
<td>
<p>Optional argument. A vector or factor with sub-groups (e.g. species). Its length should be the same as the number of records in x</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector with group assignments
</p>


<h3>Author(s)</h3>

<p>Robert J. Hijmans
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(disdat)
train &lt;- disPo("NSW")
## a single species
srsp1 &lt;- subset(train, spid=="nsw01")
folds(srsp1, k = 5)

## all species
k = folds(train, k=5, by=train$spid)

## each group has the same number of records 
##(except for adjustments if the number of records 
## divided by k is not an integer) 

table(k[train$spid=="nsw01"])
</code></pre>

<hr>
<h2 id='hullModel'>hull model</h2><span id='topic+HullModel-class'></span><span id='topic+hullModel'></span><span id='topic+hullModel+2CSpatVector-method'></span><span id='topic+hullModel+2Cmatrix-method'></span><span id='topic+hullModel+2Cdata.frame-method'></span><span id='topic+geometry'></span><span id='topic+geometry+2CHullModel-method'></span><span id='topic+plot+2CHullModel+2Cmissing-method'></span>

<h3>Description</h3>

<p>The hull model predicts that a species is present at sites inside the a hull that contains the training points, and is absent outside that circle.
</p>
<p>The hull can be &quot;convex&quot;, &quot;circle&quot;, or &quot;rectangle&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SpatVector'
hullModel(p, type="convex", n=1)

## S4 method for signature 'data.frame'
hullModel(p, type="convex", crs="", n=1)

## S4 method for signature 'matrix'
hullModel(p, type="convex", crs="", n=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hullModel_+3A_p">p</code></td>
<td>
<p>point locations (presence). Two column matrix, data.frame or SpatVector</p>
</td></tr>
<tr><td><code id="hullModel_+3A_type">type</code></td>
<td>
<p>character. The type of hull. One of &quot;convex&quot;, &quot;circle&quot;, or &quot;rectangle&quot;</p>
</td></tr>
<tr><td><code id="hullModel_+3A_crs">crs</code></td>
<td>
<p>character. The coordinate reference system</p>
</td></tr>
<tr><td><code id="hullModel_+3A_n">n</code></td>
<td>
<p>positive integer. The number of hulls to make</p>
</td></tr>
</table>


<h3>Value</h3>

<p>&quot;HullModel&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r &lt;- rast(system.file("ex/logo.tif", package="terra"))   
#presence data
pts &lt;- matrix(c(17, 42, 85, 70, 19, 53, 26, 84, 84, 46, 48, 85, 4,
    95, 48, 54, 66, 74, 50, 48, 28, 73, 38, 56, 43, 29, 63, 22, 46, 45,
    7, 60, 46, 34, 14, 51, 70, 31, 39, 26), ncol=2)
train &lt;- pts[1:12, ]
test &lt;- pts[13:20, ]
				 
ch &lt;- hullModel(train, crs="+proj=longlat")
predict(ch, test)

plot(r)
plot(ch, border="red", lwd=2, add=TRUE)
points(train, col="red", pch=20, cex=2)
points(test, col="black", pch=20, cex=2)

pr &lt;- predict(ch, r)
plot(pr)
points(test, col="black", pch=20, cex=2)
points(train, col="red", pch=20, cex=2)

# to get the polygons:
p &lt;- geometry(ch)
p
</code></pre>

<hr>
<h2 id='MaxEnt'>MaxEnt</h2><span id='topic+MaxEnt_model-class'></span><span id='topic+MaxEnt_model_replicates-class'></span><span id='topic+MaxEnt'></span><span id='topic+MaxEnt+2Cmissing+2Cmissing-method'></span><span id='topic+MaxEnt+2CSpatRaster+2CANY-method'></span><span id='topic+MaxEnt+2CSpatRaster+2CSpatVector-method'></span><span id='topic+MaxEnt+2Cdata.frame+2Cnumeric-method'></span><span id='topic+MaxEnt_model-class'></span><span id='topic+MaxEnt_model_replicates-class'></span>

<h3>Description</h3>

<p>Build a &quot;maxent&quot; (Maximum Entropy) species distribution model (see references below). The function uses environmental data for locations of known presence and for a large number of 'background' locations. Environmental data can be extracted from raster files. The result is a model object that can be used to predict the suitability of other locations, for example, to predict the entire range of a species. 
</p>
<p>Background points are sampled randomly from the cells that are not <code>NA</code> in the first predictor variable, unless background points are specified with argument <code>a</code>. 
</p>
<p>This function uses the MaxEnt species distribution model software by Phillips, Dudik and Schapire.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SpatRaster,SpatVector'
MaxEnt(x, p, a=NULL, removeDuplicates=TRUE, nbg=10000, ...)

## S4 method for signature 'data.frame,numeric'
MaxEnt(x, p, args=NULL, path, silent=FALSE, ...)

## S4 method for signature 'missing,missing'
MaxEnt(x, p, silent=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MaxEnt_+3A_x">x</code></td>
<td>
<p>Predictors. Either a SpatRaster to extract values from for the locations in <code>y</code>; or a data.frame, in which case each column should be a predictor variable and each row a presence or background record</p>
</td></tr>
<tr><td><code id="MaxEnt_+3A_p">p</code></td>
<td>
<p>If <code>x</code> is a SpatRaster: occurence data. This can be a data.frame, matrix, or SpatVector. If <code>p</code> is a data.frame or matrix it represents a set of point locations; and it must have two columns with the first being the x-coordinate (longitude) and the second the y-coordinate (latitude). 
</p>
<p>If <code>x</code> is a data.frame, <code>p</code> should be a vector with a length equal to <code>nrow(x)</code> and contain 0 (background) and 1 (presence) values, to indicate which records (rows) in data.frame <code>x</code> are presence records, and which are background records</p>
</td></tr>
<tr><td><code id="MaxEnt_+3A_a">a</code></td>
<td>
<p>Background points. Only used if <code>p</code> is not a vector and not missing</p>
</td></tr>
<tr><td><code id="MaxEnt_+3A_nbg">nbg</code></td>
<td>
<p>Number of background points to use. These are sampled randomly from the cells that are not <code>NA</code> in the first predictor variable. Ignored if background points are specified with argument <code>a</code></p>
</td></tr> 
<tr><td><code id="MaxEnt_+3A_args">args</code></td>
<td>
<p>character. Additional argument that can be passed to MaxEnt. See the MaxEnt help for more information. The R MaxEnt function only uses the arguments relevant to model fitting. There is no point in using args='outputformat=raw' when *fitting* the model; but you can use arguments relevant for *prediction* when using the predict function. Some other arguments do not apply at all to the R implementation. An example is 'outputfiletype', because the 'predict' function has its own 'filename' argument for that</p>
</td></tr>
<tr><td><code id="MaxEnt_+3A_removeduplicates">removeDuplicates</code></td>
<td>
<p>Boolean. If <code>TRUE</code>, duplicate presence points (that fall in the same grid cell) are removed</p>
</td></tr>
<tr><td><code id="MaxEnt_+3A_path">path</code></td>
<td>
<p>character. Optional argument to set where you want the MaxEnt output files to be stored. This allows you to permanently keep these files. If not supplied the MaxEnt files will be stored in a temporary file. These are the files that are shown in a browser when typing the model name or when you use &quot;show(model)&quot;</p>
</td></tr>
<tr><td><code id="MaxEnt_+3A_silent">silent</code></td>
<td>
<p>Boolean. If <code>TRUE</code> a message is printed</p>
</td></tr>
<tr><td><code id="MaxEnt_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class 'MaxEnt_model'. Or a 'MaxEnt_model_replicates' object if you use 'replicates=' as part of the <code>args</code> argument. 
</p>
<p>If the function is run without any arguments a boolean value is returned (<code>TRUE</code> if MaxEnt.jar was found).
</p>


<h3>Author(s)</h3>

<p>Steven Phillips and Robert J. Hijmans</p>


<h3>References</h3>

<p><a href="https://biodiversityinformatics.amnh.org/open_source/maxent/">https://biodiversityinformatics.amnh.org/open_source/maxent/</a>
</p>
<p>Steven J. Phillips, Miroslav Dudik, Robert E. Schapire, 2004.  A maximum entropy approach to species distribution modeling. Proceedings of the Twenty-First International Conference on Machine Learning. p. 655-662.
</p>
<p>Steven J. Phillips, Robert P. Anderson, Robert E. Schapire, 2006. Maximum entropy modeling of species geographic distributions. Ecological Modelling 190:231-259. 
</p>
<p>Jane Elith, Steven J. Phillips, Trevor Hastie, Miroslav Dudik, Yung En Chee, Colin J. Yates, 2011. A statistical explanation of MaxEnt for ecologists. Diversity and Distributions 17:43-57. <a href="https://doi.org/10.1111/j.1472-4642.2010.00725.x">doi:10.1111/j.1472-4642.2010.00725.x</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict">predict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


# test if you can use MaxEnt 
MaxEnt()

if (MaxEnt()) {

# get predictor variables
f &lt;- system.file("ex/bio.tif", package="predicts")
preds &lt;- rast(f)
plot(preds)

# file with presence points
occurence &lt;- system.file("/ex/bradypus.csv", package="predicts")
occ &lt;- read.csv(occurence)[,-1]

# witholding a 20% sample for testing 
fold &lt;- folds(occ, k=5)
occtest &lt;- occ[fold == 1, ]
occtrain &lt;- occ[fold != 1, ]

# fit model
me &lt;- MaxEnt(preds, occtrain)

# see the MaxEnt results in a browser:
me

# use "args"
me2 &lt;- MaxEnt(preds, occtrain, factors='biome', args=c("-J", "-P"))

# plot showing importance of each variable
plot(me)

# response curves
# response(me)

# predict to entire dataset
r &lt;- predict(me, preds) 

# with some options:
r &lt;- predict(me, preds, args=c("outputformat=raw"))

plot(r)
points(occ)

#testing
# background sample
bg &lt;- backgroundSample(preds, 1000)

#simplest way to use 'evaluate'
e1 &lt;- pa_evaluate(me, p=occtest, a=bg, x=preds)

# alternative 1
# extract values
pvtest &lt;- data.frame(extract(preds, occtest))
avtest &lt;- data.frame(extract(preds, bg))

e2 &lt;- pa_evaluate(me, p=pvtest, a=avtest)

# alternative 2 
# predict to testing points 
testp &lt;- predict(me, pvtest) 
head(testp)
testa &lt;- predict(me, avtest) 

e3 &lt;- pa_evaluate(p=testp, a=testa)
e3
threshold(e3)

plot(e3, 'ROC')
}


</code></pre>

<hr>
<h2 id='mess'>Multivariate environmental similarity surfaces (MESS)</h2><span id='topic+mess'></span><span id='topic+mess+2CSpatRaster-method'></span><span id='topic+mess+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>Compute multivariate environmental similarity surfaces (MESS), as described by Elith et al., 2010</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SpatRaster'
mess(x, v, full=FALSE, filename="", ...)

## S4 method for signature 'data.frame'
mess(x, v, full=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mess_+3A_x">x</code></td>
<td>
<p>SpatRaster or data.frame</p>
</td></tr>
<tr><td><code id="mess_+3A_v">v</code></td>
<td>
<p>matrix or data.frame containing the reference values; each column should correspond to one layer of the SpatRaster object. If <code>x</code> is a SpatRaster, it can also be a SpatVector with reference locations (points)</p>
</td></tr>
<tr><td><code id="mess_+3A_full">full</code></td>
<td>
<p>logical. If <code>FALSE</code> a SpatRaster with the MESS values is returned. If <code>TRUE</code>, a SpatRaster is returned with <code>n</code> layers corresponding to the layers of the input SpatRaster and an additional layer with the MESS values</p>
</td></tr>
<tr><td><code id="mess_+3A_filename">filename</code></td>
<td>
<p>character. Output filename (optional)</p>
</td></tr>
<tr><td><code id="mess_+3A_...">...</code></td>
<td>
<p>additional arguments as for <code><a href="terra.html#topic+writeRaster">writeRaster</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>v</code> can be obtained for a set of points using <code><a href="raster.html#topic+extract">extract</a></code> .
</p>


<h3>Value</h3>

<p>SpatRaster (or data.frame) with layers (columns) corresponding to the input layers and an additional layer with the mess values (if <code>full=TRUE</code> and <code>nlyr(x) &gt; 1</code>) or a SpatRaster (data.frame) with the MESS values (if <code>full=FALSE</code>).
</p>


<h3>Author(s)</h3>

<p>Jean-Pierre Rossi, Robert Hijmans, Paulo van Breugel
</p>


<h3>References</h3>

<p>Elith J., M. Kearney M., and S. Phillips, 2010. The art of modelling range-shifting species. Methods in Ecology and Evolution 1:330-342. <a href="https://doi.org/10.1111/j.2041-210X.2010.00036.x">doi:10.1111/j.2041-210X.2010.00036.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(9)
r &lt;- rast(ncol=10, nrow=10)
r1 &lt;- setValues(r, (1:ncell(r))/10 + rnorm(ncell(r)))
r2 &lt;- setValues(r, (1:ncell(r))/10 + rnorm(ncell(r)))
r3 &lt;- setValues(r, (1:ncell(r))/10 + rnorm(ncell(r)))
s &lt;- c(r1,r2,r3)
names(s) &lt;- c('a', 'b', 'c')
xy &lt;- cbind(rep(c(10,30,50), 3), rep(c(10,30,50), each=3))
refpt &lt;- extract(s, xy)

ms &lt;- mess(s, refpt, full=TRUE)
plot(ms)

## Not run: 
filename &lt;- paste0(system.file(package="predicts"), "/ex/bradypus.csv")
bradypus &lt;- read.table(filename, header=TRUE, sep=',')
bradypus &lt;- bradypus[,2:3]

predfile &lt;- paste0(system.file(package="predicts"), "/ex/bio.tif")
predictors &lt;- rast(predfile)
reference_points &lt;- extract(predictors, bradypus, ID=FALSE)
mss &lt;- mess(x=predictors, v=reference_points, full=TRUE)

breaks &lt;- c(-500, -50, -25, -5, 0, 5, 25, 50, 100)
fcol &lt;- colorRampPalette(c("blue", "beige", "red"))
plot(mss[[10]], breaks=breaks, col=fcol(9), plg=list(x="bottomleft"))

## End(Not run)

</code></pre>

<hr>
<h2 id='pa_evaluate'>Presence/absence Model evaluation </h2><span id='topic+paModelEvaluation-class'></span><span id='topic+pa_evaluate'></span><span id='topic+plot+2CpaModelEvaluation+2CANY-method'></span>

<h3>Description</h3>

 
<p>Evaluation of models with presence/absence data. Given a vector of presence and a vector of absence values, confusion matrices are computed for a sequence of thresholds, and model evaluation statistics are computed for each confusion matrix / threshold. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pa_evaluate(p, a, model=NULL, x=NULL, tr, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pa_evaluate_+3A_p">p</code></td>
<td>
<p>either (1) predictions for presence points  (<code>model</code> and <code>x</code> are not <code>NULL</code>); or (2) predictor values for presence points (<code>model</code> is not <code>NULL</code>, <code>x</code> is <code>NULL</code>; or locations for presence points (<code>model</code> and <code>x</code> are not <code>NULL</code>)</p>
</td></tr>   
<tr><td><code id="pa_evaluate_+3A_a">a</code></td>
<td>
<p>as above for absence or background points</p>
</td></tr>
<tr><td><code id="pa_evaluate_+3A_model">model</code></td>
<td>
<p>A fitted model used to make predictions</p>
</td></tr>
<tr><td><code id="pa_evaluate_+3A_x">x</code></td>
<td>
<p>SpatRaster used to extract predictor values from</p>
</td></tr>
<tr><td><code id="pa_evaluate_+3A_tr">tr</code></td>
<td>
<p>Optional. a vector of threshold values to use for computing the confusion matrices</p>
</td></tr>
<tr><td><code id="pa_evaluate_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code>predict(model,...)</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>pa_ModelEvaluation object
</p>


<h3>details</h3>

<p>A pa_ModelEvaluation object has the the following slots 
</p>

<dl>
<dt><code>presence</code>:</dt><dd><p>presence values used </p>
</dd>
<dt><code>absence</code>:</dt><dd><p>absence values used</p>
</dd>
<dt><code>confusion</code>:</dt><dd><p>confusion matrix for each threshold</p>
</dd>
<dt><code>stats</code>:</dt><dd><p>statistics that are not threshold dependent</p>
</dd>
<dt><code>tr_stats</code>:</dt><dd><p>statistics that are threshold dependent</p>
</dd>
<dt><code>thresholds</code>:</dt><dd><p>optimal thresholds to classify values into presence and absence</p>
</dd>
</dl>

<p><code>stats</code> has the following values
</p>

<dl>
<dt><code>np</code>:</dt><dd><p>number of presence points</p>
</dd>
<dt><code>na</code>:</dt><dd><p>number of absence points</p>
</dd>
<dt><code>auc</code>:</dt><dd><p>Area under the receiver operator (ROC) curve</p>
</dd>
<dt><code>pauc</code>:</dt><dd><p> p-value for the AUC (for the Wilcoxon test W statistic</p>
</dd>
<dt><code>cor</code>:</dt><dd><p> Correlation coefficient</p>
</dd>
<dt><code>pcor</code>:</dt><dd><p>p-value for correlation coefficient </p>
</dd>
<dt><code>prevalence</code>:</dt><dd><p> Prevalence </p>
</dd>
<dt><code>ODP</code>:</dt><dd><p> Overall diagnostic power </p>
</dd>
</dl>

<p><code>tr_stats</code> has the following values
</p>

<dl>
<dt><code>tresholds</code>:</dt><dd><p> vector of thresholds used to compute confusion matrices </p>
</dd>
<dt><code>CCR</code>:</dt><dd><p> Correct classification rate </p>
</dd>
<dt><code>TPR</code>:</dt><dd><p> True positive rate </p>
</dd>
<dt><code>TNR</code>:</dt><dd><p> True negative rate </p>
</dd>
<dt><code>FPR</code>:</dt><dd><p> False positive rate </p>
</dd>
<dt><code>FNR</code>:</dt><dd><p> False negative rate </p>
</dd>
<dt><code>PPP</code>:</dt><dd><p> Positive predictive power </p>
</dd>
<dt><code>NPP</code>:</dt><dd><p> Negative predictive power </p>
</dd>
<dt><code>MCR</code>:</dt><dd><p> Misclassification rate </p>
</dd>
<dt><code>OR</code>:</dt><dd><p> Odds-ratio </p>
</dd>
<dt><code>kappa</code>:</dt><dd><p> Cohen's kappa </p>
</dd>
</dl>

<p><code>thresholds</code> has the following values
</p>

<dl>
<dt><code>max_kappa</code>:</dt><dd><p>the threshold at which kappa is highest</p>
</dd>
<dt><code>max_spec_sens</code>:</dt><dd><p>the threshold at which the sum of the sensitivity (true positive rate) and specificity (true negative rate) is highest</p>
</dd>
<dt><code>no_omission</code>:</dt><dd><p>the highest threshold at which there is no omission</p>
</dd>
<dt><code>prevalence</code>:</dt><dd><p>modeled prevalence is closest to observed prevalence</p>
</dd>
<dt><code>equal_sens_spec</code>:</dt><dd><p>equal sensitivity and specificity</p>
</dd>
</dl>



<h3>References</h3>

<p>Fielding, A.H. and J.F. Bell, 1997. A review of methods for the assessment of prediction errors in conservation presence/absence models. Environmental Conservation 24:38-49
</p>
<p>Liu, C., M. White &amp; G. Newell, 2011. Measuring and comparing the accuracy of species distribution models with presence-absence data. Ecography 34: 232-243.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
# p has the predicted values for 50 known cases (locations) 
# with presence of the phenomenon (species)
p &lt;- rnorm(50, mean=0.6, sd=0.3)
# a has the predicted values for 50 background locations (or absence)
a &lt;- rnorm(50, mean=0.4, sd=0.4)

e &lt;- pa_evaluate(p=p, a=a)
e

e@stats

plot(e, "ROC")
plot(e, "TPR")
plot(e, "boxplot")
plot(e, "density")

str(e)
</code></pre>

<hr>
<h2 id='partialResponse'>
Get partial response data
</h2><span id='topic+partialResponse'></span><span id='topic+partialResponse2'></span>

<h3>Description</h3>

<p>Get partial response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partialResponse(model, data, var=1, rng=NULL, nsteps=25)
partialResponse2(model, data, var, var2, var2levels, rng=NULL, nsteps=25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partialResponse_+3A_model">model</code></td>
<td>
<p>a model object</p>
</td></tr>
<tr><td><code id="partialResponse_+3A_data">data</code></td>
<td>
<p>data.frame with data for all model variables</p>
</td></tr>
<tr><td><code id="partialResponse_+3A_var">var</code></td>
<td>
<p>character or positive integer to identify the variable of interest in <code>data</code></p>
</td></tr>
<tr><td><code id="partialResponse_+3A_var2">var2</code></td>
<td>
<p>character. A second variable of interest</p>
</td></tr>
<tr><td><code id="partialResponse_+3A_var2levels">var2levels</code></td>
<td>
<p>character. The levels of the second variable to consider</p>
</td></tr>
<tr><td><code id="partialResponse_+3A_rng">rng</code></td>
<td>
<p>optional vector of two numbers to set the range or the variable</p>
</td></tr>
<tr><td><code id="partialResponse_+3A_nsteps">nsteps</code></td>
<td>
<p>positive integer. Number of steps to consider for the variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fsp &lt;- system.file("/ex/bradypus.csv", package="predicts")
occ &lt;- read.csv(fsp)[,-1]
f &lt;- system.file("ex/bio.tif", package="predicts")
preds &lt;- rast(f)[[c(1,7,9)]]
v &lt;- extract(preds, occ, ID=FALSE)

bc &lt;- envelope(v)

pr &lt;- partialResponse(bc, data=v, var="bio12", nsteps=30)
plot(pr, type="l", las=1)
</code></pre>

<hr>
<h2 id='plot'>
Plot predictor values 
</h2><span id='topic+plot+2Cenvelope_model+2Cmissing-method'></span><span id='topic+plot+2CMaxEnt_model+2CANY-method'></span>

<h3>Description</h3>

<p>Plot predictor values for occurrence (presence and absence) data in a model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'envelope_model,missing'
plot(x, a = 1, b = 2, p = 0.9, ...)

## S4 method for signature 'MaxEnt_model,ANY'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>model object</p>
</td></tr>
<tr><td><code id="plot_+3A_a">a</code></td>
<td>
<p>describe</p>
</td></tr>
<tr><td><code id="plot_+3A_b">b</code></td>
<td>
<p>describe</p>
</td></tr>
<tr><td><code id="plot_+3A_p">p</code></td>
<td>
<p>describe</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>missing</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>arguments passed to <a href="base.html#topic+plot">plot</a></p>
</td></tr>
</table>

<hr>
<h2 id='predict'>Spatial model predictions</h2><span id='topic+predict'></span><span id='topic+predict+2Cenvelope_model-method'></span><span id='topic+predict+2Cmaxent_model-method'></span><span id='topic+predict+2Cmaxent_model_replicates-method'></span>

<h3>Description</h3>

<p>Make predictions with models defined in the <code>predicts</code> package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'envelope_model'
predict(object, x, tails=NULL, extent=NULL, filename="", ...)

## S4 method for signature 'maxent_model'
predict(object, x, args="", extent=NULL, filename="", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict_+3A_object">object</code></td>
<td>
<p>model defined in this package (e.g. &quot;envelope_model&quot; and &quot;maxent_model&quot;)</p>
</td></tr>
<tr><td><code id="predict_+3A_x">x</code></td>
<td>
<p>data to predict to. Either a data.frame or a SpatRaster</p>
</td></tr>
<tr><td><code id="predict_+3A_tails">tails</code></td>
<td>
<p>character. You can use this to ignore the left or right tail of the percentile distribution for a variable. If supplied, tails should be a character vector with a length equal to the number of variables used in the model. Valid values are &quot;both&quot; (the default), &quot;low&quot; and &quot;high&quot;. For example, if you have a variable x with an observed distribution between 10 and 20 and you are predicting the bioclim value for a value of 25, the default result would be zero (outside of all observed values); but if you use tail='low', the high (right) tail is ignored and the value returned will be 1. </p>
</td></tr>
<tr><td><code id="predict_+3A_args">args</code></td>
<td>
<p>Pass *prediction* arguments (options) to the maxent software. See <code><a href="#topic+maxent">maxent</a></code></p>
</td></tr>
<tr><td><code id="predict_+3A_extent">extent</code></td>
<td>
<p>SpatExtent that can be supplied to limit the prediction to a sub-region of <code>x</code></p>
</td></tr>
<tr><td><code id="predict_+3A_filename">filename</code></td>
<td>
<p>character. Output filename</p>
</td></tr>
<tr><td><code id="predict_+3A_...">...</code></td>
<td>
<p>additional arguments for writing files as in <code><a href="terra.html#topic+writeRaster">writeRaster</a></code></p>
</td></tr> 
</table>


<h3>Value</h3>

<p>SpatRaster or vector (if <code>x</code> is a data.frame). 
</p>


<h3>See Also</h3>

<p><code><a href="terra.html#topic+predict">predict</a></code> function in the &quot;terra&quot; package for spatial predictions with glm, randomForest, etc.
</p>

<hr>
<h2 id='pwd_sample'>Pair-wise distance sampling</h2><span id='topic+pwd_sample'></span>

<h3>Description</h3>

<p>Select pairs of points from two sets (without replacement) that have a similar distance to their nearest point in another set of points. 
</p>
<p>For each point in &quot;<code>fixed</code>&quot;, a point is selected from &quot;<code>sample</code>&quot; that has a similar distance (as defined by <code>threshold</code>) to its nearest point in &quot;<code>reference</code>&quot; (note that these are likely to be different points in <code>reference</code>). The select point is either the nearest point <code>nearest=TRUE</code>, or a randomly select point <code>nearest=FALSE</code> that is within the threshold distance. If no point within the threshold distance is found in <code>sample</code>, the point in <code>fixed</code> is dropped.
</p>
<p>Hijmans (2012) proposed this sampling approach to remove 'spatial sorting bias' from evaluation data used in cross-validation of presence-only species distribution models. In that context, <code>fixed</code> are the testing-presence points, <code>sample</code> the testing-absence (or testing-background) points, and <code>reference</code> the training-presence points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwd_sample(fixed, sample, reference, tr=0.33, nearest=TRUE, n=1, lonlat=TRUE, warn=TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwd_sample_+3A_fixed">fixed</code></td>
<td>
<p>two column matrix (x, y) or (longitude/latitude) or SpatialPoints object, for point locations for which a pair should be found in <code>sample</code> </p>
</td></tr>
<tr><td><code id="pwd_sample_+3A_sample">sample</code></td>
<td>
<p>as above for point locations from which to sample to make a pair with a point from <code>fixed</code></p>
</td></tr>
<tr><td><code id="pwd_sample_+3A_reference">reference</code></td>
<td>
<p>as above for reference point locations to which distances are computed</p>
</td></tr>
<tr><td><code id="pwd_sample_+3A_n">n</code></td>
<td>
<p>How many pairs do you want for each point in <code>fixed</code></p>
</td></tr>
<tr><td><code id="pwd_sample_+3A_tr">tr</code></td>
<td>
<p>Numeric, normally below 1. The threshold distance for a pair of points (one of <code>fixed</code> and one of <code>sample</code>) to their respective nearest points in <code>reference</code> to be considered a valid pair. The absolute difference in distance between the candidate point pairs in <code>fixed</code> and <code>reference</code> (dfr) and the distance between candidate point pairs in <code>sample</code> and <code>reference</code> (dsr) must be smaller than <code>tr</code> * dfr. I.e. if the dfr = 100 km, and tr = 0.1, dsr must be between &gt;90 and &lt;110 km to be considered a valid pair.</p>
</td></tr>
<tr><td><code id="pwd_sample_+3A_nearest">nearest</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the pair with the smallest difference in distance to their nearest <code>reference</code> point is selected. If <code>FALSE</code>, a random point from the valid pairs (with a difference in distance below the threshold defined by <code>tr</code>) is selected (generally leading to higher SSB</p>
</td></tr>
<tr><td><code id="pwd_sample_+3A_lonlat">lonlat</code></td>
<td>
<p> Logical. Use <code>TRUE</code> if the coordinates are spherical (in degrees), and use <code>FALSE</code> if they are planar </p>
</td></tr>
<tr><td><code id="pwd_sample_+3A_warn">warn</code></td>
<td>
<p> Logical. If <code>TRUE</code> a warning is given if <code>nrow(fixed) &lt; nrow(sample)</code> </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of nrow(fixed) and ncol(n), that indicates, for each point (row) in <code>fixed</code> which point(s) in <code>sample</code> it is paired to; or <code>NA</code> if no suitable pair was available.
</p>


<h3>References</h3>

<p>Hijmans, R.J., 2012. Cross-validation of species distribution models: removing spatial sorting bias and calibration with a null-model. Ecology 93: 679-688
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ref &lt;- matrix(c(-54.5,-38.5, 2.5, -9.5, -45.5, 1.5, 9.5, 4.5, -10.5, -10.5), ncol=2)
fix &lt;- matrix(c(-56.5, -30.5, -6.5, 14.5, -25.5, -48.5, 14.5, -2.5, 14.5,
               -11.5, -17.5, -11.5), ncol=2)
r &lt;- rast()
ext(r) &lt;- c(-110, 110, -45, 45)
r[] &lt;- 1
set.seed(0)
sam &lt;- spatSample(r, 50, xy=TRUE, as.points=TRUE)

plot(sam, pch='x')
points(ref, col='red', pch=18, cex=2)
points(fix, col='blue', pch=20, cex=2)

i &lt;- pwd_sample(fix, sam, ref, lonlat=TRUE)
i
sfix &lt;- fix[!is.na(i), ]
ssam &lt;- sam[i[!is.na(i)], ]
ssam

plot(sam, pch='x', cex=0)
points(ssam, pch='x')
points(ref, col='red', pch=18, cex=2)
points(sfix, col='blue', pch=20, cex=2)

# try to get 3 pairs for each point in 'fixed'
pwd_sample(fix, sam, ref, lonlat=TRUE, n=3)
</code></pre>

<hr>
<h2 id='pycnophy'>
Pycnophylactic interpolation.
</h2><span id='topic+pycnophy'></span>

<h3>Description</h3>

<p>Given a <code>SpatVector</code> of polygons and population data for each polygon, compute a population density estimate based on Tobler's pycnophylactic interpolation algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pycnophy(x, v, pop, r = 0.2, converge = 3, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pycnophy_+3A_x">x</code></td>
<td>
<p>SpatRaster to interpolate to</p>
</td></tr>
<tr><td><code id="pycnophy_+3A_v">v</code></td>
<td>
<p>SpatVector of polygons</p>
</td></tr>
<tr><td><code id="pycnophy_+3A_pop">pop</code></td>
<td>
<p>Either a character (name in <code>v</code>) or a numeric vector of length <code>nrow(v)</code></p>
</td></tr>
<tr><td><code id="pycnophy_+3A_r">r</code></td>
<td>
<p> A relaxation parameter for the iterative step in the pycnophylactic algorithm.  Prevents over-compensation in the smoothing step.  In practice the default value works well</p>
</td></tr>
<tr><td><code id="pycnophy_+3A_converge">converge</code></td>
<td>
<p> A convergence parameter, informing the decision on when iterative improvements on the smooth surface have converged sufficiently - see details</p>
</td></tr>
<tr><td><code id="pycnophy_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> the function report the maximum change in any grid cell value for each iterative step</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method uses an iterative approach, and for each iteration notes the maximum change in a pixel.  When this value falls below a certain level (10^(-converge) times the largest initial grid cell value) the iteration stops.  
</p>


<h3>Value</h3>

<p>SpatRaster 
</p>


<h3>Note</h3>

<p>Pycnophylatic interpolation has the property that the sum of the estimated values associated with all of the pixels in any polygon equals the supplied population for that polygon.  A further property is that all pixel values are greater than or equal to zero.  The method is generally used to obtain pixel-based population estimates when total populations for a set of irregular polygons (eg. counties) are known.
</p>


<h3>Author(s)</h3>

<p>Chris Brunsdon (adapted for terra objects by Robert Hijmans)
</p>


<h3>References</h3>

<p>Tobler, W.R. (1979) <em>Smooth Pycnophylactic Interpolation for Geographical Regions</em>. Journal of the American Statistical Association, v74(367) pp. 519-530.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- system.file("ex/lux.shp", package="terra")
v &lt;- vect(f)
r &lt;- rast(v, resolution = 0.01)
p &lt;- pycnophy(r, v, "POP", converge=3, verbose=FALSE)
plot(p); lines(v)
</code></pre>

<hr>
<h2 id='RMSE'>
Root Mean Square Error
</h2><span id='topic+RMSE'></span><span id='topic+RMSE_null'></span>

<h3>Description</h3>

<p>Compute the Root Mean Square Error (RMSE)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSE(obs, prd, na.rm=FALSE)

RMSE_null(obs, prd, na.rm=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSE_+3A_obs">obs</code></td>
<td>
<p>observed values</p>
</td></tr>
<tr><td><code id="RMSE_+3A_prd">prd</code></td>
<td>
<p>predicted values</p>
</td></tr>
<tr><td><code id="RMSE_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. If <code>TRUE</code>, <code>NA</code>s are removed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric
</p>

<hr>
<h2 id='SDM'>Class &quot;SDM&quot;</h2><span id='topic+SDM-class'></span>

<h3>Description</h3>

<p>Parent class for a number of models defined in the predicts package. This is a virtual Class, no objects may be direclty created from it. 
</p>

<hr>
<h2 id='threshold'> Find a threshold </h2><span id='topic+threshold'></span><span id='topic+threshold+2CpaModelEvaluation-method'></span>

<h3>Description</h3>

 
<p>Find a threshold (cut-off) to transform model predictions (probabilities, distances, or similar values) to a binary score (presence or absence). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'paModelEvaluation'
threshold(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="threshold_+3A_x">x</code></td>
<td>
<p>paModelEvaluation object (see <code><a href="#topic+pa_evaluate">pa_evaluate</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with the following columns:
</p>
<p>kappa: the threshold at which kappa is highest (&quot;max kappa&quot;)
</p>
<p>spec_sens: the threshold at which the sum of the sensitivity (true positive rate) and specificity (true negative rate) is highest
</p>
<p>no_omission: the highest threshold at which there is no omission 
</p>
<p>prevalence: modeled prevalence is closest to observed prevalence
</p>
<p>equal_sens_spec: equal sensitivity and specificity
</p>


<h3>Author(s)</h3>

<p>Robert J. Hijmans and Diego Nieto-Lugilde
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pa_evaluate">pa_evaluate</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## See ?maxent for an example with real data.
# this is a contrived example:
# p has the predicted values for 50 known cases (locations)
# with presence of the phenomenon (species)
p &lt;- rnorm(50, mean=0.7, sd=0.3)
# b has the predicted values for 50 background locations (or absence)
a &lt;- rnorm(50, mean=0.4, sd=0.4)
e &lt;- pa_evaluate(p=p, a=a)

threshold(e)
</code></pre>

<hr>
<h2 id='varImportance'>
Get variable importance
</h2><span id='topic+varImportance'></span>

<h3>Description</h3>

<p>Get variable importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varImportance(model, data, vars=colnames(data), n=10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varImportance_+3A_model">model</code></td>
<td>
<p>a model object</p>
</td></tr>
<tr><td><code id="varImportance_+3A_data">data</code></td>
<td>
<p>data.frame with data for all model variables</p>
</td></tr>
<tr><td><code id="varImportance_+3A_vars">vars</code></td>
<td>
<p>character. The variables of interest</p>
</td></tr>
<tr><td><code id="varImportance_+3A_n">n</code></td>
<td>
<p>positive integer. Number of simulations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>named numeric vector
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
