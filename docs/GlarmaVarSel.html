<!DOCTYPE html><html><head><title>Help for package GlarmaVarSel</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GlarmaVarSel}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#GlarmaVarSel-package'>
<p>Variable Selection in Sparse GLARMA Models</p></a></li>
<li><a href='#grad_hess_beta'>
<p>Gradient and Hessian of the log-likelihood with respect to beta</p></a></li>
<li><a href='#grad_hess_gamma'>
<p>Gradient and Hessian of the log-likelihood with respect to gamma</p></a></li>
<li><a href='#NR_gamma'>
<p>Newton-Raphson method for estimation of gamma</p></a></li>
<li><a href='#variable_selection'>
<p>Variable selection</p></a></li>
<li><a href='#Y'>
<p>Observation matrix Y</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Selection in Sparse GLARMA Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-09-15</td>
</tr>
<tr>
<td>Author:</td>
<td>M. Gomtsyan, C. Levy-Leduc, S. Ouadah, L. Sansonnet</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marina Gomtsyan &lt;marina.gomtsyan@agroparistech.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs variable selection in high-dimensional sparse GLARMA models. For further details we refer the reader to the paper Gomtsyan et al. (2020), &lt;<a href="https://arxiv.org/abs/2007.08623v1">arXiv:2007.08623v1</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), Matrix, glmnet, stats, ggplot2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, markdown, formatR, doMC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-15 15:26:37 UTC; marina</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-16 07:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='GlarmaVarSel-package'>
Variable Selection in Sparse GLARMA Models
</h2><span id='topic+GlarmaVarSel-package'></span><span id='topic+GlarmaVarSel'></span>

<h3>Description</h3>

<p>GlarmaVarSel consists of four functions: &quot;variable_selection.R&quot;, &quot;grad_hess_beta.R&quot;, &quot;grad_hess_gamma.R&quot; and &quot;NR_gamma.R&quot;
For further information on how to use these functions, 
we refer the reader to the vignette of the package.
</p>


<h3>Details</h3>

<p>GlarmaVarSel consists of four functions: &quot;variable_selection.R&quot;, &quot;grad_hess_beta.R&quot;, &quot;grad_hess_gamma.R&quot; and &quot;NR_gamma.R&quot;
For further information on how to use these functions, 
we refer the reader to the vignette of the package.
</p>


<h3>Author(s)</h3>

<p>Marina Gomtsyan, Celine Levy-Leduc, Sarah Ouadah, Laure Sansonnet
</p>
<p>Maintainer: Marina Gomtsyan &lt;marina.gomtsyan@agroparistech.fr&gt;
</p>


<h3>References</h3>

<p>M. Gomtsyan et al. &quot;Variable selection in sparse GLARMA models&quot;, arXiv:2007.08623v1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=50
p=30
X = matrix(NA,(p+1),n)
f = 1/0.7
for(t in 1:n){X[,t]&lt;-c(1,cos(2*pi*(1:(p/2))*t*f/n),sin(2*pi*(1:(p/2))*t*f/n))}
gamma0 = c(0)
data(Y)
result = variable_selection(Y, X, gamma0, k_max=2, n_iter=100, method="min",
nb_rep_ss=1000, threshold=0.7, parallel=FALSE, nb.cores=1)
beta_est = result$beta_est
Estim_active = result$estim_active
gamma_est = result$gamma_est    
</code></pre>

<hr>
<h2 id='grad_hess_beta'>
Gradient and Hessian of the log-likelihood with respect to beta
</h2><span id='topic+grad_hess_beta'></span>

<h3>Description</h3>

<p>This function calculates the gradient and Hessian of the log-likelihood with
respect to beta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad_hess_beta(Y, X, beta0, gamma0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grad_hess_beta_+3A_y">Y</code></td>
<td>

<p>Observation matrix
</p>
</td></tr>
<tr><td><code id="grad_hess_beta_+3A_x">X</code></td>
<td>

<p>Design matrix
</p>
</td></tr>
<tr><td><code id="grad_hess_beta_+3A_beta0">beta0</code></td>
<td>

<p>Initial beta vector
</p>
</td></tr>
<tr><td><code id="grad_hess_beta_+3A_gamma0">gamma0</code></td>
<td>

<p>Initial gamma vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>grad_L_beta</code></td>
<td>

<p>Vector of the gradient of L with respect to beta
</p>
</td></tr>
<tr><td><code>hess_L_beta</code></td>
<td>

<p>Matrix of the Hessian of L with respect to beta
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marina Gomtsyan, Celine Levy-Leduc, Sarah Ouadah, Laure Sansonnet
</p>
<p>Maintainer: Marina Gomtsyan &lt;marina.gomtsyan@agroparistech.fr&gt;
</p>


<h3>References</h3>

<p>M. Gomtsyan et al. &quot;Variable selection in sparse GLARMA models&quot;, arXiv:2007.08623v1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=50
p=30
X = matrix(NA,(p+1),n)
f = 1/0.7
for(t in 1:n){X[,t]&lt;-c(1,cos(2*pi*(1:(p/2))*t*f/n),sin(2*pi*(1:(p/2))*t*f/n))}
gamma0 = c(0)
data(Y)
glm_pois&lt;-glm(Y~t(X)[,2:(p+1)],family = poisson)
beta0&lt;-as.numeric(glm_pois$coefficients)
result = grad_hess_beta(Y, X, beta0, gamma0)
grad = result$grad_L_beta
Hessian = result$hess_L_beta
</code></pre>

<hr>
<h2 id='grad_hess_gamma'>
Gradient and Hessian of the log-likelihood with respect to gamma
</h2><span id='topic+grad_hess_gamma'></span>

<h3>Description</h3>

<p>This function calculates the gradient and Hessian of the log-likelihood with
respect to gamma
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad_hess_gamma(Y, X, beta0, gamma0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grad_hess_gamma_+3A_y">Y</code></td>
<td>

<p>Observation matrix
</p>
</td></tr>
<tr><td><code id="grad_hess_gamma_+3A_x">X</code></td>
<td>

<p>Design matrix
</p>
</td></tr>
<tr><td><code id="grad_hess_gamma_+3A_beta0">beta0</code></td>
<td>

<p>Initial beta vector
</p>
</td></tr>
<tr><td><code id="grad_hess_gamma_+3A_gamma0">gamma0</code></td>
<td>

<p>Initial gamma vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>grad_L_gamma</code></td>
<td>

<p>Vector of the gradient of L with respect to gamma
</p>
</td></tr>
<tr><td><code>hess_L_gamma</code></td>
<td>

<p>Matrix of the Hessian of L with respect to gamma
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marina Gomtsyan, Celine Levy-Leduc, Sarah Ouadah, Laure Sansonnet
</p>
<p>Maintainer: Marina Gomtsyan &lt;marina.gomtsyan@agroparistech.fr&gt;
</p>


<h3>References</h3>

<p>M. Gomtsyan et al. &quot;Variable selection in sparse GLARMA models&quot;, arXiv:2007.08623v1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=50
p=30
X = matrix(NA,(p+1),n)
f = 1/0.7
for(t in 1:n){X[,t]&lt;-c(1,cos(2*pi*(1:(p/2))*t*f/n),sin(2*pi*(1:(p/2))*t*f/n))}
gamma0 = c(0)
data(Y)
glm_pois&lt;-glm(Y~t(X)[,2:(p+1)],family = poisson)
beta0&lt;-as.numeric(glm_pois$coefficients) 
result = grad_hess_gamma(Y, X, beta0, gamma0)
grad = result$grad_L_gamma
Hessian = result$hess_L_gamma
</code></pre>

<hr>
<h2 id='NR_gamma'>
Newton-Raphson method for estimation of gamma
</h2><span id='topic+NR_gamma'></span>

<h3>Description</h3>

<p>This function estimates gamma with Newton-Raphson method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NR_gamma(Y, X, beta0, gamma0, n_iter)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NR_gamma_+3A_y">Y</code></td>
<td>

<p>Observation matrix
</p>
</td></tr>
<tr><td><code id="NR_gamma_+3A_x">X</code></td>
<td>

<p>Design matrix
</p>
</td></tr> 
<tr><td><code id="NR_gamma_+3A_beta0">beta0</code></td>
<td>

<p>Initial beta vector
</p>
</td></tr>
<tr><td><code id="NR_gamma_+3A_gamma0">gamma0</code></td>
<td>

<p>Initial gamma vector
</p>
</td></tr>
<tr><td><code id="NR_gamma_+3A_n_iter">n_iter</code></td>
<td>

<p>Number of iterations of the algorithm. Default=100
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>gamma</code></td>
<td>

<p>Estimated gamma vector
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marina Gomtsyan, Celine Levy-Leduc, Sarah Ouadah, Laure Sansonnet
</p>
<p>Maintainer: Marina Gomtsyan &lt;marina.gomtsyan@agroparistech.fr&gt;
</p>


<h3>References</h3>

<p>M. Gomtsyan et al. &quot;Variable selection in sparse GLARMA models&quot;, arXiv:2007.08623v1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=50
p=30
X = matrix(NA,(p+1),n)
f = 1/0.7
for(t in 1:n){X[,t]&lt;-c(1,cos(2*pi*(1:(p/2))*t*f/n),sin(2*pi*(1:(p/2))*t*f/n))}
gamma0 = c(0)
data(Y)
glm_pois&lt;-glm(Y~t(X)[,2:(p+1)],family = poisson)
beta0&lt;-as.numeric(glm_pois$coefficients)
gamma_est = NR_gamma(Y, X, beta0, gamma0, n_iter=100)
</code></pre>

<hr>
<h2 id='variable_selection'>
Variable selection
</h2><span id='topic+variable_selection'></span>

<h3>Description</h3>

<p>This function performs variable selection, estimates a new vector beta and a new vector gamma
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_selection(Y, X, gamma0, k_max = 2, n_iter = 100, method = "min", 
  nb_rep_ss = 1000, threshold = 0.8, parallel = FALSE, nb.cores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variable_selection_+3A_y">Y</code></td>
<td>

<p>Observation matrix
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_x">X</code></td>
<td>

<p>Design matrix
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_gamma0">gamma0</code></td>
<td>

<p>Initial gamma vector
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_k_max">k_max</code></td>
<td>

<p>Number of iteration to repeat the whole algorithm
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_n_iter">n_iter</code></td>
<td>

<p>Number of iteration for Newton-Raphson algorithm
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_method">method</code></td>
<td>

<p>Stability selection method: &quot;fast&quot;, &quot;min&quot; or &quot;cv&quot;. In &quot;min&quot; the smallest lambda is chosen, in &quot;cv&quot; cross-validation lambda is chosen for stability selection. &quot;fast&quot; is a fater stability selection approach. The default is &quot;min&quot;
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_nb_rep_ss">nb_rep_ss</code></td>
<td>

<p>Number of replications in stability selection step. The default is 1000
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_threshold">threshold</code></td>
<td>

<p>Threshold for stability selection. The default is 0.9
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_parallel">parallel</code></td>
<td>

<p>Whether to parallelize stability selection step or not. The default is FALSE
</p>
</td></tr>
<tr><td><code id="variable_selection_+3A_nb.cores">nb.cores</code></td>
<td>

<p>Number of cores for parallelization. The default is 1
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>estim_active</code></td>
<td>
<p>Estimated active coefficients</p>
</td></tr>
<tr><td><code>beta_est</code></td>
<td>
<p>Vector of estimated beta values</p>
</td></tr>
<tr><td><code>gamma_est</code></td>
<td>
<p>Vector of estimated gamma values</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Marina Gomtsyan, Celine Levy-Leduc, Sarah Ouadah, Laure Sansonnet
</p>
<p>Maintainer: Marina Gomtsyan &lt;marina.gomtsyan@agroparistech.fr&gt;
</p>


<h3>References</h3>

<p>M. Gomtsyan et al. &quot;Variable selection in sparse GLARMA models&quot;, arXiv:2007.08623v1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=50
p=30
X = matrix(NA,(p+1),n)
f = 1/0.7
for(t in 1:n){X[,t]&lt;-c(1,cos(2*pi*(1:(p/2))*t*f/n),sin(2*pi*(1:(p/2))*t*f/n))}
gamma0 = c(0)
data(Y)
result = variable_selection(Y, X, gamma0, k_max=2, n_iter=100, method="min",
nb_rep_ss=1000, threshold=0.7, parallel=FALSE, nb.cores=1)
beta_est = result$beta_est
Estim_active = result$estim_active
gamma_est = result$gamma_est    
</code></pre>

<hr>
<h2 id='Y'>
Observation matrix Y
</h2><span id='topic+Y'></span>

<h3>Description</h3>

<p>An example of observation matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Y")</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:50] 11 8 3 3 3 4 4 4 3 1 ...
</p>


<h3>References</h3>

<p>M. Gomtsyan et al. &quot;Variable selection in sparse GLARMA models&quot;, arXiv:2007.08623v1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Y)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
