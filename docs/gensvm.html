<!DOCTYPE html><html><head><title>Help for package gensvm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gensvm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gensvm-package'><p>GenSVM: A Generalized Multiclass Support Vector Machine</p></a></li>
<li><a href='#coef.gensvm'><p>Get the coefficients of the fitted GenSVM model</p></a></li>
<li><a href='#coef.gensvm.grid'><p>Get the parameter grid from a GenSVM Grid object</p></a></li>
<li><a href='#fitted.gensvm'><p>Show fitted labels for the GenSVM model</p></a></li>
<li><a href='#fitted.gensvm.grid'><p>Fitted labels for the GenSVMGrid class</p></a></li>
<li><a href='#gensvm'><p>Fit the GenSVM model</p></a></li>
<li><a href='#gensvm.accuracy'><p>Compute the accuracy score</p></a></li>
<li><a href='#gensvm.generate.cv.idx'><p>Generate a vector of cross-validation indices</p></a></li>
<li><a href='#gensvm.grid'><p>Cross-validated grid search for GenSVM</p></a></li>
<li><a href='#gensvm.load.full.grid'><p>Load a large parameter grid for the GenSVM grid search</p></a></li>
<li><a href='#gensvm.load.small.grid'><p>Load the small parameter grid for the GenSVM grid search</p></a></li>
<li><a href='#gensvm.load.tiny.grid'><p>Load a tiny parameter grid for the GenSVM grid search</p></a></li>
<li><a href='#gensvm.maxabs.scale'><p>Scale each column of a matrix by its maximum absolute value</p></a></li>
<li><a href='#gensvm.rank.score'><p>Compute the ranks for the numbers in a given vector</p></a></li>
<li><a href='#gensvm.refit'><p>Train an already fitted model on new data</p></a></li>
<li><a href='#gensvm.train.test.split'><p>Create a train/test split of a dataset</p></a></li>
<li><a href='#gensvm.validate.param.grid'><p>[internal] Validate parameter grid</p></a></li>
<li><a href='#gensvm.validate.params'><p>[internal] Validate parameters</p></a></li>
<li><a href='#plot.gensvm'><p>Plot the simplex space of the fitted GenSVM model</p></a></li>
<li><a href='#plot.gensvm.grid'><p>Plot the simplex space of the best fitted model in the GenSVMGrid</p></a></li>
<li><a href='#predict.gensvm'><p>Predict class labels with the GenSVM model</p></a></li>
<li><a href='#predict.gensvm.grid'><p>Predict class labels from the GenSVMGrid class</p></a></li>
<li><a href='#print.gensvm'><p>Print the fitted GenSVM model</p></a></li>
<li><a href='#print.gensvm.grid'><p>Print the fitted GenSVMGrid model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.1.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-01-28</td>
</tr>
<tr>
<td>Title:</td>
<td>A Generalized Multiclass Support Vector Machine</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gertjan van den Burg &lt;gertjanvandenburg@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The GenSVM classifier is a generalized multiclass support vector
	machine (SVM). This classifier aims to find decision boundaries that
	separate the classes with as wide a margin as possible. In GenSVM, the
	loss function is very flexible in the way that misclassifications are
	penalized.  This allows the user to tune the classifier to the dataset
	at hand and potentially obtain higher classification accuracy than
	alternative multiclass SVMs.  Moreover, this flexibility means that
	GenSVM has a number of other multiclass SVMs as special cases. One of
	the other advantages of GenSVM is that it is trained in the primal
	space, allowing the use of warm starts during optimization.  This
	means that for common tasks such as cross validation or repeated model
	fitting, GenSVM can be trained very quickly. Based on: G.J.J. van den
	Burg and P.J.F. Groenen (2018) <a href="https://www.jmlr.org/papers/v17/14-526.html">https://www.jmlr.org/papers/v17/14-526.html</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Classification/MSC:</td>
<td>62H30, 68T10</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/GjjvdBurg/RGenSVM">https://github.com/GjjvdBurg/RGenSVM</a>
<a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/GjjvdBurg/RGenSVM">https://github.com/GjjvdBurg/RGenSVM</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-01-28 11:41:37 UTC; gertjan</td>
</tr>
<tr>
<td>Author:</td>
<td>Gertjan van den Burg [aut, cre],
  Patrick Groenen [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-01-28 12:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='gensvm-package'>GenSVM: A Generalized Multiclass Support Vector Machine</h2><span id='topic+gensvm-package'></span><span id='topic+gensvm.package'></span>

<h3>Description</h3>

<p>The GenSVM classifier is a generalized multiclass support vector machine 
(SVM). This classifier aims to find decision boundaries that separate the 
classes with as wide a margin as possible. In GenSVM, the loss functions 
that measures how misclassifications are counted is very flexible.  This 
allows the user to tune the classifier to the dataset at hand and 
potentially obtain higher classification accuracy. Moreover, this 
flexibility means that GenSVM has a number of alternative multiclass SVMs as 
special cases. One of the other advantages of GenSVM is that it is trained 
in the primal space, allowing the use of warm starts during optimization.  
This means that for common tasks such as cross validation or repeated model 
fitting, GenSVM can be trained very quickly.
</p>


<h3>Details</h3>

<p>This package provides functions for training the GenSVM model either as a 
separate model or through a cross-validated parameter grid search. In both 
cases the GenSVM C library is used for speed. Auxiliary functions for 
evaluating and using the model are also provided.
</p>


<h3>GenSVM functions</h3>

<p>The main GenSVM functions are:
</p>

<dl>
<dt><code><a href="#topic+gensvm">gensvm</a></code></dt><dd><p>Fit a GenSVM model for specific model 
parameters.</p>
</dd>
<dt><code><a href="#topic+gensvm.grid">gensvm.grid</a></code></dt><dd><p>Run a cross-validated grid search for 
GenSVM.</p>
</dd>
</dl>

<p>For the GenSVM and GenSVMGrid models the following two functions are 
available. When applied to a GenSVMGrid object, the function is applied to 
the best GenSVM model.
</p>

<dl>
<dt><code><a href="graphics.html#topic+plot">plot</a></code></dt><dd><p>Plot the low-dimensional <em>simplex</em> space 
where the decision boundaries are fixed (for problems with 3 classes).</p>
</dd>
<dt><code><a href="stats.html#topic+predict">predict</a></code></dt><dd><p>Predict the class labels of new data using the 
GenSVM model.</p>
</dd>
</dl>

<p>Moreover, for the GenSVM and GenSVMGrid models a <code>coef</code> function is 
defined:
</p>

<dl>
<dt><code><a href="#topic+coef.gensvm">coef.gensvm</a></code></dt><dd><p>Get the coefficients of the fitted GenSVM 
model.</p>
</dd>
<dt><code><a href="#topic+coef.gensvm.grid">coef.gensvm.grid</a></code></dt><dd><p>Get the parameter grid of the GenSVM 
grid search.</p>
</dd>
</dl>

<p>The following utility functions are also included:
</p>

<dl>
<dt><code><a href="#topic+gensvm.accuracy">gensvm.accuracy</a></code></dt><dd><p>Compute the accuracy score between true 
and predicted class labels</p>
</dd>
<dt><code><a href="#topic+gensvm.maxabs.scale">gensvm.maxabs.scale</a></code></dt><dd><p>Scale each column of the dataset by 
its maximum absolute value, preserving sparsity and mapping the data to [-1, 
1]</p>
</dd>
<dt><code><a href="#topic+gensvm.train.test.split">gensvm.train.test.split</a></code></dt><dd><p>Split a dataset into a training 
and testing sample</p>
</dd>
<dt><code><a href="#topic+gensvm.refit">gensvm.refit</a></code></dt><dd><p>Refit a fitted GenSVM model with slightly 
different parameters or on a different dataset</p>
</dd>
</dl>



<h3>Kernels in GenSVM</h3>

<p>GenSVM can be used for both linear and nonlinear multiclass support vector 
machine classification. In general, linear classification will be faster but 
depending on the dataset higher classification performance can be achieved 
using a nonlinear kernel.
</p>
<p>The following nonlinear kernels are implemented in the GenSVM package:
</p>

<dl>
<dt>RBF</dt><dd><p>The Radial Basis Function kernel is a well-known kernel function 
based on the Euclidean distance between objects. It is defined as
</p>
<p style="text-align: center;"><code class="reqn">
     k(x_i, x_j) = exp( -\gamma || x_i - x_j ||^2 )
     </code>
</p>

</dd>
<dt>Polynomial</dt><dd><p>A polynomial kernel can also be used in GenSVM. This 
kernel function is implemented very generally and therefore takes three 
parameters (<code>coef</code>, <code>gamma</code>, and <code>degree</code>). It is defined 
as:
</p>
<p style="text-align: center;"><code class="reqn">
     k(x_i, x_j) = ( \gamma x_i' x_j + coef)^{degree}
 </code>
</p>

</dd>
<dt>Sigmoid</dt><dd><p>The sigmoid kernel is the final kernel implemented in 
GenSVM. This kernel has two parameters and is implemented as follows:
</p>
<p style="text-align: center;"><code class="reqn">
     k(x_i, x_j) = \tanh( \gamma x_i' x_j + coef)
 </code>
</p>

</dd>
</dl>



<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm.grid">gensvm.grid</a></code>
</p>

<hr>
<h2 id='coef.gensvm'>Get the coefficients of the fitted GenSVM model</h2><span id='topic+coef.gensvm'></span>

<h3>Description</h3>

<p>Returns the model coefficients of the GenSVM object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.gensvm_+3A_object">object</code></td>
<td>
<p>a <code>gensvm</code> object</p>
</td></tr>
<tr><td><code id="coef.gensvm_+3A_...">...</code></td>
<td>
<p>further arguments are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients of the GenSVM model. This is a matrix of size
<code class="reqn">(n_{features} + 1) x (n_{classes} - 1)</code>. This matrix is used to project 
the input data to a low dimensional space using the equation: <code class="reqn">XW + t</code> 
where <code class="reqn">X</code> is the input matrix, <code class="reqn">t</code> is the first row of the matrix 
returned by this function, and <code class="reqn">W</code> is the <code class="reqn">n_{features} x 
(n_{classes} - 1)</code> matrix formed by the remaining rows.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+plot.gensvm">plot.gensvm</a></code>, 
<code><a href="#topic+predict.gensvm">predict.gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

fit &lt;- gensvm(x, y)
V &lt;- coef(fit)

</code></pre>

<hr>
<h2 id='coef.gensvm.grid'>Get the parameter grid from a GenSVM Grid object</h2><span id='topic+coef.gensvm.grid'></span>

<h3>Description</h3>

<p>Returns the parameter grid of a <code>gensvm.grid</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm.grid'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.gensvm.grid_+3A_object">object</code></td>
<td>
<p>a <code>gensvm.grid</code> object</p>
</td></tr>
<tr><td><code id="coef.gensvm.grid_+3A_...">...</code></td>
<td>
<p>further arguments are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The parameter grid of the GenSVMGrid object as a data frame.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- iris[, -5]
y &lt;- iris[, 5]

grid &lt;- gensvm.grid(x, y)
pg &lt;- coef(grid)


</code></pre>

<hr>
<h2 id='fitted.gensvm'>Show fitted labels for the GenSVM model</h2><span id='topic+fitted.gensvm'></span>

<h3>Description</h3>

<p>This function shows the fitted class labels of training data 
using a fitted GenSVM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.gensvm_+3A_object">object</code></td>
<td>
<p>Fitted <code>gensvm</code> object</p>
</td></tr>
<tr><td><code id="fitted.gensvm_+3A_...">...</code></td>
<td>
<p>further arguments are passed to predict</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of class labels, with the same type as the original class 
labels.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.gensvm">plot.gensvm</a></code>, <code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, 
<code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# fit GenSVM and compute training set predictions
fit &lt;- gensvm(x, y)
yhat &lt;- fitted(fit)

# compute the accuracy with gensvm.accuracy
gensvm.accuracy(y, yhat)

</code></pre>

<hr>
<h2 id='fitted.gensvm.grid'>Fitted labels for the GenSVMGrid class</h2><span id='topic+fitted.gensvm.grid'></span>

<h3>Description</h3>

<p>Wrapper to get the fitted class labels from the best estimator 
of the fitted GenSVMGrid model. Only works if refit was enabled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm.grid'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.gensvm.grid_+3A_object">object</code></td>
<td>
<p>A <code>gensvm.grid</code> object</p>
</td></tr>
<tr><td><code id="fitted.gensvm.grid_+3A_...">...</code></td>
<td>
<p>further arguments are passed to fitted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of class labels, with the same type as the original class 
labels.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.gensvm">plot.gensvm</a></code>, <code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, 
<code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# fit GenSVM and compute training set predictions
fit &lt;- gensvm(x, y)
yhat &lt;- fitted(fit)

# compute the accuracy with gensvm.accuracy
gensvm.accuracy(y, yhat)

</code></pre>

<hr>
<h2 id='gensvm'>Fit the GenSVM model</h2><span id='topic+gensvm'></span>

<h3>Description</h3>

<p>Fits the Generalized Multiclass Support Vector Machine model
with the given parameters. See the package documentation
(<code><a href="#topic+gensvm-package">gensvm-package</a></code>) for more general information about GenSVM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm(
  x,
  y,
  p = 1,
  lambda = 1e-08,
  kappa = 0,
  epsilon = 1e-06,
  weights = "unit",
  kernel = "linear",
  gamma = "auto",
  coef = 1,
  degree = 2,
  kernel.eigen.cutoff = 1e-08,
  verbose = FALSE,
  random.seed = NULL,
  max.iter = 1e+08,
  seed.V = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm_+3A_x">x</code></td>
<td>
<p>data matrix with the predictors. <br /><br />
Note that for SVMs categorical features should be converted to binary dummy
features. This can be done with using the <code><a href="stats.html#topic+model.matrix">model.matrix</a></code>
function (i.e. <code>model.matrix( ~ var - 1)</code>).</p>
</td></tr>
<tr><td><code id="gensvm_+3A_y">y</code></td>
<td>
<p>class labels</p>
</td></tr>
<tr><td><code id="gensvm_+3A_p">p</code></td>
<td>
<p>parameter for the L_p norm of the loss function (1.0 &lt;= p &lt;= 2.0)</p>
</td></tr>
<tr><td><code id="gensvm_+3A_lambda">lambda</code></td>
<td>
<p>regularization parameter for the loss function (lambda &gt; 0)</p>
</td></tr>
<tr><td><code id="gensvm_+3A_kappa">kappa</code></td>
<td>
<p>parameter for the hinge function in the loss function (kappa &gt;
-1.0)</p>
</td></tr>
<tr><td><code id="gensvm_+3A_epsilon">epsilon</code></td>
<td>
<p>Stopping parameter for the optimization algorithm. The 
optimization will stop if the relative change in the loss function is below 
this value.</p>
</td></tr>
<tr><td><code id="gensvm_+3A_weights">weights</code></td>
<td>
<p>type or vector of instance weights to use. Options are 'unit'
for unit weights and 'group' for group size correction weights (eq. 4 in the
paper). Alternatively, a vector of weights can be provided.</p>
</td></tr>
<tr><td><code id="gensvm_+3A_kernel">kernel</code></td>
<td>
<p>the kernel type to use in the classifier. It must be one of
'linear', 'poly', 'rbf', or 'sigmoid'. See the section &quot;Kernels in GenSVM&quot;
in <code><a href="#topic+gensvm-package">gensvm-package</a></code> for more info.</p>
</td></tr>
<tr><td><code id="gensvm_+3A_gamma">gamma</code></td>
<td>
<p>kernel parameter for the rbf, polynomial, and sigmoid kernel.
If gamma is 'auto', then 1/n_features will be used.</p>
</td></tr>
<tr><td><code id="gensvm_+3A_coef">coef</code></td>
<td>
<p>parameter for the polynomial and sigmoid kernel.</p>
</td></tr>
<tr><td><code id="gensvm_+3A_degree">degree</code></td>
<td>
<p>parameter for the polynomial kernel</p>
</td></tr>
<tr><td><code id="gensvm_+3A_kernel.eigen.cutoff">kernel.eigen.cutoff</code></td>
<td>
<p>Cutoff point for the reduced eigendecomposition
used with kernel-GenSVM. Eigenvectors for which the ratio between their
corresponding eigenvalue and the largest eigenvalue is smaller than this
cutoff value will be dropped.</p>
</td></tr>
<tr><td><code id="gensvm_+3A_verbose">verbose</code></td>
<td>
<p>Turn on verbose output and fit progress</p>
</td></tr>
<tr><td><code id="gensvm_+3A_random.seed">random.seed</code></td>
<td>
<p>Seed for the random number generator (useful for
reproducible output)</p>
</td></tr>
<tr><td><code id="gensvm_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations of the optimization algorithm.</p>
</td></tr>
<tr><td><code id="gensvm_+3A_seed.v">seed.V</code></td>
<td>
<p>Matrix to warm-start the optimization algorithm. This is
typically the output of <code>coef(fit)</code>. Note that this function will
silently drop seed.V if the dimensions don't match the provided data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;gensvm&quot; S3 object is returned for which the print, predict, coef,
and plot methods are available. It has the following items:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call that was used to construct the model.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>The value of the lp norm in the loss function</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The regularization parameter used in the model.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>The hinge function parameter used.</p>
</td></tr>
<tr><td><code>epsilon</code></td>
<td>
<p>The stopping criterion used.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>The instance weights type used.</p>
</td></tr>
<tr><td><code>kernel</code></td>
<td>
<p>The kernel function used.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>The value of the gamma parameter of the kernel, if applicable</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>The value of the coef parameter of the kernel, if applicable</p>
</td></tr>
<tr><td><code>degree</code></td>
<td>
<p>The degree of the kernel, if applicable</p>
</td></tr>
<tr><td><code>kernel.eigen.cutoff</code></td>
<td>
<p>The cutoff value of the reduced
eigendecomposition of the kernel matrix.</p>
</td></tr>
<tr><td><code>verbose</code></td>
<td>
<p>Whether or not the model was fitted with progress output</p>
</td></tr>
<tr><td><code>random.seed</code></td>
<td>
<p>The random seed used to seed the model.</p>
</td></tr>
<tr><td><code>max.iter</code></td>
<td>
<p>Maximum number of iterations of the algorithm.</p>
</td></tr>
<tr><td><code>n.objects</code></td>
<td>
<p>Number of objects in the dataset</p>
</td></tr>
<tr><td><code>n.features</code></td>
<td>
<p>Number of features in the dataset</p>
</td></tr>
<tr><td><code>n.classes</code></td>
<td>
<p>Number of classes in the dataset</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>Array with the actual class labels</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>Coefficient matrix</p>
</td></tr>
<tr><td><code>n.iter</code></td>
<td>
<p>Number of iterations performed in training</p>
</td></tr>
<tr><td><code>n.support</code></td>
<td>
<p>Number of support vectors in the final model</p>
</td></tr>
<tr><td><code>training.time</code></td>
<td>
<p>Total training time</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function returns partial results when the computation is interrupted by
the user.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research,
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="base.html#topic+print">print</a></code>, <code><a href="stats.html#topic+predict">predict</a></code>,
<code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# fit using the default parameters and show progress
fit &lt;- gensvm(x, y, verbose=TRUE)

# fit with some changed parameters
fit &lt;- gensvm(x, y, lambda=1e-6)

# Early stopping defined through epsilon
fit &lt;- gensvm(x, y, epsilon=1e-3)

# Early stopping defined through max.iter
fit &lt;- gensvm(x, y, max.iter=1000)

# Nonlinear training
fit &lt;- gensvm(x, y, kernel='rbf', max.iter=1000)
fit &lt;- gensvm(x, y, kernel='poly', degree=2, gamma=1.0, max.iter=1000)

# Setting the random seed and comparing results
fit &lt;- gensvm(x, y, random.seed=123, max.iter=1000)
fit2 &lt;- gensvm(x, y, random.seed=123, max.iter=1000)
all.equal(coef(fit), coef(fit2))


</code></pre>

<hr>
<h2 id='gensvm.accuracy'>Compute the accuracy score</h2><span id='topic+gensvm.accuracy'></span>

<h3>Description</h3>

<p>Compute the accuracy score between the true labels and the 
predicted labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.accuracy(y.true, y.pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm.accuracy_+3A_y.true">y.true</code></td>
<td>
<p>vector of true labels</p>
</td></tr>
<tr><td><code id="gensvm.accuracy_+3A_y.pred">y.pred</code></td>
<td>
<p>vector of predicted labels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The accuracy as a value in the range [0.0, 1.0]
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, <code><a href="#topic+predict.gensvm">predict.gensvm</a></code>, 
<code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

fit &lt;- gensvm(x, y)
gensvm.accuracy(predict(fit, x), y)

</code></pre>

<hr>
<h2 id='gensvm.generate.cv.idx'>Generate a vector of cross-validation indices</h2><span id='topic+gensvm.generate.cv.idx'></span>

<h3>Description</h3>

<p>This function generates a vector of length <code>n</code> with values from 0 to 
<code>folds-1</code> to mark train and test splits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.generate.cv.idx(n, folds)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm.generate.cv.idx_+3A_n">n</code></td>
<td>
<p>the number of instances</p>
</td></tr>
<tr><td><code id="gensvm.generate.cv.idx_+3A_folds">folds</code></td>
<td>
<p>the number of cross validation folds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an array of length <code>n</code> with values in the range [0, folds-1] 
indicating the test fold of each instance.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm.grid">gensvm.grid</a></code>
</p>

<hr>
<h2 id='gensvm.grid'>Cross-validated grid search for GenSVM</h2><span id='topic+gensvm.grid'></span>

<h3>Description</h3>

<p>This function performs a cross-validated grid search of the 
model parameters to find the best hyperparameter configuration for a given 
dataset. This function takes advantage of GenSVM's ability to use warm 
starts to speed up computation. The function uses the GenSVM C library for 
speed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.grid(
  x,
  y,
  param.grid = "tiny",
  refit = TRUE,
  scoring = NULL,
  cv = 3,
  verbose = 0,
  return.train.score = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm.grid_+3A_x">x</code></td>
<td>
<p>training data matrix. We denote the size of this matrix by 
n_samples x n_features.</p>
</td></tr>
<tr><td><code id="gensvm.grid_+3A_y">y</code></td>
<td>
<p>training vector of class labels of length n_samples. The number of 
unique labels in this vector is denoted by n_classes.</p>
</td></tr>
<tr><td><code id="gensvm.grid_+3A_param.grid">param.grid</code></td>
<td>
<p>String (<code>'tiny'</code>, <code>'small'</code>, or <code>'full'</code>) 
or data frame with parameter configurations to evaluate.  Typically this is 
the output of <code>expand.grid</code>. For more details, see &quot;Using a Parameter 
Grid&quot; below.</p>
</td></tr>
<tr><td><code id="gensvm.grid_+3A_refit">refit</code></td>
<td>
<p>boolean variable. If true, the best model from cross validation 
is fitted again on the entire dataset.</p>
</td></tr>
<tr><td><code id="gensvm.grid_+3A_scoring">scoring</code></td>
<td>
<p>metric to use to evaluate the classifier performance during 
cross validation. The metric should be an R function that takes two 
arguments: y_true and y_pred and that returns a float such that higher 
values are better. If it is NULL, the accuracy score will be used.</p>
</td></tr>
<tr><td><code id="gensvm.grid_+3A_cv">cv</code></td>
<td>
<p>the number of cross-validation folds to use or a vector with the 
same length as <code>y</code> where each unique value denotes a test split.</p>
</td></tr>
<tr><td><code id="gensvm.grid_+3A_verbose">verbose</code></td>
<td>
<p>integer to indicate the level of verbosity (higher is more 
verbose)</p>
</td></tr>
<tr><td><code id="gensvm.grid_+3A_return.train.score">return.train.score</code></td>
<td>
<p>whether or not to return the scores on the 
training splits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;gensvm.grid&quot; S3 object with the following items:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>Call that produced this object</p>
</td></tr>
<tr><td><code>param.grid</code></td>
<td>
<p>Sorted version of the parameter grid used in training</p>
</td></tr>
<tr><td><code>cv.results</code></td>
<td>
<p>A data frame with the cross validation results</p>
</td></tr>
<tr><td><code>best.estimator</code></td>
<td>
<p>If refit=TRUE, this is the GenSVM model fitted with 
the best hyperparameter configuration, otherwise it is NULL</p>
</td></tr>
<tr><td><code>best.score</code></td>
<td>
<p>Mean cross-validated test score for the model with the 
best hyperparameter configuration</p>
</td></tr>
<tr><td><code>best.params</code></td>
<td>
<p>Parameter configuration that provided the highest mean 
cross-validated test score</p>
</td></tr>
<tr><td><code>best.index</code></td>
<td>
<p>Row index of the cv.results data frame that corresponds to 
the best hyperparameter configuration</p>
</td></tr>
<tr><td><code>n.splits</code></td>
<td>
<p>The number of cross-validation splits</p>
</td></tr>
<tr><td><code>n.objects</code></td>
<td>
<p>The number of instances in the data</p>
</td></tr>
<tr><td><code>n.features</code></td>
<td>
<p>The number of features of the data</p>
</td></tr>
<tr><td><code>n.classes</code></td>
<td>
<p>The number of classes in the data</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>Array with the unique classes in the data</p>
</td></tr>
<tr><td><code>total.time</code></td>
<td>
<p>Training time for the grid search</p>
</td></tr>
<tr><td><code>cv.idx</code></td>
<td>
<p>Array with cross validation indices used to split the data</p>
</td></tr>
</table>


<h3>Using a Parameter Grid</h3>

<p>To evaluate certain parameter configurations, a data frame can be supplied 
to the <code>param.grid</code> argument of the function. Such a data frame can 
easily be generated using the R function <code>expand.grid</code>, or could be 
created through other ways to test specific parameter configurations.
</p>
<p>Three parameter grids are predefined:
</p>

<dl>
<dt><code>'tiny'</code></dt><dd><p>This parameter grid is generated by the function 
<code><a href="#topic+gensvm.load.tiny.grid">gensvm.load.tiny.grid</a></code> and is the default parameter grid. It 
consists of parameter configurations that are likely to perform well on 
various datasets.</p>
</dd>
<dt><code>'small'</code></dt><dd><p>This grid is generated by 
<code><a href="#topic+gensvm.load.small.grid">gensvm.load.small.grid</a></code> and generates a data frame with 90 
configurations. It is typically fast to train but contains some 
configurations that are unlikely to perform well. It is included for 
educational purposes.</p>
</dd>
<dt><code>'full'</code></dt><dd><p>This grid loads the parameter grid as used in the 
GenSVM paper. It consists of 342 configurations and is generated by the 
<code><a href="#topic+gensvm.load.full.grid">gensvm.load.full.grid</a></code> function. Note that in the GenSVM paper 
cross validation was done with this parameter grid, but the final training 
step used <code>epsilon=1e-8</code>. The <code><a href="#topic+gensvm.refit">gensvm.refit</a></code> function is 
useful in this scenario.</p>
</dd>
</dl>

<p>When you provide your own parameter grid, beware that only certain column 
names are allowed in the data frame corresponding to parameters for the 
GenSVM model. These names are:
</p>

<dl>
<dt>p</dt><dd><p>Parameter for the lp norm. Must be in [1.0, 2.0].</p>
</dd>
<dt>kappa</dt><dd><p>Parameter for the Huber hinge function. Must be larger than 
-1.</p>
</dd>
<dt>lambda</dt><dd><p>Parameter for the regularization term. Must be larger than 0.</p>
</dd>
<dt>weights</dt><dd><p>Instance weights specification. Allowed values are &quot;unit&quot; for 
unit weights and &quot;group&quot; for group-size correction weights</p>
</dd>
<dt>epsilon</dt><dd><p>Stopping parameter for the algorithm. Must be larger than 0.</p>
</dd>
<dt>max.iter</dt><dd><p>Maximum number of iterations of the algorithm. Must be 
larger than 0.</p>
</dd>
<dt>kernel</dt><dd><p>The kernel to used, allowed values are &quot;linear&quot;, &quot;poly&quot;, 
&quot;rbf&quot;, and &quot;sigmoid&quot;. The default is &quot;linear&quot;</p>
</dd>
<dt>coef</dt><dd><p>Parameter for the &quot;poly&quot; and &quot;sigmoid&quot; kernels. See the section 
&quot;Kernels in GenSVM&quot; in the codeinkgensvm-package page for more info.</p>
</dd>
<dt>degree</dt><dd><p>Parameter for the &quot;poly&quot; kernel. See the section &quot;Kernels in 
GenSVM&quot; in the codeinkgensvm-package page for more info.</p>
</dd>
<dt>gamma</dt><dd><p>Parameter for the &quot;poly&quot;, &quot;rbf&quot;, and &quot;sigmoid&quot; kernels. See the 
section &quot;Kernels in GenSVM&quot; in the codeinkgensvm-package page for more 
info.</p>
</dd>
</dl>

<p>For variables that are not present in the <code>param.grid</code> data frame the 
default parameter values in the <code><a href="#topic+gensvm">gensvm</a></code> function will be used.
</p>
<p>Note that this function reorders the parameter grid to make the warm starts 
as efficient as possible, which is why the param.grid in the result will not 
be the same as the param.grid in the input.
</p>


<h3>Note</h3>

<p>1. This function returns partial results when the computation is interrupted 
by the user.
2. The score.time reported in the results only covers the time needed to 
compute the score from the predictions and true class labels. It does not 
include the time to compute the predictions themselves.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, <code><a href="#topic+print.gensvm.grid">print.gensvm.grid</a></code>, 
<code><a href="#topic+plot.gensvm.grid">plot.gensvm.grid</a></code>, <code><a href="#topic+gensvm">gensvm</a></code>, 
<code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]


# use the default parameter grid
grid &lt;- gensvm.grid(x, y, verbose=TRUE)


# use a smaller parameter grid
pg &lt;- expand.grid(p=c(1.0, 1.5, 2.0), kappa=c(-0.9, 1.0), epsilon=c(1e-3))
grid &lt;- gensvm.grid(x, y, param.grid=pg)

# print the result
print(grid)


# Using a custom scoring function (accuracy as percentage)
acc.pct &lt;- function(yt, yp) { return (100 * sum(yt == yp) / length(yt)) }
grid &lt;- gensvm.grid(x, y, scoring=acc.pct)

# With RBF kernel and very verbose progress printing
pg &lt;- expand.grid(kernel=c('rbf'), gamma=c(1e-2, 1e-1, 1, 1e1, 1e2),
                  lambda=c(1e-8, 1e-6), max.iter=c(5000))
grid &lt;- gensvm.grid(x, y, param.grid=pg, verbose=2)


</code></pre>

<hr>
<h2 id='gensvm.load.full.grid'>Load a large parameter grid for the GenSVM grid search</h2><span id='topic+gensvm.load.full.grid'></span>

<h3>Description</h3>

<p>This loads the parameter grid from the GenSVM paper. It 
consists of 342 configurations and is constructed from all possible 
combinations of the following parameter sets:
</p>
<p><code>p = c(1.0, 1.5, 2.0)</code>
<code>lambda = 2^seq(-18, 18, 2)</code>
<code>kappa = c(-0.9, 0.5, 5.0)</code>
<code>weights = c('unit', 'group')</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.load.full.grid()
</code></pre>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, <code><a href="#topic+gensvm.load.tiny.grid">gensvm.load.tiny.grid</a></code>, 
<code><a href="#topic+gensvm.load.full.grid">gensvm.load.full.grid</a></code>.
</p>

<hr>
<h2 id='gensvm.load.small.grid'>Load the small parameter grid for the GenSVM grid search</h2><span id='topic+gensvm.load.small.grid'></span>

<h3>Description</h3>

<p>This function loads a small parameter grid to use for the 
GenSVM gridsearch. It contains all possible combinations of the following 
parameter sets:
</p>
<p><code>p = c(1.0, 1.5, 2.0)</code>
<code>lambda = c(1e-8, 1e-6, 1e-4, 1e-2, 1)</code>
<code>kappa = c(-0.9, 0.5, 5.0)</code>
<code>weights= c('unit', 'group')</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.load.small.grid()
</code></pre>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, <code><a href="#topic+gensvm.load.tiny.grid">gensvm.load.tiny.grid</a></code>, 
<code><a href="#topic+gensvm.load.small.grid">gensvm.load.small.grid</a></code>.
</p>

<hr>
<h2 id='gensvm.load.tiny.grid'>Load a tiny parameter grid for the GenSVM grid search</h2><span id='topic+gensvm.load.tiny.grid'></span>

<h3>Description</h3>

<p>This function returns a parameter grid to use in the GenSVM 
grid search. This grid was obtained by analyzing the experiments done for 
the GenSVM paper and selecting the configurations that achieve accuracy 
within the 95th percentile on over 90
for a parameter search with a reasonably high chance of achieving good 
performance on most datasets.
</p>
<p>Note that this grid is only tested to work well in combination with the 
linear kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.load.tiny.grid()
</code></pre>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, <code><a href="#topic+gensvm.load.small.grid">gensvm.load.small.grid</a></code>, 
<code><a href="#topic+gensvm.load.full.grid">gensvm.load.full.grid</a></code>.
</p>

<hr>
<h2 id='gensvm.maxabs.scale'>Scale each column of a matrix by its maximum absolute value</h2><span id='topic+gensvm.maxabs.scale'></span>

<h3>Description</h3>

<p>Scaling a dataset can greatly decrease the computation time of 
GenSVM. This function scales the data by dividing each column of a matrix by 
the maximum absolute value of that column. This preserves sparsity in the 
data while mapping each column to the interval [-1, 1].
</p>
<p>Optionally a test dataset can be provided as well. In this case, the scaling 
will be computed on the first argument (<code>x</code>) and applied to the test 
dataset. Note that the return value is a list when this argument is 
supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.maxabs.scale(x, x.test = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm.maxabs.scale_+3A_x">x</code></td>
<td>
<p>a matrix to scale</p>
</td></tr>
<tr><td><code id="gensvm.maxabs.scale_+3A_x.test">x.test</code></td>
<td>
<p>(optional) a test matrix to scale as well.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if x.test=NULL a scaled matrix where the maximum value of the 
columns is 1 and the minimum value of the columns isn't below -1. If x.test 
is supplied, a list with elements <code>x</code> and <code>x.test</code> representing 
the scaled datasets.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, 
<code><a href="#topic+gensvm.train.test.split">gensvm.train.test.split</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]

# check the min and max of the columns
apply(x, 2, min)
apply(x, 2, max)

# scale the data
x.scale &lt;- gensvm.maxabs.scale(x)

# check again (max should be 1.0, min shouldn't be below -1)
apply(x.scale, 2, min)
apply(x.scale, 2, max)

# with a train and test dataset
split &lt;- gensvm.train.test.split(x)
x.train &lt;- split$x.train
x.test &lt;- split$x.test
scaled &lt;- gensvm.maxabs.scale(x.train, x.test)
x.train.scl &lt;- scaled$x
x.test.scl &lt;- scaled$x.test

</code></pre>

<hr>
<h2 id='gensvm.rank.score'>Compute the ranks for the numbers in a given vector</h2><span id='topic+gensvm.rank.score'></span>

<h3>Description</h3>

<p>This function computes the ranks for the values in an array. 
The highest value gets the smallest rank. Ties are broken by assigning the 
smallest value. The smallest rank is 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.rank.score(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm.rank.score_+3A_x">x</code></td>
<td>
<p>array of numeric values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>array with the ranks of the values in the input array.
</p>

<hr>
<h2 id='gensvm.refit'>Train an already fitted model on new data</h2><span id='topic+gensvm.refit'></span>

<h3>Description</h3>

<p>This function can be used to train an existing model on new 
data or fit an existing model with slightly different parameters. It is 
useful for retraining without having to copy all the parameters over. One 
common application for this is to refit the best model found by a grid 
search, as illustrated in the examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.refit(
  fit,
  x,
  y,
  p = NULL,
  lambda = NULL,
  kappa = NULL,
  epsilon = NULL,
  weights = NULL,
  kernel = NULL,
  gamma = NULL,
  coef = NULL,
  degree = NULL,
  kernel.eigen.cutoff = NULL,
  max.iter = NULL,
  verbose = NULL,
  random.seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm.refit_+3A_fit">fit</code></td>
<td>
<p>Fitted <code>gensvm</code> object</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_x">x</code></td>
<td>
<p>Data matrix of the new data</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_y">y</code></td>
<td>
<p>Label vector of the new data</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_p">p</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, otherwise 
override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_lambda">lambda</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_kappa">kappa</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_epsilon">epsilon</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_weights">weights</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_kernel">kernel</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_gamma">gamma</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_coef">coef</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_degree">degree</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_kernel.eigen.cutoff">kernel.eigen.cutoff</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new 
model, otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_max.iter">max.iter</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_verbose">verbose</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
<tr><td><code id="gensvm.refit_+3A_random.seed">random.seed</code></td>
<td>
<p>if NULL use the value from <code>fit</code> in the new model, 
otherwise override with this value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new fitted <code>gensvm</code> model
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# fit a standard model and refit with slightly different parameters
fit &lt;- gensvm(x, y)
fit2 &lt;- gensvm.refit(fit, x, y, epsilon=1e-8)


# refit a model returned by a grid search
grid &lt;- gensvm.grid(x, y)
fit &lt;- gensvm.refit(fit, x, y, epsilon=1e-8)


# refit on different data
idx &lt;- runif(nrow(x)) &gt; 0.5
x1 &lt;- x[idx, ]
x2 &lt;- x[!idx, ]
y1 &lt;- y[idx]
y2 &lt;- y[!idx]

fit1 &lt;- gensvm(x1, y1)
fit2 &lt;- gensvm.refit(fit1, x2, y2)

</code></pre>

<hr>
<h2 id='gensvm.train.test.split'>Create a train/test split of a dataset</h2><span id='topic+gensvm.train.test.split'></span>

<h3>Description</h3>

<p>Often it is desirable to split a dataset into a training and 
testing sample. This function is included in GenSVM to make it easy to do 
so. The function is inspired by a similar function in Scikit-Learn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.train.test.split(
  x,
  y = NULL,
  train.size = NULL,
  test.size = NULL,
  shuffle = TRUE,
  random.state = NULL,
  return.idx = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gensvm.train.test.split_+3A_x">x</code></td>
<td>
<p>array to split</p>
</td></tr>
<tr><td><code id="gensvm.train.test.split_+3A_y">y</code></td>
<td>
<p>another array to split (typically this is a vector)</p>
</td></tr>
<tr><td><code id="gensvm.train.test.split_+3A_train.size">train.size</code></td>
<td>
<p>size of the training dataset. This can be provided as 
float or as int. If it's a float, it should be between 0.0 and 1.0 and 
represents the fraction of the dataset that should be placed in the training 
dataset.  If it's an int, it represents the exact number of samples in the 
training dataset. If it is NULL, the complement of <code>test.size</code> will be 
used.</p>
</td></tr>
<tr><td><code id="gensvm.train.test.split_+3A_test.size">test.size</code></td>
<td>
<p>size of the test dataset. Similarly to train.size both a 
float or an int can be supplied. If it's NULL, the complement of train.size 
will be used. If both train.size and test.size are NULL, a default test.size 
of 0.25 will be used.</p>
</td></tr>
<tr><td><code id="gensvm.train.test.split_+3A_shuffle">shuffle</code></td>
<td>
<p>shuffle the rows or not</p>
</td></tr>
<tr><td><code id="gensvm.train.test.split_+3A_random.state">random.state</code></td>
<td>
<p>seed for the random number generator (int)</p>
</td></tr>
<tr><td><code id="gensvm.train.test.split_+3A_return.idx">return.idx</code></td>
<td>
<p>whether or not to return the indices in the output</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with <code>x.train</code> and <code>x.test</code> splits of the <code>x</code> 
array provided. If <code>y</code> is provided, also <code>y.train</code> and 
<code>y.test</code>. If <code>return.idx</code> is TRUE, also <code>idx.train</code> and 
<code>idx.test</code>.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# using the default values
split &lt;- gensvm.train.test.split(x, y)

# using the split in a GenSVM model
fit &lt;- gensvm(split$x.train, split$y.train)
gensvm.accuracy(split$y.test, predict(fit, split$x.test))

# using attach makes the results directly available
attach(gensvm.train.test.split(x, y))
fit &lt;- gensvm(x.train, y.train)
gensvm.accuracy(y.test, predict(fit, x.test))

</code></pre>

<hr>
<h2 id='gensvm.validate.param.grid'>[internal] Validate parameter grid</h2><span id='topic+gensvm.validate.param.grid'></span>

<h3>Description</h3>

<p>Internal function to validate all parameters in a parameter 
grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.validate.param.grid(df)
</code></pre>


<h3>Value</h3>

<p>TRUE if all values pass their respective conditions, FALSE 
otherwise.
</p>

<hr>
<h2 id='gensvm.validate.params'>[internal] Validate parameters</h2><span id='topic+gensvm.validate.params'></span>

<h3>Description</h3>

<p>Internal function used to validate the parameters passed to the 
gensvm() function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gensvm.validate.params(
  p = NULL,
  kappa = NULL,
  lambda = NULL,
  epsilon = NULL,
  gamma = NULL,
  weights = NULL,
  kernel = NULL,
  ...
)
</code></pre>


<h3>Value</h3>

<p>TRUE if all values pass their respective conditions, FALSE 
otherwise.
</p>

<hr>
<h2 id='plot.gensvm'>Plot the simplex space of the fitted GenSVM model</h2><span id='topic+plot.gensvm'></span>

<h3>Description</h3>

<p>This function creates a plot of the simplex space for a fitted 
GenSVM model and the given data set. This function works for dataset with 
two or three classes. For more than 3 classes, the simplex space is too high 
dimensional to easily visualize.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm'
plot(
  x,
  labels,
  newdata = NULL,
  with.margins = TRUE,
  with.shading = TRUE,
  with.legend = TRUE,
  center.plot = TRUE,
  xlim = NULL,
  ylim = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gensvm_+3A_x">x</code></td>
<td>
<p>A fitted <code>gensvm</code> object</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_labels">labels</code></td>
<td>
<p>the labels to color points with. If this is omitted the 
predicted labels are used.</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_newdata">newdata</code></td>
<td>
<p>the dataset to plot. If this is NULL the training data is 
used.</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_with.margins">with.margins</code></td>
<td>
<p>plot the margins</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_with.shading">with.shading</code></td>
<td>
<p>show shaded areas for the class regions</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_with.legend">with.legend</code></td>
<td>
<p>show the legend for the class labels</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_center.plot">center.plot</code></td>
<td>
<p>ensure that the boundaries and margins are always visible 
in the plot</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_xlim">xlim</code></td>
<td>
<p>allows the user to force certain plot limits. If set, these 
bounds will be used for the horizontal axis.</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_ylim">ylim</code></td>
<td>
<p>allows the user to force certain plot limits. If set, these 
bounds will be used for the vertical axis and the value of center.plot will 
be ignored</p>
</td></tr>
<tr><td><code id="plot.gensvm_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the builtin plot() function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the object passed as input
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.gensvm.grid">plot.gensvm.grid</a></code>, <code><a href="#topic+predict.gensvm">predict.gensvm</a></code>, 
<code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# train the model
fit &lt;- gensvm(x, y)

# plot the simplex space
plot(fit)

# plot and use the true colors (easier to spot misclassified samples)
plot(fit, y)

# plot only misclassified samples
x.mis &lt;- x[predict(fit) != y, ]
y.mis.true &lt;- y[predict(fit) != y]
plot(fit, newdata=x.mis)
plot(fit, y.mis.true, newdata=x.mis)

# plot a 2-d model
xx &lt;- x[y %in% c('versicolor', 'virginica'), ]
yy &lt;- y[y %in% c('versicolor', 'virginica')]
fit &lt;- gensvm(xx, yy, kernel='rbf', max.iter=1000)
plot(fit)

</code></pre>

<hr>
<h2 id='plot.gensvm.grid'>Plot the simplex space of the best fitted model in the GenSVMGrid</h2><span id='topic+plot.gensvm.grid'></span>

<h3>Description</h3>

<p>This is a wrapper which calls the plot function for the best 
model in the provided GenSVMGrid object. See the documentation for 
<code><a href="#topic+plot.gensvm">plot.gensvm</a></code> for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm.grid'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gensvm.grid_+3A_x">x</code></td>
<td>
<p>A <code>gensvm.grid</code> object trained with refit=TRUE</p>
</td></tr>
<tr><td><code id="plot.gensvm.grid_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the plot function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the object passed as input
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.gensvm">plot.gensvm</a></code>, <code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, 
<code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- iris[, -5]
y &lt;- iris[, 5]

grid &lt;- gensvm.grid(x, y)
plot(grid, x)


</code></pre>

<hr>
<h2 id='predict.gensvm'>Predict class labels with the GenSVM model</h2><span id='topic+predict.gensvm'></span>

<h3>Description</h3>

<p>This function predicts the class labels of new data using a 
fitted GenSVM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm'
predict(object, newdata, add.rownames = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gensvm_+3A_object">object</code></td>
<td>
<p>Fitted <code>gensvm</code> object</p>
</td></tr>
<tr><td><code id="predict.gensvm_+3A_newdata">newdata</code></td>
<td>
<p>Matrix of new data for which predictions need to be made.</p>
</td></tr>
<tr><td><code id="predict.gensvm_+3A_add.rownames">add.rownames</code></td>
<td>
<p>add the rownames from the training data to the 
predictions</p>
</td></tr>
<tr><td><code id="predict.gensvm_+3A_...">...</code></td>
<td>
<p>further arguments are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of class labels, with the same type as the original class 
labels.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.gensvm">plot.gensvm</a></code>, <code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, 
<code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# create a training and test sample
attach(gensvm.train.test.split(x, y))
fit &lt;- gensvm(x.train, y.train)

# predict the class labels of the test sample
y.test.pred &lt;- predict(fit, x.test)

# compute the accuracy with gensvm.accuracy
gensvm.accuracy(y.test, y.test.pred)

</code></pre>

<hr>
<h2 id='predict.gensvm.grid'>Predict class labels from the GenSVMGrid class</h2><span id='topic+predict.gensvm.grid'></span>

<h3>Description</h3>

<p>Predict class labels using the best model from a grid search.  
After doing a grid search with the <code><a href="#topic+gensvm.grid">gensvm.grid</a></code> function, this 
function can be used to make predictions of class labels. It uses the best 
GenSVM model found during the grid search to do the predictions. Note that 
this model is only available if <code>refit=TRUE</code> was specified in the 
<code><a href="#topic+gensvm.grid">gensvm.grid</a></code> call (the default).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm.grid'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gensvm.grid_+3A_object">object</code></td>
<td>
<p>A <code>gensvm.grid</code> object trained with <code>refit=TRUE</code></p>
</td></tr>
<tr><td><code id="predict.gensvm.grid_+3A_newdata">newdata</code></td>
<td>
<p>Matrix of new values for <code>x</code> for which predictions need 
to be computed.</p>
</td></tr>
<tr><td><code id="predict.gensvm.grid_+3A_...">...</code></td>
<td>
<p>further arguments are passed to predict.gensvm()</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of class labels, with the same type as the original class 
labels provided to gensvm.grid()
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, 
<code><a href="#topic+plot.gensvm">plot.gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- iris[, -5]
y &lt;- iris[, 5]

# run a grid search
grid &lt;- gensvm.grid(x, y)

# predict training sample
y.hat &lt;- predict(grid, x)


</code></pre>

<hr>
<h2 id='print.gensvm'>Print the fitted GenSVM model</h2><span id='topic+print.gensvm'></span>

<h3>Description</h3>

<p>Prints a short description of the fitted GenSVM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.gensvm_+3A_x">x</code></td>
<td>
<p>A <code>gensvm</code> object to print</p>
</td></tr>
<tr><td><code id="print.gensvm_+3A_...">...</code></td>
<td>
<p>further arguments are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the object passed as input. This can be useful for chaining 
operations on a fit object.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm">gensvm</a></code>, <code><a href="#topic+predict.gensvm">predict.gensvm</a></code>, 
<code><a href="#topic+plot.gensvm">plot.gensvm</a></code>, <code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- iris[, -5]
y &lt;- iris[, 5]

# fit and print the model
fit &lt;- gensvm(x, y)
print(fit)

# (advanced) use the fact that print returns the fitted model
fit &lt;- gensvm(x, y)
predict(print(fit), x)

</code></pre>

<hr>
<h2 id='print.gensvm.grid'>Print the fitted GenSVMGrid model</h2><span id='topic+print.gensvm.grid'></span>

<h3>Description</h3>

<p>Prints the summary of the fitted GenSVMGrid model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gensvm.grid'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.gensvm.grid_+3A_x">x</code></td>
<td>
<p>a <code>gensvm.grid</code> object to print</p>
</td></tr>
<tr><td><code id="print.gensvm.grid_+3A_...">...</code></td>
<td>
<p>further arguments are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns the object passed as input
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized 
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research, 
17(225):1&ndash;42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, <code><a href="#topic+predict.gensvm.grid">predict.gensvm.grid</a></code>, 
<code><a href="#topic+plot.gensvm.grid">plot.gensvm.grid</a></code>, <code><a href="#topic+gensvm.grid">gensvm.grid</a></code>, 
<code><a href="#topic+gensvm-package">gensvm-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- iris[, -5]
y &lt;- iris[, 5]

# fit a grid search and print the resulting object
grid &lt;- gensvm.grid(x, y)
print(grid)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
