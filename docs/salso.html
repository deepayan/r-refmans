<!DOCTYPE html><html lang="en"><head><title>Help for package salso</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {salso}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#salso-package'><p>salso: Search Algorithms and Loss Functions for Bayesian Clustering</p></a></li>
<li><a href='#bell'><p>Compute the Bell Number</p></a></li>
<li><a href='#chips'><p>CHiPS Partition Greedy Search</p></a></li>
<li><a href='#dlso'><p>Latent Structure Optimization Based on Draws</p></a></li>
<li><a href='#enumerate.partitions'><p>Enumerate Partitions of a Set</p></a></li>
<li><a href='#enumerate.permutations'><p>Enumerate Permutations of Items</p></a></li>
<li><a href='#iris.clusterings'><p>Clusterings of the Iris Data</p></a></li>
<li><a href='#partition.loss'><p>Compute Partition Loss or the Expectation of Partition Loss</p></a></li>
<li><a href='#plot.salso.summary'><p>Heatmap, Multidimensional Scaling, Pairs, and Dendrogram Plotting for</p>
Partition Estimation</a></li>
<li><a href='#psm'><p>Compute an Adjacency or Pairwise Similarity Matrix</p></a></li>
<li><a href='#salso'><p>SALSO Greedy Search</p></a></li>
<li><a href='#summary.salso.estimate'><p>Summary of Partitions Estimated Using Posterior Expected Loss</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Search Algorithms and Loss Functions for Bayesian Clustering</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.42</td>
</tr>
<tr>
<td>Description:</td>
<td>The SALSO algorithm is an efficient randomized greedy search method to find a point estimate for a random partition based on a loss function and posterior Monte Carlo samples. The algorithm is implemented for many loss functions, including the Binder loss and a generalization of the variation of information loss, both of which allow for unequal weights on the two types of clustering mistakes. Efficient implementations are also provided for Monte Carlo estimation of the posterior expected loss of a given clustering estimate. See Dahl, Johnson, Müller (2022) &lt;<a href="https://doi.org/10.1080%2F10618600.2022.2069779">doi:10.1080/10618600.2022.2069779</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE | <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/dbdahl/salso">https://github.com/dbdahl/salso</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/dbdahl/salso/issues">https://github.com/dbdahl/salso/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2.0)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Cargo (Rust's package manager), rustc (&gt;= 1.66.1)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-15 01:42:25 UTC; dahl</td>
</tr>
<tr>
<td>Author:</td>
<td>David B. Dahl <a href="https://orcid.org/0000-0002-8173-1547"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Devin J. Johnson <a href="https://orcid.org/0000-0003-2619-6649"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Peter Müller [aut],
  Alex Crichton [ctb] (Rust crates: cfg-if, proc-macro2),
  Brendan Zabarauskas [ctb] (Rust crate: approx),
  David B. Dahl [ctb] (Rust crates: dahl-bellnumber, dahl-partition,
    dahl-salso, roxido, roxido_macro),
  David Tolnay [ctb] (Rust crates: proc-macro2, quote, syn,
    unicode-ident),
  Jim Turner [ctb] (Rust crate: ndarray),
  Josh Stone [ctb] (Rust crate: autocfg),
  R. Janis Goldschmidt [ctb] (Rust crate: matrixmultiply),
  Sean McArthur [ctb] (Rust crate: num_cpus),
  Stefan Lankes [ctb] (Rust crate: hermit-abi),
  The Cranelift Project Developers [ctb] (Rust crate: wasi),
  The CryptoCorrosion Contributors [ctb] (Rust crates: ppv-lite86,
    rand_chacha),
  The Rand Project Developers [ctb] (Rust crates: getrandom, rand,
    rand_chacha, rand_core, rand_pcg),
  The Rust Project Developers [ctb] (Rust crates: libc, num-bigint,
    num-complex, num-integer, num-traits, rand, rand_chacha, rand_core),
  Ulrik Sverdrup "bluss" [ctb] (Rust crate: ndarray),
  bluss [ctb] (Rust crates: matrixmultiply, rawpointer)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David B. Dahl &lt;dahl@stat.byu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-16 12:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='salso-package'>salso: Search Algorithms and Loss Functions for Bayesian Clustering</h2><span id='topic+salso-package'></span>

<h3>Description</h3>

<p>The SALSO algorithm is an efficient randomized greedy search method to find a point estimate for a random partition based on a loss function and posterior Monte Carlo samples. The algorithm is implemented for many loss functions, including the Binder loss and a generalization of the variation of information loss, both of which allow for unequal weights on the two types of clustering mistakes. Efficient implementations are also provided for Monte Carlo estimation of the posterior expected loss of a given clustering estimate. See Dahl, Johnson, Müller (2022) <a href="https://doi.org/10.1080/10618600.2022.2069779">doi:10.1080/10618600.2022.2069779</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: David B. Dahl <a href="mailto:dahl@stat.byu.edu">dahl@stat.byu.edu</a> (<a href="https://orcid.org/0000-0002-8173-1547">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Devin J. Johnson <a href="mailto:devin.j.johnson7@gmail.com">devin.j.johnson7@gmail.com</a> (<a href="https://orcid.org/0000-0003-2619-6649">ORCID</a>)
</p>
</li>
<li><p> Peter Müller <a href="mailto:pmueller@math.utexas.edu">pmueller@math.utexas.edu</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Alex Crichton <a href="mailto:alex@alexcrichton.com">alex@alexcrichton.com</a> (Rust crates: cfg-if, proc-macro2) [contributor]
</p>
</li>
<li><p> Brendan Zabarauskas <a href="mailto:bjzaba@yahoo.com.au">bjzaba@yahoo.com.au</a> (Rust crate: approx) [contributor]
</p>
</li>
<li><p> David B. Dahl <a href="mailto:dahl@stat.byu.edu">dahl@stat.byu.edu</a> (Rust crates: dahl-bellnumber, dahl-partition, dahl-salso, roxido, roxido_macro) [contributor]
</p>
</li>
<li><p> David Tolnay <a href="mailto:dtolnay@gmail.com">dtolnay@gmail.com</a> (Rust crates: proc-macro2, quote, syn, unicode-ident) [contributor]
</p>
</li>
<li><p> Jim Turner (Rust crate: ndarray) [contributor]
</p>
</li>
<li><p> Josh Stone <a href="mailto:cuviper@gmail.com">cuviper@gmail.com</a> (Rust crate: autocfg) [contributor]
</p>
</li>
<li><p> R. Janis Goldschmidt (Rust crate: matrixmultiply) [contributor]
</p>
</li>
<li><p> Sean McArthur <a href="mailto:sean@seanmonstar.com">sean@seanmonstar.com</a> (Rust crate: num_cpus) [contributor]
</p>
</li>
<li><p> Stefan Lankes (Rust crate: hermit-abi) [contributor]
</p>
</li>
<li><p> The Cranelift Project Developers (Rust crate: wasi) [contributor]
</p>
</li>
<li><p> The CryptoCorrosion Contributors (Rust crates: ppv-lite86, rand_chacha) [contributor]
</p>
</li>
<li><p> The Rand Project Developers (Rust crates: getrandom, rand, rand_chacha, rand_core, rand_pcg) [contributor]
</p>
</li>
<li><p> The Rust Project Developers (Rust crates: libc, num-bigint, num-complex, num-integer, num-traits, rand, rand_chacha, rand_core) [contributor]
</p>
</li>
<li><p> Ulrik Sverdrup &quot;bluss&quot; (Rust crate: ndarray) [contributor]
</p>
</li>
<li><p> bluss (Rust crates: matrixmultiply, rawpointer) [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/dbdahl/salso">https://github.com/dbdahl/salso</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/dbdahl/salso/issues">https://github.com/dbdahl/salso/issues</a>
</p>
</li></ul>


<hr>
<h2 id='bell'>Compute the Bell Number</h2><span id='topic+bell'></span><span id='topic+lbell'></span>

<h3>Description</h3>

<p>These functions compute the Bell number (the number of partitions of a given
number of items) or its natural logarithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bell(nItems)

lbell(nItems)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bell_+3A_nitems">nItems</code></td>
<td>
<p>The size of the set <code class="reqn">{1, 2, ..., n}</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of length one giving the Bell number or its natural
logarithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bell(12)
lbell(300)
all.equal( bell(5), exp(lbell(5)) )

</code></pre>

<hr>
<h2 id='chips'>CHiPS Partition Greedy Search</h2><span id='topic+chips'></span>

<h3>Description</h3>

<p>This function provides a partition to a subset of items which has high
marginal probability based on samples from a partition distribution
using the CHiPS greedy search method (Dahl, Page, Barrientos, 2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chips(
  x,
  threshold = 0,
  nRuns = 64,
  intermediateResults = TRUE,
  allCandidates = FALSE,
  nCores = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chips_+3A_x">x</code></td>
<td>
<p>A <code class="reqn">B</code>-by-<code class="reqn">n</code> matrix, where each of the <code class="reqn">B</code> rows
represents a clustering of <code class="reqn">n</code> items using cluster labels. For the
<code class="reqn">b</code>th clustering, items <code class="reqn">i</code> and <code class="reqn">j</code> are in the same cluster if
<code>x[b, i] == x[b, j]</code>.</p>
</td></tr>
<tr><td><code id="chips_+3A_threshold">threshold</code></td>
<td>
<p>The minimum marginal probability for the partial partition.
Values closer to 1.0 will yield a partition of fewer items and values
closer to 0.0 will yield a partition of more items.</p>
</td></tr>
<tr><td><code id="chips_+3A_nruns">nRuns</code></td>
<td>
<p>The number of runs to try, where the best result is returned.</p>
</td></tr>
<tr><td><code id="chips_+3A_intermediateresults">intermediateResults</code></td>
<td>
<p>Should intermediate subset partitions be returned?</p>
</td></tr>
<tr><td><code id="chips_+3A_allcandidates">allCandidates</code></td>
<td>
<p>Should all the final subset partitions from multiple runs
be returned?</p>
</td></tr>
<tr><td><code id="chips_+3A_ncores">nCores</code></td>
<td>
<p>The number of CPU cores to use, i.e., the number of
simultaneous runs at any given time. A value of zero indicates to use all
cores on the system.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>intermediateResults</code> is <code>FALSE</code>, an integer vector giving the
estimated subset partition, encoded using cluster labels with <code>-1</code>
indicating not allocated.  If <code>TRUE</code>, a matrix with intermediate subset
partitions in the rows.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For examples, use 'nCores = 1' per CRAN rules, but in practice omit this.
data(iris.clusterings)
draws &lt;- iris.clusterings
chips(draws, threshold = 0, nRuns = 1)
chips(draws, nCores = 1)
</code></pre>

<hr>
<h2 id='dlso'>Latent Structure Optimization Based on Draws</h2><span id='topic+dlso'></span>

<h3>Description</h3>

<p>This function provides a partition to summarize a partition distribution
using the draws-based latent structure optimization (DLSO) method, which is
also known as the least-squares clustering method (Dahl 2006). The method
seeks to minimize an estimation criterion by picking the minimizer among the
partitions supplied. The implementation currently supports the minimization
of several partition estimation criteria. For details on these criteria, see
<code><a href="#topic+partition.loss">partition.loss</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlso(truth, loss = VI(), estimate = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dlso_+3A_truth">truth</code></td>
<td>
<p>An integer vector of cluster labels for <code class="reqn">n</code> items
representing the true clustering. Two items are in the same cluster if
their labels are equal. Or, a matrix of <code class="reqn">n</code> columns where each row is a
clustering.</p>
</td></tr>
<tr><td><code id="dlso_+3A_loss">loss</code></td>
<td>
<p>The loss function to use, as indicated by <code>"binder"</code>,
<code>"omARI"</code>, <code>"VI"</code>, <code>"NVI"</code>, <code>"ID"</code>, <code>"NID"</code>, or
the result of calling a function with these names. Also supported are
<code>"binder.psm"</code>, <code>"VI.lb"</code>, <code>"omARI.approx"</code>, or the result
of calling a function with these names, in which case <code>x</code> above can
optionally be a pairwise similarity matrix, i.e., <code class="reqn">n</code>-by-<code class="reqn">n</code>
symmetric matrix whose <code class="reqn">(i,j)</code> element gives the (estimated)
probability that items <code class="reqn">i</code> and <code class="reqn">j</code> are in the same subset (i.e.,
cluster) of a partition (i.e., clustering).</p>
</td></tr>
<tr><td><code id="dlso_+3A_estimate">estimate</code></td>
<td>
<p>An integer vector of cluster labels having the same length as
<code>truth</code> representing the estimated clustering. Or, a matrix of
<code class="reqn">n</code> columns where each row is a clustering.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer vector giving the estimated partition, encoded using
cluster labels.
</p>


<h3>References</h3>

<p>D. B. Dahl (2006), Model-Based Clustering for Expression Data via a Dirichlet
Process Mixture Model, in <em>Bayesian Inference for Gene Expression and
Proteomics</em>, Kim-Anh Do, Peter Müller, Marina Vannucci (Eds.), Cambridge
University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partition.loss">partition.loss</a></code>, <code><a href="#topic+psm">psm</a></code>,
<code><a href="#topic+summary.salso.estimate">summary.salso.estimate</a></code>, <code><a href="#topic+salso">salso</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris.clusterings)
dlso(iris.clusterings, loss=VI())
dlso(iris.clusterings, loss=binder())

# Compute expected loss using all draws, but pick the best among the first 10.
dlso(iris.clusterings, loss=VI(), estimate=iris.clusterings[1:10,])

</code></pre>

<hr>
<h2 id='enumerate.partitions'>Enumerate Partitions of a Set</h2><span id='topic+enumerate.partitions'></span>

<h3>Description</h3>

<p>This function produces a matrix whose rows provide all possible partitions of
the set <code class="reqn">{1, 2, ..., n}</code>. These partitions are provided as cluster
labels, where two items are in the same subset (i.e., cluster) if their
labels are equal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enumerate.partitions(nItems)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="enumerate.partitions_+3A_nitems">nItems</code></td>
<td>
<p>The size of the set <code class="reqn">{1, 2, ..., n}</code>, i.e., <code class="reqn">n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of integers, where each row is a partition encoded as a
vector of cluster labels.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>enumerate.partitions(5)

</code></pre>

<hr>
<h2 id='enumerate.permutations'>Enumerate Permutations of Items</h2><span id='topic+enumerate.permutations'></span>

<h3>Description</h3>

<p>This function produces a matrix whose rows provide all possible permutations
of the set <code class="reqn">{1, 2, ..., n}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enumerate.permutations(nItems)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="enumerate.permutations_+3A_nitems">nItems</code></td>
<td>
<p>The size of the set <code class="reqn">{1, 2, ..., n}</code>, i.e., <code class="reqn">n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of integers, where each row is a permutation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>enumerate.permutations(5)

</code></pre>

<hr>
<h2 id='iris.clusterings'>Clusterings of the Iris Data</h2><span id='topic+iris.clusterings'></span>

<h3>Description</h3>

<p>Randomly generated clusterings for the <code>iris</code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iris.clusterings
</code></pre>


<h3>Format</h3>

<p>A 1000-by-150 matrix of 1000 randomly generated clusterings of the
150 observations in the <code>iris</code> dataset.
</p>


<h3>Source</h3>

<p>Unknown.
</p>


<h3>See Also</h3>

<p><code><a href="datasets.html#topic+iris">iris</a></code>
</p>

<hr>
<h2 id='partition.loss'>Compute Partition Loss or the Expectation of Partition Loss</h2><span id='topic+partition.loss'></span><span id='topic+binder'></span><span id='topic+RI'></span><span id='topic+omARI'></span><span id='topic+omARI.approx'></span><span id='topic+ARI'></span><span id='topic+VI'></span><span id='topic+VI.lb'></span><span id='topic+NVI'></span><span id='topic+ID'></span><span id='topic+NID'></span>

<h3>Description</h3>

<p>Given two partitions <code class="reqn">\pi*</code> and <code class="reqn">\pi</code>, these functions compute the
specified loss when using <code class="reqn">\pi*</code> to estimate <code class="reqn">\pi</code>. Smaller loss
values indicate higher concordance between partitions. These functions also
compute a Monte Carlo estimate of the expectation for the specified loss
based on samples or a pairwise similarity matrix. This function also supports
computing approximations to the expectation of several losses. Supported
criteria are described below. Some criteria only require the pairwise
similarity matrix (as computed, for example, by <code><a href="#topic+psm">psm</a></code>) whereas
others require samples from a partition distribution. For those criteria that
only need the pairwise similarity matrix, posterior samples can still be
provided in the <code>truth</code> argument and the pairwise similarity matrix will
automatically be computed as needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partition.loss(truth, estimate, loss = VI())

binder(truth, estimate, a = 1)

RI(truth, estimate)

omARI(truth, estimate)

omARI.approx(truth, estimate)

ARI(truth, estimate)

VI(truth, estimate, a = 1)

VI.lb(truth, estimate)

NVI(truth, estimate)

ID(truth, estimate)

NID(truth, estimate)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="partition.loss_+3A_truth">truth</code></td>
<td>
<p>An integer vector of cluster labels for <code class="reqn">n</code> items
representing the true clustering. Two items are in the same cluster if
their labels are equal. Or, a matrix of <code class="reqn">n</code> columns where each row is a
clustering.</p>
</td></tr>
<tr><td><code id="partition.loss_+3A_estimate">estimate</code></td>
<td>
<p>An integer vector of cluster labels having the same length as
<code>truth</code> representing the estimated clustering. Or, a matrix of
<code class="reqn">n</code> columns where each row is a clustering.</p>
</td></tr>
<tr><td><code id="partition.loss_+3A_loss">loss</code></td>
<td>
<p>The loss function to use, as indicated by <code>"binder"</code>,
<code>"omARI"</code>, <code>"VI"</code>, <code>"NVI"</code>, <code>"ID"</code>, <code>"NID"</code>, or
the result of calling a function with these names. Also supported are
<code>"binder.psm"</code>, <code>"VI.lb"</code>, <code>"omARI.approx"</code>, or the result
of calling a function with these names, in which case <code>x</code> above can
optionally be a pairwise similarity matrix, i.e., <code class="reqn">n</code>-by-<code class="reqn">n</code>
symmetric matrix whose <code class="reqn">(i,j)</code> element gives the (estimated)
probability that items <code class="reqn">i</code> and <code class="reqn">j</code> are in the same subset (i.e.,
cluster) of a partition (i.e., clustering).</p>
</td></tr>
<tr><td><code id="partition.loss_+3A_a">a</code></td>
<td>
<p>(Only used for Binder and VI loss) The argument <code>a</code> is either:
i. a nonnegative scalar in <code class="reqn">[0,2]</code> giving (for Binder loss) the cost of
placing two items in separate clusters when in truth they belong to the
same cluster, ii. <code>NULL</code>, in which case <code>a</code> that maximizes the
expected loss is found, and iii. a list containing the desired number of
clusters (<code>"nClusters"</code>) when searching for <code>a</code> that yields this
number of clusters. In all but the first case, one may want to modifying
<code>maxSize</code> in the <code><a href="#topic+salso">salso</a></code> function. To increase the
probability of hitting exactly the desired number of clusters, the
<code>nRuns</code> in the <code><a href="#topic+salso">salso</a></code> function may need to be increased.
Without loss of generality, the cost (under Binder loss) of placing two
items in the same cluster when in truth they belong to separate clusters is
fixed <code>2-a</code>. For VI, <code>a</code> has a similar interpretation, although is
not a unit cost. See Dahl, Johnson, Müller (2021).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The partition estimation criterion can be specified using the <code>loss</code>
argument, which is either a string or a result of calling the associated
functions. These losses are described below: </p>

<dl>
<dt><code>"binder"</code></dt><dd><p>Binder. Whereas high values of the Rand index <code class="reqn">R</code>
between <code class="reqn">\pi*</code> and <code class="reqn">\pi</code> correspond to high concordance between the
partitions, the N-invariant Binder loss <code class="reqn">L</code> for a partition <code class="reqn">\pi*</code> in
estimating <code class="reqn">\pi</code> is <code class="reqn">L = (1-R)*(n-1)/n</code>, meaning that low values
correspond to high concordance between the partitions. This package reports
the N-invariant Binder loss. The original Binder loss equals the N-invariant
Binder loss multiplied by <code class="reqn">n^2 / 2</code>. Only the pairwise similarity matrix
is required for this loss, but samples can be provided. As originally
discussed by Binder (1978), two mistakes are possible: 1. Placing two items
in separate clusters when in truth they belong to the same cluster, and 2.
Placing two items in the same cluster when in truth they belong to separate
clusters. The default cost of the first mistake is one, but can be specified
with the argument <code>a</code> in <code class="reqn">[0,2]</code>. Without loss of generality, the cost of
the second mistake is set as <code>2-a</code>. For a discussion of general
weights, see Dahl, Johnson, and Müller (2021). For a discussion of the equal
weights case, see also Dahl (2006), Lau and Green (2007), Dahl and Newton
(2007), Fritsch and Ickstadt (2009), and Wade and Ghahramani (2018).</p>
</dd>
<dt><code>"omARI"</code></dt><dd><p>One Minus Adjusted Rand Index. Computes the expectation
of one minus the adjusted Rand index (Hubert and Arabie, 1985). Whereas high
values of the adjusted Rand index between <code class="reqn">\pi*</code> and <code class="reqn">\pi</code> correspond
to high concordance between the partitions, the loss associated with the
adjusted Rand index for a partition <code class="reqn">\pi*</code> in estimating <code class="reqn">\pi</code> is one
minus the adjusted Rand index between the partitions, meaning that low values
correspond to high concordance between the partitions. Samples from a
partition distribution are required for this loss. See Fritsch and Ickstadt
(2009).</p>
</dd>
<dt><code>"omARI.approx"</code></dt><dd><p>Approximation of One Minus Adjusted Rand Index.
Computes the first-order approximation of the expectation of one minus the
adjusted Rand index. The adjusted Rand index involves a ratio and the
first-order approximation of the expectation is based on <code class="reqn">E(X/Y) \approx
E(X)/E(Y)</code>. Only the pairwise similarity matrix is required for this
criterion, but samples can be provided. See Fritsch and Ickstadt (2009).</p>
</dd>
<dt><code>"VI"</code></dt><dd><p>Variation of Information. Computes the expectation of the
(generalized) variation of information loss. Samples from a partition
distribution are required for this loss. See Meilă (2007), Wade and
Ghahramani (2018), and Rastelli and Friel (2018). The original variation of
information of Meilă (2007) has been extended to the generalized variation of
information of Dahl, Johnson, and  Müller (2021) to allow for unequal
weighting of two possible mistakes: 1. Placing two items in separate clusters
when in truth they belong to the same cluster, and 2. Placing two items in
the same cluster when in truth they belong to separate clusters.  The value
<code>a</code> controls the cost of the first mistake and defaults to one, but can
be specified with the argument <code>a</code> in <code class="reqn">[0,2]</code>. Without loss of generality,
the cost of the second mistake is controlled by <code>2-a</code>. See Dahl,
Johnson, Müller (2021).</p>
</dd>
<dt><code>"VI.lb"</code></dt><dd><p>Lower Bound of the Variation of Information. Computes
the lower bound of the expectation of the variation of information loss,
where the lower bound is obtained by Jensen's inequality. Only the pairwise
similarity matrix is required for this criterion, but samples can be
provided. See Wade and Ghahramani (2018).</p>
</dd>
<dt><code>"NVI"</code></dt><dd><p>Normalized Variation of Information. Computes the
expectation of the normalized variation of information loss. Samples from a
partition distribution are required for this loss. See Vinh, Epps, and Bailey
(2010) and Rastelli and Friel (2018).</p>
</dd>
<dt><code>"ID"</code></dt><dd><p>Information Distance. Computes the expectation of the
information distance (<code class="reqn">D_{max}</code>) loss. Samples from a partition
distribution are required for this loss. See Vinh, Epps, and Bailey (2010).</p>
</dd>
<dt><code>"NID"</code></dt><dd><p>Normalized Information Distance. Computes the expectation
of the normalized information distance loss. Samples from a partition
distribution are required for this loss. See Vinh, Epps, and Bailey (2010)
and Rastelli and Friel (2018).</p>
</dd>
</dl>

<p>The functions <code><a href="#topic+RI">RI</a></code> and <code><a href="#topic+ARI">ARI</a></code> are convenience
functions. Note that:
</p>

<ul>
<li> <p><code>binder(p1, p2, a=1) = ( 1 - RI(p1, p2) )*(n-1)/n</code>
</p>
</li>
<li> <p><code>omARI(p1, p2) = 1 - ARI(p1, p2)</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A numeric vector.
</p>


<h3>References</h3>

<p>W. M. Rand (1971), Objective Criteria for the Evaluation of Clustering
Methods. <em>Journal of the American Statistical Association</em>, <b>66</b>:
846–850.
</p>
<p>D. A. Binder (1978), Bayesian cluster analysis, <em>Biometrika</em> <b>65</b>,
31-38.
</p>
<p>L. Hubert and P. Arabie (1985), Comparing Partitions. <em>Journal of
Classification</em>, <b>2</b>, 193–218.
</p>
<p>D. B. Dahl (2006), Model-Based Clustering for Expression Data via a Dirichlet
Process Mixture Model, in <em>Bayesian Inference for Gene Expression and
Proteomics</em>, Kim-Anh Do, Peter Müller, Marina Vannucci (Eds.), Cambridge
University Press.
</p>
<p>J. W. Lau and P. J. Green (2007), Bayesian model based clustering procedures,
<em>Journal of Computational and Graphical Statistics</em> <b>16</b>, 526-558.
</p>
<p>M. Meilă (2007), Comparing Clusterings - an Information Based Distance.
<em>Journal of Multivariate Analysis</em>, <b>98</b>: 873–895.
</p>
<p>D. B. Dahl and M. A. Newton (2007), Multiple Hypothesis Testing by Clustering
Treatment Effects, <em>Journal of the American Statistical Association</em>,
<b>102</b>, 517-526.
</p>
<p>A. Fritsch and K. Ickstadt (2009), An improved criterion for clustering based
on the posterior similarity matrix, <em>Bayesian Analysis</em>, <b>4</b>,
367-391.
</p>
<p>N. X. Vinh, J. Epps, and J. Bailey (2010), Information Theoretic Measures for
Clusterings Comparison: Variants, Properties, Normalization and Correction
for Chance, <em>Journal of Machine Learning Research</em>, <b>11</b>,
2837-2854.
</p>
<p>S. Wade and Z. Ghahramani (2018), Bayesian cluster analysis: Point estimation
and credible balls. <em>Bayesian Analysis</em>, <b>13:2</b>, 559-626.
</p>
<p>R. Rastelli and N. Friel (2018), Optimal Bayesian estimators for latent
variable cluster models. <em>Statistics and Computing</em>, <b>28</b>,
1169-1186.
</p>
<p>D. B. Dahl, D. J. Johnson, and P. Müller (2022), Search Algorithms and Loss
Functions for Bayesian Clustering, <em>Journal of Computational and
Graphical Statistics</em>, 31(4), 1189-1201, <a href="https://doi.org/10.1080/10618600.2022.2069779">doi:10.1080/10618600.2022.2069779</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psm">psm</a></code>, <code><a href="#topic+salso">salso</a></code>, <code><a href="#topic+dlso">dlso</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For examples, use 'nCores=1' per CRAN rules, but in practice omit this.
data(iris.clusterings)
partitions &lt;- iris.clusterings[1:5,]

all.equal(partition.loss(partitions, partitions, loss=binder(a=1.4)),
          binder(partitions, partitions, a=1.4))
all.equal(partition.loss(partitions, partitions, loss=omARI()),
          omARI(partitions, partitions))
all.equal(partition.loss(partitions, partitions, loss=VI(a=0.8)),
          VI(partitions, partitions, a=0.8))

truth &lt;- iris.clusterings[1,]
estimate &lt;- iris.clusterings[2,]

VI(truth, estimate, a=1.0)
n &lt;- length(truth)
all.equal(binder(truth, estimate), ( 1 - RI(truth, estimate) ) * (n-1) / n)
all.equal(omARI(truth, estimate), 1 - ARI(truth, estimate))

</code></pre>

<hr>
<h2 id='plot.salso.summary'>Heatmap, Multidimensional Scaling, Pairs, and Dendrogram Plotting for
Partition Estimation</h2><span id='topic+plot.salso.summary'></span>

<h3>Description</h3>

<p>This function produces one of four plots:  1. <code>"heatmap"</code>: A heatmap
showing the pairwise allocation probabilities that items are clustered. 2.
<code>"mds"</code>: A scatter plot using classical multidimensional scaling (also
known as principal coordinates analysis) with the exemplar (i.e., the most
representative observation) of each cluster emphasized. 3. <code>"pairs"</code>:
Pairs plots of all the variables with the exemplar (i.e., the most
representative observation) of each cluster emphasized. 4.
<code>"dendrogram"</code>: A dendrogram based on expected partition loss showing
the relationships among clusters when merging pairs of clusters such that the
increase in the expectation of the posterior loss is minimized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'salso.summary'
plot(
  x,
  type = c("heatmap", "mds", "pairs", "dendrogram")[1],
  data = NULL,
  showLabels = TRUE,
  showIDs = length(x$estimate) &lt;= 50,
  cexAdjustment = 0.7,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.salso.summary_+3A_x">x</code></td>
<td>
<p>An object returned by <code>summary(y)</code>, where <code>y</code> itself is
returned by the <code><a href="#topic+salso">salso</a></code> function.</p>
</td></tr>
<tr><td><code id="plot.salso.summary_+3A_type">type</code></td>
<td>
<p>A string equal to <code>"heatmap"</code>, <code>"mds"</code>, <code>"pairs"</code>,
or <code>"dendrogram"</code>.</p>
</td></tr>
<tr><td><code id="plot.salso.summary_+3A_data">data</code></td>
<td>
<p>The data from which the partition estimation was obtained. This
is required when <code>type='pairs'</code> and ignored otherwise.</p>
</td></tr>
<tr><td><code id="plot.salso.summary_+3A_showlabels">showLabels</code></td>
<td>
<p>Should the cluster labels be shown in the plot when
<code>type="heatmap"</code>?</p>
</td></tr>
<tr><td><code id="plot.salso.summary_+3A_showids">showIDs</code></td>
<td>
<p>Should the ID of the items be shown in the plot?</p>
</td></tr>
<tr><td><code id="plot.salso.summary_+3A_cexadjustment">cexAdjustment</code></td>
<td>
<p>Scalar multiplier for adjust text size.</p>
</td></tr>
<tr><td><code id="plot.salso.summary_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to methods, such as graphical parameters
(see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code>, invisibly.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+salso">salso</a></code>, <code><a href="#topic+summary.salso.estimate">summary.salso.estimate</a></code>,
<code><a href="stats.html#topic+cmdscale">cmdscale</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For examples, use 'nCores=1' per CRAN rules, but in practice omit this.
data(iris.clusterings)
draws &lt;- iris.clusterings
est &lt;- salso(draws, nCores=1)
summ &lt;- summary(est)
plot(summ, type="heatmap")
plot(summ, type="mds")
plot(summ, type="pairs", data=iris)
plot(summ, type="dendrogram")

</code></pre>

<hr>
<h2 id='psm'>Compute an Adjacency or Pairwise Similarity Matrix</h2><span id='topic+psm'></span>

<h3>Description</h3>

<p>If only one sample is provided, this function computes an adjacency matrix,
i.e., a binary matrix whose <code class="reqn">(i,j)</code> element is one if and only if
elements <code class="reqn">i</code> and <code class="reqn">j</code> in the partition have the same cluster label. If
multiple samples are provided (as rows of the <code>x</code> matrix), this function
computes the <code class="reqn">n</code>-by-<code class="reqn">n</code> matrix whose <code class="reqn">(i,j)</code> element gives the
relative frequency (i.e., estimated probability) that items <code class="reqn">i</code> and
<code class="reqn">j</code> are in the same subset (i.e., cluster).  This is the mean of the
adjacency matrices of the provided samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psm(x, nCores = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="psm_+3A_x">x</code></td>
<td>
<p>A <code class="reqn">B</code>-by-<code class="reqn">n</code> matrix, where each of the <code class="reqn">B</code> rows
represents a clustering of <code class="reqn">n</code> items using cluster labels. For the
<code class="reqn">b</code>th clustering, items <code class="reqn">i</code> and <code class="reqn">j</code> are in the same cluster if
<code>x[b,i] == x[b,j]</code>.</p>
</td></tr>
<tr><td><code id="psm_+3A_ncores">nCores</code></td>
<td>
<p>The number of CPU cores to use, i.e., the number of
simultaneous runs at any given time. A value of zero indicates to use all
cores on the system.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code class="reqn">n</code>-by-<code class="reqn">n</code> symmetric matrix whose <code class="reqn">(i,j)</code> element gives
the relative frequency that that items <code class="reqn">i</code> and <code class="reqn">j</code> are in the same
subset (i.e., cluster).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For examples, use 'nCores=1' per CRAN rules, but in practice omit this.
data(iris.clusterings)
partition &lt;- iris.clusterings[1,]
psmatrix &lt;- psm(partition, nCores=1)
psmatrix[1:6, 1:6]

dim(iris.clusterings)
probs &lt;- psm(iris.clusterings, nCores=1)
dim(probs)
probs[1:6, 1:6]

</code></pre>

<hr>
<h2 id='salso'>SALSO Greedy Search</h2><span id='topic+salso'></span>

<h3>Description</h3>

<p>This function provides a partition to summarize a partition distribution
using the SALSO greedy search method (Dahl, Johnson, and Müller, 2022). The
implementation currently supports the minimization of several partition
estimation criteria. For details on these criteria, see
<code><a href="#topic+partition.loss">partition.loss</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>salso(
  x,
  loss = VI(),
  maxNClusters = 0,
  nRuns = 16,
  maxZealousAttempts = 10,
  probSequentialAllocation = 0.5,
  nCores = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="salso_+3A_x">x</code></td>
<td>
<p>A <code class="reqn">B</code>-by-<code class="reqn">n</code> matrix, where each of the <code class="reqn">B</code> rows
represents a clustering of <code class="reqn">n</code> items using cluster labels. For the
<code class="reqn">b</code>th clustering, items <code class="reqn">i</code> and <code class="reqn">j</code> are in the same cluster if
<code>x[b,i] == x[b,j]</code>.</p>
</td></tr>
<tr><td><code id="salso_+3A_loss">loss</code></td>
<td>
<p>The loss function to use, as indicated by <code>"binder"</code>,
<code>"omARI"</code>, <code>"VI"</code>, <code>"NVI"</code>, <code>"ID"</code>, <code>"NID"</code>, or
the result of calling a function with these names. Also supported are
<code>"binder.psm"</code>, <code>"VI.lb"</code>, <code>"omARI.approx"</code>, or the result
of calling a function with these names, in which case <code>x</code> above can
optionally be a pairwise similarity matrix, i.e., <code class="reqn">n</code>-by-<code class="reqn">n</code>
symmetric matrix whose <code class="reqn">(i,j)</code> element gives the (estimated)
probability that items <code class="reqn">i</code> and <code class="reqn">j</code> are in the same subset (i.e.,
cluster) of a partition (i.e., clustering). The loss functions
<code>"binder.psm"</code>, <code>"VI.lb"</code>, and <code>"omARI.approx"</code> are
generally not recommended and the current implementation requires that
<code>maxZealousAttempts = 0</code> and <code>probSequentialAllocation = 1.0</code>.</p>
</td></tr>
<tr><td><code id="salso_+3A_maxnclusters">maxNClusters</code></td>
<td>
<p>The maximum number of clusters that can be considered by
the optimization algorithm, which has important implications for the
interpretability of the resulting clustering and can greatly influence the
RAM needed for the optimization algorithm. If the supplied value is zero
and <code>x</code> is a matrix of clusterings, the optimization is constrained by
the maximum number of clusters among the clusterings in <code>x</code>. If the
supplied value is zero and <code>x</code> is a pairwise similarity matrix, there
is no constraint.</p>
</td></tr>
<tr><td><code id="salso_+3A_nruns">nRuns</code></td>
<td>
<p>The number of runs to try, although the actual number may differ
for the following reasons: 1. The actual number is a multiple of the number
of cores specified by the <code>nCores</code> argument, and 2. The search is
curtailed when the <code>seconds</code> threshold is exceeded.</p>
</td></tr>
<tr><td><code id="salso_+3A_maxzealousattempts">maxZealousAttempts</code></td>
<td>
<p>The maximum number of attempts for zealous updates,
in which entire clusters are destroyed and items are sequentially
reallocated. While zealous updates may be helpful in optimization, they
also take more CPU time which might be better used trying additional runs.</p>
</td></tr>
<tr><td><code id="salso_+3A_probsequentialallocation">probSequentialAllocation</code></td>
<td>
<p>For the initial allocation, the probability
of sequential allocation instead of using <code>sample(1:K, ncol(x),
  TRUE)</code>, where <code>K</code> is set according to the <code>maxNClusters</code>
argument.</p>
</td></tr>
<tr><td><code id="salso_+3A_ncores">nCores</code></td>
<td>
<p>The number of CPU cores to use, i.e., the number of
simultaneous runs at any given time. A value of zero indicates to use all
cores on the system.</p>
</td></tr>
<tr><td><code id="salso_+3A_...">...</code></td>
<td>
<p>Extra arguments not intended for the end user, including: 1.
<code>seconds</code>: Instead of performing all the requested number of runs,
curtail the search after the specified expected number of seconds. Note
that the function will finish earlier if all the requested runs are
completed. The specified seconds does not account for the overhead involved
in starting the search and returning results. 2. <code>maxScans</code> The
maximum number of full reallocation scans. The actual number of scans may
be less than <code>maxScans</code> since the method stops if the result does not
change between scans, and 3. <code>probSingletonsInitialization</code>: When
doing a sequential allocation to obtain the initial allocation, the
probability of placing the first <code>maxNClusters</code> randomly-selected
items in singletons subsets.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer vector giving the estimated partition, encoded using
cluster labels.
</p>


<h3>References</h3>

<p>D. B. Dahl, D. J. Johnson, and P. Müller (2022), Search Algorithms and Loss
Functions for Bayesian Clustering, <em>Journal of Computational and
Graphical Statistics</em>, 31(4), 1189-1201, <a href="https://doi.org/10.1080/10618600.2022.2069779">doi:10.1080/10618600.2022.2069779</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partition.loss">partition.loss</a></code>, <code><a href="#topic+psm">psm</a></code>,
<code><a href="#topic+summary.salso.estimate">summary.salso.estimate</a></code>, <code><a href="#topic+dlso">dlso</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For examples, use 'nCores=1' per CRAN rules, but in practice omit this.
data(iris.clusterings)
draws &lt;- iris.clusterings
salso(draws, loss=VI(), nRuns=1, nCores=1)
salso(draws, loss=VI(a=0.7), nRuns=1, nCores=1)
salso(draws, loss=binder(), nRuns=1, nCores=1)
salso(iris.clusterings, binder(a=NULL), nRuns=4, nCores=1)
salso(iris.clusterings, binder(a=list(nClusters=3)), nRuns=4, nCores=1)

</code></pre>

<hr>
<h2 id='summary.salso.estimate'>Summary of Partitions Estimated Using Posterior Expected Loss</h2><span id='topic+summary.salso.estimate'></span>

<h3>Description</h3>

<p>Assessing the quality of clusters in a partition estimate is added by this
function. The result can then be plotted with
<code><a href="#topic+plot.salso.summary">plot.salso.summary</a></code>. The current implementation of the
calculation of these summaries is not terribly efficient and may be improved
in the future.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'salso.estimate'
summary(object, alternative, orderingMethod = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.salso.estimate_+3A_object">object</code></td>
<td>
<p>An object returned by the <code><a href="#topic+salso">salso</a></code> function.</p>
</td></tr>
<tr><td><code id="summary.salso.estimate_+3A_alternative">alternative</code></td>
<td>
<p>An optional argument specifying an alternative clustering
to use instead of that provided by <code>object</code>. Use this feature to
obtain numerical and graphical summaries of a clustering estimate from
other procedures. This clustering must be provided in canonical form:
cluster labels as integers starting at 1 for the first observation and
incrementing by one for each new label.</p>
</td></tr>
<tr><td><code id="summary.salso.estimate_+3A_orderingmethod">orderingMethod</code></td>
<td>
<p>An integer giving method to use to order the
observations for a heatmap plot.  Currently values <code>1</code> or <code>2</code> are
supported.</p>
</td></tr>
<tr><td><code id="summary.salso.estimate_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the estimate, the pairwise similarity matrix, the
mean pairwise similarity matrix, the score and mean pairwise similarity for
each observation, exemplar observation for each cluster, a dendrogram
object, a vector for ordering observations in the heatmap plot, the size of
each cluster, and the number of clusters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For examples, use 'nCores=1' per CRAN rules, but in practice omit this.
data(iris.clusterings)
draws &lt;- iris.clusterings
est &lt;- salso(draws, nCores=1)
summ &lt;- summary(est)
plot(summ, type="heatmap")
plot(summ, type="mds")
plot(summ, type="pairs", data=iris)
plot(summ, type="dendrogram")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
