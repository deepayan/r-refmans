<!DOCTYPE html><html><head><title>Help for package hmmr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hmmr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#balance8'><p>Repeated measures on the balance scale</p></a></li>
<li><a href='#balance8pars'><p>Parameter estimates of models for the balance8 data set</p></a></li>
<li><a href='#confint'><p>Confidence intervals Visser et al (2000)</p></a></li>
<li><a href='#conservation'><p>Conservation of liquid</p></a></li>
<li><a href='#dccs'><p>Dimensional Change Card Sort Task Data</p></a></li>
<li><a href='#dccs_boot_LR'>
<p>dccs boot LR</p></a></li>
<li><a href='#disc42'><p>Discrimination Learning Data</p></a></li>
<li><a href='#discrimination'><p>Discrimination Learning Data</p></a></li>
<li><a href='#FFBS_BinomialNormal'>
<p>Posterior (MCMC) samples for a hidden Markov model with a Binomial and Normal response using the forward-filtering backward-sampling algorithm.</p>
</p></a></li>
<li><a href='#hmm'>
<p>Fit hidden Markov and latent class models.</p>
</p></a></li>
<li><a href='#IGT'><p>Iowa Gambling Task data</p></a></li>
<li><a href='#MAR_simulation_results'>
<p>Missing at random (MAR) simulation results.</p></a></li>
<li><a href='#MNAR_simulation_results'>
<p>Missing not at random (MNAR) simulation results.</p></a></li>
<li><a href='#perth'><p>Perth dams water levels.</p></a></li>
<li><a href='#SEsamples'>
<p>Bootstrap Samples for Simple 2-State Model</p></a></li>
<li><a href='#simplehmm'><p>Hmm toy data set from Visser et al (2000)</p></a></li>
<li><a href='#speed_boot_LR'>
<p>speed boot LR</p></a></li>
<li><a href='#speed_boot_LR_extra'>
<p>speed boot LR</p></a></li>
<li><a href='#speed_boot_par'>
<p>speed boot par</p></a></li>
<li><a href='#speed1'><p>Speed Accuracy Switching Data</p></a></li>
<li><a href='#WPT'><p>Weather Prediction Task Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.0-0</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-05-26</td>
</tr>
<tr>
<td>Title:</td>
<td>"Mixture and Hidden Markov Models with R" Datasets and Example
Code</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), depmixS4, stats4</td>
</tr>
<tr>
<td>Description:</td>
<td>Datasets and code examples that accompany our book Visser &amp; Speekenbrink (2021), "Mixture and Hidden Markov Models with R", <a href="https://depmix.github.io/hmmr/">https://depmix.github.io/hmmr/</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td>&lt;<a href="https://depmix.github.io/hmmr/&amp;gt;">https://depmix.github.io/hmmr/&gt;</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-26 08:15:24 UTC; ingmar</td>
</tr>
<tr>
<td>Author:</td>
<td>Ingmar Visser [aut, cre],
  Maarten Speekenbrink [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ingmar Visser &lt;i.visser@uva.nl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-27 07:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='balance8'>Repeated measures on the balance scale</h2><span id='topic+balance8'></span>

<h3>Description</h3>

<p>Data are from 8 repeated measurements of 25 balance scale items with 1004 
participants ranging from 6-17 years of age. The data are aggregated over
5 item types: weight (w), distance (d), conflict weight (cw), conflict 
distance (cd), and conflict balance (cb). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(balance8)</code></pre>


<h3>Format</h3>

<p>A data frame with 8032 observations on the following 23 variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>the participant id number.</p>
</dd>
<dt><code>age</code></dt><dd><p>the participant age in years.</p>
</dd>
<dt><code>sex</code></dt><dd><p>a factor with levels <code>m</code> <code>f</code></p>
</dd>
<dt><code>group</code></dt><dd><p>the participant school group number; groups 3-8 are in primary school; 
corollary10 and 11 in secondary school.</p>
</dd>
<dt><code>school</code></dt><dd><p>a factor with levels <code>primary</code> <code>secondary</code></p>
</dd>
<dt><code>time</code></dt><dd><p>the number of the repeated measurement.</p>
</dd>
<dt><code>wc</code></dt><dd><p>the number of correct weight items.</p>
</dd>
<dt><code>wi</code></dt><dd><p>the number of incorrect weight items.</p>
</dd>
<dt><code>ws</code></dt><dd><p>the total number of weight items.</p>
</dd>
<dt><code>dc</code></dt><dd><p>the number of correct distance items.</p>
</dd>
<dt><code>di</code></dt><dd><p>the number of incorrect distance items.</p>
</dd>
<dt><code>ds</code></dt><dd><p>the total number of distance items.</p>
</dd>
<dt><code>cwc</code></dt><dd><p>the number of correct conflict-weight items.</p>
</dd>
<dt><code>cwi</code></dt><dd><p>the number of incorrect conflict-weight items.</p>
</dd>
<dt><code>cws</code></dt><dd><p>the total number of conflict-weight items.</p>
</dd>
<dt><code>cdc</code></dt><dd><p>the number of correct conflict-distance items.</p>
</dd>
<dt><code>cdi</code></dt><dd><p>the number of incorrect conflict-distance items.</p>
</dd>
<dt><code>cds</code></dt><dd><p>the total number of conflict-distance items.</p>
</dd>
<dt><code>cbc</code></dt><dd><p>the number of correct conflict-balance items.</p>
</dd>
<dt><code>cbi</code></dt><dd><p>the number of incorrect conflict-balance items.</p>
</dd>
<dt><code>cbs</code></dt><dd><p>the total number of conflict-balance items.</p>
</dd>
<dt><code>totalCor</code></dt><dd><p>the total number of correct  items.</p>
</dd>
<dt><code>totalTrials</code></dt><dd><p>the total number of items.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Brenda Jansen, University of Amsterdam. Unpublished data. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(balance8)
</code></pre>

<hr>
<h2 id='balance8pars'>Parameter estimates of models for the balance8 data set</h2><span id='topic+balance8pars'></span>

<h3>Description</h3>

<p>Parameter estimates of hidden Markov models with 3-8 states for the balance8 data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(balance8pars)</code></pre>


<h3>Format</h3>

<p>A (named) list with parameter estumates for models with 3-8 states. Each 
element contains additional attributes such as &quot;message&quot; reflecting the 
corresponding slots of the depmix.fitted object from which the parameters
were extracted (using getpars).
</p>


<h3>Details</h3>

<p>The list is generated with the following code: 
</p>
<pre>
data(balance8)
multstart &lt;- function(model, nr=10, initIters=10, verbose=TRUE) {
  llbest &lt;- as.numeric(logLik(model))
  bestmodel &lt;- model
  for(i in 1:nr) {
    fmod &lt;- fit(model, emcontrol=em.control(maxit=initIters)) 
	if(verbose) print(paste(i,": ", logLik(fmod)))
    if(logLik(fmod) &gt; llbest) {
      llbest &lt;- logLik(fmod)
      bestmodel &lt;- fmod
    }
  }
  bestmodel &lt;- fit(bestmodel, emcontrol=em.control(random.start=FALSE))
  return(bestmodel)
}

set.seed(12)

hm3id &lt;- depmix(list(cbind(wc,wi)~1,cbind(dc,di)~1,cbind(cwc,cwi)~1,
  cbind(cdc,cdi)~1,cbind(cbc,cbi)~1), 
	data=balance8, family=list(binomial("identity"),binomial("identity"),
	binomial("identity"),binomial("identity"),binomial("identity")), 
	ntimes=rep(8,1004), ns=3,
	respst=rep(0.5,15))
	
fhm3id &lt;- multstart(hm3id)

hm4id &lt;- depmix(list(cbind(wc,wi)~1,cbind(dc,di)~1,cbind(cwc,cwi)~1,
  cbind(cdc,cdi)~1,cbind(cbc,cbi)~1), 
	data=balance8, family=list(binomial("identity"),binomial("identity"),
	binomial("identity"),binomial("identity"),binomial("identity")), 
	ntimes=rep(8,1004), ns=4,
	respst=rep(0.5,20))
	
fhm4id &lt;- multstart(hm4id)


hm5id &lt;- depmix(list(cbind(wc,wi)~1,cbind(dc,di)~1,cbind(cwc,cwi)~1,
  cbind(cdc,cdi)~1,cbind(cbc,cbi)~1), 
	data=balance8, family=list(binomial("identity"),binomial("identity"),
	binomial("identity"),binomial("identity"),binomial("identity")), 
	ntimes=rep(8,1004), ns=5,
	respst=rep(0.5,25))
	
fhm5id &lt;- multstart(hm5id)

hm6id &lt;- depmix(list(cbind(wc,wi)~1,cbind(dc,di)~1,cbind(cwc,cwi)~1,
  cbind(cdc,cdi)~1,cbind(cbc,cbi)~1), 
	data=balance8, family=list(binomial("identity"),binomial("identity"),
	binomial("identity"),binomial("identity"),binomial("identity")), 
	ntimes=rep(8,1004), ns=6,
	respst=rep(0.5,30))
	
fhm6id &lt;- multstart(hm6id)

hm7id &lt;- depmix(list(cbind(wc,wi)~1,cbind(dc,di)~1,cbind(cwc,cwi)~1,
  cbind(cdc,cdi)~1,cbind(cbc,cbi)~1), 
	data=balance8, family=list(binomial("identity"),binomial("identity"),
	binomial("identity"),binomial("identity"),binomial("identity")), 
	ntimes=rep(8,1004), ns=7,
	respst=rep(0.5,35))
	
fhm7id &lt;- multstart(hm7id)

set.seed(1)

hm8id &lt;- depmix(list(cbind(wc,wi)~1,cbind(dc,di)~1,cbind(cwc,cwi)~1,
  cbind(cdc,cdi)~1,cbind(cbc,cbi)~1), 
	data=balance8, family=list(binomial("identity"),binomial("identity"),
	binomial("identity"),binomial("identity"),binomial("identity")), 
	ntimes=rep(8,1004), ns=8,
	respst=rep(0.5,40))
	
fhm8id &lt;- multstart(hm8id)

balance8models &lt;- list(fhm3id,fhm4id,fhm5id,fhm6id,fhm7id,fhm8id)

balance8pars &lt;- list()
for(i in 1:length(balance8models)) {
  balance8pars[[i]] &lt;- getpars(balance8models[[i]])
  attr(balance8pars[[i]], "message") &lt;- balance8models[[i]]@message
  attr(balance8pars[[i]], "conMat") &lt;- balance8models[[i]]@conMat
  attr(balance8pars[[i]], "lin.upper") &lt;- balance8models[[i]]@lin.upper
  attr(balance8pars[[i]], "lin.lower") &lt;- balance8models[[i]]@lin.lower
}
names(balance8pars) &lt;- c("fhm3id","fhm4id","fhm5id","fhm6id","fhm7id","fhm8id")
</pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(balance8)
data(balance8pars)
# reconstruct the list of fitted models from the parameters
balance8models &lt;- list()
for(i in 1:length(balance8pars)) {
  # define model
  mod &lt;- depmix(list(cbind(wc,wi)~1,cbind(dc,di)~1,cbind(cwc,cwi)~1,
    cbind(cdc,cdi)~1,cbind(cbc,cbi)~1), 
    data=balance8, family=list(binomial("identity"),binomial("identity"),
    binomial("identity"),binomial("identity"),binomial("identity")), 
    ntimes=rep(8,1004), ns=attr(balance8pars[[i]],"nstates"))
  # set the parameters to the estimated ones
  mod &lt;- setpars(mod, balance8pars[[i]])
  # convert to a depmix.fitted object
  mod &lt;- as(mod,"depmix.fitted")
  # set slots of depmix.fitted object
  mod@message &lt;- attr(balance8pars[[i]],"message")
  mod@conMat &lt;- attr(balance8pars[[i]],"conMat")
  mod@lin.upper &lt;- attr(balance8pars[[i]],"lin.upper")
  mod@lin.lower &lt;- attr(balance8pars[[i]],"lin.lower")
  mod@posterior &lt;- viterbi(mod)
  # add to list of models
  balance8models[[i]] &lt;- mod
}
names(balance8models) &lt;- c("fhm3id","fhm4id","fhm5id","fhm6id","fhm7id","fhm8id")
</code></pre>

<hr>
<h2 id='confint'>Confidence intervals Visser et al (2000)</h2><span id='topic+confint'></span>

<h3>Description</h3>

<p>Values from Table 1 of Visser et al (2000) with confidence intervals obtained using
four different methods; 1) likelihood profiles, 2) bootstrap with 500 samples, 
3) bootstrap with 1000 samples, 4) finite differences approximation of the hessian. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(confint)</code></pre>


<h3>Format</h3>

<p>A data.frame with 9 variables for each parameter of a 2-state hidden Markov model fitted
to data <code><a href="#topic+simplehmm">simplehmm</a></code>:
</p>

<dl>
<dt>par</dt><dd><p>parameter name, see Visser et al (2000) for details.</p>
</dd>
<dt>true</dt><dd><p>true value of the parameter.</p>
</dd>
<dt>mle</dt><dd><p>maximum likelihood estimate of the parameter.</p>
</dd>
<dt>prof</dt><dd><p>the size of the confidence interval resulting from the profile likelihood method.</p>
</dd>
<dt>left</dt><dd><p>the left hand boundary of the (95%) confidence interval using the likelihood profile method.</p>
</dd>
<dt>right</dt><dd><p>the right hand boundary of the (95%) confidence interval using the likelihood profile method.</p>
</dd>
<dt>b500</dt><dd><p>the size of the confidence interval resulting from 500 bootstrap samples.</p>
</dd>
<dt>b1000</dt><dd><p>the size of the confidence interval resulting from 1000 bootstrap samples.</p>
</dd>
<dt>fdh</dt><dd><p>the size of the confidence interval based on the finite differences approximation of the hessian.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ingmar Visser, Maartje E. J. Raijmakers, and Peter C. M. Molenaar (2000).
Confidence intervals for hidden Markov model parameters. <em>British journal
of mathematical and statistical psychology</em>, 53, p. 317-327.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(confint)
</code></pre>

<hr>
<h2 id='conservation'>Conservation of liquid</h2><span id='topic+conservation'></span>

<h3>Description</h3>

<p>This data set is from a conservation of liquid task adminstered to 101
children aged 6-10, measured at 5 occasions.  The data provided here
are those analyzed in <cite>Schmittmann et al.  2005</cite> in Illustration
1, which is part of a larger data set described <cite>Van der Maas,
1993</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(discrimination)
</code></pre>


<h3>Format</h3>

<p>A data frame with 101 rows with 6 variables:
</p>

<dl>
<dt><code>sex</code></dt><dd><p>a factor giving the sex of the participants.</p>
</dd>
<dt><code>r1</code></dt><dd><p>participant responses at measurement occascion 1.</p>
</dd>
<dt><code>r2</code></dt><dd><p>participant responses at measurement occascion 2.</p>
</dd>
<dt><code>r3</code></dt><dd><p>participant responses at measurement occascion 3.</p>
</dd>
<dt><code>r4</code></dt><dd><p>participant responses at measurement occascion 4.</p>
</dd>
<dt><code>r5</code></dt><dd><p>participant responses at measurement occascion 5.</p>
</dd>
</dl>



<h3>Source</h3>

<p>van der Maas, H. L. J..  (1993).  <em>Catastrophe analysis of
stagewise cognitive development: Model, method and applications.</em>
Doctoral dissertation (Dissertatie reeks 1993-2), University of
Amsterdam.
</p>
<p>Schmittmann, V. D., Dolan, C. V., van der Maas, H. L., &amp; Neale, M. C.
(2005).  Discrete latent Markov models for normally distributed response
data.  <em>Multivariate Behavioral Research</em>, 40(4), 461-488.
</p>

<hr>
<h2 id='dccs'>Dimensional Change Card Sort Task Data</h2><span id='topic+dccs'></span><span id='topic+dccslong'></span>

<h3>Description</h3>

<p>Data from 3-5 year old children performing on the dimensional 
change card sort task published in Van Bers et al (2011). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dccs)
data(dccslong)
</code></pre>


<h3>Format</h3>

<p>A data.frame consisting of the following variable:
</p>

<dl>
<dt><code>pp</code></dt><dd><p>participant number</p>
</dd>
<dt><code>ageM</code></dt><dd><p>(numeric) age in months</p>
</dd>
<dt><code>ageY</code></dt><dd><p>(numeric) age in years</p>
</dd>
<dt><code>ageGr</code></dt><dd><p>(numeric) age group</p>
</dd>
<dt><code>sex</code></dt><dd><p>(numeric) age group</p>
</dd>
<dt><code>nTrPre</code></dt><dd><p>(numeric) number of trials completed pre-switch</p>
</dd>
<dt><code>nTrPre</code></dt><dd><p>(numeric) number of trials correct in pre-switch trials</p>
</dd>
<dt><code>t1Post</code></dt><dd><p>(numeric) indicator variable for post switch trial 
indicating correct (1) or incorrect (0)</p>
</dd>
<dt><code>t2Post</code></dt><dd><p>(numeric) indicator variable for post switch trial 
indicating correct (1) or incorrect (0)</p>
</dd>
<dt><code>t3Post</code></dt><dd><p>(numeric) indicator variable for post switch trial 
indicating correct (1) or incorrect (0)</p>
</dd>
<dt><code>t4Post</code></dt><dd><p>(numeric) indicator variable for post switch trial 
indicating correct (1) or incorrect (0)</p>
</dd>
<dt><code>t5Post</code></dt><dd><p>(numeric) indicator variable for post switch trial 
indicating correct (1) or incorrect (0)</p>
</dd>
<dt><code>t6Post</code></dt><dd><p>(numeric) indicator variable for post switch trial 
indicating correct (1) or incorrect (0)</p>
</dd>
<dt><code>nCorPost</code></dt><dd><p>(numeric) number of trials correct post-switch</p>
</dd>
<dt><code>passPost</code></dt><dd><p>(numeric) indicator variable whether post-switch test was passed</p>
</dd>
</dl>



<h3>Source</h3>

<p>Bianca M.C.W. van Bers, Ingmar Visser, Tessa J.P. van Schijndel, 
Dorothy J. Mandell and Maartje E.J. Raijmakers (2011). The dynamics 
of development on the Dimensional Change Card Sorting task. 
<em>Developmental Science, vol 14(5)</em>, 960-971.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the original data was in wide format; for analysis with hidden Markov models, 
# data in long format is more convenient; the following code was used to reshape 
# the data from wide to long format (and make a selection of the columns)

data(dccs)
dccslong &lt;- reshape(
	dccs[,c("pp","ageM","sex","t1Post","t2Post","t3Post","t4Post","t5Post","t6Post")],
	direction="long",
	varying=list(4:9) )
dccslong &lt;- dccslong[order(dccslong$pp),-6]
names(dccslong) &lt;- c("pp","ageM","sex","trial","acc")

</code></pre>

<hr>
<h2 id='dccs_boot_LR'>
dccs boot LR
</h2><span id='topic+dccs_boot_LR'></span>

<h3>Description</h3>

<p>Example of a parametric bootstrap for model selection with the dccs data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("dccs_boot_LR")</code></pre>


<h3>Format</h3>

<p>A <code>boot</code> object
</p>


<h3>Details</h3>

<p>The bootstrap sample was generated by the following code:
</p>
<pre>require(depmixS4)
      require(hmmr)
      require(boot)
      
      data(dccs)
      m2 &lt;- mix(response=cbind(nCorPost,6-nCorPost)~1,nstates=2,
                data=dccs,family=binomial())
      set.seed(1234)
      fm2 &lt;- fit(m2)
      set.seed(1234)
      fm3 &lt;- fit(mix(response=cbind(nCorPost,6-nCorPost)~1, 
                     nstates=3, data=dccs,family=binomial()))
      
      boot.fun &lt;- function(model) {
        ok &lt;- FALSE
        while(!ok) {
          bootdat &lt;- data.frame(
            simulate(model)@response[[1]][[1]]@y)
          fboot2 &lt;- try({
            mod &lt;- mix(cbind(X1,X2)~1, nstates=2, 
                       family=binomial(), data=bootdat)
            mod &lt;- setpars(mod,getpars(fm2))
            fit(mod,emcontrol=em.control(random.start=FALSE),
                verbose=FALSE)
          })
          fboot3 &lt;- try({
            mod &lt;- mix(cbind(X1,X2)~1, nstates=3, 
                       family=binomial(), data=bootdat)
            mod &lt;- setpars(mod,getpars(fm3))
            fit(mod,emcontrol=em.control(random.start=FALSE),
                verbose=FALSE)
          })
          if(!inherits(fboot2,"try-error") &amp;&amp; 
             !inherits(fboot3,"try-error") &amp;&amp;
             logLik(fboot3) &gt;= logLik(fboot2)) ok &lt;- TRUE
          # if(ok) if(logLik(fboot3) &lt; logLik(fboot2)) ok &lt;- FALSE
        }  
        llratio(fboot3,fboot2)@value
      }
      set.seed(1234)
      dccs_boot_LR &lt;- boot(fm2, boot.fun, R=10000, sim="parametric")
    </pre>


<h3>Examples</h3>

<pre><code class='language-R'>  data(dccs_boot_LR)
</code></pre>

<hr>
<h2 id='disc42'>Discrimination Learning Data</h2><span id='topic+disc42'></span>

<h3>Description</h3>

<p>This data set is a selection of six participants' responses from the 
<code>discrimination</code> data set. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(disc42)
</code></pre>


<h3>Format</h3>

<p>A data frame consisting of the following variable:
</p>

<dl>
<dt><code>acc</code></dt><dd><p>a factor of accuracy scores (incorrect/correct)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Maartje E. J. Raijmakers, Conor V. Dolan and Peter C. M. Molenaar 
(2001).  Finite mixture distribution models of simple discrimination
learning. <em>Memory \&amp; Cognition</em>, vol 29(5).
</p>
<p>Ingmar Visser, Verena D. Schmittmann, and Maartje E. J. Raijmakers
(2007).  Markov process models for discrimination learning.  In: Kees
van Montfort, Han Oud, and Albert Satorra (Eds.), <em>Longitudinal
models in the behavioral and related sciences</em>, Mahwah (NJ): Lawrence
Erlbaum Associates.
</p>
<p>Verena D. Schmittmann, Ingmar Visser and Maartje E. J. Raijmakers
(2006).  Multiple learning modes in the development of rule-based
category-learning task performance.  <em>Neuropsychologia, vol
44(11)</em>, p.  2079-2091.
</p>

<hr>
<h2 id='discrimination'>Discrimination Learning Data</h2><span id='topic+discrimination'></span>

<h3>Description</h3>

<p>This data set is from a simple discrimation learning experiment.  It
consists of 192 binary series of responses of different lengths. This
is a subset of the data described by <cite>Raijmakers et al. (2001)</cite>, and
it is analyzed much more extensively using latent Markov models and depmix in
<cite>Schmittmann et al. (2006)</cite> and <cite>Visser et al. (2006).</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(discrimination)
</code></pre>


<h3>Format</h3>

<p>A data frame with a total of 3139 observations on the following variable:
</p>

<dl>
<dt><code>acc</code></dt><dd><p>a factor of accuracy scores (incorrect/correct)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Maartje E. J. Raijmakers, Conor V. Dolan and Peter C. M. Molenaar 
(2001).  Finite mixture distribution models of simple discrimination
learning. <em>Memory \&amp; Cognition</em>, vol 29(5).
</p>
<p>Ingmar Visser, Verena D. Schmittmann, and Maartje E. J. Raijmakers
(2007).  Markov process models for discrimination learning.  In: Kees
van Montfort, Han Oud, and Albert Satorra (Eds.), <em>Longitudinal
models in the behavioral and related sciences</em>, Mahwah (NJ): Lawrence
Erlbaum Associates.
</p>
<p>Verena D. Schmittmann, Ingmar Visser and Maartje E. J. Raijmakers
(2006).  Multiple learning modes in the development of rule-based
category-learning task performance.  <em>Neuropsychologia, vol
44(11)</em>, p.  2079-2091.
</p>

<hr>
<h2 id='FFBS_BinomialNormal'>
Posterior (MCMC) samples for a hidden Markov model with a Binomial and Normal response using the forward-filtering backward-sampling algorithm.
</h2><span id='topic+FFBS_BinomialNormal'></span>

<h3>Description</h3>

<p>Posterior (MCMC) samples for a hidden Markov model with a Binomial and Normal response using the forward-filtering backward-sampling algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  
  FFBS_BinomialNormal(bin,norm,nstates,hyperPars=list(),ntimes,niter=1000,nburnin=0)
  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FFBS_BinomialNormal_+3A_bin">bin</code></td>
<td>
<p>the Binomial response variable. As in the glm function, this can be a binary vector with 1 indicating success and 0 failure, a factor where the first level is considered a failure and all other leves success, or a matrix with the number of successes and failures in the columns.</p>
</td></tr>
<tr><td><code id="FFBS_BinomialNormal_+3A_norm">norm</code></td>
<td>
<p>the Normal response variable. This should be a numeric vector.</p>
</td></tr>
<tr><td><code id="FFBS_BinomialNormal_+3A_nstates">nstates</code></td>
<td>
<p>the required number of states in the hidden Markov model.</p>
</td></tr>
<tr><td><code id="FFBS_BinomialNormal_+3A_hyperpars">hyperPars</code></td>
<td>
<p>a named <code>list</code> with values of the hyper-parameters. See details.</p>
</td></tr>
<tr><td><code id="FFBS_BinomialNormal_+3A_ntimes">ntimes</code></td>
<td>
<p>the lengths of time series in arguments <code>bin</code> and <code>norm</code>; it
defaults to assuming a single time series of length <code>length(bin)</code>.</p>
</td></tr>
<tr><td><code id="FFBS_BinomialNormal_+3A_niter">niter</code></td>
<td>
<p>number of iterations to run the sampler for.</p>
</td></tr>
<tr><td><code id="FFBS_BinomialNormal_+3A_nburnin">nburnin</code></td>
<td>
<p>number of initial samples to discard as burnin,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function runs the forward-filtering backwards-sampling MCMC algorithm for a hidden Markov model with a Binomial and Normal response variable. The response variables are assumed conditionally independent given the states.
</p>
<p>The following conjugate prior distributions are used:
</p>
<p>For the initial state probabilities, a Dirichlet prior with parameter vector <code>init_alpha</code>
</p>
<p>For each row in the transition probability matrix, a Dirichlet prior is used. The parameters of these Dirichlet distributions are contained in the matrix <code>trans_alpha</code>.
</p>
<p>For the probability of correct in the Binomial response, a Beta prior is used, with parameters <code>bin_alpha</code> and <code>bin_beta</code>.
</p>
<p>For the mean and variance of the Normal response, a Normal-inverse-Gamma prior is used.
</p>
<p>This function was written mainly for didactive purposes, not for speed (or compatibility with other packages which provide posterior samples). 
</p>


<h3>Value</h3>

<p>A named list with samples of the different parameters.
</p>


<h3>Author(s)</h3>

<p>Maarten Speekenbrink
</p>


<h3>References</h3>

<p>Visser, I., &amp; Speekenbrink, M. (in preparation). Mixture and hidden Markov models in R.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
  data(speed)
  set.seed(1)
  hyperPars &lt;- list(norm_invsigma_scale=.01,norm_invsigma_shape=.01,norm_mu_sca=.1)
  mcmc_samples &lt;- FFBS_BinomialNormal(speed$corr,speed$rt,nstates=2,
        ntimes=c(168,134,137),niter=500,hyperPars = hyperPars)
        
  plot(mcmc_samples$mu[,1])
  hist(mcmc_samples$mu[,1])

## End(Not run)

</code></pre>

<hr>
<h2 id='hmm'>
Fit hidden Markov and latent class models.
</h2><span id='topic+hmm'></span><span id='topic+lca'></span>

<h3>Description</h3>

<p><code>hmm</code> fits a hidden Markov model to its first argument.  
<code>lca</code> fits a latent class model or mixture model to its first
argument.  
</p>
<p>Both functions provide an easy user-interface to the functions
provided in <span class="pkg">depmixS4</span> by automagically setting some argument values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
hmm(data, nstates, fit = TRUE, ntimes = NULL, family = NULL, verbose=FALSE, ...)
lca(data, nclasses, fit = TRUE, family = NULL, verbose=FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hmm_+3A_data">data</code></td>
<td>
<p>(columns of) a <code>data.frame</code> or <code>matrix</code> like
object.</p>
</td></tr>
<tr><td><code id="hmm_+3A_nstates">nstates</code></td>
<td>
<p>the required number of states of the hidden Markov
model.</p>
</td></tr>
<tr><td><code id="hmm_+3A_nclasses">nclasses</code></td>
<td>
<p>the required number of classes of the mixture or latent
class model.</p>
</td></tr>
<tr><td><code id="hmm_+3A_fit">fit</code></td>
<td>
<p><code>logical</code> indicating whether the model needs to be
fitted or returned unfitted; the latter is necessary if one wants to
set constraints on the parameters, which then requires using the
<code>fit</code> function from <span class="pkg">depmixS4</span>.</p>
</td></tr>
<tr><td><code id="hmm_+3A_ntimes">ntimes</code></td>
<td>
<p>the lengths of time series in argument <code>data</code>; it
defaults to assuming a single time series of length <code>nrow(data)</code>.</p>
</td></tr>
<tr><td><code id="hmm_+3A_family">family</code></td>
<td>
<p>(a list of) name(s) of the distribution(s) to be used in
fitting; if provided, it should have length of the number of the number
of columns in <code>data</code>, see Details.</p>
</td></tr>
<tr><td><code id="hmm_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code>; when <code>TRUE</code> iteration information
of the fitting process is printed.</p>
</td></tr>
<tr><td><code id="hmm_+3A_...">...</code></td>
<td>
<p>not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distributions used in fitting models are the <code>multinomial</code> for
<code>factor</code> data columns and <code>gaussian</code> for <code>numeric</code> data
columns.  Data columns are treated as conditionally independent variables.
Use <code>makeDepmix</code> in the <span class="pkg">depmixS4</span> package to specify multivariate
distributions.
</p>


<h3>Value</h3>

<p><code>hmm</code> returns a <code>depmix</code> or <code>depmix.fitted</code> object depending
on the value of the <code>fit</code> argument; <code>lca</code> similarly returns
either a <code>mix</code> or <code>mix.fitted</code> object.
</p>
<p>All these can be <code>print</code>'ed and <code>summary</code>'zed.
</p>


<h3>Author(s)</h3>

<p>Ingmar Visser
</p>


<h3>References</h3>

<p>Visser, I., &amp; Speekenbrink, M. (2010).  depmixS4: an R-package for hidden
Markov models.  Journal of Statistical Software, 36(7), 1-21.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(conservation)

set.seed(1)
m2 &lt;- lca(conservation$"r1", nclasses=2)
m2
summary(m2)

data(speed1)

set.seed(1)
hm2 &lt;- hmm(speed1$"RT", nstates=2)
hm2
summary(hm2)

</code></pre>

<hr>
<h2 id='IGT'>Iowa Gambling Task data</h2><span id='topic+IGT'></span>

<h3>Description</h3>

<p>This data set contains responses of 30 participants on the Iowa Gambling Task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(IGT)</code></pre>


<h3>Format</h3>

<p>A data frame with 3000 observations on the following variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>a factor with participant IDs</p>
</dd>
<dt><code>trial</code></dt><dd><p>a numeric vector with trial numbers</p>
</dd>
<dt><code>deck</code></dt><dd><p>a factor with the deck chosen on each trial (A-D)</p>
</dd>
<dt><code>wager</code></dt><dd><p>a factor indicating whether participants wagered low or high</p>
</dd>
<dt><code>win</code></dt><dd><p>a numeric variable with the amount won on each trial</p>
</dd>
<dt><code>loss</code></dt><dd><p>a numeric variable with the amount lost on each trial</p>
</dd>
<dt><code>gdeck</code></dt><dd><p>a factor indicating whether the chosen deck was good/advantageous (TRUE) or not (FALSE)</p>
</dd>
<dt><code>fdeck</code></dt><dd><p>a factor indicating whether the chosen deck has a relatively high frequency of losses (TRUE) or not (FALSE)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Konstantinidis, E. and Shanks, D.R. (2014). Don't Bet on it! Wagering as a Measure of Awareness in Decision Making under Uncertainty. <em>Journal of Experimental Psychology: General</em>, 143(6), 2111-2134.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(IGT)
</code></pre>

<hr>
<h2 id='MAR_simulation_results'>
Missing at random (MAR) simulation results.
</h2><span id='topic+MAR_simulation_results'></span>

<h3>Description</h3>

<p>Results of a simulation study on the effect of missing data on estimates of parameters of a hidden Markov model. In the simulation, 1000 datasets were simulated, each consisting of 100 time series of length 50. The model generating the data was a hidden Markov model with 3 states. Missing values were generated for 25% of cases, independent of the hidden state (i.e. data can be considered missing at random.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("MAR_simulation_results")</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with the following variables:
</p>

<dl>
<dt><code>parameter</code></dt><dd><p>Parameter name</p>
</dd>
<dt><code>true</code></dt><dd><p>True value of parameter</p>
</dd>
<dt><code>MAR_estimates_mean</code></dt><dd><p>Average of parameter estimates for a model that assumes MAR.</p>
</dd>
<dt><code>MAR_estimates_sd</code></dt><dd><p>Standard deviation of parameter estimates for a model that assumes MAR.</p>
</dd>
<dt><code>MAR_estimates_MAE</code></dt><dd><p>Mean Absolute Error of parameter estimates for a model that assumes MAR.</p>
</dd>
<dt><code>MNAR_estimates_mean</code></dt><dd><p>Average of parameter estimates for a model that assumes MNAR.</p>
</dd>
<dt><code>MNAR_estimates_sd</code></dt><dd><p>Standard deviation of parameter estimates for a model that assumes MNAR.</p>
</dd>
<dt><code>MNAR_estimates_MAE</code></dt><dd><p>Mean Absolute Error of parameter estimates for a model that assumes MNAR.</p>
</dd>
<dt><code>percMAE</code></dt><dd><p>Relative MAE of the MNAR model over the MAR model (e.g. MAE_MNAR/MAE_MAR)</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data frame was generated with the following code
</p>
<pre>
library(depmixS4)

### Start simulation

nsim &lt;- 1000
nrep &lt;- 100
nt &lt;- 50

set.seed(1234)
randomSeeds &lt;- sample(seq(1,nsim*1000),nsim)
out &lt;- rep(list(vector("list",3)),nsim)

prior &lt;- c(8,1,1)
prior &lt;- prior/sum(prior)
transition &lt;- 5*diag(3) + 1
transition &lt;- transition/rowSums(transition)
means &lt;- c(-1,0,1)
sds &lt;- c(3,3,3)
pmiss &lt;- c(.25,.25,.25)

truepars1 &lt;- c(prior,as.numeric(t(transition)),as.numeric(rbind(means,sds)))
truepars2 &lt;- c(prior,as.numeric(t(transition)),as.numeric(rbind(means,sds,1-pmiss,pmiss)))

for(sim in 1:nsim) {
  set.seed(randomSeeds[sim])
  truestate &lt;- matrix(nrow=nt,ncol=nrep) 
  for(i in 1:nrep) {
    truestate[1,i] &lt;- sample(1:3,size=1,prob=prior)
    for(t in 2:nt) {
      truestate[t,i] &lt;- sample(1:3,size=1,prob=transition[truestate[t-1,i],])
    }
  }
  dat &lt;- data.frame(trueState=as.numeric(truestate),trial=1:nt)
  dat$trueResponse &lt;- rnorm(nrow(dat),mean=means[dat$trueState],sd=sds[dat$trueState])
  dat$missing &lt;- rbinom(nrow(dat),size=1,prob=pmiss[dat$trueState])
  dat$response &lt;- dat$trueResponse
  dat$response[dat$missing==1] &lt;- NA
  
  set.seed(randomSeeds[sim])
  mod &lt;- depmix(list(response~1),family=list(gaussian()),data=dat,nstates=3,ntimes=rep(nt,nrep))
  mod &lt;- setpars(mod,truepars1)
  ok &lt;- FALSE
  ntry &lt;- 1
  while(!ok &amp; ntry &lt;= 50) {
    fmod &lt;- try(fit(mod,emcontrol=em.control(maxit = 5000, random.start=FALSE),verbose=FALSE))
    if(!inherits(fmod,"try-error")) {
      if(fmod@message == "Log likelihood converged to within tol. (relative change)") ok &lt;- TRUE
    }
    ntry &lt;- ntry + 1
  }
  out[[sim]][[1]] &lt;- list(pars=getpars(fmod),logLik=logLik(fmod),viterbi=posterior(fmod)[,1],trueState=dat$trueState)
  
  set.seed(randomSeeds[sim])
  mod &lt;- depmix(list(response~1,missing~1),family=list(gaussian(),multinomial("identity")),data=dat,nstates=3,ntimes=rep(nt,nrep))
  mod &lt;- setpars(mod,truepars2)
  ok &lt;- FALSE
  ntry &lt;- 1
  while(!ok &amp; ntry &lt;= 50) {
    fmod &lt;- try(fit(mod,emcontrol=em.control(maxit = 5000, random.start = FALSE),verbose=FALSE))
    if(!inherits(fmod,"try-error")) {
      if(fmod@message == "Log likelihood converged to within tol. (relative change)") ok &lt;- TRUE
    }
    ntry &lt;- ntry + 1
  }
  out[[sim]][[2]] &lt;- list(pars=getpars(fmod),logLik=logLik(fmod),viterbi=posterior(fmod)[,1],trueState=dat$trueState)
}

### End simulation

### Process results
library(reshape2)
library(dplyr)
library(tidyr)

simi &lt;- out

bias1 &lt;- matrix(0.0,ncol=length(truepars1),nrow=nsim)
bias2 &lt;- matrix(0.0,ncol=length(truepars2),nrow=nsim)

colnames(bias1) &lt;- names(simi[[1]][[1]][[1]])
colnames(bias2) &lt;- names(simi[[1]][[2]][[1]])

pcorstate1 &lt;- rep(0.0,nsim)
pcorstate2 &lt;- rep(0.0,nsim)

for(sim in 1:nsim) {
  tmp &lt;- simi[[sim]][[1]][[1]]
  pr &lt;- tmp[1:3]
  trt &lt;- matrix(tmp[4:12],ncol=3)
  ms &lt;- tmp[c(13,15,17)]
  sds &lt;- tmp[c(14,16,18)] 
  ord &lt;- order(ms)
  bias1[sim,] &lt;- c(pr[ord],trt[ord,ord],as.numeric(rbind(ms[ord],sds[ord]))) - truepars1
  fsta &lt;- recode(simi[[sim]][[1]]$viterbi,`1` = which(ord == 1), `2` = which(ord == 2), `3` = which(ord == 3))
  pcorstate1[sim] &lt;- sum(fsta == simi[[sim]][[1]]$trueState)/(nrep*nt)
  
  tmp &lt;- simi[[sim]][[2]][[1]]
  pr &lt;- tmp[1:3]
  trt &lt;- matrix(tmp[4:12],ncol=3)
  ms &lt;- tmp[c(13,17,21)]
  sds &lt;- tmp[c(14,18,22)]
  ps0 &lt;- tmp[c(15,19,23)]
  ps1 &lt;- tmp[c(16,20,24)]
  ord &lt;- order(ms)
  bias2[sim,] &lt;- c(pr[ord],trt[ord,ord],as.numeric(rbind(ms[ord],sds[ord],ps0[ord],ps1[ord]))) - truepars2
  fsta &lt;- recode(simi[[sim]][[2]]$viterbi,`1` = which(ord == 1), `2` = which(ord == 2), `3` = which(ord == 3))
  pcorstate2[sim] &lt;- sum(fsta == simi[[sim]][[2]]$trueState)/(nrep*nt)
}

sim3_bias1 &lt;- bias1
sim3_bias2 &lt;- bias2
sim3_est1 &lt;- t(t(bias1) + truepars1)
sim3_est2 &lt;- t(t(bias2) + truepars2)
sim3_pcorstate1 &lt;- pcorstate1
sim3_pcorstate2 &lt;- pcorstate2

tmp &lt;- as.data.frame(sim3_est1)
colnames(tmp) &lt;- c("$\pi_1$","$\pi_2$","$\pi_3$","$a_{11}$","$a_{12}$","$a_{13}$","$a_{21}$","$a_{22}$","$a_{23}$","$a_{31}$","$a_{32}$", "$a_{33}$", "$\mu_1$","$\sigma_1$","$\mu_2$","$\sigma_2$","$\mu_3$","$\sigma_3$")
tmp$sim &lt;- 1:nsim
tmp &lt;- gather(tmp,key="param",value="estimate",-sim)
tmp$true &lt;- rep(truepars1,each=nsim)
tmp$method &lt;- "MAR"
tmp$variance &lt;- "low"
tmp$missing &lt;- "equal"
sim4_est1_long &lt;- tmp

tmp &lt;- as.data.frame(sim3_est2)
colnames(tmp) &lt;- c("$\pi_1$","$\pi_2$","$\pi_3$","$a_{11}$","$a_{12}$","$a_{13}$","$a_{21}$","$a_{22}$","$a_{23}$","$a_{31}$","$a_{32}$", "$a_{33}$", "$\mu_1$","$\sigma_1$","pnm_1","$p(M=1|S=1)$","$\mu_2$","$\sigma_2$","pnm_2","$p(M=1|S=2)$","$\mu_3$","$\sigma_3$","pnm_3","$p(M=1|S=3)$")
tmp$sim &lt;- 1:nsim
tmp &lt;- gather(tmp,key="param",value="estimate",-sim)
tmp$true &lt;- rep(truepars2,each=nsim)
tmp$method &lt;- "MNAR"
tmp$variance &lt;- "low"
tmp$missing &lt;- "equal"
sim4_est2_long &lt;- tmp

all_long &lt;- rbind(
  sim4_est1_long,
  subset(sim4_est2_long,!(param 
)

my_table &lt;- all_long 
  group_by(param, method, variance, missing) 
  summarize(true = mean(true),
            mean = mean(estimate),
            sd = sd(estimate),
            bias = mean(abs(true - estimate)/abs(true)),
            MAE = mean(abs(true - estimate))) 
  gather(measure,value,-c(param,method,variance,missing)) 
  recast(param + variance + missing  ~  method + measure)

MAR_simulation_results &lt;- my_table 
  filter(variance == "low" &amp; missing == "equal") 
  dplyr::select(param,MAR_true,paste0("MAR_",c("mean","sd","MAE"),sep=""),
                paste0("MNAR_",c("mean","sd","MAE"),sep="")) 
  mutate(percMAE = MNAR_MAE/MAR_MAE) 

colnames(MAR_simulation_results) &lt;- c("parameter", "true", "MAR_estimates_mean", 
  "MAR_estimates_sd", "MAR_estimates_MAE", "MNAR_estimates_mean",
  "MNAR_estimates_sd", "MNAR_estimates_MAE", "percMAE")
MAR_simulation_results &lt;- MAR_simulation_results[c(1:3,7:9,4:6,10:21),]
</pre>


<h3>Examples</h3>

<pre><code class='language-R'>  data(MAR_simulation_results)
</code></pre>

<hr>
<h2 id='MNAR_simulation_results'>
Missing not at random (MNAR) simulation results.
</h2><span id='topic+MNAR_simulation_results'></span>

<h3>Description</h3>

<p>Results of a simulation study on the effect of missing data on estimates of parameters of a hidden Markov model. In the simulation, 1000 datasets were simulated, each consisting of 100 time series of length 50. The model generating the data was a hidden Markov model with 3 states. Missing values were generated for 5% of cases in state 1, 25% of cases in state 2, and 50% of cases in state 3 (i.e. data can be considered missing not at random, as missingness is state-dependent).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("MNAR_simulation_results")</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with the following variables:
</p>

<dl>
<dt><code>parameter</code></dt><dd><p>Parameter name</p>
</dd>
<dt><code>true</code></dt><dd><p>True value of parameter</p>
</dd>
<dt><code>MAR_estimates_mean</code></dt><dd><p>Average of parameter estimates for a model that assumes MAR.</p>
</dd>
<dt><code>MAR_estimates_sd</code></dt><dd><p>Standard deviation of parameter estimates for a model that assumes MAR.</p>
</dd>
<dt><code>MAR_estimates_MAE</code></dt><dd><p>Mean Absolute Error of parameter estimates for a model that assumes MAR.</p>
</dd>
<dt><code>MNAR_estimates_mean</code></dt><dd><p>Average of parameter estimates for a model that assumes MNAR.</p>
</dd>
<dt><code>MNAR_estimates_sd</code></dt><dd><p>Standard deviation of parameter estimates for a model that assumes MNAR.</p>
</dd>
<dt><code>MNAR_estimates_MAE</code></dt><dd><p>Mean Absolute Error of parameter estimates for a model that assumes MNAR.</p>
</dd>
<dt><code>percMAE</code></dt><dd><p>Relative MAE of the MNAR model over the MAR model (e.g. MAE_MNAR/MAE_MAR)</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data frame was generated with the following code
</p>
<pre>

library(depmixS4)

### Start simulation

nsim &lt;- 1000
nrep &lt;- 100
nt &lt;- 50

set.seed(1234)
randomSeeds &lt;- sample(seq(1,nsim*1000),nsim)
out &lt;- rep(list(vector("list",3)),nsim)

prior &lt;- c(8,1,1)
prior &lt;- prior/sum(prior)
transition &lt;- 5*diag(3) + 1
transition &lt;- transition/rowSums(transition)
means &lt;- c(-1,0,1)
sds &lt;- c(3,3,3)
pmiss &lt;- c(.05,.25,.5)

truepars1 &lt;- c(prior,as.numeric(t(transition)),as.numeric(rbind(means,sds)))
truepars2 &lt;- c(prior,as.numeric(t(transition)),as.numeric(rbind(means,sds,1-pmiss,pmiss)))

for(sim in 1:nsim) {
  set.seed(randomSeeds[sim])
  truestate &lt;- matrix(nrow=nt,ncol=nrep) 
  for(i in 1:nrep) {
    truestate[1,i] &lt;- sample(1:3,size=1,prob=prior)
    for(t in 2:nt) {
      truestate[t,i] &lt;- sample(1:3,size=1,prob=transition[truestate[t-1,i],])
    }
  }
  dat &lt;- data.frame(trueState=as.numeric(truestate),trial=1:nt)
  dat$trueResponse &lt;- rnorm(nrow(dat),mean=means[dat$trueState],sd=sds[dat$trueState])
  dat$missing &lt;- rbinom(nrow(dat),size=1,prob=pmiss[dat$trueState])
  dat$response &lt;- dat$trueResponse
  dat$response[dat$missing==1] &lt;- NA
  
  set.seed(randomSeeds[sim])
  mod &lt;- depmix(list(response~1),family=list(gaussian()),data=dat,nstates=3,ntimes=rep(nt,nrep))
  mod &lt;- setpars(mod,truepars1)
  ok &lt;- FALSE
  ntry &lt;- 1
  while(!ok &amp; ntry &lt;= 50) {
    fmod &lt;- try(fit(mod,emcontrol=em.control(maxit = 5000, random.start=FALSE),verbose=FALSE))
    if(!inherits(fmod,"try-error")) {
      if(fmod@message == "Log likelihood converged to within tol. (relative change)") ok &lt;- TRUE
    }
    ntry &lt;- ntry + 1
  }
  out[[sim]][[1]] &lt;- list(pars=getpars(fmod),logLik=logLik(fmod),viterbi=posterior(fmod)[,1],trueState=dat$trueState)
  
  set.seed(randomSeeds[sim])
  mod &lt;- depmix(list(response~1,missing~1),family=list(gaussian(),multinomial("identity")),data=dat,nstates=3,ntimes=rep(nt,nrep))
  mod &lt;- setpars(mod,truepars2)
  ok &lt;- FALSE
  ntry &lt;- 1
  while(!ok &amp; ntry &lt;= 50) {
    fmod &lt;- try(fit(mod,emcontrol=em.control(maxit = 5000, random.start = FALSE),verbose=FALSE))
    if(!inherits(fmod,"try-error")) {
      if(fmod@message == "Log likelihood converged to within tol. (relative change)") ok &lt;- TRUE
    }
    ntry &lt;- ntry + 1
  }
  out[[sim]][[2]] &lt;- list(pars=getpars(fmod),logLik=logLik(fmod),viterbi=posterior(fmod)[,1],trueState=dat$trueState)
}

### End simulation

### Process results
library(reshape2)
library(dplyr)
library(tidyr)

simi &lt;- out

bias1 &lt;- matrix(0.0,ncol=length(truepars1),nrow=nsim)
bias2 &lt;- matrix(0.0,ncol=length(truepars2),nrow=nsim)

colnames(bias1) &lt;- names(simi[[1]][[1]][[1]])
colnames(bias2) &lt;- names(simi[[1]][[2]][[1]])

pcorstate1 &lt;- rep(0.0,nsim)
pcorstate2 &lt;- rep(0.0,nsim)

for(sim in 1:nsim) {
  tmp &lt;- simi[[sim]][[1]][[1]]
  pr &lt;- tmp[1:3]
  trt &lt;- matrix(tmp[4:12],ncol=3)
  ms &lt;- tmp[c(13,15,17)]
  sds &lt;- tmp[c(14,16,18)] 
  ord &lt;- order(ms)
  bias1[sim,] &lt;- c(pr[ord],trt[ord,ord],as.numeric(rbind(ms[ord],sds[ord]))) - truepars1
  fsta &lt;- recode(simi[[sim]][[1]]$viterbi,`1` = which(ord == 1), `2` = which(ord == 2), `3` = which(ord == 3))
  pcorstate1[sim] &lt;- sum(fsta == simi[[sim]][[1]]$trueState)/(nrep*nt)
  
  tmp &lt;- simi[[sim]][[2]][[1]]
  pr &lt;- tmp[1:3]
  trt &lt;- matrix(tmp[4:12],ncol=3)
  ms &lt;- tmp[c(13,17,21)]
  sds &lt;- tmp[c(14,18,22)]
  ps0 &lt;- tmp[c(15,19,23)]
  ps1 &lt;- tmp[c(16,20,24)]
  ord &lt;- order(ms)
  bias2[sim,] &lt;- c(pr[ord],trt[ord,ord],as.numeric(rbind(ms[ord],sds[ord],ps0[ord],ps1[ord]))) - truepars2
  fsta &lt;- recode(simi[[sim]][[2]]$viterbi,`1` = which(ord == 1), `2` = which(ord == 2), `3` = which(ord == 3))
  pcorstate2[sim] &lt;- sum(fsta == simi[[sim]][[2]]$trueState)/(nrep*nt)
}

sim2_bias1 &lt;- bias1
sim2_bias2 &lt;- bias2
sim2_est1 &lt;- t(t(bias1) + truepars1)
sim2_est2 &lt;- t(t(bias2) + truepars2)
sim2_pcorstate1 &lt;- pcorstate1
sim2_pcorstate2 &lt;- pcorstate2

tmp &lt;- as.data.frame(sim2_est1)
colnames(tmp) &lt;- c("$\pi_1$","$\pi_2$","$\pi_3$","$a_{11}$","$a_{12}$","$a_{13}$","$a_{21}$","$a_{22}$","$a_{23}$","$a_{31}$","$a_{32}$", "$a_{33}$", "$\mu_1$","$\sigma_1$","$\mu_2$","$\sigma_2$","$\mu_3$","$\sigma_3$")
tmp$sim &lt;- 1:nsim
tmp &lt;- gather(tmp,key="param",value="estimate",-sim)
tmp$true &lt;- rep(truepars1,each=nsim)
tmp$method &lt;- "MAR"
tmp$variance &lt;- "low"
tmp$missing &lt;- "equal"
sim2_est1_long &lt;- tmp

tmp &lt;- as.data.frame(sim2_est2)
colnames(tmp) &lt;- c("$\pi_1$","$\pi_2$","$\pi_3$","$a_{11}$","$a_{12}$","$a_{13}$","$a_{21}$","$a_{22}$","$a_{23}$","$a_{31}$","$a_{32}$", "$a_{33}$", "$\mu_1$","$\sigma_1$","pnm_1","$p(M=1|S=1)$","$\mu_2$","$\sigma_2$","pnm_2","$p(M=1|S=2)$","$\mu_3$","$\sigma_3$","pnm_3","$p(M=1|S=3)$")
tmp$sim &lt;- 1:nsim
tmp &lt;- gather(tmp,key="param",value="estimate",-sim)
tmp$true &lt;- rep(truepars2,each=nsim)
tmp$method &lt;- "MNAR"
tmp$variance &lt;- "low"
tmp$missing &lt;- "equal"
sim2_est2_long &lt;- tmp

all_long &lt;- rbind(
  sim2_est1_long,
  subset(sim2_est2_long,!(param 
)

my_table &lt;- all_long 
  group_by(param, method, variance, missing) 
  summarize(true = mean(true),
            mean = mean(estimate),
            sd = sd(estimate),
            bias = mean(abs(true - estimate)/abs(true)),
            MAE = mean(abs(true - estimate))) 
  gather(measure,value,-c(param,method,variance,missing)) 
  recast(param + variance + missing  ~  method + measure)

MAR_simulation_results &lt;- my_table 
  filter(variance == "low" &amp; missing == "equal") 
  dplyr::select(param,MNAR_true,paste0("MAR_",c("mean","sd","MAE"),sep=""),
                paste0("MNAR_",c("mean","sd","MAE"),sep="")) 
  mutate(percMAE = MNAR_MAE/MAR_MAE) 

colnames(MNAR_simulation_results) &lt;- c("parameter", "true", "MAR_estimates_mean", 
  "MAR_estimates_sd", "MAR_estimates_MAE", "MNAR_estimates_mean",
  "MNAR_estimates_sd", "MNAR_estimates_MAE", "percMAE")
MNAR_simulation_results &lt;- MNAR_simulation_results[c(1:3,7:9,4:6,10:21),]
</pre>


<h3>Examples</h3>

<pre><code class='language-R'>  data(MNAR_simulation_results)
</code></pre>

<hr>
<h2 id='perth'>Perth dams water levels.</h2><span id='topic+perth'></span>

<h3>Description</h3>

<p>Data from the Water Corporation of Western Australia. They state the following 
about these data on their website:
&quot;Streamflow is the amount of water entering our dams from our catchments 
and is measured by changing water storage levels.&quot;
This dataset has the annual averages of these storage levels. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(perth)
</code></pre>


<h3>Format</h3>

<p>A data.frame consisting of the following variable:
</p>

<dl>
<dt><code>water</code></dt><dd><p>water level (in GL)</p>
</dd>
<dt><code>year</code></dt><dd><p>year</p>
</dd>
<dt><code>wtmin1</code></dt><dd><p>water level in the previous year (GL)</p>
</dd>
</dl>



<h3>Source</h3>

<p>These data are provided by the Water Corporation of Western Australia and can be found here: 
<a href="https://www.watercorporation.com.au/water-supply/rainfall-and-dams/streamflow/streamflowhistorical">https://www.watercorporation.com.au/water-supply/rainfall-and-dams/streamflow/streamflowhistorical</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the data is first changed to a timeseries object and then plotted
data(perth)
wts &lt;- ts(perth$water,start=1911)
plot(wts,ylab="GL", main="Perth dams water inflow", xlab="year", frame=FALSE, xaxp=c(1910,2020,10))

</code></pre>

<hr>
<h2 id='SEsamples'>
Bootstrap Samples for Simple 2-State Model
</h2><span id='topic+SEsamples'></span>

<h3>Description</h3>

<p>Parametric bootstrap samples for a 2-state hidden Markov model used to compute
standard errors. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SEsamples")</code></pre>


<h3>Format</h3>

<p>A matrix with 1000 rows for each sample, 12 columns for each parameter of the model, 
including the parameters that are fixed at their boundary values. 
</p>


<h3>Details</h3>

<p>The bootstrap sample was generated by the following code:
</p>
<pre>require(depmixS4)
library(hmmr)
data(simplehmm)

# define the model
set.seed(214)
mod1 &lt;- depmix(obs~1,data=simplehmm,nstates=2,
	family=multinomial("identity"), respst=c(.6,0,.4,0,.2,.8), trst=runif(4), inst=c(1,0))

# fit the model
fm1 &lt;- fit(mod1,emcontrol=em.control(random.start=FALSE))

# compute bootstrap samples
nsamples &lt;- 1000
SEsamples &lt;- matrix(0,ncol=npar(fm1),nrow=nsamples)

for(i in 1:nsamples) {
	sample &lt;- simulate(fm1)
	fmsam &lt;- fit(sample,emcontrol=em.control(random.start=FALSE))
	SEsamples[i,] &lt;- getpars(fmsam)
}
</pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(SEsamples)
# standard errors
bootses &lt;- apply(SEsamples,2,sd)
bootses[which(bootses==0)] &lt;- NA
bootses
# compare with standard errors from finite differences
library(hmmr)
data(simplehmm)
# define the model
set.seed(214)
mod1 &lt;- depmix(obs~1,data=simplehmm,nstates=2,
	family=multinomial("identity"), respst=c(.6,0,.4,0,.2,.8), trst=runif(4), inst=c(1,0))
# fit the model
fm1 &lt;- fit(mod1,emcontrol=em.control(random.start=FALSE))
ses &lt;- cbind(standardError(fm1),bootses)
ses
</code></pre>

<hr>
<h2 id='simplehmm'>Hmm toy data set from Visser et al (2000)</h2><span id='topic+simplehmm'></span>

<h3>Description</h3>

<p>Data are 2000 observations generated from a 2-state hidden Markov model with 
three observation categories. These data were used in the simuation study in 
Visser et al. (2000) for testing the quality of several methods of computing 
parameter standard errors. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(simplehmm)</code></pre>


<h3>Format</h3>

<p>A dataframe with 2000 observations on a single variable: 
</p>

<dl>
<dt><code>obs</code></dt><dd><p>a factor with levels 1, 2, and 3.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ingmar Visser, Maartje E. J. Raijmakers, and Peter C. M. Molenaar (2000).
Confidence intervals for hidden Markov model parameters. <em>British journal
of mathematical and statistical psychology</em>, 53, p. 317-327.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(simplehmm)
set.seed(1)
md2 &lt;- hmm(simplehmm, 2)
summary(md2)
</code></pre>

<hr>
<h2 id='speed_boot_LR'>
speed boot LR
</h2><span id='topic+speed_boot_LR'></span>

<h3>Description</h3>

<p>Example of a parametric bootstrap for model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("speed_boot_LR")</code></pre>


<h3>Format</h3>

<p>A <code>boot</code> object
</p>


<h3>Details</h3>

<p>The bootstrap sample was generated by the following code:
</p>
<pre>require(depmixS4)
      require(hmmr)
      require(boot)
      
      data(speed1)
      set.seed(5)
      spmix2 &lt;- mix(RT~1, data=speed1, nstates=2)
      fspmix2 &lt;- fit(spmix2,verbose=FALSE)
      
      set.seed(5)
      fspmix3 &lt;- fit(mix(RT~1,data=speed1,nstates=3))
      
      speed.fun.LR &lt;- function(model) {
        ok &lt;- FALSE
        while(!ok) {
          bootdat &lt;- data.frame(RT = simulate(model)@response[[1]][[1]]@y)
          fboot2 &lt;- try({
            mod &lt;- mix(RT~1,data=bootdat,nstates=2)
            mod &lt;- setpars(mod,getpars(fspmix2))
            fit(mod,emcontrol=em.control(random.start=FALSE),verbose=FALSE)
          },TRUE)
          fboot3 &lt;- try({
            mod &lt;- mix(RT~1,data=bootdat,nstates=3)
            mod &lt;- setpars(mod,getpars(fspmix3))
            fit(mod,emcontrol=em.control(random.start=FALSE),verbose=FALSE)
          },TRUE)
          if(!inherits(fboot2,"try-error") &amp; !inherits(fboot3,"try-error")) ok &lt;- TRUE
        }
        if(ok &amp; logLik(fboot3) &lt; logLik(fboot2)) ok &lt;- FALSE
        while(!ok) {
          cat("trying different starting-values")
          fboot3 &lt;- try({
            mod &lt;- mix(RT~1,data=bootdat,nstates=3)
            mod &lt;- setpars(mod,getpars(fspmix3))
            fit(mod,verbose=FALSE)
          },TRUE)
          if(!inherits(fboot3,"try-error") &amp; logLik(fboot3) &gt; logLik(fboot2)) ok &lt;- TRUE
        }
        llratio(fboot3,fboot2)@value
      }
      set.seed(5)
      speed_boot_LR &lt;- boot(fspmix2,speed.fun.LR,R=1000,sim="parametric")
    </pre>


<h3>Examples</h3>

<pre><code class='language-R'>  data(speed_boot_LR)
</code></pre>

<hr>
<h2 id='speed_boot_LR_extra'>
speed boot LR
</h2><span id='topic+speed_boot_LR_extra'></span>

<h3>Description</h3>

<p>Example of a parametric bootstrap for model selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("speed_boot_LR")</code></pre>


<h3>Format</h3>

<p>A <code>boot</code> object
</p>


<h3>Details</h3>

<p>The bootstrap sample was generated by the following code:
</p>
<pre>require(depmixS4)
      require(hmmr)
      require(boot)
      
      data(speed1)
      set.seed(5)
      spmix2 &lt;- mix(RT~1, data=speed1, nstates=2)
      fspmix2 &lt;- fit(spmix2,verbose=FALSE)
      
      set.seed(5)
      fspmix3 &lt;- fit(mix(RT~1,data=speed1,nstates=3))
      
      speed.fun.LR &lt;- function(model) {
        ok &lt;- FALSE
        while(!ok) {
          bootdat &lt;- data.frame(RT = simulate(model)@response[[1]][[1]]@y)
          fboot2 &lt;- try({
            mod &lt;- mix(RT~1,data=bootdat,nstates=2)
            mod &lt;- setpars(mod,getpars(fspmix2))
            fit(mod,emcontrol=em.control(random.start=FALSE),verbose=FALSE)
          },TRUE)
          fboot3 &lt;- try({
            mod &lt;- mix(RT~1,data=bootdat,nstates=3)
            mod &lt;- setpars(mod,getpars(fspmix3))
            fit(mod,emcontrol=em.control(random.start=FALSE),verbose=FALSE)
          },TRUE)
          if(!inherits(fboot2,"try-error") &amp; !inherits(fboot3,"try-error")) ok &lt;- TRUE
        }
        if(ok &amp; logLik(fboot3) &lt; logLik(fboot2)) ok &lt;- FALSE
        while(!ok) {
          cat("trying different starting-values")
          fboot3 &lt;- try({
            mod &lt;- mix(RT~1,data=bootdat,nstates=3)
            mod &lt;- setpars(mod,getpars(fspmix3))
            fit(mod,verbose=FALSE)
          },TRUE)
          if(!inherits(fboot3,"try-error") &amp; logLik(fboot3) &gt; logLik(fboot2)) ok &lt;- TRUE
        }
        llratio(fboot3,fboot2)@value
      }
      set.seed(5)
      speed_boot_LR &lt;- boot(fspmix2,speed.fun.LR,R=1000,sim="parametric")
      
      set.seed(7)
      speed_boot_LR_extra &lt;- boot(fspmix2,speed.fun.LR,R=4000,
          sim="parametric",parallel="multicore",ncpus=6)
      (1+sum(c(speed_boot_LR$t,speed_boot_LR_extra$t) &gt; 
          llratio(fspmix3,fspmix2)@value))/
          ((speed_boot_LR$R+speed_boot_LR_extra$R)+1)
    </pre>


<h3>Examples</h3>

<pre><code class='language-R'>  data(speed_boot_LR)
</code></pre>

<hr>
<h2 id='speed_boot_par'>
speed boot par
</h2><span id='topic+speed_boot_par'></span>

<h3>Description</h3>

<p>Example of a parametric bootstrap for paraneter inference
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("speed_boot_par")</code></pre>


<h3>Format</h3>

<p>A <code>boot</code> object
</p>


<h3>Details</h3>

<p>The bootstrap sample was generated by the following code:
</p>
<pre>require(depmixS4)
require(hmmr)
require(boot)

data(speed1)
set.seed(5)
spmix2 &lt;- mix(RT~1, data=speed1, nstates=2)
fspmix2 &lt;- fit(spmix2,verbose=FALSE)

# define a function to produce a bootstrap sample 
speed.rg &lt;- function(data,mle) {
  simulate(data)
}
# define what to do with a sample (i.e. estimate parameters)
speed.fun &lt;- function(data) { 
  getpars(fit(data,verbose=FALSE,emcontrol=
              em.control(random.start=FALSE)))
}
# produce 1000 bootstrap samples (may take some time!)
speed_boot_par &lt;- boot(fspmix2,speed.fun,R=1000,sim="parametric",
                   ran.gen = speed.rg)
</pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(speed_boot_par)
# confidence intervals
confint &lt;- apply(speed_boot_par$t,2,quantile,probs=c(.025,.975))
colnames(confint) &lt;- c("p1","p2","m1","sd1","m2","sd2")
confint
</code></pre>

<hr>
<h2 id='speed1'>Speed Accuracy Switching Data</h2><span id='topic+speed1'></span>

<h3>Description</h3>

<p>This data set is a bivariate series of response times and accuracy
scores of a single participant switching between slow/accurate
responding and fast guessing on a lexical decision task.  The slow and
accurate responding, and the fast guessing can be modelled using two
states, with a switching regime between them.  The dataset further
contains a third variable called Pacc, representing the relative
pay-off for accurate responding, which is on a scale of zero to one.
The value of Pacc was varied during the experiment to induce the
switching.  This data set is a from participant A in experiment 
1a from Dutilh et al (2011). The data here is the first series of
168 trials. The <code>speed</code> data set in the <code>depmixS4</code> package 
has two more series of 134 and 137 trials respectively. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(speed1)</code></pre>


<h3>Format</h3>

<p>A data frame with 168 observations on the following 3 variables.
</p>

<dl>
<dt><code>RT</code></dt><dd><p>a numeric vector of response times (log ms)</p>
</dd>
<dt><code>ACC</code></dt><dd><p>a numeric vector of accuracy scores (0/1)</p>
</dd>
<dt><code>Pacc</code></dt><dd><p>a numeric vector of the pay-off for accuracy</p>
</dd>
</dl>



<h3>Source</h3>

<p>Gilles Dutilh, Eric-Jan Wagenmakers, Ingmar Visser, &amp; Han L. J. van der Maas (2011).
A phase transition model for the speed-accuracy trade-off in response time experiments.
<em>Cognitive Science</em>, 35:211-250.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(speed1)
</code></pre>

<hr>
<h2 id='WPT'>Weather Prediction Task Data</h2><span id='topic+WPT'></span>

<h3>Description</h3>

<p>This data set contains responses of 11 Parkinsons' patients and 13 age-matched
controls on the Weather Prediction Task. Both groups were tested twice. The PD
patients were either on or off dopaminergic medication.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(WPT)</code></pre>


<h3>Format</h3>

<p>A data.frame with 9600 observations on the following variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>a factor with participant IDs</p>
</dd>
<dt><code>group</code></dt><dd><p>a factor with group IDs (Parksinson's patient or control)</p>
</dd>
<dt><code>med</code></dt><dd><p>a factor indicating, for the PD patients, whether they were on dopaminergic medicine or not</p>
</dd>
<dt><code>occ</code></dt><dd><p>a numeric vector with testing occassions</p>
</dd>
<dt><code>trial</code></dt><dd><p>a numeric vector with trial numbers</p>
</dd>
<dt><code>c1</code></dt><dd><p>a numeric (binary) vector indicating whether the first cue was present (1) or not (0)</p>
</dd>
<dt><code>c2</code></dt><dd><p>a numeric (binary) vector indicating whether the second cue was present (1) or not (0)</p>
</dd>
<dt><code>c3</code></dt><dd><p>a numeric (binary) vector indicating whether the third cue was present (1) or not (0)</p>
</dd>
<dt><code>c4</code></dt><dd><p>a numeric (binary) vector indicating whether the fourth cue was present (1) or not (0)</p>
</dd>
<dt><code>y</code></dt><dd><p>a factor with the actual outcome (Rainy or Fine)</p>
</dd>
<dt><code>r</code></dt><dd><p>a factor with participants' prediction of the outcome</p>
</dd>
</dl>



<h3>Source</h3>

<p>Speekenbrink, M., Lagnado, D. A., Wilkinson, L., Jahanshahi, M., &amp; Shanks, D. R. (2010). 
Models of probabilistic category learning in Parkinson's disease: Strategy use and the 
effects of L-dopa. <em>Journal of Mathematical Psychology</em>, <em>54</em>, 123-136.
</p>
<p>Corresponding author: m.speekenbrink@ucl.ac.uk
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(WPT)

# set up predictors for the different strategies
WPT$sngl &lt;- 0 # singleton strategy
WPT$sngl[WPT$c1 == 1 &amp; rowSums(WPT[,c("c1","c2","c3","c4")]) == 1] &lt;- -1
WPT$sngl[WPT$c2 == 1 &amp; rowSums(WPT[,c("c1","c2","c3","c4")]) == 1] &lt;- -1
WPT$sngl[WPT$c3 == 1 &amp; rowSums(WPT[,c("c1","c2","c3","c4")]) == 1] &lt;- 1
WPT$sngl[WPT$c4 == 1 &amp; rowSums(WPT[,c("c1","c2","c3","c4")]) == 1] &lt;- 1
WPT$sc1 &lt;- 1 - 2*WPT$c1
WPT$sc2 &lt;- 1 - 2*WPT$c2
WPT$sc3 &lt;- -1 + 2*WPT$c3
WPT$sc4 &lt;- -1 + 2*WPT$c4
WPT$mc &lt;- sign(-WPT$c1 - WPT$c2 + WPT$c3 + WPT$c4)

rModels &lt;- list(
	list(GLMresponse(formula=r~-1,data=WPT,family=binomial())),
	list(GLMresponse(formula=r~sngl-1,data=WPT,family=binomial())),
	list(GLMresponse(formula=r~sc1-1,data=WPT,family=binomial())),
	list(GLMresponse(formula=r~sc2-1,data=WPT,family=binomial())),
	list(GLMresponse(formula=r~sc3-1,data=WPT,family=binomial())),
	list(GLMresponse(formula=r~sc4-1,data=WPT,family=binomial())),
	list(GLMresponse(formula=r~mc-1,data=WPT,family=binomial()))
)

transition &lt;- list()
for(i in 1:7) {
  transition[[i]] &lt;- transInit(~1,nstates=7,family=multinomial(link="identity"))
}

inMod &lt;- transInit(~1,ns=7,data=data.frame(rep(1,48)),family=multinomial("identity"))

mod &lt;- makeDepmix(response=rModels,transition=transition, 
	prior=inMod,ntimes=rep(200,48),stationary=TRUE)

fmod &lt;- fit(mod)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
