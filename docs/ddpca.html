<!DOCTYPE html><html lang="en"><head><title>Help for package ddpca</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ddpca}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ddpca-package'>
<p>Diagonally Dominant Principal Component Analysis</p></a></li>
<li><a href='#DDHC'>
<p>DD-HC test</p></a></li>
<li><a href='#DDPCA_convex'>
<p>Diagonally Dominant Principal Component Analysis using Convex approach</p></a></li>
<li><a href='#DDPCA_nonconvex'>
<p>Diagonally Dominant Principal Component Analysis using Nonconvex approach</p></a></li>
<li><a href='#HCdetection'>
<p>Higher Criticism for detecting rare and weak signals</p></a></li>
<li><a href='#IHCDD'>
<p>IHC-DD test</p></a></li>
<li><a href='#ProjDD'>
<p>Projection onto the Diagonally Dominant Cone</p></a></li>
<li><a href='#ProjSDD'>
<p>Projection onto the Symmetric Diagonally Dominant Cone</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Diagonally Dominant Principal Component Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-09-14</td>
</tr>
<tr>
<td>Author:</td>
<td>Tracy Ke [aut],
  Lingzhou Xue [aut],
  Fan Yang [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fan Yang &lt;fyang1@uchicago.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient procedures for fitting the DD-PCA (Ke et al., 2019, &lt;<a href="https://doi.org/10.48550/arXiv.1906.00051">doi:10.48550/arXiv.1906.00051</a>&gt;)  by decomposing a large covariance matrix into a low-rank matrix plus a diagonally dominant matrix. The implementation of DD-PCA includes the convex approach using the Alternating Direction Method of Multipliers (ADMM) and the non-convex approach using the iterative projection algorithm. Applications of DD-PCA to large covariance matrix estimation and global multiple testing are also included in this package. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>RSpectra, Matrix, quantreg, MASS</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-09-14 15:08:01 UTC; fanyang</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-09-14 20:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ddpca-package'>
Diagonally Dominant Principal Component Analysis
</h2><span id='topic+ddpca-package'></span><span id='topic+ddpca'></span>

<h3>Description</h3>

<p>Efficient procedures for fitting the DD-PCA (Ke et al., 2019, &lt;arXiv:1906.00051&gt;)  by decomposing a large covariance matrix into a low-rank matrix plus a diagonally dominant matrix. The implementation of DD-PCA includes the convex approach using the Alternating Direction Method of Multipliers (ADMM) and the non-convex approach using the iterative projection algorithm. Applications of DD-PCA to large covariance matrix estimation and global multiple testing are also included in this package. 
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>
<p>Index of help topics:
</p>
<pre>
DDHC                    DD-HC test
DDPCA_convex            Diagonally Dominant Principal Component
                        Analysis using Convex approach
DDPCA_nonconvex         Diagonally Dominant Principal Component
                        Analysis using Nonconvex approach
HCdetection             Higher Criticism for detecting rare and weak
                        signals
IHCDD                   IHC-DD test
ProjDD                  Projection onto the Diagonally Dominant Cone
ProjSDD                 Projection onto the Symmetric Diagonally
                        Dominant Cone
ddpca-package           Diagonally Dominant Principal Component
                        Analysis
</pre>
<p>This package contains <code><a href="#topic+DDPCA_nonconvex">DDPCA_nonconvex</a></code> and <code><a href="#topic+DDPCA_convex">DDPCA_convex</a></code> function, which decomposes a positive semidefinite matrix into a low rank component, and a diagonally dominant component using either nonconvex approach or convex approach. 
</p>


<h3>Note</h3>

<p>Please cite the reference paper to cite this <span class="rlang"><b>R</b></span> package.
</p>


<h3>Author(s)</h3>

<p>Tracy Ke [aut], Lingzhou Xue [aut], Fan Yang [aut, cre]
</p>
<p>Maintainer: Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review.
</p>

<hr>
<h2 id='DDHC'>
DD-HC test
</h2><span id='topic+DDHC'></span>

<h3>Description</h3>

<p>Combining DDPCA with orthodox Higher Criticism for detecting sparse mean effect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DDHC(X, known_Sigma = NA, method = "nonconvex", K = 1, lambda = 3, 
max_iter_nonconvex = 15 ,SDD_approx = TRUE, max_iter_SDD = 20, eps = NA, 
rho = 20, max_iter_convex = 50, alpha = 0.5, pvalcut = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DDHC_+3A_x">X</code></td>
<td>

<p>A <code class="reqn">n\times p</code> data matrix, where each row is drawn i.i.d from <code class="reqn">\mathcal{N}(\mu,\Sigma)</code> 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_known_sigma">known_Sigma</code></td>
<td>

<p>The true covariance matrix of data. Default NA. If NA, then <code class="reqn">\Sigma</code> will be estimated from data matrix X. 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_method">method</code></td>
<td>

<p>Either &quot;convex&quot; or &quot;noncovex&quot;, indicating which method to use for DDPCA.
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_k">K</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. Need to be specified when <code>method = "nonconvex"</code>
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_lambda">lambda</code></td>
<td>

<p>Argument in function <code>DDPCA_convex</code>. Need to be specified when <code>method = "convex"</code>
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_max_iter_nonconvex">max_iter_nonconvex</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_sdd_approx">SDD_approx</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_max_iter_sdd">max_iter_SDD</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_eps">eps</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_rho">rho</code></td>
<td>

<p>Argument in function <code>DDPCA_convex</code>. 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_max_iter_convex">max_iter_convex</code></td>
<td>

<p>Argument in function <code>DDPCA_convex</code>. 
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_alpha">alpha</code></td>
<td>

<p>Argument in function <code>HCdetection</code>.
</p>
</td></tr>
<tr><td><code id="DDHC_+3A_pvalcut">pvalcut</code></td>
<td>

<p>Argument in function <code>HCdetection</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See reference paper for more details. 
</p>


<h3>Value</h3>

<p>Returns a list containing the following items
</p>
<table role = "presentation">
<tr><td><code>H</code></td>
<td>
<p>0 or 1 scalar indicating whether <code class="reqn">H_0</code> the global null is rejected (1) or not rejected (0). The use of <code>H</code> is not recommended as it's approximately valid only when <code>p</code> is sufficiently large and mean effect in alternative is really sparse.</p>
</td></tr>
<tr><td><code>HCT</code></td>
<td>
<p>DD-HC Test statistic</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IHCDD">IHCDD</a></code>, <code><a href="#topic+HCdetection">HCdetection</a></code>, <code><a href="#topic+DDPCA_convex">DDPCA_convex</a></code>, <code><a href="#topic+DDPCA_nonconvex">DDPCA_nonconvex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
n = 200
p = 200
k = 3
rho = 0.5
a = 0:(p-1)
Sigma_mu = rho^abs(outer(a,a,'-'))
Sigma_mu = (diag(p) + Sigma_mu)/2 # Now Sigma_mu is a symmetric diagonally dominant matrix
B = matrix(rnorm(p*k),nrow = p)
Sigma = Sigma_mu + B %*% t(B)
X = mvrnorm(n,rep(0,p),Sigma)
results = DDHC(X,K = k)
print(results$H)
print(results$HCT)
</code></pre>

<hr>
<h2 id='DDPCA_convex'>
Diagonally Dominant Principal Component Analysis using Convex approach
</h2><span id='topic+DDPCA_convex'></span>

<h3>Description</h3>

<p>This function decomposes a positive semidefinite matrix into a low rank component, and a diagonally dominant component by solving a convex relaxation using ADMM. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DDPCA_convex(Sigma, lambda, rho = 20, max_iter_convex = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DDPCA_convex_+3A_sigma">Sigma</code></td>
<td>

<p>Input matrix of size <code class="reqn">n\times n</code>
</p>
</td></tr>
<tr><td><code id="DDPCA_convex_+3A_lambda">lambda</code></td>
<td>

<p>The parameter in the convex program that controls the rank of the low rank component 
</p>
</td></tr>
<tr><td><code id="DDPCA_convex_+3A_rho">rho</code></td>
<td>

<p>The parameter used in each ADMM update.
</p>
</td></tr>
<tr><td><code id="DDPCA_convex_+3A_max_iter_convex">max_iter_convex</code></td>
<td>

<p>Maximal number of iterations of ADMM update. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function decomposes a positive semidefinite matrix <code>Sigma</code> into a low rank component <code>L</code> and a symmetric diagonally dominant component <code>A</code>, by solving the following convex program 
</p>
<p style="text-align: center;"><code class="reqn">\textrm{minimize} \quad 0.5*\|\Sigma - L - A\|^2 + \lambda \|L\|_{*}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textrm{subject to} \quad A\in SDD</code>
</p>

<p>where <code class="reqn">\|L\|_{*}</code> is the nuclear norm of <code>L</code> (sum of singular values) and <code>SDD</code> is the symmetric diagonally dominant cone. 
</p>


<h3>Value</h3>

<p>A list containing the following items
</p>
<table role = "presentation">
<tr><td><code>L</code></td>
<td>
<p>The low rank component</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>The diagonally dominant component</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DDPCA_nonconvex">DDPCA_nonconvex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
p = 30
n = 30
k = 3
rho = 0.5
a = 0:(p-1)
Sigma_mu = rho^abs(outer(a,a,'-'))
Sigma_mu = (diag(p) + Sigma_mu)/2 # Now Sigma_mu is a symmetric diagonally dominant matrix
mu = mvrnorm(n,rep(0,p),Sigma_mu)
B = matrix(rnorm(p*k),nrow = p)
F = matrix(rnorm(k*n),nrow = k)
Y = mu + t(B %*% F) 
Sigma_sample = cov(Y)
result = DDPCA_convex(Sigma_sample,lambda=3)
</code></pre>

<hr>
<h2 id='DDPCA_nonconvex'>
Diagonally Dominant Principal Component Analysis using Nonconvex approach
</h2><span id='topic+DDPCA_nonconvex'></span>

<h3>Description</h3>

<p>This function decomposes a positive semidefinite matrix into a low rank component, and a diagonally dominant component using an iterative projection algorithm. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DDPCA_nonconvex(Sigma, K, max_iter_nonconvex = 15, SDD_approx = TRUE, 
max_iter_SDD = 20, eps = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DDPCA_nonconvex_+3A_sigma">Sigma</code></td>
<td>

<p>Input matrix of size <code class="reqn">n\times n</code>
</p>
</td></tr>
<tr><td><code id="DDPCA_nonconvex_+3A_k">K</code></td>
<td>

<p>A positive integer indicating the rank of the low rank component.
</p>
</td></tr>
<tr><td><code id="DDPCA_nonconvex_+3A_max_iter_nonconvex">max_iter_nonconvex</code></td>
<td>

<p>Maximal number of iterations of the iterative projection algorithm. 
</p>
</td></tr>
<tr><td><code id="DDPCA_nonconvex_+3A_sdd_approx">SDD_approx</code></td>
<td>

<p>If set to TRUE, then the projection onto SDD cone step in each iteration will be replaced by projection onto DD cone followed by symmetrization. This approximation will reduce the computational cost, but the output matrix <code>A</code> may only be approximately diagonally dominant. 
</p>
</td></tr>
<tr><td><code id="DDPCA_nonconvex_+3A_max_iter_sdd">max_iter_SDD</code>, <code id="DDPCA_nonconvex_+3A_eps">eps</code></td>
<td>

<p>Arguments in function <code>ProjSDD</code>. Matters only when <code>SDD_approx = False</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs iterative projection algorithm to decompose a positive semidefinite matrix <code>Sigma</code> into a low rank component <code>L</code> and a symmetric diagonally dominant component <code>A</code>. The projection onto the set of low rank matrices is done via eigenvalue decomposition, while the projection onto the symmetric diagonally dominant (SDD) cone is done via function <code>ProjSDD</code>, unless <code>SDD_approx = TRUE</code> where an approximation is used to speed up the algorithm. 
</p>


<h3>Value</h3>

<p>A list containing the following items
</p>
<table role = "presentation">
<tr><td><code>L</code></td>
<td>
<p>The low rank component</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>The diagonally dominant component</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DDPCA_convex">DDPCA_convex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
p = 200
n = 200
k = 3
rho = 0.5
a = 0:(p-1)
Sigma_mu = rho^abs(outer(a,a,'-'))
Sigma_mu = (diag(p) + Sigma_mu)/2 # Now Sigma_mu is a symmetric diagonally dominant matrix
mu = mvrnorm(n,rep(0,p),Sigma_mu)
B = matrix(rnorm(p*k),nrow = p)
F = matrix(rnorm(k*n),nrow = k)
Y = mu + t(B %*% F) 
Sigma_sample = cov(Y)
result = DDPCA_nonconvex(Sigma_sample,K=k)
</code></pre>

<hr>
<h2 id='HCdetection'>
Higher Criticism for detecting rare and weak signals
</h2><span id='topic+HCdetection'></span>

<h3>Description</h3>

<p>This function takes a bunch of p-values as input and ouput the Higher Criticism statistics as well as the decision (rejection or not).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCdetection(p, alpha = 0.5, pvalcut = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HCdetection_+3A_p">p</code></td>
<td>

<p>A vector of size <code>n</code> containing p-values from data
</p>
</td></tr>
<tr><td><code id="HCdetection_+3A_alpha">alpha</code></td>
<td>

<p>A number between 0 and 1. The smallest alpha*n p-values will be
used to calculate the HC statistic. Default is 0.5.
</p>
</td></tr>
<tr><td><code id="HCdetection_+3A_pvalcut">pvalcut</code></td>
<td>

<p>A number between 0 and 1. Those small p-values (smaller than
pvalcut) will be taken away to avoid heavy tails of test
statistic. Set it to <code>NA</code> is equivalent to setting it to <code class="reqn">1/n</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is an adaptation of the Matlab code here <a href="http://www.stat.cmu.edu/~jiashun/Research/software/HC/">http://www.stat.cmu.edu/~jiashun/Research/software/HC/</a>
</p>


<h3>Value</h3>

<p>Returns a list containing the following items
</p>
<table role = "presentation">
<tr><td><code>H</code></td>
<td>
<p>0 or 1 scalar indicating whether <code class="reqn">H_0</code> the global null is rejected (1) or not rejected (0)</p>
</td></tr>
<tr><td><code>HCT</code></td>
<td>
<p>Higher Criticism test statistic</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Donoho, D. and Jin, J., Higher criticism for detecting sparse heterogeneous mixtures. Ann. Statist. 32 (2004), no. 3, 962&ndash;994. 
</p>
<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 1e5
data = rnorm(n)
p = 2*(1 - pnorm(abs(data)))
result = HCdetection(p)
print(result$H)
print(result$HCT)
</code></pre>

<hr>
<h2 id='IHCDD'>
IHC-DD test 
</h2><span id='topic+IHCDD'></span>

<h3>Description</h3>

<p>Combining Innovated Higher Criticism with DDPCA for detecting sparse mean effect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IHCDD(X, method = "nonconvex", K = 1, lambda = 3, max_iter_nonconvex = 15, 
SDD_approx = TRUE, max_iter_SDD = 20, eps = NA, rho = 20, max_iter_convex = 50, 
alpha = 0.5, pvalcut = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IHCDD_+3A_x">X</code></td>
<td>

<p>A <code class="reqn">n\times p</code> data matrix, where each row is drawn i.i.d from <code class="reqn">\mathcal{N}(\mu,\Sigma)</code>
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_method">method</code></td>
<td>

<p>Either &quot;convex&quot; or &quot;noncovex&quot;, indicating which method to use for DDPCA.
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_k">K</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. Need to be specified when <code>method = "nonconvex"</code>
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_lambda">lambda</code></td>
<td>

<p>Argument in function <code>DDPCA_convex</code>. Need to be specified when <code>method = "convex"</code>
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_max_iter_nonconvex">max_iter_nonconvex</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_sdd_approx">SDD_approx</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_max_iter_sdd">max_iter_SDD</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_eps">eps</code></td>
<td>

<p>Argument in function <code>DDPCA_nonconvex</code>. 
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_rho">rho</code></td>
<td>

<p>Argument in function <code>DDPCA_convex</code>. 
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_max_iter_convex">max_iter_convex</code></td>
<td>

<p>Argument in function <code>DDPCA_convex</code>. 
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_alpha">alpha</code></td>
<td>

<p>Argument in function <code>HCdetection</code>.
</p>
</td></tr>
<tr><td><code id="IHCDD_+3A_pvalcut">pvalcut</code></td>
<td>

<p>Argument in function <code>HCdetection</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See reference paper for more details.
</p>


<h3>Value</h3>

<p>Returns a list containing the following items
</p>
<table role = "presentation">
<tr><td><code>H</code></td>
<td>
<p>0 or 1 scalar indicating whether <code class="reqn">H_0</code> the global null is rejected (1) or not rejected (0). Not recommended for use.</p>
</td></tr>
<tr><td><code>HCT</code></td>
<td>
<p>IHC-DD Test statistic</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DDHC">DDHC</a></code>, <code><a href="#topic+HCdetection">HCdetection</a></code>, <code><a href="#topic+DDPCA_convex">DDPCA_convex</a></code>, <code><a href="#topic+DDPCA_nonconvex">DDPCA_nonconvex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
n = 200
p = 200
k = 3
rho = 0.5
a = 0:(p-1)
Sigma_mu = rho^abs(outer(a,a,'-'))
Sigma_mu = (diag(p) + Sigma_mu)/2 # Now Sigma_mu is a symmetric diagonally dominant matrix
B = matrix(rnorm(p*k),nrow = p)
Sigma = Sigma_mu + B %*% t(B)
X = mvrnorm(n,rep(0,p),Sigma)
results = IHCDD(X,K = k)
print(results$H)
print(results$HCT)
</code></pre>

<hr>
<h2 id='ProjDD'>
Projection onto the Diagonally Dominant Cone
</h2><span id='topic+ProjDD'></span>

<h3>Description</h3>

<p>Given a matrix C, this function outputs the projection of C onto the cones of diagonally domimant matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ProjDD(C)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ProjDD_+3A_c">C</code></td>
<td>

<p>A <code class="reqn">n \times n</code> matrix
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function projects the input matrix <code class="reqn">C</code> of size <code class="reqn">n\times n</code> onto the cones of diagonally domimant matrices defined as 
</p>
<p style="text-align: center;"><code class="reqn"> \{A = (a_{ij})_{1\le i\le n, 1\le j\le n} : a_{jj} \ge \sum_{k\not=j} |a_{jk}| \quad  \textrm{for all} \quad 1\le j\le n \}</code>
</p>

<p>The algorithm is described in Mendoza, M., Raydan, M. and Tarazaga, P., 1998. Computing the nearest diagonally dominant matrix.
</p>


<h3>Value</h3>

<p>A <code class="reqn">n\times n</code> diagonally dominant matrix
</p>


<h3>Author(s)</h3>

<p>Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Mendoza, M., Raydan, M. and Tarazaga, P., 1998. Computing the nearest diagonally dominant matrix. Numerical linear algebra with applications, 5(6), pp.461-474.
</p>
<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ProjSDD">ProjSDD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ProjDD(matrix(runif(100),nrow=10))
</code></pre>

<hr>
<h2 id='ProjSDD'>
Projection onto the Symmetric Diagonally Dominant Cone
</h2><span id='topic+ProjSDD'></span>

<h3>Description</h3>

<p>Given a matrix C, this function outputs the projection of C onto the cones of symmetric diagonally domimant matrices using Dykstra's projection algorithm. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ProjSDD(A, max_iter_SDD = 20, eps = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ProjSDD_+3A_a">A</code></td>
<td>

<p>Input matrix of size <code class="reqn">n\times n</code>
</p>
</td></tr>
<tr><td><code id="ProjSDD_+3A_max_iter_sdd">max_iter_SDD</code></td>
<td>

<p>Maximal number of iterations of the Dykstra's projection algorithm 
</p>
</td></tr>
<tr><td><code id="ProjSDD_+3A_eps">eps</code></td>
<td>

<p>The iterations will stop either when the Frobenious norm of difference matrix between two updates is less than <code>eps</code> or after <code>max_iter_SDD</code> steps. If set to <code>NA</code>, then no check will be done during iterations and the iteration will stop after <code>max_iter_SDD</code> steps. Default is <code>NA</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function projects the input matrix <code class="reqn">C</code> of size <code class="reqn">n\times n</code> onto the cones of symmetric diagonally domimant matrices defined as 
</p>
<p style="text-align: center;"><code class="reqn"> \{A = (a_{ij})_{1\le i\le n, 1\le j\le n} : a_{ij} = a_{ji}, a_{jj} \ge \sum_{k\not=j} |a_{jk}| \quad \textrm{for all} \quad 1\le j\le n, 1\le i\le n \}</code>
</p>

<p>It makes use of Dykstra's algorithm, which is a variation of iterative projection algorithm. The two key steps are projection onto the diagonally domimant cone by calling function <code>ProjDD</code> and projection onto the symmetric matrix cone by simple symmetrization. 
</p>
<p>More details can be found in Mendoza, M., Raydan, M. and Tarazaga, P., 1998. Computing the nearest diagonally dominant matrix.
</p>


<h3>Value</h3>

<p>A <code class="reqn">n\times n</code> symmetric diagonally dominant matrix
</p>


<h3>Author(s)</h3>

<p>Fan Yang &lt;fyang1@uchicago.edu&gt;
</p>


<h3>References</h3>

<p>Mendoza, M., Raydan, M. and Tarazaga, P., 1998. Computing the nearest diagonally dominant matrix. Numerical linear algebra with applications, 5(6), pp.461-474.
</p>
<p>Ke, Z., Xue, L. and Yang, F., 2019. Diagonally Dominant Principal Component Analysis. Journal of Computational and Graphic Statistics, under review.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ProjDD">ProjDD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ProjSDD(matrix(runif(100),nrow=10))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
