<!DOCTYPE html><html><head><title>Help for package RANKS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RANKS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RANKS-package'>
<p>RANKS: Ranking of Nodes with Kernelized Score Functions</p></a></li>
<li><a href='#do.GBA'>
<p>GBA cross-validation experiments with multiple classes</p></a></li>
<li><a href='#do.loo.RANKS'>
<p>RANKS leave-one-out experiments with multiple classes</p></a></li>
<li><a href='#do.RANKS'>
<p>RANKS cross-validation experiments with multiple classes</p></a></li>
<li><a href='#do.RW'>
<p>Random walk cross-validation experiments with multiple classes</p></a></li>
<li><a href='#do.RWR'>
<p>Random walk with restart cross-validation experiments with multiple classes</p></a></li>
<li><a href='#find.optimal.thresh.cv'>
<p>Function to find the optimal RANKS score thereshold</p></a></li>
<li><a href='#GBAmax'>
<p>Guilt By Association (GBA) using the maximum rule</p></a></li>
<li><a href='#GBAsum'>
<p>Guilt By Association (GBA) using the sum rule</p></a></li>
<li><a href='#ker.score.classifier.cv'>
<p>Multiple cross-validation with RANKS for classification</p></a></li>
<li><a href='#ker.score.classifier.holdout'>
<p>RANKS held-out procedure for a single class</p></a></li>
<li><a href='#ker.score.cv'>
<p>RANKS cross-validation for a single class</p></a></li>
<li><a href='#kernel.functions'>
<p>Kernel functions</p></a></li>
<li><a href='#label.prop'>
<p>Label propagation</p></a></li>
<li><a href='#multiple.ker.score.cv'>
<p>RANKS multiple cross-validation for a single class</p></a></li>
<li><a href='#multiple.ker.score.thresh.cv'>
<p>Function for RANKS multiple cross-validation and optimal threshold finding for a single class</p></a></li>
<li><a href='#multiple.RW.cv'>
<p>Random walk, GBA and labelprop multiple cross-validation for a single class</p></a></li>
<li><a href='#RW'>
<p>Random walk on a graph</p></a></li>
<li><a href='#RW.cv'>
<p>Random walk, GBA and labelprop cross-validation for a single class</p></a></li>
<li><a href='#rw.kernel-methods'><p> Random walk kernel</p></a></li>
<li><a href='#RWR'>
<p>Random walk with Restart on a graph</p></a></li>
<li><a href='#score.multiple.vertex-methods'><p>Multiple vertex score functions</p></a></li>
<li><a href='#score.single.vertex-methods'><p>Single vertex score functions</p></a></li>
<li><a href='#Utilities'>
<p>Utility functions</p></a></li>
<li><a href='#weighted.score.multiple.vertex-methods'><p>Multiple vertex score functions - weighted version</p></a></li>
<li><a href='#weighted.score.single.vertex-methods'><p>Single vertex score functions - weighted version</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Ranking of Nodes with Kernelized Score Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-09-20</td>
</tr>
<tr>
<td>Author:</td>
<td>Giorgio Valentini [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Giorgio Valentini &lt;valentini@di.unimi.it&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of Kernelized score functions and other semi-supervised learning algorithms for node label ranking to analyze  biomolecular networks. RANKS can be easily applied to a large set of different relevant problems in computational biology, ranging from automatic protein function prediction, to gene disease prioritization and drug repositioning, and more in general to any bioinformatics problem that can be formalized as a node label ranking problem in a graph. The modular nature of the implementation allows to experiment with different score functions and kernels and to easily compare the results with baseline network-based methods such as label propagation and random walk algorithms, as well as to enlarge the algorithmic scheme by adding novel user-defined score functions and kernels.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, graph, RBGL, limma, NetPreProc, PerfMeas</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bionetdata</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-20 15:05:16 UTC; valenti</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-20 22:40:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='RANKS-package'>
RANKS: Ranking of Nodes with Kernelized Score Functions
</h2><span id='topic+RANKS-package'></span><span id='topic+RANKS'></span>

<h3>Description</h3>

<p>Implementation of Kernelized score functions and other semi-supervised learning algorithms for node label ranking 
in biomolecular networks. 
</p>


<h3>Details</h3>

<p>RANKS can be easily applied to a large set of different relevant problems in computational biology, 
ranging from automatic protein function prediction, to gene disease prioritization and drug repositioning, and more in general 
to any bioinformatics problem that can be formalized as a node label ranking problem in a graph. 
The modular nature of the implementation allows to experiment with different score functions and kernels and to easily 
compare the results with baseline network-based methods such as label propagation and random walk algorithms, as well 
as to enlarge the algorithmic scheme by adding novel user-defined score functions and kernels.
</p>


<h3>Author(s)</h3>

<p><em>Giorgio Valentini</em> 
</p>
<p>AnacletoLab
</p>
<p>DI, Dipartimento di Informatica
</p>
<p>Universita' degli Studi di Milano
</p>
<p><a href="mailto:valentini@di.unimi.it">valentini@di.unimi.it</a>
</p>
<p>Maintainer: 
<em>Giorgio Valentini</em> 
</p>


<h3>References</h3>

<p>Giorgio Valentini, Giuliano Armano, Marco Frasca, Jianyi Lin, Marco Mesiti, and Matteo Re 
RANKS: a flexible tool for node label ranking and classification in biological networks
Bioinformatics first published online June 2, 2016 doi:10.1093/bioinformatics/btw235 
</p>
<p>Re M, Mesiti M, Valentini G: A fast ranking algorithm for predicting gene functions in biomolecular networks.
IEEE ACM Trans Comput Biol Bioinform 2012, 9(6):1812-1818.
</p>
<p>Re M, Valentini G: Cancer module genes ranking using kernelized score functions.
BMC Bioinformatics 2012, 13(S14):S3.
</p>
<p>Re M, Valentini G: Network-based drug ranking and repositioning with respect to DrugBank therapeutic categories.
IEEE/ACM Trans Comput Biol Bioinform 2013, 10(6):1359-1371. 
</p>
<p>G. Valentini, A. Paccanaro, H. Caniza, A. Romero, M. Re: An extensive analysis of disease-gene associations using network integration
and fast kernel-based gene prioritization methods, Artif. Intell. in Med. 61 (2) (2014) 63-78
</p>

<hr>
<h2 id='do.GBA'>
GBA cross-validation experiments with multiple classes
</h2><span id='topic+do.GBA'></span>

<h3>Description</h3>

<p>High level function to perform experiments with GBA.
It perform a k fold CV repeated 1 time on a given data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.GBA(fun = GBAsum, k = 5, stratified=TRUE, filter = TRUE,  seed = 1, 
       data.dir, labels.dir, output.dir, data, labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do.GBA_+3A_fun">fun</code></td>
<td>
<p>function performing GBA. it can be one of the following:
</p>
<p>- GBAsum: it sums the edge weights connecting a node to its positive neighbours
</p>
<p>- GBAmax: it computes the maximum between the edge weights connecting a node to its positive neighbours</p>
</td></tr>
<tr><td><code id="do.GBA_+3A_k">k</code></td>
<td>
<p>number of folds for the cross validation (def. 5)</p>
</td></tr>
<tr><td><code id="do.GBA_+3A_stratified">stratified</code></td>
<td>
<p>boolean. If TRUE (def.) stratified CV is performed otherwise vanilla CV is done</p>
</td></tr> 
<tr><td><code id="do.GBA_+3A_filter">filter</code></td>
<td>
<p>if TRUE (def) the adjacency  matrix is sparsified otherwise not</p>
</td></tr>
<tr><td><code id="do.GBA_+3A_seed">seed</code></td>
<td>
<p>seed of the random generator for the generation of the folds (def: 1)</p>
</td></tr>
<tr><td><code id="do.GBA_+3A_data.dir">data.dir</code></td>
<td>
<p>relative path to directory where the adjiacency matrix is stored </p>
</td></tr>
<tr><td><code id="do.GBA_+3A_labels.dir">labels.dir</code></td>
<td>
<p>relative path to directory where the label matrix is stored </p>
</td></tr>
<tr><td><code id="do.GBA_+3A_output.dir">output.dir</code></td>
<td>
<p>relative path to directory where the results are stored </p>
</td></tr>
<tr><td><code id="do.GBA_+3A_data">data</code></td>
<td>
<p>name of the data set to loaded (without rda extension). It must be  an .rda file containing the adjiacency matrix of the graph.
It assumes that it is in the &quot;data.dir&quot; directory</p>
</td></tr>
<tr><td><code id="do.GBA_+3A_labels">labels</code></td>
<td>
<p>name of the target labels (without rda extension). It must be  an .rda file containing the label matrix of the examples.
Rows correspond to examples and columns to classes
It assumes that it is in the &quot;labels.dir&quot; directory</p>
</td></tr>
</table>


<h3>Details</h3>

<p>High level function to perform cross-validation experiments with multiple classes using GBA.
</p>
<p>It performs a k fold CV on a given data set, and output scores, AUC and Precision at a given recall results for multiple classes.
</p>
<p>Graph data are read from a matrix representing the adjiacency matrix of the graph stored as a .rda file. The labels are read from a matrix having examples as rows and classes as columns stored as a .rda file. If M is the label matrix, then M[i,j]=1, if example i is annotated with class j, otherwise M[i,j] = 0.
</p>
<p>Results are included in matrices representing Scores, AUC and precision at a given recall results stored as .rda files.
</p>


<h3>Value</h3>

<p>3 rda files stored in the &quot;Results&quot; directory:
</p>
<table>
<tr><td><code>Scores results</code></td>
<td>
<p>A matrix with examples on rows and classes on columns representing the computed scores for each example and for each considered class</p>
</td></tr>
<tr><td><code>AUC results</code></td>
<td>
<p>AUC results files computed through <code>AUC.single.over.classes</code> from the package PerfMeas</p>
</td></tr>
<tr><td><code>Precision at given recall results</code></td>
<td>
<p>computed through <code>precision.at.multiple.recall.level.over.classes</code> from the package PerfMeas.</p>
</td></tr>
</table>
<p>The name of the Score file starts with Score, of the AUC file with AUC, and of the Precision at given recall file with PXR.
Other learning parameters are appended to the name of the file. All the results .rda files are stored in the Results directory (that must exist in advance).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GBAmax">GBAmax</a></code>, <code><a href="#topic+GBAsum">GBAsum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Yeast prediction of 177 FunCat classes by 5-fold cross validation using STRING data
# data obtained from the bionetdata package from CRAN
# See the AUC and Precision/recall results in the Results directory
library(bionetdata);
dd=tempdir();
rr=tempdir();
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
save(Yeast.STRING.data, file=paste(dd,"/net.rda", sep=""));
save(Yeast.STRING.FunCat, file=paste(dd,"/labels.rda", sep=""));
do.GBA(data.dir=dd, labels.dir=dd, output.dir=rr, data="/net", labels="/labels");

</code></pre>

<hr>
<h2 id='do.loo.RANKS'>
RANKS leave-one-out experiments with multiple classes
</h2><span id='topic+do.loo.RANKS'></span>

<h3>Description</h3>

<p>High level function to perform RANKS leave one out (loo) experiments with mutliple classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.loo.RANKS(score = eav.score, compute.kernel = TRUE, kernel = rw.kernel, a = 2, 
k = 19, d = 2, p = 1, sparsify = FALSE, norm = FALSE, data, labels, output.name, 
data.dir, labels.dir, output.dir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do.loo.RANKS_+3A_score">score</code></td>
<td>
<p>function. It must be a kernel-based score method:
</p>
<p>- eav.score (default)
</p>
<p>- NN.score
</p>
<p>- KNN.score
</p>
<p>- WSLD.score
</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_compute.kernel">compute.kernel</code></td>
<td>
<p>logical. If TRUE (def.) a kernel matrix is computed from data according to the choice of the function kernel, otherwise the data matrix is used as it is.</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_kernel">kernel</code></td>
<td>
<p>kernel method or function (def. rw.kernel)</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_a">a</code></td>
<td>
<p>kernel parameter (def. 2)</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_k">k</code></td>
<td>
<p>number of neighbours for KNN.score. It is meaningful only for  kNN  (def.19)</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_d">d</code></td>
<td>
<p>integer. Coefficient of linear decay for the WSLD score. It is meaningful only for  the WSLD score  (def.2)</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_p">p</code></td>
<td>
<p>number of steps of the RW kernel (def. 1)</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_sparsify">sparsify</code></td>
<td>
<p>boolean. If TRUE the input matrix is sparsified using Sparsify.matrix from the package NetpreProc (def: FALSE)</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_norm">norm</code></td>
<td>
<p>logical. If TRUE for each class the score is normalized in [0,1], otherwise the raw scores are maintained (default).</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_data">data</code></td>
<td>
<p>name of the network data set to be loaded (without rda extension). It must be  an .rda file containing the adjiacency matrix of the graph.
By default it assumes that it is in the data.dir directory</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_labels">labels</code></td>
<td>
<p>name of the target labels (without rda extension). It must be  an .rda file containing the label matrix of the examples.
By default it assumes that it is in the net.dir directory</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_output.name">output.name</code></td>
<td>
<p>name of the output file (without rda extension). Other informations including the learning parameters are added in the name of the file</p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_data.dir">data.dir</code></td>
<td>
<p>relative path to the directory where the adjiacency matrix is stored </p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_labels.dir">labels.dir</code></td>
<td>
<p>relative path to directory where the label matrix is stored </p>
</td></tr>
<tr><td><code id="do.loo.RANKS_+3A_output.dir">output.dir</code></td>
<td>
<p>relative path to directory where the results are stored. Note that data and labels must have the same number of rows and in the same order. Moreover if any label column corresponds to any GO root term, this is eliminated to avoid prediction of GO root nodes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>High level function to perform loo experiments with multiple classes using RANKS.
</p>
<p>It performs a loo on a given data set, and scores, AUC and Precision at a given recall results for multiple classes are generated.
</p>
<p>Graph data are read from a matrix representing the adjiacency matrix of the graph stored as a .rda file. The labels are read from a matrix having examples as rows and classes as columns stored as a .rda file. If <code class="reqn">M</code> is the label matrix, then <code class="reqn">M[i,j]=1</code>, if example <code class="reqn">i</code> is annotated with class <code class="reqn">j</code>, otherwise <code class="reqn">M[i,j] = 0</code>.
</p>
<p>Results are included in matrices representing Scores, AUC and precision at a given recall results stored as .rda files.
</p>


<h3>Value</h3>

<p>3 rda files stored in the output.dir directory:
</p>
<table>
<tr><td><code>Scores results</code></td>
<td>
<p>A matrix with examples on rows and classes on columns representing the computed scores for each example and for each considered class</p>
</td></tr>
<tr><td><code>AUC results</code></td>
<td>
<p>AUC results files computed through <code>AUC.single.over.classes</code> from the package PerfMeas</p>
</td></tr>
<tr><td><code>Precision at given recall results</code></td>
<td>
<p>computed through <code>precision.at.multiple.recall.level.over.classes</code> from the package PerfMeas.</p>
</td></tr>
</table>
<p>The name of the Score file starts with Score.loo, of the AUC file with AUC.loo, and of the Precision at given recall file with PXR.loo.
Other learning parameters are appended to the name of the file.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+do.RANKS">do.RANKS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Yeast prediction of 177 FunCat classes by leave-one-out using STRING data
# data obtained from the bionetdata package from CRAN. 
# See the AUC and Precision/recall results in the Results directory
library(bionetdata);
dd=tempdir();
rr=tempdir();
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
save(Yeast.STRING.data, file=paste(dd,"/net.rda", sep=""));
save(Yeast.STRING.FunCat, file=paste(dd,"/labels.rda", sep=""));
do.loo.RANKS(data.dir=dd, labels.dir=dd, output.dir=rr, data="/net", 
labels="/labels", output.name="Yeast.loo");
# another  leave-one-out prediction using KNN score and 2 steps random walk kernel
do.loo.RANKS(score = KNN.score, k=3, p=2, data.dir=dd, labels.dir=dd, output.dir=rr, 
data="/net", labels="/labels", output.name="Yeast.loo");

</code></pre>

<hr>
<h2 id='do.RANKS'>
RANKS cross-validation experiments with multiple classes
</h2><span id='topic+do.RANKS'></span>

<h3>Description</h3>

<p>High level function to perform RANKS cross-validation experiments with multiple classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.RANKS(score = eav.score, kernel = rw.kernel, a = 2, p = 1, sparsify = TRUE, kk = 5, 
rep = 1, stratified=TRUE, seed = 0, data.dir, labels.dir, 
output.dir, data, labels, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do.RANKS_+3A_score">score</code></td>
<td>
<p>function. It must be a kernel-based score method:
</p>
<p>- eav.score (default)
</p>
<p>- NN.score
</p>
<p>- KNN.score
</p>
<p>- WSLD.score
</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_kernel">kernel</code></td>
<td>
<p>kernel metod or function (def. rw.kernel)</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_a">a</code></td>
<td>
<p>kernel parameter (def. 2)</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_p">p</code></td>
<td>
<p>number of steps of the RW kernel (def. 1)</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_sparsify">sparsify</code></td>
<td>
<p>boolean. If TRUE (def) the input matrix is sparsified using Sparsify.matrix from the package NetpreProc</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_kk">kk</code></td>
<td>
<p>number of folds of the cross validation (def: 5)</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_rep">rep</code></td>
<td>
<p>number of repetitions of the cross validation (def: 1)</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_stratified">stratified</code></td>
<td>
<p>boolean. If TRUE (def.) stratified CV is performed otherwise vanilla CV is done</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_seed">seed</code></td>
<td>
<p>initialization seed for the random generator to create folds (def:0)</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_data.dir">data.dir</code></td>
<td>
<p>relative path to directory where the adjiacency matrix is stored</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_labels.dir">labels.dir</code></td>
<td>
<p>relative path to directory where the label matrix is stored</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_output.dir">output.dir</code></td>
<td>
<p>relative path to directory where the results are stored</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_data">data</code></td>
<td>
<p>name of the data set to loaded (without rda extension). It must be  an .rda file containing the adjiacency matrix of the graph.
It assumes that it is in the data.dir directory</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_labels">labels</code></td>
<td>
<p>name of the target labels (without rda extension). It must be  an .rda file containing the label matrix of the examples.
It assumes that it is in the labels.dir directory. Note that data and labels must have the same number of rows and in the same order</p>
</td></tr>
<tr><td><code id="do.RANKS_+3A_...">...</code></td>
<td>
<p>optional arguments to be passed to the function <code>multiple.ker.score.cv</code> that performs the CV</p>
</td></tr>
</table>


<h3>Details</h3>

<p>High level function to perform cross-validation experiments with multiple classes using RANKS.
</p>
<p>It performs a k fold CV repeated multiple times on a given data set, and scores, AUC and Precision at a given recall results for multiple classes are generated.
</p>
<p>Graph data are read from a matrix representing the adjiacency matrix of the graph stored as a .rda file. The labels are read from a matrix having examples as rows and classes as columns stored as a .rda file. If <code class="reqn">M</code> is the label matrix, then <code class="reqn">M[i,j]=1</code>, if example <code class="reqn">i</code> is annotated with class <code class="reqn">j</code>, otherwise <code class="reqn">M[i,j] = 0</code>.
</p>
<p>Results are included in matrices representing Scores, AUC and precision at a given recall results stored as .rda files.
</p>


<h3>Value</h3>

<p>3 rda files stored in the output.dir directory:
</p>
<table>
<tr><td><code>Scores results</code></td>
<td>
<p>A matrix with examples on rows and classes on columns representing the computed scores for each example and for each considered class</p>
</td></tr>
<tr><td><code>AUC results</code></td>
<td>
<p>AUC results files computed through <code>AUC.single.over.classes</code> from the package PerfMeas</p>
</td></tr>
<tr><td><code>Precision at given recall results</code></td>
<td>
<p>computed through <code>precision.at.multiple.recall.level.over.classes</code> from the package PerfMeas.</p>
</td></tr>
</table>
<p>The name of the Score file starts with Score, of the AUC file with AUC, and of the Precision at given recall file with PXR.
Other learning parameters are appended to the name of the file.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiple.ker.score.cv">multiple.ker.score.cv</a></code>, <code><a href="#topic+do.loo.RANKS">do.loo.RANKS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Yeast prediction of 177 FunCat classes by 5-fold cross validation using STRING data
# data obtained from the bionetdata package from CRAN
# See the AUC and Precision/recall results in the Results directory
library(bionetdata);
dd=tempdir();
rr=tempdir();
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
save(Yeast.STRING.data, file=paste(dd,"/net.rda", sep=""));
save(Yeast.STRING.FunCat, file=paste(dd,"/labels.rda", sep=""));
do.RANKS(data.dir=dd, labels.dir=dd, output.dir=rr, data="/net", labels="/labels");

</code></pre>

<hr>
<h2 id='do.RW'>
Random walk cross-validation experiments with multiple classes
</h2><span id='topic+do.RW'></span>

<h3>Description</h3>

<p>High level function to perform random walk cross-validation experiments with multiple classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.RW(tmax = 1000, eps = 1e-10, k = 5, stratified=TRUE, filter = TRUE, seed = 1, 
      data.dir, labels.dir, output.dir, data, labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do.RW_+3A_tmax">tmax</code></td>
<td>
<p>maximum number of iterations (def: 1000)</p>
</td></tr>
<tr><td><code id="do.RW_+3A_eps">eps</code></td>
<td>
<p>maximum allowed difference between the computed probabilities at the steady state (def. 1e-10)</p>
</td></tr>
<tr><td><code id="do.RW_+3A_k">k</code></td>
<td>
<p>number of folds for the cross validation (def. 5)</p>
</td></tr>
<tr><td><code id="do.RW_+3A_stratified">stratified</code></td>
<td>
<p>boolean. If TRUE (def.) stratified CV is performed otherwise vanilla CV is done</p>
</td></tr>
<tr><td><code id="do.RW_+3A_filter">filter</code></td>
<td>
<p>if TRUE (def) the adjacency matrix is sparsified otherwise not</p>
</td></tr>
<tr><td><code id="do.RW_+3A_seed">seed</code></td>
<td>
<p>seed of the random generator for the generation of the folds (def: 1)</p>
</td></tr>
<tr><td><code id="do.RW_+3A_data.dir">data.dir</code></td>
<td>
<p>relative path to directory where the adjiacency matrix is stored </p>
</td></tr>
<tr><td><code id="do.RW_+3A_labels.dir">labels.dir</code></td>
<td>
<p>relative path to directory where the label matrix is stored </p>
</td></tr>
<tr><td><code id="do.RW_+3A_output.dir">output.dir</code></td>
<td>
<p>relative path to directory where the results are stored  </p>
</td></tr>
<tr><td><code id="do.RW_+3A_data">data</code></td>
<td>
<p>name of the data set to loaded (without rda extension). It must be  an .rda file containing the adjacency matrix of the graph.
It assumes that it is in the data.dir directory</p>
</td></tr>
<tr><td><code id="do.RW_+3A_labels">labels</code></td>
<td>
<p>name of the target labels (without rda extension). It must be  an .rda file containing the label matrix of the examples.
It assumes that it is in the labels.dir directory</p>
</td></tr>
</table>


<h3>Details</h3>

<p>High level function to perform cross-validation experiments with multiple classes using RW.
</p>
<p>It performs a k fold CV on a given data set, and output scores, AUC and Precision at a given recall results for multiple classes.
</p>
<p>Graph data are read from a matrix representing the adjiacency matrix of the graph stored as a .rda file. The labels are read from a matrix having examples as rows and classes as columns stored as a .rda file. If <code class="reqn">M</code> is the label matrix, then <code class="reqn">M[i,j]=1</code>, if example <code class="reqn">i</code> is annotated with class <code class="reqn">j</code>, otherwise <code class="reqn">M[i,j] = 0</code>.
</p>
<p>Results are included in matrices representing Scores, AUC and precision at a given recall results stored as .rda files.
</p>


<h3>Value</h3>

<p>3 rda files stored in the Results directory:
</p>
<table>
<tr><td><code>Scores results</code></td>
<td>
<p>A matrix with examples on rows and classes on columns representing the computed scores for each example and for each considered class</p>
</td></tr>
<tr><td><code>AUC results</code></td>
<td>
<p>AUC results files computed through <code>AUC.single.over.classes</code> from the package PerfMeas</p>
</td></tr>
<tr><td><code>Precision at given recall results</code></td>
<td>
<p>computed through <code>precision.at.multiple.recall.level.over.classes</code> from the package PerfMeas.</p>
</td></tr>
</table>
<p>The name of the Score file starts with Score, of the AUC file with AUC, and of the Precision at given recall file with PXR.
Other learning parameters are appended to the name of the file. All the results .rda files are stored in the Results directory (that must exist in advance).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RW">RW</a></code>,  <code><a href="#topic+multiple.RW.cv">multiple.RW.cv</a></code>, <code><a href="#topic+do.RWR">do.RWR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Yeast prediction of 177 FunCat classes by 5-fold cross validation 
# using 3 steps of Random walk and STRING data. 
# data obtained from the bionetdata package from CRAN
# See the AUC and Precision/recall results in the Results directory
library(bionetdata);
dd=tempdir();
rr=tempdir();
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
save(Yeast.STRING.data, file=paste(dd,"/net.rda", sep=""));
save(Yeast.STRING.FunCat, file=paste(dd,"/labels.rda", sep=""));
do.RW(tmax = 3, filter = FALSE, seed = 1, data.dir=dd, labels.dir=dd, 
output.dir=rr, data="/net", labels="/labels");

</code></pre>

<hr>
<h2 id='do.RWR'>
Random walk with restart cross-validation experiments with multiple classes
</h2><span id='topic+do.RWR'></span>

<h3>Description</h3>

<p>High level function to perform random walk with restart cross-validation experiments with multiple classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.RWR(gamma = 0.6, tmax = 1000, eps = 1e-10, k = 5, stratified=TRUE, filter = TRUE, 
 seed = 1, data.dir, labels.dir, output.dir, data, labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do.RWR_+3A_gamma">gamma</code></td>
<td>
<p>restart parameter (def: 0.6)</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_tmax">tmax</code></td>
<td>
<p>maximum number of iterations (def: 1000)</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_eps">eps</code></td>
<td>
<p>maximum allowed difference between the computed probabilities at the steady state (def. 1e-10)</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_k">k</code></td>
<td>
<p>number of folds for the cross validation (def. 5)</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_stratified">stratified</code></td>
<td>
<p>boolean. If TRUE (def.) stratified CV is performed otherwise vanilla CV is done</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_filter">filter</code></td>
<td>
<p>if TRUE (def) the adjacency matrix is sparsified otherwise not</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_seed">seed</code></td>
<td>
<p>seed of the random generator for the generation of the folds (def: 1)</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_data.dir">data.dir</code></td>
<td>
<p>relative path to directory where the adjiacency matrix is stored </p>
</td></tr>
<tr><td><code id="do.RWR_+3A_labels.dir">labels.dir</code></td>
<td>
<p>relative path to directory where the label matrix is stored </p>
</td></tr>
<tr><td><code id="do.RWR_+3A_output.dir">output.dir</code></td>
<td>
<p>relative path to directory where the results are stored  </p>
</td></tr>
<tr><td><code id="do.RWR_+3A_data">data</code></td>
<td>
<p>name of the data set to loaded (without rda extension). It must be  an .rda file containing the adjiacency matrix of the graph.
It assumes that it is in the data.dir directory</p>
</td></tr>
<tr><td><code id="do.RWR_+3A_labels">labels</code></td>
<td>
<p>name of the target labels (without rda extension). It must be  an .rda file containing the label matrix of the examples.
It assumes that it is in the labels.dir directory</p>
</td></tr>
</table>


<h3>Details</h3>

<p>High level function to perform cross-validation experiments with multiple classes using RWR.
</p>
<p>It performs a k fold CV on a given data set, and output scores, AUC and Precision at a given recall results for multiple classes.
</p>
<p>Graph data are read from a matrix representing the adjiacency matrix of the graph stored as a .rda file. The labels are read from a matrix having examples as rows and classes as columns stored as a .rda file. If <code class="reqn">M</code> is the label matrix, then <code class="reqn">M[i,j]=1</code>, if example <code class="reqn">i</code> is annotated with class <code class="reqn">j</code>, otherwise <code class="reqn">M[i,j] = 0</code>.
</p>
<p>Results are included in matrices representing Scores, AUC and precision at a given recall results stored as .rda files.
</p>


<h3>Value</h3>

<p>3 rda files stored in the output.dir directory:
</p>
<table>
<tr><td><code>Scores results</code></td>
<td>
<p>A matrix with examples on rows and classes on columns representing the computed scores for each example and for each considered class</p>
</td></tr>
<tr><td><code>AUC results</code></td>
<td>
<p>AUC results files computed through <code>AUC.single.over.classes</code> from the package PerfMeas</p>
</td></tr>
<tr><td><code>Precision at given recall results</code></td>
<td>
<p>computed through <code>precision.at.multiple.recall.level.over.classes</code> from the package PerfMeas.</p>
</td></tr>
</table>
<p>The name of the Score file starts with Score, of the AUC file with AUC, and of the Precision at given recall file with PXR.
Other learning parameters are appended to the name of the file. All the results .rda files are stored in the Results directory (that must exist in advance).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RWR">RWR</a></code>,  <code><a href="#topic+multiple.RW.cv">multiple.RW.cv</a></code>, <code><a href="#topic+do.RW">do.RW</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Yeast prediction of 177 FunCat classes by 5-fold cross validation 
# using 3 steps of Random walk with restart and STRING data. 
# data obtained from the bionetdata package from CRAN
# See the AUC and Precision/recall results in the Results directory
library(bionetdata);
dd=tempdir();
rr=tempdir();
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
save(Yeast.STRING.data, file=paste(dd,"/net.rda", sep=""));
save(Yeast.STRING.FunCat, file=paste(dd,"/labels.rda", sep=""));
do.RWR(tmax = 3, k = 5, filter = FALSE, seed = 1, data.dir=dd, labels.dir=dd, 
output.dir=rr, data="/net", labels="/labels");
# the same experiment, but the iterations are repeated till to convergence 
# (this can require a quite long time ...)
do.RWR(tmax = 1000, k = 5, eps = 1e-5, filter = FALSE, seed = 1, data.dir=dd, 
labels.dir=dd, output.dir=rr, data="/net", labels="/labels");

</code></pre>

<hr>
<h2 id='find.optimal.thresh.cv'>
Function to find the optimal RANKS score thereshold
</h2><span id='topic+find.optimal.thresh.cv'></span>

<h3>Description</h3>

<p>Function to find the optimal quantile alpha and corresponding threshold by  cross-validation with a kernel-based
score method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find.optimal.thresh.cv(K, ind.pos, ind.non.pos, m = 5, 
alpha = seq(from = 0.05, to = 0.6, by = 0.05), init.seed = NULL, 
opt.fun = compute.F, fun = KNN.score, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find.optimal.thresh.cv_+3A_k">K</code></td>
<td>
<p>matrix. Kernel matrix or any valid symmetric matrix</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the positive examples. They are the indices the row of RW corresponding to positive examples of the training set.</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_ind.non.pos">ind.non.pos</code></td>
<td>
<p>indices of the non positive examples. They are the indices the row of RW corresponding to non positive examples  of the training set.</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_m">m</code></td>
<td>
<p>number of folds (default: 5)</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_alpha">alpha</code></td>
<td>
<p>vector of the quantiles to be tested</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_init.seed">init.seed</code></td>
<td>
<p>initial seed for the random generator. If NULL (def) no initialization is performed</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_opt.fun">opt.fun</code></td>
<td>
<p>Function implementing the metric to select the optimal threshold.
The F-score (compute.F) is the default. Available functions:
</p>
<p>- compute.F: F-score (default) 
</p>
<p>- compute.acc:accuracy.  
</p>
<p>Any function having two arguments representing the vector of predicted and true labels can be in principle used.
</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_fun">fun</code></td>
<td>
<p>function. It must be a kernel-based score method (default KNN.score)</p>
</td></tr>
<tr><td><code id="find.optimal.thresh.cv_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function to find the optimal quantile alpha and corresponding threshold by  cross-validation with a kernel-based
score method. The optimality is computed with respect to a specific metric (def: F-score).
This function is used by <code>multiple.ker.score.thresh.cv</code>, <code>ker.score.classifier.holdout</code>, <code>ker.score.classifier.cv</code>.
</p>


<h3>Value</h3>

<p>A list with 3 elements:
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>quantile corresponding to the best F-score</p>
</td></tr>
<tr><td><code>thresh</code></td>
<td>
<p>threshold corresponding to the best F-score</p>
</td></tr>
<tr><td><code>pos.scores</code></td>
<td>
<p>scores of the positive elements computed through CV</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+multiple.ker.score.thresh.cv">multiple.ker.score.thresh.cv</a></code>, <code><a href="#topic+Kernel+20functions">Kernel functions</a></code>, <code><a href="#topic+ker.score.classifier.holdout">ker.score.classifier.holdout</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Finding the optimal threshold in the Tanimoto chemical structure similarity network 
# between 1253 DrugBank drugs for the prediction of the DrugBank category Penicillins using
# the KNN-score with the random walk kernel 
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
K &lt;- rw.kernel(DD.chem.data);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
ind.non.pos &lt;- which(labels==0);
res &lt;- find.optimal.thresh.cv(K, ind.pos, ind.non.pos);
res
</code></pre>

<hr>
<h2 id='GBAmax'>
Guilt By Association (GBA) using the maximum rule
</h2><span id='topic+GBAmax'></span>

<h3>Description</h3>

<p>GBAmax implements a Guilt By Association (GBA) method based on the maximum of incident edge weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GBAmax(W, ind.positives)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GBAmax_+3A_w">W</code></td>
<td>
<p>numeric matrix representing the adjacency matrix of the graph</p>
</td></tr>
<tr><td><code id="GBAmax_+3A_ind.positives">ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph. They represent the indices of W corresponding to the positive examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GBAmax implements a Guilt By Association (GBA) method for  label ranking based on
the maximum between the edge weights connecting a node to its positive neighbours
</p>


<h3>Value</h3>

<p>a list with one element:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>score associated to each node</p>
</td></tr>
</table>


<h3>References</h3>

<p>Oliver, S., Guilt-by-association goes global, Nature, 403, pp. 601-603, 2000.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GBAsum">GBAsum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Application of GBAmax to the prediction of the DrugBank category Penicillins
# using the Tanimoto chemical structure similarity network 
# between 1253 DrugBank drugs
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
GBAmax(DD.chem.data, ind.pos);
# Application of GBAmax to the prediction of the DrugBank category "Anti_HIV_Agents"
labels &lt;- DrugBank.Cat[,"Anti_HIV_Agents"];
ind.pos &lt;- which(labels==1);
GBAmax(DD.chem.data, ind.pos);
</code></pre>

<hr>
<h2 id='GBAsum'>
Guilt By Association (GBA) using the sum rule
</h2><span id='topic+GBAsum'></span>

<h3>Description</h3>

<p>GBAsum implements a Guilt By Association (GBA) method based on the sum of incident edge weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GBAsum(W, ind.positives)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GBAsum_+3A_w">W</code></td>
<td>
<p>numeric matrix representing the adjacency matrix of the graph</p>
</td></tr>
<tr><td><code id="GBAsum_+3A_ind.positives">ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph. They represent the indices of W corresponding to the positive examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function that implements a Guilt By Association (GBA) method for  label ranking based on
the sum of edge weights connecting a node to its positive neighbours.
</p>


<h3>Value</h3>

<p>a list with one element:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>score associated to each node</p>
</td></tr>
</table>


<h3>References</h3>

<p>Oliver, S., Guilt-by-association goes global, Nature, 403, pp. 601-603, 2000.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GBAmax">GBAmax</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Application of GBAsum to the prediction of the DrugBank category Penicillins
# using the Tanimoto chemical structure similarity network 
# between 1253 DrugBank drugs
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
GBAsum(DD.chem.data, ind.pos);
# Application of GBAsum to the prediction of the DrugBank category "Anti_HIV_Agents"
labels &lt;- DrugBank.Cat[,"Anti_HIV_Agents"];
ind.pos &lt;- which(labels==1);
GBAsum(DD.chem.data, ind.pos);
</code></pre>

<hr>
<h2 id='ker.score.classifier.cv'>
Multiple cross-validation with RANKS for classification
</h2><span id='topic+ker.score.classifier.cv'></span>

<h3>Description</h3>

<p>Function to classify labels according to an external cross-validation procedure with a kernel-based score method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ker.score.classifier.cv(K, ind.pos, m = 5, p = 100, 
alpha = seq(from = 0.05, to = 0.6, by = 0.05), init.seed = 0, 
opt.fun = compute.F, fun = KNN.score, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ker.score.classifier.cv_+3A_k">K</code></td>
<td>
<p>matrix. Kernel matrix or any valid symmetric matrix</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the positive examples. They are the row indices  of RW corresponding to positive examples.</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_m">m</code></td>
<td>
<p>number of folds for each cross-validation</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_p">p</code></td>
<td>
<p>number of repeated cross-validations</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_alpha">alpha</code></td>
<td>
<p>vector of the quantiles to be tested</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_init.seed">init.seed</code></td>
<td>
<p>initial seed for the random generator (def: 0)</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_opt.fun">opt.fun</code></td>
<td>
<p>: function. Function implementing the metric to choice the optimal threshold.
The F-score (compute.F) is the default. Available functions:
</p>
<p>- compute.F: F-score (default) 
</p>
<p>- compute.acc: accuracy.  
</p>
<p>Any function having two arguments representing the vector of predicted and true labels can be in principle used.
</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_fun">fun</code></td>
<td>
<p>function. It must be a kernel-based score method (default KNN.score)</p>
</td></tr>
<tr><td><code id="ker.score.classifier.cv_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function to classify labels according to an external cross-validation procedure with a kernel-based score method. The optimal
threshold for a given class id found by internal cross-validation.
Scores are computed by averaging across (possibly) multiple external cross-validations.
The optimal quantile and corresponding threshold  are selected by internal cross-validation using the F-score (default) or the accuracy as metric.
</p>


<h3>Value</h3>

<p>A list with 4 components:
</p>
<table>
<tr><td><code>labels</code></td>
<td>
<p>vector of the predicted labels (1 represents positive, 0 negative)</p>
</td></tr>
<tr><td><code>av.scores</code></td>
<td>
<p>a vector with the average scores across multiple cross-validations.
Elements of the vector av.scores correspond to the rows of RW</p>
</td></tr>
<tr><td><code>opt.alpha</code></td>
<td>
<p>the optimal quantile alpha</p>
</td></tr>
<tr><td><code>opt.thresh</code></td>
<td>
<p>the optimal threshold</p>
</td></tr>
</table>
<p>a vector of the predicted scores for the test set
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rw.kernel-methods">rw.kernel-methods</a></code>, <code><a href="#topic+Kernel+20functions">Kernel functions</a></code>, <code><a href="#topic+ker.score.classifier.holdout">ker.score.classifier.holdout</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nodel label classification of the DrugBank category Penicillins
# on the Tanimoto chemical structure similarity network (1253 drugs)
# using 5 fold cross-validation repeated 3 times 
# and NN-score with 1-step random walk kernel
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
K &lt;- rw.kernel(DD.chem.data);
res &lt;- ker.score.classifier.cv(K, ind.pos, m = 5, p = 3, fun = NN.score);
</code></pre>

<hr>
<h2 id='ker.score.classifier.holdout'>
RANKS held-out procedure for a single class
</h2><span id='topic+ker.score.classifier.holdout'></span><span id='topic+ker.score.holdout'></span>

<h3>Description</h3>

<p>Functions to perform an held-out procedure for a single class with a kernel-based score method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ker.score.classifier.holdout(K, ind.pos, ind.test, m = 5, p = 10, 
alpha = seq(from = 0.05, to = 0.6, by = 0.05), init.seed = 0, 
opt.fun = compute.F, fun = KNN.score, ...)
ker.score.holdout (K, ind.pos, ind.test, fun=KNN.score, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ker.score.classifier.holdout_+3A_k">K</code></td>
<td>
<p>matrix. Kernel matrix or any valid symmetric matrix</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the positive examples of the training set. They are the indices the row of RW corresponding to
positive examples of the training set</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_ind.test">ind.test</code></td>
<td>
<p>indices of the examples of the test set. They are the indices the row of RW corresponding to
examples of the test set</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_m">m</code></td>
<td>
<p>number of folds for the cross-validation on the training set</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_p">p</code></td>
<td>
<p>number of repeated  cross-validations on the training set</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_alpha">alpha</code></td>
<td>
<p>vector of the quantiles to be tested</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_init.seed">init.seed</code></td>
<td>
<p>nitial seed for the random generator (def: 0)</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_opt.fun">opt.fun</code></td>
<td>
<p>Function implementing the metric to select the optimal threshold.
The F-score (compute.F) is the default. Available functions:
</p>
<p>- compute.F: F-score (default) 
</p>
<p>- compute.acc:accuracy.  
</p>
<p>Any function having two arguments representing the vector of predicted and true labels can be in principle used.
</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_fun">fun</code></td>
<td>
<p>function. It must be a kernel-based score method (default KNN.score)</p>
</td></tr>
<tr><td><code id="ker.score.classifier.holdout_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ker.score.classifier.holdout</code> is a function to classify labels according to an hold-out procedure with a kernel-based score method.
The optimal threshold for a given class is obtained by (possibly multiple) internal cross-validation on the training set.
Scores of the held-out nodes are computed. Thresholds are computed on the training set
by cross-validation and then are used to classify the held-out nodes in the test set.
The optimal quantile and corresponding threshold  are selected by internal cross-validation using the F-score as metrics.
Note the test examples are given as indices of the rows of the input matrix.
</p>
<p><code>ker.score.holdout</code> provides a ranking according to an hold-out procedure with a kernel-based score method.
</p>


<h3>Value</h3>

<p><code>ker.score.classifier.holdout</code>
returns a list with four components:
A list with 4 components:
</p>
<table>
<tr><td><code>labels</code></td>
<td>
<p>vector of the predicted labels for the test set(1 represent positive, 0 negative)</p>
</td></tr>
<tr><td><code>av.scores</code></td>
<td>
<p>a vector with the  scores computed on the test set.
Elements of the vector av.scores correspond to ind.test rows of RW</p>
</td></tr>
<tr><td><code>opt.alpha</code></td>
<td>
<p>the optimal quantile alpha</p>
</td></tr>
<tr><td><code>opt.thresh</code></td>
<td>
<p>the optimal threshold</p>
</td></tr>
</table>
<p><code>ker.score.holdout</code>
returns a vector of the predicted scores for the test set
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rw.kernel-methods">rw.kernel-methods</a></code>, <code><a href="#topic+Kernel+20functions">Kernel functions</a></code>, <code><a href="#topic+ker.score.classifier.cv">ker.score.classifier.cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Node label classification of the DrugBank category Penicillins
# on the Tanimoto chemical structure similarity network (1253 drugs)
# with eav-score with 1-step random walk kernel
# using held-out with 5-fold CV repeated 10 times on the training set 
# to set the "optimal" threshold for classifiaction
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.test &lt;- 1:300;
ind.train &lt;- 301:length(labels);
ind.pos &lt;- which(labels==1);
ind.pos &lt;- ind.pos[ind.pos&gt;300];
K &lt;- rw.kernel(DD.chem.data);
res &lt;- ker.score.classifier.holdout(K, ind.pos, ind.test, m = 5, p = 10, fun = eav.score);
</code></pre>

<hr>
<h2 id='ker.score.cv'>
RANKS cross-validation for a single class
</h2><span id='topic+ker.score.cv'></span>

<h3>Description</h3>

<p>Function to perform cross-validation for a single class with a kernel-based score method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ker.score.cv(RW, ind.pos, m = 5, init.seed = NULL, fun = KNN.score, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ker.score.cv_+3A_rw">RW</code></td>
<td>
<p>matrix. It can be a kernel matrix or the adjacency matrix of a graph</p>
</td></tr>
<tr><td><code id="ker.score.cv_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the positive examples. They are the row indices  of RW corresponding to positive examples.</p>
</td></tr>
<tr><td><code id="ker.score.cv_+3A_m">m</code></td>
<td>
<p>number of folds (def: 5)</p>
</td></tr>
<tr><td><code id="ker.score.cv_+3A_init.seed">init.seed</code></td>
<td>
<p>initial seed for the random generator to generate folds. If NULL (default) no initialization is performed</p>
</td></tr>
<tr><td><code id="ker.score.cv_+3A_fun">fun</code></td>
<td>
<p>function. It must be a kernel-based score method (default KNN.score)</p>
</td></tr>
<tr><td><code id="ker.score.cv_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It performs a cross-validation using RANKS to predict the cross-validated scores. The cross-validation is stratified: 
the folds are constructed separately for each class, to maintain an equal ratio between classes among folds.
</p>


<h3>Value</h3>

<p>a numeric vector with the scores computed for each example
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multiple.ker.score.cv">multiple.ker.score.cv</a></code>, <code><a href="#topic+multiple.ker.score.thresh.cv">multiple.ker.score.thresh.cv</a></code>, <code><a href="#topic+rw.kernel-methods">rw.kernel-methods</a></code>, <code><a href="#topic+Kernel+20functions">Kernel functions</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nodel label ranking of the DrugBank category Penicillins
# on the Tanimoto chemical structure similarity network (1253 drugs)
# using 5 fold cross-validation
# and eav-score with 1-step random walk kernel
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
K &lt;- rw.kernel(DD.chem.data);
res &lt;- ker.score.cv(K, ind.pos, m = 5, init.seed = NULL, fun = eav.score);
</code></pre>

<hr>
<h2 id='kernel.functions'>
Kernel functions
</h2><span id='topic+Kernel+20functions'></span><span id='topic+cauchy.kernel'></span><span id='topic+laplacian.kernel'></span><span id='topic+gaussian.kernel'></span><span id='topic+inv.multiquadric.kernel'></span><span id='topic+identity.kernel'></span><span id='topic+linear.kernel'></span><span id='topic+poly.kernel'></span>

<h3>Description</h3>

<p>Compute similarities between feature vectors according to a specific kernel function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cauchy.kernel(W, sigma = 1)
laplacian.kernel(W, sigma = 1)
gaussian.kernel(W, sigma = 1)
inv.multiquadric.kernel(W, v = 1)
identity.kernel(W, a = 1)
linear.kernel(W, a = 1)
poly.kernel(W, degree = 2, scale = -1, v = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernel.functions_+3A_w">W</code></td>
<td>

<p>a numeric matrix, Rows are examples and columns are features
</p>
</td></tr>
<tr><td><code id="kernel.functions_+3A_sigma">sigma</code></td>
<td>

<p>a real value representing the sigma parameter (def. 1) of the Cauchy, Gaussian and Laplacian kernel
</p>
</td></tr>
<tr><td><code id="kernel.functions_+3A_v">v</code></td>
<td>

<p>constant factor (def. 1) of the inverse multiquadric kernel and of the polynomail kernel; for the inverse multiquadric kernel v must be larger than 0.
</p>
</td></tr>
<tr><td><code id="kernel.functions_+3A_a">a</code></td>
<td>

<p>unused parameter, maintained for compatibility reasons .
</p>
</td></tr>
<tr><td><code id="kernel.functions_+3A_degree">degree</code></td>
<td>

<p>integer corresponding to a degree of the polynomial (def. 2)
</p>
</td></tr>
<tr><td><code id="kernel.functions_+3A_scale">scale</code></td>
<td>

<p>double: scaling factor of the polynomial kernel. If <code class="reqn">scale=-1</code> (def) scale is set to <code class="reqn">1/ncol(W)</code>;
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All the kernel matrices are computed by calling C code to speed-up the computation.
</p>
<p><code>cauchy.kernel</code> computes the Cauchy kernel.
</p>
<p><code>laplacian.kernel</code> computes the Lapalacian kernel.
</p>
<p><code>gaussian.kernel</code> computes the Gaussian kernel.
</p>
<p><code>inv.multiquadric.kernel</code> computes the inverse multiquadric kernel.
</p>
<p><code>identity.kernel</code> computes the identity kernel. In this case the input W  represents a similarity square matrix (obtained i.e. through the Pearson correlation) between examples.
</p>
<p><code>linear.kernel</code> computes the linear kernel.
</p>


<h3>Value</h3>

<p>A kernel matrix representing the similarities between the examples (rows of W), according to a specific kernel function. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rw.kernel-methods">rw.kernel-methods</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># computing kernels on the Tanimoto chemical structure similarity matrix
library(bionetdata);
data(DD.chem.data);
K &lt;- identity.kernel(DD.chem.data);
K &lt;- linear.kernel(DD.chem.data);

K &lt;- gaussian.kernel(DD.chem.data);
K &lt;- inv.multiquadric.kernel(DD.chem.data);
K &lt;- poly.kernel(DD.chem.data);

</code></pre>

<hr>
<h2 id='label.prop'>
Label propagation
</h2><span id='topic+label.prop'></span>

<h3>Description</h3>

<p>Function that implements the Label propagation algorithm of Zhu and Ghahramani
</p>


<h3>Usage</h3>

<pre><code class='language-R'>label.prop(W, ind.positives, tmax = 1000, eps = 1e-05, norm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="label.prop_+3A_w">W</code></td>
<td>
<p>a numeric matrix representing the adjacency matrix of the graph</p>
</td></tr>
<tr><td><code id="label.prop_+3A_ind.positives">ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph.
They represent the indices of W corresponding to the positive examples</p>
</td></tr>
<tr><td><code id="label.prop_+3A_tmax">tmax</code></td>
<td>
<p>maximum number of iterations (def: 1000)</p>
</td></tr>
<tr><td><code id="label.prop_+3A_eps">eps</code></td>
<td>
<p>numeric. Maximum allowed difference between the computed probabilities at the steady state (def. 1e-5)</p>
</td></tr>
<tr><td><code id="label.prop_+3A_norm">norm</code></td>
<td>
<p>boolean. If TRUE (def) the adjacency matrix <code class="reqn">W</code> of the graph is normalized to <code class="reqn">M = D^{-1} * W</code>, otherwise
it is assumed that the matrix <code class="reqn">W</code> is just normalized</p>
</td></tr>
</table>


<h3>Details</h3>

<p>label.prop implements the label propagation algorithm on a given graph by performing 1 or more steps on the graph, depending on the value of the tmax parameter. It stops also if the difference of the norm of the scores between two consecutive steps is less than eps.
</p>


<h3>Value</h3>

<p>A list with three elements:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>numeric vector. Scores of each node at the steady state or after tmax iterations</p>
</td></tr>
<tr><td><code>ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph (it is equal to the same input parameter)</p>
</td></tr>
<tr><td><code>n.iter</code></td>
<td>
<p>number of performed steps/iterations</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhu, X., Ghahramani, Z., Lafferty, J.: Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions. In: Proc. of the Twentieth International Conference on Machine Learning, Washington DC (2003) 912-919
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Application of label prop algorithm to the prediction of the DrugBank category Penicillins
# using the Tanimoto chemical structure similarity network 
# between 1253 DrugBank drugs
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
label.prop(DD.chem.data, ind.pos, tmax = 10, eps = 1e-05, norm = TRUE);
</code></pre>

<hr>
<h2 id='multiple.ker.score.cv'>
RANKS multiple cross-validation for a single class 
</h2><span id='topic+multiple.ker.score.cv'></span>

<h3>Description</h3>

<p>Function to execute multiple cross-validation with RANKS for a single class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiple.ker.score.cv(RW, ind.pos, m = 5, p = 100, stratified=TRUE, 
                      init.seed = 0, fun = KNN.score, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiple.ker.score.cv_+3A_rw">RW</code></td>
<td>
<p>matrix. Kernel matrix or any valid symmetric matrix</p>
</td></tr>
<tr><td><code id="multiple.ker.score.cv_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the positive examples. They are the row indices  of RW corresponding to positive examples.</p>
</td></tr>
<tr><td><code id="multiple.ker.score.cv_+3A_m">m</code></td>
<td>
<p>number of folds for each cross-validation</p>
</td></tr>
<tr><td><code id="multiple.ker.score.cv_+3A_p">p</code></td>
<td>
<p>number of repeated cross-validations</p>
</td></tr>
<tr><td><code id="multiple.ker.score.cv_+3A_stratified">stratified</code></td>
<td>
<p>boolean. If TRUE (def.) stratified CV is performed otherwise vanilla CV is done</p>
</td></tr>
<tr><td><code id="multiple.ker.score.cv_+3A_init.seed">init.seed</code></td>
<td>
<p>initial seed for the random generator (def: 0)</p>
</td></tr>
<tr><td><code id="multiple.ker.score.cv_+3A_fun">fun</code></td>
<td>
<p>function. It must be a kernel-based score method (default KNN.score)</p>
</td></tr>
<tr><td><code id="multiple.ker.score.cv_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It performs multiple cross-validation using RANKS to predict the cross-validated scores. The cross-validation is stratified: 
the folds are constructed separately for each class, to maintain an equal ratio between classes among folds.
It computes the scores by averaging across multiple cross validations.
</p>


<h3>Value</h3>

<p>A list with two components:
</p>
<table>
<tr><td><code>av.scores</code></td>
<td>
<p>a vector with the average scores across multiple cross-validations.
Elements of the vector av.scores correspond to the rows of RW</p>
</td></tr>
<tr><td><code>pos.scores</code></td>
<td>
<p>a vector with the scores of positive elements collected at each iteration</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ker.score.cv">ker.score.cv</a></code>, <code><a href="#topic+multiple.ker.score.thresh.cv">multiple.ker.score.thresh.cv</a></code>, <code><a href="#topic+rw.kernel-methods">rw.kernel-methods</a></code>, <code><a href="#topic+Kernel+20functions">Kernel functions</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nodel label ranking for the DrugBank category Penicillins
# on the Tanimoto chemical structure similarity network (1253 drugs)
# using 5 fold cross-validation repeated 10 times
# and eav-score with 1-step random walk kernel
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
K &lt;- rw.kernel(DD.chem.data);
res &lt;- multiple.ker.score.cv(K, ind.pos, m = 5, p = 10, init.seed = 0, fun = eav.score);
# the same but using the NN-score
res &lt;- multiple.ker.score.cv(K, ind.pos, m = 5, p = 10, init.seed = 0, fun = NN.score);
</code></pre>

<hr>
<h2 id='multiple.ker.score.thresh.cv'>
Function for RANKS multiple cross-validation and optimal threshold finding for a single class
</h2><span id='topic+multiple.ker.score.thresh.cv'></span>

<h3>Description</h3>

<p>Function to execute multiple cross-validation and to find the optimal threshold with RANKS for a single class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiple.ker.score.thresh.cv(K, ind.pos, m = 5, p = 100, 
alpha = seq(from = 0.05, to = 0.6, by = 0.05), 
init.seed = 0, fun = KNN.score, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_k">K</code></td>
<td>
<p>matrix. Kernel matrix or any valid symmetric matrix</p>
</td></tr>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the positive examples. They are the row indices  of RW corresponding to positive examples.</p>
</td></tr>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_m">m</code></td>
<td>
<p>number of folds for each cross-validation</p>
</td></tr>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_p">p</code></td>
<td>
<p>number of repeated cross-validations</p>
</td></tr>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_alpha">alpha</code></td>
<td>
<p>vector of the quantiles to be tested</p>
</td></tr>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_init.seed">init.seed</code></td>
<td>
<p>initial seed for the random generator (def: 0)</p>
</td></tr>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_fun">fun</code></td>
<td>
<p>function. It must be a kernel-based score method  (default KNN.score)</p>
</td></tr>
<tr><td><code id="multiple.ker.score.thresh.cv_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function to execute multiple cross-validation with a kernel-based score method and to find the optimal
threshold for a given class by internal cross-validation.
</p>
<p>Scores are computed by averaging across multiple external cross-validations.
The optimal quantile and corresponding threshold  are selected by internal cross-validation using a
specific metric (def: F-score).
</p>


<h3>Value</h3>

<p>A list with three components:
</p>
<table>
<tr><td><code>av.scores</code></td>
<td>
<p>a vector with the average scores across multiple cross-validations.
Elements of the vector av.scores correspond to the rows of RW</p>
</td></tr>
<tr><td><code>opt.alpha</code></td>
<td>
<p>the optimal quantile alpha</p>
</td></tr>
<tr><td><code>opt.thresh</code></td>
<td>
<p>the optimal threshold</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ker.score.cv">ker.score.cv</a></code>, <code><a href="#topic+multiple.ker.score.cv">multiple.ker.score.cv</a></code>, <code><a href="#topic+rw.kernel-methods">rw.kernel-methods</a></code>, <code><a href="#topic+Kernel+20functions">Kernel functions</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Node label ranking and best threshold search for the DrugBank category Penicillins
# on the Tanimoto chemical structure similarity network (1253 drugs)
# using 5 fold cross-validation repeated 2 times
# and eav-score with 1-step random walk kernel
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
K &lt;- rw.kernel(DD.chem.data);
res &lt;- multiple.ker.score.thresh.cv (K, ind.pos, m = 5, p = 2, init.seed = 0, fun = KNN.score);
</code></pre>

<hr>
<h2 id='multiple.RW.cv'>
Random walk, GBA and labelprop multiple cross-validation for a single class
</h2><span id='topic+multiple.RW.cv'></span>

<h3>Description</h3>

<p>Function to execute multiple cross-validation with random walk based, labelprop and GBA methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiple.RW.cv(W, ind.pos, k = 5, p = 100, init.seed = 0, fun = RW, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiple.RW.cv_+3A_w">W</code></td>
<td>
<p>a numeric matrix representing the adjacency matrix of the graph.
Note that if the optional argument norm=TRUE (def.), the W matrix is normalized, otherwise it
is assumed that W is just normalized</p>
</td></tr>
<tr><td><code id="multiple.RW.cv_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph. They represent the indices of W corresponding to the positive examples</p>
</td></tr>
<tr><td><code id="multiple.RW.cv_+3A_k">k</code></td>
<td>
<p>number of folds (def: 5)</p>
</td></tr>
<tr><td><code id="multiple.RW.cv_+3A_p">p</code></td>
<td>
<p>number of repeated cross-validations</p>
</td></tr>
<tr><td><code id="multiple.RW.cv_+3A_init.seed">init.seed</code></td>
<td>
<p>initial seed for the random generator. If 0 (default) no initialization is performed</p>
</td></tr>
<tr><td><code id="multiple.RW.cv_+3A_fun">fun</code></td>
<td>
<p>function. It must be one of the following functions:
</p>
<p>- RW (default)
</p>
<p>- RWR
</p>
<p>- label.prop
</p>
<p>- GBAsum
</p>
<p>- GBAmax
</p>
</td></tr>
<tr><td><code id="multiple.RW.cv_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun:
</p>
<p>- gamma : restart parameter (def: 0.6) (meaningful only for RWR)
</p>
<p>- tmax : maximum number of iterations (def: 1000)
</p>
<p>- eps : maximum allowed difference between the computed probabilities at the steady state (def. 1e-10)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function to execute multiple cross-validation with random walk based, labelprop and GBA methods for a single class.
It computes the scores by averaging across multiple cross validations.
It can be used with of the following methods: RW, RWR, label.prop, GBAsum, GBAmax.
</p>


<h3>Value</h3>

<p>a vector with the the probabilities for each example at the steady state averaged across multiple cross-validations
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RW">RW</a></code>, <code><a href="#topic+RWR">RWR</a></code>, <code><a href="#topic+label.prop">label.prop</a></code>, <code><a href="#topic+GBAsum">GBAsum</a></code>, <code><a href="#topic+GBAmax">GBAmax</a></code>,  <code><a href="#topic+RW.cv">RW.cv</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nodel label ranking of the DrugBank category Penicillins
# on the Tanimoto chemical structure similarity network (1253 drugs)
# using 5 fold cross-validation repeated 2 times
# and "vanilla" 2-step random walk
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);

res &lt;- multiple.RW.cv(DD.chem.data, ind.pos, k = 5, p = 2, init.seed = 0, fun = GBAmax)


# the same but using the label.prop
res &lt;- multiple.RW.cv(DD.chem.data, ind.pos, k = 5, p = 2, init.seed = 0, fun = label.prop, tmax=2)

# the same but using "vanilla" 2-step random walk
res &lt;- multiple.RW.cv(DD.chem.data, ind.pos, k = 5, p = 2, init.seed = 0, fun = RW, tmax=2)


</code></pre>

<hr>
<h2 id='RW'>
Random walk on a graph
</h2><span id='topic+RW'></span>

<h3>Description</h3>

<p>The function performs a random Walk on a given graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RW(W, ind.positives, tmax = 1000, eps = 1e-10, norm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RW_+3A_w">W</code></td>
<td>
<p>a numeric matrix representing the adjacency matrix of the graph</p>
</td></tr>
<tr><td><code id="RW_+3A_ind.positives">ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph.
They represent the indices of W corresponding to the positive examples</p>
</td></tr>
<tr><td><code id="RW_+3A_tmax">tmax</code></td>
<td>
<p>maximum number of iterations (steps) (def: 1000)</p>
</td></tr>
<tr><td><code id="RW_+3A_eps">eps</code></td>
<td>
<p>maximum allowed difference between the computed probabilities at the steady state (def. 1e-10)</p>
</td></tr>
<tr><td><code id="RW_+3A_norm">norm</code></td>
<td>
<p>if TRUE (def) the adjacency matrix <code class="reqn">W</code> of the graph is normalized to <code class="reqn">M = D^{-1} * W</code>, otherwise
it is assumed that the matrix <code class="reqn">W</code> is just normalized</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RW performs a random Walk on a given graph by performing 1 or more steps on the graph, depending on the value of the tmax parameter.
It stops also if the difference of the norm of the probabilities between two consecutive steps is less than eps.
</p>


<h3>Value</h3>

<p>A list with three elements:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>numeric vector. Probability of each node at the steady state or after tmax iterations</p>
</td></tr>
<tr><td><code>ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph (it is equal to the same input parameter)</p>
</td></tr>
<tr><td><code>n.iter</code></td>
<td>
<p>number of performed steps/iterations</p>
</td></tr>
</table>


<h3>References</h3>

<p>L. Lovasz, Random Walks on Graphs: a Survey, Combinatorics, Paul Erdos is Eighty, vol. 2, pp. 146, 1993.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RWR">RWR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Application of the random walk to the prediction of the DrugBank category Penicillins
# using the Tanimoto chemical structure similarity network 
# between 1253 DrugBank drugs
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
# 2-step random walk
res &lt;- RW(DD.chem.data, ind.pos, tmax = 2);

# 5 steps random walk
res &lt;- RW(DD.chem.data, ind.pos, tmax = 5);

</code></pre>

<hr>
<h2 id='RW.cv'>
Random walk, GBA and labelprop cross-validation for a single class
</h2><span id='topic+RW.cv'></span>

<h3>Description</h3>

<p>Function to execute cross-validation with random walk based, labelprop and GBA methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RW.cv(W, ind.pos, k = 5, stratified=TRUE, init.seed = 0, fun = RW, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RW.cv_+3A_w">W</code></td>
<td>
<p>a numeric matrix representing the adjacency matrix of the graph.
Note that if the optional argument norm=TRUE (def.), the W matrix is normalized, otherwise it
is assumed that W is just normalized</p>
</td></tr>
<tr><td><code id="RW.cv_+3A_ind.pos">ind.pos</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph. They represent the indices of W corresponding to the positive examples</p>
</td></tr>
<tr><td><code id="RW.cv_+3A_k">k</code></td>
<td>
<p>number of folds (def: 5)</p>
</td></tr>
<tr><td><code id="RW.cv_+3A_stratified">stratified</code></td>
<td>
<p>boolean. If TRUE (def.) stratified CV is performed otherwise vanilla CV is done</p>
</td></tr>
<tr><td><code id="RW.cv_+3A_init.seed">init.seed</code></td>
<td>
<p>initial seed for the random generator. If 0 (default) no initialization is performed</p>
</td></tr>
<tr><td><code id="RW.cv_+3A_fun">fun</code></td>
<td>
<p>function. It must be one of the following functions:
</p>
<p>- RW (default)
</p>
<p>- RWR
</p>
<p>- label.prop
</p>
<p>- GBAsum
</p>
<p>- GBAmax
</p>
</td></tr>
<tr><td><code id="RW.cv_+3A_...">...</code></td>
<td>
<p>optional arguments for the function fun:
</p>
<p>- gamma : restart parameter (def: 0.6) (meaningful only for RWR)
</p>
<p>- tmax : maximum number of iterations (def: 1000)
</p>
<p>- eps : maximum allowed difference between the computed probabilities at the steady state (def. 1e-10)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It performs a single cross-validation for a single class. It can be used with of the following methods: RW, RWR, label.prop, GBAsum, GBAmax.
</p>


<h3>Value</h3>

<p>a vector with the the probabilities for each example at the steady state
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RW">RW</a></code>, <code><a href="#topic+RWR">RWR</a></code>, <code><a href="#topic+label.prop">label.prop</a></code>, <code><a href="#topic+GBAsum">GBAsum</a></code>, <code><a href="#topic+GBAmax">GBAmax</a></code>,  <code><a href="#topic+multiple.RW.cv">multiple.RW.cv</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nodel label ranking of the DrugBank category Penicillins
# on the Tanimoto chemical structure similarity network (1253 drugs)
# using 5 fold cross-validation and GBAsum
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
res &lt;- RW.cv(DD.chem.data, ind.pos, k = 5, init.seed = 0, fun = GBAsum);


# the same but using label.prop
res &lt;- RW.cv(DD.chem.data, ind.pos, k = 5, init.seed = 0, fun = label.prop, tmax=2);

# the same but using "vanilla" 2-step random walk
res &lt;- RW.cv(DD.chem.data, ind.pos, k = 5, init.seed = 0, fun = RW, tmax=2);

</code></pre>

<hr>
<h2 id='rw.kernel-methods'> Random walk kernel</h2><span id='topic+rw.kernel-methods'></span><span id='topic+rw.kernel+2Cgraph-method'></span><span id='topic+rw.kernel+2Cmatrix-method'></span><span id='topic+p.step.rw.kernel-methods'></span><span id='topic+p.step.rw.kernel+2Cgraph-method'></span><span id='topic+p.step.rw.kernel+2Cmatrix-method'></span><span id='topic+rw.kernel'></span><span id='topic+p.step.rw.kernel'></span>

<h3>Description</h3>

<p>Methods to compute the random walk kernel (Smola and Kondor, 2003)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'matrix'
rw.kernel(W, a = 2)
## S4 method for signature 'graph'
rw.kernel(W, a = 2)
## S4 method for signature 'graph'
p.step.rw.kernel(RW, p = 2)
## S4 method for signature 'matrix'
p.step.rw.kernel(RW, p = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rw.kernel-methods_+3A_w">W</code></td>
<td>
<p>a square symmetric matrix with positive values or an object of the class graphAM  or graphNEL of the package graph</p>
</td></tr>
<tr><td><code id="rw.kernel-methods_+3A_rw">RW</code></td>
<td>
<p>matrix. It must be a random walk kernel matrix</p>
</td></tr>
<tr><td><code id="rw.kernel-methods_+3A_a">a</code></td>
<td>
<p>numeric. It is correlated to the probability of remaining at the same vertex. Larger a, larger the probability (def. 2)</p>
</td></tr>
<tr><td><code id="rw.kernel-methods_+3A_p">p</code></td>
<td>
<p> integer. Number of steps (def: p=2)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rw.kernel</code> methods computes the one step random walk kernel RW, i.e.:
</p>
<p style="text-align: center;"><code class="reqn">
RW = (a-1)I + D^{-\frac{1}{2}} * W * D^{-\frac{1}{2}}
</code>
</p>

<p>where <code class="reqn">I</code> is the identity matrix, <code class="reqn">W</code> is the weighted adjacency matrix of an undirected graph,
and  <code class="reqn">D</code> is a diagonal matrix with <code class="reqn">D_{ii} = \sum_j W_{ij}</code>
</p>
<p><code>p.step.rw.kernel</code> methods compute the p-step random walk kernel pRW, i.e.:
</p>
<p style="text-align: center;"><code class="reqn">
pRW = RW^p
</code>
</p>



<h3>Value</h3>

<p><code>rw.kernel</code>: A numeric square matrix representing a one-step random walk kernel matrix 
</p>
<p><code>p.step.rw.kernel</code>:  A numeric square matrix representing a p-step random walk kernel matrix
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(W = "graph")</code></dt><dd>
<p><code>rw.kernel</code> computes the random walk kernel starting from a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph) 
</p>
</dd>
<dt><code>signature(W = "matrix")</code></dt><dd>
<p><code>rw.kernel</code> computes the random walk kernel starting from a weighted adjacency matrix representing the graph
</p>
</dd>
<dt><code>signature(RW = "graph")</code></dt><dd>
<p><code>p.step.rw.kernel</code> computes the a p-step random walk kernel starting from a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph) 
</p>
</dd>
<dt><code>signature(RW = "matrix")</code></dt><dd>
<p><code>p.step.rw.kernel</code> computes the p-step random walk kernel starting from a one-step random walk kernel matrix
</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># Random walk kernel computation using Functional Interaction network data
library(bionetdata);
data(FIN.data);
W &lt;- as.matrix(FIN.data);
K &lt;- rw.kernel(W);
# this a 2-step random walk kernel

K2 &lt;- p.step.rw.kernel(K, p=2);
</code></pre>

<hr>
<h2 id='RWR'>
Random walk with Restart on a graph
</h2><span id='topic+RWR'></span>

<h3>Description</h3>

<p>Function that performs a random Walk with restart (RWR) on a given graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RWR(W, ind.positives, gamma = 0.6, tmax = 1000, eps = 1e-10, norm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RWR_+3A_w">W</code></td>
<td>
<p>a numeric matrix representing the adjacency matrix of the graph</p>
</td></tr>
<tr><td><code id="RWR_+3A_ind.positives">ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph.
They represent the indices of W corresponding to the positive examples</p>
</td></tr>
<tr><td><code id="RWR_+3A_gamma">gamma</code></td>
<td>
<p>restart parameter (def: 0.6)</p>
</td></tr>
<tr><td><code id="RWR_+3A_tmax">tmax</code></td>
<td>
<p>maximum number of iterations (steps) (def: 1000)</p>
</td></tr>
<tr><td><code id="RWR_+3A_eps">eps</code></td>
<td>
<p>maximum allowed difference between the computed probabilities at the steady state (def. 1e-10)</p>
</td></tr>
<tr><td><code id="RWR_+3A_norm">norm</code></td>
<td>
<p>if TRUE (def) the adjacency matrix <code class="reqn">W</code> of the graph is normalized to <code class="reqn">M = D^{-1} * W</code>, otherwise it is assumed that the matrix <code class="reqn">W</code> is just normalized</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RWR performs a random Walk with restart on a given graph by performing 1 or more steps on the graph, depending on the value of the tmax parameter.
The restart parameter expresses the probability of &quot;restarting&quot; from a &quot;core&quot; node at each step of the random walk algorithm.
It stops also if the difference of the norm of the probabilities between two consecutive steps is less than eps.
</p>


<h3>Value</h3>

<p>A list with three elements:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>numeric vector. Probability of each node at the steady state or after tmax iterations</p>
</td></tr>
<tr><td><code>ind.positives</code></td>
<td>
<p>indices of the &quot;core&quot; positive examples of the graph (it is equal to the same input parameter)</p>
</td></tr>
<tr><td><code>n.iter</code></td>
<td>
<p>number of performed steps/iterations</p>
</td></tr>
</table>


<h3>References</h3>

<p>L. Lovasz, Random Walks on Graphs: a Survey, Combinatorics, Paul Erdos is Eighty, vol. 2, pp. 146, 1993.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RW">RW</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Application of the random walk with restart to the prediction of the 
# DrugBank category Penicillins
# using the Tanimoto chemical structure similarity network 
# between 1253 DrugBank drugs
library(bionetdata);
data(DD.chem.data);
data(DrugBank.Cat);
labels &lt;- DrugBank.Cat[,"Penicillins"];
ind.pos &lt;- which(labels==1);
# 2-step RWR
res &lt;- RWR(DD.chem.data, ind.pos, tmax = 2);

# till to convergence
res &lt;- RWR(DD.chem.data, ind.pos, tmax = 5000, eps=1e-6);
# 5 steps and higher gamma
res &lt;- RWR(DD.chem.data, ind.pos, tmax = 5, gamma=0.8);

</code></pre>

<hr>
<h2 id='score.multiple.vertex-methods'>Multiple vertex score functions</h2><span id='topic+Methods+20for+20scoring+20multiple+20vertices'></span><span id='topic+NN.score-methods'></span><span id='topic+NN.score+2Cgraph-method'></span><span id='topic+NN.score+2Cmatrix-method'></span><span id='topic+KNN.score-methods'></span><span id='topic+KNN.score+2Cgraph-method'></span><span id='topic+KNN.score+2Cmatrix-method'></span><span id='topic+eav.score-methods'></span><span id='topic+eav.score+2Cgraph-method'></span><span id='topic+eav.score+2Cmatrix-method'></span><span id='topic+WSLD.score-methods'></span><span id='topic+WSLD.score+2Cgraph-method'></span><span id='topic+WSLD.score+2Cmatrix-method'></span><span id='topic+NN.score'></span><span id='topic+KNN.score'></span><span id='topic+eav.score'></span><span id='topic+WSLD.score'></span>

<h3>Description</h3>

<p>Methods to compute score functions for multiple vertices of the graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'graph'
NN.score(RW, x, x.pos, auto = FALSE, norm = TRUE)
## S4 method for signature 'matrix'
NN.score(RW, x, x.pos, auto = FALSE, norm = TRUE)
## S4 method for signature 'graph'
KNN.score(RW, x, x.pos, k = 3, auto = FALSE, norm = TRUE)
## S4 method for signature 'matrix'
KNN.score(RW, x, x.pos, k = 3, auto = FALSE, norm = TRUE)
## S4 method for signature 'graph'
eav.score(RW, x, x.pos, auto = FALSE, norm = TRUE)
## S4 method for signature 'matrix'
eav.score(RW, x, x.pos, auto = FALSE, norm = TRUE)
## S4 method for signature 'graph'
WSLD.score(RW, x, x.pos, d = 2, auto = FALSE, norm = TRUE)
## S4 method for signature 'matrix'
WSLD.score(RW, x, x.pos, d = 2, auto = FALSE, norm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.multiple.vertex-methods_+3A_rw">RW</code></td>
<td>
<p>matrix. It must be a kernel matrix or a symmetric matrix expressing the similarity between nodes</p>
</td></tr>
<tr><td><code id="score.multiple.vertex-methods_+3A_x">x</code></td>
<td>
<p>vector of integer. Indices corresponding to the elements of the RW matrix for which the score must be computed</p>
</td></tr>
<tr><td><code id="score.multiple.vertex-methods_+3A_x.pos">x.pos</code></td>
<td>
<p>vector of integer. Indices of the positive elements of the RW matrix</p>
</td></tr>
<tr><td><code id="score.multiple.vertex-methods_+3A_k">k</code></td>
<td>
<p>integer. Number of the k nearest neighbours to be considered</p>
</td></tr>
<tr><td><code id="score.multiple.vertex-methods_+3A_d">d</code></td>
<td>
<p>integer. Coefficient of linear decay (def. 2)</p>
</td></tr>
<tr><td><code id="score.multiple.vertex-methods_+3A_auto">auto</code></td>
<td>
<p>boolean. If TRUE the components <code class="reqn">K(x,x) + K(x_i,x_i)</code> are computed, otherwise are discarded (default)</p>
</td></tr>
<tr><td><code id="score.multiple.vertex-methods_+3A_norm">norm</code></td>
<td>
<p>boolean. If TRUE (def.) the scores are normalized between 0 and 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods compute the scores for multiple vertices according to NN, KNN, Empirical Average or WSLD score (see reference for bibliographic details).
Note that the argument x indicates the set of nodes for which the score must be computed. 
The vector x represents the indices of the rows of the matrix RW corresponding to the vertices for which the scores must be computed. 
If x = 1:nrow(RW) the scores for all the vertices of the graph are computed. 
</p>


<h3>Value</h3>

<p><code>NN.score</code>: a numeric vector with the NN scores of the vertices. The names of the vector correspond to the indices x
</p>
<p><code>KNN.score</code>:  a numeric vector with the KNN scores of the vertices. The names of the vector correspond to the indices x
</p>
<p><code>eav.score</code>: a numeric vector with the  Empirical Average score of the vertices. The names of the vector correspond to the indices x
</p>
<p><code>WSLD.score</code>: a numeric vector with the Weighted Sum with Linear Decay score (WSLD) of the vertices. The names of the vector correspond to the indices x
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(RW = "graph")</code></dt><dd>
<p><code>NN.score</code> computes the  NN score for multiple vertices using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>KNN.score</code> computes the  KNN score for multiple vertices using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>eav.score</code> computes the  Empirical Average score for multiple verticesusing a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>WSLD.score</code> computes the  Weighted Sum with Linear Decay score for multiple vertices using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
</dd>
<dt><code>signature(RW = "matrix")</code></dt><dd>
<p><code>NN.score</code> computes the  NN score for multiple vertices using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>KNN.score</code> computes the  KNN score for multiple vertices using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>eav.score</code> computes the  Empirical Average score multiple for vertices using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>WSLD.score</code> computes the  Weighted Sum with Linear Decay score for multiple vertices using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
</dd>
</dl>



<h3>References</h3>

<p>Re M, Mesiti M, Valentini G: A fast ranking algorithm for predicting gene functions in biomolecular networks.
IEEE ACM Trans Comput Biol Bioinform 2012, 9(6):1812-1818.
</p>
<p>Insuk Lee, Bindu Ambaru, Pranjali Thakkar, Edward M. Marcotte, and Seung Y. Rhee. Nature Biotechnology 28, 149-156, 2010
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Methods+20for+20scoring+20a+20single+20vertex">Methods for scoring a single vertex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Computation of scores using STRING data with respect to 
# the FunCat category 11.02.01 rRNA synthesis 
library(bionetdata);
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
labels &lt;- Yeast.STRING.FunCat[,"11.02.01"];
n &lt;- length(labels);
ind.pos &lt;- which(labels==1);
# NN-scores computed directly on the STRING matrix 
s &lt;- NN.score(Yeast.STRING.data, 1:n, ind.pos);

# NN-scores computed on the 1 step and 2-step random walk kernel matrix
K &lt;- rw.kernel(Yeast.STRING.data);
sK &lt;- NN.score(K, 1:n, ind.pos);
K2 &lt;- p.step.rw.kernel(K, p=2);
sK2 &lt;- NN.score(K2, 1:n, ind.pos);
# WSLD-scores computed directly on the STRING matrix 
s &lt;- WSLD.score(Yeast.STRING.data, 1:n, ind.pos);
# WSLD-scores computed on the 1 step and 2-step random walk kernel matrix
sK &lt;- WSLD.score(K, 1:n, ind.pos);
sK2 &lt;- WSLD.score(K2, 1:n, ind.pos);

</code></pre>

<hr>
<h2 id='score.single.vertex-methods'>Single vertex score functions</h2><span id='topic+Methods+20for+20scoring+20a+20single+20vertex'></span><span id='topic+single.NN.score-methods'></span><span id='topic+single.NN.score+2Cgraph-method'></span><span id='topic+single.NN.score+2Cmatrix-method'></span><span id='topic+single.KNN.score-methods'></span><span id='topic+single.KNN.score+2Cgraph-method'></span><span id='topic+single.KNN.score+2Cmatrix-method'></span><span id='topic+single.eav.score-methods'></span><span id='topic+single.eav.score+2Cgraph-method'></span><span id='topic+single.eav.score+2Cmatrix-method'></span><span id='topic+single.WSLD.score-methods'></span><span id='topic+single.WSLD.score+2Cgraph-method'></span><span id='topic+single.WSLD.score+2Cmatrix-method'></span><span id='topic+single.NN.score'></span><span id='topic+single.KNN.score'></span><span id='topic+single.eav.score'></span><span id='topic+single.WSLD.score'></span>

<h3>Description</h3>

<p>Methods to compute score functions applied to a single vertex of the graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'graph'
single.NN.score(RW, x, x.pos, auto = FALSE)
## S4 method for signature 'matrix'
single.NN.score(RW, x, x.pos, auto = FALSE)
## S4 method for signature 'graph'
single.KNN.score(RW, x, x.pos, k = 3, auto = FALSE)
## S4 method for signature 'matrix'
single.KNN.score(RW, x, x.pos, k = 3, auto = FALSE)
## S4 method for signature 'graph'
single.eav.score(RW, x, x.pos, auto = FALSE)
## S4 method for signature 'matrix'
single.eav.score(RW, x, x.pos, auto = FALSE)
## S4 method for signature 'graph'
single.WSLD.score(RW, x, x.pos, d = 2, auto = FALSE)
## S4 method for signature 'matrix'
single.WSLD.score(RW, x, x.pos, d = 2, auto = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.single.vertex-methods_+3A_rw">RW</code></td>
<td>
<p>matrix. It must be a kernel matrix or a symmetric matrix expressing the similarity between nodes</p>
</td></tr>
<tr><td><code id="score.single.vertex-methods_+3A_x">x</code></td>
<td>
<p>integer. Index corresponding to the element of the RW matrix for which the score must be computed</p>
</td></tr>
<tr><td><code id="score.single.vertex-methods_+3A_x.pos">x.pos</code></td>
<td>
<p>vector of integer. Indices of the positive elements of the RW matrix</p>
</td></tr>
<tr><td><code id="score.single.vertex-methods_+3A_k">k</code></td>
<td>
<p>integer. Number of the k nearest neighbours to be considered</p>
</td></tr>
<tr><td><code id="score.single.vertex-methods_+3A_d">d</code></td>
<td>
<p>integer. Coefficient of linear decay (def. 2)</p>
</td></tr>
<tr><td><code id="score.single.vertex-methods_+3A_auto">auto</code></td>
<td>
<p>boolean. If TRUE the components <code class="reqn">K(x,x) + K(x_i,x_i)</code> are computed, otherwise are discarded (default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>single.NN.score</code> computes the  NN score for a single vertex:
</p>
<p style="text-align: center;"><code class="reqn">score(x) = - \min_{x_i \in V_C} ( K(x,x) + K(x_i,x_i) -2 K(x,x_i))</code>
</p>

<p>where <code class="reqn">V_C</code> is the set of positive vertices.
</p>
<p><code>single.KNN.score</code> compute KNN score for a single vertex:
</p>
<p style="text-align: center;"><code class="reqn">score(x) = - \sum_{k \; nearest \; x_i \in V_C} ( K(x,x) + K(x_i,x_i) - 2 K(x,x_i))</code>
</p>

<p><code>single.eav.score</code> computes the Empirical Average score for a single vertex:
</p>
<p style="text-align: center;"><code class="reqn">score(x) = - K(x,x) + \frac{2}{|V_C|} * \sum_{x_i \in V_C} K(x,x_i)</code>
</p>

<p><code>single.WSLD.score</code> computes the  WSLD score for a single vertex:
</p>
<p>Let <code class="reqn">K(x, x_{jk})</code> be the kth rank order index w.r.t. <code class="reqn">x_j \in V_C</code>, and <code class="reqn">m=|V_C|</code>, then:
</p>
<p style="text-align: center;"><code class="reqn">score(x) = \max_{x_i \in V_C} K(x,x_i) + \sum_{k=2}^m [(1/(d * (k-1))) * K(x, x_{jk})]</code>
</p>



<h3>Value</h3>

<p><code>single.NN.score</code>: the NN score of the vertex
</p>
<p><code>single.KNN.score</code>:  the KNN score of the vertex
</p>
<p><code>single.eav.score</code>: the  Empirical Average score of the vertex
</p>
<p><code>single.WSLD.score</code>: the  Weighted Sum with Linear Decay score (WSLD) of the vertex
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(RW = "graph")</code></dt><dd>
<p><code>single.NN.score</code> computes the  NN score for a single vertex using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>single.KNN.score</code> computes the  KNN score for a single vertex using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>single.eav.score</code> computes the  Empirical Average score for a single vertex using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>single.WSLD.score</code> computes the  Weighted Sum with Linear Decay score for a single vertex using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
</dd>
<dt><code>signature(RW = "matrix")</code></dt><dd>
<p><code>single.NN.score</code> computes the  NN score for a single vertex using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>single.KNN.score</code> computes the  KNN score for a single vertex using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>single.eav.score</code> computes the  Empirical Average score using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>single.WSLD.score</code> computes the  Weighted Sum with Linear Decay score for a single vertex using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+Methods+20for+20scoring+20multiple+20vertices">Methods for scoring multiple vertices</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Computation of scores using STRING data with respect to 
# the FunCat category 11.02.01 rRNA synthesis 
library(bionetdata);
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
labels &lt;- Yeast.STRING.FunCat[,"11.02.01"];
n &lt;- length(labels);
ind.pos &lt;- which(labels==1);
# NN-score computed directly on the STRING matrix on the first yeast gene YJR121W
s &lt;- single.NN.score(Yeast.STRING.data, 1, ind.pos);

# NN-score computed on the 1 step and 2-step random walk kernel matrix
K &lt;- rw.kernel(Yeast.STRING.data);
sK &lt;- single.NN.score(K, 1, ind.pos);
K2 &lt;- p.step.rw.kernel(K, p=2);
sK2 &lt;- single.NN.score(K2, 1, ind.pos);

# WSLD-score computed directly on the STRING matrix on the first  yeast gene YJR121W
s &lt;- single.WSLD.score(Yeast.STRING.data, 1, ind.pos);
# WSLD-scores computed on the 1 step and 2-step random walk kernel matrix
sK &lt;- single.WSLD.score(K, 1, ind.pos);
sK2 &lt;- single.WSLD.score(K2, 1, ind.pos);

</code></pre>

<hr>
<h2 id='Utilities'>
Utility functions
</h2><span id='topic+compute.acc'></span><span id='topic+compute.F'></span><span id='topic+norm1'></span><span id='topic+Unit.sphere.norm'></span><span id='topic+do.stratified.cv.data'></span><span id='topic+do.cv.data'></span><span id='topic+labelsfromscores'></span><span id='topic+Multiple.labels.from.scores'></span><span id='topic+selection.test'></span>

<h3>Description</h3>

<p>Mixed utility functions to compute accuracy, norms, labels from scores and to perform stratified cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.acc(pred, labels)
compute.F(pred, labels)
norm1(x)
Unit.sphere.norm(K)
do.stratified.cv.data(examples, positives, k = 5, seed = NULL)
do.cv.data(examples, positives, k = 5, seed = NULL)
labelsfromscores(scores, thresh)
Multiple.labels.from.scores(S, thresh.vect)
selection.test(pos.scores, av.scores, ind.positives, alpha = 0.05, thresh.pos = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Utilities_+3A_pred">pred</code></td>
<td>
<p>vector of the predicted labels</p>
</td></tr>
<tr><td><code id="Utilities_+3A_labels">labels</code></td>
<td>
<p>vector of the true labels.
Note that 0  stands for negative and 1 for positive.
In general the first level is negative and the second positive</p>
</td></tr>
<tr><td><code id="Utilities_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="Utilities_+3A_k">K</code></td>
<td>
<p>a kernel matrix</p>
</td></tr>
<tr><td><code id="Utilities_+3A_examples">examples</code></td>
<td>
<p>indices of the examples (a vector of integer)</p>
</td></tr>
<tr><td><code id="Utilities_+3A_positives">positives</code></td>
<td>
<p>vector of integer. Indices of the positive examples. The indices refer to the indices of examples</p>
</td></tr>
<tr><td><code id="Utilities_+3A_k">k</code></td>
<td>
<p>number of folds (def = 5)</p>
</td></tr>
<tr><td><code id="Utilities_+3A_seed">seed</code></td>
<td>
<p>seed of the random generator (def=NULL). If is set to NULL no initiazitation is performed</p>
</td></tr>
<tr><td><code id="Utilities_+3A_scores">scores</code></td>
<td>
<p>numeric. Vector of scores: each element correspond to the score of an example</p>
</td></tr>
<tr><td><code id="Utilities_+3A_thresh">thresh</code></td>
<td>
<p>real value. Threshold for the classification</p>
</td></tr>
<tr><td><code id="Utilities_+3A_s">S</code></td>
<td>
<p>numeric matrix. Matrix of scores: rows represent examples, columns classes</p>
</td></tr>
<tr><td><code id="Utilities_+3A_thresh.vect">thresh.vect</code></td>
<td>
<p>numeric vector. Vector of the thresholds for multiple classes (one threshold for each class)</p>
</td></tr>
<tr><td><code id="Utilities_+3A_pos.scores">pos.scores</code></td>
<td>
<p>vector with scores of positive examples. It is returned from multiple.ker.score.cv.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_av.scores">av.scores</code></td>
<td>
<p>a vector with the average scores computed by multiple.ker.score.cv. It may be a named vector. 
If not, the names attributes corresponding to the indices of the vector are added.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_ind.positives">ind.positives</code></td>
<td>
<p>indices of the positive examples. They are the indices of av.scores corresponding to positive examples.</p>
</td></tr>
<tr><td><code id="Utilities_+3A_alpha">alpha</code></td>
<td>
<p>quantile level (def. 0.05)</p>
</td></tr>
<tr><td><code id="Utilities_+3A_thresh.pos">thresh.pos</code></td>
<td>
<p>only values larger than thresh.pos are retained in pos.scores (def.: 0)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>compute.acc</code> computes  the accuracy for a single class
</p>
<p><code>compute.F</code> computes  the F-score for a single class
</p>
<p><code>norm1</code> computes the L1-norm of a numeric vector
</p>
<p><code>Unit.sphere.norm</code> normalize a kernel according to the unit sphere
</p>
<p><code>do.stratified.cv.data</code> generates data for the stratified cross-validation. In particular subdivides the indices that refer to the rows of the data matrix in different folds (separated for positive and negative examples)
</p>
<p><code>do.cv.data</code> generates data for the vanilla not stratified cross-validation.
</p>
<p><code>labelsfromscores</code> computes the labels of a single class from the corresponding scores
</p>
<p><code>Multiple.labels.from.scores</code> computes the labels of multiple classes from the corresponding scores
</p>
<p><code>selection.test</code> is a non parametric test to select the most significant unlabeled examples 
</p>


<h3>Value</h3>

<p><code>compute.acc</code> returns the accuracy
</p>
<p><code>compute.F</code> returns the F-score
</p>
<p><code>norm1</code> returns the L1-norm value
</p>
<p><code>Unit.sphere.norm</code> returns  the kernel normalized according to the unit sphere
</p>
<p><code>do.stratified.cv.data</code> returns a list with 2 two components:
</p>
<table>
<tr><td><code>fold.non.positives</code></td>
<td>
<p>a list with k components. Each component is a vector with the indices of the non positive elements of the fold</p>
</td></tr>
<tr><td><code>fold.positives</code></td>
<td>
<p>a list with k components. Each component is a vector with the indices of the positive elements of the fold</p>
</td></tr>
</table>
<p>Indices refer to row numbers of the data matrix
</p>
<p><code>do.cv.data</code> returns a list with 2 two components:
</p>
<table>
<tr><td><code>fold.non.positives</code></td>
<td>
<p>a list with k components. Each component is a vector with the indices of the non positive elements of the fold</p>
</td></tr>
<tr><td><code>fold.positives</code></td>
<td>
<p>a list with k components. Each component is a vector with the indices of the positive elements of the fold</p>
</td></tr>
</table>
<p>Indices refer to row numbers of the data matrix
</p>
<p><code>labelsfromscores</code> returns a numeric vector res with 0 or 1 values. The label res[i]=1 if scores[i]&gt;thresh, otherwise res[i]=0
</p>
<p><code>Multiple.labels.from.scores</code> returns a binary matrix with the labels of the predictions. Rows represent examples, columns classes. Element L[i,j] is the label of example i w.r.t. class j.  L[i,j]=1 if i belongs to j, 0 otherwise.
</p>
<p><code>selection.test</code> returns a list with 5 components:
</p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>a named vector with the components of av.scores selected by the test</p>
</td></tr>
<tr><td><code>selected.labeled</code></td>
<td>
<p>a named vector with the labeled components of av.scores selected by the test</p>
</td></tr>
<tr><td><code>selected.unlabeled</code></td>
<td>
<p>a named vector with the unlabeled components of av.scores selected by the test</p>
</td></tr>
<tr><td><code>thresh</code></td>
<td>
<p>the score threshold selected by the test</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>significance level (the same value of the input)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># L1-norm of a vector
norm1(rnorm(10));
# generation of 5 stratified folds;
do.stratified.cv.data(1:100, 1:10, k = 5, seed = NULL);
# generation of labels form scores.
labelsfromscores(runif(20), thresh=0.3);
</code></pre>

<hr>
<h2 id='weighted.score.multiple.vertex-methods'>Multiple vertex score functions - weighted version</h2><span id='topic+Methods+20for+20scoring+20multiple+20vertices+20-+20weighted+20version'></span><span id='topic+NN.w.score-methods'></span><span id='topic+NN.w.score+2Cgraph-method'></span><span id='topic+NN.w.score+2Cmatrix-method'></span><span id='topic+KNN.w.score-methods'></span><span id='topic+KNN.w.score+2Cgraph-method'></span><span id='topic+KNN.w.score+2Cmatrix-method'></span><span id='topic+eav.w.score-methods'></span><span id='topic+eav.w.score+2Cgraph-method'></span><span id='topic+eav.w.score+2Cmatrix-method'></span><span id='topic+NN.w.score'></span><span id='topic+KNN.w.score'></span><span id='topic+eav.w.score'></span>

<h3>Description</h3>

<p>Methods to compute weighted score functions for multiple vertices of the graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'graph'
NN.w.score(RW, x, x.pos, w, norm = TRUE)
## S4 method for signature 'matrix'
NN.w.score(RW, x, x.pos, w, norm = TRUE)
## S4 method for signature 'graph'
KNN.w.score(RW, x, x.pos, w, k = 3, norm = TRUE)
## S4 method for signature 'matrix'
KNN.w.score(RW, x, x.pos, w, k = 3, norm = TRUE)
## S4 method for signature 'graph'
eav.w.score(RW, x, x.pos, w, auto = FALSE, norm = TRUE)
## S4 method for signature 'matrix'
eav.w.score(RW, x, x.pos, w, auto = FALSE, norm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.score.multiple.vertex-methods_+3A_rw">RW</code></td>
<td>
<p>matrix. It must be a kernel matrix or a symmetric matrix expressing the similarity between nodes</p>
</td></tr>
<tr><td><code id="weighted.score.multiple.vertex-methods_+3A_x">x</code></td>
<td>
<p>vector of integer. Indices corresponding to the elements of the RW matrix for which the score must be computed</p>
</td></tr>
<tr><td><code id="weighted.score.multiple.vertex-methods_+3A_x.pos">x.pos</code></td>
<td>
<p>vector of integer. Indices of the positive elements of the RW matrix</p>
</td></tr>
<tr><td><code id="weighted.score.multiple.vertex-methods_+3A_k">k</code></td>
<td>
<p>integer. Number of the k nearest neighbours to be considered</p>
</td></tr>
<tr><td><code id="weighted.score.multiple.vertex-methods_+3A_w">w</code></td>
<td>
<p>vector of numeric. Its elements represent the initial likelihood that the nodes of the graph belong to the class under study. 
The elements of w correspond to the columns of RW and the length of w and the number of columns of RW must be equal.</p>
</td></tr>
<tr><td><code id="weighted.score.multiple.vertex-methods_+3A_auto">auto</code></td>
<td>
<p>boolean. If TRUE the components <code class="reqn">K(x,x) + K(x_i,x_i)</code> are computed, otherwise are discarded (default)</p>
</td></tr>
<tr><td><code id="weighted.score.multiple.vertex-methods_+3A_norm">norm</code></td>
<td>
<p>boolean. If TRUE (def.) the scores are normalized between 0 and 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods compute the weighted scores for multiple vertices according to the weighted version of NN, KNN, and Empirical Average  score.
Note that the argument x indicates the set of nodes for which the score must be computed. 
The vector x represents the indices of the rows of the matrix RW corresponding to the vertices for which the scores must be computed. 
If x = 1:nrow(RW) the scores for all the vertices of the graph are computed. 
</p>


<h3>Value</h3>

<p><code>NN.w.score</code>: a numeric vector with the weighted NN scores of the vertices. The names of the vector correspond to the indices x
</p>
<p><code>KNN.score</code>:  a numeric vector with the weighted KNN scores of the vertices. The names of the vector correspond to the indices x
</p>
<p><code>eav.score</code>: a numeric vector with the  weighted Empirical Average score of the vertices. The names of the vector correspond to the indices x
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(RW = "graph")</code></dt><dd>
<p><code>NN.w.score</code> computes the weighted NN score for multiple vertices using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>KNN.w.score</code> computes the  weighted KNN score for multiple vertices using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>eav.w.score</code> computes the  weighted Empirical Average score for multiple verticesusing a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
</dd>
<dt><code>signature(RW = "matrix")</code></dt><dd>
<p><code>NN.w.score</code> computes the  weighted NN score for multiple vertices using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>KNN.w.score</code> computes the  weighted KNN score for multiple vertices using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>eav.w.score</code> computes the  weighted Empirical Average score multiple for vertices using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
</dd>
</dl>



<h3>References</h3>

<p>Giorgio Valentini, Giuliano Armano, Marco Frasca, Jianyi Lin, Marco Mesiti, and Matteo Re 
RANKS: a flexible tool for node label ranking and classification in biological networks
Bioinformatics first published online June 2, 2016 doi:10.1093/bioinformatics/btw235 
</p>
<p>Re M, Mesiti M, Valentini G: A fast ranking algorithm for predicting gene functions in biomolecular networks.
IEEE ACM Trans Comput Biol Bioinform 2012, 9(6):1812-1818.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Methods+20for+20scoring+20a+20single+20vertex+20-+20weighted+20version">Methods for scoring a single vertex - weighted version</a></code>
<code><a href="#topic+Methods+20for+20scoring+20multiple+20vertices">Methods for scoring multiple vertices</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Computation of scores using STRING data with respect to 
# the FunCat category 11.02.01 rRNA synthesis 
library(bionetdata);
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
labels &lt;- Yeast.STRING.FunCat[,"11.02.01"];
n &lt;- length(labels);
ind.pos &lt;- which(labels==1);
# NN-scores computed directly on the STRING matrix 
s &lt;- NN.w.score(Yeast.STRING.data, 1:n, ind.pos, w=labels);
# Weighted NN-scores computed directly on the STRING matrix 
# using this time random weights for the value of positive nodes
w &lt;- runif(n);
s &lt;- NN.w.score(Yeast.STRING.data, 1:n, ind.pos, w=w);

# Weighted NN-scores computed on the 1 step and 2-step random walk kernel matrix
K &lt;- rw.kernel(Yeast.STRING.data);
sK &lt;- NN.w.score(K, 1:n, ind.pos, w);
K2 &lt;- p.step.rw.kernel(K, p=2);
sK2 &lt;- NN.w.score(K2, 1:n, ind.pos, w);

</code></pre>

<hr>
<h2 id='weighted.score.single.vertex-methods'>Single vertex score functions - weighted version</h2><span id='topic+Methods+20for+20scoring+20a+20single+20vertex+20-+20weighted+20version'></span><span id='topic+single.NN.w.score-methods'></span><span id='topic+single.NN.w.score+2Cgraph-method'></span><span id='topic+single.NN.w.score+2Cmatrix-method'></span><span id='topic+single.KNN.w.score-methods'></span><span id='topic+single.KNN.w.score+2Cgraph-method'></span><span id='topic+single.KNN.w.score+2Cmatrix-method'></span><span id='topic+single.eav.w.score-methods'></span><span id='topic+single.eav.w.score+2Cgraph-method'></span><span id='topic+single.eav.w.score+2Cmatrix-method'></span><span id='topic+single.NN.w.score'></span><span id='topic+single.KNN.w.score'></span><span id='topic+single.eav.w.score'></span>

<h3>Description</h3>

<p>Methods to compute weighted score functions applied to a single vertex of the graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'graph'
single.NN.w.score(RW, x, x.pos, w)
## S4 method for signature 'matrix'
single.NN.w.score(RW, x, x.pos, w)
## S4 method for signature 'graph'
single.KNN.w.score(RW, x, x.pos, w, k = 3)
## S4 method for signature 'matrix'
single.KNN.w.score(RW, x, x.pos, w, k = 3)
## S4 method for signature 'graph'
single.eav.w.score(RW, x, x.pos, w, auto = FALSE)
## S4 method for signature 'matrix'
single.eav.w.score(RW, x, x.pos, w, auto = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted.score.single.vertex-methods_+3A_rw">RW</code></td>
<td>
<p>matrix. It must be a kernel matrix or a symmetric matrix expressing the similarity between nodes</p>
</td></tr>
<tr><td><code id="weighted.score.single.vertex-methods_+3A_x">x</code></td>
<td>
<p>integer. Index corresponding to the element of the RW matrix for which the score must be computed</p>
</td></tr>
<tr><td><code id="weighted.score.single.vertex-methods_+3A_x.pos">x.pos</code></td>
<td>
<p>vector of integer. Indices of the positive elements of the RW matrix</p>
</td></tr>
<tr><td><code id="weighted.score.single.vertex-methods_+3A_w">w</code></td>
<td>
<p>vector of numeric. Its elements represent the initial likelihood that the nodes of the graph belong to the class under study. 
The elements of w correspond to the columns of RW and the length of w and the number of columns of RW must be equal.</p>
</td></tr>
<tr><td><code id="weighted.score.single.vertex-methods_+3A_k">k</code></td>
<td>
<p>integer. Number of the k nearest neighbours to be considered</p>
</td></tr>
<tr><td><code id="weighted.score.single.vertex-methods_+3A_auto">auto</code></td>
<td>
<p>boolean. If TRUE the components <code class="reqn">K(x,x) + K(x_i,x_i)</code> are computed, otherwise are discarded (default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>single.NN.w.score</code> computes the weighted NN score for a single vertex:
</p>
<p style="text-align: center;"><code class="reqn">score(x) = - \min_{x_i \in V_C} -2 K(x,x_i)) * w(x_i)</code>
</p>

<p>where <code class="reqn">V_C</code> is the set of positive vertices, and <code class="reqn">w(x_i)</code> is the weight associated to the node <code class="reqn">x_i</code>
</p>
<p><code>single.KNN.w.score</code> compute the weighted KNN score for a single vertex:
</p>
<p style="text-align: center;"><code class="reqn">score(x) = \sum_{k \; nearest \; x_i \in V_C}  2 K(x,x_i) * w(x_i)</code>
</p>

<p><code>single.eav.score</code> computes the weighted Empirical Average score for a single vertex:
</p>
<p style="text-align: center;"><code class="reqn">score(x) = - K(x,x) * w(x) + \frac{2}{(\sum_{x_i \in x.pos} w(x_i))} * \sum_{x_i \in x.pos} K(x,x_i) * w(x_i)</code>
</p>



<h3>Value</h3>

<p><code>single.NN.w.score</code>: the weighted NN score of the vertex
</p>
<p><code>single.KNN.w.score</code>:  the weighted KNN score of the vertex
</p>
<p><code>single.eav.w.score</code>: the  weighted Empirical Average score of the vertex
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(RW = "graph")</code></dt><dd>
<p><code>single.NN.w.score</code> computes the weighted NN score for a single vertex using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>single.KNN.w.score</code> computes the  weighted KNN score for a single vertex using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
<p><code>single.eav.w.score</code> computes the  weighted Empirical Average score for a single vertex using a graph of class graph 
(hence including objects of class graphAM  and graphNEL from the package graph)
</p>
</dd>
<dt><code>signature(RW = "matrix")</code></dt><dd>
<p><code>single.NN.w.score</code> computes the  weighted NN score for a single vertex using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>single.KNN.w.score</code> computes the  weighted KNN score for a single vertex using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
<p><code>single.eav.score</code> computes the weighted  Empirical Average score using a kernel matrix or a symmetric matrix expressing the similarity between nodes
</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+Methods+20for+20scoring+20a+20single+20vertex">Methods for scoring a single vertex</a></code>
<code><a href="#topic+Methods+20for+20scoring+20multiple+20vertices+20-+20weighted+20version">Methods for scoring multiple vertices - weighted version</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Computation of scores using STRING data with respect to 
# the FunCat category 11.02.01 rRNA synthesis 
library(bionetdata);
data(Yeast.STRING.data);
data(Yeast.STRING.FunCat);
labels &lt;- Yeast.STRING.FunCat[,"11.02.01"];
n &lt;- length(labels);
ind.pos &lt;- which(labels==1);
# NN-score  computed directly on the STRING matrix on the first yeast gene YJR121W
s &lt;- single.NN.w.score(Yeast.STRING.data, 1, ind.pos, w=labels);
# NN-score weighted computed directly on the STRING matrix on the first yeast gene YJR121W,
# using this time random weights for the value of positive nodes
w &lt;- runif(n);
s &lt;- single.NN.w.score(Yeast.STRING.data, 1, ind.pos, w=w);

# NN-score weighted computed on the 1 step and 2-step random walk kernel matrix
K &lt;- rw.kernel(Yeast.STRING.data);
sK &lt;- single.NN.w.score(K, 1, ind.pos, w);
K2 &lt;- p.step.rw.kernel(K, p=2);
sK2 &lt;- single.NN.w.score(K2, 1, ind.pos, w);

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
