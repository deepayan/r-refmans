<!DOCTYPE html><html><head><title>Help for package sparseGAM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sparseGAM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.grpreg.gamma'><p>Cross-validation for Group-regularized Gamma Regression</p></a></li>
<li><a href='#cv.grpreg.nb'><p>Cross-validation for Group-regularized Negative Binomial Regression</p></a></li>
<li><a href='#cv.SBGAM'><p>Cross-Validation for Sparse Bayesian Generalized Additive Model</p></a></li>
<li><a href='#cv.SFGAM'><p>Sparse Frequentist Generalized Additive Models</p></a></li>
<li><a href='#cv.SSGL'><p>Cross-Validation for Spike-and-Slab Group Lasso Regression</p></a></li>
<li><a href='#grpreg.gamma'><p>Group-regularized Gamma Regression</p></a></li>
<li><a href='#grpreg.nb'><p>Group-regularized Negative Binomial Regression</p></a></li>
<li><a href='#SBGAM'><p>Sparse Bayesian Generalized Additive Models</p></a></li>
<li><a href='#SFGAM'><p>Sparse Frequentist Generalized Additive Models</p></a></li>
<li><a href='#SSGL'><p>Spike-and-Slab Group Lasso Regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sparse Generalized Additive Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-05-29</td>
</tr>
<tr>
<td>Author:</td>
<td>Ray Bai</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ray Bai &lt;raybaistat@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits sparse frequentist GAMs (SF-GAM) for continuous and discrete responses in the exponential dispersion family with the group lasso, group smoothly clipped absolute deviation (SCAD), and group minimax concave (MCP) penalties &lt;<a href="https://doi.org/10.1007%2Fs11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>&gt;. Also fits sparse Bayesian generalized additive models (SB-GAM) with the spike-and-slab group lasso (SSGL) penalty of Bai et al. (2021) &lt;<a href="https://doi.org/10.1080%2F01621459.2020.1765784">doi:10.1080/01621459.2020.1765784</a>&gt;. B-spline basis functions are used to model the sparse additive functions. Stand-alone functions for group-regularized negative binomial regression, group-regularized gamma regression, and group-regularized regression in the exponential dispersion family with the SSGL penalty are also provided.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, splines, MASS, pracma, grpreg</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-29 07:20:57 UTC; rayba</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-31 10:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.grpreg.gamma'>Cross-validation for Group-regularized Gamma Regression</h2><span id='topic+cv.grpreg.gamma'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized gamma regression with a known shape parameter <code class="reqn">\nu</code> and the log link. For a description of group-regularized gamma regression, see the description for the <code>grpreg.gamma</code> function.
</p>
<p>Our implementation is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than <code class="reqn">\frac{K-1}{K} \times</code> sample size, where <code class="reqn">K</code> is the number of folds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.grpreg.gamma(y, X, groups, gamma.shape=1, penalty=c("gLASSO","gSCAD","gMCP"),
                nfolds=10, weights, taper, nlambda=100, lambda, max.iter=10000, 
                tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.grpreg.gamma_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the name of the factor level that the <code class="reqn">j</code>th covariate belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for the responses. Default is <code>gamma.shape=1</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, and <code>"gMCP"</code>. To implement cross-validation for gamma regression with the SSGL penalty, use the <code>cv.SSGL</code> function.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>nfolds=10</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_weights">weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_nlambda">nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.gamma_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*11), nrow=100)
n = dim(X)[1]
groups = c(1,1,1,2,2,2,3,3,4,5,5)
true.beta = c(-1,1,1,0,0,0,0,0,0,1.5,-1.5)

## Generate responses from gamma regression with known shape parameter 1
eta = crossprod(t(X), true.beta)
shape = 1
y = rgamma(n, rate=shape/exp(eta), shape=shape)

## 10-fold cross-validation for group-regularized gamma regression
## with the group LASSO penalty
gamma.cv = cv.grpreg.gamma(y, X, groups, penalty="gLASSO")

## Plot cross-validation curve
plot(gamma.cv$lambda, gamma.cv$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes mean CVE
gamma.cv$lambda.min
</code></pre>

<hr>
<h2 id='cv.grpreg.nb'>Cross-validation for Group-regularized Negative Binomial Regression</h2><span id='topic+cv.grpreg.nb'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized negative binomial regression with a known size parameter <code class="reqn">\alpha</code> and the log link. For a description of group-regularized negative binomial regression, see the description for the <code>grpreg.nb</code> function.
</p>
<p>Our implementation is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than <code class="reqn">\frac{K-1}{K} \times</code> sample size, where <code class="reqn">K</code> is the number of folds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.grpreg.nb(y, X, groups, nb.size=1, penalty=c("gLASSO","gSCAD","gMCP"),
            nfolds=10, weights, taper, nlambda=100, lambda, max.iter=10000, 
            tol=1e-4) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.grpreg.nb_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the name of the factor level that the <code class="reqn">j</code>th covariate belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses. Default is <code>nb.size=1</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, and <code>"gMCP"</code>. To implement cross-validation for negative binomoial regression with the SSGL penalty, use the <code>cv.SSGL</code> function.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>nfolds=10</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_weights">weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_nlambda">nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg.nb_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(1234)
X = matrix(runif(100*16), nrow=100)
n = dim(X)[1]
groups = c(1,1,1,2,2,2,2,3,4,5,5,6,7,8,8,8)
true.beta = c(-2,2,2,0,0,0,0,0,0,1.5,-1.5,0,0,-2,2,2)

## Generate count responses from negative binomial regression
eta = crossprod(t(X), true.beta)
y = rnbinom(n,size=1, mu=exp(eta))

## 10-fold cross-validation for group-regularized negative binomial
## regression with the group SCAD penalty
nb.cv = cv.grpreg.nb(y,X,groups,penalty="gMCP")

## Plot cross-validation curve
plot(nb.cv$lambda, nb.cv$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes mean CVE
nb.cv$lambda.min 
</code></pre>

<hr>
<h2 id='cv.SBGAM'>Cross-Validation for Sparse Bayesian Generalized Additive Model</h2><span id='topic+cv.SBGAM'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for sparse Bayesian generalized additive models (GAMs) with the spike-and-slab group lasso (SSGL) penalty. The identity link function is used for Gaussian GAMs, the logit link is used for binomial GAMs, and the log link is used for Poisson, negative binomial, and gamma GAMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.SBGAM(y, X, df=6, 
         family=c("gaussian","binomial","poisson","negativebinomial","gamma"), 
         nb.size=1, gamma.shape=1, nfolds=5, nlambda0=20, lambda0, lambda1, 
         a, b, max.iter=100, tol = 1e-6, print.fold=TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.SBGAM_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_df">df</code></td>
<td>
<p>number of B-spline basis functions to use in each basis expansion. Default is <code>df=6</code>, but the user may specify degrees of freedom as any integer greater than or equal to 3.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_family">family</code></td>
<td>
<p>exponential dispersion family. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified, while for <code>"gamma"</code>, the shape parameter must be specified.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for negative binomial responses. Default is <code>nb.size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for gamma responses. Default is <code>gamma.shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>nfolds=5</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_nlambda0">nlambda0</code></td>
<td>
<p>number of spike hyperparameter <code class="reqn">L</code>. Default is <code>nlambda0=20</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_lambda0">lambda0</code></td>
<td>
<p>grid of <code class="reqn">L</code> spike hyperparameters <code class="reqn">\lambda_0</code>. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_lambda1">lambda1</code></td>
<td>
<p>slab hyperparameter <code class="reqn">\lambda_1</code> in the SSGL prior. Default is <code>lambda1=1</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_a">a</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>a=1</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_b">b</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>b=dim(X)[2]</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=100</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-6</code>.</p>
</td></tr>
<tr><td><code id="cv.SBGAM_+3A_print.fold">print.fold</code></td>
<td>
<p>Boolean variable for whether or not to print the current fold in the algorithm. Default is <code>print.fold=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of spike hyperparameters <code>lambda0</code> used to fit the model. <code>lambda0</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>lambda0.min</code></td>
<td>
<p>value of <code>lambda0</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bai R. (2021). &quot;Spike-and-slab group lasso for consistent Bayesian estimation and variable selection in non-Gaussian generalized additive models.&quot; <em>arXiv pre-print arXiv:2007.07021</em>.
</p>
<p>Bai, R., Moran, G. E., Antonelli, J. L., Chen, Y., and Boland, M.R. (2021). &quot;Spike-and-slab group lassos for grouped regression and sparse generalized additive models.&quot; <em>Journal of the American Statistical Association</em>, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(30*3), nrow=30)
n = dim(X)[1]
y = 2.5*sin(pi*X[,1]) + rnorm(n)

## K-fold cross-validation for 4 degrees of freedom and 4 values of lambda0
## Note that if user does not specify lambda0, cv.SBGAM chooses a grid automatically.

cv.mod = cv.SBGAM(y, X, df=4, family="gaussian", lambda0=seq(from=25,to=5,by=-10))

## Plot CVE curve
plot(cv.mod$lambda0, cv.mod$cve, type="l", xlab="lambda0", ylab="CVE")
## lambda which minimizes cross-validation error
cv.mod$lambda0.min
</code></pre>

<hr>
<h2 id='cv.SFGAM'>Sparse Frequentist Generalized Additive Models</h2><span id='topic+cv.SFGAM'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for sparse frequentist generalized additive models (GAMs) with the group LASSO, group SCAD, and group MCP penalties. The identity link function is used for Gaussian GAMs, the logit link is used for binomial GAMs, and the log link is used for Poisson, negative binomial, and gamma GAMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.SFGAM(y, X, df=6, 
         family=c("gaussian","binomial", "poisson", "negativebinomial","gamma"),
         nb.size=1, gamma.shape=1, penalty=c("gLASSO","gMCP","gSCAD"), taper,
         nfolds=10, nlambda=100, lambda, max.iter=10000, tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.SFGAM_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_df">df</code></td>
<td>
<p>number of B-spline basis functions to use in each basis expansion. Default is <code>df=6</code>, but the user may specify degrees of freedom as any integer greater than or equal to 3.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_family">family</code></td>
<td>
<p>exponential dispersion family. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified, while for <code>"gamma"</code>, the shape parameter must be specified.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for negative binomial responses. Default is <code>nb.size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for gamma responses. Default is <code>gamma.shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of basis coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, and <code>"gMCP"</code>. To implement sparse GAMs with the SSGL penalty, use the <code>SBGAM</code> function.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>nfolds=10</code>.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_nlambda">nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td></tr>
<tr><td><code id="cv.SFGAM_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). Model selection and estimation in regression with grouped variables. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>: 49-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*20), nrow=100)
n = dim(X)[1]
y = 5*sin(2*pi*X[,1])-5*cos(2*pi*X[,2]) + rnorm(n)

## Test data with 50 observations
X.test = matrix(runif(50*20), nrow=50)

## Fit sparse Gaussian generalized additive model to data with the MCP penalty
gam.mod = SFGAM(y, X, X.test, family="gaussian", penalty="gMCP")

## The model corresponding to the 75th tuning parameter
gam.mod$lambda[75] 
gam.mod$classifications[,75] ## The covariate index is listed first

## Plot first function f_1(x_1) in 75th model
x1 = X.test[,1] 
## Estimates of all 20 function evaluations on test data
f.hat = gam.mod$f.pred[[75]] 
## Extract estimates of f_1 
f1.hat = f.hat[,1] 

## Plot X_1 against f_1(x_1)
plot(x1[order(x1)], f1.hat[order(x1)], xlab=expression(x[1]), 
     ylab=expression(f[1](x[1])))
</code></pre>

<hr>
<h2 id='cv.SSGL'>Cross-Validation for Spike-and-Slab Group Lasso Regression</h2><span id='topic+cv.SSGL'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized regression in the exponential dispersion family with the spike-and-slab group lasso (SSGL) penalty. The identity link function is used for Gaussian regression, the logit link is used for binomial regression, and the log link is used for Poisson, negative binomial, and gamma regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.SSGL(y, X, groups, 
        family=c("gaussian","binomial","poisson","negativebinomial","gamma"), 
        nb.size=1, gamma.shape=1, weights, nfolds=5, nlambda0=20,
        lambda0, lambda1, a, b, max.iter=100, tol=1e-6, print.fold=TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.SSGL_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the name of the factor level that the <code class="reqn">j</code>th covariate belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_family">family</code></td>
<td>
<p>exponential dispersion family. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified, while for <code>"gamma"</code>, the shape parameter must be specified.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for negative binomial responses. Default is <code>nb.size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for gamma responses. Default is <code>gamma.shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_weights">weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>nfolds=5</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_nlambda0">nlambda0</code></td>
<td>
<p>number of spike hyperparameters <code class="reqn">L</code>. Default is <code>nlambda0=20</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_lambda0">lambda0</code></td>
<td>
<p>grid of <code class="reqn">L</code> spike hyperparameters <code class="reqn">\lambda_0</code>. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_lambda1">lambda1</code></td>
<td>
<p>slab hyperparameter <code class="reqn">\lambda_1</code> in the SSGL prior. Default is <code>lambda1=1</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_a">a</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>a=1</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_b">b</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>b=dim(X)[2]</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=100</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-6</code>.</p>
</td></tr>
<tr><td><code id="cv.SSGL_+3A_print.fold">print.fold</code></td>
<td>
<p>Boolean variable for whether or not to print the current fold in the algorithm. Default is <code>print.fold=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of spike hyperparameters <code>lambda0</code> used to fit the model. <code>lambda0</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>lambda0.min</code></td>
<td>
<p>value of <code>lambda0</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bai R. (2021). &quot;Spike-and-slab group lasso for consistent Bayesian estimation and variable selection in non-Gaussian generalized additive models.&quot; <em>arXiv pre-print arXiv:2007.07021</em>.
</p>
<p>Bai, R., Moran, G. E., Antonelli, J. L., Chen, Y., and Boland, M.R. (2021). &quot;Spike-and-slab group lassos for grouped regression and sparse generalized additive models.&quot; <em>Journal of the American Statistical Association</em>, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(30*6), nrow=30)
n = dim(X)[1]
groups = c(1,1,1,2,2,3)
true.beta = c(-1.5,0.5,-1.5,0,0,0)

## Generate responses from Gaussian distribution
y = crossprod(t(X), true.beta) + rnorm(n)

## K-fold cross-validation for 3 choices of lambda0
## Note that if user does not specify lambda0, cv.SSGL chooses a grid automatically.

ssgl.mods = cv.SSGL(y, X, groups, family="gaussian", lambda0=seq(from=10,to=2,by=-4))

## Plot cross-validation curve
plot(ssgl.mods$lambda0, ssgl.mods$cve, type="l", xlab="lambda0", ylab="CVE")
## lambda which minimizes mean CVE
ssgl.mods$lambda0.min


## Example with Poisson regression

## Generate count responses
eta = crossprod(t(X), true.beta)
y = rpois(n,exp(eta))

## K-fold cross-validation with 4 choices of lambda0
## Note that if user does not specify lambda0, cv.SSGL chooses a grid automatically.

ssgl.poisson.mods = cv.SSGL(y, X, groups, family="poisson", lambda0=seq(from=8,to=2,by=-2))

## Plot cross-validation curve
plot(ssgl.poisson.mods$lambda0, ssgl.poisson.mods$cve, type="l", xlab="lambda0", ylab="CVE")
## lambda which minimizes mean CVE
ssgl.poisson.mods$lambda0.min
</code></pre>

<hr>
<h2 id='grpreg.gamma'>Group-regularized Gamma Regression</h2><span id='topic+grpreg.gamma'></span>

<h3>Description</h3>

<p>This function implements group-regularized gamma regression with a known shape parameter <code class="reqn">\nu</code> and the log link. In gamma regression, we assume that <code class="reqn">y_i \sim Gamma(\mu_i, \nu)</code>, where
</p>
<p style="text-align: center;"><code class="reqn">f(y_i | \mu_i, \nu ) = \frac{1}{\Gamma(\nu)} (\frac{\nu}{\mu_i})^{\nu} \exp(-\frac{\nu}{\mu_i}y_i) y_i^{\nu-1}, y &gt; 0.</code>
</p>

<p>Then <code class="reqn">E(y_i) = \mu_i</code>, and we relate <code class="reqn">\mu_i</code> to a set of <code class="reqn">p</code> covariates <code class="reqn">x_i</code> through the log link,
</p>
<p style="text-align: center;"><code class="reqn">\log(\mu_i) = \beta_0 + x_i^T \beta, i=1,..., n</code>
</p>

<p>If the covariates in each <code class="reqn">x_i</code> are grouped according to known groups <code class="reqn">g=1, ..., G</code>, then this function may estimate some of the <code class="reqn">G</code> groups of coefficients as all zero, depending on the amount of regularization. 
</p>
<p>Our implementation for regularized gamma regression is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grpreg.gamma(y, X, X.test, groups, gamma.shape=1, 
             penalty=c("gLASSO","gSCAD","gMCP"),
             weights, taper, nlambda=100, lambda, max.iter=10000, tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grpreg.gamma_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_x.test">X.test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X.test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X.test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the name of the factor level that the <code class="reqn">j</code>th covariate belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for the responses. Default is <code>gamma.shape=1</code>.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement gamma regression with the SSGL penalty, use the <code>SSGL</code> function.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_weights">weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_nlambda">nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td></tr>
<tr><td><code id="grpreg.gamma_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of estimated regression coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>mu.pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X.test</code> (or training data <code>X</code> if no argument was specified for <code>X.test</code>). The <code class="reqn">k</code>th column in <code>mu.pred</code> corresponds to the predictions for the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">G \times L</code> matrix of classifications, where <code class="reqn">G</code> is the number of groups. An entry of &quot;1&quot; indicates that the group was classified as nonzero, and an entry of &quot;0&quot; indicates that the group was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of negative log-likelihood of the fitted models. The <code class="reqn">k</code>th entry in <code>loss</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*11), nrow=100)
n = dim(X)[1]
groups = c("a","a","a","b","b","b","c","c","d","e","e")
groups = as.factor(groups)
true.beta = c(-1,1,1,0,0,0,0,0,0,1.5,-1.5)

## Generate responses from gamma regression with known shape parameter 1
eta = crossprod(t(X), true.beta)
shape = 1
y = rgamma(n, rate=shape/exp(eta), shape=shape)

## Generate test data
n.test = 50
X.test = matrix(runif(n.test*11), nrow=n.test)

## Fit gamma regression models with the group LASSO penalty
gamma.mod = grpreg.gamma(y, X, X.test, groups, penalty="gLASSO")

## Tuning parameters used to fit models 
gamma.mod$lambda

# Predicted n.test-dimensional vectors mu=E(Y.test) based on test data, X.test. 
# The kth column of 'mu.pred' corresponds to the kth entry in 'lambda.'
gamma.mod$mu.pred 

# Classifications of the 5 groups. The kth column of 'classifications'
# corresponds to the kth entry in 'lambda.'
gamma.mod$classifications
</code></pre>

<hr>
<h2 id='grpreg.nb'>Group-regularized Negative Binomial Regression</h2><span id='topic+grpreg.nb'></span>

<h3>Description</h3>

<p>This function implements group-regularized negative binomial regression with a known size parameter <code class="reqn">\alpha</code> and the log link. In negative binomial regression, we assume that <code class="reqn">y_i \sim NB(\alpha, \mu_i)</code>, where
</p>
<p style="text-align: center;"><code class="reqn">f(y_i | \alpha, \mu_i ) = \frac{\Gamma(y+\alpha)}{y! \Gamma(\alpha)} (\frac{\mu_i}{\mu_i+\alpha})^{y}(\frac{\alpha}{\mu_i +\alpha})^{\alpha}, y = 0, 1, 2, ...</code>
</p>

<p>Then <code class="reqn">E(y_i) = \mu_i</code>, and we relate <code class="reqn">\mu_i</code> to a set of <code class="reqn">p</code> covariates <code class="reqn">x_i</code> through the log link,
</p>
<p style="text-align: center;"><code class="reqn">\log(\mu_i) = \beta_0 + x_i^T \beta, i=1,..., n</code>
</p>

<p>If the covariates in each <code class="reqn">x_i</code> are grouped according to known groups <code class="reqn">g=1, ..., G</code>, then this function may estimate some of the <code class="reqn">G</code> groups of coefficients as all zero, depending on the amount of regularization. 
</p>
<p>Our implementation for regularized negative binomial regression is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than sample size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grpreg.nb(y, X, X.test, groups, nb.size=1, penalty=c("gLASSO","gSCAD","gMCP"),
          weights, taper, nlambda=100, lambda, max.iter=10000, tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grpreg.nb_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_x.test">X.test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X.test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X.test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the name of the factor level that the <code class="reqn">j</code>th covariate belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses. Default is <code>nb.size=1</code>.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement negative binomial regression with the SSGL penalty, use the <code>SSGL</code> function.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_weights">weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_nlambda">nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td></tr>
<tr><td><code id="grpreg.nb_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of estimated regression coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>mu.pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X.test</code> (or training data <code>X</code> if no argument was specified for <code>X.test</code>). The <code class="reqn">k</code>th column in <code>mu.pred</code> corresponds to the predictions for the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">G \times L</code> matrix of classifications, where <code class="reqn">G</code> is the number of groups. An entry of &quot;1&quot; indicates that the group was classified as nonzero, and an entry of &quot;0&quot; indicates that the group was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of negative log-likelihood of the fitted models. The <code class="reqn">k</code>th entry in <code>loss</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate training data
set.seed(1234)
X = matrix(runif(100*16), nrow=100) 
n = dim(X)[1]
groups = c("A","A","A","B","B","B","C","C","D","E","E","F","G","H","H","H")
groups = as.factor(groups)
true.beta = c(-2,2,2,0,0,0,0,0,0,1.5,-1.5,0,0,-2,2,2)
  
## Generate count responses from negative binomial regression
eta = crossprod(t(X), true.beta)
y = rnbinom(n,size=1, mu=exp(eta))
  
## Generate test data
n.test = 50
X.test = matrix(runif(n.test*16), nrow=n.test)
  
## Fit negative binomial regression models with the group SCAD penalty
nb.mod = grpreg.nb(y, X, X.test, groups, penalty="gSCAD")
  
## Tuning parameters used to fit models 
nb.mod$lambda
  
# Predicted n.test-dimensional vectors mu=E(Y.test) based on test data, X.test. 
# The kth column of 'mu.pred' corresponds to the kth entry in 'lambda.'
nb.mod$mu.pred 
  
# Classifications of the 8 groups. The kth column of 'classifications'
# corresponds to the kth entry in lambda.
nb.mod$classifications
</code></pre>

<hr>
<h2 id='SBGAM'>Sparse Bayesian Generalized Additive Models</h2><span id='topic+SBGAM'></span>

<h3>Description</h3>

<p>This function implements sparse Bayesian generalized additive models (GAMs) with the spike-and-slab group lasso (SSGL) penalty. Let <code class="reqn">y_i</code> denote the <code class="reqn">i</code>th response and <code class="reqn">x_i</code> denote a <code class="reqn">p</code>-dimensional vector of covariates. GAMs are of the form,
</p>
<p style="text-align: center;"><code class="reqn">g(E(y_i)) = \beta_0 + \sum_{j=1}^{p} f_j (x_{ij}), i = 1, ..., n,</code>
</p>

<p>where <code class="reqn">g</code> is a monotone increasing link function. The identity link function is used for Gaussian regression, the logit link is used for binomial regression, and the log link is used for Poisson, negative binomial, and gamma regression. With the SSGL penalty, some of the univariate functions <code class="reqn">f_j(x_j)</code> will be estimated as <code class="reqn">\hat{f}_j(x_j) = 0</code>, depending on the size of the spike hyperparameter <code class="reqn">\lambda_0</code> in the SSGL prior. The functions <code class="reqn">f_j(x_j), j = 1, ..., p</code>, are modeled using B-spline basis expansions. 
</p>
<p>There is another implementation of sparse Gaussian GAMs with the SSGL penalty available at https://github.com/jantonelli111/SSGL, which uses natural cubic splines as the basis functions. This package <code>sparseGAM</code> uses B-spline basis functions and also implements sparse GAMs with the SSGL penalty for binomial, Poisson, negative binomial, and gamma regression.
</p>
<p>For implementation of sparse <em>frequentist</em> GAMs with the group LASSO, group SCAD, and group MCP penalties, use the <code>SFGAM</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SBGAM(y, X, X.test, df=6, 
      family=c("gaussian","binomial","poisson","negativebinomial","gamma"), 
      nb.size=1, gamma.shape=1, nlambda0=20, lambda0, lambda1, a, b, 
      max.iter=100, tol = 1e-6, print.iter=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SBGAM_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_x.test">X.test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X.test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X.test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_df">df</code></td>
<td>
<p>number of B-spline basis functions to use in each basis expansion. Default is <code>df=6</code>, but the user may specify degrees of freedom as any integer greater than or equal to 3.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_family">family</code></td>
<td>
<p>exponential dispersion family. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified, while for <code>"gamma"</code>, the shape parameter must be specified.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for negative binomial responses. Default is <code>nb.size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for gamma responses. Default is <code>gamma.shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_nlambda0">nlambda0</code></td>
<td>
<p>number of spike hyperparameter <code class="reqn">L</code>. Default is <code>nlambda0=20</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_lambda0">lambda0</code></td>
<td>
<p>grid of <code class="reqn">L</code> spike hyperparameters <code class="reqn">\lambda_0</code>. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_lambda1">lambda1</code></td>
<td>
<p>slab hyperparameter <code class="reqn">\lambda_1</code> in the SSGL prior. Default is <code>lambda1=1</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_a">a</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>a=1</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_b">b</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>b=dim(X)[2]</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=100</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-6</code>.</p>
</td></tr>
<tr><td><code id="SBGAM_+3A_print.iter">print.iter</code></td>
<td>
<p>Boolean variable for whether or not to print the current <code>nlambda0</code> in the algorithm. Default is <code>print.iter=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of spike hyperparameters <code>lambda0</code> used to fit the model. <code>lambda0</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>f.pred</code></td>
<td>
<p>List of <code class="reqn">L</code> <code class="reqn">n_{test} \times p</code> matrices, where the <code class="reqn">k</code>th matrix in the list corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>. The <code class="reqn">j</code>th column in each matrix in <code>f.pred</code> is the estimate of the <code class="reqn">j</code>th function evaluated on the test data in <code>X.test</code> for the <code class="reqn">j</code>th covariate (or training data <code>X</code> if <code>X.test</code> was not specified). </p>
</td></tr>
<tr><td><code>mu.pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X.test</code> (or training data <code>X</code> if no argument was specified for <code>X.test</code>). The <code class="reqn">k</code>th column in <code>mu.pred</code> corresponds to the predictions for the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of classifications. An entry of &quot;1&quot; indicates that the corresponding function was classified as nonzero, and an entry of &quot;0&quot; indicates that the function was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">dp \times L</code> matrix of estimated basis coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>vector of either the residual sum of squares (<code>"gaussian"</code>) or the negative log-likelihood (<code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, <code>"gamma"</code>) of the fitted model. The <code class="reqn">k</code>th entry in <code>loss</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bai R. (2021). &quot;Spike-and-slab group lasso for consistent Bayesian estimation and variable selection in non-Gaussian generalized additive models.&quot; <em>arXiv pre-print arXiv:2007.07021</em>.
</p>
<p>Bai, R., Moran, G. E., Antonelli, J. L., Chen, Y., and Boland, M.R. (2021). &quot;Spike-and-slab group lassos for grouped regression and sparse generalized additive models.&quot; <em>Journal of the American Statistical Association</em>, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*5), nrow=100)
n = dim(X)[1]
y = 3*sin(2*pi*X[,1])-3*cos(2*pi*X[,2]) + rnorm(n)

## Test data with 30 observations
X.test = matrix(runif(30*5), nrow=30)

## Fit sparse Bayesian generalized additive model to data with the SSGL penalty
## and 5 spike hyperparameters
SBGAM.mod = SBGAM(y, X, X.test, family="gaussian", lambda0=seq(from=50,to=10,by=-10))

## The model corresponding to the 1st spike hyperparameter
SBGAM.mod$lambda[1] 
SBGAM.mod$classifications[,1] 

## Plot first function f_1(x_1) in 2nd model
x1 = X.test[,1] 
## Estimates of all 20 function evaluations on test data
f.hat = SBGAM.mod$f.pred[[1]] 
## Extract estimates of f_1 
f1.hat = f.hat[,1] 

## Plot X_1 against f_1(x_1)
plot(x1[order(x1)], f1.hat[order(x1)], xlab=expression(x[1]), 
     ylab=expression(f[1](x[1])))
</code></pre>

<hr>
<h2 id='SFGAM'>Sparse Frequentist Generalized Additive Models</h2><span id='topic+SFGAM'></span>

<h3>Description</h3>

<p>This function implements sparse frequentist generalized additive models (GAMs) with the group LASSO, group SCAD, and group MCP penalties. Let <code class="reqn">y_i</code> denote the <code class="reqn">i</code>th response and <code class="reqn">x_i</code> denote a <code class="reqn">p</code>-dimensional vector of covariates. GAMs are of the form,
</p>
<p style="text-align: center;"><code class="reqn">g(E(y_i)) = \beta_0 + \sum_{j=1}^{p} f_j (x_{ij}), i = 1, ..., n,</code>
</p>

<p>where <code class="reqn">g</code> is a monotone increasing link function. The identity link function is used for Gaussian regression, the logit link is used for binomial regression, and the log link is used for Poisson, negative binomial, and gamma regression. The univariate functions are estimated using linear combinations of B-spline basis functions. Under group regularization of the basis coefficients, some of the univariate functions <code class="reqn">f_j(x_j)</code> will be estimated as <code class="reqn">\hat{f}_j(x_j) = 0</code>, depending on the size of the regularization parameter <code class="reqn">\lambda</code>. 
</p>
<p>For implementation of sparse <em>Bayesian</em> GAMs with the SSGL penalty, use the <code>SBGAM</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SFGAM(y, X, X.test, df=6, 
      family=c("gaussian","binomial", "poisson", "negativebinomial","gamma"),
      nb.size=1, gamma.shape=1, penalty=c("gLASSO","gMCP","gSCAD"), taper, 
      nlambda=100, lambda, max.iter=10000, tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SFGAM_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_x.test">X.test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X.test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X.test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_df">df</code></td>
<td>
<p>number of B-spline basis functions to use in each basis expansion. Default is <code>df=6</code>, but the user may specify degrees of freedom as any integer greater than or equal to 3.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_family">family</code></td>
<td>
<p>exponential dispersion family. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified, while for <code>"gamma"</code>, the shape parameter must be specified.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for negative binomial responses. Default is <code>nb.size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for gamma responses. Default is <code>gamma.shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of basis coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, and <code>"gMCP"</code>. To implement sparse GAMs with the SSGL penalty, use the <code>SBGAM</code> function.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_nlambda">nlambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>nlambda=100</code>.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=10000</code>.</p>
</td></tr>
<tr><td><code id="SFGAM_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>f.pred</code></td>
<td>
<p>List of <code class="reqn">L</code> <code class="reqn">n_{test} \times p</code> matrices, where the <code class="reqn">k</code>th matrix in the list corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>. The <code class="reqn">j</code>th column in each matrix in <code>f.pred</code> is the estimate of the <code class="reqn">j</code>th function evaluated on the test data in <code>X.test</code> for the <code class="reqn">j</code>th covariate (or training data <code>X</code> if <code>X.test</code> was not specified). </p>
</td></tr>
<tr><td><code>mu.pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X.test</code> (or training data <code>X</code> if no argument was specified for <code>X.test</code>). The <code class="reqn">k</code>th column in <code>mu.pred</code> corresponds to the predictions for the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of classifications. An entry of &quot;1&quot; indicates that the corresponding function was classified as nonzero, and an entry of &quot;0&quot; indicates that the function was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">dp \times L</code> matrix of estimated basis coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>vector of either the residual sum of squares (<code>"gaussian"</code>) or the negative log-likelihood (<code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, <code>"gamma"</code>) of the fitted model. The <code class="reqn">k</code>th entry in <code>loss</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). Model selection and estimation in regression with grouped variables. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>: 49-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*20), nrow=100)
n = dim(X)[1]
y = 5*sin(2*pi*X[,1])-5*cos(2*pi*X[,2]) + rnorm(n)

## Test data with 50 observations
X.test = matrix(runif(50*20), nrow=50)

## K-fold cross-validation with group MCP penalty
cv.mod = cv.SFGAM(y, X, family="gaussian", penalty="gMCP")
## Plot CVE curve
plot(cv.mod$lambda, cv.mod$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes cross-validation error
lambda.opt = cv.mod$lambda.min

## Fit a single model with lambda.opt
SFGAM.mod = SFGAM(y, X, X.test, penalty="gMCP", lambda=lambda.opt)

## Classifications
SFGAM.mod$classifications
## Predicted function evaluations on test data
f.pred = SFGAM.mod$f.pred  

## Plot estimated first function
x1 = X.test[,1]
f1.hat = f.pred[,1]

## Plot x_1 against f_1(x_1)
plot(x1[order(x1)], f1.hat[order(x1)], xlab=expression(x[1]), 
     ylab=expression(f[1](x[1])))
</code></pre>

<hr>
<h2 id='SSGL'>Spike-and-Slab Group Lasso Regression</h2><span id='topic+SSGL'></span>

<h3>Description</h3>

<p>This is a stand-alone function for group-regularized regression models in the exponential dispersion family with the spike-and-slab group lasso (SSGL) penalty.  Let <code class="reqn">y_i</code> denote the <code class="reqn">i</code>th response and <code class="reqn">x_i</code> denote a <code class="reqn">p</code>-dimensional vector of covariates. We fit models of the form,
</p>
<p style="text-align: center;"><code class="reqn">g(E(y_i)) = \beta_0 + x_i^T \beta, i = 1, ..., n,</code>
</p>

<p>where <code class="reqn">g</code> is a monotone increasing link function. The identity link function is used for Gaussian regression, the logit link is used for binomial regression, and the log link is used for Poisson, negative binomial, and gamma regression.
</p>
<p>If the covariates in each <code class="reqn">x_i</code> are grouped according to known groups <code class="reqn">g=1, ..., G</code>, then this function may estimate some of the <code class="reqn">G</code> groups of coefficients as all zero, depending on the amount of regularization. 
</p>
<p>Another implementation of the SSGL model for Gaussian regression models is available on Github at https://github.com/jantonelli111/SSGL. This package <code>sparseGAM</code> also implements the SSGL model for binomial, Poisson, negative binomial, and gamma regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SSGL(y, X, X.test, groups, 
     family=c("gaussian","binomial","poisson","negativebinomial","gamma"), 
     nb.size=1, gamma.shape=1, weights, nlambda0=20, lambda0, lambda1, a, b, 
     max.iter=100, tol = 1e-6, print.iter=TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SSGL_+3A_y">y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_x.test">X.test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X.test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X.test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the name of the factor level that the <code class="reqn">j</code>th covariate belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_family">family</code></td>
<td>
<p>exponential dispersion family. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified, while for <code>"gamma"</code>, the shape parameter must be specified.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_nb.size">nb.size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the negative binomial responses. Default is <code>nb.size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_gamma.shape">gamma.shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for gamma responses. Default is <code>gamma.shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_weights">weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_nlambda0">nlambda0</code></td>
<td>
<p>number of spike hyperparameters <code class="reqn">L</code>. Default is <code>nlambda0=20</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_lambda0">lambda0</code></td>
<td>
<p>grid of <code class="reqn">L</code> spike hyperparameters <code class="reqn">\lambda_0</code>. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_lambda1">lambda1</code></td>
<td>
<p>slab hyperparameter <code class="reqn">\lambda_1</code> in the SSGL prior. Default is <code>lambda1=1</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_a">a</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>a=1</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_b">b</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>b=dim(X)[2]</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max.iter=100</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-6</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_print.iter">print.iter</code></td>
<td>
<p>Boolean variable for whether or not to print the current <code>nlambda0</code> in the algorithm. Default is <code>print.iter=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of spike hyperpameters <code>lambda0</code> used to fit the model. <code>lambda0</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of estimated regression coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>mu.pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X.test</code> (or training data <code>X</code> if no argument was specified for<code>X.test</code>). The <code class="reqn">k</code>th column in <code>mu.pred</code> corresponds to the predictions for the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">G \times L</code> matrix of classifications, where <code class="reqn">G</code> is the number of groups. An entry of &quot;1&quot; indicates that the group was classified as nonzero, and an entry of &quot;0&quot; indicates that the group was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>loss</code></td>
<td>
<p>vector of either the residual sum of squares (<code>"gaussian"</code>) or the negative log-likelihood (<code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, <code>"gamma"</code>) of the fitted model. The <code class="reqn">k</code>th entry in <code>loss</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bai R. (2021). &quot;Spike-and-slab group lasso for consistent Bayesian estimation and variable selection in non-Gaussian generalized additive models.&quot; <em>arXiv pre-print arXiv:2007.07021</em>.
</p>
<p>Bai, R., Moran, G. E., Antonelli, J. L., Chen, Y., and Boland, M.R. (2021). &quot;Spike-and-slab group lassos for grouped regression and sparse generalized additive models.&quot; <em>Journal of the American Statistical Association</em>, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*10), nrow=100)
n = dim(X)[1]
groups = c("A","A","A","B","B","B","C","C","D","D")
groups = as.factor(groups)
true.beta = c(-2.5,1.5,1.5,0,0,0,2,-2,0,0)

## Generate responses from Gaussian distribution
y = crossprod(t(X),true.beta) + rnorm(n)

## Generate test data
n.test = 50
X.test = matrix(runif(n.test*10), nrow=n.test)

## Fit SSGL model with 10 spike hyperparameters
## Note that if user does not specify lambda0, the SSGL function chooses a grid automatically.

SSGL.mod = SSGL(y, X, X.test, groups, family="gaussian", lambda0=seq(from=50,to=5,by=-5))

## Regression coefficient estimates
SSGL.mod$beta

# Predicted n.test-dimensional vectors mu=E(Y.test) based on test data, X.test. 
# The kth column of 'mu.pred' corresponds to the kth entry in 'lambda.'
SSGL.mod$mu.pred 

# Classifications of the 8 groups. The kth column of 'classifications'
# corresponds to the kth entry in 'lambda.'
SSGL.mod$classifications


## Example with binomial regression

## Generate binary responses
eta = crossprod(t(X), true.beta)
y = rbinom(n, size=1, prob=1/(1+exp(-eta)))

## Fit SSGL model with 10 spike hyperparameters
## Note that if user does not specify lambda0, the SSGL function chooses a grid automatically.

SSGL.mod = SSGL(y, X, X.test, groups, family="binomial", 
		lambda0=seq(from=10,to=1,by=-1))

## Predicted probabilities of success mu=E(Y.test) based on test data, X.test
SSGL.mod$mu.pred

## Classifications of the 8 groups. 
SSGL.mod$classifications

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
