<!DOCTYPE html><html><head><title>Help for package HeteroGGM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HeteroGGM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#example.data'><p>Some example data</p></a></li>
<li><a href='#FGGM'><p>Fused Gaussian graphical model.</p></a></li>
<li><a href='#FGGM.refit'><p>Refitting of FGGM</p></a></li>
<li><a href='#genelambda.obo'><p>Generate tuning parameters</p></a></li>
<li><a href='#generate.data'><p>Data Generation</p></a></li>
<li><a href='#GGMPF'><p>GGM-based heterogeneity analysis.</p></a></li>
<li><a href='#linked_node_names'><p>Indexes the names of all nodes connected to some particular nodes in a subgroup.</p></a></li>
<li><a href='#PGGMBC'><p>Penalized GGM-based clustering.</p></a></li>
<li><a href='#plot_network'><p>Visualization of network structures.</p></a></li>
<li><a href='#Power.law.network'><p>Power law network</p></a></li>
<li><a href='#summary_network'><p>The summary of the resulting network structures.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Gaussian Graphical Model-Based Heterogeneity Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-10</td>
</tr>
<tr>
<td>Description:</td>
<td>The goal of this package is to user-friendly realizing Gaussian 
             graphical model-based heterogeneity analysis.
             Recently, several Gaussian graphical model-based heterogeneity 
             analysis techniques have been developed. A common methodological limitation 
             is that the number of subgroups is assumed to be known a priori, which 
             is not realistic. In a very recent study (Ren et al., 2022), a novel approach 
             based on the penalized fusion technique is developed to fully 
             data-dependently determine the number and structure of subgroups in 
             Gaussian graphical model-based heterogeneity analysis. It opens the door for utilizing 
             the Gaussian graphical model technique in more practical settings. Beyond 
             Ren et al. (2022), more estimations and functions are added, so 
             that the package is self-contained and more comprehensive and can 
             provide &ldquo;more direct&rdquo; insights to practitioners (with the 
             visualization function). Reference: 
             Ren, M., Zhang S., Zhang Q. and Ma S. (2022). Gaussian Graphical 
             Model-based Heterogeneity Analysis via Penalized Fusion. 
             Biometrics, 78 (2), 524-535.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>igraph, Matrix, MASS, huge</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-11 12:39:18 UTC; 10259</td>
</tr>
<tr>
<td>Author:</td>
<td>Mingyang Ren <a href="https://orcid.org/0000-0002-8061-9940"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Sanguo Zhang [aut],
  Qingzhao Zhang [aut],
  Shuangge Ma [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mingyang Ren &lt;renmingyang17@mails.ucas.ac.cn&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-11 13:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='example.data'>Some example data</h2><span id='topic+example.data'></span>

<h3>Description</h3>

<p>Some example data
</p>


<h3>Format</h3>

<p>A list including:
data: The 600 x 20 matrix, the design matrix.
L0: The subgroup to which each sample truly belongs.
Mu0: The true mean parameters of 3 subgroups.
Theta0: The true precision matrices of 3 subgroups.
n_all: The total sample size.
K0: The true number of subgroups 3.
</p>


<h3>Source</h3>

<p>Simulated data (see examples in the function tuning.lambda.FGGM)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example.data)
</code></pre>

<hr>
<h2 id='FGGM'>Fused Gaussian graphical model.</h2><span id='topic+FGGM'></span>

<h3>Description</h3>

<p>The base function of Gaussian graphical model-based heterogeneity analysis via penalized fusion: identifying the order of subgroups and reconstructing the network structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FGGM(data, K, lambda1 = 0.5, lambda2 = 0.2, lambda3 = 2, a = 3, rho = 1,
            eps = 5e-2, niter = 20, maxiter=10, maxiter.AMA=5, initialization=T,
            initialize, average=F, asymmetric=T, local_appro=T,
            penalty = "MCP", theta.fusion=T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FGGM_+3A_data">data</code></td>
<td>
<p>n * p matrix, the design matrix.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_k">K</code></td>
<td>
<p>Int, a selected upper bound of K_0.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_lambda1">lambda1</code></td>
<td>
<p>A float value, the tuning parameter controlling the sparse of the mean parameter.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_lambda2">lambda2</code></td>
<td>
<p>A float value, the tuning parameter controlling the sparse of the precision matrix.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_lambda3">lambda3</code></td>
<td>
<p>A float value, the tuning parameter controlling the number of subgroup.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_a">a</code></td>
<td>
<p>A float value, regularization parameter in MCP, the default setting is 3.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_rho">rho</code></td>
<td>
<p>A float value, the penalty parameter in ADMM algorithm of updating precision matrix Theta, the default setting is 1.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_eps">eps</code></td>
<td>
<p>A float value, algorithm termination threshold.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_niter">niter</code></td>
<td>
<p>Int, maximum number of cycles of the EM algorithm, the default setting is 20.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_maxiter">maxiter</code></td>
<td>
<p>Int, maximum number of cycles of the ADMM algorithm.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_maxiter.ama">maxiter.AMA</code></td>
<td>
<p>Int, maximum number of cycles of the AMA algorithm.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_initialization">initialization</code></td>
<td>
<p>The logical variable, whether to calculate the initial value, the default setting is T, if initialization = F, the initial value uses initialize.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_initialize">initialize</code></td>
<td>
<p>A given initial value used if initialization = F.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_average">average</code></td>
<td>
<p>The logical variable, whether to use averaging when integrating parameters that are identified as identical subgroups, the default setting is F, which means the estimated parameters for the subgroup with the largest sample size among the subgroups identified as identical subgroups is used as the final parameter for this subgroup.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_asymmetric">asymmetric</code></td>
<td>
<p>The logical variable, symmetry of the precision matrices or not, the default setting is T.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_local_appro">local_appro</code></td>
<td>
<p>The logical variable, whether to use local approximations when updating mean parameters, the default setting is T.</p>
</td></tr>
<tr><td><code id="FGGM_+3A_penalty">penalty</code></td>
<td>
<p>The type of the penalty, which can be selected from c(&quot;MCP&quot;, &quot;SCAD&quot;, &quot;lasso&quot;).</p>
</td></tr>
<tr><td><code id="FGGM_+3A_theta.fusion">theta.fusion</code></td>
<td>
<p>Whether or not the fusion penalty term contains elements of the precision matrices. The default setting is T.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including all estimated parameters and the BIC value.
</p>


<h3>Author(s)</h3>

<p>Mingyang Ren, Sanguo Zhang, Qingzhao Zhang, Shuangge Ma. Maintainer: Mingyang Ren &lt;renmingyang17@mails.ucas.ac.cn&gt;.
</p>


<h3>References</h3>

<p>Ren, M., Zhang S., Zhang Q. and Ma S. (2020). Gaussian Graphical Model-based Heterogeneity Analysis via Penalized Fusion. Biometrics, Published Online.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 200              # The sample size of each subgroup
p &lt;- 20               # The dimension of the precision matrix
K0 &lt;- 3               # The true number of subgroups
N &lt;- rep(n,K0)        # The sample sizes of K0 subgroups
K &lt;- 6                # The given upper bound of K0.

################ The true parameters ################
mue &lt;- 1.5
nonnum &lt;- 4
mu01 &lt;- c(rep(mue,nonnum),rep(-mue,nonnum),rep(0,p-2*nonnum))
mu02 &lt;- c(rep(mue,2*nonnum),rep(0,p-2*nonnum))
mu03 &lt;- c(rep(-mue,2*nonnum),rep(0,p-2*nonnum))

# Power law network
set.seed(2)
A.list &lt;- Power.law.network(p,s=5,I2=c(1),I3=c(2))
Theta01 &lt;- A.list$A1
Theta02 &lt;- A.list$A2
Theta03 &lt;- A.list$A3
sigma01 &lt;- solve(Theta01)
sigma02 &lt;- solve(Theta02)
sigma03 &lt;- solve(Theta03)
Mu0.list &lt;- list(mu01,mu02,mu03)
Sigma0.list &lt;- list(sigma01,sigma02,sigma03)
Theta0.list &lt;- list(Theta01,Theta02,Theta03)

################ Generating simulated data ################
whole.data &lt;- generate.data(N,Mu0.list,Theta0.list,Sigma0.list)

PP = FGGM(whole.data$data, K, lambda1 = 0.22, lambda2 = 0.12, lambda3 = 1.83)
mu_hat=PP$mu; Theta_hat=PP$Xi; L.mat = PP$L.mat0
group = PP$group; prob = PP$prob0; bic = PP$bic; member = PP$member
K0_hat = as.numeric(dim(Theta_hat)[3])
K0_hat


</code></pre>

<hr>
<h2 id='FGGM.refit'>Refitting of FGGM</h2><span id='topic+FGGM.refit'></span>

<h3>Description</h3>

<p>Refitting when K0 is identified using FGGM().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FGGM.refit(data, K, lambda1 = 0.5, lambda2 = 0.2, lambda3 = 2, a = 3, rho = 1,
                  eps = 5e-2, niter = 20, maxiter=10, maxiter.AMA=5,
                  initialization=T, initialize, average=F,
                  asymmetric=T, local_appro=T, penalty = "MCP", theta.fusion=T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FGGM.refit_+3A_data">data</code></td>
<td>
<p>n * p matrix, the design matrix.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_k">K</code></td>
<td>
<p>Int, a selected upper bound of K_0.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_lambda1">lambda1</code></td>
<td>
<p>A float value, the tuning parameter controlling the sparse of the mean parameter.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_lambda2">lambda2</code></td>
<td>
<p>A float value, the tuning parameter controlling the sparse of the precision matrix.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_lambda3">lambda3</code></td>
<td>
<p>A float value, the tuning parameter controlling the number of subgroup.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_a">a</code></td>
<td>
<p>A float value, regularization parameter in MCP, the default setting is 3.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_rho">rho</code></td>
<td>
<p>A float value, the penalty parameter in ADMM algorithm of updating precision matrix Theta, the default setting is 1.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_eps">eps</code></td>
<td>
<p>A float value, algorithm termination threshold.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_niter">niter</code></td>
<td>
<p>Int, maximum number of cycles of the algorithm, the default setting is 20.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_maxiter">maxiter</code></td>
<td>
<p>Int, maximum number of cycles of the ADMM algorithm.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_maxiter.ama">maxiter.AMA</code></td>
<td>
<p>Int, maximum number of cycles of the AMA algorithm.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_initialization">initialization</code></td>
<td>
<p>The logical variable, whether to calculate the initial value, the default setting is T, if initialization = F, the initial value uses initialize.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_initialize">initialize</code></td>
<td>
<p>A given initial value used if initialization = F.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_average">average</code></td>
<td>
<p>The logical variable, whether to use averaging when integrating parameters that are identified as identical subgroups, the default setting is F, which means the estimated parameters for the subgroup with the largest sample size among the subgroups identified as identical subgroups is used as the final parameter for this subgroup.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_asymmetric">asymmetric</code></td>
<td>
<p>The logical variable, symmetry of the precision matrices or not, the default setting is T.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_local_appro">local_appro</code></td>
<td>
<p>The logical variable, whether to use local approximations when updating mean parameters, the default setting is T.</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_penalty">penalty</code></td>
<td>
<p>The type of the penalty, which can be selected from c(&quot;MCP&quot;, &quot;SCAD&quot;, &quot;lasso&quot;).</p>
</td></tr>
<tr><td><code id="FGGM.refit_+3A_theta.fusion">theta.fusion</code></td>
<td>
<p>Whether or not the fusion penalty term contains elements of the precision matrices. The default setting is T.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including all estimated parameters and the BIC value after refitting.
</p>


<h3>Author(s)</h3>

<p>Mingyang Ren, Sanguo Zhang, Qingzhao Zhang, Shuangge Ma. Maintainer: Mingyang Ren &lt;renmingyang17@mails.ucas.ac.cn&gt;.
</p>


<h3>References</h3>

<p>Ren, M., Zhang S., Zhang Q. and Ma S. (2020). Gaussian Graphical Model-based Heterogeneity Analysis via Penalized Fusion. Biometrics, Published Online.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 200              # The sample size of each subgroup
p &lt;- 20               # The dimension of the precision matrix
K0 &lt;- 3               # The true number of subgroups
N &lt;- rep(n,K0)        # The sample sizes of K0 subgroups
K &lt;- 6                # The given upper bound of K0.

################ The true parameters ################
mue &lt;- 1.5
nonnum &lt;- 4
mu01 &lt;- c(rep(mue,nonnum),rep(-mue,nonnum),rep(0,p-2*nonnum))
mu02 &lt;- c(rep(mue,2*nonnum),rep(0,p-2*nonnum))
mu03 &lt;- c(rep(-mue,2*nonnum),rep(0,p-2*nonnum))
# Power law network
set.seed(2)
A.list &lt;- Power.law.network(p,s=5,I2=c(1),I3=c(2))
Theta01 &lt;- A.list$A1
Theta02 &lt;- A.list$A2
Theta03 &lt;- A.list$A3
sigma01 &lt;- solve(Theta01)
sigma02 &lt;- solve(Theta02)
sigma03 &lt;- solve(Theta03)
Mu0.list &lt;- list(mu01,mu02,mu03)
Sigma0.list &lt;- list(sigma01,sigma02,sigma03)
Theta0.list &lt;- list(Theta01,Theta02,Theta03)

################ Generating simulated data ################
whole.data &lt;- generate.data(N,Mu0.list,Theta0.list,Sigma0.list)

PP = FGGM.refit(whole.data$data, K, lambda1 = 0.22, lambda2 = 0.12, lambda3 = 1.83)
mu_hat=PP$mu; Theta_hat=PP$Xi; L.mat = PP$L.mat0
group = PP$group; prob = PP$prob0; bic = PP$bic; member = PP$member
K0_hat = as.numeric(dim(Theta_hat)[3])
K0_hat


</code></pre>

<hr>
<h2 id='genelambda.obo'>Generate tuning parameters</h2><span id='topic+genelambda.obo'></span>

<h3>Description</h3>

<p>Generating a sequence of the tuning parameters (lambda1, lambda2, and lambda3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genelambda.obo(nlambda1=10,lambda1_max=1,lambda1_min=0.05,
                      nlambda2=10,lambda2_max=1,lambda2_min=0.01,
                      nlambda3=10,lambda3_max=5,lambda3_min=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genelambda.obo_+3A_nlambda1">nlambda1</code></td>
<td>
<p>The numbers of lambda 1.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_lambda1_max">lambda1_max</code></td>
<td>
<p>The maximum values of lambda 1.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_lambda1_min">lambda1_min</code></td>
<td>
<p>The minimum values of lambda 1.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_nlambda2">nlambda2</code></td>
<td>
<p>The numbers of lambda 2.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_lambda2_max">lambda2_max</code></td>
<td>
<p>The maximum values of lambda 2.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_lambda2_min">lambda2_min</code></td>
<td>
<p>The minimum values of lambda 2.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_nlambda3">nlambda3</code></td>
<td>
<p>The numbers of lambda 3.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_lambda3_max">lambda3_max</code></td>
<td>
<p>The maximum values of lambda 3.</p>
</td></tr>
<tr><td><code id="genelambda.obo_+3A_lambda3_min">lambda3_min</code></td>
<td>
<p>The minimum values of lambda 3.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sequence of the tuning parameters (lambda1, lambda2, and lambda3).
</p>


<h3>Author(s)</h3>

<p>Mingyang Ren
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lambda &lt;- genelambda.obo(nlambda1=5,lambda1_max=0.5,lambda1_min=0.1, nlambda2=15,lambda2_max=1.5,
                         lambda2_min=0.1, nlambda3=10,lambda3_max=3.5,lambda3_min=0.5)
lambda
</code></pre>

<hr>
<h2 id='generate.data'>Data Generation</h2><span id='topic+generate.data'></span>

<h3>Description</h3>

<p>Data Generation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate.data(N,Mu0.list,Theta0.list,Sigma0.list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate.data_+3A_n">N</code></td>
<td>
<p>K0 * 1 vector, the sample sizes of subgroups.</p>
</td></tr>
<tr><td><code id="generate.data_+3A_mu0.list">Mu0.list</code></td>
<td>
<p>A list including K0 mean vectors (p * 1).</p>
</td></tr>
<tr><td><code id="generate.data_+3A_theta0.list">Theta0.list</code></td>
<td>
<p>A list including K0 precision matrices (p * p).</p>
</td></tr>
<tr><td><code id="generate.data_+3A_sigma0.list">Sigma0.list</code></td>
<td>
<p>A list including K0 correlation matrices (p * p).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The simulated data and the true parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200              # The sample size of each subgroup
p &lt;- 20               # The dimension of the precision matrix
K0 &lt;- 3               # The true number of subgroups
N &lt;- rep(n,K0)        # The sample sizes of K0 subgroups

################ The true parameters ################
mue &lt;- 1.5
nonnum &lt;- 4
mu01 &lt;- c(rep(mue,nonnum),rep(-mue,nonnum),rep(0,p-2*nonnum))
mu02 &lt;- c(rep(mue,2*nonnum),rep(0,p-2*nonnum))
mu03 &lt;- c(rep(-mue,2*nonnum),rep(0,p-2*nonnum))

# Power law network
set.seed(2)
A.list &lt;- Power.law.network(p,s=5,I2=c(1),I3=c(2))
Theta01 &lt;- A.list$A1
Theta02 &lt;- A.list$A2
Theta03 &lt;- A.list$A3
sigma01 &lt;- solve(Theta01)
sigma02 &lt;- solve(Theta02)
sigma03 &lt;- solve(Theta03)
Mu0.list &lt;- list(mu01,mu02,mu03)
Sigma0.list &lt;- list(sigma01,sigma02,sigma03)
Theta0.list &lt;- list(Theta01,Theta02,Theta03)

################ Generating simulated data ################
whole.data &lt;- generate.data(N,Mu0.list,Theta0.list,Sigma0.list)

</code></pre>

<hr>
<h2 id='GGMPF'>GGM-based heterogeneity analysis.</h2><span id='topic+GGMPF'></span>

<h3>Description</h3>

<p>The main function of Gaussian graphical model-based heterogeneity analysis via penalized fusion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GGMPF(lambda, data, K, initial.selection="K-means", initialize, average=F,
             asymmetric=T, eps = 5e-2, maxiter=10,
             maxiter.AMA=5, local_appro=T, trace = F, penalty = "MCP", theta.fusion=T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GGMPF_+3A_lambda">lambda</code></td>
<td>
<p>A list, the sequences of the tuning parameters (lambda1, lambda2, and lambda3).</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_data">data</code></td>
<td>
<p>n * p matrix, the design matrix.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_k">K</code></td>
<td>
<p>Int, a selected upper bound of K_0.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_initial.selection">initial.selection</code></td>
<td>
<p>The different initial values from two clustering methods, which can be selected from c(&quot;K-means&quot;,&quot;dbscan&quot;).</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_initialize">initialize</code></td>
<td>
<p>A given initial values, which should be given when initial.selection is not in c(&quot;K-means&quot;,&quot;dbscan&quot;).</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_average">average</code></td>
<td>
<p>The logical variable, whether to use averaging when integrating parameters that are identified as identical subgroups, the default setting is F, which means the estimated parameters for the subgroup with the largest sample size among the subgroups identified as identical subgroups is used as the final parameter for this subgroup.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_asymmetric">asymmetric</code></td>
<td>
<p>The logical variable, symmetry of the precision matrices or not, the default setting is T.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_eps">eps</code></td>
<td>
<p>A float value, algorithm termination threshold.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_maxiter">maxiter</code></td>
<td>
<p>Int, maximum number of cycles of the ADMM algorithm.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_maxiter.ama">maxiter.AMA</code></td>
<td>
<p>Int, maximum number of cycles of the AMA algorithm.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_local_appro">local_appro</code></td>
<td>
<p>The logical variable, whether to use local approximations when updating mean parameters, the default setting is T.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_trace">trace</code></td>
<td>
<p>The logical variable, whether or not to output the number of identified subgroups during the search for parameters.</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_penalty">penalty</code></td>
<td>
<p>The type of the penalty, which can be selected from c(&quot;MCP&quot;, &quot;SCAD&quot;, &quot;lasso&quot;).</p>
</td></tr>
<tr><td><code id="GGMPF_+3A_theta.fusion">theta.fusion</code></td>
<td>
<p>Whether or not the fusion penalty term contains elements of the precision matrices. The default setting is T.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including all estimated parameters and the BIC values with all choices of given tuning parameters, and the selected optional parameters.
</p>


<h3>Author(s)</h3>

<p>Mingyang Ren, Sanguo Zhang, Qingzhao Zhang, Shuangge Ma. Maintainer: Mingyang Ren &lt;renmingyang17@mails.ucas.ac.cn&gt;.
</p>


<h3>References</h3>

<p>Ren, M., Zhang S., Zhang Q. and Ma S. (2022). Gaussian Graphical Model-based Heterogeneity Analysis via Penalized Fusion. Biometrics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
######## Example 1: Generate simulation data and apply this method to analysis #######
n &lt;- 200              # The sample size of each subgroup
p &lt;- 20               # The dimension of the precision matrix
K0 &lt;- 3               # The true number of subgroups
N &lt;- rep(n,K0)        # The sample sizes of K0 subgroups
K &lt;- 6                # The given upper bound of K0.

################ The true parameters ################
mue &lt;- 1.5
nonnum &lt;- 4
mu01 &lt;- c(rep(mue,nonnum),rep(-mue,nonnum),rep(0,p-2*nonnum))
mu02 &lt;- c(rep(mue,2*nonnum),rep(0,p-2*nonnum))
mu03 &lt;- c(rep(-mue,2*nonnum),rep(0,p-2*nonnum))

# Power law network
set.seed(2)
A.list &lt;- Power.law.network(p,s=5,I2=c(1),I3=c(2))
Theta01 &lt;- A.list$A1
Theta02 &lt;- A.list$A2
Theta03 &lt;- A.list$A3
sigma01 &lt;- solve(Theta01)
sigma02 &lt;- solve(Theta02)
sigma03 &lt;- solve(Theta03)
Mu0.list &lt;- list(mu01,mu02,mu03)
Sigma0.list &lt;- list(sigma01,sigma02,sigma03)
Theta0.list &lt;- list(Theta01,Theta02,Theta03)

################ Generating simulated data ################
whole.data &lt;- generate.data(N,Mu0.list,Theta0.list,Sigma0.list)

################ The implementation and evaluation ################
lambda &lt;- genelambda.obo(nlambda1=5,lambda1_max=0.5,lambda1_min=0.1,
                         nlambda2=15,lambda2_max=1.5,lambda2_min=0.1,
                         nlambda3=10,lambda3_max=3.5,lambda3_min=0.5)
res &lt;- GGMPF(lambda, whole.data$data, K, initial.selection="K-means")
Theta_hat.list &lt;- res$Theta_hat.list
Mu_hat.list &lt;- res$Mu_hat.list
prob.list &lt;- res$prob.list
L.mat.list &lt;- res$L.mat.list
opt_num &lt;- res$Opt_num
opt_Theta_hat &lt;- Theta_hat.list[[opt_num]]
opt_Mu_hat &lt;- Mu_hat.list[[opt_num]]
opt_L.mat &lt;- L.mat.list[[opt_num]]
opt_prob &lt;- prob.list[[opt_num]]
K_hat &lt;- dim(opt_Theta_hat)[3]
K_hat


######## Example 2: Call the built-in simulation data set and analyze #######
data(example.data)
K &lt;- 6
lambda &lt;- genelambda.obo(nlambda1=5,lambda1_max=0.5,lambda1_min=0.1,
                         nlambda2=15,lambda2_max=1.5,lambda2_min=0.1,
                         nlambda3=10,lambda3_max=3.5,lambda3_min=0.5)
res &lt;- GGMPF(lambda, example.data$data, K, initial.selection="K-means")
Theta_hat.list &lt;- res$Theta_hat.list
opt_num &lt;- res$Opt_num
opt_Theta_hat &lt;- Theta_hat.list[[opt_num]]
K_hat &lt;- dim(opt_Theta_hat)[3]
K_hat


</code></pre>

<hr>
<h2 id='linked_node_names'>Indexes the names of all nodes connected to some particular nodes in a subgroup.</h2><span id='topic+linked_node_names'></span>

<h3>Description</h3>

<p>Indexes the names of all nodes connected to some particular nodes in a subgroup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linked_node_names(summ, va_names, num_subgroup=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linked_node_names_+3A_summ">summ</code></td>
<td>
<p>A list, the summary of the resulting network structures.</p>
</td></tr>
<tr><td><code id="linked_node_names_+3A_va_names">va_names</code></td>
<td>
<p>A vector, the names of nodes of interest.</p>
</td></tr>
<tr><td><code id="linked_node_names_+3A_num_subgroup">num_subgroup</code></td>
<td>
<p>Int, the subgroup numbering.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the names of connected nodes to the nodes of interest in a subgroup.
</p>

<hr>
<h2 id='PGGMBC'>Penalized GGM-based clustering.</h2><span id='topic+PGGMBC'></span>

<h3>Description</h3>

<p>The main function of penalized Gaussian graphical model-based clustering with unconstrained covariance matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PGGMBC(lambda, data, K, initial.selection="K-means", initialize, average=F,
              asymmetric=T, eps = 5e-2, maxiter=10,
              maxiter.AMA=5, local_appro=T, trace = F, penalty = "MCP")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PGGMBC_+3A_lambda">lambda</code></td>
<td>
<p>A list, the sequences of the tuning parameters (lambda1 and lambda2).</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_data">data</code></td>
<td>
<p>n * p matrix, the design matrix.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_k">K</code></td>
<td>
<p>Int, a given number of subgroups.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_initial.selection">initial.selection</code></td>
<td>
<p>The different initial values from two clustering methods, which can be selected from c(&quot;K-means&quot;,&quot;dbscan&quot;).</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_initialize">initialize</code></td>
<td>
<p>A given initial values, which should be given when initial.selection is not in c(&quot;K-means&quot;,&quot;dbscan&quot;).</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_average">average</code></td>
<td>
<p>The logical variable, whether to use averaging when integrating parameters that are identified as identical subgroups, the default setting is F, which means the estimated parameters for the subgroup with the largest sample size among the subgroups identified as identical subgroups is used as the final parameter for this subgroup.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_asymmetric">asymmetric</code></td>
<td>
<p>The logical variable, symmetry of the precision matrices or not, the default setting is T.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_eps">eps</code></td>
<td>
<p>A float value, algorithm termination threshold.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_maxiter">maxiter</code></td>
<td>
<p>Int, maximum number of cycles of the ADMM algorithm.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_maxiter.ama">maxiter.AMA</code></td>
<td>
<p>Int, maximum number of cycles of the AMA algorithm.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_local_appro">local_appro</code></td>
<td>
<p>The logical variable, whether to use local approximations when updating mean parameters, the default setting is T.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_trace">trace</code></td>
<td>
<p>The logical variable, whether or not to output the number of identified subgroups during the search for parameters.</p>
</td></tr>
<tr><td><code id="PGGMBC_+3A_penalty">penalty</code></td>
<td>
<p>The type of the penalty, which can be selected from c(&quot;MCP&quot;, &quot;SCAD&quot;, &quot;lasso&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including all estimated parameters and the BIC values with all choices of given tuning parameters, and the selected optional parameters.
</p>


<h3>Author(s)</h3>

<p>Mingyang Ren, Sanguo Zhang, Qingzhao Zhang, Shuangge Ma. Maintainer: Mingyang Ren &lt;renmingyang17@mails.ucas.ac.cn&gt;.
</p>


<h3>References</h3>

<p>Ren, M., Zhang S., Zhang Q. and Ma S. (2020). Gaussian Graphical Model-based Heterogeneity Analysis via Penalized Fusion. Biometrics, Published Online, https://doi.org/10.1111/biom.13426.
Zhou, H., Pan, W., &amp; Shen, X. (2009). Penalized model-based clustering with unconstrained covariance matrices. Electronic journal of statistics, 3, 1473.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
######## Example 1: Generate simulation data and apply this method to analysis #######
n &lt;- 200              # The sample size of each subgroup
p &lt;- 20               # The dimension of the precision matrix
K &lt;- 3               # The true number of subgroups
N &lt;- rep(n,K)        # The sample sizes of K subgroups

################ The true parameters ################
mue &lt;- 1.5
nonnum &lt;- 4
mu01 &lt;- c(rep(mue,nonnum),rep(-mue,nonnum),rep(0,p-2*nonnum))
mu02 &lt;- c(rep(mue,2*nonnum),rep(0,p-2*nonnum))
mu03 &lt;- c(rep(-mue,2*nonnum),rep(0,p-2*nonnum))

# Power law network
set.seed(2)
A.list &lt;- Power.law.network(p,s=5,I2=c(1),I3=c(2))
Theta01 &lt;- A.list$A1
Theta02 &lt;- A.list$A2
Theta03 &lt;- A.list$A3
sigma01 &lt;- solve(Theta01)
sigma02 &lt;- solve(Theta02)
sigma03 &lt;- solve(Theta03)
Mu0.list &lt;- list(mu01,mu02,mu03)
Sigma0.list &lt;- list(sigma01,sigma02,sigma03)
Theta0.list &lt;- list(Theta01,Theta02,Theta03)

################ Generating simulated data ################
whole.data &lt;- generate.data(N,Mu0.list,Theta0.list,Sigma0.list)

################ The implementation and evaluation of competitors ################
lambda &lt;- genelambda.obo(nlambda1=5,lambda1_max=0.5,lambda1_min=0.1,
                         nlambda2=15,lambda2_max=1.5,lambda2_min=0.1)
res &lt;- PGGMBC(lambda, whole.data$data, K, initial.selection="K-means")
Theta_hat.list &lt;- res$Theta_hat.list
Mu_hat.list &lt;- res$Mu_hat.list
prob.list &lt;- res$prob.list
L.mat.list &lt;- res$L.mat.list
opt_num &lt;- res$Opt_num
opt_Theta_hat &lt;- Theta_hat.list[[opt_num]]
opt_Mu_hat &lt;- Mu_hat.list[[opt_num]]
opt_L.mat &lt;- L.mat.list[[opt_num]]
opt_prob &lt;- prob.list[[opt_num]]

######## Example 2: Call the built-in simulation data set and analyze #######
data(example.data)
K &lt;- 3
lambda &lt;- genelambda.obo(nlambda1=5,lambda1_max=0.5,lambda1_min=0.1,
                         nlambda2=15,lambda2_max=1.5,lambda2_min=0.1)
res &lt;- PGGMBC(lambda, example.data$data, K, initial.selection="K-means")
Theta_hat.list &lt;- res$Theta_hat.list
opt_num &lt;- res$Opt_num
opt_Theta_hat &lt;- Theta_hat.list[[opt_num]]


</code></pre>

<hr>
<h2 id='plot_network'>Visualization of network structures.</h2><span id='topic+plot_network'></span>

<h3>Description</h3>

<p>Visualization of network structures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_network(summ, num_subgroup = 1, plot.mfrow,
                    vertex.size=2,vertex.label.cex=0.7,
                    vertex.label.dist=0.75, edge.width = 0.1, l=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_network_+3A_summ">summ</code></td>
<td>
<p>A list, the summary of the resulting network structures.</p>
</td></tr>
<tr><td><code id="plot_network_+3A_num_subgroup">num_subgroup</code></td>
<td>
<p>Int/vector, the subgroup numbering.</p>
</td></tr>
<tr><td><code id="plot_network_+3A_plot.mfrow">plot.mfrow</code></td>
<td>
<p>Figure Layout.</p>
</td></tr>
<tr><td><code id="plot_network_+3A_vertex.size">vertex.size</code></td>
<td>
<p>The vertex size.</p>
</td></tr>
<tr><td><code id="plot_network_+3A_vertex.label.cex">vertex.label.cex</code></td>
<td>
<p>The vertex label size.</p>
</td></tr>
<tr><td><code id="plot_network_+3A_vertex.label.dist">vertex.label.dist</code></td>
<td>
<p>The distance of vertex labels.</p>
</td></tr>
<tr><td><code id="plot_network_+3A_edge.width">edge.width</code></td>
<td>
<p>The edge width.</p>
</td></tr>
<tr><td><code id="plot_network_+3A_l">l</code></td>
<td>
<p>Node Coordinates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Visualization of network structure
</p>

<hr>
<h2 id='Power.law.network'>Power law network</h2><span id='topic+Power.law.network'></span>

<h3>Description</h3>

<p>Generating three s-block power-law precision matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Power.law.network(p, s = 10, umin = 0.1, umax = 0.4, I2 = 0, I3 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Power.law.network_+3A_p">p</code></td>
<td>
<p>The dimensions of the precision matrix.</p>
</td></tr>
<tr><td><code id="Power.law.network_+3A_s">s</code></td>
<td>
<p>The number of sub-networks.</p>
</td></tr>
<tr><td><code id="Power.law.network_+3A_umin">umin</code></td>
<td>
<p>The lower bound of non-zero elements on non-diagonal elements.</p>
</td></tr>
<tr><td><code id="Power.law.network_+3A_umax">umax</code></td>
<td>
<p>The upper bound of non-zero elements on non-diagonal elements.</p>
</td></tr>
<tr><td><code id="Power.law.network_+3A_i2">I2</code></td>
<td>
<p>The replacement blocks for the precision matrix of the second subgroup.</p>
</td></tr>
<tr><td><code id="Power.law.network_+3A_i3">I3</code></td>
<td>
<p>The replacement blocks for the precision matrix of the third subgroup.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including The precision matrices of three subgroups.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- 20               # The dimension of the precision matrix
################ The true parameters ################
# Power law network
set.seed(2)
A.list &lt;- Power.law.network(p,s=5,I2=c(1),I3=c(2))
Theta01 &lt;- A.list$A1
Theta02 &lt;- A.list$A2
Theta03 &lt;- A.list$A3
sigma01 &lt;- solve(Theta01)
sigma02 &lt;- solve(Theta02)
sigma03 &lt;- solve(Theta03)
Sigma0.list &lt;- list(sigma01,sigma02,sigma03)
Theta0.list &lt;- list(Theta01,Theta02,Theta03)

</code></pre>

<hr>
<h2 id='summary_network'>The summary of the resulting network structures.</h2><span id='topic+summary_network'></span>

<h3>Description</h3>

<p>Summarize the characteristics of the resulting network structures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary_network(opt_Mu_hat, opt_Theta_hat, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_network_+3A_opt_mu_hat">opt_Mu_hat</code></td>
<td>
<p>A p * K0_hat matrix, the optional mean vectors of K0_hat subgroups.</p>
</td></tr>
<tr><td><code id="summary_network_+3A_opt_theta_hat">opt_Theta_hat</code></td>
<td>
<p>n * p * K0_hat matrix, the optional precision matrices of K0_hat subgroups.</p>
</td></tr>
<tr><td><code id="summary_network_+3A_data">data</code></td>
<td>
<p>A n * p matrix, the design matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the overlap of edges of different subgroups, the number of edges, and the names of connected nodes to each nodes in each subgroup.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(example.data)
K &lt;- 6
lambda &lt;- genelambda.obo(nlambda1=5,lambda1_max=0.5,lambda1_min=0.1,
                         nlambda2=15,lambda2_max=1.5,lambda2_min=0.1,
                         nlambda3=10,lambda3_max=3.5,lambda3_min=0.5)

res &lt;- GGMPF(lambda, example.data$data, K, initial.selection="K-means")
Theta_hat.list &lt;- res$Theta_hat.list
Mu_hat.list &lt;- res$Mu_hat.list
opt_num &lt;- res$Opt_num
opt_Theta_hat &lt;- Theta_hat.list[[opt_num]]
opt_Mu_hat &lt;- Mu_hat.list[[opt_num]]
K_hat &lt;- dim(opt_Theta_hat)[3]
K_hat

summ &lt;- summary_network(opt_Mu_hat, opt_Theta_hat, example.data$data)
summ$Theta_summary$overlap
va_names &lt;- c("1","6")
linked_node_names(summ, va_names, num_subgroup=1)
plot_network(summ, num_subgroup = c(1:K_hat), plot.mfrow = c(1,K_hat))


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
