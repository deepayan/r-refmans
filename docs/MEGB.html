<!DOCTYPE html><html lang="en"><head><title>Help for package MEGB</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MEGB}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bay'><p>Title</p></a></li>
<li><a href='#logV'><p>Title</p></a></li>
<li><a href='#MEGB'><p>Mixed Effect Gradient Boosting (MEGB) Algorithm</p></a></li>
<li><a href='#predict.MEGB'><p>Predict with longitudinal trees and random forests.</p></a></li>
<li><a href='#sig'><p>Title</p></a></li>
<li><a href='#simLong'><p>Simulate Low/High Dimensional and Linear/Nonlinear Longitudinal dataset.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Gradient Boosting for Longitudinal Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Oyebayo Ridwan Olaniran [aut, cre],
  Saidat Fehintola Olaniran [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Oyebayo Ridwan Olaniran &lt;olaniran.or@unilorin.edu.ng&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Gradient boosting is a powerful statistical learning method known for its ability to model 
    complex relationships between predictors and outcomes while performing inherent variable selection. 
    However, traditional gradient boosting methods lack flexibility in handling longitudinal data where 
    within-subject correlations play a critical role. In this package, we propose a novel approach 
    Mixed Effect Gradient Boosting ('MEGB'), designed specifically for high-dimensional longitudinal data. 
    'MEGB' incorporates a flexible semi-parametric model that embeds random effects within the gradient boosting 
    framework, allowing it to account for within-individual covariance over time. Additionally, the method 
    efficiently handles scenarios where the number of predictors greatly exceeds the number of observations
    (p&gt;&gt;n) making it particularly suitable for genomics data and other large-scale biomedical studies.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, gbm, MASS, latex2exp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2.9000</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-24 13:47:19 UTC; USER</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-29 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bay'>Title</h2><span id='topic+bay'></span>

<h3>Description</h3>

<p>Title
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bay(bhat, Bhat, Z, id, sigmahat)
</code></pre>

<hr>
<h2 id='logV'>Title</h2><span id='topic+logV'></span>

<h3>Description</h3>

<p>Title
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logV(Y, f, Z, time, id, B, gamma, sigma)
</code></pre>

<hr>
<h2 id='MEGB'>Mixed Effect Gradient Boosting (MEGB) Algorithm</h2><span id='topic+MEGB'></span>

<h3>Description</h3>

<p>MEGB is an adaptation of the gradient boosting regression method to longitudinal data similar to the Mixed Effect Random Forest (MERF) developed by Hajjem et. al. (2014) &lt;doi:10.1080/00949655.2012.741599&gt; which was implemented by Capitaine et. al. (2020) &lt;doi:10.1177/0962280220946080&gt;.
The algorithm estimates the parameters of a semi-parametric mixed-effects model: </p>
<p style="text-align: center;"><code class="reqn">Y_i(t)=f(X_i(t))+Z_i(t)\beta_i+\epsilon_i</code>
</p>

<p>with <code class="reqn">Y_i(t)</code> the output at time <code class="reqn">t</code> for the <code class="reqn">i</code>th individual; <code class="reqn">X_i(t)</code> the input predictors (fixed effects) at time <code class="reqn">t</code> for the <code class="reqn">i</code>th individual;
<code class="reqn">Z_i(t)</code> are the random effects at time <code class="reqn">t</code> for the <code class="reqn">i</code>th individual;
<code class="reqn">\epsilon_i</code> is the residual error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MEGB(
  X,
  Y,
  id,
  Z,
  iter = 100,
  ntree = 500,
  time,
  shrinkage = 0.05,
  interaction.depth = 1,
  n.minobsinnode = 5,
  cv.folds = 0,
  delta = 0.001,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MEGB_+3A_x">X</code></td>
<td>
<p>[matrix]: A <code>N</code> x <code>p</code> matrix containing the <code>p</code> predictors of the fixed effects, column codes for a predictor.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_y">Y</code></td>
<td>
<p>[vector]: A vector containing the output trajectories.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_id">id</code></td>
<td>
<p>[vector]: Is the vector of the identifiers for the different trajectories.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_z">Z</code></td>
<td>
<p>[matrix]: A <code>N</code> x <code>q</code> matrix containing the <code>q</code> predictor of the random effects.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_iter">iter</code></td>
<td>
<p>[numeric]: Maximal number of iterations of the algorithm. The default is set to <code>iter=100</code></p>
</td></tr>
<tr><td><code id="MEGB_+3A_ntree">ntree</code></td>
<td>
<p>[numeric]: Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets predicted at least a few times. The default value is <code>ntree=500</code>.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_time">time</code></td>
<td>
<p>[vector]: Is the vector of the measurement times associated with the trajectories in <code>Y</code>,<code>Z</code> and <code>X</code>.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_shrinkage">shrinkage</code></td>
<td>
<p>[numeric]: a shrinkage parameter applied to each tree in the expansion. Also known as the learning rate or step-size reduction. The default value is set to 0.05.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_interaction.depth">interaction.depth</code></td>
<td>
<p>[numeric]: The maximum depth of variable interactions: 1 builds an additive model, 2 builds a model with up to two-way interactions, etc. The default value is set to 1.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_n.minobsinnode">n.minobsinnode</code></td>
<td>
<p>[numeric]: minimum number of observations (not total weights) in the terminal nodes of the trees. The default value is set to 5.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_cv.folds">cv.folds</code></td>
<td>
<p>[numeric]: Number of cross-validation folds to perform. If cv.folds&gt;1 then gbm, in addition to the usual fit, will perform a cross-validation and calculate an estimate of generalization error returned in cv_error. The default value is set to 0.</p>
</td></tr>
<tr><td><code id="MEGB_+3A_delta">delta</code></td>
<td>
<p>[numeric]: The algorithm stops when the difference in log likelihood between two iterations is smaller than <code>delta</code>. The default value is set to 0.001</p>
</td></tr>
<tr><td><code id="MEGB_+3A_verbose">verbose</code></td>
<td>
<p>[boolean]: If TRUE, MEGB will print out number of iterations to achieve convergence. Default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted MEGB model which is a list of the following elements: </p>

<ul>
<li> <p><code>forest:</code> GBMFit obtained at the last iteration.
</p>
</li>
<li> <p><code>random_effects :</code> Predictions of random effects for different trajectories.
</p>
</li>
<li> <p><code>id_btilde:</code> Identifiers of individuals associated with the predictions <code>random_effects</code>.
</p>
</li>
<li> <p><code>var_random_effects: </code> Estimation of the variance covariance matrix of random effects.
</p>
</li>
<li> <p><code>sigma: </code> Estimation of the residual variance parameter.
</p>
</li>
<li> <p><code>time: </code> The vector of the measurement times associated with the trajectories in <code>Y</code>,<code>Z</code> and <code>X</code>.
</p>
</li>
<li> <p><code>LL:</code> Log-likelihood of the different iterations.
</p>
</li>
<li> <p><code>id: </code> Vector of the identifiers for the different trajectories.
</p>
</li>
<li> <p><code>OOB: </code> OOB error of the fitted random forest at each iteration.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
data &lt;-simLong(n = 20,p = 6,rel_p = 6,time_points = 10,rho_W = 0.6, rho_Z=0.6,
              random_sd_intercept = sqrt(0.5),
              random_sd_slope = sqrt(3),
              noise_sd = 0.5,linear=TRUE)  # Generate the data composed by n=20 individuals.
# Train a MEGB model on the generated data. Should take ~ 7 seconds
megb &lt;-   MEGB(X=as.matrix(data[,-1:-5]),Y=as.matrix(data$Y),
Z=as.matrix(data[,4:5]),id=data$id,time=data$time,ntree=500,cv.folds=0,verbose=TRUE)
megb$forest # is the fitted gradient boosting (GBMFit) (obtained at the last iteration).
megb$random_effects # are the predicted random effects for each individual.
plot(megb$LL,type="o",col=2) # evolution of the log-likelihood.
megb$OOB # OOB error at each iteration.


</code></pre>

<hr>
<h2 id='predict.MEGB'>Predict with longitudinal trees and random forests.</h2><span id='topic+predict.MEGB'></span>

<h3>Description</h3>

<p>Predict with longitudinal trees and random forests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MEGB'
predict(object, X, Z, id, time, ntree, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.MEGB_+3A_object">object</code></td>
<td>
<p>: a <code>longituRF</code> output of (S)MERF; (S)REEMforest; (S)MERT or (S)REEMtree function.</p>
</td></tr>
<tr><td><code id="predict.MEGB_+3A_x">X</code></td>
<td>
<p>[matrix]: matrix of the fixed effects for the new observations to be predicted.</p>
</td></tr>
<tr><td><code id="predict.MEGB_+3A_z">Z</code></td>
<td>
<p>[matrix]: matrix of the random effects for the new observations to be predicted.</p>
</td></tr>
<tr><td><code id="predict.MEGB_+3A_id">id</code></td>
<td>
<p>[vector]: vector of the identifiers of the new observations to be predicted.</p>
</td></tr>
<tr><td><code id="predict.MEGB_+3A_time">time</code></td>
<td>
<p>[vector]: vector of the time measurements of the new observations to be predicted.</p>
</td></tr>
<tr><td><code id="predict.MEGB_+3A_ntree">ntree</code></td>
<td>
<p>[numeric]: Number of trees to be used in prediction not less than number of trees used in the model object MEGB. The default value is <code>ntree=500</code>.</p>
</td></tr>
<tr><td><code id="predict.MEGB_+3A_...">...</code></td>
<td>
<p>: low levels arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of the predicted output for the new observations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>oldpar &lt;- par(no.readonly = TRUE)
oldopt &lt;- options()
set.seed(1)
data &lt;-simLong(n = 20,p = 6,rel_p = 6,time_points = 10,rho_W = 0.6, rho_Z=0.6,
              random_sd_intercept = sqrt(0.5),
              random_sd_slope = sqrt(3),
              noise_sd = 0.5,linear=TRUE)  # Generate the data composed by n=20 individuals.
# Train a MEGB model on the generated data. Should take ~ 7 seconds
megb &lt;-   MEGB(X=as.matrix(data[,-1:-5]),Y=as.matrix(data$Y),
Z=as.matrix(data[,4:5]),id=data$id,time=data$time,ntree=500,verbose=TRUE)
# Then we predict on the learning sample :
pred.MEGB &lt;- predict(megb, X=as.matrix(data[,-1:-5]), Z=as.matrix(data[,4:5]),
id=data$id, time=data$time,ntree=500)
# Let's have a look at the predictions
# the predictions are in red while the real output trajectories are in blue:
par(mfrow=c(4,5),mar=c(2,2,2,2))
for (i in unique(data$id)){
  w &lt;- which(data$id==i)
  plot(data$time[w],data$Y[w],type="l",col="blue")
  lines(data$time[w],pred.MEGB[w], col="red")
}
par(oldpar)
options(oldopt)

</code></pre>

<hr>
<h2 id='sig'>Title</h2><span id='topic+sig'></span>

<h3>Description</h3>

<p>Title
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sig(sigma, id, Z, epsilon, Btilde)
</code></pre>

<hr>
<h2 id='simLong'>Simulate Low/High Dimensional and Linear/Nonlinear Longitudinal dataset.</h2><span id='topic+simLong'></span>

<h3>Description</h3>

<p>Simulate p-dimensional linear/Nonlinear mixed-effects model given by: </p>
<p style="text-align: center;"><code class="reqn">Y_i(t)=f(X_i(t))+Z_i(t)\beta_i+\epsilon_i</code>
</p>

<p>with <code class="reqn">Y_i(t)</code> the output at time <code class="reqn">t</code> for the <code class="reqn">i</code>th individual; <code class="reqn">X_i(t)</code> the input predictors (fixed effects) at time <code class="reqn">t</code> for the <code class="reqn">i</code>th individual;
<code class="reqn">Z_i(t)</code> are the random effects at time <code class="reqn">t</code> for the <code class="reqn">i</code>th individual; <code class="reqn">\epsilon_i</code> is the residual error with
variance <code class="reqn">\sigma^2</code>. If linear, <code class="reqn">f(X_i(t)) = X_i(t)\theta</code>, where <code class="reqn">\theta = 1, \forall p</code>, otherwise if nonlinear, the
approach by Capitaine et al. (2021) is adapted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simLong(
  n,
  p,
  rel_p = 6,
  time_points,
  rho_W = 0.5,
  rho_Z = 0.5,
  random_sd_intercept = 2,
  random_sd_slope = 1,
  noise_sd = 1,
  linear = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simLong_+3A_n">n</code></td>
<td>
<p>[numeric]: Number of individuals.</p>
</td></tr>
<tr><td><code id="simLong_+3A_p">p</code></td>
<td>
<p>[numeric]: Number of predictors.</p>
</td></tr>
<tr><td><code id="simLong_+3A_rel_p">rel_p</code></td>
<td>
<p>[numeric]: Number of relevant predictors (true predictors that are correlated to the outcome.). The default value is <code>rel_p=6</code> if linear and <code>rel_p=2</code> if nonlinear.</p>
</td></tr>
<tr><td><code id="simLong_+3A_time_points">time_points</code></td>
<td>
<p>[numeric]: Number of realizations per individual.  The default value is <code>time_points=10</code>.</p>
</td></tr>
<tr><td><code id="simLong_+3A_rho_w">rho_W</code></td>
<td>
<p>[numeric]: Within subject correlation. The default value is <code>rho_W=0.5</code>.</p>
</td></tr>
<tr><td><code id="simLong_+3A_rho_z">rho_Z</code></td>
<td>
<p>[numeric]: Correlation between intercept and slope for the random effect coefficients. The default value is <code>rho_Z=0.5</code>.</p>
</td></tr>
<tr><td><code id="simLong_+3A_random_sd_intercept">random_sd_intercept</code></td>
<td>
<p>[numeric]: Standard deviation for the random intercept. The default value is <code>random_sd_intercept=</code><code class="reqn">\sqrt{0.5}</code>.</p>
</td></tr>
<tr><td><code id="simLong_+3A_random_sd_slope">random_sd_slope</code></td>
<td>
<p>[numeric]: Standard deviation for the random slope. The default value is <code>random_sd_slope=</code><code class="reqn">\sqrt{3}</code>.</p>
</td></tr>
<tr><td><code id="simLong_+3A_noise_sd">noise_sd</code></td>
<td>
<p>[numeric]: Standard deviation for the random slope. The default value is <code>noise_sd=0.5</code>.</p>
</td></tr>
<tr><td><code id="simLong_+3A_linear">linear</code></td>
<td>
<p>[boolean]: If TRUE, a linear mixed effect model is simulated, if otherwise, a semi-parametric model similar to the one used in Capitaine et al. (2021).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a dataframe of dimension (n*time_points) by (p+5) containing the following elements: </p>

<ul>
<li> <p><code>id:</code> vector of the individual IDs.
</p>
</li>
<li> <p><code>time:</code> vector of the time realizations.
</p>
</li>
<li> <p><code>Y:</code> vector of the outcomes variable.
</p>
</li>
<li> <p><code>RandomIntercept:</code> vector of the Random Intercept.
</p>
</li>
<li> <p><code>RandomSlope:</code> vector of the Random Slope.
</p>
</li>
<li> <p><code>Vars :</code> Remainder columns corresponding to the fixed effect variables.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
data = simLong(n = 17,p = 6,rel_p = 6,time_points = 10,rho_W = 0.6, rho_Z=0.6,
              random_sd_intercept = sqrt(0.5),
              random_sd_slope = sqrt(3),
              noise_sd = 0.5,linear=FALSE) # Generate the data
head(data)   # first six rows of the data.
# Let's see the output :
w &lt;- which(data$id==1)
plot(data$time[w],data$Y[w],type="l",ylim=c(min(data$Y),max(data$Y)), col="grey")
for (i in unique(data$id)){
  w &lt;- which(data$id==i)
  lines(data$time[w],data$Y[w], col='grey')
}
# Let's see the fixed effects predictors:
oldpar &lt;- par(no.readonly = TRUE)
oldopt &lt;- options()
par(mfrow=c(2,3), mar=c(2,3,3,2))
for (i in 1:ncol(data[,-1:-5])){
  w &lt;- which(data$id==1)
  plot(data$time[w],data[,-1:-5][w,i], col="grey",ylim=c(min(data[,-1:-5][,i]),
  max(data[,-1:-5][,i])),xlim=c(1,max(data$time)),main=latex2exp::TeX(paste0("$X^{(",i,")}$")))
  for (k in unique(data$id)){
    w &lt;- which(data$id==k)
    lines(data$time[w],data[,-1:-5][w,i], col="grey")
  }
}
par(oldpar)
options(oldopt)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
