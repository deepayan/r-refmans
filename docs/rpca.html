<!DOCTYPE html><html><head><title>Help for package rpca</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rpca}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#F2norm'>
<p>Frobenius norm of a matrix</p></a></li>
<li><a href='#rpca'>
<p>Decompose a matrix into a low-rank component and a sparse component by solving Principal Components Pursuit</p></a></li>
<li><a href='#rpca-package'>
<p>RobustPCA: Decompose a Matrix into Low-Rank and Sparse Components</p></a></li>
<li><a href='#thresh.l1'>
<p>Shrinkage operator</p></a></li>
<li><a href='#thresh.nuclear'>
<p>Thresholding operator</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>RobustPCA: Decompose a Matrix into Low-Rank and Sparse
Components</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-07-19</td>
</tr>
<tr>
<td>Author:</td>
<td>Maciek Sykulski [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Maciek Sykulski &lt;macieksk@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Candes, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 11. prove that we can recover each component individually under some suitable assumptions. It is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the L1 norm. This package implements this decomposition algorithm resulting with Robust PCA approach.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>compiler</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2015-07-30 22:24:20 UTC; macieksk</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2015-07-31 01:15:38</td>
</tr>
</table>
<hr>
<h2 id='F2norm'>
Frobenius norm of a matrix
</h2><span id='topic+F2norm'></span>

<h3>Description</h3>

<p>Frobenius norm of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>F2norm(M)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F2norm_+3A_m">M</code></td>
<td>
<p> A matrix. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Frobenius norm of M.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is currently defined as
function (M) 
sqrt(sum(M^2))

F2norm(matrix(runif(100),nrow=5))
</code></pre>

<hr>
<h2 id='rpca'>
Decompose a matrix into a low-rank component and a sparse component by solving Principal Components Pursuit
</h2><span id='topic+rpca'></span>

<h3>Description</h3>

<p>This function decomposes a rectangular matrix <var>M</var> into a low-rank component, and a sparse component, by solving a convex program called Principal Component Pursuit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpca(M, 
     lambda = 1/sqrt(max(dim(M))), mu = prod(dim(M))/(4 * sum(abs(M))), 
     term.delta = 10^(-7), max.iter = 5000, trace = FALSE,
     thresh.nuclear.fun = thresh.nuclear, thresh.l1.fun = thresh.l1, 
     F2norm.fun = F2norm)




</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpca_+3A_m">M</code></td>
<td>
<p> a rectangular matrix that is to be decomposed into a low-rank component and a sparse component
<code class="reqn">M = L + S</code> .
</p>
</td></tr>
<tr><td><code id="rpca_+3A_lambda">lambda</code></td>
<td>

<p>parameter of the convex problem <code class="reqn">\|L\|_{*} + \lambda \|S\|_{1} </code>
which is minimized in the Principal Components Pursuit algorithm. 
The default value is the one suggested in Candès, E. J., section 1.4, 
and together with reasonable assumptions about <var>L</var> and <var>S</var> 
guarantees that a correct decomposition is obtained.
</p>
</td></tr>
<tr><td><code id="rpca_+3A_mu">mu</code></td>
<td>

<p>parameter from the augumented Lagrange multiplier formulation of the PCP, Candès, E. J., section 5. 
Default value is the one suggested in references.
</p>
</td></tr>
<tr><td><code id="rpca_+3A_term.delta">term.delta</code></td>
<td>

<p>The algorithm terminates when <code class="reqn">\|M-L-S\|_{F} \leq \delta \|M\|_{F}</code> 
where <code class="reqn">\|\ \|_{F}</code> is Frobenius norm of a matrix. 

</p>
</td></tr>
<tr><td><code id="rpca_+3A_max.iter">max.iter</code></td>
<td>

<p>Maximal number of iterations of the augumented Lagrange multiplier algorithm. 
A warning is issued if the algorithm does not converge by then.
</p>
</td></tr>
<tr><td><code id="rpca_+3A_trace">trace</code></td>
<td>

<p>Print out information with every iteration. 
</p>
</td></tr>



<tr><td><code id="rpca_+3A_thresh.nuclear.fun">thresh.nuclear.fun</code>, <code id="rpca_+3A_thresh.l1.fun">thresh.l1.fun</code>, <code id="rpca_+3A_f2norm.fun">F2norm.fun</code></td>
<td>

<p>Arguments for internal use only.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions decompose a rectangular matrix <var>M</var> into a low-rank component, and a sparse component, by solving a convex program called Principal Component Pursuit:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{minimize}\quad   \|L\|_{*} + \lambda \|S\|_{1} </code>
</p>
                                                                    
<p style="text-align: center;"><code class="reqn"> \textrm{subject to}\quad   L+S = M </code>
</p>

<p>where <code class="reqn">\|L\|_{*}</code> is the nuclear norm of <var>L</var> (sum of singular values).
</p>


<h3>Value</h3>

<p>The function returns two matrices <code>S</code> and <code>L</code>, which have the property that 
<code class="reqn">L+S \simeq M</code>, where the quality of the approximation depends on the argument <code>term.delta</code>,
and the convergence of the algorithm.


</p>
<table>
<tr><td><code>S</code></td>
<td>
<p>The sparse component of the matrix decomposition.</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>The low-rank component of the matrix decomposition.</p>
</td></tr>
<tr><td><code>L.svd</code></td>
<td>
<p>The singular value decomposition of <code>L</code>, as returned by the function <code>La.svd</code> .</p>
</td></tr>
<tr><td><code>convergence$converged</code></td>
<td>
<p><code>TRUE</code> if the algorithm converged with respect to <code>term.delta</code>.</p>
</td></tr>
<tr><td><code>convergence$iterations</code></td>
<td>
<p>Number of performed iterations.</p>
</td></tr>
<tr><td><code>convergence$final.delta</code></td>
<td>
<p>The final iteration <code>delta</code> which is compared with <code>term.delta</code>.</p>
</td></tr>
<tr><td><code>convergence$all.delta</code></td>
<td>
<p>All <code>delta</code> from all iterations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maciek Sykulski [aut, cre]
</p>


<h3>References</h3>

<p>Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 11.
</p>
<p>Yuan, X., &amp; Yang, J. (2009). Sparse and low-rank matrix decomposition via alternating direction methods. preprint, 12.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
M &lt;- as.matrix(iris[,1:4])
Mcent &lt;- sweep(M,2,colMeans(M))

res &lt;- rpca(Mcent)

## Check convergence and number of iterations
with(res$convergence,list(converged,iterations))
## Final delta F2 norm divided by F2norm(Mcent)
with(res$convergence,final.delta)

## Check properites of the decomposition
with(res,c(
all(abs( L+S - Mcent ) &lt; 10^-5),
all( L == L.svd$u%*%(L.svd$d*L.svd$vt) )
))
# [1] TRUE TRUE

## The low rank component has rank 2
length(res$L.svd$d)
## However, the sparse component is not sparse 
## - thus this data set is not the best example here.
mean(res$S==0)

## Plot the first (the only) two principal components
## of the low-rank component L
rpc&lt;-res$L.svd$u%*%diag(res$L.svd$d)
plot(jitter(rpc[,1:2],amount=.001),col=iris[,5])

## Compare with classical principal components
pc &lt;- prcomp(M,center=TRUE)
plot(pc$x[,1:2],col=iris[,5])
points(rpc[,1:2],col=iris[,5],pch="+")

## "Sparse" elements distribution
plot(density(abs(res$S),from=0))
curve(dexp(x,rate=1/mean(abs(res$S))),add=TRUE,lty=2)

## Plot measurements against measurements corrected by sparse components
par(mfcol=c(2,2))
for(i in 1:4) {
plot(M[,i],M[,i]-res$S[,i],col=iris[,5],xlab=colnames(M)[i])
}
</code></pre>

<hr>
<h2 id='rpca-package'>
RobustPCA: Decompose a Matrix into Low-Rank and Sparse Components
</h2><span id='topic+rpca-package'></span>

<h3>Description</h3>

<p>Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Candes, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 11. prove that we can recover each component individually under some suitable assumptions. It is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the L1 norm. This package implements this decomposition algorithm resulting with Robust PCA approach.
</p>


<h3>Details</h3>



<p>Index of help topics:
</p>
<pre>
F2norm                  Frobenius norm of a matrix
rpca                    Decompose a matrix into a low-rank component
                        and a sparse component by solving Principal
                        Components Pursuit
rpca-package            RobustPCA: Decompose a Matrix into Low-Rank and
                        Sparse Components
thresh.l1               Shrinkage operator
thresh.nuclear          Thresholding operator
</pre>


<p>This package contains <code><a href="#topic+rpca">rpca</a></code> function,

which decomposes 
a rectangular matrix <var>M</var> into a low-rank component, and a sparse component, by solving a convex program called Principal Component Pursuit:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{minimize}\quad   \|L\|_{*} + \lambda \|S\|_{1} </code>
</p>
                                                                    
<p style="text-align: center;"><code class="reqn"> \textrm{subject to}\quad   L+S = M </code>
</p>

<p>where <code class="reqn">\|L\|_{*}</code> is the nuclear norm of <var>L</var> (sum of singular values).
</p>


<h3>Note</h3>

<p>Use <code>citation("rpca")</code> to cite this <span class="rlang"><b>R</b></span> package.
</p>


<h3>Author(s)</h3>

<p>Maciek Sykulski [aut, cre]
</p>
<p>Maintainer: Maciek Sykulski &lt;macieksk@gmail.com&gt;
</p>


<h3>References</h3>

<p>Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 11.
</p>
<p>Yuan, X., &amp; Yang, J. (2009). Sparse and low-rank matrix decomposition via alternating direction methods. preprint, 12.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpca-package">rpca</a></code> 
</p>

<hr>
<h2 id='thresh.l1'>
Shrinkage operator
</h2><span id='topic+thresh.l1'></span>

<h3>Description</h3>

<p>Shrinkage operator: S[x] = sgn(x) max(|x| - thr, 0). For description see section 5 of Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thresh.l1(x, thr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thresh.l1_+3A_x">x</code></td>
<td>
<p> a vector or a matrix.
</p>
</td></tr>
<tr><td><code id="thresh.l1_+3A_thr">thr</code></td>
<td>

<p>threshold &gt;= 0 to shrink with.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>S[x] = sgn(x) max(|x| - thr, 0)
</p>


<h3>References</h3>

<p>Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 11
</p>
<p>Yuan, X., &amp; Yang, J. (2009). Sparse and low-rank matrix decomposition via alternating direction methods. preprint, 12.
</p>


<h3>See Also</h3>


<p><code><a href="#topic+thresh.nuclear">thresh.nuclear</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is currently defined as
function(x,thr){sign(x)*pmax(abs(x)-thr,0)}

summary(thresh.l1(runif(100),0.3))
</code></pre>

<hr>
<h2 id='thresh.nuclear'>
Thresholding operator
</h2><span id='topic+thresh.nuclear'></span>

<h3>Description</h3>

<p>Thresholding operator, an application of the shrinkage operator on a singular value decomposition: D[X] = U S[Sigma] V .
For description see section 5 of Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thresh.nuclear(M, thr)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thresh.nuclear_+3A_m">M</code></td>
<td>
<p> a rectangular matrix.
</p>
</td></tr>
<tr><td><code id="thresh.nuclear_+3A_thr">thr</code></td>
<td>

<p>threshold &gt;= 0 to shrink singular values with.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returned is a thresholded Singular Value Decomposition with <code>thr</code> subtracted from singular values, 
and values smaller than 0 dropped together with their singular vectors. 
</p>
<table>
<tr><td><code>u</code>, <code>d</code>, <code>vt</code></td>
<td>
<p>as in return value of <code>La.svd</code></p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>the resulting low-rank matrix: <code class="reqn">L = U D V^t</code> </p>
</td></tr>
</table>


<h3>References</h3>

<p>Candès, E. J., Li, X., Ma, Y., &amp; Wright, J. (2011). Robust principal component analysis?. Journal of the ACM (JACM), 58(3), 11
</p>
<p>Yuan, X., &amp; Yang, J. (2009). Sparse and low-rank matrix decomposition via alternating direction methods. preprint, 12.
</p>


<h3>See Also</h3>


<p><code><a href="#topic+thresh.l1">thresh.l1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The function is currently defined as
function (M, thr) {
    s &lt;- La.svd.cmp(M)
    dd &lt;- thresh.l1(s$d, thr)
    id &lt;- which(dd != 0)
    s$d &lt;- dd[id]
    s$u &lt;- s$u[, id, drop = FALSE]
    s$vt &lt;- s$vt[id, , drop = FALSE]
    s$L &lt;- s$u %*% (s$d * s$vt)
    s
  }

l&lt;-thresh.nuclear(matrix(runif(600),nrow=20),2)
l$d
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
