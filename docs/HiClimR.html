<!DOCTYPE html><html><head><title>Help for package HiClimR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HiClimR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coarseR'><p>Coarsening spatial resolution for gridded data</p></a></li>
<li><a href='#fastCor'><p>Fast correlation for large matrices</p></a></li>
<li><a href='#geogMask'><p>Geographic mask from longitude and latitude</p></a></li>
<li><a href='#grid2D'><p>Generate longitude and latitude grid matrices</p></a></li>
<li><a href='#HiClimR'><p>Hierarchical Climate Regionalization</p></a></li>
<li><a href='#HiClimR2nc'><p>Export NetCDF-4 file for Hierarchical Climate Regionalization</p></a></li>
<li><a href='#minSigCor'><p>Minimum significant correlation for a sample size</p></a></li>
<li><a href='#TestCase'><p>Test Data for Functionality Demonstration of <code>HiClimR</code> Package</p></a></li>
<li><a href='#validClimR'><p>Validation of Hierarchical Climate Regionalization</p></a></li>
<li><a href='#WorldMask'><p>World Mask for Geographic Masking in HiClimR</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Hierarchical Climate Regionalization</td>
</tr>
<tr>
<td>Description:</td>
<td>A tool for Hierarchical Climate Regionalization applicable to any correlation-based clustering.
             It adds several features and a new clustering method (called, 'regional' linkage) to hierarchical
             clustering in R ('hclust' function in 'stats' library): data regridding, coarsening spatial resolution,
             geographic masking, contiguity-constrained clustering, data filtering by mean and/or variance
             thresholds, data preprocessing (detrending, standardization, and PCA), faster correlation function
             with preliminary big data support, different clustering methods, hybrid hierarchical clustering,
             multivariate clustering (MVC), cluster validation, visualization of regionalization results, and
             exporting region map and mean timeseries into NetCDF-4 file.
             The technical details are described in Badr et al. (2015) &lt;<a href="https://doi.org/10.1007%2Fs12145-015-0221-7">doi:10.1007/s12145-015-0221-7</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://hsbadr.github.io/HiClimR/">https://hsbadr.github.io/HiClimR/</a>,
<a href="https://github.com/hsbadr/HiClimR">https://github.com/hsbadr/HiClimR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/hsbadr/HiClimR/issues">https://github.com/hsbadr/HiClimR/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats, utils, ncdf4</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, devtools, knitr, rmarkdown, roxygen2, spelling,
testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Biarch:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>NetCDF (&gt;= 4.1)</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-20 18:52:03 UTC; hbadr1</td>
</tr>
<tr>
<td>Author:</td>
<td>Hamada S. Badr <a href="https://orcid.org/0000-0002-9808-2344"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Benjamin F. Zaitchik
    <a href="https://orcid.org/0000-0002-0698-0658"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Amin K. Dezfuli <a href="https://orcid.org/0000-0003-3274-8542"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hamada S. Badr &lt;badr@jhu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-20 20:02:52 UTC</td>
</tr>
</table>
<hr>
<h2 id='coarseR'>Coarsening spatial resolution for gridded data</h2><span id='topic+coarseR'></span>

<h3>Description</h3>

<p><code><a href="#topic+coarseR">coarseR</a></code> is a helper function that helps coarsening spatial
resolution of the input matrix for the <code><a href="#topic+HiClimR">HiClimR</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coarseR(x = x, lon = lon, lat = lat, lonStep = 1, latStep = 1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coarseR_+3A_x">x</code></td>
<td>
<p>an (<code>N</code> rows by <code>M</code> columns) matrix of 'double' values:
<code>N</code> objects (spatial points or stations) to be clustered by <code>M</code>
observations (temporal points or years). For gridded data, the <code>N</code>
objects should be created from the original matrix <code>x0</code> using
<code>as.vector(t(x0))</code>, where <code>x0</code> is an (<code>n</code> rows by
<code>m</code> columns) matrix, <code>n = length(unique(lon))</code> and
<code>m = length(unique(lat))</code>.</p>
</td></tr>
<tr><td><code id="coarseR_+3A_lon">lon</code></td>
<td>
<p>a vector of longitudes with length <code>N</code>. For gridded data,
the length may have the value (<code>n</code>) provided that <code>n * m = N</code> where
<code>n = length(unique(lon))</code> and <code>m = length(unique(lat))</code>.</p>
</td></tr>
<tr><td><code id="coarseR_+3A_lat">lat</code></td>
<td>
<p>a vector of latitudes with length <code>N</code> or <code>m</code>. See <code>lon</code>.</p>
</td></tr>
<tr><td><code id="coarseR_+3A_lonstep">lonStep</code></td>
<td>
<p>an integer greater than or equal to <code>1</code> for longitude
step to coarsen gridded data in the longitudinal direction. If <code>lonStep = 1</code>,
gridded data will not be coarsened in the longitudinal direction (the default).
If <code>lonStep = 2</code>, every other grid in longitudinal direction will be retained.</p>
</td></tr>
<tr><td><code id="coarseR_+3A_latstep">latStep</code></td>
<td>
<p>an integer greater than or equal to <code>1</code> for latitude
step to coarsen gridded data in the latitudinal direction. If <code>latStep = 1</code>,
gridded data will not be coarsened in the latitudinal direction (the default).
If <code>latStep = 2</code>, every other grid in latitudinal direction will be retained.
<code>lonStep</code> and <code>latStep</code> are independent so that user can optionally
apply different coarsening level to each dimension.</p>
</td></tr>
<tr><td><code id="coarseR_+3A_verbose">verbose</code></td>
<td>
<p>logical to print processing information if <code>verbose = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For high-resolution data, the computational and memory requirements may not be
met on old machines. This function enables the user to use coarser data in any
spatial dimension:longitude, latitude, or both. It is available  for testing
or running <code>HiClimR</code> package on old computers or machines with small memory
resources. The rows of output matrix (<code>x</code> component) will be also named
by longitude and latitude coordinates. If <code>lonStep = 1</code> and <code>latStep = 1</code>,
<code><a href="#topic+coarseR">coarseR</a></code> function will just rename rows of matrix <code>x</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>lon</code></td>
<td>
<p>longitude mesh vector for the coarsened data.</p>
</td></tr>
<tr><td><code>lat</code></td>
<td>
<p>latitude mesh vector for the coarsened data.</p>
</td></tr>
<tr><td><code>rownum</code></td>
<td>
<p>original row numbers for the coarsened data.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>coarsened data of the input data matrix <code>x</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F., and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F., and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>,
<code><a href="#topic+geogMask">geogMask</a></code>, <code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>,
<code><a href="#topic+grid2D">grid2D</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

## Load test case data
x &lt;- TestCase$x

## Generate longitude and latitude mesh vectors
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)

## Coarsening spatial resolution
xc &lt;- coarseR(x = x, lon = lon, lat = lat, lonStep = 2, latStep = 2)
lon &lt;- xc$lon
lat &lt;- xc$lat
x &lt;- xc$x
</code></pre>

<hr>
<h2 id='fastCor'>Fast correlation for large matrices</h2><span id='topic+fastCor'></span>

<h3>Description</h3>

<p><code><a href="#topic+fastCor">fastCor</a></code> is a helper function that compute Pearson correlation matrix
for <code><a href="#topic+HiClimR">HiClimR</a></code> and <code><a href="#topic+validClimR">validClimR</a></code> functions. It is similar
to <code><a href="stats.html#topic+cor">cor</a></code> function in R but uses a faster implementation on 64-bit
machines (an optimized <code>BLAS</code> library is highly recommended). <code><a href="#topic+fastCor">fastCor</a></code>
also uses a memory-efficient algorithm that allows for splitting the data matrix and
only compute the upper-triangular part of the correlation matrix. It can be used to
compute correlation matrix for the columns of any data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastCor(xt, nSplit = 1, upperTri = FALSE, optBLAS = FALSE, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastCor_+3A_xt">xt</code></td>
<td>
<p>an (<code>M</code> rows by <code>N</code> columns) matrix of 'double' values:
<code>N</code> objects (spatial points or stations) to be clustered by <code>M</code>
observations (temporal points or years). It is the transpose of the input
matrix <code>x</code> required for <code><a href="#topic+HiClimR">HiClimR</a></code> and
<code><a href="#topic+validClimR">validClimR</a></code> functions.</p>
</td></tr>
<tr><td><code id="fastCor_+3A_nsplit">nSplit</code></td>
<td>
<p>integer number greater than or equal to one, to split the data matrix into
<code>nSplit</code> splits of the total number of columns <code>ncol(xt)</code>. If <code>nSplit = 1</code>,
the default method will be used to compute correlation matrix for the full data matrix
(no splits). If <code>nSplit &gt; 1</code>, the correlation matrix (or the upper-triangular part
if <code>upperTri = TRUE</code>) will be allocated and filled with the computed correlation
sub-matrix for each split. the first <code>n-1</code> splits have equal size while the last
split may include any remaining columns. This is used with <code>upperTri = TRUE</code> to
compute only the upper-triangular part of the correlation matrix. The maximum number of
splits <code>nSplitMax = floor(N / 2)</code> makes splits with 2 columns;
if <code>nSplit &gt; nSplitMax</code>, <code>nSplitMax</code> will be used. Very large number of splits
<code>nSplit</code> makes computation slower but it could handle big data or if the available
memory is not enough to allocate the correlation matrix, which helps in solving the
&ldquo;Error: cannot allocate vector of size...&rdquo; memory limitation problem. It is
recommended to start with a small number of splits. If the data is very large
compared to the physical memory, it is highly recommended to use a 64-Bit machine
with enough memory resources and/or use coarsening feature for gridded data by setting
<code>lonStep &gt; 1</code> and <code>latStep &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="fastCor_+3A_uppertri">upperTri</code></td>
<td>
<p>logical to compute only the upper-triangular half of the correlation
matrix if <code>upperTri = TRUE</code> and <code>nSplit &gt; 1</code>., which includes all required info
since the correlation/dissimilarity matrix is symmetric. This almost halves memory use,
which can be very important for big data.</p>
</td></tr>
<tr><td><code id="fastCor_+3A_optblas">optBLAS</code></td>
<td>
<p>logical to use optimized BLAS library if installed and <code>optBLAS = TRUE</code>
only on 64-bit machines.</p>
</td></tr>
<tr><td><code id="fastCor_+3A_verbose">verbose</code></td>
<td>
<p>logical to print processing information if <code>verbose = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+fastCor">fastCor</a></code> function computes the correlation matrix by
calling the cross product function in the Basic Linear Algebra Subroutines
(BLAS) library used by R. A significant performance improvement can be
achieved when building R on 64-bit machines with an optimized BLAS library,
such as <em>ATLAS</em>, <em>OpenBLAS</em>, or the commercial <em>Intel MKL</em>.
For big data, the memory required to allocate the square matrix of correlations
may exceed the total amount of physical memory available resulting in
&ldquo;Error: cannot allocate vector of size...&rdquo;. <code><a href="#topic+fastCor">fastCor</a></code> allows
for splitting the data matrix into <code>nSplit</code> splits and only computes the
upper-triangular part of the correlation matrix with <code>upperTri = TRUE</code>.
This almost halves memory use, which can be very important for big data.
If <code>nSplit &gt; 1</code>, the correlation matrix (or the upper-triangular part if
<code>upperTri = TRUE</code>) will be allocated and filled with computed correlation
sub-matrix for each split. the first <code>n-1</code> splits have equal size while
the last split may include any remaining columns.
</p>


<h3>Value</h3>

<p>An (<code>N</code> rows by <code>N</code> columns) correlation matrix.
</p>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>,
<code><a href="#topic+geogMask">geogMask</a></code>, <code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>,
<code><a href="#topic+grid2D">grid2D</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

## Load test case data
x &lt;- TestCase$x

## Use fastCor function to compute the correlation matrix
t0 &lt;- proc.time() ; xcor &lt;- fastCor(t(x)) ; proc.time() - t0
## compare with cor function
t0 &lt;- proc.time() ; xcor0 &lt;- cor(t(x)) ; proc.time() - t0

## Not run: 

## Split the data into 10 splits and return upper-triangular half only
xcor10 &lt;- fastCor(t(x), nSplit = 10, upperTri = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='geogMask'>Geographic mask from longitude and latitude</h2><span id='topic+geogMask'></span>

<h3>Description</h3>

<p><code><a href="#topic+geogMask">geogMask</a></code> is a helper function that preprocess input for the
<code><a href="#topic+HiClimR">HiClimR</a></code> via <code>geogMask</code> parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geogMask(continent = NULL, region = NULL, country = NULL, lon = NULL, lat = NULL,
  InDispute = TRUE, verbose = TRUE, plot = FALSE, colPalette = NULL, pch = 15, cex = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geogMask_+3A_continent">continent</code></td>
<td>
<p><code>NULL</code> or a string (or array of strings) to specify
<code>continent</code> name(s): only one of <code>continent</code>, <code>region</code>, or
<code>country</code> should be specified. Valid list of <code>continent</code> names
can be obtained by running <code>geogMask()</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_region">region</code></td>
<td>
<p><code>NULL</code> or a string (or array of strings) to specify
<code>region</code> name(s): only one of <code>continent</code>, <code>region</code>, or
<code>country</code> should be specified. Valid list of <code>region</code> names
can be obtained by running <code>geogMask()</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_country">country</code></td>
<td>
<p><code>NULL</code> or a string (or array of strings) to specify
<code>country</code> ISO3 character code(s): only one of <code>continent</code>,
<code>region</code>, or <code>country</code> should be specified. Valid list of
<code>country</code> ISO3 character code(s) can be obtained by running
<code>geogMask()</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_lon">lon</code></td>
<td>
<p>a vector of longitudes with length <code>N</code>. Longitudes takes
values from <code>-180</code> to <code>180</code> (not <code>0</code> to <code>360</code>).
For gridded data, the length may have the value (<code>n</code>) provided that
<code>n * m = N</code> where <code>n = length(unique(lon))</code> and <code>m = length(unique(lat))</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_lat">lat</code></td>
<td>
<p>a vector of latitudes with length <code>N</code> or <code>m</code>. See <code>lon</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_indispute">InDispute</code></td>
<td>
<p>a logical: should the areas in dispute be considered for
geographic masking by country? If <code>InDispute = TRUE</code> (the default),
areas in dispute will be considered as a part of the <code>country</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_verbose">verbose</code></td>
<td>
<p>logical to print processing information if <code>verbose = TRUE</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_plot">plot</code></td>
<td>
<p>logical to call the plotting method if <code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_colpalette">colPalette</code></td>
<td>
<p>a color palette or a list of colors such as that generated
by <code>rainbow</code>, <code>heat.colors</code>, <code>topo.colors</code>,
<code>terrain.colors</code> or similar functions.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_pch">pch</code></td>
<td>
<p>Either an integer specifying a symbol or a single character to
be used as the default in plotting points. See <code><a href="graphics.html#topic+points">points</a></code> for
possible values.</p>
</td></tr>
<tr><td><code id="geogMask_+3A_cex">cex</code></td>
<td>
<p>A numerical value giving the amount by which plotting symbols should
be magnified relative to the <code>default = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In some applications, a user may want to focus on an area that is a
mask-defined subset of the full dataset. For instance, the NASA Tropical
Rainfall Measuring Mission (TRMM) data covers ocean and land, while a
researcher might be interested in the precipitation variability only over
land, a country, or a list of countries (e.g., Nile Basin countries). This
masking capability is supported by the <code><a href="#topic+geogMask">geogMask</a></code> helper function.
It requires the longitude (<code>lon</code>) and latitude (<code>lat</code>) vectors
together with a string (or array of strings) to specify <code>continent</code>
name(s), <code>region</code> name(s), or <code>country</code> ISO3 character code(s) via
either <code>continent</code>, <code>region</code>, or <code>country</code> parameters. Valid
values for them can be obtained by running <code>geogMask()</code>. World mask data
is based on the HIU Large Scale International Boundaries (LSIB) data
(<a href="https://hiu.state.gov/data">https://hiu.state.gov/data</a>).
</p>


<h3>Value</h3>

<p>A vector of indices for the spatial elements to be masked,
as required by <code><a href="#topic+HiClimR">HiClimR</a></code>.
</p>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>,
<code><a href="#topic+geogMask">geogMask</a></code>, <code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>,
<code><a href="#topic+grid2D">grid2D</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

## Load test case data
x &lt;- TestCase$x

## Generate longitude and latitude mesh vectors
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)

## Check the valid options for geographic masking
geogMask()

## geographic mask for Africa
gMask &lt;- geogMask(continent = "Africa", lon = lon, lat = lat, plot = TRUE)
</code></pre>

<hr>
<h2 id='grid2D'>Generate longitude and latitude grid matrices</h2><span id='topic+grid2D'></span>

<h3>Description</h3>

<p><code><a href="#topic+grid2D">grid2D</a></code> is a helper function that generates longitude and latitude
rectangular mesh from short longitude and latitude vectors in gridded data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grid2D(lon = lon, lat = lat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grid2D_+3A_lon">lon</code></td>
<td>
<p>a vector of longitudes with length <code>N</code>. Longitudes takes
values from <code>-180</code> to <code>180</code> (not <code>0</code> to <code>360</code>).
For gridded data, the length may have the value (<code>n</code>) provided that
<code>n * m = N</code> where <code>n = length(unique(lon))</code> and <code>m = length(unique(lat))</code>.</p>
</td></tr>
<tr><td><code id="grid2D_+3A_lat">lat</code></td>
<td>
<p>a vector of latitudes with length <code>N</code> or <code>m</code>. See <code>lon</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+grid2D">grid2D</a></code> function convert the long latitude and longitude vectors
to a rectangular two-dimensional grid for visualization and geographic masking
purposes for gridded data in <code>HiClimR</code> package.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>lon</code></td>
<td>
<p>an (<code>n</code> rows by <code>m</code> columns) matrix of 'double' values
for longitude mesh grid, or a vector with length <code>n * m</code>.</p>
</td></tr>
<tr><td><code>lat</code></td>
<td>
<p>an (<code>n</code> rows by <code>m</code> columns) matrix of 'double' values
for latitude mesh grid, or a vector with length <code>n * m</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>,
<code><a href="#topic+geogMask">geogMask</a></code>, <code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>,
<code><a href="#topic+grid2D">grid2D</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

## Load test case data
x &lt;- TestCase$x

## Generate longitude and latitude mesh vectors
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)
</code></pre>

<hr>
<h2 id='HiClimR'>Hierarchical Climate Regionalization</h2><span id='topic+HiClimR'></span>

<h3>Description</h3>

<p><span class="pkg">HiClimR</span> is a tool for <b>Hi</b>erarchical <b>Clim</b>ate <b>R</b>egionalization
applicable to any correlation-based clustering. Climate regionalization is the process
of dividing an area into smaller regions that are homogeneous with respect to a specified
climatic metric. Several features are added to facilitate the applications of climate
regionalization (or spatiotemporal analysis in general) and to implement cluster validation
with an objective tree cutting to find an optimal number of clusters for a user-specified
confidence level. These include options for preprocessing and postprocessing as well as
efficient code execution for large datasets and options for splitting big data and
computing only the upper-triangular half of the correlation/dissimilarity matrix to
overcome memory limitations. Hybrid hierarchical clustering reconstructs the upper part
of the tree above a cut to get the best of the available methods. Multivariate clustering
(MVC) provides options for filtering all variables before preprocessing, detrending and
standardization of each variable, and applying weights for the preprocessed variables.
The correlation distance for MVC represents the (weighted) average of distances between
all variables.
</p>
<p><code><a href="#topic+HiClimR">HiClimR</a></code> is the main function that calls all helper functions. It adds
several features and a new clustering method (called, <em>regional</em> linkage) to
hierarchical clustering in R (<code><a href="stats.html#topic+hclust">hclust</a></code> function in <em>stats</em> library):
data regridding (<code><a href="#topic+grid2D">grid2D</a></code> function), coarsening spatial resolution
(<code><a href="#topic+coarseR">coarseR</a></code> function), geographic masking (<code><a href="#topic+geogMask">geogMask</a></code> function),
contiguity-constrained clustering, data filtering by mean and/or variance thresholds,
data preprocessing (detrending, standardization, and PCA), faster correlation function
(<code><a href="#topic+fastCor">fastCor</a></code> function), hybrid hierarchical clustering, multivariate clustering
(MVC), cluster validation (<code><a href="#topic+validClimR">validClimR</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code> functions),
and visualization of regionalization results, and exporting region map and mean timeseries
into NetCDF-4 file.
</p>
<p>Badr et al. (2015) describes the regionalization algorithms, features, and data processing
tools included in the package and presents a demonstration application in which the package
is used to regionalize Africa on the basis of interannual precipitation variability.
</p>
<p><em><span class="pkg">HiClimR</span> is applicable to any correlation-based clustering.</em>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HiClimR(

  # Input data matrix (N spatial elements x M observations)
  x = list(),

  # Geographic coordinates
  lon = NULL, lat = NULL,

  # Coarsening spatial resolution
  lonStep = 1, latStep = 1,

  # Geographic masking:
  geogMask = FALSE, gMask = NULL, continent = NULL, region = NULL, country = NULL,

  # Contiguity constraint:
  contigConst = 0,

  # Data thresholds:
  meanThresh = if (inherits(x, "list")) {
      vector("list", length(x))
  } else {
      list(NULL)
  },
  varThresh = if (inherits(x, "list")) {
      as.list(rep(0, length(x)))
  } else {
      list(0)
  },

  # Data preprocessing:
  detrend = if (inherits(x, "list")) {
      as.list(rep(FALSE, length(x)))
  } else {
      list(FALSE)
  },
  standardize = if (inherits(x, "list")) {
      as.list(rep(FALSE, length(x)))
  } else {
      list(FALSE)
  },
  weightMVC = if (inherits(x, "list")) {
      as.list(rep(1, length(x)))
  } else {
      list(1)
  },
  nPC = NULL,

  # Clustering options:
  method = "ward", hybrid = FALSE, kH = NULL, members = NULL,

  # Big data support:
  nSplit = 1, upperTri = TRUE, verbose = TRUE,

  # Cluster validation:
  validClimR = TRUE, rawStats = TRUE, k = NULL, minSize = 1, alpha = 0.05,

  # Graphical options:
  plot = TRUE, dendrogram = TRUE, colPalette = NULL,
  hang = -1, labels = FALSE, pch = 15, cex = 1

  )

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HiClimR_+3A_x">x</code></td>
<td>
<p>an (<code>N</code> rows by <code>M</code> columns) matrix of 'double' values:
<code>N</code> objects (spatial points or stations) to be clustered by <code>M</code>
observations (temporal points or years). For gridded data, the <code>N</code>
objects should be created from the original matrix <code>x0</code> using
<code>as.vector(t(x0))</code>, where <code>x0</code> is an (<code>n</code> rows by
<code>m</code> columns) matrix, <code>n = length(unique(lon))</code> and
<code>m = length(unique(lat))</code>. Zero-variance rows (e.g., stations
with zero variability) and/or missing values (e.g., years with missing
observations) are allowed. The zero-variance rows and the columns with
missing values will be removed. However, it is recommended to take care of
both zero-variance rows and missing values before clustering.
For Multivariate Clustering (MVC), <code>x</code> can be a list of <code>nvar</code> matrices
for the <code>nvar</code> variables (one matrix for each variable). The matrixes in
<code>x</code> list should have the same number of rows (objects: spatial points or stations)
Data preprocessing is specified by lists of <code>meanThresh</code>, <code>varThresh</code>,
<code>detrend</code>, and <code>standardize</code> with the same length of <code>x</code> where
<code>length(x) = nvar</code>. Each variable is separately preprocessed to allow for all
possible options. However, it is strongly recommended to standardize all variables
since their magnitude range could be different.
Note that: for gridded data, the rows of input data matrix for each variable is
ordered by longitudes (check <code>TestCase$x</code> for more details).</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_lon">lon</code></td>
<td>
<p>a vector of longitudes with length <code>N</code>. Longitudes takes
values from <code>-180</code> to <code>180</code> (not <code>0</code> to <code>360</code>).
For gridded data, the length may have the value (<code>n</code>) provided that
<code>n * m = N</code> where <code>n = length(unique(lon))</code> and <code>m = length(unique(lat))</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_lat">lat</code></td>
<td>
<p>a vector of latitudes with length <code>N</code> or <code>m</code>. See <code>lon</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_lonstep">lonStep</code></td>
<td>
<p>an integer greater than or equal to <code>1</code> for longitude
step to coarsen gridded data in the longitudinal direction. If <code>lonStep = 1</code>,
gridded data will not be coarsened in the longitudinal direction (the default).
If <code>lonStep = 2</code>, every other grid in longitudinal direction will be retained.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_latstep">latStep</code></td>
<td>
<p>an integer greater than or equal to <code>1</code> for latitude
step to coarsen gridded data in the latitudinal direction. If <code>latStep = 1</code>,
gridded data will not be coarsened in the latitudinal direction (the default).
If <code>latStep = 2</code>, every other grid in latitudinal direction will be retained.
<code>lonStep</code> and <code>latStep</code> are independent so that user can optionally
apply different coarsening level to each dimension.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_geogmask">geogMask</code></td>
<td>
<p>a logical: if <code>geogMask = TRUE</code>, <code><a href="#topic+geogMask">geogMask</a></code>
function will be called. Additional arguments are required.
It requires the longitude and latitude vector together with a string
(or array of strings) to specify <code>continent</code>, <code>region</code>
name(s), or <code>country</code> ISO3 character code(s). If <code>gMask != NULL</code>,
the provided <code>gmask</code> vector will be used for geographic masking without
calling <code><a href="#topic+geogMask">geogMask</a></code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_gmask">gMask</code></td>
<td>
<p>A vector of indices for the spatial elements to be masked,
as required by <code><a href="#topic+HiClimR">HiClimR</a></code>. This is typically an output vector
from <code><a href="#topic+geogMask">geogMask</a></code> function. This helps in saving time when the
same geographic mask will be used many times.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_continent">continent</code></td>
<td>
<p><code>NULL</code> or a string (or array of strings) to specify
<code>continent</code> name(s): only one of <code>continent</code>, <code>region</code>, or
<code>country</code> should be specified. Valid list of <code>continent</code> names
can be obtained by running <code>geogMask()</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_region">region</code></td>
<td>
<p><code>NULL</code> or a string (or array of strings) to specify
<code>region</code> name(s): only one of <code>continent</code>, <code>region</code>, or
<code>country</code> should be specified. Valid list of <code>region</code> names
can be obtained by running <code>geogMask()</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_country">country</code></td>
<td>
<p><code>NULL</code> or a string (or array of strings) to specify
<code>country</code> ISO3 character code(s): only one of <code>continent</code>,
<code>region</code>, or <code>country</code> should be specified. Valid list of
<code>country</code> ISO3 character code(s) can be obtained by running
<code>geogMask()</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_contigconst">contigConst</code></td>
<td>
<p><code>0</code> or a positive value for contiguity constraint:
This is used to apply weighted geographic distances on the initial
dissimilarity matrix between the variable(s) in the data matrix <code>x</code>.
It should be a positive real value (<code>contigConst &gt; 0</code>, recommended
between <code>0</code> and <code>1</code>) where <code>contigConst = 0</code> means that clustering
is completely based on the data with no constraints for contiguity while
<code>contigConst &gt; 0</code> gives priority to merging contiguous points.
Geographic coordinates <code>lon</code> and <code>lat</code> are required to compute
the geographic distances.
<code>regional</code> linkage method does not support contiguity constraints.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_meanthresh">meanThresh</code></td>
<td>
<p><code>NULL</code> or a threshold for the temporal mean:
This is used with <code>varThresh</code> to mask zero- and near-zero-variance
data, Observations with mean less than or equal to <code>meanThresh</code> will
be removed. If <code>meanThresh = NULL</code>, then the <code>varThresh</code> will
be used either to mask zero-variance data by default or by increased
variance threshold to mask near-zero-variance data.
For Multivariate Clustering (MVC), <code>meanThresh</code> is a list of thresholds
with the same length of <code>x</code> where <code>length(x) = nvar</code>.
Each variable is separately preprocessed to allow for all possible options.
However, it is strongly recommended to standardize all variables since their
magnitude range could be different.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_varthresh">varThresh</code></td>
<td>
<p>zero or a threshold for the temporal variance: This is
used with <code>meanThresh</code> to mask zero- and near-zero-variance data,
Observations with variance less than or equal to <code>varThresh</code> will
be removed. If <code>varThresh = 0</code>, then the zero-variance data
will masked (default).
For Multivariate Clustering (MVC), <code>varThresh</code> is a list of thresholds
with the same length of <code>x</code> where <code>length(x) = nvar</code>.
Each variable is separately preprocessed to allow for all possible options.
However, it is strongly recommended to standardize all variables since their
magnitude range could be different.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_detrend">detrend</code></td>
<td>
<p>a logical: should the data be detrended before clustering?
Detrending (removing the linear trend) is important when variations from
temporal point to another is of interest (e.g., interannual variability).
The columns of the data matrix <code>x</code> should be temporally ordered (constant
step size) or have appropriate names (e.g., <code>colnames(x) = years[1:M]</code>).
For Multivariate Clustering (MVC), <code>detrend</code> is a list of thresholds
with the same length of <code>x</code> where <code>length(x) = nvar</code>.
Each variable is separately preprocessed to allow for all possible options.
However, it is strongly recommended to standardize all variables since their
magnitude range could be different.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_standardize">standardize</code></td>
<td>
<p>a logical: should the data be standardized before
clustering? The standardized data makes use of the mean of equally-weighted
objects within each cluster (cluster mean = mean of standardized variables
within the cluster). Otherwise, the mean of raw data will be used (cluster
mean = mean of raw variables within the cluster). The variance of the mean
is updated at each agglomeration step.
For Multivariate Clustering (MVC), <code>standardize</code> is a list of thresholds
with the same length of <code>x</code> where <code>length(x) = nvar</code>.
Each variable is separately preprocessed to allow for all possible options.
However, it is strongly recommended to standardize all variables since their
magnitude range could be different.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_weightmvc">weightMVC</code></td>
<td>
<p>a list of positive wights (<code>weightMVC &gt; 0</code>) for
Multivariate Clustering (MVC) with the same length of <code>x</code> where
<code>length(x) = number of variables</code>. The filtered variables
are weighted and combined by column (for each object: spatial points or stations)
after preprocessing (detrending and standardization) and before PCA (if requested)
and computing the correlation/dissimilarity matrix. The default weight is
<code>weightMVC = 1</code> for all variables.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_npc">nPC</code></td>
<td>
<p><code>NULL</code> or number of principal components (PCs) to be retained.
If <code>nPC = NULL</code>, then the raw data will be used for clustering.
Otherwise, the data will be filtered and reconstructed using <code>nPC</code> PCs
obtained from SVD-based PCA. The <code>detrend</code> and/or <code>standardize</code>
options will be applied, if requested, before PCA.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_method">method</code></td>
<td>
<p>the agglomeration method to be used. This should be (an
unambiguous abbreviation of) one of <code>"regional"</code>, <code>"ward"</code>,
<code>"single"</code>, <code>"complete"</code>, <code>"average"</code>, <code>"mcquitty"</code>,
<code>"median"</code> or <code>"centroid"</code>. The default is <code>"ward"</code> method.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_hybrid">hybrid</code></td>
<td>
<p>a logical: should the upper part of the tree be reconstructed
using <code>regional</code> linkage clustering method?
This adds hybrid hierarchical clustering feature to get the best of
the available methods. It utilizes the pros of available methods, especially
the better overall homogeneity in <em>ward</em>'s method and the separation,
contiguity, and objective tree cut of <em>regional</em> linkage method.
If <code>hybrid = FALSE</code>, only the default clustering using the selected
<code>method</code> will be used (i.e., no hybrid clustering).Otherwise, the upper part
of the tree will be reconstructed above a cut of <code>kH</code> clusters using
<code>regional</code> linkage method. Note: <code>hybrid</code> option is redundant
when using <code>regional</code> linkage as the main clustering method.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_kh">kH</code></td>
<td>
<p><code>NULL</code> or an integer for the number of regions/clusters in the
upper part of the tree to be reconstructed with <code>regional</code> linkage method,
if <code>hybrid = TRUE</code>. If <code>kH = NULL</code>, the tree will be reconstructed
for the upper part with the first merging cost larger than the mean merging cost
for the entire tree. If hybrid clustering is requested, the updated upper part
of the tree will be used for cluster validation, and so <code>kH</code> should be
greater than the final number of clusters <code>k</code>, if selected.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_members">members</code></td>
<td>
<p><code>NULL</code> or a vector with length size of <code>d</code>.
See the &lsquo;Details&rsquo; section.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_nsplit">nSplit</code></td>
<td>
<p>integer number greater than or equal to one, to split the data matrix into
<code>nSplit</code> splits of the total number of columns <code>ncol(xt)</code>. If <code>nSplit = 1</code>,
the default method will be used to compute correlation matrix for the full data matrix
(no splits). If <code>nSplit &gt; 1</code>, the correlation matrix (or the upper-triangular part
if <code>upperTri = TRUE</code>) will be allocated and filled with the computed correlation
sub-matrix for each split. the first <code>n-1</code> splits have equal size while the last
split may include any remaining columns. This is used with <code>upperTri = TRUE</code> to
compute only the upper-triangular part of the correlation matrix. The maximum number of
splits <code>nSplitMax = floor(N / 2)</code> makes splits with 2 columns;
if <code>nSplit &gt; nSplitMax</code>, <code>nSplitMax</code> will be used. Very large number of splits
<code>nSplit</code> makes computation slower but it could handle big data or if the available
memory is not enough to allocate the correlation matrix, which helps in solving the
&ldquo;Error: cannot allocate vector of size...&rdquo; memory limitation problem. It is
recommended to start with a small number of splits. If the data is very large
compared to the physical memory, it is highly recommended to use a 64-Bit machine
with enough memory resources and/or use coarsening feature for gridded data by setting
<code>lonStep &gt; 1</code> and <code>latStep &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_uppertri">upperTri</code></td>
<td>
<p>logical to compute only the upper-triangular half of the correlation
matrix if <code>upperTri = TRUE</code> and <code>nSplit &gt; 1</code>., which includes all required info
since the correlation/dissimilarity matrix is symmetric. This almost halves memory use,
which can be very important for big data.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_verbose">verbose</code></td>
<td>
<p>logical to print processing information if <code>verbose = TRUE</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_validclimr">validClimR</code></td>
<td>
<p>a logical: If <code>validClimR = TRUE</code>, <code><a href="#topic+validClimR">validClimR</a></code>
will be called to compute validation indices including statistical summary for
inter- and intra-cluster correlations. This is computationally expensive. It can
also objectively cut the dendrogram tree for <code>regional</code> clustering method,
if <code>k = NULL</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_rawstats">rawStats</code></td>
<td>
<p>a logical: should validation indices be computed based on
the raw data or PCA-filtered data?</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_k">k</code></td>
<td>
<p><code>NULL</code> or an integer <code>k &gt; 1</code> for the number of regions/clusters.
Only for <code>regional</code> linkage method, <code>k = NULL</code> is supported, where the
&quot;optimal&quot; number of regions will be used at a user specified significance
level <code>alpha</code>. It is required to specify number of clusters <code>k</code>
for the other methods, since they are not based on inter-cluster correlation.
If <code>k = NULL</code> for these methods (except <code>regional</code>) linkage, the
<code>validClimR</code> with be aborted. One can use <code><a href="#topic+validClimR">validClimR</a></code> function
to compute inter-cluster correlation at different number of clusters to objectively
cut the tree for the other methods, which could be computationally expensive to
cover the entire merging history for large number of spatial elements.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_minsize">minSize</code></td>
<td>
<p>minimum cluster size. The <code>regional</code> linkage method tend to
isolate noisy data in small clusters. The <code>minSize</code> can be used to
exclude these very small clusters from the <code>statSum</code> statistical
summary, because they are most likely noisy data that need to be checked
in a quality control step. The analysis may be then repeated.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_alpha">alpha</code></td>
<td>
<p>confidence level: the default is <code>alpha = 0.05</code> for
95% confidence level.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_plot">plot</code></td>
<td>
<p>logical to call the plotting method if <code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_dendrogram">dendrogram</code></td>
<td>
<p>logical to enable or disable dendrogram plotting.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_colpalette">colPalette</code></td>
<td>
<p>a color palette or a list of colors such as that generated
by <code>rainbow</code>, <code>heat.colors</code>, <code>topo.colors</code>,
<code>terrain.colors</code> or similar functions.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_hang">hang</code></td>
<td>
<p>The fraction of the plot height by which labels should hang
below the rest of the plot.
A negative value will cause the labels to hang down from 0.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_labels">labels</code></td>
<td>
<p>A character vector of labels for the leaves of the
tree. By default the row names or row numbers of the original data are
used. If <code>labels = FALSE</code> no labels at all are plotted.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_pch">pch</code></td>
<td>
<p>Either an integer specifying a symbol or a single character to
be used as the default in plotting points. See <code><a href="graphics.html#topic+points">points</a></code> for
possible values.</p>
</td></tr>
<tr><td><code id="HiClimR_+3A_cex">cex</code></td>
<td>
<p>A numerical value giving the amount by which plotting symbols should
be magnified relative to the <code>default = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code> function is based on <code><a href="stats.html#topic+hclust">hclust</a></code>, which now uses an
optimized algorithm to deal with only the upper/lower triangular-half of the symmetric
dissimilarity matrix instead of the old algorithm that uses the full matrix in the
merging steps. It performs a hierarchical cluster analysis using Pearson correlation
distance dissimilarity for the <code class="reqn">N</code> objects being clustered. Initially, each object
is assigned to its own cluster and then the algorithm proceeds iteratively, at each
stage joining the two most similar clusters, continuing until there is just a single
cluster. At each stage distances between clusters are recomputed by a dissimilarity
update formula according to the particular clustering method being used.
</p>
<p>All clustering methods in <code><a href="stats.html#topic+hclust">hclust</a></code> are included. The <em>regional</em>
linkage method minimizes inter-cluster correlations between cluster means
(see <code>Badr et al. 2015</code>). <em>Ward's</em> minimum variance method aims at finding
compact, spherical clusters. The <em>complete linkage</em> method finds similar clusters.
The <em>single linkage</em> method (which is closely related to the minimal spanning tree)
adopts a &lsquo;friends of friends&rsquo; clustering strategy. The other methods can be
regarded as aiming for clusters with characteristics somewhere between the single and
complete link methods. Note however, that methods <code>"median"</code> and <code>"centroid"</code>
are <em>not</em> leading to a <em>monotone distance</em> measure, or equivalently the
resulting dendrograms can have so called <em>inversions</em> (which are hard to interpret).
</p>
<p>The <code>regional</code> linkage method is explained in the context of a spatiotemporal
problem, in which <code>N</code> spatial elements (e.g., weather stations) are divided
into <code>k</code> regions, given that each element has a time series of length <code>M</code>.
It is based on inter-regional correlation distance between the temporal means of
different regions (or elements at the first merging step). It modifies the update
formulae of <code>average</code> linkage method by incorporating the standard deviation
of the merged region timeseries,  which is a function of the correlation between the
individual regions, and their standard deviations before merging. It is equal to the
average of their standard deviations if and only if the correlation between the two
merged regions is <code>100%</code>. In this special case, the <code>regional</code> linkage
method is reduced to the classic <code>average</code> linkage clustering method.
</p>
<p>If <code>members != NULL</code>, then <code>d</code> is taken to be a
dissimilarity matrix between clusters instead of dissimilarities
between singletons and <code>members</code> gives the number of observations
per cluster.  This way the hierarchical cluster algorithm can be
&lsquo;started in the middle of the dendrogram&rsquo;, e.g., in order to
reconstruct the part of the tree above a cut (see examples).
Dissimilarities between clusters can be efficiently computed (i.e.,
without <code>hclust</code> itself) only for a limited number of
distance/linkage combinations, the simplest one being squared
Euclidean distance and centroid linkage.  In this case the
dissimilarities between the clusters are the squared Euclidean
distances between cluster means.
</p>
<p>In hierarchical cluster displays, a decision is needed at each merge to
specify which subtree should go on the left and which on the right.
Since, for <code class="reqn">n</code> observations there are <code class="reqn">n-1</code> merges,
there are <code class="reqn">2^{(n-1)}</code> possible orderings for the leaves
in a cluster tree, or dendrogram.
The algorithm used in <code>hclust</code> is to order the subtree so that
the tighter cluster is on the left (the last, i.e., most recent,
merge of the left subtree is at a lower value than the last
merge of the right subtree).
Single observations are the tightest clusters possible,
and merges involving two observations place them in order by their
observation sequence number.
</p>


<h3>Value</h3>

<p>An object of class <code>HiClimR</code> and <code>hclust</code>, which
describes the tree produced by the clustering process.
The object is a list with the following components:
</p>
<table>
<tr><td><code>merge</code></td>
<td>
<p>an <code class="reqn">n-1</code> by 2 matrix.
Row <code class="reqn">i</code> of <code>merge</code> describes the merging of clusters
at step <code class="reqn">i</code> of the clustering.
If an element <code class="reqn">j</code> in the row is negative,
then observation <code class="reqn">-j</code> was merged at this stage.
If <code class="reqn">j</code> is positive then the merge
was with the cluster formed at the (earlier) stage <code class="reqn">j</code>
of the algorithm.
Thus negative entries in <code>merge</code> indicate agglomerations
of singletons, and positive entries indicate agglomerations
of non-singletons.</p>
</td></tr>
<tr><td><code>height</code></td>
<td>
<p>a set of <code class="reqn">n-1</code> real values (non-decreasing for
ultrametric trees).
The clustering <em>height</em>: that is, the value of
the criterion associated with the clustering
<code>method</code> for the particular agglomeration.</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>a vector giving the permutation of the original
observations suitable for plotting, in the sense that a cluster
plot using this ordering and matrix <code>merge</code> will not have
crossings of the branches.</p>
</td></tr>
<tr><td><code>labels</code></td>
<td>
<p>labels for each of the objects being clustered.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the cluster method that has been used.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call which produced the result.</p>
</td></tr>
<tr><td><code>dist.method</code></td>
<td>
<p>the distance that has been used to create <code>d</code>
(only returned if the distance object has a <code>"method"</code>
attribute).</p>
</td></tr>
<tr><td><code>skip</code></td>
<td>
<p>a vector of <code>lonStep</code> and <code>latStep</code> if <code>coarseR = TRUE</code>.</p>
</td></tr>
<tr><td><code>PCA</code></td>
<td>
<p>if <code>nPC != NULL</code>, the eigenvalues, explained variance,
and accumulated variance will be stored here.</p>
</td></tr>
<tr><td><code>coords</code></td>
<td>
<p>an (<code>Nc</code> rows by <code>2</code> columns) matrix of 'double' values:
longitude and latitude coordinates for the preprocessed data used for clustering,
where <code>NC</code> is the number of spatial elements to be clustered after coarsening
spatial resolution by <code>lonStep</code> and <code>latStep</code>. It will be returned only
if <code>lon</code> and <code>lat</code> vectors were defined. It will be similar to the provided
<code>lon</code> and <code>lat</code> if <code>lonStep = 1</code> and <code>latStep = 1</code>.</p>
</td></tr>
<tr><td><code>nvars</code></td>
<td>
<p>number of variables used for multivariate clustering (MVC).</p>
</td></tr>
<tr><td><code>ncols</code></td>
<td>
<p>number of columns for each variable.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the preprocessed data used for clustering will be stored here.
If <code>rawData = TRUE</code> and <code>nPC != NULL</code>, the preprocessed data without
filtering (PCA) will be returned here.</p>
</td></tr>
<tr><td><code>mask</code></td>
<td>
<p>a vector of the indices of masked spatial points by both
geographic masking and data thresholds.</p>
</td></tr>
<tr><td><code>treeH</code></td>
<td>
<p>An object of class <code>hclust</code>, which describes the upper part of
the tree reconstructed by the hybrid clustering process if <code>hybrid = TRUE</code>.</p>
</td></tr>
</table>
<p>If <code>validClimR = TRUE</code>, an object of class <code>HiClimR</code>, which produces
indices for validating the tree produced by the clustering process, will be merged
in the dendrogram tree above. This object is a list with the following components:
</p>
<table>
<tr><td><code>cutLevel</code></td>
<td>
<p>the minimum significant correlation used for objective
tree cut together with the corresponding confidence level.</p>
</td></tr>
<tr><td><code>clustMean</code></td>
<td>
<p>the cluster means which are the region's mean timeseries for
all selected regions.</p>
</td></tr>
<tr><td><code>clustSize</code></td>
<td>
<p>cluster sizes for all selected regions.</p>
</td></tr>
<tr><td><code>clustFlag</code></td>
<td>
<p>a flag <code>0 or 1</code> to indicate the cluster used
in <code>statSum</code> validation indices (<code>interCor</code>,
<code>intraCor</code>, <code>diffCor</code>, and <code>statSum</code>), based on
<code>minSize</code> minimum cluster size.
If <code>clustFlag = 0</code>, the cluster has been excluded because its size
is less than the <code>minSize</code> minimum cluster size. The sum of
<code>clustFlag</code> elements represents the selected number clusters.</p>
</td></tr>
<tr><td><code>interCor</code></td>
<td>
<p>inter-cluster correlations for all selected regions. It is
the inter-cluster correlations between cluster means. The maximum inter-cluster
correlation is a measure for separation or contiguity, and it is
used for objective tree cut (to find the &quot;optimal&quot; number of clusters).</p>
</td></tr>
<tr><td><code>intraCor</code></td>
<td>
<p>intra-cluster correlations for all selected regions. It is
the intra-cluster correlations between the mean of each cluster and its
members. The average intra-cluster correlation is a weighted average for
all clusters, and it is a measure for homogeneity.</p>
</td></tr>
<tr><td><code>diffCor</code></td>
<td>
<p>difference between intra-cluster correlation and maximum
inter-cluster correlation for all selected regions.</p>
</td></tr>
<tr><td><code>statSum</code></td>
<td>
<p>overall statistical summary for i<code>nterCluster</code>,
<code>intraCor</code>, and <code>diffCor</code>.</p>
</td></tr>
<tr><td><code>region</code></td>
<td>
<p>ordered regions vector of size <code>N</code> number of spatial
elements for the selected number of clusters, after excluding the
small clusters defined by <code>minSize</code> argument.</p>
</td></tr>
<tr><td><code>regionID</code></td>
<td>
<p>ordered regions ID vector of length equals the selected number
of clusters, after excluding the small clusters defined by <code>minSize</code> argument.
It helps in mapping ordered regions and their actual names before ordering.
Only the <code>region</code> component uses ordered ID, while other components use
the names used during the clustering process.</p>
</td></tr>
</table>
<p>There are <code><a href="base.html#topic+print">print</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code> and <code>identify</code>
(see <code><a href="stats.html#topic+identify.hclust">identify.hclust</a></code>) methods and
<code><a href="stats.html#topic+rect.hclust">rect.hclust</a>()</code> functions for <code>hclust</code> objects.
</p>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;. <code><a href="#topic+HiClimR">HiClimR</a></code> is
a modification of <code><a href="stats.html#topic+hclust">hclust</a></code> function, which is based
on Fortran code contributed to STATLIB by F. Murtagh.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>
<p>Wilks, D. S. (2011):
<em>Statistical methods in the atmospheric sciences</em>,
Academic press.
</p>
<p>Gordon, A. D. (1999):
<em>Classification</em>. Second Edition.
London: Chapman and Hall / CRC
</p>
<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988):
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole. (S version.)
</p>
<p>Murtagh, F. (1985):
&ldquo;Multidimensional Clustering Algorithms&rdquo;, in
<em>COMPSTAT Lectures 4</em>.
Wuerzburg: Physica-Verlag
(for algorithmic details of algorithms used).
</p>
<p>Hartigan, J. A. (1975):
<em>Clustering  Algorithms</em>.
New York: Wiley.
</p>
<p>Everitt, B. (1974):
<em>Cluster Analysis</em>.
London: Heinemann Educ. Books.
</p>
<p>Anderberg, M. R. (1973):
<em>Cluster Analysis for Applications</em>.
Academic Press: New York.
</p>
<p>Sneath, P. H. A. and R. R. Sokal (1973):
<em>Numerical Taxonomy</em>.
San Francisco: Freeman.
</p>
<p>McQuitty, L.L. (1966):
Similarity Analysis by Reciprocal Pairs for Discrete and Continuous Data.
<em>Educational and Psychological Measurement</em>, <b>26</b>, 825-831.
</p>
<p>Source Code: <a href="https://github.com/hsbadr/HiClimR">https://github.com/hsbadr/HiClimR</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>, <code><a href="#topic+geogMask">geogMask</a></code>,
<code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>, <code><a href="#topic+grid2D">grid2D</a></code>,
<code><a href="#topic+minSigCor">minSigCor</a></code>. <code><a href="stats.html#topic+identify.hclust">identify.hclust</a></code>, <code><a href="stats.html#topic+rect.hclust">rect.hclust</a></code>,
<code><a href="stats.html#topic+cutree">cutree</a></code>, <code><a href="stats.html#topic+dendrogram">dendrogram</a></code>, and <code><a href="stats.html#topic+kmeans">kmeans</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

#----------------------------------------------------------------------------------#
# Typical use of HiClimR for single-variate clustering:                            #
#----------------------------------------------------------------------------------#

## Load the test data included/loaded in the package (1 degree resolution)
x &lt;- TestCase$x
lon &lt;- TestCase$lon
lat &lt;- TestCase$lat

## Generate/check longitude and latitude mesh vectors for gridded data
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)

## Single-Variate Hierarchical Climate Regionalization
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = FALSE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = FALSE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## For more examples: https://github.com/hsbadr/HiClimR#examples

## Not run: 

#----------------------------------------------------------------------------------#
# Additional Examples:                                                             #
#----------------------------------------------------------------------------------#

## Use Ward's method
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = FALSE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = FALSE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## Use data splitting for big data
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = FALSE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = TRUE, kH = NULL,
    members = NULL, nSplit = 10, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## Use hybrid Ward-Regional method
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = FALSE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = TRUE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)
## Check senitivity to kH for the hybrid method above


#----------------------------------------------------------------------------------#
# Typical use of HiClimR for multivariate clustering:                              #
#----------------------------------------------------------------------------------#

## Load the test data included/loaded in the package (1 degree resolution)
x1 &lt;- TestCase$x
lon &lt;- TestCase$lon
lat &lt;- TestCase$lat

## Generate/check longitude and latitude mesh vectors for gridded data
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)

## Test if we can replicate single-variate region map with repeated variable
y &lt;- HiClimR(x=list(x1, x1), lon = lon, lat = lat, lonStep = 1, latStep = 1,
    geogMask = FALSE, continent = "Africa", meanThresh = list(10, 10),
    varThresh = list(0, 0), detrend = list(TRUE, TRUE), standardize = list(TRUE, TRUE),
    nPC = NULL, method = "ward", hybrid = FALSE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## Generate a random matrix with the same number of rows
x2 &lt;- matrix(rnorm(nrow(x1) * 100, mean=0, sd=1), nrow(x1), 100)

## Multivariate Hierarchical Climate Regionalization
y &lt;- HiClimR(x=list(x1, x2), lon = lon, lat = lat, lonStep = 1, latStep = 1,
    geogMask = FALSE, continent = "Africa", meanThresh = list(10, NULL),
    varThresh = list(0, 0), detrend = list(TRUE, FALSE), standardize = list(TRUE, TRUE),
    weightMVC = list(1, 1), nPC = NULL, method = "ward", hybrid = FALSE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)
## You can apply all clustering methods and options

#----------------------------------------------------------------------------------#
# Miscellaneous examples to provide more information about functionality and usage #
# of the helper functions that can be used separately or for other applications.   #
#----------------------------------------------------------------------------------#

## Load test case data
x &lt;- TestCase$x

## Generate longitude and latitude mesh vectors
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)

## Coarsening spatial resolution
xc &lt;- coarseR(x = x, lon = lon, lat = lat, lonStep = 2, latStep = 2)
lon &lt;- xc$lon
lat &lt;- xc$lat
x &lt;- xc$x

## Use fastCor function to compute the correlation matrix
t0 &lt;- proc.time(); xcor &lt;- fastCor(t(x)); proc.time() - t0
## compare with cor function
t0 &lt;- proc.time(); xcor0 &lt;- cor(t(x)); proc.time() - t0

## Check the valid options for geographic masking
geogMask()

## geographic mask for Africa
gMask &lt;- geogMask(continent = "Africa", lon = lon, lat = lat, plot = TRUE,
    colPalette = NULL)

## Hierarchical Climate Regionalization Without geographic masking
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = FALSE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = FALSE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## With geographic masking (you may specify the mask produced above to save time)
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = TRUE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = FALSE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## With geographic masking and contiguity contraint
## Change contigConst as appropriate
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = TRUE,
    continent = "Africa", contigConst = 1, meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = FALSE, kH = NULL,
    members = NULL, nSplit = 1, upperTri = TRUE, verbose = TRUE,
    validClimR = TRUE, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## Find minimum significant correlation at 95
rMin &lt;- minSigCor(n = nrow(x), alpha = 0.05, r = seq(0, 1, by = 1e-06))

## Validtion of Hierarchical Climate Regionalization
z &lt;- validClimR(y, k = 12, minSize = 1, alpha = 0.01,
    plot = TRUE, colPalette = NULL)

## Apply minimum cluster size (minSize = 25)
z &lt;- validClimR(y, k = 12, minSize = 25, alpha = 0.01,
    plot = TRUE, colPalette = NULL)

## The optimal number of clusters, including small clusters
k &lt;- length(z$clustFlag)

## The selected number of clusters, after excluding small clusters (if minSize &gt; 1)
ks &lt;- sum(z$clustFlag)

## Dendrogram plot
plot(y, hang = -1, labels = FALSE)

## Tree cut
cutTree &lt;- cutree(y, k = k)
table(cutTree)

## Visualization for gridded data
RegionsMap &lt;- matrix(y$region, nrow = length(unique(y$coords[, 1])), byrow = TRUE)
colPalette &lt;- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan",
    "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))
image(unique(y$coords[, 1]), unique(y$coords[, 2]), RegionsMap, col = colPalette(ks))

## Visualization for gridded or ungridded data
plot(y$coords[, 1], y$coords[, 2], col = colPalette(max(Regions, na.rm = TRUE))[y$region],
    pch = 15, cex = 1)

## Export region map and mean timeseries into NetCDF-4 file
y.nc &lt;- HiClimR2nc(y=y, ncfile="HiClimR.nc", timeunit="years", dataunit="mm")
## The NetCDF-4 file is still open to add other variables or close it
nc_close(y.nc)


## End(Not run)
</code></pre>

<hr>
<h2 id='HiClimR2nc'>Export NetCDF-4 file for Hierarchical Climate Regionalization</h2><span id='topic+HiClimR2nc'></span>

<h3>Description</h3>

<p><code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code> is a helper function that exports region map
and mean timeseries into NetCDF-4 file, using the <code>ncdf4</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HiClimR2nc(y = NULL, ncfile = "HiClimR.nc", timeunit = "", dataunit = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HiClimR2nc_+3A_y">y</code></td>
<td>
<p>a dendrogram tree produced by <code><a href="#topic+HiClimR">HiClimR</a></code>.</p>
</td></tr>
<tr><td><code id="HiClimR2nc_+3A_ncfile">ncfile</code></td>
<td>
<p>Path and name of the NetCDF-4 file to be created.</p>
</td></tr>
<tr><td><code id="HiClimR2nc_+3A_timeunit">timeunit</code></td>
<td>
<p>an optional character string for the time units,
A zero-length string (default: <code>timeunit=""</code>) removes units attribute.</p>
</td></tr>
<tr><td><code id="HiClimR2nc_+3A_dataunit">dataunit</code></td>
<td>
<p>an optional character string for the data units,
A zero-length string (default: <code>timeunit=""</code>) removes units attribute.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code> function exports region map and mean timeseries
from <code>HiClimR</code> tree into NetCDF-4 file, using the <code>ncdf4</code> package.
The NetCDF-4 file will be open to add other variables, if needed.
It is important to close the created file using <code><a href="ncdf4.html#topic+nc_close">nc_close</a></code>,
which flushes any unwritten data to disk.
</p>


<h3>Value</h3>

<p>An object of class <code>ncdf4</code>, which has the fields described in <code><a href="ncdf4.html#topic+nc_open">nc_open</a></code>.
</p>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>,
<code><a href="#topic+geogMask">geogMask</a></code>, <code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>,
<code><a href="#topic+grid2D">grid2D</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)
require(ncdf4)

## Load test case data
x &lt;- TestCase$x

## Generate longitude and latitude mesh vectors
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)

## Hierarchical Climate Regionalization
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = FALSE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = FALSE,
    kH = NULL, members = NULL, validClimR = TRUE, k = 12, minSize = 1,
    alpha = 0.01, plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## Not run: 

## Export region map and mean timeseries into NetCDF-4 file
y.nc &lt;- HiClimR2nc(y=y, ncfile="HiClimR.nc", timeunit="years", dataunit="mm")
## The NetCDF-4 file is still open to add other variables or close it
nc_close(y.nc)


## End(Not run)
</code></pre>

<hr>
<h2 id='minSigCor'>Minimum significant correlation for a sample size</h2><span id='topic+minSigCor'></span>

<h3>Description</h3>

<p><code><a href="#topic+minSigCor">minSigCor</a></code> is a helper function that estimates the minimum
significant correlation for a sample size <code>n</code> at a confidence level
defined by the argument <code>alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minSigCor(n = 41, alpha = 0.05, r = seq(0, 1, by = 1e-6))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="minSigCor_+3A_n">n</code></td>
<td>
<p>sample size or the length of a timeseries vector.</p>
</td></tr>
<tr><td><code id="minSigCor_+3A_alpha">alpha</code></td>
<td>
<p>confidence level: the default is <code>alpha = 0.05</code> for
95% confidence level.</p>
</td></tr>
<tr><td><code id="minSigCor_+3A_r">r</code></td>
<td>
<p>a vector of values from <code>0</code> to <code>1</code> to search for the
minimum significant correlation for the user-specified sample size
<code>n</code> at confidence level <code>alpha</code>. This should be a subset of the
valid positive correlation range <code>0-1</code>. The default is to search for the
minimum significant correlation in the complete range <code>0-1</code> with a very
fine step of <code>1e-6</code>. For faster computations, the user may set a shorter
range with larger step (e.g., seq(0.1, 0.5, by=1e-3)).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+minSigCor">minSigCor</a></code> function estimates the minimum significant correlation
for a sample size (number of observations or temporal points in a timeseries)
at a certain confidence level selected by the argument <code>alpha</code> and an
optional search range <code>r</code>. It is called by <code><a href="#topic+validClimR">validClimR</a></code>
function objective tree cut based on the specified confidence level.
</p>


<h3>Value</h3>

<p>A positive value between <code>0</code> and <code>1</code> for the estimated the minimum
significant correlation.
</p>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>,
<code><a href="#topic+geogMask">geogMask</a></code>, <code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>,
<code><a href="#topic+grid2D">grid2D</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

## Find minimum significant correlation at 95% confidence level
rMin &lt;- minSigCor(n = 41, alpha = 0.05, r = seq(0, 1, by = 1e-06))
</code></pre>

<hr>
<h2 id='TestCase'>Test Data for Functionality Demonstration of <code>HiClimR</code> Package</h2><span id='topic+TestCase'></span><span id='topic+lon'></span><span id='topic+lat'></span><span id='topic+x'></span>

<h3>Description</h3>

<p>This data is a subset of University of East Anglia Climatic Research Unit
(CRU) TS (timeseries) precipitation dataset version 3.2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(TestCase)
</code></pre>


<h3>Format</h3>

<p><code>TestCase</code> is a list of three components: <code>x</code>, <code>lon</code>, and <code>lat</code>.
<code>x</code> is an (<code>6400</code> rows by <code>41</code> columns) matrix as required for
<code><a href="#topic+HiClimR">HiClimR</a></code> function. The rows represent spatial points (or stations),
while the columns represent observations (temporal points or years). <code>lon</code>
and <code>lat</code> are vectors of length <code>80</code> for unique longitudes and
latitudes coordinates, where <code>80 * 80 = 6400</code> for this gridded data.
</p>


<h3>Details</h3>

<p>CRU TS 3.21 data (1901-2012) is monthly gridded precipitation with <code>0.5</code>
degree resolution. This test data is a subset with 1 degree resolution for
African precipitation in January, 1949-1989.
</p>


<h3>Source</h3>

<p>Climatic Research Unit (CRU) time-series datasets of variations in climate with
variations in other phenomena.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>
<p>Harris, I., Jones, P. D., Osborn, T. J., and Lister, D. H. (2014):
Updated high-resolution grids of monthly climatic observations - the CRU TS3.10 Dataset,
<em>International journal of climatology</em>, <b>34</b>, 623-642,
doi: <a href="https://doi.org/10.1002/joc.3711">10.1002/joc.3711</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

x &lt;- TestCase$x
dim(x)
colnames(x)
</code></pre>

<hr>
<h2 id='validClimR'>Validation of Hierarchical Climate Regionalization</h2><span id='topic+validClimR'></span>

<h3>Description</h3>

<p><code><a href="#topic+validClimR">validClimR</a></code> computes indices for cluster validation, and an
objective tree cut for <code>regional</code> linkage clustering method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validClimR(y = NULL, k = NULL, minSize = 1, alpha = 0.05, verbose = TRUE,
    plot = FALSE, colPalette = NULL, pch = 15, cex = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validClimR_+3A_y">y</code></td>
<td>
<p>a dendrogram tree produced by <code><a href="#topic+HiClimR">HiClimR</a></code>.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_k">k</code></td>
<td>
<p><code>NULL</code> or a n integer <code>k &gt; 1</code> for the number of regions/clusters.
Only for <code>regional</code> linkage method, <code>k = NULL</code> is supported, where the
&quot;optimal&quot; number of regions will be used at a user specified significance
level <code>alpha</code>. It is required to specify number of clusters <code>k</code>
for the other methods, since they are not based on inter-cluster correlation.
If <code>k = NULL</code> for these methods (except <code>regional</code>) linkage, the
<code>validClimR</code> with be aborted. One can use <code><a href="#topic+validClimR">validClimR</a></code> function
to compute inter-cluster correlation at different number of clusters to objectively
cut the tree for the other methods, which could be computationally expensive to
cover the entire merging history for large number of spatial elements.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_minsize">minSize</code></td>
<td>
<p>minimum cluster size. The <code>regional</code> linkage method tend to
isolate noisy data in small clusters. The <code>minSize</code> can be used to
exclude these very small clusters from the <code>statSum</code> statistical
summary, because they are most likely noisy data that need to be checked
in a quality control step. The analysis may be then repeated.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_alpha">alpha</code></td>
<td>
<p>confidence level: the default is <code>alpha = 0.05</code> for
95% confidence level.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_verbose">verbose</code></td>
<td>
<p>logical to print processing information if <code>verbose = TRUE</code>.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_plot">plot</code></td>
<td>
<p>logical to call the plotting method if <code>plot = TRUE</code>.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_colpalette">colPalette</code></td>
<td>
<p>a color palette or a list of colors such as that generated
by <code>rainbow</code>, <code>heat.colors</code>, <code>topo.colors</code>,
<code>terrain.colors</code> or similar functions.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_pch">pch</code></td>
<td>
<p>Either an integer specifying a symbol or a single character to
be used as the default in plotting points. See <code><a href="graphics.html#topic+points">points</a></code> for
possible values.</p>
</td></tr>
<tr><td><code id="validClimR_+3A_cex">cex</code></td>
<td>
<p>A numerical value giving the amount by which plotting symbols should
be magnified relative to the <code>default = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>validClimR</code> function is used for validation of a dendrogram tree
produced by <code>HiClimR</code>, by computing  detailed statistical information for
each cluster about cluster means, sizes, intra- and inter-cluster correlations,
and overall summary. It requires the preprocessed data matrix and the tree from
<code><a href="#topic+HiClimR">HiClimR</a></code> function as inputs. An optional parameter can be used to
validate clustering for a selected number of clusters <code>k</code>. If <code>k = NULL</code>,
the default which supports only the <code>regional</code> linkage method, objective cutting
of the tree to find the optimal number of clusters will be applied based on a user
specified significance level (<code>alpha</code> parameter). In <code>regional</code> linkage method,
noisy spatial elements are isolated in very small-size clusters or individuals since
they do not correlate well with any other elements. They can be excluded from the
validation indices (<code>interCor</code>, <code>intraCor</code>, <code>diffCor</code>, and <code>statSum</code>),
based on <code>minSize</code> minimum cluster size. The excluded clusters are identified in
the output of <code>validClimR</code> in <code>clustFlag</code>, which takes a value of <code>1</code>
for selected clusters or <code>0</code> for excluded clusters. The sum of <code>clustFlag</code>
elements represents the selected number clusters.This should be followed by a quality
control step before repeating the analysis.
</p>


<h3>Value</h3>

<p>An object of class <code>HiClimR</code> which produces indices for validating
the tree produced by the clustering process.
The object is a list with the following components:
</p>
<table>
<tr><td><code>cutLevel</code></td>
<td>
<p>the minimum significant correlation used for objective
tree cut together with the corresponding confidence level.</p>
</td></tr>
<tr><td><code>clustMean</code></td>
<td>
<p>the cluster means which are the region's mean timeseries for
all selected regions.</p>
</td></tr>
<tr><td><code>clustSize</code></td>
<td>
<p>cluster sizes for all selected regions.</p>
</td></tr>
<tr><td><code>clustFlag</code></td>
<td>
<p>a flag <code>0 or 1</code> to indicate the cluster used
in <code>statSum</code> validation indices (<code>interCor</code>,
<code>intraCor</code>, <code>diffCor</code>, and <code>statSum</code>), based on
<code>minSize</code> minimum cluster size.
If <code>clustFlag = 0</code>, the cluster has been excluded because its size
is less than the <code>minSize</code> minimum cluster size. The sum of
<code>clustFlag</code> elements represents the selected number clusters.</p>
</td></tr>
<tr><td><code>interCor</code></td>
<td>
<p>inter-cluster correlations for all selected regions. It is
the inter-cluster correlations between cluster means. The maximum inter-cluster
correlation is a measure for separation or contiguity, and it is
used for objective tree cut (to find the &quot;optimal&quot; number of clusters).</p>
</td></tr>
<tr><td><code>intraCor</code></td>
<td>
<p>intra-cluster correlations for all selected regions. It is
the intra-cluster correlations between the mean of each cluster and its
members. The average intra-cluster correlation is a weighted average for
all clusters, and it is a measure for homogeneity.</p>
</td></tr>
<tr><td><code>diffCor</code></td>
<td>
<p>difference between intra-cluster correlation and maximum
inter-cluster correlation for all selected regions.</p>
</td></tr>
<tr><td><code>statSum</code></td>
<td>
<p>overall statistical summary for i<code>nterCluster</code>,
<code>intraCor</code>, and <code>diffCor</code>.</p>
</td></tr>
<tr><td><code>region</code></td>
<td>
<p>ordered regions vector of size <code>N</code> number of spatial
elements for the selected number of clusters, after excluding the
small clusters defined by <code>minSize</code> argument.</p>
</td></tr>
<tr><td><code>regionID</code></td>
<td>
<p>ordered regions ID vector of length equals the selected number
of clusters, after excluding the small clusters defined by <code>minSize</code> argument.
It helps in mapping ordered regions and their actual names before ordering.
Only the <code>region</code> component uses ordered ID, while other components use
the names used during the clustering process.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hamada S. Badr &lt;badr@jhu.edu&gt;, Benjamin F. Zaitchik &lt;zaitchik@jhu.edu&gt;,
and Amin K. Dezfuli &lt;amin.dezfuli@nasa.gov&gt;. <code><a href="#topic+HiClimR">HiClimR</a></code> is
a modification of <code><a href="stats.html#topic+hclust">hclust</a></code> function, which is based on
Fortran code contributed to STATLIB by F. Murtagh.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HiClimR">HiClimR</a></code>, <code><a href="#topic+HiClimR2nc">HiClimR2nc</a></code>, <code><a href="#topic+validClimR">validClimR</a></code>,
<code><a href="#topic+geogMask">geogMask</a></code>, <code><a href="#topic+coarseR">coarseR</a></code>, <code><a href="#topic+fastCor">fastCor</a></code>,
<code><a href="#topic+grid2D">grid2D</a></code> and <code><a href="#topic+minSigCor">minSigCor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

## Load test case data
x &lt;- TestCase$x

## Generate longitude and latitude mesh vectors
xGrid &lt;- grid2D(lon = unique(TestCase$lon), lat = unique(TestCase$lat))
lon &lt;- c(xGrid$lon)
lat &lt;- c(xGrid$lat)

## Hierarchical Climate Regionalization
y &lt;- HiClimR(x, lon = lon, lat = lat, lonStep = 1, latStep = 1, geogMask = FALSE,
    continent = "Africa", meanThresh = 10, varThresh = 0, detrend = TRUE,
    standardize = TRUE, nPC = NULL, method = "ward", hybrid = FALSE,
    kH = NULL, members = NULL, validClimR = TRUE, k = 12, minSize = 1,
    alpha = 0.01, plot = TRUE, colPalette = NULL, hang = -1, labels = FALSE)

## Validtion of Hierarchical Climate Regionalization
z &lt;- validClimR(y, k = 12, minSize = 1, alpha = 0.01, plot = TRUE)

## Use a specified number of clusters (k = 12)
z &lt;- validClimR(y, k = 12, minSize = 1, alpha = 0.01, plot = TRUE)

## Apply minimum cluster size (minSize = 25)
z &lt;- validClimR(y, k = 12, minSize = 25, alpha = 0.01, plot = TRUE)

## The optimal number of clusters, including small clusters
k &lt;- length(z$clustFlag)

## The selected number of clusters, after excluding small clusters (if minSize &gt; 1)
ks &lt;- sum(z$clustFlag)
</code></pre>

<hr>
<h2 id='WorldMask'>World Mask for Geographic Masking in HiClimR</h2><span id='topic+WorldMask'></span><span id='topic+info'></span><span id='topic+mask'></span>

<h3>Description</h3>

<p>This data is used for geographic masking by <code><a href="#topic+geogMask">geogMask</a></code>
function in <code>HiClimR</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(WorldMask)
</code></pre>


<h3>Format</h3>

<p><code>WorldMask</code> is a list with two components: <code>info</code> and <code>mask</code>.
<code>info</code> is an (<code>284</code> rows by <code>10</code> columns) matrix. The rows are for
areas or countries while the columns are for codes required by <code><a href="#topic+geogMask">geogMask</a></code>.
<code>mask</code> is an (<code>3601</code> rows by <code>1801</code> columns) matrix with integer
values from <code>1</code> to <code>284</code> for the areas defined in <code>info</code>.
</p>


<h3>Details</h3>

<p>This data is used internally by <code><a href="#topic+geogMask">geogMask</a></code> function for geographic masking
in <code>HiClimR</code> package. The user is advised to refer to the function manual for more
details. The world mask is available in <code>0.1</code> degree (<code>10</code> km) resolution. The
<code>info</code> data provides information for continents, regions, and country codes).
</p>


<h3>Source</h3>

<p>The data are based on the Humanitarian Information Unit (HIU) Large Scale
International Boundaries (LSIB) dataset.
</p>


<h3>References</h3>

<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2015):
A Tool for Hierarchical Climate Regionalization, <em>Earth Science Informatics</em>,
<b>8</b>(4), 949-958, doi: <a href="https://doi.org/10.1007/s12145-015-0221-7">10.1007/s12145-015-0221-7</a>.
</p>
<p>Hamada S. Badr, Zaitchik, B. F. and Dezfuli, A. K. (2014):
Hierarchical Climate Regionalization,
<em>Comprehensive R Archive Network (CRAN)</em>,
<a href="https://cran.r-project.org/package=HiClimR">https://cran.r-project.org/package=HiClimR</a>.
</p>
<p>LSIB Data: <a href="https://hiu.state.gov/data/">https://hiu.state.gov/data/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(HiClimR)

geogMask()
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
