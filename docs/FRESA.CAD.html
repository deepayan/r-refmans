<!DOCTYPE html><html lang="en"><head><title>Help for package FRESA.CAD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FRESA.CAD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#FRESA.CAD-package'><p>FeatuRE Selection Algorithms for Computer-Aided Diagnosis (FRESA.CAD)</p></a></li>
<li><a href='#backVarElimination_Bin'><p>IDI/NRI-based backwards variable elimination</p></a></li>
<li><a href='#backVarElimination_Res'><p>NeRI-based backwards variable elimination</p></a></li>
<li><a href='#baggedModel'><p>Get the bagged model from a list of models</p></a></li>
<li><a href='#barPlotCiError'><p>Bar plot with error bars</p></a></li>
<li><a href='#benchmarking'><p>Compare performance of different model fitting/filtering algorithms</p></a></li>
<li><a href='#BESS'><p>CV BeSS fit</p></a></li>
<li><a href='#bootstrapValidation_Bin'><p>Bootstrap validation of binary classification models</p></a></li>
<li><a href='#bootstrapValidation_Res'><p>Bootstrap validation of regression models</p></a></li>
<li><a href='#bootstrapVarElimination_Bin'><p>IDI/NRI-based backwards variable elimination with bootstrapping</p></a></li>
<li><a href='#bootstrapVarElimination_Res'><p>NeRI-based backwards variable elimination with bootstrapping</p></a></li>
<li><a href='#BSWiMS.model'><p>BSWiMS model selection</p></a></li>
<li><a href='#calBinProb'><p>Calibrates Predicted Binary Probabilities</p></a></li>
<li><a href='#CalibrationProbPoissonRisk'><p>Baseline hazard and interval time Estimations</p></a></li>
<li><a href='#cancerVarNames'><p>Data frame used in several examples of this package</p></a></li>
<li><a href='#ClustClass'><p>Hybrid Hierarchical Modeling</p></a></li>
<li><a href='#clusterISODATA'><p>Cluster Clustering using the Isodata Approach</p></a></li>
<li><a href='#crossValidationFeatureSelection_Bin'><p>IDI/NRI-based selection of a linear, logistic, or Cox proportional hazards regression model from a set of candidate variables</p></a></li>
<li><a href='#crossValidationFeatureSelection_Res'><p>NeRI-based selection of a linear, logistic, or Cox proportional hazards regression model from a set of candidate variables</p></a></li>
<li><a href='#CVsignature'><p>Cross-validated Signature</p></a></li>
<li><a href='#EmpiricalSurvDiff'><p>Estimate the LR value and its associated p-values</p></a></li>
<li><a href='#ensemblePredict'><p>The median prediction from a list of models</p></a></li>
<li><a href='#featureAdjustment'><p>Adjust each listed variable to the provided set of covariates</p></a></li>
<li><a href='#filteredFit'><p>A generic pipeline of Feature Selection, Transformation, Scale and fit</p></a></li>
<li><a href='#FilterUnivariate'><p>Univariate Filters</p></a></li>
<li><a href='#ForwardSelection.Model.Bin'><p>IDI/NRI-based feature selection procedure for linear, logistic, and Cox proportional hazards regression models</p></a></li>
<li><a href='#ForwardSelection.Model.Res'><p>NeRI-based feature selection procedure for linear, logistic, or Cox proportional hazards regression models</p></a></li>
<li><a href='#FRESA.Model'><p>Automated model selection</p></a></li>
<li><a href='#FRESAScale'><p>Data frame normalization</p></a></li>
<li><a href='#getKNNpredictionFromFormula'><p>Predict classification using KNN</p></a></li>
<li><a href='#getLatentCoefficients'><p>Derived Features of the UPLTM transform</p></a></li>
<li><a href='#getMedianSurvCalibratedPrediction'><p>Binary Predictions Calibration of Random CV</p></a></li>
<li><a href='#getSignature'><p>Returns a CV signature template</p></a></li>
<li><a href='#getVar.Bin'><p>Analysis of the effect of each term of a binary classification model by analysing its reclassification performance</p></a></li>
<li><a href='#getVar.Res'><p>Analysis of the effect of each term of a linear regression model by analysing its residuals</p></a></li>
<li><a href='#GLMNET'><p>GLMNET fit with feature selection&quot;</p></a></li>
<li><a href='#GMVEBSWiMS'><p>Hybrid Hierarchical Modeling with GMVE and BSWiMS</p></a></li>
<li><a href='#GMVECluster'><p>Set Clustering using the Generalized Minimum Volume Ellipsoid (GMVE)</p></a></li>
<li><a href='#heatMaps'><p>Plot a heat map of selected variables</p></a></li>
<li><a href='#HLCM'><p>Latent class based modeling of binary outcomes</p></a></li>
<li><a href='#IDeA'><p>Decorrelation of data frames</p></a></li>
<li><a href='#improvedResiduals'><p>Estimate the significance of the reduction of predicted residuals</p></a></li>
<li><a href='#jaccardMatrix'><p>Jaccard Index of two labeled sets</p></a></li>
<li><a href='#KNN_method'><p>KNN Setup for KNN prediction</p></a></li>
<li><a href='#listTopCorrelatedVariables'><p>List the variables that are highly correlated with each other</p></a></li>
<li><a href='#LM_RIDGE_MIN'><p>Ridge Linear Models</p></a></li>
<li><a href='#metric95ci'><p>Estimators and 95CI</p></a></li>
<li><a href='#modelFitting'><p>Fit a model to the data</p></a></li>
<li><a href='#mRMR.classic_FRESA'><p>FRESA.CAD wrapper of mRMRe::mRMR.classic</p></a></li>
<li><a href='#multivariate_BinEnsemble'><p>Multivariate Filters</p></a></li>
<li><a href='#NAIVE_BAYES'><p>Naive Bayes Modeling</p></a></li>
<li><a href='#nearestCentroid'><p>Class Label Based on the Minimum Mahalanobis Distance</p></a></li>
<li><a href='#nearestNeighborImpute'><p>nearest neighbor NA imputation</p></a></li>
<li><a href='#plot.bootstrapValidation_Bin'><p>Plot ROC curves of bootstrap results</p></a></li>
<li><a href='#plot.bootstrapValidation_Res'><p>Plot ROC curves of bootstrap results</p></a></li>
<li><a href='#plot.FRESA_benchmark'><p>Plot the results of the model selection benchmark</p></a></li>
<li><a href='#plotModels.ROC'><p>Plot test ROC curves of each cross-validation model</p></a></li>
<li><a href='#ppoisGzero'><p>Probability of more than zero events</p></a></li>
<li><a href='#predict.BAGGS'><p>Predicts <code>baggedModel</code> bagged models</p></a></li>
<li><a href='#predict.CLUSTER_CLASS'><p>Predicts <code>ClustClass</code> outcome</p></a></li>
<li><a href='#predict.fitFRESA'><p>Linear or probabilistic prediction</p></a></li>
<li><a href='#predict.FRESA_BESS'><p>Predicts <code>BESS</code> models</p></a></li>
<li><a href='#predict.FRESA_FILTERFIT'><p>Predicts <code>filteredFit</code> models</p></a></li>
<li><a href='#predict.FRESA_GLMNET'><p>Predicts GLMNET fitted objects</p></a></li>
<li><a href='#predict.FRESA_HLCM'><p>Predicts BOOST_BSWiMS models</p></a></li>
<li><a href='#predict.FRESA_NAIVEBAYES'><p>Predicts <code>NAIVE_BAYES</code> models</p></a></li>
<li><a href='#predict.FRESA_RIDGE'><p>Predicts <code>LM_RIDGE_MIN</code> models</p></a></li>
<li><a href='#predict.FRESA_SVM'><p>Predicts <code>TUNED_SVM</code> models</p></a></li>
<li><a href='#predict.FRESAKNN'><p>Predicts <code>class::knn</code> models</p></a></li>
<li><a href='#predict.FRESAsignature'><p>Predicts <code>CVsignature</code> models</p></a></li>
<li><a href='#predict.GMVE'><p>Predicts <code>GMVECluster</code> clusters</p></a></li>
<li><a href='#predict.GMVE_BSWiMS'><p>Predicts <code>GMVEBSWiMS</code> outcome</p></a></li>
<li><a href='#predict.LogitCalPred'><p>Predicts calibrated probabilities</p></a></li>
<li><a href='#predictionStats'><p>Prediction Evaluation</p></a></li>
<li><a href='#randomCV'><p>Cross Validation of Prediction Models</p></a></li>
<li><a href='#rankInverseNormalDataFrame'><p>rank-based inverse normal transformation of the data</p></a></li>
<li><a href='#reportEquivalentVariables'><p>Report the set of variables that will perform an equivalent IDI discriminant function</p></a></li>
<li><a href='#residualForFRESA'><p>Return residuals from prediction</p></a></li>
<li><a href='#RRPlot'><p>Plot and Analysis of Indices of Risk</p></a></li>
<li><a href='#signatureDistance'><p>Distance to the signature template</p></a></li>
<li><a href='#summary.bootstrapValidation_Bin'><p>Generate a report of the results obtained using the bootstrapValidation_Bin function</p></a></li>
<li><a href='#summary.fitFRESA'><p>Returns the summary of the fit</p></a></li>
<li><a href='#summaryReport'><p>Report the univariate analysis, the cross-validation analysis and the correlation analysis</p></a></li>
<li><a href='#timeSerieAnalysis'><p>Fit the listed time series variables to a given model</p></a></li>
<li><a href='#trajectoriesPolyFeatures'><p>Extract the per patient polynomial Coefficients of a feature trayectory</p></a></li>
<li><a href='#TUNED_SVM'><p>Tuned SVM</p></a></li>
<li><a href='#uniRankVar'><p>Univariate analysis of features (additional values returned)</p></a></li>
<li><a href='#univariateRankVariables'><p>Univariate analysis of features</p></a></li>
<li><a href='#update.uniRankVar'><p>Update the univariate analysis using new data</p></a></li>
<li><a href='#updateModel.Bin'><p>Update the IDI/NRI-based model using new data or new threshold values</p></a></li>
<li><a href='#updateModel.Res'><p>Update the NeRI-based model using new data or new threshold values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Feature Selection Algorithms for Computer Aided Diagnosis</td>
</tr>
<tr>
<td>Version:</td>
<td>3.4.8</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-06-25</td>
</tr>
<tr>
<td>Author:</td>
<td>Jose Gerardo Tamez-Pena, Antonio Martinez-Torteya, Israel Alanis and Jorge Orozco</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jose Gerardo Tamez-Pena &lt;jose.tamezpena@tec.mx&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains a set of utilities for building and testing statistical models (linear, logistic,ordinal or COX) for Computer Aided Diagnosis/Prognosis applications. Utilities include data adjustment, univariate analysis, model building, model-validation, longitudinal analysis, reporting and visualization.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-2">LGPL-2</a> | <a href="https://www.r-project.org/Licenses/LGPL-2.1">LGPL-2.1</a> | <a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a> [expanded from: LGPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>Rcpp (&ge; 0.10.0),stringr,miscTools,Hmisc,pROC</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>nlme,rpart,gplots,RColorBrewer,class,cvTools,glmnet,randomForest,survival,
e1071,MASS,naivebayes,mRMRe,epiR,DescTools,
irr,survminer,BeSS,ggplot2,robustbase,mda,twosamples,Rfast,whitening,corrplot</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-25 21:10:19 UTC; jtame</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-25 21:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='FRESA.CAD-package'>FeatuRE Selection Algorithms for Computer-Aided Diagnosis (FRESA.CAD)</h2><span id='topic+FRESA.CAD-package'></span><span id='topic+FRESA.CAD'></span>

<h3>Description</h3>

<p>Contains a set of utilities for building and testing formula-based models for Computer Aided Diagnosis/prognosis applications via feature selection.
Bootstrapped Stage Wise Model Selection (B:SWiMS) controls the false selection (FS) for linear, logistic, or Cox proportional hazards regression models.
Utilities include functions for: univariate/longitudinal analysis, data conditioning (i.e. covariate adjustment and normalization), model validation and visualization.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
        Package: </td><td style="text-align: left;"> FRESA.CAD</td>
</tr>
<tr>
 <td style="text-align: left;">
        Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
        Version: </td><td style="text-align: left;"> 3.4.8</td>
</tr>
<tr>
 <td style="text-align: left;">
        Date: </td><td style="text-align: left;"> 2024-06-25</td>
</tr>
<tr>
 <td style="text-align: left;">
        License: </td><td style="text-align: left;"> LGPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>

<p>Purpose: The design of diagnostic or prognostic multivariate models via the selection of significantly discriminant features.
The models are selected via the bootstrapped step-wise selection of model features that offer a significant improvement in subject classification/error.
The false selection control is achieved by train-test partitions, where train sets are used to select variables and test sets used to evaluate model performance.
Variables that do not improve subject classification/error on the blind test are not included in the models.
The main function of this package is the selection and cross-validation of diagnostic/prognostic linear, logistic, or Cox proportional hazards regression model constructed from a large set of candidate features.
The variable selection may start by conditioning all variables via a covariate-adjustment and a <em>z</em>-inverse-rank-transformation. 
In order to integrate features with partial discriminant power, the package can be used to categorize the continuous variables and rank their discriminant power.
Once ranked, each feature is bootstrap-tested in a multivariate model, and its blind performance is evaluated.
Variables with a statistical significant improvement in classification/error are stored and finally inserted into the final model according to their relative store frequency. 
A cross-validation procedure may be used to diagnose the amount of model shrinkage produced by the selection scheme.
</p>


<h3>Author(s)</h3>

<p>Jose Gerardo Tamez-Pena, Antonio Martinez-Torteya, Israel Alanis and Jorge Orozco 
Maintainer: &lt;jose.tamezpena@tec.mx&gt;
</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Not run: 
    ### Fresa Package Examples ####
    library("epiR")
    library("FRESA.CAD")
    library(network)
    library(GGally)
    library("e1071")


    # Start the graphics device driver to save all plots in a pdf format
    pdf(file = "Fresa.Package.Example.pdf",width = 8, height = 6)


    # Get the stage C prostate cancer data from the rpart package

    data(stagec,package = "rpart")
    options(na.action = 'na.pass')
    dataCancer &lt;- cbind(pgstat = stagec$pgstat,
                        pgtime = stagec$pgtime,
                        as.data.frame(model.matrix(Surv(pgtime,pgstat) ~ .,stagec))[-1])

    #Impute missing values
    dataCancerImputed &lt;- nearestNeighborImpute(dataCancer)

    # Remove the incomplete cases
    dataCancer &lt;- dataCancer[complete.cases(dataCancer),]


    # Load a pre-stablished data frame with the names and descriptions of all variables
    data(cancerVarNames)
    # the Heat Map
    hm &lt;- heatMaps(cancerVarNames,varRank=NULL,Outcome="pgstat",
                   data=dataCancer,title="Heat Map",hCluster=FALSE
                   ,prediction=NULL,Scale=TRUE,
                   theFiveColors=c("blue","cyan","black","yellow","red"),
                   outcomeColors = 
                     c("blue","lightgreen","yellow","orangered","red"),
                   transpose=FALSE,cexRow=0.50,cexCol=0.80,srtCol=35)

    # The univariate analysis
    UniRankFeaturesRaw &lt;- univariateRankVariables(variableList = cancerVarNames,
                                                  formula = "pgstat ~ 1+pgtime",
                                                  Outcome = "pgstat",
                                                  data = dataCancer, 
                                                  categorizationType = "Raw", 
                                                  type = "LOGIT", 
                                                  rankingTest = "zIDI",
                                                  description = "Description",
                                                  uniType="Binary")

    print(UniRankFeaturesRaw)

    # A simple BSIWMS Model

    BSWiMSModel &lt;- BSWiMS.model(formula = Surv(pgtime, pgstat) ~ 1, dataCancerImputed)

    # The Log-Rank Analysis using survdiff

    lrsurvdiff &lt;- survdiff(Surv(pgtime,pgstat)~
                  BSWiMSModel$BSWiMS.model$back.model$linear.predictors &gt; 0,
                  data=dataCancerImputed)

    # The Log-Rank Analysis EmpiricalSurvDiff and permutations of the null Chi distribution
    lrp &lt;- EmpiricalSurvDiff(dataCancerImputed$pgtime,dataCancerImputed$pgstat,
                             BSWiMSModel$BSWiMS.model$back.model$linear.predictors &gt; 0,
                             type="Chi",plots=TRUE,samples=10000)

    # The Log-Rank Analysis EmpiricalSurvDiff and permutations of the null SLR distribution
    lrp &lt;- EmpiricalSurvDiff(dataCancerImputed$pgtime,dataCancerImputed$pgstat,
                             BSWiMSModel$BSWiMS.model$back.model$linear.predictors &gt; 0,
                             type="SLR",plots=TRUE,samples=10000)

    # The Log-Rank Analysis EmpiricalSurvDiff and bootstrapping the SLR distribution
    lrp &lt;- EmpiricalSurvDiff(dataCancerImputed$pgtime,dataCancerImputed$pgstat,
                             BSWiMSModel$BSWiMS.model$back.model$linear.predictors &gt; 0,
                             computeDist=TRUE,plots=TRUE)

    #The performance of the final model using the summary function
    sm &lt;- summary(BSWiMSModel$BSWiMS.model$back.model)
    print(sm$coefficients)
    pv &lt;- plot(sm$bootstrap)

    # The equivalent model
    eq &lt;- reportEquivalentVariables(BSWiMSModel$BSWiMS.model$back.model,data=dataCancer,
                                    variableList=cancerVarNames,Outcome = "pgstat",
                                    timeOutcome="pgtime",
                                    type = "COX");

    print(eq$equivalentMatrix)

    #The list of all models of the bootstrap forward selection 
    print(BSWiMSModel$forward.selection.list)

    #With FRESA.CAD we can do a leave-one-out using the list of models
    pm &lt;- ensemblePredict(BSWiMSModel$forward.selection.list,
                          dataCancer,predictType = "linear",type="LOGIT",Outcome="pgstat")

    #Ploting the ROC with 95
    pm &lt;- plotModels.ROC(cbind(dataCancer$pgstat,
                               pm$ensemblePredict),main=("LOO Forward Selection Median Predict"))

    #The plotModels.ROC provides the diagnosis confusion matrix.
    summary(epi.tests(pm$predictionTable))



    #FRESA.CAD can be used to create a bagged model using the forward selection formulas
    bagging &lt;- baggedModel(BSWiMSModel$forward.selection.list,dataCancer,useFreq=32)
    pm &lt;- predict(bagging$bagged.model)
    pm &lt;- plotModels.ROC(cbind(dataCancer$pgstat,pm),main=("Bagged"))

    #Let's check the performance of the model 
    sm &lt;- summary(bagging$bagged.model)
    print(sm$coefficients)

    #Using bootstrapping object I can check the Jaccard Index
    print(bagging$Jaccard.SM)

    #Ploting the evolution of the coefficient value
    plot(bagging$coefEvolution$grade,main="Evolution of grade")


    gplots::heatmap.2(bagging$formulaNetwork,trace="none",
                      mar=c(10,10),main="eB:SWIMS Formula Network")
    barplot(bagging$frequencyTable,las = 2,cex.axis=1.0,
            cex.names=0.75,main="Feature Frequency")
    n &lt;- network::network(bagging$formulaNetwork, directed = FALSE,
                          ignore.eval = FALSE,names.eval = "weights")
    ggnet2(n, label = TRUE, size = "degree",size.cut = 3,size.min = 1, 
           mode = "circle",edge.label = "weights",edge.label.size=4)


    # Get a Cox proportional hazards model using:
    # - The default parameters

    mdCOXs &lt;- FRESA.Model(formula = Surv(pgtime, pgstat) ~ 1,data = dataCancer)
    sm &lt;- summary(mdCOXs$BSWiMS.model)
    print(sm$coefficients)

    # The model with singificant improvement in the residual error
    mdCOXs &lt;- FRESA.Model(formula = Surv(pgtime, pgstat) ~ 1,
                          data = dataCancer,OptType = "Residual" )
    sm &lt;- summary(mdCOXs$BSWiMS.model)
    print(sm$coefficients)

    # Get a Cox proportional hazards model using second order models:
    mdCOX &lt;- FRESA.Model(formula = Surv(pgtime, pgstat) ~ 1,
                         data = dataCancer,categorizationType="RawRaw")
    sm &lt;- summary(mdCOX$BSWiMS.model)
    print(sm$coefficients)

    namesc &lt;- names(mdCOX$BSWiMS.model$coefficients)[-1]
    hm &lt;- heatMaps(mdCOX$univariateAnalysis[namesc,],varRank=NULL,
                   Outcome="pgstat",data=dataCancer,
                   title="Heat Map",hCluster=FALSE,prediction=NULL,Scale=TRUE,
                   theFiveColors=c("blue","cyan","black","yellow","red"),
                   outcomeColors = c("blue","lightgreen","yellow","orangered","red"),
                   transpose=FALSE,cexRow=0.50,cexCol=0.80,srtCol=35)

    # The LOO estimation
    pm &lt;- ensemblePredict(mdCOX$BSWiMS.models$formula.list,dataCancer,
                          predictType = "linear",type="LOGIT",Outcome="pgstat")
    pm &lt;- plotModels.ROC(cbind(dataCancer$pgstat,pm$ensemblePredict),main=("LOO Median Predict"))
    #Let us check the diagnosis performance
    summary(epi.tests(pm$predictionTable))

    # Get a Logistic model using FRESA.Model
    # - The default parameters
    dataCancer2 &lt;-dataCancer 
    dataCancer2$pgtime &lt;-NULL
    mdLOGIT &lt;- FRESA.Model(formula = pgstat ~ 1,data = dataCancer2)
    if (!is.null(mdLOGIT$bootstrappedModel)) pv &lt;- plot(mdLOGIT$bootstrappedModel)
    sm &lt;- summary(mdLOGIT$BSWiMS.model)
    print(sm$coefficients)


    ## FRESA.Model with Cross Validation and Recursive Partitioning and Regression Trees


    md &lt;- FRESA.Model(formula = Surv(pgtime, pgstat) ~ 1,data = dataCancer,
                      CVfolds = 10,repeats = 5,equivalent = TRUE,usrFitFun=rpart::rpart)

    colnames(md$cvObject$Models.testPrediction)

    pm &lt;- plotModels.ROC(md$cvObject$LASSO.testPredictions,theCVfolds=10,main="CV LASSO",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$KNN.testPrediction,theCVfolds=10,main="KNN",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="Prediction",main="B:SWiMS Bagging",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="Ensemble.B.SWiMS"
                         ,main="Forward Selection Median Ensemble",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="Ensemble.Forward",main="Forward Selection Bagging",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="eB.SWiMS",main="Equivalent Model",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="Forward.Selection.Bagged",main="The Forward Bagging",cex=0.90)

    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=20,
                         predictor="usrFitFunction",
                         main="Recursive Partitioning and Regression Trees",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=20,
                         predictor="usrFitFunction_Sel",
                         main="Recursive Partitioning and Regression Trees with FS",cex=0.90)


    ## FRESA.Model with Cross Validation, LOGISTIC and Support Vector Machine


    md &lt;- FRESA.Model(formula = pgstat ~ 1,data = dataCancer2,
                      CVfolds = 10,repeats = 5,equivalent = TRUE,usrFitFun=svm)

    pm &lt;- plotModels.ROC(md$cvObject$LASSO.testPredictions,theCVfolds=10,main="CV LASSO",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$KNN.testPrediction,theCVfolds=10,main="KNN",cex=0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="Prediction",main="B:SWiMS Bagging",cex=0.90)

    md$cvObject$Models.testPrediction[,"usrFitFunction"] &lt;- 
                      md$cvObject$Models.testPrediction[,"usrFitFunction"] - 0.5
    md$cvObject$Models.testPrediction[,"usrFitFunction_Sel"] &lt;- 
                      md$cvObject$Models.testPrediction[,"usrFitFunction_Sel"] - 0.5
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="usrFitFunction",
                         main="SVM",cex = 0.90)
    pm &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds=10,
                         predictor="usrFitFunction_Sel",
                         main="SVM with FS",cex = 0.90)


    # Shut down the graphics device driver
    dev.off()

   
## End(Not run)
</code></pre>

<hr>
<h2 id='backVarElimination_Bin'>IDI/NRI-based backwards variable elimination</h2><span id='topic+backVarElimination_Bin'></span>

<h3>Description</h3>

<p>This function removes model terms that do not significantly affect the integrated discrimination improvement (IDI) or the net reclassification improvement (NRI) of the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	backVarElimination_Bin(object,
	                   pvalue = 0.05,
	                   Outcome = "Class",
	                   data,
	                   startOffset = 0,
	                   type = c("LOGIT", "LM", "COX"),
	                   selectionType = c("zIDI", "zNRI")
					   )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="backVarElimination_Bin_+3A_object">object</code></td>
<td>
 
<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="backVarElimination_Bin_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to either IDI or NRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="backVarElimination_Bin_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="backVarElimination_Bin_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="backVarElimination_Bin_+3A_startoffset">startOffset</code></td>
<td>

<p>Only terms whose position in the model is larger than the <code>startOffset</code> are candidates to be removed
</p>
</td></tr>
<tr><td><code id="backVarElimination_Bin_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="backVarElimination_Bin_+3A_selectiontype">selectionType</code></td>
<td>

<p>The type of index to be evaluated by the <code>improveProb</code> function (<code>Hmisc</code> package): <em>z</em>-score of IDI or of NRI
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each model term <code class="reqn">x_i</code>, the IDI or NRI is computed for the Full model and the reduced model( where the term <code class="reqn">x_i</code> removed).
The term whose removal results in the smallest drop in improvement is selected. The hypothesis: the 
term adds classification improvement is tested by checking the pvalue of improvement. If <code class="reqn">p(IDI or NRI)&gt;pvalue</code>, then the term is removed. 
In other words, only model terms that significantly aid in subject classification are kept.
The procedure is repeated until no term fulfils the removal criterion.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>back.model</code></td>
<td>

<p>An object of the same class as <code>object</code> containing the reduced model
</p>
</td></tr>
<tr><td><code>loops</code></td>
<td>

<p>The number of loops it took for the model to stabilize
</p>
</td></tr>
<tr><td><code>reclas.info</code></td>
<td>

<p>A list with the NRI and IDI statistics of the reduced model, as given by the <code>getVar.Bin</code> function
</p>
</td></tr>
<tr><td><code>back.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the reduced model
</p>
</td></tr>
<tr><td><code>lastRemoved</code></td>
<td>

<p>The name of the last term that was removed (-1 if all terms were removed)
</p>
</td></tr>
<tr><td><code>at.opt.model</code></td>
<td>

<p>the model before the BH procedure
</p>
</td></tr>
<tr><td><code>beforeFSC.formula</code></td>
<td>

<p>the string formula of the model before the BH procedure
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>See Also</h3>

<p><code><a href="#topic+backVarElimination_Res">backVarElimination_Res</a>, 
				 <a href="#topic+bootstrapVarElimination_Bin">bootstrapVarElimination_Bin</a>,
				 <a href="#topic+bootstrapVarElimination_Res">bootstrapVarElimination_Res</a></code></p>

<hr>
<h2 id='backVarElimination_Res'>NeRI-based backwards variable elimination</h2><span id='topic+backVarElimination_Res'></span>

<h3>Description</h3>

<p>This function removes model terms that do not significantly improve the &quot;net residual&quot; (NeRI) 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	backVarElimination_Res(object,
	                       pvalue = 0.05,
	                       Outcome = "Class",
	                       data,
	                       startOffset = 0, 
	                       type = c("LOGIT", "LM", "COX"),
	                       testType = c("Binomial", "Wilcox", "tStudent", "Ftest"),
	                       setIntersect = 1
						   )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="backVarElimination_Res_+3A_object">object</code></td>
<td>
 
<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="backVarElimination_Res_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the NeRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="backVarElimination_Res_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="backVarElimination_Res_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="backVarElimination_Res_+3A_startoffset">startOffset</code></td>
<td>

<p>Only terms whose position in the model is larger than the <code>startOffset</code> are candidates to be removed
</p>
</td></tr>
<tr><td><code id="backVarElimination_Res_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="backVarElimination_Res_+3A_testtype">testType</code></td>
<td>

<p>Type of non-parametric test to be evaluated by the <code>improvedResiduals</code> function: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
<tr><td><code id="backVarElimination_Res_+3A_setintersect">setIntersect</code></td>
<td>

<p>The intersect of the model (To force a zero intersect, set this value to 0)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each model term <code class="reqn">x_i</code>, the residuals are computed for the Full model and the reduced model( where the term <code class="reqn">x_i</code> removed).
The term whose removal results in the smallest drop in residuals improvement is selected. The hypothesis: the 
term improves residuals is tested by checking the pvalue of improvement. If <code class="reqn">p(residuals better than reduced residuals)&gt;pvalue</code>, then the term is removed. 
In other words, only model terms that significantly aid in improving residuals are kept.
The procedure is repeated until no term fulfils the removal criterion.
The p-values of improvement can be computed via a sign-test (Binomial) a paired Wilcoxon test, paired t-test or f-test. The first three tests compare the absolute values of
the residuals, while the f-test test if the variance of the residuals is improved significantly.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>back.model</code></td>
<td>

<p>An object of the same class as <code>object</code> containing the reduced model
</p>
</td></tr>
<tr><td><code>loops</code></td>
<td>

<p>The number of loops it took for the model to stabilize
</p>
</td></tr>
<tr><td><code>reclas.info</code></td>
<td>

<p>A list with the NeRI statistics of the reduced model, as given by the <code>getVar.Res</code> function
</p>
</td></tr>
<tr><td><code>back.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the reduced model
</p>
</td></tr>
<tr><td><code>lastRemoved</code></td>
<td>

<p>The name of the last term that was removed (-1 if all terms were removed)
</p>
</td></tr>
<tr><td><code>at.opt.model</code></td>
<td>

<p>the model with before the FSR procedure. 
</p>
</td></tr>
<tr><td><code>beforeFSC.formula</code></td>
<td>

<p>the string formula of the the FSR procedure
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+backVarElimination_Bin">backVarElimination_Bin</a>,
				 <a href="#topic+bootstrapVarElimination_Bin">bootstrapVarElimination_Bin</a>
				 <a href="#topic+bootstrapVarElimination_Res">bootstrapVarElimination_Res</a></code></p>

<hr>
<h2 id='baggedModel'>Get the bagged model from a list of models</h2><span id='topic+baggedModel'></span><span id='topic+baggedModelS'></span>

<h3>Description</h3>

<p>This function will take the frequency-ranked of variables and the list of models to create a single bagged model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	baggedModel(modelFormulas,
	            data,
	            type=c("LM","LOGIT","COX"),
	            Outcome=NULL,
	            timeOutcome=NULL,
	            frequencyThreshold=0.025,
	            univariate=NULL,
				useFreq=TRUE,
				n_bootstrap=1,
				equifreqCorrection=0
	            )
	baggedModelS(modelFormulas,
                 data,
                 type=c("LM","LOGIT","COX"),
                 Outcome=NULL,
                 timeOutcome=NULL)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="baggedModel_+3A_modelformulas">modelFormulas</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_data">data</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to outcome
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event (needed only for a Cox proportional hazards regression model fitting)
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_frequencythreshold">frequencyThreshold</code></td>
<td>

<p>set the frequency the threshold of the frequency of features to be included in the model)
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_univariate">univariate</code></td>
<td>

<p>The FFRESA.CAD univariate analysis matrix
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_usefreq">useFreq</code></td>
<td>

<p>Use the feature frequency to order the formula terms. If set to a positive value is the number of estimation loops
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_n_bootstrap">n_bootstrap</code></td>
<td>

<p>if greater than 1, defines the number of bootstraps samples to be used
</p>
</td></tr>
<tr><td><code id="baggedModel_+3A_equifreqcorrection">equifreqCorrection</code></td>
<td>

<p>Indicates the average size of repeated features in an equivalent model
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>bagged.model</code></td>
<td>

<p>the bagged model
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>the formula of the model
</p>
</td></tr>
<tr><td><code>frequencyTable</code></td>
<td>

<p>the table of variables ranked by their model frequency
</p>
</td></tr>
<tr><td><code>faverageSize</code></td>
<td>

<p>the average size of the models
</p>
</td></tr>
<tr><td><code>formulaNetwork</code></td>
<td>

<p>The matrix of interaction between formulas
</p>
</td></tr>
<tr><td><code>Jaccard.SM</code></td>
<td>

<p>The Jaccard Stability Measure of the formulas
</p>
</td></tr>
<tr><td><code>coefEvolution</code></td>
<td>

<p>The evolution of the coefficients
</p>
</td></tr>
<tr><td><code>avgZvalues</code></td>
<td>

<p>The average Z value of each coefficient
</p>
</td></tr>	
<tr><td><code>featureLocation</code></td>
<td>

<p>The average location of the feature in the formulas
</p>
</td></tr>	
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+ensemblePredict">ensemblePredict</a></code></p>

<hr>
<h2 id='barPlotCiError'>Bar plot with error bars</h2><span id='topic+barPlotCiError'></span>

<h3>Description</h3>

<p>Ranked Plot a set of measurements with error bars or confidence intervals (CI)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>barPlotCiError(ciTable, 
               metricname, 
			   thesets, 
			   themethod, 
			   main, 
			   angle = 0, 
			   offsets = c(0.1,0.1),
               scoreDirection = "&gt;",
               ho=NULL,		   
			   ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="barPlotCiError_+3A_citable">ciTable</code></td>
<td>

<p>A matrix with three columns: the value, the low CI value and the high CI value 
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_metricname">metricname</code></td>
<td>

<p>The name of the plotted values
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_thesets">thesets</code></td>
<td>

<p>A character vector with the names of the sets
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_themethod">themethod</code></td>
<td>

<p>A character vector with the names of the methods
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_main">main</code></td>
<td>

<p>The plot title
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_angle">angle</code></td>
<td>

<p>The angle of the x labels
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_offsets">offsets</code></td>
<td>

<p>The offset of the x-labels
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_scoredirection">scoreDirection</code></td>
<td>

<p>Indicates how to aggregate the supMethod score and the ingMethod score.
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_ho">ho</code></td>
<td>

<p>the null hypothesis
</p>
</td></tr>
<tr><td><code id="barPlotCiError_+3A_...">...</code></td>
<td>

<p>Extra parametrs pased to the barplot function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>barplot</code></td>
<td>

<p>the x-location of the bars
</p>
</td></tr>
<tr><td><code>ciTable</code></td>
<td>

<p>the ordered matrix with the 95 CI
</p>
</td></tr>
<tr><td><code>barMatrix</code></td>
<td>

<p>the mean values of the bars
</p>
</td></tr>
<tr><td><code>supMethod</code></td>
<td>

<p>A superiority score equal to the numbers of methods that were inferior
</p>
</td></tr>
<tr><td><code>infMethod</code></td>
<td>

<p>A inferiority score equal to the number of methods that were superior
</p>
</td></tr>
<tr><td><code>interMethodScore</code></td>
<td>

<p>the sum of supMethod and infMethod defined by the score direction.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='benchmarking'>Compare performance of different model fitting/filtering algorithms</h2><span id='topic+BinaryBenchmark'></span><span id='topic+RegresionBenchmark'></span><span id='topic+OrdinalBenchmark'></span><span id='topic+CoxBenchmark'></span>

<h3>Description</h3>

<p>Evaluates a data set with a set of fitting/filtering methods and returns the observed cross-validation performance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
BinaryBenchmark(theData = NULL, theOutcome = "Class", reps = 100, trainFraction = 0.5,
                referenceCV = NULL,referenceName = "Reference"
                ,referenceFilterName="Reference")
RegresionBenchmark(theData = NULL, theOutcome = "Class", reps = 100, trainFraction = 0.5,
                referenceCV = NULL,referenceName = "Reference"
                ,referenceFilterName="Reference")
OrdinalBenchmark(theData = NULL, theOutcome = "Class", reps = 100, trainFraction = 0.5,
                referenceCV = NULL,referenceName = "Reference"
                ,referenceFilterName="Reference")

CoxBenchmark(theData = NULL, theOutcome = "Class", reps = 100, trainFraction = 0.5,
                referenceCV = NULL,referenceName = "Reference"
                ,referenceFilterName="COX.BSWiMS")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="benchmarking_+3A_thedata">theData</code></td>
<td>

<p>The data frame
</p>
</td></tr>
<tr><td><code id="benchmarking_+3A_theoutcome">theOutcome</code></td>
<td>

<p>The outcome feature
</p>
</td></tr>
<tr><td><code id="benchmarking_+3A_reps">reps</code></td>
<td>

<p>The number of times that the random cross-validation will be performed
</p>
</td></tr>
<tr><td><code id="benchmarking_+3A_trainfraction">trainFraction</code></td>
<td>

<p>The fraction of the data used for training.
</p>
</td></tr>
<tr><td><code id="benchmarking_+3A_referencecv">referenceCV</code></td>
<td>

<p>A  single random cross-validation object to be benchmarked or a list of CVObjects to be compared
</p>
</td></tr>
<tr><td><code id="benchmarking_+3A_referencename">referenceName</code></td>
<td>

<p>The name of the reference classifier to be used in the reporting tables
</p>
</td></tr>
<tr><td><code id="benchmarking_+3A_referencefiltername">referenceFilterName</code></td>
<td>

<p>The name of the reference filter to be used in the reporting tables
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The benchmark functions provide the performance of different classification algorithms (BinaryBenchmark), registration algorithms (RegresionBenchmark) or ordinal regression algorithms (OrdinalBenchmark)
The evaluation method is based on applying the random cross-validation method (<code><a href="#topic+randomCV">randomCV</a></code>) that randomly splits the data into train and test sets.
The user can provide a Cross validated object that will define the train-test partitions.
</p>
<p>The BinaryBenchmark compares: BSWiMS,Random Forest ,RPART,LASSO,SVM/mRMR,KNN and the ensemble of them in their ability to correctly classify the test data.
Furthermore, it evaluates the ability of the following feature selection algorithms:
BSWiMS or ReferenceCV,
LASSO,
RPART,
RF/BSWiMS,
IDI,
NRI,
t-test,
Wilcoxon,
Kendall,
and mRMR
in their ability to select the best set of features for the following classification methods:
SVM,
KNN,
Naive Bayes,
Random Forest
Nearest Centroid (NC) with root sum square (RSS) ,
and NC with Spearman correlation
</p>
<p>The RegresionBenchmark compares: BSWiMS,Random Forest ,RPART,LASSO,SVM/mRMR and the ensemble of them in their ability to correctly predict the test data.
Furthermore, it evaluates the ability of the following feature selection algorithms:
BSWiMS or referenceCV,
LASSO,
RPART,
RF/BSWiMS,
F-Test,
W-Test,
Pearson
Kendall,
and mRMR
in their ability to select the best set of features for the following regression methods:
Linear Regression,
Robust Regression,
Ridge Regression,
LASSO,
SVM,
and Random Forest.
</p>
<p>The OrdinalBenchmark  compares: BSWiMS,Random Forest ,RPART,LASSO,KNN ,SVM and the ensemble of them in their ability to correctly predict the test data.
Furthermore, it evaluates the ability of the following feature selection algorithms:
BSWiMS or referenceCV,
LASSO,
RPART,
RF/BSWiMS,
F-Test,
Kendall,
and mRMR
in their ability to select the best set of features for the following regression methods:
Ordinal,
KNN,
SVM,
Random Forest,
and Naive Bayes.
</p>
<p>The CoxBenchmark compares: BSWiMS, LASSO, BeSS and Univariate Cox analysis in their ability to correctly predict the risk of event happening.
It uses cox regression with the four alternatives, but BSWiMS, LASSO are also compared as Wrapper methods.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>errorciTable</code></td>
<td>

<p>the matrix of the balanced error with the 95 CI
</p>
</td></tr>
<tr><td><code>accciTable</code></td>
<td>

<p>the matrix of the classification accuracy with the 95 CI
</p>
</td></tr>
<tr><td><code>aucTable</code></td>
<td>

<p>the matrix of the ROC AUC with the 95 CI
</p>
</td></tr>
<tr><td><code>senTable</code></td>
<td>

<p>the matrix of the sensitivity with the 95 CI
</p>
</td></tr>
<tr><td><code>speTable</code></td>
<td>

<p>the matrix of the specificity with the 95 CI
</p>
</td></tr>
<tr><td><code>errorciTable_filter</code></td>
<td>

<p>the matrix of the balanced error with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>accciTable_filter</code></td>
<td>

<p>the matrix of the classification accuracy with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>senciTable_filter</code></td>
<td>

<p>the matrix of the classification sensitivity with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>speciTable_filter</code></td>
<td>

<p>the matrix of the classification specificity with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>aucTable_filter</code></td>
<td>

<p>the matrix of the ROC AUC with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>CorTable</code></td>
<td>

<p>the matrix of the Pearson correlation with the 95 CI
</p>
</td></tr>
<tr><td><code>RMSETable</code></td>
<td>

<p>the matrix of the root mean square error (RMSE) with the 95 CI
</p>
</td></tr>
<tr><td><code>BiasTable</code></td>
<td>

<p>the matrix of the prediction bias with the 95 CI
</p>
</td></tr>
<tr><td><code>CorTable_filter</code></td>
<td>

<p>the matrix of the Pearson correlation with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>RMSETable_filter</code></td>
<td>

<p>the matrix of the root mean square error (RMSE) with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>BiasTable_filter</code></td>
<td>

<p>the matrix of the prediction bias with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>BMAETable</code></td>
<td>

<p>the matrix of the balanced mean absolute error (MEA) with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>KappaTable</code></td>
<td>

<p>the matrix of the Kappa value with the 95 CI
</p>
</td></tr>
<tr><td><code>BiasTable</code></td>
<td>

<p>the matrix of the prediction Bias with the 95 CI
</p>
</td></tr>
<tr><td><code>KendallTable</code></td>
<td>

<p>the matrix of the Kendall correlation with the 95 CI
</p>
</td></tr>
<tr><td><code>MAETable_filter</code></td>
<td>

<p>the matrix of the mean absolute error (MEA) with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>KappaTable_filter</code></td>
<td>

<p>the matrix of the Kappa value with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>BiasTable_filter</code></td>
<td>

<p>the matrix of the prediction Bias with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>KendallTable_filter</code></td>
<td>

<p>the matrix of the Kendall correlation with the 95 CI for filter methods
</p>
</td></tr>
<tr><td><code>CIRiskTable</code></td>
<td>

<p>the matrix of the concordance index on Risk with the 95 CI 
</p>
</td></tr>
<tr><td><code>LogRankTable</code></td>
<td>

<p>the matrix of the LogRank Test with the 95 CI 
</p>
</td></tr>
<tr><td><code>CIRisksTable_filter</code></td>
<td>

<p>the matrix of the concordance index on Risk with the 95 CI for the filter methods
</p>
</td></tr>
<tr><td><code>LogRankTable_filter</code></td>
<td>

<p>the matrix of the LogRank Test with the 95 CI for the filter methods
</p>
</td></tr>
<tr><td><code>times</code></td>
<td>

<p>The average CPU time used by the method
</p>
</td></tr>
<tr><td><code>jaccard_filter</code></td>
<td>

<p>The average Jaccard Index of the feature selection methods
</p>
</td></tr>
<tr><td><code>TheCVEvaluations</code></td>
<td>

<p>The output of the randomCV (<code><a href="#topic+randomCV">randomCV</a></code>) evaluations of the different methods
</p>
</td></tr>
<tr><td><code>testPredictions</code></td>
<td>

<p>A matrix with all the test predictions
</p>
</td></tr>
<tr><td><code>featureSelectionFrequency</code></td>
<td>

<p>The frequency of feature selection
</p>
</td></tr>
<tr><td><code>cpuElapsedTimes</code></td>
<td>

<p>The mean elapsed times
</p>
</td></tr>
</table>
<p>cpuElapsedTimes
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+randomCV">randomCV</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 

		### Binary Classification Example ####
		# Start the graphics device driver to save all plots in a pdf format
		pdf(file = "BinaryClassificationExample.pdf",width = 8, height = 6)
		# Get the stage C prostate cancer data from the rpart package

		data(stagec,package = "rpart")

		# Prepare the data. Create a model matrix without the event time
		stagec$pgtime &lt;- NULL
		stagec$eet &lt;- as.factor(stagec$eet)
		options(na.action = 'na.pass')
		stagec_mat &lt;- cbind(pgstat = stagec$pgstat,
		as.data.frame(model.matrix(pgstat ~ .,stagec))[-1])

		# Impute the missing data
        dataCancerImputed &lt;- nearestNeighborImpute(stagec_mat)
        dataCancerImputed[,1:ncol(dataCancerImputed)] &lt;- sapply(dataCancerImputed,as.numeric)	

		# Cross validating a LDA classifier.
		# 80
		cv &lt;- randomCV(dataCancerImputed,"pgstat",MASS::lda,trainFraction = 0.8, 
		repetitions = 10,featureSelectionFunction = univariate_tstudent,
		featureSelection.control = list(limit = 0.5,thr = 0.975));

		# Compare the LDA classifier with other methods
		cp &lt;- BinaryBenchmark(referenceCV = cv,referenceName = "LDA",
		                      referenceFilterName="t.Student")
		pl &lt;- plot(cp,prefix = "StageC: ")

		# Default Benchmark classifiers method (BSWiMS) and filter methods. 
		# 80
		cp &lt;- BinaryBenchmark(theData = dataCancerImputed,
		theOutcome = "pgstat", reps = 10, fraction = 0.8)

		# plot the Cross Validation Metrics
		pl &lt;- plot(cp,prefix = "Stagec:");

		# Shut down the graphics device driver
		dev.off()

		#### Regression Example ######
		# Start the graphics device driver to save all plots in a pdf format
		pdf(file = "RegressionExample.pdf",width=8, height=6)

		# Get the body fat data from the TH package

		data("bodyfat", package = "TH.data")

		# Benchmark regression methods and filter methods. 
		#80
		cp &lt;- RegresionBenchmark(theData = bodyfat, 
		theOutcome = "DEXfat", reps = 10, fraction = 0.8)

		# plot the Cross Validation Metrics
		pl &lt;- plot(cp,prefix = "Body Fat:");
		# Shut down the graphics device driver
		dev.off()

		#### Ordinal Regression Example #####
		# Start the graphics device driver to save all plots in a pdf format
		pdf(file = "OrdinalRegressionExample.pdf",width=8, height=6)


		# Get the GBSG2 data
		data("GBSG2", package = "TH.data")

		# Prepare the model frame for benchmarking
		GBSG2$time &lt;- NULL;
		GBSG2$cens &lt;- NULL;
		GBSG2_mat &lt;- cbind(tgrade = as.numeric(GBSG2$tgrade),
		as.data.frame(model.matrix(tgrade~.,GBSG2))[-1])

		# Benchmark regression methods and filter methods. 
		#30
		cp &lt;- OrdinalBenchmark(theData = GBSG2_mat, 
		theOutcome = "tgrade", reps = 10, fraction = 0.3)

		# plot the Cross Validation Metrics
		pl &lt;- plot(cp,prefix = "GBSG:");

		# Shut down the graphics device driver
		dev.off()

	
## End(Not run)

</code></pre>

<hr>
<h2 id='BESS'>CV BeSS fit</h2><span id='topic+BESS'></span><span id='topic+BESS_GSECTION'></span><span id='topic+BESS_EBIC'></span>

<h3>Description</h3>

<p>Fits a <code>BeSS::bess</code> object to the data, and return the selected features  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	BESS(formula = formula, data=NULL, method="sequential", ic.type="BIC",...)
    BESS_GSECTION(formula = formula, data=NULL, method="gsection", ic.type="NULL",...)
    BESS_EBIC(formula = formula, data=NULL, ic.type="EBIC",...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BESS_+3A_formula">formula</code></td>
<td>

<p>The base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="BESS_+3A_data">data</code></td>
<td>

<p>The data to be used for training the bess model
</p>
</td></tr>
<tr><td><code id="BESS_+3A_method">method</code></td>
<td>

<p>BeSS: Methods to be used to select the optimal model size
</p>
</td></tr>
<tr><td><code id="BESS_+3A_ic.type">ic.type</code></td>
<td>

<p>BeSS: Types of best model returned.
</p>
</td></tr>
<tr><td><code id="BESS_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the <code>BeSS::bess</code> function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fit</code></td>
<td>

<p>The <code>BsSS::bess</code> fitted object
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>The formula
</p>
</td></tr>
<tr><td><code>usedFeatures</code></td>
<td>

<p>The list of features used by fit
</p>
</td></tr>
<tr><td><code>selectedfeatures</code></td>
<td>

<p>The character vector of the model features according to BeSS type
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jorge Orozco</p>


<h3>See Also</h3>

<p><code>BeSS::bess</code></p>

<hr>
<h2 id='bootstrapValidation_Bin'>Bootstrap validation of binary classification models</h2><span id='topic+bootstrapValidation_Bin'></span>

<h3>Description</h3>

<p>This function bootstraps the model <em>n</em> times to estimate for each variable the empirical distribution of model coefficients, area under ROC curve (AUC), integrated discrimination improvement (IDI) and net reclassification improvement (NRI).
At each bootstrap the non-observed data is predicted by the trained model, and statistics of the test prediction are stored and reported.
The method keeps track of predictions and plots the bootstrap-validated ROC.
It may  plots the blind test accuracy, sensitivity, and specificity, contrasted with the bootstrapped trained distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	bootstrapValidation_Bin(fraction = 1,
	                    loops = 200,
	                    model.formula,
	                    Outcome,
	                    data,
	                    type = c("LM", "LOGIT", "COX"),
	                    plots = FALSE,
						best.model.formula=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrapValidation_Bin_+3A_fraction">fraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Bin_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Bin_+3A_model.formula">model.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be used
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Bin_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Bin_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Bin_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Bin_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>, density distribution plots are displayed
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Bin_+3A_best.model.formula">best.model.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be used for the best model
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bootstrap validation will estimate the confidence interval of the model coefficients and the NRI and IDI.
The non-sampled values will be used to estimate the blind accuracy, sensitivity, and specificity.  
A plot to monitor the evolution of the bootstrap procedure will be displayed if <code>plots</code> is set to TRUE.
The plot shows the train and blind test ROC.
The density distribution of the train accuracy, sensitivity, and specificity are also shown, with the blind test results drawn along the y-axis.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>data</code></td>
<td>

<p>The data frame used to bootstrap and validate the model
</p>
</td></tr>
<tr><td><code>outcome</code></td>
<td>

<p>A vector with the predictions made by the model
</p>
</td></tr>
<tr><td><code>blind.accuracy</code></td>
<td>

<p>The accuracy of the model in the blind test set
</p>
</td></tr>
<tr><td><code>blind.sensitivity</code></td>
<td>

<p>The sensitivity of the model in the blind test set
</p>
</td></tr>
<tr><td><code>blind.specificity</code></td>
<td>

<p>The specificity of the model in the blind test set
</p>
</td></tr>
<tr><td><code>train.ROCAUC</code></td>
<td>

<p>A vector with the AUC in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>blind.ROCAUC</code></td>
<td>

<p>An object of class <code>roc</code> containing the AUC in the bootstrap blind test set
</p>
</td></tr>
<tr><td><code>boot.ROCAUC</code></td>
<td>

<p>An object of class <code>roc</code> containing the AUC using the mean of the bootstrapped coefficients
</p>
</td></tr>
<tr><td><code>fraction</code></td>
<td>

<p>The fraction of data that was sampled with replacement
</p>
</td></tr>
<tr><td><code>loops</code></td>
<td>

<p>The number of loops it took for the model to stabilize
</p>
</td></tr>
<tr><td><code>base.Accuracy</code></td>
<td>

<p>The accuracy of the original model
</p>
</td></tr>
<tr><td><code>base.sensitivity</code></td>
<td>

<p>The sensitivity of the original model
</p>
</td></tr>
<tr><td><code>base.specificity</code></td>
<td>

<p>The specificity of the original model
</p>
</td></tr>
<tr><td><code>accuracy</code></td>
<td>

<p>A vector with the accuracies in the bootstrap test sets
</p>
</td></tr>
<tr><td><code>sensitivities</code></td>
<td>

<p>A vector with the sensitivities in the bootstrap test sets
</p>
</td></tr>
<tr><td><code>specificities</code></td>
<td>

<p>A vector with the specificities in the bootstrap test sets
</p>
</td></tr>
<tr><td><code>train.accuracy</code></td>
<td>

<p>A vector with the accuracies in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>train.sensitivity</code></td>
<td>

<p>A vector with the sensitivities in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>train.specificity</code></td>
<td>

<p>A vector with the specificities in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>s.coef</code></td>
<td>

<p>A matrix with the coefficients in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>boot.model</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing a model whose coefficients are the median of the coefficients of the bootstrapped models
</p>
</td></tr>
<tr><td><code>boot.accuracy</code></td>
<td>

<p>The accuracy of the <code>mboot.model</code> model
</p>
</td></tr>
<tr><td><code>boot.sensitivity</code></td>
<td>

<p>The sensitivity of the <code>mboot.model</code> model
</p>
</td></tr>
<tr><td><code>boot.specificity</code></td>
<td>

<p>The specificity of the <code>mboot.model</code> model
</p>
</td></tr>
<tr><td><code>z.NRIs</code></td>
<td>

<p>A matrix with the <em>z</em>-score of the NRI for each model term, estimated using the bootstrap train sets
</p>
</td></tr>
<tr><td><code>z.IDIs</code></td>
<td>

<p>A matrix with the <em>z</em>-score of the IDI for each model term, estimated using the bootstrap train sets
</p>
</td></tr>
<tr><td><code>test.z.NRIs</code></td>
<td>

<p>A matrix with the <em>z</em>-score of the NRI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>test.z.IDIs</code></td>
<td>

<p>A matrix with the <em>z</em>-score of the IDI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>NRIs</code></td>
<td>

<p>A matrix with the NRI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>IDIs</code></td>
<td>

<p>A matrix with the IDI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>testOutcome</code></td>
<td>

<p>A vector that contains all the individual outcomes used to validate the model in the bootstrap test sets
</p>
</td></tr>
<tr><td><code>testPrediction</code></td>
<td>

<p>A vector that contains all the individual predictions used to validate the model in the bootstrap test sets
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrapValidation_Res">bootstrapValidation_Res</a>,
				 <a href="#topic+plot.bootstrapValidation_Bin">plot.bootstrapValidation_Bin</a>,
				 <a href="#topic+summary.bootstrapValidation_Bin">summary.bootstrapValidation_Bin</a></code></p>

<hr>
<h2 id='bootstrapValidation_Res'>Bootstrap validation of regression models</h2><span id='topic+bootstrapValidation_Res'></span>

<h3>Description</h3>

<p>This function bootstraps the model <em>n</em> times to estimate for each variable the empirical bootstrapped distribution of model coefficients, and net residual improvement (NeRI).
At each bootstrap the non-observed data is predicted by the trained model, and statistics of the test prediction are stores and reported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	bootstrapValidation_Res(fraction = 1,
	                        loops = 200,
	                        model.formula,
	                        Outcome,
	                        data,
	                        type = c("LM", "LOGIT", "COX"),
	                        plots = FALSE,
							bestmodel.formula=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrapValidation_Res_+3A_fraction">fraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Res_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Res_+3A_model.formula">model.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be used
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Res_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Res_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Res_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Res_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>, density distribution plots are displayed
</p>
</td></tr>
<tr><td><code id="bootstrapValidation_Res_+3A_bestmodel.formula">bestmodel.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the best formula to be compared
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bootstrap validation will estimate the confidence interval of the model coefficients and the NeRI.
It will also compute the train and blind test root-mean-square error (RMSE), as well as the distribution of the NeRI <em>p</em>-values.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>data</code></td>
<td>

<p>The data frame used to bootstrap and validate the model
</p>
</td></tr>
<tr><td><code>outcome</code></td>
<td>

<p>A vector with the predictions made by the model
</p>
</td></tr>
<tr><td><code>boot.model</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing a model whose coefficients are the median of the coefficients of the bootstrapped models
</p>
</td></tr>
<tr><td><code>NeRIs</code></td>
<td>

<p>A matrix with the NeRI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>tStudent.pvalues</code></td>
<td>

<p>A matrix with the <em>t</em>-test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap train sets
</p>
</td></tr>
<tr><td><code>wilcox.pvalues</code></td>
<td>

<p>A matrix with the Wilcoxon rank-sum test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap train sets
</p>
</td></tr>
<tr><td><code>bin.pvalues</code></td>
<td>

<p>A matrix with the binomial test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap train sets
</p>
</td></tr>
<tr><td><code>F.pvalues</code></td>
<td>

<p>A matrix with the <em>F</em>-test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap train sets
</p>
</td></tr>
<tr><td><code>test.tStudent.pvalues</code></td>
<td>

<p>A matrix with the <em>t</em>-test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>test.wilcox.pvalues</code></td>
<td>

<p>A matrix with the Wilcoxon rank-sum test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>test.bin.pvalues</code></td>
<td>

<p>A matrix with the binomial test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>test.F.pvalues</code></td>
<td>

<p>A matrix with the <em>F</em>-test <em>p</em>-value of the NeRI for each model term, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>testPrediction</code></td>
<td>

<p>A vector that contains all the individual predictions used to validate the model in the bootstrap test sets
</p>
</td></tr>
<tr><td><code>testOutcome</code></td>
<td>

<p>A vector that contains all the individual outcomes used to validate the model in the bootstrap test sets
</p>
</td></tr>
<tr><td><code>testResiduals</code></td>
<td>

<p>A vector that contains all the residuals used to validate the model in the bootstrap test sets
</p>
</td></tr>
<tr><td><code>trainPrediction</code></td>
<td>

<p>A vector that contains all the individual predictions used to validate the model in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>trainOutcome</code></td>
<td>

<p>A vector that contains all the individual outcomes used to validate the model in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>trainResiduals</code></td>
<td>

<p>A vector that contains all the residuals used to validate the model in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>testRMSE</code></td>
<td>

<p>The global RMSE, estimated using the bootstrap test sets
</p>
</td></tr>
<tr><td><code>trainRMSE</code></td>
<td>

<p>The global RMSE, estimated using the bootstrap train sets
</p>
</td></tr>
<tr><td><code>trainSampleRMSE</code></td>
<td>

<p>A vector with the RMSEs in the bootstrap train sets
</p>
</td></tr>
<tr><td><code>testSampledRMSE</code></td>
<td>

<p>A vector with the RMSEs in the bootstrap test sets
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrapValidation_Bin">bootstrapValidation_Bin</a>,
				 <a href="#topic+plot.bootstrapValidation_Res">plot.bootstrapValidation_Res</a></code></p>

<hr>
<h2 id='bootstrapVarElimination_Bin'>IDI/NRI-based backwards variable elimination with bootstrapping</h2><span id='topic+bootstrapVarElimination_Bin'></span>

<h3>Description</h3>

<p>This function removes model terms that do not improve the bootstrapped integrated discrimination improvement (IDI) or net reclassification improvement (NRI) significantly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	bootstrapVarElimination_Bin(object,
	                        pvalue = 0.05,
	                        Outcome = "Class",
	                        data,
	                        startOffset = 0, 
	                        type = c("LOGIT", "LM", "COX"),
	                        selectionType = c("zIDI", "zNRI"),
	                        loops = 64,
	                        print=TRUE,
	                        plots=TRUE
	                        )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrapVarElimination_Bin_+3A_object">object</code></td>
<td>
 
<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to either IDI or NRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_startoffset">startOffset</code></td>
<td>

<p>Only terms whose position in the model is larger than the <code>startOffset</code> are candidates to be removed
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_selectiontype">selectionType</code></td>
<td>

<p>The type of index to be evaluated by the <code>improveProb</code> function (<code>Hmisc</code> package): <em>z</em>-score of IDI or of NRI
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_print">print</code></td>
<td>

<p>Logical. If <code>TRUE</code>, information will be displayed
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Bin_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>,  plots are displayed
</p>
</td></tr>	
</table>


<h3>Details</h3>

<p>For each model term <code class="reqn">x_i</code>, the IDI or NRI is computed for the Full model and the reduced model( where the term <code class="reqn">x_i</code> removed).
The term whose removal results in the smallest drop in bootstrapped improvement is selected. The hypothesis: the 
term adds classification improvement is tested by checking the p value of average improvement. If <code class="reqn">p(IDI or NRI)&gt;pvalue</code>, then the term is removed. 
In other words, only model terms that significantly aid in subject classification are kept.
The procedure is repeated until no term fulfils the removal criterion.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>back.model</code></td>
<td>

<p>An object of the same class as <code>object</code> containing the reduced model
</p>
</td></tr>
<tr><td><code>loops</code></td>
<td>

<p>The number of loops it took for the model to stabilize
</p>
</td></tr>
<tr><td><code>reclas.info</code></td>
<td>

<p>A list with the NRI and IDI statistics of the reduced model, as given by the <code>getVar.Bin</code> function
</p>
</td></tr>
<tr><td><code>bootCV</code></td>
<td>

<p>An object of class <code>bootstrapValidation_Bin</code> containing the results of the bootstrap validation in the reduced model
</p>
</td></tr>
<tr><td><code>back.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the reduced model
</p>
</td></tr>
<tr><td><code>lastRemoved</code></td>
<td>

<p>The name of the last term that was removed (-1 if all terms were removed)
</p>
</td></tr>
<tr><td><code>at.opt.model</code></td>
<td>

<p>The model will have the fitted model that had close to maximum bootstrapped test accuracy 
</p>
</td></tr>
<tr><td><code>beforeFSC.formula</code></td>
<td>

<p>The formula of the model before False Selection Correction
</p>
</td></tr>
<tr><td><code>at.Accuracy.formula</code></td>
<td>

<p>the string formula of the model that had the best or close to tbe best test accuracy 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrapVarElimination_Res">bootstrapVarElimination_Res</a>,
				 <a href="#topic+backVarElimination_Bin">backVarElimination_Bin</a>,
				 <a href="#topic+backVarElimination_Res">backVarElimination_Res</a></code></p>

<hr>
<h2 id='bootstrapVarElimination_Res'>NeRI-based backwards variable elimination with bootstrapping</h2><span id='topic+bootstrapVarElimination_Res'></span>

<h3>Description</h3>

<p>This function removes model terms that do not improve the bootstrapped net residual improvement (NeRI) significantly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	bootstrapVarElimination_Res(object,
	                            pvalue = 0.05,
	                            Outcome = "Class",
	                            data,
	                            startOffset = 0, 
	                            type = c("LOGIT", "LM", "COX"),
	                            testType = c("Binomial",
	                                         "Wilcox",
	                                         "tStudent",
	                                         "Ftest"),
	                            loops = 64,
	                            setIntersect = 1,
	                            print=TRUE,
	                            plots=TRUE
                                )

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootstrapVarElimination_Res_+3A_object">object</code></td>
<td>
 
<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analysed
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the NeRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_startoffset">startOffset</code></td>
<td>

<p>Only terms whose position in the model is larger than the <code>startOffset</code> are candidates to be removed
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_testtype">testType</code></td>
<td>

<p>Type of non-parametric test to be evaluated by the <code>improvedResiduals</code> function: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_setintersect">setIntersect</code></td>
<td>

<p>The intersect of the model (To force a zero intersect, set this value to 0)
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_print">print</code></td>
<td>

<p>Logical. If <code>TRUE</code>, information will be displayed
</p>
</td></tr>
<tr><td><code id="bootstrapVarElimination_Res_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>,  plots are displayed
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each model term <code class="reqn">x_i</code>, the residuals are computed for the Full model and the reduced model( where the term <code class="reqn">x_i</code> removed).
The term whose removal results in the smallest drop in bootstrapped test residuals improvement is selected. The hypothesis: the 
term improves residuals is tested by checking the p-value of average improvement. If <code class="reqn">p(residuals better than reduced residuals)&gt;pvalue</code>, then the term is removed. 
In other words, only model terms that significantly aid in improving residuals are kept.
The procedure is repeated until no term fulfils the removal criterion.
The p-values of improvement can be computed via a sign-test (Binomial) a paired Wilcoxon test, paired t-test or f-test. The first three tests compare the absolute values of
the residuals, while the f-test test if the variance of the residuals is improved significantly.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>back.model</code></td>
<td>

<p>An object of the same class as <code>object</code> containing the reduced model
</p>
</td></tr>
<tr><td><code>loops</code></td>
<td>

<p>The number of loops it took for the model to stabilize
</p>
</td></tr>
<tr><td><code>reclas.info</code></td>
<td>

<p>A list with the NeRI statistics of the reduced model, as given by the <code>getVar.Res</code> function
</p>
</td></tr>
<tr><td><code>bootCV</code></td>
<td>

<p>An object of class <code>bootstrapValidation_Res</code> containing the results of the bootstrap validation in the reduced model
</p>
</td></tr>
<tr><td><code>back.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the reduced model
</p>
</td></tr>
<tr><td><code>lastRemoved</code></td>
<td>

<p>The name of the last term that was removed (-1 if all terms were removed)
</p>
</td></tr>
<tr><td><code>at.opt.model</code></td>
<td>

<p>The model with close to minimum bootstrapped RMSE 
</p>
</td></tr>
<tr><td><code>beforeFSC.formula</code></td>
<td>

<p>The formula of the model before the FSC stage
</p>
</td></tr>
<tr><td><code>at.RMSE.formula</code></td>
<td>

<p>the string formula of the model that had the minimum or close to minimum RMSE
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrapVarElimination_Bin">bootstrapVarElimination_Bin</a>,
				 <a href="#topic+backVarElimination_Res">backVarElimination_Res</a>,
				 <a href="#topic+bootstrapValidation_Res">bootstrapValidation_Res</a></code></p>

<hr>
<h2 id='BSWiMS.model'>BSWiMS model selection</h2><span id='topic+BSWiMS.model'></span>

<h3>Description</h3>

<p>This function returns a set of models that best predict the outcome. Based on a Bootstrap Stage Wise Model Selection algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	BSWiMS.model(formula,
	            data,
	            type = c("Auto","LM","LOGIT","COX"),
	            testType = c("Auto","zIDI",
	                         "zNRI",
	                         "Binomial",
	                         "Wilcox",
	                         "tStudent",
	                         "Ftest"),
	            pvalue=0.05,
	            variableList=NULL,
	            size=0,
	            loops=20,
	            elimination.bootstrap.steps = 200,
	            fraction=1.0,
	            maxTrainModelSize=20,
	            maxCycles=20,
	            print=FALSE,
	            plots=FALSE,
	            featureSize=0,
	            NumberofRepeats=1,
	            bagPredictType=c("Bag","wNN","Ens")
	            )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BSWiMS.model_+3A_formula">formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be fitted
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_type">type</code></td>
<td>

<p>The fit type. Auto will determine the fitting based on the formula
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_testtype">testType</code></td>
<td>

<p>For an Binary-based optimization, the type of index to be evaluated by the <code>improveProb</code> function (<code>Hmisc</code> package): <em>z</em>-value of Binary or of NRI. For a NeRI-based optimization, the type of non-parametric test to be evaluated by the <code>improvedResiduals</code> function: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the <code>testType</code>, allowed for a term in the model (it will control the false selection rate)
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_size">size</code></td>
<td>

<p>The number of candidate variables to be tested (the first <code>size</code> variables from <code>variableList</code>)
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops for the forward selection procedure
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_elimination.bootstrap.steps">elimination.bootstrap.steps</code></td>
<td>

<p>The number of bootstrap loops for the backwards elimination procedure
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_fraction">fraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the each forward selection model
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_maxcycles">maxCycles</code></td>
<td>

<p>The maximum number of model generation cycles 
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_print">print</code></td>
<td>

<p>Logical. If <code>TRUE</code>, information will be displayed
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>, plots are displayed
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_featuresize">featureSize</code></td>
<td>

<p>The original number of features to be explored in the data frame.
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_numberofrepeats">NumberofRepeats</code></td>
<td>

<p>How many times the BSWiMS search will be repeated
</p>
</td></tr>
<tr><td><code id="BSWiMS.model_+3A_bagpredicttype">bagPredictType</code></td>
<td>

<p>Type of prediction of the bagged formulas
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a core function of FRESA.CAD. The function will generate a set of B:SWiMS models from the data based on the provided baseline formula. The function will loop extracting a models whose all terms are statistical significant. After each loop it will remove the significant terms, and it will repeat the model generation until no mode significant models are found or the maximum number of cycles is reached.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>BSWiMS.model</code></td>
<td>

<p>the output of the bootstrap backwards elimination step
</p>
</td></tr>
<tr><td><code>forward.model</code></td>
<td>

<p>The output of the forward selection step
</p>
</td></tr>
<tr><td><code>update.model</code></td>
<td>

<p>The output of the forward selection step
</p>
</td></tr>
<tr><td><code>univariate</code></td>
<td>

<p>The univariate ranking of variables if no list of features was provided
</p>
</td></tr>
<tr><td><code>bagging</code></td>
<td>

<p>The model after bagging the set of models
</p>
</td></tr>
<tr><td><code>formula.list</code></td>
<td>

<p>The formulas extracted at each cycle
</p>
</td></tr>
<tr><td><code>forward.selection.list</code></td>
<td>

<p>All formulas generated by the forward selection procedure
</p>
</td></tr>
<tr><td><code>oridinalModels</code></td>
<td>

<p>A list of scores, the data and a formulas vector required for ordinal scores predictions 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 

		# Start the graphics device driver to save all plots in a pdf format
		pdf(file = "BSWiMS.model.Example.pdf",width = 8, height = 6)

		# Get the stage C prostate cancer data from the rpart package
		data(stagec,package = "rpart")
		options(na.action = 'na.pass')
		stagec_mat &lt;- cbind(pgstat = stagec$pgstat,
             pgtime = stagec$pgtime,
             as.data.frame(model.matrix(Surv(pgtime,pgstat) ~ .*.,stagec))[-1])
		fnames &lt;- colnames(stagec_mat)
		fnames &lt;- str_replace_all(fnames,":","__")
		colnames(stagec_mat) &lt;- fnames

		dataCancerImputed &lt;- nearestNeighborImpute(stagec_mat)

		# Get a Cox proportional hazards model using:
		# - The default parameters
		md &lt;- BSWiMS.model(formula = Surv(pgtime, pgstat) ~ 1,
						  data = dataCancerImputed)

		#Plot the bootstrap validation
		pt &lt;- plot(md$BSWiMS.model$bootCV)

		#Get the coefficients summary
		sm &lt;- summary(md)
		print(sm$coefficients)

		#Plot the bagged model 
		pl &lt;- plotModels.ROC(cbind(dataCancerImputed$pgstat,
							  predict(md,dataCancerImputed)),
							 main = "Bagging Predictions")


		# Get a Cox proportional hazards model using:
		# - The default parameters but repeated 10 times
		md &lt;- BSWiMS.model(formula = Surv(pgtime, pgstat) ~ 1,
						   data = dataCancerImputed,
						   NumberofRepeats = 10)

		#Get the coefficients summary
		sm &lt;- summary(md)
		print(sm$coefficients)

		#Check all the formulas
		print(md$formula.list)

		#Plot the bagged model 
		pl &lt;- plotModels.ROC(cbind(dataCancerImputed$pgstat,
								   predict(md,dataCancerImputed)),
							 main = "Bagging Predictions")


		# Get a  regression of the survival time

		timeSubjects &lt;- dataCancerImputed
		timeSubjects$pgtime &lt;- log(timeSubjects$pgtime)

		md &lt;- BSWiMS.model(formula = pgtime ~ 1,
						  data = timeSubjects,
						  )
		pt &lt;- plot(md$BSWiMS.model$bootCV)
		sm &lt;- summary(md)
		print(sm$coefficients)

		# Get a logistic regression model using
		# - The default parameters and removing time as possible predictor
		data(stagec,package = "rpart")
		stagec$pgtime &lt;- NULL
		stagec_mat &lt;- cbind(pgstat = stagec$pgstat,
                     as.data.frame(model.matrix(pgstat ~ .*.,stagec))[-1])
		fnames &lt;- colnames(stagec_mat)
		fnames &lt;- str_replace_all(fnames,":","__")
		colnames(stagec_mat) &lt;- fnames
		dataCancerImputed &lt;- nearestNeighborImpute(stagec_mat)


		md &lt;- BSWiMS.model(formula = pgstat ~ 1,
						  data = dataCancerImputed)

		pt &lt;- plot(md$BSWiMS.model$bootCV)
		sm &lt;- summary(md)
		print(sm$coefficients)


		# Get a ordinal regression of grade model using GBSG2 data
		# - The default parameters and removing the 
		# time and status as possible predictor

		data("GBSG2", package = "TH.data")

		# Prepare the model frame for prediction
		GBSG2$time &lt;- NULL;
		GBSG2$cens &lt;- NULL;
		GBSG2_mat &lt;- cbind(tgrade = as.numeric(GBSG2$tgrade),
                       as.data.frame(model.matrix(tgrade~.*.,GBSG2))[-1])

		fnames &lt;- colnames(GBSG2_mat)
		fnames &lt;- str_replace_all(fnames,":","__")
		colnames(GBSG2_mat) &lt;- fnames

		md &lt;- BSWiMS.model(formula = tgrade ~ 1,
						   data = GBSG2_mat)

		sm &lt;- summary(md$oridinalModels$theBaggedModels[[1]]$bagged.model)
		print(sm$coefficients)
		sm &lt;- summary(md$oridinalModels$theBaggedModels[[2]]$bagged.model)
		print(sm$coefficients)

		print(table(GBSG2_mat$tgrade,predict(md,GBSG2_mat)))

		# Shut down the graphics device driver
		dev.off()

	
## End(Not run)
</code></pre>

<hr>
<h2 id='calBinProb'>Calibrates Predicted Binary Probabilities</h2><span id='topic+calBinProb'></span>

<h3>Description</h3>

<p>The predicted binary probabilities are calibrated to match the observed event rate.
A logistic model is used to calibrate the predicted probability to the actual event rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	
    calBinProb(BinaryOutcome=NULL, 
	            OutcomeProbability=NULL
				)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calBinProb_+3A_binaryoutcome">BinaryOutcome</code></td>
<td>

<p>The observed binary outcome
</p>
</td></tr>
<tr><td><code id="calBinProb_+3A_outcomeprobability">OutcomeProbability</code></td>
<td>

<p>The predicted probability
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The logistic model calibrated to the observed outcome rate
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='CalibrationProbPoissonRisk'>Baseline hazard and interval time Estimations</h2><span id='topic+CoxRiskCalibration'></span><span id='topic+CalibrationProbPoissonRisk'></span>

<h3>Description</h3>

<p>It will estimate the baseline hazard (ho) and the time interval that best describes a estimations of the probabilities of time-to-event Poisson events
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	CalibrationProbPoissonRisk(Riskdata,trim=0.10)
	CoxRiskCalibration(ml,data,outcome,time,trim=0.10,timeInterval=NULL)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CalibrationProbPoissonRisk_+3A_riskdata">Riskdata</code></td>
<td>

<p>The data frame with thre columns:  Event, Probability of event, time to event
</p>
</td></tr>	
<tr><td><code id="CalibrationProbPoissonRisk_+3A_trim">trim</code></td>
<td>

<p>The percentge of tails of data not to be used to estimate the time interval
</p>
</td></tr>	
<tr><td><code id="CalibrationProbPoissonRisk_+3A_timeinterval">timeInterval</code></td>
<td>

<p>The time interval for event rate estimation
</p>
</td></tr>	
<tr><td><code id="CalibrationProbPoissonRisk_+3A_ml">ml</code></td>
<td>

<p>A Cox model of the events
</p>
</td></tr>
<tr><td><code id="CalibrationProbPoissonRisk_+3A_data">data</code></td>
<td>

<p>the new dataframe to predict the model
</p>
</td></tr>
<tr><td><code id="CalibrationProbPoissonRisk_+3A_outcome">outcome</code></td>
<td>

<p>The name of the columnt that has the event: 1 uncensored, 0; Censored
</p>
</td></tr>
<tr><td><code id="CalibrationProbPoissonRisk_+3A_time">time</code></td>
<td>

<p>The time to event, or time to last observation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will estimate the baseline hazard of Poisson events and its corresponding time interval from a list of predicted probability that the event will occur for censored (Outome=0) of the actual event happened (Outcome=1). If the timeInterval is not provided, the funtion will estimete the initial time interval  to be used to get the best time interval that models the rate of events.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>index</code></td>
<td>

<p>A vector with the prognistic index based on the provided probabilities
</p>
</td></tr>
<tr><td><code>probGZero</code></td>
<td>

<p>The vector with the calibrated probabilites of the event happening
</p>
</td></tr>
<tr><td><code>hazard</code></td>
<td>

<p>The predicted hazard of each event
</p>
</td></tr>
<tr><td><code>h0</code></td>
<td>

<p>The estimated bsaeline hazard
</p>
</td></tr>
<tr><td><code>hazardGain</code></td>
<td>

<p>The calibration gain
</p>
</td></tr>
<tr><td><code>timeInterval</code></td>
<td>

<p>The time interval of the Poisson event
</p>
</td></tr>
<tr><td><code>meaninterval</code></td>
<td>

<p>The mean observed interval of events
</p>
</td></tr>
<tr><td><code>Ahazard</code></td>
<td>

<p>The cumulated hazzard after calibration
</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>

<p>The relative difference between observed and estimated number of events.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>RRPlot</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  #TBD
</code></pre>

<hr>
<h2 id='cancerVarNames'>Data frame used in several examples of this package</h2><span id='topic+cancerVarNames'></span>

<h3>Description</h3>

<p>This data frame contains two columns, one with names of variables, and the other with descriptions of such variables.
It is used in several examples of this package.
Specifically, it is used in examples working with the stage C prostate cancer data from the <code>rpart</code> package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	data(cancerVarNames)
</code></pre>


<h3>Format</h3>

<p>A data frame with names and descriptions of the variables used in several examples
</p>

<dl>
<dt><code>Var</code></dt><dd>
<p>A column with the names of the variables
</p>
</dd>
<dt><code>Description</code></dt><dd>
<p>A column with a short description of the variables
</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>	data(cancerVarNames)
</code></pre>

<hr>
<h2 id='ClustClass'>Hybrid Hierarchical Modeling</h2><span id='topic+ClustClass'></span>

<h3>Description</h3>

<p>This function returns the outcome associated features and the supervised-classifier present at each one of the unsupervised data clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	ClustClass(formula = formula,
	            data=NULL,
	            filtermethod=univariate_KS,
	            clustermethod=GMVECluster,
	            classmethod=LASSO_1SE,
	            filtermethod.control=list(pvalue=0.1,limit=21),
	            clustermethod.control= list(p.threshold = 0.95, 
	                                   p.samplingthreshold = 0.5),
	            classmethod.control=list(family = "binomial"),
	            pca=TRUE,
	            normalize=TRUE
	            )

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ClustClass_+3A_formula">formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be fitted
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_filtermethod">filtermethod</code></td>
<td>

<p>The function name that will return the relevant features
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_clustermethod">clustermethod</code></td>
<td>

<p>The function name that will cluster the data points
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_classmethod">classmethod</code></td>
<td>

<p>The function name of the binary classification method
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_filtermethod.control">filtermethod.control</code></td>
<td>

<p>A list with the parameters to be passed to the filter function
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_clustermethod.control">clustermethod.control</code></td>
<td>

<p>A list with the parameters to be passed to the clustering function
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_classmethod.control">classmethod.control</code></td>
<td>

<p>A list with the parameters to be passed to the classification function
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_pca">pca</code></td>
<td>

<p>if TRUE it will compute the PCA transform
</p>
</td></tr>
<tr><td><code id="ClustClass_+3A_normalize">normalize</code></td>
<td>

<p>if pca=TRUE and normalize=TRUE it will normalize all the data.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will first call the filter function that should return the relevant a named vector with the p-value of the features associated with the outcome. 
Then it will call user-supplied clustering algorithm that must return a relevant data partition based on the discovered features.
The returned object of the clustering function must contain a $classification object indicates the class label of each data point. 
Finally, the function will call the classification function on each cluster returned by the clustering function.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>features</code></td>
<td>

<p>The named vector of FDR adjusted p-values returned by the filtering function.
</p>
</td></tr>
<tr><td><code>cluster</code></td>
<td>

<p>The clustering function output
</p>
</td></tr>
<tr><td><code>models</code></td>
<td>

<p>The list of classification objects per data cluster
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 	
      library(mlbench) # Location of the Sonar data set
	  library(mclust) # The cluster library
      data(Sonar)
      Sonar$Class &lt;- 1*(Sonar$Class == "M")
	  #Train hierachical classifier
      mc &lt;- ClustClass(Class~.,Sonar,clustermethod=Mclust,clustermethod.control=list(G = 1:4))
	  #report the classification
      pb &lt;- predict(mc,Sonar)
      print(table(1*(pb&gt;0.0),Sonar$Class))
	
## End(Not run)
</code></pre>

<hr>
<h2 id='clusterISODATA'>Cluster Clustering using the Isodata Approach</h2><span id='topic+clusterISODATA'></span>

<h3>Description</h3>

<p>Returns the set of Gaussian Ellipsoids that best model the data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   clusterISODATA(dataset,
                 clusteringMethod=GMVECluster,
                 trainFraction=0.99,
                 randomTests=10,
                 jaccardThreshold=0.45,
                 isoDataThreshold=0.75,
                 plot=TRUE,
                 ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clusterISODATA_+3A_dataset">dataset</code></td>
<td>

<p>The data set to be clustered
</p>
</td></tr>
<tr><td><code id="clusterISODATA_+3A_clusteringmethod">clusteringMethod</code></td>
<td>

<p>The clustering method.
</p>
</td></tr>
<tr><td><code id="clusterISODATA_+3A_trainfraction">trainFraction</code></td>
<td>

<p>The fraction of the data used to train the clusters
</p>
</td></tr>
<tr><td><code id="clusterISODATA_+3A_randomtests">randomTests</code></td>
<td>

<p>The number of clustering sets that will be generated
</p>
</td></tr>
<tr><td><code id="clusterISODATA_+3A_jaccardthreshold">jaccardThreshold</code></td>
<td>

<p>The minimum Jaccard index to be considered for data clustering
</p>
</td></tr>
<tr><td><code id="clusterISODATA_+3A_isodatathreshold">isoDataThreshold</code></td>
<td>

<p>The minimum distance (as p.value) between gaussian clusters
</p>
</td></tr>
<tr><td><code id="clusterISODATA_+3A_plot">plot</code></td>
<td>

<p>If true it will plot the clustered points
</p>
</td></tr>
<tr><td><code id="clusterISODATA_+3A_...">...</code></td>
<td>

<p>Parameter list to be passed to the clustering method
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data will be clustered N times as defined by a number of randomTests. After clustering, the Jaccard Index map
will be generated and ordered from high to low. The mean clusters parameters (Covariance sets) associated with the point with the highest Jaccard index
will define the first cluster. A cluster will be added if the Mahalanobis distance between clusters is greater than the given acceptance p.value (isoDataThreshold)
Only clusters associated with points with a Jaccard index greater than jaccardThreshold will be considered.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>cluster</code></td>
<td>

<p>The numeric vector with the cluster label of each point
</p>
</td></tr>
<tr><td><code>classification</code></td>
<td>

<p>The numeric vector with the cluster label of each point
</p>
</td></tr>
<tr><td><code>robustCovariance</code></td>
<td>

<p>The list of robust covariances per cluster
</p>
</td></tr>
<tr><td><code>pointjaccard</code></td>
<td>

<p>The mean of jaccard index per data point
</p>
</td></tr>
<tr><td><code>centers</code></td>
<td>

<p>The list of cluster centers
</p>
</td></tr>
<tr><td><code>covariances</code></td>
<td>

<p>The list of cluster covariance
</p>
</td></tr>
<tr><td><code>features</code></td>
<td>

<p>The characer vector with the names of the features used
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='crossValidationFeatureSelection_Bin'>IDI/NRI-based selection of a linear, logistic, or Cox proportional hazards regression model from a set of candidate variables</h2><span id='topic+crossValidationFeatureSelection_Bin'></span>

<h3>Description</h3>

<p>This function performs a cross-validation analysis of a feature selection algorithm based on the integrated discrimination improvement (IDI) or the net reclassification improvement (NRI) to return a predictive model.
It is composed of an IDI/NRI-based feature selection followed by an update procedure, ending with a bootstrapping backwards feature elimination.
The user can control how many train and blind test sets will be evaluated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	crossValidationFeatureSelection_Bin(size = 10,
	                                fraction = 1.0,
	                                pvalue = 0.05,
	                                loops = 100,
	                                covariates = "1",
	                                Outcome,
	                                timeOutcome = "Time",
	                                variableList,
	                                data,
	                                maxTrainModelSize = 20,
	                                type = c("LM", "LOGIT", "COX"),
	                                selectionType = c("zIDI", "zNRI"),
	                                startOffset = 0,
	                                elimination.bootstrap.steps = 100,
	                                trainFraction = 0.67,
	                                trainRepetition = 9,
	                                bootstrap.steps = 100,
	                                nk = 0,
	                                unirank = NULL,
	                                print=TRUE,
	                                plots=TRUE,
	                                lambda="lambda.1se",
	                                equivalent=FALSE,
	                                bswimsCycles=10,
	                                usrFitFun=NULL,
	                                featureSize=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_size">size</code></td>
<td>

<p>The number of candidate variables to be tested (the first <code>size</code> variables from <code>variableList</code>)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_fraction">fraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to either IDI or NRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_covariates">covariates</code></td>
<td>

<p>A string of the type &quot;1 + var1 + var2&quot; that defines which variables will always be included in the models (as covariates)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event (needed only for a Cox proportional hazards regression model fitting)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_selectiontype">selectionType</code></td>
<td>

<p>The type of index to be evaluated by the <code>improveProb</code> function (<code>Hmisc</code> package): <em>z</em>-score of IDI or of NRI
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_startoffset">startOffset</code></td>
<td>

<p>Only terms whose position in the model is larger than the <code>startOffset</code> are candidates to be removed
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_elimination.bootstrap.steps">elimination.bootstrap.steps</code></td>
<td>

<p>The number of bootstrap loops for the backwards elimination procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_trainfraction">trainFraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train for the cross-validation procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_trainrepetition">trainRepetition</code></td>
<td>

<p>The number of cross-validation folds (it should be at least equal to <code class="reqn">1/</code><code>trainFraction</code> for a complete cross-validation)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_bootstrap.steps">bootstrap.steps</code></td>
<td>

<p>The number of bootstrap loops for the confidence intervals estimation
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_nk">nk</code></td>
<td>

<p>The number of neighbours used to generate a <em>k</em>-nearest neighbours (KNN) classification. If zero, <em>k</em> is set to the square root of the number of cases. If less than zero, it will not perform the KNN classification
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_unirank">unirank</code></td>
<td>

<p>A list with the results yielded by the <code>uniRankVar</code> function, required only if the rank needs to be updated during the cross-validation procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_print">print</code></td>
<td>

<p>Logical. If <code>TRUE</code>, information will be displayed
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>, plots are displayed
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_lambda">lambda</code></td>
<td>

<p>The passed value to the s parameter of the glmnet cross validation coefficient
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_equivalent">equivalent</code></td>
<td>

<p>Is set to TRUE CV will compute the equivalent model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_bswimscycles">bswimsCycles</code></td>
<td>

<p>The maximum number of models to be returned by <code>BSWiMS.model</code>
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_usrfitfun">usrFitFun</code></td>
<td>

<p>A user fitting function to be evaluated by the cross validation procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Bin_+3A_featuresize">featureSize</code></td>
<td>

<p>The original number of features to be explored in the data frame.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a set of data and plots that can be used to inspect the degree of over-fitting or shrinkage of a model.
It uses bootstrapped data, cross-validation data, and, if possible, retrain data.
During each cycle, a train and a test ROC will be generated using bootstrapped data.
At the end of the cross-validation feature selection procedure, a set of three plots may be produced depending on the specifications of the analysis.
The first plot shows the ROC for each cross-validation blind test.
The second plot, if enough samples are given, shows the ROC of each model trained and tested in the blind test partition.
The final plot shows ROC curves generated with the train, the bootstrapped blind test, and the cross-validation test data.
Additionally, this plot will also contain the ROC of the cross-validation mean test data, and of the cross-validation coherence.
These set of plots may be used to get an overall perspective of the expected model shrinkage.
Along with the plots, the function provides the overall performance of the system (accuracy, sensitivity, and specificity).
The function also produces a report of the expected performance of a KNN algorithm trained with the selected features of the model, and an elastic net algorithm.
The test predictions obtained with these algorithms can then be compared to the predictions generated by the logistic, linear, or Cox proportional hazards regression model.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>formula.list</code></td>
<td>

<p>A list containing objects of class <code>formula</code> with the formulas used to fit the models found at each cycle
</p>
</td></tr>
<tr><td><code>Models.testPrediction</code></td>
<td>

<p>A data frame with the blind test set predictions (Full B:SWiMS,Median,Bagged,Forward,Backwards Eliminations) made at each fold of the cross validation, where the models used to generate such predictions (<code>formula.list</code>) were generated via a feature selection process which included only the train set.
It also includes a column with the <code>Outcome</code> of each prediction, and a column with the number of the fold at which the prediction was made.
</p>
</td></tr>
<tr><td><code>FullBSWiMS.testPrediction</code></td>
<td>

<p>A data frame similar to <code>Models.testPrediction</code>, but where the model used to generate the predictions was the Full model, generated via a feature selection process which included all data.
</p>
</td></tr>
<tr><td><code>TestRetrained.blindPredictions</code></td>
<td>

<p>A data frame similar to <code>Models.testPrediction</code>, but where the models were retrained on an independent set of data (only if enough samples are given at each fold)
</p>
</td></tr>
<tr><td><code>LastTrainBSWiMS.bootstrapped</code></td>
<td>

<p>An object of class <code>bootstrapValidation_Bin</code> containing the results of the bootstrap validation in the last trained model
</p>
</td></tr>
<tr><td><code>Test.accuracy</code></td>
<td>

<p>The global blind test accuracy of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>Test.sensitivity</code></td>
<td>

<p>The global blind test sensitivity of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>Test.specificity</code></td>
<td>

<p>The global blind test specificity of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>Train.correlationsToFull</code></td>
<td>

<p>The Spearman <code class="reqn">\rho</code> rank correlation coefficient between the predictions made with each model from <code>formula.list</code> and the Full model in the train set
</p>
</td></tr>
<tr><td><code>Blind.correlationsToFull</code></td>
<td>

<p>The Spearman <code class="reqn">\rho</code> rank correlation coefficient between the predictions made with each model from <code>formula.list</code> and the Full model in the test set
</p>
</td></tr>
<tr><td><code>FullModelAtFoldAccuracies</code></td>
<td>

<p>The blind test accuracy for the Full model at each cross-validation fold
</p>
</td></tr>
<tr><td><code>FullModelAtFoldSpecificties</code></td>
<td>

<p>The blind test specificity for the Full model at each cross-validation fold
</p>
</td></tr>
<tr><td><code>FullModelAtFoldSensitivities</code></td>
<td>

<p>The blind test sensitivity for the Full model at each cross-validation fold
</p>
</td></tr>
<tr><td><code>FullModelAtFoldAUC</code></td>
<td>

<p>The blind test ROC AUC for the Full model at each cross-validation fold
</p>
</td></tr>
<tr><td><code>AtCVFoldModelBlindAccuracies</code></td>
<td>

<p>The blind test accuracy for the Full model at each final cross-validation fold
</p>
</td></tr>
<tr><td><code>AtCVFoldModelBlindSpecificities</code></td>
<td>

<p>The blind test specificity for the Full model at each final cross-validation fold
</p>
</td></tr>
<tr><td><code>AtCVFoldModelBlindSensitivities</code></td>
<td>

<p>The blind test sensitivity for the Full model at each final cross-validation fold
</p>
</td></tr>
<tr><td><code>CVTrain.Accuracies</code></td>
<td>

<p>The train accuracies at each fold
</p>
</td></tr>
<tr><td><code>CVTrain.Sensitivity</code></td>
<td>

<p>The train sensitivity at each fold
</p>
</td></tr>
<tr><td><code>CVTrain.Specificity</code></td>
<td>

<p>The train specificity at each fold
</p>
</td></tr>
<tr><td><code>CVTrain.AUCs</code></td>
<td>

<p>The train ROC AUC for each fold
</p>
</td></tr>
<tr><td><code>forwardSelection</code></td>
<td>

<p>A list containing the values returned by <code>ForwardSelection.Model.Bin</code> using all data
</p>
</td></tr>
<tr><td><code>updateforwardSelection</code></td>
<td>

<p>A list containing the values returned by <code>updateModel.Bin</code> using all data and the model from <code>forwardSelection</code>
</p>
</td></tr>
<tr><td><code>BSWiMS</code></td>
<td>

<p>A list containing the values returned by <code>bootstrapVarElimination_Bin</code> using all data and the model from <code>updateforwardSelection</code>
</p>
</td></tr>
<tr><td><code>FullBSWiMS.bootstrapped</code></td>
<td>

<p>An object of class <code>bootstrapValidation_Bin</code> containing the results of the bootstrap validation in the Full model
</p>
</td></tr>
<tr><td><code>Models.testSensitivities</code></td>
<td>

<p>A matrix with the mean ROC sensitivities at certain specificities for each train and all test cross-validation folds using the cross-validation models (i.e. 0.95, 0.90, 0.80, 0.70, 0.60, 0.50, 0.40, 0.30, 0.20, 0.10, and 0.05)
</p>
</td></tr>
<tr><td><code>FullKNN.testPrediction</code></td>
<td>

<p>A data frame similar to <code>Models.testPrediction</code>, but where a KNN classifier with the same features as the Full model was used to generate the predictions
</p>
</td></tr>
<tr><td><code>KNN.testPrediction</code></td>
<td>

<p>A data frame similar to <code>Models.testPrediction</code>, but where KNN classifiers with the same features as the cross-validation models were used to generate the predictions at each cross-validation fold
</p>
</td></tr>
<tr><td><code>Fullenet</code></td>
<td>

<p>An object of class <code>cv.glmnet</code> containing the results of an elastic net cross-validation fit
</p>
</td></tr>
<tr><td><code>LASSO.testPredictions</code></td>
<td>

<p>A data frame similar to <code>Models.testPrediction</code>, but where the predictions were made by the elastic net model
</p>
</td></tr>
<tr><td><code>LASSOVariables</code></td>
<td>

<p>A list with the elastic net Full model and the models found at each cross-validation fold
</p>
</td></tr>
<tr><td><code>uniTrain.Accuracies</code></td>
<td>

<p>The list of accuracies of an univariate analysis on each one of the model variables in the train sets
</p>
</td></tr>
<tr><td><code>uniTest.Accuracies</code></td>
<td>

<p>The list of accuracies of an univariate analysis on each one of the model variables in the test sets
</p>
</td></tr>
<tr><td><code>uniTest.TopCoherence</code></td>
<td>

<p>The accuracy coherence of the top ranked variable on the test set
</p>
</td></tr>
<tr><td><code>uniTrain.TopCoherence</code></td>
<td>

<p>The accuracy coherence of the top ranked variable on the train set
</p>
</td></tr>
<tr><td><code>Models.trainPrediction</code></td>
<td>

<p>A data frame with the outcome and the train prediction of every model
</p>
</td></tr>
<tr><td><code>FullBSWiMS.trainPrediction</code></td>
<td>

<p>A data frame with the outcome and the train prediction at each CV fold for the main model
</p>
</td></tr>
<tr><td><code>LASSO.trainPredictions</code></td>
<td>

<p>A data frame with the outcome and the prediction of each enet lasso model
</p>
</td></tr>	
<tr><td><code>BSWiMS.ensemble.prediction</code></td>
<td>

<p>The ensemble prediction by all models on the test data
</p>
</td></tr>
<tr><td><code>AtOptFormulas.list</code></td>
<td>

<p>The list of formulas with &quot;optimal&quot; performance 
</p>
</td></tr>
<tr><td><code>ForwardFormulas.list</code></td>
<td>

<p>The list of formulas produced by the forward procedure
</p>
</td></tr>
<tr><td><code>baggFormulas.list</code></td>
<td>

<p>The list of the bagged models
</p>
</td></tr>
<tr><td><code>LassoFilterVarList</code></td>
<td>

<p>The list of variables used by LASSO fitting
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>See Also</h3>

<p><code><a href="#topic+crossValidationFeatureSelection_Res">crossValidationFeatureSelection_Res</a>,
				 <a href="#topic+ForwardSelection.Model.Bin">ForwardSelection.Model.Bin</a>,
				 <a href="#topic+ForwardSelection.Model.Res">ForwardSelection.Model.Res</a></code></p>

<hr>
<h2 id='crossValidationFeatureSelection_Res'>NeRI-based selection of a linear, logistic, or Cox proportional hazards regression model from a set of candidate variables</h2><span id='topic+crossValidationFeatureSelection_Res'></span>

<h3>Description</h3>

<p>This function performs a cross-validation analysis of a feature selection algorithm based on net residual improvement (NeRI) to return a predictive model.
It is composed of a NeRI-based feature selection followed by an update procedure, ending with a bootstrapping backwards feature elimination.
The user can control how many train and blind test sets will be evaluated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	crossValidationFeatureSelection_Res(size = 10,
	                                    fraction = 1.0,
	                                    pvalue = 0.05,
	                                    loops = 100,
	                                    covariates = "1",
	                                    Outcome,
	                                    timeOutcome = "Time",
	                                    variableList,
	                                    data,
	                                    maxTrainModelSize = 20,
	                                    type = c("LM", "LOGIT", "COX"),
	                                    testType = c("Binomial",
	                                                 "Wilcox",
	                                                 "tStudent",
	                                                 "Ftest"),
	                                    startOffset = 0,
	                                    elimination.bootstrap.steps = 100,
	                                    trainFraction = 0.67,
	                                    trainRepetition = 9,
	                                    setIntersect = 1,
	                                    unirank = NULL,
	                                    print=TRUE,
	                                    plots=TRUE,
	                                    lambda="lambda.1se",
	                                    equivalent=FALSE,
	                                    bswimsCycles=10,
	                                    usrFitFun=NULL,
	                                    featureSize=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_size">size</code></td>
<td>

<p>The number of candidate variables to be tested (the first <code>size</code> variables from <code>variableList</code>)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_fraction">fraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the NeRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_covariates">covariates</code></td>
<td>

<p>A string of the type &quot;1 + var1 + var2&quot; that defines which variables will always be included in the models (as covariates)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event (needed only for a Cox proportional hazards regression model fitting)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_testtype">testType</code></td>
<td>

<p>Type of non-parametric test to be evaluated by the <code>improvedResiduals</code> function: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_startoffset">startOffset</code></td>
<td>

<p>Only terms whose position in the model is larger than the <code>startOffset</code> are candidates to be removed
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_elimination.bootstrap.steps">elimination.bootstrap.steps</code></td>
<td>

<p>The number of bootstrap loops for the backwards elimination procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_trainfraction">trainFraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train for the cross-validation procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_setintersect">setIntersect</code></td>
<td>

<p>The intersect of the model (To force a zero intersect, set this value to 0)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_trainrepetition">trainRepetition</code></td>
<td>

<p>The number of cross-validation folds (it should be at least equal to <code class="reqn">1/trainFraction</code> for a complete cross-validation)
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_unirank">unirank</code></td>
<td>

<p>A list with the results yielded by the <code>uniRankVar</code> function, required only if the rank needs to be updated during the cross-validation procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_print">print</code></td>
<td>

<p>Logical. If <code>TRUE</code>, information will be displayed
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>, plots are displayed
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_lambda">lambda</code></td>
<td>

<p>The passed value to the s parameter of the glmnet cross validation coefficient
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_equivalent">equivalent</code></td>
<td>

<p>Is set to TRUE CV will compute the equivalent model
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_bswimscycles">bswimsCycles</code></td>
<td>

<p>The maximum number of models to be returned by <code>BSWiMS.model</code>
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_usrfitfun">usrFitFun</code></td>
<td>

<p>A user fitting function to be evaluated by the cross validation procedure
</p>
</td></tr>
<tr><td><code id="crossValidationFeatureSelection_Res_+3A_featuresize">featureSize</code></td>
<td>

<p>The original number of features to be explored in the data frame.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces a set of data and plots that can be used to inspect the degree of over-fitting or shrinkage of a model.
It uses bootstrapped data, cross-validation data, and, if possible, retrain data.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>formula.list</code></td>
<td>

<p>A list containing objects of class <code>formula</code> with the formulas used to fit the models found at each cycle
</p>
</td></tr>
<tr><td><code>Models.testPrediction</code></td>
<td>

<p>A data frame with the blind test set predictions made at each fold of the cross validation (Full B:SWiMS,Median,Bagged,Forward,Backward Elimination), where the models used to generate such predictions (<code>formula.list</code>) were generated via a feature selection process which included only the train set.
It also includes a column with the <code>Outcome</code> of each prediction, and a column with the number of the fold at which the prediction was made.
</p>
</td></tr>
<tr><td><code>FullBSWiMS.testPrediction</code></td>
<td>

<p>A data frame similar to <code>Models.testPrediction</code>, but where the model used to generate the predictions was the Full model, generated via a feature selection process which included all data.
</p>
</td></tr>
<tr><td><code>BSWiMS</code></td>
<td>

<p>A list containing the values returned by <code>bootstrapVarElimination_Res</code> using all data and the model from <code>updatedforwardModel</code>
</p>
</td></tr>
<tr><td><code>forwardSelection</code></td>
<td>

<p>A list containing the values returned by <code>ForwardSelection.Model.Res</code> using all data
</p>
</td></tr>
<tr><td><code>updatedforwardModel</code></td>
<td>

<p>A list containing the values returned by <code>updateModel.Res</code> using all data and the model from <code>forwardSelection</code>
</p>
</td></tr>
<tr><td><code>testRMSE</code></td>
<td>

<p>The global blind test root-mean-square error (RMSE) of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>testPearson</code></td>
<td>

<p>The global blind test Pearson <em>r</em> product-moment correlation coefficient of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>testSpearman</code></td>
<td>

<p>The global blind test Spearman <code class="reqn">\rho</code> rank correlation coefficient of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>FulltestRMSE</code></td>
<td>

<p>The global blind test RMSE of the Full model
</p>
</td></tr>
<tr><td><code>FullTestPearson</code></td>
<td>

<p>The global blind test Pearson <em>r</em> product-moment correlation coefficient of the Full model
</p>
</td></tr>
<tr><td><code>FullTestSpearman</code></td>
<td>

<p>The global blind test Spearman <code class="reqn">\rho</code> rank correlation coefficient of the Full model
</p>
</td></tr>
<tr><td><code>trainRMSE</code></td>
<td>

<p>The train RMSE at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>trainPearson</code></td>
<td>

<p>The train Pearson <em>r</em> product-moment correlation coefficient at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>trainSpearman</code></td>
<td>

<p>The train Spearman <code class="reqn">\rho</code> rank correlation coefficient at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>FullTrainRMSE</code></td>
<td>

<p>The train RMSE of the Full model at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>FullTrainPearson</code></td>
<td>

<p>The train Pearson <em>r</em> product-moment correlation coefficient of the Full model at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>FullTrainSpearman</code></td>
<td>

<p>The train Spearman <code class="reqn">\rho</code> rank correlation coefficient of the Full model at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>testRMSEAtFold</code></td>
<td>

<p>The blind test RMSE at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>FullTestRMSEAtFold</code></td>
<td>

<p>The blind test RMSE of the Full model at each fold of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>Fullenet</code></td>
<td>

<p>An object of class <code>cv.glmnet</code> containing the results of an elastic net cross-validation fit
</p>
</td></tr>
<tr><td><code>LASSO.testPredictions</code></td>
<td>

<p>A data frame similar to <code>Models.testPrediction</code>, but where the predictions were made by the elastic net model
</p>
</td></tr>
<tr><td><code>LASSOVariables</code></td>
<td>

<p>A list with the elastic net Full model and the models found at each cross-validation fold
</p>
</td></tr>
<tr><td><code>byFoldTestMS</code></td>
<td>

<p>A vector with the Mean Square error for each blind fold
</p>
</td></tr>
<tr><td><code>byFoldTestSpearman</code></td>
<td>

<p>A vector with the Spearman correlation between prediction and outcome for each blind fold
</p>
</td></tr>
<tr><td><code>byFoldTestPearson</code></td>
<td>

<p>A vector with the Pearson correlation between prediction and outcome for each blind fold
</p>
</td></tr>
<tr><td><code>byFoldCstat</code></td>
<td>

<p>A vector with the C-index (Somers' Dxy rank correlation :<code>rcorr.cens</code>) between prediction and outcome for each blind fold
</p>
</td></tr>
<tr><td><code>CVBlindPearson</code></td>
<td>

<p>A vector with the Pearson correlation between the outcome and prediction for each repeated experiment
</p>
</td></tr>
<tr><td><code>CVBlindSpearman</code></td>
<td>

<p>A vector with the Spearm correlation between the outcome and prediction for each repeated experiment
</p>
</td></tr>
<tr><td><code>CVBlindRMS</code></td>
<td>

<p>A vector with the RMS between the outcome and prediction for each repeated experiment
</p>
</td></tr>
<tr><td><code>Models.trainPrediction</code></td>
<td>

<p>A data frame with the outcome and the train prediction of every model
</p>
</td></tr>
<tr><td><code>FullBSWiMS.trainPrediction</code></td>
<td>

<p>A data frame with the outcome and the train prediction at each CV fold for the main model
</p>
</td></tr>
<tr><td><code>LASSO.trainPredictions</code></td>
<td>

<p>A data frame with the outcome and the prediction of each enet lasso model
</p>
</td></tr>	
<tr><td><code>uniTrainMSS</code></td>
<td>

<p>A data frame with mean square of the train residuals from the univariate models of the model terms
</p>
</td></tr>	
<tr><td><code>uniTestMSS</code></td>
<td>

<p>A data frame with mean square of the test residuals of the univariate models of the model terms
</p>
</td></tr>
<tr><td><code>BSWiMS.ensemble.prediction</code></td>
<td>

<p>The ensemble prediction by all models on the test data
</p>
</td></tr>
<tr><td><code>AtOptFormulas.list</code></td>
<td>

<p>The list of formulas with &quot;optimal&quot; performance
</p>
</td></tr>
<tr><td><code>ForwardFormulas.list</code></td>
<td>

<p>The list of formulas produced by the forward procedure
</p>
</td></tr>
<tr><td><code>baggFormulas.list</code></td>
<td>

<p>The list of the bagged models
</p>
</td></tr>
<tr><td><code>LassoFilterVarList</code></td>
<td>

<p>The list of variables used by LASSO fitting
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+crossValidationFeatureSelection_Bin">crossValidationFeatureSelection_Bin</a>,
				 <a href="#topic+improvedResiduals">improvedResiduals</a>,
				 <a href="#topic+bootstrapVarElimination_Res">bootstrapVarElimination_Res</a></code></p>

<hr>
<h2 id='CVsignature'>Cross-validated Signature</h2><span id='topic+CVsignature'></span>

<h3>Description</h3>

<p>A  formula based wrapper of the <code><a href="#topic+getSignature">getSignature</a></code> function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	CVsignature(formula = formula,data=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CVsignature_+3A_formula">formula</code></td>
<td>

<p>The base formula
</p>
</td></tr>
<tr><td><code id="CVsignature_+3A_data">data</code></td>
<td>

<p>The data to be used for training the signature method
</p>
</td></tr>
<tr><td><code id="CVsignature_+3A_...">...</code></td>
<td>

<p>Parameters for the <code><a href="#topic+getSignature">getSignature</a></code> function 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fit</code></td>
<td>

<p>A <code><a href="#topic+getSignature">getSignature</a></code> object.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>The distance method 
</p>
</td></tr>
<tr><td><code>variable.importance</code></td>
<td>

<p>The named vector of relevant features
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+getSignature">getSignature</a></code>,<code><a href="#topic+signatureDistance">signatureDistance</a></code> </p>

<hr>
<h2 id='EmpiricalSurvDiff'>Estimate the LR value and its associated p-values</h2><span id='topic+EmpiricalSurvDiff'></span>

<h3>Description</h3>

<p>Permutations or Bootstrapping computation of the standardized log-rank (SLR) or the Chi=SLR^2 p-values for differences in survival times 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	EmpiricalSurvDiff(times=times,
	                  status=status,
	                  groups=groups,
	                  samples=1000,
	                  type=c("SLR","Chi"),
	                  plots=FALSE,
	                  minAproxSamples=100,
	                  computeDist=FALSE,
	                  ...
	                  )

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EmpiricalSurvDiff_+3A_times">times</code></td>
<td>

<p>A numeric vector with he observed times to event
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_status">status</code></td>
<td>

<p>A numeric vector indicating if the time to event is censored
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_groups">groups</code></td>
<td>

<p>A numeric vector indicating the label of the two survival groups 
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_samples">samples</code></td>
<td>

<p>The number of bootstrap samples
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_type">type</code></td>
<td>

<p>The type of log-rank statistics. SLR or Chi
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_plots">plots</code></td>
<td>

<p>If TRUE, the Kaplan-Meier plot will be plotted 
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_minaproxsamples">minAproxSamples</code></td>
<td>

<p>The number of tail samples used for the normal-distribution approximation
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_computedist">computeDist</code></td>
<td>

<p>If TRUE, it will compute the bootstrapped distribution of the SLR
</p>
</td></tr>
<tr><td><code id="EmpiricalSurvDiff_+3A_...">...</code></td>
<td>

<p>Additional parameters for the plot
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It will compute the null distribution of the SRL or the square SLR (Chi) via permutations, and it will return the p-value of differences between survival times between two groups.
It may also be used to compute the empirical distribution of the difference in SLR using bootstrapping. (computeDist=TRUE)
The p-values will be estimated based on the sampled distribution, or normal-approximated along the tails.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>pvalue</code></td>
<td>

<p>the minimum one-tailed p-value : min[p(SRL &lt; 0),p(SRL &gt; 0)] for type=&quot;SLR&quot; or the two tailed p-value: 1-p(|SRL| &gt; 0) for type=&quot;Chi&quot;
</p>
</td></tr>
<tr><td><code>LR</code></td>
<td>

<p>A list of LR statistics: LR=Expected, VR=Variance, SLR=Standardized LR.
</p>
</td></tr>
<tr><td><code>p.equal</code></td>
<td>

<p>The two tailed p-value: 1-p(|SRL| &gt; 0)
</p>
</td></tr>
<tr><td><code>p.sup</code></td>
<td>

<p>The one tailed p-value: p(SRL &lt; 0), return NA for type=&quot;Chi&quot;
</p>
</td></tr>
<tr><td><code>p.inf</code></td>
<td>

<p>The one tailed p-value: p(SRL &gt; 0), return NA for type=&quot;Chi&quot;
</p>
</td></tr>
<tr><td><code>nullDist</code></td>
<td>

<p>permutation derived probability density function of the null distribution
</p>
</td></tr>
<tr><td><code>LRDist</code></td>
<td>

<p>bootstrapped derived probability density function of the SLR (computeDist=TRUE)
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 

      library(rpart)
      data(stagec)

      # The Log-Rank Analysis using survdiff

      lrsurvdiff &lt;- survdiff(Surv(pgtime,pgstat)~grade&gt;2,data=stagec)
      print(lrsurvdiff)

      # The Log-Rank Analysis: permutations of the null Chi distribution
      lrp &lt;- EmpiricalSurvDiff(stagec$pgtime,stagec$pgstat,stagec$grade&gt;2,
                         type="Chi",plots=TRUE,samples=10000,
                         main="Chi Null Distribution")
      print(list(unlist(c(lrp$LR,lrp$pvalue))))

      # The Log-Rank Analysis: permutations of the null SLR distribution
      lrp &lt;- EmpiricalSurvDiff(stagec$pgtime,stagec$pgstat,stagec$grade&gt;2,
                         type="SLR",plots=TRUE,samples=10000,
                         main="SLR Null Distribution")
      print(list(unlist(c(lrp$LR,lrp$pvalue))))

      # The Log-Rank Analysis: Bootstraping the SLR distribution
      lrp &lt;- EmpiricalSurvDiff(stagec$pgtime,stagec$pgstat,stagec$grade&gt;2,
                         computeDist=TRUE,plots=TRUE,samples=100000,
                         main="SLR Null and SLR bootrapped")
      print(list(unlist(c(lrp$LR,lrp$pvalue))))
	
	
## End(Not run)
</code></pre>

<hr>
<h2 id='ensemblePredict'>The median prediction from a list of models</h2><span id='topic+ensemblePredict'></span>

<h3>Description</h3>

<p>Given a list of model formulas, this function will train such models and return the a single(ensemble) prediction from the list of formulas on a test data set.
It may also provides a <em>k</em>-nearest neighbors (KNN) prediction using the features listed in such models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	ensemblePredict(formulaList,
	              trainData,
	              testData = NULL, 
	              predictType = c("prob", "linear"),
	              type = c("LOGIT", "LM", "COX","SVM"),
	              Outcome = NULL,
	              nk = 0
				  )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ensemblePredict_+3A_formulalist">formulaList</code></td>
<td>

<p>A list made of objects of class <code>formula</code>, each representing a model formula to be fitted and predicted with
</p>
</td></tr>
<tr><td><code id="ensemblePredict_+3A_traindata">trainData</code></td>
<td>

<p>A data frame with the data to train the model, where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="ensemblePredict_+3A_testdata">testData</code></td>
<td>

<p>A data frame similar to <code>trainData</code>, but with the data set to be predicted. If <code>NULL</code>, <code>trainData</code> will be used
</p>
</td></tr>
<tr><td><code id="ensemblePredict_+3A_predicttype">predictType</code></td>
<td>

<p>Prediction type: Probability (&quot;prob&quot;) or linear predictor (&quot;linear&quot;)
</p>
</td></tr>
<tr><td><code id="ensemblePredict_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="ensemblePredict_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="ensemblePredict_+3A_nk">nk</code></td>
<td>

<p>The number of neighbors used to generate the KNN classification. If zero, <em>k</em> is set to the square root of the number of cases. If less than zero, it will not perform the KNN classification
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>ensemblePredict</code></td>
<td>

<p>A vector with the median prediction for the <code>testData</code> data set, using the models from <code>formulaList</code>
</p>
</td></tr>
<tr><td><code>medianKNNPredict</code></td>
<td>

<p>A vector with the median prediction for the <code>testData</code> data set, using the KNN models
</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>

<p>A matrix, where each column represents the predictions made with each model from <code>formulaList</code>
</p>
</td></tr>
<tr><td><code>KNNpredictions</code></td>
<td>

<p>A matrix, where each column represents the predictions made with a different KNN model
</p>
</td></tr>
<tr><td><code>wPredict</code></td>
<td>

<p>A vector with the weighted mean ensemble
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>

<hr>
<h2 id='featureAdjustment'>Adjust each listed variable to the provided set of covariates</h2><span id='topic+featureAdjustment'></span>

<h3>Description</h3>

<p>This function fits the candidate variables to the provided model formula,for each strata, on a control population.
If the variance of the residual (the fitted observation minus the real observation) is reduced significantly, then, such residual is used in the resulting data frame.
Otherwise, the control mean is subtracted to the observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	featureAdjustment(variableList,
	                  baseFormula,
	                  strata = NA,
	                  data,
	                  referenceframe,
	                  type = c("LM", "GLS", "RLM","NZLM","SPLINE","MARS","LOESS"),
	                  pvalue = 0.05,
	                  correlationGroup = "ID",
	                  ...
	                  )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="featureAdjustment_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_baseformula">baseFormula</code></td>
<td>

<p>A string of the type &quot;var1 +...+ varn&quot; that defines the model formula to which variables will be fitted
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_strata">strata</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable that will be used to stratify the fitting
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_referenceframe">referenceframe</code></td>
<td>

<p>A data frame similar to <code>data</code>, but with only the control population
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_type">type</code></td>
<td>

<p>Fit type: linear fitting (&quot;LM&quot;), generalized least squares fitting (&quot;GLS&quot;) or Robust (&quot;RLM&quot;)
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the <em>F</em>-test, for the model to be allowed to reduce variability
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_correlationgroup">correlationGroup</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be used to group the data (only needed if <code>type</code> defined as &quot;GLS&quot;)
</p>
</td></tr>
<tr><td><code id="featureAdjustment_+3A_...">...</code></td>
<td>

<p>parameters for smooth.spline,loess or mda::mars)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame, where each input observation has been adjusted from <code>data</code> at each <code>strata</code>
</p>


<h3>Note</h3>

<p>This function prints the residuals and the <em>F</em>-statistic for all candidate variables</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>

<hr>
<h2 id='filteredFit'>A generic pipeline of Feature Selection, Transformation, Scale and fit</h2><span id='topic+filteredFit'></span>

<h3>Description</h3>

<p>Sequential application of feature selection, linear transformation, data scaling then fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	
    filteredFit(formula = formula, 
	            data=NULL,
	            filtermethod=univariate_KS,
	            filtermethod.control=list(limit=0),
				Transf=c("none","PCA","CCA","ILAA"),
				Transf.control=list(thr=0.8),
	            Scale="none",
				Scale.control=list(strata=NA),
				refNormIDs=NULL,
				trainIDs=NULL,
	            fitmethod=e1071::svm,
	            ...
	            )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="filteredFit_+3A_formula">formula</code></td>
<td>

<p>the base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_data">data</code></td>
<td>

<p>the data to be used for training the KNN method
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_filtermethod">filtermethod</code></td>
<td>

<p>the method for feature selection
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_filtermethod.control">filtermethod.control</code></td>
<td>

<p>the set of parameters required by the feature selection function
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_scale">Scale</code></td>
<td>

<p>Scale the data using the provided method
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_scale.control">Scale.control</code></td>
<td>

<p>Scale parameters
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_transf">Transf</code></td>
<td>

<p>Data transformations: &quot;none&quot;,&quot;PCA&quot;,&quot;CCA&quot; or &quot;ILAA&quot;,
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_transf.control">Transf.control</code></td>
<td>

<p>Parameters to the transformation function
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_fitmethod">fitmethod</code></td>
<td>

<p>The fit function to be used
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_trainids">trainIDs</code></td>
<td>

<p>The list of sample IDs to be used for training
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_refnormids">refNormIDs</code></td>
<td>

<p>The list of sample IDs to be used for transformations. ie. Reference Control IDs
</p>
</td></tr>
<tr><td><code id="filteredFit_+3A_...">...</code></td>
<td>

<p>Parameters for the fitting function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fit</code></td>
<td>

<p>The fitted model
</p>
</td></tr>
<tr><td><code>filter</code></td>
<td>

<p>The output of the feature selection function
</p>
</td></tr>
<tr><td><code>selectedfeatures</code></td>
<td>

<p>The character vector with all the selected features
</p>
</td></tr>
<tr><td><code>usedFeatures</code></td>
<td>

<p>The set of features used for training
</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>The parameters passed to the fitting method
</p>
</td></tr>
<tr><td><code>asFactor</code></td>
<td>

<p>Indicates if the fitting was to a factor
</p>
</td></tr>
<tr><td><code>classLen</code></td>
<td>

<p>The number of possible outcomes
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='FilterUnivariate'>Univariate Filters</h2><span id='topic+FilterUnivariate'></span><span id='topic+univariate_Logit'></span><span id='topic+univariate_residual'></span><span id='topic+univariate_Wilcoxon'></span><span id='topic+univariate_tstudent'></span><span id='topic+univariate_correlation'></span><span id='topic+correlated_Remove'></span><span id='topic+univariate_cox'></span><span id='topic+univariate_BinEnsemble'></span><span id='topic+univariate_KS'></span><span id='topic+univariate_DTS'></span><span id='topic+univariate_Strata'></span>

<h3>Description</h3>

<p>Returns the top set of features that are statistically associated with the outcome.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>univariate_Logit(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH", 
                 uniTest=c("zIDI","zNRI"),limit=0,...,n=0)
univariate_residual(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH",
                    uniTest=c("Ftest","Binomial","Wilcox","tStudent"),
                    type=c("LM","LOGIT"),limit=0,...,n=0)
univariate_tstudent(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH",
                    limit=0,...,n=0)
univariate_Wilcoxon(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH",
                     limit=0,...,n=0)
univariate_KS(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH",
                     limit=0,...,n=0)
univariate_DTS(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH",
                     limit=0,...,n=0)
univariate_correlation(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH",
                       method = "kendall",limit=0,...,n=0)
univariate_cox(data=NULL, Outcome=NULL, pvalue=0.2, adjustMethod="BH",
                     limit=0,...,n=0)
univariate_BinEnsemble(data,Outcome, pvalue=0.2,limit=0,adjustMethod="BH",...)
univariate_Strata(data,Outcome,pvalue=0.2,limit=0,
                   adjustMethod="BH",
                   unifilter=univariate_BinEnsemble,strata="Gender",...)
correlated_Remove(data=NULL,fnames=NULL,thr=0.999,isDataCorMatrix=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FilterUnivariate_+3A_data">data</code></td>
<td>

<p>The data frame
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_outcome">Outcome</code></td>
<td>

<p>The outcome feature
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_pvalue">pvalue</code></td>
<td>

<p>The threshold pvalue used after the p.adjust method
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_adjustmethod">adjustMethod</code></td>
<td>

<p>The method used by the p.adjust method
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_unitest">uniTest</code></td>
<td>

<p>The unitTest to be performed by the linear fitting model
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_type">type</code></td>
<td>

<p>The type of linear model: LM or LOGIT
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_method">method</code></td>
<td>

<p>The correlation method: pearson,spearman or kendall.
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_limit">limit</code></td>
<td>

<p>The samples-wise fraction of features to return. 
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_fnames">fnames</code></td>
<td>

<p>The list of features to test inside the correlated_Remove function
</p>
</td></tr>    
<tr><td><code id="FilterUnivariate_+3A_thr">thr</code></td>
<td>

<p>The maximum correlation to allow between features
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_unifilter">unifilter</code></td>
<td>

<p>The filter function to be stratified
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_strata">strata</code></td>
<td>

<p>The feature to be used for data stratification
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the correlated_Remove function
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_n">n</code></td>
<td>

<p>the number of original features passed to p.adjust
</p>
</td></tr>
<tr><td><code id="FilterUnivariate_+3A_isdatacormatrix">isDataCorMatrix</code></td>
<td>

<p>The provided data is the correlation matrix
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named vector with the adjusted p-values or the list of no-correlated features for the correlated_Remove 
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Not run: 

        library("FRESA.CAD")

        ### Univariate Filter Examples ####

        # Get the stage C prostate cancer data from the rpart package
        data(stagec,package = "rpart")

        # Prepare the data. Create a model matrix without the event time and interactions
        stagec$pgtime &lt;- NULL
        stagec$eet &lt;- as.factor(stagec$eet)
        options(na.action = 'na.pass')
        stagec_mat &lt;- cbind(pgstat = stagec$pgstat,
                            as.data.frame(model.matrix(pgstat ~ .*.,stagec))[-1])
        fnames &lt;- colnames(stagec_mat)
        fnames &lt;- str_replace_all(fnames,":","__")
        colnames(stagec_mat) &lt;- fnames

        # Impute the missing data
        dataCancerImputed &lt;- nearestNeighborImpute(stagec_mat)
        dataCancerImputed[,1:ncol(dataCancerImputed)] &lt;- sapply(dataCancerImputed,as.numeric)

        # Get the top Features associated to pgstat

        q_values &lt;- univariate_Logit(data=dataCancerImputed, 
                                    Outcome="pgstat",
                                    pvalue = 0.05)

        qValueMatrix &lt;- q_values
        idiqValueMatrix &lt;- q_values
        barplot(-log(q_values),las=2,cex.names=0.4,ylab="-log(Q)",
        main="Association with PGStat: IDI Test")

        q_values &lt;- univariate_Logit(data=dataCancerImputed, 
                                    Outcome="pgstat", 
                                    uniTest="zNRI",pvalue = 0.05)
        qValueMatrix &lt;- cbind(idiqValueMatrix,q_values[names(idiqValueMatrix)])

        q_values &lt;- univariate_residual(data=dataCancerImputed, 
                                    Outcome="pgstat", 
                                    pvalue = 0.05,type="LOGIT")
        qValueMatrix &lt;- cbind(qValueMatrix,q_values[names(idiqValueMatrix)])

        q_values &lt;- univariate_tstudent(data=dataCancerImputed, 
                                       Outcome="pgstat", 
                                       pvalue = 0.05)
        qValueMatrix &lt;- cbind(qValueMatrix,q_values[names(idiqValueMatrix)])

        q_values &lt;- univariate_Wilcoxon(data=dataCancerImputed, 
                                       Outcome="pgstat", 
                                       pvalue = 0.05)
        qValueMatrix &lt;- cbind(qValueMatrix,q_values[names(idiqValueMatrix)])

        q_values &lt;- univariate_correlation(data=dataCancerImputed, 
                                       Outcome="pgstat", 
                                       pvalue = 0.05)
        qValueMatrix &lt;- cbind(qValueMatrix,q_values[names(idiqValueMatrix)])

        q_values &lt;- univariate_correlation(data=dataCancerImputed, 
                                          Outcome="pgstat", 
                                          pvalue = 0.05,
                                          method = "pearson")

        #The qValueMatrix has the qValues of all filter methods.  
        qValueMatrix &lt;- cbind(qValueMatrix,q_values[names(idiqValueMatrix)])
        colnames(qValueMatrix) &lt;- c("IDI","NRI","F","t","W","K","P")
        #Do the log transform to display the heatmap
        qValueMatrix &lt;- -log10(qValueMatrix)
        #the Heatmap of the q-values
        gplots::heatmap.2(qValueMatrix,Rowv = FALSE,dendrogram = "col",
        main = "Method q.values",cexRow = 0.4)

    
## End(Not run)
</code></pre>

<hr>
<h2 id='ForwardSelection.Model.Bin'>IDI/NRI-based feature selection procedure for linear, logistic, and Cox proportional hazards regression models</h2><span id='topic+ForwardSelection.Model.Bin'></span>

<h3>Description</h3>

<p>This function performs a bootstrap sampling to rank the variables that statistically improve prediction.
After the frequency rank, the function uses a forward selection procedure to create a final model, whose terms all have a significant contribution to the integrated discrimination improvement (IDI) or the net reclassification improvement (NRI).
For each bootstrap, the IDI/NRI is computed and the variable with the largest statically significant IDI/NRI is added to the model.
The procedure is repeated at each bootstrap until no more variables can be inserted.
The variables that enter the model are then counted, and the same procedure is repeated for the rest of the bootstrap loops.
The frequency of variable-inclusion in the model is returned as well as a model that uses the frequency of inclusion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	ForwardSelection.Model.Bin(size = 100,
	                            fraction = 1,
	                            pvalue = 0.05, 
	                            loops = 100,
	                            covariates = "1",
	                            Outcome,
	                            variableList,
	                            data, 
	                            maxTrainModelSize = 20,
	                            type = c("LM", "LOGIT", "COX"),
	                            timeOutcome = "Time",
	                            selectionType=c("zIDI", "zNRI"),
	                            cores = 6,
	                            randsize = 0,
	                            featureSize=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ForwardSelection.Model.Bin_+3A_size">size</code></td>
<td>

<p>The number of candidate variables to be tested (the first <code>size</code> variables from <code>variableList</code>)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_fraction">fraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to either IDI or NRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_covariates">covariates</code></td>
<td>

<p>A string of the type &quot;1 + var1 + var2&quot; that defines which variables will always be included in the models (as covariates)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the model
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event (needed only for a Cox proportional hazards regression model fitting)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_selectiontype">selectionType</code></td>
<td>

<p>The type of index to be evaluated by the <code>improveProb</code> function (<code>Hmisc</code> package): <em>z</em>-score of IDI or of NRI
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_cores">cores</code></td>
<td>

<p>Cores to be used for parallel processing
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_randsize">randsize</code></td>
<td>

<p>the model size of a random outcome. If randsize is less than zero. It will estimate the size
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Bin_+3A_featuresize">featureSize</code></td>
<td>

<p>The original number of features to be explored in the data frame.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>final.model</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the final model
</p>
</td></tr>
<tr><td><code>var.names</code></td>
<td>

<p>A vector with the names of the features that were included in the final model
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the final model
</p>
</td></tr>
<tr><td><code>ranked.var</code></td>
<td>

<p>An array with the ranked frequencies of the features
</p>
</td></tr>
<tr><td><code>z.selection</code></td>
<td>

<p>A vector in which each term represents the <em>z</em>-score of the index defined in <code>selectionType</code> obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>formula.list</code></td>
<td>

<p>A list containing objects of class <code>formula</code> with the formulas used to fit the models found at each cycle
</p>
</td></tr>
<tr><td><code>variableList</code></td>
<td>

<p>A list of variables used in the forward selection
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>See Also</h3>

<p><code><a href="#topic+ForwardSelection.Model.Res">ForwardSelection.Model.Res</a></code></p>

<hr>
<h2 id='ForwardSelection.Model.Res'>NeRI-based feature selection procedure for linear, logistic, or Cox proportional hazards regression models</h2><span id='topic+ForwardSelection.Model.Res'></span>

<h3>Description</h3>

<p>This function performs a bootstrap sampling to rank the most frequent variables that statistically aid the models by minimizing the residuals.
After the frequency rank, the function uses a forward selection procedure to create a final model, whose terms all have a significant contribution to the net residual improvement (NeRI).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	ForwardSelection.Model.Res(size = 100, 
	                     fraction = 1, 
	                     pvalue = 0.05, 
	                     loops = 100, 
	                     covariates = "1", 
	                     Outcome, 
	                     variableList, 
	                     data, 
	                     maxTrainModelSize = 20, 
	                     type = c("LM", "LOGIT", "COX"), 
	                     testType=c("Binomial", "Wilcox", "tStudent", "Ftest"),
	                     timeOutcome = "Time",
	                     cores = 6,
	                     randsize = 0,
	                     featureSize=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ForwardSelection.Model.Res_+3A_size">size</code></td>
<td>

<p>The number of candidate variables to be tested (the first <code>size</code> variables from <code>variableList</code>)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_fraction">fraction</code></td>
<td>

<p>The fraction of data (sampled with replacement) to be used as train
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the NeRI, allowed for a term in the model (controls the false selection rate)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_covariates">covariates</code></td>
<td>

<p>A string of the type &quot;1 + var1 + var2&quot; that defines which variables will always be included in the models (as covariates)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the model
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_testtype">testType</code></td>
<td>

<p>Type of non-parametric test to be evaluated by the <code>improvedResiduals</code> function: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event (needed only for a Cox proportional hazards regression model fitting)
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_cores">cores</code></td>
<td>

<p>Cores to be used for parallel processing
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_randsize">randsize</code></td>
<td>

<p>the model size of a random outcome. If randsize is less than zero. It will estimate the size
</p>
</td></tr>
<tr><td><code id="ForwardSelection.Model.Res_+3A_featuresize">featureSize</code></td>
<td>

<p>The original number of features to be explored in the data frame.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>final.model</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the final model
</p>
</td></tr>
<tr><td><code>var.names</code></td>
<td>

<p>A vector with the names of the features that were included in the final model
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the final model
</p>
</td></tr>
<tr><td><code>ranked.var</code></td>
<td>

<p>An array with the ranked frequencies of the features
</p>
</td></tr>
<tr><td><code>formula.list</code></td>
<td>

<p>A list containing objects of class <code>formula</code> with the formulas used to fit the models found at each cycle
</p>
</td></tr>
<tr><td><code>variableList</code></td>
<td>

<p>A list of variables used in the forward selection
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+ForwardSelection.Model.Bin">ForwardSelection.Model.Bin</a></code></p>

<hr>
<h2 id='FRESA.Model'>Automated model selection</h2><span id='topic+FRESA.Model'></span>

<h3>Description</h3>

<p>This function uses a wrapper procedure to select the best features of a non-penalized linear model that best predict the outcome, given the formula of an initial model template (linear, logistic, or Cox proportional hazards), an optimization procedure, and a data frame.
A filter scheme may be enabled to reduce the search space of the wrapper procedure.
The false selection rate may be empirically controlled by enabling bootstrapping, and model shrinkage can be evaluated by cross-validation. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	FRESA.Model(formula,
	            data,
	            OptType = c("Binary", "Residual"),
	            pvalue = 0.05,
	            filter.p.value = 0.10,
	            loops = 32,
	            maxTrainModelSize = 20,
	            elimination.bootstrap.steps = 100,
	            bootstrap.steps = 100,
	            print = FALSE,
	            plots = FALSE,
	            CVfolds = 1,
	            repeats = 1,
	            nk = 0,
	            categorizationType = c("Raw",
	                                   "Categorical",
	                                   "ZCategorical",
	                                   "RawZCategorical",
	                                   "RawTail",
	                                   "RawZTail",
	                                   "Tail",
	                                   "RawRaw"),
	            cateGroups = c(0.1, 0.9),
	            raw.dataFrame = NULL,
	            var.description = NULL,
	            testType = c("zIDI",
	                         "zNRI",
	                         "Binomial",
	                         "Wilcox",
	                         "tStudent",
	                         "Ftest"),
	            lambda="lambda.1se",
	            equivalent=FALSE,
	            bswimsCycles=20,
	            usrFitFun=NULL
	            )

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FRESA.Model_+3A_formula">formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be fitted
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_opttype">OptType</code></td>
<td>

<p>Optimization type: Based on the integrated discrimination improvement (Binary) index for binary classification (&quot;Binary&quot;), or based on the net residual improvement (NeRI) index for linear regression (&quot;Residual&quot;) 
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the <code>testType</code>, allowed for a term in the model (it will control the false selection rate)
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_filter.p.value">filter.p.value</code></td>
<td>

<p>The maximum <em>p</em>-value, for a variable to be included to the feature selection procedure
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_loops">loops</code></td>
<td>

<p>The number of bootstrap loops for the forward selection procedure
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the model
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_elimination.bootstrap.steps">elimination.bootstrap.steps</code></td>
<td>

<p>The number of bootstrap loops for the backwards elimination procedure
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_bootstrap.steps">bootstrap.steps</code></td>
<td>

<p>The number of bootstrap loops for the bootstrap validation procedure
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_print">print</code></td>
<td>

<p>Logical. If <code>TRUE</code>, information will be displayed
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_plots">plots</code></td>
<td>

<p>Logical. If <code>TRUE</code>, plots are displayed
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_cvfolds">CVfolds</code></td>
<td>

<p>The number of folds for the final cross-validation
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_repeats">repeats</code></td>
<td>

<p>The number of times that the cross-validation procedure will be repeated
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_nk">nk</code></td>
<td>

<p>The number of neighbors used to generate a <em>k</em>-nearest neighbors (KNN) classification. If zero, <em>k</em> is set to the square root of the number of cases. If less than zero, it will not perform the KNN classification
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_categorizationtype">categorizationType</code></td>
<td>

<p>How variables will be analyzed: As given in <code>data</code> (&quot;Raw&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code> (&quot;Categorical&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code>, and weighted by the <em>z</em>-score (&quot;ZCategorical&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code>, weighted by the <em>z</em>-score, plus the raw values (&quot;RawZCategorical&quot;); raw values, plus the tails (&quot;RawTail&quot;); or raw values, weighted by the <em>z</em>-score, plus the tails (&quot;RawZTail&quot;)
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_categroups">cateGroups</code></td>
<td>

<p>A vector of percentiles to be used for the categorization procedure
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_raw.dataframe">raw.dataFrame</code></td>
<td>

<p>A data frame similar to <code>data</code>, but with unadjusted data, used to get the means and variances of the unadjusted data
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_var.description">var.description</code></td>
<td>

<p>A vector of the same length as the number of columns of <em>data</em>, containing a description of the variables
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_testtype">testType</code></td>
<td>

<p>For an Binary-based optimization, the type of index to be evaluated by the <code>improveProb</code> function (<code>Hmisc</code> package): <em>z</em>-value of Binary or of NRI. For a NeRI-based optimization, the type of non-parametric test to be evaluated by the <code>improvedResiduals</code> function: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_lambda">lambda</code></td>
<td>

<p>The passed value to the s parameter of the glmnet cross validation coefficient
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_equivalent">equivalent</code></td>
<td>

<p>Is set to TRUE CV will compute the equivalent model
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_bswimscycles">bswimsCycles</code></td>
<td>

<p>The maximum number of models to be returned by <code>BSWiMS.model</code>
</p>
</td></tr>
<tr><td><code id="FRESA.Model_+3A_usrfitfun">usrFitFun</code></td>
<td>

<p>An optional user provided fitting function to be evaluated by the cross validation procedure: fitting: usrFitFun(formula,data), with a predict function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This important function of FRESA.CAD will model or cross validate the models. Given an outcome formula, and a data.frame this function will do an univariate analysis of the data (<code>univariateRankVariables</code>),
then it will select the top ranked variables; after that it will select the model that best describes the outcome. At output it will return the bootstrapped performance of the model 
(<code>bootstrapValidation_Bin</code> or <code>bootstrapValidation_Res</code>). It can be set to report the cross-validation performance of the selection process which will return either 
a  <code>crossValidationFeatureSelection_Bin</code> or a <code>crossValidationFeatureSelection_Res</code> object.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>BSWiMS.model</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the final model
</p>
</td></tr>
<tr><td><code>reducedModel</code></td>
<td>

<p>The resulting object of the backward elimination procedure
</p>
</td></tr>
<tr><td><code>univariateAnalysis</code></td>
<td>

<p>A data frame with the results from the univariate analysis
</p>
</td></tr>
<tr><td><code>forwardModel</code></td>
<td>

<p>The resulting object of the feature selection function.
</p>
</td></tr>
<tr><td><code>updatedforwardModel</code></td>
<td>

<p>The resulting object of the the update procedure
</p>
</td></tr>
<tr><td><code>bootstrappedModel</code></td>
<td>

<p>The resulting object of the bootstrap procedure on <code>final.model</code>
</p>
</td></tr>
<tr><td><code>cvObject</code></td>
<td>

<p>The resulting object of the cross-validation procedure
</p>
</td></tr>
<tr><td><code>used.variables</code></td>
<td>

<p>The number of terms that passed the filter procedure
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>the function call
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 

		# Start the graphics device driver to save all plots in a pdf format
		pdf(file = "FRESA.Model.Example.pdf",width = 8, height = 6)
		# Get the stage C prostate cancer data from the rpart package
		data(stagec,package = "rpart")
		options(na.action = 'na.pass')
		stagec_mat &lt;- cbind(pgstat = stagec$pgstat,
		    pgtime = stagec$pgtime,
		    as.data.frame(model.matrix(Surv(pgtime,pgstat) ~ .,stagec))[-1])

		data(cancerVarNames)
		dataCancerImputed &lt;- nearestNeighborImpute(stagec_mat)

		# Get a Cox proportional hazards model using:
		# - The default parameters
		md &lt;- FRESA.Model(formula = Surv(pgtime, pgstat) ~ 1,
						  data = dataCancerImputed,
						  var.description = cancerVarNames[,2])
		pt &lt;- plot(md$bootstrappedModel)
		sm &lt;- summary(md$BSWiMS.model)
		print(sm$coefficients)


		# Get a 10 fold CV Cox proportional hazards model using:
		# - Repeat 10 times de CV
		md &lt;- FRESA.Model(formula = Surv(pgtime, pgstat) ~ 1,
						  data = dataCancerImputed, CVfolds = 10, 
						  repeats = 10,
						  var.description = cancerVarNames[,2])
		pt &lt;- plotModels.ROC(md$cvObject$Models.testPrediction,theCVfolds = 10)
		print(pt$predictionTable)

		pt &lt;- plotModels.ROC(md$cvObject$LASSO.testPredictions,theCVfolds = 10)
		pt &lt;- plotModels.ROC(md$cvObject$KNN.testPrediction,theCVfolds = 10)

		# Get a  regression of the survival time

		timeSubjects &lt;- dataCancerImputed
		timeSubjects$pgtime &lt;- log(timeSubjects$pgtime)

		md &lt;- FRESA.Model(formula = pgtime ~ 1,
						  data = timeSubjects,
						  var.description = cancerVarNames[,2])
		pt &lt;- plot(md$bootstrappedModel)
		sm &lt;- summary(md$BSWiMS.model)
		print(sm$coefficients)

		# Get a logistic regression model using
		# - The default parameters and removing time as possible predictor

		dataCancerImputed$pgtime &lt;- NULL

		md &lt;- FRESA.Model(formula = pgstat ~ 1,
						  data = dataCancerImputed,
						  var.description = cancerVarNames[,2])
		pt &lt;- plot(md$bootstrappedModel)
		sm &lt;- summary(md$BSWiMS.model)
		print(sm$coefficients)

		# Get a logistic regression model using:
		# - residual-based optimization
		md &lt;- FRESA.Model(formula = pgstat ~ 1,
						  data = dataCancerImputed,
						  OptType = "Residual",
						  var.description = cancerVarNames[,2])
		pt &lt;- plot(md$bootstrappedModel)
		sm &lt;- summary(md$BSWiMS.model)
		print(sm$coefficients)


		# Shut down the graphics device driver
		dev.off()

	
## End(Not run)
</code></pre>

<hr>
<h2 id='FRESAScale'>Data frame normalization</h2><span id='topic+FRESAScale'></span>

<h3>Description</h3>

<p>All features from the <code>data</code> will be normalized based on the distribution of the reference data-frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	FRESAScale(data,refFrame=NULL,method=c("Norm","Order",
	           "OrderLogit","RankInv","LRankInv"),
    refMean=NULL,refDisp=NULL,strata=NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FRESAScale_+3A_data">data</code></td>
<td>

<p>The dataframe to be normalized
</p>
</td></tr>
<tr><td><code id="FRESAScale_+3A_refframe">refFrame</code></td>
<td>

<p>The reference frame that will be used to extract the feature distribution
</p>
</td></tr>
<tr><td><code id="FRESAScale_+3A_method">method</code></td>
<td>

<p>The normalization method. Norm: Mean and Std, Order: Median and IQR,OrderLogit order plus logit, RankInv: <code><a href="#topic+rankInverseNormalDataFrame">rankInverseNormalDataFrame</a></code> 
</p>
</td></tr>
<tr><td><code id="FRESAScale_+3A_refmean">refMean</code></td>
<td>

<p>The mean vector of the reference frame
</p>
</td></tr>
<tr><td><code id="FRESAScale_+3A_refdisp">refDisp</code></td>
<td>

<p>the data dispersion method of the reference frame
</p>
</td></tr>
<tr><td><code id="FRESAScale_+3A_strata">strata</code></td>
<td>

<p>the data stratification variable for the RankInv method
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data-frame will be normalized according to the distribution of the reference frame or the mean vector(<code>refMean</code>) scaled by the reference dispersion vector(<code>refDisp</code>).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>scaledData</code></td>
<td>

<p>The scaled data set
</p>
</td></tr>
<tr><td><code>refMean</code></td>
<td>

<p>The mean or median vector of the reference frame
</p>
</td></tr>
<tr><td><code>refDisp</code></td>
<td>

<p>The data dispersion (standard deviation or IQR)
</p>
</td></tr>
<tr><td><code>strata</code></td>
<td>

<p>The normalization strata
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>

<p>The normalization method
</p>
</td></tr>
<tr><td><code>refFrame</code></td>
<td>

<p>The data frame used to estimate the normalization
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+rankInverseNormalDataFrame">rankInverseNormalDataFrame</a></code></p>

<hr>
<h2 id='getKNNpredictionFromFormula'>Predict classification using KNN</h2><span id='topic+getKNNpredictionFromFormula'></span>

<h3>Description</h3>

<p>This function will return the classification of the samples of a test set using a <em>k</em>-nearest neighbors (KNN) algorithm with euclidean distances, given a formula and a train set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	getKNNpredictionFromFormula(model.formula,
	                            trainData,
	                            testData,
	                            Outcome = "CLASS",
	                            nk = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getKNNpredictionFromFormula_+3A_model.formula">model.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be used
</p>
</td></tr>
<tr><td><code id="getKNNpredictionFromFormula_+3A_traindata">trainData</code></td>
<td>

<p>A data frame with the data to train the model, where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="getKNNpredictionFromFormula_+3A_testdata">testData</code></td>
<td>

<p>A data frame similar to <code>trainData</code>, but with the data set to be predicted
</p>
</td></tr>
<tr><td><code id="getKNNpredictionFromFormula_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>trainData</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="getKNNpredictionFromFormula_+3A_nk">nk</code></td>
<td>

<p>The number of neighbors used to generate the KNN classification
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>prediction</code></td>
<td>

<p>A vector with the predicted outcome for the <code>testData</code> data set
</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>

<p>The proportion of <em>k</em> neighbors that predicted the class to be the one being reported in <code>prediction</code>
</p>
</td></tr>
<tr><td><code>binProb</code></td>
<td>

<p>The proportion of <em>k</em> neighbors that predicted the class of the outcome to be equal to 1
</p>
</td></tr>
<tr><td><code>featureList</code></td>
<td>

<p>A vector with the names of the features used by the KNN procedure
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.fitFRESA">predict.fitFRESA</a></code></p>

<hr>
<h2 id='getLatentCoefficients'>Derived Features of the UPLTM transform </h2><span id='topic+getLatentCoefficients'></span><span id='topic+getObservedCoef'></span>

<h3>Description</h3>

<p>Returs the list latent features, and their corresponding coeficients, from the UPLTM transform
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	getLatentCoefficients(decorrelatedobject)
    getObservedCoef(decorrelatedobject,latentModel)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getLatentCoefficients_+3A_decorrelatedobject">decorrelatedobject</code></td>
<td>

<p>The returned dataframe of the <code>IDeA</code> function
</p>
</td></tr>
<tr><td><code id="getLatentCoefficients_+3A_latentmodel">latentModel</code></td>
<td>

<p>A linear model with coefficients
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The UPLTM transformation extracted by the <code>IDeA</code> function is analyzed and a named list of latent features will be returned with their required formula used to compute the latent varible.
Given a coeficient vector of latent variables. The getObservedCoef will return a vector of coefficients associated with the observed variables.
</p>


<h3>Value</h3>

<p>The list of derived coefficients of each one of latent feature or vector of coefficients	
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>IDeA</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
	# load FRESA.CAD library
#	library("FRESA.CAD")

# iris data set
	data('iris')


	#Decorrelating with usupervised basis and correlation goal set to 0.25
	system.time(irisDecor &lt;- IDeA(iris,thr=0.25))
	print(getLatentCoefficients(irisDecor));
</code></pre>

<hr>
<h2 id='getMedianSurvCalibratedPrediction'>Binary Predictions Calibration of Random CV</h2><span id='topic+getMedianSurvCalibratedPrediction'></span><span id='topic+getMedianLogisticCalibratedPrediction'></span>

<h3>Description</h3>

<p>Remove the bias from the test predictions generated via RandomCV
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
      getMedianSurvCalibratedPrediction(testPredictions)
      getMedianLogisticCalibratedPrediction(testPredictions)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getMedianSurvCalibratedPrediction_+3A_testpredictions">testPredictions</code></td>
<td>

<p>A matrix with the test predictions from the randomCV() function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is one function for binary predictions and one for survival predictions.
For each trained-test prediction partition. The funciton will subtract the bias. Then it will compute the median prediction.
Warning: This procedure is not blinded to the outcome hence it has infromation leakage.
</p>


<h3>Value</h3>

<p>The median estimation of each calibrated predictions
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+randomCV">randomCV</a></code></p>

<hr>
<h2 id='getSignature'>Returns a CV signature template</h2><span id='topic+getSignature'></span>

<h3>Description</h3>

<p>This function returns the matrix template [mean,sd,IQR] that maximizes the ROC AUC between cases of controls. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	getSignature(
	              data,
	              varlist=NULL,
	              Outcome=NULL,
	              target=c("All","Control","Case"),
	              CVFolds=3,
	              repeats=9,
	              distanceFunction=signatureDistance,
	              ...
	)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSignature_+3A_data">data</code></td>
<td>

<p>A data frame whose rows contains the sampled &quot;subject&quot; data, and each column is a feature.
</p>
</td></tr>
<tr><td><code id="getSignature_+3A_varlist">varlist</code></td>
<td>

<p>The varlist is a character vector that list all the features to be searched by the Backward elimination forward selection procedure.
</p>
</td></tr>
<tr><td><code id="getSignature_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column that has the binary outcome. 1 for cases, 0 for controls
</p>
</td></tr>
<tr><td><code id="getSignature_+3A_target">target</code></td>
<td>

<p>The target template that will be used to maximize the AUC.
</p>
</td></tr>
<tr><td><code id="getSignature_+3A_cvfolds">CVFolds</code></td>
<td>

<p>The number of folds to be used
</p>
</td></tr>
<tr><td><code id="getSignature_+3A_repeats">repeats</code></td>
<td>

<p>how many times the CV procedure will be repeated
</p>
</td></tr>
<tr><td><code id="getSignature_+3A_distancefunction">distanceFunction</code></td>
<td>

<p>The function to be used to compute the distance between the template and each sample
</p>
</td></tr>
<tr><td><code id="getSignature_+3A_...">...</code></td>
<td>

<p>the parameters to be passed to the distance function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function repeats full cycles of a Cross Validation (RCV) procedure. At each CV cycle the algorithm estimate the mean template and the distance between the template and the test samples.
The ROC AUC is computed after the RCV is completed. A forward selection scheme. The set of features that maximize the AUC during the Forward loop is returned.      
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>controlTemplate</code></td>
<td>

<p>the control matrix  with quantile probs[0.025,0.25,0.5,0.75,0.975] that maximized the AUC (template of controls subjects)
</p>
</td></tr>
<tr><td><code>caseTamplate</code></td>
<td>

<p>the case matrix  with quantile probs[0.025,0.25,0.5,0.75,0.975] that maximized the AUC (template of case subjects)
</p>
</td></tr>
<tr><td><code>AUCevolution</code></td>
<td>

<p>The AUC value at each cycle
</p>
</td></tr>
<tr><td><code>featureSizeEvolution</code></td>
<td>

<p>The number of features at each cycle
</p>
</td></tr>
<tr><td><code>featureList</code></td>
<td>

<p>The final list of features
</p>
</td></tr>
<tr><td><code>CVOutput</code></td>
<td>

<p>A data frame with four columns: ID, Outcome, Case Distances, Control Distances. Each row contains the CV test results 
</p>
</td></tr>
<tr><td><code>MaxAUC</code></td>
<td>

<p>The maximum ROC AUC
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='getVar.Bin'>Analysis of the effect of each term of a binary classification model by analysing its reclassification performance</h2><span id='topic+getVar.Bin'></span>

<h3>Description</h3>

<p>This function provides an analysis of the effect of each model term by comparing the binary classification performance between the Full model and the model without each term.
The model is fitted using the train data set, but probabilities are predicted for the train and test data sets.
Reclassification improvement is evaluated using the <code>improveProb</code> function (<code>Hmisc</code> package).
Additionally, the integrated discrimination improvement (IDI) and the net reclassification improvement (NRI) of each model term are reported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	getVar.Bin(object,
	                       data,
	                       Outcome = "Class", 
	                       type = c("LOGIT", "LM", "COX"),
	                       testData = NULL,
	                       callCpp=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getVar.Bin_+3A_object">object</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analysed
</p>
</td></tr>
<tr><td><code id="getVar.Bin_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="getVar.Bin_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="getVar.Bin_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="getVar.Bin_+3A_testdata">testData</code></td>
<td>

<p>A data frame similar to <code>data</code>, but with a data set to be independently tested. If <code>NULL</code>, <code>data</code> will be used.
</p>
</td></tr>
<tr><td><code id="getVar.Bin_+3A_callcpp">callCpp</code></td>
<td>

<p>is set to true it will use the c++ implementation of improvement.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>z.IDIs</code></td>
<td>

<p>A vector in which each term represents the <em>z</em>-score of the IDI obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>z.NRIs</code></td>
<td>

<p>A vector in which each term represents the <em>z</em>-score of the NRI obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>IDIs</code></td>
<td>

<p>A vector in which each term represents the IDI obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>NRIs</code></td>
<td>

<p>A vector in which each term represents the NRI obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>testData.z.IDIs</code></td>
<td>

<p>A vector similar to <code>z.IDIs</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>testData.z.NRIs</code></td>
<td>

<p>A vector similar to <code>z.NRIs</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>testData.IDIs</code></td>
<td>

<p>A vector similar to <code>IDIs</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>testData.NRIs</code></td>
<td>

<p>A vector similar to <code>NRIs</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>uniTrainAccuracy</code></td>
<td>

<p>A vector with the univariate train accuracy of each model variable
</p>
</td></tr>
<tr><td><code>uniTestAccuracy</code></td>
<td>

<p>A vector with the univariate test accuracy of each model variable
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>See Also</h3>

<p><code><a href="#topic+getVar.Res">getVar.Res</a></code></p>

<hr>
<h2 id='getVar.Res'>Analysis of the effect of each term of a linear regression model by analysing its residuals</h2><span id='topic+getVar.Res'></span>

<h3>Description</h3>

<p>This function provides an analysis of the effect of each model term by comparing the residuals of the Full model and the model without each term.
The model is fitted using the train data set, but analysis of residual improvement is done on the train and test data sets.
Residuals are compared by a paired <em>t</em>-test, a paired Wilcoxon rank-sum test, a binomial sign test and the <em>F</em>-test on residual variance.
Additionally, the net residual improvement (NeRI) of each model term is reported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	getVar.Res(object,
	           data,
	           Outcome = "Class",
	           type = c("LM", "LOGIT", "COX"),
	           testData = NULL,
	           callCpp=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getVar.Res_+3A_object">object</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="getVar.Res_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="getVar.Res_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="getVar.Res_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="getVar.Res_+3A_testdata">testData</code></td>
<td>

<p>A data frame similar to <code>data</code>, but with a data set to be independently tested. If <code>NULL</code>, <code>data</code> will be used.
</p>
</td></tr>
<tr><td><code id="getVar.Res_+3A_callcpp">callCpp</code></td>
<td>

<p>is set to true it will use the c++ implementation of residual improvement.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>tP.value</code></td>
<td>

<p>A vector in which each element represents the single sided <em>p</em>-value of the paired <em>t</em>-test comparing the absolute values of the residuals obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>BinP.value</code></td>
<td>

<p>A vector in which each element represents the <em>p</em>-value associated with a significant improvement in residuals according to the binomial sign test
</p>
</td></tr>
<tr><td><code>WilcoxP.value</code></td>
<td>

<p>A vector in which each element represents the single sided <em>p</em>-value of the Wilcoxon rank-sum test comparing the absolute values of the residuals obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>FP.value</code></td>
<td>

<p>A vector in which each element represents the single sided <em>p</em>-value of the <em>F</em>-test comparing the residual variances of the residuals obtained with the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>NeRIs</code></td>
<td>

<p>A vector in which each element represents the net residual improvement between the Full model and the model without one term
</p>
</td></tr>
<tr><td><code>testData.tP.value</code></td>
<td>

<p>A vector similar to <code>tP.value</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>testData.BinP.value</code></td>
<td>

<p>A vector similar to <code>BinP.value</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>testData.WilcoxP.value</code></td>
<td>

<p>A vector similar to <code>WilcoxP.value</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>testData.FP.value</code></td>
<td>

<p>A vector similar to <code>FP.value</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>testData.NeRIs</code></td>
<td>

<p>A vector similar to <code>NeRIs</code>, where values were estimated in <code>testdata</code>
</p>
</td></tr>
<tr><td><code>unitestMSE</code></td>
<td>

<p>A vector with the univariate residual mean sum of squares of each model variable on the test data
</p>
</td></tr>
<tr><td><code>unitrainMSE</code></td>
<td>

<p>A vector with the univariate residual mean sum of squares of each model variable on the train data
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+getVar.Bin">getVar.Bin</a></code></p>

<hr>
<h2 id='GLMNET'>GLMNET fit with feature selection&quot;</h2><span id='topic+GLMNET'></span><span id='topic+LASSO_MIN'></span><span id='topic+LASSO_1SE'></span><span id='topic+GLMNET_ELASTICNET_MIN'></span><span id='topic+GLMNET_ELASTICNET_1SE'></span><span id='topic+GLMNET_RIDGE_MIN'></span><span id='topic+GLMNET_RIDGE_1SE'></span>

<h3>Description</h3>

<p>Fits a <code>glmnet::cv.glmnet</code> object to the data, and sets the prediction to use the features that created the minimum CV error or one SE. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	GLMNET(formula = formula,data=NULL,coef.thr=0.001,s="lambda.min",...)
	LASSO_MIN(formula = formula,data=NULL,...)
	LASSO_1SE(formula = formula,data=NULL,...)
	GLMNET_ELASTICNET_MIN(formula = formula,data=NULL,...)
	GLMNET_ELASTICNET_1SE(formula = formula,data=NULL,...)
	GLMNET_RIDGE_MIN(formula = formula,data=NULL,...)
	GLMNET_RIDGE_1SE(formula = formula,data=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GLMNET_+3A_formula">formula</code></td>
<td>

<p>The base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="GLMNET_+3A_data">data</code></td>
<td>

<p>The data to be used for training the KNN method
</p>
</td></tr>
<tr><td><code id="GLMNET_+3A_coef.thr">coef.thr</code></td>
<td>

<p>The threshold for feature selection when alpha &lt; 1.
</p>
</td></tr>
<tr><td><code id="GLMNET_+3A_s">s</code></td>
<td>

<p>The lambda threshold to be use at prediction and feature selection
</p>
</td></tr>
<tr><td><code id="GLMNET_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the cv.glmnet function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fit</code></td>
<td>

<p>The <code>glmnet::cv.glmnet</code> fitted object
</p>
</td></tr>
<tr><td><code>s</code></td>
<td>

<p>The s. Set to &quot;lambda.min&quot; or  &quot;lambda.1se&quot; for prediction
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>The formula
</p>
</td></tr>
<tr><td><code>outcome</code></td>
<td>

<p>The name of the outcome
</p>
</td></tr>
<tr><td><code>usedFeatures</code></td>
<td>

<p>The list of features to be used
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>glmnet::cv.glmnet</code></p>

<hr>
<h2 id='GMVEBSWiMS'>Hybrid Hierarchical Modeling with GMVE and BSWiMS</h2><span id='topic+GMVEBSWiMS'></span>

<h3>Description</h3>

<p>This function returns the BSWiMS supervised-classifier present at each one of the GMVE unsupervised Gaussian data clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   GMVEBSWiMS(formula = formula,
            data=NULL,
            GMVE.control = list(p.threshold = 0.95,p.samplingthreshold = 0.5),
            ...
   )

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GMVEBSWiMS_+3A_formula">formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be fitted
</p>
</td></tr>
<tr><td><code id="GMVEBSWiMS_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="GMVEBSWiMS_+3A_gmve.control">GMVE.control</code></td>
<td>

<p>Control parameters of the GMVECluster function 
</p>
</td></tr>
<tr><td><code id="GMVEBSWiMS_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the BSWiMS.model function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, the function calls the BSWiMS function that returns the relevant features associated with the outcome. 
Then, it calls the GMVE clustering algorithm (GMVECluster) that returns a relevant data partition based on Gaussian clusters.
Finally, the function will execute the BSWiMS.model classification function on each cluster returned by GMVECluster.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>features</code></td>
<td>

<p>The character vector with the releavant BSWiMS features.
</p>
</td></tr>
<tr><td><code>cluster</code></td>
<td>

<p>The GMVECluster object
</p>
</td></tr>
<tr><td><code>models</code></td>
<td>

<p>The list of BSWiMS.model models per cluster
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>Examples</h3>

<pre><code class='language-R'>   ## Not run: 
   # Get the Sonar data set
      library(mlbench)
      data(Sonar)
      Sonar$Class &lt;- 1*(Sonar$Class == "M")
     #Train hierachical classifier
      mc &lt;- GMVEBSWiMS(Class~.,Sonar)
     #report the classification
      pb &lt;- predict(mc,Sonar)
      print(table(1*(pb&gt;0.0),Sonar$Class))
   
## End(Not run)
</code></pre>

<hr>
<h2 id='GMVECluster'>Set Clustering using the Generalized Minimum Volume Ellipsoid (GMVE)</h2><span id='topic+GMVECluster'></span>

<h3>Description</h3>

<p>The Function will return the set of Gaussian Ellipsoids that best model the data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	GMVECluster(dataset, 
	            p.threshold=0.975,
	            samples=10000,
	            p.samplingthreshold=0.50,
	            sampling.rate = 3,
	            jitter=TRUE,
	            tryouts=25,
	            pca=TRUE,
	            verbose=FALSE)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GMVECluster_+3A_dataset">dataset</code></td>
<td>

<p>The data set to be clustered
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_p.threshold">p.threshold</code></td>
<td>

<p>The p-value threshold of point acceptance into a set.
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_samples">samples</code></td>
<td>

<p>If the set is large, The number of random samples
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_p.samplingthreshold">p.samplingthreshold</code></td>
<td>

<p>Defines the maximum distance between set candidate points
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_sampling.rate">sampling.rate</code></td>
<td>

<p>Uniform sampling rate for candidate clusters
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_jitter">jitter</code></td>
<td>

<p>If true, will jitter the data set
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_tryouts">tryouts</code></td>
<td>

<p>The number of cluster candidates that will be analyed per sampled point
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_pca">pca</code></td>
<td>

<p>If TRUE, it will use the PCA transform for dimension reduction
</p>
</td></tr>
<tr><td><code id="GMVECluster_+3A_verbose">verbose</code></td>
<td>

<p>If true it will print the clustering evolution
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implementation of the GMVE clustering algorithm as proposed by Jolion et al. (1991).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>cluster</code></td>
<td>

<p>The numeric vector with the cluster label of each point
</p>
</td></tr>
<tr><td><code>classification</code></td>
<td>

<p>The numeric vector with the cluster label of each point
</p>
</td></tr>
<tr><td><code>centers</code></td>
<td>

<p>The list of cluster centers
</p>
</td></tr>
<tr><td><code>covariances</code></td>
<td>

<p>The list of cluster covariance
</p>
</td></tr>
<tr><td><code>robCov</code></td>
<td>

<p>The list of robust covariances per cluster
</p>
</td></tr>
<tr><td><code>k</code></td>
<td>

<p>The number of discovered clusters
</p>
</td></tr>
<tr><td><code>features</code></td>
<td>

<p>The characer vector with the names of the features used
</p>
</td></tr>
<tr><td><code>jitteredData</code></td>
<td>

<p>The jittered dataset
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>References</h3>

<p>Jolion, Jean-Michel, Peter Meer, and Samira Bataouche. &quot;Robust clustering with applications in computer vision.&quot; IEEE Transactions on Pattern Analysis &amp; Machine Intelligence 8 (1991): 791-802.</p>

<hr>
<h2 id='heatMaps'>Plot a heat map of selected variables</h2><span id='topic+heatMaps'></span>

<h3>Description</h3>

<p>This function creates a heat map for a data set based on a univariate or frequency ranking
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	heatMaps(variableList=NULL,
	         varRank = NULL,
	         Outcome,
	         data,
	         title = "Heat Map",
	         hCluster = FALSE,
	         prediction = NULL,
	         Scale = FALSE,
	         theFiveColors=c("blue","cyan","black","yellow","red"),
	         outcomeColors = c("blue","lightgreen","yellow","orangered","red"),
	         transpose=FALSE,
	         ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="heatMaps_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_varrank">varRank</code></td>
<td>

<p>A data frame with the name of the variables in <code>variableList</code>, ranked according to a certain metric
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_title">title</code></td>
<td>

<p>The title of the plot
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_hcluster">hCluster</code></td>
<td>

<p>Logical. If <code>TRUE</code>, variables will be clustered
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_prediction">prediction</code></td>
<td>

<p>A vector with a prediction for each subject, which will be used to rank the heat map
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_scale">Scale</code></td>
<td>

<p>An optional value to force the data normalization <code>outcome</code>
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_thefivecolors">theFiveColors</code></td>
<td>

<p>the colors of the heatmap 
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_outcomecolors">outcomeColors</code></td>
<td>

<p>the colors of the outcome bar 
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_transpose">transpose</code></td>
<td>

<p>transpose the heatmap 
</p>
</td></tr>
<tr><td><code id="heatMaps_+3A_...">...</code></td>
<td>

<p>additional parameters for the heatmap.2 function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>dataMatrix</code></td>
<td>

<p>A matrix with all the terms in <code>data</code> described by <code>variableList</code>
</p>
</td></tr>
<tr><td><code>orderMatrix</code></td>
<td>

<p>A matrix similar to <code>dataMatrix</code>, where rows are ordered according to the <code>outcome</code>
</p>
</td></tr>
<tr><td><code>heatMap</code></td>
<td>

<p>A list with the values returned by the <code>heatmap.2</code> function (<code>gplots</code> package)
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 

		library(rpart)
		data(stagec)

		# Set the options to keep the na
		options(na.action='na.pass')
		# create a model matrix with all the NA values imputed
		stagecImputed &lt;- as.data.frame(nearestNeighborImpute(model.matrix(~.,stagec)[,-1]))

		# the simple heat map
		hm &lt;- heatMaps(Outcome="pgstat",data=stagecImputed,title="Heat Map",Scale=TRUE) 

		# transposing the heat-map with clustered colums
		hm &lt;- heatMaps(Outcome="pgstat",data=stagecImputed,title="Heat Map",Scale=TRUE,
					   transpose= TRUE,hCluster = TRUE,
					   cexRow=0.80,cexCol=0.50,srtCol=35) 

		# transposing the heat-map with reds and time to event as outcome
		hm &lt;- heatMaps(Outcome="pgtime",data=stagecImputed,title="Heat Map",Scale=TRUE,
					   theFiveColors=c("black","red","orange","yellow","white"),
					   cexRow=0.50,cexCol=0.80,srtCol=35) 
	
## End(Not run)
</code></pre>

<hr>
<h2 id='HLCM'>Latent class based modeling of binary outcomes</h2><span id='topic+HLCM'></span><span id='topic+HLCM_EM'></span>

<h3>Description</h3>

<p>Modeling a binary outcome via the the discovery of latent clusters. Each discovered latent cluster is modeled by the user provided fit function. Discovered clusters will be modeled by KNN or SVM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	HLCM(formula = formula, 
	                data=NULL,
	                method=BSWiMS.model,
	                hysteresis = 0.1,
					classMethod=KNN_method,
					classModel.Control=NULL,
					minsize=10,
	                ...
					)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HLCM_+3A_formula">formula</code></td>
<td>

<p>the base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="HLCM_+3A_data">data</code></td>
<td>

<p>the data to be used for training the method
</p>
</td></tr>
<tr><td><code id="HLCM_+3A_method">method</code></td>
<td>

<p>the binary classification function
</p>
</td></tr>
<tr><td><code id="HLCM_+3A_hysteresis">hysteresis</code></td>
<td>

<p>the hysteresis shift for detecting wrongly classified subjects
</p>
</td></tr>
<tr><td><code id="HLCM_+3A_classmethod">classMethod</code></td>
<td>

<p>the function name for modeling the discovered latent clusters
</p>
</td></tr>
<tr><td><code id="HLCM_+3A_classmodel.control">classModel.Control</code></td>
<td>

<p>the parameters to be passed to the latent-class fitting function
</p>
</td></tr>
<tr><td><code id="HLCM_+3A_minsize">minsize</code></td>
<td>

<p>the minimum size of the discovered clusters
</p>
</td></tr>
<tr><td><code id="HLCM_+3A_...">...</code></td>
<td>

<p>parameters for the classification function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>original</code></td>
<td>

<p>The original model trained with all the dataset
</p>
</td></tr>
<tr><td><code>alternativeModel</code></td>
<td>

<p>The model used to classify the wrongly classified samples
</p>
</td></tr>
<tr><td><code>classModel</code></td>
<td>

<p>The method that models the latent class
</p>
</td></tr>
<tr><td><code>accuracy</code></td>
<td>

<p>The original accuracy
</p>
</td></tr>
<tr><td><code>selectedfeatures</code></td>
<td>

<p>The character vector of selected features
</p>
</td></tr>
<tr><td><code>hysteresis</code></td>
<td>

<p>The used hysteresis
</p>
</td></tr>
<tr><td><code>classSet</code></td>
<td>

<p>The discovered class label of each sample
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>class::knn</code></p>

<hr>
<h2 id='IDeA'>Decorrelation of data frames</h2><span id='topic+IDeA'></span><span id='topic+ILAA'></span><span id='topic+predictDecorrelate'></span>

<h3>Description</h3>

<p>All continous features that with significant correlation will be decorrelated
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ILAA(data=NULL,
                thr=0.80,
                method=c("pearson","spearman"),
                Outcome=NULL,
                drivingFeatures=NULL,
                maxLoops=100,
                verbose=FALSE,
                bootstrap=0
                )
                
  IDeA(data=NULL,thr=0.80,
                       method=c("fast","pearson","spearman","kendall"),
                       Outcome=NULL,
                       refdata=NULL,
                       drivingFeatures=NULL,
                       useDeCorr=TRUE,
                       relaxed=TRUE,
                       corRank=TRUE,
                       maxLoops=100,
                       unipvalue=0.05,
                       verbose=FALSE,
                       ...)

  
  predictDecorrelate(decorrelatedobject,testData)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IDeA_+3A_data">data</code></td>
<td>

<p>The dataframe whose features will de decorrelated
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_thr">thr</code></td>
<td>

<p>The maximum allowed correlation.
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_refdata">refdata</code></td>
<td>

<p>Option: A data frame that may be used to decorrelate the target dataframe 
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_outcome">Outcome</code></td>
<td>

<p>The target outcome for supervised basis
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_drivingfeatures">drivingFeatures</code></td>
<td>

<p>A vector of features to be used as basis vectors. 
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_unipvalue">unipvalue</code></td>
<td>

<p>Maximum p-value for correlation significance
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_usedecorr">useDeCorr</code></td>
<td>

<p>if TRUE, the transformation matrix (UPLTM) will be computed
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_maxloops">maxLoops</code></td>
<td>

<p>the maxumum number of iteration loops
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_verbose">verbose</code></td>
<td>

<p>if TRUE, it will display internal evolution of algorithm.
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_method">method</code></td>
<td>

<p>if not set to &quot;fast&quot; the method will be pased to the <code>cor()</code> function.
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_relaxed">relaxed</code></td>
<td>

<p>is set to TRUE it will use relaxed convergence
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_corrank">corRank</code></td>
<td>

<p>is set to TRUE it will correlation matrix to break ties.
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_...">...</code></td>
<td>

<p>parameters passed to the <code>featureAdjustment</code> function.
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_decorrelatedobject">decorrelatedobject</code></td>
<td>

<p>The returned dataframe of the <code>IDeA</code> function
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_testdata">testData</code></td>
<td>

<p>The new dataframe to be decorrelated
</p>
</td></tr>
<tr><td><code id="IDeA_+3A_bootstrap">bootstrap</code></td>
<td>

<p>If greater than 1 the number of boostrapping loops
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dataframe will be analyzed and significantly correlated features whose correlation 
is larger than the user supplied threshold will be decorrelated. 
Basis feature selection may be based on Outcome association or by an unsupervised method. 
The default options will run the decorrelation using fast matrix operations using <code>Rfast</code>;
hence, Pearson correlation will be used to estimate the unit-preserving spatial transformation matrix (UPLTM).
ILAA is a wrapper of the more comprensive IDeA method. It estimates linear transforms and allows for boosted transform estimations 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>decorrelatedDataframe</code></td>
<td>

<p>The decorrelated data frame with the follwing attributes 
</p>
</td></tr>
<tr><td><code>attr:UPLTM</code></td>
<td>

<p>Attribute of decorrelatedDataframe: The Decorrelation matrix with the beta coefficients
</p>
</td></tr>
<tr><td><code>attr:fscore</code></td>
<td>

<p>Attribute of decorrelatedDataframe: The score of each feature.
</p>
</td></tr>
<tr><td><code>attr:drivingFeatures</code></td>
<td>

<p>Attribute of decorrelatedDataframe: The list of features used as base features for supervised basis
</p>
</td></tr>
<tr><td><code>attr:unipvalue</code></td>
<td>

<p>Attribute of decorrelatedDataframe: The p-value used to check for fit significance
</p>
</td></tr>
<tr><td><code>attr:R.critical</code></td>
<td>

<p>Attribute of decorrelatedDataframe: The pearson correlation critical value
</p>
</td></tr>
<tr><td><code>attr:IDeAEvolution</code></td>
<td>

<p>Attribute of decorrelatedDataframe: The R measure history and the sparcity
</p>
</td></tr>
<tr><td><code>attr:VarRatio</code></td>
<td>

<p>Attribute of decorrelatedDataframe: The variance ratio between the output latent variable and the observed 
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>featureAdjustment</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
  # load FRESA.CAD library
  #  library("FRESA.CAD")

  # iris data set
  data('iris')

  colors &lt;- c("red","green","blue")
  names(colors) &lt;- names(table(iris$Species))
  classcolor &lt;- colors[iris$Species]

  #Decorrelating with usupervised basis and correlation goal set to 0.25
  system.time(irisDecor &lt;- IDeA(iris,thr=0.25))
  
  ## The transformation matrix is stored at "UPLTM" attribute
  UPLTM &lt;- attr(irisDecor,"UPLTM")
  print(UPLTM)

  #Decorrelating with supervised basis and correlation goal set to 0.25
  system.time(irisDecorOutcome &lt;- IDeA(iris,Outcome="Species",thr=0.25))
  ## The transformation matrix is stored at "UPLTM" attribute
  UPLTM &lt;- attr(irisDecorOutcome,"UPLTM")
  print(UPLTM)

  ## Compute PCA 
  features &lt;- colnames(iris[,sapply(iris,is,"numeric")])
  irisPCA &lt;- prcomp(iris[,features]);
  ## The PCA transformation
  print(irisPCA$rotation)

  ## Plot the transformed sets
  plot(iris[,features],col=classcolor,main="Raw IRIS")

  plot(as.data.frame(irisPCA$x),col=classcolor,main="PCA IRIS")

  featuresDecor &lt;- colnames(irisDecor[,sapply(irisDecor,is,"numeric")])
  plot(irisDecor[,featuresDecor],col=classcolor,main="Outcome-Blind IDeA IRIS")


  featuresDecor &lt;- colnames(irisDecorOutcome[,sapply(irisDecorOutcome,is,"numeric")])
  plot(irisDecorOutcome[,featuresDecor],col=classcolor,main="Outcome-Driven IDeA IRIS")
  
## End(Not run)
</code></pre>

<hr>
<h2 id='improvedResiduals'>Estimate the significance of the reduction of predicted residuals</h2><span id='topic+improvedResiduals'></span>

<h3>Description</h3>

<p>This function will test the hypothesis that, given a set of two residuals (new vs. old), the new ones are better than the old ones as measured with non-parametric tests.
Four <em>p</em>-values are provided: one for the binomial sign test, one for the paired Wilcoxon rank-sum test, one for the paired <em>t</em>-test, and one for the <code>F</code>-test.
The proportion of subjects that improved their residuals, the proportion that worsen their residuals, and the net residual improvement (NeRI) will be returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	improvedResiduals(oldResiduals,
	                  newResiduals,
	                  testType = c("Binomial", "Wilcox", "tStudent", "Ftest"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="improvedResiduals_+3A_oldresiduals">oldResiduals</code></td>
<td>

<p>A vector with the residuals of the original model
</p>
</td></tr>
<tr><td><code id="improvedResiduals_+3A_newresiduals">newResiduals</code></td>
<td>

<p>A vector with the residuals of the new model
</p>
</td></tr>
<tr><td><code id="improvedResiduals_+3A_testtype">testType</code></td>
<td>

<p>Type of non-parametric test to be evaluated: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will test the hypothesis that the new residuals are &quot;better&quot; than the old residuals.
To test this hypothesis, four types of tests are performed:
</p>

<ol>
<li><p> The paired <em>t</em>-test, which compares the absolute value of the residuals
</p>
</li>
<li><p> The paired Wilcoxon rank-sum test, which compares the absolute value of residuals
</p>
</li>
<li><p> The binomial sign test, which evaluates whether the number of subjects with improved residuals is greater than the number of subjects with worsened residuals
</p>
</li>
<li><p> The <em>F</em>-test, which is the standard test for evaluating whether the residual variance is &quot;better&quot; in the new residuals.
</p>
</li></ol>

<p>The proportions of subjects that improved and worsen their residuals are returned, and so is the NeRI.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>p1</code></td>
<td>

<p>Proportion of subjects that improved their residuals to the total number of subjects
</p>
</td></tr>
<tr><td><code>p2</code></td>
<td>

<p>Proportion of subjects that worsen their residuals to the total number of subjects
</p>
</td></tr>
<tr><td><code>NeRI</code></td>
<td>

<p>The net residual improvement (<code>p1</code>-<code>p2</code>)
</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>

<p>The one tail <em>p</em>-value of the test specified in <em>testType</em>
</p>
</td></tr>
<tr><td><code>BinP.value</code></td>
<td>

<p>The <em>p</em>-value associated with a significant improvement in residuals
</p>
</td></tr>
<tr><td><code>WilcoxP.value</code></td>
<td>

<p>The single sided <em>p</em>-value of the Wilcoxon rank-sum test comparing the absolute values of the new and old residuals
</p>
</td></tr>
<tr><td><code>tP.value</code></td>
<td>

<p>The single sided <em>p</em>-value of the paired t-test comparing the absolute values of the new and old residuals
</p>
</td></tr>
<tr><td><code>FP.value</code></td>
<td>

<p>The single sided <em>p</em>-value of the F-test comparing the residual variances of the new and old residuals
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>

<hr>
<h2 id='jaccardMatrix'>Jaccard Index of two labeled sets</h2><span id='topic+jaccardMatrix'></span>

<h3>Description</h3>

<p>The Jaccard Index analysis of two labeled sets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	jaccardMatrix(clustersA=NULL,clustersB=NULL)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jaccardMatrix_+3A_clustersa">clustersA</code></td>
<td>

<p>The first labeled point set
</p>
</td></tr>
<tr><td><code id="jaccardMatrix_+3A_clustersb">clustersB</code></td>
<td>

<p>The second labeled point set
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will compute the Jaccard Index Matrix: <code class="reqn">[(A=i) \cap (B=j)]/[(A=i) \cup (B=j)]</code> for all <code class="reqn">(i,j)</code> possible label pairs presenet in A and B
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>jaccardMat</code></td>
<td>

<p>The numeric matrix of Jaccard Indexes of all possible paired sets 
</p>
</td></tr>
<tr><td><code>elementJaccard</code></td>
<td>

<p>The corresponding Jaccard index for each data point
</p>
</td></tr>
<tr><td><code>balancedMeanJaccard</code></td>
<td>

<p>The average of all marginal Jaccards
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='KNN_method'>KNN Setup for KNN prediction</h2><span id='topic+KNN_method'></span>

<h3>Description</h3>

<p>Prepares the KNN function to be used to predict the class of a new set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	KNN_method(formula = formula,data=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KNN_method_+3A_formula">formula</code></td>
<td>

<p>the base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="KNN_method_+3A_data">data</code></td>
<td>

<p>the data to be used for training the KNN method
</p>
</td></tr>
<tr><td><code id="KNN_method_+3A_...">...</code></td>
<td>

<p>parameters for the KNN function and the data scaling method
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>trainData</code></td>
<td>

<p>The data frame to be used to train the KNN prediction
</p>
</td></tr>
<tr><td><code>scaledData</code></td>
<td>

<p>The scaled training set
</p>
</td></tr>
<tr><td><code>classData</code></td>
<td>

<p>A vector with the outcome to be used by the KNN function
</p>
</td></tr>
<tr><td><code>outcome</code></td>
<td>

<p>The name of the outcome
</p>
</td></tr>
<tr><td><code>usedFeatures</code></td>
<td>

<p>The list of features to be used by the KNN method
</p>
</td></tr>
<tr><td><code>mean_col</code></td>
<td>

<p>A vector with the mean of each training feature
</p>
</td></tr>
<tr><td><code>disp_col</code></td>
<td>

<p>A vector with the dispesion of each training feature
</p>
</td></tr>
<tr><td><code>kn</code></td>
<td>

<p>The number of neigbors to be used by the predict function
</p>
</td></tr>
<tr><td><code>scaleMethod</code></td>
<td>

<p>The scaling method to be used by FRESAScale() function
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>class::knn</code>,<code><a href="#topic+FRESAScale">FRESAScale</a></code> </p>

<hr>
<h2 id='listTopCorrelatedVariables'>List the variables that are highly correlated with each other</h2><span id='topic+listTopCorrelatedVariables'></span>

<h3>Description</h3>

<p>This function computes the Pearson, Spearman, or Kendall correlation for each specified variable in the data set and returns a list of the variables that are correlated to them.
It also provides a short variable list without the highly correlated variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	listTopCorrelatedVariables(variableList,
	                           data,
	                           pvalue = 0.001,
	                           corthreshold = 0.9,
	                           method = c("pearson", "kendall", "spearman"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="listTopCorrelatedVariables_+3A_variablelist">variableList</code></td>
<td>
 
<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="listTopCorrelatedVariables_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="listTopCorrelatedVariables_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to <code>method</code>, allowed for a pair of variables to be defined as significantly correlated
</p>
</td></tr>
<tr><td><code id="listTopCorrelatedVariables_+3A_corthreshold">corthreshold</code></td>
<td>

<p>The minimum correlation score, associated to <code>method</code>, allowed for a pair of variables to be defined as significantly correlated
</p>
</td></tr>
<tr><td><code id="listTopCorrelatedVariables_+3A_method">method</code></td>
<td>

<p>Correlation method: Pearson product-moment (&quot;pearson&quot;), Spearman's rank (&quot;spearman&quot;), or Kendall rank (&quot;kendall&quot;)
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>correlated.variables</code></td>
<td>

<p>A data frame with two columns:</p>
<ol>
<li><p> cor.var.names: The variables that are correlated	</p>
</li>
<li><p> cor.var.value: The correlation value</p>
</li></ol>

</td></tr>
<tr><td><code>short.list</code></td>
<td>

<p>A vector with a list of variables that are not correlated to each other. For every correlated pair, only the variable that first entered the correlation analysis was kept
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
	# Start the graphics device driver to save all plots in a pdf format
	pdf(file = "Example.pdf")
	# Get the stage C prostate cancer data from the rpart package
	library(rpart)
	data(stagec)
	# Split the stages into several columns
	dataCancer &lt;- cbind(stagec[,c(1:3,5:6)],
	                    gleason4 = 1*(stagec[,7] == 4),
	                    gleason5 = 1*(stagec[,7] == 5),
	                    gleason6 = 1*(stagec[,7] == 6),
	                    gleason7 = 1*(stagec[,7] == 7),
	                    gleason8 = 1*(stagec[,7] == 8),
	                    gleason910 = 1*(stagec[,7] &gt;= 9),
	                    eet = 1*(stagec[,4] == 2),
	                    diploid = 1*(stagec[,8] == "diploid"),
	                    tetraploid = 1*(stagec[,8] == "tetraploid"),
	                    notAneuploid = 1-1*(stagec[,8] == "aneuploid"))
	# Remove the incomplete cases
	dataCancer &lt;- dataCancer[complete.cases(dataCancer),]
	# Load a pre-stablished data frame with the names and descriptions of all variables
	data(cancerVarNames)
	# Get the variables that have a correlation coefficient larger 
	# than 0.65 at a p-value of 0.05
	cor &lt;- listTopCorrelatedVariables(variableList = cancerVarNames,
	                                  data = dataCancer,
	                                  pvalue = 0.05,
	                                  corthreshold = 0.65,
	                                  method = "pearson")
	# Shut down the graphics device driver
	dev.off()
## End(Not run)
</code></pre>

<hr>
<h2 id='LM_RIDGE_MIN'>Ridge Linear Models</h2><span id='topic+LM_RIDGE_MIN'></span>

<h3>Description</h3>

<p>FRESA wrapper to fit <code>MASS::lm.ridge</code> object to the data and returning the coef with minimum GCV
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	LM_RIDGE_MIN(formula = formula,data=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LM_RIDGE_MIN_+3A_formula">formula</code></td>
<td>

<p>The base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="LM_RIDGE_MIN_+3A_data">data</code></td>
<td>

<p>The data to be used for training the method
</p>
</td></tr>
<tr><td><code id="LM_RIDGE_MIN_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the MASS::lm.ridge function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fit</code></td>
<td>

<p>The <code>MASS::lm.ridge</code> fitted object
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>MASS::lm.ridge</code></p>

<hr>
<h2 id='metric95ci'>Estimators and 95CI</h2><span id='topic+metric95ci'></span><span id='topic+concordance95ci'></span><span id='topic+sperman95ci'></span><span id='topic+MAE95ci'></span><span id='topic+ClassMetric95ci'></span>

<h3>Description</h3>

<p>Bootstraped estimation of mean and 95CI 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>      metric95ci(metric,nss=1000,ssize=0)
      concordance95ci(datatest,nss=1000)
      sperman95ci(datatest,nss=4000)
      MAE95ci(datatest,nss=4000)
      ClassMetric95ci(datatest,nss=4000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metric95ci_+3A_datatest">datatest</code></td>
<td>

<p>A matrix whose first column is the model predictionground truth, and the second the prediction
</p>
</td></tr>
<tr><td><code id="metric95ci_+3A_nss">nss</code></td>
<td>

<p>The number of bootstrap samples
</p>
</td></tr>
<tr><td><code id="metric95ci_+3A_metric">metric</code></td>
<td>

<p>A vector with metric estimations
</p>
</td></tr>
<tr><td><code id="metric95ci_+3A_ssize">ssize</code></td>
<td>

<p>The maximim number of samples to use
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A set of auxiliary samples to bootstrap estimations of the 95CI
</p>


<h3>Value</h3>

<p>the mean estimation of the metrics with its corresponding  95CI
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+randomCV">randomCV</a></code></p>

<hr>
<h2 id='modelFitting'>Fit a model to the data</h2><span id='topic+modelFitting'></span>

<h3>Description</h3>

<p>This function fits a linear, logistic, or Cox proportional hazards regression model to given data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	modelFitting(model.formula,
	             data,
	             type = c("LOGIT", "LM", "COX","SVM"),
	             fitFRESA=TRUE,
	              ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modelFitting_+3A_model.formula">model.formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be used
</p>
</td></tr>
<tr><td><code id="modelFitting_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="modelFitting_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), Cox proportional hazards (&quot;COX&quot;) or &quot;SVM&quot;
</p>
</td></tr>
<tr><td><code id="modelFitting_+3A_fitfresa">fitFRESA</code></td>
<td>

<p>if true it will perform use the FRESA cpp code for fitting
</p>
</td></tr>
<tr><td><code id="modelFitting_+3A_...">...</code></td>
<td>

<p>Additional parameters for fitting a default <code>glm</code> object
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted model of the type defined in <code>type</code>
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>

<hr>
<h2 id='mRMR.classic_FRESA'>FRESA.CAD wrapper of mRMRe::mRMR.classic</h2><span id='topic+mRMR.classic_FRESA'></span>

<h3>Description</h3>

<p>Returns the positive MI-scored set of maximum relevance minimum redundancy (mRMR) features returned by the mMRM.classic function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
mRMR.classic_FRESA(data=NULL, Outcome=NULL,feature_count=0,...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mRMR.classic_FRESA_+3A_data">data</code></td>
<td>

<p>The data frame
</p>
</td></tr>
<tr><td><code id="mRMR.classic_FRESA_+3A_outcome">Outcome</code></td>
<td>

<p>The outcome feature
</p>
</td></tr>
<tr><td><code id="mRMR.classic_FRESA_+3A_feature_count">feature_count</code></td>
<td>

<p>The number of features to return
</p>
</td></tr>
<tr><td><code id="mRMR.classic_FRESA_+3A_...">...</code></td>
<td>

<p>Extra parameters to be passed to the <code>mRMRe::mMRM.classic</code> function
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named vector with the MI-score of the selected features
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>mRMRe::mRMR.classic</code></p>

<hr>
<h2 id='multivariate_BinEnsemble'>Multivariate Filters</h2><span id='topic+multivariate_BinEnsemble'></span>

<h3>Description</h3>

<p>Returns the top set of features that are associated with the outcome based on Multivariate logistic models: LASSO and BSWiMS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariate_BinEnsemble(data,Outcome,limit=-1,adjustMethod="BH",...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multivariate_BinEnsemble_+3A_data">data</code></td>
<td>

<p>The data frame
</p>
</td></tr>
<tr><td><code id="multivariate_BinEnsemble_+3A_outcome">Outcome</code></td>
<td>

<p>The outcome feature
</p>
</td></tr>
<tr><td><code id="multivariate_BinEnsemble_+3A_adjustmethod">adjustMethod</code></td>
<td>

<p>The method used by the p.adjust method
</p>
</td></tr>
<tr><td><code id="multivariate_BinEnsemble_+3A_limit">limit</code></td>
<td>

<p>The samples-wise fraction of features to return. 
</p>
</td></tr>
<tr><td><code id="multivariate_BinEnsemble_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the correlated_Remove function
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named vector with the adjusted p-values of the associted features
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>Examples</h3>

<pre><code class='language-R'>    ## Not run: 

        library("FRESA.CAD")

        ### Univariate Filter Examples ####

        # Get the stage C prostate cancer data from the rpart package
        data(stagec,package = "rpart")

        # Prepare the data. Create a model matrix without the event time and interactions
        stagec$pgtime &lt;- NULL
        stagec$eet &lt;- as.factor(stagec$eet)
        options(na.action = 'na.pass')
        stagec_mat &lt;- cbind(pgstat = stagec$pgstat,
                            as.data.frame(model.matrix(pgstat ~ .*.,stagec))[-1])
        fnames &lt;- colnames(stagec_mat)
        fnames &lt;- str_replace_all(fnames,":","__")
        colnames(stagec_mat) &lt;- fnames

        # Impute the missing data
        dataCancerImputed &lt;- nearestNeighborImpute(stagec_mat)
        dataCancerImputed[,1:ncol(dataCancerImputed)] &lt;- sapply(dataCancerImputed,as.numeric)

        # Get the top Features associated to pgstat

        q_values &lt;- multivariate_BinEnsemble(data=dataCancerImputed, 
                                    Outcome="pgstat")



    
## End(Not run)
</code></pre>

<hr>
<h2 id='NAIVE_BAYES'>Naive Bayes Modeling</h2><span id='topic+NAIVE_BAYES'></span>

<h3>Description</h3>

<p>FRESA wrapper to fit <code>naivebayes::naive_bayes</code> object to the data 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	NAIVE_BAYES(formula = formula,data=NULL,pca=TRUE,normalize=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NAIVE_BAYES_+3A_formula">formula</code></td>
<td>

<p>The base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="NAIVE_BAYES_+3A_data">data</code></td>
<td>

<p>The data to be used for training the method
</p>
</td></tr>
<tr><td><code id="NAIVE_BAYES_+3A_pca">pca</code></td>
<td>

<p>Apply PCA?
</p>
</td></tr>
<tr><td><code id="NAIVE_BAYES_+3A_normalize">normalize</code></td>
<td>

<p>Apply data normalization?
</p>
</td></tr>
<tr><td><code id="NAIVE_BAYES_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the naivebayes::naive_bayes function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fit</code></td>
<td>

<p>The <code>naivebayes::naive_bayes</code> fitted object
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>naivebayes::naive_bayes</code></p>

<hr>
<h2 id='nearestCentroid'>Class Label Based on the Minimum Mahalanobis Distance</h2><span id='topic+nearestCentroid'></span>

<h3>Description</h3>

<p>The function will return the set of labels of a data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   nearestCentroid(dataset,
                  clustermean=NULL,
                  clustercov=NULL, 
                  p.threshold=1.0e-6)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nearestCentroid_+3A_dataset">dataset</code></td>
<td>

<p>The data set to be labeled
</p>
</td></tr>
<tr><td><code id="nearestCentroid_+3A_clustermean">clustermean</code></td>
<td>

<p>The list of cluster centers.
</p>
</td></tr>
<tr><td><code id="nearestCentroid_+3A_clustercov">clustercov</code></td>
<td>

<p>The list of cluster covariances
</p>
</td></tr>
<tr><td><code id="nearestCentroid_+3A_p.threshold">p.threshold</code></td>
<td>

<p>The minimum aceptance p.value
</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The data set will be labeled based on the nearest cluster label. Points distance with membership probability
lower than the acceptance threshold will have the &quot;0&quot; label.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>ClusterLabels</code></td>
<td>

<p>The labels of each point
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='nearestNeighborImpute'>nearest neighbor NA imputation</h2><span id='topic+nearestNeighborImpute'></span>

<h3>Description</h3>

<p>The function will replace any NA present in the data-frame with the median values of the nearest neighbours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	nearestNeighborImpute(tobeimputed,
	                      referenceSet=NULL,
						  catgoricCol=NULL,
	                      distol=1.05,
						  useorder=TRUE
	                     )

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nearestNeighborImpute_+3A_tobeimputed">tobeimputed</code></td>
<td>

<p>a data frame with missing values (NA values)
</p>
</td></tr>
<tr><td><code id="nearestNeighborImpute_+3A_referenceset">referenceSet</code></td>
<td>

<p>An optional data frame with a set of complete observations. This data frame will be added to the search set
</p>
</td></tr>
<tr><td><code id="nearestNeighborImpute_+3A_catgoriccol">catgoricCol</code></td>
<td>

<p>An optional list of columns names that should be consider categorical
</p>
</td></tr>
<tr><td><code id="nearestNeighborImpute_+3A_distol">distol</code></td>
<td>

<p>The tolerance used to define if a particular set of row observations is similar to the minimum distance 
</p>
</td></tr>
<tr><td><code id="nearestNeighborImpute_+3A_useorder">useorder</code></td>
<td>

<p>Impute using the last observation on startified by categorical data	
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will find any NA present in the data set and it will search for the row set of complete observations that have the closest IQR normalized Manhattan distance to the row with missing values. 
If a set of rows have similar minimum distances (toldis*(minimum distance) &gt; row set distance) the median value will be used.
</p>


<h3>Value</h3>

<p>A data frame, where each NA has been replaced with the value of the nearest neighbors
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
	# Get the stage C prostate cancer data from the rpart package
	library(rpart)
	data(stagec)
	# Set the options to keep the na
	options(na.action='na.pass')
	# create a model matrix with all the NA values imputed
	stagecImputed &lt;- nearestNeighborImpute(model.matrix(~.,stagec)[,-1])
	
## End(Not run)
</code></pre>

<hr>
<h2 id='plot.bootstrapValidation_Bin'>Plot ROC curves of bootstrap results</h2><span id='topic+plot'></span><span id='topic+plot.bootstrapValidation_Bin'></span>

<h3>Description</h3>

<p>This function plots ROC curves and a Kaplan-Meier curve (when fitting a Cox proportional hazards regression model) of a bootstrapped model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'bootstrapValidation_Bin'
plot(x,
	     xlab = "Years",
	     ylab = "Survival",
		 strata.levels=c(0),
	     main = "ROC",
		 cex=1.0,
		 ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.bootstrapValidation_Bin_+3A_x">x</code></td>
<td>

<p>A <code>bootstrapValidation_Bin</code> object
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Bin_+3A_xlab">xlab</code></td>
<td>

<p>The label of the <em>x</em>-axis
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Bin_+3A_ylab">ylab</code></td>
<td>

<p>The label of the <em>y</em>-axis
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Bin_+3A_strata.levels">strata.levels</code></td>
<td>

<p>stratification level for the Kaplan-Meier plots
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Bin_+3A_main">main</code></td>
<td>

<p>Main Plot title
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Bin_+3A_cex">cex</code></td>
<td>

<p>The text cex
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Bin_+3A_...">...</code></td>
<td>

<p>Additional parameters for the generic <code>plot</code> function
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.bootstrapValidation_Res">plot.bootstrapValidation_Res</a></code></p>

<hr>
<h2 id='plot.bootstrapValidation_Res'>Plot ROC curves of bootstrap results</h2><span id='topic+plot.bootstrapValidation_Res'></span>

<h3>Description</h3>

<p>This function plots ROC curves and a Kaplan-Meier curve (when fitting a Cox proportional hazards regression model) of a bootstrapped model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'bootstrapValidation_Res'
plot(x,
	     xlab = "Years",
	     ylab = "Survival",
	     ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.bootstrapValidation_Res_+3A_x">x</code></td>
<td>

<p>A <code>bootstrapValidation_Res</code> object
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Res_+3A_xlab">xlab</code></td>
<td>

<p>The label of the <em>x</em>-axis
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Res_+3A_ylab">ylab</code></td>
<td>

<p>The label of the <em>y</em>-axis
</p>
</td></tr>
<tr><td><code id="plot.bootstrapValidation_Res_+3A_...">...</code></td>
<td>

<p>Additional parameters for the plot
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.bootstrapValidation_Bin">plot.bootstrapValidation_Bin</a></code></p>

<hr>
<h2 id='plot.FRESA_benchmark'>Plot the results of the model selection benchmark</h2><span id='topic+plot.FRESA_benchmark'></span>

<h3>Description</h3>

<p>The different output metrics of the benchmark (BinaryBenchmark,RegresionBenchmark or OrdinalBenchmark) are plotted.
It returns data matrices that describe the different plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_benchmark'
plot(x,...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.FRESA_benchmark_+3A_x">x</code></td>
<td>

<p>A <code>FRESA_benchmark</code> object
</p>
</td></tr>
<tr><td><code id="plot.FRESA_benchmark_+3A_...">...</code></td>
<td>

<p>Additional parameters for the generic <code>plot</code> function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>metrics</code></td>
<td>

<p>The model test performance based on the <code>predictionStats_binary</code>, <code>predictionStats_regression</code> or <code>predictionStats_ordinal</code> functions.
</p>
</td></tr>
<tr><td><code>barPlotsCI</code></td>
<td>

<p>The <code>barPlotCiError</code> outputs for each metric.
</p>
</td></tr>
<tr><td><code>metrics_filter</code></td>
<td>

<p>The model test performance for each filter method based on the <code>predictionStats_binary</code> function.
</p>
</td></tr>
<tr><td><code>barPlotsCI_filter</code></td>
<td>

<p>The <code>barPlotCiError</code> outputs for each metric on the filter methods
</p>
</td></tr>
<tr><td><code>minMaxMetrics</code></td>
<td>

<p>Reports the min and maximum value for each reported metric.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+BinaryBenchmark">BinaryBenchmark</a></code>, <code><a href="#topic+predictionStats_binary">predictionStats_binary</a></code></p>

<hr>
<h2 id='plotModels.ROC'>Plot test ROC curves of each cross-validation model</h2><span id='topic+plotModels.ROC'></span>

<h3>Description</h3>

<p>This function plots test ROC curves of each model found in the cross validation process.
It will also aggregate the models into a single prediction performance, plotting the resulting ROC curve (models coherence).
Furthermore, it will plot the mean sensitivity for a given set of specificities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   plotModels.ROC(modelPredictions,
    number.of.models=0,
    specificities=c(0.975,0.95,0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10,0.05),
    theCVfolds=1,
    predictor="Prediction",
	cex=1.0,
	thr=NULL,
    ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotModels.ROC_+3A_modelpredictions">modelPredictions</code></td>
<td>

<p>A data frame returned by the <code>crossValidationFeatureSelection_Bin</code> function, either the <code>Models.testPrediction</code>, the <code>FullBSWiMS.testPrediction</code>,<br /> the <code>Models.CVtestPredictions</code>, the <code>TestRetrained.blindPredictions</code>,<br /> the <code>KNN.testPrediction</code>, or the <code>LASSO.testPredictions</code> value
</p>
</td></tr>
<tr><td><code id="plotModels.ROC_+3A_number.of.models">number.of.models</code></td>
<td>

<p>The maximum number of models to plot
</p>
</td></tr>
<tr><td><code id="plotModels.ROC_+3A_specificities">specificities</code></td>
<td>

<p>Vector containing the specificities at which the ROC sensitivities will be calculated
</p>
</td></tr>
<tr><td><code id="plotModels.ROC_+3A_thecvfolds">theCVfolds</code></td>
<td>

<p>The number of folds performed in a Cross-validation experiment
</p>
</td></tr>
<tr><td><code id="plotModels.ROC_+3A_predictor">predictor</code></td>
<td>

<p>The name of the column to be plotted
</p>
</td></tr>
<tr><td><code id="plotModels.ROC_+3A_cex">cex</code></td>
<td>

<p>Controlling the font size of the text inside the plots
</p>
</td></tr>
<tr><td><code id="plotModels.ROC_+3A_thr">thr</code></td>
<td>

<p>The threshold for confusion matrix
</p>
</td></tr>
<tr><td><code id="plotModels.ROC_+3A_...">...</code></td>
<td>

<p>Additional parameters for the <code>roc</code> function (<code>pROC</code> package)
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>ROC.AUCs</code></td>
<td>

<p>A vector with the AUC of each ROC
</p>
</td></tr>
<tr><td><code>mean.sensitivities</code></td>
<td>

<p>A vector with the mean sensitivity at the specificities given by <code>specificities</code>
</p>
</td></tr>
<tr><td><code>model.sensitivities</code></td>
<td>

<p>A matrix where each row represents the sensitivity at the specificity given by <code>specificities</code> for a different ROC
</p>
</td></tr>
<tr><td><code>specificities</code></td>
<td>

<p>The specificities used to calculate the sensitivities
</p>
</td></tr>
<tr><td><code>senAUC</code></td>
<td>

<p>The AUC of the ROC curve that resulted from using <code>mean.sensitivities</code>
</p>
</td></tr>
<tr><td><code>predictionTable</code></td>
<td>

<p>The confusion matrix between the outcome and the ensemble prediction
</p>
</td></tr>
<tr><td><code>ensemblePrediction</code></td>
<td>

<p>The ensemble (median prediction) of the repeated predictions
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>

<hr>
<h2 id='ppoisGzero'>Probability of more than zero events</h2><span id='topic+adjustProb'></span><span id='topic+ppoisGzero'></span><span id='topic+meanTimeToEvent'></span><span id='topic+expectedEventsPerInterval'></span>

<h3>Description</h3>

<p>Returns the probability of having 1 or more Poisson events
the adjusted probability (adjustProb)
the exptected time to event (meanTimeToEvent)
or the exected number of events per interval (expectedEventsPerInterval)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	ppoisGzero(index,h0)
	adjustProb(probGZero,gain)
	meanTimeToEvent(probGZero,timeInterval)
	expectedEventsPerInterval(probGZero)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ppoisGzero_+3A_index">index</code></td>
<td>

<p>The hazard index 
</p>
</td></tr>	
<tr><td><code id="ppoisGzero_+3A_h0">h0</code></td>
<td>

<p>Baseline hazard
</p>
</td></tr>
<tr><td><code id="ppoisGzero_+3A_probgzero">probGZero</code></td>
<td>

<p>The probability of having any event
</p>
</td></tr>
<tr><td><code id="ppoisGzero_+3A_gain">gain</code></td>
<td>

<p>The calibration gain
</p>
</td></tr>	
<tr><td><code id="ppoisGzero_+3A_timeinterval">timeInterval</code></td>
<td>

<p>The time interval 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Auxiliary functions for the estimation of the probability of having at least one Poisson event. Or the mean time to event. 
</p>


<h3>Value</h3>

<p>The probability of nozero events.
Or the expected time to event (meanTimeToEvent)
Or the expected number of events per interval (expectedEventsPerInterval)
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>RRPlot</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  #TBD
</code></pre>

<hr>
<h2 id='predict.BAGGS'>Predicts <code><a href="#topic+baggedModel">baggedModel</a></code> bagged models</h2><span id='topic+predict.BAGGS'></span>

<h3>Description</h3>

<p>This function predicts the class of a BAGGS generated models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'BAGGS'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.BAGGS_+3A_object">object</code></td>
<td>

<p>An object of class BAGGS 
</p>
</td></tr>
<tr><td><code id="predict.BAGGS_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list with the predicted class of every data sample
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+baggedModel">baggedModel</a></code></p>

<hr>
<h2 id='predict.CLUSTER_CLASS'>Predicts <code><a href="#topic+ClustClass">ClustClass</a></code> outcome</h2><span id='topic+predict.CLUSTER_CLASS'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a ClustClass classifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'CLUSTER_CLASS'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.CLUSTER_CLASS_+3A_object">object</code></td>
<td>

<p>An object of class CLUSTER_CLASS 
</p>
</td></tr>
<tr><td><code id="predict.CLUSTER_CLASS_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predict of a hierarchical ClustClass classifier
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+ClustClass">ClustClass</a></code></p>

<hr>
<h2 id='predict.fitFRESA'>Linear or probabilistic prediction</h2><span id='topic+predict'></span><span id='topic+predict.fitFRESA'></span>

<h3>Description</h3>

<p>This function returns the predicted outcome of a specific model.
The model is used to generate linear predictions.
The probabilistic values are generated using the logistic transformation on the linear predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'fitFRESA'
predict(object,
	                ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fitFRESA_+3A_object">object</code></td>
<td>

<p>An object of class fitFRESA containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="predict.fitFRESA_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata;predictType=c(&quot;linear&quot;,&quot;prob&quot;) and impute=FALSE.
If impute is set to TRUE it will use the object model to impute missing data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the predicted values
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+nearestNeighborImpute">nearestNeighborImpute</a></code></p>

<hr>
<h2 id='predict.FRESA_BESS'>Predicts <code><a href="#topic+BESS">BESS</a></code> models</h2><span id='topic+predict.FRESA_BESS'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a BESS model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_BESS'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESA_BESS_+3A_object">object</code></td>
<td>

<p>An object of class FRESA_BESS 
</p>
</td></tr>
<tr><td><code id="predict.FRESA_BESS_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predict BESS object
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+BESS">BESS</a></code></p>

<hr>
<h2 id='predict.FRESA_FILTERFIT'>Predicts <code><a href="#topic+filteredFit">filteredFit</a></code> models</h2><span id='topic+predict.FRESA_FILTERFIT'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a filteredFit model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_FILTERFIT'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESA_FILTERFIT_+3A_object">object</code></td>
<td>

<p>An object of class FRESA_FILTERFIT 
</p>
</td></tr>
<tr><td><code id="predict.FRESA_FILTERFIT_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predicted outcome
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='predict.FRESA_GLMNET'>Predicts GLMNET fitted objects </h2><span id='topic+predict.FRESA_GLMNET'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a FRESA_GLMNET fitted object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_GLMNET'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESA_GLMNET_+3A_object">object</code></td>
<td>

<p>An object of class FRESA_GLMNET containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="predict.FRESA_GLMNET_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the predicted values
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+GLMNET">GLMNET</a></code></p>

<hr>
<h2 id='predict.FRESA_HLCM'>Predicts BOOST_BSWiMS models</h2><span id='topic+predict.FRESA_HLCM'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a BOOST_BSWiMS model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_HLCM'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESA_HLCM_+3A_object">object</code></td>
<td>

<p>An object of class FRESA_HLCM 
</p>
</td></tr>
<tr><td><code id="predict.FRESA_HLCM_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predict of boosted BSWiMS
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+BSWiMS.model">BSWiMS.model</a></code></p>

<hr>
<h2 id='predict.FRESA_NAIVEBAYES'>Predicts <code><a href="#topic+NAIVE_BAYES">NAIVE_BAYES</a></code> models</h2><span id='topic+predict.FRESA_NAIVEBAYES'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a FRESA_NAIVEBAYES model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_NAIVEBAYES'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESA_NAIVEBAYES_+3A_object">object</code></td>
<td>

<p>An object of class FRESA_NAIVEBAYES 
</p>
</td></tr>
<tr><td><code id="predict.FRESA_NAIVEBAYES_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the predicted values
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+NAIVE_BAYES">NAIVE_BAYES</a></code></p>

<hr>
<h2 id='predict.FRESA_RIDGE'>Predicts <code><a href="#topic+LM_RIDGE_MIN">LM_RIDGE_MIN</a></code> models</h2><span id='topic+predict.FRESA_RIDGE'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a LM_RIDGE_MIN model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_RIDGE'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESA_RIDGE_+3A_object">object</code></td>
<td>

<p>An object of class FRESA_RIDGE 
</p>
</td></tr>
<tr><td><code id="predict.FRESA_RIDGE_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the predicted values
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+LM_RIDGE_MIN">LM_RIDGE_MIN</a></code></p>

<hr>
<h2 id='predict.FRESA_SVM'>Predicts <code><a href="#topic+TUNED_SVM">TUNED_SVM</a></code> models</h2><span id='topic+predict.FRESA_SVM'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a TUNED_SVM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESA_SVM'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESA_SVM_+3A_object">object</code></td>
<td>

<p>An object of class FRESA_SVM 
</p>
</td></tr>
<tr><td><code id="predict.FRESA_SVM_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predict e1071::svm object
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+TUNED_SVM">TUNED_SVM</a></code></p>

<hr>
<h2 id='predict.FRESAKNN'>Predicts <code>class::knn</code> models</h2><span id='topic+predict.FRESAKNN'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a FRESAKNN model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESAKNN'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESAKNN_+3A_object">object</code></td>
<td>

<p>An object of class FRESAKNN containing the KNN train set
</p>
</td></tr>
<tr><td><code id="predict.FRESAKNN_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the predicted values
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+KNN_method">KNN_method</a></code>, <code>class::knn</code></p>

<hr>
<h2 id='predict.FRESAsignature'>Predicts <code><a href="#topic+CVsignature">CVsignature</a></code> models</h2><span id='topic+predict.FRESAsignature'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a FRESAsignature model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'FRESAsignature'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FRESAsignature_+3A_object">object</code></td>
<td>

<p>An object of class FRESAsignature 
</p>
</td></tr>
<tr><td><code id="predict.FRESAsignature_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the predicted values
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+CVsignature">CVsignature</a></code>,<code><a href="#topic+getSignature">getSignature</a></code>,<code><a href="#topic+signatureDistance">signatureDistance</a></code></p>

<hr>
<h2 id='predict.GMVE'>Predicts <code><a href="#topic+GMVECluster">GMVECluster</a></code> clusters</h2><span id='topic+predict.GMVE'></span>

<h3>Description</h3>

<p>This function predicts the class of a GMVE generated cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'GMVE'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.GMVE_+3A_object">object</code></td>
<td>

<p>An object of class GMVE 
</p>
</td></tr>
<tr><td><code id="predict.GMVE_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata. thr=p.value threshold
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list with the predicted class of every data sample
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+GMVECluster">GMVECluster</a></code></p>

<hr>
<h2 id='predict.GMVE_BSWiMS'>Predicts <code><a href="#topic+GMVEBSWiMS">GMVEBSWiMS</a></code> outcome</h2><span id='topic+predict.GMVE_BSWiMS'></span>

<h3>Description</h3>

<p>This function predicts the outcome from a GMVEBSWiMS classifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'GMVE_BSWiMS'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.GMVE_BSWiMS_+3A_object">object</code></td>
<td>

<p>An object of class GMVE_BSWiMS 
</p>
</td></tr>
<tr><td><code id="predict.GMVE_BSWiMS_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the predict of a hierarchical GMVE-BSWiMS classifier
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+GMVEBSWiMS">GMVEBSWiMS</a></code></p>

<hr>
<h2 id='predict.LogitCalPred'>Predicts calibrated probabilities</h2><span id='topic+predict.LogitCalPred'></span>

<h3>Description</h3>

<p>This function predicts the calibrated probability of a binary outcome
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'LogitCalPred'
predict(object,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.LogitCalPred_+3A_object">object</code></td>
<td>

<p>An object of class LogitCalPred 
</p>
</td></tr>
<tr><td><code id="predict.LogitCalPred_+3A_...">...</code></td>
<td>

<p>A list with: testdata=testdata
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the calibrated probability
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+calBinProb">calBinProb</a></code></p>

<hr>
<h2 id='predictionStats'>Prediction Evaluation</h2><span id='topic+predictionStats_binary'></span><span id='topic+predictionStats_regression'></span><span id='topic+predictionStats_ordinal'></span><span id='topic+predictionStats_survival'></span>

<h3>Description</h3>

<p>This function returns the statistical metrics describing the association between model predictions and the ground truth outcome 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
      predictionStats_binary(predictions, plotname="", center=FALSE,...)
      predictionStats_regression(predictions, plotname="",...)
      predictionStats_ordinal(predictions,plotname="",...)
      predictionStats_survival(predictions,plotname="",atriskthr=1.0,...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictionStats_+3A_predictions">predictions</code></td>
<td>

<p>A matrix whose first column is the ground truth, and the second is the model prediction
</p>
</td></tr>
<tr><td><code id="predictionStats_+3A_plotname">plotname</code></td>
<td>

<p>The main title to be used by the plot function. If empty, no plot will be provided 
</p>
</td></tr>
<tr><td><code id="predictionStats_+3A_center">center</code></td>
<td>

<p>For binary predictions indicates if the prediction is around zero 
</p>
</td></tr>
<tr><td><code id="predictionStats_+3A_atriskthr">atriskthr</code></td>
<td>

<p>For survival predictions indicates the threshoold for at risk subjects. 
</p>
</td></tr>
<tr><td><code id="predictionStats_+3A_...">...</code></td>
<td>

<p>Extra parameters to be passed to the plot function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions will analyze the prediction outputs and will compare to the ground truth.
The output will depend on the prediction task: Binary classification, Linear Regression, Ordinal regression or Cox regression.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>accc</code></td>
<td>

<p>The classification accuracy with its95% confidence intervals (95/
</p>
</td></tr>
<tr><td><code>berror</code></td>
<td>

<p>The balanced error rate with its 95%CI
</p>
</td></tr>
<tr><td><code>aucs</code></td>
<td>

<p>The ROC area under the curve (ROC AUC) of the binary classifier with its 95%CI
</p>
</td></tr>
<tr><td><code>specificity</code></td>
<td>

<p>The specificity with its 95%CI
</p>
</td></tr>
<tr><td><code>sensitivity</code></td>
<td>

<p>The sensitivity with its 95%CI
</p>
</td></tr>
<tr><td><code>ROC.analysis</code></td>
<td>

<p>The output of the ROC function
</p>
</td></tr>
<tr><td><code>CM.analysis</code></td>
<td>

<p>The output of the <code>epiR::epi.tests</code> function
</p>
</td></tr>
<tr><td><code>corci</code></td>
<td>

<p>the Pearson correlation with its 95%CI
</p>
</td></tr>
<tr><td><code>biasci</code></td>
<td>

<p>the regression bias and its 95%CI
</p>
</td></tr>
<tr><td><code>RMSEci</code></td>
<td>

<p>the root mean square error (RMSE) and its 95%CI
</p>
</td></tr>
<tr><td><code>spearmanci</code></td>
<td>

<p>the Spearman correlation and its 95%CI
</p>
</td></tr>
<tr><td><code>MAEci</code></td>
<td>

<p>the mean absolute difference(MAE) and its 95%CI
</p>
</td></tr>
<tr><td><code>pearson</code></td>
<td>

<p>the output of the <code>cor.test</code> function
</p>
</td></tr>
<tr><td><code>Kendall</code></td>
<td>

<p>the Kendall correlation and its 95%CI
</p>
</td></tr>
<tr><td><code>Bias</code></td>
<td>

<p>the ordinal regression bias and its 95%CI
</p>
</td></tr>
<tr><td><code>BMAE</code></td>
<td>

<p>the balanced mean absolute difference for ordinal regression
</p>
</td></tr>
<tr><td><code>class95ci</code></td>
<td>

<p>the output of the bootstrapped estimation of accuracy, sensitivity, and ROC AUC
</p>
</td></tr>
<tr><td><code>KendallTauB</code></td>
<td>

<p>the output of the <code>DescTools::KendallTauB</code> function
</p>
</td></tr>
<tr><td><code>Kappa.analysis</code></td>
<td>

<p>the output of the <code>irr::kappa2</code> function
</p>
</td></tr>
<tr><td><code>CIFollowUp</code></td>
<td>

<p>The follow-up concordance index with its95% confidence intervals (95/
</p>
</td></tr>
<tr><td><code>CIRisk</code></td>
<td>

<p>The risks concordance index with its95% confidence intervals (95/
</p>
</td></tr>
<tr><td><code>LogRank</code></td>
<td>

<p>The LogRank test with its95% confidence intervals (95/
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+randomCV">randomCV</a></code></p>

<hr>
<h2 id='randomCV'>Cross Validation of Prediction Models</h2><span id='topic+randomCV'></span>

<h3>Description</h3>

<p>The data set will be divided into a random train set and a test sets. The train set will be modeled by the user provided fitting 
method. Each fitting method must have a prediction function that will be used to predict the outcome of the test set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	randomCV(theData = NULL,
             theOutcome = "Class",
             fittingFunction=NULL, 
             trainFraction = 0.5,
             repetitions = 100,
             trainSampleSets=NULL,
             featureSelectionFunction=NULL,
             featureSelection.control=NULL,
             asFactor=FALSE,
             addNoise=FALSE,
             classSamplingType=c("Proportional",
                                  "Balanced",
                                  "Augmented",
                                  "LOO"),
              testingSet=NULL,
             ...
             )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="randomCV_+3A_thedata">theData</code></td>
<td>

<p>The data-frame for cross-validation
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_theoutcome">theOutcome</code></td>
<td>

<p>The name of the outcome
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_fittingfunction">fittingFunction</code></td>
<td>

<p>The fitting function used to model the data
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_trainfraction">trainFraction</code></td>
<td>

<p>The percentage of the data to be used for training
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_repetitions">repetitions</code></td>
<td>

<p>The number of times that the CV process will be repeated
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_trainsamplesets">trainSampleSets</code></td>
<td>

<p>A set of train samples
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_featureselectionfunction">featureSelectionFunction</code></td>
<td>

<p>The feature selection function to be used to filter out irrelevant features
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_featureselection.control">featureSelection.control</code></td>
<td>

<p>The parameters to control the feature selection function
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_asfactor">asFactor</code></td>
<td>

<p>Set theOutcome as factor
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_addnoise">addNoise</code></td>
<td>

<p>if TRUE will add 0.1
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_classsamplingtype">classSamplingType</code></td>
<td>

<p>if &quot;Proportional&quot;: proportional to the data classes. 
&quot;Augmented&quot;: Augment samples to balance training class
&quot;Balanced&quot;: All class in training set have the same samples
&quot;LOO&quot;: Leave one out per class
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_testingset">testingSet</code></td>
<td>

<p>An extra set for testing Models
</p>
</td></tr>
<tr><td><code id="randomCV_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the fitting function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>testPredictions</code></td>
<td>

<p>All the predicted outcomes. Is a data matrix with three columns c(&quot;Outcome&quot;,&quot;Model&quot;,&quot;Prediction&quot;). Each row has a prediction for a given test subject
</p>
</td></tr>
<tr><td><code>trainPredictions</code></td>
<td>

<p>All the predicted outcomes in the train data set. Is a data matrix with three columns c(&quot;Outcome&quot;,&quot;Model&quot;,&quot;Prediction&quot;). Each row has a prediction for a given test subject
</p>
</td></tr>
<tr><td><code>medianTest</code></td>
<td>

<p>The median of the test prediction for each subject
</p>
</td></tr>
<tr><td><code>medianTrain</code></td>
<td>

<p>The median of the prediction for each train subject
</p>
</td></tr>
<tr><td><code>boxstaTest</code></td>
<td>

<p>The statistics of the boxplot for test data
</p>
</td></tr>
<tr><td><code>boxstaTrain</code></td>
<td>

<p>The statistics of the boxplot for train data
</p>
</td></tr>
<tr><td><code>trainSamplesSets</code></td>
<td>

<p>The id of the subjects used for training
</p>
</td></tr>
<tr><td><code>selectedFeaturesSet</code></td>
<td>

<p>A list with all the features used at each training cycle
</p>
</td></tr>
<tr><td><code>featureFrequency</code></td>
<td>

<p>A order table object that describes how many times a feature was selected.
</p>
</td></tr>
<tr><td><code>jaccard</code></td>
<td>

<p>The jaccard index of the features as well as the average number of features used for prediction
</p>
</td></tr>
<tr><td><code>theTimes</code></td>
<td>

<p>The CPU time analysis
</p>
</td></tr>
<tr><td><code>formula.list</code></td>
<td>

<p>If fit method returns the formulas: the agregated list of formulas
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 

        ### Cross Validation Example ####
        # Start the graphics device driver to save all plots in a pdf format
        pdf(file = "CrossValidationExample.pdf",width = 8, height = 6)

        # Get the stage C prostate cancer data from the rpart package
        data(stagec,package = "rpart")

        # Prepare the data. Create a model matrix with interactions but no event time 
        stagec$pgtime &lt;- NULL
        stagec$eet &lt;- as.factor(stagec$eet)
        options(na.action = 'na.pass')
        stagec_mat &lt;- cbind(pgstat = stagec$pgstat,
                         as.data.frame(model.matrix(pgstat ~ .*.,stagec))[-1])
        fnames &lt;- colnames(stagec_mat)
        fnames &lt;- str_replace_all(fnames,":","__")
        colnames(stagec_mat) &lt;- fnames

        # Impute the missing data
        dataCancerImputed &lt;- nearestNeighborImpute(stagec_mat)
        dataCancerImputed[,1:ncol(dataCancerImputed)] &lt;- sapply(dataCancerImputed,as.numeric)

        # Cross validating a Random Forest classifier
        cvRF &lt;- randomCV(dataCancerImputed,"pgstat",
                         randomForest::randomForest,
                         trainFraction = 0.8, 
                         repetitions = 10,
                         asFactor = TRUE);

        # Evaluate the prediction performance of the Random Forest classifier
        RFStats &lt;- predictionStats_binary(cvRF$medianTest,
        plotname = "Random Forest",cex = 0.9);

        # Cross validating a BSWiMS with the same train/test set
        cvBSWiMS &lt;- randomCV(fittingFunction = BSWiMS.model,
        	trainSampleSets = cvRF$trainSamplesSets);

        # Evaluate the prediction performance of the BSWiMS classifier
        BSWiMSStats &lt;- predictionStats_binary(cvBSWiMS$medianTest,
        	plotname = "BSWiMS",cex = 0.9);

        # Cross validating a LDA classifier with a t-student filter
        cvLDA &lt;- randomCV(dataCancerImputed,"pgstat",MASS::lda,
                          trainSampleSets = cvRF$trainSamplesSets,
                          featureSelectionFunction = univariate_tstudent,
                          featureSelection.control = list(limit = 0.5,thr = 0.975));

        # Evaluate the prediction performance of the LDA classifier
        LDAStats &lt;- predictionStats_binary(cvLDA$medianTest,plotname = "LDA",cex = 0.9);

        # Cross validating a QDA classifier with LDA t-student features and RF train/test set
        cvQDA &lt;- randomCV(fittingFunction = MASS::qda,
                          trainSampleSets = cvRF$trainSamplesSets,
                          featureSelectionFunction = cvLDA$selectedFeaturesSet);

        # Evaluate the prediction performance of the QDA classifier
        QDAStats &lt;- predictionStats_binary(cvQDA$medianTest,plotname = "QDA",cex = 0.9);

        #Create a barplot with 95
        errorciTable &lt;- rbind(RFStats$berror,
        	BSWiMSStats$berror,
        	LDAStats$berror,
        	QDAStats$berror)

        bpCI &lt;- barPlotCiError(as.matrix(errorciTable),metricname = "Balanced Error",
                        	   thesets =  c("Classifier Method"),
                        	   themethod = c("RF","BSWiMS","LDA","QDA"),
                        	   main = "Balanced Error",
                        	   offsets = c(0.5,0.15),
                        	   scoreDirection = "&lt;",
                        	   ho = 0.5,
                        	   args.legend = list(bg = "white",x = "topright"),
                        	   col = terrain.colors(4));



        dev.off()
	
## End(Not run)
</code></pre>

<hr>
<h2 id='rankInverseNormalDataFrame'>rank-based inverse normal transformation of the data</h2><span id='topic+rankInverseNormalDataFrame'></span>

<h3>Description</h3>

<p>This function takes a data frame and a reference control population to return a <em>z</em>-transformed data set conditioned to the reference population.
Each sample data for each feature column in the data frame is conditionally <em>z</em>-transformed using a rank-based inverse normal transformation, based on the rank of the sample in the reference frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	rankInverseNormalDataFrame(variableList,
	                           data,
	                           referenceframe,
	                           strata=NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rankInverseNormalDataFrame_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="rankInverseNormalDataFrame_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="rankInverseNormalDataFrame_+3A_referenceframe">referenceframe</code></td>
<td>

<p>A data frame similar to <code>data</code>, but with only the control population
</p>
</td></tr>
<tr><td><code id="rankInverseNormalDataFrame_+3A_strata">strata</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable that will be used to stratify the model
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame where each observation has been conditionally <em>z</em>-transformed, given control data
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
	# Start the graphics device driver to save all plots in a pdf format
	pdf(file = "Example.pdf")
	# Get the stage C prostate cancer data from the rpart package
	library(rpart)
	data(stagec)
	# Split the stages into several columns
	dataCancer &lt;- cbind(stagec[,c(1:3,5:6)],
	                    gleason4 = 1*(stagec[,7] == 4),
	                    gleason5 = 1*(stagec[,7] == 5),
	                    gleason6 = 1*(stagec[,7] == 6),
	                    gleason7 = 1*(stagec[,7] == 7),
	                    gleason8 = 1*(stagec[,7] == 8),
	                    gleason910 = 1*(stagec[,7] &gt;= 9),
	                    eet = 1*(stagec[,4] == 2),
	                    diploid = 1*(stagec[,8] == "diploid"),
	                    tetraploid = 1*(stagec[,8] == "tetraploid"),
	                    notAneuploid = 1-1*(stagec[,8] == "aneuploid"))
	# Remove the incomplete cases
	dataCancer &lt;- dataCancer[complete.cases(dataCancer),]
	# Load a pre-established data frame with the names and descriptions of all variables
	data(cancerVarNames)
	# Set the group of no progression
	noProgress &lt;- subset(dataCancer,pgstat==0)
	# z-transform g2 values using the no-progression group as reference
	dataCancerZTransform &lt;- rankInverseNormalDataFrame(variableList = cancerVarNames[2,],
	                                                   data = dataCancer,
	                                                   referenceframe = noProgress)
	# Shut down the graphics device driver
	dev.off()
## End(Not run)
</code></pre>

<hr>
<h2 id='reportEquivalentVariables'>Report the set of variables that will perform an equivalent IDI discriminant function</h2><span id='topic+reportEquivalentVariables'></span>

<h3>Description</h3>

<p>Given a model, this function will report a data frame with all the variables that may be interchanged in the model without affecting its classification performance.
For each variable in the model, this function will loop all candidate variables and report all of which result in an equivalent or better zIDI than the original model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	reportEquivalentVariables(object,
	                          pvalue = 0.05,
	                          data,
	                          variableList,
	                          Outcome = "Class",
	                          timeOutcome=NULL,
	                          type = c("LOGIT", "LM", "COX"),
	                          description = ".",
	                          method="BH",
	                          osize=0,
	                          fitFRESA=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reportEquivalentVariables_+3A_object">object</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the IDI , allowed for a pair of variables to be considered equivalent
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_description">description</code></td>
<td>

<p>The name of the column in <code>variableList</code> that stores the variable description
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_method">method</code></td>
<td>

<p>The method used by the p-value adjustment algorithm
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_osize">osize</code></td>
<td>

<p>The number of features used for p-value adjustment
</p>
</td></tr>
<tr><td><code id="reportEquivalentVariables_+3A_fitfresa">fitFRESA</code></td>
<td>

<p>if TRUE it will use the cpp based fitting method 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>pvalueList</code></td>
<td>

<p>A list with all the unadjusted p-values of the equivalent features per model variable
</p>
</td></tr>
<tr><td><code>equivalentMatrix</code></td>
<td>

<p>A data frame with three columns. The first column is the original variable of the model. 
The second column lists all variables that, if interchanged, will not statistically affect the performance of the model.
The third column lists the corresponding <em>z</em>-scores of the IDI for each equivalent variable.
</p>
</td></tr>
<tr><td><code>formulaList</code></td>
<td>

<p>a character vector with all the equivalent formulas 
</p>
</td></tr>
<tr><td><code>equivalentModel</code></td>
<td>

<p>a bagged model that used all the equivalent formulas. The model size is limited by the number of observations
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='residualForFRESA'>Return residuals from prediction</h2><span id='topic+residualForFRESA'></span>

<h3>Description</h3>

<p>Given a model and a new data set, this function will return the residuals of the predicted values.
When dealing with a Cox proportional hazards regression model, the function will return the Martingale residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	residualForFRESA(object,
	                 testData,
	                 Outcome,
	                 eta = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residualForFRESA_+3A_object">object</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the model to be analyzed
</p>
</td></tr>
<tr><td><code id="residualForFRESA_+3A_testdata">testData</code></td>
<td>

<p>A data frame  where all variables are stored in different columns, with the data set to be predicted
</p>
</td></tr>
<tr><td><code id="residualForFRESA_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="residualForFRESA_+3A_eta">eta</code></td>
<td>

<p>The weight of the contribution of the Martingale residuals, or 1 - the weight of the contribution of the classification residuals (only needed if <code>object</code> is of class <code>coxph</code>)
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the residuals (i.e. the differences between the predicted and the real outcome)
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>

<hr>
<h2 id='RRPlot'>Plot and Analysis of Indices of Risk</h2><span id='topic+RRPlot'></span>

<h3>Description</h3>

<p>Plots of calibration and performance of risk probabilites 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	RRPlot(riskData=NULL,
	timetoEvent=NULL,
	riskTimeInterval=NULL,
	ExpectedPrevalence=NULL,
	atRate=c(0.90,0.80),
	atThr=NULL,
    plotRR=TRUE,
	title="",
	ysurvlim=c(0,1.0)
	)	
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RRPlot_+3A_riskdata">riskData</code></td>
<td>

<p>The data frame with two columns: First: Event label (event=1, censored=0). Second: Probability of any future event within the riskTimeInterval
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_timetoevent">timetoEvent</code></td>
<td>

<p>The time to event vector
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_risktimeinterval">riskTimeInterval</code></td>
<td>

<p>The time interval of the probability estimations
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_expectedprevalence">ExpectedPrevalence</code></td>
<td>

<p>For Case-Control Studies: The expected prevalence of events.
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_atrate">atRate</code></td>
<td>

<p>The desired TNR (specificity) or FNR (1.0-sensitivity) of the computed risk at threshold
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_atthr">atThr</code></td>
<td>

<p>The risk threshold
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_plotrr">plotRR</code></td>
<td>

<p>If set to FALSE it will not generate the plots
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_title">title</code></td>
<td>

<p>The title postfix to be appended on each one of the generated plot titles
</p>
</td></tr>
<tr><td><code id="RRPlot_+3A_ysurvlim">ysurvlim</code></td>
<td>

<p>The y limits of the survival plot
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RRPlot function will analyze the provided probabilities of risk and its associated events to generate calibration plots and plots of Relative Risk (RR) vs all the sensitivity values. Furthermore, it will compute and analyze the RR of the computed threshold that contains the prescribed rate of true negative cases (TNR) or if the atRate value is lower than 0.5 it will assume that it is the FNR (1-Specificity). If the user provides the time to event data, the function will also plot the Kaplan-Meier curve and return the logrank probability of differences between risk categories. For the calibration plot it will use the user provided riskTimeInterval to get the expected number of events. If the user does not provide the riskTimeInterval the function will use the maximum time of observations with events.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>CumulativeOvs</code></td>
<td>

<p>Matrix with the Cumulative and Observed Events
</p>
</td></tr>
<tr><td><code>OEData</code></td>
<td>

<p>Matrix with the Estimated and Observed Events
</p>
</td></tr>
<tr><td><code>DCA</code></td>
<td>

<p>Decision Curve Analysis data matrix
</p>
</td></tr>
<tr><td><code>RRData</code></td>
<td>

<p>The risk ratios data matrix for the ploted observations
</p>
</td></tr>
<tr><td><code>timetoEventData</code></td>
<td>

<p>The dataframe with hazards, class and expeted time to event 
</p>
</td></tr>
<tr><td><code>keyPoints</code></td>
<td>

<p>The threshold values and metrics at: Specified, Max BACC, Max RR, and 100
</p>
</td></tr>
<tr><td><code>OERatio</code></td>
<td>

<p>The Observed/Expected poisson test
</p>
</td></tr>
<tr><td><code>OE95ci</code></td>
<td>

<p>The mean OE Ratio over the top 90
</p>
</td></tr>
<tr><td><code>OARatio</code></td>
<td>

<p>The Observed/Accumlated poisson test
</p>
</td></tr>
<tr><td><code>OAcum95ci</code></td>
<td>

<p>The mean O/A Ratio over the top 90
</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>

<p>The loess fit of the Risk Ratios
</p>
</td></tr>
<tr><td><code>ROCAnalysis</code></td>
<td>

<p>The Reciver Operating Curve and Binary performance analysis
</p>
</td></tr>
<tr><td><code>prevalence</code></td>
<td>

<p>The prevalence of events
</p>
</td></tr>
<tr><td><code>thr_atP</code></td>
<td>

<p>The p-value that contains atProb of the negative subjects
</p>
</td></tr>
<tr><td><code>c.index</code></td>
<td>

<p>The c-index with 90
</p>
</td></tr>
<tr><td><code>surfit</code></td>
<td>

<p>The survival fit object
</p>
</td></tr>
<tr><td><code>surdif</code></td>
<td>

<p>The logrank test analysis
</p>
</td></tr>
<tr><td><code>LogRankE</code></td>
<td>

<p>The bootstreped p-value of the logrank test
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>EmpiricalSurvDiff</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 

        ### RR Plot Example ####
        # Start the graphics device driver to save all plots in a pdf format
        pdf(file = "RRPlot.pdf",width = 8, height = 6)

		library(survival)
		library(FRESA.CAD)

		op &lt;- par(no.readonly = TRUE)

		### Libraries

		data(cancer, package="survival")
		lungD &lt;- lung
		lungD$inst &lt;- NULL
		lungD$status &lt;- lungD$status - 1
		lungD &lt;- lungD[complete.cases(lungD),]


		## Exploring Raw Features with RRPlot

		convar &lt;- colnames(lungD)[lapply(apply(lungD,2,unique),length) &gt; 10]
		convar &lt;- convar[convar != "time"]
		topvar &lt;- univariate_BinEnsemble(lungD[,c("status",convar)],"status")
		print(names(topvar))
		topv &lt;- min(5,length(topvar))
		topFive &lt;- names(topvar)[1:topv]
		RRanalysis &lt;- list();
		idx &lt;- 1
		for (topf in topFive)
		{
		  RRanalysis[[idx]] &lt;- RRPlot(cbind(lungD$status,lungD[,topf]),
									  atRate=c(0.90),
									  timetoEvent=lungD$time,
									  title=topf,
									  # plotRR=FALSE
		  )
		  idx &lt;- idx + 1
		}
		names(RRanalysis) &lt;- topFive

		## Reporting the Metrics

		ROCAUC &lt;- NULL
		CstatCI &lt;- NULL
		LogRangp &lt;- NULL
		Sensitivity &lt;- NULL
		Specificity &lt;- NULL

		for (topf in topFive)
		{
		  CstatCI &lt;- rbind(CstatCI,RRanalysis[[topf]]$c.index$cstatCI)
		  LogRangp &lt;- rbind(LogRangp,RRanalysis[[topf]]$surdif$pvalue)
		  Sensitivity &lt;- rbind(Sensitivity,RRanalysis[[topf]]$ROCAnalysis$sensitivity)
		  Specificity &lt;- rbind(Specificity,RRanalysis[[topf]]$ROCAnalysis$specificity)
		  ROCAUC &lt;- rbind(ROCAUC,RRanalysis[[topf]]$ROCAnalysis$aucs)
		}
		rownames(CstatCI) &lt;- topFive
		rownames(LogRangp) &lt;- topFive
		rownames(Sensitivity) &lt;- topFive
		rownames(Specificity) &lt;- topFive
		rownames(ROCAUC) &lt;- topFive

		print(ROCAUC)
		print(CstatCI)
		print(LogRangp)
		print(Sensitivity)
		print(Specificity)

		meanMatrix &lt;- cbind(ROCAUC[,1],CstatCI[,1],Sensitivity[,1],Specificity[,1])
		colnames(meanMatrix) &lt;- c("ROCAUC","C-Stat","Sen","Spe")
		print(meanMatrix)

		## COX Modeling
		ml &lt;- BSWiMS.model(Surv(time,status)~1,data=lungD,NumberofRepeats = 10)
		sm &lt;- summary(ml)
		print(sm$coefficients)

		### Cox Model Performance


		timeinterval &lt;- 2*mean(subset(lungD,status==1)$time)

		h0 &lt;- sum(lungD$status &amp; lungD$time &lt;= timeinterval)
		h0 &lt;- h0/sum((lungD$time &gt; timeinterval) | (lungD$status==1))
		print(t(c(h0=h0,timeinterval=timeinterval)),caption="Initial Parameters")

		index &lt;- predict(ml,lungD)

		rdata &lt;- cbind(lungD$status,ppoisGzero(index,h0))

		rrAnalysisTrain &lt;- RRPlot(rdata,atRate=c(0.90),
								  timetoEvent=lungD$time,
								  title="Raw Train: lung Cancer",
								  ysurvlim=c(0.00,1.0),
								  riskTimeInterval=timeinterval)


		### Reporting Performance 


		print(rrAnalysisTrain$keyPoints,caption="Key Values")
		print(rrAnalysisTrain$OERatio,caption="O/E Test")
		print(t(rrAnalysisTrain$OE95ci),caption="O/E Mean")
		print(rrAnalysisTrain$OARatio,caption="O/Acum Test")
		print(t(rrAnalysisTrain$OAcum95ci),caption="O/Acum Mean")
		print(rrAnalysisTrain$c.index$cstatCI,caption="C. Index")
		print(t(rrAnalysisTrain$ROCAnalysis$aucs),caption="ROC AUC")
		print((rrAnalysisTrain$ROCAnalysis$sensitivity),caption="Sensitivity")
		print((rrAnalysisTrain$ROCAnalysis$specificity),caption="Specificity")
		print(t(rrAnalysisTrain$thr_atP),caption="Probability Thresholds")
		print(rrAnalysisTrain$surdif,caption="Logrank test")


  
        dev.off()
	
## End(Not run)
</code></pre>

<hr>
<h2 id='signatureDistance'>Distance to the signature template</h2><span id='topic+signatureDistance'></span>

<h3>Description</h3>

<p>This function returns a normalized distance to the signature template 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	signatureDistance(
	              template,
	              data=NULL,
	              method = c("pearson","spearman","kendall","RSS","MAN","NB"),
	              fwts=NULL
	)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="signatureDistance_+3A_template">template</code></td>
<td>

<p>A list with a template matrix of the signature described with 
quantiles = [0.025,0.100,0.159,0.250,0.500,0.750,0.841,0.900,0.975]
</p>
</td></tr>
<tr><td><code id="signatureDistance_+3A_data">data</code></td>
<td>

<p>A data frame that will be used to compute the distance
</p>
</td></tr>
<tr><td><code id="signatureDistance_+3A_method">method</code></td>
<td>

<p>The distance method.
</p>
</td></tr>
<tr><td><code id="signatureDistance_+3A_fwts">fwts</code></td>
<td>

<p>A numeric vector defining the weight of each feature
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance to the template:
&quot;pearson&quot;,&quot;spearman&quot; and &quot;kendall&quot; distances are computed using the correlation function i.e. 1-r. 
&quot;RSS&quot; distance is the normalized root sum square distance
&quot;MAN&quot; Manhattan. The standardized L^1 distance  
&quot;NB&quot; Weighted Naive-Bayes distance  
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>

<p>the distance to the template
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='summary.bootstrapValidation_Bin'>Generate a report of the results obtained using the bootstrapValidation_Bin function</h2><span id='topic+summary.bootstrapValidation_Bin'></span>

<h3>Description</h3>

<p>This function prints two tables describing the results of the bootstrap-based validation of binary classification models.
The first table reports the accuracy, sensitivity, specificity and area under the ROC curve (AUC) of the train and test data set, along with their confidence intervals.
The second table reports the model coefficients and their corresponding integrated discrimination improvement (IDI) and net reclassification improvement (NRI) values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'bootstrapValidation_Bin'
summary(object,
	        ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.bootstrapValidation_Bin_+3A_object">object</code></td>
<td>

<p>An object of class <code>bootstrapValidation_Bin</code>
</p>
</td></tr>
<tr><td><code id="summary.bootstrapValidation_Bin_+3A_...">...</code></td>
<td>

<p>Additional parameters for the generic <code>summary</code> function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>performance</code></td>
<td>

<p>A vector describing the results of the bootstrapping procedure
</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>

<p>An object of class <code>summary.lm</code>, <code>summary.glm</code>, or <code>summary.coxph</code> containing a summary of the analyzed model
</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>

<p>A matrix with the coefficients, IDI, NRI, and the 95% confidence intervals obtained via bootstrapping
</p>
</td></tr>
<tr><td><code>performance.table</code></td>
<td>

<p>A matrix with the tabulated results of the blind test accuracy, sensitivity, specificities, and area under the ROC curve
</p>
</td></tr>  
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+summaryReport">summaryReport</a></code></p>

<hr>
<h2 id='summary.fitFRESA'>Returns the summary of the fit</h2><span id='topic+summary'></span><span id='topic+summary.fitFRESA'></span>

<h3>Description</h3>

<p>Returns a summary of fitted model created by the modelFitting function with the fitFRESA parameter set to TRUE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'fitFRESA'
summary(object,
	type=c("Improvement","Residual"),
	ci=c(0.025,0.975),
	data=NULL,
	...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fitFRESA_+3A_object">object</code></td>
<td>

<p>fitted model with the <code>modelFitting</code> function
</p>
</td></tr>
<tr><td><code id="summary.fitFRESA_+3A_type">type</code></td>
<td>

<p>the type of coefficient estimation
</p>
</td></tr>
<tr><td><code id="summary.fitFRESA_+3A_ci">ci</code></td>
<td>

<p>lower and upper limit of the ci estimation
</p>
</td></tr>
<tr><td><code id="summary.fitFRESA_+3A_data">data</code></td>
<td>

<p>the data to be used for 95
</p>
</td></tr>
<tr><td><code id="summary.fitFRESA_+3A_...">...</code></td>
<td>

<p>parameters of the boostrap method
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the analysis results.
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+modelFitting">modelFitting</a></code>,<code><a href="#topic+bootstrapValidation_Bin">bootstrapValidation_Bin</a></code>,<code><a href="#topic+bootstrapValidation_Res">bootstrapValidation_Res</a></code></p>

<hr>
<h2 id='summaryReport'>Report the univariate analysis, the cross-validation analysis and the correlation analysis</h2><span id='topic+summaryReport'></span>

<h3>Description</h3>

<p>This function takes the variables of the cross-validation analysis and extracts the results from the univariate and correlation analyses.
Then, it prints the cross-validation results, the univariate analysis results, and the correlated variables.
As output, it returns a list of each one of these results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	summaryReport(univariateObject,
	              summaryBootstrap,
	              listOfCorrelatedVariables = NULL,
	              digits = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summaryReport_+3A_univariateobject">univariateObject</code></td>
<td>

<p>A data frame that contains the results of the <code>univariateRankVariables</code> function
</p>
</td></tr>
<tr><td><code id="summaryReport_+3A_summarybootstrap">summaryBootstrap</code></td>
<td>

<p>A list that contains the results of the <code>summary.bootstrapValidation_Bin</code> function
</p>
</td></tr>
<tr><td><code id="summaryReport_+3A_listofcorrelatedvariables">listOfCorrelatedVariables</code></td>
<td>

<p>A matrix that contains the <code>correlated.variables</code> value from the results obtained with the <code>listTopCorrelatedVariables</code> function
</p>
</td></tr>
<tr><td><code id="summaryReport_+3A_digits">digits</code></td>
<td>

<p>The number of significant digits to be used in the print function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>performance.table</code></td>
<td>

<p>A matrix with the tabulated results of the blind test accuracy, sensitivity, specificities, and area under the ROC curve
</p>
</td></tr>
<tr><td><code>coefStats</code></td>
<td>

<p>A data frame that lists all the model features along with its univariate statistics and bootstrapped coefficients
</p>
</td></tr>
<tr><td><code>cor.varibles</code></td>
<td>

<p>A matrix that lists all the features that are correlated to the model variables
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.bootstrapValidation_Bin">summary.bootstrapValidation_Bin</a></code></p>

<hr>
<h2 id='timeSerieAnalysis'>Fit the listed time series variables to a given model</h2><span id='topic+timeSerieAnalysis'></span>

<h3>Description</h3>

<p>This function plots the time evolution and does a longitudinal analysis of time dependent features. 
Features listed are fitted to the provided time model (mixed effect model) with a generalized least squares (GLS) procedure.
As output, it returns the coefficients, standard errors, <em>t</em>-values, and corresponding <em>p</em>-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	timeSerieAnalysis(variableList,
	                  baseModel,
	                  data,
	                  timevar = "time",
	                  contime = ".",
	                  Outcome = ".",
	                  ...,
	                  description = ".",
	                  Ptoshow = c(1),
	                  plegend = c("p"),
	                  timesign = "-",
	                  catgo.names = c("Control", "Case")
	                  )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timeSerieAnalysis_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_basemodel">baseModel</code></td>
<td>

<p>A string of the type &quot;1 + var1 + var2&quot; that defines the model to which variables will be fitted
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_timevar">timevar</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the visit ID
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_contime">contime</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the continuous time (e.g. days or months) that has elapsed since the baseline visit
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores an optional binary outcome that may be used to show the stratified analysis
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_description">description</code></td>
<td>

<p>The name of the column in <code>variableList</code> that stores the variable description
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_ptoshow">Ptoshow</code></td>
<td>

<p>Index of the <em>p</em>-values to be shown in the plot
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_plegend">plegend</code></td>
<td>

<p>Legend of the <em>p</em>-values to be shown in the plot
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_timesign">timesign</code></td>
<td>

<p>The direction of the arrow of time
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_catgo.names">catgo.names</code></td>
<td>

<p>The legends of the binary categories
</p>
</td></tr>
<tr><td><code id="timeSerieAnalysis_+3A_...">...</code></td>
<td>

<p>Additional parameters to be passed to the <code>gls</code> function
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will plot the evolution of the mean value of the listed variables with its corresponding error bars.
Then, it will fit the data to the provided time model with a GLS procedure and it will plot the fitted values. 
If a binary variable was provided, the plots will contain the case and control data.
As output, the function will return the model coefficients and their corresponding <em>t</em>-values, and the standard errors and their associated <em>p</em>-values.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>coef</code></td>
<td>

<p>A matrix with the coefficients of the GLS fitting
</p>
</td></tr>
<tr><td><code>std.Errors</code></td>
<td>

<p>A matrix with the standardized error of each coefficient
</p>
</td></tr>
<tr><td><code>t.values</code></td>
<td>

<p>A matrix with the <em>t</em>-value of each coefficient
</p>
</td></tr>
<tr><td><code>p.values</code></td>
<td>

<p>A matrix with the <em>p</em>-value of each coefficient
</p>
</td></tr>
<tr><td><code>sigmas</code></td>
<td>

<p>The root-mean-square error of the fitting
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>

<hr>
<h2 id='trajectoriesPolyFeatures'>Extract the per patient polynomial Coefficients of a feature trayectory</h2><span id='topic+trajectoriesPolyFeatures'></span>

<h3>Description</h3>

<p>Given a longituinal data set, it will extract the associated polynomial coefficients for each sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	trajectoriesPolyFeatures(data,
                              feature="v1", 
                              degree=2, 
                              time="t", 
                              group="ID",
                              timeOffset=0,
                              strata=NULL,
                              plot=TRUE,
                              ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trajectoriesPolyFeatures_+3A_data">data</code></td>
<td>

<p>The dataframe 
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_feature">feature</code></td>
<td>

<p>The name of the outcome
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_degree">degree</code></td>
<td>

<p>The fitting function used to model the data
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_time">time</code></td>
<td>

<p>The percentage of the data to be used for training
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_group">group</code></td>
<td>

<p>The number of times that the CV process will be repeated
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_timeoffset">timeOffset</code></td>
<td>

<p>The time offset
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_strata">strata</code></td>
<td>

<p>Data strafication
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_plot">plot</code></td>
<td>

<p>if TRUE it will plot the data
</p>
</td></tr>
<tr><td><code id="trajectoriesPolyFeatures_+3A_...">...</code></td>
<td>

<p>parameters passed to plot
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>coef</code></td>
<td>

<p>The trayaectory coefficient matrix
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>

<hr>
<h2 id='TUNED_SVM'>Tuned SVM</h2><span id='topic+TUNED_SVM'></span>

<h3>Description</h3>

<p>FRESA wrapper to fit grid-tuned <code> e1071::svm</code> object 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	TUNED_SVM(formula = formula,
	          data=NULL,
	          gamma = 10^(-5:-1),
	          cost = 10^(-3:1),
	          ...
	          )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TUNED_SVM_+3A_formula">formula</code></td>
<td>

<p>The base formula to extract the outcome
</p>
</td></tr>
<tr><td><code id="TUNED_SVM_+3A_data">data</code></td>
<td>

<p>The data to be used for training the method
</p>
</td></tr>
<tr><td><code id="TUNED_SVM_+3A_gamma">gamma</code></td>
<td>

<p>The vector of possible gamma values
</p>
</td></tr>
<tr><td><code id="TUNED_SVM_+3A_cost">cost</code></td>
<td>

<p>The vector of possible cost values 
</p>
</td></tr>
<tr><td><code id="TUNED_SVM_+3A_...">...</code></td>
<td>

<p>Parameters to be passed to the e1071::svm function
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fit</code></td>
<td>

<p>The <code>e1071::svm</code> fitted object
</p>
</td></tr>
<tr><td><code>tuneSVM</code></td>
<td>

<p>The <code>e1071::tune.svm</code> object
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code>e1071::svm</code></p>

<hr>
<h2 id='uniRankVar'>Univariate analysis of features (additional values returned)</h2><span id='topic+uniRankVar'></span>

<h3>Description</h3>

<p>This function reports the mean and standard deviation for each feature in a model, and ranks them according to a user-specified score.
Additionally, it does a Kolmogorov-Smirnov (KS) test on the raw and <em>z</em>-standardized data.
It also reports the raw and <em>z</em>-standardized <em>t</em>-test score, the <em>p</em>-value of the Wilcoxon rank-sum test, the integrated discrimination improvement (IDI), the net reclassification improvement (NRI), the net residual improvement (NeRI), and the area under the ROC curve (AUC).
Furthermore, it reports the <em>z</em>-value of the variable significance	on the fitted model.
Besides reporting an ordered data frame, this function returns all arguments as values, so that the results can be updates with the <code>update.uniRankVar</code> if needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	uniRankVar(variableList,
	           formula,
	           Outcome,
	           data,
	           categorizationType = c("Raw",
	                                   "Categorical",
	                                   "ZCategorical",
	                                   "RawZCategorical",
	                                   "RawTail",
	                                   "RawZTail",
	                                   "Tail",
	                                   "RawRaw"),
	           type = c("LOGIT", "LM", "COX"),
	           rankingTest = c("zIDI",
	                           "zNRI",
	                           "IDI",
	                           "NRI",
	                           "NeRI",
	                           "Ztest",
	                           "AUC",
	                           "CStat",
	                           "Kendall"),
	            cateGroups = c(0.1, 0.9),
	            raw.dataFrame = NULL,
	            testData = NULL,
	            description = ".",
	            uniType = c("Binary", "Regression"),
	            FullAnalysis=TRUE,
	            acovariates = NULL, 
	            timeOutcome = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="uniRankVar_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_formula">formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be fitted
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores an optional binary outcome that may be used to show the stratified analysis
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_categorizationtype">categorizationType</code></td>
<td>

<p>How variables will be analyzed : As given in <code>data</code> (&quot;Raw&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code> (&quot;Categorical&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code>, and weighted by the <em>z</em>-score (&quot;ZCategorical&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code>, weighted by the <em>z</em>-score, plus the raw values (&quot;RawZCategorical&quot;); raw values, plus the tails (&quot;RawTail&quot;); or raw values, weighted by the <em>z</em>-score, plus the tails (&quot;RawZTail&quot;)
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_rankingtest">rankingTest</code></td>
<td>

<p>Variables will be ranked based on: The <em>z</em>-score of the IDI (&quot;zIDI&quot;), the <em>z</em>-score of the NRI (&quot;zNRI&quot;), the IDI (&quot;IDI&quot;), the NRI (&quot;NRI&quot;), the NeRI (&quot;NeRI&quot;), the <em>z</em>-score of the model fit (&quot;Ztest&quot;), the AUC (&quot;AUC&quot;), the Somers' rank correlation (&quot;Cstat&quot;), or the Kendall rank correlation (&quot;Kendall&quot;)
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_categroups">cateGroups</code></td>
<td>

<p>A vector of percentiles to be used for the categorization procedure
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_raw.dataframe">raw.dataFrame</code></td>
<td>

<p>A data frame similar to <code>data</code>, but with unadjusted data, used to get the means and variances of the unadjusted data
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_testdata">testData</code></td>
<td>

<p>A data frame for model testing
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_description">description</code></td>
<td>

<p>The name of the column in <code>variableList</code> that stores the variable description
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_unitype">uniType</code></td>
<td>

<p>Type of univariate analysis: Binary classification (&quot;Binary&quot;) or regression (&quot;Regression&quot;)
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_fullanalysis">FullAnalysis</code></td>
<td>

<p>If FALSE it will only order the features according to its z-statistics of the linear model
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_acovariates">acovariates</code></td>
<td>

<p>the list of covariates
</p>
</td></tr>
<tr><td><code id="uniRankVar_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>the name of the Time to event feature
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will create valid dummy categorical variables if, and only if, <code>data</code> has been <em>z</em>-standardized.
The <em>p</em>-values provided in <code>cateGroups</code> will be converted to its corresponding <em>z</em>-score, which will then be used to create the categories.
If non <em>z</em>-standardized data were to be used, the categorization analysis would return wrong results.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>orderframe</code></td>
<td>

<p>A sorted list of model variables stored in a data frame 
</p>
</td></tr>
<tr><td><code>variableList</code></td>
<td>

<p>The argument <code>variableList</code>
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>The argument <code>formula</code>
</p>
</td></tr>
<tr><td><code>Outcome</code></td>
<td>

<p>The argument <code>Outcome</code>
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>The argument <code>data</code>
</p>
</td></tr>
<tr><td><code>categorizationType</code></td>
<td>

<p>The argument <code>categorizationType</code>
</p>
</td></tr>
<tr><td><code>type</code></td>
<td>

<p>The argument <code>type</code>
</p>
</td></tr>
<tr><td><code>rankingTest</code></td>
<td>

<p>The argument <code>rankingTest</code>
</p>
</td></tr>
<tr><td><code>cateGroups</code></td>
<td>

<p>The argument <code>cateGroups</code>
</p>
</td></tr>
<tr><td><code>raw.dataFrame</code></td>
<td>

<p>The argument <code>raw.dataFrame</code>
</p>
</td></tr>
<tr><td><code>description</code></td>
<td>

<p>The argument <code>description</code>
</p>
</td></tr>
<tr><td><code>uniType</code></td>
<td>

<p>The argument <code>uniType</code>
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>


<h3>See Also</h3>

<p><code><a href="#topic+update.uniRankVar">update.uniRankVar</a>, 
				 <a href="#topic+univariateRankVariables">univariateRankVariables</a></code></p>

<hr>
<h2 id='univariateRankVariables'>Univariate analysis of features</h2><span id='topic+univariateRankVariables'></span>

<h3>Description</h3>

<p>This function reports the mean and standard deviation for each feature in a model, and ranks them according to a user-specified score.
Additionally, it does a Kolmogorov-Smirnov (KS) test on the raw and <em>z</em>-standardized data.
It also reports the raw and <em>z</em>-standardized <em>t</em>-test score, the <em>p</em>-value of the Wilcoxon rank-sum test, the integrated discrimination improvement (IDI), the net reclassification improvement (NRI), the net residual improvement (NeRI), and the area under the ROC curve (AUC).
Furthermore, it reports the <em>z</em>-value of the variable significance	on the fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	univariateRankVariables(variableList,
	                        formula,
	                        Outcome,
	                        data, 
	                        categorizationType = c("Raw",
	                                               "Categorical",
	                                               "ZCategorical",
	                                               "RawZCategorical",
	                                               "RawTail",
	                                               "RawZTail",
	                                               "Tail",
	                                               "RawRaw"), 
	                        type = c("LOGIT", "LM", "COX"), 
	                        rankingTest = c("zIDI",
	                                        "zNRI",
	                                        "IDI",
	                                        "NRI",
	                                        "NeRI",
	                                        "Ztest",
	                                        "AUC",
	                                        "CStat",
	                                        "Kendall"), 
	                        cateGroups = c(0.1, 0.9),
	                        raw.dataFrame = NULL,
	                        description = ".",
	                        uniType = c("Binary","Regression"),
	                        FullAnalysis=TRUE,
	                        acovariates = NULL,
	                        timeOutcome = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="univariateRankVariables_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with the candidate variables to be ranked
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_formula">formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula to be fitted
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_categorizationtype">categorizationType</code></td>
<td>

<p>How variables will be analyzed: As given in <code>data</code> (&quot;Raw&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code> (&quot;Categorical&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code>, and weighted by the <em>z</em>-score (&quot;ZCategorical&quot;); broken into the <em>p</em>-value categories given by <code>cateGroups</code>, weighted by the <em>z</em>-score, plus the raw values (&quot;RawZCategorical&quot;); raw values, plus the tails (&quot;RawTail&quot;); or raw values, weighted by the <em>z</em>-score, plus the tails (&quot;RawZTail&quot;)
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_rankingtest">rankingTest</code></td>
<td>

<p>Variables will be ranked based on: The <em>z</em>-score of the IDI (&quot;zIDI&quot;), the <em>z</em>-score of the NRI (&quot;zNRI&quot;), the IDI (&quot;IDI&quot;), the NRI (&quot;NRI&quot;), the NeRI (&quot;NeRI&quot;), the <em>z</em>-score of the model fit (&quot;Ztest&quot;), the AUC (&quot;AUC&quot;), the Somers' rank correlation (&quot;Cstat&quot;), or the Kendall rank correlation (&quot;Kendall&quot;)
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_categroups">cateGroups</code></td>
<td>

<p>A vector of percentiles to be used for the categorization procedure
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_raw.dataframe">raw.dataFrame</code></td>
<td>

<p>A data frame similar to <code>data</code>, but with unadjusted data, used to get the means and variances of the unadjusted data
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_description">description</code></td>
<td>

<p>The name of the column in <code>variableList</code> that stores the variable description
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_unitype">uniType</code></td>
<td>

<p>Type of univariate analysis: Binary classification (&quot;Binary&quot;) or regression (&quot;Regression&quot;)
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_fullanalysis">FullAnalysis</code></td>
<td>

<p>If FALSE it will only order the features according to its z-statistics of the linear model
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_acovariates">acovariates</code></td>
<td>

<p>the list of covariates
</p>
</td></tr>
<tr><td><code id="univariateRankVariables_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>the name of the Time to event feature
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will create valid dummy categorical variables if, and only if, <code>data</code> has been <em>z</em>-standardized.
The <em>p</em>-values provided in <code>cateGroups</code> will be converted to its corresponding <em>z</em>-score, which will then be used to create the categories.
If non <em>z</em>-standardized data were to be used, the categorization analysis would return wrong results.
</p>


<h3>Value</h3>

<p>A sorted data frame.
In the case of a binary classification analysis, the data frame will have the following columns:
</p>
<table role = "presentation">
<tr><td><code>Name</code></td>
<td>

<p>Name of the raw variable or of the dummy variable if the data has been categorized
</p>
</td></tr>
<tr><td><code>parent</code></td>
<td>

<p>Name of the raw variable from which the dummy variable was created
</p>
</td></tr>
<tr><td><code>descrip</code></td>
<td>

<p>Description of the parent variable, as defined in <code>description</code>
</p>
</td></tr>
<tr><td><code>cohortMean</code></td>
<td>

<p>Mean value of the variable
</p>
</td></tr>
<tr><td><code>cohortStd</code></td>
<td>

<p>Standard deviation of the variable
</p>
</td></tr>
<tr><td><code>cohortKSD</code></td>
<td>

<p>D statistic of the KS test when comparing a normal distribution and the distribution of the variable
</p>
</td></tr>
<tr><td><code>cohortKSP</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>cohortKSD</code>
</p>
</td></tr>
<tr><td><code>caseMean</code></td>
<td>

<p>Mean value of cases (subjects with <code>Outcome</code> equal to 1)
</p>
</td></tr>
<tr><td><code>caseStd</code></td>
<td>

<p>Standard deviation of cases
</p>
</td></tr>
<tr><td><code>caseKSD</code></td>
<td>

<p>D statistic of the KS test when comparing a normal distribution and the distribution of the variable only for cases
</p>
</td></tr>
<tr><td><code>caseKSP</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>caseKSD</code>
</p>
</td></tr>
<tr><td><code>caseZKSD</code></td>
<td>

<p>D statistic of the KS test when comparing a normal distribution and the distribution of the <em>z</em>-standardized variable only for cases
</p>
</td></tr>
<tr><td><code>caseZKSP</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>caseZKSD</code>
</p>
</td></tr>
<tr><td><code>controlMean</code></td>
<td>

<p>Mean value of controls (subjects with <code>Outcome</code> equal to 0)
</p>
</td></tr>
<tr><td><code>controlStd</code></td>
<td>

<p>Standard deviation of controls
</p>
</td></tr>
<tr><td><code>controlKSD</code></td>
<td>

<p>D statistic of the KS test when comparing a normal distribution and the distribution of the variable only for controls
</p>
</td></tr>
<tr><td><code>controlKSP</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>controlsKSD</code>
</p>
</td></tr>
<tr><td><code>controlZKSD</code></td>
<td>

<p>D statistic of the KS test when comparing a normal distribution and the distribution of the <em>z</em>-standardized variable only for controls
</p>
</td></tr>
<tr><td><code>controlZKSP</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>controlsZKSD</code>
</p>
</td></tr>
<tr><td><code>t.Rawvalue</code></td>
<td>

<p>Normal inverse <em>p</em>-value (<em>z</em>-value) of the <em>t</em>-test performed on <code>raw.dataFrame</code>
</p>
</td></tr>
<tr><td><code>t.Zvalue</code></td>
<td>

<p><em>z</em>-value of the <em>t</em>-test performed on <code>data</code>
</p>
</td></tr>
<tr><td><code>wilcox.Zvalue</code></td>
<td>

<p><em>z</em>-value of the Wilcoxon rank-sum test performed on <code>data</code>
</p>
</td></tr>
<tr><td><code>ZGLM</code></td>
<td>

<p><em>z</em>-value returned by the <code>lm</code>, <code>glm</code>, or <code>coxph</code> functions for the <code>z</code>-standardized variable
</p>
</td></tr>
<tr><td><code>zNRI</code></td>
<td>

<p><em>z</em>-value returned by the <code>improveProb</code> function (<code>Hmisc</code> package) when evaluating the NRI
</p>
</td></tr>
<tr><td><code>zIDI</code></td>
<td>

<p><em>z</em>-value returned by the <code>improveProb</code> function (<code>Hmisc</code> package) when evaluating the IDI
</p>
</td></tr>
<tr><td><code>zNeRI</code></td>
<td>

<p><em>z</em>-value returned by the <code>improvedResiduals</code> function when evaluating the NeRI
</p>
</td></tr>
<tr><td><code>ROCAUC</code></td>
<td>

<p>Area under the ROC curve returned by the <code>roc</code> function (<code>pROC</code> package)
</p>
</td></tr>
<tr><td><code>cStatCorr</code></td>
<td>

<p><em>c</em> index of Somers' rank correlation returned by the <code>rcorr.cens</code> function (<code>Hmisc</code> package)
</p>
</td></tr>
<tr><td><code>NRI</code></td>
<td>

<p>NRI returned by the <code>improveProb</code> function (<code>Hmisc</code> package)
</p>
</td></tr>
<tr><td><code>IDI</code></td>
<td>

<p>IDI returned by the <code>improveProb</code> function (<code>Hmisc</code> package)
</p>
</td></tr>
<tr><td><code>NeRI</code></td>
<td>

<p>NeRI returned by the <code>improvedResiduals</code> function
</p>
</td></tr>
<tr><td><code>kendall.r</code></td>
<td>

<p>Kendall <code class="reqn">\tau</code> rank correlation coefficient between the variable and the binary outcome
</p>
</td></tr>
<tr><td><code>kendall.p</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>kendall.r</code>
</p>
</td></tr>
<tr><td><code>TstudentRes.p</code></td>
<td>

<p><em>p</em>-value of the improvement in residuals, as evaluated by the paired <em>t</em>-test
</p>
</td></tr>
<tr><td><code>WilcoxRes.p</code></td>
<td>

<p><em>p</em>-value of the improvement in residuals, as evaluated by the paired Wilcoxon rank-sum test
</p>
</td></tr>
<tr><td><code>FRes.p</code></td>
<td>

<p><em>p</em>-value of the improvement in residual variance, as evaluated by the <em>F</em>-test
</p>
</td></tr>
<tr><td><code>caseN_Z_Low_Tail</code></td>
<td>

<p>Number of cases in the low tail
</p>
</td></tr>
<tr><td><code>caseN_Z_Hi_Tail</code></td>
<td>

<p>Number of cases in the top tail
</p>
</td></tr>
<tr><td><code>controlN_Z_Low_Tail</code></td>
<td>

<p>Number of controls in the low tail
</p>
</td></tr>
<tr><td><code>controlN_Z_Hi_Tail</code></td>
<td>

<p>Number of controls in the top tail
</p>
</td></tr>
</table>
<p>In the case of regression analysis, the data frame will have the following columns:
</p>
<table role = "presentation">
<tr><td><code>Name</code></td>
<td>

<p>Name of the raw variable or of the dummy variable if the data has been categorized
</p>
</td></tr>
<tr><td><code>parent</code></td>
<td>

<p>Name of the raw variable from which the dummy variable was created
</p>
</td></tr>
<tr><td><code>descrip</code></td>
<td>

<p>Description of the parent variable, as defined in <code>description</code>
</p>
</td></tr>
<tr><td><code>cohortMean</code></td>
<td>

<p>Mean value of the variable
</p>
</td></tr>
<tr><td><code>cohortStd</code></td>
<td>

<p>Standard deviation of the variable
</p>
</td></tr>
<tr><td><code>cohortKSD</code></td>
<td>

<p>D statistic of the KS test when comparing a normal distribution and the distribution of the variable
</p>
</td></tr>
<tr><td><code>cohortKSP</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>cohortKSP</code>
</p>
</td></tr>
<tr><td><code>cohortZKSD</code></td>
<td>

<p>D statistic of the KS test when comparing a normal distribution and the distribution of the <em>z</em>-standardized variable
</p>
</td></tr>
<tr><td><code>cohortZKSP</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>cohortZKSD</code>
</p>
</td></tr>
<tr><td><code>ZGLM</code></td>
<td>

<p><em>z</em>-value returned by the glm or Cox procedure for the z-standardized variable
</p>
</td></tr>
<tr><td><code>zNRI</code></td>
<td>

<p><em>z</em>-value returned by the <code>improveProb</code> function (<code>Hmisc</code> package) when evaluating the NRI
</p>
</td></tr>
<tr><td><code>NeRI</code></td>
<td>

<p>NeRI returned by the <code>improvedResiduals</code> function
</p>
</td></tr>
<tr><td><code>cStatCorr</code></td>
<td>

<p><em>c</em> index of Somers' rank correlation returned by the <code>rcorr.cens</code> function (<code>Hmisc</code> package)
</p>
</td></tr>
<tr><td><code>spearman.r</code></td>
<td>

<p>Spearman <code class="reqn">\rho</code> rank correlation coefficient between the variable and the outcome
</p>
</td></tr>
<tr><td><code>pearson.r</code></td>
<td>

<p>Pearson <em>r</em> product-moment correlation coefficient between the variable and the outcome
</p>
</td></tr>
<tr><td><code>kendall.r</code></td>
<td>

<p>Kendall <code class="reqn">\tau</code> rank correlation coefficient between the variable and the outcome
</p>
</td></tr>
<tr><td><code>kendall.p</code></td>
<td>

<p>Associated <em>p</em>-value to the <code>kendall.r</code>
</p>
</td></tr>
<tr><td><code>TstudentRes.p</code></td>
<td>

<p><em>p</em>-value of the improvement in residuals, as evaluated by the paired <em>t</em>-test
</p>
</td></tr>
<tr><td><code>WilcoxRes.p</code></td>
<td>

<p><em>p</em>-value of the improvement in residuals, as evaluated by the paired Wilcoxon rank-sum test
</p>
</td></tr>
<tr><td><code>FRes.p</code></td>
<td>

<p><em>p</em>-value of the improvement in residual variance, as evaluated by the <em>F</em>-test
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>References</h3>

<p>Pencina, M. J., D'Agostino, R. B., &amp; Vasan, R. S. (2008). Evaluating the added predictive ability of a new marker: from area under the ROC curve to reclassification and beyond. <em>Statistics in medicine</em> <b>27</b>(2), 157-172.</p>

<hr>
<h2 id='update.uniRankVar'>Update the univariate analysis using new data</h2><span id='topic+update'></span><span id='topic+update.uniRankVar'></span>

<h3>Description</h3>

<p>This function updates the results from an univariate analysis using a new data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	## S3 method for class 'uniRankVar'
update(object,
	           ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update.uniRankVar_+3A_object">object</code></td>
<td>

<p>A list with the results from the <code>uniRankVar</code> function
</p>
</td></tr>
<tr><td><code id="update.uniRankVar_+3A_...">...</code></td>
<td>

<p>Additional parameters  to be passed to the <code>uniRankVar</code> function, used to update the univariate analysis
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the same format as the one yielded by the <code>uniRankVar</code> function
</p>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena</p>


<h3>See Also</h3>

<p><code><a href="#topic+uniRankVar">uniRankVar</a></code></p>

<hr>
<h2 id='updateModel.Bin'>Update the IDI/NRI-based model using new data or new threshold values</h2><span id='topic+updateModel.Bin'></span>

<h3>Description</h3>

<p>This function will take the frequency-ranked set of variables and will generate a new model with terms that meet either the integrated discrimination improvement (IDI), or the net reclassification improvement (NRI), threshold criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	updateModel.Bin(Outcome,
	            covariates = "1",
	            pvalue = c(0.025, 0.05),
	            VarFrequencyTable, 
	            variableList,
	            data,
	            type = c("LM", "LOGIT", "COX"), 
	            lastTopVariable = 0,
	            timeOutcome = "Time",
	            selectionType = c("zIDI","zNRI"),
	            maxTrainModelSize = 0,
	            zthrs = NULL
	            )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="updateModel.Bin_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_covariates">covariates</code></td>
<td>

<p>A string of the type &quot;1 + var1 + var2&quot; that defines which variables will always be included in the models (as covariates)
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to either IDI or NRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_varfrequencytable">VarFrequencyTable</code></td>
<td>

<p>An array with the ranked frequencies of the features, (e.g. the <code>ranked.var</code> value returned by the <code>ForwardSelection.Model.Bin</code> function)
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_lasttopvariable">lastTopVariable</code></td>
<td>

<p>The maximum number of variables to be tested
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event (needed only for a Cox proportional hazards regression model fitting)
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_selectiontype">selectionType</code></td>
<td>

<p>The type of index to be evaluated by the <code>improveProb</code> function (<code>Hmisc</code> package): <em>z</em>-score of IDI or of NRI
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the model
</p>
</td></tr>
<tr><td><code id="updateModel.Bin_+3A_zthrs">zthrs</code></td>
<td>

<p>The z-thresholds estimated in forward selection
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>final.model</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the final model
</p>
</td></tr>
<tr><td><code>var.names</code></td>
<td>

<p>A vector with the names of the features that were included in the final model
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the final model
</p>
</td></tr>
<tr><td><code>z.selectionType</code></td>
<td>

<p>A vector in which each term represents the <em>z</em>-score of the index defined in <code>selectionType</code> obtained with the Full model and the model without one term
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+updateModel.Res">updateModel.Res</a></code></p>

<hr>
<h2 id='updateModel.Res'>Update the NeRI-based model using new data or new threshold values</h2><span id='topic+updateModel.Res'></span>

<h3>Description</h3>

<p>This function will take the frequency-ranked set of variables and will generate a new model with terms that meet the net residual improvement (NeRI) threshold criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	updateModel.Res(Outcome, 
	                covariates = "1", 
	                pvalue = c(0.025, 0.05),
	                VarFrequencyTable, 
	                variableList, 
	                data, 
	                type = c("LM", "LOGIT", "COX"),
	                testType=c("Binomial", "Wilcox", "tStudent"), 
	                lastTopVariable = 0, 
	                timeOutcome = "Time",
	                maxTrainModelSize = -1,
	                p.thresholds = NULL
	                )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="updateModel.Res_+3A_outcome">Outcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the variable to be predicted by the model
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_covariates">covariates</code></td>
<td>

<p>A string of the type &quot;1 + var1 + var2&quot; that defines which variables will always be included in the models (as covariates)
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_pvalue">pvalue</code></td>
<td>

<p>The maximum <em>p</em>-value, associated to the NeRI, allowed for a term in the model
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_varfrequencytable">VarFrequencyTable</code></td>
<td>

<p>An array with the ranked frequencies of the features, (e.g. the <code>ranked.var</code> value returned by the <code>ForwardSelection.Model.Res</code> function)
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_variablelist">variableList</code></td>
<td>

<p>A data frame with two columns. The first one must have the names of the candidate variables and the other one the description of such variables
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_data">data</code></td>
<td>

<p>A data frame where all variables are stored in different columns
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_type">type</code></td>
<td>

<p>Fit type: Logistic (&quot;LOGIT&quot;), linear (&quot;LM&quot;), or Cox proportional hazards (&quot;COX&quot;)
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_testtype">testType</code></td>
<td>

<p>Type of non-parametric test to be evaluated by the <code>improvedResiduals</code> function: Binomial test (&quot;Binomial&quot;), Wilcoxon rank-sum test (&quot;Wilcox&quot;), Student's <em>t</em>-test (&quot;tStudent&quot;), or <em>F</em>-test (&quot;Ftest&quot;)
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_lasttopvariable">lastTopVariable</code></td>
<td>

<p>The maximum number of variables to be tested
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_timeoutcome">timeOutcome</code></td>
<td>

<p>The name of the column in <code>data</code> that stores the time to event (needed only for a Cox proportional hazards regression model fitting)
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_maxtrainmodelsize">maxTrainModelSize</code></td>
<td>

<p>Maximum number of terms that can be included in the model
</p>
</td></tr>
<tr><td><code id="updateModel.Res_+3A_p.thresholds">p.thresholds</code></td>
<td>

<p>The p.value thresholds estimated in forward selection
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>final.model</code></td>
<td>

<p>An object of class <code>lm</code>, <code>glm</code>, or <code>coxph</code> containing the final model
</p>
</td></tr>
<tr><td><code>var.names</code></td>
<td>

<p>A vector with the names of the features that were included in the final model
</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>

<p>An object of class <code>formula</code> with the formula used to fit the final model
</p>
</td></tr>
<tr><td><code>z.NeRI</code></td>
<td>

<p>A vector in which each element represents the <em>z</em>-score of the NeRI, associated to the <code>testType</code>, for each feature found in the final model
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jose G. Tamez-Pena and Antonio Martinez-Torteya</p>


<h3>See Also</h3>

<p><code><a href="#topic+updateModel.Bin">updateModel.Bin</a></code></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
