<!DOCTYPE html><html><head><title>Help for package AATtools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {AATtools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aat_bootstrap'><p>Compute bootstrapped approach-bias scores</p></a></li>
<li><a href='#aat_compute'><p>Compute simple AAT scores</p></a></li>
<li><a href='#aat_covreliability'><p>Compute a dataset's reliability from its covariance matrix</p></a></li>
<li><a href='#aat_simulate'><p>Simulate AAT datasets and predict parameters</p></a></li>
<li><a href='#aat_splithalf'><p>Compute the bootstrapped split-half reliability for approach-avoidance task data</p></a></li>
<li><a href='#aat_stimulus_rest'><p>Compute stimulus-rest correlations of double-difference scores</p>
This function provides a statistic that can give an indication of how deviant
the responses to specific stimuli are, in comparison to the rest of the stimulus set.
The algorithm computes stimulus-rest correlations of stimulus-specific double-difference scores.
It takes single-difference approach-avoidance scores for each stimulus, and computes
every possible subtraction between individual stimuli from both stimulus categories.
It then computes correlations between every such subtraction of stimuli on one hand, and
the mean double difference score of all other stimuli. Stimulus-rest correlations are then
computed by averaging every such subtraction-rest correlation involving a specific stimulus.</a></li>
<li><a href='#aat_stimulusscores'><p>Compute stimulus-specific bias scores</p>
Computes mean single-difference scores (push - pull) for each stimulus.</a></li>
<li><a href='#Algorithms'><p>AAT score computation algorithms</p></a></li>
<li><a href='#cormean'><p>Compute a minimally biased average of correlation values</p></a></li>
<li><a href='#correlation-tools'><p>Correlation tools</p></a></li>
<li><a href='#covEM'><p>Covariance matrix computation with multiple imputation</p></a></li>
<li><a href='#covrel'><p>Covariance Matrix-Based Reliability Coefficients</p></a></li>
<li><a href='#erotica'><p>AAT examining approach bias for erotic stimuli</p></a></li>
<li><a href='#multiple.cor'><p>Multiple correlation</p>
Computes the <a href="https://en.wikipedia.org/wiki/Multiple_correlation">multiple correlation coefficient</a>
of variables in <code>ymat</code> with the variable <code>x</code></a></li>
<li><a href='#partial.cor'><p>Partial correlation</p>
Compute the correlation between x and y while controlling for z.</a></li>
<li><a href='#Preprocessing'><p>Pre-processing rules</p></a></li>
<li><a href='#q_reliability'><p>Compute psychological experiment reliability</p></a></li>
<li><a href='#splitrel'><p>Split Half-Based Reliability Coefficients</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Reliability and Scoring Routines for the Approach-Avoidance Task</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Compute approach bias scores using different scoring algorithms,
    compute bootstrapped and exact split-half reliability estimates,
    and compute confidence intervals for individual participant scores.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>magrittr, dplyr, doParallel, foreach</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Spiritspeak/AATtools/issues">https://github.com/Spiritspeak/AATtools/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-12 13:12:35 UTC; b1066151</td>
</tr>
<tr>
<td>Author:</td>
<td>Sercan Kahveci [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sercan Kahveci &lt;sercan.kahveci@sbg.ac.at&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-12 13:40:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='aat_bootstrap'>Compute bootstrapped approach-bias scores</h2><span id='topic+aat_bootstrap'></span><span id='topic+print.aat_bootstrap'></span><span id='topic+plot.aat_bootstrap'></span>

<h3>Description</h3>

<p>Compute bootstrapped approach-bias scores with confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_bootstrap(
  ds,
  subjvar,
  pullvar,
  targetvar = NULL,
  rtvar,
  iters,
  algorithm = c("aat_doublemeandiff", "aat_doublemediandiff", "aat_dscore",
    "aat_dscore_multiblock", "aat_regression", "aat_standardregression",
    "aat_singlemeandiff", "aat_singlemediandiff"),
  trialdropfunc = c("prune_nothing", "trial_prune_3SD", "trial_prune_3MAD",
    "trial_prune_SD_dropcases", "trial_recode_SD", "trial_prune_percent_subject",
    "trial_prune_percent_sample", "trial_prune_grubbs"),
  errortrialfunc = c("prune_nothing", "error_replace_blockmeanplus",
    "error_prune_dropcases"),
  plot = TRUE,
  include.raw = FALSE,
  parallel = TRUE,
  ...
)

## S3 method for class 'aat_bootstrap'
print(x, ...)

## S3 method for class 'aat_bootstrap'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aat_bootstrap_+3A_ds">ds</code></td>
<td>
<p>a longformat data.frame</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_subjvar">subjvar</code></td>
<td>
<p>Quoted name of the participant identifier column</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_pullvar">pullvar</code></td>
<td>
<p>Quoted name of the column indicating pull trials.
Pull trials should either be represented by 1, or by the second level of a factor.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_targetvar">targetvar</code></td>
<td>
<p>Name of the column indicating trials featuring the target stimulus.
Target stimuli should either be represented by 1, or by the second level of a factor.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_rtvar">rtvar</code></td>
<td>
<p>Name of the reaction time column.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_iters">iters</code></td>
<td>
<p>Total number of desired iterations. At least 200 are required to get confidence intervals that make sense.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_algorithm">algorithm</code></td>
<td>
<p>Function (without brackets or quotes) to be used to compute AAT scores. See <a href="#topic+Algorithms">Algorithms</a> for a list of usable algorithms.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_trialdropfunc">trialdropfunc</code></td>
<td>
<p>Function (without brackets or quotes) to be used to exclude outlying trials in each half.
The way you handle outliers for the reliability computation should mimic the way you do it in your regular analyses.
It is recommended to exclude outlying trials when computing AAT scores using the mean double-dfference scores and regression scoring approaches,
but not when using d-scores or median double-difference scores.
</p>

<ul>
<li> <p><code>prune_nothing</code> excludes no trials (default)
</p>
</li>
<li> <p><code>trial_prune_grubbs</code> applies a Grubbs' test to the data, removing one outlier at a time until the test is no longer significant.
</p>
</li>
<li> <p><code>trial_prune_3SD</code> excludes trials deviating more than 3SD from the mean per participant.
</p>
</li>
<li> <p><code>trial_prune_SD_dropcases</code> removes trials deviating more than a specific number of standard deviations from the participant's mean,
and removes participants with an excessive percentage of outliers.
Required arguments:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than <code>trialsd</code> standard deviations from the participant's mean are excluded (optional; default is 3)
</p>
</li>
<li> <p><code>maxoutliers</code> - participants with a higher percentage of outliers are removed from the data. (optional; default is .15)
</p>
</li></ul>

</li>
<li> <p><code>trial_recode_SD</code> recodes outlying reaction times to the nearest non-outlying value,
with outliers defined as reaction times deviating more than a certain number of standard deviations from the participant's mean. Required argument:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than this many standard deviations from the mean are classified as outliers.
</p>
</li></ul>

</li>
<li> <p><code>trial_prune_percent_subject</code> and <code>trial_prune_percent_sample</code> remove trials below and/or above certain percentiles,
on a subject-by-subject basis or sample-wide, respectively. The following arguments are available:
</p>

<ul>
<li> <p><code>lowerpercent</code> and <code>uppperpercent</code> (optional; defaults are .01 and .99).
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_errortrialfunc">errortrialfunc</code></td>
<td>
<p>Function (without brackets or quotes) to apply to an error trial.
</p>

<ul>
<li> <p><code>prune_nothing</code> removes no errors (default).
</p>
</li>
<li> <p><code>error_replace_blockmeanplus</code> replaces error trial reaction times with the block mean, plus an arbitrary extra quantity.
If used, the following additional arguments are required:
</p>

<ul>
<li> <p><code>blockvar</code> - Quoted name of the block variable (mandatory)
</p>
</li>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>errorbonus</code> - Amount to add to the reaction time of error trials. Default is 0.6 (recommended by <code>Greenwald, Nosek, &amp; Banaji, 2003</code>)
</p>
</li></ul>

</li>
<li> <p><code>error_prune_dropcases</code> removes errors and drops participants if they have more errors than a given percentage. The following arguments are available:
</p>

<ul>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>maxerrors</code> - participants with a higher percentage of errors are excluded from the dataset. Default is .15.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_plot">plot</code></td>
<td>
<p>Plot the bias scores and their confidence intervals after computation is complete. This gives a good overview of the data.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_include.raw">include.raw</code></td>
<td>
<p>logical indicating whether raw split-half data should be included in the output object.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_parallel">parallel</code></td>
<td>
<p>If TRUE (default), will use parallel computing to compute results faster.
If a doParallel backend has not been registered beforehand,
this function will register a cluster and stop it after finishing, which takes some extra time.</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_...">...</code></td>
<td>
<p>Other arguments, to be passed on to the algorithm or outlier rejection functions (see arguments above)</p>
</td></tr>
<tr><td><code id="aat_bootstrap_+3A_x">x</code></td>
<td>
<p>An <code>aat_bootstrap</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, containing bootstrapped bias scores, their variance, bootstrapped 95 percent confidence intervals,
the number of iterations, and a matrix of bias scores for each iteration.
</p>


<h3>Author(s)</h3>

<p>Sercan Kahveci
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute 10 bootstrapped AAT scores.
boot&lt;-aat_bootstrap(ds=erotica[erotica$is_irrelevant==0,], subjvar="subject",
                    pullvar="is_pull", targetvar="is_target",rtvar="RT",
                    iters=10,algorithm="aat_doublemediandiff",
                    trialdropfunc="trial_prune_3SD",
                    plot=FALSE, parallel=FALSE)
plot(boot)
print(boot)

</code></pre>

<hr>
<h2 id='aat_compute'>Compute simple AAT scores</h2><span id='topic+aat_compute'></span>

<h3>Description</h3>

<p>Compute simple AAT scores, with optional outlier exclusion and error trial recoding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_compute(
  ds,
  subjvar,
  pullvar,
  targetvar = NULL,
  rtvar,
  algorithm = c("aat_doublemeandiff", "aat_doublemediandiff", "aat_dscore",
    "aat_dscore_multiblock", "aat_regression", "aat_standardregression",
    "aat_doublemeanquotient", "aat_doublemedianquotient", "aat_singlemeandiff",
    "aat_singlemediandiff"),
  trialdropfunc = c("prune_nothing", "trial_prune_3SD", "trial_prune_3MAD",
    "trial_prune_SD_dropcases", "trial_recode_SD", "trial_prune_percent_subject",
    "trial_prune_percent_sample", "trial_prune_grubbs"),
  errortrialfunc = c("prune_nothing", "error_replace_blockmeanplus",
    "error_prune_dropcases"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aat_compute_+3A_ds">ds</code></td>
<td>
<p>a long-format data.frame</p>
</td></tr>
<tr><td><code id="aat_compute_+3A_subjvar">subjvar</code></td>
<td>
<p>column name of subject variable</p>
</td></tr>
<tr><td><code id="aat_compute_+3A_pullvar">pullvar</code></td>
<td>
<p>column name of pull/push indicator variable, must be numeric or logical (where pull is 1 or TRUE)</p>
</td></tr>
<tr><td><code id="aat_compute_+3A_targetvar">targetvar</code></td>
<td>
<p>column name of target stimulus indicator, must be numeric or logical (where target is 1 or TRUE)</p>
</td></tr>
<tr><td><code id="aat_compute_+3A_rtvar">rtvar</code></td>
<td>
<p>column name of reaction time variable</p>
</td></tr>
<tr><td><code id="aat_compute_+3A_algorithm">algorithm</code></td>
<td>
<p>Function (without brackets or quotes) to be used to compute AAT scores. See <a href="#topic+Algorithms">Algorithms</a> for a list of usable algorithms.</p>
</td></tr>
<tr><td><code id="aat_compute_+3A_trialdropfunc">trialdropfunc</code></td>
<td>
<p>Function (without brackets or quotes) to be used to exclude outlying trials in each half.
The way you handle outliers for the reliability computation should mimic the way you do it in your regular analyses.
It is recommended to exclude outlying trials when computing AAT scores using the mean double-dfference scores and regression scoring approaches,
but not when using d-scores or median double-difference scores.
</p>

<ul>
<li> <p><code>prune_nothing</code> excludes no trials (default)
</p>
</li>
<li> <p><code>trial_prune_3SD</code> excludes trials deviating more than 3SD from the mean per participant.
</p>
</li>
<li> <p><code>trial_prune_grubbs</code> applies a Grubbs' test to the data, removing one outlier at a time until the test is no longer significant.
</p>
</li>
<li> <p><code>trial_prune_SD_dropcases</code> removes trials deviating more than a specific number of standard deviations from the participant's mean,
and removes participants with an excessive percentage of outliers.
Required arguments:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than <code>trialsd</code> standard deviations from the participant's mean are excluded (optional; default is 3)
</p>
</li>
<li> <p><code>maxoutliers</code> - participants with a higher percentage of outliers are removed from the data. (optional; default is .15)
</p>
</li></ul>

</li>
<li> <p><code>trial_recode_SD</code> recodes outlying reaction times to the nearest non-outlying value,
with outliers defined as reaction times deviating more than a certain number of standard deviations from the participant's mean. Required argument:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than this many standard deviations from the mean are classified as outliers.
</p>
</li></ul>

</li>
<li> <p><code>trial_prune_percent_subject</code> and <code>trial_prune_percent_sample</code> remove trials below and/or above certain percentiles,
on a subject-by-subject basis or sample-wide, respectively. The following arguments are available:
</p>

<ul>
<li> <p><code>lowerpercent</code> and <code>uppperpercent</code> (optional; defaults are .01 and .99).
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="aat_compute_+3A_errortrialfunc">errortrialfunc</code></td>
<td>
<p>Function (without brackets or quotes) to apply to an error trial.
</p>

<ul>
<li> <p><code>prune_nothing</code> removes no errors (default).
</p>
</li>
<li> <p><code>error_replace_blockmeanplus</code> replaces error trial reaction times with the block mean, plus an arbitrary extra quantity.
If used, the following additional arguments are required:
</p>

<ul>
<li> <p><code>blockvar</code> - Quoted name of the block variable (mandatory)
</p>
</li>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>errorbonus</code> - Amount to add to the reaction time of error trials. Default is 0.6 (recommended by <code>Greenwald, Nosek, &amp; Banaji, 2003</code>)
</p>
</li></ul>

</li>
<li> <p><code>error_prune_dropcases</code> removes errors and drops participants if they have more errors than a given percentage. The following arguments are available:
</p>

<ul>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>maxerrors</code> - participants with a higher percentage of errors are excluded from the dataset. Default is .15.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="aat_compute_+3A_...">...</code></td>
<td>
<p>Other arguments, to be passed on to the algorithm or outlier rejection functions (see arguments above)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>#Compute the correlation between relevant-feature and irrelevant-feature AAT scores
ds&lt;-erotica[erotica$correct==1,]
relevant &lt;- aat_compute(ds=ds[ds$is_irrelevant==0,],
                        pullvar="is_pull",targetvar="is_target",
                        rtvar="RT",subjvar="subject",
                        trialdropfunc="trial_prune_3SD",
                        algorithm="aat_doublemediandiff")

irrelevant &lt;- aat_compute(ds=ds[ds$is_irrelevant==1,],
                        pullvar="is_pull",targetvar="is_target",
                        rtvar="RT",subjvar="subject",
                        trialdropfunc="trial_prune_3SD",
                        algorithm="aat_doublemediandiff")

comparison.df &lt;- merge(relevant, irrelevant, by = "subject")
cor(comparison.df$ab.x, comparison.df$ab.y)
# 0.1145726
</code></pre>

<hr>
<h2 id='aat_covreliability'>Compute a dataset's reliability from its covariance matrix</h2><span id='topic+aat_covreliability'></span><span id='topic+print.aat_covreliability'></span><span id='topic+aat_covreliability_jackknife'></span><span id='topic+print.aat_covreliability_jackknife'></span><span id='topic+plot.aat_covreliability_jackknife'></span>

<h3>Description</h3>

<p>This function computes mean single-difference scores (push minus pull) for individual stimuli,
and computes the reliability from that information.
Missing values are dealt with using multiple imputation.
</p>
<p>This function computes the reliability when stimuli and participants are removed,
allowing for the diagnosis of potential sources of unreliability within the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_covreliability(
  ds,
  subjvar,
  stimvar,
  pullvar,
  targetvar = NULL,
  rtvar,
  aggfunc = c("mean", "median"),
  algorithm = c("calpha", "lambda2", "lambda4"),
  iters = 5
)

## S3 method for class 'aat_covreliability'
print(x, ...)

aat_covreliability_jackknife(
  ds,
  subjvar,
  stimvar,
  pullvar,
  targetvar = NULL,
  rtvar,
  algorithm = c("calpha", "lambda2", "lambda4"),
  iters = 5,
  holdout = c("both", "participant", "stimulus", "cross")
)

## S3 method for class 'aat_covreliability_jackknife'
print(x, ...)

## S3 method for class 'aat_covreliability_jackknife'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aat_covreliability_+3A_ds">ds</code></td>
<td>
<p>the <code>data.frame</code> to use</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_subjvar">subjvar</code></td>
<td>
<p>Name of the subject-identifying variable</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_stimvar">stimvar</code></td>
<td>
<p>Name of the stimulus-identifying variable</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_pullvar">pullvar</code></td>
<td>
<p>Name of the movement-direction identifying variable</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_targetvar">targetvar</code></td>
<td>
<p>Optional. Name of the stimulus-category identifying variable</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_rtvar">rtvar</code></td>
<td>
<p>Name of the reaction-time identifying variable</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_aggfunc">aggfunc</code></td>
<td>
<p>The function with which to aggregate the RTs before computing difference scores. Defaults to mean but can be changed to median.</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_algorithm">algorithm</code></td>
<td>
<p>The reliability formula to use. Defaults to Cronbach's alpha, but Guttman's Lambda-2 is recommended instead.</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_iters">iters</code></td>
<td>
<p>If there are missing values (which is almost inevitable) then
multiple imputation will be used to complete the covariance matrix - this option sets
the number of multiple imputations to be used.</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_x">x</code></td>
<td>
<p>Object to be printed</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_...">...</code></td>
<td>
<p>Ignored</p>
</td></tr>
<tr><td><code id="aat_covreliability_+3A_holdout">holdout</code></td>
<td>
<p>What should be removed from the data for computation of jackknife statistics?
&quot;both&quot; computes reliability when stimuli and participants are separately removed,
while &quot;cross&quot; computes  reliability when stimuli and participants are simultaneously removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When only one stimulus category is indicated, one of the commonly known reliability algorithms
provided with the <code>algorithm</code> argument is used.
When two stimulus categories are indicated, this function uses Lord's (1963) algorithm to
compute the reliability of a double mean difference score, using the algorithms in <code>algorithm</code>
to estimate the reliability of indiviau lstimulus categories.
</p>
<p>When one wants to compute the reliability of a double median difference score or D-score,
<code>aat_splithalf()</code> is recommended instead.
</p>


<h3>Value</h3>

<p>Returns an <code>aat_covreliability</code> object containing the reliability value
as well as the dataset and covariance matrix with replaced missing values. When
the argument <code>targetvar</code> is provided, the output also contains the reliability of the
individual stimulus categories and their intercorrelation.
</p>
<p><code>aat_covreliability_jackknife()</code> returns an <code>aat_covreliability_jackknife</code> object,
containing jackknife reliability statistics. If argument <code>holdout</code> was set to &quot;cross&quot;,
then these statistics are provided in a matrix where rows represent participants and columns represent stimuli.
Otherwise, they are provided in <code>data.frame</code>s where the stimulus or participant is represented in a column
alongside the associated reliability value.
</p>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>print(aat_covreliability)</code>: Print an <code>aat_covreliability</code> object
</p>
</li></ul>


<h3>Functions</h3>


<ul>
<li> <p><code>print(aat_covreliability_jackknife)</code>: Print an <code>aat_covreliability_jackknife</code> object
</p>
</li>
<li> <p><code>plot(aat_covreliability_jackknife)</code>: Plot an <code>aat_covreliability_jackknife</code> object
</p>
</li></ul>


<h3>References</h3>

<p>Lord, F.Y. (1963), &quot;Elementary Models for Measuring Change&quot;,
in Problems in Measuring Change, C.W. Harris, ed.. Madison. Wisconsin:
University of Wisconsin.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#We generate a dataset with 16 stimuli in each category
ds&lt;-aat_simulate(biasfx_jitter=40,nstims=16)
ds$stim&lt;-paste0(ds$stim,"-",ds$is_target)

# If Lord's formula and
# bootstrapped splithalf measure something similar,
# then the outcomes should be close to each other.
aat_covreliability(ds=ds,subjvar="subj",stimvar="stim",pullvar="is_pull",
                           targetvar="is_target",rtvar="rt")
aat_splithalf(ds=ds,subjvar="subj",pullvar="is_pull",targetvar="is_target",rtvar="rt",
              algorithm="aat_doublemeandiff",iters=100,plot=FALSE)

#Testing reliability for single-difference scores
ds&lt;-ds[ds$is_target==1,]
aat_covreliability(ds=ds,subjvar="subj",stimvar="stim",pullvar="is_pull",rtvar="rt")
hh&lt;-aat_simulate()
test&lt;-aat_covreliability_jackknife(ds=hh,subjvar="subj",stimvar="stim",pullvar="is_pull",
                                   targetvar="is_target",rtvar="rt",holdout="cross")
print(test)
plot(test)
</code></pre>

<hr>
<h2 id='aat_simulate'>Simulate AAT datasets and predict parameters</h2><span id='topic+aat_simulate'></span><span id='topic+aat_simulate2'></span><span id='topic+aat_getstudydata'></span>

<h3>Description</h3>

<p><code>aat_simulate()</code> generates approach-avoidance task datasets.
</p>
<p><code>aat_getstudydata()</code> retrieves the properties of datasets from a number of pre-existing studies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_simulate(
  npps = 36,
  nstims = 16,
  stimreps = 4,
  meanrt = 632,
  meanrt_jitter = 90.1,
  sdrt = 158,
  sdrt_jitter = 49.9,
  pullfx = -39.2,
  pullfx_jitter = 40.5,
  stimfx = -30.9,
  stimfx_jitter = 32.5,
  biasfx = 39,
  biasfx_jitter = 60.1,
  empirical = FALSE,
  ...
)

aat_simulate2(..., defaults = "none", slowols = 0, fastols = 0, olsd = 3)

aat_getstudydata()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aat_simulate_+3A_npps">npps</code></td>
<td>
<p>Number of participants</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_nstims">nstims</code></td>
<td>
<p>Number of stimuli</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_stimreps">stimreps</code></td>
<td>
<p>Number of repetitions of each stimulus within each group
(i.e. within approach target, avoid target, approach control, avoid control)</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_meanrt">meanrt</code></td>
<td>
<p>Mean sample reaction time</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_meanrt_jitter">meanrt_jitter</code></td>
<td>
<p>Extent by which participants' mean RTs
deviate from mean sample RT.</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_sdrt">sdrt</code></td>
<td>
<p>Standard deviation of samplewide RTs,
ignoring effects of movement, stimulus, and approach bias.
In essence, this represents the amount of pure noise present in the data.</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_sdrt_jitter">sdrt_jitter</code></td>
<td>
<p>Extent by which standard deviations of individual participants' RTs
are larger or smaller than the samplewide SD.</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_pullfx">pullfx</code></td>
<td>
<p>size of the effect of approach-versus-avoidance, in milliseconds</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_pullfx_jitter">pullfx_jitter</code></td>
<td>
<p>Individual variation in the effect of approach-versus-avoidance</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_stimfx">stimfx</code></td>
<td>
<p>size of the effect of stimulus category, in milliseconds</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_stimfx_jitter">stimfx_jitter</code></td>
<td>
<p>Individual variation in the effect of stimulus category</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_biasfx">biasfx</code></td>
<td>
<p>Size of the approach bias effect, in milliseconds</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_biasfx_jitter">biasfx_jitter</code></td>
<td>
<p>Individual variation in the approach bias effect</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_empirical">empirical</code></td>
<td>
<p>If TRUE, then effect sizes and standard deviations will be exact</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_...">...</code></td>
<td>
<p>Any parameters of <code>aat_simulate</code> provided here will override the defaults
from the defaults parameter.</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_defaults">defaults</code></td>
<td>
<p>Which set of default values should be used?</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_slowols">slowols</code></td>
<td>
<p>Number of slow outliers to insert per participant</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_fastols">fastols</code></td>
<td>
<p>Number of fats outliers to insert per participant</p>
</td></tr>
<tr><td><code id="aat_simulate_+3A_olsd">olsd</code></td>
<td>
<p>Number of standard deviations by which (slow) outliers deviate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Defaults of <code>aat_simulate()</code> are based on
Kahveci, Van Alebeek, Berking, &amp; Blechert (2021).
</p>
<p>&quot;Lender2018&quot; parameters are taken from the relevant-feature AAT of
Lender, Meule, Rinck, Brockmeyer, &amp; Blechert (2018). &quot;Kahveci2021&quot; parameters
are taken from Kahveci, Van Alebeek, Berking, &amp; Blechert (in review).
</p>
<p>Lender, A., Meule, A., Rinck, M., Brockmeyer, T., &amp; Blechert, J. (2018).
Measurement of food-related approachâ€“avoidance biases:
Larger biases when food stimuli are task relevant. Appetite, 125, 42-47.
</p>
<p>Kahveci, S., Van Alebeek, H., Berking, M., &amp; Blechert, J. (in review).
Touchscreen based assessment of food approach biases: investigation of
reliability and stimulus-specific effects.
</p>


<h3>Value</h3>

<p><code>aat_simulate()</code> returns a <code>data.frame</code> with the following columns:
subj (participant ID), stim (stimulus number), rep (stimulus repetition number),
is_pull (0 = avoid, 1 = approach), is_target (0 = control stimulus, 1 = target stimulus),
meanrt (participant's mean RT), sdrt (participant's residual standard deviation),
pullfx (participant approach-avoidance effect size in ms),
stimfx (participant stimulus category effect size in ms),
biasfx (participant approach bias effect size in ms),
and rt (trial reaction time).
Additionally, the data.frame has the attribute <code>population_reliability</code> which represents
the expected reliability of the data given the provided parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ts&lt;- aat_simulate(pullfx = 50, stimfx = 10, biasfx = 100)
mod&lt;-lm(rt~is_pull*is_target,data=ts)
coef(mod) #these should be somewhat close to the provided coefficients

# Here's how one might derive the parameters used in this function from a real dataset
## Not run: 
mod&lt;-lmer(decisiontime ~ is_pull * is_food + (is_pull * is_food | subjectid),data=dsa)
fixef(mod) # from here, all the fx and mean RTs are derived
ranef(mod)$subjectid %&gt;% apply(2,sd) #from here, all the fx jitters are derived
dsa %&gt;% group_by(subjectid) %&gt;% summarise(sd=sd(resid)) %&gt;%
summarise(m=mean(sd),s=sd(sd)) # from here, sdrt_jitter is derived

## End(Not run)
hist(aat_simulate2(defaults="Lender2018_relevant_raw",slowols=10,fastols=10)$rt)
</code></pre>

<hr>
<h2 id='aat_splithalf'>Compute the bootstrapped split-half reliability for approach-avoidance task data</h2><span id='topic+aat_splithalf'></span><span id='topic+print.aat_splithalf'></span><span id='topic+plot.aat_splithalf'></span>

<h3>Description</h3>

<p>Compute bootstrapped split-half reliability for approach-avoidance task data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_splithalf(
  ds,
  subjvar,
  pullvar,
  targetvar = NULL,
  rtvar,
  stratvars = NULL,
  iters,
  algorithm = c("aat_doublemeandiff", "aat_doublemediandiff", "aat_dscore",
    "aat_dscore_multiblock", "aat_regression", "aat_standardregression",
    "aat_singlemeandiff", "aat_singlemediandiff"),
  trialdropfunc = c("prune_nothing", "trial_prune_3SD", "trial_prune_3MAD",
    "trial_prune_SD_dropcases", "trial_recode_SD", "trial_prune_percent_subject",
    "trial_prune_percent_sample", "trial_prune_grubbs"),
  errortrialfunc = c("prune_nothing", "error_replace_blockmeanplus",
    "error_prune_dropcases"),
  casedropfunc = c("prune_nothing", "case_prune_3SD"),
  plot = TRUE,
  include.raw = FALSE,
  parallel = TRUE,
  ...
)

## S3 method for class 'aat_splithalf'
print(x, coef = c("SpearmanBrown", "Raju", "FlanaganRulon"), ...)

## S3 method for class 'aat_splithalf'
plot(x, type = c("median", "minimum", "maximum", "random"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aat_splithalf_+3A_ds">ds</code></td>
<td>
<p>a longformat data.frame</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_subjvar">subjvar</code></td>
<td>
<p>Quoted name of the participant identifier column</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_pullvar">pullvar</code></td>
<td>
<p>Quoted name of the column indicating pull trials.
Pull trials should either be represented by 1, or by the second level of a factor.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_targetvar">targetvar</code></td>
<td>
<p>Name of the column indicating trials featuring the target stimulus.
Target stimuli should either be represented by 1, or by the second level of a factor.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_rtvar">rtvar</code></td>
<td>
<p>Name of the reaction time column.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_stratvars">stratvars</code></td>
<td>
<p>Names of additional variables to stratify splits by.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_iters">iters</code></td>
<td>
<p>Total number of desired iterations. At least 6000 are recommended for reasonable estimates.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_algorithm">algorithm</code></td>
<td>
<p>Function (without brackets or quotes) to be used to compute AAT scores. See <a href="#topic+Algorithms">Algorithms</a> for a list of usable algorithms.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_trialdropfunc">trialdropfunc</code></td>
<td>
<p>Function (without brackets or quotes) to be used to exclude outlying trials in each half.
The way you handle outliers for the reliability computation should mimic the way you do it in your regular analyses.
It is recommended to exclude outlying trials when computing AAT scores using the mean double-dfference scores and regression scoring approaches,
but not when using d-scores or median double-difference scores.
</p>

<ul>
<li> <p><code>prune_nothing</code> excludes no trials (default)
</p>
</li>
<li> <p><code>trial_prune_grubbs</code> applies a Grubbs' test to the data, removing one outlier at a time until the test is no longer significant.
</p>
</li>
<li> <p><code>trial_prune_3SD</code> excludes trials deviating more than 3SD from the mean per participant.
</p>
</li>
<li> <p><code>trial_prune_SD_dropcases</code> removes trials deviating more than a specific number of standard deviations from the participant's mean,
and removes participants with an excessive percentage of outliers.
Required arguments:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than <code>trialsd</code> standard deviations from the participant's mean are excluded (optional; default is 3)
</p>
</li>
<li> <p><code>maxoutliers</code> - participants with a higher percentage of outliers are removed from the data. (optional; default is .15)
</p>
</li></ul>

</li>
<li> <p><code>trial_recode_SD</code> recodes outlying reaction times to the nearest non-outlying value,
with outliers defined as reaction times deviating more than a certain number of standard deviations from the participant's mean. Required argument:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than this many standard deviations from the mean are classified as outliers.
</p>
</li></ul>

</li>
<li> <p><code>trial_prune_percent_subject</code> and <code>trial_prune_percent_sample</code> remove trials below and/or above certain percentiles,
on a subject-by-subject basis or sample-wide, respectively. The following arguments are available:
</p>

<ul>
<li> <p><code>lowerpercent</code> and <code>uppperpercent</code> (optional; defaults are .01 and .99).
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_errortrialfunc">errortrialfunc</code></td>
<td>
<p>Function (without brackets or quotes) to apply to an error trial.
</p>

<ul>
<li> <p><code>prune_nothing</code> removes no errors (default).
</p>
</li>
<li> <p><code>error_replace_blockmeanplus</code> replaces error trial reaction times with the block mean, plus an arbitrary extra quantity.
If used, the following additional arguments are required:
</p>

<ul>
<li> <p><code>blockvar</code> - Quoted name of the block variable (mandatory)
</p>
</li>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>errorbonus</code> - Amount to add to the reaction time of error trials. Default is 0.6 (recommended by <code>Greenwald, Nosek, &amp; Banaji, 2003</code>)
</p>
</li></ul>

</li>
<li> <p><code>error_prune_dropcases</code> removes errors and drops participants if they have more errors than a given percentage. The following arguments are available:
</p>

<ul>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>maxerrors</code> - participants with a higher percentage of errors are excluded from the dataset. Default is .15.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_casedropfunc">casedropfunc</code></td>
<td>
<p>Function (without brackets or quotes) to be used to exclude outlying participant scores in each half.
The way you handle outliers here should mimic the way you do it in your regular analyses.
</p>

<ul>
<li> <p><code>prune_nothing</code> excludes no participants (default)
</p>
</li>
<li> <p><code>case_prune_3SD</code> excludes participants deviating more than 3SD from the sample mean.
</p>
</li></ul>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_plot">plot</code></td>
<td>
<p>Create a scatterplot of the AAT scores computed from each half of the data from the last iteration.
This is highly recommended, as it helps to identify outliers that can inflate or diminish the reliability.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_include.raw">include.raw</code></td>
<td>
<p>logical indicating whether raw split-half data should be included in the output object.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_parallel">parallel</code></td>
<td>
<p>If TRUE (default), will use parallel computing to compute results faster.
If a doParallel backend has not been registered beforehand,
this function will register a cluster and stop it after finishing, which takes some extra time.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_...">...</code></td>
<td>
<p>Other arguments, to be passed on to the algorithm or outlier rejection functions (see arguments above)</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_x">x</code></td>
<td>
<p>an <code>aat_splithalf</code> object</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_coef">coef</code></td>
<td>
<p>Optional character argument,
indicating which reliability coefficient should be printed.
Defaults to Raju's beta.</p>
</td></tr>
<tr><td><code id="aat_splithalf_+3A_type">type</code></td>
<td>
<p>Character argument indicating which iteration should be chosen. Must be an abbreviation of
<code>"median"</code> (default), <code>"minimum"</code>, <code>"maximum"</code>, or <code>"random"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculated split-half coefficients are described in Warrens (2016).
</p>


<h3>Value</h3>

<p>A list, containing the mean bootstrapped split-half reliability, bootstrapped 95
a list of data.frames used over each iteration, and a vector containing the split-half reliability of each iteration.
</p>


<h3>Author(s)</h3>

<p>Sercan Kahveci
</p>


<h3>References</h3>

<p>Warrens, M. J. (2016). A comparison of reliability coefficients for
psychometric tests that consist of two parts.
Advances in Data Analysis and Classification, 10(1), 71-84.
</p>


<h3>See Also</h3>

<p><a href="#topic+q_reliability">q_reliability</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>split &lt;- aat_splithalf(ds=erotica[erotica$is_irrelevant==0,],
                       subjvar="subject", pullvar="is_pull", targetvar="is_target",
                       rtvar="RT", stratvars="stimuluscode", iters=10,
                       trialdropfunc="trial_prune_3SD",
                       casedropfunc="case_prune_3SD", algorithm="aat_dscore",
                       plot=FALSE, parallel=FALSE)

print(split)
#Mean reliability: 0.521959
#Spearman-Brown-corrected r: 0.6859041
#95%CI: [0.4167018, 0.6172474]

plot(split)


#Regression Splithalf
aat_splithalf(ds=erotica[erotica$is_irrelevant==0,],
              subjvar="subject", pullvar="is_pull", targetvar="is_target",
              rtvar="RT", iters=10, trialdropfunc="trial_prune_3SD",
              casedropfunc="case_prune_3SD", algorithm="aat_regression",
              formula = RT ~ is_pull * is_target, aatterm = "is_pull:is_target",
              plot=FALSE, parallel=FALSE)
#Mean reliability: 0.5313939
#Spearman-Brown-corrected r: 0.6940003
#95%CI: [0.2687186, 0.6749176]

</code></pre>

<hr>
<h2 id='aat_stimulus_rest'>Compute stimulus-rest correlations of double-difference scores
This function provides a statistic that can give an indication of how deviant
the responses to specific stimuli are, in comparison to the rest of the stimulus set.
The algorithm computes stimulus-rest correlations of stimulus-specific double-difference scores.
It takes single-difference approach-avoidance scores for each stimulus, and computes
every possible subtraction between individual stimuli from both stimulus categories.
It then computes correlations between every such subtraction of stimuli on one hand, and
the mean double difference score of all other stimuli. Stimulus-rest correlations are then
computed by averaging every such subtraction-rest correlation involving a specific stimulus.</h2><span id='topic+aat_stimulus_rest'></span><span id='topic+plot.aat_stimulus_rest'></span>

<h3>Description</h3>

<p>Compute stimulus-rest correlations of double-difference scores
This function provides a statistic that can give an indication of how deviant
the responses to specific stimuli are, in comparison to the rest of the stimulus set.
The algorithm computes stimulus-rest correlations of stimulus-specific double-difference scores.
It takes single-difference approach-avoidance scores for each stimulus, and computes
every possible subtraction between individual stimuli from both stimulus categories.
It then computes correlations between every such subtraction of stimuli on one hand, and
the mean double difference score of all other stimuli. Stimulus-rest correlations are then
computed by averaging every such subtraction-rest correlation involving a specific stimulus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_stimulus_rest(
  ds,
  subjvar,
  stimvar,
  pullvar,
  targetvar,
  rtvar,
  method = c("pearson", "spearman", "kendall")
)

## S3 method for class 'aat_stimulus_rest'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aat_stimulus_rest_+3A_ds">ds</code></td>
<td>
<p>a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_subjvar">subjvar</code></td>
<td>
<p>the label of the participant identifier variable</p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_stimvar">stimvar</code></td>
<td>
<p>the label of the stimulus identifier variable</p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_pullvar">pullvar</code></td>
<td>
<p>the label of the movement direction identifier variable</p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_targetvar">targetvar</code></td>
<td>
<p>the label of the stimulus category identifier variable</p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_rtvar">rtvar</code></td>
<td>
<p>the label of the reaction time variable</p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_method">method</code></td>
<td>
<p>Optional, the correlation method to be used (pearson, spearman, kendall)</p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_x">x</code></td>
<td>
<p>an <code>aat_stimulus_rest</code> object</p>
</td></tr>
<tr><td><code id="aat_stimulus_rest_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>aat_stimulus_rest</code> object containing statistics for each stimulus.
Stats include the average stimulus-rest correlation (mcor); the standard deviation of
dyad-rest correlations for this stimulus (sdcor);
the number of valid correlations involved in these statistic (n);
the average percentile of dyad-rest correlations involving the stimulus within
the distribution of all other dyad-rest correlations (restpercentile);
as well as z-scores (zpercentile) and p-values for this percentile (pval).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ds&lt;-aat_simulate()
stimrest&lt;-aat_stimulus_rest(ds,subjvar="subj",stimvar="stim",pullvar="is_pull",
                     targetvar="is_target",rtvar="rt")
plot(stimrest)
print(stimrest)
</code></pre>

<hr>
<h2 id='aat_stimulusscores'>Compute stimulus-specific bias scores
Computes mean single-difference scores (push - pull) for each stimulus.</h2><span id='topic+aat_stimulusscores'></span>

<h3>Description</h3>

<p>Compute stimulus-specific bias scores
Computes mean single-difference scores (push - pull) for each stimulus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_stimulusscores(
  ds,
  subjvar,
  stimvar,
  pullvar,
  targetvar = NULL,
  rtvar,
  aggfunc = c("mean", "median"),
  iters = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aat_stimulusscores_+3A_ds">ds</code></td>
<td>
<p>the <code>data.frame</code> to use</p>
</td></tr>
<tr><td><code id="aat_stimulusscores_+3A_subjvar">subjvar</code></td>
<td>
<p>Name of the subject-identifying variable</p>
</td></tr>
<tr><td><code id="aat_stimulusscores_+3A_stimvar">stimvar</code></td>
<td>
<p>Name of the stimulus-identifying variable</p>
</td></tr>
<tr><td><code id="aat_stimulusscores_+3A_pullvar">pullvar</code></td>
<td>
<p>Name of the movement-direction identifying variable</p>
</td></tr>
<tr><td><code id="aat_stimulusscores_+3A_targetvar">targetvar</code></td>
<td>
<p>Optional. Name of the stimulus-category identifying variable</p>
</td></tr>
<tr><td><code id="aat_stimulusscores_+3A_rtvar">rtvar</code></td>
<td>
<p>Name of the reaction-time identifying variable</p>
</td></tr>
<tr><td><code id="aat_stimulusscores_+3A_aggfunc">aggfunc</code></td>
<td>
<p>The function with which to aggregate the RTs before computing difference scores. Defaults to mean but can be changed to median.</p>
</td></tr>
<tr><td><code id="aat_stimulusscores_+3A_iters">iters</code></td>
<td>
<p>If there are missing values (which is almost inevitable) then
multiple imputation will be used to complete the covariance matrix - this argument sets
the number of multiple imputations to be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Exports a <code>list</code> containing
a <code>data.frame</code> with stimulus-specific bias scores, indicated in the column names,
a covariance matrix of that same data, and
a <code>data.frame</code> indicating to which stimulus category each stimulus belongs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ds&lt;-aat_simulate(biasfx_jitter=40,nstims=16)
ds$stim&lt;-paste0(ds$stim,"-",ds$is_target)
aat_stimulusscores(ds,"subj","stim","is_pull","is_target","rt")
</code></pre>

<hr>
<h2 id='Algorithms'>AAT score computation algorithms</h2><span id='topic+Algorithms'></span><span id='topic+aat_doublemeandiff'></span><span id='topic+aat_doublemediandiff'></span><span id='topic+aat_dscore'></span><span id='topic+aat_mediandscore'></span><span id='topic+aat_dscore_multiblock'></span><span id='topic+aat_regression'></span><span id='topic+aat_standardregression'></span><span id='topic+aat_singlemeandiff'></span><span id='topic+aat_singlemediandiff'></span>

<h3>Description</h3>

<p>AAT score computation algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aat_doublemeandiff(ds, subjvar, pullvar, targetvar, rtvar, ...)

aat_doublemediandiff(ds, subjvar, pullvar, targetvar, rtvar, ...)

aat_dscore(ds, subjvar, pullvar, targetvar, rtvar, ...)

aat_mediandscore(ds, subjvar, pullvar, targetvar, rtvar, ...)

aat_dscore_multiblock(ds, subjvar, pullvar, targetvar, rtvar, blockvar, ...)

aat_regression(ds, subjvar, formula, aatterm, ...)

aat_standardregression(ds, subjvar, formula, aatterm, ...)

aat_singlemeandiff(ds, subjvar, pullvar, rtvar, ...)

aat_singlemediandiff(ds, subjvar, pullvar, rtvar, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Algorithms_+3A_ds">ds</code></td>
<td>
<p>A long-format data.frame</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_subjvar">subjvar</code></td>
<td>
<p>Column name of the participant identifier variable</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_pullvar">pullvar</code></td>
<td>
<p>Column name of the movement variable (0: avoid; 1: approach)</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_targetvar">targetvar</code></td>
<td>
<p>Column name of the stimulus category variable (0: control stimulus; 1: target stimulus)</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_rtvar">rtvar</code></td>
<td>
<p>Column name of the reaction time variable</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_...">...</code></td>
<td>
<p>Other arguments passed on by functions (ignored)</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_blockvar">blockvar</code></td>
<td>
<p>name of the variable indicating block number</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_formula">formula</code></td>
<td>
<p>A regression formula to fit to the data to compute an AAT score</p>
</td></tr>
<tr><td><code id="Algorithms_+3A_aatterm">aatterm</code></td>
<td>
<p>A character naming the formula term representing the approach bias.
Usually this is the interaction of the movement-direction and stimulus-category terms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame containing participant number and computed AAT score.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>aat_doublemeandiff()</code>: computes a mean-based double-difference score:
<code>(mean(push_target) - mean(pull_target)) - (mean(push_control) - mean(pull_control))</code>
</p>
</li>
<li> <p><code>aat_doublemediandiff()</code>: computes a median-based double-difference score:
<code>(median(push_target) - median(pull_target)) - (median(push_control) - median(pull_control))</code>
</p>
</li>
<li> <p><code>aat_dscore()</code>: computes D-scores for a 2-block design (see Greenwald, Nosek, and Banaji, 2003):
<code>((mean(push_target) - mean(pull_target)) - (mean(push_control) - mean(pull_control))) / sd(participant_reaction_times)</code>
</p>
</li>
<li> <p><code>aat_mediandscore()</code>: computes a double-difference score usign medians,
and divides it by the median absolute deviation of the participant's overall reaction times:
<code>((median(push_target) - median(pull_target)) - (median(push_control) - median(pull_control))) / mad(participant_reaction_times)</code>
</p>
</li>
<li> <p><code>aat_dscore_multiblock()</code>: computes D-scores for pairs of sequential blocks
and averages the resulting score (see Greenwald, Nosek, and Banaji, 2003).
Requires extra <code>blockvar</code> argument, indicating the name of the block variable.
</p>
</li>
<li> <p><code>aat_regression()</code>: <code>aat_regression</code> and <code>aat_standardregression</code> fit regression models to participants' reaction times and extract a term that serves as AAT score.
<code>aat_regression</code> extracts the raw coefficient, equivalent to a mean difference score.
<code>aat_standardregression</code> extracts the t-score of the coefficient, standardized on the basis of the variability of the participant's reaction times.
These algorithms can be used to regress nuisance variables out of the data before computing AAT scores.
When using these functions, additional arguments must be provided:
</p>

<ul>
<li> <p><code>formula</code> - a formula to fit to the data
</p>
</li>
<li> <p><code>aatterm</code> - the term within the formula that indicates the approach bias; this is usually the interaction of the pull and target terms.
</p>
</li></ul>

</li>
<li> <p><code>aat_standardregression()</code>: See above
</p>
</li>
<li> <p><code>aat_singlemeandiff()</code>: subtracts the mean approach reaction time from the mean avoidance reaction time.
Using this algorithm is only sensible if the supplied data contain a single stimulus category.
</p>
</li>
<li> <p><code>aat_singlemediandiff()</code>: subtracts the median approach reaction time from the median avoidance reaction time.
Using this algorithm is only sensible if the supplied data contain a single stimulus category.
</p>
</li></ul>

<hr>
<h2 id='cormean'>Compute a minimally biased average of correlation values</h2><span id='topic+cormean'></span>

<h3>Description</h3>

<p>This function computes a minimally biased average of correlation values.
This is needed because simple averaging of correlations is negatively biased,
and the often used z-transformation method of averaging correlations is positively biased.
The algorithm was developed by Olkin &amp; Pratt (1958).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cormean(
  r,
  n,
  wts = c("none", "n", "df"),
  type = c("OP5", "OPK", "OP2"),
  na.rm = F
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cormean_+3A_r">r</code></td>
<td>
<p>a vector containing correlation values</p>
</td></tr>
<tr><td><code id="cormean_+3A_n">n</code></td>
<td>
<p>a single value or vector containing sample sizes</p>
</td></tr>
<tr><td><code id="cormean_+3A_wts">wts</code></td>
<td>
<p>Character. How should the correlations be weighted?
<code>none</code> leads to no weighting, <code>n</code> weights by sample size, <code>df</code> weights by sample size minus one.</p>
</td></tr>
<tr><td><code id="cormean_+3A_type">type</code></td>
<td>
<p>Character. Determines which averaging algorithm to use, with &quot;OP5&quot; being the most accurate.</p>
</td></tr>
<tr><td><code id="cormean_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. Should missing values be removed?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An average correlation.
</p>


<h3>References</h3>

<p>Olkin, I., &amp; Pratt, J. (1958). Unbiased estimation of certain correlation coefficients.
The Annals of Mathematical Statistics, 29. https://doi.org/10.1214/aoms/1177706717
</p>
<p>Shieh, G. (2010). Estimation of the simple correlation coefficient. Behavior Research Methods,
42(4), 906-917. https://doi.org/10.3758/BRM.42.4.906
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cormean(c(0,.3,.5),c(30,30,60))
</code></pre>

<hr>
<h2 id='correlation-tools'>Correlation tools</h2><span id='topic+correlation-tools'></span><span id='topic+r2z'></span><span id='topic+z2r'></span><span id='topic+r2t'></span><span id='topic+r2p'></span><span id='topic+rconfint'></span><span id='topic+compcorr'></span>

<h3>Description</h3>

<p>Helper functions to compute important statistics from correlation coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r2z(r)

z2r(z)

r2t(r, n)

r2p(r, n)

rconfint(r, n, alpha = 0.05)

compcorr(r1, r2, n1, n2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correlation-tools_+3A_r">r</code>, <code id="correlation-tools_+3A_r1">r1</code>, <code id="correlation-tools_+3A_r2">r2</code></td>
<td>
<p>a correlation value</p>
</td></tr>
<tr><td><code id="correlation-tools_+3A_z">z</code></td>
<td>
<p>a Z-score</p>
</td></tr>
<tr><td><code id="correlation-tools_+3A_n">n</code>, <code id="correlation-tools_+3A_n1">n1</code>, <code id="correlation-tools_+3A_n2">n2</code></td>
<td>
<p>sample sizes</p>
</td></tr>
<tr><td><code id="correlation-tools_+3A_alpha">alpha</code></td>
<td>
<p>the significance level to use</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>r2z()</code>: converts correlation coefficients to z-scores
</p>
</li>
<li> <p><code>z2r()</code>: converts z-scores to correlation coefficients
</p>
</li>
<li> <p><code>r2t()</code>: Converts correlation coefficients to t-scores
</p>
</li>
<li> <p><code>r2p()</code>: Computes the two-sided p-value for a given correlation
</p>
</li>
<li> <p><code>rconfint()</code>: Computes confidence intervals for a given correlation coefficient
</p>
</li>
<li> <p><code>compcorr()</code>: computes the significance of the difference between two correlation coefficients
</p>
</li></ul>


<h3>See Also</h3>

<p><a href="#topic+cormean">cormean</a>, <a href="#topic+multiple.cor">multiple.cor</a>, <a href="#topic+partial.cor">partial.cor</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z &lt;- r2z(.5)
r &lt;- z2r(z)
t&lt;-r2t(r,30)
r2p(r,30)
print(rconfint(r,30))
print(compcorr(.5,.7,20,20))
</code></pre>

<hr>
<h2 id='covEM'>Covariance matrix computation with multiple imputation</h2><span id='topic+covEM'></span>

<h3>Description</h3>

<p>This function computes a covariance matrix from data with some values missing at random.
The code was written by Eric from StackExchange. https://stats.stackexchange.com/questions/182718/ml-covariance-estimation-from-expectation-maximization-with-missing-data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covEM(dat_missing, iters = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covEM_+3A_dat_missing">dat_missing</code></td>
<td>
<p>a matrix with missing values</p>
</td></tr>
<tr><td><code id="covEM_+3A_iters">iters</code></td>
<td>
<p>the number of iterations to perform to estimate missing values</p>
</td></tr>
</table>


<h3>References</h3>

<p>Beale, E. M. L., &amp; Little, R. J. A.. (1975). Missing Values in Multivariate Analysis. Journal of the Royal Statistical Society. Series B (methodological), 37(1), 129â€“145.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># make data with missing values
missing_mtcars &lt;- mtcars
for(i in 1:20){
  missing_mtcars[sample(1:nrow(mtcars),1),sample(1:ncol(mtcars),1)]&lt;-NA
}
covmat&lt;-covEM(as.matrix(missing_mtcars))$sigma
calpha(covmat)
</code></pre>

<hr>
<h2 id='covrel'>Covariance Matrix-Based Reliability Coefficients</h2><span id='topic+covrel'></span><span id='topic+calpha'></span><span id='topic+lambda2'></span><span id='topic+lambda4'></span>

<h3>Description</h3>

<p>These functions allow for the computation of the reliability of a dataset
from the covariance matrix of its variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calpha(covmat)

lambda2(covmat)

lambda4(covmat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covrel_+3A_covmat">covmat</code></td>
<td>
<p>a covariance matrix</p>
</td></tr>
</table>


<h3>Functions</h3>


<ul>
<li> <p><code>calpha()</code>: Cronbach's alpha
</p>
</li>
<li> <p><code>lambda2()</code>: Guttman's Lambda-2
</p>
</li>
<li> <p><code>lambda4()</code>: Guttman's Lambda-4. This algorithm tries to get the highest attainable reliability by
</p>
</li></ul>


<h3>See Also</h3>

<p><a href="#topic+splitrel">splitrel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># compute reliability from covariance
h&lt;-cov(iris[,1:4])
calpha(h)
lambda2(h)
lambda4(h)
# Lambda-2 and Lambda-4 are significantly larger because
# some of the variables in the iris dataset are negatively correlated.
</code></pre>

<hr>
<h2 id='erotica'>AAT examining approach bias for erotic stimuli</h2><span id='topic+erotica'></span>

<h3>Description</h3>

<p>AAT
</p>


<h3>Usage</h3>

<pre><code class='language-R'>erotica
</code></pre>


<h3>Format</h3>

<p>An object of class <code>"data.frame"</code>
</p>


<h3>Source</h3>

<p><a href="https://osf.io/6h2rj/">osf.io repository</a>
</p>


<h3>References</h3>

<p>Kahveci, S., Van Bockstaele, B.D., &amp; Wiers, R.W. (in preparation).
Pulling for Pleasure? Erotic Approach-Bias Associated With Porn Use, Not Problems. DOI:10.17605/OSF.IO/6H2RJ
</p>

<hr>
<h2 id='multiple.cor'>Multiple correlation
Computes the <a href="https://en.wikipedia.org/wiki/Multiple_correlation">multiple correlation coefficient</a>
of variables in <code>ymat</code> with the variable <code>x</code></h2><span id='topic+multiple.cor'></span>

<h3>Description</h3>

<p>Multiple correlation
Computes the <a href="https://en.wikipedia.org/wiki/Multiple_correlation">multiple correlation coefficient</a>
of variables in <code>ymat</code> with the variable <code>x</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiple.cor(x, ymat, use = "everything")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiple.cor_+3A_x">x</code></td>
<td>
<p>Either a matrix of variables whose multiple correlation with each other is to be estimated; or a vector of which the multiple correlation with variables in <code>ymat</code> is to be estimated</p>
</td></tr>
<tr><td><code id="multiple.cor_+3A_ymat">ymat</code></td>
<td>
<p>a matrix or data.frame of variables of which the multiple correlation with <code>x</code> is to be estimated</p>
</td></tr>
<tr><td><code id="multiple.cor_+3A_use">use</code></td>
<td>
<p>optional character indicating how to handle missing values (see <a href="stats.html#topic+cor">cor</a>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The multiple correlation coefficient
</p>


<h3>See Also</h3>

<p>https://www.personality-project.org/r/book/chapter5.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'>multiple.cor(mtcars[,1],mtcars[,2:4])
</code></pre>

<hr>
<h2 id='partial.cor'>Partial correlation
Compute the correlation between x and y while controlling for z.</h2><span id='topic+partial.cor'></span>

<h3>Description</h3>

<p>Partial correlation
Compute the correlation between x and y while controlling for z.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partial.cor(x, y, z, use = c("complete.obs", "everything"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partial.cor_+3A_x">x</code>, <code id="partial.cor_+3A_y">y</code>, <code id="partial.cor_+3A_z">z</code></td>
<td>
<p>x and y will be correlated while controlling for z</p>
</td></tr>
<tr><td><code id="partial.cor_+3A_use">use</code></td>
<td>
<p>optional character indicating how to handle missing values (see <a href="stats.html#topic+cor">cor</a>)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>partial.cor(mtcars$mpg,mtcars$cyl,mtcars$disp)
</code></pre>

<hr>
<h2 id='Preprocessing'>Pre-processing rules</h2><span id='topic+Preprocessing'></span><span id='topic+prune_nothing'></span><span id='topic+trial_prune_percent_subject'></span><span id='topic+trial_prune_percent_sample'></span><span id='topic+trial_prune_3SD'></span><span id='topic+trial_prune_3MAD'></span><span id='topic+trial_prune_SD_dropcases'></span><span id='topic+trial_recode_SD'></span><span id='topic+trial_prune_grubbs'></span><span id='topic+case_prune_3SD'></span><span id='topic+error_replace_blockmeanplus'></span><span id='topic+error_prune_dropcases'></span>

<h3>Description</h3>

<p>These are pre-processing rules that can be used in <a href="#topic+aat_splithalf">aat_splithalf</a>, <a href="#topic+aat_bootstrap">aat_bootstrap</a>, and <a href="#topic+aat_compute">aat_compute</a>.
</p>

<ul>
<li><p> The following rules are to be used for the <code>trialdropfunc</code> argument.
The way you handle outliers for the reliability computation and bootstrapping more broadly
should mimic the way you do it in your regular analyses.
It is recommended to exclude outlying trials when computing AAT scores using the mean double-dfference scores and regression scoring approaches,
but not when using d-scores or median double-difference scores.
</p>

<ul>
<li> <p><code>prune_nothing</code> excludes no trials (default)
</p>
</li>
<li> <p><code>trial_prune_3SD</code> excludes trials deviating more than 3SD from the mean per participant.
</p>
</li>
<li> <p><code>trial_prune_3MAD</code> excludes trials deviating more than 3 median absolute deviations from the median per participant.
</p>
</li>
<li> <p><code>trial_prune_grubbs</code> applies a Grubbs' test to the data, removing one outlier at a time until the test is no longer significant.
</p>
</li>
<li> <p><code>trial_prune_SD_dropcases</code> removes trials deviating more than a specific number of standard deviations from the participant's mean,
and removes participants with an excessive percentage of outliers.
Required arguments:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than <code>trialsd</code> standard deviations from the participant's mean are excluded (optional; default is 3)
</p>
</li>
<li> <p><code>maxoutliers</code> - participants with a higher percentage of outliers are removed from the data. (optional; default is .15)
</p>
</li></ul>

</li>
<li> <p><code>trial_recode_SD</code> recodes outlying reaction times to the nearest non-outlying value,
with outliers defined as reaction times deviating more than a certain number of standard deviations from the participant's mean. Required argument:
</p>

<ul>
<li> <p><code>trialsd</code> - trials deviating more than this many standard deviations from the mean are classified as outliers.
</p>
</li></ul>

</li>
<li> <p><code>trial_prune_percent_subject</code> and <code>trial_prune_percent_sample</code> remove trials below and/or above certain percentiles,
on a subject-by-subject basis or sample-wide, respectively. The following arguments are available:
</p>

<ul>
<li> <p><code>lowerpercent</code> and <code>uppperpercent</code> (optional; defaults are .01 and .99).
</p>
</li></ul>

</li></ul>

</li>
<li><p> The following pre-procesing rules are to be used for the <code>errortrialfunc</code> argument.
They determine what is to be done with errors - remove or recode?
</p>

<ul>
<li> <p><code>prune_nothing</code> removes no errors (default).
</p>
</li>
<li> <p><code>error_replace_blockmeanplus</code> replaces error trial reaction times with the block mean, plus an arbitrary extra quantity.
If used, the following additional arguments are required:
</p>

<ul>
<li> <p><code>blockvar</code> - Quoted name of the block variable (mandatory)
</p>
</li>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>errorbonus</code> - Amount to add to the reaction time of error trials. Default is 0.6 (recommended by <code>Greenwald, Nosek, &amp; Banaji, 2003</code>)
</p>
</li></ul>

</li>
<li> <p><code>error_prune_dropcases</code> removes errors and drops participants if they have more errors than a given percentage. The following arguments are available:
</p>

<ul>
<li> <p><code>errorvar</code> - Quoted name of the error variable, where errors are 1 or TRUE and correct trials are 0 or FALSE (mandatory)
</p>
</li>
<li> <p><code>maxerrors</code> - participants with a higher percentage of errors are excluded from the dataset. Default is .15.
</p>
</li></ul>

</li></ul>

</li>
<li><p> These are pre-processing rules to be used for the <code>casedropfunc</code> argument.
The way you handle outliers here should mimic the way you do it in your regular analyses.
</p>

<ul>
<li> <p><code>prune_nothing</code> excludes no participants (default)
</p>
</li>
<li> <p><code>case_prune_3SD</code> excludes participants deviating more than 3SD from the sample mean.
</p>
</li></ul>

</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>prune_nothing(ds, ...)

trial_prune_percent_subject(
  ds,
  subjvar,
  rtvar,
  lowerpercent = 0.01,
  upperpercent = 0.99,
  ...
)

trial_prune_percent_sample(
  ds,
  rtvar,
  lowerpercent = 0.01,
  upperpercent = 0.99,
  ...
)

trial_prune_3SD(ds, subjvar, rtvar, ...)

trial_prune_3MAD(ds, subjvar, rtvar, ...)

trial_prune_SD_dropcases(
  ds,
  subjvar,
  rtvar,
  trialsd = 3,
  maxoutliers = 0.15,
  ...
)

trial_recode_SD(ds, subjvar, rtvar, trialsd = 3, ...)

trial_prune_grubbs(ds, subjvar, rtvar, ...)

case_prune_3SD(ds, ...)

error_replace_blockmeanplus(
  ds,
  subjvar,
  rtvar,
  blockvar,
  errorvar,
  errorbonus,
  ...
)

error_prune_dropcases(ds, subjvar, errorvar, maxerrors = 0.15, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Preprocessing_+3A_ds">ds</code></td>
<td>
<p>A data.frame.</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_...">...</code></td>
<td>
<p>Other arguments (ignored).</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_subjvar">subjvar</code></td>
<td>
<p>The name of the subject variable.</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_rtvar">rtvar</code></td>
<td>
<p>The name of the reaction time variable.</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_lowerpercent">lowerpercent</code>, <code id="Preprocessing_+3A_upperpercent">upperpercent</code></td>
<td>
<p>for <code>trial_prune_percent_subject</code> and <code>trial_prune_percent_sample</code>,
the lower and upper proportions beyond which trials are considered outliers and removed (defaults to .01 and .99).</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_trialsd">trialsd</code></td>
<td>
<p>The amount of deviation from the participant mean (in SD) after which a trial is considered an outlier and excluded (defaults to 3).</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_maxoutliers">maxoutliers</code></td>
<td>
<p>for <code>trial_prune_SD_dropcases</code>, the maximum percentage of outliers, after which a participant is excluded from the data.</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_blockvar">blockvar</code></td>
<td>
<p>The name of the block variable.</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_errorvar">errorvar</code></td>
<td>
<p>The name of the error variable.</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_errorbonus">errorbonus</code></td>
<td>
<p>for <code>error_replace_blockmeanplus</code>, the amount of seconds to add to the block mean
and use as a replacement for error trial reaction times (default is 0.6).</p>
</td></tr>
<tr><td><code id="Preprocessing_+3A_maxerrors">maxerrors</code></td>
<td>
<p>for <code>error_prune_dropcases</code>, the maximum percentage of errors, after which a participant is excluded from the data.</p>
</td></tr>
</table>

<hr>
<h2 id='q_reliability'>Compute psychological experiment reliability</h2><span id='topic+q_reliability'></span><span id='topic+q_reliability2'></span><span id='topic+print.qreliability'></span><span id='topic+plot.qreliability'></span>

<h3>Description</h3>

<p>This function can be used to compute an exact reliability score for a psychological task whose results involve a difference score.
The resulting intraclass correlation coefficient is equivalent to the average all possible split-half reliability scores.
It ranges from -1 to 1, with -1 implying that all variance in the data is explained by within-subjects variability,
1 implying that all variance is explained by between-subjects variability,
and 0 implying that within-subjects and between-subjects variability contribute equally to the total variance in the sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>q_reliability(ds, subjvar, formula, aatterm = NA)

q_reliability2(ds, subjvar, splitvars, rtvar, dscore = F, na.rm = F)

## S3 method for class 'qreliability'
print(x, ...)

## S3 method for class 'qreliability'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="q_reliability_+3A_ds">ds</code></td>
<td>
<p>a long-format data.frame</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_subjvar">subjvar</code></td>
<td>
<p>name of the subject variable</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_formula">formula</code></td>
<td>
<p>a formula predicting the participant's reaction time using trial-level variables such as movement direction and stimulus category</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_aatterm">aatterm</code></td>
<td>
<p>a string denoting the term in the formula that contains the participant's approach bias</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_splitvars">splitvars</code></td>
<td>
<p>Vector of column names over which to split the data
to compute difference scores. This can be used to compute the
reliability of single, double, or even triple difference scores.</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_rtvar">rtvar</code></td>
<td>
<p>Column name of the variable containing reaction times</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_dscore">dscore</code></td>
<td>
<p>If true, reliability will be computed for a difference score
that is divided by the subject's standard deviation (as in D-scores)</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_na.rm">na.rm</code></td>
<td>
<p>If true, remove rows with missing values from the data</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_x">x</code></td>
<td>
<p>a <code>qreliability</code> object</p>
</td></tr>
<tr><td><code id="q_reliability_+3A_...">...</code></td>
<td>
<p>Other arguments passed to the generic <code>print</code> and <code>plot</code> functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a qreliability object, containing the reliability coefficient,
and a data.frame with participants' bias scores and score variance.
</p>
<p>Please note that the valence of the bias scores may or may not correspond with
approach and avoidance. If you plan to use these scores in your analyses,
always verify that they are in the right direction by correlating them with
independently calculated bias scores, for example using <code>aat_compute()</code>.
</p>


<h3>Author(s)</h3>

<p>Sercan Kahveci
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Double-difference score reliability
q_reliability(ds=erotica,subjvar="subject",
              formula= RT ~ is_pull * is_target, aatterm = "is_pull:is_target")

# Single-difference reliability for target stimuli
q_reliability(ds=erotica[erotica$is_target ==1,],subjvar="subject",
              formula= RT ~ is_pull, aatterm = "is_pull")

# Reliability of the mean reaction time of approaching target stimuli (no difference score)
q_reliability(ds=erotica[erotica$is_target ==1 &amp; erotica$is_pull ==1,],subjvar="subject",
              formula= RT ~ 1, aatterm = "1")

q_reliability2(ds=erotica,subjvar="subject",
              splitvars=c("is_pull", "is_target"),rtvar="RT")
</code></pre>

<hr>
<h2 id='splitrel'>Split Half-Based Reliability Coefficients</h2><span id='topic+splitrel'></span><span id='topic+SpearmanBrown'></span><span id='topic+FlanaganRulon'></span><span id='topic+RajuCoefficient'></span>

<h3>Description</h3>

<p>Split Half-Based Reliability Coefficients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpearmanBrown(
  corr,
  ntests = 2,
  fix.negative = c("none", "nullify", "bilateral")
)

FlanaganRulon(x1, x2, fix.negative = c("none", "nullify", "bilateral"))

RajuCoefficient(x1, x2, prop, fix.negative = c("none", "nullify", "bilateral"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitrel_+3A_corr">corr</code></td>
<td>
<p>To-be-corrected correlation coefficient</p>
</td></tr>
<tr><td><code id="splitrel_+3A_ntests">ntests</code></td>
<td>
<p>An integer indicating how many times larger the full test is, for which the corrected correlation coefficient is being computed.
When <code>ntests=2</code>, the formula will compute what the correlation coefficient would be if the test were twice as long.</p>
</td></tr>
<tr><td><code id="splitrel_+3A_fix.negative">fix.negative</code></td>
<td>
<p>Determines how to deal with a negative value. &quot;nullify&quot; sets it to zero,
&quot;bilateral&quot; applies the correction as if it were a positive number, and then sets it to negative.
&quot;none&quot; gives the raw value. It should be noted that negative values are not supposed to occur,
and there is no commonly accepted way to deal with them when they do occur.</p>
</td></tr>
<tr><td><code id="splitrel_+3A_x1">x1</code></td>
<td>
<p>scores from half 1</p>
</td></tr>
<tr><td><code id="splitrel_+3A_x2">x2</code></td>
<td>
<p>scores from half 2</p>
</td></tr>
<tr><td><code id="splitrel_+3A_prop">prop</code></td>
<td>
<p>Proportion of the first half to the complete sample</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Spearman-Brown-corrected correlation coefficient.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>SpearmanBrown()</code>: Perform a Spearman-Brown correction on the provided correlation score.
</p>
</li>
<li> <p><code>FlanaganRulon()</code>: Compute the true reliability using the Flanagan-Rulon formula,
which takes into account inequal variances between split halves.
</p>
</li>
<li> <p><code>RajuCoefficient()</code>: Compute split-half reliability using the Raju formula,
which takes into account unequal split-halves and variances.
</p>
</li></ul>


<h3>See Also</h3>

<p><a href="#topic+covrel">covrel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
SpearmanBrown(.5)
FlanaganRulon(a&lt;-rnorm(50),rnorm(50)+a*.5,fix.negative="bilateral")
a&lt;-rnorm(50)
b&lt;-rnorm(50)+a*.5
RajuCoefficient(a,b,prop=.4,fix.negative="bilateral")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
