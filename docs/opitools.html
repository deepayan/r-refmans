<!DOCTYPE html><html><head><title>Help for package opitools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {opitools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#covid_theme'><p>keywords relating to COVID-19 pandemics</p></a></li>
<li><a href='#debate_dtd'><p>Comments on a video of a political debate.</p></a></li>
<li><a href='#opi_impact'><p>Statistical assessment of</p>
impacts of a specified theme from a DTD.</a></li>
<li><a href='#opi_score'><p>Opinion score of a digital text document (DTD)</p></a></li>
<li><a href='#opi_sim'><p>Simulates the opinion expectation distribution</p>
of a digital text document.</a></li>
<li><a href='#osd_data'><p>Observed sentiment document (OSD).</p></a></li>
<li><a href='#policing_dtd'><p>Twitter posts on police/policing</p></a></li>
<li><a href='#refreshment_theme'><p>Keywords relating to facilities at train stations</p></a></li>
<li><a href='#reviews_dtd'><p>Customer reviews from tripadvisor website</p></a></li>
<li><a href='#signage_theme'><p>Keywords relating to signages at train stations</p></a></li>
<li><a href='#tweets'><p>Fake Twitter posts on police/policing 2</p></a></li>
<li><a href='#word_distrib'><p>Words Distribution</p></a></li>
<li><a href='#word_imp'><p>Importance of words (terms) embedded</p>
in a text document</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyzing the Opinions in a Big Text Document</td>
</tr>
<tr>
<td>Version:</td>
<td>1.8.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Monsuru Adepeju [cre, aut],</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Monsuru Adepeju &lt;monsuur2010@yahoo.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Designed for performing impact analysis of
  opinions in a digital text document (DTD). The 
  package allows a user to assess the extent to which a theme
  or subject within a document impacts the overall opinion 
  expressed in the document. The package can be applied to a wide 
  range of opinion-based DTD, including commentaries on social media
  platforms (such as 'Facebook', 'Twitter' and 'Youtube'), 
  online products reviews, and so on. 
  The utility of 'opitools' was originally demonstrated 
  in Adepeju and Jimoh (2021) &lt;<a href="https://doi.org/10.31235%2Fosf.io%2Fc32qh">doi:10.31235/osf.io/c32qh</a>&gt; in the 
  assessment of COVID-19 impacts on neighbourhood policing using 
  Twitter data. Further examples can be found in the vignette of 
  the package.</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/MAnalytics/opitools">https://github.com/MAnalytics/opitools</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/MAnalytics/opitools/issues/1">https://github.com/MAnalytics/opitools/issues/1</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, tibble, tidytext, magrittr, dplyr, stringr, purrr,
tidyr, likert, tm, wordcloud2, forcats, cowplot</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, rvest, kableExtra</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-07-29 14:43:01 UTC; monsu</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-07-29 15:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='covid_theme'>keywords relating to COVID-19 pandemics</h2><span id='topic+covid_theme'></span>

<h3>Description</h3>

<p>A list of keywords relating to the COVID-19 pandemic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covid_theme
</code></pre>


<h3>Format</h3>

<p>A dataframe containing one variable:
</p>

<ul>
<li><p> keys: list of keywords
</p>
</li></ul>


<hr>
<h2 id='debate_dtd'>Comments on a video of a political debate.</h2><span id='topic+debate_dtd'></span>

<h3>Description</h3>

<p>A DTD containing individual comments on a video
showing the first debate between two US presidential
nominees (Donald Trump and Hillary Clinton)
in Sept. 2016. (Credit: NBC News).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>debate_dtd
</code></pre>


<h3>Format</h3>

<p>A dataframe containing one variable
</p>

<ul>
<li><p> text: individual text records
</p>
</li></ul>



<h3>Details</h3>

<p>The DTD only include the comments within the first 24hrs
in which the video was posted. All individual comments
in which the names of both candidates are mentioned
are filtered out.
</p>

<hr>
<h2 id='opi_impact'>Statistical assessment of
impacts of a specified theme from a DTD.</h2><span id='topic+opi_impact'></span>

<h3>Description</h3>

<p>This function assesses the impacts of a theme
(or subject) on the overall opinion computed for a DTD
Different themes in a DTD can be identified by the keywords
used in the DTD. These keywords (or words) can be extracted by
any analytical means available to the users, e.g.
<code>word_imp</code> function. The keywords must be collated and
supplied this function through the <code>theme_keys</code> argument
(see below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>opi_impact(textdoc, theme_keys=NULL, metric = 1,
fun = NULL, nsim = 99, alternative="two.sided",
quiet=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="opi_impact_+3A_textdoc">textdoc</code></td>
<td>
<p>An <code>n</code> x <code>1</code> list (dataframe) of
individual text records, where <code>n</code> is the total
number of individual records.</p>
</td></tr>
<tr><td><code id="opi_impact_+3A_theme_keys">theme_keys</code></td>
<td>
<p>(a list) A one-column dataframe (of any
number of length) containing a list of keywords relating
to the theme or secondary subject to be investigated.
The keywords can also be defined as a vector of characters.</p>
</td></tr>
<tr><td><code id="opi_impact_+3A_metric">metric</code></td>
<td>
<p>(an integer) Specify the metric to utilize
for the calculation of opinion score. Default: <code>1</code>.
See detailed documentation
in the <code>opi_score</code> function.</p>
</td></tr>
<tr><td><code id="opi_impact_+3A_fun">fun</code></td>
<td>
<p>A user-defined function given that parameter
<code>metric</code> (above) is set equal to <code>5</code>.
See detailed documentation
in the <code>opi_score</code> function.</p>
</td></tr>
<tr><td><code id="opi_impact_+3A_nsim">nsim</code></td>
<td>
<p>(an integer) Number of replicas (ESD) to generate.
See detailed documentation in the <code>opi_sim</code> function.
Default: <code>99</code>.</p>
</td></tr>
<tr><td><code id="opi_impact_+3A_alternative">alternative</code></td>
<td>
<p>(a character) Default: <code>"two.sided"</code>,
indicating a two-tailed test. A user can override
this default value by specifying <code>“less”</code> or <code>“greater”</code>
to run the analysis as one-tailed test when the observed score
is located at the lower or upper regions of the expectation
distribution, respectively. Note: for <code>metric=1</code>,
the <code>alternative</code> parameter should be
set equal to <code>"two.sided"</code> because the opinion score is
bounded by both positive and negative values. For an opinion
score bounded by positive values, such as when
<code>metric = 2, 3 or 4</code>, the <code>alternative</code> parameter
should be set as &quot;greater&quot;, and set as &quot;less&quot; otherwise.
If metric parameter is set equal to <code>5</code>, with a user-defined
opinion score function (i.e. <code>fun</code> not NULL ), the user is required
to determine the limits of the opinion scores, and set the
<code>alternative</code> argument appropriately.</p>
</td></tr>
<tr><td><code id="opi_impact_+3A_quiet">quiet</code></td>
<td>
<p>(TRUE or FALSE) To suppress processing
messages. Default: <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the statistical
significance value (<code>p-value</code>) of an opinion score
by comparing the observed score (from the <code>opi_score</code>
function) with the expected scores (distribution) (from the
<code>opi_sim</code> function). The formula is given as
<code>p = (S.beat+1)/(S.total+1)</code>, where <code>S_total</code> is the total
number of replicas (<code>nsim</code>) specified, <code>S.beat</code> is number of replicas
in which their expected scores are than the observed score (See
further details in Adepeju and Jimoh, 2021).
</p>


<h3>Value</h3>

<p>Details of statistical significance of impacts
of a secondary subject <code>B</code> on the opinion concerning the
primary subject <code>A</code>.
</p>


<h3>References</h3>

<p>(1) Adepeju, M. and Jimoh, F. (2021). An Analytical
Framework for Measuring Inequality in the Public Opinions on
Policing – Assessing the impacts of COVID-19 Pandemic using
Twitter Data. https://doi.org/10.31235/osf.io/c32qh
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Application in marketing:

#`data` -&gt; 'reviews_dtd'
#`theme_keys` -&gt; 'refreshment_theme'

#RQ2a: "Do the refreshment outlets impact customers'
#opinion of the services at the Piccadilly train station?"

##execute function
output &lt;- opi_impact(textdoc = reviews_dtd,
          theme_keys=refreshment_theme, metric = 1,
          fun = NULL, nsim = 99, alternative="two.sided",
          quiet=TRUE)

#To print results
print(output)

#extracting the pvalue in order to answer RQ2a
output$pvalue


</code></pre>

<hr>
<h2 id='opi_score'>Opinion score of a digital text document (DTD)</h2><span id='topic+opi_score'></span>

<h3>Description</h3>

<p>Given a DTD,
this function computes the overall opinion score based on the
proportion of text records classified as expressing positive,
negative or a neutral sentiment.
The function first transforms
the text document into a tidy-format dataframe, described as the
<code style="white-space: pre;">&#8288;observed sentiment document (OSD)&#8288;</code> (Adepeju and Jimoh, 2021),
in which each text record is assigned a sentiment class based
on the summation of all sentiment scores expressed by the words in
the text record.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>opi_score(textdoc, metric = 1, fun = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="opi_score_+3A_textdoc">textdoc</code></td>
<td>
<p>An <code>n</code> x <code>1</code> list (dataframe) of
individual text records, where <code>n</code> is the total
number of individual records.</p>
</td></tr>
<tr><td><code id="opi_score_+3A_metric">metric</code></td>
<td>
<p>(an integer) Specify the metric to utilize for
the calculation of opinion score. Valid values include
<code>1, 2, ...,5</code>.
Assuming <code>P</code>, <code>N</code> and <code>O</code> represent positive,
negative, and neutral record sentiments, respectively,
the followings are the details of the opinion score function
represented by the numerical arguments above:
<code>1</code>: Polarity (percentage difference)
<code>((P - N)/(P + N))*100</code>, (Bound: -100%, +100%);
<code>2</code>: Polarity (proportional difference)
<code>((abs(P - N) / (P + N + O))*100</code>,
(Bound: 0, +100%);
<code>3</code>: Positivity <code>(P/ (P + N + O))*100</code>,
(Bound: 0, +100%); <code>4</code>: Negativity <code>(N / (P + N + O))*100</code>,
(Bound: 0, +100%) (Malshe, A. 2019;
Lowe et al. 2011). <code>5</code>: To pass a
user-defined opinion score function (also see the <code>fun</code>
parameter below.</p>
</td></tr>
<tr><td><code id="opi_score_+3A_fun">fun</code></td>
<td>
<p>A user-defined function given that <code>metric</code>
parameter (above) is set equal to <code>5</code>.
For example, given a defined opinion score function
<code>myfun</code> &lt;- <code style="white-space: pre;">&#8288;function(P, N, O){&#8288;</code>
<code>("some tasks to do")</code>; <code style="white-space: pre;">&#8288;return("a value")}&#8288;</code>, the input
argument of <code>fun</code> parameter then becomes <code>fun = myfun</code>.
Default: <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An opinion score is derived from all the sentiments
(i.e. positive, negative (and neutral) expressed within a
text document. We deploy a lexicon-based approach
(Taboada et al. 2011) using the <code>AFINN</code> lexicon
(Nielsen, 2011).
</p>


<h3>Value</h3>

<p>Returns an <code>opi_object</code> containing details of the
opinion measures from the text document.
</p>


<h3>References</h3>

<p>(1) Adepeju, M. and Jimoh, F. (2021). An
Analytical Framework for Measuring Inequality in the
Public Opinions on Policing – Assessing the impacts
of COVID-19 Pandemic using Twitter Data.
https://doi.org/10.31235/osf.io/c32qh
(2) Malshe, A. (2019) Data Analytics Applications.
Online book available at:
https://ashgreat.github.io/analyticsAppBook/index.html.
Date accessed: 15th December 2020.
(3) Taboada, M.et al. (2011).
Lexicon-based methods for sentiment analysis. Computational
linguistics, 37(2), pp.267-307.
(4) Lowe, W. et al. (2011).
Scaling policy preferences from coded political texts.
Legislative studies quarterly, 36(1), pp.123-155.
(5) Razorfish (2009) Fluent: The Razorfish Social Influence
Marketing Report. Accessed: 24th February, 2021.
(6) Nielsen, F. A. (2011), “A new ANEW: Evaluation of a word
list for sentiment analysis in microblogs”, Proceedings of the
ESWC2011 Workshop on 'Making Sense of Microposts': Big things
come in small packages (2011) 93-98.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use police/pandemic posts on Twitter
# Experiment with a standard metric (e.g. metric 1)
score &lt;- opi_score(textdoc = policing_dtd, metric = 1, fun = NULL)
#print result
print(score)

#Example using a user-defined opinion score -
#a demonstration with a component of SIM opinion
#Score function (by Razorfish, 2009). The opinion
#function can be expressed as:

myfun &lt;- function(P, N, O){
  score &lt;- (P + O - N)/(P + O + N)
return(score)
}

#Run analysis
score &lt;- opi_score(textdoc = policing_dtd, metric = 5, fun = myfun)
#print results
print(score)


</code></pre>

<hr>
<h2 id='opi_sim'>Simulates the opinion expectation distribution
of a digital text document.</h2><span id='topic+opi_sim'></span>

<h3>Description</h3>

<p>This function simulates the expectation distribution of the
observed opinion score (computed using the <code>opi_score</code> function).
The resulting tidy-format dataframe can be described as the
<code style="white-space: pre;">&#8288;expected sentiment document (ESD)&#8288;</code> (Adepeju and Jimoh, 2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>opi_sim(osd_data, nsim=99, metric = 1, fun = NULL, quiet=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="opi_sim_+3A_osd_data">osd_data</code></td>
<td>
<p>A list (dataframe). An <code>n</code> x <code>3</code>
OSD, in which <code>n</code> represents the length of the
text records that have been successfully classified as
expressing positive, negative or a neutral sentiment.
Column <code>1</code> of the OSD is the text record ID,
column <code>2</code> shows the sentiment classes (i.e. positive,
negative, or neutral), while column <code>3</code> contains two
variables: <code>present</code> and <code>absent</code> indicating records that
include and records that do not include any of the specified
theme keywords, respectively.</p>
</td></tr>
<tr><td><code id="opi_sim_+3A_nsim">nsim</code></td>
<td>
<p>(an integer) Number of replicas (ESD) to simulate.
Recommended values are: 99, 999, 9999, and so on. Since the run time
is proportional to the number of replicas, a moderate number of
simulation, such as 999, is recommended. Default: <code>99</code>.</p>
</td></tr>
<tr><td><code id="opi_sim_+3A_metric">metric</code></td>
<td>
<p>(an integer) Specify the metric to utilize for the
calculation of the opinion score. Default: <code>1</code>. See
details in the documentation of <code>opi_score</code> function.
The input argument here must correspond to that of <code>opi_score</code>
function in order to compute a statistical significance value (p-value).</p>
</td></tr>
<tr><td><code id="opi_sim_+3A_fun">fun</code></td>
<td>
<p>A user-defined function given that parameter
<code>metric</code> is set equal to <code>5</code>. See details in the
documentation of the <code>opi_score</code> function.</p>
</td></tr>
<tr><td><code id="opi_sim_+3A_quiet">quiet</code></td>
<td>
<p>(TRUE or FALSE) To suppress processing
messages. Default: <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Employs non-parametric randomization testing approach in
order to generate the expectation distribution of the observed
opinion scores (see details in Adepeju and Jimoh 2021).
</p>


<h3>Value</h3>

<p>Returns a list of expected opinion scores with length equal
to the number of simulation (<code>nsim</code>) specified.
</p>


<h3>References</h3>

<p>(1) Adepeju, M. and Jimoh, F. (2021). An Analytical
Framework for Measuring Inequality in the Public Opinions on
Policing – Assessing the impacts of COVID-19 Pandemic using
Twitter Data. https://doi.org/10.31235/osf.io/c32qh
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Prepare an osd data from the output
#of `opi_score` function.

score &lt;- opi_score(textdoc = policing_dtd,
                     metric = 1, fun = NULL)
#extract OSD
OSD &lt;- score$OSD
#note that `OSD` is shorter in length
#than `policing_dtd`, meaning that some
#text records were not classified

#Bind a fictitious indicator column
osd_data2 &lt;- data.frame(cbind(OSD,
           keywords = sample(c("present","absent"), nrow(OSD),
           replace=TRUE, c(0.35, 0.65))))

#generate expected distribution
exp_score &lt;- opi_sim(osd_data2, nsim=99, metric = 1,
                                 fun = NULL, quiet=TRUE)
#preview the distribution
hist(exp_score)

</code></pre>

<hr>
<h2 id='osd_data'>Observed sentiment document (OSD).</h2><span id='topic+osd_data'></span>

<h3>Description</h3>

<p>A tidy-format list (dataframe) showing the resulting
classification of each text record into positive, negative
or neutral sentiment. The second column of the dataframe consists of
labels variables <code>present</code> and <code>absent</code> to indicate whether any of the secondary
keywords exist in a text record.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>osd_data
</code></pre>


<h3>Format</h3>

<p>A dataframe with the following variables:
</p>

<ul>
<li><p> ID: numeric id of text record with valid
resultant sentiments score and classification.
</p>
</li>
<li><p> sentiment: Containing the sentiment classes.
</p>
</li>
<li><p> keywords: Indicator to show whether a secondary
keyword in present or absent in a text record.
</p>
</li></ul>


<hr>
<h2 id='policing_dtd'>Twitter posts on police/policing</h2><span id='topic+policing_dtd'></span>

<h3>Description</h3>

<p>A text document (an DTD) containing twitter posts
(for an anonymous geographical location 'A') on police/policing.
The DTD also includes
posts that express sentiments on policing in relation to
the COVID-19 pandemic (Secondary subject B)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>policing_dtd
</code></pre>


<h3>Format</h3>

<p>A dataframe containing one variable
</p>

<ul>
<li><p> text: individual text records
</p>
</li></ul>


<hr>
<h2 id='refreshment_theme'>Keywords relating to facilities at train stations</h2><span id='topic+refreshment_theme'></span>

<h3>Description</h3>

<p>List of words relating to refreshments that can
be found at the Piccadilly Train
Station (Manchester)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>refreshment_theme
</code></pre>


<h3>Format</h3>

<p>A dataframe containing one variable:
</p>

<ul>
<li><p> keys: list of keywords
</p>
</li></ul>


<hr>
<h2 id='reviews_dtd'>Customer reviews from tripadvisor website</h2><span id='topic+reviews_dtd'></span>

<h3>Description</h3>

<p>A text document (an DTD) containing the  customer reviews
of the Piccadilly train station (Manchester) downloaded
from the www.tripadvisor.co.uk'. The reviews cover from
July 2016 to March 2021.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reviews_dtd
</code></pre>


<h3>Format</h3>

<p>A dataframe containing one variable
</p>

<ul>
<li><p> text: individual text records
</p>
</li></ul>


<hr>
<h2 id='signage_theme'>Keywords relating to signages at train stations</h2><span id='topic+signage_theme'></span>

<h3>Description</h3>

<p>List of signages at the Piccadilly Train
Station (Manchester)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signage_theme
</code></pre>


<h3>Format</h3>

<p>A dataframe containing one variable:
</p>

<ul>
<li><p> keys: list of keywords
</p>
</li></ul>


<hr>
<h2 id='tweets'>Fake Twitter posts on police/policing 2</h2><span id='topic+tweets'></span>

<h3>Description</h3>

<p>A text document (an DTD) containing twitter posts
(for an anonymous geographical location 2) on police/policing
(primary subject A). The DTD includes
posts that express sentiments on policing in relation to
the COVID-19 pandemic (Secondary subject B)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweets
</code></pre>


<h3>Format</h3>

<p>A dataframe with the following variables:
</p>

<ul>
<li><p> text: individual text records
</p>
</li>
<li><p> group: real/arbitrary groups of text records
</p>
</li></ul>


<hr>
<h2 id='word_distrib'>Words Distribution</h2><span id='topic+word_distrib'></span>

<h3>Description</h3>

<p>This function examines whether the distribution
of word frequencies in a text document follows the Zipf distribution
(Zipf 1934). The Zipf's distribution is considered the ideal
distribution of a perfect natural language text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_distrib(textdoc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_distrib_+3A_textdoc">textdoc</code></td>
<td>
<p><code>n</code> x <code>1</code> list (dataframe)
of individual text records, where <code>n</code> is the number
of individual records.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Zipf's distribution is most easily observed by
plotting the data on a log-log graph, with the axes being
log(word rank order) and log(word frequency). For a perfect
natural language text, the relationship between the word rank
and the word frequency should have a negative slope with all points
falling on a straight line. Any deviation from the straight
line can be considered an imperfection attributable to the
texts within the document.
</p>


<h3>Value</h3>

<p>A list of word ranks and their respective
frequencies, and a plot showing the relationship between
the two variables.
</p>


<h3>References</h3>

<p>Zipf G (1936). The Psychobiology of Language.
London: Routledge; 1936.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#Get an \code{n} x 1 text document
tweets_dat &lt;- data.frame(text=tweets[,1])
plt = word_distrib(textdoc = tweets_dat)

plt

</code></pre>

<hr>
<h2 id='word_imp'>Importance of words (terms) embedded
in a text document</h2><span id='topic+word_imp'></span>

<h3>Description</h3>

<p>Produces a wordcloud which represents the
level of importance of each word (across different text groups)
within a text document, according to a specified measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_imp(textdoc, metric= "tf",
words_to_filter=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_imp_+3A_textdoc">textdoc</code></td>
<td>
<p>An <code>n</code> x <code>1</code> list (dataframe) of
individual text records, where <code>n</code> is the total
number of individual records. An <code>n</code> x code2 dataframe can
also be supplied, in which the second column represents the
labels of the pre-defined groupings of the text records,
e.g. labels of geographical areas where each text record
originates.
For an <code>n</code> x <code>1</code> dataframe, an arbitrary grouping is
automatically imposed.</p>
</td></tr>
<tr><td><code id="word_imp_+3A_metric">metric</code></td>
<td>
<p>(character) The measure for determining the level of
importance of each word within the text document. Options include <code>'tf'</code>
representing <code style="white-space: pre;">&#8288;term frequency&#8288;</code> and <code>'tf-idf'</code>
representing <code style="white-space: pre;">&#8288;term frequency inverse document frequency&#8288;</code>
(Silge &amp; Robinson, 2016).</p>
</td></tr>
<tr><td><code id="word_imp_+3A_words_to_filter">words_to_filter</code></td>
<td>
<p>A pre-defined vector of words (terms) to
filter out from the DTD prior to highlighting words importance.
default: <code>NULL</code>. This parameter helps to eliminate
non-necessary words that may be too dominant in the results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function determines the most important words
across various grouping of a text document. The measure
options include the <code>tf</code> and <code>tf-idf</code>. The idea of <code>tf</code>
is to rank words in the order of their number of occurrences
across the text document, whereas <code>tf-idf</code> finds words that
are not used very much, but appear across
many groups in the document.
</p>


<h3>Value</h3>

<p>Graphical representation of words importance
according to a specified metric. A wordcloud is used
to represent words importance if <code>tf</code> is specified, while
facet wrapped histogram is used if <code>tf-idf</code> is specified.
A wordcloud is represents each word with a size corresponding
to its level of importance. In the facet wrapped histograms
words are ranked in each group (histogram) in their order
of importance.
</p>


<h3>References</h3>

<p>Silge, J. and Robinson, D. (2016) tidytext:
Text mining and analysis using tidy data principles in R.
Journal of Open Source Software, 1, 37.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#words to filter out
wf &lt;- c("police","policing")
output &lt;- word_imp(textdoc = policing_dtd, metric= "tf",
words_to_filter= wf)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
