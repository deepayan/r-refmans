<!DOCTYPE html><html><head><title>Help for package compositions</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {compositions}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Aar'><p>Composition of glaciar sediments from the Aar massif (Switzerland)</p></a></li>
<li><a href='#acomp'><p>Aitchison compositions</p></a></li>
<li><a href='#acomp-class'><p>Class <code>"acomp"</code></p></a></li>
<li><a href='#acomparith'><p>Power transform in the simplex</p></a></li>
<li><a href='#acompmargin'><p>Marginal compositions in Aitchison Compositions</p></a></li>
<li><a href='#acompscalarproduct'><p>inner product for datasets with a vector space structure</p></a></li>
<li><a href='#Activity10'><p>Activity patterns  of a statistician for 20 days</p></a></li>
<li><a href='#Activity31'><p>Activity patterns  of a statistician for 20 days</p></a></li>
<li><a href='#alr'><p>Additive log ratio transform</p></a></li>
<li><a href='#amounts-class'><p>Class <code>"amounts"</code></p></a></li>
<li><a href='#AnimalVegetation'><p>Animal and vegetation measurement</p></a></li>
<li><a href='#aplus'><p>Amounts analysed in log-scale</p></a></li>
<li><a href='#aplus-class'><p>Class <code>"aplus"</code></p></a></li>
<li><a href='#aplusarithm'><p>vectorial arithmetic for data sets with aplus class</p></a></li>
<li><a href='#apt'><p>Additive planar transform</p></a></li>
<li><a href='#ArcticLake'><p>Artic lake sediment samples of different water depth</p></a></li>
<li><a href='#arrows3D'><p>arrows in 3D, based on package rgl</p></a></li>
<li><a href='#as.data.frame'><p>Convert &quot;compositions&quot; classes to data frames or matrices</p></a></li>
<li><a href='#axis3D'><p>Drawing a 3D coordiante system to a plot, based on package rgl</p></a></li>
<li><a href='#backtransform'><p>Automatic common backtransformation for compositions</p></a></li>
<li><a href='#balance'><p>Compute balances for a compositional dataset.</p></a></li>
<li><a href='#barplot.acomp'><p>Bar charts of amounts</p></a></li>
<li><a href='#Bayesite'><p>Permeabilities of bayesite</p></a></li>
<li><a href='#binary'><p>Treating binary and g-adic numbers</p></a></li>
<li><a href='#biplot3D'><p>Three-dimensional biplots, based on package rgl</p></a></li>
<li><a href='#Blood23'><p>Blood samples</p></a></li>
<li><a href='#Boxite'><p>Compositions and depth of 25 specimens of boxite</p></a></li>
<li><a href='#boxplot'><p>Displaying compositions and amounts with box-plots</p></a></li>
<li><a href='#ccomp'><p>Count compositions</p></a></li>
<li><a href='#ccomp-class'><p>Class <code>"ccomp"</code></p></a></li>
<li><a href='#ccompgof'><p>Compositional Goodness of fit test</p></a></li>
<li><a href='#cdt'><p>Centered default transform</p></a></li>
<li><a href='#ClamEast'><p>Color-size compositions of 20 clam colonies from East Bay</p></a></li>
<li><a href='#ClamWest'><p>Color-size compositions of 20 clam colonies from West Bay</p></a></li>
<li><a href='#clo'><p>Closure of a composition</p></a></li>
<li><a href='#clr'><p>Centered log ratio transform</p></a></li>
<li><a href='#clr2ilr'><p>Convert between clr and ilr, and between cpt and ipt.</p></a></li>
<li><a href='#ClusterFinder1'><p>Heuristics to find subpopulations of outliers</p></a></li>
<li><a href='#CoDaDendrogram'><p>Dendrogram representation of acomp or rcomp objects</p></a></li>
<li><a href='#coloredBiplot'><p>A biplot providing somewhat easier access to details of the plot.</p></a></li>
<li><a href='#colorsForOutliers'><p>Create a color/char palette or for groups of outliers</p></a></li>
<li><a href='#CompLinModCoReg'><p>Compositional Linear Model of Coregionalisation</p></a></li>
<li><a href='#compOKriging'><p>Compositional Ordinary Kriging</p></a></li>
<li><a href='#compositional-class'><p>Class <code>"compositional"</code></p></a></li>
<li><a href='#compositions-package'>
<p>Compositional Data Analysis</p></a></li>
<li><a href='#ConfRadius'><p>Helper to compute confidence ellipsoids</p></a></li>
<li><a href='#cor.acomp'><p>Correlations of amounts and compositions</p></a></li>
<li><a href='#Coxite'><p>Compositions, depths and porosities of 25 specimens of coxite</p></a></li>
<li><a href='#cpt'><p>Centered planar transform</p></a></li>
<li><a href='#DiagnosticProb'><p>Diagnostic probabilities</p></a></li>
<li><a href='#dist'><p>Distances in variouse approaches</p></a></li>
<li><a href='#ellipses'><p>Draw ellipses</p></a></li>
<li><a href='#endmemberCoordinates'><p>Recast amounts as mixtures of end-members</p></a></li>
<li><a href='#Firework'><p>Firework mixtures</p></a></li>
<li><a href='#fitdirichlet'><p>Fitting a Dirichlet distribution</p></a></li>
<li><a href='#fitSameMeanDifferentVarianceModel'><p>Fit Same Mean Different Variance Model</p></a></li>
<li><a href='#gausstest'><p>Classical Gauss Test</p></a></li>
<li><a href='#geometricmean'><p>The geometric mean</p></a></li>
<li><a href='#getdetectionlimit'><p>Gets the detection limit stored in the data set</p></a></li>
<li><a href='#Glacial'><p>Compositions and total pebble counts of 92 glacial tills</p></a></li>
<li><a href='#gof'><p>Compositional Goodness of fit test</p></a></li>
<li><a href='#groupparts'><p>Group amounts of parts</p></a></li>
<li><a href='#gsi.add'><p>Internal functions: Parallel operations of single and multiple datasets</p></a></li>
<li><a href='#gsi.addclass'><p>Internal function: give a derived subclass to an object</p></a></li>
<li><a href='#gsi.csum'><p>Internal function: row and column sums of matrices</p></a></li>
<li><a href='#gsi.diagExtract'><p>Internal functions: Get the diagonal of a matrix</p></a></li>
<li><a href='#gsi.diagGenerate'><p>Internal functions: Generate a diagonal matrix</p></a></li>
<li><a href='#gsi.drop'><p>Internal functions: A conditional drop</p></a></li>
<li><a href='#gsi.eq'><p>Internal function: Checking equality of IEEE special numbers</p></a></li>
<li><a href='#gsi.expandrcomp'><p>Internal function: Scaling rcomp</p></a></li>
<li><a href='#gsi.getD'><p>Interal function: Get number of samples and number of parts in a compositional object</p></a></li>
<li><a href='#gsi.isSingleRow'><p>Internal function: Can something be considered as a single</p>
multivariate data item?</a></li>
<li><a href='#gsi.mapin01'><p>Internal functions: Storing integers as reals</p></a></li>
<li><a href='#gsi.margin'><p>Internal function: Compute a desired compositional margin</p></a></li>
<li><a href='#gsi.merge2signary'><p>Auxiliary functions to compute user-defined ilr and ipt transforms.</p></a></li>
<li><a href='#gsi.plain'><p>Internal function: Convert to plain vector or matrix</p></a></li>
<li><a href='#gsi.PrinBal'><p>The canonical basis in the clr plane used for ilr and ipt transforms.</p></a></li>
<li><a href='#gsi.recode'><p>Internal function: Recode missings with IEEE number and vice versa</p></a></li>
<li><a href='#gsi.simshape'><p>Internal function: Reshape an object to the shape type of another</p></a></li>
<li><a href='#gsi.svdsolve'><p>Internal function: Solves singular and non square equation systems</p></a></li>
<li><a href='#gsi.textpanel'><p>Internal function: A panel displaying a label only</p></a></li>
<li><a href='#gsi.varwithlosts'><p>Internal function: computes variance of compositional data set with missing/zero values</p></a></li>
<li><a href='#gsi2.invperm'><p>Internal function: Invert a permutation</p></a></li>
<li><a href='#gsicall'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#gsiCoorInfo'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#gsifiltercall'><p>Calling from a function with the own parameters</p></a></li>
<li><a href='#gsigetBalStruct'><p>An auxiliary functions to compute user-defined ilr and ipt transforms.</p></a></li>
<li><a href='#gsiinternal'><p>Environment containing the old gsi functions</p></a></li>
<li><a href='#gsiinternal1'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#gsiinternal2'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#gsiinternal3'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#gsipairs'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#gsiplotmargin'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#gsireset3D'><p>Internal functions of the compositions package</p></a></li>
<li><a href='#Hongite'><p>Compositions of 25 specimens of hongite</p></a></li>
<li><a href='#HotellingsTsq'><p>Hotellings T square distribution</p></a></li>
<li><a href='#HouseholdExp'><p>Household Expenditures</p></a></li>
<li><a href='#Hydrochem'><p>Hydrochemical composition data set of Llobregat river basin water (NE Spain)</p></a></li>
<li><a href='#idt'><p>Isometric default transform</p></a></li>
<li><a href='#iit'><p>Isometric identity transform</p></a></li>
<li><a href='#ilr'><p>Isometric log ratio transform</p></a></li>
<li><a href='#ilrBase'><p>The canonical basis in the clr plane used for ilr and ipt transforms.</p></a></li>
<li><a href='#ilt'><p>Isometric log transform</p></a></li>
<li><a href='#ipt'><p>Isometric planar transform</p></a></li>
<li><a href='#is.acomp'><p>Check for compositional data type</p></a></li>
<li><a href='#IsMahalanobisOutlier'><p>Checking for outliers</p></a></li>
<li><a href='#isoPortionLines'><p>Isoportion- and Isoproportion-lines</p></a></li>
<li><a href='#jura'><p>The jura dataset</p></a></li>
<li><a href='#kdeDirichlet'><p>Density estimation on the simplex with Dirichlet kernel</p></a></li>
<li><a href='#kingTetrahedron'><p>Ploting composition into rotable tetrahedron</p></a></li>
<li><a href='#Kongite'><p>Compositions of 25 specimens of kongite</p></a></li>
<li><a href='#lines'><p>Draws connected lines from point to point.</p></a></li>
<li><a href='#logratioVariogram'><p>Empirical variograms for compositions</p></a></li>
<li><a href='#lrvgram'><p>vgram2lrvgram</p></a></li>
<li><a href='#MahalanobisDist'><p>Compute Mahalanobis distances based von robust Estimations</p></a></li>
<li><a href='#matmult'><p>inner product for matrices and vectors</p></a></li>
<li><a href='#mean.acomp'><p>Mean amounts and mean compositions</p></a></li>
<li><a href='#meanrow'><p>The arithmetic mean of rows or columns</p></a></li>
<li><a href='#Metabolites'><p>Steroid metabolite patterns in adults and children</p></a></li>
<li><a href='#missing.compositions'><p>The policy of treatment of missing values in the &quot;compositions&quot; package</p></a></li>
<li><a href='#missingProjector'><p>Returns a projector the the observed space in case of missings.</p></a></li>
<li><a href='#missingsummary'><p>Classify and summarize missing values in a dataset</p></a></li>
<li><a href='#mix.Read'><p>Reads a data file in a mixR format</p></a></li>
<li><a href='#mvar'><p>Metric summary statistics of real, amount or compositional data</p></a></li>
<li><a href='#names'><p>The names of the parts</p></a></li>
<li><a href='#norm'><p>Vector space norm</p></a></li>
<li><a href='#normalize'><p>Normalize vectors to norm 1</p></a></li>
<li><a href='#NormalTests'><p>Compositional Goodness of fit test</p></a></li>
<li><a href='#oneOrDataset'><p>Treating single compositions as one-row datasets</p></a></li>
<li><a href='#outlierclassifier'><p>Detect and classify compositional outliers.</p></a></li>
<li><a href='#outlierplot'><p>Plot various graphics to analyse outliers.</p></a></li>
<li><a href='#outliersInCompositions'><p>Analysing outliers in compositions.</p></a></li>
<li><a href='#pairs'><p>Pairs plot method for compositions</p></a></li>
<li><a href='#pairwiseplot'><p>Creates a paneled plot like pairs for two different datasets.</p></a></li>
<li><a href='#parametricMat'><p>Unique parametrisations for matrices.</p></a></li>
<li><a href='#perturbe'><p>Perturbation of compositions</p></a></li>
<li><a href='#plot.acomp'><p>Ternary diagrams</p></a></li>
<li><a href='#plot.aplus'><p>Displaying amounts in scatterplots</p></a></li>
<li><a href='#plot3D'><p>plot in 3D based on rgl</p></a></li>
<li><a href='#plot3Dacomp'><p>3D-plot of compositional data</p></a></li>
<li><a href='#plot3Daplus'><p>3D-plot of positive data</p></a></li>
<li><a href='#plot3Drmult'><p>plot in 3D based on rgl</p></a></li>
<li><a href='#plot3Drplus'><p>plot in 3D based on rgl</p></a></li>
<li><a href='#plotlogratioVariogram'><p>Empirical variograms for compositions</p></a></li>
<li><a href='#plotmissingsummary'><p>Plot a Missing Summary</p></a></li>
<li><a href='#PogoJump'>
<p>Honk Kong Pogo-Jumps Championship</p></a></li>
<li><a href='#powerofpsdmatrix'><p>power transform of a matrix</p></a></li>
<li><a href='#princomp.acomp'><p>Principal component analysis for Aitchison compositions</p></a></li>
<li><a href='#princomp.aplus'><p>Principal component analysis for amounts in log geometry</p></a></li>
<li><a href='#princomp.rcomp'><p>Principal component analysis for real compositions</p></a></li>
<li><a href='#princomp.rmult'><p>Principal component analysis for real data</p></a></li>
<li><a href='#princomp.rplus'><p>Principal component analysis for real amounts</p></a></li>
<li><a href='#print.acomp'><p>Printing compositional data.</p></a></li>
<li><a href='#pwlr'><p>Pairwise log ratio transform</p></a></li>
<li><a href='#pwlrPlot'><p>Plots of pairwise logratio against a covariable.</p></a></li>
<li><a href='#qqnorm'><p>Normal quantile plots for compositions and amounts</p></a></li>
<li><a href='#R2'><p>R square</p></a></li>
<li><a href='#rAitchison'><p>Aitchison Distribution</p></a></li>
<li><a href='#ratioLoadings'><p>Loadings of relations of two amounts</p></a></li>
<li><a href='#rcomp'><p>Compositions as elements of the simplex embedded in the D-dimensional real space</p></a></li>
<li><a href='#rcomp-class'><p>Class <code>"rcomp"</code></p></a></li>
<li><a href='#rcomparithm'><p>Arithmetic operations for compositions in a real geometry</p></a></li>
<li><a href='#rcompmargin'><p>Marginal compositions in real geometry</p></a></li>
<li><a href='#rDirichlet'><p>Dirichlet distribution</p></a></li>
<li><a href='#Read standard data files'><p>Reads a data file in a geoeas format</p></a></li>
<li><a href='#replot'><p>Modify parameters of compositional plots.</p></a></li>
<li><a href='#rlnorm'><p>The multivariate lognormal distribution</p></a></li>
<li><a href='#rMahalanobis'><p>Compute distributions of empirical Mahalanobis distances based on</p>
simulations</a></li>
<li><a href='#rmult'><p>Simple treatment of real vectors</p></a></li>
<li><a href='#rmult-class'><p>Class <code>"rmult"</code></p></a></li>
<li><a href='#rmultarithm'><p>vectorial arithmetic for datasets in a classical vector scale</p></a></li>
<li><a href='#rmultmatmult'><p>inner product for datasets with vector scale</p></a></li>
<li><a href='#rnorm'><p>Normal distributions on special spaces</p></a></li>
<li><a href='#robustnessInCompositions'><p>Handling robustness issues and outliers in compositions.</p></a></li>
<li><a href='#rplus'><p>Amounts i.e. positive numbers analysed as objects of the real vector space</p></a></li>
<li><a href='#rplus-class'><p>Class <code>"rplus"</code></p></a></li>
<li><a href='#rplusarithm'><p>vectorial arithmetic for data sets with rplus class</p></a></li>
<li><a href='#rpois'><p>Simulate count compositions without overdispersion</p></a></li>
<li><a href='#runif'><p>The uniform distribution on the simplex</p></a></li>
<li><a href='#scalar'><p>Parallel scalar products</p></a></li>
<li><a href='#scale'><p>Normalizing datasets by centering and scaling</p></a></li>
<li><a href='#Sediments'><p>Proportions of sand, silt and clay in sediments specimens</p></a></li>
<li><a href='#segments'><p>Draws straight lines from point to point.</p></a></li>
<li><a href='#SerumProtein'><p>Serum Protein compositions of blood samples</p></a></li>
<li><a href='#ShiftOperators'><p>Shifts of machine operators</p></a></li>
<li><a href='#simplemissingplot'><p>Ternary diagrams</p></a></li>
<li><a href='#SimulatedAmounts'><p>Simulated amount datasets</p></a></li>
<li><a href='#simulatemissings'><p>Artifical simulation of various kinds of missings/polluted data</p></a></li>
<li><a href='#Skulls'><p>Measurement of skulls</p></a></li>
<li><a href='#SkyeAFM'><p>AFM compositions of 23 aphyric Skye lavas</p></a></li>
<li><a href='#split'><p>Splitting datasets in groups given by factors</p></a></li>
<li><a href='#straight'><p>Draws straight lines.</p></a></li>
<li><a href='#subsetting'><p>Subsetting of compositions</p></a></li>
<li><a href='#summary.acomp'><p>Summarizing a compositional dataset in terms of ratios</p></a></li>
<li><a href='#summary.aplus'><p>Summaries of amounts</p></a></li>
<li><a href='#summary.rcomp'><p>Summary of compositions in real geometry</p></a></li>
<li><a href='#sumprojector'><p>Compute the global projector to the observed subspace.</p></a></li>
<li><a href='#Supervisor'><p>Proportions of supervisor's statements assigned to different categories</p></a></li>
<li><a href='#ternaryAxis'><p>Axis for ternary diagrams</p></a></li>
<li><a href='#totals'><p>Total sum of amounts</p></a></li>
<li><a href='#transformations from 'mixtures' to  'compositions' classes'><p>Transformations from 'mixtures' to  'compositions' classes</p></a></li>
<li><a href='#tryDebugger'><p>Empirical variograms for compositions</p></a></li>
<li><a href='#ult'><p>Uncentered log transform</p></a></li>
<li><a href='#var.acomp'><p>Variances and covariances of amounts and compositions</p></a></li>
<li><a href='#variation'><p>Variation matrices of amounts and compositions</p></a></li>
<li><a href='#variograms'><p>Variogram functions</p></a></li>
<li><a href='#varmlm'><p>Residual variance of a model</p></a></li>
<li><a href='#vcovAcomp'><p>Variance covariance matrix of parameters in compositional regression</p></a></li>
<li><a href='#vgmFit'><p>Compositional variogram model fitting</p></a></li>
<li><a href='#WhiteCells'><p>White-cell composition of 30 blood samples by two different methods</p></a></li>
<li><a href='#wrapped_functions'><p>Standard R functions wrapped for compatibility</p></a></li>
<li><a href='#Yatquat'><p>Yatquat fruit evaluation</p></a></li>
<li><a href='#zeroreplace'><p>Zero-replacement routine</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.0-8</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-25</td>
</tr>
<tr>
<td>Title:</td>
<td>Compositional Data Analysis</td>
</tr>
<tr>
<td>Author:</td>
<td>K. Gerald van den Boogaart &lt;boogaart@hzdr.de&gt;, 
	Raimon Tolosana-Delgado, Matevz Bren  </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>K. Gerald van den Boogaart &lt;support@boogaart.de&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, utils, grDevices, stats, tensorA, robustbase, bayesm,
graphics, MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rgl (&ge; 1.0.1), combinat, energy, knitr, rmarkdown</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for the consistent analysis of compositional 
  data (e.g. portions of substances) and positive numbers (e.g. concentrations) 
  in the way proposed by J. Aitchison and V. Pawlowsky-Glahn.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.stat.boogaart.de/compositions/">http://www.stat.boogaart.de/compositions/</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-31 11:51:19 UTC; raimon</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-31 15:30:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='Aar'>Composition of glaciar sediments from the Aar massif (Switzerland)</h2><span id='topic+Aar'></span>

<h3>Description</h3>

<p>Geochemical composition of glaciar sediments from the Aar massif region (Switzerland), major oxides and trace elements. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Aar)
</code></pre>


<h3>Details</h3>

<p>Composition of recent sediments of several morraines and streams from glaciers around the Aar massif, including both major oxides and trace elements. The major oxides are expressed in weight percent (total sum reported in column <code>SumOxides</code>), from Silica (<code>SiO2</code>, column 3) to total Iron 3 Oxide (<code>Fe2O3t</code>, column12, incorporating FeO recasted to Fe2O3). The trace elements are reported in parts per million (ppm, mg/Kg) between columns 14 (<code>Ba</code>) and 29 (<code>Nd</code>). Partial sum of the trace elements (in ppm) and of all traces and major oxides (in %) are also reported.
</p>
<p>Apart of the compositional information, two covariables are included: Sample and GS. The variable <code>Sample</code> reports the ID of the sample material. This material was sieved in 11 grain size fractions, and each fraction was analysed separately after drying. The grain size fraction of each subsample is reported in variable <code>GS</code>, representing the upper limit of the size fraction reported in <code class="reqn">\phi</code> scale, e.g. the binary log transformation of the average diameter <code class="reqn">\bar{d}</code>
</p>
<p style="text-align: center;"><code class="reqn"> \phi = -\log_2 (\bar{d})</code>
</p>

<p>The Aar is a granitic-granodioritic-gneissic massif of the Alps, in Switzerland, comprised of several intrusions with different compositions within the range of granitoid lithologies. Details of the region, mineralogy, procedures and study questions behind the data can be found in von Eynatten at al (2012) and references thereon.
</p>


<h3>Note</h3>

<p>Courtesy of H. von Eynatten</p>


<h3>Source</h3>

<p>von Eynatten H.; Tolosana-Delgado, R.; Karius, V (2012) Sediment generation in modern glacial settings: Grain-size and source-rock control on sediment composition. Sedimentary Geology 280 (1): 80-92 doi: <a href="https://doi.org/10.1016/j.sedgeo.2012.03.008">10.1016/j.sedgeo.2012.03.008</a>
</p>


<h3>References</h3>

<p>von Eynatten H.; Tolosana-Delgado, R.; Karius, V (2012) Sediment generation in modern glacial settings: Grain-size and source-rock control on sediment composition. Sedimentary Geology 280 (1): 80-92 doi: <a href="https://doi.org/10.1016/j.sedgeo.2012.03.008">10.1016/j.sedgeo.2012.03.008</a>
</p>

<hr>
<h2 id='acomp'>Aitchison compositions</h2><span id='topic+acomp'></span>

<h3>Description</h3>

<p>A class providing the means to analyse compositions in the
philosophical framework of the Aitchison Simplex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  acomp(X,parts=1:NCOL(oneOrDataset(X)),total=1,warn.na=FALSE,
          detectionlimit=NULL,BDL=NULL,MAR=NULL,MNAR=NULL,SZ=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acomp_+3A_x">X</code></td>
<td>
<p>composition or dataset of compositions</p>
</td></tr>
<tr><td><code id="acomp_+3A_parts">parts</code></td>
<td>
<p>vector containing the indices xor names of the columns to be used</p>
</td></tr>
<tr><td><code id="acomp_+3A_total">total</code></td>
<td>
<p>the total amount to be used, typically 1 or 100</p>
</td></tr>
<tr><td><code id="acomp_+3A_warn.na">warn.na</code></td>
<td>
<p>should the user be warned in case of NA,NaN or 0
coding different types of missing values?</p>
</td></tr>
<tr><td><code id="acomp_+3A_detectionlimit">detectionlimit</code></td>
<td>
<p>a number, vector or matrix of positive
numbers giving the detection limit of all values, all columns or
each value, respectively</p>
</td></tr>
<tr><td><code id="acomp_+3A_bdl">BDL</code></td>
<td>
<p>the code for 'Below Detection Limit' in X</p>
</td></tr>
<tr><td><code id="acomp_+3A_sz">SZ</code></td>
<td>
<p>the code for 'Structural Zero' in X</p>
</td></tr>
<tr><td><code id="acomp_+3A_mar">MAR</code></td>
<td>
<p>the code for 'Missing At Random' in X</p>
</td></tr>
<tr><td><code id="acomp_+3A_mnar">MNAR</code></td>
<td>
<p>the code for 'Missing Not At Random' in X</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many multivariate datasets essentially describe amounts of D different
parts in a whole. This has some important implications justifying to
regard them as a scale for its own, called a
composition. This scale  was in-depth analysed by Aitchison
(1986) and the functions around the class <code>"acomp"</code> follow his
approach.<br />
Compositions have some important properties: Amounts are always
positive. The amount of every part is limited to the whole. The
absolute amount of the whole is noninformative since it is typically due
to artifacts on the measurement procedure. Thus only relative changes
are relevant. If the relative amount of one part
increases, the amounts of other parts must decrease, introducing
spurious anticorrelation (Chayes 1960), when analysed directly. Often
parts (e.g H2O, Si) are missing in the dataset leaving the total
amount unreported and longing for analysis procedures avoiding
spurious effects when applied to such subcompositions. Furthermore, 
the result of an analysis should be indepent of the units (ppm, g/l, vol.%, mass.%, molar
fraction) of the dataset.
<br />
From these properties Aitchison showed that the
analysis should be based on ratios or log-ratios only. He introduced 
several transformations (e.g. <code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+alr">alr</a></code>),
operations (e.g. <code><a href="#topic+perturbe">perturbe</a></code>, <code><a href="#topic+power.acomp">power.acomp</a></code>),
and a distance (<code><a href="#topic+dist">dist</a></code>) which are compatible
with these
properties. Later it was found that the set of compostions equipped with
perturbation as addition and power-transform as scalar multiplication
and the <code><a href="#topic+dist">dist</a></code> as distance form a D-1 dimensional
euclidean vector space (Billheimer, Fagan and Guttorp, 2001), which 
can be mapped isometrically to a usual real vector space by <code><a href="#topic+ilr">ilr</a></code> 
(Pawlowsky-Glahn and Egozcue, 2001).
<br />
The general approach in analysing acomp objects is thus to perform
classical multivariate analysis on clr/alr/ilr-transformed coordinates
and to backtransform or display the results in such a way that they
can be interpreted in terms of the original compositional parts.   
<br />
A side effect of the procedure is to force the compositions to sum up to a
<var>total</var>, which is done by the closure operation <code><a href="#topic+clo">clo</a></code> . 
</p>


<h3>Value</h3>

<p>a vector of class <code>"acomp"</code> representing one closed composition
or a matrix of class <code>"acomp"</code> representing
multiple closed compositions each in one row.
</p>


<h3>Missing Policy</h3>

<p>The policy of treatment of zeroes, missing values and values 
below detecion limit is explained in depth in <a href="#topic+compositions.missing">compositions.missing</a>. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>
<p>Billheimer, D., P. Guttorp, W.F. and Fagan (2001) Statistical interpretation of species composition,
<em>Journal of the American Statistical Association</em>, <b>96</b> (456), 1205-1214<br />
</p>
<p>Chayes, F. (1960). On correlation between variables of constant
sum. Journal of Geophysical Research 65~(12), 4185&ndash;4193.
</p>
<p>Pawlowsky-Glahn, V. and J.J. Egozcue (2001) Geometric approach to
statistical analysis on the simplex. <em>SERRA</em> <b>15</b>(5), 384-398<br />
</p>
<p>Pawlowsky-Glahn, V. (2003) Statistical modelling on coordinates. In: 
Thi\'o-Henestrosa, S. and Mart\'in-Fern\'andez, J.A. (Eds.)
<em>Proceedings of the 1st International Workshop on Compositional Data Analysis</em>,
Universitat de Girona, ISBN 84-8458-111-X, <a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p>Mateu-Figueras, G. and Barcel\'o-Vidal, C. (Eds.)
<em>Proceedings of the 2nd International Workshop on Compositional Data Analysis</em>,
Universitat de Girona, ISBN 84-8458-222-1, <a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a><br />
</p>
<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+aplus">aplus</a></code>,
<code><a href="#topic+princomp.acomp">princomp.acomp</a></code>, 
<code><a href="#topic+plot.acomp">plot.acomp</a></code>, <code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code>,
<code><a href="#topic+barplot.acomp">barplot.acomp</a></code>, <code><a href="#topic+mean.acomp">mean.acomp</a></code>,
<code><a href="#topic+var.acomp">var.acomp</a></code>, <code><a href="#topic+variation.acomp">variation.acomp</a></code>,
<code><a href="#topic+cov.acomp">cov.acomp</a></code>, <code><a href="#topic+msd">msd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(acomp(sa.lognormals))
</code></pre>

<hr>
<h2 id='acomp-class'>Class <code>"acomp"</code></h2><span id='topic+acomp-class'></span><span id='topic+coerce+2Cacomp+2Cdata.frame-method'></span><span id='topic+coerce+2Cacomp+2Cstructure-method'></span><span id='topic+coerce+3C-+2Cacomp+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>The S4-version of the data container &quot;acomp&quot; for compositional data. More information in 
<code><a href="#topic+acomp">acomp</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be directly created from it. 
This is provided to ensure that acomp objects behave as data.frame or structure under certain circumstances. Use <code><a href="#topic+acomp">acomp</a></code> to create these objects.</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Object of class <code>"list"</code> containing the data itself </p>
</dd>
<dt><code>names</code>:</dt><dd><p>Object of class <code>"character"</code> with column names </p>
</dd>
<dt><code>row.names</code>:</dt><dd><p>Object of class <code>"data.frameRowLabels"</code> with row names </p>
</dd>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code> with the class string </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+data.frame-class">data.frame</a>"</code>, directly.
Class <code>"<a href="#topic+compositional-class">compositional</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+list-class">list</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;data.frame&quot;, distance 3.
</p>


<h3>Methods</h3>


<dl>
<dt>coerce</dt><dd><p><code>signature(from = "acomp", to = "data.frame")</code>: to generate a data.frame </p>
</dd>
<dt>coerce</dt><dd><p><code>signature(from = "acomp", to = "structure")</code>: to generate a structure (i.e. a vector, matrix or array) </p>
</dd>
<dt>coerce&lt;-</dt><dd><p><code>signature(from = "acomp", to = "data.frame")</code>: to overwrite a composition with a data.frame</p>
</dd>
</dl>



<h3>Note</h3>

<p>see <code><a href="#topic+acomp">acomp</a></code>
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>References</h3>

<p>see <code><a href="#topic+acomp">acomp</a></code>
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+acomp">acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("acomp")
</code></pre>

<hr>
<h2 id='acomparith'>Power transform in the simplex</h2><span id='topic+power.acomp'></span><span id='topic++2A.acomp'></span><span id='topic++2F.acomp'></span>

<h3>Description</h3>

<p>The Aitchison Simplex with its two operations perturbation as +  and
power transform as * is a vector space. This vector space is
represented by these operations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.acomp(x,s)
## Methods for class "acomp"
## x*y
## x/y
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acomparith_+3A_x">x</code></td>
<td>
<p>an acomp composition or dataset of compositions (or a number
or a numeric vector)</p>
</td></tr>
<tr><td><code id="acomparith_+3A_y">y</code></td>
<td>
<p>a numeric vector of size 1 or nrow(x)</p>
</td></tr>
<tr><td><code id="acomparith_+3A_s">s</code></td>
<td>
<p>a numeric vector of size 1 or nrow(x)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power transform is the basic multiplication operation of the
Aitchison simplex seen as a vector space. It is defined as:
</p>
<p style="text-align: center;"><code class="reqn">(x*y)_i:=  clo( (x_i^{y_i})_i )_i </code>
</p>

<p>The division operation is just the multiplication with <code class="reqn">1/y</code>.
</p>


<h3>Value</h3>

<p>An <code>"acomp"</code> vector or matrix.
</p>


<h3>Note</h3>

<p>For <code>*</code> the arguments x and y can be exchanged. Note that 
this definition generalizes the power by a scalar, since <code>y</code> or 
<code>s</code> may be given as a scalar, or as a vector with as many components as
the composition in <code><a href="#topic+acomp">acomp</a></code> <code>x</code>. The result is then a matrix 
where each row corresponds to the composition powered by one of the scalars 
in the vector.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>
<p>Pawlowsky-Glahn, V. and J.J. Egozcue (2001) Geometric approach to
statistical analysis on the simplex. <em>SERRA</em> <b>15</b>(5), 384-398<br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+clr">clr</a></code>, <code><a href="#topic+alr">alr</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>acomp(1:5)* -1 + acomp(1:5)
data(SimulatedAmounts)
cdata &lt;- acomp(sa.lognormals)
plot( tmp &lt;- (cdata-mean(cdata))/msd(cdata) )
class(tmp)
mean(tmp)
msd(tmp)
var(tmp)
</code></pre>

<hr>
<h2 id='acompmargin'>Marginal compositions in Aitchison Compositions</h2><span id='topic+acompmargin'></span>

<h3>Description</h3>

<p>Compute marginal compositions of selected parts, by computing the rest as the
geometric mean of the non-selected parts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          acompmargin(X,d=c(1,2),name="*",pos=length(d)+1,what="data")
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acompmargin_+3A_x">X</code></td>
<td>
<p>composition or dataset of compositions</p>
</td></tr>
<tr><td><code id="acompmargin_+3A_d">d</code></td>
<td>
<p>vector containing the indices xor names of the columns selected</p>
</td></tr>
<tr><td><code id="acompmargin_+3A_name">name</code></td>
<td>
<p>The new name of the amalgamation column</p>
</td></tr>
<tr><td><code id="acompmargin_+3A_pos">pos</code></td>
<td>
<p>The position where the new amalgamation column should be
stored. This defaults to the last column.</p>
</td></tr>
<tr><td><code id="acompmargin_+3A_what">what</code></td>
<td>
<p>The role of X either <code>"data"</code> for data (or means) to be
transformed or <code>"var"</code> for (acomp-clr)-variances to be transformed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The amalgamation column is simply computed by taking the
geometric mean of the non-selected components. This is
consistent with the <code><a href="#topic+acomp">acomp</a></code> approach and gives clear ternary
diagrams. However, this geometric mean is difficult to interpret.
</p>


<h3>Value</h3>

<p>A closed compositions with class <code>"acomp"</code> containing the
variables given by <code>d</code> and the the amalgamation column.  </p>


<h3>Missing Policy</h3>

<p>MNAR has the highest priority, MAR afterwards, and WZERO (BDL,SZ) values are
considered as 0 and finally reported as BDL. 
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Vera Pawlowsky-Glahn (2003) personal communication.
Universitat de Girona.
</p>
<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008)
&quot;compositions&quot;: a unified R package to analyze Compositional Data,
<em>Computers &amp; Geosciences</em>, 34 (4), pages 320-338,
doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rcompmargin">rcompmargin</a></code>, <code><a href="#topic+acomp">acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot.acomp(sa.lognormals5,margin="acomp")
plot.acomp(acompmargin(sa.lognormals5,c("Pb","Zn")))
plot.acomp(acompmargin(sa.lognormals5,c(1,2)))
</code></pre>

<hr>
<h2 id='acompscalarproduct'>inner product for datasets with a vector space structure</h2><span id='topic++25+2A+25.acomp'></span><span id='topic++25+2A+25.aplus'></span>

<h3>Description</h3>

  
<p>acomp and aplus objects are considered as (sets of) vectors. The
<code>%*%</code> is considered as the inner multiplication. An inner
multiplication with another vector is the scalar product. An inner
multiplication with a matrix is a matrix multiplication, where the
vectors are either considered as row or as column vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
x %*% y
## S3 method for class 'aplus'
x %*% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acompscalarproduct_+3A_x">x</code></td>
<td>
<p>a acomp or aplus object or a matrix interpreted in clr, ilr or ilt coordinates</p>
</td></tr>
<tr><td><code id="acompscalarproduct_+3A_y">y</code></td>
<td>
<p>a acomp or aplus object or a matrix interpreted in clr, ilr or ilt coordinates</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The operators try to mimic the behavior of <code>%*%</code> on
<code>c()</code>-vectors as inner product, applied in parallel to all row-vectors of
the dataset. Thus the product of a vector with a vector of the same
type results in the scalar product of both. For the multiplication with a matrix
each vector is considered as a row or column, whatever is more
appropriate. The matrix itself is considered as representing a linear
mapping (endomorphism) of the vector space to a space of the same type. The mapping is
represented in clr, ilr or ilt coordinates. Which of the aforementioned
coordinate systems is used is judged from the type of <var>x</var> and from
the dimensions of the <var>A</var>. 
</p>


<h3>Value</h3>

<p>Either a numeric vector containing the scalar products, or an object of
type acomp or aplus containing the vectors transformed with the given
matrix. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic++25+2A+25.rmult">%*%.rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- acomp(matrix( sqrt(1:12), ncol= 3 ))
x%*%x
A &lt;- matrix( 1:9,nrow=3)
x %*% A %*% x
x %*% A
A %*% x
A &lt;- matrix( 1:4,nrow=2)
x %*% A %*% x
x %*% A
A %*% x
x &lt;- aplus(matrix( sqrt(1:12), ncol= 3 ))
x%*%x
A &lt;- matrix( 1:9,nrow=3)
x %*% A %*% x
x %*% A
A %*% x
</code></pre>

<hr>
<h2 id='Activity10'>Activity patterns  of a statistician for 20 days</h2><span id='topic+Activity10'></span><span id='topic+DATA10'></span>

<h3>Description</h3>

<p>Proportion of a day in activity teaching, consulting, administrating, research,
other wakeful activities and sleep for 20 days are given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Activity10)
</code></pre>


<h3>Details</h3>

<p>The activity of an academic statistician were divided into 
following six categories
</p>

<table>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    teac	 </td><td style="text-align: left;"> teaching  </td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    cons	 </td><td style="text-align: left;"> consultation</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    admi	 </td><td style="text-align: left;"> administration</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    rese	 </td><td style="text-align: left;"> research</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    wake	 </td><td style="text-align: left;"> other wakeful activities</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    slee	 </td><td style="text-align: left;"> sleep
</td>
</tr>

</table>

<p>Data show the proportions of the 24 hours devoted to each activity,
recorded on each of 20 days, selected randomly from working days in alternate weeks,
so as to avoid any possible carry-over effects, such as short-sleep day being compensated
by make-up sleep on a succeeding day.
</p>
<p>The six activity may be divided into two categories 'work' comprising activities
1,2,3,4: and 'leisure' comprising activities 5 and 6.
</p>
<p>All rows sum to one.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name STATDAY.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 10, pp15.
</p>

<hr>
<h2 id='Activity31'>Activity patterns  of a statistician for 20 days</h2><span id='topic+Activity31'></span><span id='topic+DATA31'></span>

<h3>Description</h3>

<p>Proportion of a day in activity teaching, consulting, administrating, research,
other wakeful activities and sleep for 20 days are given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Activity31)
</code></pre>


<h3>Details</h3>

<p>The activity of an academic statistician were divided into 
following six categories
</p>

<table>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    teac	 </td><td style="text-align: left;"> teaching </td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    cons	 </td><td style="text-align: left;"> consultation</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    admi	 </td><td style="text-align: left;"> administration</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    rese	 </td><td style="text-align: left;"> research</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    wake	 </td><td style="text-align: left;"> other wakeful activities</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    slee	 </td><td style="text-align: left;"> sleep
  </td>
</tr>

</table>

<p>Data shows the proportions of the 24 hours devoted to each activity,
recorded on each of 20 days, selected randomly from working days in alternate weeks,
so as to avoid any possible carry-over effects, such as short-sleep day being compensated
by make-up sleep on a succeeding day.
</p>
<p>The six activity may be divided into two categories 'work' comprising activities
1,2,3,4: and 'leisure' comprising activities 5 and 6.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name ACTIVITY.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 31.
</p>

<hr>
<h2 id='alr'>Additive log ratio transform</h2><span id='topic+alr'></span><span id='topic+alrInv'></span>

<h3>Description</h3>

<p>Compute the additive log ratio transform of a (dataset of)
composition(s), and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          alr( x ,ivar=ncol(x), ... )
          alrInv( z, ...,orig=gsi.orig(z))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alr_+3A_x">x</code></td>
<td>
<p>a composition, not necessarily closed</p>
</td></tr>
<tr><td><code id="alr_+3A_z">z</code></td>
<td>
<p>the alr-transform of a composition, thus a (D-1)-dimensional
real vector</p>
</td></tr>
<tr><td><code id="alr_+3A_...">...</code></td>
<td>
<p>generic arguments. not used.</p>
</td></tr>
<tr><td><code id="alr_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked 
by the inverse transformation. It is especially used to
reconstruct the names of the parts.</p>
</td></tr>
<tr><td><code id="alr_+3A_ivar">ivar</code></td>
<td>
<p>The column to be used as denominator variable. Unfortunately
not yet supported in alrInv. The default works even if x is a vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The alr-transform maps a composition in the D-part Aitchison-simplex
non-isometrically to a D-1 dimensonal euclidian vector, treating the
last part as common denominator of the others. The data can then
be analysed in this transformation by all classical multivariate
analysis tools not relying on a distance. The interpretation of
the results is relatively simple, since the relation to the original D-1
first parts is preserved. However distance is an extremely relevant
concept in most types of analysis, where a <code><a href="#topic+clr">clr</a></code> or
<code><a href="#topic+ilr">ilr</a></code> transformation should be preferred.<br />
</p>
<p>The additive logratio transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> alr(x)_i := \ln\frac{x_i}{x_D}  </code>
</p>
<p>.
</p>


<h3>Value</h3>

<p><code>alr</code> gives the additive log ratio transform; accepts a compositional dataset
<code>alrInv</code> gives a closed composition with the given alr-transform; accepts a dataset
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+apt">apt</a></code>,
<a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- alr(c(1,2,3)))
alrInv(tmp)
unclass(alrInv(tmp)) - clo(c(1,2,3)) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(alr(cdata),pch=".")
</code></pre>

<hr>
<h2 id='amounts-class'>Class <code>"amounts"</code></h2><span id='topic+amounts-class'></span>

<h3>Description</h3>

<p>Abstract class containing all amounts classes carrying total information: <code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code> and <code><a href="#topic+ccomp">ccomp</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be created from it.</p>


<h3>Methods</h3>

<p>No methods defined with class &quot;amounts&quot; in the signature.
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compositional-class">compositional-class</a></code> for classes with relative information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("amounts")
</code></pre>

<hr>
<h2 id='AnimalVegetation'>Animal and vegetation measurement</h2><span id='topic+AnimalVegetation'></span><span id='topic+Data25'></span>

<h3>Description</h3>

<p>Areal compositions by abundance of vegetation and animals
for 50 plots in each of regions A and B.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(AnimalVegetation)
</code></pre>


<h3>Details</h3>

<p>In a regional ecology study, plots of land of equal area were inspected 
and the parts of each plot which were thick or thin in vegetation and
dense or sparse in animals were identified.
From this field work the areal proportions of each plot were calculated for
the four mutually exclusive and exhaustive categories:
thick-dense, thick-sparse, thin-dense, thin-sparse.
These sets of proportions are recorded for 50 plots from each of two different
regions A and B. 
</p>
<p>All rows sum to 1, except for some rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name ANIVEG.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 25, pp22. 
</p>

<hr>
<h2 id='aplus'>Amounts analysed in log-scale</h2><span id='topic+aplus'></span>

<h3>Description</h3>

<p>A class to analyse positive amounts in a logistic framework.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  aplus(X,parts=1:NCOL(oneOrDataset(X)),total=NA,warn.na=FALSE,
          detectionlimit=NULL,BDL=NULL,MAR=NULL,MNAR=NULL,SZ=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aplus_+3A_x">X</code></td>
<td>
<p>vector or dataset of positive numbers</p>
</td></tr>
<tr><td><code id="aplus_+3A_parts">parts</code></td>
<td>
<p>vector containing the indices  xor names of the columns to be used</p>
</td></tr>
<tr><td><code id="aplus_+3A_total">total</code></td>
<td>
<p>a numeric vectors giving the total amounts of each
dataset. </p>
</td></tr>
<tr><td><code id="aplus_+3A_warn.na">warn.na</code></td>
<td>
<p>should the user be warned in case of NA,NaN or 0
coding different types of missing values?</p>
</td></tr>
<tr><td><code id="aplus_+3A_detectionlimit">detectionlimit</code></td>
<td>
<p>a number, vector or matrix of positive
numbers giving the detection limit of all values, all columns or
each value, respectively</p>
</td></tr>
<tr><td><code id="aplus_+3A_bdl">BDL</code></td>
<td>
<p>the code for 'Below Detection Limit' in X</p>
</td></tr>
<tr><td><code id="aplus_+3A_sz">SZ</code></td>
<td>
<p>the code for 'Structural Zero' in X</p>
</td></tr>
<tr><td><code id="aplus_+3A_mar">MAR</code></td>
<td>
<p>the code for 'Missing At Random' in X</p>
</td></tr>
<tr><td><code id="aplus_+3A_mnar">MNAR</code></td>
<td>
<p>the code for 'Missing Not At Random' in X</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many multivariate datasets essentially describe amounts of D different
parts in a whole. When the whole is large in relation to the
considered parts, such that they do not exclude each other, or when
the total amount of each componenten is indeed determined by the
phenomenon under investigation and not by sampling artifacts (such as dilution
or sample preparation), then the parts can be treated as amounts rather
than as a composition (cf. <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>).
<br />
Like compositions, amounts have some important properties. Amounts are
always positive. An amount of exactly zero essentially means that we have a
substance of another quality. Different amounts - spanning different
orders of magnitude  -  are often given in
different units (ppm, ppb, g/l, vol.%, mass %, molar
fraction). Often, these amounts are also taken as indicators of
other non-measured components (e.g. K as indicator for potassium feldspar),
which might be proportional to the measured amount. 
However, in contrast to compositions, amounts
themselves do matter. Amounts are typically heavily
skewed and in many practical cases a log-transform makes their
distribution roughly symmetric, even normal.
<br />
In full analogy to Aitchison's compositions, vector
space operations are introduced for amounts: the perturbation
<code><a href="#topic+perturbe.aplus">perturbe.aplus</a></code> as a vector space addition (corresponding
to change of units), the power transformation
<code><a href="#topic+power.aplus">power.aplus</a></code> as scalar multiplication describing the law
of mass action, and a distance <code><a href="#topic+dist">dist</a></code> which is
independent of the chosen units. The induced vector space is mapped
isometrically to a classical <code class="reqn">R^D</code> by a simple log-transformation called
<code><a href="#topic+ilt">ilt</a></code>, resembling classical log transform approaches.  
<br />
The general approach in analysing aplus objects is thus to perform
classical multivariate analysis on ilt-transformed coordinates (i.e., logs)
and to backtransform or display the results in such a way that they
can be interpreted in terms of the original amounts.   
<br />
The class aplus is complemented by the <code><a href="#topic+rplus">rplus</a></code>, allowing to
analyse amounts directly as real numbers, and by the classes
<code><a href="#topic+acomp">acomp</a></code> and <code><a href="#topic+rcomp">rcomp</a></code> to analyse the same data
as compositions disregarding the total amounts, focusing on relative
weights only.
<br />
The classes rcomp, acomp, aplus, and rplus are designed as similar as
possible in order to allow direct comparison between results achieved  
by the different approaches. Especially the acomp simplex transforms
<code><a href="#topic+clr">clr</a></code>, <code><a href="#topic+alr">alr</a></code>, <code><a href="#topic+ilr">ilr</a></code> are mirrored
in the aplus class by the single bijective isometric transform <code><a href="#topic+ilt">ilt</a></code>
</p>


<h3>Value</h3>

<p>a vector of class <code>"aplus"</code> representing a vector of amounts
or a matrix of class <code>"aplus"</code> representing
multiple vectors of amounts, each vector in one row.  
</p>


<h3>Missing Policy</h3>

<p>The policy of treatment of zeroes, missing values and values 
below detecion limit is explained in depth in <a href="#topic+compositions.missing">compositions.missing</a>. 
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilt">ilt</a></code>,<code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rplus">rplus</a></code>,
<code><a href="#topic+princomp.aplus">princomp.aplus</a></code>, 
<code><a href="#topic+plot.aplus">plot.aplus</a></code>, <code><a href="#topic+boxplot.aplus">boxplot.aplus</a></code>,
<code><a href="#topic+barplot.aplus">barplot.aplus</a></code>, <code><a href="#topic+mean.aplus">mean.aplus</a></code>,
<code><a href="#topic+var.aplus">var.aplus</a></code>, <code><a href="#topic+variation.aplus">variation.aplus</a></code>,
<code><a href="#topic+cov.aplus">cov.aplus</a></code>, <code><a href="#topic+msd">msd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(aplus(sa.lognormals))
</code></pre>

<hr>
<h2 id='aplus-class'>Class <code>"aplus"</code></h2><span id='topic+aplus-class'></span><span id='topic+coerce+2Caplus+2Cdata.frame-method'></span><span id='topic+coerce+2Caplus+2Cstructure-method'></span><span id='topic+coerce+3C-+2Caplus+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>The S4-version of the data container &quot;aplus&quot; for compositional data. More information in 
<code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be directly created from it. 
This is provided to ensure that aplus objects behave as data.frame or structure under certain circumstances. Use <code><a href="#topic+aplus">aplus</a></code> to create these objects.</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Object of class <code>"list"</code> containing the data itself </p>
</dd>
<dt><code>names</code>:</dt><dd><p>Object of class <code>"character"</code> with column names </p>
</dd>
<dt><code>row.names</code>:</dt><dd><p>Object of class <code>"data.frameRowLabels"</code> with row names </p>
</dd>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code> with the class string </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+data.frame-class">data.frame</a>"</code>, directly.
Class <code>"<a href="#topic+compositional-class">compositional</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+list-class">list</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;data.frame&quot;, distance 3.
</p>


<h3>Methods</h3>


<dl>
<dt>coerce</dt><dd><p><code>signature(from = "aplus", to = "data.frame")</code>: to generate a data.frame </p>
</dd>
<dt>coerce</dt><dd><p><code>signature(from = "aplus", to = "structure")</code>: to generate a structure (i.e. a vector, matrix or array) </p>
</dd>
<dt>coerce&lt;-</dt><dd><p><code>signature(from = "aplus", to = "data.frame")</code>: to overwrite a composition with a data.frame</p>
</dd>
</dl>



<h3>Note</h3>

<p>see <code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>References</h3>

<p>see <code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("aplus")
</code></pre>

<hr>
<h2 id='aplusarithm'>vectorial arithmetic for data sets with aplus class</h2><span id='topic++2B.aplus'></span><span id='topic+-.aplus'></span><span id='topic++2A.aplus'></span><span id='topic++2F.aplus'></span><span id='topic+perturbe.aplus'></span><span id='topic+power.aplus'></span>

<h3>Description</h3>

<p>The positive vectors equipped with the perturbation (defined as
the element-wise product) as Abelian sum, and powertransform (defined as the element-wise
powering with a scalar) as scalar multiplication forms a real vector
space. These vector space operations are defined here in a similar way
to <code><a href="#topic++2B.rmult">+.rmult</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perturbe.aplus(x,y)
## S3 method for class 'aplus'
x + y
## S3 method for class 'aplus'
x - y
## S3 method for class 'aplus'
x * y
## S3 method for class 'aplus'
x / y
##  Methods for aplus
##   x+y
##   x-y
##   -x
##   x*r
##   r*x
##   x/r
power.aplus(x,r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aplusarithm_+3A_x">x</code></td>
<td>
<p>an aplus vector or dataset of vectors </p>
</td></tr>
<tr><td><code id="aplusarithm_+3A_y">y</code></td>
<td>
<p>an aplus vector or dataset of vectors </p>
</td></tr>
<tr><td><code id="aplusarithm_+3A_r">r</code></td>
<td>
<p>a numeric vector of size 1 or nrow(x)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The operators try to mimic the parallel operation of R for vectors of
real numbers to vectors of amounts, represented as matrices containing
the vectors as rows and works like the operators for <code>{<a href="#topic+rmult">rmult</a>}</code> 
</p>


<h3>Value</h3>

<p>an object of class <code>"aplus"</code> containing the result of the
corresponding operation on the vectors.  
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+rmult">rmult</a></code>, <code><a href="#topic++25+2A+25.rmult">%*%.rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- aplus(matrix( sqrt(1:12), ncol= 3 ))
x
x+x
x + aplus(1:3)
x * 1:4
1:4 * x
x / 1:4
x / 10
power.aplus(x,1:4)
</code></pre>

<hr>
<h2 id='apt'>Additive planar transform</h2><span id='topic+apt'></span><span id='topic+aptInv'></span>

<h3>Description</h3>

<p>Compute the additive planar  transform of a (dataset of)
compositions or its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          apt( x ,...)
          aptInv( z ,..., orig=gsi.orig(z))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apt_+3A_x">x</code></td>
<td>
<p>a composition or a matrix of compositions, not necessarily closed</p>
</td></tr>
<tr><td><code id="apt_+3A_z">z</code></td>
<td>
<p>the apt-transform of a composition or  a matrix of
alr-transforms of compositions</p>
</td></tr>
<tr><td><code id="apt_+3A_...">...</code></td>
<td>
<p>generic arguments, not used.</p>
</td></tr>
<tr><td><code id="apt_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked 
by the inverse transformation. It is especially used to
reconstruct the names of the parts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The apt-transform maps a composition in the D-part real-simplex
linearly to a D-1 dimensional euclidian vector. Although the
transformation does not reach the whole <code class="reqn">R^{D-1}</code>, resulting covariance
matrices are typically of full rank.
<br /> 
</p>
<p>The data can then
be analysed in this transformation by all classical multivariate
analysis tools not relying on distances. See
<code><a href="#topic+cpt">cpt</a></code> and <code><a href="#topic+ipt">ipt</a></code> for alternatives. The
interpretation of the results is easy since the relation to the first
D-1 original variables is preserved.<br />
</p>
<p>The additive planar transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> apt(x)_i := clo(x)_i, i=1,\ldots,D-1 </code>
</p>



<h3>Value</h3>

<p><code>apt</code> gives the centered planar transform,
<code>aptInv</code> gives closed compositions with the given apt-transforms
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+alr">alr</a></code>,<code><a href="#topic+cpt">cpt</a></code>,<code><a href="#topic+ipt">ipt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- apt(c(1,2,3)))
aptInv(tmp)
aptInv(tmp) - clo(c(1,2,3)) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(apt(cdata),pch=".") 
</code></pre>

<hr>
<h2 id='ArcticLake'>Artic lake sediment samples of different water depth</h2><span id='topic+ArcticLake'></span><span id='topic+Data05'></span>

<h3>Description</h3>

<p>Sand, silt and clay compositions of 39 sediment samples of different water depth
in an Arctic lake. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ArcticLake)
</code></pre>


<h3>Details</h3>

<p>Sand, silt and clay compositions of 39 sediment samples at different water depth (in meters)
in an Arctic lake. The additional feature is a concomitant variable or <em>covariate,</em>
water depth, which may account for some of the variation in the compositions.
In statistical terminology we have a multivariate regression problem with sediment composition 
as regressand and water depth as regressor.
</p>
<p>All row percentage sums to 100, except for rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name ARCTIC.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 5, pp5.
</p>

<hr>
<h2 id='arrows3D'>arrows in 3D, based on package rgl</h2><span id='topic+arrows3D'></span><span id='topic+arrows3D.default'></span>

<h3>Description</h3>

<p>adds 3-dimensional arrows to an rgl plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arrows3D(...)
## Default S3 method:
arrows3D(x0,x1,...,length=0.25,
                     angle=30,code=2,col="black",
                     lty=NULL,lwd=2,orth=c(1,0.0001,0.0000001),
                     labs=NULL,size=lwd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="arrows3D_+3A_x0">x0</code></td>
<td>
<p>a matrix or vector giving the starting points of the arrows</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_x1">x1</code></td>
<td>
<p>a matrix or vector giving the end points of the arrows</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_...">...</code></td>
<td>
<p>additional plotting parameters as described in <code>rgl::material3d</code>

</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_length">length</code></td>
<td>
<p>a number giving the length of the arrowhead</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_angle">angle</code></td>
<td>
<p>numeric giving the angle of the arrowhead</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_code">code</code></td>
<td>
<p>0=no arrowhead,1=arrowhead at x0,2=arrowhead at
x1,3=double headed</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_col">col</code></td>
<td>
<p>the color of the arrow</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_lty">lty</code></td>
<td>
<p>Not implemented, here for compatibility reasons with
<code>arrows</code></p>
</td></tr>
<tr><td><code id="arrows3D_+3A_lwd">lwd</code></td>
<td>
<p>line width in pixels</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_orth">orth</code></td>
<td>
<p>the flat side of the arrow is not unique by x0 and
x1. This ambiguity is solved in a way that the arrow seams as wide
as possible from the viewing direction orth.</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_labs">labs</code></td>
<td>
<p>labels to be plotted to the endpoints of the arrows</p>
</td></tr>
<tr><td><code id="arrows3D_+3A_size">size</code></td>
<td>
<p>size of the plotting symbol</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is called to plot arrows into an rgl plot. The size of
the arrow head is given in a absolute way. Therefore it is
important to give the right scale for the length, to see the arrow head and
that it does not fill the whole window. 
</p>


<h3>Value</h3>

<p>the 3D plotting coordinates of the tips of the arrows displayed, 
returned invisibly
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>



<p><code><a href="#topic+plot3D">plot3D</a></code>,
<code>rgl::points3d</code>, <code>graphics::plot</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- cbind(rnorm(10),rnorm(10),rnorm(10))
if(requireNamespace("rgl", quietly = TRUE)) {
  plot3D(x)
  x0 &lt;- x*0
  arrows3D(x0,x)
} ## this function requires package 'rgl'
</code></pre>

<hr>
<h2 id='as.data.frame'>Convert &quot;compositions&quot; classes to data frames or matrices</h2><span id='topic+as.data.frame.acomp'></span><span id='topic+as.data.frame.rcomp'></span><span id='topic+as.data.frame.aplus'></span><span id='topic+as.data.frame.rplus'></span><span id='topic+as.data.frame.rmult'></span><span id='topic+as.data.frame.ccomp'></span><span id='topic+as.matrix.rmult'></span>

<h3>Description</h3>

<p>Convert a compositional object to a dataframe
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
as.data.frame(x,...)
## S3 method for class 'rcomp'
as.data.frame(x,...)
## S3 method for class 'aplus'
as.data.frame(x,...)
## S3 method for class 'rplus'
as.data.frame(x,...)
## S3 method for class 'rmult'
as.data.frame(x,...)
## S3 method for class 'ccomp'
as.data.frame(x,...)
## S3 method for class 'rmult'
as.matrix(x,...)

          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.frame_+3A_x">x</code></td>
<td>
<p>an object to be converted to a dataframe</p>
</td></tr>
<tr><td><code id="as.data.frame_+3A_...">...</code></td>
<td>
<p>additional arguments are not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame containing the given data, or (for rmult only) as matrix.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
as.data.frame(acomp(sa.groups))
# The central perpose of providing this command is that the following
# works properly:
data.frame(acomp(sa.groups),groups=sa.groups.area)
</code></pre>

<hr>
<h2 id='axis3D'>Drawing a 3D coordiante system to a plot, based on package rgl</h2><span id='topic+axis3D'></span>

<h3>Description</h3>

<p>Adds a coordinate system to a 3D rgl graphic. In future releases,
functionality to add tickmarks will be (hopefully) provided. 
Now, it is just a system of arrows giving the
directions of the three axes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>axis3D(axis.origin=c(0,0,0),axis.scale=1,axis.col="gray",vlabs=c("x","y","z"),
       vlabs.col=axis.col,bbox=FALSE,axis.lwd=2,axis.len=mean(axis.scale)/10,
       axis.angle=30,orth=c(1,0.0001,0.000001),axes=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="axis3D_+3A_axis.origin">axis.origin</code></td>
<td>
<p>The location where to put the origin of the
coordinate arrows typicall either 0, the minimum or the mean of the
dataset</p>
</td></tr>
<tr><td><code id="axis3D_+3A_axis.scale">axis.scale</code></td>
<td>
<p>either a number or a 3D vector giving the length of
the arrows for the axis in the coordiantes of the plot</p>
</td></tr>
<tr><td><code id="axis3D_+3A_axis.col">axis.col</code></td>
<td>
<p>Color to plot the coordinate system</p>
</td></tr>
<tr><td><code id="axis3D_+3A_vlabs">vlabs</code></td>
<td>
<p>The names of the axes, plotted at the end</p>
</td></tr>
<tr><td><code id="axis3D_+3A_vlabs.col">vlabs.col</code></td>
<td>
<p>color for the axes labels</p>
</td></tr>
<tr><td><code id="axis3D_+3A_bbox">bbox</code></td>
<td>
<p>boolean, whether to plot a bounding box</p>
</td></tr>
<tr><td><code id="axis3D_+3A_axis.lwd">axis.lwd</code></td>
<td>
<p>line width of the axes</p>
</td></tr>
<tr><td><code id="axis3D_+3A_axis.angle">axis.angle</code></td>
<td>
<p>angle of the arrow heads</p>
</td></tr>
<tr><td><code id="axis3D_+3A_axis.len">axis.len</code></td>
<td>
<p>length of the arrow heads</p>
</td></tr>
<tr><td><code id="axis3D_+3A_orth">orth</code></td>
<td>
<p>the orth argument of <code><a href="#topic+arrows3D">arrows3D</a></code>  </p>
</td></tr>
<tr><td><code id="axis3D_+3A_axes">axes</code></td>
<td>
<p>a boolean, wether to plot the axes</p>
</td></tr>
<tr><td><code id="axis3D_+3A_...">...</code></td>
<td>
<p>these arguments are passed to arrows3D as

<code>rgl::material3d</code> arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is called to plot a coordiante system consisting of
arrows into an rgl plot.  
</p>


<h3>Value</h3>

<p>Nothing
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>



<p><code>rgl::points3d</code>, <code>graphics::plot</code>,
<code><a href="#topic+plot3D">plot3D</a></code>,<code><a href="#topic+arrows3D">arrows3D</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- cbind(rnorm(10),rnorm(10),rnorm(10))
if(requireNamespace("rgl", quietly = TRUE)) {
  plot3D(x)
  x0 &lt;- x*0
  axis3D()
} ## this function requires package 'rgl'
</code></pre>

<hr>
<h2 id='backtransform'>Automatic common backtransformation for compositions</h2><span id='topic+backtransform'></span><span id='topic+backtransform.rmult'></span><span id='topic+gsi.orig'></span><span id='topic+gsi.getV'></span>

<h3>Description</h3>

<p>Functions to automatically determine and compute the relevant back-transformation
for a rmult object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          backtransform(x, as=x)
          backtransform.rmult(x, as=x)
          gsi.orig(x,y=NULL)
          gsi.getV(x,y=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backtransform_+3A_x">x</code></td>
<td>
<p>an rmult object to be backtransformed; for both <code>gsi.*</code> functions: an rmult object to extract the relevant information from</p>
</td></tr>
<tr><td><code id="backtransform_+3A_as">as</code></td>
<td>
<p>an rmult object previously obtained with any compositional 
transformation of this package.</p>
</td></tr>
<tr><td><code id="backtransform_+3A_y">y</code></td>
<td>
<p>for both <code>gsi.*</code> functions: an alternative object to extract the relevant information
from, in case that <code>x</code> does not include it</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The general idea of this package is to analyse the same data with
different geometric concepts, in a fashion as similar as possible. For each of the
four concepts there exists a family of transforms expressing the geometry
in aan appropriate manner. Transformed data can be further analysed, and certain
results may be back-transformed to the original scale. These functions take 
care of tracking, constructing and computing the inverse transformation, whichever was the original
geometry and forward transformation used.
</p>


<h3>Value</h3>

<p>For functions <code>backtransform</code> or <code>backtransform.rmult</code>, a corresponding matrix or vector containing the backtransformation of <code>x</code>. Efforts are taken to keep any extra attributes (beyond, &quot;dim&quot;, &quot;dimnames&quot; and &quot;class&quot;) the argument &quot;x&quot; may have   \
For function <code>gsi.orig</code>, the original data with a compositional class, if it exists (or NULL otherwise).  \
For function <code>gsi.getV</code>, the transposed, inverse matrix of log-contrasts originally used to forward transform the original composition <code>orig</code> to its coefficients/coordinates. If it does not exists, the output is NULL.
</p>


<h3>Author(s)</h3>

<p>R. Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdt">cdt</a></code>, <code><a href="#topic+idt">idt</a></code>, <code><a href="#topic+clr">clr</a></code>, <code><a href="#topic+cpt">cpt</a></code>, <code><a href="#topic+ilt">ilt</a></code>, <code><a href="#topic+iit">iit</a></code>, <code><a href="#topic+ilr">ilr</a></code>, <code><a href="#topic+ipt">ipt</a></code>, <code><a href="#topic+alr">alr</a></code>, <code><a href="#topic+apt">apt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- acomp(1:5)
x
backtransform(ilr(x))
backtransform(clr(x))
backtransform(idt(x))
backtransform(cdt(x))
backtransform(alr(x))
</code></pre>

<hr>
<h2 id='balance'>Compute balances for a compositional dataset.</h2><span id='topic+balanceBase'></span><span id='topic+balance01'></span><span id='topic+balance01.acomp'></span><span id='topic+balance01.rcomp'></span><span id='topic+balance'></span><span id='topic+balance.acomp'></span><span id='topic+balance.rcomp'></span><span id='topic+balance.aplus'></span><span id='topic+balance.rplus'></span><span id='topic+balanceBase.acomp'></span><span id='topic+balanceBase.rcomp'></span><span id='topic+balanceBase.aplus'></span><span id='topic+balanceBase.rplus'></span>

<h3>Description</h3>

<p>Compute balances in a compositional dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>balance(X,...)
## S3 method for class 'acomp'
balance(X,expr,...)
## S3 method for class 'rcomp'
balance(X,expr,...)
## S3 method for class 'aplus'
balance(X,expr,...)
## S3 method for class 'rplus'
balance(X,expr,...)
balance01(X,...)
## S3 method for class 'acomp'
balance01(X,expr,...)
## S3 method for class 'rcomp'
balance01(X,expr,...)
balanceBase(X,...)
## S3 method for class 'acomp'
balanceBase(X,expr,...)
## S3 method for class 'rcomp'
balanceBase(X,expr,...)
## S3 method for class 'acomp'
balanceBase(X,expr,...)
## S3 method for class 'rcomp'
balanceBase(X,expr,...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="balance_+3A_x">X</code></td>
<td>
<p> compositional dataset (or optionally just its column names
for balanceBase)</p>
</td></tr>
<tr><td><code id="balance_+3A_expr">expr</code></td>
<td>
<p> a <code>~</code> formula using the column names of X as
variables and
seperating them by <code>/</code> and organize by paranthesis
<code>()</code>. <code>:</code> and <code>*</code> can be used instead of <code>/</code>
when the corresponding balance should not be created. <code>-</code> can
be used as an synonym to <code>/</code> in the real geometries. <code>1</code>
can be used in the unclosed geometries to level against a constant. 
</p>
</td></tr>
<tr><td><code id="balance_+3A_...">...</code></td>
<td>
<p>for future perposes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>acomp</code>-compositions balances are defined as orthogonal
projections representing the log ratio of the geometric means of
subsets of elements. Based on a recursive subdivision (provided by the
<code>expr=</code>) this projections provide a (complete or incomplete) basis of
the clr-plane. The basis is given by the <code>balanceBase</code>
functions. The transform is given by the <code>balance</code> functions. The
<code>balance01</code> functions are a backtransform of the balances to the
amount of the first portion if this was the only balance in a 2
element composition, providing an &quot;interpretation&quot; for the values of
the balances.
</p>
<p>The package tries to give similar concepts for the other scales.
For <code>rcomp</code> objects the concept is mainly unchanges but augmented
by a virtual component 1, which always has portion 1. 
</p>
<p>For
<code>rcomp</code> objects, we choose not a &quot;orthogonal&quot; transformation
since such a concept anyway does not really exist in the given space,
but merily use the difference of one subset to the other. The
balance01 is than not really a transform of the balance but simply the
portion of the first group of parts in all contrasted parts. 
</p>
<p>For <code>rplus</code> objects we just used an analog to generalisation from
the <code>rcomp</code> defintion as <code>aplus</code> is generalized from
<code>acomp</code>. However at this time we have no idea wether this has any
usefull interpretation.
</p>


<h3>Value</h3>

<table>
<tr><td><code>balance</code></td>
<td>
<p>a matrix (or vector) with the corresponding balances
of the dataset.</p>
</td></tr>
<tr><td><code>balance01</code></td>
<td>
<p>a matrix (or vector) with the corresponding balances
in the dataset transformed in the given geometry to a value between
0 and 1.</p>
</td></tr>
<tr><td><code>balanceBase</code></td>
<td>
<p>a matrix (or vector) with column vectors giving the
transform in the cdt-transform used to achiev the correponding
balances. </p>
</td></tr>
</table>


<h3>References</h3>

<p><a href="https://ima.udg.edu/Activitats/CoDaWork08/">https://ima.udg.edu/Activitats/CoDaWork08/</a> Papers of Boogaart and Tolosana
<a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a> Paper of Egozcue
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+ipt">ipt</a></code>, <code><a href="#topic+ilrBase">ilrBase</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- rnorm(100)
Y &lt;- rnorm.acomp(100,acomp(c(A=1,B=1,C=1)),0.1*diag(3))+acomp(t(outer(c(0.2,0.3,0.4),X,"^")))
colnames(Y) &lt;- c("A","B","C")

subComps &lt;- function(X,...,all=list(...)) {
  X &lt;- oneOrDataset(X)
  nams &lt;- sapply(all,function(x) paste(x[[2]],x[[3]],sep=","))
  val  &lt;- sapply(all,function(x){
              a = X[,match(as.character(x[[2]]),colnames(X)) ]
              b = X[,match(as.character(x[[2]]),colnames(X)) ]
              c = X[,match(as.character(x[[3]]),colnames(X)) ] 
              return(a/(b+c))
             }) 
  colnames(val)&lt;-nams
  val
}
pairs(cbind(ilr(Y),X),panel=function(x,y,...) {points(x,y,...);abline(lm(y~x))})
pairs(cbind(balance(Y,~A/B/C),X),panel=function(x,y,...) {points(x,y,...);abline(lm(y~x))})

pairwisePlot(balance(Y,~A/B/C),X)
pairwisePlot(X,balance(Y,~A/B/C),panel=function(x,y,...) {plot(x,y,...);abline(lm(y~x))})
pairwisePlot(X,balance01(Y,~A/B/C))
pairwisePlot(X,subComps(Y,A~B,A~C,B~C))



balance(rcomp(Y),~A/B/C)
balance(aplus(Y),~A/B/C)
balance(rplus(Y),~A/B/C)



</code></pre>

<hr>
<h2 id='barplot.acomp'>Bar charts of amounts</h2><span id='topic+barplot.acomp'></span><span id='topic+barplot.rcomp'></span><span id='topic+barplot.aplus'></span><span id='topic+barplot.rplus'></span><span id='topic+barplot.ccomp'></span>

<h3>Description</h3>

<p>Compositions and amounts dispalyed as bar plots. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
barplot(height,...,legend.text=TRUE,beside=FALSE,total=1,
plotMissings=TRUE,missingColor="red",missingPortion=0.01)
## S3 method for class 'rcomp'
barplot(height,...,legend.text=TRUE,beside=FALSE,total=1,
plotMissings=TRUE,missingColor="red",missingPortion=0.01)
## S3 method for class 'aplus'
barplot(height,...,legend.text=TRUE,beside=TRUE,total=NULL,
plotMissings=TRUE,missingColor="red",missingPortion=0.01)
## S3 method for class 'rplus'
barplot(height,...,legend.text=TRUE,beside=TRUE,total=NULL,
plotMissings=TRUE,missingColor="red",missingPortion=0.01)
## S3 method for class 'ccomp'
barplot(height,...,legend.text=TRUE,beside=FALSE,total=1,
plotMissings=TRUE,missingColor="red",missingPortion=0.01)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="barplot.acomp_+3A_height">height</code></td>
<td>
<p>an acomp, rcomp, aplus, or rplus object giving amounts
to be displayed</p>
</td></tr>
<tr><td><code id="barplot.acomp_+3A_...">...</code></td>
<td>
<p>further graphical parameters as in
<code><a href="graphics.html#topic+barplot">barplot</a></code></p>
</td></tr>
<tr><td><code id="barplot.acomp_+3A_legend.text">legend.text</code></td>
<td>
<p>same as legend.text in <code><a href="graphics.html#topic+barplot">barplot</a></code></p>
</td></tr>
<tr><td><code id="barplot.acomp_+3A_beside">beside</code></td>
<td>
<p>same as beside in <code><a href="graphics.html#topic+barplot">barplot</a></code></p>
</td></tr>
<tr><td><code id="barplot.acomp_+3A_total">total</code></td>
<td>
<p>The total to be used in displaying the composition,
typically 1, 100 or the number of parts. If NULL no normalisation
takes place.</p>
</td></tr>
<tr><td><code id="barplot.acomp_+3A_plotmissings">plotMissings</code></td>
<td>
<p>logical: shall missings be annotate in the plot</p>
</td></tr>
<tr><td><code id="barplot.acomp_+3A_missingcolor">missingColor</code></td>
<td>
<p>color to draw missings</p>
</td></tr>
<tr><td><code id="barplot.acomp_+3A_missingportion">missingPortion</code></td>
<td>
<p>The space portion to be reserved for missings</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are essentially light-weighted wrappers for
<code><a href="graphics.html#topic+barplot">barplot</a></code>, just adding an adequate default
behavior for each of the scales. The missingplot functionality will
work well with the default settings.
</p>
<p>If <code>plotMissings</code> is true, there will be an additional portion
introduced, which is not counted in the total. This might make the
plots looking less nice, however they make clear to the viewer that it
is by no means clear how the rest of the plot should be interpreted
and that the missing value really casts some unsureness on the rest of
the data.  
</p>


<h3>Value</h3>

<p>A numeric vector (or matrix, when <code>beside = TRUE</code>) giving
the coordinates of all the bar midpoints drawn, as in
<code><a href="graphics.html#topic+barplot">barplot</a></code> </p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>,   <code><a href="#topic+rplus">rplus</a></code>
<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+plot.acomp">plot.acomp</a></code>,
<code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
barplot(mean(acomp(sa.lognormals[1:10,])))
barplot(mean(rcomp(sa.lognormals[1:10,])))
barplot(mean(aplus(sa.lognormals[1:10,])))
barplot(mean(rplus(sa.lognormals[1:10,])))

barplot(acomp(sa.lognormals[1:10,]))
barplot(rcomp(sa.lognormals[1:10,]))
barplot(aplus(sa.lognormals[1:10,]))
barplot(rplus(sa.lognormals[1:10,]))

barplot(acomp(sa.tnormals))
</code></pre>

<hr>
<h2 id='Bayesite'>Permeabilities of bayesite</h2><span id='topic+Bayesite'></span><span id='topic+Data21'></span>

<h3>Description</h3>

<p>Relation of mechanical properties of a new fibreboard with its composition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Bayesite)
</code></pre>


<h3>Details</h3>

<p>In the development of bayesite, a new fibreboard,
experiments were conducted to obtain some insight into the nature of
the relationship of its permeability to the mix of its four ingredients
</p>

<table>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> A: </td><td style="text-align: left;"> short fibres,</td>
</tr>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> B: </td><td style="text-align: left;"> medium fibres,</td>
</tr>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> C: </td><td style="text-align: left;"> long fibres,</td>
</tr>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> D: </td><td style="text-align: left;"> binder,
</td>
</tr>

</table>

<p>and the pressure of which these are bonded. The results of 21 
such experiments are reported. It is required to investigate the
dependence of permeability of mixture and bonding pressure.
</p>
<p>All 4-part compositions sum to one.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name BAYESITE.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 21, pp21.
</p>

<hr>
<h2 id='binary'>Treating binary and g-adic numbers</h2><span id='topic+binary'></span><span id='topic+bit'></span><span id='topic+bit.numeric'></span><span id='topic+bit.character'></span><span id='topic+bit+3C-'></span><span id='topic+bit+3C-.numeric'></span><span id='topic+bit+3C-.character'></span><span id='topic+maxBit'></span><span id='topic+maxBit.numeric'></span><span id='topic+maxBit.character'></span><span id='topic+bitCount'></span><span id='topic+gsi.orSum'></span><span id='topic+whichBits'></span><span id='topic+binary2logical'></span><span id='topic+unbinary'></span><span id='topic+gadic'></span>

<h3>Description</h3>

<p>Allows the access to individual digits in binary (and general
g-adic) numbers. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binary(x,mb=max(maxBit(x,g)),g=2)
unbinary(x,g=2)
bit(x,b,g=2)                       
## S3 method for class 'numeric'
bit(x,b=0:maxBit(x,g),g=2)
## S3 method for class 'character'
bit(x,b=0:maxBit(x,g),g=2)
bit(x,b,g=2) &lt;- value                      
## S3 replacement method for class 'numeric'
bit(x,b=0:maxBit(x,g),g=2) &lt;- value
## S3 replacement method for class 'character'
bit(x,b=0:maxBit(x,g),g=2) &lt;- value
maxBit(x,g=2)
## S3 method for class 'numeric'
maxBit(x,g=2)
## S3 method for class 'character'
maxBit(x,g=2)
bitCount(x,mb=max(maxBit(x,g)),g=2)
gsi.orSum(...,g=2)
whichBits(x,mb=max(maxBit(x,g)),g=2,values=c(TRUE))
binary2logical(x,mb=max(maxBit(x,g)),g=2,values=c(TRUE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binary_+3A_x">x</code></td>
<td>
<p>a number either represented a g-adic character string or as a
integeral numeric value</p>
</td></tr>
<tr><td><code id="binary_+3A_b">b</code></td>
<td>
<p>the indicies of the bits to be processes. The least
significant bit has index 0.</p>
</td></tr>
<tr><td><code id="binary_+3A_mb">mb</code></td>
<td>
<p>maximal bit. The index of the most significant bit to be treated</p>
</td></tr>
<tr><td><code id="binary_+3A_g">g</code></td>
<td>
<p>the base of the g-adic representation. 2 corresponds to
binary numbers, 8 to octal numbers, 16 to hexadecimal numbers. g is
limited by 36. </p>
</td></tr>
<tr><td><code id="binary_+3A_value">value</code></td>
<td>
<p> a vector of bit values to be selected or setted. </p>
</td></tr>
<tr><td><code id="binary_+3A_values">values</code></td>
<td>
<p> a vector of bit values that should be considered as TRUE. </p>
</td></tr>
<tr><td><code id="binary_+3A_...">...</code></td>
<td>
<p>some binary numbers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These routines are primerily intended to manipulate g-adic numbers for
user interface purposes and condensed representation of
information. They are not intended for a long number arithmetic. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>binary</code></td>
<td>
<p>returns a standard binary (or g-adic) character representation of
the number</p>
</td></tr>
<tr><td><code>unbinary</code></td>
<td>
<p>returns a binary (or g-adic) representation of
the number</p>
</td></tr>
<tr><td><code>bit</code></td>
<td>
<p>returns the values of the requested bits. The values are
returned as a logical vector for binary numbers an as numeric digit
values for other g-adic numbers.</p>
</td></tr>
<tr><td><code>maxBit</code></td>
<td>
<p>returns the most significant bit represented in the number. This is
the highest bit set in numeric numbers and the highest actually given
character in a character representation. </p>
</td></tr>
<tr><td><code>bitCount</code></td>
<td>
<p>returns the g-adic crossfoot of the number. For a binary
number this is the number of bits set</p>
</td></tr>
<tr><td><code>gsi.orSum</code></td>
<td>
<p> Only works for binary numbers and does a parallel or
on each of the bits for a list of binary numbers.</p>
</td></tr>
<tr><td><code>whichBits</code></td>
<td>
<p>returns the indices of the bits acutally set (or more
precisely of the bits with value in <code>values</code>)</p>
</td></tr>
<tr><td><code>binary2logical</code></td>
<td>
<p>returns the a true false vector of the bits
acutally set (or more
precisely of the bits with value in <code>values</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+outlierplot">outlierplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(x&lt;-unbinary("10101010"))
(y&lt;-binary(x))
bit(x,1:3)
bit(y,0:3)
maxBit(x)
maxBit(y)
whichBits(x)
whichBits(y)
binary2logical(y)
bit(x) 
bit(y) 
gsi.orSum(y,1)
bitCount(x)
bitCount(y)
bit(x,2)&lt;-1
x
bit(y,2)&lt;-1
y

</code></pre>

<hr>
<h2 id='biplot3D'>Three-dimensional biplots, based on package rgl</h2><span id='topic+biplot3D'></span><span id='topic+biplot3D.default'></span><span id='topic+biplot3D.princomp'></span>

<h3>Description</h3>

<p>Plots variables and cases in the same plot, based on a principal
component analysis. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biplot3D(x,...)
## Default S3 method:
biplot3D(x,y,var.axes=TRUE,col=c("green","red"),cex=c(2,2),
            xlabs = NULL, ylabs = NULL, expand = 1,arrow.len = 0.1,
            ...,add=FALSE)
 ## S3 method for class 'princomp'
biplot3D(x,choices=1:3,scale=1,...,
            comp.col=1,comp.labs=paste("Comp.",1:3),
            scale.scores=lambda[choices]^(1-scale),
            scale.var=scale.comp, scale.comp=sqrt(lambda[choices]), 
            scale.disp=1/scale.comp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biplot3D_+3A_x">x</code></td>
<td>
<p>princomp object or matrix of point locations to be drawn
(typically, cases)</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_choices">choices</code></td>
<td>
<p>Which principal components should be used?</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_scale">scale</code></td>
<td>
<p>a scaling parameter like in <code><a href="stats.html#topic+biplot">biplot</a></code></p>
</td></tr>
<tr><td><code id="biplot3D_+3A_scale.scores">scale.scores</code></td>
<td>
<p>a vector giving the scaling applied to the scores</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_scale.var">scale.var</code></td>
<td>
<p>a vector giving the scaling applied to the variables</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_scale.comp">scale.comp</code></td>
<td>
<p>a vector giving the scaling applied to the unit length
of each component</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_scale.disp">scale.disp</code></td>
<td>
<p>a vector giving the scaling of the display in the
directions of the components</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_comp.col">comp.col</code></td>
<td>
<p>color to draw the axes of the components, defaults to black</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_comp.labs">comp.labs</code></td>
<td>
<p>labels for the components</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_...">...</code></td>
<td>
<p>further plotting parameters as defined in 
<code>rgl::material3d</code></p>
</td></tr>
<tr><td><code id="biplot3D_+3A_y">y</code></td>
<td>
<p>matrix of  second point/arrow-head locations (typically, variables)</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_var.axes">var.axes</code></td>
<td>
<p>logical, TRUE draws arrows and FALSE points for y</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_col">col</code></td>
<td>
<p>vector/list of two elements the first giving the
color/colors for the first data set and the second giving
color/colors for the second data set.</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_cex">cex</code></td>
<td>
<p>vector/list of two elements the first giving the
size for the first data set and the second giving
size for the second data set.</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_xlabs">xlabs</code></td>
<td>
<p>labels to be plotted at x-locations</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_ylabs">ylabs</code></td>
<td>
<p>labels to be plotted at y-locations</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_expand">expand</code></td>
<td>
<p>the relative expansion of the y data set with respect to
x</p>
</td></tr>
<tr><td><code id="biplot3D_+3A_arrow.len">arrow.len</code></td>
<td>
<p>The length of the arrows as defined in <code><a href="#topic+arrows3D">arrows3D</a></code></p>
</td></tr>
<tr><td><code id="biplot3D_+3A_add">add</code></td>
<td>
<p>logical, adding to existing plot or making a new one?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This &quot;biplot&quot; is a triplot, relating data, variables and principal
components. The relative scaling of the components is still
experimental, meant to mimic the behavior of classical
biplots.
</p>


<h3>Value</h3>

<p>the 3D plotting coordinates of the tips of the arrows of the variables 
displayed, returned invisibly
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pc &lt;- princomp(acomp(sa.lognormals5))
pc
summary(pc)
plot(pc)      #plot(pc,type="screeplot")
biplot(pc)
if(requireNamespace("rgl", quietly = TRUE)) {
  biplot3D(pc)
} ## this function requires package 'rgl'

</code></pre>

<hr>
<h2 id='Blood23'>Blood samples</h2><span id='topic+Blood23'></span><span id='topic+Data23'></span>

<h3>Description</h3>

<p>Percentage of different leukocytes in blood samples of ten patients,
determined by four different methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Blood23)
</code></pre>


<h3>Details</h3>

<p>In a comparative study of four different methods of assessing leukocytes
composition of a blood sample, aliquots of blood samples from ten patients were assessed
by the four methods. Data show the percentage in the 40 analyses of:
</p>

<table>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;"> P: </td><td style="text-align: left;"> polymorphonuclear leukocytes,</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;"> S: </td><td style="text-align: left;"> small lymphocytes,</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;"> L: </td><td style="text-align: left;"> large mononuclears.
  </td>
</tr>

</table>

<p>All rows sum to 100.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name BLOOD.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 23, pp22. 
</p>

<hr>
<h2 id='Boxite'>Compositions and depth of 25 specimens of boxite</h2><span id='topic+Boxite'></span><span id='topic+Data03'></span>

<h3>Description</h3>

<p>A mineral compositions of 25 rock specimens of boxite type.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite, as well as the depth of location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Boxite)
</code></pre>


<h3>Details</h3>

<p>A mineral compositions of 25 rock specimens of boxite type are given.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite, and the recorded depth of location
of each specimen. We abbreviate the minerals names to A, B, C, D, E.
</p>
<p>All row percentage sums to 100, except the 6-th 102.3 and the 10-th 99.9.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name BOXITE.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 3, pp4.
</p>

<hr>
<h2 id='boxplot'>Displaying compositions and amounts with box-plots</h2><span id='topic+boxplot.acomp'></span><span id='topic+boxplot.rcomp'></span><span id='topic+boxplot.rplus'></span><span id='topic+boxplot.aplus'></span><span id='topic+vp.boxplot'></span><span id='topic+vp.logboxplot'></span>

<h3>Description</h3>

<p>For the different interpretations of amounts or compositional data, a different type of
boxplot is feasible. Thus different boxplots are drawn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
boxplot(x,fak=NULL,...,
                         xlim=NULL,ylim=NULL,log=TRUE,
                         panel=vp.logboxplot,dots=!boxes,boxes=TRUE,
                          notch=FALSE,
                          plotMissings=TRUE,
                          mp=~simpleMissingSubplot(missingPlotRect,
                                                missingInfo,c("NM","TM",cn))
                          )
## S3 method for class 'rcomp'
boxplot(x,fak=NULL,...,
                         xlim=NULL,ylim=NULL,log=FALSE,
                         panel=vp.boxplot,dots=!boxes,boxes=TRUE,
                          notch=FALSE,
                          plotMissings=TRUE,
                          mp=~simpleMissingSubplot(missingPlotRect,
                                                missingInfo,c("NM","TM",cn)))
## S3 method for class 'aplus'
boxplot(x,fak=NULL,...,log=TRUE,
                          plotMissings=TRUE,
                          mp=~simpleMissingSubplot(missingPlotRect,
                                                   missingInfo,
                                                   names(missingInfo)))
## S3 method for class 'rplus'
boxplot(x,fak=NULL,...,ylim=NULL,log=FALSE,
                          plotMissings=TRUE,
                          mp=~simpleMissingSubplot(missingPlotRect,
                                                   missingInfo,
                                                   names(missingInfo)))
vp.boxplot(x,y,...,dots=FALSE,boxes=TRUE,xlim=NULL,ylim=NULL,log=FALSE,
                          notch=FALSE,plotMissings=TRUE,
                          mp=~simpleMissingSubplot(missingPlotRect,
                                                   missingInfo,c("NM","TM",cn)),
                          missingness=attr(y,"missingness") ) 
vp.logboxplot(x,y,...,dots=FALSE,boxes=TRUE,xlim,ylim,log=TRUE,notch=FALSE,
                          plotMissings=TRUE, 
                          mp=~simpleMissingSubplot(missingPlotRect,
                                                   missingInfo,c("NM","TM",cn)),
                          missingness=attr(y,"missingness")) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boxplot_+3A_x">x</code></td>
<td>
<p>a data set</p>
</td></tr>
<tr><td><code id="boxplot_+3A_fak">fak</code></td>
<td>
<p>a factor to split the data set, not yet implemented in aplus
and rplus</p>
</td></tr>
<tr><td><code id="boxplot_+3A_xlim">xlim</code></td>
<td>
<p>x-limits of the plot.</p>
</td></tr>
<tr><td><code id="boxplot_+3A_ylim">ylim</code></td>
<td>
<p>y-limits of the plot.</p>
</td></tr>
<tr><td><code id="boxplot_+3A_log">log</code></td>
<td>
<p>logical indicating whether ploting should be done on log
scale</p>
</td></tr>
<tr><td><code id="boxplot_+3A_panel">panel</code></td>
<td>
<p>the panel function to be used or a list of multiple panel
functions</p>
</td></tr>
<tr><td><code id="boxplot_+3A_...">...</code></td>
<td>
<p>further graphical parameters</p>
</td></tr>
<tr><td><code id="boxplot_+3A_dots">dots</code></td>
<td>
<p>a logical indicating whether the points should be drawn</p>
</td></tr>  
<tr><td><code id="boxplot_+3A_boxes">boxes</code></td>
<td>
<p>a logical indicating whether the boxes should be drawn</p>
</td></tr>
<tr><td><code id="boxplot_+3A_y">y</code></td>
<td>
<p>used by pairs</p>
</td></tr>
<tr><td><code id="boxplot_+3A_notch">notch</code></td>
<td>
<p>logical, should the boxes be notched?</p>
</td></tr>
<tr><td><code id="boxplot_+3A_plotmissings">plotMissings</code></td>
<td>
<p>Logical indicating that missings should be
displayed.</p>
</td></tr>
<tr><td><code id="boxplot_+3A_mp">mp</code></td>
<td>
<p>A formula providing a function call, which will be evaluated
within each panel with missings to plot the missingness situation. The
call can use the variables <code>missingPlotRect</code>, which provides a
rectangle to plot the information to in a par(&quot;usr&quot;) like
specification. In the r<code>X</code> is the current data </p>
</td></tr>
<tr><td><code id="boxplot_+3A_missingness">missingness</code></td>
<td>
<p>The missingness information as a result from
<code><a href="#topic+missingType">missingType</a></code> of the full data information the panels could base there
missing plots on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>boxplot.aplus</code> and <code>boxplot.rplus</code> are wrappers of <code><a href="graphics.html#topic+bxp">bxp</a></code>, 
which just take into account the possible logarithmic scale of the data. <br />
</p>
<p><code>boxplot.acomp</code> and <code>boxplot.rcomp</code> generate a matrix of box-plots, where 
each cell represents the difference between the row and column variables. Such 
difference is respectively computed as a log-ratio and a rest.<br />
</p>
<p><code>vp.boxplot</code> and <code>vp.logboxplot</code> are only used as panel functions. 
They should not be directly called.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>, <code><a href="#topic+qqnorm.acomp">qqnorm.acomp</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
boxplot(acomp(sa.lognormals))
boxplot(rcomp(sa.lognormals))
boxplot(aplus(sa.lognormals))
boxplot(rplus(sa.lognormals))
# And now with missing!!!
boxplot(acomp(sa.tnormals))

</code></pre>

<hr>
<h2 id='ccomp'>Count compositions</h2><span id='topic+ccomp'></span>

<h3>Description</h3>

<p>A class providing the means to analyse count compositions understood
as Poisson or multinomial realisation, where the portions are given by
an unkown Aitchison compositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    ccomp(X,parts=1:NCOL(oneOrDataset(X)),total=NA,warn.na=FALSE,
            detectionlimit=NULL,BDL=NULL,MAR=NULL,MNAR=NULL,SZ=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ccomp_+3A_x">X</code></td>
<td>
<p>composition or dataset of compositions</p>
</td></tr>
<tr><td><code id="ccomp_+3A_parts">parts</code></td>
<td>
<p>vector containing the indices xor names of the columns to be used</p>
</td></tr>
<tr><td><code id="ccomp_+3A_total">total</code></td>
<td>
<p>the total amount to be used, typically 1 or 100</p>
</td></tr>
<tr><td><code id="ccomp_+3A_warn.na">warn.na</code></td>
<td>
<p>should the user be warned in case of NA,NaN or 0
coding different types of missing values?</p>
</td></tr>
<tr><td><code id="ccomp_+3A_detectionlimit">detectionlimit</code></td>
<td>
<p>a number, vector or matrix of positive
numbers giving the detection limit of all values, all columns or
each value, respectively</p>
</td></tr>
<tr><td><code id="ccomp_+3A_bdl">BDL</code></td>
<td>
<p>the code for 'Below Detection Limit' in X</p>
</td></tr>
<tr><td><code id="ccomp_+3A_sz">SZ</code></td>
<td>
<p>the code for 'Structural Zero' in X</p>
</td></tr>
<tr><td><code id="ccomp_+3A_mar">MAR</code></td>
<td>
<p>the code for 'Missing At Random' in X</p>
</td></tr>
<tr><td><code id="ccomp_+3A_mnar">MNAR</code></td>
<td>
<p>the code for 'Missing Not At Random' in X</p>
</td></tr>
</table>


<h3>Details</h3>

<p> A count composition contains an indirect observation of an
Aitchison composition by a Poisson or multinomial variable.  A count
composition can only contain integer counts. It is assumed that the
total sum is a an artefact and does not contain information on the
actual composition. But it does contain information on the precision
of the relative observation.
</p>


<h3>Value</h3>

<p>a vector of class <code>"ccomp"</code> representing count composition 
or a matrix of class <code>"ccomp"</code> representing
multiple count compositions each in one row.
</p>


<h3>Missing Policy</h3>

<p>The policy of treatment of zeroes, missing values and values 
below detecion limit is explained in depth in <a href="#topic+compositions.missing">compositions.missing</a>. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

 
<p><code><a href="#topic+barplot.ccomp">barplot.ccomp</a></code> <code><a href="#topic+ccompMultinomialGOF.test">ccompMultinomialGOF.test</a></code>
<code><a href="#topic+ccompPoissonGOF.test">ccompPoissonGOF.test</a></code> <code><a href="#topic+cdt.ccomp">cdt.ccomp</a></code>
<code><a href="#topic+cdtInv.ccomp">cdtInv.ccomp</a></code>
<code><a href="#topic+fitSameMeanDifferentVarianceModel">fitSameMeanDifferentVarianceModel</a></code>
<code><a href="#topic+groupparts.ccomp">groupparts.ccomp</a></code> <code><a href="#topic+idt.ccomp">idt.ccomp</a></code>
<code><a href="#topic+idtInv.ccomp">idtInv.ccomp</a></code> <code><a href="#topic+is.ccomp">is.ccomp</a></code>
<code><a href="#topic+mean.ccomp">mean.ccomp</a></code> <code><a href="#topic+names+3C-.ccomp">names&lt;-.ccomp</a></code>
<code><a href="#topic+names.ccomp">names.ccomp</a></code> <code><a href="#topic+plot.ccomp">plot.ccomp</a></code>
<code><a href="#topic+PoissonGOF.test">PoissonGOF.test</a></code> <code><a href="#topic+rmultinom.ccomp">rmultinom.ccomp</a></code>
<code><a href="#topic+rnorm.ccomp">rnorm.ccomp</a></code> <code><a href="#topic+rpois.ccomp">rpois.ccomp</a></code>
<code><a href="#topic+split.ccomp">split.ccomp</a></code> <code><a href="#topic+totals.ccomp">totals.ccomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(acomp(sa.lognormals))
</code></pre>

<hr>
<h2 id='ccomp-class'>Class <code>"ccomp"</code></h2><span id='topic+ccomp-class'></span><span id='topic+coerce+2Cccomp+2Cdata.frame-method'></span><span id='topic+coerce+2Cccomp+2Cstructure-method'></span><span id='topic+coerce+3C-+2Cccomp+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>The S4-version of the data container &quot;ccomp&quot; for compositional data. More information in 
<code><a href="#topic+ccomp">ccomp</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be directly created from it. 
This is provided to ensure that ccomp objects behave as data.frame or structure under certain circumstances. Use <code><a href="#topic+ccomp">ccomp</a></code> to create these objects.</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Object of class <code>"list"</code> containing the data itself </p>
</dd>
<dt><code>names</code>:</dt><dd><p>Object of class <code>"character"</code> with column names </p>
</dd>
<dt><code>row.names</code>:</dt><dd><p>Object of class <code>"data.frameRowLabels"</code> with row names </p>
</dd>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code> with the class string </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+data.frame-class">data.frame</a>"</code>, directly.
Class <code>"<a href="#topic+compositional-class">compositional</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+list-class">list</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;data.frame&quot;, distance 3.
</p>


<h3>Methods</h3>


<dl>
<dt>coerce</dt><dd><p><code>signature(from = "ccomp", to = "data.frame")</code>: to generate a data.frame </p>
</dd>
<dt>coerce</dt><dd><p><code>signature(from = "ccomp", to = "structure")</code>: to generate a structure (i.e. a vector, matrix or array) </p>
</dd>
<dt>coerce&lt;-</dt><dd><p><code>signature(from = "ccomp", to = "data.frame")</code>: to overwrite a composition with a data.frame</p>
</dd>
</dl>



<h3>Note</h3>

<p>see <code><a href="#topic+ccomp">ccomp</a></code>
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>References</h3>

<p>see <code><a href="#topic+ccomp">ccomp</a></code>
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+ccomp">ccomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("ccomp")
</code></pre>

<hr>
<h2 id='ccompgof'>Compositional Goodness of fit test</h2><span id='topic+PoissonGOF.test'></span><span id='topic+ccompPoissonGOF.test'></span><span id='topic+ccompMultinomialGOF.test'></span>

<h3>Description</h3>

<p>Goodness of fit tests for count compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoissonGOF.test(x,lambda=mean(x),R=999,estimated=missing(lambda))
ccompPoissonGOF.test(x,simulate.p.value=TRUE,R=1999)
ccompMultinomialGOF.test(x,simulate.p.value=TRUE,R=1999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ccompgof_+3A_x">x</code></td>
<td>
<p>a dataset integer numbers (PoissonGOF) or count compositions (compPoissonGOF)</p>
</td></tr>
<tr><td><code id="ccompgof_+3A_lambda">lambda</code></td>
<td>
<p>the expected value to check against</p>
</td></tr>
<tr><td><code id="ccompgof_+3A_r">R</code></td>
<td>
<p>The number of replicates to compute the distribution
of the test statistic</p>
</td></tr>
<tr><td><code id="ccompgof_+3A_estimated">estimated</code></td>
<td>
<p>states whether the lambda parameter should be
considered as estimated for the computation of the p-value.</p>
</td></tr>
<tr><td><code id="ccompgof_+3A_simulate.p.value">simulate.p.value</code></td>
<td>
<p>should all p-values be infered by simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compositional goodness of fit testing problem is essentially a
multivariate goodness of fit test. However there is a lack of
standardized multivariate goodness of fit tests in R. Some can be found in
the <code>energy</code>-package.
</p>
<p>In principle there is only one test behind the Goodness of fit tests
provided here, a two sample test with test statistic.
</p>
<p style="text-align: center;"><code class="reqn">\frac{\sum_{ij} k(x_i,y_i)}{\sqrt{\sum_{ij} k(x_i,x_i)\sum_{ij} k(y_i,y_i)}}</code>
</p>

<p>The idea behind that statistic is to measure the cos of an angle
between the distributions in a scalar product given by
</p>
<p style="text-align: center;"><code class="reqn">
  (X,Y)=E[k(X,Y)]=E[\int K(x-X)K(x-Y) dx]
  </code>
</p>

<p>where k and K are Gaussian kernels with different spread. The bandwith
is actually the standarddeviation of k.<br />
The other goodness of fit tests against a specific distribution are
based on estimating the parameters of the distribution, simulating a
large dataset of that distribution and apply the two sample goodness
of fit test. 
</p>


<h3>Value</h3>

<p>A classical <code>"htest"</code> object
</p>
<table>
<tr><td><code>data.name</code></td>
<td>
<p>The name of the dataset as specified</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a name for the test used</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>an empty string</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>a dataset of p-value distributions under the
Null-Hypothesis got from
nonparametric bootstrap</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p.value computed for this test</p>
</td></tr>
</table>


<h3>Missing Policy</h3>

<p>Up to now the tests can not handle missings. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitDirichlet">fitDirichlet</a></code>,<code><a href="#topic+rDirichlet">rDirichlet</a></code>, <code><a href="#topic+runif.acomp">runif.acomp</a></code>,
<code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- runif.acomp(100,4)
y &lt;- runif.acomp(100,4)

erg &lt;- acompGOF.test(x,y)
#continue
erg
unclass(erg)
erg &lt;- acompGOF.test(x,y)


x &lt;- runif.acomp(100,4)
y &lt;- runif.acomp(100,4)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(100,4),runif.acomp(100,4))$p.value)
hist(dd)

dd &lt;- replicate(1000,acompGOF.test(runif.acomp(20,4),runif.acomp(100,4))$p.value)
hist(dd)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(10,4),runif.acomp(100,4))$p.value)

hist(dd)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(10,4),runif.acomp(400,4))$p.value)
hist(dd)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(400,4),runif.acomp(10,4),bandwidth=4)$p.value)
hist(dd)


dd &lt;- replicate(1000,acompGOF.test(runif.acomp(20,4),runif.acomp(100,4)+acomp(c(1,2,3,1)))$p.value)

hist(dd)


x &lt;- runif.acomp(100,4)
acompUniformityGOF.test(x)

dd &lt;- replicate(1000,acompUniformityGOF.test(runif.acomp(10,4))$p.value)

hist(dd)


## End(Not run)
</code></pre>

<hr>
<h2 id='cdt'>Centered default transform</h2><span id='topic+cdt'></span><span id='topic+cdt.default'></span><span id='topic+cdt.acomp'></span><span id='topic+cdt.rcomp'></span><span id='topic+cdt.aplus'></span><span id='topic+cdt.rplus'></span><span id='topic+cdt.rmult'></span><span id='topic+cdt.ccomp'></span><span id='topic+cdt.factor'></span><span id='topic+cdt.data.frame'></span><span id='topic+cdtInv'></span><span id='topic+cdtInv.default'></span><span id='topic+cdtInv.acomp'></span><span id='topic+cdtInv.rcomp'></span><span id='topic+cdtInv.aplus'></span><span id='topic+cdtInv.rplus'></span><span id='topic+cdtInv.rmult'></span><span id='topic+cdtInv.ccomp'></span><span id='topic+cdtInv.factor'></span><span id='topic+cdtInv.data.frame'></span>

<h3>Description</h3>

<p>Compute the centered default transform of a (data set of)
compositions or amounts (or its inverse).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          cdt(x,...)
          ## Default S3 method:
cdt( x ,...)
          ## S3 method for class 'acomp'
cdt( x ,...)
          ## S3 method for class 'rcomp'
cdt( x ,...)
          ## S3 method for class 'aplus'
cdt( x ,...)
          ## S3 method for class 'rplus'
cdt( x ,...)
          ## S3 method for class 'rmult'
cdt( x ,...)
          ## S3 method for class 'ccomp'
cdt( x ,...)
          ## S3 method for class 'factor'
cdt( x ,...)
          ## S3 method for class 'data.frame'
cdt( x ,...)
          cdtInv(x,orig=gsi.orig(x),...)
          ## Default S3 method:
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'acomp'
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'rcomp'
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'aplus'
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'rplus'
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'rmult'
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'ccomp'
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'factor'
cdtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'data.frame'
cdtInv( x ,orig=gsi.orig(x),...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdt_+3A_x">x</code></td>
<td>
<p>a classed (matrix of) amount or composition, to be transformed with its
centered default transform, or its inverse; in case of the method for <code><a href="base.html#topic+data.frame">data.frame</a></code>
objects, the function attempts to track information about a previous class (in an attribute
<code>origClass</code>, and if found, a cdt/Inv transformation is tried with it; for factors, 
cdt expands the factor in indicator values for each category, or vice-versa.)</p>
</td></tr>
<tr><td><code id="cdt_+3A_...">...</code></td>
<td>
<p>generic arguments past to underlying functions.</p>
</td></tr>
<tr><td><code id="cdt_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked
by the inverse transformation. It is used to determine the
backtransform to be used and eventually to
reconstruct the names of the parts. It is the generic
argument. Typically this argument is extracted from <code>x</code>,
but if this fails you can give the data set that
has be transformed in the first place.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The general idea of this package is to analyse the same data with
different geometric concepts, in a fashion as similar as possible. For each of the
four concepts there exists a unique transform expressing the geometry
in a linear subspace, keeping the relation to the variables. This
unique transformation is computed by <code>cdt</code>. For
<code><a href="#topic+acomp">acomp</a></code> the transform is <code><a href="#topic+clr">clr</a></code>, for
<code><a href="#topic+rcomp">rcomp</a></code> it is <code><a href="#topic+cpt">cpt</a></code>, for 
<code><a href="#topic+aplus">aplus</a></code> it is <code><a href="#topic+ilt">ilt</a></code>, and for
<code><a href="#topic+rplus">rplus</a></code> it is <code><a href="#topic+iit">iit</a></code>. Each component of the result
is identified with a unit vector in the direction of the corresponding
component of the original composition or amount. Keep in mind that the
transform is not necessarily surjective and thus variances in the
image space might be singular.
</p>


<h3>Value</h3>

<p>A corresponding matrix or vector containing the transforms. (Exception: cdt.data.frame can return
a data.frame if the input has no &quot;origClass&quot;-attribute)
</p>


<h3>Author(s)</h3>

<p>R. Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+backtransform">backtransform</a></code>, <code><a href="#topic+idt">idt</a></code>, <code><a href="#topic+clr">clr</a></code>, <code><a href="#topic+cpt">cpt</a></code>, <code><a href="#topic+ilt">ilt</a></code>, <code><a href="#topic+iit">iit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# the cdt is defined by
cdt         &lt;- function(x) UseMethod("cdt",x)
cdt.default &lt;- function(x) x
cdt.acomp   &lt;- clr 
cdt.rcomp   &lt;- cpt 
cdt.aplus   &lt;- ilt 
cdt.rplus   &lt;- iit 

## End(Not run)
x &lt;- acomp(1:5)
(ds &lt;- cdt(x))
cdtInv(ds,x)
(ds &lt;- cdt(rcomp(1:5)))
cdtInv(ds,rcomp(x))
  data(Hydrochem)
  x = Hydrochem[,c("Na","K","Mg","Ca")]
  y = acomp(x)
  z = cdt(y)
  y2 = cdtInv(z,y)
  par(mfrow=c(2,2))
  for(i in 1:4){plot(y[,i],y2[,i])}

</code></pre>

<hr>
<h2 id='ClamEast'>Color-size compositions of 20 clam colonies from East Bay</h2><span id='topic+ClamEast'></span><span id='topic+Data14'></span>

<h3>Description</h3>

<p>From East Bay, 20 clam colonies were randomly selected and from each a sample of clams were taken.
Each sample was sieved into three size ranges, large, medium, and small.
Then each size range was sorted by the shale colour, dark or light.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ClamEast)
</code></pre>


<h3>Details</h3>

<p>The data consist of 20 cases and <code class="reqn">2\times 3</code> variables denoted:
</p>

<table>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> dl</td><td style="text-align: left;">  portion of dark large clams, </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> dm</td><td style="text-align: left;">  portion of dark medium clams,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> ds</td><td style="text-align: left;">  portion of dark small clams, </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> ll</td><td style="text-align: left;">  portion of light large clams, </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> lm</td><td style="text-align: left;">  portion of light medium clams,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> ls</td><td style="text-align: left;">  portion of light small clams. 
</td>
</tr>

</table>

<p>All 6-part compositions sum to one, except for rounding errors.</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name CLAMEAST.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 14, pp18. 
</p>

<hr>
<h2 id='ClamWest'>Color-size compositions of 20 clam colonies from West Bay</h2><span id='topic+ClamWest'></span><span id='topic+Data15'></span>

<h3>Description</h3>

<p>From West Bay, 20 clam colonies were randomly selected, and from each a sample of clams were taken.
Each sample was sieved into three size ranges, large, medium, and small.
Then each size range was sorted by the shale colour, dark or light.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ClamWest)
</code></pre>


<h3>Details</h3>

<p>The data consist of 20 cases and <code class="reqn">2\times 3</code> variables denoted:
</p>

<table>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> dl</td><td style="text-align: left;">  portion of dark large clams, </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> dm</td><td style="text-align: left;">  portion of dark medium clams,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> ds</td><td style="text-align: left;">  portion of dark small clams, </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> ll</td><td style="text-align: left;">  portion of light large clams, </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> lm</td><td style="text-align: left;">  portion of light medium clams,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> ls</td><td style="text-align: left;">  portion of light small clams.
</td>
</tr>

</table>

<p>All 6-part compositions sum up to one.</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name CLAMWEST.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 15, pp17. 
</p>

<hr>
<h2 id='clo'>Closure of a composition</h2><span id='topic+clo'></span>

<h3>Description</h3>

<p>Closes compositions to sum up to one (or an optional total), by dividing each part by the sum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          clo( X, parts=1:NCOL(oneOrDataset(X)),total=1,
               detectionlimit=attr(X,"detectionlimit"),
               BDL=NULL,MAR=NULL,MNAR=NULL,SZ=NULL,
               storelimit=!is.null(attr(X,"detectionlimit"))
               )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clo_+3A_x">X</code></td>
<td>
<p>composition or dataset of compositions</p>
</td></tr>
<tr><td><code id="clo_+3A_parts">parts</code></td>
<td>
<p>vector containing the indices xor names of the columns to be
used</p>
</td></tr>
<tr><td><code id="clo_+3A_total">total</code></td>
<td>
<p>the total amount to which the compositions should be closed; either 
a single number, or a numeric vector of length
<code>gsi.getN(X)</code> specifying a different total for each
compositional vector in the dataset.</p>
</td></tr>
<tr><td><code id="clo_+3A_detectionlimit">detectionlimit</code></td>
<td>
<p>a number, vector or matrix of positive
numbers giving the detection limit of all values, all variables, or
each value</p>
</td></tr>
<tr><td><code id="clo_+3A_bdl">BDL</code></td>
<td>
<p>the code for values below detection limit in X</p>
</td></tr>
<tr><td><code id="clo_+3A_sz">SZ</code></td>
<td>
<p>the code for structural zeroes in X</p>
</td></tr>
<tr><td><code id="clo_+3A_mar">MAR</code></td>
<td>
<p>the code for values missed at random in X</p>
</td></tr>
<tr><td><code id="clo_+3A_mnar">MNAR</code></td>
<td>
<p>the code for values missed not at random in X</p>
</td></tr>
<tr><td><code id="clo_+3A_storelimit">storelimit</code></td>
<td>
<p>a boolean indicating wether to store the
detection limit as an attribute in the data. It defaults to FALSE if
the detection limit is not already stored in the dataset. The
attribute is only needed for very advanced analysis. Most times, this 
will not be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The closure operation is given by
</p>
<p style="text-align: center;"><code class="reqn"> clo(x) := \left(x_i / \sum_{j=1}^D  x_j\right) </code>
</p>

<p><code>clo</code> generates a composition without assigning one of the
compositional classes <code><a href="#topic+acomp">acomp</a></code> or <code><a href="#topic+rcomp">rcomp</a></code>. 
Note that after computing the closed-to-one version, obtaining a 
version closed to any other value is done by simple multiplication. 
<br />
</p>


<h3>Value</h3>

<p>a composition or a data matrix of compositions, maybe without compositional
class. The individual compositions are forced to sum to 1 (or to 
the optionally-specified total). The result
should have the same shape as the input (vector, row, matrix). 
</p>


<h3>Missing Policy</h3>

<p>How missing values are coded in the output always follows the general rules
described in <code><a href="#topic+compositions.missing">compositions.missing</a></code>. The BDL values are
accordingly scaled during the scaling operations but not taken into
acount for the calculation of the total sum. 
</p>


<h3>Note</h3>

<p><code>clo</code> can be used to unclass compositions.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+acomp">acomp</a></code>,<code><a href="#topic+rcomp">rcomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- clo(c(1,2,3)))
clo(tmp,total=100)
data(Hydrochem)
plot( clo(Hydrochem,8:9) ) # Giving points on a line 

</code></pre>

<hr>
<h2 id='clr'>Centered log ratio transform</h2><span id='topic+clr'></span><span id='topic+clrInv'></span>

<h3>Description</h3>

<p>Compute the centered log ratio transform of a (dataset of)
composition(s) and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          clr( x,... )
          clrInv( z,..., orig=gsi.orig(z) )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clr_+3A_x">x</code></td>
<td>
<p>a composition or a data matrix of compositions, not necessarily closed</p>
</td></tr>
<tr><td><code id="clr_+3A_z">z</code></td>
<td>
<p>the clr-transform of a composition or a data matrix of
clr-transforms of compositions, not necessarily centered
(i.e. summing up to zero)</p>
</td></tr>
<tr><td><code id="clr_+3A_...">...</code></td>
<td>
<p>for generic use only</p>
</td></tr>
<tr><td><code id="clr_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked 
by the inverse transformation. It is especially used to
reconstruct the names of the parts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The clr-transform maps a composition in the D-part Aitchison-simplex
isometrically to a D-dimensonal euclidian vector subspace: consequently, the
transformation is not injective. Thus resulting covariance matrices
are always singular. 
<br /> 
The data can then
be analysed in this transformation by all classical multivariate
analysis tools not relying on a full rank of the covariance. See
<code><a href="#topic+ilr">ilr</a></code> and <code><a href="#topic+alr">alr</a></code> for alternatives. The
interpretation of the results is relatively easy since the relation between each original
part and a transformed variable is preserved.
<br />  
The centered logratio transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> clr(x) := \left(\ln x_i - \frac1D \sum_{j=1}^D \ln x_j\right)_i </code>
</p>

<p>The image of the <code>clr</code> is a vector with entries
summing to 0. This hyperplane is also called the clr-plane.
</p>


<h3>Value</h3>

<p><code>clr</code> gives the centered log ratio transform,
<code>clrInv</code> gives closed compositions with the given clr-transform
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart
<a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em>, Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+alr">alr</a></code>,<code><a href="#topic+apt">apt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- clr(c(1,2,3)))
clrInv(tmp)
clrInv(tmp) - clo(c(1,2,3)) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(clr(cdata),pch=".") 
</code></pre>

<hr>
<h2 id='clr2ilr'>Convert between clr and ilr, and between cpt and ipt. </h2><span id='topic+clr2ilr'></span><span id='topic+ilr2clr'></span><span id='topic+clrvar2ilr'></span><span id='topic+ilrvar2clr'></span><span id='topic+clrvar2variation'></span><span id='topic+variation2clrvar'></span><span id='topic+is.clrvar'></span><span id='topic+is.ilrvar'></span>

<h3>Description</h3>

<p>Compute the centered log ratio transform of a (dataset of) from
isometric log-ratio transform(s) and its inverse. Equivalently, 
compute centered and isometric planar transforms from each other.
Acts in vectors and in bilinear forms. For bilinear forms, 
transform between variation-form from clr-form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clr2ilr( x , V=ilrBase(x=x) )
ilr2clr( z , V=ilrBase(z=z), x=gsi.orig(z) )
clrvar2ilr( varx , V=ilrBase(D=ncol(varx)) )
ilrvar2clr( varz , V=ilrBase(D=ncol(varz)+1) ,x=NULL)
clrvar2variation(Sigma)
variation2clrvar(TT)
is.clrvar(M, tol=1e-10)
is.ilrvar(M, tol=1e-10)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clr2ilr_+3A_x">x</code></td>
<td>
<p>the clr/cpt-transform of composition(s) (in the ilr2-routines
provided only to give column names.)</p>
</td></tr>
<tr><td><code id="clr2ilr_+3A_z">z</code></td>
<td>
<p>the ilr/ipt-transform of composition(s)</p>
</td></tr>
<tr><td><code id="clr2ilr_+3A_varx">varx</code>, <code id="clr2ilr_+3A_sigma">Sigma</code></td>
<td>
<p>variance or covariance matrix of clr/cpt-transformed
compositions</p>
</td></tr>
<tr><td><code id="clr2ilr_+3A_varz">varz</code></td>
<td>
<p>variance or covariance matrix of ilr/ipt-transformed
compositions</p>
</td></tr>
<tr><td><code id="clr2ilr_+3A_v">V</code></td>
<td>
<p>a matrix with columns giving the chosen  basis of the clr-plane</p>
</td></tr>
<tr><td><code id="clr2ilr_+3A_tt">TT</code></td>
<td>
<p>variation matrix</p>
</td></tr>
<tr><td><code id="clr2ilr_+3A_m">M</code></td>
<td>
<p>a matrix, to check if it is a valid variance</p>
</td></tr>
<tr><td><code id="clr2ilr_+3A_tol">tol</code></td>
<td>
<p>tolerance for the check</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions perform a matrix multiplication with <code>V</code> in an
appropriate way. 
</p>


<h3>Value</h3>

<p><code>clr2ilr</code> gives the ilr/ipt transform of the same composition(s),<br />
<code>ilr2clr</code> gives the clr/cpt transform of the same
composition(s),<br />
<code>clrvar2ilr</code> gives the variance-/covariance-matrix of the ilr/ipt transform of the same compositional data set,<br />
<code>ilrvar2clr</code> and <code>clrvar2variation</code> give the variance-/covariance-matrix of the clr/cpt
transform of the same compositional data set.<br />
<code>variation2clrvar</code> gives the variation matrix from the clr-covariance matrix<br />
<code>is.*var</code> check if the given matrix satisfies the conditions to be an ilr-variance 
resp. a clr-variance
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Egozcue J.J., V. Pawlowsky-Glahn, G. Mateu-Figueras and
C. Barcel'o-Vidal (2003) Isometric logratio transformations for
compositional data analysis. <em>Mathematical Geology</em>, <b>35</b>(3)
279-300<br />
Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003
</p>


<h3>See Also</h3>

<p><code><a href="#topic+variation">variation</a></code>, <code><a href="#topic+ilr">ilr</a></code>, <code><a href="#topic+ipt">ipt</a></code>,
<code><a href="#topic+clr">clr</a></code>, <code><a href="#topic+cpt">cpt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
ilrInv(clr2ilr(clr(sa.lognormals)))-clo(sa.lognormals)
clrInv(ilr2clr(ilr(sa.lognormals)))-clo(sa.lognormals)
ilrvar2clr(var(ilr(sa.lognormals)))-var(clr(sa.lognormals))
clrvar2ilr(var(cpt(sa.lognormals)))-var(ipt(sa.lognormals))
variation(acomp(sa.lognormals))
clrvar2variation(var(acomp(sa.lognormals)))
</code></pre>

<hr>
<h2 id='ClusterFinder1'>Heuristics to find subpopulations of outliers</h2><span id='topic+ClusterFinder1'></span><span id='topic+ClusterFinder1.acomp'></span>

<h3>Description</h3>

<p>The ClusterFinder is a heuristic to find subpopulations of outliers
essentially by looking for secondary modes in a density
estimate. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ClusterFinder1(X,...)
## S3 method for class 'acomp'
ClusterFinder1(X,...,sigma=0.3,radius=1,asig=1,minGrp=3,
                                 robust=TRUE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ClusterFinder1_+3A_x">X</code></td>
<td>
<p>the dataset to be clustered</p>
</td></tr>
<tr><td><code id="ClusterFinder1_+3A_...">...</code></td>
<td>
<p>Further arguments to <code>MahalanobisDist(X,...,robust=robust,pairwise=TRUE)</code> </p>
</td></tr>
<tr><td><code id="ClusterFinder1_+3A_sigma">sigma</code></td>
<td>
<p>numeric: The Bandwidth of the density estimation kernel
in a robustly Mahalanobis transformed space. (i.e. in the transform,
where the main group has unit variance)</p>
</td></tr>
<tr><td><code id="ClusterFinder1_+3A_radius">radius</code></td>
<td>
<p>The minimum size of a cluster in a robustly Mahalanobis
transformed space. (i.e. in the transform, where the main group has unit
variance)</p>
</td></tr>
<tr><td><code id="ClusterFinder1_+3A_asig">asig</code></td>
<td>
<p>a scaling factor for the geometry of the robustly
Mahalanobis transformed space when computing the likelihood of an
observation to belong to group (under a Gaussian assumption). Higher
values </p>
</td></tr>
<tr><td><code id="ClusterFinder1_+3A_mingrp">minGrp</code></td>
<td>
<p>the minimum size of group to be used. Smaller groups are
treated as single outliers</p>
</td></tr>
<tr><td><code id="ClusterFinder1_+3A_robust">robust</code></td>
<td>
<p>A robustness description for estimating the variance of
the main group. FALSE is probably not a usefull value. However later
other robustness techniques than mcd might be usefull. <code>TRUE</code>
just picks the default method of the package.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="#topic+outliersInCompositions">outliersInCompositions</a> for a comprehensive introduction
into the outlier
treatment in compositions.
<br />
The ClusterFinder is labeled with a number to make clear that this is
just an implementation of some heuristic and not based on some eternal
truth. Other might give better Clusterfinders. 
<br />
Unlike other Clustering Algorithms the basic model of this
algorithm assumes that there is one dominating subpopulation and an
unkown number of smaller subpopulations with a similar covariance
structure but a different mean. The algorithm thus first estimates the
covariance structure of the main population by a robust location scale
estimator. Then it uses a simplified (Gaussian) kernel density
estimator to find
nonrandom secondary modes. The it tries to a assign the different
observations according to discrimination analysis model to the
different modes. Groups under a given size are considered as single
outliers forming a seperate group. In this way the number of clusters
is kept low even if there are many erratic measurements in the dataset.
<br />
The main use of the
clusters is descriptive plotting. The advantage of these cluster
against other cluster techniques like k-mean or hclust is that it does
not tear appart the central mass of the data, as these methods do to
make the clusters as compact as possible.
</p>


<h3>Value</h3>

<p>A list
</p>
<table>
<tr><td><code>types</code></td>
<td>
<p>a factor representing the group assignments, when the
small groups are ignored</p>
</td></tr>
<tr><td><code>typesTbl</code></td>
<td>
<p>a table giving the number of members in each of these
groups</p>
</td></tr>
<tr><td><code>groups</code></td>
<td>
<p>a factor representing the found group assignments</p>
</td></tr>
<tr><td><code>isMax</code></td>
<td>
<p>a logical vector indicating for each observation,whether
it represent a local maximum in the density estimate.</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>the infered probability to belong to the different groups
given as an acomp composition.</p>
</td></tr>
<tr><td><code>nmembers</code></td>
<td>
<p>a tabel giving the number of members of each group</p>
</td></tr>
<tr><td><code>density</code></td>
<td>
<p>the density estimated in each observation location</p>
</td></tr>
<tr><td><code>likeli</code></td>
<td>
<p>The infered likelihood see this observation, for each of
the groups</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="stats.html#topic+kmeans">kmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
  cl &lt;- ClusterFinder1(sa.outliers5,sigma=0.4,radius=1) 
  plot(sa.outliers5,col=as.numeric(cl$types),pch=as.numeric(cl$types))
  legend(1,1,legend=levels(cl$types),xjust=1,col=1:length(levels(cl$types)),
                     pch=1:length(levels(cl$types)))

</code></pre>

<hr>
<h2 id='CoDaDendrogram'>Dendrogram representation of acomp or rcomp objects</h2><span id='topic+CoDaDendrogram'></span>

<h3>Description</h3>

<p>Function for plotting CoDa-dendrograms of acomp or rcomp objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoDaDendrogram(X, V = NULL, expr=NULL, mergetree = NULL, signary = NULL, 
    range = c(-4,4), ..., xlim = NULL, ylim = NULL, yaxt = NULL, box.pos = 0,
    box.space = 0.25, col.tree = "black", lty.tree = 1, lwd.tree = 1,
    col.leaf = "black", lty.leaf = 1, lwd.leaf = 1, add = FALSE,border=NULL,
    type = "boxplot")
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoDaDendrogram_+3A_x">X</code></td>
<td>
<p> data set to plot (an rcomp or acomp object) </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_v">V</code></td>
<td>
<p> basis to use, described as an ilr matrix </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_expr">expr</code></td>
<td>
<p> a formula describing the partition basis, as with <code><a href="#topic+balanceBase">balanceBase</a></code> </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_mergetree">mergetree</code></td>
<td>
<p> basis to use, described as a merging tree (as in <code><a href="stats.html#topic+hclust">hclust</a></code>) </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_signary">signary</code></td>
<td>
<p> basis to use, described as a sign matrix (as in the example below)</p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_range">range</code></td>
<td>
<p> minimum and maximum value for all coordinates (horizontal axes) </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_...">...</code></td>
<td>
<p>further parameters to pass to any function, be it a plotting function or one related to the &quot;type&quot; parameter below; likely to produce lots of warnings</p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_xlim">xlim</code></td>
<td>
<p> minimum and maximum values for the horizontal direction of the plot (related to number of parts) </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_ylim">ylim</code></td>
<td>
<p> minimum and maximum values for the vertical direction of the plot (related to variance of coordinates) </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_yaxt">yaxt</code></td>
<td>
<p> axis type for the vertical direction of the plot (see <code><a href="graphics.html#topic+par">par</a></code>)</p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_box.pos">box.pos</code></td>
<td>
<p> if type=&quot;boxplot&quot;, this is the relative position of the box in the vertical direction: 0 means centered on the axis, -1 aligned below the axis and +1 aligned above the axis </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_box.space">box.space</code></td>
<td>
<p> if type=&quot;boxplot&quot;, size of the box in the vertical direction as a portion of the minimal variance of the coordinates </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_col.tree">col.tree</code></td>
<td>
<p> color for the horizontal axes </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_lty.tree">lty.tree</code></td>
<td>
<p> line type for the horizontal axes </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_lwd.tree">lwd.tree</code></td>
<td>
<p> line width for the horizontal axes </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_col.leaf">col.leaf</code></td>
<td>
<p> color for the vertical conections between an axis and a part (leaf) </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_lty.leaf">lty.leaf</code></td>
<td>
<p> line type for the leaves </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_lwd.leaf">lwd.leaf</code></td>
<td>
<p> line width for the leaves </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_add">add</code></td>
<td>
<p> should a new plot be triggered, or is the material to be added to an existing CoDa-dendrogram? </p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_border">border</code></td>
<td>
<p>the color for drawing the rectangles</p>
</td></tr>
<tr><td><code id="CoDaDendrogram_+3A_type">type</code></td>
<td>
<p> what to represent? one of
&quot;boxplot&quot;,&quot;density&quot;,&quot;histogram&quot;,&quot;lines&quot;,&quot;nothing&quot; or &quot;points&quot;, or an
univocal abbreviation </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The object <em>and an isometric basis</em> are represented in a
CoDa-dendrogram, as defined by Egozcue and Pawlowsky-Glahn
(2005). This is a representation of the following elements:
</p>

<dl>
<dt>a</dt><dd><p>a hierarchical partition (which can be specified either through an ilrBase matrix (see <code><a href="#topic+ilrBase">ilrBase</a></code>), a merging tree structure (see <code><a href="stats.html#topic+hclust">hclust</a></code>) or a signary matrix (see <code><a href="#topic+gsi.merge2signary">gsi.merge2signary</a></code>))</p>
</dd>
<dt>b</dt><dd><p>the sample mean of each coordinate of the ilr basis associated to that partition</p>
</dd>
<dt>c</dt><dd><p>the sample variance of each coordinate of the ilr basis associated to that partition</p>
</dd>
<dt>d</dt><dd><p>optionally (potentially!), any graphical representation of each coordinate, as long as this representation is suitable for a univariate data set (box-plot, histogram, dispersion and kernel density are programmed or intended to, but any other may be added with little work).</p>
</dd>
</dl>

<p>Each coordinate is represented in a horizontal axis, which limits correspond to the values given in the parameter <code>range</code>. The vertical bar going up from each one of these coordinate axes represent the variance of that specific coordinate, and the contact point the coordinate mean. Note that to be able to represent an initial dendrogram, the first call to this function must be given a full data set, as means and variances must be computed. This information is afterwards stored in a global list, to add any sort of new material to all coordinates.
<br />
The default option is <code>type="boxplot"</code>, which produces a box-plot for each coordinate, customizable using <code>box.pos</code> and <code>box.space</code>, as well as typical <code><a href="graphics.html#topic+par">par</a></code> parameters (col, border, lty, lwd, etc.). To obtain only the first three aspects, the function must be called with <code>type="lines"</code>. As extensions, one might represent a single datum/few data (e.g., a mean or a random subsample of the data set) calling the function with <code>add=TRUE</code> and <code>type="points"</code>. Other options (calling functions <code><a href="lattice.html#topic+histogram">histogram</a></code> or <code><a href="stats.html#topic+density">density</a></code>, and admitting their parameters) will be  also soon available.
<br />
Note that the original coda-dendrogram as defined by Egozcue and Pawlowsky-Glahn (2005) works with acomp objects and ilr bases. Functionality is extended to rcomp objects using calls to <code><a href="#topic+idt">idt</a></code>.
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Egozcue J.J., V. Pawlowsky-Glahn, G. Mateu-Figueras and
C. Barcel'o-Vidal (2003) Isometric logratio transformations for
compositional data analysis. <em>Mathematical Geology</em>, <b>35</b>(3)
279-300<br />
</p>
<p>Egozcue, J.J. and V. Pawlowsky-Glahn (2005). CoDa-Dendrogram: a new exploratory tool.
In: Mateu-Figueras, G. and Barcel\'o-Vidal, C. (Eds.)
<em>Proceedings of the 2nd International Workshop on Compositional Data Analysis</em>,
Universitat de Girona, ISBN 84-8458-222-1, <a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a><br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilrBase">ilrBase</a></code>,<code><a href="#topic+balanceBase">balanceBase</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+acomp">acomp</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'># first example: take the data set from the example, select only
# compositional parts
data(Hydrochem)
x = acomp(Hydrochem[,-c(1:5)])
gr = Hydrochem[,4] # river groups (useful afterwards)
# use an ilr basis coming from a clustering of parts
dd = dist(t(clr(x)))
hc1 = hclust(dd,method="ward.D")
plot(hc1)
mergetree=hc1$merge
CoDaDendrogram(X=acomp(x),mergetree=mergetree,col="red",range=c(-8,8),box.space=1)
# add the mean of each river
color=c("green3","red","blue","darkviolet")
aux = sapply(split(x,gr),mean)
aux
CoDaDendrogram(X=acomp(t(aux)),add=TRUE,col=color,type="points",pch=4)

# second example: box-plots by rivers (filled)
CoDaDendrogram(X=acomp(x),mergetree=mergetree,col="black",range=c(-8,8),type="l")
xsplit = split(x,gr)
for(i in 1:4){
 CoDaDendrogram(X=xsplit[[i]],col=color[i],type="box",box.pos=i-2.5,box.space=0.5,add=TRUE)
}

# third example: fewer parts, partition defined by a signary, and empty box-plots
x = acomp(Hydrochem[,c("Na","K","Mg","Ca","Sr","Ba","NH4")])
signary = t(matrix(  c(1,   1,   1,  1,   1,   1,  -1,
                       1,   1,  -1, -1,  -1,  -1,   0,
                       1,  -1,   0,  0,   0,   0,   0,
                       0,   0,  -1,  1,  -1,  -1,   0,
                       0,   0,   1,  0,  -1,   1,   0,
                       0,   0,   1,  0,   0,  -1,   0),ncol=7,nrow=6,byrow=TRUE))

CoDaDendrogram(X=acomp(x),signary=signary,col="black",range=c(-8,8),type="l")
xsplit = split(x,gr)
for(i in 1:4){
  CoDaDendrogram(X=acomp(xsplit[[i]]),border=color[i],
       type="box",box.pos=i-2.5,box.space=1.5,add=TRUE)
  CoDaDendrogram(X=acomp(xsplit[[i]]),col=color[i],
       type="line",add=TRUE)
}
</code></pre>

<hr>
<h2 id='coloredBiplot'>A biplot providing somewhat easier access to details of the plot.</h2><span id='topic+coloredBiplot'></span><span id='topic+coloredBiplot.default'></span><span id='topic+coloredBiplot.princomp'></span><span id='topic+coloredBiplot.prcomp'></span>

<h3>Description</h3>

<p>This function generates a simple biplot out of various sources and
allows to give color and symbol to the x-objects individually. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## Default S3 method:
coloredBiplot(x, y, var.axes = TRUE, col, 
         cex = rep(par("cex"), 2), xlabs = NULL, ylabs = NULL, expand=1, 
         xlim = NULL, ylim = NULL, arrow.len = 0.1, main = NULL, sub = NULL, 
         xlab = NULL, ylab = NULL, xlabs.col = NULL, xlabs.bg = NULL, 
         xlabs.pc=NULL, ...)
## S3 method for class 'princomp'
coloredBiplot(x, choices = 1:2, scale = 1, 
         pc.biplot=FALSE, ...)
## S3 method for class 'prcomp'
coloredBiplot(x, choices = 1:2, scale = 1, 
         pc.biplot=FALSE, ...)
         
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coloredBiplot_+3A_x">x</code></td>
<td>
<p>a representation of the the co-information to be
plotted, given by a result of princomp or prcomp; or the first set of
coordinates to be plotted</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_y">y</code></td>
<td>
<p>optional, the second set of coordinates to be potted</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_var.axes">var.axes</code></td>
<td>
<p>if 'TRUE' the second set of points have arrows representing
them as (unscaled) axes</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_col">col</code></td>
<td>
<p>one color (to be used for the y set) or a vector of two colors 
(to be used for x and y sets respectively, if <code>xlabs.col</code> is NULL)</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_cex">cex</code></td>
<td>
<p>the usual cex parameter for plotting; can be a length-2 vector to
format differently x and y labels/symbols</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_xlabs">xlabs</code></td>
<td>
<p>names to write for the points of the first set</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_ylabs">ylabs</code></td>
<td>
<p>names to write for the points of the second set</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_expand">expand</code></td>
<td>
<p>expansion factor to apply when plotting the second set of 
points relative to the first. This can be used to tweak the scaling of the 
two sets to a physically comparable scale</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_xlim">xlim</code></td>
<td>
<p>horizontal axis limits</p>
</td></tr>  
<tr><td><code id="coloredBiplot_+3A_ylim">ylim</code></td>
<td>
<p>vertical axis limits</p>
</td></tr>  
<tr><td><code id="coloredBiplot_+3A_arrow.len">arrow.len</code></td>
<td>
<p>length of the arrow heads on the axes plotted if 
'var.axes' is true. The arrow head can be suppressed by 'arrow.len=0'</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_main">main</code></td>
<td>
<p>main title</p>
</td></tr>  
<tr><td><code id="coloredBiplot_+3A_sub">sub</code></td>
<td>
<p>subtitle</p>
</td></tr>  
<tr><td><code id="coloredBiplot_+3A_xlab">xlab</code></td>
<td>
<p>horizontal axis title</p>
</td></tr>  
<tr><td><code id="coloredBiplot_+3A_ylab">ylab</code></td>
<td>
<p>vertical axis title</p>
</td></tr>  
<tr><td><code id="coloredBiplot_+3A_xlabs.col">xlabs.col</code></td>
<td>
<p>the color(s) to draw the points of the first set, if
<code>xlabs</code> is null</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_xlabs.bg">xlabs.bg</code></td>
<td>
<p>the filling color(s) to draw the points of the first set, if
<code>xlabs</code> is null and <code>xlabs.pc</code> is between 21 and 25.</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_xlabs.pc">xlabs.pc</code></td>
<td>
<p>the plotting character(s) for the first set, if
<code>xlabs</code> is null</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_scale">scale</code></td>
<td>
<p>the way to distribute the singular values on the 
right or left singular vectors for princomp and prcomp objects 
(see <code><a href="stats.html#topic+biplot">biplot</a></code>)</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_choices">choices</code></td>
<td>
<p>the components to be plotted (see <code><a href="stats.html#topic+biplot">biplot</a></code>)</p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_pc.biplot">pc.biplot</code></td>
<td>
<p>should be scaled by <code>sqrt(nrow(X))</code>? 
(see <code><a href="stats.html#topic+biplot">biplot</a></code>) </p>
</td></tr>
<tr><td><code id="coloredBiplot_+3A_...">...</code></td>
<td>
<p>further parameters for plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions is provided for convenience. 
</p>


<h3>Value</h3>

<p>The function is called only for the side effect of plotting. It is a modification 
of the standard R routine 'biplot'.
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+biplot">biplot</a></code>, <code><a href="#topic+plot.acomp">plot.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
coloredBiplot(x=princomp(acomp(sa.outliers5)),pc.biplot=FALSE,
          xlabs.pc=c(1,2,3), xlabs.col=2:4, col="black")
</code></pre>

<hr>
<h2 id='colorsForOutliers'>Create a color/char palette or for groups of outliers</h2><span id='topic+colorsForOutliers1'></span><span id='topic+colorsForOutliers2'></span><span id='topic+pchForOutliers1'></span>

<h3>Description</h3>

<p>Conveniance Functions to generate meaningfull color palettes for
factors representing different types of outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colorsForOutliers1(outfac, family=rainbow,
                          extreme="cyan",outlier="red",ok="gray40",unknown="blue")
colorsForOutliers2(outfac,use=whichBits(gsi.orSum(levels(outfac))),
                        codes=c(2^outer(c(24,16,8),1:7,"-")),ok="yellow")
pchForOutliers1(outfac,ok='.',outlier='\004',extreme='\003',unknown='\004',...,
  other=c('\001','\002','\026','\027','\010','\011','\012','\013','\014','\015',
    '\016',strsplit("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ","")[[1]])
    )  

          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colorsForOutliers_+3A_outfac">outfac</code></td>
<td>
<p>a factor given by an OutlierClassifier
(e.g. <code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code>). <code>colorsForOutliers1</code>
is used for the types
&quot;best&quot;,&quot;type&quot;,&quot;outlier&quot;,&quot;grade&quot;. <code>colorsForOutliers2</code> is used
for type all. </p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_family">family</code></td>
<td>
<p>a function generating a color palette from  a numer of
colors requested.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_extreme">extreme</code></td>
<td>
<p>The color/char for extrem but not definitivly outlying observations.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_outlier">outlier</code></td>
<td>
<p>The color/char for detected outliers.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_unknown">unknown</code></td>
<td>
<p>The color/char for observation with unclear
classification.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_other">other</code></td>
<td>
<p>The character codes for other outlier classes.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_ok">ok</code></td>
<td>
<p>The color/char for nonoutlying usual observations.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_use">use</code></td>
<td>
<p>a numerical vector giving the indices of the bits of the
output to be represented. The sequence of the bits determins how each
bit is represented.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_codes">codes</code></td>
<td>
<p>The color influences to be used for each bit.</p>
</td></tr>
<tr><td><code id="colorsForOutliers_+3A_...">...</code></td>
<td>
<p>further codings for other factorlevels</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions are provided for coveniance to quickly generate a
palette of reasonable colors or plotting chars for groups of outliers
classified by OutlierClassifier1.
</p>


<h3>Value</h3>

<p>a character vector of colors or a numeric vector of plot chars.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(SimulatedAmounts)
data5 &lt;- acomp(sa.outliers5)
olc &lt;- OutlierClassifier1(data5)
plot(data5,col=colorsForOutliers1(olc)[olc])
olc &lt;- OutlierClassifier1(data5,type="all")
plot(data5,col=colorsForOutliers2(olc)[olc])

## End(Not run)
</code></pre>

<hr>
<h2 id='CompLinModCoReg'>Compositional Linear Model of Coregionalisation</h2><span id='topic+CompLinModCoReg'></span>

<h3>Description</h3>

<p>Creates a Variogram model according to the linear model of spatial
corregionalisation for a compositional geostatistical analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CompLinModCoReg(formula,comp,D=ncol(comp),envir=environment(formula))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompLinModCoReg_+3A_formula">formula</code></td>
<td>
<p>A formula without left side providing a formal
description of a variogram model.</p>
</td></tr>
<tr><td><code id="CompLinModCoReg_+3A_comp">comp</code></td>
<td>
<p>a compositional dataset, needed to provide the frame size</p>
</td></tr>
<tr><td><code id="CompLinModCoReg_+3A_d">D</code></td>
<td>
<p>The dimension of the multivariate dataset</p>
</td></tr>
<tr><td><code id="CompLinModCoReg_+3A_envir">envir</code></td>
<td>
<p>The enviroment in which formula should be interpreted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The linear model of coregionalisation uses the fact that sums of
valid variogram models are valid variograms, and that scalar variograms
multiplied with a positive definite matrix are valid variograms for
vector-valued random functions. 
</p>
<p>This command computes such a variogram function from a
formal description, via a formula without left-hand side. 
The right-hand side of the formula is a sum. Each summand is either a
product of a matrix description and a scalar variogram description or
only a scalar variogram description. Scalar variogram descriptions are
either formal function calls to
</p>

<dl>
<dt><code>sph(range)</code></dt><dd><p> for spherical variogram with range <code>range</code></p>
</dd>
<dt><code>exp(range)</code></dt><dd><p> for an exponential variogram with effective range 
<code>range</code></p>
</dd>
<dt><code>gauss(range)</code></dt><dd><p> for a Gaussian variogram with effective range
<code>range</code></p>
</dd>
<dt><code>gauss(range)</code></dt><dd><p> for a cardinal sine variogram with range parameter
<code>range</code></p>
</dd>
<dt><code>pow(range)</code></dt><dd><p> for an power variogram with range parameter
<code>range</code></p>
</dd>
<dt><code>lin(unit)</code></dt><dd><p> linear variogram 1 at <code>unit</code>.</p>
</dd>
<dt><code>nugget()</code></dt><dd><p> for adding a nuggeteffect.</p>
</dd>
</dl>

<p>Alternatively it can be any expression, which will be evaluated in
envir and should depende on a dataset of distantce vectrs <code>h</code>.
An effective range is that distance at which one reaches the sill (for spherical)
of 95% of its values (for all other models). Parametric ranges are given for those
models that do not have an effective range formula.
<br />
The matrix description always comes first. It can be <code>R1</code> for a
rank 1 matrix; <code>PSD</code> for a Positive Semidefinite matrix; \(S\)
for a scalar Sill factor to be multiplied with the identity matrix; or any other
construct evaluating to a matrix, like e.g. a function of some parameters with
default values, that if called is evaluated to a positive semidefinite
matrix. <code>R1</code> and <code>PSD</code> can also be written as calls
providing a vector or respectively a matrix providing the parameter.
<br />
The variogram is created with default parameter values. The parameters
can later be modified by modifiying the default parameter with
assignments like <code>formals(vg)$sPSD1 =
    parameterPosdefMat(4*diag(5))</code>.
We would anyway expect you to fit the model to the data by a command
like <code>fit.lmc(logratioVariogram(...),CompLinModCoReg(...))</code>  
</p>


<h3>Value</h3>

<p>A variogram function, with the extra class &quot;<code>CompLinModCoReg</code>&quot;. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>What to cite??
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vgram2lrvgram">vgram2lrvgram</a></code>,
<code><a href="#topic+vgmFit2lrv">vgmFit2lrv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(juraset)
X &lt;- with(juraset,cbind(X,Y))
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
CompLinModCoReg(~nugget()+sph(0.5)+R1*exp(0.7),comp)
CompLinModCoReg(~nugget()+R1*sph(0.5)+R1*exp(0.7)+(0.3*diag(5))*gauss(0.3),comp)
CompLinModCoReg(~nugget()+R1*sph(0.5)+R1(c(1,2,3,4,5))*exp(0.7),comp)

## End(Not run)
</code></pre>

<hr>
<h2 id='compOKriging'>Compositional Ordinary Kriging</h2><span id='topic+compOKriging'></span>

<h3>Description</h3>

<p>Geostatistical prediction for compositional data with missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compOKriging(comp,X,Xnew,vg,err=FALSE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compOKriging_+3A_comp">comp</code></td>
<td>
<p>an acomp compositional dataset</p>
</td></tr>
<tr><td><code id="compOKriging_+3A_x">X</code></td>
<td>
<p>A dataset of locations</p>
</td></tr>
<tr><td><code id="compOKriging_+3A_xnew">Xnew</code></td>
<td>
<p>The locations, where a geostatistical prediction should be
computed.</p>
</td></tr>
<tr><td><code id="compOKriging_+3A_vg">vg</code></td>
<td>
<p>A compositional variogram function.</p>
</td></tr>
<tr><td><code id="compOKriging_+3A_err">err</code></td>
<td>
<p>boolean: If true kriging errors are computed additionally. A bug was found here; the argument is currently disabled.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performes multivariate ordinary kriging of compositions
based on transformes addapted to the missings in every case. The
variogram is assumed to be a clr variogram.
</p>


<h3>Value</h3>

<p>A list of class <code>"logratioVariogram"</code>
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>The new locations as given by Xnew</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>The predicted values as acomp compositions.</p>
</td></tr>
<tr><td><code>err</code></td>
<td>
<p>A bug has been found here. This output is currently disabled (An ncol(Z)xDxD array with the clr kriging errors.)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Pawlowsky-Glahn, Vera and Olea, Ricardo A. (2004) Geostatistical
Analysis of Compositional Data, Oxford University Press, Studies in
Mathematical Geology
</p>
<p>Tolosana (2008) ...
</p>
<p>Tolosana, van den Boogaart, Pawlowsky-Glahn (2009) Estimating and
modeling variograms of compositional data with occasional missing
variables in R, StatGis09
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vgram2lrvgram">vgram2lrvgram</a></code>,
<code><a href="#topic+CompLinModCoReg">CompLinModCoReg</a></code>,
<code><a href="#topic+vgmFit">vgmFit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Load data
data(juraset)
X &lt;- with(juraset,cbind(X,Y))
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
lrv &lt;- logratioVariogram(comp,X,maxdist=1,nbins=10)
plot(lrv)

# Fit a variogram model
vgModel &lt;- CompLinModCoReg(~nugget()+sph(0.5)+R1*exp(0.7),comp)
fit &lt;- vgmFit2lrv(lrv,vgModel)
fit
plot(lrv,lrvg=vgram2lrvgram(fit$vg))

# Define A grid
x &lt;- (0:10/10)*6
y &lt;- (0:10/10)*6
Xnew &lt;- cbind(rep(x,length(y)),rep(y,each=length(x)))

# Kriging
erg &lt;- compOKriging(comp,X,Xnew,fit$vg,err=FALSE)
par(mar=c(0,0,1,0))
pairwisePlot(erg$Z,panel=function(a,b,xlab,ylab) {image(x,y,
                     structure(log(a/b),dim=c(length(x),length(y))),
                     main=paste("log(",xlab,"/",ylab,")",sep=""));points(X,pch=".")})


# Check interpolation properties 
ergR &lt;- compOKriging(comp,X,X,fit$vg,err=FALSE)
pairwisePlot(ilr(comp),ilr(ergR$Z))
ergR &lt;- compOKriging(comp,X,X+1E-7,fit$vg,err=FALSE)
pairwisePlot(ilr(comp),ilr(ergR$Z))
ergR &lt;- compOKriging(comp,X,X[rev(1:31),],fit$vg,err=FALSE)
pairwisePlot(ilr(comp)[rev(1:31),],ilr(ergR$Z))

## End(Not run)
</code></pre>

<hr>
<h2 id='compositional-class'>Class <code>"compositional"</code></h2><span id='topic+compositional-class'></span>

<h3>Description</h3>

<p>Abstract class containing all compositional classes with (at least, partly) a closed geometry: <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code> and <code><a href="#topic+ccomp">ccomp</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be created from it.</p>


<h3>Methods</h3>

<p>No methods defined with class &quot;compositional&quot; in the signature.
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>See Also</h3>

<p><code><a href="#topic+amounts-class">amounts-class</a></code> for classes with total information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("compositional")
</code></pre>

<hr>
<h2 id='compositions-package'>
Compositional Data Analysis
</h2><span id='topic+compositions-package'></span><span id='topic+compositions'></span>

<h3>Description</h3>

<p>&quot;compositions&quot; is a package for the analysis of compositional and
multivariate positive data (generally called &quot;amounts&quot;), based on several alternative approaches.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> compositions</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.0-8</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-01-25</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Compositional Data Analysis</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> K. Gerald van den Boogaart &lt;boogaart@hzdr.de&gt;, 
	Raimon Tolosana-Delgado, Matevz Bren  </td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> K. Gerald van den Boogaart &lt;support@boogaart.de&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.6)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> methods, utils, grDevices,  stats, tensorA, robustbase, bayesm, graphics, MASS</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> rgl (&gt;= 1.0.1),
combinat,
energy,
knitr,
rmarkdown</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Provides functions for the consistent analysis of compositional 
  data (e.g. portions of substances) and positive numbers (e.g. concentrations) 
  in the way proposed by J. Aitchison and V. Pawlowsky-Glahn.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> http://www.stat.boogaart.de/compositions/</td>
</tr>
<tr>
 <td style="text-align: left;">
VignetteBuilder: </td><td style="text-align: left;"> knitr</td>
</tr>
<tr>
 <td style="text-align: left;">
RoxygenNote: </td><td style="text-align: left;"> 7.1.1</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>


                        structure
Aar                     Composition of glaciar sediments from the Aar 
                        massif (Switzerland)
acomp                   Aitchison compositions
acompmargin             Marginal compositions in Aitchison Compositions
Activity10              Activity patterns of a statistician for 20 days
Activity31              Activity patterns of a statistician for 20 days
alr                     Additive log ratio transform
AnimalVegetation        Animal and vegetation measurement
+.aplus                 vectorial arithmetic for data sets with aplus
                        class
aplus                   Amounts analysed in log-scale
apt                     Additive planar transform
ArcticLake              Artic lake sediment samples of different water
                        depth
arrows3D                arrows in 3D, based on package rgl
as.data.frame.acomp     Convert "compositions" classes to data frames
axis3D                  Drawing a 3D coordiante system to a plot, based
                        on package rgl
balance                 Compute balances for a compositional dataset.
barplot.acomp           Bar charts of amounts
Bayesite                Permeabilities of bayesite
binary                  Treating binary and g-adic numbers
biplot3D                Three-dimensional biplots, based on package rgl
Blood23                 Blood samples
Boxite                  Compositions and depth of 25 specimens of
                        boxite
boxplot.acomp           Displaying compositions and amounts with
                        box-plots
cdt                     Centered default transform
ClamEast                Color-size compositions of 20 clam colonies
                        from East Bay
ClamWest                Color-size compositions of 20 clam colonies
                        from West Bay
clo                     Closure of a composition
clr                     Centered log ratio transform
clr2ilr                 Convert between clr and ilr, and between cpt
                        and ipt.
ClusterFinder1          Heuristics to find subpopulations of outliers
CoDaDendrogram          Dendrogram representation of acomp or rcomp
                        objects
coloredBiplot           A biplot providing somewhat easier access to
                        details of the plot.
colorsForOutliers1      Create a color/char palette or for groups of
                        outliers
CompLinModCoReg         Compositional Linear Model of Coregionalisation
compOKriging            Compositional Ordinary Kriging
compositions-package    library(compositions)
ConfRadius              Helper to compute confidence ellipsoids
cor.acomp               Correlations of amounts and compositions
Coxite                  Compositions, depths and porosities of 25
                        specimens of coxite
cpt                     Centered planar transform
DiagnosticProb          Diagnostic probabilities
dist                    Distances in variouse approaches
ellipses                Draw ellipses
endmemberCoordinates    Recast amounts as mixtures of end-members
Firework                Firework mixtures
geometricmean           The geometric mean
getDetectionlimit       Gets the detection limit stored in the data set
Glacial                 Compositions and total pebble counts of 92
                        glacial tills
groupparts              Group amounts of parts
Hongite                 Compositions of 25 specimens of hongite
HouseholdExp            Household Expenditures
Hydrochem               Hydrochemical composition data set of Llobregat
                        river basin water (NE Spain)
idt                     Isometric default transform
iit                     Isometric identity transform
ilr                     Isometric log ratio transform
ilrBase                 The canonical basis in the clr plane used for
                        ilr and ipt transforms.
ilt                     Isometric log transform
ipt                     Isometric planar transform
is.acomp                Check for compositional data type
IsMahalanobisOutlier    Checking for outliers
isoPortionLines         Isoportion- and Isoproportion-lines
juraset                 The jura dataset
kingTetrahedron         Ploting composition into rotable tetrahedron
Kongite                 Compositions of 25 specimens of kongite
lines.rmult             Draws connected lines from point to point.
logratioVariogram       Empirical variograms for compositions
MahalanobisDist         Compute Mahalanobis distances based von robust
                        Estimations
mean.acomp              Mean amounts and mean compositions
meanRow                 The arithmetic mean of rows or columns
Metabolites             Steroid metabolite patterns in adults and
                        children
missingProjector        Returns a projector the the observed space in
                        case of missings.
missingsInCompositions
                        The policy of treatment of missing values in
                        the "compositions" package
missingSummary          Classify and summarize missing values in a
                        dataset
mix.2aplus              Transformations from 'mixtures' to
                        'compositions' classes
mix.Read                Reads a data file in a mixR format
mvar                    Metric summary statistics of real, amount or
                        compositional data
names.acomp             The names of the parts
normalize               Normalize vectors to norm 1
norm.default            Vector space norm
oneOrDataset            Treating single compositions as one-row
                        datasets
OutlierClassifier1      Detect and classify compositional outliers.
outlierplot             Plot various graphics to analyse outliers.
outliersInCompositions
                        Analysing outliers in compositions.
pairwisePlot            Creates a paneled plot like pairs for two
                        different datasets.
parametricPosdefMat     Unique parametrisations for matrices.
perturbe                Perturbation of compositions
plot3D                  plot in 3D based on rgl
plot3D.acomp            3D-plot of compositional data
plot3D.aplus            3D-plot of positive data
plot3D.rmult            plot in 3D based on rgl
plot3D.rplus            plot in 3D based on rgl
plot.acomp              Ternary diagrams
plot.aplus              Displaying amounts in scatterplots
plot.logratioVariogram
                        Empirical variograms for compositions
plot.missingSummary     Plot a Missing Summary
pMaxMahalanobis         Compute distributions of empirical Mahalanobis
                        distances based on simulations
PogoJump                Honk Kong Pogo-Jumps Championship
power.acomp             Power transform in the simplex
powerofpsdmatrix        power transform of a matrix
princomp.acomp          Principal component analysis for Aitchison
                        compositions
princomp.aplus          Principal component analysis for amounts in log
                        geometry
princomp.rcomp          Principal component analysis for real
                        compositions
princomp.rmult          Principal component analysis for real data
princomp.rplus          Principal component analysis for real amounts
print.acomp             Printing compositional data.
qHotellingsTsq          Hotellings T square distribution
qqnorm.acomp            Normal quantile plots for compositions and
                        amounts
R2                      R square
rAitchison              Aitchison Distribution
+.rcomp                 Arithmetic operations for compositions in a
                        real geometry
rcomp                   Compositions as elements of the simplex
                        embedded in the D-dimensional real space
rcompmargin             Marginal compositions in real geometry
rDirichlet              Dirichlet distribution
read.geoeas             Reads a data file in a geoeas format
relativeLoadings        Loadings of relations of two amounts
replot                  Modify parameters of compositional plots.
rlnorm.rplus            The multivariate lognormal distribution

+.rmult                 vectorial arithmetic for datasets in a
                        classical vector scale
rmult                   Simple treatment of real vectors
rnorm.acomp             Normal distributions on special spaces
robustnessInCompositions
                        Handling robustness issues and outliers in
                        compositions.
+.rplus                 vectorial arithmetic for data sets with rplus
                        class
rplus                   Amounts i.e. positive numbers analysed as
                        objects of the real vector space
runif.acomp             The uniform distribution on the simplex
scalar                  Parallel scalar products
scale                   Normalizing datasets by centering and scaling
Sediments               Proportions of sand, silt and clay in sediments
                        specimens
segments.rmult          Draws straight lines from point to point.
SerumProtein            Serum Protein compositions of blood samples
ShiftOperators          Shifts of machine operators
simpleMissingSubplot    Ternary diagrams
SimulatedAmounts        Simulated amount datasets
simulateMissings        Artifical simulation of various kinds of
                        missings
Skulls                  Measurement of skulls
SkyeAFM                 AFM compositions of 23 aphyric Skye lavas
split.acomp             Splitting datasets in groups given by factors
straight                Draws straight lines.
summary.acomp           Summarizing a compositional dataset in terms of
                        ratios
summary.aplus           Summaries of amounts
summary.rcomp           Summary of compositions in real geometry
sumMissingProjector     Compute the global projector to the observed
                        subspace.
Supervisor              Proportions of supervisor's statements assigned
                        to different categories
ternaryAxis             Axis for ternary diagrams
totals                  Total sum of amounts
tryDebugger             Empirical variograms for compositions
ult                     Uncentered log transform
var.acomp               Variances and covariances of amounts and
                        compositions
variation               Variation matrices of amounts and compositions
var.lm                  Residual variance of a model
vcovAcomp               Variance covariance matrix of parameters in
                        compositional regression
vgmFit                  Compositional variogram model fitting
vgram2lrvgram           vgram2lrvgram
vgram.sph               Variogram functions
WhiteCells              White-cell composition of 30 blood samples by
                        two different methods
Yatquat                 Yatquat fruit evaluation
zeroreplace             Zero-replacement routine
</pre>
<p>To get detailed &quot;getting started&quot; introduction use
<code>help.start()</code> or <code>help.start(browser="myfavouritebrowser")</code>
Go to &quot;Packages&quot; then &quot;compositions&quot; and then &quot;overview&quot;
and then launch the file &quot;UsingCompositions.pdf&quot; from there. Please
also check the web-site: http://www.stat.boogaart.de/compositions/ for
improved material and our new book expected to appear spring 2009.  
<br />
The package is devoted to the analysis of multiple amounts. Amounts
have typically non-negative values, and often sum up to 100% or one. These
constraints lead to spurious effects on the covariance structure, 
as pointed out by Chayes (1960). The problem is treated rigorously 
in the monography by Aitchison (1986), 
who characterizes compositions as vectors having a relative scale,
and identifies its sample space with the D-part simplex. 
However still (i.e. 2005) most statistical packages do not
provided any support for this scale.
<br />
The grounding idea of the package exploits the class concept: 
the analyst gives the data a compositional or amount class, and
then all further analysis are (should be) automatically  done
in a consistent way, e.g. <code>x &lt;- acomp(X); plot(x)</code> 
should plot the data as a composition (in a ternary diagram) 
directly without any further interaction of the user. 
<br />
The package provides four different approaches to analyse
amounts. These approaches are associated to four R-classes,
representing four different geometries of the sampling space of
amounts. These geometries depend on two questions: whether the total sum
of the amounts is a relevant information, and which is the meaningful
measure of difference of the data.
<br />
</p>
<p><code><a href="#topic+rplus">rplus</a></code> : (Real Plus) The total amount matters, and amounts should be
compared on an absolute basis. i.e. the difference between 1g and
2g is the same as the difference between 1kg and 1001g, one gram.
<br />
<code><a href="#topic+aplus">aplus</a></code> : (Aitchison Plus) The total amount matters,
but amounts should be compared relatively, i.e. the difference
between 1mg and 2mg is the same as that of 1g and 2g: the double.
<br />
<code><a href="#topic+acomp">acomp</a></code> : (Aitchison composition) the total amount is constant 
(or an artifact of the sampling/measurement procedure), and the meaningful 
difference is a relative one. This class follows
the original proposals of Aitchison.
<br />
<code><a href="#topic+rcomp">rcomp</a></code> : (Real composition) the sum
is a constant, and the difference in amount from 0% to 1% and from
10% to 11% is regarded as equal. This class represents the
raw/naive treatment of compositions as elements of the real simplex based
on an absolute geometry. This treatment is implicitly used 
in most amalgamation problems. However the whole approach suffers
from the drawbacks and problems discussed in Chayes (1960) and Aitchison
(1986).
<br />
The aim of the package is to provide all the functionality to do a
consistent analysis in all of these approaches and to make the
results obtained with different geometries as easy to compare as possible. 
</p>


<h3>Note</h3>

<p>The package compositions has grown a lot in the last year:
missings, robust estimations, outlier detection and classification,
codadendrogram. This makes everything much more complex especially
from the side of programm testing. Thus we would like to urge our
users to report all errors and problems of the lastest version (please
check first) to
support@boogaart.de.
</p>


<h3>Author(s)</h3>

<p>K. Gerald van den Boogaart &lt;boogaart@hzdr.de&gt;, 
	Raimon Tolosana-Delgado, Matevz Bren  
</p>
<p>Maintainer: K. Gerald van den Boogaart &lt;support@boogaart.de&gt;
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>
<p>Billheimer, D., P. Guttorp, W.F. and Fagan (2001) Statistical interpretation of species composition,
<em>Journal of the American Statistical Association</em>, <b>96</b> (456), 1205-1214<br />
</p>
<p>Chayes, F. (1960). On correlation between variables of constant
sum. Journal of Geophysical Research 65~(12), 4185&ndash;4193.
</p>
<p>Pawlowsky-Glahn, V. and J.J. Egozcue (2001) Geometric approach to
statistical analysis on the simplex. <em>SERRA</em> <b>15</b>(5), 384-398<br />
</p>
<p>Pawlowsky-Glahn, V. (2003) Statistical modelling on coordinates. In: 
Thi\'o -Henestrosa, S. and Mart\'in-Fern\'a ndez, J.A. (Eds.)
<em>Proceedings of the 1st International Workshop on Compositional Data Analysis</em>,
Universitat de Girona, ISBN 84-8458-111-X, <a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p>Mateu-Figueras, G. and Barcel\'o-Vidal, C. (Eds.)
<em>Proceedings of the 2nd International Workshop on Compositional Data Analysis</em>,
Universitat de Girona, ISBN 84-8458-222-1, <a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a><br />
</p>
<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+compositions-package">compositions-package</a>, <a href="#topic+missingsInCompositions">missingsInCompositions</a>,
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a>, <a href="#topic+outliersInCompositions">outliersInCompositions</a>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(compositions)      # load library
data(SimulatedAmounts)     # load data sa.lognormals
x &lt;- acomp(sa.lognormals)  # Declare the dataset to be compositional
                           # and use relative geometry
plot(x)                    # plot.acomp : ternary diagram
ellipses(mean(x),var(x),r=2,col="red")  # Simplex 2sigma predictive region
pr &lt;- princomp(x)
straight(mean(x),pr$Loadings) 

x &lt;- rcomp(sa.lognormals)  # Declare the dataset to be compositional
                           # and use absolute geometry
plot(x)                    # plot.acomp : ternary diagram
ellipses(mean(x),var(x),r=2,col="red")  # Real 2sigma predictive region
pr &lt;- princomp(x)          
straight(mean(x),pr$Loadings) 
</code></pre>

<hr>
<h2 id='ConfRadius'>Helper to compute confidence ellipsoids</h2><span id='topic+ConfRadius'></span>

<h3>Description</h3>

<p>Computes the quantile of the Mahalanobis distance needed to draw
confidence ellipsoids.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConfRadius(model,prob=1-alpha,alpha)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConfRadius_+3A_model">model</code></td>
<td>
<p>A multivariate linear model</p>
</td></tr>
<tr><td><code id="ConfRadius_+3A_prob">prob</code></td>
<td>
<p>The confidence probability</p>
</td></tr>
<tr><td><code id="ConfRadius_+3A_alpha">alpha</code></td>
<td>
<p>The alpha error allowed, i.e. the complement of the
confidence probability</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the radius to be used in confidence ellipses for the
parameters based on the Hottelings <code class="reqn">T^2</code> distribution. 
</p>


<h3>Value</h3>

<p>a scalar
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+mvar">mvar</a></code>, <code><a href="stats.html#topic+AIC">AIC</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
model &lt;- lm(ilr(sa.groups)~sa.groups.area)
cf = coef(model)
plot(ilrInv(cf, x=sa.groups))
for(i in 1:nrow(cf)){
  vr = vcovAcomp(model)[,,i,i]
  vr = ilrvar2clr(vr)
  ellipses(ilrInv(cf[i,]), vr, r=ConfRadius(model, alpha=0.05) )
 }
</code></pre>

<hr>
<h2 id='cor.acomp'>Correlations of amounts and compositions</h2><span id='topic+cor'></span><span id='topic+cor.default'></span><span id='topic+cor.acomp'></span><span id='topic+cor.rcomp'></span><span id='topic+cor.aplus'></span><span id='topic+cor.rplus'></span><span id='topic+cor.rmult'></span>

<h3>Description</h3>

<p>Computes the correlation matrix in the various approaches of compositional
and amount  data analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          cor(x,y=NULL,...)
          ## Default S3 method:
cor(x, y=NULL, use="everything", 
                       method=c("pearson", "kendall", "spearman"),...)
          ## S3 method for class 'acomp'
cor(x,y=NULL,...,robust=getOption("robust"))
          ## S3 method for class 'rcomp'
cor(x,y=NULL,...,robust=getOption("robust"))
          ## S3 method for class 'aplus'
cor(x,y=NULL,...,robust=getOption("robust"))
          ## S3 method for class 'rplus'
cor(x,y=NULL,...,robust=getOption("robust"))
          ## S3 method for class 'rmult'
cor(x,y=NULL,...,robust=getOption("robust"))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor.acomp_+3A_x">x</code></td>
<td>
<p>a data set, eventually of amounts or compositions</p>
</td></tr>
<tr><td><code id="cor.acomp_+3A_y">y</code></td>
<td>
<p>a second data set, eventually of amounts or compositions</p>
</td></tr>
<tr><td><code id="cor.acomp_+3A_use">use</code></td>
<td>
<p>see <code><a href="stats.html#topic+cor">cor</a></code></p>
</td></tr>
<tr><td><code id="cor.acomp_+3A_method">method</code></td>
<td>
<p>see <code><a href="stats.html#topic+cor">cor</a></code></p>
</td></tr>
<tr><td><code id="cor.acomp_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stats.html#topic+cor">cor</a></code>
e.g. <code>use</code></p>
</td></tr>
<tr><td><code id="cor.acomp_+3A_robust">robust</code></td>
<td>

<p>A description of a robust estimator. FALSE for the classical
estimators.  See <a href="#topic+mean.acomp">mean.acomp</a> for
further details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The correlation matrix does not make much sense for compositions.
</p>
<p>In R versions older than v2.0.0, <code><a href="stats.html#topic+cor">cor</a></code> was defined
in package &ldquo;base&rdquo; instead of in &ldquo;stats&rdquo;.
This might produce some misfunction.
</p>


<h3>Value</h3>

<p>The correlation  matrix.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+var.acomp">var.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
meanCol(sa.lognormals)
cor(acomp(sa.lognormals5[,1:3]),acomp(sa.lognormals5[,4:5]))
cor(rcomp(sa.lognormals5[,1:3]),rcomp(sa.lognormals5[,4:5]))
cor(aplus(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))
cor(rplus(sa.lognormals5[,1:3]),rplus(sa.lognormals5[,4:5]))
cor(acomp(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))
</code></pre>

<hr>
<h2 id='Coxite'>Compositions, depths and porosities of 25 specimens of coxite</h2><span id='topic+Coxite'></span><span id='topic+Data04'></span>

<h3>Description</h3>

<p>A mineral compositions of 25 rock specimens of coxite type.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite, the depth of location, and porosity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Coxite)
</code></pre>


<h3>Details</h3>

<p>A mineral compositions of 25 rock specimens of coxite type.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite,the recorded depth of location
of each specimen, and porosity. Porosity is the percentage of void space
that the specimen contains.
We abbreviate the minerals names to A, B, C, D, E.
</p>
<p>All row percentage sums to 100.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name BOXITE.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 4, pp4.
</p>

<hr>
<h2 id='cpt'>Centered planar transform</h2><span id='topic+cpt'></span><span id='topic+cptInv'></span>

<h3>Description</h3>

<p>Compute the centered planar  transform of a (dataset of)
compositions and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          cpt( x,... )
          cptInv( z,...,orig=gsi.orig(z) )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cpt_+3A_x">x</code></td>
<td>
<p>a composition or a data.matrix of compositions, not necessarily closed</p>
</td></tr>
<tr><td><code id="cpt_+3A_z">z</code></td>
<td>
<p>the cpt-transform of a composition or a data matrix of
cpt-transforms of compositions. It is checked that the z sum up to
0.</p>
</td></tr>
<tr><td><code id="cpt_+3A_...">...</code></td>
<td>
<p>generic arguments. not used.</p>
</td></tr>
<tr><td><code id="cpt_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked 
by the inverse transformation. It is especially used to
reconstruct the names of the parts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cpt-transform maps a composition in the D-part real-simplex
isometrically to a D-1 dimensional euclidian vector space, identified with a plane parallel 
to the simplex but passing through the origin. However the
transformation is not injective and does not even reach the whole
plane. Thus resulting covariance matrices are always singular.
<br /> 
</p>
<p>The data can then
be analysed in this transformed space by all classical multivariate
analysis tools not relying on a full rank of the covariance matrix. See
<code><a href="#topic+ipt">ipt</a></code> and <code><a href="#topic+apt">apt</a></code> for alternatives. The
interpretation of the results is relatively easy since the relation of each 
transformed component to the original parts is preserved.<br />
</p>
<p>The centered planar transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> cpt(x)_i := clo(x)_i - \frac1D </code>
</p>



<h3>Value</h3>

<p><code>cpt</code> gives the centered planar transform,
<code>cptInv</code> gives closed compositions with the given cpt-transforms.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+apt">apt</a></code>,<code><a href="#topic+ipt">ipt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- cpt(c(1,2,3)))
cptInv(tmp)
cptInv(tmp) - clo(c(1,2,3)) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(cpt(cdata),pch=".") 
</code></pre>

<hr>
<h2 id='DiagnosticProb'>Diagnostic probabilities</h2><span id='topic+DiagnosticProb'></span><span id='topic+Data17'></span>

<h3>Description</h3>

<p>Data record the probabilities assigned by subjective diagnostic of 15
clinicians and 15 statisticians.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DiagnosticProb)
</code></pre>


<h3>Details</h3>

<p>The data consist of 30 cases: 15 diagnostics probabilities assigned by clinicians,
15 diagnostics probabilities assigned by statisticians, and
4 variables: probabilities A, B, and C, and type i.e. 1 for clinicians, 
2 for statisticians.
</p>
<p>In the study of subjective performance in inferential task the subject is faced
with the finite set of mutually exclusive and exhaustive hypothesis, 
and the basis of specific information presented to him/her is required to
divide the available unit of probability among these probabilities.
In this study the task is presented as a problem of differential diagnosis of
three mutually exclusive and exhaustive diseases of students, known under the
generic title of 'newmath syndrome',
</p>

<table>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> A </td><td style="text-align: left;"> - algebritis,  </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> B </td><td style="text-align: left;"> - bilateral paralexia,  </td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> C </td><td style="text-align: left;"> - calculus deficiency.  
 </td>
</tr>

</table>

<p>The subject, playing the role of diagnostician, is informed that the three diseases
types are equally common and is shown the results of 10 diagnostic tests on 60
previous cases of known diagnosis, 20 of each type. The subject is then shown the results
of the 10 tests for a new undiagnosed cases and asked to assign diagnostic probabilities
to the three possible disease types.
</p>
<p>Data record the subjective assessments of 15
clinicians and 15 statisticians for the same case. For this case the objective
diagnosis probabilities are known to be $(.08, .05, .87).$
</p>
<p>All row probabilities sum to 1, except for some rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name DIAGPROB.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 17, pp20.
</p>

<hr>
<h2 id='dist'>Distances in variouse approaches</h2><span id='topic+dist'></span><span id='topic+dist.default'></span>

<h3>Description</h3>

<p>Calculates a distance matrix from a data set. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist(x,...)
## Default S3 method:
dist(x,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist_+3A_x">x</code></td>
<td>
<p>a  dataset</p>
</td></tr>
<tr><td><code id="dist_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stats.html#topic+dist">dist</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance is computed based on <code><a href="#topic+cdt">cdt</a></code>
</p>


<h3>Value</h3>

<p>a distance matrix
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
phc &lt;- function(d) { plot(hclust(d))}
phc(dist(iris[,1:4]))
phc(dist(acomp(sa.lognormals),method="manhattan"))
phc(dist(rcomp(sa.lognormals)))
phc(dist(aplus(sa.lognormals)))
phc(dist(rplus(sa.lognormals)))

</code></pre>

<hr>
<h2 id='ellipses'>Draw ellipses</h2><span id='topic+ellipses'></span><span id='topic+ellipses.rmult'></span><span id='topic+ellipses.acomp'></span><span id='topic+ellipses.rcomp'></span><span id='topic+ellipses.aplus'></span><span id='topic+ellipses.rplus'></span>

<h3>Description</h3>

<p>Draws ellipses from a mean and a variance into a plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'acomp'
ellipses(mean,var,r=1,...,steps=72,
                                         thinRatio=NULL,aspanel=FALSE)
  ## S3 method for class 'rcomp'
ellipses(mean,var,r=1,...,steps=72,
                                         thinRatio=NULL,aspanel=FALSE)
  ## S3 method for class 'aplus'
ellipses(mean,var,r=1,...,steps=72,thinRatio=NULL)
  ## S3 method for class 'rplus'
ellipses(mean,var,r=1,...,steps=72,thinRatio=NULL)
  ## S3 method for class 'rmult'
ellipses(mean,var,r=1,...,steps=72,thinRatio=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ellipses_+3A_mean">mean</code></td>
<td>
<p>a compositional dataset or value of means or midpoints of
the ellipses</p>
</td></tr>
<tr><td><code id="ellipses_+3A_var">var</code></td>
<td>
<p>a variance matrix or a set of variance matrices given by
<code>var[i,,]</code> (multiple covariance matrices are not consitently
implemented as of today). The principal axis of the variance give
the axis of
the ellipses, whereas the square-root of the eigenvalues times r give the
half-diameters of the ellipse.</p>
</td></tr>
<tr><td><code id="ellipses_+3A_r">r</code></td>
<td>
<p>a scaling of the half-diameters</p>
</td></tr>
<tr><td><code id="ellipses_+3A_...">...</code></td>
<td>
<p>further graphical parameters</p>
</td></tr>
<tr><td><code id="ellipses_+3A_steps">steps</code></td>
<td>
<p>the number of discretisation points to draw the
ellipses.</p>
</td></tr>
<tr><td><code id="ellipses_+3A_thinratio">thinRatio</code></td>
<td>
<p>The ellipse function now be default plots the whole
ellipsiod by giving its principle circumferences. However this is
not reasonable for the thinner directions. If a direction other than
the first two eigendirections has an eigenvalue not bigger than
thinRatio*rmax it is not plotted. Thus thinRatio=1 reinstantiates
the old behavior of the function. Later thinratio=NULL will become the
default, in which case the projection of the ellipse is
plotted. However this is not implemented yet. 
</p>
</td></tr>
<tr><td><code id="ellipses_+3A_aspanel">aspanel</code></td>
<td>
<p>Is the function called as slave to draw in a panel of a
gsi.pairs plot, or as a user function setting up the plots. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ellipsoid/ellipse drawn is given by the solutions of
</p>
<p style="text-align: center;"><code class="reqn">(x-mean)^tvar^{-1}(x-mean)=r^2</code>
</p>

<p>in the respective geometry of the parameter space. Note that
these ellipses can be added to panel plots (by means of 
orthogonal projections in the corresponding geometry).
</p>
<p>There are actually three possibilities of drawing a a hyperdimensional
ellipsoid or ellipse and non of them is perfect.
</p>

<dl>
<dt>thinRatio=1.1</dt><dd>
<p>This works like, what was implemented in the older versions of
compositons, but never correctly documented. It draws an ellipse
with main axes given by the two largest Eigendirections of the
<code>var</code>-Matrix given. 
</p>
</dd>
<dt>thinRatio=0</dt><dd>
<p>Draws all the ellipses given by every pair of eigendirections. In
this way we get a visual impression of the high dimensional
ellipsoid represend by the variance matrix. However the plots gets
fastly cluttered in dimensions, when D&gt;4. A 0&lt;thinRatio&lt;1 can avoid
using eigendirection with small extend (i.e. smaller than
thinRatio*largest Eigenvalue. 
</p>
</dd>
<dt>thinRatio=NULL</dt><dd>
<p>Draws in each Panel a two dimensional ellipse representing the
marginal variance in the projection of the plot, if var was to be
interpreted as a variance matrix. This can be seen as some sort of
projection of the high dimensional ellipsoid, but is not necessarily
its visual outline. 
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)

plot(acomp(sa.lognormals))
tt&lt;-acomp(sa.lognormals); ellipses(mean(tt),var(tt),r=2,col="red")
tt&lt;-rcomp(sa.lognormals); ellipses(mean(tt),var(tt),r=2,col="blue")

plot(aplus(sa.lognormals[,1:2]))
tt&lt;-aplus(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="red")
tt&lt;-rplus(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="blue")

plot(rplus(sa.lognormals[,1:2]))
tt&lt;-aplus(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="red")
tt&lt;-rplus(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="blue")
tt&lt;-rmult(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="green")

</code></pre>

<hr>
<h2 id='endmemberCoordinates'>Recast amounts as mixtures of end-members</h2><span id='topic+endmemberCoordinates'></span><span id='topic+endmemberCoordinatesInv'></span><span id='topic+endmemberCoordinates.default'></span><span id='topic+endmemberCoordinates.acomp'></span><span id='topic+endmemberCoordinates.aplus'></span><span id='topic+endmemberCoordinates.rplus'></span><span id='topic+endmemberCoordinatesInv'></span><span id='topic+endmemberCoordinatesInv.rmult'></span><span id='topic+endmemberCoordinatesInv.acomp'></span><span id='topic+endmemberCoordinatesInv.aplus'></span><span id='topic+endmemberCoordinatesInv.rcomp'></span><span id='topic+endmemberCoordinatesInv.rplus'></span>

<h3>Description</h3>

<p>Computes the convex combination of amounts as mixtures of <code>endmembers</code>
to explain <code>X</code> as well as possible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    endmemberCoordinates(X,...)
    endmemberCoordinatesInv(K,endmembers,...)
    ## Default S3 method:
endmemberCoordinates(X,
                         endmembers=diag(gsi.getD(X)), ...)
    ## S3 method for class 'acomp'
endmemberCoordinates(X,
                    endmembers=clrInv(diag(gsi.getD(X))),...)
    ## S3 method for class 'aplus'
endmemberCoordinates(X,endmembers,...)
    ## S3 method for class 'rplus'
endmemberCoordinates(X,endmembers,...)
    ## S3 method for class 'rmult'
endmemberCoordinatesInv(K,endmembers,...)
    ## S3 method for class 'acomp'
endmemberCoordinatesInv(K,endmembers,...)
    ## S3 method for class 'rcomp'
endmemberCoordinatesInv(K,endmembers,...)
    ## S3 method for class 'aplus'
endmemberCoordinatesInv(K,endmembers,...)
    ## S3 method for class 'rplus'
endmemberCoordinatesInv(K,endmembers,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="endmemberCoordinates_+3A_x">X</code></td>
<td>
<p>a data set of amounts or compositions, to be represented in
as convex combination of the <code>endmembers</code> in the given geometry</p>
</td></tr>
<tr><td><code id="endmemberCoordinates_+3A_k">K</code></td>
<td>
<p>weights of the <code>endmembers</code> in the convex combination</p>
</td></tr>
<tr><td><code id="endmemberCoordinates_+3A_endmembers">endmembers</code></td>
<td>
<p>a dataset of compositions of the same class as X. 
The number of endmembers given must not exceed the dimension of 
the space plus one.</p>
</td></tr>
<tr><td><code id="endmemberCoordinates_+3A_...">...</code></td>
<td>
<p>currently unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The convex combination is performed in the respective geometry. This
means that, for rcomp objects, positivity of the result is only guaranteed 
with endmembers corresponding to extremal individuals of the sample, or 
completely outside its hull. Note also that, in acomp geometry, the 
endmembers must necessarily be outside the hull. 
<br />
The main idea behind this functions is that the composition actually 
observed came from a convex combination of some extremal
compositions, specified by <code>endmembers</code>. Up to now, this is considered as
meaningful only in rplus geometry, and under some special circumstances, 
in rcomp geometry. It is not meaningful in terms of mass conservation 
in acomp and aplus geometries, because these geometries do not preserve
mass: whether such an operation has an interpretation is still a matter of 
debate. In rcomp geometry, the convex combination is dependent on the units of
measurements, and will be completely different for volume and mass %. 
Even more, it is valid only if the whole composition is observed (!). 
</p>


<h3>Value</h3>

<p>The <code>endmemberCoordinates</code> functions give a <code><a href="#topic+rmult">rmult</a></code>
data set with the weights (a.k.a. barycentric coordinates) allowing 
to build <code>X</code> as good as possible as a convex combination 
(a mixture) from <code>endmembers</code>. The result is of class rmult
because there is no guarantee that the resulting weights are positive
(although they sum up to one).
<br />
The <code>endmemberCoordinatesInv</code> functions reconstruct the convex
combination from the weights <code>K</code> and the given
<code>endmembers</code>. The class of <code>endmembers</code> determines the
geometry chosen and the class of the result.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>,
Raimon Tolosana-Delgado</p>


<h3>References</h3>

<p>Shurtz, Robert F., 2003. Compositional geometry and mass conservation.
Mathematical Geology 35 (8), 972&ndash;937.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
ep &lt;- aplus(rbind(c(2,1,2),c(2,2,1),c(1,2,2)))
# mix the endmembers in "ep" with weights given by "sa.lognormals"
dat &lt;- endmemberCoordinatesInv(acomp(sa.lognormals),acomp(ep))
par(mfrow=c(1,2))
plot(dat)
  plot(acomp(ep),add=TRUE,col="red",pch=19)
# compute the barycentric coordinates of the mixture in the "end-member simplex"
plot( acomp(endmemberCoordinates(dat,acomp(ep))))

dat &lt;- endmemberCoordinatesInv(rcomp(sa.lognormals),rcomp(ep))
plot(dat)
plot( rcomp(endmemberCoordinates(dat,rcomp(ep))))

dat &lt;- endmemberCoordinatesInv(aplus(sa.lognormals),aplus(ep))
plot(dat)
plot( endmemberCoordinates(dat,aplus(ep)))

dat &lt;- endmemberCoordinatesInv(rplus(sa.lognormals),rplus(ep))
plot(dat)
plot(endmemberCoordinates(rplus(dat),rplus(ep)))


</code></pre>

<hr>
<h2 id='Firework'>Firework mixtures</h2><span id='topic+Firework'></span><span id='topic+Data13'></span>

<h3>Description</h3>

<p>Data show two measured properties, brilliance and vorticity, of 81 girandoles
composed of different mixtures of five ingredients: a &ndash; e.
Of these ingredients, a and b are the primary light-producting, 
c is principal propellant, and d and e are binding agents for c. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Firework)
</code></pre>


<h3>Details</h3>

<p>The data consist of 81 cases and 7 variables: ingredients a, b, c, d, and e, 
and the two measured properties <em>brilliance</em> and <em>vorticity</em>.
The 81 different mixtures form a special experiment design. First the 81 
possible quadruples formed from the three values -1, 0, 1 were arranged 
in ascending order. Then for each such quadruple z, the corresponding mixture
x(z)=(a,b,c,d,e)=alrInv(z) is computed. Thus the No. 4 girandole corresponds 
to z=(-1,-1,0,-1) and so is composed of a mixture x=(.12,.12,.32,.12,.32) 
of the five ingredients. All 5-part mixtures sum up to one.</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name YATQUAD.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 13, pp17.  
</p>

<hr>
<h2 id='fitdirichlet'>Fitting a Dirichlet distribution</h2><span id='topic+fitDirichlet'></span>

<h3>Description</h3>

<p> Fits a Dirichtlet Distribution to a dataset
by maximum likelihood.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>fitDirichlet(x,elog=mean(ult(x)),alpha0=rep(1,length(elog)),maxIter=20,n=nrow(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitdirichlet_+3A_x">x</code></td>
<td>
<p>a dataset of compositions (acomp)</p>
</td></tr>
<tr><td><code id="fitdirichlet_+3A_elog">elog</code></td>
<td>
<p>the expected log can provided instead of the dataset
itself.</p>
</td></tr>
<tr><td><code id="fitdirichlet_+3A_alpha0">alpha0</code></td>
<td>
<p>the start value for alpha parameter in the
iteration</p>
</td></tr>
<tr><td><code id="fitdirichlet_+3A_maxiter">maxIter</code></td>
<td>
<p>The maximum number of iterations in the
Fischer scoring method. </p>
</td></tr>
<tr><td><code id="fitdirichlet_+3A_n">n</code></td>
<td>
<p>the number of datapoints used to estimate elog</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fitting is done using a modified version of the Fisher-Scoring
method using analytiscal expressions for log mean and log variance. The
modification is introducted to prevent the algorithm from leaving the
admissible parameter set. It reduced the stepsize to at most have of
distance to the limit of the admissible parameter set.
</p>


<h3>Value</h3>

<table>
<tr><td><code>alpha</code></td>
<td>
<p>the estimated parameter</p>
</td></tr>
<tr><td><code>loglikelihood</code></td>
<td>
<p>the likelihood</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The dimension of the dataset minus the dimension of the
parameter</p>
</td></tr>
</table>


<h3>Missing Policy</h3>

<p>Up to now the fitting can not handle missings. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+rDirichlet">rDirichlet</a></code>, <code>acompDirichletGOF.test</code>,
<code><a href="#topic+runif.acomp">runif.acomp</a></code>, <code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>, </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rDirichlet.acomp(100,c(1,2,3,4))
fitDirichlet(x)
</code></pre>

<hr>
<h2 id='fitSameMeanDifferentVarianceModel'>Fit Same Mean Different Variance Model</h2><span id='topic+fitSameMeanDifferentVarianceModel'></span>

<h3>Description</h3>

<p>Fits a model of the same mean, but different variances model to a set
of several multivariate normal groups by maximum likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitSameMeanDifferentVarianceModel(x)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitSameMeanDifferentVarianceModel_+3A_x">x</code></td>
<td>
<p>list of rmult type datasets</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function tries to fit a normal model with different variances but the
same mean between different groups.
</p>


<h3>Value</h3>

<table>
<tr><td><code>mean</code></td>
<td>
<p>the estimated mean</p>
</td></tr>
<tr><td><code>vars</code></td>
<td>
<p>a list of estimated variance-covariance matrices</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>a vector containing the sizes of the groups</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acompNormalLocation.test">acompNormalLocation.test</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fitSameMeanDifferentVarianceModel
</code></pre>

<hr>
<h2 id='gausstest'>Classical Gauss Test</h2><span id='topic+Gauss.test'></span>

<h3>Description</h3>

<p>One and two sample Gauss test for equal mean of normal random variates
with known variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gauss.test(x,y=NULL,mean=0,sd=1,alternative = c("two.sided", "less", "greater"))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gausstest_+3A_x">x</code></td>
<td>
<p>a numeric vector providing the first dataset </p>
</td></tr>
<tr><td><code id="gausstest_+3A_y">y</code></td>
<td>
<p>optional second dataset</p>
</td></tr>
<tr><td><code id="gausstest_+3A_mean">mean</code></td>
<td>
<p>the mean to compare with</p>
</td></tr>
<tr><td><code id="gausstest_+3A_sd">sd</code></td>
<td>
<p>the known standard deviation </p>
</td></tr>
<tr><td><code id="gausstest_+3A_alternative">alternative</code></td>
<td>
<p>the alternative to be used in the test</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gauss test is in every Text-Book, but not in R, because it is nearly
never used. However it is included here for educational purposes.  
</p>


<h3>Value</h3>

<p>A classical <code>"htest"</code> object
</p>
<table>
<tr><td><code>data.name</code></td>
<td>
<p>The name of the dataset as specified</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a name for the test used</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the mean and variance provided to the test</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>an empty string</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p.value computed for this test</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)
y &lt;- rnorm(100)
Gauss.test(x,y)

</code></pre>

<hr>
<h2 id='geometricmean'>The geometric mean</h2><span id='topic+geometricmean'></span><span id='topic+geometricmeanRow'></span><span id='topic+geometricmeanCol'></span><span id='topic+gsi.geometricmean'></span><span id='topic+gsi.geometricmeanRow'></span><span id='topic+gsi.geometricmeanCol'></span><span id='topic+gsi.geometricmean.Row'></span><span id='topic+gsi.geometricmean.Col'></span>

<h3>Description</h3>

<p>Computes the geometric mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          geometricmean(x,...)
          geometricmeanRow(x,...)
          geometricmeanCol(x,...)
          gsi.geometricmean(x,...)
          gsi.geometricmeanRow(x,...)
          gsi.geometricmeanCol(x,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geometricmean_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix of data </p>
</td></tr>
<tr><td><code id="geometricmean_+3A_...">...</code></td>
<td>
<p>further arguments to compute the mean </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The geometric mean is defined as:
</p>
<p style="text-align: center;"><code class="reqn">geometricmean(x) := \left( \prod_{i=1}^n x_i\right)^{1/n}</code>
</p>

<p>The geometric mean is actually computed by
<code>exp(mean(log(c(unclass(x))),...))</code>.
</p>


<h3>Value</h3>

<p>The geometric means of x as a whole (geometricmean), its rows
(geometricmeanRow) or its columns (geometricmeanCol).
</p>


<h3>Missing Policy</h3>

<p>The the first three functions take the geometric mean of all non-missing values. 
This is because they should yield a result in term of data analysis. 
</p>
<p>Contrarily, the gsi.* functions inherit the arithmetic IEEE policy of R through
<code>exp(mean(log(c(unclass(x))),...))</code>. Thus,  NA codes a not available i.e. 
not measured, NaN codes a below detection limit, and 0.0 codes a structural zero.
If any of the elements involved is 0, NA or NaN the result is of the same
type. Here 0 takes precedence over NA, and NA takes precedence
over NaN. For example, if a structural 0 appears, the geometric mean is 0
regardless of the presence of NaN's or NA's in the rest. Values below detection 
limit become NaN's if they are coded as negative values.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+mean.rplus">mean.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>geometricmean(1:10)  
geometricmean(c(1,0,NA,NaN))  # 0
X &lt;- matrix(c(1,NA,NaN,0,1,2,3,4),nrow=4)
X  
geometricmeanRow(X)
geometricmeanCol(X)
</code></pre>

<hr>
<h2 id='getdetectionlimit'>Gets the detection limit stored in the data set</h2><span id='topic+getDetectionlimit'></span>

<h3>Description</h3>

<p>The detection limit of those values below-detection-limit are 
stored as negative values in compositional dataset. This function 
extracts that information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDetectionlimit(x,dl=attr(x,"detectionlimit"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getdetectionlimit_+3A_x">x</code></td>
<td>
<p>a data set</p>
</td></tr>
<tr><td><code id="getdetectionlimit_+3A_dl">dl</code></td>
<td>
<p>a default to replace the information in the dataset</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a proper treatment of truncated data it would be necessary to know
the detection limit even for observed data. Unfortunately, there
is no clear way to encode this information without annoying the user.
</p>


<h3>Value</h3>

<p>a matrix in the same shape as x, with a positive value (the detection limit)
where available, and NA in the other cells. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald van den Boogaart</p>


<h3>References</h3>

<p>Boogaart, K.G. v.d., R. Tolosana-Delgado, M. Bren (2006) Concepts for
handling of zeros and missing values in compositional data, in
E. Pirard (ed.) (2006)Proceedings of the IAMG'2006 Annual Conference
on &quot;Quantitative Geology from multiple sources&quot;, September 2006,
Liege, Belgium, S07-01, 4pages, ISBN 978-2-9600644-0-7, <a href="http://www.stat.boogaart.de/Publications/iamg06_s07_01.pdf">http://www.stat.boogaart.de/Publications/iamg06_s07_01.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compositions.missings">compositions.missings</a></code>,<code><a href="#topic+zeroreplace">zeroreplace</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(2,-0.5,4,3,-0.5,5,BDLvalue,MARvalue,MNARvalue)
getDetectionlimit(x)

</code></pre>

<hr>
<h2 id='Glacial'>Compositions and total pebble counts of 92 glacial tills</h2><span id='topic+DATA18'></span><span id='topic+Glacial'></span>

<h3>Description</h3>

<p>In a pebble analysis of glacial tills, the total number of pebbles in each
of 92 samples was counted and the pebbles were sorted into four categories
red sandstone,  gray sandstone, crystalline and miscellaneous.
The percentages of these four categories and the total pebble counts
are recorded. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Glacial)
</code></pre>


<h3>Details</h3>

<p>Percentages by weight in 92 samples of pebbles of glacial tills sorted 
into four categories, red sandstone,  gray sandstone, crystalline and miscellaneous.
The percentages of these four categories and the total pebbles counts
are recorded. The glaciologist is interested in describing the pattern of variability
of his data and whether the compositions are in any way related to abundance.
All rows sum to 100, except for some rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name GLACIAL.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison: The Statistical Analysis of Compositional Data, 1986, Data 18, pp21.
</p>

<hr>
<h2 id='gof'>Compositional Goodness of fit test</h2><span id='topic+acompGOF.test'></span><span id='topic+acompGOF.test.list'></span><span id='topic+acompGOF.test.formula'></span><span id='topic+gsi.acompUniformityGOF.test'></span><span id='topic+acompNormalGOF.test'></span><span id='topic+acompTwoSampleGOF.test'></span>

<h3>Description</h3>

<p>Goodness of fit tests for compositional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acompGOF.test(x,...)
acompNormalGOF.test(x,...,method="etest")
## S3 method for class 'formula'
acompGOF.test(formula, data,...,method="etest")
## S3 method for class 'list'
acompGOF.test(x,...,method="etest")
gsi.acompUniformityGOF.test(x,samplesize=nrow(x)*20,R=999)
acompTwoSampleGOF.test(x,y,...,method="etest",data=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gof_+3A_x">x</code></td>
<td>
<p>a dataset of compositions (acomp)</p>
</td></tr>
<tr><td><code id="gof_+3A_y">y</code></td>
<td>
<p>a dataset of compositions (acomp)</p>
</td></tr>
<tr><td><code id="gof_+3A_samplesize">samplesize</code></td>
<td>
<p>number of observations in a reference sample
specifying the distribution to compare with. Typically substantially
larger than the sample under investigation</p>
</td></tr>
<tr><td><code id="gof_+3A_r">R</code></td>
<td>
<p>The number of replicates to compute the distribution
of the test statistic</p>
</td></tr>
<tr><td><code id="gof_+3A_method">method</code></td>
<td>
<p>Selecting a method to be used. Currently only &quot;etest&quot;
for using an energy test is supported.</p>
</td></tr>
<tr><td><code id="gof_+3A_...">...</code></td>
<td>
<p>further arguments to the methods</p>
</td></tr>
<tr><td><code id="gof_+3A_formula">formula</code></td>
<td>
<p>an anova model formula defining groups in the dataset </p>
</td></tr>
<tr><td><code id="gof_+3A_data">data</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compositional goodness of fit testing problem is essentially a
multivariate goodness of fit test. However there is a lack of
standardized multivariate goodness of fit tests in R. Some can be found in
the <code>energy</code>-package.
</p>
<p>In principle there is only one test behind the Goodness of fit tests
provided here, a two sample test with test statistic.
</p>
<p style="text-align: center;"><code class="reqn">\frac{\sum_{ij} k(x_i,y_i)}{\sqrt{\sum_{ij} k(x_i,x_i)\sum_{ij} k(y_i,y_i)}}</code>
</p>

<p>The idea behind that statistic is to measure the cos of an angle
between the distributions in a scalar product given by
</p>
<p style="text-align: center;"><code class="reqn">
  (X,Y)=E[k(X,Y)]=E[\int K(x-X)K(x-Y) dx]
  </code>
</p>

<p>where k and K are Gaussian kernels with different spread. The bandwith
is actually the standarddeviation of k.<br />
The other goodness of fit tests against a specific distribution are
based on estimating the parameters of the distribution, simulating a
large dataset of that distribution and apply the two sample goodness
of fit test. 
</p>
<p>For the moment, this function covers: two-sample tests, uniformity tests and additive
logistic normality tests. Dirichlet distribution tests will be included soon.
</p>


<h3>Value</h3>

<p>A classical <code>"htest"</code> object
</p>
<table>
<tr><td><code>data.name</code></td>
<td>
<p>The name of the dataset as specified</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a name for the test used</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>an empty string</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>a dataset of p-value distributions under the
Null-Hypothesis got from
nonparametric bootstrap</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p.value computed for this test</p>
</td></tr>
</table>


<h3>Missing Policy</h3>

<p>Up to now the tests can not handle missings. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitDirichlet">fitDirichlet</a></code>,<code><a href="#topic+rDirichlet">rDirichlet</a></code>, <code><a href="#topic+runif.acomp">runif.acomp</a></code>,
<code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- runif.acomp(100,4)
y &lt;- runif.acomp(100,4)

erg &lt;- acompTwoSampleGOF.test(x,y)
#continue
erg
unclass(erg)
erg &lt;- acompGOF.test(x,y)


x &lt;- runif.acomp(100,4)
y &lt;- runif.acomp(100,4)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(100,4),runif.acomp(100,4))$p.value)
hist(dd)

dd &lt;- replicate(1000,acompGOF.test(runif.acomp(20,4),runif.acomp(100,4))$p.value)
hist(dd)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(10,4),runif.acomp(100,4))$p.value)

hist(dd)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(10,4),runif.acomp(400,4))$p.value)
hist(dd)
dd &lt;- replicate(1000,acompGOF.test(runif.acomp(400,4),runif.acomp(10,4),bandwidth=4)$p.value)
hist(dd)


dd &lt;- replicate(1000,acompGOF.test(runif.acomp(20,4),runif.acomp(100,4)+acomp(c(1,2,3,1)))$p.value)

hist(dd)

# test uniformity

attach("gsi") # the uniformity test is only available as an internal function
x &lt;- runif.acomp(100,4)
gsi.acompUniformityGOF.test.test(x)

dd &lt;- replicate(1000,gsi.acompUniformityGOF.test.test(runif.acomp(10,4))$p.value)
hist(dd)
detach("gsi")


## End(Not run)
</code></pre>

<hr>
<h2 id='groupparts'>Group amounts of parts</h2><span id='topic+groupparts'></span><span id='topic+groupparts.acomp'></span><span id='topic+groupparts.rcomp'></span><span id='topic+groupparts.aplus'></span><span id='topic+groupparts.rplus'></span><span id='topic+groupparts.ccomp'></span>

<h3>Description</h3>

<p>Groups parts by amalgamation or balancing of their amounts or proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>groupparts(x,...)
## S3 method for class 'acomp'
groupparts(x,...,groups=list(...))
## S3 method for class 'rcomp'
groupparts(x,...,groups=list(...))
## S3 method for class 'aplus'
groupparts(x,...,groups=list(...))
## S3 method for class 'rplus'
groupparts(x,...,groups=list(...))
## S3 method for class 'ccomp'
groupparts(x,...,groups=list(...))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="groupparts_+3A_x">x</code></td>
<td>
<p>an amount/compositional dataset</p>
</td></tr>
<tr><td><code id="groupparts_+3A_...">...</code></td>
<td>
<p>further parameters to use (actually ignored)</p>
</td></tr>
<tr><td><code id="groupparts_+3A_groups">groups</code></td>
<td>
<p>a list of numeric xor character vectors, each giving a group of parts</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>In the real geometry grouping is done by amalgamation (i.e. adding the
parts). In the Aitchison-geometry grouping is done by taking geometric
means. The new parts are named by named
formal arguments. Not-mentioned parts remain ungrouped.
</p>


<h3>Value</h3>

<p>a new dataset of the same type with each group represented by a single column
</p>


<h3>Missing Policy</h3>

<p>For the real geometries, SZ and BDL are considered as 0, and MAR and MNAR
are kept as missing of the same type. For the relative geometries, a BDL is a
special kind of MNAR, whereas a SZ is qualitatively different (thus a
balance with a SZ has no sense). MAR values transfer their MAR property to the 
resulting new variable. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Egozcue, J.J. and V. Pawlowsky-Glahn (2005) Groups of Parts and their
Balances in Compositional Data Analysis, Mathematical Geology, in press
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(groupparts(acomp(sa.lognormals5),A=c(1,2),B=c(3,4),C=5))
plot(groupparts(aplus(sa.lognormals5),B=c(3,4),C=5))
plot(groupparts(rcomp(sa.lognormals5),A=c("Cu","Pb"),B=c(2,5)))
hist(groupparts(rplus(sa.lognormals5),1:5))
</code></pre>

<hr>
<h2 id='gsi.add'>Internal functions: Parallel operations of single and multiple datasets</h2><span id='topic+gsi.add'></span><span id='topic+gsi.sub'></span><span id='topic+gsi.mul'></span><span id='topic+gsi.div'></span>

<h3>Description</h3>

<p>The given operations are performed in parallel for multiple datasets
or for two single datasets, or for multiple datasets with a single dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.add(x,y)
gsi.sub(x,y)
gsi.mul(x,y)
gsi.div(x,y)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.add_+3A_x">x</code></td>
<td>
<p>a vector or a matrix</p>
</td></tr>
<tr><td><code id="gsi.add_+3A_y">y</code></td>
<td>
<p>a vector or a matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All operations +,-,*,/ are performed on unclassed objects.
</p>


<h3>Value</h3>

<p>a vector or a matrix with the operated values 
</p>


<h3>Note</h3>

<p>It is better not to use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+perturbe">perturbe</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmp1 &lt;- matrix(1:12,ncol=3)
tmp2 &lt;- 1:3
#gsi.add(tmp1,tmp2)
#gsi.sub(tmp1,tmp2)
#gsi.mul(tmp1,tmp2)
#gsi.div(tmp1,tmp2)

#gsi.add(tmp2,tmp2)
#gsi.sub(tmp2,tmp2)
#gsi.mul(tmp2,tmp2)
#gsi.div(tmp2,tmp2)

#gsi.add(tmp1,tmp1)
#gsi.sub(tmp1,tmp1)
#gsi.mul(tmp1,tmp1)
#gsi.div(tmp1,tmp1)

</code></pre>

<hr>
<h2 id='gsi.addclass'>Internal function: give a derived subclass to an object</h2><span id='topic+gsi.addclass'></span>

<h3>Description</h3>

<p>This function just extends the class of an object by the given class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.addclass( x , cls)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.addclass_+3A_x">x</code></td>
<td>
<p>the object</p>
</td></tr>
<tr><td><code id="gsi.addclass_+3A_cls">cls</code></td>
<td>
<p>the new additional class</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object x with additional class attached.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>x=rplus(1:10)
x
#gsi.addclass(x,"goofy")
</code></pre>

<hr>
<h2 id='gsi.csum'>Internal function: row and column sums of matrices</h2><span id='topic+gsi.csum'></span><span id='topic+gsi.rsum'></span>

<h3>Description</h3>

<p>Abbreviation for collapsing matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.csum(x)
gsi.rsum(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.csum_+3A_x">x</code></td>
<td>
<p>the matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>gsi.csum computes the sums of all the columns of x and gsi.rsum
computes the sums of the rows of x. For convenience, only finite values
are added.
</p>


<h3>Value</h3>

<p>A numeric vector.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sum">sum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#A &lt;- matrix(c(0,1,0,0,0,0),ncol=2)
#b &lt;- diag(3)
#erg &lt;- gsi.svdsolve(A,b)
#erg
#A %*% erg 
#diag(c(0,1,0))  # richtig
</code></pre>

<hr>
<h2 id='gsi.diagExtract'>Internal functions: Get the diagonal of a matrix</h2><span id='topic+gsi.diagExtract'></span>

<h3>Description</h3>

<p>Get the main diagonal of a matrix, even if the matrix is 1x1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.diagExtract(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.diagExtract_+3A_x">x</code></td>
<td>
<p> a matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The difference to original <code><a href="base.html#topic+diag">diag</a></code> is that it always
gives the diagonal and does nothing flawed in case of a 1x1 matrix or
a single number considered as such matrix.
</p>


<h3>Value</h3>

<p>a vector containing the main diagonal entries of x.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi.diagGenerate">gsi.diagGenerate</a></code>, <code><a href="base.html#topic+diag">diag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data(SimulatedAmounts)
#gsi.diagExtract(var(acomp(sa.lognormals,c(1,2))))
#gsi.diagExtract(var(ilr(acomp(sa.lognormals,c(1,2)))))
#gsi.diagExtract(var(ilt(aplus(sa.lognormals,c(1)))))
</code></pre>

<hr>
<h2 id='gsi.diagGenerate'>Internal functions: Generate a diagonal matrix </h2><span id='topic+gsi.diagGenerate'></span>

<h3>Description</h3>

<p>Generate a diagonal matrix from a vector of
the diagonal entries like.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.diagGenerate(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.diagGenerate_+3A_x">x</code></td>
<td>
<p> a vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The difference to original <code><a href="base.html#topic+diag">diag</a></code> is that it always
gives a diagonal matrix and does nothing flawed in case of a length
one vector.
</p>


<h3>Value</h3>

<p>a diagonal matrix.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi.diagExtract">gsi.diagExtract</a></code>, <code><a href="base.html#topic+diag">diag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>diag(1:3)
#gsi.diagGenerate(1:3)
#gsi.diagGenerate(3)
diag(3)
</code></pre>

<hr>
<h2 id='gsi.drop'>Internal functions: A conditional drop</h2><span id='topic+gsi.drop'></span>

<h3>Description</h3>

<p>drop, if drop is needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.drop(X,drop)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.drop_+3A_x">X</code></td>
<td>
<p> an array which dimensions should be dropped</p>
</td></tr>
<tr><td><code id="gsi.drop_+3A_drop">drop</code></td>
<td>
<p> a logical whether to drop dimensions</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>X</code> or <code>drop(X)</code>
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+drop">drop</a></code>, <code><a href="#topic+gsi">gsi</a></code>
</p>

<hr>
<h2 id='gsi.eq'>Internal function: Checking equality of IEEE special numbers</h2><span id='topic+gsi.eq'></span><span id='topic+gsi.eq'></span>

<h3>Description</h3>

<p>Works like == 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.eq(x,y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.eq_+3A_x">x</code></td>
<td>
<p>A numeric vector or matrix</p>
</td></tr>
<tr><td><code id="gsi.eq_+3A_y">y</code></td>
<td>
<p>A single numerical value, possibly including NaN,Inf,NA,-Inf,-0,0</p>
</td></tr>
</table>


<h3>Details</h3>

<p>unlike <code>==</code> does not return NA's and all sorts of NA's as an
actuall value.
</p>


<h3>Value</h3>

<p>A logical vector of the shape of x with TRUE exactly where the given
value shows up.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+compositions.missing">compositions.missing</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.plain(acomp(c(12,3,4)))
</code></pre>

<hr>
<h2 id='gsi.expandrcomp'>Internal function: Scaling rcomp</h2><span id='topic+gsi.expandrcomp'></span>

<h3>Description</h3>

<p>This functions tries to compute something similar to a scaling of an
acomp object in the context of the rcomp geometry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.expandrcomp(x,alpha)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.expandrcomp_+3A_x">x</code></td>
<td>
<p>an rcomp object</p>
</td></tr>
<tr><td><code id="gsi.expandrcomp_+3A_alpha">alpha</code></td>
<td>
<p>a number or a numeric vector between 0 and 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an rcomp-object
</p>


<h3>Note</h3>

<p>It is better not to use gsi.* functions directly since they are internal
functions of the package
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.expandrcomp(rcomp(1:3),0.5)
</code></pre>

<hr>
<h2 id='gsi.getD'>Interal function: Get number of samples and number of parts in a compositional object</h2><span id='topic+gsi.getD'></span><span id='topic+gsi.getN'></span>

<h3>Description</h3>

<p>Get the number of samples N and the number of parts D of the
compositions in an <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>,
<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.getD(x)
gsi.getN(x)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.getD_+3A_x">x</code></td>
<td>
<p>an <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>,
<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code> object or something that
could be cast to one of them</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an integer giving the number of parts D or the number of samples N.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>gsi.getD(1:5)
#gsi.getN(1:5)
NCOL(1:5)
NROW(1:5)
data(SimulatedAmounts)
gsi.getD(sa.lognormals5)
#gsi.getN(sa.lognormals5)
</code></pre>

<hr>
<h2 id='gsi.isSingleRow'>Internal function: Can something be considered as a single
multivariate data item?</h2><span id='topic+gsi.isSingleRow'></span>

<h3>Description</h3>

<p>Checks wether something can be regarded as a single multivariate item,
being a matrix or a vector, which is only a row or a column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.isSingleRow(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.isSingleRow_+3A_x">X</code></td>
<td>
<p>the matrix or vector to be checked</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is defined as <code>
    gsi.isSingleRow &lt;- function(X) {
      return( NROW(X) == 1 || NCOL(X) ==1 )
    }
  </code>
</p>


<h3>Value</h3>

<p>a logical value 
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.isSingleRow(1:10)
</code></pre>

<hr>
<h2 id='gsi.mapin01'>Internal functions: Storing integers as reals</h2><span id='topic+gsi.mapin01'></span><span id='topic+gsi.mapfrom01'></span><span id='topic+gsi.mapmin'></span><span id='topic+gsi.mapmax'></span>

<h3>Description</h3>

<p>An integer number is stored in a dataset with a given range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.mapin01(i,min=0,max=1)
gsi.mapfrom01(x)
gsi.mapmin(x)
gsi.mapmax(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.mapin01_+3A_i">i</code></td>
<td>
<p>an integer number to be masked</p>
</td></tr>
<tr><td><code id="gsi.mapin01_+3A_x">x</code></td>
<td>
<p>a numeric vector created by <code>gsi.mapin01</code>.</p>
</td></tr>
<tr><td><code id="gsi.mapin01_+3A_max">max</code></td>
<td>
<p>the maximum of the created dataset</p>
</td></tr>
<tr><td><code id="gsi.mapin01_+3A_min">min</code></td>
<td>
<p>the minimum of the created dataset</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is used to get full control over the graphic ranges in
pair plots and to pass the used column to panel functions.
</p>


<h3>Value</h3>

<p><code>gsi.mapin01</code> gives a vector <var>x</var> with
<code>range(<var>x</var>)==c(min,max)</code> and <code>gsi.mapfrom01(<var>x</var>)</code>,
<code>gsi.mapmin(<var>x</var>)</code>, <code>gsi.mapmax(<var>x</var>)</code> result in <code>i</code>,
<code>max</code> and <code>min</code>. 
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>, <code><a href="#topic+plot.acomp">plot.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.mapin01(5)
</code></pre>

<hr>
<h2 id='gsi.margin'>Internal function: Compute a desired compositional margin</h2><span id='topic+gsi.margin'></span><span id='topic+gsi.margin.acomp'></span><span id='topic+gsi.margin.rcomp'></span><span id='topic+gsi.margin.aplus'></span><span id='topic+gsi.margin.rplus'></span>

<h3>Description</h3>

<p>This generic function should select the selected type of margin based
on the class of the dataset and the specified margin type. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.margin(X,...)
## S3 method for class 'acomp'
gsi.margin(X,what,...,margin="acomp")
## S3 method for class 'rcomp'
gsi.margin(X,what,...,margin="rcomp")
## S3 method for class 'aplus'
gsi.margin(X,what,...)
## S3 method for class 'rplus'
gsi.margin(X,what,...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.margin_+3A_x">X</code></td>
<td>
<p>The dataset to take the margin from.</p>
</td></tr>
<tr><td><code id="gsi.margin_+3A_what">what</code></td>
<td>
<p>The indices xor column names to be kept.</p>
</td></tr>
<tr><td><code id="gsi.margin_+3A_margin">margin</code></td>
<td>
<p>The type of marginalisation to be used. Possible values
are: '&quot;sub&quot;', '&quot;rcomp&quot;', '&quot;acomp&quot;' and an index xor a name of a
variable in the dataset.</p>
</td></tr>
<tr><td><code id="gsi.margin_+3A_...">...</code></td>
<td>
<p> other arguments </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A marginalized dataset (or vector) still containing the variables given
by <code>what</code> and optionally one
additional part named '&quot;+&quot;', '&quot;*&quot;' or <var>margin</var>.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data(SimulatedAmounts)
#plot(gsi.margin(acomp(sa.lognormals5),c("Cd","Cu")))
</code></pre>

<hr>
<h2 id='gsi.merge2signary'>Auxiliary functions to compute user-defined ilr and ipt transforms.</h2><span id='topic+gsi.merge2signary'></span><span id='topic+gsi.ilrBase2signary'></span><span id='topic+gsi.optimalilrBase'></span><span id='topic+gsi.buildilrBase'></span><span id='topic+gsi.signary2ilrBase'></span><span id='topic+gsi.OrderIlr'></span>

<h3>Description</h3>

<p>Compute the basis of a clr-plane, to use with isometric log-ratio or planar transform of a (dataset of)
compositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          gsi.merge2signary( M )
          gsi.ilrBase2signary( V )
          gsi.optimalilrBase( x )
          gsi.buildilrBase( W=c(1,-1) )
          gsi.signary2ilrBase( W=c(1,-1) )
          gsi.OrderIlr( V )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.merge2signary_+3A_m">M</code></td>
<td>
<p> a merge structure (as explained in <code>hclust</code>) </p>
</td></tr>
<tr><td><code id="gsi.merge2signary_+3A_x">x</code></td>
<td>
<p> a compositional data set </p>
</td></tr>
<tr><td><code id="gsi.merge2signary_+3A_w">W</code></td>
<td>
<p> a signary matrix (as explained below) defining a partition </p>
</td></tr>
<tr><td><code id="gsi.merge2signary_+3A_v">V</code></td>
<td>
<p> a matrix of change of basis from clr/cpt to ilr/ipt </p>
</td></tr>
</table>


<h3>Details</h3>

<p>A signary matrix is a matrix with the same shape as an ilr matrix, 
but containing only +1, 0 or -1 values (thus, it is a kind of &quot;extended 
binary&quot;). If the value W[i,j]= +1, then part &quot;i&quot; is involved in 
coordinate &quot;j&quot; in the numerator; if W[i,j]=-1, it is involed
in the denominator, and if W[i,j]=0 then part &quot;i&quot; does not take 
part in coordinate &quot;j&quot;.
</p>
<p>Functions <code>gsi.merge2signary</code> and <code>gsi.buildilrBase</code> are 
intended to compute <code>ilrBase</code> matrices associated to user-defined 
partition structures. Function <code>gsi.ilrBase2signary</code> offers the 
inverse functionality.
</p>
<p>Function <code>gsi.OrderIlr</code> returns a list with two elements: 
&quot;ilrBase&quot; and &quot;order&quot;. The first one contains the ilr basis with 
coordinates reordered in decreasing number of involved parts (so, 
all parts are involved in the first coordinate, and only two in the 
last). The second one gives a permutation of the parts so that 
involved parts in each coordinate are always together. 
Note that ilrBase does not have its parts permuted!
</p>


<h3>Value</h3>

<p>These functions will not be usually called on themselves, but 
through their wrappers, mainly <code>ilrBase</code>. Functions
<code>gsi.merge2signary</code> and <code>gsi.ilrBase2signary</code> return 
a signary matrix (as explained in &quot;details&quot;), <code>gsi.optimalilrBase</code> 
returns a merge structure (as epxlained in <code>hclust</code>), and
<code>gsi.buildilrBase</code> (and its alias <code>gsi.signary2ilrBase</code>) 
returns an ilr matrix. These functions are thought to be called 
sequentially. <br />
Apart, <code>gsi.OrderIlr</code> reorders both parts and coordinates to 
ease dendrogram-like representations (see <code><a href="#topic+CoDaDendrogram">CoDaDendrogram</a></code>).
</p>


<h3>Note</h3>

<p>It is better not to use gsi.* functions directly since they are internal
functions of the package. Use their wrappers.</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Egozcue J.J., V. Pawlowsky-Glahn, G. Mateu-Figueras and
C. Barcel'o-Vidal (2003) Isometric logratio transformations for
compositional data analysis. <em>Mathematical Geology</em>, <b>35</b>(3)
279-300<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilrBase">ilrBase</a></code>,<code><a href="#topic+ipt">ipt</a></code>,<code><a href="#topic+ilr">ilr</a></code>,
<a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- matrix(data=c(-1,-2,
                  -3,-4,
                   1, 2),ncol=2,nrow=3,byrow=TRUE)
w &lt;- gsi.merge2signary(m)
w
V=gsi.buildilrBase(w)
V
gsi.ilrBase2signary(V)
gsi.OrderIlr(V)
</code></pre>

<hr>
<h2 id='gsi.plain'>Internal function: Convert to plain vector or matrix</h2><span id='topic+gsi.plain'></span>

<h3>Description</h3>

<p>The dataset is converted into a plain vector or matrix: data.frames are
converted to data matrices and class attributes are removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.plain( x )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.plain_+3A_x">x</code></td>
<td>
<p>The dataset to be converted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>unclassed object, typically a vector or matrix.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.plain(acomp(c(12,3,4)))
</code></pre>

<hr>
<h2 id='gsi.PrinBal'>The canonical basis in the clr plane used for ilr and ipt transforms.</h2><span id='topic+gsi.PrinBal'></span>

<h3>Description</h3>

<p>Compute the basis of a clr-plane, to use with isometric log-ratio or planar 
transform of a (dataset of) compositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          gsi.PrinBal( x, method="PBhclust" )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.PrinBal_+3A_x">x</code></td>
<td>
<p>a data set (required)</p>
</td></tr>
<tr><td><code id="gsi.PrinBal_+3A_method">method</code></td>
<td>
<p>method to build the principal balances; currently, one of
&quot;PBhclust&quot;, &quot;PBmaxvar&quot; or &quot;PBangprox&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method &quot;PBhclust&quot; generates a Ward cluster analysis of the parts (not of
the observations!) using as distance between parts the variation matrix. 
</p>
<p>Method &quot;PBmaxvar&quot; splits all parts in two groups after a PCA (those with
positive weight against those with negative weight in the first PC),
and then checks for each element whether moving it increases the variance of
the resulting balance. The largest variance balance is chosen. That variance 
is removed, and each of the groups of parts is analysed recursively.
</p>
<p>Method &quot;angprox&quot; calculates all possible balances (exhaustive combinations of 
&quot;ncol(x)&quot; elements split in three groups: +1, 0 and -1), and computes their angles
with the first PC. The nearest balance is chosen. Its variance is substracted, and
the algorithm is repeated recursively ensuring orthogonality of the next 
splittings with respect to the balances already chosen. 
This method creates a temporary file &quot;.APtable&quot; that can be removed
after execution (or copypasted in your logfiles).
</p>
<p>Note that more methods can appear in the future, and that, except &quot;PBhclust&quot;,
all methods can be VERY slow. Extensive reprogramming of these routines can 
be expected in the future.
</p>


<h3>Value</h3>

<p>All methods give a matrix containing by columns the basis elements for the
canonical basis of the clr-plane used for the ilr and ipt transform. Principal
Balances are balance bases approximating Principal Component in certain ways,
depending on the specific method chosen.
</p>


<h3>Author(s)</h3>

<p>J.J. Egozcue (programming &quot;PBmaxvar&quot;) and R. Tolosana-Delgado (programming other methods and wrapper)</p>


<h3>References</h3>

<p>Pawlowsky-Glahn, V., J.J. Egozcue and R. Tolosana-Delgado (2011) Principal 
Balances. In: Egozcue, J.J., R. Tolosana-Delgado and M.I. Ortego (eds) 
Proceedings of CoDaWork'2011, the 4th International Workshop on Compositional
Data Analysis. CIMNE, Barcelona (E)
</p>



<h3>See Also</h3>

<p><code><a href="#topic+ilrBase">ilrBase</a></code>,<code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+clr">clr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Hydrochem")
x = acomp(Hydrochem[,c(6:10)])
(v1 = gsi.PrinBal(x, "PBhclust"))
(v2 = gsi.PrinBal(x, "PBmaxvar"))
(v3 = gsi.PrinBal(x, "PBangprox"))
</code></pre>

<hr>
<h2 id='gsi.recode'>Internal function: Recode missings with IEEE number and vice versa</h2><span id='topic+gsi.recodeM2C'></span><span id='topic+gsi.recodeC2M'></span><span id='topic+gsi.recodeM2Clean'></span><span id='topic+gsi.cleanR'></span>

<h3>Description</h3>

<p>The missing codes can be replace with arbitrary value e.g. IEEE
numbers and viceversa through this interface.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.recodeM2C(x,y=x,BDL,SZ,MAR,MNAR,NMV)
gsi.recodeC2M(x,y=x,na,nan,ninf,inf,neg,zero,pos)
gsi.recodeM2Clean(x,y=x,BDL=NaN,SZ=NaN,MAR=NaN,MNAR=NA,NMV)
gsi.cleanR(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.recode_+3A_x">x</code></td>
<td>
<p>the dataset having missings or IEEE numbers</p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_y">y</code></td>
<td>
<p>a dataset of similar shape, where the replacment should take
place</p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_bdl">BDL</code></td>
<td>
<p>value to replace for BDL</p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_sz">SZ</code></td>
<td>
<p>value to replace for SZ</p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_mar">MAR</code></td>
<td>
<p>value to replace for MAR</p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_mnar">MNAR</code></td>
<td>
<p>value to replace for MNAR</p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_nmv">NMV</code></td>
<td>
<p>value to replace for NMV</p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_na">na</code></td>
<td>
<p>value to replace for <code>NA</code></p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_nan">nan</code></td>
<td>
<p>value to replace for <code>NaN</code></p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_ninf">ninf</code></td>
<td>
<p>value to replace for <code>-Inf</code></p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_inf">inf</code></td>
<td>
<p>value to replace for <code>Inf</code></p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_neg">neg</code></td>
<td>
<p>value to replace for numbers with <code>x&lt;0</code></p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_zero">zero</code></td>
<td>
<p>value to replace for numbers with <code>x==0</code></p>
</td></tr>
<tr><td><code id="gsi.recode_+3A_pos">pos</code></td>
<td>
<p>value to replace for numbers with <code>x&gt;0</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions are used internally to transform the different types of
missings correctly.
</p>


<h3>Value</h3>

<p>y with entries replaced. gsi.cleanR replaces all improper numbers
with 0.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package. To use a gsi function, attach the <code>gsi</code>
environment. </p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+compositions.missing">compositions.missing</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.plain(acomp(c(12,3,4)))
</code></pre>

<hr>
<h2 id='gsi.simshape'>Internal function: Reshape an object to the shape type of another</h2><span id='topic+gsi.simshape'></span>

<h3>Description</h3>

<p>Reshape an object to the shape of another
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          gsi.simshape(x,oldx)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.simshape_+3A_x">x</code></td>
<td>
<p>the data set to be reshaped</p>
</td></tr>
<tr><td><code id="gsi.simshape_+3A_oldx">oldx</code></td>
<td>
<p>a data set of the intended shape</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function changes the dimension attribute accordingly.    
</p>


<h3>Value</h3>

<p><code>x</code>, but re-shaped as <code>oldx</code>
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package. To use a gsi function, attach the <code>gsi</code>
environment.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.simshape(matrix(1:4,nrow=1),1:3)
</code></pre>

<hr>
<h2 id='gsi.svdsolve'>Internal function: Solves singular and non square equation systems</h2><span id='topic+gsi.svdsolve'></span>

<h3>Description</h3>

<p>Based on the singular value decomposition, a singular equation system ax=b
is solved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.svdsolve(a,b,...,cond=1E-10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.svdsolve_+3A_a">a</code></td>
<td>
<p>the matrix of ax=b (a.k.a. left-hand side matrix)</p>
</td></tr>
<tr><td><code id="gsi.svdsolve_+3A_b">b</code></td>
<td>
<p>the vector or matrix b of ax=b (a.k.a right-hand side, 
independent element)</p>
</td></tr>
<tr><td><code id="gsi.svdsolve_+3A_cond">cond</code></td>
<td>
<p>the smallest-acceptable condition of the matrix. Smaller
singular values are truncate</p>
</td></tr>
<tr><td><code id="gsi.svdsolve_+3A_...">...</code></td>
<td>
<p>additional arguments to svd</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The &quot;smallest&quot; vector or matrix solving this system with minimal 
joint error among all vectors. 
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>#A &lt;- matrix(c(0,1,0,0,0,0),ncol=2)
#b &lt;- diag(3)
#erg &lt;- gsi.svdsolve(A,b)
#erg
#A %*% erg 
#diag(c(0,1,0))  # richtig
</code></pre>

<hr>
<h2 id='gsi.textpanel'>Internal function: A panel displaying a label only</h2><span id='topic+gsi.textpanel'></span>

<h3>Description</h3>

<p>A function useful as a text.panel in pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.textpanel(x,y,lab,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.textpanel_+3A_x">x</code></td>
<td>
<p>discarded</p>
</td></tr>
<tr><td><code id="gsi.textpanel_+3A_y">y</code></td>
<td>
<p>discarded</p>
</td></tr>
<tr><td><code id="gsi.textpanel_+3A_lab">lab</code></td>
<td>
<p>text to be plotted to the middle of the panel</p>
</td></tr>
<tr><td><code id="gsi.textpanel_+3A_...">...</code></td>
<td>
<p>further graphical parameters passed to <code><a href="graphics.html#topic+text">text</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is used against log-scale problems in pairs
called by function <code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code>.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data(iris)
#pairs(iris,text.panel=gsi.textpanel)
</code></pre>

<hr>
<h2 id='gsi.varwithlosts'>Internal function: computes variance of compositional data set with missing/zero values</h2><span id='topic+gsi.varwithlosts'></span>

<h3>Description</h3>

<p>Computes an unbiased estimate of the variance of a compositional data set with some missing and zero values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.varwithlosts(x,giveCenter=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi.varwithlosts_+3A_x">x</code></td>
<td>
<p>data set of the classes in <code><a href="#topic+compositions">compositions</a></code> </p>
</td></tr>
<tr><td><code id="gsi.varwithlosts_+3A_givecenter">giveCenter</code></td>
<td>
<p>a logical. If TRUE the function reports the mean as
an attribute &quot;center&quot; to the result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A variance matrix using all the observed information, where some of its 
components have been downweighted to account for the missing values. 
ATTENTION: function quite slow. It will be called directly by <code><a href="#topic+var.acomp">var.acomp</a></code> 
and similar generic functions only if <code><a href="stats.html#topic+na.action">na.action</a></code> is set to <code><a href="stats.html#topic+na.pass">na.pass</a></code>.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package.</p>


<h3>Author(s)</h3>

<p>R. Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K. G., R. Tolosana-Delgado, and M. Bren (2006) Concepts 
for handling of zeros and missing values in compositional data, In: 
<em>2006 Annual Conference of the International Association for Mathematical 
Geology (IAMG)</em>, Universit\'e de Li\'ege, Belgium.
</p>
<p>Bren, M., R. Tolosana-Delgado, and K.G. van den Boogaart (2008) News
from compositions, the R package. In:  Daunis-i-Estadella, J. and
Mart\'in-Fern\'a ndez, J.A. (Eds.)
<em>Proceedings of the 3rd International Workshop on Compositional Data Analysis</em>,
Universitat de Girona, Spain. <a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generates a 3-part compositional data set with missings
A &lt;- matrix(c(0.5,0.3,0.1, 0.3,0.2,0, 0.1, 0, 0.75),nrow=3)
Mvar &lt;- 2*ilrvar2clr(A)
Mcenter &lt;- acomp(c(1,5,2,3))
x &lt;- rnorm.acomp(100,Mcenter,Mvar) 
colnames(x)&lt;-c("A","B","C","D")
# eliminate 20 values completely at random
 slost &lt;- sample(1:length(x), size=30)
 x[slost] &lt;- 0
# compute the variance with losts
#print(vr &lt;- gsi.varwithlosts(cdt(x)))
# compare with Mvar
</code></pre>

<hr>
<h2 id='gsi2.invperm'>Internal function: Invert a permutation</h2><span id='topic+gsi2.invperm'></span>

<h3>Description</h3>

<p>Finds the inverse of a permutation given as a vector of indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi2.invperm( i,n )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsi2.invperm_+3A_i">i</code></td>
<td>
<p> a sequence of different integers in <code>1:n</code> considered as
a permutation given by <code>p=unique(c(i,1:n))</code></p>
</td></tr>
<tr><td><code id="gsi2.invperm_+3A_n">n</code></td>
<td>
<p> the number of elements to be permuted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The inverse permutation is defined by <code>p[<var>v</var>]==1:n</code> and
<code>v[<var>p</var>]==1:n</code>.  
</p>


<h3>Value</h3>

<p>an integer vector <var>v</var> describing the inverse permutation of p.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi2.invperm(c(2,3),10)
</code></pre>

<hr>
<h2 id='gsicall'>Internal functions of the compositions package</h2><span id='topic+gsi.call'></span>

<h3>Description</h3>

<p>Calls a function with a list of arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.call(fkt,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsicall_+3A_fkt">fkt</code></td>
<td>
<p>The function to be called</p>
</td></tr>
<tr><td><code id="gsicall_+3A_...">...</code></td>
<td>
<p>The arguments to call the function with</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is only useful in conjunction with do.call and allows to call
anonymous functions with parameters given by a list. 
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mypars &lt;- list(x=3)
#do.call("gsi.call",c(list(function(x){x}),mypars))
</code></pre>

<hr>
<h2 id='gsiCoorInfo'>Internal functions of the compositions package</h2><span id='topic+gsi.coorInfo'></span><span id='topic+gsi.setCoorInfo'></span><span id='topic+gsi.addCoorInfo'></span><span id='topic+gsi.getCoorInfo'></span>

<h3>Description</h3>

<p>Sets or gets the triangular/barycentric coordinate system for
the current ternary diagrams in the current plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.getCoorInfo()
gsi.setCoorInfo(...,all=list(...))
gsi.addCoorInfo(...,all=list(...))
gsi.plots
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsiCoorInfo_+3A_...">...</code></td>
<td>
<p>The info to be set. See details.</p>
</td></tr>
<tr><td><code id="gsiCoorInfo_+3A_all">all</code></td>
<td>
<p>The complete list of information</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Typically the information set contains a center <code>mean</code> (an acomp
object),
a scaling <code>scale</code> (a real number),
the geometry of rescaling <code>geo</code> (typically &quot;acomp&quot; or &quot;rcomp&quot;),
the dimension <code>D</code>, the margin <code>margin</code> type (&quot;acomp&quot; or
&quot;rcomp&quot; or a variable number or name) and eventually a numeric vector
of the two informations <code>d</code>.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>, 
</p>

<hr>
<h2 id='gsifiltercall'>Calling from a function with the own parameters</h2><span id='topic+gsi.filtercall'></span>

<h3>Description</h3>

<p>gsi.filtercall gives those arguments of the arguments of the calling
function to called function that are made for this function. It is possible
to modify the parameters on the flight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.filtercall(fkt,...,overwrite=NULL,
               transmit=character(0),default=list(...),
               prefix=if(is.character(fkt)) fkt else NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsifiltercall_+3A_fkt">fkt</code></td>
<td>
<p>a function or a name of a function to be called</p>
</td></tr>
<tr><td><code id="gsifiltercall_+3A_...">...</code></td>
<td>
<p>default arguments, which are used if not overwritten by own
arguments</p>
</td></tr>
<tr><td><code id="gsifiltercall_+3A_overwrite">overwrite</code></td>
<td>
<p>a named list overwriting arguments provided in any other way</p>
</td></tr>
<tr><td><code id="gsifiltercall_+3A_transmit">transmit</code></td>
<td>
<p>a character vector containing all named arguments that
should be given to <code>fkt</code>, although they are not formal parameters of
<code>fkt</code></p>
</td></tr>
<tr><td><code id="gsifiltercall_+3A_default">default</code></td>
<td>
<p>the list of default parameters to be used if not otherwise
specified</p>
</td></tr>	
<tr><td><code id="gsifiltercall_+3A_prefix">prefix</code></td>
<td>
<p>the user can specify arguments for <code>fkt</code>
explicitly by prefixing them with <code>prefix</code>.. Typically the prefix is the
name of the function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>gsi.filtercall is a kind of R technology help. It allows to pass parameters in a
... fashion with less effort, more robustness and more control, since one
does not need to copy all explicitly-given parameters. It simply manages the
...-parameters accepted by <code>fkt</code>, allowing for giving default
values, or overwriting specific parameters without need to mention them in
the formal arguments. This also helps to clarify the documentation of <code>fkt</code>.
</p>


<h3>Value</h3>

<p>The value of a call to <code>fkt</code> with those parameters modified by 
<code>gsi.filtercall</code> itself
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package. However I would like to propose a function like
this to become standard technology</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#	fxy &lt;- function(x,y) x+y
#	fxz &lt;- function(x,z) x*z
#	fxyz &lt;- function(...) {
#	   list(gsi.filtercall("fxy"),gsi.filtercall("fxz"))
#        }	 
#	fxyz(x=1,y=2,z=7)
#	fxyz(x=1,fxz.x=2,y=10,z=55)
</code></pre>

<hr>
<h2 id='gsigetBalStruct'>An auxiliary functions to compute user-defined ilr and ipt transforms.</h2><span id='topic+gsi.getBalStruct'></span>

<h3>Description</h3>

<p>Parses the expressions for the balance functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.getBalStruct(descr,names,allowMinus=FALSE,allowOne=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsigetBalStruct_+3A_descr">descr</code></td>
<td>
<p>the expression</p>
</td></tr>
<tr><td><code id="gsigetBalStruct_+3A_names">names</code></td>
<td>
<p>character: the variables in the dataset</p>
</td></tr>
<tr><td><code id="gsigetBalStruct_+3A_allowminus">allowMinus</code></td>
<td>
<p>whether to allow for <code>-</code> as a synonym for <code>/</code></p>
</td></tr>
<tr><td><code id="gsigetBalStruct_+3A_allowone">allowOne</code></td>
<td>
<p>whether to allow <code>1</code> as a variable name playing the role of a
a constant.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions will not be usually called on themselves, but 
through their wrappers, mainly <code>balanceBase</code>.
</p>


<h3>Value</h3>

<p>provides a list of pairs giving the components in the Numerator and
the Denominator of the balances.
</p>


<h3>Note</h3>

<p>It is better not to use gsi.* functions directly since they are internal
functions of the package. Use their wrappers.</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Egozcue J.J., V. Pawlowsky-Glahn, G. Mateu-Figueras and
C. Barcel'o-Vidal (2003) Isometric logratio transformations for
compositional data analysis. <em>Mathematical Geology</em>, <b>35</b>(3)
279-300<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilrBase">ilrBase</a></code>,<code><a href="#topic+ipt">ipt</a></code>,<code><a href="#topic+ilr">ilr</a></code>,
<a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.getBalStruct(~A/B/C,c("A","B","C"))

</code></pre>

<hr>
<h2 id='gsiinternal'>Environment containing the old gsi functions</h2><span id='topic+gsi'></span>

<h3>Description</h3>

<p>If you need some of the old deprecated gsi.functions you can attach
this environment, which contains them all. Use at your own risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi
</code></pre>


<h3>Arguments</h3>

<p>None
</p>


<h3>Details</h3>

<p>Will not be given.
</p>


<h3>Value</h3>

<p>unkown
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>attach(gsi)
objects("gsi")
detach(gsi)
"Hello don't call these functions, they will be removed in the next version"
</code></pre>

<hr>
<h2 id='gsiinternal1'>Internal functions of the compositions package</h2><span id='topic+gsi.closespread'></span>

<h3>Description</h3>

<p>Internal functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.closespread(spread)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsiinternal1_+3A_spread">spread</code></td>
<td>
</td></tr>
</table>


<h3>Value</h3>

<p>like <code>spread</code>, but projected to the orthogonal complement of <code>c(1,...,1)</code>
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>

<hr>
<h2 id='gsiinternal2'>Internal functions of the compositions package</h2><span id='topic+gsi.pairrelativeMatrix'></span>

<h3>Description</h3>

<p>Internal functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.pairrelativeMatrix(names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsiinternal2_+3A_names">names</code></td>
<td>
<p>a character vector provinding names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix containing pairwise contrasts
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gsi.pairrelativeMatrix(c("a","b","c"))
</code></pre>

<hr>
<h2 id='gsiinternal3'>Internal functions of the compositions package</h2><span id='topic+gsi.spreadToIsoSpace'></span>

<h3>Description</h3>

<p>Internal functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.spreadToIsoSpace(spread)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsiinternal3_+3A_spread">spread</code></td>
<td>
<p>a matrix or a dataset of matrices</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Converts a clr covariance matrix to a ilr covariance matrix
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>, <code><a href="#topic+clrvar2ilr">clrvar2ilr</a></code>
</p>

<hr>
<h2 id='gsipairs'>Internal functions of the compositions package</h2><span id='topic+gsi.pairs'></span><span id='topic+gsi.add2pairs'></span><span id='topic+gsi.plots'></span>

<h3>Description</h3>

<p>Creates a paired plot like <code>pairs</code> but allows to add additional panels
afterwards
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.pairs(x, labels, panel = points, ..., main = NULL, oma = NULL, 
    font.main = par("font.main"), cex.main = par("cex.main"), 
    lower.panel = panel, upper.panel = panel, diag.panel = NULL, 
    text.panel = textPanel, label.pos = 0.5 + has.diag/3, cex.labels = NULL, 
    font.labels = 1, row1attop = TRUE, gap = 1, add=list(), 
    xlim=apply(x,2,range), ylim=apply(x,2,range), log="",
    onlyPanel=NULL,noplot=FALSE,trimode=FALSE)
gsi.add2pairs(x,panel,...,noplot=FALSE)
gsi.plots
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsipairs_+3A_x">x</code></td>
<td>
<p>a multivariate dataset</p>
</td></tr>
<tr><td><code id="gsipairs_+3A_labels">labels</code></td>
<td>
<p>The names of the variables</p>
</td></tr>
<tr><td><code id="gsipairs_+3A_panel">panel</code></td>
<td>
<p>The function to performe the actual pairwise plots.</p>
</td></tr>
<tr><td><code id="gsipairs_+3A_...">...</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_main">main</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_oma">oma</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_font.main">font.main</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_cex.main">cex.main</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_lower.panel">lower.panel</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_upper.panel">upper.panel</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_diag.panel">diag.panel</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_text.panel">text.panel</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_label.pos">label.pos</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_cex.labels">cex.labels</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_font.labels">font.labels</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_row1attop">row1attop</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_gap">gap</code></td>
<td>
<p>see <code>graphics::pairs</code></p>
</td></tr> 
<tr><td><code id="gsipairs_+3A_add">add</code></td>
<td>
<p>additional parameter containing a list of additional
panels</p>
</td></tr>
<tr><td><code id="gsipairs_+3A_xlim">xlim</code></td>
<td>
<p>additional 2x<code>ncol(x)</code>-matrix parameter giving in
<code>xlim[,j]</code> the xlims of the j-th column
</p>
</td></tr>
<tr><td><code id="gsipairs_+3A_ylim">ylim</code></td>
<td>
<p>additional 2x<code>ncol()</code>-matrix parameter giving in
<code>ylim[,i]</code> the ylims of the j-th column
</p>
</td></tr>
<tr><td><code id="gsipairs_+3A_log">log</code></td>
<td>
<p>additional parameter with possible values like in

<code>graphics::plot</code>
allowing to log some plots, without a warning</p>
</td></tr>
<tr><td><code id="gsipairs_+3A_noplot">noplot</code></td>
<td>
<p>Logical indicating wether the plotting should be
suppressed. This is usefull for plotting single page postscripts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gsi.pairs</code>  essentially copies the functionality of

<code>graphics::pairs</code>.
However it additionally stores its own
parameters in the dev.cur() position of gsi.plots and allows to modify
the parameters and re-do a modified plot afterwards. This is mainly
done by <code>gsi.add2pairs</code> by modifying the additional <code>add</code>
parameter, that specifies more panels. This mechanism should not be
used directly, since it is planed to replace it by a more rigorous solution soon.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>, 
</p>

<hr>
<h2 id='gsiplotmargin'>Internal functions of the compositions package</h2><span id='topic+gsi.plotmargin'></span>

<h3>Description</h3>

<p>Internal function to compute 2D marginal compositions for plots  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.plotmargin(X,d,margin,what="data")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsiplotmargin_+3A_x">X</code></td>
<td>
<p>a multivariate compositional dataset</p>
</td></tr>
<tr><td><code id="gsiplotmargin_+3A_d">d</code></td>
<td>
<p>a numeric or character vector of two elements specifying the
parts to be kept in the marginalization process</p>
</td></tr>
<tr><td><code id="gsiplotmargin_+3A_margin">margin</code></td>
<td>
<p>a character specifying the type of margin to be
chosen. Possible values are &quot;acomp&quot;, &quot;rcomp&quot; or a column name from
the dataset.</p>
</td></tr>
<tr><td><code id="gsiplotmargin_+3A_what">what</code></td>
<td>
<p>simply here to avoid an error if the argument is passed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a composition of three elements.
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>

<hr>
<h2 id='gsireset3D'>Internal functions of the compositions package</h2><span id='topic+gsi.reset3D'></span>

<h3>Description</h3>

<p>Internal function to reset the rgl device  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsi.reset3D(userMatrix=diag(rep(1,4)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsireset3D_+3A_usermatrix">userMatrix</code></td>
<td>
<p>the new user matrix of the rgl Device</p>
</td></tr>
</table>


<h3>Value</h3>

<p>none
</p>


<h3>Note</h3>

<p>Do not use gsi.* functions directly since they are internal
functions of the package</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+gsi">gsi</a></code>
</p>

<hr>
<h2 id='Hongite'>Compositions of 25 specimens of hongite</h2><span id='topic+Data01'></span><span id='topic+Hongite'></span>

<h3>Description</h3>

<p>A mineral compositions of 25 rock specimens of hongite type.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Hongite)
</code></pre>


<h3>Details</h3>

<p>A mineral compositions of 25 rock specimens of hongite type.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite, which we conveniently abbreviate
to A, B, C, D, E.  All row sums are equal to 100, except for rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name HONGITE.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison (1986): The Statistical Analysis of Compositional Data; (Data 1), pp2, 9.
</p>

<hr>
<h2 id='HotellingsTsq'>Hotellings T square distribution</h2><span id='topic+qHotellingsTsq'></span><span id='topic+pHotellingsTsq'></span>

<h3>Description</h3>

<p>The Hotellings T square distribution is the distribution of the squared
Mahalanobis distances with respected to estimated variance covariance
matrices. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qHotellingsTsq(p,n,m)
pHotellingsTsq(q,n,m)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HotellingsTsq_+3A_p">p</code></td>
<td>
<p>a (vector of) probabilities</p>
</td></tr>
<tr><td><code id="HotellingsTsq_+3A_q">q</code></td>
<td>
<p>a vector of quantils</p>
</td></tr>
<tr><td><code id="HotellingsTsq_+3A_n">n</code></td>
<td>
<p>number of parameters, the p parameter of Hotellings
<code class="reqn">T^2</code> distribution</p>
</td></tr>
<tr><td><code id="HotellingsTsq_+3A_m">m</code></td>
<td>
<p>number of dimensions, the m parameter of the Hotellings <code class="reqn">T^2</code>
distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Hotellings <code class="reqn">T^2</code> with paramter p and m is the distribution
empirical squared Mahalanobis distances of a m dimensional vector with respect
to a  variance covariance matrix estimated based on np degrees of freedom. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>qHotellingsT2</code></td>
<td>
<p>a vector of quantils</p>
</td></tr>
<tr><td><code>pHotellingsT2</code></td>
<td>
<p>a vector of probabilities</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+ellipses">ellipses</a></code>, <code><a href="#topic+ConfRadius">ConfRadius</a></code>, <code><a href="stats.html#topic+pf">pf</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(q &lt;- qHotellingsTsq(seq(0,0.9,by=0.1),3,25))
pHotellingsTsq(q,3,25)
</code></pre>

<hr>
<h2 id='HouseholdExp'>Household Expenditures</h2><span id='topic+HouseholdExp'></span><span id='topic+DATA08'></span><span id='topic+HEMF'></span>

<h3>Description</h3>

<p>Household budget survey data on month expenditures of twenty men and twenty women
for four commodity groups: housing, foodstuffs, other, and services. Amounts in HK-Dollar
are given. There are 40 cases and 5 variables for 4 commodity groups and sex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HouseholdExp)
</code></pre>


<h3>Details</h3>

<p>In a sample survey of people living alone in a rented accommodation,
twenty men and twenty women were randomly selected and asked to record
over a period of one month their expenditures on the following four 
mutually exclusive and exhaustive commodity groups:
Housing, including fuel and lights, Foodstuffs, including alcohol and tobacco,
Other goods, including clothing, footwear and durable goods, and
Services, including transport and vehicles.
Amounts in HK-Dollar are given. There are 40 cases, 20 men and 20 women and
5 variables: 4 for commodity groups Housing, Food, Other, Services and the fifth sex,
$+1$ for men, $-1$ for women. Note that the data has no sum constraint. 
</p>


<h3>Source</h3>

 
<p>Aitchison: CODA microcomputer statistical package, 1986, the file name HEMF.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison (1986): The Statistical Analysis of Compositional Data, (Data 08), pp13.
</p>

<hr>
<h2 id='Hydrochem'>Hydrochemical composition data set of Llobregat river basin water (NE Spain)</h2><span id='topic+Hydrochem'></span>

<h3>Description</h3>

<p>Contains a hydrochemical amount/compositional data set obtained from
several rivers in the Llobregat river basin, in northeastern Spain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Hydrochem)
</code></pre>


<h3>Format</h3>

<p>Data matrix with 485 cases and 19 variables.</p>


<h3>Details</h3>

<p>This hydrochemical data set contains measurements of 14 components, H,
Na, K, Ca, Mg, Sr, Ba, <code class="reqn">\mathrm{NH}_4</code>,
Cl, <code class="reqn">\mathrm{HCO}_3</code>, <code class="reqn">\mathrm{NO}_3</code>,
<code class="reqn">\mathrm{SO}_4</code>, <code class="reqn">\mathrm{PO}_4</code>,
TOC. From them, hydrogen was derived by inverting the relationship
between its stable form in water,
<code class="reqn">\mathrm{H}_3\mathrm{O}^+</code>, and pH. Details can be
found in Otero et al. (2005). Each of these parameters is measured
approximately once each month during 2 years in 31 stations, placed
along the rivers and main tributaries of the Llobregat river, one of the
medium rivers in northeastern Spain.
</p>
<p>The Llobregat river drains an area of 4948.2 <code class="reqn">km^2</code>, and it
is 156.6 km long, with two main tributaries,
Cardener and Anoia. The headwaters of Llobregat and Cardener are in a
rather unpolluted area of the
Eastern Pyrenees. Mid-waters these rivers flow through a densely
populated and industrialized area, where potash mining activity occurs
and there are large salt mine tailings stored with no water
proofing. There, the main land use is agriculture and stockbreeding. The
lower course flows through one of the most densely populated areas of
the Mediterranean region (around the city of Barcelona) and the river
receives large inputs from industry and urban origin, while intensive
agriculture activity is again present in the Llobregat delta. Anoia is
quite different. Its headwaters are in an agricultural area, downwaters
it flows through an industrialized zone (paper mills, tannery and
textile industries), and near the confluence with Llobregat the main
land use is agriculture again, mainly vineyards, with a decrease in
industry and urban contribution. Given this variety in geological
background and human activities, the sample has been splitted in four
groups (higher Llobregat course, Cardener, Anoia and lower Llobregat
course), which in turn are splitted into main river and tributaries
(Otero et al, 2005). Information on these groupings, the sampling
locations and sampling time is included in 5 complementary variables.
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado</p>


<h3>Source</h3>

<p>The dataset is also accessible in Otero et al. (2005), and are here
included under the  GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Otero, N.; R. Tolosana-Delgado, A. Soler, V. Pawlowsky-Glahn
and A. Canals (2005).  Relative vs. absolute statistical analysis of
compositions: A comparative study of surface waters of a Mediterranean
river. Water Research, 39(7): 1404-1414. doi: <a href="https://doi.org/10.1016/j.watres.2005.01.012">10.1016/j.watres.2005.01.012</a>.
</p>
<p>Tolosana-Delgado, R.; Otero, N.; Pawlowsky-Glahn, V.; Soler, A. (2005). 
Latent Compositional Factors in The Llobregat River Basin (Spain) 
Hydrogeochemistry. Mathematical Geology 37(7): 681-702.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Hydrochem)
cHydrochem=Hydrochem[, 6:19]
biplot(princomp(rplus(cHydrochem)))
biplot(princomp(rcomp(cHydrochem)))

biplot(princomp(aplus(cHydrochem)))
biplot(princomp(acomp(cHydrochem)))
</code></pre>

<hr>
<h2 id='idt'>Isometric default transform</h2><span id='topic+idt'></span><span id='topic+idt.default'></span><span id='topic+idt.acomp'></span><span id='topic+idt.ccomp'></span><span id='topic+idt.rcomp'></span><span id='topic+idt.aplus'></span><span id='topic+idt.rplus'></span><span id='topic+idt.rmult'></span><span id='topic+idt.factor'></span><span id='topic+idt.data.frame'></span><span id='topic+idtInv'></span><span id='topic+idtInv.default'></span><span id='topic+idtInv.acomp'></span><span id='topic+idtInv.ccomp'></span><span id='topic+idtInv.rcomp'></span><span id='topic+idtInv.aplus'></span><span id='topic+idtInv.rplus'></span><span id='topic+idtInv.rmult'></span><span id='topic+idtInv.factor'></span><span id='topic+idtInv.data.frame'></span>

<h3>Description</h3>

<p>Compute the isometric default transform of a vector (or dataset) of
compositions or amounts in the selected class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          idt(x,...)
          ## Default S3 method:
idt( x,... )
          ## S3 method for class 'acomp'
idt( x ,...)
          ## S3 method for class 'rcomp'
idt( x ,...)
          ## S3 method for class 'aplus'
idt( x ,...)
          ## S3 method for class 'rplus'
idt( x ,...)
          ## S3 method for class 'rmult'
idt( x ,...)
          ## S3 method for class 'ccomp'
idt( x ,...)
          ## S3 method for class 'factor'
idt( x ,...)
          ## S3 method for class 'data.frame'
idt( x ,...)
          idtInv(x,orig=gsi.orig(x),...)
          ## Default S3 method:
idtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'acomp'
idtInv( x ,orig=gsi.orig(x), V=gsi.getV(x),...)
          ## S3 method for class 'rcomp'
idtInv( x ,orig=gsi.orig(x), V=gsi.getV(x),...)
          ## S3 method for class 'aplus'
idtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'rplus'
idtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'ccomp'
idtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'rmult'
idtInv( x ,orig=gsi.orig(x),...)
          ## S3 method for class 'factor'
idtInv( x ,orig=gsi.orig(x), V=gsi.getV(x),...)
          ## S3 method for class 'data.frame'
idtInv( x , orig=gsi.orig(x), ...)

          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="idt_+3A_x">x</code></td>
<td>
<p>a classed amount or composition, to be transformed with its
isometric default transform, or its inverse; in case of the method for <code><a href="base.html#topic+data.frame">data.frame</a></code>
objects, the function attempts to track information about a previous class (in an attribute
<code>origClass</code>, and if found, a transformation is tried with it; for factors, idt expands
the factor according to the contrasts represented by <code>V</code>, or vice-versa.)</p>
</td></tr>
<tr><td><code id="idt_+3A_...">...</code></td>
<td>
<p>generic arguments past to underlying functions</p>
</td></tr>
<tr><td><code id="idt_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked
by the inverse transformation. It is the generic
argument. Typically the <code>orig</code> argument is stored as an attribute 
in <code>x</code> and will be extracted automatically by this function; if this
fails, <code>orig</code> can be set equal to the dataset that
was transformed in the first place.</p>
</td></tr>
<tr><td><code id="idt_+3A_v">V</code></td>
<td>
<p>matrix of (<em>transposed, inverted</em>) logcontrasts; 
together with <code>orig</code>, it defines the back-transformation.
Typically the <code>V</code> argument is stored as an attribute 
in <code>x</code> and will be extracted automatically by this function; if this
fails, <code>V</code> must be manually set to the matrix V used in the idt/ilr/ipt
calculations. Argument not used in amounts or counts geometries.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The general idea of this package is to analyse the same data with
different geometric concepts, in a fashion as similar as possible. For each of the
four concepts there exists an isometric transform expressing the geometry
in a full-rank euclidean vector space. Such a transformation is computed 
by <code>idt</code>. For <code><a href="#topic+acomp">acomp</a></code> the transform is <code><a href="#topic+ilr">ilr</a></code>, for
<code><a href="#topic+rcomp">rcomp</a></code> it is <code><a href="#topic+ipt">ipt</a></code>, for 
<code><a href="#topic+aplus">aplus</a></code> it is <code><a href="#topic+ilt">ilt</a></code>, and for
<code><a href="#topic+rplus">rplus</a></code> it is <code><a href="#topic+iit">iit</a></code>. Keep in mind that the
transform does not keep the variable names, since there is no guaranteed 
one-to-one relation between the original parts and each transformed
variable.
<br />
The inverse <code>idtInv</code> is intended to allow for an &quot;easy&quot; and automatic 
back-transformation, without intervention of the user. The argument <code>orig</code> 
(the one determining the behaviour of <code>idtInv</code> as a generic function) 
tells the function which back-transformation should be applied, and
gives the column names of <code>orig</code> to the back-transformed
values of <code>x</code>. Therefore, it is very conventient to give the original classed
data set used in the analysis as <code>orig</code>.
</p>


<h3>Value</h3>

<p>A corresponding matrix of row-vectors containing the transforms. (Exception: idt.data.frame can return a data.frame if the input has no &quot;origClass&quot;-attribute)
</p>


<h3>Author(s)</h3>

<p>R. Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+backtransform">backtransform</a></code>, <code><a href="#topic+cdt">cdt</a></code>, <code><a href="#topic+ilr">ilr</a></code>, <code><a href="#topic+ipt">ipt</a></code>,
<code><a href="#topic+ilt">ilt</a></code>, <code><a href="#topic+cdtInv">cdtInv</a></code>, <code><a href="#topic+ilrInv">ilrInv</a></code>, <code><a href="#topic+iptInv">iptInv</a></code>, 
<code><a href="#topic+iltInv">iltInv</a></code>, <code><a href="#topic+iitInv">iitInv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# the idt is defined by
idt         &lt;- function(x) UseMethod("idt",x)
idt.default &lt;- function(x) x
idt.acomp   &lt;- function(x) ilr(x) 
idt.rcomp   &lt;- function(x) ipt(x) 
idt.aplus   &lt;- ilt 
idt.rplus   &lt;- iit 

## End(Not run)
idt(acomp(1:5))
idt(rcomp(1:5))
  data(Hydrochem)
  x = Hydrochem[,c("Na","K","Mg","Ca")]
  y = acomp(x)
  z = idt(y)
  y2 = idtInv(z,y)
  par(mfrow=c(2,2))
  for(i in 1:4){plot(y[,i],y2[,i])}
</code></pre>

<hr>
<h2 id='iit'>Isometric identity transform</h2><span id='topic+iit'></span><span id='topic+iitInv'></span>

<h3>Description</h3>

<p>Compute the isometric identity  transform of a vector (dataset) of
amounts and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          iit( x ,...)
          iitInv( z ,... )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iit_+3A_x">x</code></td>
<td>
<p>a vector or data matrix of amounts</p>
</td></tr>
<tr><td><code id="iit_+3A_z">z</code></td>
<td>
<p>the iit-transform of a vector or  data.matrix of
iit-transforms of amounts</p>
</td></tr>
<tr><td><code id="iit_+3A_...">...</code></td>
<td>
<p>generic arguments, to pass to other functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The iit-transform maps D amounts (considered in a real geometry)
isometrically to a D dimensonal euclidian vector. The <code>iit</code> is
part of the <code><a href="#topic+rplus">rplus</a></code> framework. Despite its trivial
operation, it is present to achieve maximal analogy between the
<code><a href="#topic+aplus">aplus</a></code> and the <code><a href="#topic+rplus">rplus</a></code> framework.
<br /> 
The data can then be analysed in this transformated space by all classical
multivariate analysis tools. The interpretation of the results is easy
since the relation to the original
variables is preserved. However results may be inconsistent, since the
multivariate analysis tools disregard the positivity condition and the
inner laws of amounts.<br />
</p>
<p>The isometric identity transform is a simple identity given by
</p>
<p style="text-align: center;"><code class="reqn"> iit(x)_i :=  x_i </code>
</p>



<h3>Value</h3>

<p><code>ilt</code> gives the isometric identity transform, i.e. simply the
input stripped of the &quot;rplus&quot; class attribute,
<code>iptInv</code> gives amounts with class &quot;rplus&quot; with the given iit,
i.e. simply the argument checked to be a valid &quot;rplus&quot; object, and 
with this class attribute.
</p>


<h3>Note</h3>

<p><code>iit</code> can be used to unclass amounts.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilt">ilt</a></code>, <code><a href="#topic+ilr">ilr</a>,</code> <code><a href="#topic+rplus">rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- iit(c(1,2,3)))
iitInv(tmp)
iitInv(tmp) - c(1,2,3) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(iit(cdata)) 
</code></pre>

<hr>
<h2 id='ilr'>Isometric log ratio transform</h2><span id='topic+ilr'></span><span id='topic+ilrInv'></span>

<h3>Description</h3>

<p>Compute the isometric log ratio transform of a (dataset of)
composition(s), and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ilr( x , V = ilrBase(x) ,...)
          ilrInv( z , V = ilrBase(z=z),..., orig=gsi.orig(z))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ilr_+3A_x">x</code></td>
<td>
<p>a composition, not necessarily closed</p>
</td></tr>
<tr><td><code id="ilr_+3A_z">z</code></td>
<td>
<p>the ilr-transform of a composition</p>
</td></tr>
<tr><td><code id="ilr_+3A_v">V</code></td>
<td>
<p>a matrix, with columns giving the chosen basis of the
clr-plane</p>
</td></tr>
<tr><td><code id="ilr_+3A_...">...</code></td>
<td>
<p>generic arguments. not used.</p>
</td></tr>
<tr><td><code id="ilr_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked 
by the inverse transformation. It is especially used to
reconstruct the names of the parts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ilr-transform maps a composition in the D-part Aitchison-simplex
isometrically to a D-1 dimensonal euclidian vector. The data can then
be analysed in this transformation by all classical multivariate
analysis tools. However the interpretation of the results may be
difficult, since there is no one-to-one relation between the original parts 
and the transformed variables.<br />
</p>
<p>The isometric logratio transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> ilr(x) := V^t clr(x)  </code>
</p>

<p>with <code><a href="#topic+clr">clr</a></code>(x) the centred log ratio transform and
<code class="reqn">V\in R^{d \times (d-1)}</code> a matrix which columns form an orthonormal 
basis of the clr-plane. A default matrix <code class="reqn">V</code> is given by
<code>ilrBase(<var>D</var>)</code>.
</p>


<h3>Value</h3>

<p><code>ilr</code> gives the isometric log ratio transform,
<code>ilrInv</code> gives closed compositions with the given ilr-transforms
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Egozcue J.J., V. Pawlowsky-Glahn, G. Mateu-Figueras and
C. Barcel'o-Vidal (2003) Isometric logratio transformations for
compositional data analysis. <em>Mathematical Geology</em>, <b>35</b>(3)
279-300<br />
Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003
<br />
<a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+alr">alr</a></code>,<code><a href="#topic+apt">apt</a></code>, <code><a href="#topic+ilrBase">ilrBase</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- ilr(c(1,2,3)))
ilrInv(tmp)
ilrInv(tmp) - clo(c(1,2,3)) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(ilr(cdata))
ilrBase(D=3) 
</code></pre>

<hr>
<h2 id='ilrBase'>The canonical basis in the clr plane used for ilr and ipt transforms.</h2><span id='topic+ilrBase'></span><span id='topic+ilrBaseList'></span>

<h3>Description</h3>

<p>Compute the basis of a clr-plane, to use with isometric log-ratio or planar transform of a (dataset of)
compositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ilrBase( x=NULL , z=NULL , D = NULL, method = "basic" )

          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ilrBase_+3A_x">x</code></td>
<td>
<p> optional dataset or vector of compositions</p>
</td></tr>
<tr><td><code id="ilrBase_+3A_z">z</code></td>
<td>
<p> optional dataset or vector containing ilr or ipt coordinates</p>
</td></tr>
<tr><td><code id="ilrBase_+3A_d">D</code></td>
<td>
<p> number of parts of the simplex</p>
</td></tr>
<tr><td><code id="ilrBase_+3A_method">method</code></td>
<td>
<p> method to build the basis, one of &quot;basic&quot;, &quot;balanced&quot;, &quot;optimal&quot;
&quot;PBhclust&quot;, &quot;PBmaxvar&quot; or &quot;PBangprox&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method &quot;basic&quot; computes a triangular Helmert matrix (corresponding to
the original ilr transformation defined by Egozcue et al, 2003).
In this case, <code>ilrBase</code> is a wrapper catching
the answers of <code>gsi.ilrBase</code> and is to be
used as the more convenient function.
</p>
<p>Method &quot;balanced&quot; returns an ilr matrix associated with a balanced partition,
splitting the parts in groups as equal as possible. Transforms <code>ilr</code> and <code>ipt</code> computed
with this basis are less affected by any component (as happens with &quot;basic&quot;).
</p>
<p>The following methods are all data-driven and will fail if <code>x</code> is not given. 
Some of these methods are extended to non-acomp datasets via the <code>cpt</code>
general functionality. Use with care with non-acomp objects!
</p>
<p>Method &quot;optimal&quot; is a wrapper to <code>gsi.optimalilrBase</code>, providing the ilr basis
with less influence of missing values. It is computed as a hierarchical
cluster of variables, with parts previously transformed to
1 (if the value is lost) or 0 (if it is recorded).
</p>
<p>Methods &quot;PBhclust&quot;, &quot;PBmaxvar&quot; and &quot;PBangprox&quot; are principal balance methods (i.e.
balances approximating principal components in different ways). These are all
resolved by calls to <code>gsi.PrinBal</code>. Principal balances functionality should be
considered beta!
</p>


<h3>Value</h3>

<p>All methods give a matrix containing by columns the basis elements for the
canonical basis of the clr-plane used for the ilr and ipt transform. Only one of the
arguments <code>x</code>, <code>z</code> or <code>D</code> is needed
to determine the dimension of the simplex.
</p>
<p>If you provide transformed data <code>z</code>, the function attempts to extract the basis 
information from it with <code><a href="#topic+gsi.getV">gsi.getV</a></code>. Otherwise, the default compatible 
ilr base matrix is created.
</p>


<h3>References</h3>

<p>Egozcue J.J., V. Pawlowsky-Glahn, G. Mateu-Figueras and
C. Barcel'o-Vidal (2003) Isometric logratio transformations for
compositional data analysis. <em>Mathematical Geology</em>, <b>35</b>(3)
279-300<br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+ipt">ipt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ilr(c(1,2,3))
ilrBase(D=2)
ilrBase(c(1,2,3))
ilrBase(z= ilr(c(1,2,3)) )
round(ilrBase(D=7),digits= 3)
ilrBase(D=7,method="basic")
ilrBase(D=7,method="balanced")
</code></pre>

<hr>
<h2 id='ilt'>Isometric log transform</h2><span id='topic+ilt'></span><span id='topic+iltInv'></span>

<h3>Description</h3>

<p>Compute the isometric log  transform of a vector (dataset) of
amounts and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ilt( x ,...)
          iltInv( z ,... )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ilt_+3A_x">x</code></td>
<td>
<p>a vector or data matrix of amounts</p>
</td></tr>
<tr><td><code id="ilt_+3A_z">z</code></td>
<td>
<p>the ilt-transform of a vector or data matrix of
ilt-transforms of amounts</p>
</td></tr>
<tr><td><code id="ilt_+3A_...">...</code></td>
<td>
<p>generic arguments, not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ilt-transform maps  D amounts (considered in log geometry)
isometrically to a D dimensional euclidean vector. The <code>ilt</code> is
part of the <code><a href="#topic+aplus">aplus</a></code> framework.
<br /> 
The data can then be analysed in this transformation by all classical
multivariate analysis tools. The interpretation of the results is easy
since the relation to the original
variables is preserved. <br />
</p>
<p>The isometric log transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> ilt(x)_i := \ln x_i </code>
</p>



<h3>Value</h3>

<p><code>ilt</code> gives the isometric log transform, i.e. simply the log of
the argument, whereas
<code>iltInv</code> gives amounts with the given ilt, i.e. simply the exp
of the argument.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilr">ilr</a></code>, <code><a href="#topic+iit">iit</a></code>, <code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- ilt(c(1,2,3)))
iltInv(tmp)
iltInv(tmp) - c(1,2,3) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(ilt(cdata)) 
</code></pre>

<hr>
<h2 id='ipt'>Isometric planar transform</h2><span id='topic+ipt'></span><span id='topic+iptInv'></span><span id='topic+uciptInv'></span>

<h3>Description</h3>

<p>Compute the isometric planar  transform of a (dataset of)
composition(s) and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ipt( x , V = ilrBase(x),... )
          iptInv( z , V = ilrBase(z=z),...,orig=gsi.orig(z))
          uciptInv( z , V = ilrBase(z=z),...,orig=gsi.orig(z) )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ipt_+3A_x">x</code></td>
<td>
<p>a composition or a data matrix of compositions, not necessarily closed</p>
</td></tr>
<tr><td><code id="ipt_+3A_z">z</code></td>
<td>
<p>the ipt-transform of a composition or a data matrix of
ipt-transforms of compositions</p>
</td></tr>
<tr><td><code id="ipt_+3A_v">V</code></td>
<td>
<p>a matrix with columns giving the chosen basis of the clr-plane</p>
</td></tr>
<tr><td><code id="ipt_+3A_...">...</code></td>
<td>
<p>generic arguments. not used.</p>
</td></tr>
<tr><td><code id="ipt_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked 
by the inverse transformation. It is especially used to
reconstruct the names of the parts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ipt-transform maps a composition in the D-part real-simplex
isometrically to a D-1 dimensonal euclidian vector. Although the
transformation does not reach the whole <code class="reqn">R^{D-1}</code>, resulting covariance
matrices are typically of full rank.
<br /> 
The data can then
be analysed in this transformation by all classical multivariate
analysis tools. However, interpretation of results may be
difficult, since the
transform does not keep the variable names, given that there is no
one-to-one relation between the original parts and each transformed variables. See
<code><a href="#topic+cpt">cpt</a></code> and <code><a href="#topic+apt">apt</a></code> for alternatives. <br />
</p>
<p>The isometric planar transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> ipt(x) := V^t cpt(x)  </code>
</p>

<p>with <code><a href="#topic+cpt">cpt</a></code>(x) the centred planar transform and
<code class="reqn">V\in R^{d \times (d-1)}</code> a matrix which columns form an orthonormal 
basis of the clr-plane. A default matrix <code class="reqn">V</code> is given by
<code>ilrBase(<var>D</var>)</code>
</p>


<h3>Value</h3>

<p><code>ipt</code> gives the centered planar transform,
<code>iptInv</code> gives closed compositions with with the given ipt-transforms,
<code>uciptInv</code> unconstrained iptInv does the same as iptInv but
sets illegal values to NA rather than giving an error. This is a
workaround to allow procedures not honoring the constraints of the
space.  
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+ilrBase">ilrBase</a></code>, <code><a href="#topic+cpt">cpt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- ipt(c(1,2,3)))
iptInv(tmp)
iptInv(tmp) - clo(c(1,2,3)) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(ipt(cdata)) 
</code></pre>

<hr>
<h2 id='is.acomp'>Check for compositional data type</h2><span id='topic+is.acomp'></span><span id='topic+is.aplus'></span><span id='topic+is.ccomp'></span><span id='topic+is.rcomp'></span><span id='topic+is.rplus'></span><span id='topic+is.rmult'></span>

<h3>Description</h3>

<p><code>is.</code><var>XXX</var> returns <code>TRUE</code> if and only if its argument is
of type <var>XXX</var> </p>


<h3>Usage</h3>

<pre><code class='language-R'>is.acomp(x)
is.rcomp(x)
is.aplus(x)
is.rplus(x)
is.rmult(x)
is.ccomp(x)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.acomp_+3A_x">x</code></td>
<td>
<p>any object to be checked</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions only check for the class of the object.
</p>


<h3>Value</h3>

<p>TRUE or FALSE
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+acomp">acomp</a></code>,  <code><a href="#topic+rcomp">rcomp</a></code>
<code><a href="#topic+aplus">aplus</a></code>,  <code><a href="#topic+rplus">rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.acomp(1:3)
is.acomp(acomp(1:3))
is.rcomp(acomp(1:3))
is.acomp(acomp(1:3)+acomp(1:3))
</code></pre>

<hr>
<h2 id='IsMahalanobisOutlier'>Checking for outliers</h2><span id='topic+IsMahalanobisOutlier'></span>

<h3>Description</h3>

<p>Detect outliers with respect to a normal distribution model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsMahalanobisOutlier(X,...,alpha=0.05,goodOnly=NULL,
                 replicates=1000,corrected=TRUE,robust=TRUE,crit=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IsMahalanobisOutlier_+3A_x">X</code></td>
<td>
<p>a dataset (e.g. given as acomp, rcomp, aplus, rplus or rmult) object
to which <code><a href="#topic+idt">idt</a></code> and <code>MahalanobisDist</code> apply. </p>
</td></tr>
<tr><td><code id="IsMahalanobisOutlier_+3A_...">...</code></td>
<td>
<p>further arguments to MahalanobisDist/gsi.mahOutlier</p>
</td></tr>
<tr><td><code id="IsMahalanobisOutlier_+3A_alpha">alpha</code></td>
<td>
<p>The confidence level for identifying outliers.</p>
</td></tr>
<tr><td><code id="IsMahalanobisOutlier_+3A_goodonly">goodOnly</code></td>
<td>
<p>an integer vector. Only the specified index of the
dataset should be used
for estimation of the outlier criteria. This parameter if only a small
portion of the dataset is reliable.</p>
</td></tr>
<tr><td><code id="IsMahalanobisOutlier_+3A_replicates">replicates</code></td>
<td>
<p>The number of replicates to be used in the Monte
Carlo simulations for determination of the quantiles. The
<code>replicates</code> not given a minimum is computed from the alpha
level to ensure reasonable precission.</p>
</td></tr>
<tr><td><code id="IsMahalanobisOutlier_+3A_corrected">corrected</code></td>
<td>
<p>logical. Literatur often proposed to compare the
Mahalanobis distances with Chisq-Approximations of there
distributions. However this does not correct for multiple
testing. If corrected is true a correction for multiple testing is
used. In any case we do not use the chisq-approximation, but a
simulation based procedure to compute confidence bounds. </p>
</td></tr>
<tr><td><code id="IsMahalanobisOutlier_+3A_robust">robust</code></td>
<td>
<p>A robustness description as define in
<code><a href="#topic+robustnessInCompositions">robustnessInCompositions</a></code></p>
</td></tr>
<tr><td><code id="IsMahalanobisOutlier_+3A_crit">crit</code></td>
<td>
<p>The critical value to be used. Typically the routine is
called mainly for the purpose of finding this value, which it does,
when crit is NULL, however
sometimes we might want to specifiy a value used by someone else to
reproduce the results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="#topic+outliersInCompositions">outliersInCompositions</a> and <a href="#topic+robustnessInCompositions">robustnessInCompositions</a>
for a comprehensive introduction into the outlier treatment in
compositions.
</p>
<p>See <code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code> for a highlevel method to
classify observations in the context of outliers.  
</p>


<h3>Value</h3>

<p>A logical vector giving for each element the result of the alpha-level
test for beeing an outlier. TRUE corresponds to a significant result.   
</p>


<h3>Note</h3>

<p>For some unkown reasons the computation sometimes produces NaN's. In
this case a warning is issued and a recomputation is tried.
</p>
<p>The package <span class="pkg">robustbase</span> is required for using the
robust estimations.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code> , <code><a href="#topic+outlierplot">outlierplot</a></code>,
<code><a href="#topic+ClusterFinder1">ClusterFinder1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(SimulatedAmounts)

datas &lt;- list(data1=sa.outliers1,data2=sa.outliers2,data3=sa.outliers3,
              data4=sa.outliers4,data5=sa.outliers5,data6=sa.outliers6)

opar&lt;-par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))
tmp&lt;-mapply(function(x,y){
plot(x,col=ifelse(IsMahalanobisOutlier(x),"red","gray"))
  title(y)
},datas,names(datas))

## End(Not run)
</code></pre>

<hr>
<h2 id='isoPortionLines'>Isoportion- and Isoproportion-lines </h2><span id='topic+isoPortionLines'></span><span id='topic+isoPortionLines.acomp'></span><span id='topic+isoPortionLines.rcomp'></span><span id='topic+isoProportionLines'></span><span id='topic+isoProportionLines.acomp'></span><span id='topic+isoProportionLines.rcomp'></span>

<h3>Description</h3>

<p>Add lines of equal portion and proportion to ternary diagrams, to serve as reference axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isoPortionLines(...)
## S3 method for class 'acomp'
isoPortionLines(by=0.2,at=seq(0,1,by=by),...,
                      parts=1:3,total=1,labs=TRUE,lines=TRUE,unit="")
## S3 method for class 'rcomp'
isoPortionLines(by=0.2,at=seq(0,1,by=by),...,
                      parts=1:3,total=1,labs=TRUE,lines=TRUE,unit="")
isoProportionLines(...)
## S3 method for class 'acomp'
isoProportionLines(by=0.2,at=seq(0,1,by=by),...,
                      parts=1:3,labs=TRUE,lines=TRUE) 
## S3 method for class 'rcomp'
isoProportionLines(by=0.2,at=seq(0,1,by=by),...,
                      parts=1:3,labs=TRUE,lines=TRUE) 
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isoPortionLines_+3A_...">...</code></td>
<td>
<p>graphical arguments</p>
</td></tr>
<tr><td><code id="isoPortionLines_+3A_at">at</code></td>
<td>
<p>numeric in [0,1]: which portions/proportions should be marked?</p>
</td></tr>
<tr><td><code id="isoPortionLines_+3A_by">by</code></td>
<td>
<p>numeric in (0,1]: steps between protions/proportions</p>
</td></tr>
<tr><td><code id="isoPortionLines_+3A_parts">parts</code></td>
<td>
<p>numeric vector subset of {1,2,3}: the variables to be
marked</p>
</td></tr>
<tr><td><code id="isoPortionLines_+3A_total">total</code></td>
<td>
<p>the total amount to be used in labeling</p>
</td></tr>
<tr><td><code id="isoPortionLines_+3A_labs">labs</code></td>
<td>
<p>logical: plot the labels?</p>
</td></tr>
<tr><td><code id="isoPortionLines_+3A_lines">lines</code></td>
<td>
<p>logical: plot the lines?</p>
</td></tr>
<tr><td><code id="isoPortionLines_+3A_unit">unit</code></td>
<td>
<p>mark of the units e.g. &quot;%&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Isoportion lines give lines of the same portion of one of the parts,
while isoproportion line gives lines of the same ratio between two
parts. The isoproportion lines are straight lines in both the 
Aitchison and the real geometries of the simplex, while the isoportion 
lines are not straight in an Aitchison sense (only in the real one).
However, note that both types of lines remain straight in the real sense
when perturbed (von Eynatten et al., 2002).
</p>


<h3>Note</h3>

<p>Currently IsoLines only works with individual plots. This is mainly due to the
fact that I have no idea, what the user interface of this function
should look like for multipanel plots. This includes philosophical
problems with the meaning of isoportions in case of marginal plots. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>von Eynatten, H., V. Pawlowsky-Glahn, and J.J. Egozcue (2002) Understanding 
perturbation on the simplex: a simple method to better visualize and interpret
compositional data in ternary diagrams. <em>Mathematical Geology</em> <b>34</b>, 
249-257<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(acomp(sa.lognormals))
isoPortionLines()
plot(acomp(sa.lognormals),center=TRUE)
isoPortionLines()
plot(rcomp(sa.lognormals))
isoPortionLines()
plot(acomp(sa.lognormals))
isoProportionLines()
plot(acomp(sa.lognormals),center=TRUE)
isoProportionLines()
plot(rcomp(sa.lognormals))
isoProportionLines()
</code></pre>

<hr>
<h2 id='jura'>The jura dataset</h2><span id='topic+juraset'></span><span id='topic+jura259'></span>

<h3>Description</h3>

<p>A geochemical dataset from the Swiss Jura.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(juraset)
data(jura259)
</code></pre>


<h3>Format</h3>

<p>A 359x11 or 259x11 dataframe </p>


<h3>Details</h3>

<p>The JURA data set
provided by J.-P. Dubois, IATE-Paedologie, Ecole Polytechnique Federale de Lausanne,
1015 Lausanne, Switzerland.
Spatial coordinates and values of categorial and continuous attributes
at the 359 sampled sites. The 100 test locartions are denoted with a star.
Rock Types: 1: Argovian, 2: Kimmeridgian, 3: Sequanian, 4: Portlandian, 5: Quaternary.
Land uses: 1: Forest, 2: Pasture, 3: Meadow , 4: Tillage 
</p>

<table>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> X</td><td style="text-align: left;"> X location coordinate</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Y</td><td style="text-align: left;"> Y location coordinate</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Rock</td><td style="text-align: left;">  Categorical: rocktype,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Land</td><td style="text-align: left;">  Categorical: land usage</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Cd</td><td style="text-align: left;">  element amount,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Cu</td><td style="text-align: left;">  element amount,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Pb</td><td style="text-align: left;">  element amount,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Co</td><td style="text-align: left;">  element amount,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Cr</td><td style="text-align: left;">  element amount,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Ni</td><td style="text-align: left;">  element amount,</td>
</tr>
<tr>
 <td style="text-align: right;">
</td>
</tr>

</table>

<p>All 3-part compositions sum to one.
</p>


<h3>Source</h3>

<p>AI-Geostats
</p>


<h3>References</h3>

<p>Atteia, O., Dubois, J.-P., Webster, R., 1994,
Geostatistical analysis of soil contamination in the Swiss Jura:
Environmental Pollution 86, 315-327
</p>
<p>Webster, R., Atteia, O., Dubois, J.-P., 1994,
Coregionalization of trace metals in the soil in the Swiss Jura:
European Journal of Soil Science 45, 205-218
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(juraset)
X &lt;- with(juraset,cbind(X,Y))
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
lrv &lt;- logratioVariogram(comp,X,maxdist=1,nbins=10)
plot(lrv)

## End(Not run)

</code></pre>

<hr>
<h2 id='kdeDirichlet'>Density estimation on the simplex with Dirichlet kernel</h2><span id='topic+kdeDirichlet'></span>

<h3>Description</h3>

<p>Function to compute the kernel density estimation on a grid of the simplex
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdeDirichlet(x, adj = 1, n = 200, kdegrid = NULL, delta = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kdeDirichlet_+3A_x">x</code></td>
<td>
<p>data set of (complete) compositional data, i.e. data summing to 1 by columns</p>
</td></tr>
<tr><td><code id="kdeDirichlet_+3A_adj">adj</code></td>
<td>
<p>accessory scaling factor, for modifying the bandwith in analogy to 
function [MASS::kde()]</p>
</td></tr>
<tr><td><code id="kdeDirichlet_+3A_n">n</code></td>
<td>
<p>integer, number of grid nodes on each component, where to estimate 
the density; ignored if 'kdegrid' is given</p>
</td></tr>
<tr><td><code id="kdeDirichlet_+3A_kdegrid">kdegrid</code></td>
<td>
<p>data frame, set of locations where to estimate the density; either
specify 'n' or 'kdegrid'</p>
</td></tr>
<tr><td><code id="kdeDirichlet_+3A_delta">delta</code></td>
<td>
<p>logical or real controlling if/how zeroes in 'x' are treated; logical 
works only for 'kdegrid=NULL' and uses correction by half the grid cell size, 
otherwise give a real value; this value will be added to the whole composition, including
the non-zero values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the kde (kernel density estimation) of the probability
density function of a random composition on the simplex, by using Dirichlet 
kernels. The method was proposed by Aitchison and Lauder (1985).
</p>


<h3>Value</h3>

<p>A list of two or three elements, depending on the value
of 'kdegrid'. If 'kdegrid' is null, the function is assumed to be used for 
two-dimensional plotting, and the output is one compatible with the function
[image()], i.e. a list of three elements (vector of x-values, vector of y-values
and matrix of density values computed). If 'kdegrid' is a grid, then the
output has two elements: the input grid and a vector of computed densities.
</p>
<p>NOTE: no effort is made to check that 'kdegrid' has the right class, dimension
or content.
</p>


<h3>References</h3>

<p>Aitchison J., Lauder I.J. (1985) Kernel density estimation for compositional data;
_J. Roy. Statist. Soc. Ser. C_, 34 (2): 129-137.
</p>
<p>Ouimet, F. and Tolosana-Delgado, R. (2022) Asymptotic properties of Dirichlet kernel 
density estimators; _Journal of Multivariate Analysis_ 187: 104832, 
doi: <a href="https://doi.org/10.1016/j.jmva.2021.104832">10.1016/j.jmva.2021.104832</a>
</p>

<hr>
<h2 id='kingTetrahedron'>Ploting composition into rotable tetrahedron</h2><span id='topic+kingTetrahedron'></span>

<h3>Description</h3>

<p>Plots acomp/rcomp objects into tetrahedron exported in kinemage format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   kingTetrahedron(X, parts=1:4, file="tmptetrahedron.kin",
   clu=NULL,vec=NULL, king=TRUE, scale=0.2, col=1, 
   title="Compositional Tetrahedron")
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kingTetrahedron_+3A_x">X</code></td>
<td>
<p>a compositional acomp or rcomp object of 4 or more parts</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_parts">parts</code></td>
<td>
<p>a numeric or character vector specifying the 4 parts to
be used.</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_file">file</code></td>
<td>

<p>file.kin for 3D display  with the KiNG (Kinemage, Next Generation) interactive
system for three-dimensional vector graphics.
</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_clu">clu</code></td>
<td>
<p>partition determining the colors of points</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_vec">vec</code></td>
<td>
<p>vector of values determining points sizes</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_king">king</code></td>
<td>
<p>FALSE for Mage; TRUE for King (described below)</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_scale">scale</code></td>
<td>
<p>relative size of points</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_col">col</code></td>
<td>
<p>color of points if clu=NULL</p>
</td></tr>
<tr><td><code id="kingTetrahedron_+3A_title">title</code></td>
<td>
<p>The title of the plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The  routine transforms a 4 parts mixture m quadrays into 3-dimensional
XYZ coordinates and writes them as file.kin. For this transformation we
apply K. Urner: Quadrays and XYZ at
<a href="http://www.grunch.net/synergetics/quadxyz.html">http://www.grunch.net/synergetics/quadxyz.html</a>. 
The kin file we display as 3-D animation with KiNG viewer.  
A kinemage is a dynamic, 3-D illustration. 
The best way to take advantage of that is by rotating it and twisting it around 
with the mouse click near the center of the graphics window and slowly draging right or left,
up or down. Furthermore by clicking on points with the mouse (left button again), 
the label associated with each point will appear in the bottom left of the graphics area
and also the distance from this point to the last will be displayed.
With the right button drag we can zoom in and out of the picture.
This animation supports coloring and different sizing of points.
</p>
<p>We can display the kin file as 3-D animation also with MAGE viewer a previous version of KiNG,

more information (and links to the software) can be found at 
<a href="https://en.wikipedia.org/wiki/Kinemage">https://en.wikipedia.org/wiki/Kinemage</a>.
For this one has to put king=FALSE as a parameter.
</p>


<h3>Value</h3>

<p>The function is called for its side effect of generating 
a file  for 3D display  with the KiNG (Kinemage, Next Generation) interactive
system for three-dimensional vector graphics.
Works only with KiNG viewer. More information (and links to the actual viewers) 
can be found at <a href="https://en.wikipedia.org/wiki/Kinemage">https://en.wikipedia.org/wiki/Kinemage</a>
</p>


<h3>Note</h3>

<p>This routine and the documentation is based on mix.Quad2net from the
MixeR-package of Vladimir Batagelj and Matevz Bren, and has been
contributed by Matevz Bren to this package. Only slight modifications
have been applied to make function compatible with the philosophy and
objects of the compositions package.
</p>


<h3>Author(s)</h3>

<p>Vladimir Batagelj and Matevz Bren, with slight modifications of K.Gerald van den Boogaart</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p><a href="http://vlado.fmf.uni-lj.si/pub/MixeR/">http://vlado.fmf.uni-lj.si/pub/MixeR/</a>
</p>
<p><a href="http://www.grunch.net/synergetics/quadxyz.html">http://www.grunch.net/synergetics/quadxyz.html</a><br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(SimulatedAmounts)
dat &lt;- acomp(sa.groups5)
hc &lt;- hclust(dist(dat), method = "complete")  # data are clustered 
kingTetrahedron(dat,parts=1:4, file="myfirst.kin", clu=cutree(hc,7),
scale=0.2)
# the 3-D plot is written into Glac1.kin file to be displayed with KiNG viewer. 
# The seven clusters partition is notated with different colors of points.

## End(Not run)
</code></pre>

<hr>
<h2 id='Kongite'>Compositions of 25 specimens of kongite</h2><span id='topic+Kongite'></span><span id='topic+Data02'></span>

<h3>Description</h3>

<p>A mineral compositions of 25 rock specimens of kongite type.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Kongite)
</code></pre>


<h3>Details</h3>

<p>A mineral compositions of 25 rock specimens of hongite type.
Each composition consists of the percentage by weight of five minerals,
albite, blandite, cornite, daubite, endite, which we conveniently abbreviate
to A, B, C, D, E.  All row percentage sums to 100.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name HONGITE.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, (Data 2), pp2.
</p>

<hr>
<h2 id='lines'>Draws connected lines from point to point.</h2><span id='topic+lines.rmult'></span><span id='topic+lines.acomp'></span><span id='topic+lines.rcomp'></span><span id='topic+lines.aplus'></span><span id='topic+lines.rplus'></span>

<h3>Description</h3>

<p>Functions taking coordinates given in various ways and
joining the corresponding points with line segments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ## S3 method for class 'acomp'
lines(x,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rcomp'
lines(x,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'aplus'
lines(x,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rplus'
lines(x,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rmult'
lines(x,...,steps=30,aspanel=FALSE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lines_+3A_x">x</code></td>
<td>
<p>a dataset of the given type</p>
</td></tr>
<tr><td><code id="lines_+3A_...">...</code></td>
<td>
<p>further graphical parameters</p>
</td></tr>
<tr><td><code id="lines_+3A_steps">steps</code></td>
<td>
<p>the number of discretisation points to draw the segments,
which might be not visually straight.</p>
</td></tr>
<tr><td><code id="lines_+3A_aspanel">aspanel</code></td>
<td>
<p>Logical, indicates use as slave to do acutal drawing only.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions add lines to the graphics generated with the corresponding
plot functions.
<br />
Adding to multipaneled plots, redraws the plot completely and is only
possible, when the plot has been created with the plotting routines from
this library.
<br />
For the rcomp/rplus geometries the main problem is providing a function
that reasonably works with lines leaving the area. We tried to use a
policy of cuting the line at the actual borders of the (high
dimensional) simplex. That can lead to very strange visual impression
showing lines ending somewhere in the middle of the plot. However these
lines actually hit some border of the simplex that is not shown in the
plot. A hyper dimensional tetrahedron is even more difficult to imagin
than a hyperdimensional cube. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>, <code><a href="#topic+straight">straight</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)

plot(acomp(sa.lognormals))
lines(acomp(sa.lognormals),col="red")
lines(rcomp(sa.lognormals),col="blue")

plot(aplus(sa.lognormals[,1:2]))
lines(aplus(sa.lognormals[,1:2]),col="red")
lines(rplus(sa.lognormals)[,1:2],col="blue")

plot(rplus(sa.lognormals[,1:2]))
tt&lt;-aplus(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="red")
tt&lt;-rplus(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="blue")
tt&lt;-rmult(sa.lognormals[,1:2]); ellipses(mean(tt),var(tt),r=2,col="green")

</code></pre>

<hr>
<h2 id='logratioVariogram'>Empirical variograms for compositions</h2><span id='topic+logratioVariogram'></span><span id='topic+logratioVariogram.acomp'></span>

<h3>Description</h3>

<p>Computes the matrix of logratio variograms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  logratioVariogram(data, ...)
  
  ## S3 method for class 'acomp'
logratioVariogram(data,
                          loc,
                          maxdist=max(dist(loc))/2,
                          nbins=20,
                          dists=seq(0,maxdist,length.out=nbins+1),
                          bins=cbind(dists[-length(dists)],dists[-1]),
                          azimuth=0,
                          azimuth.tol=180,
                          comp=data,
                          ...
                          )
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logratioVariogram_+3A_data">data</code></td>
<td>
<p>an acomp compositional dataset</p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_...">...</code></td>
<td>
<p>arguments for generic functionality</p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_loc">loc</code></td>
<td>
<p>a matrix or dataframe providing the observation locations
of the compositions. Any number of dimension &gt;= 2 is supported.</p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_maxdist">maxdist</code></td>
<td>
<p>the maximum distance to compute the variogram for.</p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_nbins">nbins</code></td>
<td>
<p>The number of distance bins to compute the variogram for</p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_dists">dists</code></td>
<td>
<p>The distances seperating the bins</p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_bins">bins</code></td>
<td>
<p>a matrix with lower and upper limit for the distances of
each bin. A pair is counted if min&lt;h&lt;=max. min and max are provided
as columns. bins is computed from maxdist,nbins and dists. If it is
provided, it is used directly.</p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_azimuth">azimuth</code></td>
<td>
<p> For directional variograms the direction, either as an
azimuth  angle (i.e. a single real number) for 2D
datasets or a unit vector pointing of the same dimension as the
locations. The angle is clockwise from North in degree. </p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_azimuth.tol">azimuth.tol</code></td>
<td>
<p> The angular tolerance it should be below 90 if a
directional variogram is intended. </p>
</td></tr>
<tr><td><code id="logratioVariogram_+3A_comp">comp</code></td>
<td>
<p>do not use, only provided for backwards compatibility. Use <code>data</code> instead</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The logratio-variogram is the set of variograms of each of the pairwise
logratios. It can be proven that it carries the same information as a
usual multivariate variogram. The great advantage is that all the
funcitions have a direct interpreation and can be estimated even with
(MAR) missings in the dataset. 
</p>


<h3>Value</h3>

<p>A list of class <code>"logratioVariogram"</code>.
</p>
<table>
<tr><td><code>vg</code></td>
<td>
<p>A nbins x D x D array containing the logratio variograms</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>A nbins x D x D array containing the mean distance the
value is computed on. </p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>A nbins x D x D array containing the
number of nonmissing pairs used for the corresponding value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Tolosana, van den Boogaart, Pawlowsky-Glahn (2009) Estimating and
modeling variograms of compositional data with occasional missing
variables in R, StatGis09
</p>
<p>Pawlowsky-Glahn, Vera and Olea, Ricardo A. (2004) Geostatistical
Analysis of Compositional Data, Oxford University Press, Studies in
Mathematical Geology
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vgram2lrvgram">vgram2lrvgram</a></code>,
<code><a href="#topic+CompLinModCoReg">CompLinModCoReg</a></code>,
<code><a href="#topic+vgmFit">vgmFit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(juraset)
X &lt;- with(juraset,cbind(X,Y))
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
lrv &lt;- logratioVariogram(comp,X,maxdist=1,nbins=10)
plot(lrv)

## End(Not run)
</code></pre>

<hr>
<h2 id='lrvgram'>vgram2lrvgram</h2><span id='topic+vgram2lrvgram'></span><span id='topic+cgram2vgram'></span>

<h3>Description</h3>

<p>Transforms model functions for different types of compositional (logratio)(co)variograms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cgram2vgram(cgram)
vgram2lrvgram(vgram)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrvgram_+3A_cgram">cgram</code></td>
<td>
<p>A (matrix valued) covariance function.</p>
</td></tr>
<tr><td><code id="lrvgram_+3A_vgram">vgram</code></td>
<td>
<p>A (matrix valued) variogram functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variogram is given by <code>cgram(0)-cgram(h)</code> and
<code>lrvgram(h)[,i,j]==vgram(h)[,i,i]+vgram(h)[,i,j]-2*vgram(h)[,i,j]</code>.  
</p>
<p>The logratio-variogram is the set of variograms of each of the pairwise
logratios. It can be proven that it carries the same information as a
usual multivariate variogram. The great advantage is that all the
funcitions have a direct interpreation and can be estimated even with
(MAR) missings in the dataset. 
</p>


<h3>Value</h3>

<p>A function that takes the same parameters as the input function
(through a ... parameterlist), but provides the correponding
variogram values (cgram2vgram) or logratio Variogram (vgram2lrvgram) values. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Tolosana, van den Boogaart, Pawlowsky-Glahn (2009) Estimating and
modeling variograms of compositional data with occasional missing
variables in R, StatGis09
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logratioVariogram">logratioVariogram</a></code>,
<code><a href="#topic+CompLinModCoReg">CompLinModCoReg</a></code>,
<code><a href="#topic+vgmFit">vgmFit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(juraset)
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
vg &lt;- CompLinModCoReg(~nugget()+sph(0.5)+R1*exp(0.7),comp)
vg(1:3)
vgram2lrvgram(vg)(1:3)
</code></pre>

<hr>
<h2 id='MahalanobisDist'>Compute Mahalanobis distances based von robust Estimations</h2><span id='topic+MahalanobisDist'></span><span id='topic+MahalanobisDist.rmult'></span><span id='topic+MahalanobisDist.acomp'></span><span id='topic+MahalanobisDist.rcomp'></span><span id='topic+MahalanobisDist.rplus'></span><span id='topic+MahalanobisDist.aplus'></span>

<h3>Description</h3>

<p>MahalanobisDist computes the Mahalanobis distances to the center or to
other observations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MahalanobisDist(x,center=NULL,cov=NULL,inverted=FALSE,...)
## S3 method for class 'rmult'
MahalanobisDist(x,center=NULL,cov=NULL,inverted=FALSE,...,
           goodOnly=NULL,pairwise=FALSE,pow=1,
robust=FALSE,giveGeometry=FALSE)
## S3 method for class 'acomp'
MahalanobisDist(x,center=NULL,cov=NULL,inverted=FALSE,...,
           goodOnly=NULL, pairwise=FALSE,pow=1,robust=FALSE,giveGeometry=FALSE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MahalanobisDist_+3A_x">x</code></td>
<td>
<p>the dataset</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_robust">robust</code></td>
<td>
<p>logical or a robust method description (see
<code><a href="#topic+robustnessInCompositions">robustnessInCompositions</a></code>) specifiying how the center and covariance
matrix are estimated,if not given.</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_...">...</code></td>
<td>
<p>Further arguments to <code><a href="Matrix.html#topic+solve">solve</a></code>. </p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_center">center</code></td>
<td>
<p>An estimated for the center (mean) of the dataset. If
center is NULL it will be estimated based using the given robust
option.</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_cov">cov</code></td>
<td>
<p>An estimated for the spread (covariance matrix) of the
dataset. If
cov is NULL it will be estimated based using the given robust
option.</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_inverted">inverted</code></td>
<td>
<p>TRUE if the inverse of the covariance matrix is
given.</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_goodonly">goodOnly</code></td>
<td>
<p>An vector of indices to the columns of x that should
be used for estimation of center and spread.</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_pairwise">pairwise</code></td>
<td>
<p>If FALSE the distances to the center are returned as a
vector. If TRUE the distances between the cases are returned as a
distance matrix.</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_pow">pow</code></td>
<td>
<p>The power of the Mahalanobis distance to be used. 1
correponds to the square root of the squared distance in
transformed space, like it is defined in most books. The choice 2
corresponds to what is implemented in many software package
including the <code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code> function in R.</p>
</td></tr>
<tr><td><code id="MahalanobisDist_+3A_givegeometry">giveGeometry</code></td>
<td>
<p>If true an atrributes <code>"center"</code> and
<code>"cov"</code> given the center and the idt-variance used for the
calculations. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mahalanobis distance is the distance in a linearly transformed
space, where the linear transformation is selected in such a way,that
the variance is the unit matrix. Thus the distances are given in
multiples of standard deviation. 
</p>


<h3>Value</h3>

<p>Either a vector of Mahalanobis distances to the center, or a distance
matrix (like from <code><a href="#topic+dist">dist</a></code>) giving the pairwise Mahalanobis
distances of the data.
</p>


<h3>Note</h3>

<p>Unlike the <code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code> function this function does not
be default compute the square of the mahalanobis distance. The pow
option is provided if the square is needed.
<br />
The package <span class="pkg">robustbase</span> is required for using the
robust estimations.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+dist">dist</a></code>, <code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
data5 &lt;- acomp(sa.outliers5)

  cl &lt;- ClusterFinder1(data5,sigma=0.4,radius=1) 
  plot(data5,col=as.numeric(cl$types),pch=as.numeric(cl$types))
  legend(1,1,legend=levels(cl$types),xjust=1,col=1:length(levels(cl$types)),
             pch=1:length(levels(cl$types)))

</code></pre>

<hr>
<h2 id='matmult'>inner product for matrices and vectors</h2><span id='topic++25+2A+25'></span><span id='topic++25+2A+25.default'></span>

<h3>Description</h3>

<p>Multiplies two matrices, if they are conformable. If one argument
is a vector, it will be coerced to either a row or a column matrix
to make the two arguments conformable. If both are vectors it will
return the inner product.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %*% y
## Default S3 method:
x %*% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matmult_+3A_x">x</code>, <code id="matmult_+3A_y">y</code></td>
<td>
<p>numeric or complex matrices or vectors</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>This is a copy of the 
<code>base::%*%</code>
function. The
function is made generic to allow the definition of specific methods.
</p>


<h3>Value</h3>

<p>The matrix product.  Uses 'drop' to get rid of dimensions which
have only one level.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic++25+2A+25.rmult">%*%.rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>M &lt;- matrix(c(
0.2,0.1,0.0,
0.1,0.2,0.0,
0.0,0.0,0.2),byrow=TRUE,nrow=3)
x &lt;- c(1,1,2)
M %*% x
x %*% M
x %*% x
M %*% M
t(x) %*% M

</code></pre>

<hr>
<h2 id='mean.acomp'>Mean amounts and mean compositions</h2><span id='topic+mean.acomp'></span><span id='topic+mean.rcomp'></span><span id='topic+mean.aplus'></span><span id='topic+mean.ccomp'></span><span id='topic+mean.rplus'></span><span id='topic+mean.rmult'></span>

<h3>Description</h3>

<p>Compute the mean in the several approaches of compositional and amount
data analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ## S3 method for class 'acomp'
mean(x,...,robust=getOption("robust"))
          ## S3 method for class 'rcomp'
mean(x,...,robust=getOption("robust"))
          ## S3 method for class 'aplus'
mean(x,...,robust=getOption("robust"))
          ## S3 method for class 'rplus'
mean(x,...,robust=getOption("robust"))
          ## S3 method for class 'ccomp'
mean(x,...,robust=getOption("robust"))
          ## S3 method for class 'rmult'
mean(x,...,na.action=NULL,robust=getOption("robust"))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mean.acomp_+3A_x">x</code></td>
<td>
<p>a classed dataset of amounts or compositions</p>
</td></tr>
<tr><td><code id="mean.acomp_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="base.html#topic+mean">mean</a></code> e.g. <code>trim</code></p>
</td></tr>
<tr><td><code id="mean.acomp_+3A_na.action">na.action</code></td>
<td>
<p>na.action </p>
</td></tr>
<tr><td><code id="mean.acomp_+3A_robust">robust</code></td>
<td>

<p>A description of a robust estimator. Possible values are FALSE or
&quot;pearson&quot; for no robustness, or TRUE or &quot;mcd&quot; for a
<a href="robustbase.html#topic+covMcd">covMcd</a> based
robust location scale estimation. Additional control parameters such
as <code>list(trim=0.2)</code> or an <code>rrcov.control</code> object can
be given as an attribute &quot;control&quot;. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The different compositional approaches <code><a href="#topic+acomp">acomp</a></code>,
<code><a href="#topic+rcomp">rcomp</a></code>,
<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code> correpond to different
geometries. The mean is calculated in the respective canonical
geometry by applying a canonical transform (see <code><a href="#topic+cdt">cdt</a></code>), taking ordinary
<code><a href="#topic+meanCol">meanCol</a></code> and backtransforming.<br />
</p>
<p>The Aitchison geometries imply that <code>mean.acomp</code> and <code>mean.aplus</code> are
geometric means, the first one closed. The real geometry implies that
<code>mean.rcomp</code> and <code>mean.rplus</code> are arithmetic means, the first
one resulting in a closed composition.<br />
</p>
<p>In all cases the mean is again an object of the same class. 
</p>


<h3>Value</h3>

<p>The mean is given as a composition or amount vector of the same class as the original dataset.
</p>


<h3>Missing Policy</h3>

<p>For the additive scales (rcomp,rplus) the SZ and BDL are 
treated as zeros and MAR and MNAR as missing information. 
This is not strictly correct for MNAR. 
<br />
For relative scales (acomp,aplus), all four types of missings 
are treated as missing information. This corresponds to the 
idea that BDL are truncated values (and have the correspoding 
effect in taking means). For SZ and MAR, only the components in 
the observed subcomposition are fully relevant. Finally, for MNAR 
the problem is again that nothing could be done without knowing
the MNAR mechanism, so the analysis is limited to taking them as 
MAR, and being <em>careful</em> with the interpretation.
Missing and Below Detecion Limit Policy is explained in more detail 
in <a href="#topic+compositions.missing">compositions.missing</a>. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+clo">clo</a></code>, <code><a href="#topic+meanCol">meanCol</a></code>,
<code><a href="#topic+geometricmean">geometricmean</a></code>, <code><a href="#topic+acomp">acomp</a></code>,
<code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
meanCol(sa.lognormals)
mean(acomp(sa.lognormals))
mean(rcomp(sa.lognormals))
mean(aplus(sa.lognormals))
mean(rplus(sa.lognormals))
mean(rmult(sa.lognormals))
</code></pre>

<hr>
<h2 id='meanrow'>The arithmetic mean of rows or columns</h2><span id='topic+meanRow'></span><span id='topic+meanCol'></span><span id='topic+mean.row'></span><span id='topic+mean.col'></span>

<h3>Description</h3>

<p>Computes the arithmetic mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          meanRow(x,..., na.action=get(getOption("na.action")))
          meanCol(x,..., na.action=get(getOption("na.action")))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meanrow_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix of data </p>
</td></tr>
<tr><td><code id="meanrow_+3A_...">...</code></td>
<td>
<p>arguments to <code><a href="base.html#topic+mean">mean</a></code> </p>
</td></tr>
<tr><td><code id="meanrow_+3A_na.action">na.action</code></td>
<td>
<p> The na.action to be used: one of
<code><a href="stats.html#topic+na.omit">na.omit</a></code>,<code><a href="stats.html#topic+na.fail">na.fail</a></code>,<code><a href="stats.html#topic+na.pass">na.pass</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the arithmetic means of the rows
(meanRow) or  columns (meanCol) of x.
</p>


<h3>Value</h3>

<p>The arithmetic means of the rows
(meanRow) or  columns (meanCol) of x.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+mean.rplus">mean.rplus</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
meanCol(sa.tnormals)
meanRow(sa.tnormals)

</code></pre>

<hr>
<h2 id='Metabolites'>Steroid metabolite patterns in adults and children</h2><span id='topic+Data09'></span><span id='topic+Metabolites'></span>

<h3>Description</h3>

<p>Data shows the urinary excretion (mg/24 hours) of 37 normal adults and 30 normal children
of
total cortisol meatbolites,
total corticosterone meatbolites,
total pregnanetriol and <code class="reqn">\Delta</code>-5-pregnentriol.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Metabolites)
</code></pre>


<h3>Details</h3>

<p>There are 67 cases for 37 adults and 30 children, and 5 columns:
Case no., met1, met2, met3 and Type, 1 for adults, $-1$ for children.
No sum constraint is placed on this data set: since the urinary excretion 
in mg for 24 hours are given.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name METABOL.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, (Data 9), pp14.
</p>

<hr>
<h2 id='missing.compositions'>The policy of treatment of missing values in the &quot;compositions&quot; package</h2><span id='topic+missingsInCompositions'></span><span id='topic+compositions.missing'></span><span id='topic+compositions.missings'></span><span id='topic+composition.missing'></span><span id='topic+composition.missings'></span><span id='topic+missings'></span><span id='topic+is.BDL'></span><span id='topic+is.SZ'></span><span id='topic+is.MAR'></span><span id='topic+is.MNAR'></span><span id='topic+is.WMNAR'></span><span id='topic+is.MNV'></span><span id='topic+is.NMV'></span><span id='topic+is.WMNAR'></span><span id='topic+is.WZERO'></span><span id='topic+has.missings'></span><span id='topic+has.missings.default'></span><span id='topic+has.missings.rmult'></span><span id='topic+SZ'></span><span id='topic+MAR'></span><span id='topic+MNAR'></span><span id='topic+BDL'></span><span id='topic+NMV'></span><span id='topic+SZvalue'></span><span id='topic+MARvalue'></span><span id='topic+MNARvalue'></span><span id='topic+BDLvalue'></span>

<h3>Description</h3>

<p>This help section discusses some general strategies of working with
missing valuess in 
a compositional, relative or vectorial context and shows how the various
types of missings are represented and treated in the &quot;compositions&quot; package, 
according to each strategy/class of analysis of compositions or amounts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.BDL(x,mc=attr(x,"missingClassifier"))
is.SZ(x,mc=attr(x,"missingClassifier"))
is.MAR(x,mc=attr(x,"missingClassifier"))
is.MNAR(x,mc=attr(x,"missingClassifier"))
is.NMV(x,mc=attr(x,"missingClassifier"))
is.WMNAR(x,mc=attr(x,"missingClassifier"))
is.WZERO(x,mc=attr(x,"missingClassifier"))
has.missings(x,...)
## Default S3 method:
has.missings(x,mc=attr(x,"missingClassifier"),...)
## S3 method for class 'rmult'
has.missings(x,mc=attr(x,"missingClassifier"),...)
SZvalue
MARvalue
MNARvalue
BDLvalue
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missing.compositions_+3A_x">x</code></td>
<td>
<p>A vector, matrix, acomp, rcomp, aplus, rplus object for which
we would like to know the missing status of the entries</p>
</td></tr>
<tr><td><code id="missing.compositions_+3A_mc">mc</code></td>
<td>
<p>A missing classifier function, giving for each value one of
the values BDL (Below Detection Limit), SZ (Structural Zero), MAR
(Missing at random), MNAR (Missing not at random), NMV (Not missing
value) This functions are introduced to allow a different coding of
the missings.</p>
</td></tr>
<tr><td><code id="missing.compositions_+3A_...">...</code></td>
<td>
<p>further generic arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the context of compositional data we have to consider at least four
types of missing and zero values:
</p>

<dl>
<dt>MAR</dt><dd><p> (Missing at random) coded by NaN, the amount was not observed or
is otherwise missing, in a way unrelated to its actual value. This is the &quot;nice&quot;
type of missing.</p>
</dd>
<dt>MNAR</dt><dd><p>(Missing not at random) coded by NA, the amount was not
observed or is otherwise missing, but it was missed in a way stochastically 
dependent on its actual value.</p>
</dd>
<dt>BDL</dt><dd><p>(Below detection limit) coded by 0.0 or a negative number
giving the detection limit; the amount was
observed but turned out to be below the detection limit and was 
thus rounded to zero. This is an informative version of MNAR.
</p>
</dd>
<dt>SZ</dt><dd><p> (Structural zero) coded by -Inf, the amount is absolutely zero 
due to structural reasons. E.g. a soil sample was dried before the analysis, 
or the sample was preprocessed so that the fraction is removed. 
Structural zeroes are mainly treated as MAR even though they are a kind of MNAR.
</p>
</dd>
</dl>
<p>Based on these basic missing types, the following extended types are defined:
</p>
<dl>
<dt>NMV</dt><dd><p>(Not Missing Value) coded by a real number, it is just an
actually-observed value.</p>
</dd>
<dt>WMNAR</dt><dd><p>(Wider MNAR) includes BDL and MNAR.</p>
</dd>
<dt>WZERO</dt><dd><p>(Wider Zero) includes BDL and SZ</p>
</dd>
</dl>

<p>Each function of type <code>is.XXX</code> checks the status of its argument according to 
the XXX type of value from those above.
<br /><br />
Different steps of a statistical analysis and different understanding
of the data will lead to different approaches with respect to missings and zeros.
<br />
In the first exploratory step, the problem is to keep the
methods working and to make the missing structure visible in the
analysis. The user should need as less as possible extra thinking
about missings, an get nevertheless a true picture of the data. To
achieve this we tried to make the basic layer of computational
functions working consitently with missings and propagating the
missingness character seamlessly. However some of this only works with
<code>acomp</code>, where a closed form missing theories are available
(e.g. proportional imputation [e.g. Mart\'in-Fern\'andez, J.A. et
al.(2003)]or estimation with missings
[Boogaart&amp;Tolosana 2006]). The main graphics should hint towards
missing and try to add missings to the plot by marking the remaining
informaion on the axes. However one again should be clear that this is
only reasonably justified in the relative geometries. Unfortunatly the
missing subsystem is currently not fully compatible with the
robustness subsystem. 
<br />
As a second step, the analyst might want to analyse the
missing structure for itself. This is preliminarly provided by these
functions, since their result can be treated as a boolean data set in
any other R function. Additionally a <code><a href="#topic+missingSummary">missingSummary</a></code>
provides some a convenience function to provide a fast overview over
the different types of missings in the dataset.  
<br /> 
In the later inferential steps, the problem is to get results valid
with respect to a model. One needs to be able to look through the data
on the true processes behind, without being distracted by artifacts
stemming from missing values. For the moment, how analyses react to the
presence of missings depend on the value of the na.action option. If this
is set to na.omit (the default), then cases with missing values on any
variable are completely ignored by the analysis. If this is set to
na.pass, then some of the following applies.
<br />
The policy on how a missing value is to be introduced into the
analysis depends on the purpose of the analysis, the type of analysis
and the model behind. With respect to this issue this package and
probabily the whole science of compositional data analysis is still
very preliminary. 
<br />
The four philosophies work with different approaches to these problems:
</p>

<dl>
<dt><code><a href="#topic+rplus">rplus</a></code></dt><dd><p> For positive real vectors, one can either identify BDL
with a true 0 or impute a value relative to the detection limit, with a
function like <code><a href="#topic+zeroreplace">zeroreplace</a></code>. A structural zero can either
be seen as a true zero or as a MAR value.</p>
</dd>
<dt><code><a href="#topic+rcomp">rcomp</a></code> and <code><a href="#topic+acomp">acomp</a></code></dt><dd><p> For these 
relative geometries, a true zero is an alien. Thus
a BDL is nothing else but a small unkown value. We could either decide
to replace the value by an imputation, or go through the whole analysis 
keeping this lack of information in mind. 
The main problem of imputation is that by
closing to 1, the absolute value of the detection limit is lost, and
the detection limit can correspond to very different portions. Raw
differences
between <em>all, observed or missed,</em> components (the ground of the rcomp geometry)
are completely distorted by the replacement. Contrarily, log-ratios
between observed
components do not change but ratios between missed components
dramatically depend on the replacement, e.g. typically the content of gold is some orders of
magnitude smaller than the contend of silver even around a gold
deposit, but far away from the deposit they both might be far under detection
limit, leading to a ratio of 1, just because nothing was observed. SZ in compositions
might be either seen as defining two sub-populations, one fully defined and one where 
only a subcomposition is defined. But SZ can also
very much be like an MAR, if only a subcomposition is measured. Thus, in general 
we can simply understand that only a subcomposition is available, i.e. a
projection of the true value onto a sub-space: for each observation, this sub-space 
might be different. For MAR values, this approach
is stricly valid, and yields unbiased estimations (because these projections are stochastically independent of the observed phenomenon). For MNAR values, the 
projections depend on the actual value, which strictly speaking yields 
biased estimations.</p>
</dd>
<dt><code><a href="#topic+aplus">aplus</a></code></dt><dd> 
<p>Imputation takes place by simple replacement of the value. However
this can lead to a dramatic change of ratios and should thus be used
only with extra care, by the same reasons explained before.</p>
</dd>
</dl>
<p>More information on how missings are actually processed can be found in the help files of each
individual functions. 

</p>


<h3>Value</h3>

<p>A logical vector or matrix with the same shape as x stating
wether or not the value is of the given type of missing. </p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana Delgado, Matevz Bren</p>


<h3>References</h3>

<p>Boogaart, K.G. v.d., R. Tolosana-Delgado, M. Bren (2006) Concepts for
handling of zeros and missing
values in compositional data, in E. Pirard (ed.) (2006)Proccedings of
the IAMG'2006 Annual Conference on &quot;Quantitative Geology from multiple
sources&quot;, September 2006, Liege, Belgium, S07-01, 4pages,
<a href="http://stat.boogaart.de/Publications/iamg06_s07_01.pdf">http://stat.boogaart.de/Publications/iamg06_s07_01.pdf</a>, ISBN: 978-2-9600644-0-7
</p>
<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
Billheimer, D., P. Guttorp, W.F. and Fagan (2001) Statistical interpretation of species composition,
<em>Journal of the American Statistical Association</em>, <b>96</b> (456), 1205-1214<br />
</p>
<p>Mart\'in-Fern\'andez, J.A., C. Barcel\'o-Vidal, and V. Pawlowsky-Glahn (2003) 
Dealing With Zeros and Missing Values in Compositional 
Data Sets Using Nonparametric Imputation. <em>Mathematical Geology</em>, <b>35</b>(3)
253-278<br />
</p>


<h3>See Also</h3>

<p><a href="#topic+compositions-package">compositions-package</a>, <a href="#topic+missingsInCompositions">missingsInCompositions</a>,
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a>, <a href="#topic+outliersInCompositions">outliersInCompositions</a>,
<code><a href="#topic+zeroreplace">zeroreplace</a></code>, <code><a href="#topic+rmult">rmult</a></code>, <code><a href="#topic+ilr">ilr</a></code>,
<code><a href="#topic+mean.acomp">mean.acomp</a></code>, <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+plot.acomp">plot.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(compositions)      # load library
data(SimulatedAmounts)     # load data sa.lognormals
dat &lt;- acomp(sa.missings)
dat
var(dat)
mean(dat)
plot(dat)
boxplot(dat)
barplot(dat)
</code></pre>

<hr>
<h2 id='missingProjector'>Returns a projector the the observed space in case of missings.</h2><span id='topic+missingProjector'></span><span id='topic+missingProjector.acomp'></span><span id='topic+missingProjector.rcomp'></span><span id='topic+missingProjector.aplus'></span><span id='topic+missingProjector.rplus'></span><span id='topic+missingProjector.rmult'></span>

<h3>Description</h3>

<p>Returns projectors on the observed subspace in the presence of missings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missingProjector(x,...,by="s")
## S3 method for class 'acomp'
missingProjector(x,has=is.NMV(x),...,by="s")
## S3 method for class 'aplus'
missingProjector(x,has=is.NMV(x),...,by="s")
## S3 method for class 'rcomp'
missingProjector(x,has=!(is.MAR(x)|is.MNAR(x)),...,by="s")
## S3 method for class 'rplus'
missingProjector(x,has=!(is.MAR(x)|is.MNAR(x)),...,by="s")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missingProjector_+3A_x">x</code></td>
<td>
<p>a dataset or object of the given class</p>
</td></tr>
<tr><td><code id="missingProjector_+3A_has">has</code></td>
<td>
<p>a boolean matrix of the same size indicating nonmissing
values</p>
</td></tr>
<tr><td><code id="missingProjector_+3A_...">...</code></td>
<td>
<p>additional arguments for generic purpose only</p>
</td></tr>
<tr><td><code id="missingProjector_+3A_by">by</code></td>
<td>
<p>the name of the dataset dimension on <code>has</code> for
tensorial computation with tensorA package</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the references for details on that function.
</p>


<h3>Value</h3>

<p>A dataset of N square matrices of dimension DxD (with N and D respectively 
equal to the number of rows and columns in <code>x</code>). Each of these 
matrices gives the projection of a data row onto its observed sub-space.
<br />
The function <code><a href="#topic+sumMissingProjector">sumMissingProjector</a></code> takes all these matrices
and sums
them, generating a &quot;summary&quot; of observed sub-spaces. This matrix is useful
to obtain estimates of the mean (and variance, in the future) still unbiased 
in the presence of lost values (only of type MAR, stricly-speaking, but anyway
useful for any type of missing value, when used with care).
</p>


<h3>Author(s)</h3>

<p>K.G.van den Boogaart</p>


<h3>References</h3>

<p>Boogaart, K.G. v.d. (2006) Concepts for handling of zeros and missing
values in compositional data, in E. Pirard (ed.) (2006)Proccedings of
the IAMG'2006 Annual Conference on &quot;Quantitative Geology from multiple
sources&quot;, September 2006, Liege, Belgium, S07-01, 4pages,
<a href="http://stat.boogaart.de/Publications/iamg06_s07_01.pdf">http://stat.boogaart.de/Publications/iamg06_s07_01.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+missingsInCompositions">missingsInCompositions</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
x &lt;- acomp(sa.lognormals)
xnew &lt;- simulateMissings(x,dl=0.05,MAR=0.05,MNAR=0.05,SZ=0.05)
xnew
plot(missingSummary(xnew))

missingProjector(acomp(xnew))
missingProjector(rcomp(xnew))
missingProjector(aplus(xnew))
missingProjector(rplus(xnew))

</code></pre>

<hr>
<h2 id='missingsummary'>Classify and summarize missing values in a dataset</h2><span id='topic+missingSummary'></span><span id='topic+missingType'></span>

<h3>Description</h3>

<p>Routines classifies codes of missing valuesas numbers in objects of the
compositions package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   missingSummary(x,..., vlabs = colnames(x), 
                 mc=attr(x,"missingClassifier"), 
                 values=eval(formals(missingType)$values))
   missingType(x,..., mc=attr(x,"missingClassifier"),
                 values=c("NMV", "BDL", "MAR", "MNAR", "SZ", "Err"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missingsummary_+3A_x">x</code></td>
<td>
<p>a dataset which might contain missings</p>
</td></tr>
<tr><td><code id="missingsummary_+3A_...">...</code></td>
<td>
<p>additional arguments for mc</p>
</td></tr>
<tr><td><code id="missingsummary_+3A_mc">mc</code></td>
<td>
<p>optionally in missingSummary, an alternate routine to be used 
instead of <code>missingType</code> </p>
</td></tr>
<tr><td><code id="missingsummary_+3A_vlabs">vlabs</code></td>
<td>
<p>labels for the variables</p>
</td></tr>
<tr><td><code id="missingsummary_+3A_values">values</code></td>
<td>
<p>the names of the different types of missings. <code>"Err"</code> is a
value that can not be classified e.g. <code>Inf</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function mainly counts the various types of missing values.
</p>


<h3>Value</h3>

<p><code>missingType</code> returns a character vector/matrix with the same dimension and
dimnames as <code>x</code> giving the type of every value.<br />
<code>missingSummary</code> returns a table giving the number of missings of each
type for each variable.
</p>


<h3>Author(s)</h3>

<p>K. Gerald van den Boogaart</p>


<h3>References</h3>

<p>Boogaart, K.G., R. Tolosana-Delgado, M. Bren (2006) Concepts for the
handling of zeros and missings in compositional data, <em>Proceedings of
IAMG 2006, Liege</em>
</p>


<h3>See Also</h3>

<p><a href="#topic+compositions.missing">compositions.missing</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
x &lt;- acomp(sa.lognormals)
xnew &lt;- simulateMissings(x,dl=0.05,MAR=0.05,MNAR=0.05,SZ=0.05)
xnew
missingSummary(xnew)
</code></pre>

<hr>
<h2 id='mix.Read'>Reads a data file in a mixR format</h2><span id='topic+mix.Read'></span>

<h3>Description</h3>

<p>Reads a data file, which is formatted in a simple
compositional file including the first row with title, the second
with data labels and afterwards the matrix with the data itself.
In the first column of the matrix are cases labels. This is the format
used in the mixR package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mix.Read(file,eps=1e-6)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mix.Read_+3A_file">file</code></td>
<td>
<p>a file name</p>
</td></tr>
<tr><td><code id="mix.Read_+3A_eps">eps</code></td>
<td>
<p>the epsilon to be used for checking null values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data files must have the adequate structure:
</p>

<dl>
<dt>1</dt><dd><p>the first row with a title of the data set,</p>
</dd>
<dt>2</dt><dd><p>the second row with variables names</p>
</dd>
<dt>3</dt><dd><p>the data set in a matrix, rows as cases, variables in columns
with the firs colum comprising cases labels.</p>
</dd>
</dl>

<p>A mixture object 'm' consists of  <code>m$tit</code>  the title, <code>m$mat</code> the matrix with the data, 
<code>m$sum</code> the value of the rows total, if constant and  <code>m$sta</code> the status of the mixture object
with values:
</p>

<table>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">   -2   </td><td style="text-align: left;">     - matrix contains negative elements,</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">   -1   </td><td style="text-align: left;">     - zero row sum exists,</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    0   </td><td style="text-align: left;">     - matrix contains zero elements,</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    1   </td><td style="text-align: left;">     - matrix contains positive elements, rows with different row sum(s), </td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    2   </td><td style="text-align: left;">     - matrix with constant row sum   and</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;">    3   </td><td style="text-align: left;">     - closed mixture, the row sums are all equal to 1.
  </td>
</tr>

</table>



<h3>Value</h3>

<p>A mixture object as a data frame with a title, row total, if constant, status
(-2, -1, 0, 1, 2 or 3 &ndash; see above) and class attributes and the data matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.geoeas">read.geoeas</a></code>
<code><a href="#topic+read.geoEAS">read.geoEAS</a></code>
<code><a href="utils.html#topic+read.table">read.table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  mix.Read("GLACIAL.DAT")
  mix.Read("ACTIVITY.DAT")

## End(Not run)
</code></pre>

<hr>
<h2 id='mvar'>Metric summary statistics of real, amount or compositional data</h2><span id='topic+mvar'></span><span id='topic+mvar.default'></span><span id='topic+mcov'></span><span id='topic+mcov.default'></span><span id='topic+mcor'></span><span id='topic+mcor.default'></span><span id='topic+msd'></span><span id='topic+msd.default'></span>

<h3>Description</h3>

<p>Compute the metric variance, covariance, correlation or standard deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvar(x,...)
mcov(x,...)
mcor(x,...)
msd(x,...)
## Default S3 method:
mvar(x,y=NULL,...)
## Default S3 method:
mcov(x,y=x,...)
## Default S3 method:
mcor(x,y,...)
## Default S3 method:
msd(x,y=NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvar_+3A_x">x</code></td>
<td>
<p>a dataset, eventually of amounts or compositions</p>
</td></tr>
<tr><td><code id="mvar_+3A_y">y</code></td>
<td>
<p>a second dataset, eventually of amounts or compositions</p>
</td></tr>
<tr><td><code id="mvar_+3A_...">...</code></td>
<td>
<p>further arguments to 
<code>stats::var</code> or <code>stats::cov</code>.
Typically a <code>robust=TRUE</code> argument. 
e.g. <code>use</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The metric variance (<code>mvar</code>) is defined by the trace of the
variance in the natural geometry of the data, or also by the generalized
variance in natural geometry. The natural geometry is equivalently
given by the <code><a href="#topic+cdt">cdt</a></code> or <code><a href="#topic+idt">idt</a></code> transforms.<br />
</p>
<p>The metric standard deviation (<code>msd</code>) is not the square root
of the metric variance, but the square root of the mean of the eigenvalues of the 
variance matrix. In this way it can be interpreted in units of the original
natural geometry, as the radius of a sperical ball around
the mean with the same volume as the 1-sigma ellipsoid of the data set.
<br />
</p>
<p>The metric covariance (<code>mvar</code>) is the sum over the absolute
singular values of the covariance of two datasets in their respective 
geometries. It is always positive. The metric covariance of a dataset 
with itself is its metric variance. The interpretation of a metric 
covariance is quite difficult, but useful in regression problems.<br />
</p>
<p>The metric correlation (<code>mcor</code>) is the metric covariance of the
datasets in their natural geometry normalized to unit variance matrix. It is a
number between 0 and the smaller dimension of both natural spaces. A
number of 1 means perfect correlation in 1 dimension, but only partial
correlations in higher dimensions.
<br />
</p>


<h3>Value</h3>

<p>a scalar number, informing of the degree of variation/covariation of one/two datasets.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Daunis-i-Estadella, J., J.J. Egozcue, and V. Pawlowsky-Glahn
(2002) Least squares regression in the Simplex on the simplex, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>
<p>Pawlowsky-Glahn, V. and J.J. Egozcue (2001) Geometric approach to
statistical analysis on the simplex. <em>SERRA</em> <b>15</b>(5), 384-398<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+var">var</a></code>, <code><a href="#topic+cov">cov</a></code>,
<code><a href="#topic+mean.acomp">mean.acomp</a></code>, <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>,
<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
mvar(acomp(sa.lognormals))
mvar(rcomp(sa.lognormals))
mvar(aplus(sa.lognormals))
mvar(rplus(sa.lognormals))

msd(acomp(sa.lognormals))
msd(rcomp(sa.lognormals))
msd(aplus(sa.lognormals))
msd(rplus(sa.lognormals))

mcov(acomp(sa.lognormals5[,1:3]),acomp(sa.lognormals5[,4:5]))
mcor(acomp(sa.lognormals5[,1:3]),acomp(sa.lognormals5[,4:5]))
mcov(rcomp(sa.lognormals5[,1:3]),rcomp(sa.lognormals5[,4:5]))
mcor(rcomp(sa.lognormals5[,1:3]),rcomp(sa.lognormals5[,4:5]))

mcov(aplus(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))
mcor(aplus(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))
mcov(rplus(sa.lognormals5[,1:3]),rplus(sa.lognormals5[,4:5]))
mcor(rplus(sa.lognormals5[,1:3]),rplus(sa.lognormals5[,4:5]))

mcov(acomp(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))
mcor(acomp(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))
</code></pre>

<hr>
<h2 id='names'>The names of the parts </h2><span id='topic+names.acomp'></span><span id='topic+names.aplus'></span><span id='topic+names.rcomp'></span><span id='topic+names.rplus'></span><span id='topic+names.rmult'></span><span id='topic+names.ccomp'></span><span id='topic+names+3C-.acomp'></span><span id='topic+names+3C-.ccomp'></span><span id='topic+names+3C-.aplus'></span><span id='topic+names+3C-.rcomp'></span><span id='topic+names+3C-.rplus'></span><span id='topic+names+3C-.rmult'></span>

<h3>Description</h3>

<p>The <code>names</code> function provide a transparent way to access the names of
the parts regardless of the shape of the dataset or data item.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
names(x)
## S3 method for class 'rcomp'
names(x)
## S3 method for class 'aplus'
names(x)
## S3 method for class 'rplus'
names(x)
## S3 method for class 'rmult'
names(x)
## S3 method for class 'ccomp'
names(x)
## S3 replacement method for class 'acomp'
names(x) &lt;- value
## S3 replacement method for class 'rcomp'
names(x) &lt;- value
## S3 replacement method for class 'aplus'
names(x) &lt;- value
## S3 replacement method for class 'rplus'
names(x) &lt;- value
## S3 replacement method for class 'rmult'
names(x) &lt;- value
## S3 replacement method for class 'ccomp'
names(x) &lt;- value

          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="names_+3A_x">x</code></td>
<td>
<p>an amount/amount dataset</p>
</td></tr>
<tr><td><code id="names_+3A_value">value</code></td>
<td>
<p>the new names of the parts</p>
</td></tr>

</table>


<h3>Value</h3>

<p>a character vector giving the names of the parts
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
tmp &lt;- acomp(sa.lognormals)
names(tmp)
names(tmp) &lt;- c("x","y","z")
tmp
</code></pre>

<hr>
<h2 id='norm'>Vector space norm</h2><span id='topic+norm'></span><span id='topic+norm.default'></span><span id='topic+norm.acomp'></span><span id='topic+norm.aplus'></span><span id='topic+norm.rcomp'></span><span id='topic+norm.rplus'></span><span id='topic+norm.rmult'></span><span id='topic+norm.matrix'></span>

<h3>Description</h3>

<p>Each of the considered space structures has an associated norm, which is
computed for each element by these functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
norm(x,...)
## S3 method for class 'acomp'
norm(x,...)
## S3 method for class 'rcomp'
norm(x,...)
## S3 method for class 'aplus'
norm(x,...)
## S3 method for class 'rplus'
norm(x,...)
## S3 method for class 'rmult'
norm(x,...)
## S3 method for class 'rmult'
norm(x,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm_+3A_x">x</code></td>
<td>
<p>a dataset or a single vector of some type</p>
</td></tr>
<tr><td><code id="norm_+3A_...">...</code></td>
<td>
<p>currently not used, intended to select a 
different norm rule in the future</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The norms of the given vectors.
ATTENTON: <code>norm.matrix</code> is a wrapper around base::norm
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+normalize">normalize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
tmp &lt;- acomp(sa.lognormals)
mvar(tmp)
sum(norm( tmp - mean(tmp) )^2)/(nrow(tmp)-1)

</code></pre>

<hr>
<h2 id='normalize'>Normalize vectors to norm 1</h2><span id='topic+normalize'></span><span id='topic+normalize.default'></span>

<h3>Description</h3>

<p>Normalize vectors to norm 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x,...)
## Default S3 method:
normalize(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>a dataset or a single vector of some type</p>
</td></tr>
<tr><td><code id="normalize_+3A_...">...</code></td>
<td>
<p>currently not used, intended to select 
a different norm in the future</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vectors given, but normalized to norm 1.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+norm.rmult">norm.rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
normalize(c(1,2,3))
normalize(acomp(c(1,2,3)))
norm(normalize(acomp(sa.groups)))
</code></pre>

<hr>
<h2 id='NormalTests'>Compositional Goodness of fit test</h2><span id='topic+acompNormalLocation.test'></span>

<h3>Description</h3>

<p>Tests for several groups of additive lognormally distributed compositions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  acompNormalLocation.test(x, g=NULL, var.equal=FALSE, paired=FALSE, 
                                R=ifelse(var.equal,999,0))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NormalTests_+3A_x">x</code></td>
<td>
<p>a dataset of compositions (acomp) or a list of such</p>
</td></tr>
<tr><td><code id="NormalTests_+3A_g">g</code></td>
<td>
<p>a factor grouping the data, not used if x is a list already. 
Alternatively, <code>g</code> can be a second compositional data set. </p>
</td></tr>
<tr><td><code id="NormalTests_+3A_var.equal">var.equal</code></td>
<td>
<p>a boolean telling wether the variance of the groups
should be considered equal</p>
</td></tr>
<tr><td><code id="NormalTests_+3A_paired">paired</code></td>
<td>
<p>true if a paired test should be performed</p>
</td></tr>
<tr><td><code id="NormalTests_+3A_r">R</code></td>
<td>
<p>number of replicates that should be used to compute
p-values. 0 means comparing the likelihood statistic with the
correponding asymptotic chisq-distribution. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tests are based on likelihood ratio statistics. 
</p>


<h3>Value</h3>

<p>A classical <code>"htest"</code> object
</p>
<table>
<tr><td><code>data.name</code></td>
<td>
<p>The name of the dataset as specified</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a name for the test used</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>an empty string</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>a dataset of p-value distributions under the
Null-Hypothesis got from
nonparametric bootstrap</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p.value computed for this test</p>
</td></tr>
</table>


<h3>Missing Policy</h3>

<p>Up to now the tests cannot handle missings. 
</p>


<h3>Note</h3>

<p>Do not trust the p-values obtained forcing <code>var.equal=TRUE</code> and <code>R=0</code>.
This will include soon equivalent spread tests.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitDirichlet">fitDirichlet</a></code>,<code><a href="#topic+rDirichlet">rDirichlet</a></code>, <code><a href="#topic+runif.acomp">runif.acomp</a></code>,
<code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>, 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif.acomp(100,4)
y &lt;- runif.acomp(100,4)
acompNormalLocation.test(list(x,y))
</code></pre>

<hr>
<h2 id='oneOrDataset'>Treating single compositions as one-row datasets</h2><span id='topic+oneOrDataset'></span>

<h3>Description</h3>

<p>A dataset is converted to a data matrix. A single data item (i.e. a
simple vector) is converted to a one-row data matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          oneOrDataset(W,B=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oneOrDataset_+3A_w">W</code></td>
<td>
<p>a vector, matrix or dataframe</p>
</td></tr>
<tr><td><code id="oneOrDataset_+3A_b">B</code></td>
<td>
<p>an optional second vector, matrix or data frame having the
intended number of rows.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data matrix containing the same data as W. If W is a vector it is
interpreded as a single row. If <code>B</code> is given and
<code>length(dim(B))!= 2</code> and <code>W</code> is a vector,
then <code>W</code> is repeated <code>nrow(B)</code> times.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>oneOrDataset(c(1,2,3))
oneOrDataset(c(1,2,3),matrix(1:12,nrow=4))
oneOrDataset(data.frame(matrix(1:12,nrow=4)))
</code></pre>

<hr>
<h2 id='outlierclassifier'>Detect and classify compositional outliers.</h2><span id='topic+OutlierClassifier1'></span><span id='topic+OutlierClassifier1.acomp'></span>

<h3>Description</h3>

<p>Detects outliers and classifies them according to different possible
explanations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OutlierClassifier1(X,...)
## S3 method for class 'acomp'
OutlierClassifier1(X,...,alpha=0.05,
           type=c("best","all","type","outlier","grade"),goodOnly=NULL,
           corrected=TRUE,RedCorrected=FALSE,robust=TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outlierclassifier_+3A_x">X</code></td>
<td>
<p>the dataset as an <code>acomp</code> object</p>
</td></tr>
<tr><td><code id="outlierclassifier_+3A_...">...</code></td>
<td>
<p>further arguments to MahalanobisDist/gsi.mahOutlier</p>
</td></tr>
<tr><td><code id="outlierclassifier_+3A_alpha">alpha</code></td>
<td>
<p>The confidence level for identifying outliers.</p>
</td></tr>
<tr><td><code id="outlierclassifier_+3A_type">type</code></td>
<td>
<p> What type of classification should be used: best: Which
single component would best explain the outlier. all: Give a binary coding
specifying all components, which could explain the outlier. type: Is
it a a normal observation <code>"ok"</code>, a single componentn outlier <code>"1"</code> or can it not
be explained by a single wrong component &quot;?&quot;. outlier: All outliers 
are marked as <code>"outlier"</code>, others are marked as
<code>"ok"</code>. <code>"grade"</code>: Proven Outliers are marked as &quot;outlier&quot;s,
suspected outliers, detected without correction of the p-value are
reported as &quot;extreme&quot;, the rest is reported as &quot;ok&quot;.</p>
</td></tr>
<tr><td><code id="outlierclassifier_+3A_goodonly">goodOnly</code></td>
<td>
<p>an integer vector. Only the specified index of the
dataset should be used
for estimation of the outlier criteria. This parameter if only a small
portion of the dataset is reliable.</p>
</td></tr>
<tr><td><code id="outlierclassifier_+3A_corrected">corrected</code></td>
<td>
<p>logical. Literatur often proposed to compare the
Mahalanobis distances with Chisq-Approximations of there
distributions. However this does not correct for multiple
testing. If corrected is true a correction for multiple testing is
used. In any case we do not use the chisq-approximation, but a
simulation based procedure to compute confidence bounds. </p>
</td></tr>
<tr><td><code id="outlierclassifier_+3A_redcorrected">RedCorrected</code></td>
<td>
<p>logical. If an outlier is detected we can try to
find out wether a single component would be sufficient to drop the
outlier under the outlier detection limit. Since in this second case
we only check a few outliers no second correction step applies as long
as the number of outliers is not very high.</p>
</td></tr>
<tr><td><code id="outlierclassifier_+3A_robust">robust</code></td>
<td>
<p>A robustness description as define in
<code><a href="#topic+var.acomp">var.acomp</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="#topic+outliersInCompositions">outliersInCompositions</a> for a comprehensive introduction into the outlier
treatment in compositions.
</p>
<p>See <code><a href="#topic+ClusterFinder1">ClusterFinder1</a></code> for an alternative method to classify
observations in the context of outliers.  
</p>


<h3>Value</h3>

<p>A factor classifying the observations in the dataset as &quot;ok&quot; or some
type of outlier. 
</p>


<h3>Note</h3>

<p>The package <span class="pkg">robustbase</span> is required for using the
robust estimations.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+outlierplot">outlierplot</a></code>, <code><a href="#topic+ClusterFinder1">ClusterFinder1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tmp&lt;-set.seed(1400)
A &lt;- matrix(c(0.1,0.2,0.3,0.1),nrow=2)
Mvar &lt;- 0.1*ilrvar2clr(A%*%t(A))
Mcenter &lt;- acomp(c(1,2,1))
data(SimulatedAmounts)
datas &lt;- list(data1=sa.outliers1,data2=sa.outliers2,data3=sa.outliers3,
              data4=sa.outliers4,data5=sa.outliers5,data6=sa.outliers6)
opar&lt;-par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
outlierplot(x,type="scatter",class.type="grade");
  title(y)
},datas,names(datas))


par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
  myCls2 &lt;- OutlierClassifier1(x,alpha=0.05,type="all",corrected=TRUE)
  outlierplot(x,type="scatter",classifier=OutlierClassifier1,class.type="best",
  Legend=legend(1,1,levels(myCls),xjust=1,col=colcode,pch=pchcode),
  pch=as.numeric(myCls2));
  legend(0,1,legend=levels(myCls2),pch=1:length(levels(myCls2)))
  title(y)
},datas,names(datas))

par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="ecdf",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="portion",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="nout",main=names(datas)[i])
par(opar)

## End(Not run)
</code></pre>

<hr>
<h2 id='outlierplot'>Plot various graphics to analyse outliers.</h2><span id='topic+outlierplot'></span><span id='topic+outlierplot.acomp'></span>

<h3>Description</h3>

<p>A collection of plots emphasing different aspects of possible outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outlierplot(X,...)
## S3 method for class 'acomp'
outlierplot(X,colcode=colorsForOutliers1,
  pchcode=pchForOutliers1,
  type=c("scatter","biplot","dendrogram","ecdf","portion","nout","distdist"),
  legend.position,pch=19,...,clusterMethod="ward",
  myCls=classifier(X,alpha=alpha,type=class.type,corrected=corrected),
  classifier=OutlierClassifier1,
  alpha=0.05,
  class.type="best",
  Legend,pow=1,
  main=paste(deparse(substitute(X))),
  corrected=TRUE,robust=TRUE,princomp.robust=FALSE,
                              mahRange=exp(c(-5,5))^pow,
                              flagColor="red",
                              meanColor="blue",
                              grayColor="gray40",
                              goodColor="green",
                              mahalanobisLabel="Mahalanobis Distance"
                              )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outlierplot_+3A_x">X</code></td>
<td>
<p>The dataset as an <code>acomp</code> object</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_colcode">colcode</code></td>
<td>
<p>A color palette for factor given by the <code>myCls</code>,
or function to create it from the factor. Use <code>colorForOutliers2</code> if
<code>class.method="all"</code> is used. </p>
</td></tr>
<tr><td><code id="outlierplot_+3A_pchcode">pchcode</code></td>
<td>
<p>A function to create a plot character palette for the factor
returned by the <code>myCls</code> call</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_type">type</code></td>
<td>
<p> The type of plot to be produced. See details for more
precise definitions.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_legend.position">legend.position</code></td>
<td>
<p>The location of the legend. Must!!! be given to
draw a classical legend.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_pch">pch</code></td>
<td>
<p>A default plotting char</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_...">...</code></td>
<td>
<p>Further arguments to the used plotting function</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_clustermethod">clusterMethod</code></td>
<td>
<p>The clustering method for <code><a href="stats.html#topic+hclust">hclust</a></code>
based outlier grouping.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_mycls">myCls</code></td>
<td>
<p>A factor presenting the groups of outliers</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_classifier">classifier</code></td>
<td>
<p>The routine to create a factor presenting the groups
of outliers heuristically. It is only used in the default argument
to <code>myCls</code>.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_alpha">alpha</code></td>
<td>
<p>The confidence level to be used for outlier
classification tests</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_class.type">class.type</code></td>
<td>
<p>The type of classification that should be generated
by <code>classifier</code></p>
</td></tr>
<tr><td><code id="outlierplot_+3A_legend">Legend</code></td>
<td>
<p>The content will be substituted and stored as list entry
legend in the result of the function. It can than be evaluated to
actually create a seperate legend on another device (e.g. for
publications).</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_pow">pow</code></td>
<td>
<p>The power of Mahalanobis distances to be used.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_main">main</code></td>
<td>
<p>The title of the graphic</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_corrected">corrected</code></td>
<td>
<p>Literature typically proposes to compare the
Mahalanobis distances with the distribution of a random Mahalanobis
distance. However it would be needed to correct this for (dependent)
multiple testing, since we always test the whole dataset, which means
comparing against the distribution of the maximum Mahalanobis
distance. This argument switches to this second behavior, giving less
outliers.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_robust">robust</code></td>
<td>
<p>A robustness description as define in
<code><a href="#topic+robustnessInCompositions">robustnessInCompositions</a></code></p>
</td></tr>
<tr><td><code id="outlierplot_+3A_princomp.robust">princomp.robust</code></td>
<td>
<p>Either a logical determining wether or not the
principal component analysis should be done robustly or a principal
component object for the dataset.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_mahrange">mahRange</code></td>
<td>
<p>The range of Mahalanobis distances displayed. This is
fixed to make views comparable among datasets. However if the preset
default is not enough a warning is issued and a red mark is drawn in
the plot</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_flagcolor">flagColor</code></td>
<td>
<p>The color to draw critical situations.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_meancolor">meanColor</code></td>
<td>
<p>The color to draw typical curves.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_goodcolor">goodColor</code></td>
<td>
<p>The color to draw confidence bounds.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_graycolor">grayColor</code></td>
<td>
<p>The color to draw less important things.</p>
</td></tr>
<tr><td><code id="outlierplot_+3A_mahalanobislabel">mahalanobisLabel</code></td>
<td>
<p>The axis label to be used for axes displaying
Mahalanobis distances.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <a href="#topic+outliersInCompositions">outliersInCompositions</a> for a comprehensive introduction
into the outlier
treatment in compositions.
</p>

<dl>
<dt><code>type="scatter"</code></dt><dd>
<p>Produces an appropriate standard plot such as a tenary diagram with
the outliers marked by there codes according to the given classifier
and colorcoding and pch coding.
<br />
This shows the actual values of the identified outliers.
</p>
</dd>
<dt><code>type="biplot"</code></dt><dd>
<p>Creates a biplot based on a nonrobust principal component analysis
showing the outliers classified through outliers in the given color
scheme. We use the nonrobust principal component analyis since it
rotates according to a good visibility of the extreme values.
<br />
This shows the position of the outliers in the usual principal
components analysis. However note that a <code><a href="#topic+coloredBiplot">coloredBiplot</a></code>
is used rather than the usual one. 
</p>
</dd>



<dt><code>type="dendrogram"</code></dt><dd>
<p>Shows a dendrogram based on robust Mahalanobis distance
based hierachical clustering, where the observations are labeled
with the identified outlier classes. 
<br />
This plot can be used to see how good different categories of
outliers cluster.
</p>
</dd>
<dt><code>type="ecdf"</code></dt><dd>
<p>This plot provides a cummulated distribution function of the
Mahalanobis distances along with an expeced curve and a lower
confidence limit. The empirical cdf is plotted in the default
color. The expected cdf is displayed in <code>meanColor</code>. The
<code>alpha</code>-quantile &ndash; i.e. a lower prediction bound &ndash; for the
cdf is given in goodColor. A line in <code>grayColor</code> show the
minium portion of observations above some limit to be
outliers, based on the portion of observations necessary to move
down to make the empirical distribution function get above its lower
prediction limit under the assumption of normality.
<br />
This plot shows the basic construction for the minimal number of
outlier computation done in <code>type="portion"</code>. 
</p>
</dd>
<dt><code>type="portion"</code></dt><dd>
<p>This plot focusses on numbers of outliers. The horizontal axis
give Mahalanobis distances and the vertical axis number of
observations. In <code>meanColor</code> we see a curve of an estimated
number of outliers above some limit, generated by estimating the
portion of outliers with a Mahalanobis distance over the given
limit by max(0,1-ecdf/cdf). The minimum
number of outliers is computed by replacing cdf by its lower
confidence limit and displayed in <code>goodColor</code>. The
Mahalanobis distances of the individual data points are added as a
stacked <code><a href="graphics.html#topic+stripchart">stripchart</a></code>, such that the influence of
individual observations can be seen.
<br />
The true problem of outlier detection is to detect &quot;near&quot;
outliers. Near outliers are outliers so near to the dataset that
they could well be extrem observation. These near outliers would
provide no problem unless they are not many showing up in
groups. Graphic allows at least to count them and to show there
probable Mahalanobis distance such, however it still does not
allow to conclude that an individual observation is an
outlier. However still the outlier candidates can be identified
comparing their mahalanobis distance (returned by the plot
as<code>$mahalanobis</code>) with a cutoff inferred from this graphic. 
</p>
</dd>
<dt><code>type="nout"</code></dt><dd>
<p>This is a simplification of the previous plot simply providing the
number of outliers over a given limit.
<br />

</p>
</dd>
<dt><code>type="distdist"</code></dt><dd>
<p>Plots a scatterplot of the the classical and robust Mahalanobis
distance with the given classification for colors and plot
symbols. Furthermore it plots a horizontal line giving the 0.95-Quantil
of the distribution of the maximum robust Mahalanobis distance of
normally distributed dataset.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>a list respresenting the criteria computed to create the plots. The
content of the list depends on the plotting type selected.
</p>


<h3>Note</h3>

<p>The package <span class="pkg">robustbase</span> is required for using the
robust estimations.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code>, <code><a href="#topic+ClusterFinder1">ClusterFinder1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(SimulatedAmounts)
outlierplot(acomp(sa.outliers5))

datas &lt;- list(data1=sa.outliers1,data2=sa.outliers2,data3=sa.outliers3,
                data4=sa.outliers4,data5=sa.outliers5,data6=sa.outliers6)

opar&lt;-par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
outlierplot(x,type="scatter",class.type="grade");
  title(y)
},datas,names(datas))


par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
  myCls2 &lt;- OutlierClassifier1(x,alpha=0.05,type="all",corrected=TRUE)
  outlierplot(x,type="scatter",classifier=OutlierClassifier1,class.type="best",
  Legend=legend(1,1,levels(myCls),xjust=1,col=colcode,pch=pchcode),
  pch=as.numeric(myCls2));
  legend(0,1,legend=levels(myCls2),pch=1:length(levels(myCls2)))
  title(y)
},datas,names(datas))
# To slow
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="ecdf",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="portion",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="nout",main=names(datas)[i])
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="distdist",main=names(datas)[i])
par(opar)


## End(Not run)
</code></pre>

<hr>
<h2 id='outliersInCompositions'>Analysing outliers in compositions.</h2><span id='topic+outliersInCompositions'></span>

<h3>Description</h3>

<p>The Philosophy behind outlier treatment in library(compositions).
</p>


<h3>Details</h3>

<p>Outliers are omnipresent in all kinds of data analysis. To avoid
catastrophic misinterpreations robust statistics has developed some
methods to avoid the distracting influence of the outliers. The
introduction of robust methods into the compositions package is
described in <a href="#topic+robustnessInCompositions">robustnessInCompositions</a>.
</p>
<p>However sometimes we are
interested directly in the analysis of outliers. The central
philosophy of the the outlier classification subsystem in
compositions is
that outlier are in most cases not simply erroneous observations, but
rather products of some systematic anomality. This can e.g. be an
error in an individual component, a secondary process or a minor
undetected but different subpopulation. The package provides various
concepts to investigate possible reasons for outliers in compositional
datasets. 
</p>

<dl>
<dt>Proven Outliers</dt><dd>
<p>The package relies on an additive&ndash;lognormal reference distribution
in the simplex (and the correponding normal distribution in each
other scale). The central tool for the detection of outliers is the
Mahalanobis distance of the observation from a robustly estimated
center based on a robustly estimated covariance. The robust
estimation can be influenced by the given robust attributes. An
outlier is considered as proven if its Mahalanobis distance is
larger that the (1-alpha) quantile of the distribution of the
maximum Mahalanobis distance of a dataset of the same size with a
corresponding
(additive)(log)normal distribution. This relies heavily on the
presumption that the robust estimation is invariant under linear
transformation, but make no assumptions about the actually used
robust estimation method. The corresponding distributions are thus
only defined with respect to a specific implementation of the robust
estimation algorithm. See 
<code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a>(...,type="outlier")</code>,
<code><a href="#topic+outlierplot">outlierplot</a>(...,type=c("scatter","biplot"),class.type="outlier")</code>, 
<code><a href="#topic+qMaxMahalanobis">qMaxMahalanobis</a>(...)</code>.
</p>
</dd>
<dt>Extrem Values / Possible outliers</dt><dd>
<p>Some cases of the dataset might have unusually high Mahalanobis
distances, e.g. such that we would expect the probility of a random
case to have such a value or higher might be below alpha. In
Literature these cases are often rendered as outliers, because this
level is approximated by the correponding chisq-based criterion
proposed. However we consider these only as extrem values, but
however provide tools to detect and plot them. See 
<code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a>(...,type="grade")</code>,
<code><a href="#topic+outlierplot">outlierplot</a>(...,type=c("scatter","biplot"),class.type="grade")</code>, 
<code><a href="#topic+qEmpiricalMahalanobis">qEmpiricalMahalanobis</a>(...)</code> 
</p>
</dd>
<dt>Single Component Outliers</dt><dd>
<p>Some Outliers can be explained by a single component, e.g. because
this single measurement error was wrong. These sort of outliers is
detected when we reduce the dataset to a subcomposition with one
component less and realise that our former outlier is now a fairly
normal member of the dataset, maybe not even extrem. Thus a outlier
is considered as as single component outlier, when it does not
appear extrem in any of the subcompositions with one component
less. For other outliers we can prove that they are still extrem for
all subcomposition with one component removed. Thus these have to be
as multicomponent outliers, that can not be explained by a single
measurment error. For remaining single component outliers, we can
ask which component is able to explain the outlying character. See 
<code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a>(...,type=c("best","type","all"))</code>.  
</p>
</dd>
<dt>Counting hidden outliers</dt><dd>
<p>If outliers are not outlying far enough to be detected by the test
for outlyingness are only at first sight harmless. One outlier is
within the reasonable bounds of what a normal distribution could
have delivered should not harm the analysis and might not even
detectable in any way. However if there is more than one they could
akt together to disrupt our analysis and more interestingly there
might be some joint reason, which than might make them an
interesting object of investigation in themselfs. Thus the package
provides methods (e.g. <code><a href="#topic+outlierplot">outlierplot</a>(...,type="portions")</code>),
to prove the existence of such outliers, to give a lower bound
for there number and to provide us with suspects, with an associated
outlyingness
probability. See <code><a href="#topic+outlierplot">outlierplot</a>(...,type="portions")</code>,
<code><a href="#topic+outlierplot">outlierplot</a>(...,type="nout")</code>, <code><a href="#topic+pQuantileMahalanobis">pQuantileMahalanobis</a>(...)</code> 
</p>
</dd>
<dt>Finding atypical subpopulations</dt><dd>
<p>When we assume smaller subpopulation we need a tool finding these
clusters. However usual cluster analysis tends to ignore the
subgroups, split the main mass and then associate the subgroups
prematurely to the next part of the main mass. For this task we have
developed special tools to find
clusters of atypical populations clearly inducing secondary modes,
without ripping apart the central
nonoutlying mass. See <code><a href="#topic+ClusterFinder1">ClusterFinder1</a></code>.
</p>
</dd>
<dt>Identifying multiple distracting processes</dt><dd>
<p>Outliers that are not due to a seperate subpopulation or due to a
single component error, might still belong together for beeing
influenced by the same secondary process distorting the composition
to a different degrees. Out proposal is to cluster the direction of
the outliers from the center, e.g. by a command like:
<code>take&lt;-OutlierClassifier1(data,type="grade")!="ok"</code>
<code>hc&lt;-hclust(dist(normalize(acomp(scale(data)[take,]))),method="compact")</code> and to plot by a command like:
<code>plot(hc)</code> and <code>plot(acomp(data[take,]),col=cutree(hc,1.5))</code>
</p>
</dd>
</dl>
  
<p>With these tools we hope to provide a systematic approach to identify
various types of outliers in a exploratory analysis. 
</p>


<h3>Note</h3>

<p>The package <span class="pkg">robustbase</span> is required for using the
robust estimations and the outlier subsystem of compositions. To
simplify installation it is not listed as required, but it will be
loaded, whenever any sort of outlierdetection or robust estimation is
used.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>K. Gerald van den Boogaart, Raimon Tolosana-Delgado, Matevz-Bren (2009)
Robustness, classification and visualization of outliers in
compositional data, in prep.
</p>


<h3>See Also</h3>

<p><a href="#topic+compositions-package">compositions-package</a>, <a href="#topic+missingsInCompositions">missingsInCompositions</a>,
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a>, <a href="#topic+outliersInCompositions">outliersInCompositions</a>,
<code><a href="#topic+outlierplot">outlierplot</a></code>,
<code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code>, <code><a href="#topic+ClusterFinder1">ClusterFinder1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# To slow
tmp&lt;-set.seed(1400)
A &lt;- matrix(c(0.1,0.2,0.3,0.1),nrow=2)
Mvar &lt;- 0.1*ilrvar2clr(A%*%t(A))
Mcenter &lt;- acomp(c(1,2,1))
typicalData &lt;- rnorm.acomp(100,Mcenter,Mvar) # main population
colnames(typicalData)&lt;-c("A","B","C")
data1 &lt;- acomp(rnorm.acomp(100,Mcenter,Mvar))
data2 &lt;- acomp(rbind(typicalData+rbinom(100,1,p=0.1)*rnorm(100)*acomp(c(4,1,1))))
data3 &lt;- acomp(rbind(typicalData,acomp(c(0.5,1.5,2))))
colnames(data3)&lt;-colnames(typicalData)
tmp&lt;-set.seed(30)
rcauchy.acomp &lt;- function (n, mean, var){
    D &lt;- gsi.getD(mean)-1
    perturbe(ilrInv(matrix(rnorm(n*D)/rep(rnorm(n),D), ncol = D) %*% chol(clrvar2ilr(var))), mean)
}
data4 &lt;- acomp(rcauchy.acomp(100,acomp(c(1,2,1)),Mvar/4))
colnames(data4)&lt;-colnames(typicalData)
data5 &lt;- acomp(rbind(unclass(typicalData)+outer(rbinom(100,1,p=0.1)*runif(100),c(0.1,1,2))))
data6 &lt;- acomp(rbind(typicalData,rnorm.acomp(20,acomp(c(4,4,1)),Mvar)))
datas &lt;- list(data1=data1,data2=data2,data3=data3,data4=data4,data5=data5,data6=data6)
tmp &lt;-c()
opar&lt;-par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
outlierplot(x,type="scatter",class.type="grade");
  title(y)
},datas,names(datas))


par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
tmp&lt;-mapply(function(x,y) {
  myCls2 &lt;- OutlierClassifier1(x,alpha=0.05,type="all",corrected=TRUE)
  outlierplot(x,type="scatter",classifier=OutlierClassifier1,class.type="best",
  Legend=legend(1,1,levels(myCls),xjust=1,col=colcode,pch=pchcode),
  pch=as.numeric(myCls2));
  legend(0,1,legend=levels(myCls2),pch=1:length(levels(myCls2)))
  title(y)
},datas,names(datas))

par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="ecdf",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="portion",main=names(datas)[i])
par(mfrow=c(2,3),pch=19,mar=c(3,2,2,1))  
for( i in 1:length(datas) ) 
  outlierplot(datas[[i]],type="nout",main=names(datas)[i])
par(opar)

moreData &lt;- acomp(rbind(data3,data5,data6))
take&lt;-OutlierClassifier1(moreData,type="grade")!="ok"
hc&lt;-hclust(dist(normalize(acomp(scale(moreData)[take,]))),method="complete")
plot(hc)
plot(acomp(moreData[take,]),col=cutree(hc,1.5))

## End(Not run)
</code></pre>

<hr>
<h2 id='pairs'>Pairs plot method for compositions</h2><span id='topic+pairs.acomp'></span><span id='topic+pairs.rcomp'></span><span id='topic+vp.lrdensityplot'></span><span id='topic+vp.diffdensityplot'></span><span id='topic+vp.lrdensityplot'></span><span id='topic+vp.lrboxplot'></span><span id='topic+vp.kde2dplot'></span>

<h3>Description</h3>

<p>Pairs plot function for compositions, allowing flexible representations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'acomp'
pairs(x, labels, panel = vp.lrdensityplot, ...,
                         horInd = 1:ncol(x), verInd = 1:ncol(x),
                         lower.panel = panel, upper.panel = panel,
                         diag.panel = NULL, text.panel = textPanel,
                         label.pos = 0.5 + has.diag/3, line.main = 3,
                         cex.labels = NULL, font.labels = 1,
                         row1attop = TRUE, gap = 1, log = "")
 ## S3 method for class 'rcomp'
pairs(x, labels, panel = vp.diffdensityplot, ...,
                         horInd = 1:ncol(x), verInd = 1:ncol(x),
                         lower.panel = panel, upper.panel = panel,
                         diag.panel = NULL, text.panel = textPanel,
                         label.pos = 0.5 + has.diag/3, line.main = 3,
                         cex.labels = NULL, font.labels = 1,
                         row1attop = TRUE, gap = 1, log = "")
  vp.lrdensityplot(x, y, col=2,..., alpha = NULL)
  vp.diffdensityplot(x, y, col=2,..., alpha = NULL)
  vp.lrboxplot(x, y, ...)
  vp.kde2dplot(x, y, grid=TRUE, legpos="bottomright", colpalette=heat.colors,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairs_+3A_x">x</code></td>
<td>
<p>a dataset of a compositional class; 
or for the panel functions, a vector of row components</p>
</td></tr>
<tr><td><code id="pairs_+3A_y">y</code></td>
<td>
<p>for the panel functions, a vector of column components</p>
</td></tr>
<tr><td><code id="pairs_+3A_...">...</code></td>
<td>
<p>further graphical parameters passed (see
<code><a href="graphics.html#topic+par">par</a></code>)</p>
</td></tr>
<tr><td><code id="pairs_+3A_labels">labels</code></td>
<td>
<p>the names of the parts</p>
</td></tr>
<tr><td><code id="pairs_+3A_panel">panel</code></td>
<td>
<p>common panel function to use for all off-diagonal plots</p>
</td></tr>
<tr><td><code id="pairs_+3A_horind">horInd</code></td>
<td>
<p>indices of columns of x to plot on the horizontal axis, defaults to all columns</p>
</td></tr> 
<tr><td><code id="pairs_+3A_verind">verInd</code></td>
<td>
<p>indices of columns of x to plot on the vertical axis, defaults to all columns</p>
</td></tr>
<tr><td><code id="pairs_+3A_lower.panel">lower.panel</code></td>
<td>
<p>panel function for the lower triangle of plots, defaults to the common panel</p>
</td></tr>
<tr><td><code id="pairs_+3A_upper.panel">upper.panel</code></td>
<td>
<p>panel function for the uppper triangle of plots, defaults to the common panel</p>
</td></tr>
<tr><td><code id="pairs_+3A_diag.panel">diag.panel</code></td>
<td>
<p>panel function for the diagonal of plots, defaults to text.panel</p>
</td></tr>
<tr><td><code id="pairs_+3A_text.panel">text.panel</code></td>
<td>
<p>panel function to write labels on the diagonal panels</p>
</td></tr>
<tr><td><code id="pairs_+3A_label.pos">label.pos</code></td>
<td>
<p>y position of labels in the text panel</p>
</td></tr> 
<tr><td><code id="pairs_+3A_line.main">line.main</code></td>
<td>
<p>if main is specified, line.main gives the line argument to mtext() which draws the title. You may want to specify oma when changing line.main</p>
</td></tr>
<tr><td><code id="pairs_+3A_cex.labels">cex.labels</code></td>
<td>
<p>graphics parameters for the text panel</p>
</td></tr>
<tr><td><code id="pairs_+3A_font.labels">font.labels</code></td>
<td>
<p>graphics parameters for the text panel</p>
</td></tr>
<tr><td><code id="pairs_+3A_row1attop">row1attop</code></td>
<td>
<p>logical. Should the layout be matrix-like with row 1 at the top, or graph-like with row 1 at the bottom?</p>
</td></tr> 
<tr><td><code id="pairs_+3A_gap">gap</code></td>
<td>
<p>distance between subplots, in margin lines</p>
</td></tr> 
<tr><td><code id="pairs_+3A_log">log</code></td>
<td>
<p>a character string indicating if logarithmic axes are to be used: see plot.default. Should not be used and left to the panel function to handle</p>
</td></tr>
<tr><td><code id="pairs_+3A_col">col</code></td>
<td>
<p>color for density and histogram components of the panel vp.*density</p>
</td></tr> 
<tr><td><code id="pairs_+3A_alpha">alpha</code></td>
<td>
<p>alpha level for marking normality in the panels vp.*density; default to no mark</p>
</td></tr> 
<tr><td><code id="pairs_+3A_grid">grid</code></td>
<td>
<p>should a unit-grid be added to each panel?</p>
</td></tr>
<tr><td><code id="pairs_+3A_legpos">legpos</code></td>
<td>
<p>where should the legend be placed? to be given as <code>x</code> in <code>graphics::legend</code></p>
</td></tr>
<tr><td><code id="pairs_+3A_colpalette">colpalette</code></td>
<td>
<p>which color palette is desired for the 2d density levels?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data is displayed in a matrix of plots, after the indications of a panel function. 
This is a simple implementation of <code><a href="graphics.html#topic+pairs">pairs</a></code> compositional methods, the real 
functionality is controlled by the panel functions. 
</p>
<p>The three panel functions included here can be used for generating either boxplots
or histograms plus kernel density plots of all pairwise logratios (in acomp) or 
differences (in rcomp) of the components. In the cas of histograms, these 
can be colored or left black-and-white depending on the adjustment to
normality, controlled by a <code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> and the alpha-level given.
These panel functions serve also as examples of how to generate user defined panels. 
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="#topic+vp.boxplot">vp.boxplot</a></code>, <code><a href="#topic+vp.logboxplot">vp.logboxplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pairs(acomp(sa.lognormals))
pairs(rcomp(sa.lognormals))
</code></pre>

<hr>
<h2 id='pairwiseplot'>Creates a paneled plot like pairs for two different datasets. </h2><span id='topic+pairwisePlot'></span><span id='topic+pairwisePlot.default'></span>

<h3>Description</h3>

<p>Creates a plot for each element of two lists or each column of each
dataset against each of the second.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwisePlot(X,Y,...)
## Default S3 method:
pairwisePlot(X,Y=X,...,
                xlab=deparse(substitute(X)),ylab=deparse(substitute(Y)),
                nm=c(length(Y),length(X)),panel=plot,
                add.line=FALSE, line.col=2,add.robust=FALSE,rob.col=4)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwiseplot_+3A_x">X</code></td>
<td>
<p>a list, a data.frame, or a matrix representing the first set
of things to be displayed.</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_y">Y</code></td>
<td>
<p>a list, a data.frame, or a matrix representing the second set
of things to be displayed.</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_...">...</code></td>
<td>
<p>furter parameters to the panel function</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_xlab">xlab</code></td>
<td>
<p>The sequence of labels for the elements of
X. Alternatively the labels can be given as colnames or names
of X. This option takes precedence if specified.</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_ylab">ylab</code></td>
<td>
<p>The sequence of labels for the elements of
Y. Alternatively the labels can be given as colnames or names
of Y. This option takes precedence if specified.</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_nm">nm</code></td>
<td>
<p>the parameter to be used in the call
<code>par(mfrow=nm)</code>. If NULL no parameter is setted and a
sequence of plots can be generated. </p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_panel">panel</code></td>
<td>
<p>The panel function to plot the individual panels.
If the panel function admits a formula interface, it is called
as <code>panel(y~x, xlab=xlab,ylab=ylab,...)</code>, otherwise
as <code>panel(x, y,xlab=xlab,ylab=ylab,...)</code>. Thus the
panel function must be capable of taking these arguments. It must
also set up its own plot. There is no negotiation on coordinate
system.     
</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_add.line">add.line</code></td>
<td>
<p>logical, to control the addition of a regression line
in each panel</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_line.col">line.col</code></td>
<td>
<p>in case the regression line is added, which color should be
used? defaults to red. </p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_add.robust">add.robust</code></td>
<td>
<p>logical, to control the addition of a robust regression line
in each panel. Ignored if covariable is a factor. This is nowadays 
based on <code><a href="robustbase.html#topic+lmrob">lmrob</a></code>, but this can change in the future.</p>
</td></tr>
<tr><td><code id="pairwiseplot_+3A_rob.col">rob.col</code></td>
<td>
<p>in case the robust regression line is added, which color should be
used? Defaults to blue. </p>
</td></tr>   
</table>


<h3>Details</h3>

<p> This is a light-weight convenience function to plot several
aspects of one dataset against several aspects of another dataset.  It
is far more straight-forward than e.g. the <code>pairs</code> function and
does not do any internal computation rather than organizing the names.
Of course, the rows of the two data sets must be the same.
</p>
<p>The current implementation may display a warning about the function
<code>panel</code> dispatching methods for generic <code>plot</code>. It can be
ignored without harm.
</p>
<p>Optionally, classical and/or robust regression lines can be drawn, though
only for non-factor covariables.
</p>
<p>It may be convenient to use <code><a href="graphics.html#topic+par">par</a></code> capabilities to fit the device
characteristics to the plot, in particular arguments <code>mar</code> and <code>oma</code>.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Boogaart, K.G. v.d. , R. Tolosana (2008) Mixing Compositions and Other
scales, Proceedings of CodaWork 08.
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a>
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork08/">https://ima.udg.edu/Activitats/CoDaWork08/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.aplus">plot.aplus</a></code>, <code><a href="#topic+balance">balance</a></code>, <code><a href="#topic+pwlrPlot">pwlrPlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- rnorm(100)
Y &lt;- rnorm.acomp(100,acomp(c(A=1,B=1,C=1)),0.1*diag(3))+acomp(t(outer(c(0.2,0.3,0.4),X,"^")))

pairs(cbind(ilr(Y),X),panel=function(x,y,...) {points(x,y,...);abline(lm(y~x))})
pairs(cbind(balance(Y,~A/B/C),X),
         panel=function(x,y,...) {points(x,y,...);abline(lm(y~x))})
pairwisePlot(balance(Y,~A/B/C),X)
pairwisePlot(X,balance(Y,~A/B/C),
         panel=function(x,y,...) {plot(x,y,...);abline(lm(y~x))})
pairwisePlot(X,balance01(Y,~A/B/C))

# A function to extract a portion representation of subcompsitions
# with two elements:
subComps &lt;- function(X,...,all=list(...)) {
  X &lt;- oneOrDataset(X)
  nams &lt;- sapply(all,function(x) paste(x[[2]],x[[3]],sep=","))
  val  &lt;- sapply(all,function(x){ 
             a = X[,match(as.character(x[[2]]),colnames(X)) ]
             b = X[,match(as.character(x[[2]]),colnames(X)) ]
             c = X[,match(as.character(x[[3]]),colnames(X)) ]
             return(a/(b+c))
           })
  colnames(val)&lt;-nams
  val
}

pairwisePlot(X,subComps(Y,A~B,A~C,B~C))

## using Hydrochemical data set as illustration of mixed possibilities
data(Hydrochem)
xc = acomp(Hydrochem[,c("Ca","Mg","Na","K")])
fk = Hydrochem$River
pH = -log10(Hydrochem$H)
covars = data.frame(pH, River=fk)
pairwisePlot(clr(xc), pH)
pairwisePlot(clr(xc), pH, col=fk)
pairwisePlot(pH, ilr(xc), add.line=TRUE)
pairwisePlot(covars, ilr(xc), add.line=TRUE, line.col="magenta")
pairwisePlot(clr(xc), covars, add.robust=TRUE)

</code></pre>

<hr>
<h2 id='parametricMat'>Unique parametrisations for matrices.</h2><span id='topic+parametricPosdefMat'></span><span id='topic+parametricRank1Mat'></span><span id='topic+parameterPosdefMat'></span><span id='topic+parameterRank1Mat'></span><span id='topic+parametricPosdefClrMat'></span><span id='topic+parametricRank1ClrMat'></span><span id='topic+parameterPosdefClrMat'></span><span id='topic+parameterRank1ClrMat'></span>

<h3>Description</h3>

<p>Helper functions to parametrize positive semidefinite matrices in
multivariate variogram models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parametricRank1Mat(p)
parametricPosdefMat(p)
parameterRank1Mat(A)
parameterPosdefMat(A)
parametricRank1ClrMat(p)
parametricPosdefClrMat(p)
parameterRank1ClrMat(A)
parameterPosdefClrMat(A)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parametricMat_+3A_a">A</code></td>
<td>
<p>a positiv definit matrix of the given type</p>
</td></tr>
<tr><td><code id="parametricMat_+3A_p">p</code></td>
<td>
<p>a vector of parameters describing the matrix, as returned by
the parameter functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rank 1 matrix is parametrised by the first eigenvector scaled by
the square root of the eigenvalue. The positiv semidefinit matrix the
entries of a upper right triangular matrix R with
<code>t(R)%*%R==A</code>. The clr matrices are work with the parameters of
the corresponding ilr matrix. 
</p>


<h3>Value</h3>

<p>A or p, depending on what is not given.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+vgram2lrvgram">vgram2lrvgram</a></code>,
<code><a href="#topic+CompLinModCoReg">CompLinModCoReg</a></code>,
<code><a href="#topic+vgmFit">vgmFit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>parametricRank1Mat(c(0,0,2))
parametricPosdefMat(c(0,0,1,0,0,0))
parameterRank1Mat(matrix(1,nr=3,nc=3))
parameterPosdefMat(diag(5))
</code></pre>

<hr>
<h2 id='perturbe'>Perturbation of compositions</h2><span id='topic+perturbe'></span><span id='topic++2B.acomp'></span><span id='topic+-.acomp'></span>

<h3>Description</h3>

<p>The perturbation is the addition operation in the Aitchison geometry
of the simplex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perturbe(x,y)
## Methods for class "acomp"
## x + y
## x - y
##   - x
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perturbe_+3A_x">x</code></td>
<td>
<p>compositions of class <code><a href="#topic+acomp">acomp</a></code></p>
</td></tr>
<tr><td><code id="perturbe_+3A_y">y</code></td>
<td>
<p>compositions of class <code><a href="#topic+acomp">acomp</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The perturbation is the basic addition operation of the Aitichson
simplex as a vector space. It is defined by:
</p>
<p style="text-align: center;"><code class="reqn"> (x+y)_i = clo( (x_i  y_i)_i )_i </code>
</p>

<p><code>perturbe</code> and <code>+</code> compute this operation. The only
difference is that <code>+</code> checks the class of its argument, while
<code>perturbe</code> does not check the type of the arguments and can thus
directly be applied to a composition in any form (unclassed, acomp,
rcomp).<br />
The <code>-</code> operation is the inverse of the addition in the usual way
and defined by:
</p>
<p style="text-align: center;"><code class="reqn">(x-y)_i:=clo( (x_i/y_i)_i )_i</code>
</p>

<p>and as unary operation respectively as: 
</p>
<p style="text-align: center;"><code class="reqn">(-x)_i:=clo( (1/y_i)_i )_i</code>
</p>



<h3>Value</h3>

<p>An <code><a href="#topic+acomp">acomp</a></code> vector or matrix.  </p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic++2A.aplus">*.aplus</a></code>, <code><a href="#topic++2B.rplus">+.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmp &lt;- -acomp(1:3)
tmp + acomp(1:3)


</code></pre>

<hr>
<h2 id='plot.acomp'>Ternary diagrams</h2><span id='topic+plot.acomp'></span><span id='topic+plot.rcomp'></span><span id='topic+plot.ccomp'></span>

<h3>Description</h3>

<p>Displaying compositions in ternary diagrams
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'acomp'
plot(x,...,labels=names(x),
          aspanel=FALSE,id=FALSE,idlabs=NULL,idcol=2,center=FALSE,
          scale=FALSE,pca=FALSE,col.pca=par("col"),margin="acomp",
          add=FALSE,triangle=!add,col=par("col"),axes=FALSE,
          plotMissings=TRUE,
          lenMissingTck=0.05,colMissingTck="red",
          mp=~simpleMissingSubplot(c(0,1,0.95,1),
                                  missingInfo,c("NM","TM",cn)),
          robust=getOption("robust"))
 ## S3 method for class 'rcomp'
plot(x,...,labels=names(x),
          aspanel=FALSE,id=FALSE,idlabs=NULL,idcol=2,center=FALSE,
          scale=FALSE,pca=FALSE,col.pca=par("col"),margin="rcomp",
          add=FALSE,triangle=!add,col=par("col"),axes=FALSE
          ,plotMissings=TRUE,
          lenMissingTck=0.05,colMissingTck="red",
          mp=~simpleMissingSubplot(c(0,1,0.95,1),
                                   missingInfo,c("NM","TM",cn)),
          robust=getOption("robust"))
 ## S3 method for class 'ccomp'
plot(x,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.acomp_+3A_x">x</code></td>
<td>
<p>a dataset of a compositional class</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_...">...</code></td>
<td>
<p>further graphical parameters passed (see
<code><a href="graphics.html#topic+par">par</a></code>)</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_margin">margin</code></td>
<td>
<p>the type of marginalisation to be computed, when
displaying the individual panels. Possible values are: <code>"acomp"</code>,
<code>"rcomp"</code> and any of the variable names/column numbers in the
composition. If one of the columns is selected each panel displays a
subcomposition given by the row part, the column part and
the given part. If one of the classes is given the corresponding
margin <code><a href="#topic+acompmargin">acompmargin</a></code>  or  <code><a href="#topic+rcompmargin">rcompmargin</a></code> is
used. </p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_add">add</code></td>
<td>
<p>a logical indicating whether the information should just
be added to an existing plot. If FALSE a new plot is created</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_triangle">triangle</code></td>
<td>
<p>a logical indicating whether the triangle should be
drawn</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_col">col</code></td>
<td>
<p>the color to plot the data</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_labels">labels</code></td>
<td>
<p>the names of the parts</p>
</td></tr>


<tr><td><code id="plot.acomp_+3A_aspanel">aspanel</code></td>
<td>
<p>logical indicating that only a single panel should be
drawn and not the whole plot. Internal use only</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_id">id</code></td>
<td>
<p>logical, if TRUE one can identify the points like with the
<code><a href="graphics.html#topic+identify">identify</a></code> command. </p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_idlabs">idlabs</code></td>
<td>
<p>a character vector providing the labels to be used with
the identification, when <code>id=TRUE</code></p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_idcol">idcol</code></td>
<td>
<p>color of the <code>idlabs</code> labels</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_center">center</code></td>
<td>
<p>a logical indicating whether a the data should be
centered prior to the plot. Centering is done in the choosen
geometry. See <code><a href="#topic+scale">scale</a></code></p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_scale">scale</code></td>
<td>
<p>a logical indicating whether a the data should be
scaled prior to the plot. Scaling is done in the choosen
geometry. See <code><a href="#topic+scale">scale</a></code></p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_pca">pca</code></td>
<td>
<p>a logical indicating whether the first principal component
should be displayed in the plot. Currently, the direction of the
principal component of the displayed subcomposition is displayed as 
a line. In a future, the projected principal componenent of the whole 
dataset should be displayed.</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_col.pca">col.pca</code></td>
<td>
<p>The color to draw the principal component.</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_axes">axes</code></td>
<td>
<p>Either a logical wether to plot the axes, or numerical
enumerating the axes sides to be used e.g. 1 for only plotting the
lower axes, or a list of parameters to ternaryAxis. </p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_plotmissings">plotMissings</code></td>
<td>
<p> logical indicating that missingness should be
represented graphically. Componentes with one missing subcomponent
in the plot are represented by tickmarks at the three
axis. Components with two or three missing components are only
represented in a special panel drawn according to the mp parameter
if missings are present. Missings of type BDL (below detection
limit) are always plotted, even if <code>plotMissings</code> is false, but
in this case this fact is not specially marked. In rcomp geometry an
actuall 0 in the data is never treated as missing.</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_lenmissingtck">lenMissingTck</code></td>
<td>
<p>length of the tick-marks to be plotted for missing
values. If 0 no tickmarks are plotted. Negative lengths point
outside. length 1 draws right through to the opposit
corner. Missing ticks in acomp geometry are inclined showing the
line of possible values in acomp geometry. Missingticks in
rcomp-geometry are vertical to the axis representing the fact that
only the other component is unkown. That these lines can leave the plot
is one of the  odd consequences of rcomp geometry.</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_colmissingtck">colMissingTck</code></td>
<td>
<p>colors to draw the missing tick-marks. NULL means
to take the colors specified for the observations.</p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_mp">mp</code></td>
<td>
<p>A formula providing a call to a function plotting
informations on the missings. The call is evaluted in the
environment of the panel plotting function and has access (among
others) to: <code>cn</code> the names of the components in the current
plot, <code>x</code> the dataset of the current plot, <code>y</code> the
transformed dataset, (c60,s60) coordinates of the upper vertex of
the triangle. <code>missingInfo</code> is a table giving the number of
observations of the types NM=Non Missing, TM=Totally missing
(i.e. at least two components of the subcomposition are missing),
and the three single component missing possibilities for the three
components. </p>
</td></tr>
<tr><td><code id="plot.acomp_+3A_robust">robust</code></td>
<td>
<p>A robustness description. See
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for details. The option is used for
centering, scaling and principle components. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data is displayed in ternary diagrams. Thus, it does not work for
two-part compositions. Compositions of three parts are displayed
in a single ternary diagram. For compositions of more than three
components, the data is arranged in a scatterplot matrix through the
command <code><a href="graphics.html#topic+pairs">pairs</a></code>.
<br />
In this case, the third component in each of the panels is chosen 
according to setting of <code>margin=</code>. Possible values of <code>margin=</code> are:
<code>"acomp"</code>, <code>"rcomp"</code> and any of the variable names/column numbers in the
composition. If one of the columns is selected each panel displays a
subcomposition given by the row part, the column part and
the given part. If one of the classes is given the corresponding
margin <code><a href="#topic+acompmargin">acompmargin</a></code>  or  <code><a href="#topic+rcompmargin">rcompmargin</a></code> is
used.
<br />
Ternary diagrams can be read in multiple ways. Each corner of the
triangle corresponds to an extreme composition containing only the part
displayed in that corner. Points on the edges correspond to
compositions containing only the parts in the adjacent corners. The
relative amounts are displayed by the distance to the opposite
corner (so-called barycentric coordinates). The individual portions 
of any point can be infered by drawing a line through the investigated point, 
and parallel to the edge opposite to the corner of the part of interest. 
The portion of this part is constant along the line. Thus we can read it 
on the sides of the ternary diagram, where the line crosses its borders.
Note that these <code><a href="#topic+isoPortionLines">isoPortionLines</a></code> remain straight under an 
arbitrary perturbation. 
<br />
ccomp ternary diagrams are always jittered to avoid overplotting.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>
<p>Billheimer, D., P. Guttorp, W.F. and Fagan (2001) Statistical interpretation of species composition,
<em>Journal of the American Statistical Association</em>, <b>96</b> (456), 1205-1214<br />
</p>
<p>Pawlowsky-Glahn, V. and J.J. Egozcue (2001) Geometric approach to
statistical analysis on the simplex. <em>SERRA</em> <b>15</b>(5), 384-398<br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.aplus">plot.aplus</a></code>, <code><a href="#topic+plot3D">plot3D</a></code> (for 3D plot),
<code><a href="#topic+kingTetrahedron">kingTetrahedron</a></code> (for 3D-plot model export),
<code><a href="#topic+qqnorm.acomp">qqnorm.acomp</a></code>,<code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(acomp(sa.lognormals))
plot(acomp(sa.lognormals),axes=TRUE)
plot(rcomp(sa.lognormals))
plot(rcomp(sa.lognormals5))

plot(acomp(sa.lognormals5),pca=TRUE,col.pca="red")
plot(rcomp(sa.lognormals5),pca=TRUE,col.pca="red",axes=TRUE)
</code></pre>

<hr>
<h2 id='plot.aplus'>Displaying amounts in scatterplots</h2><span id='topic+plot.aplus'></span><span id='topic+plot.rplus'></span><span id='topic+plot.rmult'></span>

<h3>Description</h3>

<p>This function displays multivariate unclosed amout datasets classes
&quot;aplus&quot; and &quot;rplus&quot; in a way respecting the choosen geometry
eventually in log scale. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'aplus'
plot(x,...,labels=colnames(X),cn=colnames(X),
                     aspanel=FALSE,id=FALSE,idlabs=NULL,idcol=2,
                     center=FALSE,scale=FALSE,pca=FALSE,col.pca=par("col"),
                     add=FALSE,logscale=TRUE,xlim=NULL,ylim=xlim,
                     col=par("col"),plotMissings=TRUE,
                     lenMissingTck=0.05,colMissingTck="red",
                     mp=~simpleMissingSubplot(missingPlotRect,missingInfo,
                                               c("NM","TM",cn)),
                     robust=getOption("robust"))
  ## S3 method for class 'rplus'
plot(x,...,labels=colnames(X),cn=colnames(X),
                     aspanel=FALSE,id=FALSE,idlabs=NULL,idcol=2,
                     center=FALSE,scale=FALSE,pca=FALSE,col.pca=par("col"),
                     add=FALSE,logscale=FALSE,
                     xlim=NULL,
                     ylim=xlim,col=par("col"),plotMissings=TRUE,
                     lenMissingTck=0.05,colMissingTck="red",
                     mp=~simpleMissingSubplot(missingPlotRect,missingInfo,
                                               c("NM","TM",cn)),
                     robust=getOption("robust"))
  ## S3 method for class 'rmult'
plot(x,...,labels=colnames(X),cn=colnames(X),
                     aspanel=FALSE,id=FALSE,idlabs=NULL,idcol=2,
                     center=FALSE,scale=FALSE,pca=FALSE,col.pca=par("col"),
                     add=FALSE,logscale=FALSE,col=par("col"),
                     robust=getOption("robust"))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.aplus_+3A_x">x</code></td>
<td>
<p>a dataset with class aplus, rplus or rmult</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_...">...</code></td>
<td>
<p>further graphical parameters passed (see
<code><a href="graphics.html#topic+par">par</a></code>)</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_add">add</code></td>
<td>
<p>a logical indicating whether the information should just
be added to an existing plot. If FALSE, a new plot is
created</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_col">col</code></td>
<td>
<p>the color to plot the data</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_plotmissings">plotMissings</code></td>
<td>
<p> logical indicating that missingness should be
represented graphically. Componentes with one missing subcomponent
in the plot are represented by tickmarks at the two
axis. Cases with two missing components are only
represented in a special panel drawn according to the <code>mp</code>
parameter
if missings are present. Missings of type BDL (below detection
limit) are always plotted in nonlogaritmic plots, even if
<code>plotMissings</code> is false, but
in this case this fact is not specially marked.</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_lenmissingtck">lenMissingTck</code></td>
<td>
<p>length of the tick-marks (in portion of the
plotting region) to be plotted for missing
values. If 0 no tickmarks are plotted. Negative lengths point
outside of the plot. A length of 1 runs right through the whole plot.</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_colmissingtck">colMissingTck</code></td>
<td>
<p>colors to draw the missing tick-marks. NULL means
to take the colors specified for the observations.</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_mp">mp</code></td>
<td>
<p>A formula providing a call to a function plotting
informations on the missings. The call is evaluted in the
environment of the panel plotting function and has access (among
others) to: <code>cn</code> the names of the components in the current
plot, <code>x</code> the dataset of the current plot, <code>missingInfo</code>
is a table giving the number of 
observations of the types NM=Non Missing, TM=Totally missing
(i.e. two components of the subcomposition are missing),
and the two single component missing possibilities. </p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_labels">labels</code></td>
<td>
<p>the labels for names of the parts</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_cn">cn</code></td>
<td>
<p>the names of the parts to be used in a single
panel. Internal use only</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_aspanel">aspanel</code></td>
<td>
<p>logical indicating that only a single panel should be
drawn and not the whole plot. Internal use only</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_id">id</code></td>
<td>
<p>a logical. If TRUE one can identify the points like with the
<code><a href="graphics.html#topic+identify">identify</a></code> command</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_idlabs">idlabs</code></td>
<td>
<p>A character vector providing the labels to be used with
the identification, when <code>id=TRUE</code></p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_idcol">idcol</code></td>
<td>
<p>color of the <code>idlabs</code> labels</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_center">center</code></td>
<td>
<p>a logical indicating whether the data should be
centered prior to the plot. Centering is done in the chosen
geometry. See <code><a href="#topic+scale">scale</a></code></p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_scale">scale</code></td>
<td>
<p>a logical indicating whether the data should be
scaled prior to the plot. Scaling is done in the chosen
geometry. See <code><a href="#topic+scale">scale</a></code></p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_pca">pca</code></td>
<td>
<p>a logical indicating whether the first principal component
should be displayed in the plot. Currently, the direction of the
principal component of the displayed subcomposition is displayed as 
a line. In a future, the projected principal componenent of the whole 
dataset should be displayed.</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_col.pca">col.pca</code></td>
<td>
<p>the color to draw the principal component.</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_logscale">logscale</code></td>
<td>
<p>logical indicating whether a log scale should be used</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_xlim">xlim</code></td>
<td>
<p>2xncol(x)-matrix giving the xlims for the columns of x</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_ylim">ylim</code></td>
<td>
<p>2xncol(x)-matrix giving the ylims for the columns of x</p>
</td></tr>
<tr><td><code id="plot.aplus_+3A_robust">robust</code></td>
<td>
<p>A robustness description. See
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for details. The option is used for
centering, scaling and principle components.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TO DO: fix pca bug
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.aplus">plot.aplus</a></code>,
<code><a href="#topic+qqnorm.acomp">qqnorm.acomp</a></code>,<code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(aplus(sa.lognormals))
plot(rplus(sa.lognormals))
plot(aplus(sa.lognormals5))
plot(rplus(sa.lognormals5))
</code></pre>

<hr>
<h2 id='plot3D'>plot in 3D based on rgl</h2><span id='topic+plot3D'></span><span id='topic+plot3D.default'></span>

<h3>Description</h3>

<p>3-dimensional plots, which can be rotated and zoomed in/out
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot3D(x,...)
## Default S3 method:
plot3D(x,...,add=FALSE,bbox=TRUE,axes=FALSE,
           cex=1,size=cex,col=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot3D_+3A_x">x</code></td>
<td>
<p>an object to be plotted, e.g. a data frame or a data matrix</p>
</td></tr>
<tr><td><code id="plot3D_+3A_...">...</code></td>
<td>
<p>additional plotting parameters as described in

<code>rgl::material3d</code>  
</p>
</td></tr>
<tr><td><code id="plot3D_+3A_add">add</code></td>
<td>
<p>logical, adding  or new plot</p>
</td></tr>
<tr><td><code id="plot3D_+3A_bbox">bbox</code></td>
<td>
<p>logical, whether to add a bounding box</p>
</td></tr>
<tr><td><code id="plot3D_+3A_axes">axes</code></td>
<td>
<p>logical, whether to plot an axes of coordinates</p>
</td></tr>
<tr><td><code id="plot3D_+3A_cex">cex</code></td>
<td>
<p>size of the plotting symbol</p>
</td></tr>
<tr><td><code id="plot3D_+3A_size">size</code></td>
<td>
<p>size of the plotting symbol, only size or cex should be
used</p>
</td></tr>
<tr><td><code id="plot3D_+3A_col">col</code></td>
<td>
<p>the color used for dots, defaults to black.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function provides a generic interface for 3-dimensional plotting
in analogy to the 2d-plotting interface of plot, using rgl package.
</p>


<h3>Value</h3>

<p>the 3D plotting coordinates of the objects displayed, returned invisibly
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>



<p><code>rgl::points3d</code>,
<code>graphics::plot</code>,
<code><a href="#topic+plot3D.rmult">plot3D.rmult</a></code>,
</p>
<p><code><a href="#topic+plot3D.acomp">plot3D.acomp</a></code>,<code><a href="#topic+plot3D.rcomp">plot3D.rcomp</a></code>,
<code><a href="#topic+plot3D.aplus">plot3D.aplus</a></code>,<code><a href="#topic+plot3D.rplus">plot3D.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- cbind(rnorm(10),rnorm(10),rnorm(10))
data(SimulatedAmounts)
if(requireNamespace("rgl", quietly = TRUE)) {
  plot3D(x)
  plot3D(sa.lognormals,cex=4,col=1:nrow(sa.lognormals))
} ## this function requires package 'rgl'
</code></pre>

<hr>
<h2 id='plot3Dacomp'>3D-plot of compositional data</h2><span id='topic+plot3D.acomp'></span><span id='topic+plot3D.rcomp'></span>

<h3>Description</h3>

<p>3D-plot of compositional data. The plot is
mainly an exploratory tool, not intended for exact display of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'acomp'
plot3D(x, parts=1:min(ncol(X),4),..., 
             lwd=2, axis.col="gray", add=FALSE, cex=2, 
             vlabs=colnames(x), vlabs.col=axis.col, center=FALSE, 
             scale=FALSE, log=FALSE, bbox=FALSE, axes=TRUE, size=cex,col=1)
## S3 method for class 'rcomp'
plot3D(x,parts=1:min(ncol(X),4),...,
             lwd=2,axis.col="gray",add=FALSE,cex=2,
             vlabs=colnames(x),vlabs.col=axis.col,center=FALSE,
             scale=FALSE,log=FALSE,bbox=FALSE,axes=TRUE,size=cex,col=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot3Dacomp_+3A_x">x</code></td>
<td>
<p>an aplus object to be plotted</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_parts">parts</code></td>
<td>
<p>a numeric xor character vector of length 3 coding the
columns to be plotted</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_...">...</code></td>
<td>
<p>additional plotting parameters as described in

<code>rgl::material3d</code>
</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_add">add</code></td>
<td>
<p>logical, adding  or new plot</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_cex">cex</code></td>
<td>
<p>size of the plotting symbols</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_lwd">lwd</code></td>
<td>
<p>line width</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_axis.col">axis.col</code></td>
<td>
<p>color of the axis</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_vlabs">vlabs</code></td>
<td>
<p>the column names to be plotted, if missing defaults to
the column names of the selected columns of X</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_vlabs.col">vlabs.col</code></td>
<td>
<p>color of the labels</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_center">center</code></td>
<td>
<p>logical, should the data be centered</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_scale">scale</code></td>
<td>
<p>logical, should the data be scaled</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_log">log</code></td>
<td>
<p>logical, indicating wether to plot in log scale</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_bbox">bbox</code></td>
<td>
<p>logical, whether to add a bounding box</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_axes">axes</code></td>
<td>
<p>logical, whether plot a coordinate cross</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_size">size</code></td>
<td>
<p>size of the plotting symbols</p>
</td></tr>
<tr><td><code id="plot3Dacomp_+3A_col">col</code></td>
<td>
<p>the color used for dots, defaults to black.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The routine behaves different when 3 or four components should be
plotted. In case of four components:
<br />
If log is TRUE the data is plotted in <code><a href="#topic+ilr">ilr</a></code>
coordinates. This is the isometric view of the data.
<br />
If log is FALSE the data is plotted in <code><a href="#topic+ipt">ipt</a></code> coordinates
and a tetrahedron is plotted around it if <code>coors == TRUE</code>. This
can be used to do a tetrahedron plot.
<br />
In case of three components:
<br />
If log is TRUE the data is plotted in <code><a href="#topic+clr">clr</a></code>
coordinates. This can be used to visualize the clr plane.
<br />
If log is FALSE the data is plotted as is, showing the embedding of
the
three-part simplex in the three-dimensional space. 
<br />
In all cases:
If <code>coors</code> is true, coordinate arrows are plotted
of length 1 in the origin of the space, except in the tetrahedron case.
</p>


<h3>Value</h3>

<p>Called for its side effect of a 3D plot of an acomp object in an rgl plot. 
It invisibly returns the 3D plotting coordinates of the objects displayed
</p>


<h3>Note</h3>

<p>The function <code><a href="#topic+kingTetrahedron">kingTetrahedron</a></code> provides an alternate way of
tetrahedron plots, based on a more advanced viewer, which must
be downloaded separately.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+kingTetrahedron">kingTetrahedron</a></code>


<code>rgl::points3d</code>,
<code>graphics::plot</code>,
<code><a href="#topic+plot3D">plot3D</a></code>,
<code><a href="#topic+plot3D.rmult">plot3D.rmult</a></code>,
</p>
<p><code><a href="#topic+plot3D.rcomp">plot3D.rcomp</a></code>,
<code><a href="#topic+plot3D.aplus">plot3D.aplus</a></code>,<code><a href="#topic+plot3D.rplus">plot3D.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
if(requireNamespace("rgl", quietly = TRUE)) {
  plot3D(acomp(sa.lognormals5),1:3,col="green")
  plot3D(acomp(sa.lognormals5),1:3,log=TRUE,col="green")
  plot3D(acomp(sa.lognormals5),1:4,col="green")
  plot3D(acomp(sa.lognormals5),1:4,log=TRUE,col="green")
} ## this function requires package 'rgl'
</code></pre>

<hr>
<h2 id='plot3Daplus'>3D-plot of positive data</h2><span id='topic+plot3D.aplus'></span>

<h3>Description</h3>

<p>3D-plot of positive data typically in log-log-log scale. The plot is
mainly an exploratory tool, and not intended for exact display of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'aplus'
plot3D(x,parts=1:3,...,
                vlabs=NULL,add=FALSE,log=TRUE,bbox=FALSE,axes=TRUE,col=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot3Daplus_+3A_x">x</code></td>
<td>
<p>an aplus object to be plotted</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_parts">parts</code></td>
<td>
<p>a numeric xor character vector of length 3 coding the
columns to be plotted</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_...">...</code></td>
<td>
<p>additional plotting parameters as described in

<code>rgl::material3d</code>
</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_add">add</code></td>
<td>
<p>logical, adding  or new plot</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_vlabs">vlabs</code></td>
<td>
<p>the column names to be plotted, if missing defaults to
the column names of the selected columns of X</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_log">log</code></td>
<td>
<p>logical, indicating wether to plot in log scale</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_bbox">bbox</code></td>
<td>
<p>logical, whether to add a bounding box</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_axes">axes</code></td>
<td>
<p>logical, plot a coordinate system</p>
</td></tr>
<tr><td><code id="plot3Daplus_+3A_col">col</code></td>
<td>
<p>the color used for dots, defaults to black.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If log is TRUE the data is plotted in <code><a href="#topic+ilt">ilt</a></code>
coordinates. If <code>coors</code> is true, coordinate arrows are plotted
of length 1 and in the (aplus-)mean of the dataset.
<br />
If log is FALSE the data is plotted with plot.rplus
</p>


<h3>Value</h3>

<p>Called for its side effect of a 3D plot of an aplus object in an rgl plot. 
It invisibly returns the 3D plotting coordinates of the objects displayed
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+kingTetrahedron">kingTetrahedron</a></code>


<code>rgl::points3d</code>,
<code>graphics::plot</code>,
<code><a href="#topic+plot3D">plot3D</a></code>,
<code><a href="#topic+plot3D.rmult">plot3D.rmult</a></code>,
</p>
<p><code><a href="#topic+plot3D.acomp">plot3D.acomp</a></code>,<code><a href="#topic+plot3D.rcomp">plot3D.rcomp</a></code>,
<code><a href="#topic+plot3D.rplus">plot3D.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
if(requireNamespace("rgl", quietly = TRUE)) {
  plot3D(aplus(sa.lognormals),size=2)
} ## this function requires package 'rgl'

</code></pre>

<hr>
<h2 id='plot3Drmult'>plot in 3D based on rgl</h2><span id='topic+plot3D.rmult'></span>

<h3>Description</h3>

<p>3-dimensional plots, which can be rotated and zoomed in/out
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rmult'
plot3D(x,parts=1:3,...,
                 center=FALSE,scale=FALSE,add=FALSE,axes=!add,
                 cex=2,vlabs=colnames(x),size=cex,bbox=FALSE,col=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot3Drmult_+3A_x">x</code></td>
<td>
<p>an object to be plotted, e.g. a data frame or a data matrix</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_parts">parts</code></td>
<td>
<p>the variables in the rmult object to be plotted</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_...">...</code></td>
<td>
<p>additional plotting parameters as described in

<code>rgl::material3d</code>
</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_center">center</code></td>
<td>
<p>logical, center the data? This might be necessary to
stay within the openGL-arithmetic used in rgl.</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_scale">scale</code></td>
<td>
<p>logical, scale the data? This might be necessary to
stay within the openGL-arithmetic used in rgl.</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_add">add</code></td>
<td>
<p>logical, adding  or new plot</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_bbox">bbox</code></td>
<td>
<p>logical, whether to add a bounding box</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_axes">axes</code></td>
<td>
<p>logical, whether to plot a coordinate cross</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_cex">cex</code></td>
<td>
<p>size of the plotting symbol (as expanding factor)</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_vlabs">vlabs</code></td>
<td>
<p>labels for the variables</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_size">size</code></td>
<td>
<p>size of the plotting symbol, only size or cex should be used</p>
</td></tr>
<tr><td><code id="plot3Drmult_+3A_col">col</code></td>
<td>
<p>the color used for dots, defaults to black.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function provides a generic interface for 3-dimensional plotting
in analogy to the 2d-plotting interface of plot, using rgl package.
</p>


<h3>Value</h3>

<p>the 3D plotting coordinates of the objects displayed, returned invisibly
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+kingTetrahedron">kingTetrahedron</a></code>


<code>rgl::points3d</code>,
<code>graphics::plot</code>,
<code><a href="#topic+plot3D">plot3D</a></code>,
</p>
<p><code><a href="#topic+plot3D.acomp">plot3D.acomp</a></code>,<code><a href="#topic+plot3D.rcomp">plot3D.rcomp</a></code>,
<code><a href="#topic+plot3D.aplus">plot3D.aplus</a></code>,<code><a href="#topic+plot3D.rplus">plot3D.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- cbind(rnorm(10),rnorm(10),rnorm(10))
data(SimulatedAmounts)
if(requireNamespace("rgl", quietly = TRUE)) {
  plot3D(x)
  plot3D(rmult(sa.lognormals),cex=4,col=1:nrow(sa.lognormals))
} ## this function requires package 'rgl'
</code></pre>

<hr>
<h2 id='plot3Drplus'>plot in 3D based on rgl</h2><span id='topic+plot3D.rplus'></span>

<h3>Description</h3>

<p>3-dimensional plots, which can be rotated and zoomed in/out
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rplus'
plot3D(x,parts=1:3,...,vlabs=NULL,add=FALSE,bbox=FALSE,
                           cex=1,size=cex,axes=TRUE,col=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot3Drplus_+3A_x">x</code></td>
<td>
<p>an rplus object to be plotted</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_parts">parts</code></td>
<td>
<p>the variables in the rplus object to be plotted</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_...">...</code></td>
<td>
<p>additional plotting parameters as described in

<code>rgl::material3d</code>
</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_vlabs">vlabs</code></td>
<td>
<p>the labels used for the variable axes</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_add">add</code></td>
<td>
<p>logical, adding  or new plot</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_bbox">bbox</code></td>
<td>
<p>logical, whether to add a bounding box</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_cex">cex</code></td>
<td>
<p>size of the plotting symbol (as character expansion factor)</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_size">size</code></td>
<td>
<p>size of the plotting symbol, only size or cex should be used</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_axes">axes</code></td>
<td>
<p>logical, whether to plot a coordinate cross</p>
</td></tr>
<tr><td><code id="plot3Drplus_+3A_col">col</code></td>
<td>
<p>the color used for dots, defaults to black.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function plots rplus objects in a 3D coordinate system, in an rgl plot. 
</p>


<h3>Value</h3>

<p>the 3D plotting coordinates of the objects displayed, returned invisibly
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+kingTetrahedron">kingTetrahedron</a></code>


<code>rgl::points3d</code>,
<code>graphics::plot</code>,
<code><a href="#topic+plot3D">plot3D</a></code>,
<code><a href="#topic+plot3D.rmult">plot3D.rmult</a></code>,
</p>
<p><code><a href="#topic+plot3D.acomp">plot3D.acomp</a></code>,<code><a href="#topic+plot3D.rcomp">plot3D.rcomp</a></code>,
<code><a href="#topic+plot3D.aplus">plot3D.aplus</a></code>,<code><a href="#topic+plot3D">plot3D</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- cbind(rnorm(10),rnorm(10),rnorm(10))
data(SimulatedAmounts)
if(requireNamespace("rgl", quietly = TRUE)) {
  plot3D(rplus(exp(x)))
  plot3D(rplus(sa.lognormals),cex=4,col=1:nrow(sa.lognormals))
} ## this function requires package 'rgl'
</code></pre>

<hr>
<h2 id='plotlogratioVariogram'>Empirical variograms for compositions</h2><span id='topic+plot.logratioVariogram'></span>

<h3>Description</h3>

<p>Plots a logratioVariogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'logratioVariogram'
plot(x,...,type="l",lrvg=NULL,
                fcols=2:length(lrvg),oma=c(4, 4, 4, 4),gap=0,ylim=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotlogratioVariogram_+3A_x">x</code></td>
<td>
<p>The logratioVariogram created by
<code><a href="#topic+logratioVariogram">logratioVariogram</a></code></p>
</td></tr>
<tr><td><code id="plotlogratioVariogram_+3A_...">...</code></td>
<td>
<p>further parameters for <code>plot.default</code></p>
</td></tr>
<tr><td><code id="plotlogratioVariogram_+3A_type">type</code></td>
<td>
<p>as in <code>plot.default</code></p>
</td></tr>
<tr><td><code id="plotlogratioVariogram_+3A_lrvg">lrvg</code></td>
<td>
<p>a model function for a logratiovariogram or a list of
several, to be added to the plot.</p>
</td></tr>
<tr><td><code id="plotlogratioVariogram_+3A_fcols">fcols</code></td>
<td>
<p>the colors for the different lrvg variograms</p>
</td></tr>
<tr><td><code id="plotlogratioVariogram_+3A_oma">oma</code></td>
<td>
<p>The outer margin of the paneled plot</p>
</td></tr>
<tr><td><code id="plotlogratioVariogram_+3A_gap">gap</code></td>
<td>
<p>The distance of the plot panals used to determin <code>mar</code></p>
</td></tr>
<tr><td><code id="plotlogratioVariogram_+3A_ylim">ylim</code></td>
<td>
<p>The limits of the Y-axis. If zero it is automatically
computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see <code><a href="#topic+logratioVariogram">logratioVariogram</a></code>
</p>


<h3>Value</h3>

<p>Nothing. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+vgram2lrvgram">vgram2lrvgram</a></code>, <code><a href="#topic+CompLinModCoReg">CompLinModCoReg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(juraset)
X &lt;- with(juraset,cbind(X,Y))
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
lrv &lt;- logratioVariogram(comp,X,maxdist=1,nbins=10)
fff &lt;- CompLinModCoReg(~nugget()+sph(0.5)+R1*exp(0.7),comp)
fit &lt;- vgmFit(lrv,fff)
fit
fff(1:3)
plot(lrv,lrvg=vgram2lrvgram(fit$vg))

## End(Not run)
</code></pre>

<hr>
<h2 id='plotmissingsummary'>Plot a Missing Summary</h2><span id='topic+plot.missingSummary'></span><span id='topic+as.missingSummary'></span>

<h3>Description</h3>

<p>Plots a missing summary as a barplot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'missingSummary'
plot(x,...,main="Missings",legend.text=TRUE,
                    col=c("gray","lightgray","yellow","red","white","magenta"))
 as.missingSummary(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotmissingsummary_+3A_x">x</code></td>
<td>
<p>a missingSummary table with columns representing different
types of missing</p>
</td></tr>
<tr><td><code id="plotmissingsummary_+3A_...">...</code></td>
<td>
<p>further graphical parameters to barplot</p>
</td></tr>
<tr><td><code id="plotmissingsummary_+3A_main">main</code></td>
<td>
<p>as in <a href="graphics.html#topic+barplot">barplot</a></p>
</td></tr>
<tr><td><code id="plotmissingsummary_+3A_legend.text">legend.text</code></td>
<td>
<p>as in barplot</p>
</td></tr>
<tr><td><code id="plotmissingsummary_+3A_col">col</code></td>
<td>
<p>as in barplot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The different types of missings are drawn in quasi-self-understandable 
colors: normal gray for NMV, and lightgray as for BDL (since they contain
semi-numeric information), yellow (slight warning) for MAR, red (serious 
warning) for MNAR, white (because they are non-existing) for SZ, and 
magenta for the strange case of errors.
</p>


<h3>Value</h3>

<p>called for its side effect. The return value is not defined.
</p>


<h3>Author(s)</h3>

<p>K.Gerald van den Boogaart</p>


<h3>References</h3>

<p>See <a href="#topic+compositions.missings">compositions.missings</a> for more details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+missingSummary">missingSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
x &lt;- acomp(sa.lognormals)
xnew &lt;- simulateMissings(x,dl=0.05,MAR=0.05,MNAR=0.05,SZ=0.05)
xnew
plot(missingSummary(xnew))
</code></pre>

<hr>
<h2 id='PogoJump'>
Honk Kong Pogo-Jumps Championship
</h2><span id='topic+Data19'></span><span id='topic+PogoJump'></span>

<h3>Description</h3>

<p>Yat, yee, sam measurements (in meters) for the final jumps of the 1985
Honk Kong Pogo-Jumps Championship, 4 jumps of the 7 finalists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PogoJump)
</code></pre>


<h3>Details</h3>

<p>The data consist of 28 cases: 4 jumps of the 7 finalists, and
4 variables: Yat, Yee, Sam measurements  in meters, and  finalist &ndash; 1 to 7.
</p>
<p>Pogo-Jumps is similar to the triple jump except that the competitor is
mounted on a pogo-stik. After a pogo-up towards the starting board the total jump
distance achieved in three consecutive bounces, known as the yat, yee and sam,
is recorded.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name HKPOGO.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1982) The Statistical Analysis of Compositional Data, (Data 19) pp21.
</p>

<hr>
<h2 id='powerofpsdmatrix'>power transform of a matrix</h2><span id='topic+powerofpsdmatrix'></span>

<h3>Description</h3>

<p>Computes the power of a positive semi-definite symmetric matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          powerofpsdmatrix( M , p,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerofpsdmatrix_+3A_m">M</code></td>
<td>
<p>a matrix, preferably symmetric</p>
</td></tr>
<tr><td><code id="powerofpsdmatrix_+3A_p">p</code></td>
<td>
<p>a single number giving the power</p>
</td></tr>
<tr><td><code id="powerofpsdmatrix_+3A_...">...</code></td>
<td>
<p>further arguments to the singular value decomposition</p>
</td></tr>
</table>


<h3>Details</h3>

<p>for a symmetric matrix the computed result can actually be considered as
a version of the given power of the matrix fullfilling the relation:
</p>
<p style="text-align: center;"><code class="reqn">M^pM^q=M^{p+q}</code>
</p>

<p>The symmetry of the matrix is not checked.
</p>


<h3>Value</h3>

<p><code>U%*% D^p %*% t(P)</code> where the <code>UDP</code> is the singular value
decomposition of M. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
d &lt;- ilr(sa.lognormals)
var( d %*% powerofpsdmatrix(var(d),-1/2)) # Unit matrix
</code></pre>

<hr>
<h2 id='princomp.acomp'>Principal component analysis for Aitchison compositions</h2><span id='topic+princomp.acomp'></span><span id='topic+print.princomp.acomp'></span><span id='topic+plot.princomp.acomp'></span><span id='topic+plot.princomp.acomp'></span><span id='topic+predict.princomp.acomp'></span>

<h3>Description</h3>

<p>A principal component analysis is done in the Aitchison geometry
(i.e. clr-transform) of the simplex. Some gimics simplify the
interpretation of the computed components as compositional perturbations.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'acomp'
princomp(x,...,scores=TRUE,center=attr(covmat,"center"),
                           covmat=var(x,robust=robust,giveCenter=TRUE),
                           robust=getOption("robust"))
 ## S3 method for class 'princomp.acomp'
print(x,...)
 ## S3 method for class 'princomp.acomp'
plot(x,y=NULL,..., npcs=min(10,length(x$sdev)),
        type=c("screeplot","variance","biplot","loadings","relative"),
        main=NULL,scale.sdev=1)
 ## S3 method for class 'princomp.acomp'
predict(object,newdata,...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="princomp.acomp_+3A_x">x</code></td>
<td>
<p>a acomp-dataset (in princomp) or a result from
princomp.acomp</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_y">y</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_scores">scores</code></td>
<td>
<p>a logical indicating whether scores should be computed or not</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_npcs">npcs</code></td>
<td>
<p>the number of components to be drawn in the scree plot</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_type">type</code></td>
<td>
<p>type of the plot: <code>"screeplot"</code> is a lined screeplot,
<code>"variance"</code> is a boxplot-like screeplot, <code>"biplot"</code> is a
biplot, <code>"loadings"</code> displays the loadings as a 
<code><a href="#topic+barplot.acomp">barplot.acomp</a></code></p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_scale.sdev">scale.sdev</code></td>
<td>
<p>the multiple of sigma to use plotting the loadings</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_main">main</code></td>
<td>
<p>title of the plot</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_object">object</code></td>
<td>
<p>a fitted princomp.acomp object</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_newdata">newdata</code></td>
<td>
<p>another compositional dataset of class acomp</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_...">...</code></td>
<td>
<p>further arguments to pass to internally-called functions</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_covmat">covmat</code></td>
<td>
<p>provides the covariance matrix to be used for the
principle component analysis</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_center">center</code></td>
<td>
<p>provides the  be used for the computation of scores</p>
</td></tr>
<tr><td><code id="princomp.acomp_+3A_robust">robust</code></td>
<td>
<p>Gives the robustness type for the calculation of the
covariance matrix. See <code><a href="#topic+robustnessInCompositions">robustnessInCompositions</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As a metric euclidean space the Aitchison simplex has its own
principal component analysis, that should be performed in terms of the
covariance matrix and not in terms of the meaningless correlation
matrix. 
<br />
To aid the interpretation we added some extra functionality to a
normal <code>princomp(clr(x))</code>. First of all the result contains as
additional information the compositional representation of the
returned vectors in the space of the data: the center as a composition
<code>Center</code>, and the loadings in terms of a composition to perturbe
with, either positively
(<code>Loadings</code>) or negatively (<code>DownLoadings</code>). The Up- and
DownLoadings are normalized to the number of parts in the simplex
and not to one to simplify the interpretation. A value of about one
means no change in the specific component. To avoid confusion the
meaningless last principal component is removed.
<br />
The <code>plot</code> routine provides screeplots (<code>type = "s"</code>,<code>type=
    "v"</code>), biplots (<code>type = "b"</code>), plots of the effect of
loadings (<code>type = "b"</code>) in <code>scale.sdev*sdev</code>-spread, and
loadings of pairwise (log-)ratios (<code>type = "r"</code>).
<br />
The interpretation of a screeplot does not differ from ordinary
screeplots. It shows the eigenvalues of the covariance matrix, which
represent the portions of variance explained by the principal
components. 
<br />
The interpretation of the biplot strongly differs from a classical one.
The relevant variables are not the arrows drawn (one for each component), 
but rather the links (i.e., the differences) between two
arrow heads, which represents the log-ratio between the two
components represented by the arrows. 
<br />
The compositional loading plot is introduced with this
package. The loadings of all component can be seen as an orthogonal basis
in the space of clr-transformed data. These vectors are displayed by a barplot with
their corresponding composition. For a better
interpretation the total of these compositons is set to the number of
parts in the composition, such that a portion of one means no
effect. This is similar to (but not exactly the same as) a zero loading in a real
principal component analysis. 
<br />
The loadings plot can work in two different modes: if
<code>scale.sdev</code> is set to <code>NA</code> it displays the composition
beeing represented by the unit vector of loadings in the clr-transformed space. If
<code>scale.sdev</code> is numeric we use this composition scaled by the
standard deviation of the respective component. 
<br />
The relative plot displays the <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> as a
barplot. The deviation from a unit bar shows the effect of each
principal component on the respective ratio. 
</p>


<h3>Value</h3>

<p><code>princomp</code> gives an object of type
<code>c("princomp.acomp","princomp")</code> with the following content:
</p>
<table>
<tr><td><code>sdev</code></td>
<td>
<p>the standard deviation of the principal components</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings (i.e., a matrix which
columns contain the eigenvectors). This is of class
<code>"loadings"</code>. The last eigenvector is removed since it should
contain the irrelevant scaling.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>the clr-transformed vector of means used to center the dataset</p>
</td></tr>
<tr><td><code>Center</code></td>
<td>
<p>the <code><a href="#topic+acomp">acomp</a></code> vector of means used to center the dataset</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the scaling applied to each variable</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>if <code>scores = TRUE</code>, the scores of the supplied data
on the principal components. Scores are coordinates in a basis given by the principal
components and thus not compositions</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>not clearly understood</p>
</td></tr>
<tr><td><code>Loadings</code></td>
<td>
<p>compositions that represent a perturbation with the
vectors represented by the loadings of each of the factors </p>
</td></tr>
<tr><td><code>DownLoadings</code></td>
<td>
<p>compositions that represent a perturbation with the
inverse of the vectors represented by the loadings of each of the
factors</p>
</td></tr>
</table>
<p><code>predict</code> returns a matrix of scores of the observations in the
<code>newdata</code> dataset
<br />.
The other routines are mainly called for their side effect of plotting or
printing and return the object <code>x</code>.   
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>
<p>Aitchison, J. and M. Greenacre (2002) <em>Biplots for Compositional
Data</em> Journal of the Royal Statistical Society, Series C (Applied Statistics)
<b>51</b> (4) 375-392<br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> 
<code><a href="#topic+princomp.aplus">princomp.aplus</a></code>, <code><a href="#topic+princomp.rcomp">princomp.rcomp</a></code>,
<code><a href="#topic+barplot.acomp">barplot.acomp</a></code>, <code><a href="#topic+mean.acomp">mean.acomp</a></code>,
<code><a href="#topic+var.acomp">var.acomp</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pc &lt;- princomp(acomp(sa.lognormals5))
pc
summary(pc)
plot(pc)           #plot(pc,type="screeplot")
plot(pc,type="v")
plot(pc,type="biplot")
plot(pc,choice=c(1,3),type="biplot")
plot(pc,type="loadings")
plot(pc,type="loadings",scale.sdev=-1) # Downward
plot(pc,type="relative",scale.sdev=NA) # The directions
plot(pc,type="relative",scale.sdev=1) # one sigma Upward 
plot(pc,type="relative",scale.sdev=-1) # one sigma Downward
biplot(pc)
screeplot(pc)
loadings(pc)
relativeLoadings(pc,mult=FALSE)
relativeLoadings(pc)
relativeLoadings(pc,scale.sdev=1)
relativeLoadings(pc,scale.sdev=2)

pc$Loadings
pc$DownLoadings
barplot(pc$Loadings)
pc$sdev^2
p = predict(pc,sa.lognormals5)
cov(p)
</code></pre>

<hr>
<h2 id='princomp.aplus'>Principal component analysis for amounts in log geometry</h2><span id='topic+princomp.aplus'></span><span id='topic+print.princomp.aplus'></span><span id='topic+plot.princomp.aplus'></span><span id='topic+plot.princomp.aplus'></span><span id='topic+predict.princomp.aplus'></span>

<h3>Description</h3>

<p>A principal component analysis is done in the Aitchison geometry
(i.e. ilt-transform). Some gimics simplify the
interpretation of the computed components as perturbations of amounts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'aplus'
princomp(x,...,scores=TRUE,center=attr(covmat,"center"),
                           covmat=var(x,robust=robust,giveCenter=TRUE),
                           robust=getOption("robust"))
## S3 method for class 'princomp.aplus'
print(x,...)
## S3 method for class 'princomp.aplus'
plot(x,y=NULL,..., npcs=min(10,length(x$sdev)),
               type=c("screeplot","variance","biplot","loadings","relative"),
               main=NULL,scale.sdev=1)
## S3 method for class 'princomp.aplus'
predict(object,newdata,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="princomp.aplus_+3A_x">x</code></td>
<td>
<p>an aplus dataset (for princomp) or a result from
princomp.aplus</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_y">y</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_scores">scores</code></td>
<td>
<p>a logical indicating whether scores should be computed or not</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_npcs">npcs</code></td>
<td>
<p>the number of components to be drawn in the scree plot</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_type">type</code></td>
<td>
<p>type of the plot: <code>"screeplot"</code> is a lined screeplot,
<code>"variance"</code> is a boxplot-like screeplot, <code>"biplot"</code> is a
biplot, <code>"loadings"</code> displays the loadings as a 
<code><a href="#topic+barplot.acomp">barplot.acomp</a></code></p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_scale.sdev">scale.sdev</code></td>
<td>
<p>the multiple of sigma to use when plotting the loadings</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_main">main</code></td>
<td>
<p>title of the plot</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_object">object</code></td>
<td>
<p>a fitted princomp.aplus object</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_newdata">newdata</code></td>
<td>
<p>another amount dataset of class aplus</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_...">...</code></td>
<td>
<p>further arguments to pass to internally-called functions</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_covmat">covmat</code></td>
<td>
<p>provides the covariance matrix to be used for the
principle component analysis</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_center">center</code></td>
<td>
<p>provides the  be used for the computation of scores</p>
</td></tr>
<tr><td><code id="princomp.aplus_+3A_robust">robust</code></td>
<td>
<p>Gives the robustness type for the calculation of the
covariance matrix. See <code><a href="#topic+var.rmult">var.rmult</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As a metric euclidean space, the positive real space described in
<code><a href="#topic+aplus">aplus</a></code> has its own
principal component analysis, that can be performed either in terms of the
covariance matrix or the correlation matrix. However, since all parts in a composition 
or in an amount vector share a natural scaling, they do not need the 
standardization (which in fact would produce a loss of important information). 
For this reason, <code>princomp.aplus</code> works on the covariance matrix.
<br />
To aid the interpretation we added some extra functionality to a
normal <code>princomp(ilt(x))</code>. First of all the result contains as
additional information the amount representation of
returned vectors in the space of the data: the center as an amount
<code>Center</code>, and the loadings in terms of amounts to perturbe
with, either positively
(<code>Loadings</code>) or negatively (<code>DownLoadings</code>). The Up- and
DownLoadings are normalized to the number of parts  
and not to one to simplify the interpretation. A value of about one
means no change in the specific component. 
<br />
The plot routine provides screeplots (<code>type = "s"</code>,<code>type=
    "v"</code>), biplots (<code>type = "b"</code>), plots of the effect of
loadings (<code>type = "b"</code>) in <code>scale.sdev*sdev</code>-spread, and
loadings of pairwise (log-)ratios (<code>type = "r"</code>).
<br />
The interpretation of a screeplot does not differ from ordinary
screeplots. It shows the eigenvalues of the covariance matrix, which
represent the portions of variance explained by the principal
components. 
<br />
The interpretation of the the biplot uses, additionally to the
classical one, a compositional concept: The
differences between two arrowheads can be interpreted as log-ratios
between the two components represented by the arrows. 
<br />
The amount loading plot is introduced with this
package. The loadings of all component can be seen as an orthogonal basis
in the space of <code><a href="#topic+ilt">ilt</a></code>-transformed data. These vectors are displayed by a barplot with
their corresponding amounts. A portion of one means no change of this
part. This is equivalent to a zero loading in a real principal component analysis. 
<br />
The loadings plot can work in two different modes. If
<code>scale.sdev</code> is set to <code>NA</code> it displays the amount vector
being represented by the unit vector of loadings in the ilt-transformed space. If
<code>scale.sdev</code> is numeric we use this amount vector scaled by the
standard deviation of the respective component. 
<br />
The relative plot displays the <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> as a
barplot. The deviation from a unit bar shows the effect of each principal component 
on the respective ratio. The
interpretation of the ratios plot may only be done in an Aitchison-compositional framework 
(see <code><a href="#topic+princomp.acomp">princomp.acomp</a></code>).  
</p>


<h3>Value</h3>

<p><code>princomp</code> gives an object of type
<code>c("princomp.acomp","princomp")</code> with the following content:
</p>
<table>
<tr><td><code>sdev</code></td>
<td>
<p>the standard deviation of the principal components</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings (i.e., a matrix which
columns contain the eigenvectors). This is of class
<code>"loadings"</code>. </p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>the ilt-transformed vector of means used to center the dataset</p>
</td></tr>
<tr><td><code>Center</code></td>
<td>
<p>the <code><a href="#topic+aplus">aplus</a></code> vector of means used to center the dataset</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the scaling applied to each variable</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>if <code>scores = TRUE</code>, the scores of the supplied data
on the principal components. Scores are coordinates in a basis given by the principal
components and thus not compositions</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>not clearly understood</p>
</td></tr>
<tr><td><code>Loadings</code></td>
<td>
<p>vectors of amounts that represent a perturbation with the
vectors represented by the loadings of each of the factors</p>
</td></tr>
<tr><td><code>DownLoadings</code></td>
<td>
<p>vectors of amounts that represent a perturbation with the
inverses of the vectors represented by the loadings of each of the
factors</p>
</td></tr>
</table>
<p><code>predict</code> returns a matrix of scores of the observations in the
<code>newdata</code> dataset
<br />.
The other routines are mainly called for their side effect of plotting or
printing and return the object <code>x</code>.   
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+ilt">ilt</a></code>,<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> 
<code><a href="#topic+princomp.acomp">princomp.acomp</a></code>, <code><a href="#topic+princomp.rplus">princomp.rplus</a></code>,
<code><a href="#topic+barplot.aplus">barplot.aplus</a></code>, <code><a href="#topic+mean.aplus">mean.aplus</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pc &lt;- princomp(aplus(sa.lognormals5))
pc
summary(pc)
plot(pc)           #plot(pc,type="screeplot")
plot(pc,type="v")
plot(pc,type="biplot")
plot(pc,choice=c(1,3),type="biplot")
plot(pc,type="loadings")
plot(pc,type="loadings",scale.sdev=-1) # Downward
plot(pc,type="relative",scale.sdev=NA) # The directions
plot(pc,type="relative",scale.sdev=1) # one sigma Upward 
plot(pc,type="relative",scale.sdev=-1) # one sigma Downward
biplot(pc)
screeplot(pc)
loadings(pc)
relativeLoadings(pc,mult=FALSE)
relativeLoadings(pc)
relativeLoadings(pc,scale.sdev=1)
relativeLoadings(pc,scale.sdev=2)

pc$Loadings
pc$DownLoadings
barplot(pc$Loadings)
pc$sdev^2
cov(predict(pc,sa.lognormals5))
</code></pre>

<hr>
<h2 id='princomp.rcomp'>Principal component analysis for real compositions</h2><span id='topic+princomp.rcomp'></span><span id='topic+print.princomp.rcomp'></span><span id='topic+plot.princomp.rcomp'></span><span id='topic+predict.princomp.rcomp'></span>

<h3>Description</h3>

<p>A principal component analysis is done in real geometry
(i.e. cpt-transform) of the simplex. Some gimics simplify the
interpretation of the obtained components.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'rcomp'
princomp(x,...,scores=TRUE,center=attr(covmat,"center"),
                           covmat=var(x,robust=robust,giveCenter=TRUE),
                           robust=getOption("robust"))
 ## S3 method for class 'princomp.rcomp'
print(x,...)
 ## S3 method for class 'princomp.rcomp'
plot(x,y=NULL,...,npcs=min(10,length(x$sdev)),
        type=c("screeplot","variance","biplot","loadings","relative"),
        main=NULL,scale.sdev=1)
 ## S3 method for class 'princomp.rcomp'
predict(object,newdata,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="princomp.rcomp_+3A_x">x</code></td>
<td>
<p>an rcomp dataset (for princomp) or a result from
princomp.rcomp</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_y">y</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_scores">scores</code></td>
<td>
<p>a logical indicating whether scores should be computed or not</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_npcs">npcs</code></td>
<td>
<p>the number of components to be drawn in the scree plot</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_type">type</code></td>
<td>
<p>type of the plot: <code>"screeplot"</code> is a lined screeplot,
<code>"variance"</code> is a boxplot-like screeplot, <code>"biplot"</code> is a
biplot, <code>"loadings"</code> displays the loadings as a 
<code><a href="graphics.html#topic+barplot">barplot</a></code></p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_scale.sdev">scale.sdev</code></td>
<td>
<p>the multiple of sigma to use when plotting the loadings</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_main">main</code></td>
<td>
<p>title of the plot</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_object">object</code></td>
<td>
<p>a fitted princomp.rcomp object</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_newdata">newdata</code></td>
<td>
<p>another compositional dataset of class rcomp</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_...">...</code></td>
<td>
<p>further arguments to pass to internally-called functions</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_covmat">covmat</code></td>
<td>
<p>provides the covariance matrix to be used for the
principle component analysis</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_center">center</code></td>
<td>
<p>provides the  be used for the computation of scores</p>
</td></tr>
<tr><td><code id="princomp.rcomp_+3A_robust">robust</code></td>
<td>
<p>Gives the robustness type for the calculation of the
covariance matrix. See <code><a href="#topic+var.rmult">var.rmult</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mainly a <code>princomp(cpt(x))</code> is performed.  To avoid confusion, the
meaningless last principal component is removed.
<br />
The plot routine provides screeplots (<code>type = "s"</code>,<code>type=
    "v"</code>), biplots (<code>type = "b"</code>), plots of the effect of
loadings (<code>type = "b"</code>) in <code>scale.sdev*sdev</code>-spread, and
loadings of pairwise differences (<code>type = "r"</code>).
<br />
The interpretation of a screeplot does not differ from ordinary
screeplots. It shows the eigenvalues of the covariance matrix, which
represent the portions of variance explained by the principal
components. 
<br />
The interpretation of the biplot strongly differs from a classical one.
The relevant variables are not the arrows drawn (one for each component), 
but rather the links (i.e., the differences) between two
arrow heads, which represents the difference between the two
components represented by the arrows, or the transfer of mass from 
one to the other.
<br />
The compositional loading plot is more or less a standard
one. The loadings are displayed by a barplot as positve and
negative changes of amounts.
<br />
The loading plot can work in
two different modes: If
<code>scale.sdev</code> is set to <code>NA</code> it displays the composition
being represented by the unit vector of loadings in cpt-transformed space. If
<code>scale.sdev</code> is numeric we use this composition scaled by the
standard deviation of the respective component. 
<br />
The relative plot displays the <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> as a
barplot. The deviation from a unit bar shows the effect of each
principal component on the respective differences. 
</p>


<h3>Value</h3>

<p><code>princomp</code> gives an object of type
<code>c("princomp.rcomp","princomp")</code> with the following content:

</p>
<table>
<tr><td><code>sdev</code></td>
<td>
<p>the standard deviation of the principal components.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings (i.e., a matrix which
columns contain the eigenvectors). This is of class
<code>"loadings"</code>. The last eigenvalue is removed since it should
contain the irrelevant scaling.</p>
</td></tr>
<tr><td><code>Loadings</code></td>
<td>
<p>the loadings as an rmult-object</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>the cpt-transformed vector of means used to center the dataset</p>
</td></tr>
<tr><td><code>Center</code></td>
<td>
<p>the <code><a href="#topic+rcomp">rcomp</a></code> vector of means used to center the dataset</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the scaling applied to each variable</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>if <code>scores = TRUE</code>, the scores of the supplied data
on the principal components. Scores are coordinates in a basis given by the principal
components and thus not compositions</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>not clearly understood</p>
</td></tr>

</table>
<p><code>predict</code> returns a matrix of scores of the observations in the
<code>newdata</code> dataset.
The other routines are mainly called for their side effect of plotting or
printing and return the object <code>x</code>.   
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+cpt">cpt</a></code>,<code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> 
<code><a href="#topic+princomp.acomp">princomp.acomp</a></code>, <code><a href="#topic+princomp.rplus">princomp.rplus</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pc &lt;- princomp(rcomp(sa.lognormals5))
pc
summary(pc)
plot(pc)           #plot(pc,type="screeplot")
plot(pc,type="v")
plot(pc,type="biplot")
plot(pc,choice=c(1,3),type="biplot")
plot(pc,type="loadings")
plot(pc,type="loadings",scale.sdev=-1) # Downward
plot(pc,type="relative",scale.sdev=NA) # The directions
plot(pc,type="relative",scale.sdev=1) # one sigma Upward 
plot(pc,type="relative",scale.sdev=-1) # one sigma Downward
biplot(pc)
screeplot(pc)
loadings(pc)
relativeLoadings(pc,mult=FALSE)
relativeLoadings(pc)
relativeLoadings(pc,scale.sdev=1)
relativeLoadings(pc,scale.sdev=2)

pc$sdev^2
cov(predict(pc,sa.lognormals5))
</code></pre>

<hr>
<h2 id='princomp.rmult'>Principal component analysis for real data</h2><span id='topic+princomp.rmult'></span>

<h3>Description</h3>

<p>Performs a principal component analysis for datasets of type rmult.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rmult'
princomp(x,cor=FALSE,scores=TRUE,
                   covmat=var(rmult(x[subset,]),robust=robust,giveCenter=TRUE),
                   center=attr(covmat,"center"),  subset = rep(TRUE, nrow(x)),
                   ..., robust=getOption("robust"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="princomp.rmult_+3A_x">x</code></td>
<td>
<p>a rmult-dataset</p>
</td></tr>
<tr><td><code id="princomp.rmult_+3A_...">...</code></td>
<td>
<p>Further arguments to call <code><a href="stats.html#topic+princomp.default">princomp.default</a></code></p>
</td></tr>
<tr><td><code id="princomp.rmult_+3A_cor">cor</code></td>
<td>
<p>logical: shall the computation be based on correlations
rather than covariances?</p>
</td></tr>
<tr><td><code id="princomp.rmult_+3A_scores">scores</code></td>
<td>
<p>logical: shall scores be computed?</p>
</td></tr>
<tr><td><code id="princomp.rmult_+3A_covmat">covmat</code></td>
<td>
<p>provides the covariance matrix to be used for the
principle component analysis</p>
</td></tr>
<tr><td><code id="princomp.rmult_+3A_center">center</code></td>
<td>
<p>provides the  be used for the computation of scores</p>
</td></tr>
<tr><td><code id="princomp.rmult_+3A_subset">subset</code></td>
<td>
<p>A rowindex to x giving the columns that should be used
to estimate the variance.</p>
</td></tr>
<tr><td><code id="princomp.rmult_+3A_robust">robust</code></td>
<td>
<p>Gives the robustness type for the calculation of the
covariance matrix. See <code><a href="#topic+var.rmult">var.rmult</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function just does <code>princomp(unclass(x),...,scale=scale)</code>
and is only here for convenience. 
</p>


<h3>Value</h3>

<p>An object of type <code>princomp</code> with the following fields
</p>
<table>
<tr><td><code>sdev</code></td>
<td>
<p>the standard deviation of the principal components.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings (i.e., a matrix whose
columns contain the eigenvectors). This is of class
<code>"loadings"</code>.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>the mean that was substracted from the data set</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the scaling applied to each variable</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>if <code>scores = TRUE</code>, the scores of the supplied data
on the principal components. Scores are coordinates in a basis given by the 
principal components.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>Not clearly understood</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+princomp.rplus">princomp.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pc &lt;- princomp(rmult(sa.lognormals5))
pc
summary(pc)
plot(pc) 
screeplot(pc)
screeplot(pc,type="l")
biplot(pc)
biplot(pc,choice=c(1,3))
loadings(pc)
plot(loadings(pc))
pc$sdev^2
cov(predict(pc,sa.lognormals5))
</code></pre>

<hr>
<h2 id='princomp.rplus'>Principal component analysis for real amounts</h2><span id='topic+princomp.rplus'></span><span id='topic+print.princomp.rplus'></span><span id='topic+plot.princomp.rplus'></span><span id='topic+predict.princomp.rplus'></span>

<h3>Description</h3>

<p>A principal component analysis is done in real geometry
(i.e. using iit-transform).   
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ## S3 method for class 'rplus'
princomp(x,...,scores=TRUE,center=attr(covmat,"center"),
                           covmat=var(x,robust=robust,giveCenter=TRUE),
                           robust=getOption("robust"))
 ## S3 method for class 'princomp.rplus'
print(x,...)
 ## S3 method for class 'princomp.rplus'
plot(x,y=NULL,...,npcs=min(10,length(x$sdev)),
          type=c("screeplot","variance","biplot","loadings","relative"),
          main=NULL,scale.sdev=1)
 ## S3 method for class 'princomp.rplus'
predict(object,newdata,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="princomp.rplus_+3A_x">x</code></td>
<td>
<p>an rplus-dataset (for princomp) or a result from
princomp.rplus</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_y">y</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_scores">scores</code></td>
<td>
<p>a logical indicating whether scores should be computed or not</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_npcs">npcs</code></td>
<td>
<p>the number of components to be drawn in the scree plot</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_type">type</code></td>
<td>
<p>type of the plot: <code>"screeplot"</code> is a lined screeplot,
<code>"variance"</code> is a boxplot-like screeplot, <code>"biplot"</code> is a
biplot, <code>"loadings"</code> displays the loadings as a 
<code><a href="graphics.html#topic+barplot">barplot</a></code></p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_scale.sdev">scale.sdev</code></td>
<td>
<p>the multiple of sigma to use when plotting the loadings</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_main">main</code></td>
<td>
<p>title of the plot</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_object">object</code></td>
<td>
<p>a fitted princomp.rplus object</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_newdata">newdata</code></td>
<td>
<p>another amount dataset of class rcomp</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_...">...</code></td>
<td>
<p>further arguments to pass to internally-called functions</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_covmat">covmat</code></td>
<td>
<p>provides the covariance matrix to be used for the
principle component analysis</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_center">center</code></td>
<td>
<p>provides the  be used for the computation of scores</p>
</td></tr>
<tr><td><code id="princomp.rplus_+3A_robust">robust</code></td>
<td>
<p>Gives the robustness type for the calculation of the
covariance matrix. See <code><a href="#topic+var.rmult">var.rmult</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mainly a <code>princomp(iit(x))</code> is performed. Note all parts in a composition 
or in an amount vector share a natural scaling. Therefore, they do not need any 
preliminary standardization (which in fact would produce a loss of important information). 
For this reason, <code>princomp.rplus</code> works on the covariance matrix.
<br />
The plot routine provides screeplots (<code>type = "s"</code>,<code>type=
    "v"</code>), biplots (<code>type = "b"</code>), plots of the effect of
loadings (<code>type = "b"</code>) in <code>scale.sdev*sdev</code>-spread, and
loadings of pairwise differences (<code>type = "r"</code>).
<br />
The interpretation of a screeplot does not differ from ordinary
screeplots. It shows the eigenvalues of the covariance matrix, which
represent the portions of variance explained by the principal
components. 
<br />
The interpretation of the biplot uses, additionally to the
classical interperation, a compositional concept: the
differences between two arrowheads can be interpreted as the shift of mass 
between the two components represented by the arrows. 
<br />
The amount loading plot is more or less a standard
loadings plot. The loadings are displayed by a barplot as positive and
negative changes of amounts.
<br />
The loadings plot can work in two different modes: If
<code>scale.sdev</code> is set to <code>NA</code> it displays the amount vector
being represented by the unit vector of loadings in the iit-transformed space. If
<code>scale.sdev</code> is numeric we use this amount vector scaled by the
standard deviation of the respective component. 
<br />
The relative plot displays the <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> as a
barplot. The deviation from a unit bar shows the effect of 
each principal component on the respective differences. 
</p>


<h3>Value</h3>

<p><code>princomp</code> gives an object of type
<code>c("princomp.rcomp","princomp")</code> with the following content:
</p>
<table>
<tr><td><code>sdev</code></td>
<td>
<p>the standard deviation of the principal components</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of variable loadings (i.e., a matrix which
columns contain the eigenvectors). This is of class
<code>"loadings"</code></p>
</td></tr>
<tr><td><code>Loadings</code></td>
<td>
<p>the loadings as an <code>"<a href="#topic+rmult">rmult</a>"</code>-object</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>the iit-transformed vector of means used to center the dataset</p>
</td></tr>
<tr><td><code>Center</code></td>
<td>
<p>the <code><a href="#topic+rplus">rplus</a></code> vector of means used to center the dataset 
(<code>center</code> and <code>Center</code> have no difference, except that the second has a class)</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the scaling applied to each variable</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>if <code>scores = TRUE</code>, the scores of the supplied data
on the principal components. Scores are coordinates in a basis given by the principal
components and thus not compositions</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>not clearly understood</p>
</td></tr>
</table>
<p><code>predict</code> returns a matrix of scores of the observations in the
<code>newdata</code> dataset.
<br />
The other routines are mainly called for their side effect of plotting or
printing and return the object <code>x</code>.   
</p>


<h3>See Also</h3>

<p><code><a href="#topic+iit">iit</a></code>,<code><a href="#topic+rplus">rplus</a></code>, <code><a href="#topic+relativeLoadings">relativeLoadings</a></code> 
<code><a href="#topic+princomp.rcomp">princomp.rcomp</a></code>, <code><a href="#topic+princomp.aplus">princomp.aplus</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pc &lt;- princomp(rplus(sa.lognormals5))
pc
summary(pc)
plot(pc)           #plot(pc,type="screeplot")
plot(pc,type="v")
plot(pc,type="biplot")
plot(pc,choice=c(1,3),type="biplot")
plot(pc,type="loadings")
plot(pc,type="loadings",scale.sdev=-1) # Downward
plot(pc,type="relative",scale.sdev=NA) # The directions
plot(pc,type="relative",scale.sdev=1) # one sigma Upward 
plot(pc,type="relative",scale.sdev=-1) # one sigma Downward
biplot(pc)
screeplot(pc)
loadings(pc)
relativeLoadings(pc,mult=FALSE)
relativeLoadings(pc)
relativeLoadings(pc,scale.sdev=1)
relativeLoadings(pc,scale.sdev=2)

pc$sdev^2
cov(predict(pc,sa.lognormals5))
</code></pre>

<hr>
<h2 id='print.acomp'>Printing compositional data.</h2><span id='topic+print.acomp'></span><span id='topic+print.rcomp'></span><span id='topic+print.rplus'></span><span id='topic+print.aplus'></span>

<h3>Description</h3>

<p>Prints compositional objects with appropriate missing encodings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
print(x,...,replace0=TRUE)
## S3 method for class 'aplus'
print(x,...,replace0=TRUE)
## S3 method for class 'rcomp'
print(x,...,replace0=FALSE)
## S3 method for class 'rplus'
print(x,...,replace0=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.acomp_+3A_x">x</code></td>
<td>
<p>a compositional object</p>
</td></tr>
<tr><td><code id="print.acomp_+3A_...">...</code></td>
<td>
<p>further arguments to <code>print.default</code></p>
</td></tr>
<tr><td><code id="print.acomp_+3A_replace0">replace0</code></td>
<td>
<p>logical: Shall 0 be treated as &quot;Below detection Limit&quot;
with unkown limit.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Missings are displayed with an appropriate encoding:
</p>

<dl>
<dt>MAR</dt><dd><p>Missing at random: The value is missing independently of
its true value.</p>
</dd>
<dt>MNAR</dt><dd><p>Missing NOT at random: The value is missing dependently of
its true value, but without a known systematic. Maybe a better name
would be: Value dependen missingness.</p>
</dd>
<dt>BDL</dt><dd><p>below detection limit (with unspecified detection limit):
The value is missing because it was below an unkown detection limit.</p>
</dd>
<dt>&lt;Detectionlimit</dt><dd><p>below detection limit (with specified detection limit):
The value is below the displayed detection limit. </p>
</dd>
<dt>SZ</dt><dd><p>Structural Zero: A true value is either bound to be zero or
does not exist for structural
nonrandom reasons. E.g. the
portion of pregnant girls at a boys school.</p>
</dd>
<dt>ERR</dt><dd><p>Error: An illegal encoding value was found in the
object. </p>
</dd>
</dl>



<h3>Value</h3>

<p>An invisible version of x.
</p>


<h3>Missing Policy</h3>

<p>The policy of treatment of zeroes, missing values and values 
below detecion limit is explained in depth in <a href="#topic+compositions.missings">compositions.missings</a>. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Boogaart, K.G. v.d., R. Tolosana-Delgado, M. Bren (2006) Concepts for 
handling of zeros and missing values in compositional data, in: 
E. Pirard (ed.) (2006)Proceedings of the IAMG'2006 Annual Conference on 
&quot;Quantitative Geology from multiple sources&quot;, September 2006, Liege, 
Belgium,, S07-01, 4pages, ISBN 978-2-9600644-0-7
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+acomp">acomp</a></code>, 
<code><a href="#topic+plot.acomp">plot.acomp</a></code>, <code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code>,
<code><a href="#topic+barplot.acomp">barplot.acomp</a></code>, <code><a href="#topic+mean.acomp">mean.acomp</a></code>,
<code><a href="#topic+var.acomp">var.acomp</a></code>, <code><a href="#topic+variation.acomp">variation.acomp</a></code>,
<code><a href="#topic+zeroreplace">zeroreplace</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
mydata &lt;- simulateMissings(sa.groups5,dl=0.01,knownlimit=TRUE,
                     MAR=0.05,MNARprob=0.05,SZprob=0.05)
mydata[1,1]&lt;-BDLvalue
print(aplus(mydata))
print(aplus(mydata),digits=3)
print(acomp(mydata))
print(rplus(mydata))
print(rcomp(mydata))

</code></pre>

<hr>
<h2 id='pwlr'>Pairwise log ratio transform</h2><span id='topic+pwlr'></span><span id='topic+pwlrInv'></span>

<h3>Description</h3>

<p>Compute the pairwise log ratio transform of a (dataset of)
composition(s), and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>      pwlr( x, as.rmult=FALSE, as.data.frame=!as.rmult, ...)
      pwlrInv( z, orig=gsi.orig(z))
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwlr_+3A_x">x</code></td>
<td>
<p>a composition, not necessarily closed</p>
</td></tr>
<tr><td><code id="pwlr_+3A_z">z</code></td>
<td>
<p>the pwlr-transform of a composition, thus a [D(D-1)/2]-dimensional
real vector, or a matrix with such many columns</p>
</td></tr>
<tr><td><code id="pwlr_+3A_as.rmult">as.rmult</code></td>
<td>
<p>logical; should the output be produced as an rmult object?</p>
</td></tr>
<tr><td><code id="pwlr_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical; should be as a data.frame? if both are false, rmult will be taken</p>
</td></tr>
<tr><td><code id="pwlr_+3A_...">...</code></td>
<td>
<p>currently unused</p>
</td></tr>
<tr><td><code id="pwlr_+3A_orig">orig</code></td>
<td>
<p>the original composition, to check consistency and recover component names</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The pwlr-transform maps a composition in the $D$-part Aitchison-simplex
isometrically to a $D(D-1)/2$ dimensonal euclidian vector, computing each possible 
logratio (accounting for the fact that $log(A/B)=-log(B/A)$, and therefore only one of 
them is necessary). The data can then
be analysed in this transformation by multivariate
analysis tools not relying on the invertibility of the covariance function. 
The interpretation of
the results is relatively simple, since each component captures the behaviour of the 
simple ratio between two party. However redundance between them is extremely high, 
and any of  <code><a href="#topic+alr">alr</a></code>, <code><a href="#topic+clr">clr</a></code> or <code><a href="#topic+ilr">ilr</a></code> transformations 
may be preferred in most applications.<br />
</p>
<p>The pairwise logratio transform is given by
</p>
<p style="text-align: center;"><code class="reqn"> pwlr(x)_{ij} := \ln\frac{x_i}{x_j}  </code>
</p>
<p>.
</p>
<p>The inverse requires some explanation, because of the redundance between pwlr scores. 
Note that for any three components $A,B,C$ it holds that $log(A/C)=log(A/B)+log(B/C)$.
So, any vector of $D(D-1)/2$ coefficients will not be necessarily a valid pwlr-transformed 
composition: if these coefficients do not satisfy that kind of relations, the vector is, 
strictly speaking, not a pwlr and should not be inverted. Nevertheless, the function gives 
a least-squares inversion, as proposed by Tolosana-Delgado and von Eynatten (2009).
</p>


<h3>Value</h3>

<p><code>pwlr</code> gives the pairwise log ratio transform; accepts a compositional dataset
<code>pwlrInv</code> gives a closed composition with the given wplr-transform; accepts a dataset
</p>


<h3>Author(s)</h3>

<p>R. Tolosana-Delgado <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.
</p>
<p>Tolosana-Delgado, R. and H. von Eynatten (2009); Grain-size control 
on petrographic composition of sediments: compositional regression 
and rounded zeroes. <em>Mathematical Geosciences</em>: 41(8): 869-886. 
doi: <a href="https://doi.org/10.1007/s11004-009-9216-6">10.1007/s11004-009-9216-6</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+alr">alr</a></code>,<code><a href="#topic+apt">apt</a></code>,
<a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- pwlr(c(1,2,3)))
pwlrInv(tmp)
</code></pre>

<hr>
<h2 id='pwlrPlot'>Plots of pairwise logratio against a covariable. </h2><span id='topic+pwlrPlot'></span><span id='topic+pwlrplot'></span>

<h3>Description</h3>

<p>Creates a matrix of plots, with each pairwise logratio against a covariable. The covariable
can be numeric or factor, and play the role of X or Y axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwlrPlot(x,y,...,add.line=FALSE,line.col=2,add.robust=FALSE,rob.col=4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwlrPlot_+3A_x">x</code></td>
<td>
<p>a vector, a column of a data.frame, or an acomp representing the first set
of things to be displayed. Either <code>x</code> or <code>y</code> must be an 
<code><a href="#topic+acomp">acomp</a></code> object, and the other must be a covariable. 
Both factors and continuous covariables allowed here.</p>
</td></tr>
<tr><td><code id="pwlrPlot_+3A_y">y</code></td>
<td>
<p>a vector, a column of a data.frame, or an acomp representing the first set
of things to be displayed. Either <code>x</code> or <code>y</code> must be an 
<code><a href="#topic+acomp">acomp</a></code> object, and the other must be a covariable. 
Factors to be used here with caution.</p>
</td></tr>
<tr><td><code id="pwlrPlot_+3A_...">...</code></td>
<td>
<p>furter parameters to the panel function</p>
</td></tr>
<tr><td><code id="pwlrPlot_+3A_add.line">add.line</code></td>
<td>
<p>logical, to control the addition of a regression line
in each panel. Ignored if covariable is a factor.</p>
</td></tr>
<tr><td><code id="pwlrPlot_+3A_line.col">line.col</code></td>
<td>
<p>in case the regression line is added, which color should be
used? Defaults to red. </p>
</td></tr>
<tr><td><code id="pwlrPlot_+3A_add.robust">add.robust</code></td>
<td>
<p>logical, to control the addition of a robust regression line
in each panel. Ignored if covariable is a factor. This is nowadays 
based on <code><a href="robustbase.html#topic+lmrob">lmrob</a></code>, but this can change in the future.</p>
</td></tr>
<tr><td><code id="pwlrPlot_+3A_rob.col">rob.col</code></td>
<td>
<p>in case the robust regression line is added, which color should be
used? Defaults to blue. </p>
</td></tr>
</table>


<h3>Details</h3>

<p> This function generates a matrix of plots of all possible pairwise
logratios of the <code><a href="#topic+acomp">acomp</a></code> argument, plotted against a covariable. The 
covariable can be a factor or a numeric vector, or a column of a matrix or data.frame.
Covariable and composition can both be represented in X or Y axis:
a factor on X axis generates a <code><a href="graphics.html#topic+boxplot">boxplot</a></code>; a factor on Y axis generates a
<code><a href="graphics.html#topic+spineplot">spineplot</a></code>; if the covariable is numeric, a default scatterplot is generated.
All dot arguments are passed to these plotting functions. In any of these cases, the diagram 
shows the logratio of the component in the row divided by the component in
the column. In the case of a numeric covariable, both classical and
robust regression lines can be added.
</p>


<h3>Author(s)</h3>

<p>Raimon
Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Boogaart, K.G. v.d. , R. Tolosana (2008) Mixing Compositions and Other
scales, Proceedings of CodaWork 08.
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a>
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork08/">https://ima.udg.edu/Activitats/CoDaWork08/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.aplus">plot.aplus</a></code>, <code><a href="#topic+pairwisePlot">pairwisePlot</a></code>, <code><a href="graphics.html#topic+boxplot">boxplot</a></code>, <code><a href="graphics.html#topic+spineplot">spineplot</a></code>, <code><a href="graphics.html#topic+plot.default">plot.default</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Hydrochem)
xc = acomp(Hydrochem[,c("Ca","Mg","Na","K")])
fk = Hydrochem$River
pH = -log10(Hydrochem$H)
## x=acomp, y=factor 
pwlrPlot(xc, fk, border=2:5)
## x=factor, y=acomp
pwlrPlot(fk,xc, col=2:5)
## x=acomp, y=numeric, with colors by river
pwlrPlot(xc, pH, col=as.integer(fk)+1)
## x=numeric, y=acomp, with line
pwlrPlot(pH, xc, add.robust=TRUE)

</code></pre>

<hr>
<h2 id='qqnorm'>Normal quantile plots for compositions and amounts</h2><span id='topic+qqnorm.acomp'></span><span id='topic+qqnorm.rcomp'></span><span id='topic+qqnorm.rplus'></span><span id='topic+qqnorm.aplus'></span><span id='topic+vp.qqnorm'></span>

<h3>Description</h3>

<p>The plots allow to check the normal distribution of multiple
univaritate marginals by normal quantile-quantile plots. 
For the different interpretations of amount data a different type of
normality is assumed and checked. When an alpha-level is given the
marginal displayed in each panel is checked for normality. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
qqnorm(y,fak=NULL,...,panel=vp.qqnorm,alpha=NULL)
## S3 method for class 'rcomp'
qqnorm(y,fak=NULL,...,panel=vp.qqnorm,alpha=NULL)
## S3 method for class 'aplus'
qqnorm(y,fak=NULL,...,panel=vp.qqnorm,alpha=NULL)
## S3 method for class 'rplus'
qqnorm(y,fak=NULL,...,panel=vp.qqnorm,alpha=NULL)
vp.qqnorm(x,y,...,alpha=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qqnorm_+3A_y">y</code></td>
<td>
<p>a dataset</p>
</td></tr>
<tr><td><code id="qqnorm_+3A_fak">fak</code></td>
<td>
<p>a factor to split the dataset, not yet implemented in aplus
and rplus</p>
</td></tr>
<tr><td><code id="qqnorm_+3A_panel">panel</code></td>
<td>
<p>the panel function to be used or a list of multiple panel
functions</p>
</td></tr>
<tr><td><code id="qqnorm_+3A_alpha">alpha</code></td>
<td>
<p>the alpha level of a test for normality to be performed
for each of the displayed marginals. The levels are adjusted for
multiple testing with a Bonferroni-correction (i.e. dividing each of
the alpha-level by the number of test performed)</p>
</td></tr>
<tr><td><code id="qqnorm_+3A_...">...</code></td>
<td>
<p>further graphical parameters</p>
</td></tr>
<tr><td><code id="qqnorm_+3A_x">x</code></td>
<td>
<p>used by pairs only. Internal use</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>qqnorm.rplus</code> and <code>qqnorm.rcomp</code> display qqnorm plots of
individual amounts (on the diagonal), of pairwise differences of amounts 
(above the diagonal) and of pairwise sums of amounts (below the
diagonal).
<br />
<code>qqnorm.aplus</code>  displays qqnorm-plots of
individual log-amounts (on the diagonal), of pairwise log-ratios of
amounts (above the diagonal) and of pairwise sums of log amount (below the
diagonal).
<br />
<code>qqnorm.acomp</code> displays qqnorm-plots of pairwise log-ratios of
amounts in all of diagonal panels. Nothing is displayed on the
diagonal.
<br />
In all cases a joint normality of the original data in the selected
framework would imply normality in all displayed marginal
distributions (although the reciprocal is in general not true!).
<br />
The marginal normality can be checked in each of the plots using a
<code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code>, by specifying an alpha level. The
alpha level is corrected for multiple testing. Plots displaying a
marginal distribution significantly deviating from a normal
distribution at that alpha level are marked by a red exclamation mark.
<br />
<code>vp.qqnorm</code> is internally used as a panel function to make high dimensional
plots. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>, <code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code>,
<code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>, <code><a href="#topic+rnorm.rcomp">rnorm.rcomp</a></code>, 
<code><a href="#topic+rnorm.aplus">rnorm.aplus</a></code>, <code><a href="#topic+rnorm.rplus">rnorm.rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
qqnorm(acomp(sa.lognormals),alpha=0.05)
qqnorm(rcomp(sa.lognormals),alpha=0.05)
qqnorm(aplus(sa.lognormals),alpha=0.05)
qqnorm(rplus(sa.lognormals),alpha=0.05)
</code></pre>

<hr>
<h2 id='R2'>R square</h2><span id='topic+R2'></span><span id='topic+R2.lm'></span><span id='topic+R2.default'></span><span id='topic+Rsquare'></span>

<h3>Description</h3>

<p>The R2 measure of determination for linear models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R2(object,...)
## S3 method for class 'lm'
R2(object,...,adjust=TRUE,ref=0)
## Default S3 method:
R2(object,...,ref=0)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R2_+3A_object">object</code></td>
<td>
<p> a statistical model</p>
</td></tr>
<tr><td><code id="R2_+3A_...">...</code></td>
<td>
<p>further not yet used parameters</p>
</td></tr>
<tr><td><code id="R2_+3A_adjust">adjust</code></td>
<td>
<p>Logical, whether the estimate of R2 should be adjusted
for the degrees of freedom of the model.</p>
</td></tr>
<tr><td><code id="R2_+3A_ref">ref</code></td>
<td>
<p>A reference model for computation of a relative <code class="reqn">R^2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">R^2</code> measure of determination is defined as:
</p>
<p style="text-align: center;"><code class="reqn">R^2=1-\frac{var(residuals)}{var(data)}</code>
</p>

<p>and provides the portion of variance explained by the model. It is a
number between 0 and 1, where 1 means the model perfectly explains the
data and 0 means that the model has no better explanation of the data
than a constant mean. In case of multivariate models metric variances
are used. 
</p>
<p>If a reference model is given by <code>ref</code>, the variance of the
residuals of that models rather than the variance of the data is
used. The value of such a relative <code class="reqn">R^2</code> estimates how much
of the residual variance is explained.
</p>
<p>If <code>adjust=TRUE</code> the unbiased estiamators for the variances are
used, to avoid the automatisme that a more parameters automatically
lead to a higher <code class="reqn">R^2</code>. 
</p>


<h3>Value</h3>

<p>The R2 measure of determination. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+mvar">mvar</a></code>, <code><a href="stats.html#topic+AIC">AIC</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Orange)
R2(lm(circumference~age,data=Orange))
R2(lm(log(circumference)~log(age),data=Orange))
</code></pre>

<hr>
<h2 id='rAitchison'>Aitchison Distribution</h2><span id='topic+rAitchison'></span><span id='topic+dAitchison'></span><span id='topic+AitchisonDistributionIntegrals'></span>

<h3>Description</h3>

<p>The Aitchison distribution is a class of distributions the simplex,
containing the normal and the Dirichlet as subfamilies.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dAitchison(x,
           theta=alpha+sigma %*% clr(mu),
           beta=-1/2*gsi.svdinverse(sigma),
           alpha=mean(theta),
           mu=clrInv(c(sigma%*%(theta-alpha))),
           sigma=-1/2*gsi.svdinverse(beta),
           grid=30,
           realdensity=FALSE,
           expKappa=AitchisonDistributionIntegrals(theta,beta,
                        grid=grid,mode=1)$expKappa)
rAitchison(n,
           theta=alpha+sigma %*% clr(mu),
           beta=-1/2*gsi.svdinverse(sigma),
           alpha=mean(theta),
           mu=clrInv(c(sigma%*%(theta-alpha))),
           sigma=-1/2*gsi.svdinverse(beta), withfit=FALSE)
AitchisonDistributionIntegrals(
           theta=alpha+sigma %*% clr(mu),
           beta=-1/2*gsi.svdinverse(sigma),
           alpha=mean(theta),
           mu=clrInv(c(sigma%*%(theta-alpha))),
           sigma=-1/2*gsi.svdinverse(beta),
           grid=30,
           mode=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rAitchison_+3A_x">x</code></td>
<td>
<p>acomp-compositions the density should be computed for.</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_n">n</code></td>
<td>
<p>integer: number of datasets to be simulated</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_theta">theta</code></td>
<td>
<p>numeric vector: Location parameter vector </p>
</td></tr>
<tr><td><code id="rAitchison_+3A_beta">beta</code></td>
<td>
<p>matrix: Spread parameter matrix (clr or ilr)</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_alpha">alpha</code></td>
<td>
<p>positiv scalar: departure from normality parameter (positive scalar)</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_mu">mu</code></td>
<td>
<p>acomp-composition, normal reference mean parameter composition</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_sigma">sigma</code></td>
<td>
<p> matrix: normal reference variance matrix (clr or ilr)</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_grid">grid</code></td>
<td>
<p> integer: number of discretisation points along each side of the simplex </p>
</td></tr>
<tr><td><code id="rAitchison_+3A_realdensity">realdensity</code></td>
<td>
<p>logical: if true the density is given with respect
to the Haar measure of the real simplex, if false the density is
given with respect to the Aitchison measure of the simplex.</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_mode">mode</code></td>
<td>
<p>integer: desired output:
-1: Compute nothing, only transform parameters,<br />
0: Compute only oneIntegral and kappaIntegral,<br />
1: compute also the clrMean,<br />
2: compute also the clrSqExpectation,<br />
3: same as 2, but compute clrVar instead of clrSqExpectation<br />
</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_expkappa">expKappa</code></td>
<td>
<p>The closing divisor of the density</p>
</td></tr>
<tr><td><code id="rAitchison_+3A_withfit">withfit</code></td>
<td>
<p>Should a pre-spliting of the Aitchison density be used for 
simulation?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Aitchison Distribution is a joint generalisation of the Dirichlet
Distribution and the additive log-normal distribution (or normal on the
simplex). It can be parametrized by Ait(theta,beta) or by
Ait(alpha,mu,Sigma). Actually, beta and Sigma can be easily
transformed into each other, such that only one of them is
necessary. Parameter theta is a vector in <code class="reqn">R^D</code>, alpha is its sum, mu is a
composition in <code class="reqn">S^D</code>, and beta and sigma are symmetric matrices, which
can either be expressed  in ilr or clr space.
The parameters are transformed as
</p>
<p style="text-align: center;"><code class="reqn">\beta=-1/2 \Sigma^{-1}</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\theta=clr(\mu)\Sigma+\alpha (1,\ldots,1)^t</code>
</p>

<p>The distribution exists, if either,
<code class="reqn">\alpha\geq 0</code> and Sigma is positive definite (or beta
negative definite) in
ilr-coordinates, or if each theta is strictly positive and Sigma has
at least one positive eigenvalue (or beta has at least one negative
eigenvalue). The simulation procedure currently only works with the
first case. 
<br />
AitchisonDistributionIntegral is a convenience function to compute the
parameter transformation and several functions of these
parameters. This is done by numerical integration over a
multinomial simplex lattice of D parts with <code>grid</code> many elements
(see <code><a href="combinat.html#topic+xsimplex">xsimplex</a></code>). 
<br />
The density of the Aitchison distribution is given by:
</p>
<p style="text-align: center;"><code class="reqn">f(x,\theta,\beta)=exp((\theta-1)^t \log(x)+ilr(x)^t \beta ilr(x))/exp(\kappa_{Ait(\theta,\beta)})</code>
</p>

<p>with respect to the classical Haar measure on the simplex, and as
</p>
<p style="text-align: center;"><code class="reqn">f(x,\theta,\beta)=exp(\theta^t \log(x)+ilr(x)^t \beta
  ilr(x))/exp(\kappa_{Ait(\theta,\beta)})</code>
</p>
<p> with respect to the Aitchison
measure of the simplex. The closure constant expKappa is computed
numerically, in <code>AitchisonDistributionIntegrals</code>.
</p>
<p>The random composition generation is done by rejection sampling based on
an optimally fitted additive logistic normal distribution. Thus, it only
works if the correponding Sigma in ilr would be positive definite.  
</p>


<h3>Value</h3>

<table>
<tr><td><code>dAitchison</code></td>
<td>
<p>Returns the density of the Aitchison distribution
evaluated at x as a numeric vector.</p>
</td></tr> 
<tr><td><code>rAitchison</code></td>
<td>
<p>Returns a sample of size n of simulated compostions
as an acomp object.</p>
</td></tr> 
<tr><td><code>AitchisondistributionIntegrals</code></td>
<td>
<p>Returns a list with
</p>

<dl>
<dt>theta</dt><dd><p>the theta parameter given or computed</p>
</dd>
<dt>beta</dt><dd><p>the beta parameter given or computed</p>
</dd>
<dt>alpha</dt><dd><p>the alpha parameter given or computed</p>
</dd>
<dt>mu</dt><dd><p>the mu parameter given or computed</p>
</dd>
<dt>sigma</dt><dd><p>the sigma parameter given or computed</p>
</dd>
<dt>expKappa</dt><dd><p>the integral over the density without closing
constant. I.e. the inverse of the closing constant and the exp
of <code class="reqn">\kappa_{Ait(\theta,\beta)}</code></p>
</dd>
<dt>kappaIntegral</dt><dd><p>The expected value of the mean of the logs of
the components as numerically computed</p>
</dd>
<dt>clrMean</dt><dd><p>The mean of the clr transformed random variable,
computed numerically</p>
</dd>
<dt>clrSqExpectation</dt><dd><p>The expectation of <code class="reqn">clr(X)clr(X)^t</code>
computed numerically.</p>
</dd>
<dt>clrVar</dt><dd><p>The variance covariance matrix of clr(X),
computed numerically</p>
</dd>
</dl>

</td></tr> 
</table>


<h3>Note</h3>

<p>The simulation procedure currently only works with a
positive definite Sigma. You need a relatively high grid constant for
precise values in the numerical integration.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart, R. Tolosana-Delgado <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runif.acomp">runif.acomp</a></code>, <code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>,
<code><a href="#topic+rDirichlet.acomp">rDirichlet.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(erg&lt;-AitchisonDistributionIntegrals(c(-1,3,-2),ilrvar2clr(-diag(c(1,2))),grid=20))

(myvar&lt;-with(erg, -1/2*ilrvar2clr(solve(clrvar2ilr(beta)))))
(mymean&lt;-with(erg,myvar%*%theta))

with(erg,myvar-clrVar)
with(erg,mymean-clrMean)

</code></pre>

<hr>
<h2 id='ratioLoadings'>Loadings of relations of two amounts</h2><span id='topic+relativeLoadings'></span><span id='topic+relativeLoadings.princomp.acomp'></span><span id='topic+relativeLoadings.princomp.aplus'></span><span id='topic+relativeLoadings.princomp.rcomp'></span><span id='topic+relativeLoadings.princomp.rplus'></span><span id='topic+print.relativeLoadings.princomp.acomp'></span><span id='topic+print.relativeLoadings.princomp.aplus'></span><span id='topic+print.relativeLoadings.princomp.rcomp'></span><span id='topic+print.relativeLoadings.princomp.rplus'></span><span id='topic+plot.relativeLoadings.princomp.acomp'></span><span id='topic+plot.relativeLoadings.princomp.aplus'></span><span id='topic+plot.relativeLoadings.princomp.rcomp'></span><span id='topic+plot.relativeLoadings.princomp.rplus'></span>

<h3>Description</h3>

<p>In a compositional dataset the relation of two objects can be
interpreted safer than a single amount. These functions compute,
display and plot the corresponding pair-information for the various
principal component analysis results. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relativeLoadings(x,...)
## S3 method for class 'princomp.acomp'
relativeLoadings(x,...,log=FALSE,scale.sdev=NA,
                                                  cutoff=0.1)
## S3 method for class 'princomp.aplus'
relativeLoadings(x,...,log=FALSE,scale.sdev=NA,
                                                  cutoff=0.1)
## S3 method for class 'princomp.rcomp'
relativeLoadings(x,...,scale.sdev=NA,
                                                  cutoff=0.1)
## S3 method for class 'princomp.rplus'
relativeLoadings(x,...,scale.sdev=NA,
                                                  cutoff=0.1)
## S3 method for class 'relativeLoadings.princomp.acomp'
print(x,...,cutoff=attr(x,"cutoff"),
                                                  digits=2)
## S3 method for class 'relativeLoadings.princomp.aplus'
print(x,...,cutoff=attr(x,"cutoff"),
                                                 digits=2)
## S3 method for class 'relativeLoadings.princomp.rcomp'
print(x,...,cutoff=attr(x,"cutoff"),
                                                 digits=2)
## S3 method for class 'relativeLoadings.princomp.rplus'
print(x,...,cutoff=attr(x,"cutoff"),
                                                 digits=2)
## S3 method for class 'relativeLoadings.princomp.acomp'
plot(x,...)
## S3 method for class 'relativeLoadings.princomp.aplus'
plot(x,...)
## S3 method for class 'relativeLoadings.princomp.rcomp'
plot(x,...)
## S3 method for class 'relativeLoadings.princomp.rplus'
plot(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ratioLoadings_+3A_x">x</code></td>
<td>
<p>a result from an amount PCA <code><a href="#topic+princomp.acomp">princomp.acomp</a></code>/<code><a href="#topic+princomp.aplus">princomp.aplus</a></code>/<code><a href="#topic+princomp.rcomp">princomp.rcomp</a></code>/<code><a href="#topic+princomp.rplus">princomp.rplus</a></code></p>
</td></tr>
<tr><td><code id="ratioLoadings_+3A_log">log</code></td>
<td>
<p>a logical indicating to use log-ratios instead of ratios</p>
</td></tr>
<tr><td><code id="ratioLoadings_+3A_scale.sdev">scale.sdev</code></td>
<td>
<p>if not <code>NA</code>, a number specifying the
multiple of a standard deviation, used to scale the components</p>
</td></tr>
<tr><td><code id="ratioLoadings_+3A_cutoff">cutoff</code></td>
<td>
<p>a single number. Changes under that (log)-cutoff are not
displayed</p>
</td></tr>
<tr><td><code id="ratioLoadings_+3A_digits">digits</code></td>
<td>
<p>the number of digits to be displayed</p>
</td></tr>
<tr><td><code id="ratioLoadings_+3A_...">...</code></td>
<td>
<p>further parameters to internally-called functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relative loadings of components allow a direct interpretation of the effects
of principal components. For acomp/aplus classes the relation is
induced by a ratio, which can optionally be log-transformed. For the
rcomp/rplus-classes the relation is induced by a difference, which
is meaningless when the units are different.
</p>


<h3>Value</h3>

<p>The value is a matrix of type
<code>"relativeLoadings.princomp.*"</code>, containing the ratios in the
compositions represented by the loadings (optionally scaled by the
standard deviation of the components and <code>scale.sdev</code>). 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+princomp.acomp">princomp.acomp</a></code>,   <code><a href="#topic+princomp.aplus">princomp.aplus</a></code>,
<code><a href="#topic+princomp.rcomp">princomp.rcomp</a></code>,   <code><a href="#topic+princomp.rplus">princomp.rplus</a></code>,
<code><a href="graphics.html#topic+barplot">barplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
pc &lt;- princomp(acomp(sa.lognormals5))
pc
summary(pc)
relativeLoadings(pc,log=TRUE)
relativeLoadings(pc)
relativeLoadings(pc,scale.sdev=1)
relativeLoadings(pc,scale.sdev=2)

plot(relativeLoadings(pc,log=TRUE))
plot(relativeLoadings(pc))
plot(relativeLoadings(pc,scale.sdev=1))
plot(relativeLoadings(pc,scale.sdev=2))


</code></pre>

<hr>
<h2 id='rcomp'>Compositions as elements of the simplex embedded in the D-dimensional real space</h2><span id='topic+rcomp'></span>

<h3>Description</h3>

<p>A class providing a way to analyse compositions in the
philosophical framework of the Simplex as subset of the <code class="reqn">R^D</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          rcomp(X,parts=1:NCOL(oneOrDataset(X)),total=1,warn.na=FALSE,
                detectionlimit=NULL,BDL=NULL,MAR=NULL,MNAR=NULL,SZ=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcomp_+3A_x">X</code></td>
<td>
<p>composition or dataset of compositions</p>
</td></tr>
<tr><td><code id="rcomp_+3A_parts">parts</code></td>
<td>
<p>vector containing the indices xor names of the columns
to be used</p>
</td></tr>
<tr><td><code id="rcomp_+3A_total">total</code></td>
<td>
<p>the total amount to be used, typically 1 or 100</p>
</td></tr>
<tr><td><code id="rcomp_+3A_warn.na">warn.na</code></td>
<td>
<p>should the user be warned in case of NA,NaN or 0
coding different types of missing values?</p>
</td></tr>
<tr><td><code id="rcomp_+3A_detectionlimit">detectionlimit</code></td>
<td>
<p>a number, vector or matrix of positive
numbers giving the detection limit of all values, all columns or
each value, respectively</p>
</td></tr>
<tr><td><code id="rcomp_+3A_bdl">BDL</code></td>
<td>
<p>the code for 'Below Detection Limit' in X</p>
</td></tr>
<tr><td><code id="rcomp_+3A_sz">SZ</code></td>
<td>
<p>the code for 'Structural Zero' in X</p>
</td></tr>
<tr><td><code id="rcomp_+3A_mar">MAR</code></td>
<td>
<p>the code for 'Missing At Random' in X</p>
</td></tr>
<tr><td><code id="rcomp_+3A_mnar">MNAR</code></td>
<td>
<p>the code for 'Missing Not At Random' in X</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many multivariate datasets essentially describe amounts of D different
parts in a whole. This has some important implications justifying to
regard them as a scale on its own, called a &quot;composition&quot;.
The functions around the class <code>"rcomp"</code> follow the traditional
(often statistically inconsistent) approach regarding compositions simply
as a multivariate vector of positive numbers summing up to 1. This space of
D positive numbers summing to 1 is traditionally called the D-1-dimensional
simplex.
</p>
<p>The compositional scale was in-depth analysed by Aitchison
(1986) and he found serious reasons why compositional data should be
analysed with a different geometry.  The functions around the class
<code>"<a href="#topic+acomp">acomp</a>"</code> follow his
approach. However the Aitchison approach based on log-ratios is 
sometimes criticized (e.g. Rehder and Zier, 2002). It cannot deal with 
absent parts (i.e. zeros). It is sensitive to large measurement errors
in small amounts. The Aitchison operations cannot represent simple
mixture of different compositions. The used transformations
are not uniformly continuous. Straight lines and ellipses in Aitchison
space look strangely in ternary diagrams. As all uncritical statistical
analysis, blind application of logratio-based analysis is sometimes
misleading. Therefore it is sometimes useful to analyse
compositional data directly as a multivariate dataset of portions
summing to 1. However a clear warning must be given that the
utilisation of almost any kind of
classical multivariate analysis introduce some kinds of artifacts
(e.g. Chayes 1960) when applied to compositional data. So, extra care
and considerable expert knowlegde is needed for the proper
interpretation of results achieved in this non-Aitchison approach. The
package tries to lead the user around these artifacts as much as
possible and gives hints to major pitfalls in the help. However
meaningless results cannot be fully avoided in this (rather inconsistent) approach. 
<br />
A side effect of the procedure is to force the compositions to sum to
one, which is done by the closure operation <code><a href="#topic+clo">clo</a></code> . 
<br />
The classes rcomp, acomp, aplus, and rplus are designed in a fashion as similar as
possible, in order to allow direct comparison between results achieved  
by the different approaches. Especially the acomp logistic transforms
<code><a href="#topic+clr">clr</a></code>, <code><a href="#topic+alr">alr</a></code>, <code><a href="#topic+ilr">ilr</a></code> are mirrored
by analogous linear transforms <code><a href="#topic+cpt">cpt</a></code>, <code><a href="#topic+apt">apt</a></code>,
<code><a href="#topic+ipt">ipt</a></code> in the rcomp class framework. 
</p>


<h3>Value</h3>

<p>a vector of class <code>"rcomp"</code> representing a closed composition
or a matrix of class <code>"rcomp"</code> representing
multiple closed compositions, by rows.  
</p>


<h3>Missing Policy</h3>

<p>Missing and Below Detecion Limit Policy is
explained in deeper detail in <a href="#topic+compositions.missing">compositions.missing</a>. 
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado, K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Rehder, S. and U. Zier (2001) Letter to the Editor: Comment on 
&ldquo;Logratio Analysis and Compositional Distance&rdquo; by J. Aitchison, C. 
Barcel\'o-Vidal, J.A. Mart\'in-Fern\'a ndez and V. Pawlowsky-Glahn,
<em>Mathematical Geology</em>, <b>33</b> (7), 845-848.<br />
</p>
<p>Zier, U. and S. Rehder (2002) Some comments on log-ratio transformation and compositional distance,
<em>Terra Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>
<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008) &quot;compositions&quot;: a unified 
R package to analyze Compositional Data, <em>Computers &amp;
Geosciences</em>, 34 (4), pages 320-338, doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cpt">cpt</a></code>, <code><a href="#topic+apt">apt</a></code>, <code><a href="#topic+ipt">ipt</a></code>,
<code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rplus">rplus</a></code>,
<code><a href="#topic+princomp.rcomp">princomp.rcomp</a></code>,
<code><a href="#topic+plot.rcomp">plot.rcomp</a></code>, <code><a href="#topic+boxplot.rcomp">boxplot.rcomp</a></code>,
<code><a href="#topic+barplot.rcomp">barplot.rcomp</a></code>, <code><a href="#topic+mean.rcomp">mean.rcomp</a></code>,
<code><a href="#topic+var.rcomp">var.rcomp</a></code>, <code><a href="#topic+variation.rcomp">variation.rcomp</a></code>,
<code><a href="#topic+cov.rcomp">cov.rcomp</a></code>, <code><a href="#topic+msd">msd</a></code>,
<code><a href="#topic+convex.rcomp">convex.rcomp</a></code>, <code><a href="#topic++2B.rcomp">+.rcomp</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(rcomp(sa.tnormals))
</code></pre>

<hr>
<h2 id='rcomp-class'>Class <code>"rcomp"</code></h2><span id='topic+rcomp-class'></span><span id='topic+coerce+2Crcomp+2Cdata.frame-method'></span><span id='topic+coerce+2Crcomp+2Cstructure-method'></span><span id='topic+coerce+3C-+2Crcomp+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>The S4-version of the data container &quot;rcomp&quot; for compositional data. More information in 
<code><a href="#topic+rcomp">rcomp</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be directly created from it. 
This is provided to ensure that rcomp objects behave as data.frame or structure under certain circumstances. Use <code><a href="#topic+rcomp">rcomp</a></code> to create these objects.</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Object of class <code>"list"</code> containing the data itself </p>
</dd>
<dt><code>names</code>:</dt><dd><p>Object of class <code>"character"</code> with column names </p>
</dd>
<dt><code>row.names</code>:</dt><dd><p>Object of class <code>"data.frameRowLabels"</code> with row names </p>
</dd>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code> with the class string </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+data.frame-class">data.frame</a>"</code>, directly.
Class <code>"<a href="#topic+compositional-class">compositional</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+list-class">list</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;data.frame&quot;, distance 3.
</p>


<h3>Methods</h3>


<dl>
<dt>coerce</dt><dd><p><code>signature(from = "rcomp", to = "data.frame")</code>: to generate a data.frame </p>
</dd>
<dt>coerce</dt><dd><p><code>signature(from = "rcomp", to = "structure")</code>: to generate a structure (i.e. a vector, matrix or array) </p>
</dd>
<dt>coerce&lt;-</dt><dd><p><code>signature(from = "rcomp", to = "data.frame")</code>: to overwrite a composition with a data.frame</p>
</dd>
</dl>



<h3>Note</h3>

<p>see <code><a href="#topic+rcomp">rcomp</a></code>
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>References</h3>

<p>see <code><a href="#topic+rcomp">rcomp</a></code>
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+rcomp">rcomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("rcomp")
</code></pre>

<hr>
<h2 id='rcomparithm'>Arithmetic operations for compositions in a real geometry</h2><span id='topic++2B.rcomp'></span><span id='topic+-.rcomp'></span><span id='topic++2A.rcomp'></span><span id='topic++2F.rcomp'></span><span id='topic+convex.rcomp'></span>

<h3>Description</h3>

<p>The real compositions form a manifold of the real vector space. The
induced operations +,-,*,/ give results valued in the real 
vector space, but possibly outside the simplex. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convex.rcomp(x,y,alpha=0.5)
## Methods for class "rcomp"
##   x+y
##   x-y
##   -x
##   x*r
##   r*x
##   x/r
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcomparithm_+3A_x">x</code></td>
<td>
<p>an rcomp composition or dataset of compositions </p>
</td></tr>
<tr><td><code id="rcomparithm_+3A_y">y</code></td>
<td>
<p>an rcomp composition or dataset of compositions </p>
</td></tr>
<tr><td><code id="rcomparithm_+3A_r">r</code></td>
<td>
<p>a numeric vector of size 1 or nrow(x)</p>
</td></tr>
<tr><td><code id="rcomparithm_+3A_alpha">alpha</code></td>
<td>
<p>a numeric vector of size 1 or nrow(x) with values between
0 and 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions behave quite like <code><a href="#topic++2B.rmult">+.rmult</a></code>.<br />
The convex combination is defined as: <code>x*alpha + (1-alpha)*y</code>
</p>


<h3>Value</h3>

<p><code>rmult</code>-objects containing the given operations on the simplex
as subset of the <code class="reqn">R^D</code>. Only the convex combination
<code>convex.rcomp</code> results in an <code>rcomp</code>-object again, since
only this operation is closed.
</p>


<h3>Note</h3>

<p>For <code>*</code> the arguments x and y can be exchanged.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic++2B.rmult">+.rmult</a></code>, <code><a href="#topic++2B.acomp">+.acomp</a></code>,<code><a href="#topic+cpt">cpt</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+rmult">rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rcomp(1:5)* -1 + rcomp(1:5)
data(SimulatedAmounts)
cdata &lt;- rcomp(sa.lognormals)
plot( tmp &lt;- (cdata-mean(cdata))/msd(cdata) )
class(tmp)
mean(tmp)
msd(tmp)
var(tmp)
plot(convex.rcomp(rcomp(c(1,1,1)),sa.lognormals,0.1))
</code></pre>

<hr>
<h2 id='rcompmargin'>Marginal compositions in real geometry</h2><span id='topic+rcompmargin'></span>

<h3>Description</h3>

<p>Compute marginal compositions by amalgamating the rest (additively).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          rcompmargin(X,d=c(1,2),name="+",pos=length(d)+1,what="data")
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcompmargin_+3A_x">X</code></td>
<td>
<p>composition or dataset of compositions</p>
</td></tr>
<tr><td><code id="rcompmargin_+3A_d">d</code></td>
<td>
<p>vector containing the indices xor names of the columns to be kept</p>
</td></tr>
<tr><td><code id="rcompmargin_+3A_name">name</code></td>
<td>
<p>The new name of the amalgamation column</p>
</td></tr>
<tr><td><code id="rcompmargin_+3A_pos">pos</code></td>
<td>
<p>The position where the new amalgamation column should be
stored. This defaults to the last column.</p>
</td></tr>
<tr><td><code id="rcompmargin_+3A_what">what</code></td>
<td>
<p>The role of X either <code>"data"</code> for data (or means) to be
transformed or <code>"var"</code> for variances to be transformed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The amalgamation column is simply computed by adding the 
non-selected components after closing the composition. This is
consistent with the <code><a href="#topic+rcomp">rcomp</a></code> approach and is widely used because
of its easy interpretation. However, it often leads to difficult-to-read
ternary diagrams and is inconsistent with the <code><a href="#topic+acomp">acomp</a></code>
approach.
</p>
<p>With the argument <code>what="var"</code> the function transformes an rcomp
variance to the resulting variance of the resulting composition.
</p>


<h3>Value</h3>

<p>A closed compositions with class <code>"rcomp"</code> containing the
selected variables given by <code>d</code> and the the amalgamation column.  </p>


<h3>Missing Policy</h3>

<p>MNAR has the highest priority, MAR next and WZERO (BDL,SZ),- values are
considered as 0 and reported as BDL in the End.  
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
olosana-Delgado</p>


<h3>References</h3>

<p>References missing
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+acompmargin">acompmargin</a></code>, <code><a href="#topic+rcomp">rcomp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot.rcomp(sa.tnormals5,margin="rcomp")
plot.rcomp(rcompmargin(sa.tnormals5,c("Cd","Zn")))
plot.rcomp(rcompmargin(sa.tnormals5,c(1,2)))

</code></pre>

<hr>
<h2 id='rDirichlet'>Dirichlet distribution</h2><span id='topic+rDirichlet'></span><span id='topic+dDirichlet'></span><span id='topic+rDirichlet.acomp'></span><span id='topic+rDirichlet.rcomp'></span>

<h3>Description</h3>

<p>The Dirichlet distribution on the simplex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dDirichlet(x, alpha, log=FALSE, measure="Lebesgue")
rDirichlet.acomp(n, alpha)
rDirichlet.rcomp(n, alpha)

          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rDirichlet_+3A_n">n</code></td>
<td>
<p>number of datasets to be simulated</p>
</td></tr>
<tr><td><code id="rDirichlet_+3A_alpha">alpha</code></td>
<td>
<p>parameters of the Dirichlet distribution</p>
</td></tr>
<tr><td><code id="rDirichlet_+3A_x">x</code></td>
<td>
<p>a data set (acomp, rcomp, data.frame, matrix; even one-row) of point(s) 
on the simplex</p>
</td></tr>
<tr><td><code id="rDirichlet_+3A_log">log</code></td>
<td>
<p>a boolean, controlling if the density or the log-density is returned</p>
</td></tr>
<tr><td><code id="rDirichlet_+3A_measure">measure</code></td>
<td>
<p>one of: &quot;Lebesgue&quot; or &quot;Aitchison&quot; (partial match applies), or else 
a function returning the reference LOG-density (see details below)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Dirichlet distribution is the result of closing a vector of equally-scaled
Gamma-distributed variables. It the conjugate prior distribution for a vector
of probabilities of a multinomial distribution. Thus, it generalizes the beta 
distribution for more than two parts.
</p>
<p>For the density, the implementation allows to obtain the conventional density
(with respect to the Lebesgue measure, default behaviour or giving 
<code>measure="Lebuesgue"</code>), the compositional density (with respect to the 
Aitchison measure, giving <code>measure="Aitchison"</code>), or else w.r.to any other
reference density (giving at <code>measure</code> a function returning the log-density
of the reference measure for any point of the simplex)
</p>


<h3>Value</h3>

<p>For <code>rDirichlet.*</code> a generated random dataset of class <code>"acomp"</code> or <code>"rcomp"</code>,
drawn from a Dirichlet distribution with the given parameter
<code>alpha</code>. The names of <code>alpha</code> are used to name the parts. 
</p>
<p>For <code>dDirichlet</code>, the (conventional) Dirichlet density 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>,
Raimon Tolosana-Delgado</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Mateu-Figueras, G.; Pawlowsky-Glahn, V. (2005). The Dirichlet distribution 
with respect to the Aitchison measure on the simplex, a first approach.
In: Mateu-Figueras, G. and Barcel\'o-Vidal, C. (Eds.)
<em>Proceedings of the 2nd International Workshop on Compositional Data Analysis</em>,
Universitat de Girona, ISBN 84-8458-222-1, <a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a><br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tmp &lt;- rDirichlet.acomp(10,alpha=c(A=2,B=0.2,C=0.2))
plot(tmp)
dDirichlet(tmp, alpha=c(A=2,B=0.2,C=0.2))
dDirichlet(tmp[1,]*0, alpha=c(A=2,B=0.2,C=0.2))

</code></pre>

<hr>
<h2 id='Read+20standard+20data+20files'>Reads a data file in a geoeas format</h2><span id='topic+read.geoeas'></span><span id='topic+read.geoEAS'></span>

<h3>Description</h3>

<p>Reads a data file, which must be formatted either as a
geoEAS file (described below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.geoeas(file)
read.geoEAS(file)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Read+2B20standard+2B20data+2B20files_+3A_file">file</code></td>
<td>
<p>a file name, with a specific format</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data files must be in the adequate format: &quot;read.geoEAS&quot; and
&quot;read.geoeas&quot; read geoEAS format.
</p>
<p>The geoEAS format has the following structure:
</p>

<dl>
<dt>1</dt><dd><p>a first row with a description of the data set</p>
</dd>
<dt>2</dt><dd><p>the number of variables (=nvars)</p>
</dd>
<dt>3</dt><dd><p>&quot;nvars&quot;  rows, each containing the name of a variable</p>
</dd>
<dt>4</dt><dd><p>the data set, in a matrix of &quot;nvars&quot; columns
and as many rows as individuals</p>
</dd>
</dl>



<h3>Value</h3>

<p>A data set, with a &quot;title&quot; attribute.
</p>


<h3>Note</h3>

<p> Labels and title should not contain tabs.
This might produce an error when reading.</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado</p>


<h3>References</h3>

<p>Missing references
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+read.table">read.table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
# Files can be found in the test-subdirectory of the package
#
## Not run: 
  read.geoeas("TRUE.DAT")
  read.geoEAS("TRUE.DAT")

## End(Not run)
</code></pre>

<hr>
<h2 id='replot'>Modify parameters of compositional plots.</h2><span id='topic+replot'></span><span id='topic+replotable'></span><span id='topic+noreplot'></span>

<h3>Description</h3>

<p>Display only a subset of the plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replot(...,dev=dev.cur(),plot=TRUE,envir=NULL,add=FALSE)
replotable(expr,add=FALSE)
noreplot(expr,dev=dev.cur())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replot_+3A_expr">expr</code></td>
<td>
<p>A (unquoted) expression that does the
plotting. <code>replotable</code> will make the generated plot replotable
and noreplot will do the inverse and avoid that the plots overwrites
the current database entry.</p>
</td></tr>
<tr><td><code id="replot_+3A_...">...</code></td>
<td>
<p>Plot parameters to be modified. E.g. onlyPanel</p>
</td></tr>
<tr><td><code id="replot_+3A_dev">dev</code></td>
<td>
<p>The device that currently contains the plot. It will be
plotted in the current device.</p>
</td></tr>
<tr><td><code id="replot_+3A_plot">plot</code></td>
<td>
<p> logical or call or list of calls.
If plot is TRUE, the new version of the plot is plotted in the
current environment (and typically stores itself here).<br />
If plot is FALSE the modified plot is simply stored, rather
than actually plotted (in its own old plotting environment).<br />
If the parameter is something else, it is stored to the internal plot
database for the given device (but not plotted or evaluated).
</p>
</td></tr>
<tr><td><code id="replot_+3A_envir">envir</code></td>
<td>
<p>a new enviroment to be assigned to the plot. Rarely
needed.</p>
</td></tr>
<tr><td><code id="replot_+3A_add">add</code></td>
<td>
<p>either a logical to indicating that the plot adds something
to the plot. Or a number / name of the added thing to be modified.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some of the plot routines of compositions internally store their
call as a mean for replaying the plot when information is added or
parameters are modified. The stored call can be modified by this
function, which pretty much works like a simplified version of
<code><a href="stats.html#topic+update">update</a></code>.
</p>
<p><code>replot</code> allows to redo the plot typically in a different
device or with different parameters. The function provides this
functionallity at a totally different level than
<code><a href="grDevices.html#topic+dev.copy">dev.copy</a></code> and allows for the modification of high level
parameters on the fly. 
</p>
<p>Plots can be stored in the internal database by calling <code>replot</code>
with a parameter <code>plot</code> set to the call of that plot. Plotting
functions without this functionallity can be filtered through
replotable(). However in this case all parameter names should be given
explicitly.   
</p>
<p>There are actually three levels of possible replay: The <code>dev.copy</code>
level on which graphic actions are replayed. The <code>gsi.pairs</code>
function level that organizes panels plots and uses an internal replotting facility
to allow modification of the parameter, e.g. addings lines .... And than
there is the high level of the actual function call generating the
plot. 
</p>


<h3>Value</h3>

<p><code>replot</code> returns an invisible copy of the modified
call. <code>replotable</code> and <code>noreplot</code> return the result of
expression. 
</p>


<h3>Note</h3>

<p>The function works by revaluating the call in its environment. Thus
the plot will change!!! if the data has changed.
</p>
<p>The function always handles the latest plot from the package. If
another plot ignorant of the replot system has meanwhile be used it will be
ignored. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>, <code><a href="#topic+plot.aplus">plot.aplus</a></code>,
<code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(acomp(sa.lognormals5))
straight(acomp(c(1,1,1,1,1)),acomp(c(1,2,3,4,5)))
replot(onlyPanel=c(2,3))
oldPlot &lt;- replot(plot=FALSE) # get the plotting call
replotable(plot(x=1:10)) # To make a graphic replottable
replot(col=1:10)
replot(plot=oldPlot)    # Restore the old plot (without plotting)
replot(onlyPanel=NULL)    # View the whole plot again
replot(pch=20)  # Acctually plot it 
replot(col=20)  # since the actual plot is gsi.pairs not a plot.acomp
 
## Not run: 
# The following line in  a plotting function stores the plot for replotting.
replot(plot=match.call()) # Store current call as plot 
replot()                  # simply plot once again
replot(dev=otherdev)      # redo a plot from an other device here.
replot(onlyPanel=c(3,4))  # modify the plot (and replot it)
replot(onlyPanel=c(3,4),dev=7,plot=FALSE) # modify a stored plot

## End(Not run)
</code></pre>

<hr>
<h2 id='rlnorm'>The multivariate lognormal distribution</h2><span id='topic+rlnorm.rplus'></span><span id='topic+dlnorm.rplus'></span>

<h3>Description</h3>

<p>Generates random amounts with a multivariate lognormal distribution, or gives the 
density of that distribution at a given point. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlnorm.rplus(n,meanlog,varlog)
dlnorm.rplus(x,meanlog,varlog)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlnorm_+3A_n">n</code></td>
<td>
<p>number of datasets to be simulated</p>
</td></tr>
<tr><td><code id="rlnorm_+3A_meanlog">meanlog</code></td>
<td>
<p>the mean-vector of the logs</p>
</td></tr>
<tr><td><code id="rlnorm_+3A_varlog">varlog</code></td>
<td>
<p>the variance/covariance matrix of the logs</p>
</td></tr>
<tr><td><code id="rlnorm_+3A_x">x</code></td>
<td>
<p>vectors in the sample space</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>rlnorm.rplus</code> gives a generated random dataset of class
<code>"rplus"</code> following a
lognormal distribution with logs having mean <code>meanlog</code> and
variance <code>varlog</code>.
<br />
<code>dlnorm.rplus</code> gives the density of the distribution with respect
to the Lesbesgue measure on R+ as a subset of R. 
</p>


<h3>Note</h3>

<p>The main difference between <code>rlnorm.rplus</code> and
<code>rnorm.aplus</code>
is that rlnorm.rplus needs a logged mean. The additional difference
for the calculation of the density by <code>dlnorm.rplus</code> and
<code>dnorm.aplus</code> is the reference measure (a log-Lebesgue one in the
second case).
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rnorm.acomp">rnorm.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MyVar &lt;- matrix(c(
0.2,0.1,0.0,
0.1,0.2,0.0,
0.0,0.0,0.2),byrow=TRUE,nrow=3)
MyMean &lt;- c(1,1,2)

plot(rlnorm.rplus(100,log(MyMean),MyVar))
plot(rnorm.aplus(100,MyMean,MyVar))
x &lt;- rnorm.aplus(5,MyMean,MyVar)
dnorm.aplus(x,MyMean,MyVar)
dlnorm.rplus(x,log(MyMean),MyVar)

</code></pre>

<hr>
<h2 id='rMahalanobis'>Compute distributions of empirical Mahalanobis distances based on
simulations</h2><span id='topic+pMaxMahalanobis'></span><span id='topic+qMaxMahalanobis'></span><span id='topic+rMaxMahalanobis'></span><span id='topic+pEmpiricalMahalanobis'></span><span id='topic+qEmpiricalMahalanobis'></span><span id='topic+rEmpiricalMahalanobis'></span><span id='topic+pPortionMahalanobis'></span><span id='topic+qPortionMahalanobis'></span><span id='topic+rPortionMahalanobis'></span><span id='topic+pQuantileMahalanobis'></span><span id='topic+gsi.pStore'></span>

<h3>Description</h3>

<p>Decissions about outliers are often made based on Mahalanobis
distances with respect to robustly estimated variances. These function
deliver the necessary distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rEmpiricalMahalanobis(n,N,d,...,sorted=FALSE,pow=1,robust=TRUE)
pEmpiricalMahalanobis(q,N,d,...,pow=1,replicates=100,resample=FALSE,
                        robust=TRUE)
qEmpiricalMahalanobis(p,N,d,...,pow=1,replicates=100,resample=FALSE,
                        robust=TRUE)
rMaxMahalanobis(n,N,d,...,pow=1,robust=TRUE)
pMaxMahalanobis(q,N,d,...,pow=1,replicates=998,resample=FALSE,
                        robust=TRUE)
qMaxMahalanobis(p,N,d,...,pow=1,replicates=998,resample=FALSE,
                        robust=TRUE)
rPortionMahalanobis(n,N,d,cut,...,pow=1,robust=TRUE)
pPortionMahalanobis(q,N,d,cut,...,replicates=1000,resample=FALSE,pow=1,
                        robust=TRUE)
qPortionMahalanobis(p,N,d,cut,...,replicates=1000,resample=FALSE,pow=1,
                        robust=TRUE)
pQuantileMahalanobis(q,N,d,p,...,replicates=1000,resample=FALSE,
                        ulimit=TRUE,pow=1,robust=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rMahalanobis_+3A_n">n</code></td>
<td>
<p>Number of simulations to do.</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_q">q</code></td>
<td>
<p>A vector giving quantiles of the distribution</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_p">p</code></td>
<td>
<p>A vector giving probabilities. (only a single probility for 
<code>pQuantileMahalanobis</code>)</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_n">N</code></td>
<td>
<p>Number of cases in the dataset.</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_d">d</code></td>
<td>
<p>degrees of freedom (i.e. dimension) of the dataset.</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_cut">cut</code></td>
<td>
<p>A cutting limit. The random variable is the portion of
Mahalanobis distances lower equal to the cutting limit.</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+MahalanobisDist">MahalanobisDist</a></code></p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_pow">pow</code></td>
<td>
<p>the power of the Mahalanobis distance to be used. Higher
powers can be used to stretch the outlierregion visually.</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_robust">robust</code></td>
<td>
<p>logical or a robust method description (see
<code><a href="#topic+robustnessInCompositions">robustnessInCompositions</a></code>) specifiying how the center
and covariance
matrix are estimated,if not given.</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_sorted">sorted</code></td>
<td>

<p>Specifies a transformation to be applied to the whole sequence of
Mahalanobis distances: FALSE is no transformation, TRUE sorts the
entries in ascending order, a numeric vector picks the given entries
from the entries sorted in ascending order; alternatively a function
such as <code>max</code> can be given to directly transform the data.
</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_replicates">replicates</code></td>
<td>
<p>the number of datasets in the
Monte-Carlo-Computations used in these routines.</p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_resample">resample</code></td>
<td>
<p>a logical forcing a resampling of the
Monte-Carlo-Sampling. See details. </p>
</td></tr>
<tr><td><code id="rMahalanobis_+3A_ulimit">ulimit</code></td>
<td>
<p>logical: is this an upper limit of a joint confidence
bound or a lower limit.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All the distribution correspond to the distribution under the
Null-Hypothesis of multivariate joint Gaussian distribution of the
dataset.
</p>
<p>The set of empirically estimated Mahalanobis distances of a dataset is
in the first step a random vector with exchangable but dependent
entries. The distribution of this vector is given by the
<code>rEmpiricalMahalanobis</code> if no sorted argument is given. Please be
advised that this is not a fixed distribution in a mathematical sense,
but an implementation dependent distribution incorporating the
performance of underlying robust spread estimator. As long as no
sorted argument is given <code>pEmpiricalMahalanobis</code> and
<code>qEmpiricalMahalanobis</code> represent the distribution function and
the quantile function of a randomly picked element of this
vector.
<br />
If a sorted attribute is given, it specifies a transformation is
applied to each of the vector prior to processing. Three important
special cases
are provided by seperate functions. The MaxMahalanobis functions
correspond to picking only the larges value. The PortionMahalanobis
functions correspond to reporting the portion of Mahalanobis distances
over a cutoff. The QuantileMahalanobis distribution correponds to the
distribution of the p-quantile of the dataset. 
<br />
The Monte-Carlo-Simulations of these
distributions are rather slow, since for each datum we need to
simulate a whole dataset and to apply a robust covariance estimator
to it, which typically itself involves
Monte-Carlo-Algorithms. Therefore each type of simulations is only
done the first time needed and stored for later use in the
environment <code><a href="#topic+gsi.pStore">gsi.pStore</a></code>. With the resampling argument a
resampling of the cashed dataset can be forced.
</p>


<h3>Value</h3>

<p>The r* functions deliver a vector (or a matrix of row-vectors) of
simulated value of the given distributions. A total of n values (or
row vectors) is returned.
<br />
The p* functions deliver a vector (of the same length as x) of
probabilities for random variable of the given distribution to be
under the given quantil values q.
<br />
The q* functions deliver a vector of quantiles corresponding to the
length of the vector p providing the probabilities.
</p>


<h3>Note</h3>

<p>Unlike the <code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code> function this function does not
be default compute the square of the mahalanobis distance. The pow
option is provided if the square is needed.
<br />
The package <span class="pkg">robustbase</span> is required for using the
robust estimations.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+dist">dist</a></code>, <code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rEmpiricalMahalanobis(10,25,2,sorted=TRUE,pow=1,robust=TRUE)
pEmpiricalMahalanobis(qchisq(0.95,df=10),11,1,pow=2,replicates=1000)
(xx&lt;-pMaxMahalanobis(qchisq(0.95,df=10),11,1,pow=2))
qEmpiricalMahalanobis(0.95,11,2)
rMaxMahalanobis(10,25,4)
qMaxMahalanobis(xx,11,1)
</code></pre>

<hr>
<h2 id='rmult'>Simple treatment of real vectors </h2><span id='topic+rmult'></span><span id='topic+print.rmult'></span>

<h3>Description</h3>

<p>A class to collect real multivariate vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> rmult(X,parts=1:NCOL(oneOrDataset(X)),orig=gsi.orig(X),
                missingProjector=attr(X,"missingProjector"),
                V = gsi.getV(X))
 ## S3 method for class 'rmult'
print(x,..., verbose=FALSE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmult_+3A_x">X</code></td>
<td>
<p>vector or dataset of numbers considered as elements of a R-vector</p>
</td></tr>
<tr><td><code id="rmult_+3A_parts">parts</code></td>
<td>
<p>vector containing the indices  xor names of the columns
to be used</p>
</td></tr>
<tr><td><code id="rmult_+3A_x">x</code></td>
<td>
<p>an rmult object</p>
</td></tr>
<tr><td><code id="rmult_+3A_orig">orig</code></td>
<td>
<p>the original untransformed dataset</p>
</td></tr>
<tr><td><code id="rmult_+3A_missingprojector">missingProjector</code></td>
<td>
<p>the Projector on the observed subspace</p>
</td></tr>
<tr><td><code id="rmult_+3A_v">V</code></td>
<td>
<p>the <em>inverse</em> of the transformation matrix</p>
</td></tr>
<tr><td><code id="rmult_+3A_...">...</code></td>
<td>
<p>further generic arguments passed to <code>print.default</code></p>
</td></tr>
<tr><td><code id="rmult_+3A_verbose">verbose</code></td>
<td>
<p>logical, do you want to get all information about original data and transformation function (if any) with a <code>print</code> call? defaults to FALSE (to print strict content only)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>rmult</code> class is a simple convenience class to treat
data in the scale of real vectors just like data in the scale of real
numbers. A major aspect to take into account is that the internal arithmetic of R is
different for these vectors, e.g. <code>mean</code> works as <code>colMeans</code> in a data frame,
or matrix-vector operations are done row-wise.    
</p>


<h3>Value</h3>

<p>a vector of class <code>"rmult"</code> representing one vector
or a matrix of class <code>"rmult"</code>, representing
multiple vectors by rows.  
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic++2B.rmult">+.rmult</a></code>, <code><a href="#topic+scalar">scalar</a></code>, <code><a href="#topic+norm.rmult">norm.rmult</a></code>,
<code><a href="#topic++25+2A+25.rmult">%*%.rmult</a></code>,
<code><a href="#topic+rplus">rplus</a></code>, <code><a href="#topic+acomp">acomp</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(rnorm.rmult(30,mean=0:4,var=diag(1:5)+10))

</code></pre>

<hr>
<h2 id='rmult-class'>Class <code>"rmult"</code></h2><span id='topic+rmult-class'></span><span id='topic+coerce+2Crmult+2Cdata.frame-method'></span><span id='topic+coerce+2Crmult+2Cstructure-method'></span><span id='topic+coerce+3C-+2Crmult+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>The S4-version of the data container &quot;rmult&quot; for compositional data. More information in 
<code><a href="#topic+rmult">rmult</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be directly created from it. 
This is provided to ensure that rmult objects behave as data.frame or structure under certain circumstances. Use <code><a href="#topic+rmult">rmult</a></code> to create these objects.</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Object of class <code>"list"</code> containing the data itself </p>
</dd>
<dt><code>names</code>:</dt><dd><p>Object of class <code>"character"</code> with column names </p>
</dd>
<dt><code>row.names</code>:</dt><dd><p>Object of class <code>"data.frameRowLabels"</code> with row names </p>
</dd>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code> with the class string </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+data.frame-class">data.frame</a>"</code>, directly.
Class <code>"<a href="#topic+compositional-class">compositional</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+list-class">list</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;data.frame&quot;, distance 3.
</p>


<h3>Methods</h3>


<dl>
<dt>coerce</dt><dd><p><code>signature(from = "rmult", to = "data.frame")</code>: to generate a data.frame </p>
</dd>
<dt>coerce</dt><dd><p><code>signature(from = "rmult", to = "structure")</code>: to generate a structure (i.e. a vector, matrix or array) </p>
</dd>
<dt>coerce&lt;-</dt><dd><p><code>signature(from = "rmult", to = "data.frame")</code>: to overwrite a composition with a data.frame</p>
</dd>
</dl>



<h3>Note</h3>

<p>see <code><a href="#topic+rmult">rmult</a></code>
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>References</h3>

<p>see <code><a href="#topic+rmult">rmult</a></code>
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+rmult">rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("rmult")
</code></pre>

<hr>
<h2 id='rmultarithm'>vectorial arithmetic for datasets in a classical vector scale</h2><span id='topic++2B.rmult'></span><span id='topic+-.rmult'></span><span id='topic++2A.rmult'></span><span id='topic++2F.rmult'></span>

<h3>Description</h3>

<p>vector space operations computed for multiple vectors in parallel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Methods for class "rmult"
## x+y
## x-y
## -x
## x*r
## r*x
## x/r
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmultarithm_+3A_x">x</code></td>
<td>
<p>an rmult vector or dataset of vectors </p>
</td></tr>
<tr><td><code id="rmultarithm_+3A_y">y</code></td>
<td>
<p>an rmult vector or dataset of vectors </p>
</td></tr>
<tr><td><code id="rmultarithm_+3A_r">r</code></td>
<td>
<p>a numeric vector of size 1 or nrow(x)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The operators try to mimic the parallel operation of R on vectors of
real numbers on vectors of vectors represented as matrices containing
the vectors as rows. 
</p>


<h3>Value</h3>

<p>an object of class <code>"rmult"</code> containing the result of the
corresponding operation on the vectors.  
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+rmult">rmult</a></code>, <code><a href="#topic++25+2A+25.rmult">%*%.rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rmult(matrix( sqrt(1:12), ncol= 3 ))
x
x+x
x + rmult(1:3)
x * 1:4
1:4 * x
x / 1:4
x / 10
</code></pre>

<hr>
<h2 id='rmultmatmult'>inner product for datasets with vector scale</h2><span id='topic++25+2A+25.rmult'></span>

<h3>Description</h3>

<p>An rmult object is considered as a sequence of vectors. The <code>%*%</code>
is considered as the inner multiplication. An inner multiplication with
another vector is the scalar product. an inner multiplication with
a matrix is a matrix multiplication, where the rmult-vectors are either
considered as row or as column vector.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rmult'
x %*% y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmultmatmult_+3A_x">x</code></td>
<td>
<p>an rmult vector or dataset of vectors, a numeric vector of
length (<code>gsi.getD(y)</code>), or a matrix</p>
</td></tr>
<tr><td><code id="rmultmatmult_+3A_y">y</code></td>
<td>
<p>an rmult vector or dataset of vectors , a numeric vector of
length (<code>gsi.getD(x)</code>), or a matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p> The operators try to minic the behavior of <code>%*%</code> on
<code>c()</code>-vectors as inner product applied in parallel to all vectors of
the dataset. Thus the product of a vector with another <code>rmult</code>
object or unclassed vector <var>v</var> results in the scalar product. For
the multiplication with a matrix each vector is considered as a row or
column, whatever is more appropriate. 
</p>


<h3>Value</h3>

<p>an object of class <code>"rmult"</code> or a numeric vector containing the
result of the
corresponding inner products.
</p>


<h3>Note</h3>

<p>The product <code>x %*% A %*% y</code> is associative. </p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+rmult">rmult</a></code>, <code><a href="#topic++25+2A+25.rmult">%*%.rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rmult(matrix( sqrt(1:12), ncol= 3 ))
x%*%x
A &lt;- matrix( 1:9,nrow=3)
x %*% A %*% x
x %*% A
A %*% x
x %*% 1:3
x %*% 1:3
1:3 %*% x 

</code></pre>

<hr>
<h2 id='rnorm'>Normal distributions on special spaces</h2><span id='topic+rnorm.acomp'></span><span id='topic+rnorm.rcomp'></span><span id='topic+rnorm.aplus'></span><span id='topic+rnorm.rplus'></span><span id='topic+rnorm.rmult'></span><span id='topic+rnorm.ccomp'></span><span id='topic+dnorm.acomp'></span><span id='topic+dnorm.aplus'></span><span id='topic+dnorm.rmult'></span>

<h3>Description</h3>

<p><code>rnorm.</code><var>X</var> generates multivariate normal random variates in
the space <var>X</var>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnorm.acomp(n,mean,var)
rnorm.rcomp(n,mean,var)
rnorm.aplus(n,mean,var)
rnorm.rplus(n,mean,var)
rnorm.rmult(n,mean,var)
rnorm.ccomp(n,mean,var,lambda)
dnorm.acomp(x,mean,var,withJacobian=FALSE)
dnorm.aplus(x,mean,var,withJacobian=FALSE)
dnorm.rmult(x,mean,var)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rnorm_+3A_n">n</code></td>
<td>
<p>number of datasets to be simulated</p>
</td></tr>
<tr><td><code id="rnorm_+3A_mean">mean</code></td>
<td>
<p>The mean of the dataset to be simulated</p>
</td></tr>
<tr><td><code id="rnorm_+3A_var">var</code></td>
<td>
<p>The variance covariance matrix</p>
</td></tr>
<tr><td><code id="rnorm_+3A_lambda">lambda</code></td>
<td>
<p>The expected total count</p>
</td></tr>
<tr><td><code id="rnorm_+3A_x">x</code></td>
<td>
<p>vectors in the sampling space</p>
</td></tr>
<tr><td><code id="rnorm_+3A_withjacobian">withJacobian</code></td>
<td>
<p>should the jacobian of the log or logratio transformation be included in
the density calculations? defaults to FALSE (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The normal distributions in the various spaces dramatically
differ. The normal distribution in the <code>rmult</code> space is the
commonly known multivariate joint normal distribution. For
<code>rplus</code> this distribution has to be somehow truncated at 0. This
is here done by setting negative values to 0, i.e. this simulation function
produces a sort of multivariate tobit model.
<br />
The normal distribution
of <code>rcomp</code> is seen as a normal distribution within the simplex as
a geometrical portion of the real vector space. The variance is thus
forced to be singular and restricted to the affine subspace generated
by the simplex. The necessary truncation of negative values is
currently done by setting them explicitly to zero and reclosing
afterwards, again in the fashion of a tobit model. 
<br />
The <code>"acomp"</code> and <code>"aplus"</code> are themselves metric vector spaces and
thus a normal distribution is defined in them just as in the real
space. The resulting distribution almost correspond to multivariate
lognormal in the case of <code>"aplus"</code> and Aitchison normal
distribution in the simplex in the case of <code>"acomp"</code>. These models
are equivalent in probability to the multivariate lognormal distribution
and the addditive logistic normal distribution respectively, albeit without
including the jacobian of the log or the logratio transformation. If you are 
interested in the density of the additive logistic normal model, give the extra
argument <code>withJacobian=TRUE</code>. If you are interested in the multivariate 
lognormal density cou can either do the same, or better call <code><a href="#topic+dlnorm.rplus">dlnorm.rplus</a></code>.
<br />
Densities are only provided for the models constructed for <code>rmult</code>, 
<code>aplus</code> and <code>acomp</code> because they do exist w
with repect to the Lebesgue measure of each of these spaces. 
In the other cases it is not possible to compute a measure, since the truncation
at zero values produce 
distributions that are not absolutely continuous with respect to the real, conventional 
Lebesgue measure. 
<br />
For count compositions <code>ccomp</code> a rnorm.acomp is realized and used
as a parameter to a Poisson distribution (see <code><a href="#topic+rpois.ccomp">rpois.ccomp</a></code>). So, this is 
in reality no normal model, but a double stochastic counting process.
</p>


<h3>Value</h3>

<p>a random dataset of the given class generated by a normal distribution
with the given mean and
variance in the given space. For the density functions <code>d*</code>, the value of the 
probability density at the values of <code>x</code> provided</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Pawlowsky-Glahn, V. and J.J. Egozcue (2001) Geometric approach to
statistical analysis on the simplex. <em>SERRA</em> <b>15</b>(5), 384-398<br />
</p>
<p>Aitchison, J, C. Barcel'o-Vidal, J.J. Egozcue, V. Pawlowsky-Glahn
(2002) A consise guide to the algebraic geometric structure of the
simplex, the sample space for compositional data analysis, <em>Terra
Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+runif.acomp">runif.acomp</a></code>, <code><a href="#topic+rlnorm.rplus">rlnorm.rplus</a></code>,
<code><a href="#topic+rDirichlet.acomp">rDirichlet.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MyVar &lt;- matrix(c(
0.2,0.1,0.0,
0.1,0.2,0.0,
0.0,0.0,0.2),byrow=TRUE,nrow=3)
MyMean &lt;- c(1,1,2)

plot(rnorm.acomp(100,MyMean,MyVar))
plot(rnorm.rcomp(100,MyMean,MyVar))
plot(rnorm.aplus(100,MyMean,MyVar))
plot(rnorm.rplus(100,MyMean,MyVar))
plot(rnorm.rmult(100,MyMean,MyVar))
x &lt;- rnorm.aplus(5,MyMean,MyVar)
dnorm.acomp(x,MyMean,MyVar)
dnorm.aplus(x,MyMean,MyVar)
dnorm.rmult(x,MyMean,MyVar)
</code></pre>

<hr>
<h2 id='robustnessInCompositions'>Handling robustness issues and outliers in compositions.</h2><span id='topic+robust'></span><span id='topic+robustnessInCompositions'></span>

<h3>Description</h3>

<p>The seamless transition to robust estimations in library(compositions).
</p>


<h3>Details</h3>

<p>A statistical method is called nonrobust if an arbitrary contamination of
a small portion of the dataset can produce results radically different
from the results without the contamination. In this sense many
classical procedures relying on distributional models or on moments
like mean and variance are highly nonrobust. 
<br />
We consider robustness as an essential prerequierement of all
statistical analysis. However in the context of compositional data
analysis robustness is still in its first years. 
<br />
As of Mai 2008 we provide a new approach to robustness in the
package. The central idea is that robustness should be more or less
automatic and that there should be no necessity to change the code to
compare results obtained from robust procedures and results from there
more efficient nonrobust counterparts. 
<br />
To achieve this all routines that rely on distributional models (such
as e.g. mean,
variance, principle component analysis, scaling) and routines relying
on those routines get a new standard argument of the form:
<br />
<code>fkt(...,robust=getOption("robust"))</code>
<br />
which defaults to a new option &quot;robust&quot;. This option can take several
values:
</p>

<dl>
<dt>FALSE</dt><dd><p>The classical estimators such as arithmetic mean and
persons product moment variance are used and the results are to be
considered nonrobust. </p>
</dd>
<dt>TRUE</dt><dd><p>The default for robust estimation in the package is
used. At this time this is <code><a href="robustbase.html#topic+covMcd">covMcd</a></code> in the
<span class="pkg">robustbase</span>-package. This default might change in future. </p>
</dd>
<dt>&quot;pearson&quot;</dt><dd><p>This is a synonym for FALSE and explicitly states
that no robustness should be used.</p>
</dd>
<dt>&quot;mcd&quot;</dt><dd><p>Minimum Covariance Determinant. This option explicitly
selects the use of <code><a href="robustbase.html#topic+covMcd">covMcd</a></code> in the
<span class="pkg">robustbase</span>-package as the main robustness engine.</p>
</dd>
</dl>

<p>More options might follow later.
To control specific parameters of the
model the string can get an attribute named &quot;control&quot; which contains
additional options for the robustness engine used. In this moment the
control attribute of mcd is a control object of
<code><a href="robustbase.html#topic+covMcd">covMcd</a></code>. The control argument of &quot;pearson&quot; is a list
containing addition options to the mean, like trim. 
<br />
The standard value for getOption(&quot;robust&quot;) is FALSE to avoid situation
in which the user thinks he uses a classical technique. Robustness
must be switched on explicitly. Either by setting the option with
<code>options(robust=TRUE)</code> or by giving the argument. This default
might change later if the authors come to the impression that robust
estimation is now considered to be the default.
</p>
<p>For those not only interested in avoiding the influence of the
outliers, but in an analysis of the outliers we added a subsystem for
outlier classification. This subsystem is described in
<a href="#topic+outliersInCompositions">outliersInCompositions</a> and also relies on the
robust option. However evidently for these routines the factory
default for the robust option is always TRUE, because it is only
applicable in an outlieraware context.
</p>
<p>We hope that in this way we can provide a seamless transition from
nonrobust analysis to a robust analysis. 
</p>


<h3>Note</h3>

<p>IMPORTANT: The robust argument only works with the classes of the
package. Only your compositional analysis is suddenly robust.
<br />
The package <span class="pkg">robustbase</span> is required for using the
robust estimations and the outlier subsystem of compositions. To
simplify installation it is not listed as required, but it will be
loaded, whenever any sort of outlierdetection or robust estimation is
used.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+var.acomp">var.acomp</a></code>, <code><a href="#topic+mean.acomp">mean.acomp</a></code>,
<span class="pkg">robustbase</span>, <a href="#topic+compositions-package">compositions-package</a>,
<a href="#topic+missings">missings</a>, <code><a href="#topic+outlierplot">outlierplot</a></code>,
<code><a href="#topic+OutlierClassifier1">OutlierClassifier1</a></code>, <code><a href="#topic+ClusterFinder1">ClusterFinder1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(0.1,0.2,0.3,0.1),nrow=2)
Mvar &lt;- 0.1*ilrvar2clr(A%*%t(A))
Mcenter &lt;- acomp(c(1,2,1))
typicalData &lt;- rnorm.acomp(100,Mcenter,Mvar) # main population
colnames(typicalData)&lt;-c("A","B","C")
data5 &lt;- acomp(rbind(unclass(typicalData)+outer(rbinom(100,1,p=0.1)*runif(100),c(0.1,1,2))))

mean(data5)
mean(data5,robust=TRUE)
var(data5)
var(data5,robust=TRUE)
Mvar
biplot(princomp(data5))
biplot(princomp(data5,robust=TRUE))

</code></pre>

<hr>
<h2 id='rplus'>Amounts i.e. positive numbers analysed as objects of the real vector space</h2><span id='topic+rplus'></span>

<h3>Description</h3>

<p>A class to analyse positive amounts in a classical (non-logarithmic) framework.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  rplus(X, parts=1:NCOL(oneOrDataset(X)), total=NA, warn.na=FALSE,
        detectionlimit=NULL, BDL=NULL, MAR=NULL, MNAR=NULL, SZ=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rplus_+3A_x">X</code></td>
<td>
<p>vector or dataset of positive numbers considered as amounts</p>
</td></tr>
<tr><td><code id="rplus_+3A_parts">parts</code></td>
<td>
<p>vector containing the indices  xor names of the columns to be used</p>
</td></tr>
<tr><td><code id="rplus_+3A_total">total</code></td>
<td>
<p>a numeric vectors giving the total amount of each
dataset</p>
</td></tr>
<tr><td><code id="rplus_+3A_warn.na">warn.na</code></td>
<td>
<p>should the user be warned in case of NA,NaN or 0
coding different types of missing values?</p>
</td></tr>
<tr><td><code id="rplus_+3A_detectionlimit">detectionlimit</code></td>
<td>
<p>a number, vector or matrix of positive
numbers giving the detection limit of all values, all columns or
each value, respectively</p>
</td></tr>
<tr><td><code id="rplus_+3A_bdl">BDL</code></td>
<td>
<p>the code for 'Below Detection Limit' in X</p>
</td></tr>
<tr><td><code id="rplus_+3A_sz">SZ</code></td>
<td>
<p>the code for 'Structural Zero' in X</p>
</td></tr>
<tr><td><code id="rplus_+3A_mar">MAR</code></td>
<td>
<p>the code for 'Missing At Random' in X</p>
</td></tr>
<tr><td><code id="rplus_+3A_mnar">MNAR</code></td>
<td>
<p>the code for 'Missing Not At Random' in X</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many multivariate datasets essentially describe amounts of D different
parts in a whole. When the whole is large in relation to the
considered parts, such that they do not exclude each other, and when
the total amount of each componenten is actually determined by the
phenomenon under investigation and not by sampling artifacts (such as dilution
or sample preparation) then the parts can be treated as amounts rather
than as a composition (cf. <code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+aplus">aplus</a></code>).
<br />
In principle, amounts are just real-scaled numbers with the single
restriction that they are nonnegative. Thus they can be analysed by
any multivariate analysis method. This class provides a simple access
interface to do so. It tries to keep in mind the positivity
property of amounts and the special point zero. However there are
strong arguments why an analyis based on log-scale might be much more
adapted to the problem. This log-approach is provided by the class
<code><a href="#topic+aplus">aplus</a></code>. 
</p>
<p>The classes rcomp, acomp, aplus, and rplus are designed in a fashion as similar as
possible in order to allow direct comparison between results obtained  
by the different approaches. In particular, the aplus logistic transform
<code><a href="#topic+ilt">ilt</a></code> is mirrored
by the simple identity transform <code><a href="#topic+iit">iit</a></code>. In terms
of computer science, this identity mapping is actually mapping an object
of type &quot;rplus&quot; to a class-less datamatrix. 
</p>


<h3>Value</h3>

<p>a vector of class <code>"rplus"</code> representing a vector of amounts
or a matrix of class <code>"rplus"</code> representing
multiple vectors of amounts, by rows.  
</p>


<h3>Missing Policy</h3>

<p>Missing and Below Detecion Limit Policy is in mored detailed
explained in <a href="#topic+compositions.missing">compositions.missing</a>. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>van den Boogaart, K.G. and R. Tolosana-Delgado (2008)
&quot;compositions&quot;: a unified R package to analyze Compositional Data,
<em>Computers &amp; Geosciences</em>, 34 (4), pages 320-338,
doi: <a href="https://doi.org/10.1016/j.cageo.2006.11.017">10.1016/j.cageo.2006.11.017</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+iit">iit</a></code>,<code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+aplus">aplus</a></code>,
<code><a href="#topic+princomp.rplus">princomp.rplus</a></code>, 
<code><a href="#topic+plot.rplus">plot.rplus</a></code>, <code><a href="#topic+boxplot.rplus">boxplot.rplus</a></code>,
<code><a href="#topic+barplot.rplus">barplot.rplus</a></code>, <code><a href="#topic+mean.rplus">mean.rplus</a></code>,
<code><a href="#topic+var.rplus">var.rplus</a></code>, <code><a href="#topic+variation.rplus">variation.rplus</a></code>,
<code><a href="#topic+cov.rplus">cov.rplus</a></code>, <code><a href="#topic+msd">msd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(rplus(sa.lognormals))

</code></pre>

<hr>
<h2 id='rplus-class'>Class <code>"rplus"</code></h2><span id='topic+rplus-class'></span><span id='topic+coerce+2Crplus+2Cdata.frame-method'></span><span id='topic+coerce+2Crplus+2Cstructure-method'></span><span id='topic+coerce+3C-+2Crplus+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>The S4-version of the data container &quot;rplus&quot; for compositional data. More information in 
<code><a href="#topic+rplus">rplus</a></code>
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be directly created from it. 
This is provided to ensure that rplus objects behave as data.frame or structure under certain circumstances. Use <code><a href="#topic+rplus">rplus</a></code> to create these objects.</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Object of class <code>"list"</code> containing the data itself </p>
</dd>
<dt><code>names</code>:</dt><dd><p>Object of class <code>"character"</code> with column names </p>
</dd>
<dt><code>row.names</code>:</dt><dd><p>Object of class <code>"data.frameRowLabels"</code> with row names </p>
</dd>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code> with the class string </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+data.frame-class">data.frame</a>"</code>, directly.
Class <code>"<a href="#topic+compositional-class">compositional</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+list-class">list</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;data.frame&quot;, distance 2.
Class <code>"<a href="methods.html#topic+vector-class">vector</a>"</code>, by class &quot;data.frame&quot;, distance 3.
</p>


<h3>Methods</h3>


<dl>
<dt>coerce</dt><dd><p><code>signature(from = "rplus", to = "data.frame")</code>: to generate a data.frame </p>
</dd>
<dt>coerce</dt><dd><p><code>signature(from = "rplus", to = "structure")</code>: to generate a structure (i.e. a vector, matrix or array) </p>
</dd>
<dt>coerce&lt;-</dt><dd><p><code>signature(from = "rplus", to = "data.frame")</code>: to overwrite a composition with a data.frame</p>
</dd>
</dl>



<h3>Note</h3>

<p>see <code><a href="#topic+rplus">rplus</a></code>
</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado
</p>


<h3>References</h3>

<p>see <code><a href="#topic+rplus">rplus</a></code>
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+rplus">rplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("rplus")
</code></pre>

<hr>
<h2 id='rplusarithm'>vectorial arithmetic for data sets with rplus class</h2><span id='topic++2B.rplus'></span><span id='topic+-.rplus'></span><span id='topic++2A.rplus'></span><span id='topic++2F.rplus'></span><span id='topic+mul.rplus'></span>

<h3>Description</h3>

<p>The positive quadrant forms a manifold of the real vector space. The
induced operations +,-,*,/ give results valued in this real vector space 
(not necessarily inside the manifold).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mul.rplus(x,r)
## Methods for class rplus
##   x+y
##  x-y
##   -x
##   x*r
##   r*x
##   x/r
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rplusarithm_+3A_x">x</code></td>
<td>
<p>an rplus composition or dataset of compositions </p>
</td></tr>
<tr><td><code id="rplusarithm_+3A_y">y</code></td>
<td>
<p>an rplus composition or dataset of compositions </p>
</td></tr>
<tr><td><code id="rplusarithm_+3A_r">r</code></td>
<td>
<p>a numeric vector of size 1 or nrow(x)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions behave quite like <code><a href="#topic++2B.rmult">+.rmult</a></code>.<br />
</p>


<h3>Value</h3>

<p><code>rmult</code>-objects containing the given operations on the rcomp
manifold as subset of the <code class="reqn">R^D</code>. Only the addition and
multiplication with positive numbers are internal
operation and results in an <code>rplus</code>-object again.
</p>


<h3>Note</h3>

<p>For <code>*</code> the arguments x and y can be exchanged.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic++2B.rmult">+.rmult</a></code>, <code><a href="#topic++2B.acomp">+.acomp</a></code>,<code><a href="#topic+cpt">cpt</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+rmult">rmult</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rplus(1:5)* -1 + rplus(1:5)
data(SimulatedAmounts)
cdata &lt;- rplus(sa.lognormals)
plot( tmp &lt;- (cdata-mean(cdata))/msd(cdata) )
class(tmp)
mean(tmp)
msd(tmp)
var(tmp)
</code></pre>

<hr>
<h2 id='rpois'>Simulate count compositions without overdispersion</h2><span id='topic+rpois.ccomp'></span><span id='topic+rmultinom.ccomp'></span>

<h3>Description</h3>

<p>Generates multinomial or multi-Poission random variates based on an
Aitchison composition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpois.ccomp(n,p,lambda)
rmultinom.ccomp(n,p,N)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpois_+3A_n">n</code></td>
<td>
<p>number of datasets to be simulated</p>
</td></tr>
<tr><td><code id="rpois_+3A_p">p</code></td>
<td>
<p>The composition representing the probabilites/portions of the
individual parts</p>
</td></tr>
<tr><td><code id="rpois_+3A_lambda">lambda</code></td>
<td>
<p>scalar or vector giving the expected total count</p>
</td></tr>
<tr><td><code id="rpois_+3A_n">N</code></td>
<td>
<p>scalar or vector giving the total count</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A count composition is a realisation of a multinomial or multivariate
Poisson distribution. 
</p>


<h3>Value</h3>

<p>a random dataset ccount dataset
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+rnorm.ccomp">rnorm.ccomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- acomp(c(3,3,3))
rpois.ccomp(10,p,40)
rmultinom.ccomp(10,p,40)

</code></pre>

<hr>
<h2 id='runif'>The uniform distribution on the simplex</h2><span id='topic+runif.acomp'></span><span id='topic+runif.rcomp'></span>

<h3>Description</h3>

<p>Generates random compositions with a uniform distribution on the
(rcomp) simplex. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runif.acomp(n,D)
runif.rcomp(n,D)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runif_+3A_n">n</code></td>
<td>
<p>number of datasets to be simulated</p>
</td></tr>
<tr><td><code id="runif_+3A_d">D</code></td>
<td>
<p>number of parts</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a generated random dataset of class <code>"acomp"</code> or <code>"rcomp"</code>
drawn from a uniform distribution on the simplex of D parts. </p>


<h3>Note</h3>

<p>The only difference between both routines is the class of
the dataset returned.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rDirichlet.acomp">rDirichlet.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(runif.acomp(10,3))
plot(runif.rcomp(10,3))
</code></pre>

<hr>
<h2 id='scalar'>Parallel scalar products </h2><span id='topic+scalar'></span><span id='topic+scalar.default'></span>

<h3>Description</h3>

<p>Computes scalar products of datasets of vectors or vectorial quantities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scalar(x,y)
## Default S3 method:
scalar(x,y)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scalar_+3A_x">x</code></td>
<td>
<p>a vector or a matrix with rows considered as vectors</p>
</td></tr>
<tr><td><code id="scalar_+3A_y">y</code></td>
<td>
<p>a vector or a matrix with rows considered as vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The scalar product of two vectors is defined as:
</p>
<p style="text-align: center;"><code class="reqn">scalar(x,y):=  \sum(x_iy_i) </code>
</p>



<h3>Value</h3>

<p>a numerical vector containing the scalar products of the vectors given
by x and y. If both <code>x</code> and <code>y</code> contain more than one
vector the function uses parallel operation like it would happen with
an ordinary product of vectors.
</p>


<h3>Note</h3>

<p>The computation of the scalar product implicitly applies
the <code><a href="#topic+cdt">cdt</a></code> transform, which implies that the scalar products
corresponding to the given geometries are returned for <code><a href="#topic+acomp">acomp</a></code>,
<code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+aplus">aplus</a></code>,
<code><a href="#topic+rplus">rplus</a></code>-objects. Even a useful scalar product for factors
is induced in this way.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>scalar(acomp(c(1,2,3)),acomp(c(1,2,3)))
scalar(rmult(c(1,2,3)),rmult(c(1,2,3)))
</code></pre>

<hr>
<h2 id='scale'>Normalizing datasets by centering and scaling</h2><span id='topic+scale.acomp'></span><span id='topic+scale.aplus'></span><span id='topic+scale.rcomp'></span><span id='topic+scale.rplus'></span><span id='topic+scale.rmult'></span><span id='topic+scale'></span><span id='topic+scale.default'></span>

<h3>Description</h3>

<p>The dataset is standardized by optional scaling and centering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale(x, center = TRUE, scale = TRUE,...)
## Default S3 method:
scale(x,center=TRUE, scale=TRUE,...)
## S3 method for class 'acomp'
scale(x,center=TRUE, scale=TRUE,...,robust=getOption("robust"))
## S3 method for class 'rcomp'
scale(x,center=TRUE, scale=TRUE,...,robust=getOption("robust"))
## S3 method for class 'aplus'
scale(x,center=TRUE, scale=TRUE,...,robust=getOption("robust"))
## S3 method for class 'rplus'
scale(x,center=TRUE, scale=TRUE,...,robust=getOption("robust"))
## S3 method for class 'rmult'
scale(x,center=TRUE, scale=TRUE,...,robust=getOption("robust"))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scale_+3A_x">x</code></td>
<td>
<p>a dataset or a single vector of some type</p>
</td></tr>
<tr><td><code id="scale_+3A_center">center</code></td>
<td>
<p>logical value or the center to be substracted.</p>
</td></tr>
<tr><td><code id="scale_+3A_scale">scale</code></td>
<td>
<p>logical value or a scaling factor to for multiplication.</p>
</td></tr>
<tr><td><code id="scale_+3A_robust">robust</code></td>
<td>
<p>A robustness description. See
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for details. </p>
</td></tr>
<tr><td><code id="scale_+3A_...">...</code></td>
<td>
<p>added for generic generality</p>
</td></tr>
</table>


<h3>Details</h3>

<p>scaling is defined in different ways for the different data types. It is
always performed as an operation in the enclosing vector space. In
all cases an independent scaling of the different coordinates is not always
appropriate. This is only done for rplus and rmult geometries. The other three
geometries are treated with a global scaling, keeping the relative variations
of every part/amount.
</p>
<p>The scaling factors can be a matrix (for cdt or idt space), a scalar,
or for the r* geometries vector for scaling the entries
individually. However scaling the entries individually does not make
sense in the a* geometries. The operation achieve in the r*-geometries
is indeed the centering of the a*-geometries. 
</p>


<h3>Value</h3>

<p>a vector or data matrix, as <code>x</code> and with the same class, but acordingly transformed.
</p>


<h3>Note</h3>

<p>Note that the <code>"rcomp"</code> and <code>"rplus"</code> objects does not
preserve their
geometry during scaling and are therefore reported as <code>"rmult"</code> objects.
</p>
<p>See the documentation in package base for details on

<code>base::scale</code> and <code>base::scale.default</code>
These functions are only modified
to allow the additional robustness parameter. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+split">split</a>{base}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(SimulatedAmounts)
  plot(scale(acomp(sa.groups)))
  ## Not run: 
plot(scale(rcomp(sa.groups)))

## End(Not run)
  plot(scale(aplus(sa.groups)))
  ## Not run: 
plot(scale(rplus(sa.groups)))

## End(Not run)
  plot(scale(rmult(sa.groups)))

</code></pre>

<hr>
<h2 id='Sediments'>Proportions of sand, silt and clay in sediments specimens</h2><span id='topic+Data20'></span><span id='topic+Sediments'></span>

<h3>Description</h3>

<p>Data provide sand, silt and clay compositions of 21  sediments specimens,
10 of which are identified as <em>offshore,</em> 7 as <em>near shore</em> and 
4 new samples. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Sediments)
</code></pre>


<h3>Format</h3>


<dl>
<dt>sand</dt><dd><p>numeric: the portion of sand</p>
</dd>
<dt>silt</dt><dd><p>numeric: the protion of silt</p>
</dd>
<dt>clay</dt><dd><p>numeric: the portion of clay</p>
</dd>
<dt>type</dt><dd><p>numeric: 1 for offshore, 2 for near shore and 3 for new
samples</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data comprise 21 cases: 10 offshore, 7 near shore and 4 new samples,
and 4 variables: sand, silt and clay proportions and in addition the type of  
sediments specimens &ndash; 1 for offshore, 2 for near shore and 3 for new samples. 
</p>
<p>All 3-part compositions sum to one.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name YATQUAD.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, (Data 20) pp17. 
</p>

<hr>
<h2 id='segments'>Draws straight lines from point to point.</h2><span id='topic+segments'></span><span id='topic+segments.default'></span><span id='topic+segments.rmult'></span><span id='topic+segments.acomp'></span><span id='topic+segments.rcomp'></span><span id='topic+segments.aplus'></span><span id='topic+segments.rplus'></span>

<h3>Description</h3>

<p>The function draws lines from a points x0 to a point y1 in the given geometry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          segments(x0,...)
          ## Default S3 method:
segments(x0,...)
          ## S3 method for class 'acomp'
segments(x0,y1,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rcomp'
segments(x0,y1,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'aplus'
segments(x0,y1,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rplus'
segments(x0,y1,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rmult'
segments(x0,y1,...,steps=30,aspanel=FALSE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segments_+3A_x0">x0</code></td>
<td>
<p>dataset of points (of the given type) to draw the line from</p>
</td></tr>
<tr><td><code id="segments_+3A_y1">y1</code></td>
<td>
<p>dataset of points (of the given type) to draw the line to</p>
</td></tr>
<tr><td><code id="segments_+3A_...">...</code></td>
<td>
<p>further graphical parameters</p>
</td></tr>
<tr><td><code id="segments_+3A_steps">steps</code></td>
<td>
<p>the number of discretisation points to draw the segments,
since the representation might not visually be a straight line</p>
</td></tr>
<tr><td><code id="segments_+3A_aspanel">aspanel</code></td>
<td>
<p>Logical, indicates use as slave to do acutal drawing only.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default 'segments.default(x0,...)' redirects to 'segments' in package &quot;graphics&quot;.
</p>
<p>The other methods add lines to the graphics generated with the corresponding
plot functions of &quot;compositions&quot;-classes.
<br />
</p>
<p>Adding to multipaneled plots redraws the plot completely, and is only
possible when the plot has been created with the plotting routines from
this library.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>,<code><a href="#topic+lines.acomp">lines.acomp</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)

plot(acomp(sa.lognormals))
segments.acomp(acomp(c(1,2,3)),acomp(c(2,3,1)),col="red")
segments.rcomp(acomp(c(1,2,3)),acomp(c(2,3,1)),col="blue")

plot(aplus(sa.lognormals[,1:2]))
segments.aplus(aplus(c(10,20)),aplus(c(20,10)),col="red")
segments.rplus(rplus(c(10,20)),rplus(c(20,10)),col="blue")

plot(rplus(sa.lognormals[,1:2]))
segments.aplus(aplus(c(10,20)),aplus(c(20,10)),col="red")
segments.rplus(rplus(c(10,20)),rplus(c(20,10)),col="blue")




</code></pre>

<hr>
<h2 id='SerumProtein'>Serum Protein compositions of blood samples</h2><span id='topic+Data16'></span><span id='topic+SerumProtein'></span>

<h3>Description</h3>

<p>Data recording the proportions of the 4 serum proteins from blood samples
of 30 patients, 14 with known disease A, 16 with known disease B, and
6 new cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SerumProtein)
</code></pre>


<h3>Format</h3>


<dl>
<dt>a</dt><dd><p>numeric a protein type</p>
</dd>
<dt>b</dt><dd><p>numeric a protein type</p>
</dd>
<dt>c</dt><dd><p>numeric a protein type</p>
</dd>
<dt>d</dt><dd><p>numeric a protein type</p>
</dd>
<dt>Type</dt><dd><p>1 deasease A, 2 disease B, 3 new cases</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data consist of 36 cases: 14 with known disease A, 16 with known disease B, and
6 new cases and 5 v variables: a, b, c, and d for 4 serum proteins and Type
for the diseases: 1 for  disease A, 2 for  disease B, and 3 for new cases. 
All row serum proteins proportions sums to 1 except some rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name SERPROT.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data (Data 16) pp20.
</p>

<hr>
<h2 id='ShiftOperators'>Shifts of machine operators</h2><span id='topic+Data22'></span><span id='topic+ShiftOperators'></span>

<h3>Description</h3>

<p>Compsitions of eight-hours shifts of 27 machine operators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ShiftOperators)
</code></pre>


<h3>Details</h3>

<p>A study of the activities of 27 machine operators during their
eight-hours shifts has been conducted, and proportions of time spend in the 
following categories:
</p>

<table>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> A: </td><td style="text-align: left;"> high-quality production,</td>
</tr>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> B: </td><td style="text-align: left;"> low-quality production,</td>
</tr>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> C: </td><td style="text-align: left;"> machine setting,</td>
</tr>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: left;"> D: </td><td style="text-align: left;"> machine repair,
</td>
</tr>

</table>

<p>are recorded.
Of particular interest are any insights which such data  might give of relationships
between productive and nonproductive parts of such shifts. All compositions sum up 
one except for rounding error.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name SHIFT.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, (Data 22), pp22. 
</p>

<hr>
<h2 id='simplemissingplot'>Ternary diagrams</h2><span id='topic+simpleMissingSubplot'></span>

<h3>Description</h3>

<p>Displaying compositions in ternary diagrams
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpleMissingSubplot(loc, portions, labels=NULL,
          col=c("white","yellow","red","green","blue"), 
          ..., border="gray60", vertical=NULL, xpd=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simplemissingplot_+3A_loc">loc</code></td>
<td>
<p>a vector of the form c(x1,x2,y1,y2) giving the drawing
rectangle for the subplot in coordinates as in par(&quot;usr&quot;). I.e. if
the plot is logrithmic the base 10 logarithm is to be used:
</p>

<dl>
<dt>x1</dt><dd><p>left boundary of drawing rectangle</p>
</dd>
<dt>y1</dt><dd><p>lower boundary of drawing rectangle</p>
</dd>
<dt>x2</dt><dd><p>right boundary of drawing rectangle</p>
</dd>
<dt>y2</dt><dd><p>upper boundary of drawing rectangle</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="simplemissingplot_+3A_portions">portions</code></td>
<td>
<p>The portions of different missing categories</p>
</td></tr>
<tr><td><code id="simplemissingplot_+3A_labels">labels</code></td>
<td>
<p>The labels for the categories. </p>
</td></tr>
<tr><td><code id="simplemissingplot_+3A_col">col</code></td>
<td>
<p>The colors to plot the different categories.</p>
</td></tr>
<tr><td><code id="simplemissingplot_+3A_...">...</code></td>
<td>
<p>further graphical parameters passed to
<code><a href="graphics.html#topic+text">text</a></code></p>
</td></tr>
<tr><td><code id="simplemissingplot_+3A_border">border</code></td>
<td>
<p>The color to draw the borders of the rectangles.</p>
</td></tr>
<tr><td><code id="simplemissingplot_+3A_vertical">vertical</code></td>
<td>
<p>Should a horizontal or a vertical plot be produced. If
NULL the choice is done automatically according to the size of the
recangle provided.</p>
</td></tr>
<tr><td><code id="simplemissingplot_+3A_xpd">xpd</code></td>
<td>
<p>extended plot region. See <code>par("xpd")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is typically not called directly,however it could in
principle be used to add to plots.
The user will modify the function call only to modify the appearance
of the missing plot.
</p>
<p>The labels are only
plotted for nonzero portions. In this way it is always possible to
realize the presence of a given missing type, even if it is a too small
portion to be actually displayed. In case of overplotting of different
labels a further investigation using missingSummary should be used.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.aplus">plot.aplus</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(acomp(sa.missings))
plot(acomp(sa.missings),mp=~simpleMissingSubplot(c(0,0.1,0.2,1),
   missingInfo[c(1,3:5,2)], 
   c("Not Missing",paste("Missing Only:",cn),"Totally Missing"),
   col=c("gray","red","green","blue","darkgray"))
)
ms &lt;- missingSummary(sa.missings)
for( i in 1:3 )
  simpleMissingSubplot(c(0.9+0.03*(i-1),0.9+0.03*i,0.2,1), ms[i,])
</code></pre>

<hr>
<h2 id='SimulatedAmounts'>Simulated amount datasets</h2><span id='topic+SimulatedAmounts'></span><span id='topic+sa.dirichlet'></span><span id='topic+sa.dirichlet.dil'></span><span id='topic+sa.dirichlet.mix'></span><span id='topic+sa.dirichlet5'></span><span id='topic+sa.dirichlet5.dil'></span><span id='topic+sa.dirichlet5.mix'></span><span id='topic+sa.uniform'></span><span id='topic+sa.uniform.dil'></span><span id='topic+sa.uniform.mix'></span><span id='topic+sa.uniform5'></span><span id='topic+sa.uniform5.dil'></span><span id='topic+sa.uniform5.mix'></span><span id='topic+sa.lognormals'></span><span id='topic+sa.lognormals.dil'></span><span id='topic+sa.lognormals.mix'></span><span id='topic+sa.lognormals5'></span><span id='topic+sa.lognormals5.dil'></span><span id='topic+sa.lognormals5.mix'></span><span id='topic+sa.tnormals'></span><span id='topic+sa.tnormals.dil'></span><span id='topic+sa.tnormals.mix'></span><span id='topic+sa.tnormals5'></span><span id='topic+sa.tnormals5.dil'></span><span id='topic+sa.tnormals5.mix'></span><span id='topic+sa.groups'></span><span id='topic+sa.groups.dil'></span><span id='topic+sa.groups.mix'></span><span id='topic+sa.groups5'></span><span id='topic+sa.groups5.dil'></span><span id='topic+sa.groups5.mix'></span><span id='topic+sa.groups.area'></span><span id='topic+sa.groups5.area'></span><span id='topic+sa.outliers1'></span><span id='topic+sa.outliers2'></span><span id='topic+sa.outliers3'></span><span id='topic+sa.outliers4'></span><span id='topic+sa.outliers5'></span><span id='topic+sa.outliers6'></span><span id='topic+sa.missings'></span><span id='topic+sa.missings5'></span>

<h3>Description</h3>

<p>Several simulated datasets intended as reference examples for various
conceptual and statistical models of compositions and amounts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SimulatedAmounts)</code></pre>


<h3>Format</h3>

<p>Data matrices with 60 cases and 3 or 5 variables.</p>


<h3>Details</h3>

<p>The statistical analysis of amounts and compositions is set to
discussion. Four essentially different approaches are
provided in this package around the classes &quot;rplus&quot;, &quot;aplus&quot;,
&quot;rcomp&quot;, &quot;acomp&quot;. There is no absolutely &quot;right&quot; approach, since there is
a conection between these approaches and the processes originating the data. 
We provide here simulated
standard datasets and the corresponding simulation procedures
following these several models to provide &quot;good&quot; analysis examples
and to show how these models actually look like in data.
<br />
</p>
<p>The data sets are simulated according to correlated lognormal
distributions (sa.lognormals, sa.lognormal5), winsorised correlated
normal distributions (sa.tnormals, sa.tnormal5), Dirichlet
distribution on the simplex (sa.dirichlet, sa.dirichlet5),
uniform distribution on the simplex  (sa.uniform, sa.uniform5), and
a grouped dataset (sa.groups, sa.groups5) with three
groups (given in sa.groups.area and sa.groups5.area) all distributed
accordingly with a lognormal distribution with group-dependent means.<br />
</p>
<p>We can imagine that amounts evolve in nature e.g. in part of the soil they are
diluted and transported in a transport medium, usually water, which
comes from independent source (the rain, for instance) and this new
composition is normalized by taking a sample of standard size.
For each of the datasets <var>sa.X</var> there is a corresponding
<var>sa.X</var><code>.dil</code> dataset which is build by simulating exactly that process
on the corresponding <var>sa.X</var> dataset . The
amounts in the <var>sa.X</var><code>.dil</code> are given in ppm. This idea
of a transport medium is a major argument for a compositional
approach, because the total amount given by the sum of the
parts is induced by the dilution given by the medium and
thus non-informative for the original process investigated.
<br />
</p>
<p>If we imagine now these amounts flowing into a river and sedimenting, the different contributions
are accumulated along the river and renormalized to a unit portion on
taking samples again. For each of the dataset
<var>sa.X</var><code>.dil</code> there is a corresponding
<var>sa.X</var><code>.mix</code> dataset which is built from the corresponding
<var>sa.X</var> dataset by simulating exactly that accumulation
process. Mixing of different compositions is a major argument against
the log based approaches (<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+acomp">acomp</a></code>)
since mixing is a highly nonlinear operation in terms of log-ratios.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>Source</h3>

<p>The datasets are simulated for this package and are under the
GNU Public Library Licence Version 2 or newer. </p>


<h3>References</h3>


<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Rehder, S. and U. Zier (2001) Letter to the Editor: Comment on 
&rdquo;Logratio Analysis and Compositional Distance&rdquo; by J. Aitchison, C. 
Barcel\'o -Vidal, J.A. Mart\'in-Fern\'andez and V. Pawlowsky-Glahn,
<em>Mathematical Geology</em>, <b>33</b> (7), 845-848.<br />
</p>
<p>Zier, U. and S. Rehder (2002) Some comments on log-ratio transformation and compositional distance,
<em>Terra Nostra</em>, Schriften der Alfred Wegener-Stiftung, 03/2003<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot.acomp(sa.lognormals)
plot.acomp(sa.lognormals.dil)
plot.acomp(sa.lognormals.mix)
plot.acomp(sa.lognormals5)
plot.acomp(sa.lognormals5.dil)
plot.acomp(sa.lognormals5.mix)

plot(acomp(sa.missings))
plot(acomp(sa.missings5))

#library(MASS)
plot.rcomp(sa.tnormals)
plot.rcomp(sa.tnormals.dil)
plot.rcomp(sa.tnormals.mix)
plot.rcomp(sa.tnormals5)
plot.rcomp(sa.tnormals5.dil)
plot.rcomp(sa.tnormals5.mix)

plot.acomp(sa.groups,col=as.numeric(sa.groups.area),pch=20)
plot.acomp(sa.groups.dil,col=as.numeric(sa.groups.area),pch=20)
plot.acomp(sa.groups.mix,col=as.numeric(sa.groups.area),pch=20)
plot.acomp(sa.groups5,col=as.numeric(sa.groups.area),pch=20)
plot.acomp(sa.groups5.dil,col=as.numeric(sa.groups.area),pch=20)
plot.acomp(sa.groups5.mix,col=as.numeric(sa.groups.area),pch=20)

plot.acomp(sa.uniform)
plot.acomp(sa.uniform.dil)
plot.acomp(sa.uniform.mix)
plot.acomp(sa.uniform5)
plot.acomp(sa.uniform5.dil)
plot.acomp(sa.uniform5.mix)

plot.acomp(sa.dirichlet)
plot.acomp(sa.dirichlet.dil)
plot.acomp(sa.dirichlet.mix)
plot.acomp(sa.dirichlet5)
plot.acomp(sa.dirichlet5.dil)
plot.acomp(sa.dirichlet5.mix)

# The data was simulated with the following commands:

#library(MASS)
dilution &lt;- function(x) {clo(cbind(x,exp(rnorm(nrow(x),5,1))))[,1:ncol(x)]*1E6}
seqmix   &lt;- function(x) {clo(apply(x,2,cumsum))*1E6}


vars  &lt;- c("Cu","Zn","Pb")
vars5 &lt;- c("Cu","Zn","Pb","Cd","Co")

sa.lognormals &lt;- structure(exp(matrix(rnorm(3*60),ncol=3) %*%
                               chol(matrix(c(1,0.8,-0.2,0.8,1,
                                             -0.2,-0.2,-0.2,1),ncol=3))+
                               matrix(rep(c(1:3),each=60),ncol=3)),
                           dimnames=list(NULL,vars))

plot.acomp(sa.lognormals)
pairs(sa.lognormals)

sa.lognormals.dil &lt;- dilution(sa.lognormals)
plot.acomp(sa.lognormals.dil)
pairs(sa.lognormals.dil)

sa.lognormals.mix &lt;- seqmix(sa.lognormals.dil)
plot.acomp(sa.lognormals.mix)
pairs(sa.lognormals.mix)


sa.lognormals5 &lt;- structure(exp(matrix(rnorm(5*60),ncol=5) %*%
                               chol(matrix(c(1,0.8,-0.2,0,0,
                                             0.8,1,-0.2,0,0,
                                             -0.2,-0.2,1,0,0,
                                             0,0,0,5,4.9,
                                             0,0,0,4.9,5),ncol=5))+
                               matrix(rep(c(1:3,-2,-2),each=60),ncol=5)),
                           dimnames=list(NULL,vars5))

plot.acomp(sa.lognormals5)
pairs(sa.lognormals5)

sa.lognormals5.dil &lt;- dilution(sa.lognormals5)
plot.acomp(sa.lognormals5.dil)
pairs(sa.lognormals5.dil)

sa.lognormals5.mix &lt;- seqmix(sa.lognormals5.dil)
plot.acomp(sa.lognormals5.mix)
pairs(sa.lognormals5.mix)



sa.groups.area &lt;- factor(rep(c("Upper","Middle","Lower"),each=20))
sa.groups &lt;- structure(exp(matrix(rnorm(3*20*3),ncol=3) %*%
                               chol(0.5*matrix(c(1,0.8,-0.2,0.8,1,
                                             -0.2,-0.2,-0.2,1),ncol=3))+
                               matrix(rep(c(1,2,2.5,2,2.9,5,4,2,5),
                                          each=20),ncol=3)),
                           dimnames=list(NULL,c("clay","sand","gravel")))

plot.acomp(sa.groups,col=as.numeric(sa.groups.area),pch=20)
pairs(sa.lognormals,col=as.numeric(sa.groups.area),pch=20)

sa.groups.dil &lt;- dilution(sa.groups)
plot.acomp(sa.groups.dil,col=as.numeric(sa.groups.area),pch=20)
pairs(sa.groups.dil,col=as.numeric(sa.groups.area),pch=20)

sa.groups.mix &lt;- seqmix(sa.groups.dil)
plot.acomp(sa.groups.mix,col=as.numeric(sa.groups.area),pch=20)
pairs(sa.groups.mix,col=as.numeric(sa.groups.area),pch=20)



sa.groups5.area &lt;- factor(rep(c("Upper","Middle","Lower"),each=20))
sa.groups5 &lt;- structure(exp(matrix(rnorm(5*20*3),ncol=5) %*%
                               chol(matrix(c(1,0.8,-0.2,0,0,
                                             0.8,1,-0.2,0,0,
                                             -0.2,-0.2,1,0,0,
                                             0,0,0,5,4.9,
                                             0,0,0,4.9,5),ncol=5))+
                               matrix(rep(c(1,2,2.5,
                                            2,2.9,5,
                                            4,2.5,0,
                                            -2,-1,-1,
                                            -1,-2,-3),
                                          each=20),ncol=5)),
                           dimnames=list(NULL,
                             vars5))

plot.acomp(sa.groups5,col=as.numeric(sa.groups5.area),pch=20)
pairs(sa.groups5,col=as.numeric(sa.groups5.area),pch=20)

sa.groups5.dil &lt;- dilution(sa.groups5)
plot.acomp(sa.groups5.dil,col=as.numeric(sa.groups5.area),pch=20)
pairs(sa.groups5.dil,col=as.numeric(sa.groups5.area),pch=20)

sa.groups5.mix &lt;- seqmix(sa.groups5.dil)
plot.acomp(sa.groups5.mix,col=as.numeric(sa.groups5.area),pch=20)
pairs(sa.groups5.mix,col=as.numeric(sa.groups5.area),pch=20)



sa.tnormals &lt;- structure(pmax(matrix(rnorm(3*60),ncol=3) %*%
                               chol(matrix(c(1,0.8,-0.2,0.8,1,
                                             -0.2,-0.2,-0.2,1),ncol=3))+
                               matrix(rep(c(0:2),each=60),ncol=3),0),
                           dimnames=list(NULL,c("clay","sand","gravel")))

plot.rcomp(sa.tnormals)
pairs(sa.tnormals)

sa.tnormals.dil &lt;- dilution(sa.tnormals)
plot.acomp(sa.tnormals.dil)
pairs(sa.tnormals.dil)

sa.tnormals.mix &lt;- seqmix(sa.tnormals.dil)
plot.acomp(sa.tnormals.mix)
pairs(sa.tnormals.mix)



sa.tnormals5 &lt;- structure(pmax(matrix(rnorm(5*60),ncol=5) %*%
                               chol(matrix(c(1,0.8,-0.2,0,0,
                                             0.8,1,-0.2,0,0,
                                             -0.2,-0.2,1,0,0,
                                             0,0,0,0.05,0.049,
                                             0,0,0,0.049,0.05),ncol=5))+
                               matrix(rep(c(0:2,0.1,0.1),each=60),ncol=5),0),
                           dimnames=list(NULL,
                             vars5))

plot.rcomp(sa.tnormals5)
pairs(sa.tnormals5)

sa.tnormals5.dil &lt;- dilution(sa.tnormals5)
plot.acomp(sa.tnormals5.dil)
pairs(sa.tnormals5.dil)

sa.tnormals5.mix &lt;- seqmix(sa.tnormals5.dil)
plot.acomp(sa.tnormals5.mix)
pairs(sa.tnormals5.mix)



sa.dirichlet &lt;- sapply(c(clay=0.2,sand=2,gravel=3),rgamma,n=60)
colnames(sa.dirichlet) &lt;- vars

plot.acomp(sa.dirichlet)
pairs(sa.dirichlet)

sa.dirichlet.dil &lt;- dilution(sa.dirichlet)
plot.acomp(sa.dirichlet.dil)
pairs(sa.dirichlet.dil)

sa.dirichlet.mix &lt;- seqmix(sa.dirichlet.dil)
plot.acomp(sa.dirichlet.mix)
pairs(sa.dirichlet.mix)



sa.dirichlet5 &lt;- sapply(c(clay=0.2,sand=2,gravel=3,humus=0.1,plant=0.1),rgamma,n=60)
colnames(sa.dirichlet5) &lt;- vars5

plot.acomp(sa.dirichlet5)
pairs(sa.dirichlet5)

sa.dirichlet5.dil &lt;- dilution(sa.dirichlet5)
plot.acomp(sa.dirichlet5.dil)
pairs(sa.dirichlet5.dil)

sa.dirichlet5.mix &lt;- seqmix(sa.dirichlet5.dil)
plot.acomp(sa.dirichlet5.mix)
pairs(sa.dirichlet5.mix)


sa.uniform   &lt;- sapply(c(clay=1,sand=1,gravel=1),rgamma,n=60)
colnames(sa.uniform) &lt;- vars

plot.acomp(sa.uniform)
pairs(sa.uniform)

sa.uniform.dil &lt;- dilution(sa.uniform)
plot.acomp(sa.uniform.dil)
pairs(sa.uniform.dil)

sa.uniform.mix &lt;- seqmix(sa.uniform.dil)
plot.acomp(sa.uniform.mix)
pairs(sa.uniform.mix)



sa.uniform5   &lt;- sapply(c(clay=1,sand=1,gravel=1,humus=1,plant=1),rgamma,n=60)
colnames(sa.uniform5) &lt;- vars5

plot.acomp(sa.uniform5)
pairs(sa.uniform5)

sa.uniform5.dil &lt;- dilution(sa.uniform5)
plot.acomp(sa.uniform5.dil)
pairs(sa.uniform5.dil)

sa.uniform5.mix &lt;- seqmix(sa.uniform5.dil)
plot.acomp(sa.uniform5.mix)
pairs(sa.uniform5.mix)

tmp&lt;-set.seed(1400)
A &lt;- matrix(c(0.1,0.2,0.3,0.1),nrow=2)
Mvar &lt;- 0.1*ilrvar2clr(A %*% t(A))
Mcenter &lt;- acomp(c(1,2,1))
typicalData &lt;- rnorm.acomp(100,Mcenter,Mvar) # main population
colnames(typicalData)&lt;-c("A","B","C")
# A dataset without outliers
sa.outliers1 &lt;- acomp(rnorm.acomp(100,Mcenter,Mvar))
# A dataset with 10% data with a large error in the first component
sa.outliers2 &lt;- acomp(rbind(typicalData+rbinom(100,1,p=0.1)*rnorm(100)*acomp(c(4,1,1))))
# A dataset with a single outlier
sa.outliers3 &lt;- acomp(rbind(typicalData,acomp(c(0.5,1.5,2))))
colnames(sa.outliers3)&lt;-colnames(typicalData)
tmp&lt;-set.seed(30)
rcauchy.acomp &lt;- function (n, mean, var){
  D &lt;- gsi.getD(mean)-1
  perturbe(ilrInv(matrix(rnorm(n*D)/rep(rnorm(n),D), ncol = D) %*% chol(clrvar2ilr(var))), mean)
}
# A dataset with a Cauchy type distribution
sa.outliers4 &lt;- acomp(rcauchy.acomp(100,acomp(c(1,2,1)),Mvar/4))
colnames(sa.outliers4)&lt;-colnames(typicalData)
# A dataset with like sa.outlier2 but a differently strong distortions
sa.outliers5 &lt;- acomp(rbind(unclass(typicalData)+outer(rbinom(100,1,p=0.1)*runif(100),c(0.1,1,2))))
# A dataset with a second population
sa.outliers6 &lt;- acomp(rbind(typicalData,rnorm.acomp(20,acomp(c(4,4,1)),Mvar)))

# Missings
sa.missings &lt;- simulateMissings(sa.lognormals,dl=0.05,MAR=0.05,MNAR=0.05,SZ=0.05)
sa.missings[5,2]&lt;-BDLvalue

sa.missings5 &lt;- simulateMissings(sa.lognormals5,dl=0.05,MAR=0.05,MNAR=0.05,SZ=0.05)
sa.missings5[5,2]&lt;-BDLvalue


objects(pattern="sa.*")
 </code></pre>

<hr>
<h2 id='simulatemissings'>Artifical simulation of various kinds of missings/polluted data</h2><span id='topic+simulateMissings'></span><span id='topic+observeWithAdditiveError'></span><span id='topic+observeWithDetectionLimit'></span><span id='topic+observeWithDetectionlimit'></span>

<h3>Description</h3>

<p>These are simulation mechanisms to check that missing techniques perform 
in sensible ways. They just generate additional missings of the various types 
in a given dataset, according to a specific process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateMissings(x, dl=NULL, knownlimit=FALSE,
     MARprob=0.0, MNARprob=0.0, mnarity=0.5, SZprob=0.0)
observeWithAdditiveError(x, sigma=dl/dlf, dl=sigma*dlf, dlf=3,
     keepObs=FALSE, digits=NA, obsScale=1,
     class="acomp")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulatemissings_+3A_x">x</code></td>
<td>
<p>a dataset that should get the missings</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_dl">dl</code></td>
<td>
<p>the detection limit described in
<code><a href="#topic+clo">clo</a></code>, to impose an artificial detection limit</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_knownlimit">knownlimit</code></td>
<td>
<p>a boolean indicating wether the actual detection
limit is still known in the dataset.</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_marprob">MARprob</code></td>
<td>
<p>the probability of occurence of 'Missings At Random' values</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_mnarprob">MNARprob</code></td>
<td>
<p>the probability of occurrence of 'Missings Not At Random'. 
The tendency is that small values have a higher probability to
be missed.</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_mnarity">mnarity</code></td>
<td>
<p>a number between 0 and 1 giving the strength of the
influence of the actual value in becoming a MNAR. 0 means a MAR
like behavior and 1 means that it is just the smallest values that
is lost</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_szprob">SZprob</code></td>
<td>
<p>the probability to obtain a structural zero. This is done
at random like a MAR.</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_sigma">sigma</code></td>
<td>
<p>the standard deviation of the normal distributed extra additive error</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_dlf">dlf</code></td>
<td>
<p>the distance from 0 at which a datum will be considered BDL</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_keepobs">keepObs</code></td>
<td>
<p>should the (closed) data without additive error be returned as an attribute?</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_digits">digits</code></td>
<td>
<p>rounding to be applied to the data with additive error (see Details)</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_obsscale">obsScale</code></td>
<td>
<p>rounding to be applied to the data with additive error 
(see Details). Should be a power of 10.</p>
</td></tr>
<tr><td><code id="simulatemissings_+3A_class">class</code></td>
<td>
<p>class of the output object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Without any additional parameters no missings are generated. 
The procedure to generate MNAR affects all variables.
</p>
<p>Function &quot;simulateMissings&quot; is a multipurpose simulator, where each class 
of missing value is treated separately, and where detection limits are 
specified as thresholds.
</p>
<p>Function &quot;observeWithAdditiveError&quot; simulates data within a very specific 
framework, where an additive error of sd=<code>sigma</code> is added to the input data
<code>x</code>, and BDLs are generated if a datum is less than <code>dfl</code> times
<code>sigma</code>. Afterwards, the resulting data are rounded as
<code>round(data/obsScale,digits)*obsScale</code>, i.e. a certain observation scale
<code>obsScale</code> is chosen, and at that scale, only some <code>digits</code> are kept.
This framework is typical of chemical analyses, and it generates both BDLs and
pollution/rounding of (apparently) &quot;right&quot; data.
</p>


<h3>Value</h3>

<p>A dataset like <code>x</code> but with some additional missings.
</p>


<h3>Author(s)</h3>

<p>K.Gerald van den Boogaart</p>


<h3>References</h3>

<p>van den Boogaart, K., R. Tolosana-Delgado, and M. Bren (2011). The Compositional
Meaning of a Detection Limit. In Proceedings of the 4th International Workshop on
Compositional Data Analysis (2011).
</p>
<p>van den Boogaart, K.G., R. Tolosana-Delgado and M. Templ (2014) Regression with
compositional response having unobserved components or below detection limit 
values. Statistical Modelling (in press).
</p>
<p>See <a href="#topic+compositions.missings">compositions.missings</a> for more details.
</p>


<h3>See Also</h3>

<p><a href="#topic+compositions.missings">compositions.missings</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
x &lt;- acomp(sa.lognormals)
xnew &lt;- simulateMissings(x,dl=0.05,MAR=0.05,MNAR=0.05,SZ=0.05)
acomp(xnew)
plot(missingSummary(xnew))
</code></pre>

<hr>
<h2 id='Skulls'>Measurement of skulls</h2><span id='topic+Data24'></span><span id='topic+Skulls'></span>

<h3>Description</h3>

<p>Measurement in degrees of the angles N, A, B in skulls of 
English seventeenth-century people and Naquada people.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Skulls)
</code></pre>


<h3>Details</h3>

<p>As a part of a study of seventeenth-century English skulls three angles
of a triangle in the cranium  
</p>

<table>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;"> N: </td><td style="text-align: left;"> nasial angle,</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;"> A: </td><td style="text-align: left;"> alveolar angle,</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td><td style="text-align: left;"> B: </td><td style="text-align: left;"> basilar angle,
  </td>
</tr>

</table>

<p>were measured for 22 female and 29 male skulls.
These, together with similar measurement of 22 female and 29 male skulls
of the Naqada race are presented. The general objective is to investigate
possible sex and race differences in skull shape. The angles sums in the 
row are all equal to 180 degrees.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name SKULLS.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, (Data 24), pp22. 
</p>

<hr>
<h2 id='SkyeAFM'>AFM compositions of 23 aphyric Skye lavas</h2><span id='topic+Data06'></span><span id='topic+SkyeAFM'></span>

<h3>Description</h3>

<p>AFM compositions of 23 aphyric Skye lavas.
AFM diagrams formed from the relative proportions of A: alkali or Na2O + K2O,
F: Fe2O3, and M: MgO,  are common in geochemistry. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SkyeAFM)
</code></pre>


<h3>Details</h3>

<p>AFM compositions of 23 aphyric Skye lavas.
AFM diagrams formed from the relative proportions of tive proportions of A: alkali or Na2O + K2O,
F: Fe2O3, and M: MgO. Adapted from Thompson, Esson and Duncan: Major element chemical variations 
in the Eocene lavas of the Isle of Skye, Scotland. All row percentage sums to 100.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name SKYEAFM.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, (Data 6) pp12.
</p>
<p>Thompson, Esson and Duncan: Major element chemical variations 
in the Eocene lavas of the Isle of Skye, Scotland. 1972, J.Petrology, 13, 219-235. 
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+Skye">Skye</a></code></p>

<hr>
<h2 id='split'>Splitting datasets in groups given by factors</h2><span id='topic+split.acomp'></span><span id='topic+split.aplus'></span><span id='topic+split.rcomp'></span><span id='topic+split.rplus'></span><span id='topic+split.rmult'></span><span id='topic+split.ccomp'></span>

<h3>Description</h3>

<p>Splits data sets of compositions in groups given by factors, 
and gives the same class as the data to the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'acomp'
split(x,f,drop=FALSE,...)
## S3 method for class 'rcomp'
split(x,f,drop=FALSE,...)
## S3 method for class 'aplus'
split(x,f,drop=FALSE,...)
## S3 method for class 'rplus'
split(x,f,drop=FALSE,...)
## S3 method for class 'rmult'
split(x,f,drop=FALSE,...)
## S3 method for class 'ccomp'
split(x,f,drop=FALSE,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_+3A_x">x</code></td>
<td>
<p>a dataset or a single vector of some type</p>
</td></tr>
<tr><td><code id="split_+3A_f">f</code></td>
<td>
<p>a factor that defines the grouping or a list of factors </p>
</td></tr>
<tr><td><code id="split_+3A_drop">drop</code></td>
<td>
<p>drop=FALSE also gives (empty) datsets for empty
categories</p>
</td></tr>
<tr><td><code id="split_+3A_...">...</code></td>
<td>
<p>Further arguments passed to split.default.
Currently (and probably) without any use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of objects of the same type as <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+split">split</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(SimulatedAmounts)
  split(acomp(sa.groups),sa.groups.area)
  lapply( split(acomp(sa.groups),sa.groups.area), mean)
</code></pre>

<hr>
<h2 id='straight'>Draws straight lines.</h2><span id='topic+straight'></span><span id='topic+straight.rmult'></span><span id='topic+straight.acomp'></span><span id='topic+straight.rcomp'></span><span id='topic+straight.aplus'></span><span id='topic+straight.rplus'></span>

<h3>Description</h3>

<p>The function draws lines in a given direction <code>d</code> through points <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          straight(x,...)
          ## S3 method for class 'acomp'
straight(x,d,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rcomp'
straight(x,d,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'aplus'
straight(x,d,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rplus'
straight(x,d,...,steps=30,aspanel=FALSE)
          ## S3 method for class 'rmult'
straight(x,d,...,steps=30,aspanel=FALSE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="straight_+3A_x">x</code></td>
<td>
<p>dataset of points of the given type to draw the line through</p>
</td></tr>
<tr><td><code id="straight_+3A_d">d</code></td>
<td>
<p>dataset of directions of the line</p>
</td></tr>
<tr><td><code id="straight_+3A_...">...</code></td>
<td>
<p>further graphical parameters</p>
</td></tr>
<tr><td><code id="straight_+3A_steps">steps</code></td>
<td>
<p>the number of discretisation points to draw the segments, 
since the representation might not visually be a straight line</p>
</td></tr>
<tr><td><code id="straight_+3A_aspanel">aspanel</code></td>
<td>
<p>Logical, indicates use as slave to do acutal drawing only.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions add lines to the graphics generated with the corresponding
plot functions.
<br />
Adding to multipaneled plots redraws the plot completely, and is only
possible when the plot has been created with the plotting routines from
this library.
<br />
Lines end when they leave the space (e.g. the simplex), which sometimes
leads to the impression of premature end (specially in <code><a href="#topic+rcomp">rcomp</a></code> 
geometry). 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.acomp">plot.acomp</a></code>,<code><a href="#topic+lines.acomp">lines.acomp</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)

plot(acomp(sa.lognormals))
straight(mean(acomp(sa.lognormals)),
         princomp(acomp(sa.lognormals))$Loadings[1,],
         col="red")
straight(mean(rcomp(sa.lognormals)),
         princomp(rcomp(sa.lognormals))$loadings[,1],
         col="blue")

plot(aplus(sa.lognormals[,1:2]))
straight(mean(aplus(sa.lognormals[,1:2])),
         princomp(aplus(sa.lognormals[,1:2]))$Loadings[1,],
         col="red")
straight(mean(rplus(sa.lognormals[,1:2])),
         princomp(rplus(sa.lognormals[,1:2]))$loadings[,1],
         col="blue")

plot(rplus(sa.lognormals[,1:2]))
straight(mean(aplus(sa.lognormals[,1:2])),
         princomp(aplus(sa.lognormals[,1:2]))$Loadings[1,],
         col="red")
straight(mean(rplus(sa.lognormals[,1:2])),
         princomp(rplus(sa.lognormals[,1:2]))$loadings[,1],
         col="blue")

</code></pre>

<hr>
<h2 id='subsetting'>Subsetting of compositions</h2><span id='topic++5B.acomp'></span><span id='topic++5B.rcomp'></span><span id='topic++5B.ccomp'></span><span id='topic++5B.aplus'></span><span id='topic++5B.rplus'></span><span id='topic++5B.rmult'></span><span id='topic++24.acomp'></span><span id='topic++24.rcomp'></span><span id='topic++24.ccomp'></span><span id='topic++24.aplus'></span><span id='topic++24.rplus'></span><span id='topic++24.rmult'></span><span id='topic+getStickyClassOption'></span><span id='topic+setStickyClassOption'></span>

<h3>Description</h3>

<p>Extract subsets (rows) or subsompositions (columns) of a compositional data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  getStickyClassOption()
  setStickyClassOption(value)
## S3 method for class 'acomp'
x[i, j, drop=gsi.LengthOne(j)]
## S3 method for class 'rcomp'
x[i, j, drop=gsi.LengthOne(j)]
## S3 method for class 'aplus'
x[i, j, drop=gsi.LengthOne(j)]
## S3 method for class 'rplus'
x[i, j, drop=gsi.LengthOne(j)]
## S3 method for class 'ccomp'
x[i, j, drop=gsi.LengthOne(j)]
## S3 method for class 'rmult'
x[i, j, drop=gsi.LengthOne(j)]
## S3 method for class 'acomp'
x$name 
## S3 method for class 'rcomp'
x$name
## S3 method for class 'aplus'
x$name 
## S3 method for class 'rplus'
x$name
## S3 method for class 'ccomp'
x$name 
## S3 method for class 'rmult'
x$name
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsetting_+3A_x">x</code></td>
<td>
<p>vector or dataset of a compositions class</p>
</td></tr>
<tr><td><code id="subsetting_+3A_i">i</code></td>
<td>
<p>row indices/names to select/exclude, resp. boolean of fitting length (recyling appplied if length(i)&lt;nrow(x)); if x is a compositional vector, this gives the elements (equivalent to variables) to be extracted/selected</p>
</td></tr>
<tr><td><code id="subsetting_+3A_j">j</code></td>
<td>
<p>column indices/names to select/exclude, resp. boolean of fitting length (recyling appplied if length(i)&lt;ncol(x))</p>
</td></tr>
<tr><td><code id="subsetting_+3A_drop">drop</code></td>
<td>
<p>boolean, should matrices be simplified to vectors? defaults to FALSE (a difference with standard R). If set to TRUE, it has the extra effect of removing the compositional class</p>
</td></tr>
<tr><td><code id="subsetting_+3A_name">name</code></td>
<td>
<p>column name of the variable to be extracted OR name of a scaling function to be applied. It accepts <code>unclass</code> (or <code>raw</code>), <code>clo</code>, <code>pwlr</code>, <code>alr</code>, <code>clr</code>, <code>ilr</code>, <code>apt</code>, <code>cpt</code>,
<code>ipt</code>, <code>iit</code>, <code>ilt</code>, <code>cdt</code>, <code>idt</code> and their inverses <code>*Inv</code></p>
</td></tr>
<tr><td><code id="subsetting_+3A_value">value</code></td>
<td>
<p>logical, controlling the global options for sticky classes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>[</code> a vector or matrix with the relevant elements selected. 
When selecting rows, this object is of the same class than <code>x</code>, i.e. the class is sticky.
When selecting columns, the class depends on the number of columns selected and the value of <code>drop</code>. With <code>drop=T</code>, output is always a matrix or a vector. The same happens if 
<code>gsi.LengthOne(j)==TRUE</code>, which happens if and only if <code>j</code> is a non-null vector of
length one (i.e. if you only want one single column).
</p>
<p>If you want to get rid of sticky classes and return to the behaviour of &quot;compositions&quot; v1.xx, call <code>setStickyClassOption(FALSE)</code>. This may be a good idea if you run old scripts written for that versions of &quot;compositions&quot;. You can recover the default behaviour from &quot;compositions&quot; v2 with <code>setStickyClassOption(TRUE)</code>, and check which sticky class status is currently defined in the global options with <code>getStickyClassOption()</code>.
</p>
<p>For <code>$</code> the output is either a transformed data set of the appropriate class, or the selected column as a class-less vector. The transformation ability is particularly useful if you have put a whole compositional class into one column of a data set, in which case you can confortably use the transformations in formula interfaces (see example below). This is NEVER sticky.
</p>


<h3>Author(s)</h3>

<p>R. Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="#topic+rmult">rmult</a></code>, <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>,
<code><a href="#topic+aplus">aplus</a></code>,
<code><a href="#topic+rplus">rplus</a></code>, <code><a href="#topic+ccomp">ccomp</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Hydrochem)
xc = acomp(Hydrochem[,6:10])
xc[1:3,]
xc[-(10:nrow(xc)),]
xc[1:3,1:3]
xc[1:3,1:3, drop=TRUE]

xc[1:3,1]
class(xc[1:4,1])
class(xc[1:4,1, drop=TRUE])

data("Hydrochem")
xc = acomp(Hydrochem[, 9:14])
Hydrochem$compo = xc
lm(compo$clr~River, data=Hydrochem)
</code></pre>

<hr>
<h2 id='summary.acomp'>Summarizing a compositional dataset in terms of ratios</h2><span id='topic+summary.acomp'></span>

<h3>Description</h3>

<p>Summaries in terms of compositions are quite different from classical
ones. Instead of analysing each variable individually, we must
analyse each pair-wise ratio in a log geometry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ## S3 method for class 'acomp'
summary( object, ... ,robust=getOption("robust"))
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.acomp_+3A_object">object</code></td>
<td>
<p>a data matrix of compositions, not necessarily closed</p>
</td></tr>
<tr><td><code id="summary.acomp_+3A_...">...</code></td>
<td>
<p>not used, only here for generics</p>
</td></tr>
<tr><td><code id="summary.acomp_+3A_robust">robust</code></td>
<td>
<p>A robustness description. See
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for details. The parameter can be
null for avoiding any estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is quite difficult to summarize a composition in a consistent and
interpretable way. We tried to provide such a summary here, based on the
idea of the variation matrix.
</p>


<h3>Value</h3>

<p>The result is an object of type <code>"summary.acomp"</code>
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>the <code><a href="#topic+mean.acomp">mean.acomp</a></code> composition</p>
</td></tr>
<tr><td><code>mean.ratio</code></td>
<td>
<p>a matrix containing the geometric mean of the
pairwise ratios</p>
</td></tr>
<tr><td><code>variation</code></td>
<td>
<p>the variation matrix of the dataset (<code>{<a href="#topic+variation.acomp">variation.acomp</a>}</code>)</p>
</td></tr>
<tr><td><code>expsd</code></td>
<td>
<p>a matrix containing the  one-sigma factor for
each ratio, computed as <code>exp(sqrt(variation.acomp(W)))</code>. To
obtain a two-sigma-factor, one has to take its squared value (power 1.96, actually).</p>
</td></tr>
<tr><td><code>invexpsd</code></td>
<td>
<p>the inverse of the preceding one, giving the reverse bound.
Additionally, it can be &quot;almost&quot; intepreted as a correlation coefficient, 
with values near one indicating high proportionality between the components.</p>
</td></tr>
<tr><td><code>min</code></td>
<td>
<p>a matrix containing the minimum of each of the pairwise ratios</p>
</td></tr>
<tr><td><code>q1</code></td>
<td>
<p>a matrix containing the 1-Quartile of each of the pairwise ratios</p>
</td></tr>
<tr><td><code>median</code></td>
<td>
<p>a matrix containing the median of each of the pairwise ratios</p>
</td></tr>
<tr><td><code>q1</code></td>
<td>
<p>a matrix containing the 3-Quartile of each of the pairwise ratios</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p>a matrix containing the maximum of each of the pairwise ratios</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, R. Tolosana-Delgado</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acomp">acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
summary(acomp(sa.lognormals))

</code></pre>

<hr>
<h2 id='summary.aplus'>Summaries of amounts </h2><span id='topic+summary.aplus'></span><span id='topic+summary.rplus'></span><span id='topic+summary.rmult'></span>

<h3>Description</h3>

<p>Summary of a vector of amounts, according to its underlying geometry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ## S3 method for class 'aplus'
summary( object, ..., 
            digits=max(3, getOption("digits")-3), robust=NULL)
          ## S3 method for class 'rplus'
summary( object, ..., robust=NULL)
          ## S3 method for class 'rmult'
summary( object, ..., robust=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.aplus_+3A_object">object</code></td>
<td>
<p>an <code><a href="#topic+aplus">aplus</a></code>/<code><a href="#topic+rplus">rplus</a></code> set of
amounts</p>
</td></tr>
<tr><td><code id="summary.aplus_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to be used. The
argument can also be used with rplus/rmult.</p>
</td></tr>
<tr><td><code id="summary.aplus_+3A_...">...</code></td>
<td>
<p>not used, only here for generics</p>
</td></tr>
<tr><td><code id="summary.aplus_+3A_robust">robust</code></td>
<td>
<p>A robustness description. See
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for details. The option is currently
not supported. If support is added the default will change to
getOption(robust). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The obtained value is the same as for the classical summary <code><a href="base.html#topic+summary">summary</a></code>,
although in the case of <code><a href="#topic+aplus">aplus</a></code> objects, the statistics have been computed in a
logarithmic geometry, and exponentiated afterwards (which just changes the mean, equivalent 
to the geometric mean of the data set).
</p>


<h3>Value</h3>

<p>A matrix containing summary statistics (minimum, the three quantiles, the mean 
and the maximum) of each component.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+aplus">aplus</a></code>,<code><a href="#topic+rplus">rplus</a></code>,<code><a href="#topic+summary.acomp">summary.acomp</a></code>,
<code><a href="#topic+summary.rcomp">summary.rcomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
summary(aplus(sa.lognormals))
summary(aplus(sa.tnormals))
summary(rplus(sa.lognormals))
summary(rplus(sa.tnormals))
summary(rmult(sa.lognormals))

</code></pre>

<hr>
<h2 id='summary.rcomp'>Summary of compositions in real geometry</h2><span id='topic+summary.rcomp'></span>

<h3>Description</h3>

<p>Compute a summary of a composition based on real geometry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ## S3 method for class 'rcomp'
summary( object, ... ,robust=NULL)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rcomp_+3A_object">object</code></td>
<td>
<p>an <code><a href="#topic+rcomp">rcomp</a></code> dataset of compositions </p>
</td></tr>
<tr><td><code id="summary.rcomp_+3A_...">...</code></td>
<td>
<p>further arguments to <code>summary</code></p>
</td></tr>
<tr><td><code id="summary.rcomp_+3A_robust">robust</code></td>
<td>
<p>A robustness description. See
<a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for details. The option is currently
not supported. If support is added the default will change to
getOption(robust). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data is applied a <code><a href="#topic+clo">clo</a></code> operation before the computation.
Note that the statistics obtained will not keep any consistency 
if computed with all the parts available or only with a subcomposition.
</p>


<h3>Value</h3>

<p>A matrix containing summary statistics.
The value is the same as for the classical summary
<code><a href="base.html#topic+summary">summary</a></code> applied to  a closed dataset.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+summary.aplus">summary.aplus</a></code>, <code><a href="#topic+summary.acomp">summary.acomp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
summary(rcomp(sa.lognormals))
summary(rcomp(sa.tnormals))

</code></pre>

<hr>
<h2 id='sumprojector'>Compute the global projector to the observed subspace.</h2><span id='topic+sumMissingProjector'></span><span id='topic+sumMissingProjector.acomp'></span><span id='topic+sumMissingProjector.rcomp'></span><span id='topic+sumMissingProjector.aplus'></span><span id='topic+sumMissingProjector.rplus'></span><span id='topic+sumMissingProjector.rmult'></span>

<h3>Description</h3>

<p>Routines to compute the global projector to the observed subspace, 
down-weighting the subspaces with more missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sumMissingProjector(x,...)
## S3 method for class 'acomp'
sumMissingProjector(x,has=is.NMV(x),...)
## S3 method for class 'aplus'
sumMissingProjector(x,has=is.NMV(x),...)
## S3 method for class 'rcomp'
sumMissingProjector(x,has=!(is.MAR(x)|is.MNAR(x)),...)
## S3 method for class 'rplus'
sumMissingProjector(x,has=!(is.MAR(x)|is.MNAR(x)),...)
## S3 method for class 'rmult'
sumMissingProjector(x,has=is.finite(x),...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sumprojector_+3A_x">x</code></td>
<td>
<p>a dataset of some type containing missings</p>
</td></tr>
<tr><td><code id="sumprojector_+3A_has">has</code></td>
<td>
<p>the values to be regarded as non missing</p>
</td></tr>
<tr><td><code id="sumprojector_+3A_...">...</code></td>
<td>
<p>further generic arguments that might be useful for other
functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code><a href="#topic+missingProjector">missingProjector</a></code> generates a list of N square 
matrices of dimension DxD (with N and D respectively 
equal to the number of rows and columns in <code>x</code>). Each of these 
matrices gives the projection of a data row onto its observed sub-space.
Then, the function <code>sumMissingProjector</code> takes all these matrices and 
sums them in a efficient way, generating a &quot;summary&quot; of observed sub-spaces.
</p>


<h3>Value</h3>

<p>The matrix of rotation/re-weighting of the original data set, 
down-weighting the subspaces with more missing values. This matrix is useful
to obtain estimates of the mean (and variance, in the future) still unbiased 
in the presence of lost values (only of type MAR, stricly-speaking, but anyway
useful for any type of missing value, when used with care). This matrix is 
the Fisher Information in the presence of missing values.
</p>


<h3>Missing Policy</h3>

<p>No missing policy is given by the routine itself. Its treatment of missing values
depends on the &quot;has&quot; argument.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>References</h3>

<p>Boogaart, K.G. v.d., R. Tolosana-Delgado, M. Bren (2006) Concepts for
handling of zeros and missing
values in compositional data, in E. Pirard (ed.) (2006)Proccedings of
the IAMG'2006 Annual Conference on &quot;Quantitative Geology from multiple
sources&quot;, September 2006, Liege, Belgium, S07-01, 4pages,
<a href="http://stat.boogaart.de/Publications/iamg06_s07_01.pdf">http://stat.boogaart.de/Publications/iamg06_s07_01.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+missingProjector">missingProjector</a></code>,
<code><a href="#topic+clr">clr</a></code>,<code><a href="#topic+rcomp">rcomp</a></code>, <code><a href="#topic+aplus">aplus</a></code>,
<code><a href="#topic+princomp.acomp">princomp.acomp</a></code>, 
<code><a href="#topic+plot.acomp">plot.acomp</a></code>, <code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code>,
<code><a href="#topic+barplot.acomp">barplot.acomp</a></code>, <code><a href="#topic+mean.acomp">mean.acomp</a></code>,
<code><a href="#topic+var.acomp">var.acomp</a></code>, <code><a href="#topic+variation.acomp">variation.acomp</a></code>,
<code><a href="#topic+cov.acomp">cov.acomp</a></code>, <code><a href="#topic+msd">msd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
sumMissingProjector(acomp(sa.lognormals))
sumMissingProjector(acomp(sa.tnormals))
</code></pre>

<hr>
<h2 id='Supervisor'>Proportions of supervisor's statements assigned to different categories</h2><span id='topic+Data07'></span><span id='topic+Supervisor'></span>

<h3>Description</h3>

<p>The results of a study of a single supervisor in his relationship to three supervisee
are recorded. Instructions in a technical subject took place in sessions of one hour 
and with only one supervisee at the time. Each supervisee attended six sessions
(once every two weeks in a twelve-week period).
All of 18 sessions were recorded and for each session the 'statements'
of the supervisor were classified into four categories.
Thus for each session the proportion of statements in the four categories
are set out in a two-way table according to the fortnight (6) and the supervisee (3).  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Supervisor)
</code></pre>


<h3>Format</h3>

<p>A 18x13  matrix</p>


<h3>Details</h3>

<p>For each session the 'statements' of the supervisor were classified into
four categories
</p>

<dl>
<dt>C:</dt><dd><p>commanding, posing a specific instruction to the supervisee,</p>
</dd>
<dt>D:</dt><dd><p>demanding, posing a specific question to the supervisee,</p>
</dd>
<dt>E:</dt><dd><p>exposing, providing the supervisee with an explanation,</p>
</dd>
<dt>F:</dt><dd><p>faulting, pointing out faulty technique to the supervisee.</p>
</dd>
</dl>

<p>Thus for each session the proportion of statements in the four categories
are set out in a two-way table according to the fortnight (6) and the supervisee (3).
The  C, D, E, F values in the rows sum mostly to 1, except for some rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name SUPERVIS.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986): The Statistical Analysis of Compositional Data, (Data 7) pp12.
</p>

<hr>
<h2 id='ternaryAxis'>Axis for ternary diagrams</h2><span id='topic+ternaryAxis'></span>

<h3>Description</h3>

<p>Displaying compositions in ternary diagrams
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ternaryAxis(side=1:3,at=seq(0.2,0.8,by=0.2),
                        labels=if(is.list(at)) lapply(at,format) else format(at),
                        ...,
                        tick=TRUE,pos=0,
                        font.axis=par("font.axis"),
                        font.lab=par("font.lab"),
                        lty="solid",lwd=1,
                        len.tck=0.025,dist.lab=0.03,
                        dist.axis=0.03,
                        lty.tck="solid",
                        col.axis=par("col.axis"),
                        col.lab=par("col.lab"),
                        cex.axis=par("cex.axis"),
                        cex.lab=par("cex.lab"),
                        Xlab=NULL,Ylab=NULL,Zlab=NULL,small=TRUE,
                        xpd=NA,aspanel=FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ternaryAxis_+3A_side">side</code></td>
<td>
<p>a vector giving the sides to draw the axis on. 1=under the
plot, 2=the upper right axis, 3=the upper left axis. -1 is the
portion axis of the first component, -2 is the portion axis of the
second component, -3 is the portion axis of the third component.
An empty vector
or 0 suppresses axis plotting, but still plots the Xlab, Ylab and Zlab
parameters.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_at">at</code></td>
<td>
<p> a vector or a list of vectors giving the positions of the
tickmarks. </p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_labels">labels</code></td>
<td>
<p>a vector giving the labels or a list of things that
can serve as graphics annotations. Each element of the list is than
sean as the labels for one of axes. IMPORTANT: if plotting formulae
enclose the list of labels into a list.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_tick">tick</code></td>
<td>
<p>a logical whether to draw the tickmark lines</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_pos">pos</code></td>
<td>
<p>the portion of the opposite component to draw the axis on.
Proportion axss shrinks, when pos&gt;0 !
</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_font.axis">font.axis</code></td>
<td>
<p>the font for the axis annotations</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_font.lab">font.lab</code></td>
<td>
<p>the font for the variable labels</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_lty">lty</code></td>
<td>
<p>the line type of the axis line. (see <code><a href="graphics.html#topic+par">par</a></code>). NA
supresses plotting.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_lty.tck">lty.tck</code></td>
<td>
<p>the line type of the tickmarks. NA suppresses plotting.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_len.tck">len.tck</code></td>
<td>
<p>the line length of the tickmarks.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_dist.axis">dist.axis</code></td>
<td>
<p>the distance of the variable labels from the
axes. Positve values point outward from the plot.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_dist.lab">dist.lab</code></td>
<td>
<p>the distance of the axes labels from the
axes. Positve values point outward from the plot.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_lwd">lwd</code></td>
<td>
<p>the line widths of axis line and tickmarks.
(see <code><a href="graphics.html#topic+par">par</a></code>)</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_col.axis">col.axis</code></td>
<td>
<p>the color to plot the axis line, the tickmarks and the
axes labels.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_col.lab">col.lab</code></td>
<td>
<p>the color to plot the variable labels.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The character size to plot the axes labels. (see
<code><a href="graphics.html#topic+par">par</a></code>)</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The character size for the variable labels</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_xlab">Xlab</code></td>
<td>
<p>the label for the lower left component.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_ylab">Ylab</code></td>
<td>
<p>the label for the lower right component.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_zlab">Zlab</code></td>
<td>
<p>the label for the upper component.</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_small">small</code></td>
<td>
<p>wether to plot the lower labels under the corners</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_xpd">xpd</code></td>
<td>
<p>Extended plotting region. See (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_aspanel">aspanel</code></td>
<td>
<p>Is this called as a slave to acutally plot the axis
(TRUE), or as a user level function to instatiate the axis (FALSE). </p>
</td></tr>
<tr><td><code id="ternaryAxis_+3A_...">...</code></td>
<td>
<p>further graphical that might be of use for other
functions, but are silently ignored here</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function has two uses. If called with <code>aspanel=TRUE</code> it
acutally draws the axes to a panel. In other cases it tries to modify
the axes argument of the current plot to add the axis. I.e. it will
force a replotting of the plot with the new axes settings. Thus an old
axes is removed.
</p>
<p>To ensure that various axes can be drawn with various parameters most
of the arguments can take a vector or list of the same length as
<code>side</code>
providing the different parameters for each of the axes to be drawn.
</p>
<p>There are two types of axes: Proportion axes (1:3) and portions axes
(-1:-3). The best place to draw a Proportion axes is pos=0, which is
the standard for axis in ternary diagrams. Portion axes are best drawn
at <code>pos=0.5</code> in the middle of the plot. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boyogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.aplus">plot.aplus</a></code>, <code><a href="#topic+plot3D">plot3D</a></code> (for 3D plot),
<code><a href="#topic+kingTetrahedron">kingTetrahedron</a></code> (for 3D-plot model export),
<code><a href="#topic+qqnorm.acomp">qqnorm.acomp</a></code>,<code><a href="#topic+boxplot.acomp">boxplot.acomp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
plot(acomp(sa.lognormals),axes=TRUE)
ternaryAxis(side=1:3,pos=0,col.axis="red",col.lab="green")
ternaryAxis(side=1:3,at=1:9/10,
            labels=expression(9:1,4:1,7:3,3:2,1:1,2:3,3:7,1:4,1:9),
            pos=0,col.axis="red",col.lab="green")
ternaryAxis(side=rep(-1:-3,3),labels=paste(seq(20,80,by=20),"%"),
            pos=rep(c(0,0.5,1),each=3),col.axis=1:3,col.lab="green")
ternaryAxis(side=rep(1:3,3),at=1:9/10,
            labels=expression(9:1,4:1,7:3,3:2,1:1,2:3,3:7,1:4,1:9),
            pos=rep(c(0,0.5,1),each=3))

plot(acomp(sa.lognormals5),axes=TRUE)
ternaryAxis(side=1:3,pos=0,col.axis="red",col.lab="green")
ternaryAxis(side=1:3,at=1:9/10,
            labels=expression(9:1,4:1,7:3,3:2,1:1,2:3,3:7,1:4,1:9),
            pos=0,col.axis="red",col.lab="green")

</code></pre>

<hr>
<h2 id='totals'>Total sum of amounts </h2><span id='topic+totals'></span><span id='topic+totals.acomp'></span><span id='topic+totals.aplus'></span><span id='topic+totals.rcomp'></span><span id='topic+totals.rplus'></span><span id='topic+totals.ccomp'></span>

<h3>Description</h3>

<p>Calculates the total amount by summing the individual parts. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>totals(x,...)
## S3 method for class 'acomp'
totals(x,...,missing.ok=TRUE)
## S3 method for class 'rcomp'
totals(x,...,missing.ok=TRUE)
## S3 method for class 'aplus'
totals(x,...,missing.ok=TRUE)
## S3 method for class 'rplus'
totals(x,...,missing.ok=TRUE)
## S3 method for class 'ccomp'
totals(x,...,missing.ok=TRUE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="totals_+3A_x">x</code></td>
<td>
<p>an amount/amount dataset</p>
</td></tr>
<tr><td><code id="totals_+3A_...">...</code></td>
<td>
<p>not used, only here for generic purposes</p>
</td></tr>
<tr><td><code id="totals_+3A_missing.ok">missing.ok</code></td>
<td>
<p>if TRUE ignores missings; if FALSE issues an error if
the total cannot be calculated due to missings.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector of length equal to <code>ncol(x)</code> containing the total amounts
</p>


<h3>Missing Policy</h3>

<p>if <code>missing.ok=TRUE</code> missings are just regarded as 0, if
<code>missing.ok=FALSE</code> WZERO values is still regarded as 0 and other
sorts lead to <code>NA</code> in the respective totals.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+aplus">aplus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
totals(acomp(sa.lognormals))
totals(rcomp(sa.lognormals,total=100))
totals(aplus(sa.lognormals))
totals(rplus(sa.lognormals))
aplus(acomp(sa.lognormals),total=totals(aplus(sa.lognormals)))


</code></pre>

<hr>
<h2 id='transformations+20from+20+27mixtures+27+20to+20+20+27compositions+27+20classes'>Transformations from 'mixtures' to  'compositions' classes</h2><span id='topic+mix.2aplus'></span><span id='topic+mix.2acomp'></span><span id='topic+mix.2rcomp'></span><span id='topic+mix.2rplus'></span><span id='topic+mix.2rmult'></span>

<h3>Description</h3>

<p>Transformations from 'mixtures' of the &quot;mixR&quot; library to 'compositions'
classes 'aplus', 'acomp', 'rcomp', 'rplus'
and 'rmult'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>   mix.2aplus(X)
   mix.2acomp(X)
   mix.2rcomp(X)
   mix.2rplus(X)
   mix.2rmult(X)
   </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transformations+2B20from+2B20+2B27mixtures+2B27+2B20to+2B20+2B20+2B27compositions+2B27+2B20classes_+3A_x">X</code></td>
<td>
<p>mixture object to be converted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A 'compositions' object is obtained from the mixtute object m, having the same data matrix
as mixture object m i.e. <code>m$mat</code>.
</p>


<h3>Value</h3>

<p>A 'compositions' object of the class 'aplus', 'acomp', 'rcomp', 'rplus' or 'rmult'.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aplus">aplus</a></code>
<code><a href="#topic+acomp">acomp</a></code>
<code><a href="#topic+rcomp">rcomp</a></code>
<code><a href="#topic+rplus">rplus</a></code>
<code><a href="#topic+rmult">rmult</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
m &lt;- mix.Read("Glac.dat")      # reads the Glacial data set from Aitchison (1986)
m &lt;- mix.Extract(m,c(1,2,3,4))   # mix object with closed four parts subcomposition
ap &lt;- mix.2aplus(m)   # ap is a 'compositions' object of the aplus class
ac &lt;- mix.2acomp(m)   # ac is a 'compositions' object of the acomp class

## End(Not run)

</code></pre>

<hr>
<h2 id='tryDebugger'>Empirical variograms for compositions</h2><span id='topic+tryDebugger'></span>

<h3>Description</h3>

<p>An R-debugger that also works with errors in parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tryDebugger(dump = last.dump)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tryDebugger_+3A_dump">dump</code></td>
<td>
<p>An R dump object created by 'dump.frames'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Works like debugger, with the small exception that it also works in
situations of nasty errors, like recursive parameter evaluation,
missing parameters, and additional errors in arguments. 
</p>


<h3>Value</h3>

<p>Nothing. 
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+debugger">debugger</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
f &lt;- function(x,y=y) {y}
f(1)
tryDebugger() # works
debugger() # Does not allow to browse anything

## End(Not run)
</code></pre>

<hr>
<h2 id='ult'>Uncentered log transform</h2><span id='topic+ult'></span><span id='topic+ultInv'></span><span id='topic+Kappa'></span>

<h3>Description</h3>

<p>Compute the uncentered log ratio transform of a (dataset of)
composition(s) and its inverse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          ult( x ,...)
          ultInv( z ,..., orig=gsi.orig(z))
          Kappa( x ,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ult_+3A_x">x</code></td>
<td>
<p>a composition or a data matrix of compositions, not necessarily closed</p>
</td></tr>
<tr><td><code id="ult_+3A_z">z</code></td>
<td>
<p>the ult-transform of a composition or
clr-transforms of compositions (or a data matrix), not necessarily centered</p>
</td></tr>
<tr><td><code id="ult_+3A_...">...</code></td>
<td>
<p>for generic use only</p>
</td></tr>
<tr><td><code id="ult_+3A_orig">orig</code></td>
<td>
<p>a compositional object which should be mimicked
by the inverse transformation. It is the generic
argument. Typically the <code>orig</code> argument is stored as an attribute 
in <code>z</code> and will be extracted automatically by this function; if this
fails, <code>orig</code> can be set equal to the dataset that
was transformed in the first place.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ult-transform is simply the elementwise log of the closed
composition. The ult has some important properties in the scope 
of Information Theory of probability vectors (but might be mostly 
misleading for exploratory analysis of compositions). DO NOT USE if 
you do not know what you are doing.
</p>


<h3>Value</h3>

<p><code>ult</code> gives the uncentered log transform,<br />
<code>ultInv</code> gives closed compositions with the given
ult/clr-transforms<br />
<code>Kappa</code> gives the difference between the clr and the ult
transforms. It is quite linked to information measures.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+ilr">ilr</a></code>,<code><a href="#topic+alr">alr</a></code>,<code><a href="#topic+apt">apt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tmp &lt;- ult(c(1,2,3)))
ultInv(tmp)
ultInv(tmp) - clo(c(1,2,3)) # 0
data(Hydrochem)
cdata &lt;- Hydrochem[,6:19]
pairs(ult(cdata),pch=".")
Kappa(c(1,2,3))
</code></pre>

<hr>
<h2 id='var.acomp'>Variances and covariances of amounts and compositions</h2><span id='topic+var'></span><span id='topic+var.default'></span><span id='topic+var.acomp'></span><span id='topic+var.rcomp'></span><span id='topic+var.aplus'></span><span id='topic+var.rplus'></span><span id='topic+var.rmult'></span><span id='topic+cov'></span><span id='topic+cov.default'></span><span id='topic+cov.acomp'></span><span id='topic+cov.rcomp'></span><span id='topic+cov.aplus'></span><span id='topic+cov.rplus'></span><span id='topic+cov.rmult'></span>

<h3>Description</h3>

<p>Compute the (co)variance matrix in the several approaches of compositional
and amount data analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  var(x,...)
    ## Default S3 method:
var(x, y=NULL, na.rm=FALSE, use, ...)
    ## S3 method for class 'acomp'
var(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'rcomp'
var(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'aplus'
var(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'rplus'
var(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'rmult'
var(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
  cov(x,y=x,...)
    ## Default S3 method:
cov(x, y=NULL, use="everything", 
       method=c("pearson", "kendall", "spearman"), ...)
    ## S3 method for class 'acomp'
cov(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'rcomp'
cov(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'aplus'
cov(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'rplus'
cov(x,y=NULL,...,robust=getOption("robust"), 
       use="all.obs",giveCenter=FALSE)
    ## S3 method for class 'rmult'
cov(x,y=NULL,...,robust=getOption("robust"), 
    use="all.obs",giveCenter=FALSE)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var.acomp_+3A_x">x</code></td>
<td>
<p>a dataset, eventually of amounts or compositions</p>
</td></tr>
<tr><td><code id="var.acomp_+3A_y">y</code></td>
<td>
<p>a second dataset, eventually of amounts or compositions</p>
</td></tr>
<tr><td><code id="var.acomp_+3A_na.rm">na.rm</code></td>
<td>
<p>see <code>stats::var</code></p>
</td></tr>
<tr><td><code id="var.acomp_+3A_use">use</code></td>
<td>
<p>see <code>stats::var</code></p>
</td></tr>
<tr><td><code id="var.acomp_+3A_method">method</code></td>
<td>
<p>see <code>stats::cov</code></p>
</td></tr>
<tr><td><code id="var.acomp_+3A_...">...</code></td>
<td>
<p>further arguments to <code>stats::var</code> 
e.g. <code>use</code></p>
</td></tr>
<tr><td><code id="var.acomp_+3A_robust">robust</code></td>
<td>

<p>A description of a robust estimator. FALSE for the classical
estimators. See <a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for
further details.
</p>
</td></tr>
<tr><td><code id="var.acomp_+3A_givecenter">giveCenter</code></td>
<td>
<p>If TRUE the center used in the variance calculation
is reported as a &quot;center&quot; attribute. This is especially necessary
for robust estimations, where a reasonable center can not be
computed independently for the me variance calculation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic functions of 
<code>stats::var</code> and <code>stats::cov</code>
are turned to
S3-generics. The original versions are copied to the default
method. This allows us to introduce generic methods to handle
variances and covariances of other data types, such as amounts or
compositions.
<br />
If classed amounts or compositions are involved, they are transformed
with their corresponding transforms, using the centered default
transform (<code><a href="#topic+cdt">cdt</a></code>). That implies that the variances have to
be interpreded in a log scale level for  <code><a href="#topic+acomp">acomp</a></code> and
<code><a href="#topic+aplus">aplus</a></code>.
<br />
We should be aware that variance matrices of compositions 
(<code><a href="#topic+acomp">acomp</a></code> and <code><a href="#topic+rcomp">rcomp</a></code>) are
singular. They can be transformed to the correponding nonsingular
variances of ilr or ipt-space by <code><a href="#topic+clrvar2ilr">clrvar2ilr</a></code>.
</p>
<p>In R versions older than v2.0.0, 

<code>stats::var</code> and <code>stats::cov</code>
were defined in package &ldquo;base&rdquo; instead of in &ldquo;stats&rdquo;.
This might produce some misfunction.
</p>


<h3>Value</h3>

<p>The variance matrix of x or the covariance matrix of x and
y.</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+cdt">cdt</a></code>, <code><a href="#topic+clrvar2ilr">clrvar2ilr</a></code>, <code><a href="#topic+clo">clo</a></code>,
<code><a href="#topic+mean.acomp">mean.acomp</a></code>, <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>,
<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code>, <code><a href="#topic+variation">variation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
meanCol(sa.lognormals)
var(acomp(sa.lognormals))
var(rcomp(sa.lognormals))
var(aplus(sa.lognormals))
var(rplus(sa.lognormals))
cov(acomp(sa.lognormals5[,1:3]),acomp(sa.lognormals5[,4:5]))
cov(rcomp(sa.lognormals5[,1:3]),rcomp(sa.lognormals5[,4:5]))
cov(aplus(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))
cov(rplus(sa.lognormals5[,1:3]),rplus(sa.lognormals5[,4:5]))
cov(acomp(sa.lognormals5[,1:3]),aplus(sa.lognormals5[,4:5]))

svd(var(acomp(sa.lognormals)))

</code></pre>

<hr>
<h2 id='variation'>Variation matrices of amounts and compositions</h2><span id='topic+variation'></span><span id='topic+variation.default'></span><span id='topic+variation.acomp'></span><span id='topic+variation.rcomp'></span><span id='topic+variation.aplus'></span><span id='topic+variation.rplus'></span><span id='topic+variation.rmult'></span><span id='topic+is.variation'></span>

<h3>Description</h3>

<p>Compute the variation  matrix in the various approaches of compositional
and amount  data analysis. Pay attention that this is not computing the variance or
covariance matrix!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    variation(x,...)
          ## S3 method for class 'acomp'
variation(x, ...,robust=getOption("robust"))
          ## S3 method for class 'rcomp'
variation(x, ...,robust=getOption("robust"))
          ## S3 method for class 'aplus'
variation(x, ...,robust=getOption("robust"))
          ## S3 method for class 'rplus'
variation(x, ...,robust=getOption("robust"))
          ## S3 method for class 'rmult'
variation(x, ...,robust=getOption("robust"))
          is.variation(M, tol=1e-10)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variation_+3A_x">x</code></td>
<td>
<p>a dataset, eventually of amounts or compositions</p>
</td></tr>
<tr><td><code id="variation_+3A_...">...</code></td>
<td>
<p>currently unused</p>
</td></tr>
<tr><td><code id="variation_+3A_robust">robust</code></td>
<td>

<p>A description of a robust estimator. FALSE for the classical
estimators. See <a href="#topic+robustnessInCompositions">robustnessInCompositions</a> for
further details.
</p>
</td></tr>
<tr><td><code id="variation_+3A_m">M</code></td>
<td>
<p>a matrix, to check if it is a valid variation</p>
</td></tr>
<tr><td><code id="variation_+3A_tol">tol</code></td>
<td>
<p>tolerance for the check</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variation matrix was defined in the <code><a href="#topic+acomp">acomp</a></code> context of
analysis of compositions as the matrix of variances of all 
possible log-ratios among components (Aitchison, 1986). The 
generalization to rcomp objects is simply to reproduce the 
variance of all possible differences between components. The 
amount (<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code>) and rmult objects 
should not be treated with variation 
matrices, because this was intended to skip the existence of a closure
(which does not exist in the case of amounts).
</p>


<h3>Value</h3>

<p>The variation matrix of x.
</p>
<p>For <code>is.variation</code>, a boolean saying if the matrix satisfies the conditions to be a variation matrix.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+cdt">cdt</a></code>, <code><a href="#topic+clrvar2ilr">clrvar2ilr</a></code>, <code><a href="#topic+clo">clo</a></code>,
<code><a href="#topic+mean.acomp">mean.acomp</a></code>, <code><a href="#topic+acomp">acomp</a></code>, <code><a href="#topic+rcomp">rcomp</a></code>,
<code><a href="#topic+aplus">aplus</a></code>, <code><a href="#topic+rplus">rplus</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
meanCol(sa.lognormals)
variation(acomp(sa.lognormals))
variation(rcomp(sa.lognormals))
variation(aplus(sa.lognormals))
variation(rplus(sa.lognormals))
variation(rmult(sa.lognormals))

</code></pre>

<hr>
<h2 id='variograms'>Variogram functions</h2><span id='topic+vgram.sph'></span><span id='topic+vgram.exp'></span><span id='topic+vgram.gauss'></span><span id='topic+vgram.cardsin'></span><span id='topic+vgram.lin'></span><span id='topic+vgram.pow'></span><span id='topic+vgram.nugget'></span>

<h3>Description</h3>

<p>Valid scalar variogram model functions.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgram.sph( h , nugget = 0, sill = 1, range= 1,... )
vgram.exp( h , nugget = 0, sill = 1, range= 1,... )
vgram.gauss( h , nugget = 0, sill = 1, range= 1,... )
vgram.cardsin( h , nugget = 0, sill = 1, range= 1,... )
vgram.lin( h , nugget = 0, sill = 1, range= 1,... )
vgram.pow( h , nugget = 0, sill = 1, range= 1,... )
vgram.nugget( h , nugget = 1,...,tol=1E-8 )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variograms_+3A_h">h</code></td>
<td>
<p>a vector providing distances, a matrix of distance vectors in
its rows or a data.frame of distance vectors. </p>
</td></tr>
<tr><td><code id="variograms_+3A_nugget">nugget</code></td>
<td>
<p>The size of the nugget effect (i.e. the limit to 0). At
zero itself the value is always 0.</p>
</td></tr>
<tr><td><code id="variograms_+3A_sill">sill</code></td>
<td>
<p>The sill (i.e. the limit to infinity)</p>
</td></tr>
<tr><td><code id="variograms_+3A_range">range</code></td>
<td>
<p>The range parameter. I.e. the distance in which sill is
reached or if this does not exist, where the value is in some sense
nearly the sill.</p>
</td></tr>
<tr><td><code id="variograms_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="variograms_+3A_tol">tol</code></td>
<td>
<p>The distance that is considered as nonzero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The univariate variograms are used in the CompLinCoReg as building
blocks of multivariate variogram models. 
</p>

<dl>
<dt>sph</dt><dd><p>Spherical variogram</p>
</dd>
<dt>exp</dt><dd><p>Exponential variogram</p>
</dd>
<dt>gauss</dt><dd><p>The Gaussian variogram.</p>
</dd>
<dt>gauss</dt><dd><p>The cardinal sine variogram.</p>
</dd>
<dt>lin</dt><dd><p>Linear Variogram. Increases over the sill, which is
reached at <code>range</code>.</p>
</dd>
<dt>pow</dt><dd><p>The power variogram. Increases over the sill, which is
reached at <code>range</code>. </p>
</dd>
<dt>nugget</dt><dd><p>The pure nugget effect variogram. </p>
</dd>
</dl>



<h3>Value</h3>

<p>A vector of size NROW(h), giving the variogram values.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>References</h3>

<p>Cressie, N.C. (1993) Spatial statistics
</p>
<p>Tolosana, van den Boogaart, Pawlowsky-Glahn (2009) Estimating and
modeling variograms of compositional data with occasional missing
variables in R, StatGis09
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vgram2lrvgram">vgram2lrvgram</a></code>,
<code><a href="#topic+CompLinModCoReg">CompLinModCoReg</a></code>,
<code><a href="#topic+vgmFit">vgmFit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(juraset)
X &lt;- with(juraset,cbind(X,Y))
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
lrv &lt;- logratioVariogram(comp,X,maxdist=1,nbins=10)
plot(lrv)

## End(Not run)
</code></pre>

<hr>
<h2 id='varmlm'>Residual variance of a model</h2><span id='topic+var.lm'></span><span id='topic+var.mlm'></span>

<h3>Description</h3>

<p>Computes the unbiased estimate for the variance of the residuals of a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlm'
var(x,...) 
## S3 method for class 'lm'
var(x,...) 
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varmlm_+3A_x">x</code></td>
<td>
<p>a linear model object</p>
</td></tr>
<tr><td><code id="varmlm_+3A_...">...</code></td>
<td>
<p>Unused, for generic purposes only.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The difference of this command to <code>var(resid(X))</code> is that this
command correctly adjusts for the degrees of freedom of the model.
</p>


<h3>Value</h3>

<table>
<tr><td><code>var.lm</code></td>
<td>
<p>returns a scalar giving the estimated variance of the residuals</p>
</td></tr>
<tr><td><code>var.mlm</code></td>
<td>
<p>returns a the estimated variance covariance matrix of  the residuals</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a>, Raimon
Tolosana-Delgado</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+vcov">vcov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Orange)
var(lm(circumference~age,data=Orange))
var(lm(cbind(circumference,age)~age,data=Orange))

</code></pre>

<hr>
<h2 id='vcovAcomp'>Variance covariance matrix of parameters in compositional regression</h2><span id='topic+vcovAcomp'></span>

<h3>Description</h3>

<p>The variance covariance tensor structured according of linear models
with ilr(acomp(...)) responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcovAcomp(object,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovAcomp_+3A_object">object</code></td>
<td>
<p> a statistical model</p>
</td></tr>
<tr><td><code id="vcovAcomp_+3A_...">...</code></td>
<td>
<p>further optional parameters for <code>vcov</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The prediction error in compositional linear regression models is a
complicated object. The function should help to organize it. 
</p>


<h3>Value</h3>

<p>An array with 4 dimensions. The first 2 are the index dimensions of
the ilr transform. The later 2 are the index of the parameter.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+vcov">vcov</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
model &lt;- lm(ilr(sa.groups)~sa.groups.area)
vcovAcomp(model)[,,1,1]
</code></pre>

<hr>
<h2 id='vgmFit'>Compositional variogram model fitting</h2><span id='topic+vgmFit'></span><span id='topic+vgmFit2lrv'></span><span id='topic+vgmGetParameters'></span><span id='topic+vgmSetParameters'></span><span id='topic+vgmGof'></span><span id='topic+fit.lmc'></span><span id='topic+fit.lmc.logratioVariogram'></span>

<h3>Description</h3>

<p>Fits a parametric variogram model to an empirical logratio-Variogram 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vgmFit2lrv(emp,vg,...,mode="log",psgn=rep(-1,length(param)),print.level=1)
## S3 method for class 'logratioVariogram'
fit.lmc(v,model,...,mode="log",psgn=rep(-1,length(param)),print.level=1)
vgmFit(emp,vg,...,mode="log",psgn=rep(-1,length(param)),print.level=1)
vgmGof(p = vgmGetParameters(vg), emp, vg, mode = "log")
vgmGetParameters(vg,envir=environment(vg))
vgmSetParameters(vg,p)
fit.lmc(v,...)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vgmFit_+3A_emp">emp</code></td>
<td>
<p>An empirical logratio-Variogram as e.g. returned by <code><a href="#topic+logratioVariogram">logratioVariogram</a></code></p>
</td></tr>
<tr><td><code id="vgmFit_+3A_v">v</code></td>
<td>
<p>An empirical logratio-Variogram as e.g. returned by <code><a href="#topic+logratioVariogram">logratioVariogram</a></code></p>
</td></tr>
<tr><td><code id="vgmFit_+3A_vg">vg</code></td>
<td>
<p>A compositional clr-variogram (or ilt-vagriogram) model function.</p>
</td></tr>
<tr><td><code id="vgmFit_+3A_model">model</code></td>
<td>
<p>A compositional clr-variogram (or ilt-vagriogram) model function, output of a call to
.</p>
</td></tr>
<tr><td><code id="vgmFit_+3A_...">...</code></td>
<td>
<p>further parameters to <code><a href="stats.html#topic+nlm">nlm</a></code></p>
</td></tr>
<tr><td><code id="vgmFit_+3A_mode">mode</code></td>
<td>
<p>either &quot;ls&quot; or &quot;log&quot;  for selection of either using either
least squares or least squares on logarithmic values.</p>
</td></tr>
<tr><td><code id="vgmFit_+3A_psgn">psgn</code></td>
<td>
<p>Contains a parameter code for each of the parameters. -1
means the parameter should be used as is. 0 means the parameter is
nonnegativ and 1 means the parameter is striktly positiv. This
allows to provide parameter limits if the fitting procedure fails.</p>
</td></tr>
<tr><td><code id="vgmFit_+3A_print.level">print.level</code></td>
<td>
<p>The print.level of <code><a href="stats.html#topic+nlm">nlm</a></code>. 0 for no
printing. 1 for a rough information about the sucess and 2 for step
by step printing.</p>
</td></tr>
<tr><td><code id="vgmFit_+3A_p">p</code></td>
<td>
<p>Is the parameter of the variogram model in linearized form as
e.g. 
returned by <code>vgmGetParameters</code>.
</p>
</td></tr>
<tr><td><code id="vgmFit_+3A_envir">envir</code></td>
<td>
<p>The environment the default parameters of the model
should be evaluated in.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is mainly a wrapper to <code><a href="stats.html#topic+nlm">nlm</a></code> specifying the
an objective function for modell fitting, taking the starting values
of fitting procedure from the default arguments and writing the
results back. Variogram model fitting is more an art than a straight
forward procedure. Fitting procedures typically only find a right
optimum if reasonable starting parameters are provided.
The fit should
be visually checked afterwards.
<br />
The meaning of <code>psgn</code> is subject to change. We will probably
provide a more automatic procedure later.
<br />
<code>vgmFit</code> is a copy of <code>vgmFit2lrv</code>, but deprecated. The name
will later be used for other functionality. 
</p>


<h3>Value</h3>

<p><code>vgmFit2lrv</code> returns a list of two elements.
</p>
<table>
<tr><td><code>nlm</code></td>
<td>
<p>The result of <code><a href="stats.html#topic+nlm">nlm</a></code> containing covergence
codes.</p>
</td></tr>
<tr><td><code>vg</code></td>
<td>
<p>A version of <code>vg</code> but with default parameters
modified according to the fitting.</p>
</td></tr>
</table>
<p><code>vgmGof</code> returns a scalar quantifiying the goodness of fit, of a
model and an empirical variogram.
<br />
<code>vgmGetParameters</code> extracts the default values of a variogram model
function to a parameter vector. It returns a numeric vector.
<br />
<code>vgmSetParameters</code> does the inverse operation and modifies the
default according to the new values in <code>p</code>. It returns <code>vg</code>
with modifiend default parameter values.
</p>


<h3>Author(s)</h3>

<p>K.Gerald v.d. Boogaart <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+vgram2lrvgram">vgram2lrvgram</a></code>,
<code><a href="#topic+CompLinModCoReg">CompLinModCoReg</a></code>,
<code><a href="#topic+logratioVariogram">logratioVariogram</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(juraset)
X &lt;- with(juraset,cbind(X,Y))
comp &lt;- acomp(juraset,c("Cd","Cu","Pb","Co","Cr"))
lrv &lt;- logratioVariogram(comp,X,maxdist=1,nbins=10)
fff &lt;- CompLinModCoReg(~nugget()+sph(0.5)+R1*exp(0.7),comp)
fit &lt;- vgmFit(lrv,fff)
fit
fff(1:3)
plot(lrv,lrvg=vgram2lrvgram(fit$vg))

## End(Not run)
</code></pre>

<hr>
<h2 id='WhiteCells'>White-cell composition of 30 blood samples by two different methods</h2><span id='topic+Data11'></span><span id='topic+WhiteCells'></span>

<h3>Description</h3>

<p>In 30 blood samples portions of three kinds of white cells
</p>

<dl>
<dt>G:</dt><dd><p>granulocytes,</p>
</dd>
<dt>L:</dt><dd><p>lymphocytes,</p>
</dd>
<dt>M:</dt><dd><p>monocytes,</p>
</dd>
</dl>

<p>were determined with two methods, time-consuming microscopic and
automatic image analysis. The resulting 30 pairs of 3-part compositions
are recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(WhiteCells)
</code></pre>


<h3>Format</h3>

<p>A 30x6  matrix</p>


<h3>Details</h3>

<p>In an experiment each of 30 blood samples was halved, one half being assigned
randomly to one method, the other half to the other method.
We have 60 cases of 3-part compositions but these are
essentially 30 pairs of related compositions. All 3-part portions sums to one, 
except for some rounding errors.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name WCELLS.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, 1986 (Data 9) pp16. 
</p>

<hr>
<h2 id='wrapped_functions'>Standard R functions wrapped for compatibility</h2><span id='topic+anova'></span>

<h3>Description</h3>

<p>These functions of a standard R distribution (from package &quot;base&quot; or &quot;stats&quot;) are wrapped by naive functions in &quot;compositions&quot; with the goal to ensure their normal behavior with compositional data objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>    anova(...)
   
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="wrapped_functions_+3A_...">...</code></td>
<td>
<p>arguments passed to the original function (all!)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions documented in this page are just wrapers around base functions 
from R that, due to a variety of reasons, need pre- or post-processing when 
&quot;compositions&quot; is loaded. Pre-processing are e.g., converting &quot;rmult&quot; class 
objects to plain &quot;matrix&quot; objects, or removing sticky class behaviour (see 
<code><a href="#topic+getStickyClassOption">getStickyClassOption</a></code>)
</p>


<h3>Value</h3>

<p>The same as the original function from package base (i.e. search for it with '?base::anova'). 

</p>


<h3>Author(s)</h3>

<p>Raimon Tolosana-Delgado <a href="http://www.stat.boogaart.de">http://www.stat.boogaart.de</a></p>


<h3>See Also</h3>

<p><code>anova</code> in package &quot;base&quot; . 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># anova:
data("Hydrochem") # load data
Z = acomp(Hydrochem[,7:19]) # select composition
Hydrochem$compo = Z # attach to dataset
md = lm(alr(compo)~log(H), data=Hydrochem) # fit model
anova(md)   # anova test

</code></pre>

<hr>
<h2 id='Yatquat'>Yatquat fruit evaluation</h2><span id='topic+Data12'></span><span id='topic+Yatquat'></span>

<h3>Description</h3>

<p>The quality of yatquat tree fruit is assessed in terms of relative proportions 
by volume of flesh, skin and stone.
In an experiment an arboriculturist uses 40 trees, randomly allocated 20
to the hormone treatment and leaves untreated the remaining 20 trees.
Data provides fruit compositions of the present season and the preceding season, 
as well as the treatment: 1 for the treated trees, -1 for untreated trees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Yatquat)
</code></pre>


<h3>Format</h3>

<p>A 40x7 data matrix</p>


<h3>Details</h3>

<p>The yatquat tree produces each season a single large fruit.
Data provides fruit compositions of the present season, the compositions of the fruit
of the same 40 trees for the preceding season when none of the trees were treated, 
and in addition the Type: 1 for the treated trees, -1 for untreated trees. 
For each of the 40 cases we have two 3-part composition on flesh, skin and stone.
The column names are:
</p>

<table>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> prFL</td><td style="text-align: left;">  portion of fruit flesh in the present season,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> prSK</td><td style="text-align: left;">  portion of fruit skin in the present season,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> prST</td><td style="text-align: left;">  portion of fruit stone in the present season,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> Type</td><td style="text-align: left;">  1 for treated,  $-1$ for untreated trees,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> paFL</td><td style="text-align: left;">  portion of fruit flesh in the preceding season,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> paSK</td><td style="text-align: left;">  portion of fruit skin in the preceding season,</td>
</tr>
<tr>
 <td style="text-align: right;">
 </td><td style="text-align: left;"> paST</td><td style="text-align: left;">  portion of fruit stone in the preceding season,
</td>
</tr>

</table>

<p>All 3-part compositions sum to one.
</p>


<h3>Note</h3>

<p>Courtesy of J. Aitchison</p>


<h3>Source</h3>

<p>Aitchison: CODA microcomputer statistical package, 1986, the file name YATQUAT.DAT,
here included under the GNU Public Library Licence Version 2 or newer.
</p>


<h3>References</h3>

<p>Aitchison, J. (1986) The Statistical Analysis of Compositional Data, (Data 12) pp17. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data(Yatquat)
#plot(acomp(Yatquat[,1:3]),col=as.numeric(Yatquat[,4])+2)
#plot(acomp(Yatquat[,5:7]),col=as.numeric(Yatquat[,4])+2)
</code></pre>

<hr>
<h2 id='zeroreplace'>Zero-replacement routine</h2><span id='topic+zeroreplace'></span>

<h3>Description</h3>

<p>A function to automatically replace rounded zeroes/BDLs in a composition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>          zeroreplace(x,d=NULL,a=2/3)
          </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zeroreplace_+3A_x">x</code></td>
<td>
<p>composition or dataset of compositions</p>
</td></tr>
<tr><td><code id="zeroreplace_+3A_d">d</code></td>
<td>
<p>vector containing the detection limits of each part</p>
</td></tr>
<tr><td><code id="zeroreplace_+3A_a">a</code></td>
<td>
<p>fraction of the detection limit to be used in replacement</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>d</code> is given, zeroes from each column of <code>x</code> are replaced by the 
corresponding detection limit contained there, scaled
down by the value of <code>a</code> (usually a scalar, although if 
it is a vector it will be recycled with a warning). The variable <code>d</code> should
be a vector of length equal to <code>ncol(x)</code> 
or a matrix of the same shape as <code>x</code>.
<br />
If <code>d=NULL</code>, then the detection limit is extracted from the data set,
if it is available there (i.e., if there are negative numbers). If no negative
number is present in the data set, and no value is given for <code>d</code>, the
result will be equal to <code>x</code>. See <code><a href="#topic+compositions.missings">compositions.missings</a></code> for more 
details on the missing policy.
</p>


<h3>Value</h3>

<p>an object of the same class as <code>x</code>, where all WZERO values have been replaced. 
Output contains a further attribute (named <code>Losts</code>), 
with a logical array of the same dimensions as <code>x</code>, 
showing which elements were replaced (TRUE) and which were 
kept unchanged (FALSE).</p>


<h3>References</h3>

<p>Aitchison, J. (1986) <em>The Statistical Analysis of Compositional
Data</em> Monographs on Statistics and Applied Probability. Chapman &amp;
Hall Ltd., London (UK). 416p.<br />
</p>
<p>Mart\'in-Fern\'andez, J.A.; Barcel\'o-Vidal, C. and Pawlowsky-Glahn, V. (2003)
Dealing With Zeros and Missing Values in Compositional Data Sets
Using Nonparametric Imputation. <em>Mathematical Geology</em>, 35 , 253-278
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork03/">https://ima.udg.edu/Activitats/CoDaWork03/</a><br />
</p>
<p><a href="https://ima.udg.edu/Activitats/CoDaWork05/">https://ima.udg.edu/Activitats/CoDaWork05/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compositions.missings">compositions.missings</a></code>,<code><a href="#topic+getDetectionlimit">getDetectionlimit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SimulatedAmounts)
x &lt;- acomp(sa.lognormals)
xnew &lt;- simulateMissings(x,dl=0.05,knownlimit=FALSE)
xnew
xrep &lt;- zeroreplace(xnew,0.05)
xrep
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
