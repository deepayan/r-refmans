<!DOCTYPE html><html><head><title>Help for package SSGL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SSGL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv_gamma_grpreg'><p>Cross-validation for Group-Regularized Gamma Regression</p></a></li>
<li><a href='#cv_nb_grpreg'><p>Cross-validation for Group-Regularized Negative Binomial Regression</p></a></li>
<li><a href='#cv_SSGL'><p>Cross-Validation for Spike-and-Slab Group Lasso in Group-Regularized Generalized Linear Models (GLMs)</p></a></li>
<li><a href='#gamma_grpreg'><p>Group-regularized Gamma Regression</p></a></li>
<li><a href='#nb_grpreg'><p>Group-regularized Negative Binomial Regression</p></a></li>
<li><a href='#SSGL'><p>Spike-and-Slab Group Lasso for Group-Regularized Generalized Linear Models (GLMs)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Spike-and-Slab Group Lasso for Group-Regularized Generalized
Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-06-25</td>
</tr>
<tr>
<td>Author:</td>
<td>Ray Bai</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ray Bai &lt;raybaistat@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits group-regularized generalized linear models (GLMs) using the spike-and-slab group lasso (SSGL) prior introduced by Bai et al. (2022) &lt;<a href="https://doi.org/10.1080%2F01621459.2020.1765784">doi:10.1080/01621459.2020.1765784</a>&gt; and extended to GLMs by Bai (2023) &lt;<a href="https://doi.org/10.48550/arXiv.2007.07021">doi:10.48550/arXiv.2007.07021</a>&gt;. This package supports fitting the SSGL model for the following GLMs with group sparsity: Gaussian linear regression, binary logistic regression, Poisson regression, negative binomial regression, and gamma regression.
 Stand-alone functions for group-regularized negative binomial regression and group-regularized gamma regression are also available, with the option of employing the group lasso penalty of Yuan and Lin (2006) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2005.00532.x">doi:10.1111/j.1467-9868.2005.00532.x</a>&gt;, the group minimax concave penalty (MCP) of Breheny and Huang &lt;<a href="https://doi.org/10.1007%2Fs11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>&gt;, or the group smoothly clipped absolute deviation (SCAD) penalty of Breheny and Huang (2015) &lt;<a href="https://doi.org/10.1007%2Fs11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, MASS, pracma, grpreg</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-26 03:41:33 UTC; rayba</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-27 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv_gamma_grpreg'>Cross-validation for Group-Regularized Gamma Regression</h2><span id='topic+cv_gamma_grpreg'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized gamma regression with a known shape parameter <code class="reqn">\nu</code> and the log link. The cross-validation error (CVE) and cross-validation standard error (CVSE) are computed using the deviance for gamma regression.
</p>
<p>For a description of group-regularized gamma regression, see the description for the <code>gamma_grpreg</code> function. Our implementation is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than <code class="reqn">\frac{K-1}{K} \times</code> sample size, where <code class="reqn">K</code> is the number of folds.
</p>
<p>Note that the <code>gamma_grpreg</code> function also returns the generalized information criterion (GIC) of Fan and Tang (2013) for each regularization parameter in <code>lambda</code>, and the GIC can also be used for model selection instead of cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_gamma_grpreg(Y, X, groups, gamma_shape=1, penalty=c("gLASSO","gSCAD","gMCP"),
                n_folds=10, group_weights, taper, n_lambda=100, lambda, 
                max_iter=10000, tol=1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_gamma_grpreg_+3A_y">Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of strictly positive, continuous responses for training data.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column corresponds to the <code class="reqn">j</code>th overall feature.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_gamma_shape">gamma_shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for the responses. Default is <code>gamma_shape=1</code>.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of regression coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement cross-validation for gamma regression with the SSGL penalty, use the <code>cv_SSGL</code> function.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_n_folds">n_folds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>n_folds=10</code>.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_group_weights">group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_n_lambda">n_lambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>n_lambda=100</code>.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=10000</code>.</p>
</td></tr>
<tr><td><code id="cv_gamma_grpreg_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>lambda_min</code></td>
<td>
<p>The value in <code>lambda</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
<tr><td><code>min_index</code></td>
<td>
<p>The index of <code>lambda_min</code> in <code>lambda</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Fan, Y. and Tang, C. Y. (2013). &quot;Tuning parameter selection in high-dimensional penalized likelihood.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>:531-552.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). &quot;Model selection and estimation in regression with grouped variables.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>:49-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*11), nrow=100)
n = dim(X)[1]
groups = c(1,1,1,2,2,2,3,3,4,5,5)
beta_true = c(-1,1,1,0,0,0,0,0,0,1.5,-1.5)

## Generate responses from gamma regression with known shape parameter 1
eta = crossprod(t(X), beta_true)
shape = 1
Y = rgamma(n, rate=shape/exp(eta), shape=shape)

## 10-fold cross-validation for group-regularized gamma regression
## with the group LASSO penalty
gamma_cv = cv_gamma_grpreg(Y, X, groups, penalty="gLASSO")

## Plot cross-validation curve
plot(gamma_cv$lambda, gamma_cv$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes mean CVE
gamma_cv$lambda_min
## index of lambda_min in lambda
gamma_cv$min_index
</code></pre>

<hr>
<h2 id='cv_nb_grpreg'>Cross-validation for Group-Regularized Negative Binomial Regression</h2><span id='topic+cv_nb_grpreg'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized negative binomial regression with a known size parameter <code class="reqn">\alpha</code> and the log link. The cross-validation error (CVE) and cross-validation standard error (CVSE) are computed using the deviance for negative binomial regression.
</p>
<p>For a description of group-regularized negative binomial regression, see the description for the <code>nb_grpreg</code> function. Our implementation is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than <code class="reqn">\frac{K-1}{K} \times</code> sample size, where <code class="reqn">K</code> is the number of folds.
</p>
<p>Note that the <code>nb_grpreg</code> function also returns the generalized information criterion (GIC) of Fan and Tang (2013) for each regularization parameter in <code>lambda</code>, and the GIC can also be used for model selection instead of cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_nb_grpreg(Y, X, groups, nb_size=1, penalty=c("gLASSO","gSCAD","gMCP"),
            n_folds=10, group_weights, taper, n_lambda=100, lambda, 
            max_iter=10000, tol=1e-4) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_nb_grpreg_+3A_y">Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of strictly nonnegative integer responses for training data.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column corresponds to the <code class="reqn">j</code>th overall feature.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_nb_size">nb_size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses. Default is <code>nb_size=1</code>.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of regression coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement cross-validation for gamma regression with the SSGL penalty, use the <code>cv_SSGL</code> function.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_n_folds">n_folds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>n_folds=10</code>.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_group_weights">group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_n_lambda">n_lambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>n_lambda=100</code>.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=10000</code>.</p>
</td></tr>
<tr><td><code id="cv_nb_grpreg_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>lambda_min</code></td>
<td>
<p>The value in <code>lambda</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
<tr><td><code>min_index</code></td>
<td>
<p>The index of <code>lambda_min</code> in <code>lambda</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Fan, Y. and Tang, C. Y. (2013). &quot;Tuning parameter selection in high dimensional penalized likelihood.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>:531-552. 
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). &quot;Model selection and estimation in regression with grouped variables.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>:49-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(1234)
X = matrix(runif(100*14), nrow=100)
n = dim(X)[1]
groups = c(1,1,1,2,2,2,2,3,3,4,5,5,6,6)
beta_true = c(-1,1,1,0,0,0,0,-1,1,0,0,0,-1.5,1.5)

## Generate count responses from negative binomial regression
eta = crossprod(t(X), beta_true)
Y = rnbinom(n, size=1, mu=exp(eta))

## 10-fold cross-validation for group-regularized negative binomial
## regression with the group MCP penalty
nb_cv = cv_nb_grpreg(Y, X, groups, penalty="gMCP")

## Plot cross-validation curve
plot(nb_cv$lambda, nb_cv$cve, type="l", xlab="lambda", ylab="CVE")
## lambda which minimizes mean CVE
nb_cv$lambda_min 
## index of lambda_min in lambda
nb_cv$min_index
</code></pre>

<hr>
<h2 id='cv_SSGL'>Cross-Validation for Spike-and-Slab Group Lasso in Group-Regularized Generalized Linear Models (GLMs)</h2><span id='topic+cv_SSGL'></span>

<h3>Description</h3>

<p>This function implements <code class="reqn">K</code>-fold cross-validation for group-regularized GLMs with the spike-and-slab group lasso (SSGL) penalty of Bai et al. (2022) and Bai (2023). The identity link function is used for Gaussian regression, the logit link is used for binomial regression, and the log link is used for Poisson, negative binomial, and gamma regression. 
</p>
<p>Although one can choose <code>lambda0</code> from cross-validation with this function, it can be very time-consuming to do so if the number of groups <code class="reqn">G</code> and/or the number of total covariantes <code class="reqn">p</code> is moderate to large. It is <em>strongly</em> recommended that the user simply run  the <code>SSGL</code> function on the training dataset and select the final model according to the <code>lambda0</code> that minimizes the generalized information criterion (GIC). See description of the <code>SSGL</code> function for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_SSGL(Y, X, groups, 
        family=c("gaussian","binomial","poisson","negativebinomial","gamma"), 
        nb_size=1, gamma_shape=1, group_weights, n_folds=5, n_lambda0=25,
        lambda0, lambda1=1, a=1, b=dim(X)[2], 
        max_iter=100, tol=1e-6, print_fold=TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_SSGL_+3A_y">Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column corresponds to the <code class="reqn">j</code>th overall feature.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_family">family</code></td>
<td>
<p>exponential dispersion family of the response variables. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified in advance, while for <code>"gamma"</code>, the shape parameter must be specified in advance.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_nb_size">nb_size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses if the user specifies <code>family="negativebinomial"</code>. Default is <code>nb_size=1</code>. Ignored if <code>family</code> is not <code>"negativebinomial"</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_gamma_shape">gamma_shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">G(\mu_i,\nu)</code> distribution for the responses if the user specifies <code>family="gamma"</code>. Default is <code>gamma_shape=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_group_weights">group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_n_folds">n_folds</code></td>
<td>
<p>number of folds <code class="reqn">K</code> to use in <code class="reqn">K</code>-fold cross-validation. Default is <code>n_folds=5</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_n_lambda0">n_lambda0</code></td>
<td>
<p>number of spike hyperparameters <code class="reqn">L</code>. Default is <code>n_lambda0=25</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_lambda0">lambda0</code></td>
<td>
<p>grid of <code class="reqn">L</code> spike hyperparameters <code class="reqn">\lambda_0</code>. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_lambda1">lambda1</code></td>
<td>
<p>slab hyperparameter <code class="reqn">\lambda_1</code> in the SSGL prior. Default is <code>lambda1=1</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_a">a</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>a=1</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_b">b</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>b=dim(X)[2]</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=100</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-6</code>.</p>
</td></tr>
<tr><td><code id="cv_SSGL_+3A_print_fold">print_fold</code></td>
<td>
<p>Boolean variable for whether or not to print the current fold in the algorithm. Default is <code>print_fold=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of spike hyperparameters <code>lambda0</code> used to fit the model. <code>lambda0</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of mean cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cve</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter parameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>cvse</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of standard errors for cross-validation error across all <code class="reqn">K</code> folds. The <code class="reqn">k</code>th entry in <code>cvse</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter parameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>lambda0_min</code></td>
<td>
<p>The value in <code>lambda0</code> that minimizes mean cross-validation error <code>cve</code>.</p>
</td></tr>
<tr><td><code>min_index</code></td>
<td>
<p>The index of <code>lambda0_min</code> in <code>lambda0</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bai, R. (2023). &quot;Bayesian group regularization in generalized linear models with a continuous spike-and-slab prior.&quot; <em>arXiv pre-print arXiv:2007.07021</em>.
</p>
<p>Bai, R., Moran, G. E., Antonelli, J. L., Chen, Y., and Boland, M.R. (2022). &quot;Spike-and-slab group lassos for grouped regression and sparse generalized additive models.&quot; <em>Journal of the American Statistical Association</em>, <b>117</b>:184-197.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(50*6), nrow=50)
n = dim(X)[1]
groups = c(1,1,1,2,2,2)
beta_true = c(-2,1,1.5,0,0,0)

## Generate responses from Gaussian distribution
Y = crossprod(t(X), beta_true) + rnorm(n)

## K-fold cross-validation 
## NOTE: If you do not specify lambda0, the function will automatically choose a suitable grid.
ssgl_mods = cv_SSGL(Y, X, groups, family="gaussian", lambda0=seq(from=16,to=4,by=-4))

## Plot cross-validation curve
plot(ssgl_mods$lambda0, ssgl_mods$cve, type="l", xlab="lambda0", ylab="CVE")
## lambda which minimizes mean CVE
ssgl_mods$lambda0_min
ssgl_mods$min_index


## Example with Poisson regression

## Generate count responses
eta = crossprod(t(X), beta_true)
Y = rpois(n,exp(eta))

## K-fold cross-validation 
## NOTE: If you do not specify lambda0, the program will automatically choose a suitable grid.
ssgl_poisson_mods = cv_SSGL(Y, X, groups, family="poisson", lambda0=seq(from=20,to=2,by=-4))

## Plot cross-validation curve
plot(ssgl_poisson_mods$lambda0, ssgl_poisson_mods$cve, type="l", xlab="lambda0", ylab="CVE")
## lambda which minimizes mean CVE
ssgl_poisson_mods$lambda0_min
ssgl_poisson_mods$min_index

</code></pre>

<hr>
<h2 id='gamma_grpreg'>Group-regularized Gamma Regression</h2><span id='topic+gamma_grpreg'></span>

<h3>Description</h3>

<p>This function implements group-regularized gamma regression with a known shape parameter <code class="reqn">\nu</code> and the log link. In gamma regression, we assume that <code class="reqn">y_i \sim Gamma(\mu_i, \nu)</code>, where
</p>
<p style="text-align: center;"><code class="reqn">f(y_i | \mu_i, \nu ) = \frac{1}{\Gamma(\nu)} (\frac{\nu}{\mu_i})^{\nu} \exp(-\frac{\nu}{\mu_i}y_i) y_i^{\nu-1}, y &gt; 0.</code>
</p>

<p>Then <code class="reqn">E(y_i) = \mu_i</code>, and we relate <code class="reqn">\mu_i</code> to a set of <code class="reqn">p</code> covariates <code class="reqn">x_i</code> through the log link,
</p>
<p style="text-align: center;"><code class="reqn">\log(\mu_i) = \beta_0 + x_i^T \beta, i=1,..., n</code>
</p>

<p>If the covariates in each <code class="reqn">x_i</code> are grouped according to known groups <code class="reqn">g=1, ..., G</code>, then this function can estimate some of the <code class="reqn">G</code> groups of coefficients as all zero, depending on the amount of regularization. Our implementation for regularized gamma regression is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than sample size.
</p>
<p>In addition, this function has the option of returning the generalized information criterion (GIC) of Fan and Tang (2013) for each regularization parameter in the grid <code>lambda</code>. The GIC can be used for model selection and serves as a useful alternative to cross-validation. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamma_grpreg(Y, X, groups, X_test, gamma_shape=1, 
             penalty=c("gLASSO","gSCAD","gMCP"), 
             group_weights, taper, n_lambda=100, lambda, 
             max_iter=10000, tol=1e-4, return_GIC=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gamma_grpreg_+3A_y">Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of strictly positive, continuous responses for training data.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column corresponds to the <code class="reqn">j</code>th overall feature.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_x_test">X_test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X_test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X_test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_gamma_shape">gamma_shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for the responses. Default is <code>gamma_shape=1</code>.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of regression coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement gamma regression with the SSGL penalty, use the <code>SSGL</code> function.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_group_weights">group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_n_lambda">n_lambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>n_lambda=100</code>.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=10000</code>.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
<tr><td><code id="gamma_grpreg_+3A_return_gic">return_GIC</code></td>
<td>
<p>Boolean variable for whether or not to return the GIC. Default is <code>return_GIC=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of estimated regression coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">G \times L</code> matrix of classifications, where <code class="reqn">G</code> is the number of groups. An entry of &quot;1&quot; indicates that the group was classified as nonzero, and an entry of &quot;0&quot; indicates that the group was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>Y_pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X_test</code> (or training data <code>X</code> if no argument was specified for <code>X_test</code>). The <code class="reqn">k</code>th column in <code>Y_pred</code> corresponds to the predictions for the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>GIC</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of GIC values. The <code class="reqn">k</code>th entry of <code>GIC</code> corresponds to the <code class="reqn">k</code>th entry in our <code>lambda</code> grid. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
<tr><td><code>lambda_min</code></td>
<td>
<p>The value in <code>lambda</code> that minimizes <code>GIC</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
<tr><td><code>min_index</code></td>
<td>
<p>The index of <code>lambda_min</code> in <code>lambda</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Fan, Y. and Tang, C. Y. (2013). &quot;Tuning parameter selection in high dimensional penalized likelihood.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>:531-552.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). &quot;Model selection and estimation in regression with grouped variables.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>:49-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(1234)
X = matrix(runif(100*11), nrow=100)
n = dim(X)[1]
groups = c(1,1,1,2,2,2,3,3,4,5,5)
beta_true = c(-1,1,1,0,0,0,0,0,0,1.5,-1.5)

## Generate responses from gamma regression with known shape parameter 1
eta = crossprod(t(X), beta_true)
shape = 1
Y = rgamma(n, rate=shape/exp(eta), shape=shape)

## Generate test data
n_test = 50
X_test = matrix(runif(n_test*11), nrow=n_test)

## Fit gamma regression models with the group SCAD penalty
gamma_mod = gamma_grpreg(Y, X, groups, X_test, penalty="gSCAD")

## Tuning parameters used to fit models 
gamma_mod$lambda

## Predicted n_test-dimensional vectors mu=E(Y_test) based on test data, X_test. 
## The kth column of 'Y_pred' corresponds to the kth entry in 'lambda.'
gamma_mod$Y_pred

## Classifications of the 5 groups. The kth column of 'classifications'
# corresponds to the kth entry in 'lambda.'
gamma_mod$classifications

## Plot lambda vs. GIC
plot(gamma_mod$lambda, gamma_mod$GIC, type='l')

## Model selection with the lambda that minimizes GIC
gamma_mod$lambda_min
gamma_mod$min_index 
gamma_mod$classifications[, gamma_mod$min_index]
gamma_mod$beta[, gamma_mod$min_index]
</code></pre>

<hr>
<h2 id='nb_grpreg'>Group-regularized Negative Binomial Regression</h2><span id='topic+nb_grpreg'></span>

<h3>Description</h3>

<p>This function implements group-regularized negative binomial regression with a known size parameter <code class="reqn">\alpha</code> and the log link. In negative binomial regression, we assume that <code class="reqn">y_i \sim NB(\alpha, \mu_i)</code>, where
</p>
<p style="text-align: center;"><code class="reqn">f(y_i | \alpha, \mu_i ) = \frac{\Gamma(y_i+\alpha)}{y_i! \Gamma(\alpha)} (\frac{\mu_i}{\mu_i+\alpha})^{y_i}(\frac{\alpha}{\mu_i +\alpha})^{\alpha}, y_i = 0, 1, 2, ...</code>
</p>

<p>Then <code class="reqn">E(y_i) = \mu_i</code>, and we relate <code class="reqn">\mu_i</code> to a set of <code class="reqn">p</code> covariates <code class="reqn">x_i</code> through the log link,
</p>
<p style="text-align: center;"><code class="reqn">\log(\mu_i) = \beta_0 + x_i^T \beta, i=1,..., n</code>
</p>

<p>If the covariates in each <code class="reqn">x_i</code> are grouped according to known groups <code class="reqn">g=1, ..., G</code>, then this function can estimate some of the <code class="reqn">G</code> groups of coefficients as all zero, depending on the amount of regularization. Our implementation for regularized negative binomial regression is based on the least squares approximation approach of Wang and Leng (2007), and hence, the function does not allow the total number of covariates <code class="reqn">p</code> to be greater than sample size.
</p>
<p>In addition, this function has the option of returning the generalized information criterion (GIC) of Fan and Tang (2013) for each regularization parameter in the grid <code>lambda</code>. The GIC can be used for model selection and serves as a useful alternative to cross-validation. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb_grpreg(Y, X, groups, X_test, nb_size=1, penalty=c("gLASSO","gSCAD","gMCP"),
          group_weights, taper, n_lambda=100, lambda, 
          max_iter=10000, tol=1e-4, return_GIC=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nb_grpreg_+3A_y">Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of strictly nonnegative integer responses for training data.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column corresponds to the <code class="reqn">j</code>th overall feature.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_x_test">X_test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X_test</code> must have the <em>same</em> number of columns as <code>X</code>, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X_test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_nb_size">nb_size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses. Default is <code>nb_size=1</code>.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_penalty">penalty</code></td>
<td>
<p>group regularization method to use on the groups of regression coefficients. The options are <code>"gLASSO"</code>, <code>"gSCAD"</code>, <code>"gMCP"</code>. To implement gamma regression with the SSGL penalty, use the <code>SSGL</code> function.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_group_weights">group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_taper">taper</code></td>
<td>
<p>tapering term <code class="reqn">\gamma</code> in group SCAD and group MCP controlling how rapidly the penalty tapers off. Default is <code>taper=4</code> for group SCAD and <code>taper=3</code> for group MCP. Ignored if <code>"gLASSO"</code> is specified as the penalty.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_n_lambda">n_lambda</code></td>
<td>
<p>number of regularization parameters <code class="reqn">L</code>. Default is <code>n_lambda=100</code>.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_lambda">lambda</code></td>
<td>
<p>grid of <code class="reqn">L</code> regularization parameters. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=10000</code>.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-4</code>.</p>
</td></tr>
<tr><td><code id="nb_grpreg_+3A_return_gic">return_GIC</code></td>
<td>
<p>Boolean variable for whether or not to return the GIC. Default is <code>return_GIC=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of regularization parameters <code>lambda</code> used to fit the model. <code>lambda</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of estimated regression coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">G \times L</code> matrix of classifications, where <code class="reqn">G</code> is the number of groups. An entry of &quot;1&quot; indicates that the group was classified as nonzero, and an entry of &quot;0&quot; indicates that the group was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>Y_pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X_test</code> (or training data <code>X</code> if no argument was specified for <code>X_test</code>). The <code class="reqn">k</code>th column in <code>Y_pred</code> corresponds to the predictions for the <code class="reqn">k</code>th regularization parameter in <code>lambda</code>.</p>
</td></tr>
<tr><td><code>GIC</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of GIC values. The <code class="reqn">k</code>th entry of <code>GIC</code> corresponds to the <code class="reqn">k</code>th entry in our <code>lambda</code> grid. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
<tr><td><code>lambda_min</code></td>
<td>
<p>The value in <code>lambda</code> that minimizes <code>GIC</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
<tr><td><code>min_index</code></td>
<td>
<p>The index of <code>lambda_min</code> in <code>lambda</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breheny, P. and Huang, J. (2015). &quot;Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors.&quot; <em>Statistics and Computing</em>, <b>25</b>:173-187.
</p>
<p>Fan, Y. and Tang, C. Y. (2013). &quot;Tuning parameter selection in high dimensional penalized likelihood.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>:531-552.
</p>
<p>Wang, H. and Leng, C. (2007). &quot;Unified LASSO estimation by least squares approximation.&quot; <em>Journal of the American Statistical Association</em>, <b>102</b>:1039-1048.
</p>
<p>Yuan, M. and Lin, Y. (2006). &quot;Model selection and estimation in regression with grouped variables.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>68</b>:49-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(1234)
X = matrix(runif(100*15), nrow=100)
n = dim(X)[1]
groups = c("A","A","A","A","B","B","B","B","C","C","D","D","E","E","E")
groups = as.factor(groups)
beta_true = c(-1.5,1.5,-1.5,1.5,0,0,0,0,0,0,2,-2,0,0,0)

## Generate count responses from negative binomial regression
eta = crossprod(t(X), beta_true)
Y = rnbinom(n,size=1, mu=exp(eta))

## Generate test data
n_test = 50
X_test = matrix(runif(n_test*15), nrow=n_test)
  
## Fit negative binomial regression models with the group MCP penalty
nb_mod = nb_grpreg(Y, X, groups, X_test, penalty="gMCP")
  
## Tuning parameters used to fit models 
nb_mod$lambda
  
# Predicted n_test-dimensional vectors mu=E(Y_test) based on test data, X_test. 
# The kth column of 'Y_pred' corresponds to the kth entry in 'lambda.'
nb_mod$Y_pred
  
# Classifications of the 8 groups. The kth column of 'classifications'
# corresponds to the kth entry in lambda.
nb_mod$classifications

## Plot lambda vs. GIC
plot(nb_mod$lambda, nb_mod$GIC, type='l')

## Model selection with the lambda that minimizes GIC
nb_mod$lambda_min
nb_mod$min_index 
nb_mod$classifications[, nb_mod$min_index]
nb_mod$beta[, nb_mod$min_index]
</code></pre>

<hr>
<h2 id='SSGL'>Spike-and-Slab Group Lasso for Group-Regularized Generalized Linear Models (GLMs)</h2><span id='topic+SSGL'></span>

<h3>Description</h3>

<p>This is a function to implement group-regularized GLMs with the spike-and-slab group lasso (SSGL) penalty of Bai et al. (2022) and Bai (2023). The identity link function is used for Gaussian regression, the logit link is used for binomial regression, and the log link is used for Poisson, negative binomial, and gamma regression. If the covariates in each <code class="reqn">x_i</code> are grouped according to known groups <code class="reqn">g=1, ..., G</code>, then this function can estimate some of the <code class="reqn">G</code> groups of coefficients as all zero, depending on the amount of regularization. 
</p>
<p>In addition, this function has the option of returning the generalized information criterion (GIC) of Fan and Tang (2013) for each regularization parameter in the grid <code>lambda0</code>. The GIC can be used for model selection and serves as a useful alternative to cross-validation. The formula for the GIC and a given <code class="reqn">\lambda_0</code> is
</p>
<p style="text-align: center;"><code class="reqn">DIC(\lambda_0) = \frac{1}{n} Deviance_{\lambda_0} + a_n \times \nu),</code>
</p>

<p>where <code class="reqn">Deviance_{\lambda_0}</code> is the deviance computed with the estimate of <code>beta</code> based on spike hyperparameter <code class="reqn">\lambda_0</code>, <code class="reqn">\nu_0</code> is the number of nonzero elements in the estimated <code>beta</code>, and <code class="reqn">a_n</code> is a sequence that diverges at a suitable rate relative to <code class="reqn">n</code>. As recommended by Fan and Tang (2013), we set <code class="reqn">a_n = \{\log(\log(n))\}\log(p)</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>SSGL(Y, X, groups, 
     family=c("gaussian","binomial","poisson","negativebinomial","gamma"), 
     X_test, nb_size=1, gamma_shape=1, group_weights, n_lambda0=25, 
     lambda0, lambda1=1, a=1, b=dim(X)[2], 
     max_iter=100, tol = 1e-6, return_GIC=TRUE, print_lambda0=TRUE) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SSGL_+3A_y">Y</code></td>
<td>
<p><code class="reqn">n \times 1</code> vector of responses for training data.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_x">X</code></td>
<td>
<p><code class="reqn">n \times p</code> design matrix for training data, where the <code class="reqn">j</code>th column of <code>X</code> corresponds to the <code class="reqn">j</code>th overall covariate.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_groups">groups</code></td>
<td>
<p><code class="reqn">p</code>-dimensional vector of group labels. The <code class="reqn">j</code>th entry in <code>groups</code> should contain either the group number <em>or</em> the factor level name that the feature in the <code class="reqn">j</code>th column of <code>X</code> belongs to. <code>groups</code> must be either a vector of integers or factors.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_family">family</code></td>
<td>
<p>exponential dispersion family of the response variables. Allows for <code>"gaussian"</code>, <code>"binomial"</code>, <code>"poisson"</code>, <code>"negativebinomial"</code>, and <code>"gamma"</code>. Note that for <code>"negativebinomial"</code>, the size parameter must be specified in advance, while for <code>"gamma"</code>, the shape parameter must be specified in advance.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_x_test">X_test</code></td>
<td>
<p><code class="reqn">n_{test} \times p</code> design matrix for test data to calculate predictions. <code>X_test</code> must have the <em>same</em> number of columns as X, but not necessarily the same number of rows. If <em>no</em> test data is provided or if in-sample predictions are desired, then the function automatically sets <code>X_test=X</code> in order to calculate <em>in-sample</em> predictions.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_nb_size">nb_size</code></td>
<td>
<p>known size parameter <code class="reqn">\alpha</code> in <code class="reqn">NB(\alpha,\mu_i)</code> distribution for the responses if the user specifies <code>family="negativebinomial"</code>. Default is <code>nb_size=1</code>. Ignored if <code>family</code> is not <code>"gamma"</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_gamma_shape">gamma_shape</code></td>
<td>
<p>known shape parameter <code class="reqn">\nu</code> in <code class="reqn">Gamma(\mu_i,\nu)</code> distribution for the responses if the user specifies <code>family="gamma"</code>. Default is <code>gamma_shape=1</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_group_weights">group_weights</code></td>
<td>
<p>group-specific, nonnegative weights for the penalty. Default is to use the square roots of the group sizes.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_n_lambda0">n_lambda0</code></td>
<td>
<p>number of spike hyperparameters <code class="reqn">L</code>. Default is <code>n_lambda0=25</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_lambda0">lambda0</code></td>
<td>
<p>grid of <code class="reqn">L</code> spike hyperparameters <code class="reqn">\lambda_0</code>. The user may specify either a scalar or a vector. If the user does not provide this, the program chooses the grid automatically.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_lambda1">lambda1</code></td>
<td>
<p>slab hyperparameter <code class="reqn">\lambda_1</code> in the SSGL prior. Default is <code>lambda1=1</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_a">a</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>a=1</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_b">b</code></td>
<td>
<p>shape hyperparameter for the <code class="reqn">Beta(a,b)</code> prior on the mixing proportion in the SSGL prior. Default is <code>b=dim(X)[2]</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iterations in the algorithm. Default is <code>max_iter=100</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_tol">tol</code></td>
<td>
<p>convergence threshold for algorithm. Default is <code>tol=1e-6</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_return_gic">return_GIC</code></td>
<td>
<p>Boolean variable for whether or not to return the GIC. Default is <code>return_GIC=TRUE</code>.</p>
</td></tr>
<tr><td><code id="SSGL_+3A_print_lambda0">print_lambda0</code></td>
<td>
<p>Boolean variable for whether or not to print the current value in <code>lambda0</code>. Default is <code>print_lambda0=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the following components:
</p>
<table>
<tr><td><code>lambda0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of spike hyperpameters <code>lambda0</code> used to fit the model. <code>lambda0</code> is displayed in descending order.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p><code class="reqn">p \times L</code> matrix of estimated regression coefficients. The <code class="reqn">k</code>th column in <code>beta</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of estimated intercepts. The <code class="reqn">k</code>th entry in <code>beta0</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>classifications</code></td>
<td>
<p><code class="reqn">G \times L</code> matrix of classifications, where <code class="reqn">G</code> is the number of groups. An entry of &quot;1&quot; indicates that the group was classified as nonzero, and an entry of &quot;0&quot; indicates that the group was classified as zero. The <code class="reqn">k</code>th column of <code>classifications</code> corresponds to the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>Y_pred</code></td>
<td>
<p><code class="reqn">n_{test} \times L</code> matrix of predicted mean response values <code class="reqn">\mu_{test} = E(Y_{test})</code> based on the <em>test</em> data in <code>X_test</code> (or training data <code>X</code> if no argument was specified for <code>X_test</code>). The <code class="reqn">k</code>th column in <code>Y_pred</code> corresponds to the predictions for the <code class="reqn">k</code>th spike hyperparameter in <code>lambda0</code>.</p>
</td></tr>
<tr><td><code>GIC</code></td>
<td>
<p><code class="reqn">L \times 1</code> vector of GIC values. The <code class="reqn">k</code>th entry of <code>GIC</code> corresponds to the <code class="reqn">k</code>th entry in our <code>lambda0</code> grid. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
<tr><td><code>lambda0_min</code></td>
<td>
<p>The value in <code>lambda0</code> that minimizes <code>GIC</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
<tr><td><code>min_index</code></td>
<td>
<p>The index of <code>lambda0_min</code> in <code>lambda0</code>. This is not returned if <code>return_GIC=FALSE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bai, R. (2023). &quot;Bayesian group regularization in generalized linear models with a continuous spike-and-slab prior.&quot; <em>arXiv pre-print arXiv:2007.07021</em>.
</p>
<p>Bai, R., Moran, G. E., Antonelli, J. L., Chen, Y., and Boland, M.R. (2022). &quot;Spike-and-slab group lassos for grouped regression and sparse generalized additive models.&quot; <em>Journal of the American Statistical Association</em>, <b>117</b>:184-197.
</p>
<p>Fan, Y. and Tang, C. Y. (2013). &quot;Tuning parameter selection in high dimensional penalized likelihood.&quot; <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>:531-552.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate data
set.seed(12345)
X = matrix(runif(100*10), nrow=100)
n = dim(X)[1]
groups = c("A","A","A","B","B","B","C","C","D","D")
groups = as.factor(groups)
beta_true = c(-2.5,1.5,1.5,0,0,0,2,-2,0,0)

## Generate responses from Gaussian distribution
Y = crossprod(t(X), beta_true) + rnorm(n)

## Generate test data
n_test = 50
X_test = matrix(runif(n_test*10), nrow=n_test)

## Fit SSGL model with 10 spike hyperparameters
## NOTE: If you do not specify lambda0, the program will automatically choose a suitable grid.
SSGL_mod = SSGL(Y, X, groups, family="gaussian", X_test, lambda0=seq(from=50,to=5,by=-5))

## Regression coefficient estimates
SSGL_mod$beta

## Predicted n_test-dimensional vectors mu=E(Y.test) based on test data, X_test. 
## The kth column of 'Y_pred' corresponds to the kth entry in 'lambda.'
SSGL_mod$Y_pred 

## Classifications of the 8 groups. The kth column of 'classifications'
## corresponds to the kth entry in 'lambda.'
SSGL_mod$classifications

## Plot lambda vs. GIC
plot(SSGL_mod$lambda0, SSGL_mod$GIC, type='l')

## Model selection with the lambda that minimizes GIC
SSGL_mod$lambda0_min
SSGL_mod$min_index 
SSGL_mod$classifications[, SSGL_mod$min_index]
SSGL_mod$beta[, SSGL_mod$min_index]



## Example with binary logistic regression

set.seed(12345)
X = matrix(runif(100*8), nrow=100)
n = dim(X)[1]
groups = c("A","A","A","B","B","B","C","C")
groups = as.factor(groups)
beta_true = c(-2.5,1.5,1.5,0,0,0,2,-2)

## Generate binary responses
eta = crossprod(t(X), beta_true)
Y = rbinom(n, size=1, prob=1/(1+exp(-eta)))

## Generate test data
n_test = 50
X_test = matrix(runif(n_test*8), nrow=n_test)

## Fit SSGL logistic regression model with 10 spike hyperparameters
## NOTE: If you do not specify lambda0, the program will automatically choose a suitable grid.
SSGL_logistic_mod = SSGL(Y, X, groups, family="binomial", X_test, lambda0=seq(from=10,to=1,by=-1.5))

## Regression coefficient estimates
SSGL_logistic_mod$beta

## Predicted n_test-dimensional vectors mu=E(Y_test) based on test data, X_test. 
## The kth column of 'Y_pred' corresponds to the kth entry in 'lambda.'
SSGL_logistic_mod$Y_pred

## Classifications of the 8 groups. The kth column of 'classifications'
## corresponds to the kth entry in 'lambda.'
SSGL_logistic_mod$classifications

## Plot lambda vs. GIC
plot(SSGL_logistic_mod$lambda0, SSGL_logistic_mod$GIC, type='l')

## Model selection with the lambda that minimizes GIC
SSGL_logistic_mod$lambda0_min
SSGL_logistic_mod$min_index 
SSGL_logistic_mod$classifications[, SSGL_logistic_mod$min_index]
SSGL_logistic_mod$beta[, SSGL_logistic_mod$min_index]

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
