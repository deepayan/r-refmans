<!DOCTYPE html><html><head><title>Help for package labourR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {labourR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#classify_occupation'><p>Classify occupations</p></a></li>
<li><a href='#cleansing_corpus'><p>Cleansing Corpus</p></a></li>
<li><a href='#get_language_code'><p>Get language code from file name</p></a></li>
<li><a href='#get_stopwords'><p>Retrieve stopwords</p></a></li>
<li><a href='#identify_language'><p>Detect Language</p></a></li>
<li><a href='#isco_occupations_bundle'><p>ISCO occupations bundle</p></a></li>
<li><a href='#occupations_bundle'><p>ESCO occupations bundle</p></a></li>
<li><a href='#tf_idf'><p>Term frequencyâ€“Inverse document frequency</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Classify Multilingual Labour Market Free-Text to Standardized
Hierarchical Occupations</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Allows the user to map multilingual free-text of occupations to a broad range
    of standardized classifications. The package facilitates automatic occupation coding
    (see, e.g., Gweon et al. (2017) &lt;<a href="https://doi.org/10.1515%2Fjos-2017-0006">doi:10.1515/jos-2017-0006</a>&gt; and Turrell et al. (2019)
    &lt;<a href="https://doi.org/10.3386%2Fw25837">doi:10.3386/w25837</a>&gt;), where the ISCO to ESCO mapping is exploited to extend the
    occupations hierarchy, Le Vrang et al. (2014) &lt;<a href="https://doi.org/10.1109%2Fmc.2014.283">doi:10.1109/mc.2014.283</a>&gt;. Document
    vectorization is performed using the multilingual ESCO corpus. A method based on the 
    nearest neighbor search is used to suggest the closest ISCO occupation.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/AleKoure/labourR">https://github.com/AleKoure/labourR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/AleKoure/labourR/issues">https://github.com/AleKoure/labourR/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 2.1.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, cld2, magrittr, stopwords, stringdist</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-07-14 17:03:19 UTC; ale</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexandros Kouretsis [aut, cre],
  Andreas Bampouris [aut],
  Petros Morfiris [aut],
  Konstantinos Papageorgiou [aut],
  Stavros Ladas [ctb],
  Athanassios Siaperas [ctb],
  Philippe Tissot [ctb],
  Nikos Vaslamatzis [ctb],
  Eworx S.A [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexandros Kouretsis &lt;ako@eworx.gr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-07-18 09:30:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='classify_occupation'>Classify occupations</h2><span id='topic+classify_occupation'></span>

<h3>Description</h3>

<p>This function takes advantage of the hierarchical structure of the ESCO-ISCO mapping and matches multilingual free-text with the
<a href="https://ec.europa.eu/esco/portal/home">ESCO</a> occupations vocabulary in order to map semi-structured vacancy data into the official
ESCO-ISCO classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classify_occupation(
  corpus,
  id_col = "id",
  text_col = "text",
  lang = "en",
  num_leaves = 10,
  isco_level = 3,
  max_dist = 0.1,
  string_dist = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classify_occupation_+3A_corpus">corpus</code></td>
<td>
<p>A data.frame or a data.table that contains the id and the text variables.</p>
</td></tr>
<tr><td><code id="classify_occupation_+3A_id_col">id_col</code></td>
<td>
<p>The name of the id variable.</p>
</td></tr>
<tr><td><code id="classify_occupation_+3A_text_col">text_col</code></td>
<td>
<p>The name of the text variable.</p>
</td></tr>
<tr><td><code id="classify_occupation_+3A_lang">lang</code></td>
<td>
<p>The language that the text is in.</p>
</td></tr>
<tr><td><code id="classify_occupation_+3A_num_leaves">num_leaves</code></td>
<td>
<p>The number of occupations/neighbors that are kept when matching.</p>
</td></tr>
<tr><td><code id="classify_occupation_+3A_isco_level">isco_level</code></td>
<td>
<p>The <a href="https://ec.europa.eu/esco/portal/escopedia/Occupation">ISCO</a> level of the suggested occupations.
Can be either 1, 2, 3, 4 for ISCO occupations, or NULL that returns ESCO occupations.</p>
</td></tr>
<tr><td><code id="classify_occupation_+3A_max_dist">max_dist</code></td>
<td>
<p>String distance used for fuzzy matching. The <code><a href="stringdist.html#topic+amatch">amatch</a></code> function from the stringdist package is used.</p>
</td></tr>
<tr><td><code id="classify_occupation_+3A_string_dist">string_dist</code></td>
<td>
<p>String dissimilarity measurement. Available string distance metrics: <code><a href="stringdist.html#topic+stringdist-metrics">stringdist-metrics</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, the input text is cleansed and tokenized. The tokens are then matched with the ESCO occupations vocabulary, created from
the preferred and alternative labels of the occupations. They are joined with the <code><a href="#topic+tf_idf">tfidf</a></code>
weighted tokens of the ESCO occupations and the sum of the tf-idf score is used to retrieve the suggested ontologies. Technically speaking, the
suggested ESCO occupations are retrieved by solving the optimization problem, </p>
<p style="text-align: center;"><code class="reqn">\arg\max_d\left\{\vec{u}_{binary}\cdot \vec{u}_d\right\}</code>
</p>

<p>where, <code class="reqn">\vec{u}_{binary}</code> stands for the binary representation of a query to the ESCO-vocabulary space,
while, <code class="reqn">\vec{u}_d</code> is the ESCO occupation normalized vector generated by the tf-idf numerical statistic.
If an ISCO level is specified, the k-nearest neighbors algorithm is used to determine the suggested occupation, classified by a plurality vote in the corresponding hierarchical level of its neighbors.
</p>
<p>Before the suggestions are returned, the preferred label of each suggested occupation is added to the result, using the
<code><a href="#topic+occupations_bundle">occupations_bundle</a></code> and <code><a href="#topic+isco_occupations_bundle">isco_occupations_bundle</a></code> as look-up tables.
</p>


<h3>Value</h3>

<p>Either a data.table with the id, the preferred label and the suggested ESCO occupation URIs (num_leaves predictions for each id),
or a data.table with the id, the preferred label and the suggested ISCO group of the inputted level (one for each id).
</p>


<h3>References</h3>

<p>M.P.J. van der Loo (2014). <a href="https://journal.r-project.org/archive/2014-1/loo.pdf">The stringdist package for approximate string matching</a>. R Journal 6(1) pp 111-122.
</p>
<p>Gweon, H., Schonlau, M., Kaczmirek, L., Blohm, M., &amp; Steiner, S. (2017). <a href="https://doi.org/10.1515/jos-2017-0006">Three Methods for Occupation Coding Based on Statistical Learning, Journal of Official Statistics</a>, 33(1), 101-122.
</p>
<p>Arthur Turrell, Bradley J. Speigner, Jyldyz Djumalieva, David Copple, James Thurgood (2019).
<a href="https://www.nber.org/papers/w25837">Transforming Naturally Occurring Text Data Into Economic Statistics:
The Case of Online Job Vacancy Postings</a>.
</p>
<p>ESCO Service Platform - <a href="https://ec.europa.eu/esco/portal/document/en/87a9f66a-1830-4c93-94f0-5daa5e00507e">
The ESCO Data Model documentation</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>corpus &lt;- data.frame(
 id = 1:3,
 text = c(
   "Junior Architect Engineer",
   "Cashier at McDonald's",
   "Priest at St. Martin Catholic Church"
 )
)
classify_occupation(corpus = corpus, isco_level = 3, lang = "en", num_leaves = 5)

</code></pre>

<hr>
<h2 id='cleansing_corpus'>Cleansing Corpus</h2><span id='topic+cleansing_corpus'></span>

<h3>Description</h3>

<p>The function performs text cleansing by removing escape characters, non alphanumeric,
long-words, excess space, and turns all letters to lower case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cleansing_corpus(
  text,
  escape_chars = TRUE,
  nonalphanum = TRUE,
  longwords = TRUE,
  whitespace = TRUE,
  tolower = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cleansing_corpus_+3A_text">text</code></td>
<td>
<p>Character vector of free text to be cleansed.</p>
</td></tr>
<tr><td><code id="cleansing_corpus_+3A_escape_chars">escape_chars</code></td>
<td>
<p>If TRUE, removes escape characters for <code style="white-space: pre;">&#8288;slash n&#8288;</code>, <code style="white-space: pre;">&#8288;slash r&#8288;</code> and <code style="white-space: pre;">&#8288;slash t&#8288;</code>.</p>
</td></tr>
<tr><td><code id="cleansing_corpus_+3A_nonalphanum">nonalphanum</code></td>
<td>
<p>If TRUE, removes non-alphanumeric characters.</p>
</td></tr>
<tr><td><code id="cleansing_corpus_+3A_longwords">longwords</code></td>
<td>
<p>If TRUE, removes words with more than 35 characters.</p>
</td></tr>
<tr><td><code id="cleansing_corpus_+3A_whitespace">whitespace</code></td>
<td>
<p>If TRUE, removes excess whitespace.</p>
</td></tr>
<tr><td><code id="cleansing_corpus_+3A_tolower">tolower</code></td>
<td>
<p>If TRUE, turns letters to lower.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector of the cleansed text.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- "It has roots in a piece of classical Latin literature from 45 BC"
cleansing_corpus(txt)
</code></pre>

<hr>
<h2 id='get_language_code'>Get language code from file name</h2><span id='topic+get_language_code'></span>

<h3>Description</h3>

<p>Occupations' labels and structure are exposed at the ESCO web portal. This function retrieves languages
from the downloadable CSVs, see <a href="https://ec.europa.eu/esco/portal/escopedia/ESCO_languages">escopedia</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_language_code(string)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_language_code_+3A_string">string</code></td>
<td>
<p>Filepath with a language code as given by ESCO downloadable .CSVs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector with two-letter language codes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_language_code("occupations_en.csv")

</code></pre>

<hr>
<h2 id='get_stopwords'>Retrieve stopwords</h2><span id='topic+get_stopwords'></span>

<h3>Description</h3>

<p>The functions retrieves stopwords from the <code><a href="stopwords.html#topic+stopwords">stopwords</a></code> package using the ISO-639-1 encoding.
For miscellaneous languages <code><a href="stopwords.html#topic+data_stopwords_misc">data_stopwords_misc</a></code> are used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_stopwords(code)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_stopwords_+3A_code">code</code></td>
<td>
<p>A string with the language code of the stopwords.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character vector with the stopwords or NULL if the language code is unknown.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_stopwords("en")[1:10]

</code></pre>

<hr>
<h2 id='identify_language'>Detect Language</h2><span id='topic+identify_language'></span>

<h3>Description</h3>

<p>This function performs language detection by using Compact Language Detector 2 from CRAN library <code><a href="cld2.html#topic+cld2">cld2</a></code>.
It is vectorised and guesses the language of each string. Note that it is not designed to do well on very short text,
lists of proper names, part numbers, etc. CLD2 has the highest F1 score and is an order of magnitude faster than CLD3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identify_language(text)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="identify_language_+3A_text">text</code></td>
<td>
<p>A string with text to classify or a connection to read from.
</p>

<ul>
<li><p> cld2: Probabilistically (NaÃ¯ve Bayesian classifier) detects over 80 languages in plain text.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector with ISO-639-1 two-letter language codes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- c("English is a West Germanic language ", "In espaniol, le lingua castilian")
identify_language(txt)

</code></pre>

<hr>
<h2 id='isco_occupations_bundle'>ISCO occupations bundle</h2><span id='topic+isco_occupations_bundle'></span>

<h3>Description</h3>

<p>The International Standard Classification of Occupations (ISCO) is a four-level classification of occupation groups managed
by the International Labour Organisation (ILO). Its structure follows a grouping by education level. The two latest versions of ISCO are
ISCO-88 (dating from 1988) and ISCO-08 (dating from 2008).
</p>

<ul>
<li><p> The ESCO version used is ESCO v1 1.0.3 retrieved at 11/12/2019.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>isco_occupations_bundle
</code></pre>


<h3>Format</h3>

<p>A data.table with 2 variables, which are:
</p>

<dl>
<dt>iscoGroup</dt><dd><p>Four-level classification of occupation groups.</p>
</dd>
<dt>preferredLabel</dt><dd><p>Preffered name of ISCO occupation concepts.</p>
</dd>
</dl>



<h3>Source</h3>

<p>International Standard Classification of Occupations (<a href="https://ec.europa.eu/esco/portal/escopedia/International_Standard_Classification_of_Occupations__40_ISCO_41_">ISCO</a>).
</p>

<hr>
<h2 id='occupations_bundle'>ESCO occupations bundle</h2><span id='topic+occupations_bundle'></span>

<h3>Description</h3>

<p>The occupations pillar is one of the three pillars of <a href="https://ec.europa.eu/esco/portal/home">ESCO</a>. It organizes
the occupation concepts. It uses hierarchical relationships between them, metadata as well as mappings to the International Standard
Classification of Occupations <a href="https://ec.europa.eu/esco/portal/escopedia/Occupation">ISCO</a> in order to structure the occupations.
The descriptions of each concept is provided only in English.
</p>

<ul>
<li><p> The ESCO version used is ESCO v1 1.0.3 retrieved at 11/12/2019.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>occupations_bundle
</code></pre>


<h3>Format</h3>

<p>A data.table with 5 variables, which are:
</p>

<dl>
<dt>conceptUri</dt><dd><p>Uniform Resource Identifier of occupations.</p>
</dd>
<dt>iscoGroup</dt><dd><p>Four-level classification of occupation groups, see <a href="https://ec.europa.eu/esco/portal/escopedia/International_Standard_Classification_of_Occupations__40_ISCO_41_">ISCO</a>.</p>
</dd>
<dt>preferredLabel</dt><dd><p>Preffered name of ESCO occupation concepts.</p>
</dd>
<dt>altLabels</dt><dd><p>Alternative labels of ESCO occupation concepts.</p>
</dd>
<dt>description</dt><dd><p>Description of ESCO occupation concepts.</p>
</dd>
</dl>



<h3>Source</h3>

<p>European Skills/Competences, Qualifications and Occupations <a href="https://ec.europa.eu/esco/portal/home">ESCO</a>.
</p>

<hr>
<h2 id='tf_idf'>Term frequencyâ€“Inverse document frequency</h2><span id='topic+tf_idf'></span>

<h3>Description</h3>

<p>Measure weighted amount of information concerning the specificity of terms in a corpus.
Term frequencyâ€“Inverse document frequency is one of the most frequently applied weighting schemes in information retrieval systems.
The tfâ€“idf is a statistical measure proportional to the number of times a word appears in the document, but is offset by the number of documents
in the corpus that contain the word. Variations of the tfâ€“idf are often used to estimate a document's relevance given a
free-text query.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf_idf(
  corpus,
  stopwords = NULL,
  id_col = "id",
  text_col = "text",
  tf_weight = "double_norm",
  idf_weight = "idf_smooth",
  min_chars = 2,
  norm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tf_idf_+3A_corpus">corpus</code></td>
<td>
<p>Input data, with an id column and a text column. Can be of type data.frame or data.table.</p>
</td></tr>
<tr><td><code id="tf_idf_+3A_stopwords">stopwords</code></td>
<td>
<p>A character vector of stopwords. Stopwords are filtered out before calculating numerical statistics.</p>
</td></tr>
<tr><td><code id="tf_idf_+3A_id_col">id_col</code></td>
<td>
<p>Input data column name with the ids of the documents.</p>
</td></tr>
<tr><td><code id="tf_idf_+3A_text_col">text_col</code></td>
<td>
<p>Input data column name with the documents.</p>
</td></tr>
<tr><td><code id="tf_idf_+3A_tf_weight">tf_weight</code></td>
<td>
<p>Weighting scheme of term frequency. Choices are <code>raw_count</code>, <code>double_norm</code> or <code>log_norm</code> for raw count, double normalization at 0.5 and log normalization respectively.</p>
</td></tr>
<tr><td><code id="tf_idf_+3A_idf_weight">idf_weight</code></td>
<td>
<p>Weighting scheme of inverse document frequency. Choices are <code>idf</code> and <code>idf_smooth</code> for inverse document frequency and inverse document frequency smooth respectively.</p>
</td></tr>
<tr><td><code id="tf_idf_+3A_min_chars">min_chars</code></td>
<td>
<p>Words with less characters than <code>min_chars</code> are filtered out before calculating numerical statistics.</p>
</td></tr>
<tr><td><code id="tf_idf_+3A_norm">norm</code></td>
<td>
<p>Boolean value for document normalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.table with three columns, namely <code>class</code> derived from given document ids, <code>term</code> and <code>tfIdf</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(data.table)
corpus &lt;- copy(occupations_bundle)
invisible(corpus[, text := paste(preferredLabel, altLabels)])
invisible(corpus[, text := cleansing_corpus(text)])
corpus &lt;- corpus[ , .(conceptUri, text)]
setnames(corpus, c("id", "text"))
tf_idf(corpus)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
