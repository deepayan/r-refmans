<!DOCTYPE html><html><head><title>Help for package archetypal</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {archetypal}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#archetypal-package'><p>Finds the Archetypal Analysis of a Data Frame</p></a></li>
<li><a href='#AbsoluteTemperature'>
<p>Global Absolute Temperature data set for Northern Hemisphere 1969-2013</p></a></li>
<li><a href='#align_archetypes_from_list'><p>Align archetypes from a list either by the most frequent found or by using a given archetype</p></a></li>
<li><a href='#archetypal'><p>archetypal: Finds the archetypal analysis of a data frame by using a variant of the PCHA algorithm</p></a></li>
<li><a href='#check_Bmatrix'><p>Function which checks B matrix of Archetypal Analysis  Y ~ A B Y</p>
in order to find the used rows for creating each archetype
and the relevant used weights.</a></li>
<li><a href='#dirichlet_sample'>
<p>Function which performs Dirichlet sampling</p></a></li>
<li><a href='#find_closer_points'><p>Function which finds the data points that are closer to the archetypes during all</p>
iterations of the algorithm PCHA</a></li>
<li><a href='#find_furthestsum_points'><p>Function which finds the furthest sum points</p>
in order to be used as initial solution in archetypal analysis</a></li>
<li><a href='#find_optimal_kappas'><p>Function for finding the optimal number of archetypes</p></a></li>
<li><a href='#find_outmost_convexhull_points'><p>Function which finds the outermost convex hull points</p>
in order to be used as initial solution in archetypal analysis</a></li>
<li><a href='#find_outmost_partitioned_convexhull_points'><p>Function which finds the outermost convex hull points after making</p>
np samples and finding convex hull for each of them.</a></li>
<li><a href='#find_outmost_points'><p>Function which finds the outermost points</p>
in order to be used as initial solution in archetypal analysis</a></li>
<li><a href='#find_outmost_projected_convexhull_points'><p>Function which finds the outermost projected convex hull points</p>
in order to be used as initial solution in archetypal analysis</a></li>
<li><a href='#find_pcha_optimal_parameters'><p>Finds the optimal updating parameters to be used for the PCHA algorithm</p></a></li>
<li><a href='#FurthestSum'><p>Application of FurthestSum algorithm in order to find an initial solution for Archetypal Analysis</p></a></li>
<li><a href='#gallupGPS6'>
<p>Gallup Global Preferences Study processed data set of six variables</p></a></li>
<li><a href='#grouped_resample'>
<p>Function for performing simple or Dirichlet resampling</p></a></li>
<li><a href='#kappa_tools'>
<p>Compute kappa tools for data dimensionality analysis</p></a></li>
<li><a href='#plot_archs'>
<p>A function for plotting arechetypes</p></a></li>
<li><a href='#plot.archetypal'>
<p>Plot an object of the class archetypal.</p></a></li>
<li><a href='#plot.kappa_tools'>
<p>Plot an object of the class kappa_tools</p></a></li>
<li><a href='#plot.study_AAconvergence'>
<p>Plot an object of the class study_AAconvergence</p></a></li>
<li><a href='#print.archetypal'>
<p>Print an object of the class archetypal.</p></a></li>
<li><a href='#study_AAconvergence'><p>Function which studies the convergence of</p>
Archetypal Analysis when using the PCHA algorithm</a></li>
<li><a href='#summary.archetypal'>
<p>Summary for an object of the class archetypal.</p></a></li>
<li><a href='#wd2'>
<p>2D data set for demonstration purposes</p></a></li>
<li><a href='#wd25'>
<p>2D data set created by 5 points for demonstration purposes</p></a></li>
<li><a href='#wd3'>
<p>3D data set for demonstration purposes</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.3.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Finds the Archetypal Analysis of a Data Frame</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs archetypal analysis by using Principal Convex Hull Analysis 
    under a full control of all algorithmic parameters. 
    It contains a set of functions for determining the initial solution, the optimal 
    algorithmic parameters and the optimal number of archetypes.
    Post run tools are also available for the assessment of the derived solution. 
    Morup, M., Hansen, LK (2012) &lt;<a href="https://doi.org/10.1016%2Fj.neucom.2011.06.033">doi:10.1016/j.neucom.2011.06.033</a>&gt;.
    Hochbaum, DS, Shmoys, DB (1985) &lt;<a href="https://doi.org/10.1287%2Fmoor.10.2.180">doi:10.1287/moor.10.2.180</a>&gt;.
    Eddy, WF (1977) &lt;<a href="https://doi.org/10.1145%2F355759.355768">doi:10.1145/355759.355768</a>&gt;.
    Barber, CB, Dobkin, DP, Huhdanpaa, HT (1996) &lt;<a href="https://doi.org/10.1145%2F235815.235821">doi:10.1145/235815.235821</a>&gt;.    
    Christopoulos, DT (2016) &lt;<a href="https://doi.org/10.2139%2Fssrn.3043076">doi:10.2139/ssrn.3043076</a>&gt;.    
    Falk, A., Becker, A., Dohmen, T., Enke, B., Huffman, D., Sunde, U. (2018), &lt;<a href="https://doi.org/10.1093%2Fqje%2Fqjy013">doi:10.1093/qje/qjy013</a>&gt;. 
    Christopoulos, DT (2015) &lt;<a href="https://doi.org/10.1016%2Fj.jastp.2015.03.009">doi:10.1016/j.jastp.2015.03.009</a>&gt; .  
    Murari, A., Peluso, E., Cianfrani, Gaudio, F., Lungaroni, M., (2019), &lt;<a href="https://doi.org/10.3390%2Fe21040394">doi:10.3390/e21040394</a>&gt;.    </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Demetris Christopoulos &lt;dchristop@econ.uoa.gr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, geometry, inflection, doParallel, lpSolve, methods,
plot3D, entropy</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Author:</td>
<td>Demetris Christopoulos [aut, cre],
  David Midgley [ctb],
  Sunil Venaik [ctb],
  INSEAD Fontainebleau France [fnd]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-23 15:07:49 UTC; demetris_ws</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-23 16:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='archetypal-package'>Finds the Archetypal Analysis of a Data Frame</h2><span id='topic+archetypal-package'></span>

<h3>Description</h3>

<p>Performs archetypal analysis by using Principal Convex Hull Analysis (PCHA) 
under a full control of all algorithmic parameters. 
It contains a set of functions for determining the initial solution, the optimal 
algorithmic parameters and the optimal number of archetypes.
Post run tools are also available for the assessment of the derived solution. 
</p>


<h3>Compute Archetypal Analysis (AA)</h3>

<p>The main function is <code><a href="#topic+archetypal">archetypal</a></code> which is a variant of PCHA algorithm, see [1], [2],
suitable for R language. It provides control to the entire set of involved parameters  and has two main options:   
</p>

<ol>
<li><p> initialrows = NULL, then a method from &quot;projected_convexhull&quot;, &quot;convexhull&quot;,<br />
&quot;partitioned_convexhul&quot;, &quot;furthestsum&quot;, &quot;outmost&quot;, &quot;random&quot; is used
</p>
</li>
<li><p> initialrows = (a vector of kappas rows), then given rows form the initial solution for AA
</p>
</li></ol>
 
<p>This is the main function of the package, but extensive trials has shown that:
</p>

<ul>
<li><p> AA may be very difficult to run if a random initial solution has been chosen
</p>
</li>
<li><p> for the same data set the final Sum of Squared Errors (SSE) may be much smaller
if initial solution is close to the final one
</p>
</li>
<li><p> even the quality of AA done is affected from the starting point
</p>
</li></ul>

<p>This is the reason why we have developed a whole set of methods for choosing initial solution for the PCHA algorithm.
</p>


<h3>Find a time efficient initial approximation for AA</h3>

 
<p>There are three functions that work with the Convex Hull (CH) of data set.
</p>

<ol>
<li>  <p><code><a href="#topic+find_outmost_convexhull_points">find_outmost_convexhull_points</a></code> computes the CH of all points    
</p>
</li>
<li> <p><code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code> computes the CH for
all possible combinations of variables taken by <code>npr</code> (default=2)
</p>
</li>
<li> <p><code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code> makes <code>np</code> partitions
of data frame (defualt=10), then computes CH for each partition and finally gives the CH of overall union  
</p>
</li></ol>

<p>The most simple method for estimating an initial solution is <code><a href="#topic+find_outmost_points">find_outmost_points</a></code>
where we just compute the outermost points, i.e. those that are the most frequent outermost for all
available points.
</p>
<p>The default method &quot;FurthestSum&quot; (FS) of PCHA (see [1], [2]) is used by <code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code> which applies
FS for <code>nfurthest</code> times (default=10) and then finds the most frequent points. 
</p>
<p>Of course &quot;random&quot; method is available for comparison reasons and that gives a random
set of kappas points as initial solution. 
</p>
<p>All methods give the number of rows for the input data frame as integers. Attention needed if your data frame
has row names which are integers but not identical to <code>1:dim(df)[1]</code>.
</p>


<h3>Find the optimal number of archetypes</h3>

<p>For that task <code><a href="#topic+find_optimal_kappas">find_optimal_kappas</a></code> is available which 
runs for each kappas from 1 to maxkappas (default=15) ntrials (default=10) times AA, 
stores SSE, VarianceExplained from each run and then computes knee or elbow point by using UIK method, see [3].
</p>


<h3>Determining the optimal updating parameters</h3>

<p>Extensive trials have shown us that choosing the proper values for algorithmic updating parameters 
(<code>muAup, muAdown, muBup, muBdown</code>) can speed up remarkably the process. That is the task of
<code><a href="#topic+find_pcha_optimal_parameters">find_pcha_optimal_parameters</a></code> which  conducts a grid search with different values 
of these parameters and returns the values which minimize the SSE after a fixed number of iterations (<code>testing_iters</code>, default=10).
</p>


<h3>Evaluate the quality of Archetypal Analysis</h3>

<p>By using function <code><a href="#topic+check_Bmatrix">check_Bmatrix</a></code> we can evaluate the overall quality of 
applied method and algorithm. Quality can be considered high:
</p>

<ol>
<li><p> if every archetype is being created by a small number of data points
</p>
</li>
<li><p> if relevant weights are not numerically insignificant
</p>
</li></ol>

<p>Of course we must take into account the SSE and VarianceExplained, but if we have to compare two solutions
with similar termination status, then we must choose that of the simplest B matrix form.
</p>


<h3>Resampling</h3>

<p>The package includes a function for resampling (<code><a href="#topic+grouped_resample">grouped_resample</a></code>) which may be used for standard bootstrapping or for subsampling. 
This function allows samples to be drawn with or without replacement, by groups and with or without Dirichlet weights. 
This provides a variety of options for researchers who wish to correct sample biases, estimate empirical confidence intervals, 
and/or subsample large data sets. 
</p>


<h3>Post-run tools</h3>

<p>Except from <code><a href="#topic+check_Bmatrix">check_Bmatrix</a></code> there exist next functions for checking the convergence process itself and
for examining the local neighborhoud of archetypes:
</p>

<ol>
<li><p> The function  <code><a href="#topic+study_AAconvergence">study_AAconvergence</a></code> analyzes the history of iterations done and produces
a multi-panel plot showing the steps and quality of the convergence to the final archetypes.
</p>
</li>
<li><p> By setting the desired number <code>npoints</code> as argument in function <code><a href="#topic+find_closer_points">find_closer_points</a></code> 
we can then find the data points that are in the local neighborhood of each archetype. 
This allows us to study the properties of the solution or manually choose an initial approximation to search for a better fit.
</p>
</li></ol>



<h3>Note</h3>

<p>Bug reports and feature requests can be sent to
<a href="mailto:dchristop@econ.uoa.gr">dchristop@econ.uoa.gr</a> or <br /> <a href="mailto:dem.christop@gmail.com">dem.christop@gmail.com</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Demetris Christopoulos <a href="mailto:dchristop@econ.uoa.gr">dchristop@econ.uoa.gr</a>
</p>
<p>Other contributors:
</p>

<ul>
<li><p> David Midgley <a href="mailto:david.midgley@insead.edu">david.midgley@insead.edu</a> [contributor]
</p>
</li>
<li><p> Sunil Venaik <a href="mailto:s.venaik@business.uq.edu.au">s.venaik@business.uq.edu.au</a> [contributor]
</p>
</li>
<li><p> INSEAD Fontainebleau France [funder]
</p>
</li></ul>



<h3>References</h3>


<p>[1] M Morup and LK Hansen, &quot;Archetypal analysis for machine learning and data mining&quot;, Neurocomputing (Elsevier, 2012).
https://doi.org/10.1016/j.neucom.2011.06.033.
</p>
<p>[2] Source: https://mortenmorup.dk/?page_id=2 , last accessed 2024-03-09
</p>
<p>[3] Christopoulos, Demetris T., Introducing Unit Invariant Knee (UIK) As an Objective Choice for
Elbow Point in Multivariate Data Analysis Techniques (March 1, 2016). 
Available at SSRN: https://ssrn.com/abstract=3043076 or http://dx.doi.org/10.2139/ssrn.3043076
</p>



<h3>See Also</h3>

<p><code><a href="#topic+archetypal">archetypal</a></code>
</p>

<hr>
<h2 id='AbsoluteTemperature'>
Global Absolute Temperature data set for Northern Hemisphere 1969-2013
</h2><span id='topic+AbsoluteTemperature'></span>

<h3>Description</h3>

<p>It is a subset from the data set which was used for publication [1], i.e. the Global Absolute Temperature for Northern Hemisphere (1800-2013) with only complete yearly observations included. Here we have kept the years 1969-2013.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("AbsoluteTemperature")</code></pre>


<h3>Format</h3>

<p>A data frame with 155862 observations on the following 18 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>an integer vector of observation years from 1969 to 2013</p>
</dd>
<dt><code>Jan</code></dt><dd><p>numeric vector of monthly average temperature for January</p>
</dd>
<dt><code>Feb</code></dt><dd><p>numeric vector of monthly average temperature for February</p>
</dd>
<dt><code>Mar</code></dt><dd><p>numeric vector of monthly average temperature for March</p>
</dd>
<dt><code>Apr</code></dt><dd><p>numeric vector of monthly average temperature for April</p>
</dd>
<dt><code>May</code></dt><dd><p>numeric vector of monthly average temperature for May</p>
</dd>
<dt><code>Jun</code></dt><dd><p>numeric vector of monthly average temperature for June</p>
</dd>
<dt><code>Jul</code></dt><dd><p>numeric vector of monthly average temperature for July</p>
</dd>
<dt><code>Aug</code></dt><dd><p>numeric vector of monthly average temperature for August</p>
</dd>
<dt><code>Sep</code></dt><dd><p>numeric vector of monthly average temperature for September</p>
</dd>
<dt><code>Oct</code></dt><dd><p>numeric vector of monthly average temperature for October</p>
</dd>
<dt><code>Nov</code></dt><dd><p>numeric vector of monthly average temperature for November</p>
</dd>
<dt><code>Dec</code></dt><dd><p>numeric vector of monthly average temperature for December</p>
</dd>
<dt><code>long</code></dt><dd><p>a numeric vector for the geographical longitude: positive values for eastings</p>
</dd>
<dt><code>lat</code></dt><dd><p>a numeric vector for the geographical latitude: positive values for northings</p>
</dd>
<dt><code>h</code></dt><dd><p>a numeric vector for the altitude in metrs</p>
</dd>
<dt><code>stid</code></dt><dd><p>an integer vector with the station identity number</p>
</dd>
<dt><code>z</code></dt><dd><p>an integer vector with the relevant climate zone:
</p>

<ul>
<li><p> 1, Tropical Zone
</p>
</li>
<li><p> 2, Subtropics
</p>
</li>
<li><p> 3, Temperate zone
</p>
</li>
<li><p> 4, Cold Zone
</p>
</li></ul>

</dd>
</dl>



<h3>Details</h3>

<p>That data set was the output of the procedure described in [1]. Initial data set was downloaded from [2]
at 2014-12-17.
</p>


<h3>References</h3>

<p>[1] Demetris T. Christopoulos. Extraction of the global absolute temperature for
Northern Hemisphere using a set of 6190 meteorological stations from 1800 to
2013. Journal of Atmospheric and Solar-Terrestrial Physics, 128:70 - 83, 3 2015.
doi:10.1016/j.jastp.2015.03.009
</p>
<p>[2] Met Office Hadley Centre observations datasets, station data sets,<br />
http:///www.metoffice.gov.uk/hadobs/crutem4/data/station_files/CRUTEM.4.2.0.0.station_files.zip <br />
(last visited 17.12.14)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
######################################
## Load absolute temperature data set:
######################################
#
data("AbsoluteTemperature")
df=AbsoluteTemperature
## Find proportions for climate zones
pcs=table(df$z)/dim(df)[1]
## Choose an approximate size of the new sample and compute resample sizes
N=1000
resamplesizes=as.integer(round(N*pcs))
sum(resamplesizes)
## Create the grouping matrix
groupmat=data.frame("Group_ID"=1:4,"Resample_Size"=resamplesizes)
groupmat
## Simple resampling:
resample_simple &lt;- grouped_resample(in_data = df,grp_vector = "z",
grp_matrix = groupmat,replace = FALSE, option = "Simple", rseed = 20191119)
cat(dim(resample_simple),"\n")
## Dirichlet resampling:
resample_dirichlet &lt;- grouped_resample(in_data = df,grp_vector = "z", 
grp_matrix = groupmat, replace = FALSE, option = "Dirichlet", rseed = 20191119)
cat(dim(resample_dirichlet),"\n")
#
#########################################
## Reproduce the results of 2015 article
#########################################
##
data("AbsoluteTemperature")
dh=AbsoluteTemperature
## Create yearly averages for every station
dh$avg = rowMeans(df[,month.abb[1:12]])
head(dh)
## Compute mean average of every year for all Northern Hemisphere
dagg=data.frame(aggregate(avg~Year,dh,function(x){c(mean(x),sd(x))}))
## Find used stations per year
daggn=aggregate(stid ~ Year,dh,length)
head(daggn)
tail(daggn)
## Combine all in a data frame
dagyears=data.frame(dagg$Year,daggn$stid,dagg$avg[,1],dagg$avg[,2])
colnames(dagyears)=c("Year","Nv","mu","Smu")
head(dagyears)
tail(dagyears)
#
## Compare with Table 7 (Columns: Year, Nv, mu_bar, Smu_bar), page 77 of article
## Extraction of the global absolute temperature for Northern Hemisphere 
## using a set of 6190 meteorological stations from 1800 to 2013
## https://doi.org/10.1016/j.jastp.2015.03.009
## and specifically the years 1969--2013
</code></pre>

<hr>
<h2 id='align_archetypes_from_list'>Align archetypes from a list either by the most frequent found or by using a given archetype</h2><span id='topic+align_archetypes_from_list'></span>

<h3>Description</h3>

<p>Align archetypes from a list either by the most frequent or by using a given archetype.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>align_archetypes_from_list(archs_list, given_arch = NULL,
  varnames = NULL, ndigits = 0, parallel = FALSE, 
  nworkers = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="align_archetypes_from_list_+3A_archs_list">archs_list</code></td>
<td>
<p>The list of archetypes that must be aligned</p>
</td></tr>
<tr><td><code id="align_archetypes_from_list_+3A_given_arch">given_arch</code></td>
<td>
<p>If it is not NULL, then <code>given_arch</code> will by used
as guide for aligning other archetypes of list. Otherwise, a heuristic
for finding the most frequent archetype will be used.</p>
</td></tr>
<tr><td><code id="align_archetypes_from_list_+3A_varnames">varnames</code></td>
<td>
<p>The character vector of variable names that must be used.
If it is NULL, then the column names of first archetype will be used.</p>
</td></tr>
<tr><td><code id="align_archetypes_from_list_+3A_ndigits">ndigits</code></td>
<td>
<p>The number of digits that will be used for truncation.</p>
</td></tr>
<tr><td><code id="align_archetypes_from_list_+3A_parallel">parallel</code></td>
<td>
<p>If it set to TRUE, then parallel processing will be applied.</p>
</td></tr>
<tr><td><code id="align_archetypes_from_list_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used for
parallel computing (usually it is the double of available physical cores).
</p>
</td></tr>
<tr><td><code id="align_archetypes_from_list_+3A_verbose">verbose</code></td>
<td>
<p>If it is set to TRUE, then  details are printed out</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> arch_guide, the archetype used as guide for aligning others
</p>
</li>
<li><p> phrases_most, a table with all rounded phrases from archetypes.
Frequencies are in decreasing order, so first row indicates the
most frequent sequence, if exists. Otherwise we take randomly
a case and proceed.
</p>
</li>
<li><p> archs_aa_output, a data frame with rows all given archetypes
</p>
</li>
<li><p> archs_aligned, the final list of aligned archetypes    
</p>
</li></ol>



<h3>References</h3>

<p>This function is a modification of &quot;align_arc&quot; function from package &quot;ParetoTI&quot;,
see <a href="https://github.com/vitkl/ParetoTI">https://github.com/vitkl/ParetoTI</a> and <a href="https://github.com/vitkl/ParetoTI/blob/master/R/align_arc.R">https://github.com/vitkl/ParetoTI/blob/master/R/align_arc.R</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wd2") #2D demo 
df = wd2
# Define 4 archetypes found for it
dalist = list(c(2.172991,3.200754,5.384013,2.579770,4.860343,3.085111),
              c(5.430821,3.128493,2.043495,3.146342,4.781851,2.710885),
              c(5.430752,2.043403,3.128520,3.146252,2.710979,4.781880),
              c(2.043854,5.430890,3.127183,2.710522,3.146432,4.780432))
archslist = lapply(dalist, function(x){matrix(x,ncol=2)}) #not aligned
# Run aligner
yy = align_archetypes_from_list(archs_list = archslist,
                                given_arch = archslist[[1]])
yy$arch_guide
aligned_archs = yy$archs_aligned
aligned_archs #observe that they are comparable now
</code></pre>

<hr>
<h2 id='archetypal'>archetypal: Finds the archetypal analysis of a data frame by using a variant of the PCHA algorithm</h2><span id='topic+archetypal'></span>

<h3>Description</h3>

<p>Performs archetypal analysis by using Principal Convex Hull Analysis (PCHA) 
under a full control of all algorithmic parameters. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>archetypal(df, kappas, initialrows = NULL,
  method = "projected_convexhull", nprojected = 2, npartition = 10,
  nfurthest = 10, maxiter = 2000, conv_crit = 1e-06,
  var_crit = 0.9999, verbose = TRUE, rseed = NULL, aupdate1 = 25,
  aupdate2 = 10, bupdate = 10, muAup = 1.2, muAdown = 0.5,
  muBup = 1.2, muBdown = 0.5, SSE_A_conv = 1e-09,
  SSE_B_conv = 1e-09, save_history = FALSE, nworkers = NULL,
  stop_varexpl = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="archetypal_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="archetypal_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="archetypal_+3A_initialrows">initialrows</code></td>
<td>
<p>The initial set of rows from data frame that will be used for starting algorithm</p>
</td></tr>
<tr><td><code id="archetypal_+3A_method">method</code></td>
<td>
<p>The method that will be used for computing initial approximation:
</p>

<ol>
<li><p> projected_convexhull, see  <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code> 
</p>
</li>
<li><p> convexhull, see <code><a href="#topic+find_outmost_convexhull_points">find_outmost_convexhull_points</a></code> 
</p>
</li>
<li><p> partitioned_convexhull, see <code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code> 
</p>
</li>
<li><p> furthestsum, see <code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code> 
</p>
</li>
<li><p> outmost, see <code><a href="#topic+find_outmost_points">find_outmost_points</a></code> 
</p>
</li>
<li><p> random, a random set of kappas points will be used
</p>
</li></ol>
</td></tr>
<tr><td><code id="archetypal_+3A_nprojected">nprojected</code></td>
<td>
<p>The dimension of the projected subspace for <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code></p>
</td></tr>
<tr><td><code id="archetypal_+3A_npartition">npartition</code></td>
<td>
<p>The number of partitions for <code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code></p>
</td></tr>
<tr><td><code id="archetypal_+3A_nfurthest">nfurthest</code></td>
<td>
<p>The number of times that <code><a href="#topic+FurthestSum">FurthestSum</a></code> algorithm will be applied
by <code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code> </p>
</td></tr>
<tr><td><code id="archetypal_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations for main algorithm application</p>
</td></tr>
<tr><td><code id="archetypal_+3A_conv_crit">conv_crit</code></td>
<td>
<p>The SSE convergence criterion of termination: iterate until |dSSE|/SSE&lt;conv_crit</p>
</td></tr>
<tr><td><code id="archetypal_+3A_var_crit">var_crit</code></td>
<td>
<p>The Variance Explained (VarExpl) convergence criterion of termination: iterate until VarExpl&lt;var_crit</p>
</td></tr>
<tr><td><code id="archetypal_+3A_verbose">verbose</code></td>
<td>
<p>If it is set to TRUE, then both initialization and iteration details are printed out</p>
</td></tr>
<tr><td><code id="archetypal_+3A_rseed">rseed</code></td>
<td>
<p>The random seed that will be used for setting initial A matrix. Useful for reproducible results.</p>
</td></tr>
<tr><td><code id="archetypal_+3A_aupdate1">aupdate1</code></td>
<td>
<p>The number of initial applications of Aupdate for improving the initially randomly selected A matrix</p>
</td></tr>
<tr><td><code id="archetypal_+3A_aupdate2">aupdate2</code></td>
<td>
<p>The number of Aupdate applications in main iteration</p>
</td></tr>
<tr><td><code id="archetypal_+3A_bupdate">bupdate</code></td>
<td>
<p>The number of Bupdate applications in main iteration</p>
</td></tr>
<tr><td><code id="archetypal_+3A_muaup">muAup</code></td>
<td>
<p>The factor (&gt;1) by which muA is multiplied when it holds SSE&lt;=SSE_old(1+SSE_A_conv)</p>
</td></tr>
<tr><td><code id="archetypal_+3A_muadown">muAdown</code></td>
<td>
<p>The factor (&lt;1) by which muA is multiplied when it holds SSE&gt;SSE_old(1+SSE_A_conv)</p>
</td></tr>
<tr><td><code id="archetypal_+3A_mubup">muBup</code></td>
<td>
<p>The factor (&gt;1) by which muB is multiplied when it holds SSE&lt;=SSE_old(1+SSE_B_conv)</p>
</td></tr>
<tr><td><code id="archetypal_+3A_mubdown">muBdown</code></td>
<td>
<p>The factor (&lt;1) by which muB is multiplied when it holds SSE&gt;SSE_old(1+SSE_B_conv)</p>
</td></tr>
<tr><td><code id="archetypal_+3A_sse_a_conv">SSE_A_conv</code></td>
<td>
<p>The convergence value used in SSE&lt;=SSE_old(1+SSE_A_conv). 
Warning: there exists a Matlab crash sometimes after setting this to 1E-16 or lower</p>
</td></tr>
<tr><td><code id="archetypal_+3A_sse_b_conv">SSE_B_conv</code></td>
<td>
<p>The convergence value used in SSE&lt;=SSE_old(1+SSE_A_conv).
Warning: there exists a Matlab crash sometimes after setting this to 1E-16 or lower</p>
</td></tr>
<tr><td><code id="archetypal_+3A_save_history">save_history</code></td>
<td>
<p>If set TRUE, then iteration history is being saved for further use</p>
</td></tr>
<tr><td><code id="archetypal_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used for
parallel computing (usually it is the double of available physical cores).
Parallel computation is applied when asked by functions <code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code>,<br /> 
<code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code> and <br /> <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code>.
</p>
</td></tr>
<tr><td><code id="archetypal_+3A_stop_varexpl">stop_varexpl</code></td>
<td>
<p>If set TRUE, then algorithm stops if varexpl is greater than var_crit</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li> <p><code>BY</code>, the <code class="reqn">kappas \times d</code> matrix of archetypes found
</p>
</li>
<li> <p><code>A</code>, the <code class="reqn">n \times kappas</code> matrix such that Y ~ ABY or Frobenius norm ||Y-ABY|| is minimum
</p>
</li>
<li> <p><code>B</code>, the <code class="reqn">kappas \times n</code> matrix such that Y ~ ABY or Frobenius norm ||Y-ABY|| is minimum
</p>
</li>
<li> <p><code>SSE</code>, the sum of squared error SSE = ||Y-ABY||^2
</p>
</li>
<li> <p><code>varexpl</code>, the Variance Explained = (SST-SSE)/SST where SST is the total sum of squares for data set matrix
</p>
</li>
<li> <p><code>initialsolution</code>, the initially used set of rows from data frame in order to start the algorithm
</p>
</li>
<li> <p><code>freqstable</code>, the frequency table for all found rows, if it is available.
</p>
</li>
<li> <p><code>iterations</code>, the number of main iterations done by algorithm
</p>
</li>
<li> <p><code>time</code>, the time in seconds that was spent from entire run 
</p>
</li>
<li> <p><code>converges</code>, if it is TRUE, then convergence was achieved before the end of maximum allowed iterations
</p>
</li>
<li> <p><code>nAup</code>, the total number of times when it was SSE&lt;=SSE_old(1+SSE_A_conv) in Aupdate processes. Useful for debugging purposes.
</p>
</li>
<li> <p><code>nAdown</code>, the total number of times when it was SSE&gt;SSE_old(1+SSE_A_conv) in Aupdate processes. Useful for debugging purposes.
</p>
</li>
<li> <p><code>nBup</code>, the total number of times when it was SSE&lt;=SSE_old(1+SSE_B_conv) in Bupdate processes. Useful for debugging purposes.
</p>
</li>
<li> <p><code>nBdown</code>, the total number of times when it was SSE&gt;SSE_old(1+SSE_A_conv in Bupdate processes. Useful for debugging purposes.
</p>
</li>
<li> <p><code>run_results</code>, a list of iteration related details: SSE, varexpl, time, B, BY for all iterations done.
</p>
</li>
<li> <p><code>Y</code>, the <code class="reqn">n \times d</code> matrix of initial data used
</p>
</li>
<li> <p><code>data.tables</code>, the initial data frame if column dimension is at most 3 or a list of frequencies for each variable 
</p>
</li>
<li> <p><code>call</code>, the exact calling used
</p>
</li></ol>



<h3>References</h3>

<p>[1] M Morup and LK Hansen, &quot;Archetypal analysis for machine learning and data mining&quot;, Neurocomputing (Elsevier, 2012). https://doi.org/10.1016/j.neucom.2011.06.033.
</p>
<p>[2] Source: https://mortenmorup.dk/?page_id=2 , last accessed 2024-03-09
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
	# Create a small 2D data set from 3 corner-points:
	p1 = c(1,2);p2 = c(3,5);p3 = c(7,3)
	dp = rbind(p1,p2,p3);dp
	set.seed(916070)
	pts = t(sapply(1:20, function(i,dp){
	  cc = runif(3)
	  cc = cc/sum(cc)
	  colSums(dp*cc)
	},dp))
	df = data.frame(pts)
	colnames(df) = c("x","y")
	# Run AA:
	aa = archetypal(df = df, kappas  =  3, verbose = FALSE, save_history  =  TRUE)
	# Print class "archetypal":
	print(aa)
	# Summary class "archetypal":
	summary(aa)
	# Plot class "archetypal":
	plot(aa)
	# See history of iterations:
	names(aa$run_results)	

}
</code></pre>

<hr>
<h2 id='check_Bmatrix'>Function which checks B matrix of Archetypal Analysis  Y ~ A B Y
in order to find the used rows for creating each archetype
and the relevant used weights.</h2><span id='topic+check_Bmatrix'></span>

<h3>Description</h3>

<p>Function which checks B matrix of Archetypal Analysis  Y ~ A B Y
in order to find the used rows for creating each archetype
and the relevant used weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_Bmatrix(B, chvertices = NULL, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_Bmatrix_+3A_b">B</code></td>
<td>
<p>The <code class="reqn">kappas \times n</code> matrix such that Y ~ ABY or Frobenius norm ||Y-ABY|| is minimum</p>
</td></tr>
<tr><td><code id="check_Bmatrix_+3A_chvertices">chvertices</code></td>
<td>
<p>The vector of rows which represent the Convex Hull of data frame</p>
</td></tr>
<tr><td><code id="check_Bmatrix_+3A_verbose">verbose</code></td>
<td>
<p>If set to TRUE, then results are printed out.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> used_rows, a list with used rows for creating each archetype
</p>
</li>
<li><p> used_weights, a list with the relevant weights that have been used
</p>
</li>
<li><p> leading_rows, the rows for each archetype with greatest weight
</p>
</li>
<li><p> leading_weights, the weights of leading rows
</p>
</li>
<li><p> used_on_convexhull, the portion of used rows which lie on Convex Hull (if given)
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+archetypal">archetypal</a></code>, <code><a href="#topic+check_Bmatrix">check_Bmatrix</a></code>, <code><a href="#topic+find_closer_points">find_closer_points</a></code>  <br />
&amp; <code><a href="#topic+study_AAconvergence">study_AAconvergence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
	# Load data "wd2"
	data("wd2")
	df = wd2
	# Run AA:
	aa = archetypal(df = df, kappas = 3, verbose = FALSE)
	# Check B matrix:
	B = aa$B
	yy = check_Bmatrix(B, verbose = TRUE)
	yy$used_rows
	yy$used_weights
	yy$leading_rows
	yy$leading_weights
	# Check if used rows lie on ConvexHull
	ch = chull(df)
	yy = check_Bmatrix(B, chvertices = ch, verbose = FALSE)
	yy$used_on_convexhull
	#

}
</code></pre>

<hr>
<h2 id='dirichlet_sample'>
Function which performs Dirichlet sampling
</h2><span id='topic+dirichlet_sample'></span>

<h3>Description</h3>

<p>It uses Dirichlet weights for creating sub-samples of initial data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dirichlet_sample(in_data = NULL, sample_size = NULL,
replacement = NULL, rseed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dirichlet_sample_+3A_in_data">in_data</code></td>
<td>

<p>The initial data frame that must be re-sampled. It must contain:
</p>

<ol>
<li><p> an ID variable
</p>
</li>
<li><p> the variables of interest
</p>
</li>
<li><p> a grouping variable
</p>
</li></ol>

</td></tr>
<tr><td><code id="dirichlet_sample_+3A_sample_size">sample_size</code></td>
<td>

<p>An integer for the size of the new sample
</p>
</td></tr>
<tr><td><code id="dirichlet_sample_+3A_replacement">replacement</code></td>
<td>

<p>A logical input: TRUE/FALSE if replacement should be used or not, respectively
</p>
</td></tr>
<tr><td><code id="dirichlet_sample_+3A_rseed">rseed</code></td>
<td>

<p>The random seed that will be used for setting initial A matrix. Useful for reproducible results
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>It returns a data frame with exactly the same variables as the initial one, 
except that group variable has now only the given value from input data frame.
</p>


<h3>Author(s)</h3>

<p>David Midgley
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grouped_resample">grouped_resample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load absolute temperature data set:
data("AbsoluteTemperature")
df=AbsoluteTemperature
## Find portions for climate zones
pcs=table(df$z)/dim(df)[1]
## Choose the approximate size of the new sample and compute resample sizes
N=1000
resamplesizes=as.integer(round(N*pcs))
sum(resamplesizes)
## Create the grouping matrix
groupmat=data.frame("Group_ID"=1:4,"Resample_Size"=resamplesizes)
groupmat
## Dirichlet resampling:
resample_dirichlet &lt;- grouped_resample(in_data = df,grp_vector = "z",
                      grp_matrix = groupmat,replace = FALSE,
                      option = "Dirichlet", rseed = 20191220)
cat(dim(resample_dirichlet),"\n")
</code></pre>

<hr>
<h2 id='find_closer_points'>Function which finds the data points that are closer to the archetypes during all
iterations of the algorithm PCHA</h2><span id='topic+find_closer_points'></span>

<h3>Description</h3>

<p>This function runs the PCHA algorithm and finds the data points that are in the local neighborhood of each archetype. The size of the neighborhood is user defined (<code>npoints</code>). This allows us to study the properties of the solution or manually choose an initial approximation to search for a better fit. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_closer_points(df, kappas, usedata = FALSE, npoints = 2, 
                     nworkers = NULL, rseed = NULL, 
                     verbose = FALSE, doparallel = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_closer_points_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_usedata">usedata</code></td>
<td>
<p>If it is TRUE, then entire data frame will be used, if <code>doparallel = TRUE</code></p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_npoints">npoints</code></td>
<td>
<p>The number of closer points to be estimated</p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used, if <code>doparallel = TRUE</code></p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_rseed">rseed</code></td>
<td>
<p>The random seed that will be used for random generator. Useful for reproducible results.</p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_verbose">verbose</code></td>
<td>
<p>If it is set to TRUE, then details will be printed, except from <code>archetypal</code></p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_doparallel">doparallel</code></td>
<td>
<p>If it is set to TRUE, then parallel processing will be performed</p>
</td></tr>
<tr><td><code id="find_closer_points_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>archetypal</code> except internally used <code>save_history = TRUE</code>
and <code>verbose = FALSE</code>. This is essential for using optimal parameters found by <code>find_pcha_optimal_parameters</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> rows_history, a list with <code>npoints</code> rows used that are closer to each archetype
for each iteration done by algorithm
</p>
</li>
<li><p> iter_terminal, iteration after which rows closer to archetypes do not change any more
</p>
</li>
<li><p> rows_closer, the rows closer to archetypes by means of Euclidean distance and are fixed
after <code>iter_terminal</code> iteration
</p>
</li>
<li><p> rows_closer_matrix, a matrix with <code>npoints</code> rows  which are closer to each archetype
</p>
</li>
<li><p> solution_used, the AA output that has been used. Some times useful, especially for big data.
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+check_Bmatrix">check_Bmatrix</a></code>, <code><a href="#topic+study_AAconvergence">study_AAconvergence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
# Load data "wd2"
data("wd2")
yy = find_closer_points(df = wd2, kappas = 3, npoints = 2, nworkers = 2)
yy$rows_history
yy$iter_terminal
yy$rows_closer
yy$rows_closer_matrix
yy$solution_used$BY

}
</code></pre>

<hr>
<h2 id='find_furthestsum_points'>Function which finds the furthest sum points
in order to be used as initial solution in archetypal analysis</h2><span id='topic+find_furthestsum_points'></span>

<h3>Description</h3>

<p>Function which finds the furthest sum points
in order to be used as initial solution in archetypal analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_furthestsum_points(df, kappas, nfurthest = 100, nworkers = NULL,
                        sortrows = TRUE, doparallel = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_furthestsum_points_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="find_furthestsum_points_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="find_furthestsum_points_+3A_nfurthest">nfurthest</code></td>
<td>
<p>The number of applications for FurthestSum algorithm</p>
</td></tr>
<tr><td><code id="find_furthestsum_points_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used.
Hint: set it such that <code>nfurthest</code> can be an exact multiple of <code>nworkers</code>.</p>
</td></tr>
<tr><td><code id="find_furthestsum_points_+3A_sortrows">sortrows</code></td>
<td>
<p>If it is TRUE, then rows will be sorted</p>
</td></tr>
<tr><td><code id="find_furthestsum_points_+3A_doparallel">doparallel</code></td>
<td>
<p>If it is set to TRUE, then parallel processing will be performed
for the <code>nfurthest</code> applications of algorithm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> outmost, the first kappas furthest sum points as rows of data frame
</p>
</li>
<li><p> outmostall, all the furthest sum points that have been found as rows of data frame
</p>
</li>
<li><p> outmostfrequency, a matrix with frequency and cumulative frequency for furthest sum rows
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+FurthestSum">FurthestSum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wd3") #3D demo 
df = wd3
yy = find_furthestsum_points(df, kappas = 4, nfurthest = 10, nworkers = 2)
yy$outmost
yy$outmostall
yy$outmostfrequency
</code></pre>

<hr>
<h2 id='find_optimal_kappas'>Function for finding the optimal number of archetypes</h2><span id='topic+find_optimal_kappas'></span>

<h3>Description</h3>

<p>Function for finding the optimal number of archetypes in order to apply Archetypal Analysis for a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_optimal_kappas(df, maxkappas = 15, method = "projected_convexhull", 
                    ntrials = 10, nworkers = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_optimal_kappas_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions <code class="reqn">n \times d</code></p>
</td></tr>
<tr><td><code id="find_optimal_kappas_+3A_maxkappas">maxkappas</code></td>
<td>
<p>The maximum number of archetypes for which algorithm will be applied</p>
</td></tr>
<tr><td><code id="find_optimal_kappas_+3A_method">method</code></td>
<td>
<p>The method that will be used for computing the initial solution</p>
</td></tr>
<tr><td><code id="find_optimal_kappas_+3A_ntrials">ntrials</code></td>
<td>
<p>The number of times that algorithm will be applied for each kappas</p>
</td></tr>
<tr><td><code id="find_optimal_kappas_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used for parallel computing 
(usually it is the double of available physical cores)</p>
</td></tr>
<tr><td><code id="find_optimal_kappas_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to function <code><a href="#topic+archetypal">archetypal</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>After having found the SSE for each kappas, UIK method (see [1]) is used
for estimating the knee or elbow point as the optimal kappas. 
</p>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> all_sse, all available SSE for all kappas and all trials per kappas
</p>
</li>
<li><p> all_sse1, all available SSE(k)/SSE(1) for all kappas and all trials per kappas
</p>
</li>
<li><p> bestfit_sse, only the best fit SSE trial for each kappas
</p>
</li>
<li><p> bestfit_sse1, only the best fit SSE(k)/SSE(1) trial for each kappas
</p>
</li>
<li><p> all_kappas, the knee point of scree plot for all 4 SSE results
</p>
</li>
<li><p> d2uik, the UIK for the absolute values of the estimated best fit SSE second derivatives,
after using second order forward divided differences approximation
</p>
</li>
<li><p> optimal_kappas, the knee point from best fit SSE results
</p>
</li></ol>



<h3>References</h3>

<p>[1] Christopoulos, Demetris T., Introducing Unit Invariant Knee (UIK) As an Objective Choice for
Elbow Point in Multivariate Data Analysis Techniques (March 1, 2016). 
Available at SSRN: http://dx.doi.org/10.2139/ssrn.3043076
</p>


<h3>See Also</h3>

<p><code><a href="#topic+archetypal">archetypal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
# Run may take a while depending on your machine ...
# Load data frame "wd2"
data("wd2")
df = wd2
# Run:
t1 = Sys.time()
yy = find_optimal_kappas(df, maxkappas = 10)
t2 = Sys.time();print(t2-t1)
# Results:
names(yy)
# Best fit SSE:
yy$bestfit_sse 
# Optimal kappas from UIK method:
yy$optimal_kappas
#

}
</code></pre>

<hr>
<h2 id='find_outmost_convexhull_points'>Function which finds the outermost convex hull points
in order to be used as initial solution in archetypal analysis</h2><span id='topic+find_outmost_convexhull_points'></span>

<h3>Description</h3>

<p>Function which finds the outermost convex hull points
in order to be used as initial solution in archetypal analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_outmost_convexhull_points(df, kappas)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_outmost_convexhull_points_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="find_outmost_convexhull_points_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code><a href="grDevices.html#topic+chull">chull</a></code> when d=2 (see [1], [2]) and the <code><a href="geometry.html#topic+convhulln">convhulln</a></code>
for d&gt;2 (see [3])  cases.
</p>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> outmost, the first kappas most frequent outermost points as rows of data frame
</p>
</li>
<li><p> outmostall, all the outermost points that have been found as rows of data frame
</p>
</li>
<li><p> outmostfrequency, a matrix with frequency and cumulative frequency for outermost rows
</p>
</li></ol>



<h3>References</h3>

<p>[1] Eddy, W. F. (1977). A new convex hull algorithm for planar sets.
ACM Transactions on Mathematical Software, 3, 398-403. doi: 10.1145/355759.355766.
</p>
<p>[2] Eddy, W. F. (1977). Algorithm 523: CONVEX, A new convex hull algorithm for planar sets [Z].
ACM Transactions on Mathematical Software, 3, 411-412. doi: 10.1145/355759.355768.
</p>
<p>[3] Barber, C.B., Dobkin, D.P., and Huhdanpaa, H.T., &quot;The Quickhull algorithm for convex hulls&quot;
ACM Trans. on Mathematical Software, 22(4):469-483, Dec 1996, http://www.qhull.org
</p>


<h3>See Also</h3>

<p><code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code>, <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code>,  
</p>
<p><code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code> &amp;  <code><a href="#topic+find_outmost_points">find_outmost_points</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wd2") #2D demo 
df = wd2
yy = find_outmost_convexhull_points(df, kappas = 3)
yy$outmost #the rows of 3 outermost points
df[yy$outmost,] #the 3 outermost points
yy$outmostall #all outermost cH rows
yy$outmostfrequency #their frequency
#
###
#
data("wd3") #3D demo 
df = wd3
yy = find_outmost_convexhull_points(df, kappas = 4)
yy$outmost #the rows of 4 outermost points
df[yy$outmost,] #the 4 outermost points
yy$outmostall #all outermost cH rows
yy$outmostfrequency #their frequency
</code></pre>

<hr>
<h2 id='find_outmost_partitioned_convexhull_points'>Function which finds the outermost convex hull points after making
np samples and finding convex hull for each of them.
</h2><span id='topic+find_outmost_partitioned_convexhull_points'></span>

<h3>Description</h3>

<p>Function which finds the outermost convex hull points after making
<code>np</code> samples and finding convex hull for each of them.
To be used as initial solution in archetypal analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_outmost_partitioned_convexhull_points(df, kappas, np = 10,
  nworkers = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_outmost_partitioned_convexhull_points_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="find_outmost_partitioned_convexhull_points_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="find_outmost_partitioned_convexhull_points_+3A_np">np</code></td>
<td>
<p>The number of partitions that will be used (or the number of samples)</p>
</td></tr>
<tr><td><code id="find_outmost_partitioned_convexhull_points_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> outmost, the first kappas most frequent outermost points as rows of data frame
</p>
</li>
<li><p> outmostall, all the outermost points that have been found as rows of data frame
</p>
</li>
<li><p> outmostfrequency, a matrix with frequency and cumulative frequency for outermost rows
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code>, <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code>, 
</p>
<p><code><a href="#topic+find_outmost_convexhull_points">find_outmost_convexhull_points</a></code> &amp; <code><a href="#topic+find_outmost_points">find_outmost_points</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wd2") #2D demo 
df = wd2
yy = find_outmost_partitioned_convexhull_points(df, kappas = 3, nworkers = 2)
yy$outmost #the rows of 3 outermost points
df[yy$outmost,] #the 3 outermost points
yy$outmostall #all outermost rows
yy$outmostfrequency #their frequency
</code></pre>

<hr>
<h2 id='find_outmost_points'>Function which finds the outermost points
in order to be used as initial solution in archetypal analysis</h2><span id='topic+find_outmost_points'></span>

<h3>Description</h3>

<p>Function which finds the outermost points
in order to be used as initial solution in archetypal analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_outmost_points(df, kappas)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_outmost_points_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="find_outmost_points_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> outmost, the first kappas most frequent outermost points as rows of data frame
</p>
</li>
<li><p> outmostall, all the outermost points that have been found as rows of data frame
</p>
</li>
<li><p> outmostfrequency, a matrix with frequency and cumulative frequency for outermost rows
</p>
</li></ol>



<h3>Warning</h3>

<p>This is a rather naive way to find the outermost points of a data frame and 
it should be used with caution since for a n x d matrix we need in general
8 n^2/(2^30) GB RAM for numeric case. Check your machine and use it.
As a rule of thumb we advice its usage for n less or equal than 20000.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code>,  <code><a href="#topic+find_outmost_convexhull_points">find_outmost_convexhull_points</a></code>, 
</p>
<p><code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code>, <br />
</p>
<p>and <code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wd2") #2D demo 
df = wd2
yy = find_outmost_points(df,kappas=3)
yy$outmost #the rows of 3 outmost points
yy$outmostall #all outmost found
yy$outmostfrequency #frequency table for all
df[yy$outmost,] #the 3 outmost points
#
###
#
data("wd3") #3D demo 
df = wd3
yy = find_outmost_points(df,kappas=4)
yy$outmost #the rows of 4 outmost points
yy$outmostall #all outmost found
yy$outmostfrequency #frequency table for all
df[yy$outmost,] #the 4 outmost points
</code></pre>

<hr>
<h2 id='find_outmost_projected_convexhull_points'>Function which finds the outermost projected convex hull points
in order to be used as initial solution in archetypal analysis</h2><span id='topic+find_outmost_projected_convexhull_points'></span>

<h3>Description</h3>

<p>Function which finds the outermost projected convex hull points
in order to be used as initial solution in archetypal analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_outmost_projected_convexhull_points(df, kappas, npr = 2, rseed = NULL,
                                         doparallel = FALSE, nworkers = NULL,
                                         uniquerows = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_outmost_projected_convexhull_points_+3A_df">df</code></td>
<td>
<p>The n x d data frame that will be used for Archetypal Analysis</p>
</td></tr>
<tr><td><code id="find_outmost_projected_convexhull_points_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="find_outmost_projected_convexhull_points_+3A_npr">npr</code></td>
<td>
<p>The dimension of the projected subspaces. It can be npr = 1 (then there are d such subspaces), 
or npr &gt; 1 (then we have C(d,npr) different subspaces)</p>
</td></tr>
<tr><td><code id="find_outmost_projected_convexhull_points_+3A_rseed">rseed</code></td>
<td>
<p>An integer to be used for the random seed if it will be necessary</p>
</td></tr>
<tr><td><code id="find_outmost_projected_convexhull_points_+3A_doparallel">doparallel</code></td>
<td>
<p>If it is set to TRUE, then parallel processing will be performed.
That is absolutely required if n is very large and d&gt;6.</p>
</td></tr>
<tr><td><code id="find_outmost_projected_convexhull_points_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used for computing the 
projected convex hulls, which they are always C(d,npr).</p>
</td></tr>
<tr><td><code id="find_outmost_projected_convexhull_points_+3A_uniquerows">uniquerows</code></td>
<td>
<p>If it is set to TRUE, then unique rows will be used for
computing distance matrix and less resources will be needed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>npr = 1</code>, then Convex Hull is identical with the range (<code>min</code>,<code>max</code>) for the relevant variable, otherwise
the function uses the <code><a href="grDevices.html#topic+chull">chull</a></code> when <code>npr = 2</code> and the <code><a href="geometry.html#topic+convhulln">convhulln</a></code>
for <code>npr</code> &gt; 2. See [1] and [2] respectively for more details.
</p>
<p>First all available projections are being considered and their Convex Hull are being computed. Then either the unique (if <code>uniquerows = TRUE</code>) or all (if <code>uniquerows = FALSE</code>) associated data rows form a matrix and finally by using <code><a href="stats.html#topic+dist">dist</a></code> we find the kappas most frequent outermost rows. <br />
A special care is needed if the rows we have found are less than kappas. In that case, if a random sampling is necessary, 
the output <code>usedrandoms</code> informs us for the number of random rows and the <code>rseed</code> can be used for reproducibility.
</p>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> outmost, the first kappas most frequent outermost points as rows of data frame
</p>
</li>
<li><p> outmostall, all the outermost points that have been found as rows of data frame
</p>
</li>
<li><p> outmostfrequency, a matrix with frequency and cumulative frequency for outermost rows
</p>
</li>
<li><p> usedrandom, an integer of randomly chosen rows, if it was necessary to complete the number of kappas rows
</p>
</li>
<li><p> chprojections, all the Convex Hulls of the different C(d,npr) projections, i.e. the coordinate projection subspaces 
</p>
</li>
<li><p> projected, a data frame with rows the unique points that have been projected in order to create 
the relevant Convex Hulls of coordinate projection subspaces
</p>
</li></ol>



<h3>References</h3>

<p>[1] Eddy, W. F. (1977). Algorithm 523: CONVEX, A new convex hull algorithm for planar sets.
ACM Transactions on Mathematical Software, 3, 411-412. doi: 10.1145/355759.355768.
</p>
<p>[2] Barber, C.B., Dobkin, D.P., and Huhdanpraa, H.T., &quot;The Quickhull algorithm for convex hulls&quot;
ACM Trans. on Mathematical Software, 22(4):469-483, Dec 1996, http://www.qhull.org
</p>


<h3>See Also</h3>

<p><code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code>, <code><a href="#topic+find_outmost_convexhull_points">find_outmost_convexhull_points</a></code> 
</p>
<p><code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code> &amp; <code><a href="#topic+find_outmost_points">find_outmost_points</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
data("wd2") #2D demo 
df = wd2
yy = find_outmost_projected_convexhull_points(df, kappas = 3)
yy$outmost #the rows of 3 outmost projected convexhull points
yy$outmostall #all outmost found
yy$outmostfrequency #frequency table for all
yy$usedrandom #No random row was used
yy$chprojections #The Convex Hull of projection (one only here) 
yy$projected #the 9 unique points that created the one only CH
df[yy$outmost,] #the 3 outmost projected convexhull points
#
###
#
data("wd3") #3D demo 
df = wd3
yy = find_outmost_projected_convexhull_points(df, kappas = 4)
yy$outmost #the rows of 4 outmost projected convexhull points
yy$outmostall #all outmost found
yy$outmostfrequency #frequency table for all
yy$usedrandom #No random row was used
yy$chprojections #All the Convex Hulls of projections top coordinate planes
yy$projected #the 14 unique points that created all CHs
df[yy$outmost,] #the 4 outmost projected convexhull points
#
</code></pre>

<hr>
<h2 id='find_pcha_optimal_parameters'>Finds the optimal updating parameters to be used for the PCHA algorithm</h2><span id='topic+find_pcha_optimal_parameters'></span>

<h3>Description</h3>

<p>After creating a grid on the space of (mu_up, mu_down) it runs <code><a href="#topic+archetypal">archetypal</a></code> by using a given <code>method</code> &amp; other running options passed by ellipsis (...) and finally finds those values which minimize the SSE at the end of <code>testing_iters</code> iterations (default=10).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_pcha_optimal_parameters(df, kappas, method = "projected_convexhull", 
testing_iters = 10, nworkers = NULL, nprojected = 2, npartition = 10,
nfurthest = 100, sortrows = FALSE,
mup1 = 1.1, mup2 = 2.50, mdown1 = 0.1, mdown2 = 0.5, nmup = 10, nmdown = 10,
rseed = NULL, plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_pcha_optimal_parameters_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_method">method</code></td>
<td>
<p>The method that will be used for computing initial approximation:
</p>

<ol>
<li><p> projected_convexhull, see  <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code> 
</p>
</li>
<li><p> convexhull, see <code><a href="#topic+find_outmost_convexhull_points">find_outmost_convexhull_points</a></code> 
</p>
</li>
<li><p> partitioned_convexhull, see <code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code> 
</p>
</li>
<li><p> furthestsum, see <code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code> 
</p>
</li>
<li><p> outmost, see <code><a href="#topic+find_outmost_points">find_outmost_points</a></code> 
</p>
</li>
<li><p> random, a random set of kappas points will be used
</p>
</li></ol>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_testing_iters">testing_iters</code></td>
<td>
<p>The maximum number of iterations to run for every pair (mu_up, mu_down) of parameters</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_nworkers">nworkers</code></td>
<td>
<p>The number of logical processors that will be used for
parallel computing (usually it is the double of available physical cores)</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_nprojected">nprojected</code></td>
<td>
<p>The dimension of the projected subspace for <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code></p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_npartition">npartition</code></td>
<td>
<p>The number of partitions for <code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code></p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_nfurthest">nfurthest</code></td>
<td>
<p>The number of times that <code><a href="#topic+FurthestSum">FurthestSum</a></code>  algorithm will be applied</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_sortrows">sortrows</code></td>
<td>
<p>If it is TRUE, then rows will be sorted in <code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code></p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_mup1">mup1</code></td>
<td>
<p>The minimum value of mu_up, default is 1.1</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_mup2">mup2</code></td>
<td>
<p>The maximum value of mu_up, default is 2.5</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_mdown1">mdown1</code></td>
<td>
<p>The minimum value of mu_down, default is 0.1</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_mdown2">mdown2</code></td>
<td>
<p>The maximum value of mu_down, default is 0.5</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_nmup">nmup</code></td>
<td>
<p>The number of points to be taken for [mup1,mup2], default is 10</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_nmdown">nmdown</code></td>
<td>
<p>The number of points to be taken for [mdown1,mdown2]</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_rseed">rseed</code></td>
<td>
<p>The random seed that will be used for setting initial A matrix. Useful for reproducible results</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_plot">plot</code></td>
<td>
<p>If it is TRUE, then a 3D plot for (mu_up, mu_down, SSE) is created</p>
</td></tr>
<tr><td><code id="find_pcha_optimal_parameters_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to function <code><a href="#topic+archetypal">archetypal</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> mu_up_opt, the optimal found value for muAup and muBup
</p>
</li>
<li><p> mu_down_opt, the optimal found value for muAdown and muBdown
</p>
</li>
<li><p> min_sse, the minimum SSE which corresponds to (mu_up_opt,mu_down_opt)
</p>
</li>
<li><p> seed_used, the used random seed, absolutely necessary for reproducing optimal results
</p>
</li>
<li><p> method_used, the method that was used for creating the initial solution
</p>
</li>
<li><p> sol_initial, the initial solution that was used for all grid computations
</p>
</li>
<li><p> testing_iters, the maximum number of iterations done by every grid computation
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+find_closer_points">find_closer_points</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
data("wd25")
out = find_pcha_optimal_parameters(df = wd25, kappas = 5, rseed = 2020)
# Time difference of 30.91101 secs
# mu_up_opt mu_down_opt     min_sse 
# 2.188889    0.100000    4.490980  
# Run now given the above optimal found parameters:
aa = archetypal(df = wd25, kappas = 5,
                initialrows = out$sol_initial, rseed = out$seed_used,
                muAup = out$mu_up_opt, muAdown = out$mu_down_opt,
                muBup = out$mu_up_opt, muBdown = out$mu_down_opt)
aa[c("SSE", "varexpl", "iterations", "time" )]
# $SSE
# [1] 3.629542
# 
# $varexpl
# [1] 0.9998924
# 
# $iterations
# [1] 146
# 
# $time
# [1] 21.96
# Compare it with a simple solution (time may vary)
aa2 = archetypal(df = wd25, kappas = 5, rseed = 2020)
aa2[c("SSE", "varexpl", "iterations", "time" )]
# $SSE
# [1] 3.629503
# 
# $varexpl
# [1] 0.9998924
# 
# $iterations
# [1] 164
# 
# $time
# [1] 23.55
## Of course the above was a "toy example", if your data has thousands or million rows,
## then the time reduction is much more conspicuous.
# Close plot device:
dev.off()

}
</code></pre>

<hr>
<h2 id='FurthestSum'>Application of FurthestSum algorithm in order to find an initial solution for Archetypal Analysis</h2><span id='topic+FurthestSum'></span>

<h3>Description</h3>

<p>The FurthestSum algorithm as was written by Morup and Hansen
in Matlab, see [1] and it is based on [2]. The algorithm has been converted in order to use commonly used 
data frames in R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FurthestSum(Y, kappas, irows, exclude = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FurthestSum_+3A_y">Y</code></td>
<td>
<p>The data frame with dimensions <code class="reqn">n \times d</code></p>
</td></tr>
<tr><td><code id="FurthestSum_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="FurthestSum_+3A_irows">irows</code></td>
<td>
<p>The initially used rows of data frame for starting algorithm</p>
</td></tr>
<tr><td><code id="FurthestSum_+3A_exclude">exclude</code></td>
<td>
<p>The rows of data frame that we want to exclude from being checked</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vector of rows that constitute the initial FurthestSum solution
</p>


<h3>References</h3>

<p>[1] Source: https://mortenmorup.dk/?page_id=2 , last accessed 2024-03-09
</p>
<p>[2] D.S. Hochbaum, D.B. Shmoys, A best possible heuristic for the k-center problem, <br />
Math. Oper. Res. 10(2) (1985) 180-184. https://doi.org/10.1287/moor.10.2.180
</p>


<h3>See Also</h3>

<p><code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wd3") #3D demo 
df = wd3
FurthestSum(df, kappas = 4, irows = sample(1:dim(df)[1],1))
</code></pre>

<hr>
<h2 id='gallupGPS6'>
Gallup Global Preferences Study processed data set of six variables
</h2><span id='topic+gallupGPS6'></span>

<h3>Description</h3>

<p>A 76132 x 6 data frame derived from Gallup Global Preferences Study, see [1] and [2] for details.
It can be used as a big data set example. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("gallupGPS6")</code></pre>


<h3>Format</h3>

<p>A data frame with 76132 complete observations on the following 6 variables.
</p>

<dl>
<dt><code>patience</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>risktaking</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>posrecip</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>negrecip</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>altruism</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>trust</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data processing:
</p>

<ol>
<li><p> The non complete rows have been removed
</p>
</li>
<li><p> The duplicated rows have also been removed
</p>
</li></ol>



<h3>Note</h3>


<ol>
<li><p> The data was provided under a Creative Commons NonCommerical ShareAlike 4.0 license:  
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">https://creativecommons.org/licenses/by-nc-sa/4.0/</a> 
</p>
</li>
<li><p> Other variables and identifiers from the original data have been dropped
</p>
</li></ol>



<h3>Source</h3>

<p>Individual data set was downloaded from <a href="https://www.gallup.com/analytics/318923/world-poll-public-datasets.aspx">https://www.gallup.com/analytics/318923/world-poll-public-datasets.aspx</a>, last accessed 2024-03-09.
</p>


<h3>References</h3>

<p>[1] Falk, A., Becker, A., Dohmen, T., Enke, B., Huffman, D., &amp; Sunde, U. (2018). Global evidence on economic preferences. Quarterly Journal of Economics, 133 (4), 1645-1692.<br />
</p>
<p>[2] Falk, A., Becker, A., Dohmen, T. J., Huffman, D., &amp; Sunde, U. (2016). The preference survey module: A validated instrument for measuring risk, time, and social preferences. IZA Discussion Paper No. 9674. <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gallupGPS6)
summary(gallupGPS6)
</code></pre>

<hr>
<h2 id='grouped_resample'>
Function for performing simple or Dirichlet resampling
</h2><span id='topic+grouped_resample'></span>

<h3>Description</h3>

<p>The function may be used for standard bootstrapping or for subsampling, see [1]. 
This function allows samples to be drawn with or without replacement, by groups and with or without 
Dirichlet weights, see [2]. This provides a variety of options for researchers who wish
to correct sample biases, estimate empirical confidence intervals, and/or subsample large data sets. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grouped_resample(in_data = NULL, grp_vector = NULL, grp_matrix = NULL, 
                 replace = FALSE, option = "Simple", number_samples = 1, 
                 nworkers = NULL, rseed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grouped_resample_+3A_in_data">in_data</code></td>
<td>

<p>The initial data frame that must be re-sampled. It must contain:
</p>

<ol>
<li><p> an ID variable
</p>
</li>
<li><p> the variables of interest
</p>
</li>
<li><p> a grouping variable
</p>
</li></ol>

</td></tr>
<tr><td><code id="grouped_resample_+3A_grp_vector">grp_vector</code></td>
<td>

<p>The grouping variable of the data frame, defined under the name 'group' for example
</p>
</td></tr>
<tr><td><code id="grouped_resample_+3A_grp_matrix">grp_matrix</code></td>
<td>

<p>A matrix that contains
</p>

<ol>
<li><p> the variable 'Group_ID' with entries all the available values of grouping variable 
</p>
</li>
<li><p> the variable 'Resample_Size' with the sizes for each sample that will be created per grouping value
</p>
</li></ol>

</td></tr>
<tr><td><code id="grouped_resample_+3A_replace">replace</code></td>
<td>

<p>A logical input: TRUE/FALSE if replacement should be used or not, respectively
</p>
</td></tr>
<tr><td><code id="grouped_resample_+3A_option">option</code></td>
<td>

<p>A character input with next possible values
</p>

<ol>
<li><p> &quot;Simple&quot;, if we want to perform a simple re-sampling
</p>
</li>
<li><p> &quot;Dirichlet&quot;, if we want to perform a Dirichlet weighted re-sampling
</p>
</li></ol>

</td></tr>
<tr><td><code id="grouped_resample_+3A_number_samples">number_samples</code></td>
<td>

<p>The number of samples to be created. If it is greater than one, then parallel processing is used.
</p>
</td></tr>
<tr><td><code id="grouped_resample_+3A_nworkers">nworkers</code></td>
<td>

<p>The number of logical processors that will be used for parallel computing
(usually it is the double of available physical cores)
</p>
</td></tr>
<tr><td><code id="grouped_resample_+3A_rseed">rseed</code></td>
<td>

<p>The random seed that will be used for sampling. Useful for reproducible results
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>It returns a list of <code>mumber_samples</code> data frames with exactly the same 
variables as the initial one, except that group variable has now only the given 
value from input data frame.
</p>


<h3>Author(s)</h3>

<p>David Midgley
</p>


<h3>References</h3>

<p>[1] D. N. Politis, J. P. Romano, M. Wolf, Subsampling (Springer-Verlag, New York, 1999).
</p>
<p>[2] Baath R (2018). bayesboot: An Implementation of Rubin's (1981) Bayesian Bootstrap. R
package version 0.2.2, URL https://CRAN.R-project.org/package=bayesboot
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dirichlet_sample">dirichlet_sample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load absolute temperature data set:
data("AbsoluteTemperature")
df &lt;- AbsoluteTemperature
## Find portions for climate zones
pcs &lt;- table(df$z)/dim(df)[1]
## Choose the approximate size of the new sample and compute resample sizes
N &lt;- round(sqrt(nrow(AbsoluteTemperature)))
resamplesizes=as.integer(round(N*pcs))
sum(resamplesizes)
## Create the grouping matrix
groupmat &lt;- data.frame("Group_ID"=1:4,"Resample_Size"=resamplesizes)
groupmat
## Simple resampling:
resample_simple &lt;- grouped_resample(in_data = df, grp_vector = "z",
                                    grp_matrix = groupmat, replace = FALSE, option = "Simple",
                                    number_samples = 1, nworkers = NULL, rseed = 20191220)
cat(dim(resample_simple[[1]]),"\n")
## Dirichlet resampling:
resample_dirichlet &lt;- grouped_resample(in_data = df, grp_vector = "z",
                                       grp_matrix = groupmat, replace = FALSE, option = "Dirichlet",
                                       number_samples = 1, nworkers = NULL, rseed = 20191220)
cat(dim(resample_dirichlet[[1]]),"\n")
##
# ## Work in parallel and create many samples
# ## Choose a random seed
# nseed &lt;- 20191119
# ## Simple
# reslist1 &lt;- grouped_resample(in_data = df, grp_vector = "z", grp_matrix = groupmat,
#                         replace = FALSE, option = "Simple",
#                         number_samples = 10, nworkers = NULL,
#                         rseed = nseed)
# sapply(reslist1, dim)
# ## Dirichlet
# reslist2 &lt;- grouped_resample(in_data = df, grp_vector = "z", grp_matrix = groupmat,
#                         replace = FALSE, option = "Dirichlet",
#                         number_samples = 10, nworkers = NULL,
#                         rseed = nseed)
# sapply(reslist2, dim)
# ## Check for same rows between 1st sample of 'Simple' and 1st sample of 'Dirichlet' ...
# mapply(function(x,y){sum(rownames(x)%in%rownames(y))},reslist1,reslist2)
#
</code></pre>

<hr>
<h2 id='kappa_tools'>
Compute kappa tools for data dimensionality analysis
</h2><span id='topic+kappa_tools'></span>

<h3>Description</h3>

<p>For a given data set and a given Archetypal Analysis (AA) solution, it finds a set of useful proxies
for the dimensionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kappa_tools(aa, df = NULL, numBins = 100, chvertices = NULL, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kappa_tools_+3A_aa">aa</code></td>
<td>

<p>An object of the class 'archetypal'
</p>
</td></tr>
<tr><td><code id="kappa_tools_+3A_df">df</code></td>
<td>

<p>The data frame that was used for AA
</p>
</td></tr>
<tr><td><code id="kappa_tools_+3A_numbins">numBins</code></td>
<td>

<p>The number of bins to be used for computing entropy
</p>
</td></tr>
<tr><td><code id="kappa_tools_+3A_chvertices">chvertices</code></td>
<td>

<p>The Convex Hull vertices, if they are given
</p>
</td></tr>
<tr><td><code id="kappa_tools_+3A_verbose">verbose</code></td>
<td>

<p>Logical, set to TRUE if details must be printed
</p>
</td></tr>
<tr><td><code id="kappa_tools_+3A_...">...</code></td>
<td>

<p>Other areguments, not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ECDF for the Squared Errors (SE) is computed and then the relevant curve
is classified as 'convex' or 'concave' and its UIK &amp; inflcetion point is found. Then the number of used
rows for cfreating archetypes is found. A procedure for creating BIC and andjusted BIC is used. 
Finally the pecentage of used points that lie on the exact Convex Hull is given.
</p>


<h3>Value</h3>

<p>A list with next arguments:
</p>
<table>
<tr><td><code>ecdf</code></td>
<td>
<p>The ECDF of SE</p>
</td></tr>
<tr><td><code>Convexity</code></td>
<td>
<p>The convex or concave classification for ECDF curve</p>
</td></tr>
<tr><td><code>UIK</code></td>
<td>
<p>The UIK points of ECDF curve by using [1]</p>
</td></tr>
<tr><td><code>INFLECTION</code></td>
<td>
<p>The inflection points of ECDF curve by using [2]</p>
</td></tr>
<tr><td><code>NumberRowsUsed</code></td>
<td>
<p>The number of rows used for creating archetypes</p>
</td></tr>
<tr><td><code>RowsUsed</code></td>
<td>
<p>The exact rows used for creating archetypes</p>
</td></tr>
<tr><td><code>SSE</code></td>
<td>
<p>The Sum of SE</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>The computed BIC by using [3], [4]</p>
</td></tr>
<tr><td><code>adjBIC</code></td>
<td>
<p>The computed adjusted BIC by using [3], [4]</p>
</td></tr>
<tr><td><code>CXHE</code></td>
<td>
<p>The percentage of used points that lie on the exact Convex Hull</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Demetris T. Christopoulos, David F. Midgley (creator of BIC and adjBIC procedures)
</p>


<h3>References</h3>

<p>[1] Demetris T. Christopoulos, Introducing Unit Invariant Knee (UIK) As an Objective Choice for Elbow Point in Multivariate Data Analysis Techniques (March 1, 2016). Available at SSRN: https://ssrn.com/abstract=3043076 or http://dx.doi.org/10.2139/ssrn.3043076
</p>
<p>[2] Demetris T. Christopoulos, On the efficient identification of an inflection point,International Journal of Mathematics and Scientific Computing,(ISSN: 2231-5330), vol. 6(1), 2016.
</p>
<p>[3] Felix Abramovich, Yoav Benjamini, David L. Donoho, Iain M. Johnstone. &quot;Adapting to unknown sparsity by
controlling the false discovery rate.&quot; The Annals of Statistics, 34(2) 584-653 April 2006.
https://doi.org/10.1214/009053606000000074
</p>
<p>[4] Murari, Andrea, Emmanuele Peluso, Francesco Cianfrani, Pasquale Gaudio, and Michele Lungaroni. 2019. &quot;On the Use of Entropy to Improve Model Selection Criteria&quot; Entropy 21, no. 4: 394. https://doi.org/10.3390/e21040394
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
	## Use the sample data "wd2"
	data(wd2)
	require("geometry")
	ch=convhulln(as.matrix(wd2),'Fx')
	chlist=as.list(ch)
	chvertices = unique(do.call(c,chlist))
	aa=archetypal(wd2, 3)
	out=kappa_tools(aa ,  df = wd2, numBins = 100, chvertices, verbose = T )
	out

}
</code></pre>

<hr>
<h2 id='plot_archs'>
A function for plotting arechetypes 
</h2><span id='topic+plot_archs'></span>

<h3>Description</h3>

<p>A data frame or matrix of archetypes can be plotted
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_archs(archs, data = NULL, show_data = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_archs_+3A_archs">archs</code></td>
<td>

<p>The matrix or data frame of archetypes where each row represents an archetype
</p>
</td></tr>
<tr><td><code id="plot_archs_+3A_data">data</code></td>
<td>

<p>Optional argument, if used data frame is known
</p>
</td></tr>
<tr><td><code id="plot_archs_+3A_show_data">show_data</code></td>
<td>

<p>if it set to TRUE, then the used data frame will be plotted at the same plot
</p>
</td></tr>
<tr><td><code id="plot_archs_+3A_...">...</code></td>
<td>

<p>Other arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the column dimension of the archetypes is less or ewqual to 3, then a normal plot is presented. <br />
Otherwise, a &quot;spike-spider&quot; plot is crerated, see <code><a href="#topic+plot.archetypal">plot.archetypal</a></code> for details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.archetypal">plot.archetypal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BY=matrix(c(5.430744, 2.043404, 3.128485, 3.146242, 2.710978, 4.781843), nrow = 3, byrow = TRUE)
plot_archs(BY)
</code></pre>

<hr>
<h2 id='plot.archetypal'>
Plot an object of the class archetypal.
</h2><span id='topic+plot.archetypal'></span>

<h3>Description</h3>

<p>It makes a plot of the archetypes creating after using <code><a href="#topic+archetypal">archetypal</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'archetypal'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.archetypal_+3A_x">x</code></td>
<td>

<p>An object of the class archetypal
</p>
</td></tr>
<tr><td><code id="plot.archetypal_+3A_...">...</code></td>
<td>

<p>Other arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the data frame has column dimension at most 3, then a direct plot is available. Otherwise we use a &quot;spike-spider&quot; plot which is a combination of the common &quot;spider&quot; or &quot;web&quot; or &quot;radar&quot; plot with an additional &quot;spike plot&quot; that shows the frequency of each variable at the same line of the spider plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
## Use the sample data "wd2"
data(wd2)
aa=archetypal(wd2, 3)
plot(aa)

}
</code></pre>

<hr>
<h2 id='plot.kappa_tools'>
Plot an object of the class kappa_tools
</h2><span id='topic+plot.kappa_tools'></span>

<h3>Description</h3>

<p>It makes a plot of the results created after using <code><a href="#topic+kappa_tools">kappa_tools</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kappa_tools'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.kappa_tools_+3A_x">x</code></td>
<td>

<p>An object of the class kappa_tools
</p>
</td></tr>
<tr><td><code id="plot.kappa_tools_+3A_...">...</code></td>
<td>

<p>Other arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A panel of 2 plots is being created, see <code><a href="#topic+kappa_tools">kappa_tools</a></code> for details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kappa_tools">kappa_tools</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
### Use the sample data "wd2"
data(wd2)
ch=convhulln(as.matrix(wd2),'Fx')
chlist=as.list(ch)
chvertices = unique(do.call(c,chlist))
aa=archetypal(wd2, 3)
out=kappa_tools(aa ,  df = wd2, numBins = 100, chvertices, verbose = T )
plot(out)

}
</code></pre>

<hr>
<h2 id='plot.study_AAconvergence'>
Plot an object of the class study_AAconvergence
</h2><span id='topic+plot.study_AAconvergence'></span>

<h3>Description</h3>

<p>It makes a plot of the results created after using <code><a href="#topic+study_AAconvergence">study_AAconvergence</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'study_AAconvergence'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.study_AAconvergence_+3A_x">x</code></td>
<td>

<p>An object of the class study_AAconvergence
</p>
</td></tr>
<tr><td><code id="plot.study_AAconvergence_+3A_...">...</code></td>
<td>

<p>Other arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A panel of 7 plots is being created, see <code><a href="#topic+study_AAconvergence">study_AAconvergence</a></code> for details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+study_AAconvergence">study_AAconvergence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
## Use the sample data "wd2"
data(wd2)
yy=study_AAconvergence(wd2, 3, plot = FALSE)
plot(yy)

}
</code></pre>

<hr>
<h2 id='print.archetypal'>
Print an object of the class archetypal.
</h2><span id='topic+print.archetypal'></span>

<h3>Description</h3>

<p>It prints the output of <code><a href="#topic+archetypal">archetypal</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'archetypal'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.archetypal_+3A_x">x</code></td>
<td>

<p>An object of the class archetypal
</p>
</td></tr>
<tr><td><code id="print.archetypal_+3A_...">...</code></td>
<td>

<p>Other arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since Archetypal Analysis (AA) is essentially one more matrix decomposition of the form Y ~ ABY, it is reasonable to print:
</p>

<ol>
<li><p> the <code class="reqn">kappas \times d</code> matrix of archetypes found
</p>
</li>
<li><p> the <code class="reqn">n \times kappas</code> matrix A such that Y ~ ABY or Frobenius norm ||Y-ABY|| is minimum
</p>
</li>
<li><p> the <code class="reqn">kappas \times n</code> matrix B such that Y ~ ABY or Frobenius norm ||Y-ABY|| is minimum
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>{
## Use the sample data "wd2"
data(wd2)
aa=archetypal(wd2, 3)
print(aa)

}
</code></pre>

<hr>
<h2 id='study_AAconvergence'>Function which studies the convergence of
Archetypal Analysis when using the PCHA algorithm</h2><span id='topic+study_AAconvergence'></span>

<h3>Description</h3>

<p>First it finds an AA solution under given arguments while storing 
all iteration history (<code>save_history = TRUE</code>).
Then it computes the LOWESS [1] of SSE and its relevant UIK point [2].
Study is performed for iterations after that point.
The list of B-matrices and archetypes that were found are stored.
The archetypes are being aligned, while the B-matrices
are used for computing the used rows-weights,
leading rows-weights and maybe percentage of used rows on Convex Hull.
The Aitken SSE extrapolation plus the relevant error are computed.
The order and rate of convergence  are estimated.
Finally a multi-plot panel is being created if asked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>study_AAconvergence(df, kappas, method = "projected_convexhull", 
                    rseed = NULL, chvertices = NULL, plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="study_AAconvergence_+3A_df">df</code></td>
<td>
<p>The data frame with dimensions n x d</p>
</td></tr>
<tr><td><code id="study_AAconvergence_+3A_kappas">kappas</code></td>
<td>
<p>The number of archetypes</p>
</td></tr>
<tr><td><code id="study_AAconvergence_+3A_method">method</code></td>
<td>
<p>The method that will be used for computing initial approximation:
</p>

<ol>
<li><p> projected_convexhull, see  <code><a href="#topic+find_outmost_projected_convexhull_points">find_outmost_projected_convexhull_points</a></code> 
</p>
</li>
<li><p> convexhull, see <code><a href="#topic+find_outmost_convexhull_points">find_outmost_convexhull_points</a></code> 
</p>
</li>
<li><p> partitioned_convexhull, see <code><a href="#topic+find_outmost_partitioned_convexhull_points">find_outmost_partitioned_convexhull_points</a></code> 
</p>
</li>
<li><p> furthestsum, see <code><a href="#topic+find_furthestsum_points">find_furthestsum_points</a></code> 
</p>
</li>
<li><p> outmost, see <code><a href="#topic+find_outmost_points">find_outmost_points</a></code> 
</p>
</li>
<li><p> random, a random set of kappas points will be used
</p>
</li></ol>
</td></tr>
<tr><td><code id="study_AAconvergence_+3A_rseed">rseed</code></td>
<td>
<p>The random seed that will be used for setting initial A matrix. Useful for reproducible results.</p>
</td></tr>
<tr><td><code id="study_AAconvergence_+3A_chvertices">chvertices</code></td>
<td>
<p>The vector of rows which represents the vertices for Convex Hull (if available)</p>
</td></tr>
<tr><td><code id="study_AAconvergence_+3A_plot">plot</code></td>
<td>
<p>If it is TRUE, then a panel of useful plots is created</p>
</td></tr>
<tr><td><code id="study_AAconvergence_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to function <code><a href="#topic+archetypal">archetypal</a></code>, except <code>save_history</code> 
which must always be TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If we take natural logarithms at the next approximate equation
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_{n+1} = c\epsilon_{n}^p</code>
</p>

<p>for <code class="reqn">n = 1, 2, 3, \ldots</code>, then we'll find
</p>
<p style="text-align: center;"><code class="reqn">\log(\epsilon_{n+1}) = \log(c)+p\log(\epsilon_{n})</code>
</p>

<p>Thus a reasonable strategy for estimating order p and rate c is to perform a linear regression
on above errors, after a selected iteration. 
That is the output of <code>order_estimation</code> and <code>rate_estimation</code>.
</p>


<h3>Value</h3>

<p>A list with members:
</p>

<ol>
<li><p> SSE, a vector of all SSE from all AA iterations
</p>
</li>
<li><p> SSE_lowess, a vector of LOWESS values for SSE 
</p>
</li>
<li><p> UIK_lowess, the UIK point [2] of SSE_lowess 
</p>
</li>
<li><p> aitken, a data frame of Aitken [3] extrapolation and error for SSE after UIK_lowess iteration 
</p>
</li>
<li><p> order_estimation, the last term in estimating order of convergence, page 56 of [4], 
by using SSE after UIK_lowess iteration 
</p>
</li>
<li><p> rate_estimation, the last term in estimating rate of convergence, page 56 of [4], 
by using SSE after UIK_lowess iteration 
</p>
</li>
<li><p> significance_estimations, a data frame with standard errors and statistical significance for estimations
</p>
</li>
<li><p> used_on_convexhull, the % of used rows which lie on Convex Hull (if given),
as a sequence for iterations after UIK_lowess one
</p>
</li>
<li><p> aligned_archetypes, the archetypes after UIK_lowess iteration are being aligned
by using <code><a href="#topic+align_archetypes_from_list">align_archetypes_from_list</a></code>. The history of archetypes creation.
</p>
</li>
<li><p> solution_used, the AA output that has been used. Some times useful, especially for big data.
</p>
</li></ol>



<h3>References</h3>

<p>[1] Cleveland, W. S. (1979) Robust locally weighted regression and smoothing scatterplots. J. Amer. Statist. Assoc. 74, 829&ndash;836.<br />
</p>
<p>[2] Christopoulos, Demetris T., Introducing Unit Invariant Knee (UIK) As an Objective Choice for
Elbow Point in Multivariate Data Analysis Techniques (March 1, 2016). 
Available at SSRN: http://dx.doi.org/10.2139/ssrn.3043076 <br />
</p>
<p>[3] Aitken, A. &quot;On Bernoulli's numerical solution of algebraic equations&quot;, Proceedings of the Royal Society of Edinburgh (1926) 46 pp. 289-305. <br />
</p>
<p>[4] Atkinson, K. E.,An Introduction to Numerical Analysis, Wiley &amp; Sons,1989 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+check_Bmatrix">check_Bmatrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
# Load data "wd2"
data(wd2)
ch = chull(wd2)
sa = study_AAconvergence(df = wd2, kappas = 3, rseed = 20191119,
                         verbose = FALSE, chvertices = ch)
	names(sa)
	# [1] "SSE"                      "SSE_lowess"               "UIK_lowess"              
	# [4] "aitken"                   "order_estimation"         "rate_estimation"         
	# [7] "significance_estimations" "used_on_convexhull"       "aligned_archetypes"      
	# [10] "solution_used"        
	# sse=sa$SSE
	# ssel=sa$SSE_lowess
	sa$UIK_lowess
	# [1] 36
	# sa$aitken
	sa$order_estimation
	# [1] 1.007674
	sa$rate_estimation
	# [1] 0.8277613
	sa$significance_estimations
	#        estimation   std.error   t.value      p.value
	# log(c) -0.1890305 0.014658947 -12.89523 5.189172e-12
	# p       1.0076743 0.001616482 623.37475 3.951042e-50
	# sa$used_on_convexhull
	# sa$aligned_archetypes
	data.frame(sa$solution_used[c("SSE","varexpl","iterations","time")])
	#        SSE   varexpl iterations time
	# 1 1.717538 0.9993186         62 8.39
	# Plot class "study_AAconvergence"
	plot(sa)

}
</code></pre>

<hr>
<h2 id='summary.archetypal'>
Summary for an object of the class archetypal.
</h2><span id='topic+summary.archetypal'></span>

<h3>Description</h3>

<p>It gives a summary for the output of <code><a href="#topic+archetypal">archetypal</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'archetypal'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.archetypal_+3A_object">object</code></td>
<td>

<p>An object of the class archetypal
</p>
</td></tr>
<tr><td><code id="summary.archetypal_+3A_...">...</code></td>
<td>

<p>Other arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Next info is given:
</p>

<ol>
<li><p> the number of observations or the row number of the data frame
</p>
</li>
<li><p> the dimension of the data variables
</p>
</li>
<li><p> the number of archetypes that was used
</p>
</li>
<li><p> the computed archetypes 
</p>
</li>
<li><p> a vector of run details: SSE, VarianceExplained, Convergence, Iterations, EllapsedTime
</p>
</li>
<li><p> the calling command
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>{
## Use the sample data "wd2"
data(wd2)
aa=archetypal(wd2, 3)
summary(aa)

}
</code></pre>

<hr>
<h2 id='wd2'>
2D data set for demonstration purposes
</h2><span id='topic+wd2'></span>

<h3>Description</h3>

<p>A data frame of 100 2D points
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("wd2")</code></pre>


<h3>Format</h3>

<p>matrix 100 x 2
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Creation of data set "wd2" from 3 corner-points:
p1 = c(1,2);p2 = c(3,5);p3 = c(7,3) 
dp = rbind(p1,p2,p3);dp
set.seed(9102)
pts = t(sapply(1:100, function(i,dp){
  cc = runif(3)
  cc = cc/sum(cc)
  colSums(dp*cc)
},dp))
df = data.frame(pts)
colnames(df) = c("x","y")
head(df)
# Check all equal:
data(wd2)
all.equal(wd2,df)
# [1] TRUE
</code></pre>

<hr>
<h2 id='wd25'>
2D data set created by 5 points for demonstration purposes
</h2><span id='topic+wd25'></span>

<h3>Description</h3>

<p>A data frame of 600 2D points 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("wd25")</code></pre>


<h3>Format</h3>

<p>matrix 600 x 2
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Creation of data set "wd25" from 5 corner points:
set.seed(20191119)
p1 = c(3,2);p2 = c(4,6);p3 = c(7,8)
p4 = c(9,4);p5 = c(6,1)
dp = rbind(p1,p2,p3,p4,p5)
colnames(dp) = c('x','y')
pts=lapply(1:150, function(i,dp){
  c0 = runif(dim(dp)[1]);c0 = c0/sum(c0);pt0 = colSums(dp*c0)
  c1 = runif(3);c1 = c1/sum(c1);pt1 = colSums(dp[1:3,]*c1)
  c2 = runif(3);c2 = c2/sum(c2);pt2 = colSums(dp[c(4,5,1),]*c2)
  c3 = runif(3);c3 = c3/sum(c3);pt3 = colSums(dp[2:4,]*c3)
  rbind(pt0,pt1,pt2,pt3)
},dp)
df = do.call(rbind,pts)
rownames(df) = 1:dim(df)[1]
head(df)
# Check all equal
data("wd25")
all.equal(df,wd25)
# [1] TRUE
</code></pre>

<hr>
<h2 id='wd3'>
3D data set for demonstration purposes
</h2><span id='topic+wd3'></span>

<h3>Description</h3>

<p>A data frame of 100 3D points 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("wd3")</code></pre>


<h3>Format</h3>

<p>matrix 100 x 3
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Creation of data set "wd3" from 4 corner points:
p1 = c(3,0,0);p2 = c(0,5,0)
p3 = c(3,5,7);p4 = c(0,0,0)
# The data frame of generators
dp = data.frame(rbind(p1,p2,p3,p4))
colnames(dp) = c("x","y","z")
dp = dp[chull(dp),]
set.seed(9102) 
df = data.frame(t(sapply(1:100, function(i,dp){
  cc = runif(4)
  cc = cc/sum(cc) 
  colSums(dp*cc)
},dp)))
colnames(df) = c("x","y","z")
head(df)
# Check all.equal to "wd3"
data(wd3)
all.equal(df,wd3)
# [1] TRUE
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
