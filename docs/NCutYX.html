<!DOCTYPE html><html><head><title>Help for package NCutYX</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NCutYX}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ancut'><p>Cluster the Columns of Y into K Groups with the Help of External Features X.</p></a></li>
<li><a href='#awncut'><p>Cluster the Rows of X into K Clusters Using the AWNCut Method.</p></a></li>
<li><a href='#awncut.selection'><p>This Function Outputs the Selection of Tuning Parameters for the AWNCut Method.</p></a></li>
<li><a href='#brca.data.cna'><p>Data on copy number aberrations from breast cancer patients.</p></a></li>
<li><a href='#brca.data.ge'><p>Data on gene expression from breast cancer patients.</p></a></li>
<li><a href='#brca.data.rppa'><p>Data on protein measurements from breast cancer patients.</p></a></li>
<li><a href='#cesc.data.cna'><p>Data on copy number aberrations from cervical cancer patients.</p></a></li>
<li><a href='#cesc.data.ge'><p>Data on gene expression from breast cancer patients.</p></a></li>
<li><a href='#cesc.data.rppa'><p>Data on protein measurements from cervical cancer patients.</p></a></li>
<li><a href='#ErrorRate'><p>This Function Calculates the True Error Rate of a Clustering Result,</p>
Assuming that There are Three Clusters.</a></li>
<li><a href='#mlbncut'><p>The MLBNCut Clusters the Columns and the Rows Simultaneously of Data from 3 Different Sources.</p></a></li>
<li><a href='#muncut'><p>MuNCut Clusters the Columns of Data from 3 Different Sources.</p></a></li>
<li><a href='#ncut'><p>Cluster the Columns of Y into K Groups Using the NCut Graph Measure.</p></a></li>
<li><a href='#pwncut'><p>Cluster the Columns of X into K Clusters by Giving a Weighted Cluster Membership while shrinking</p>
Weights Towards Each Other.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Clustering of Omics Data of Multiple Types with a Multilayer
Network Representation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Sebastian J. Teran Hidalgo, Shuangge Ma, Ruofan Bie</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian J. Teran Hidalgo &lt;sebastianteranhidalgo@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Omics data come in different forms: gene expression, methylation, copy number, protein measurements and more.
    'NCutYX' allows clustering of variables, of samples, and both variables and samples (biclustering),
    while incorporating the dependencies across multiple types of Omics data.
    (SJ Teran Hidalgo et al (2017), &lt;<a href="https://doi.org/10.1186%2Fs12864-017-3990-1">doi:10.1186/s12864-017-3990-1</a>&gt;). </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.2), glmnet (&ge; 2.0-5), MASS (&ge; 7.3-47), mvtnorm
(&ge; 1.0-6), fields (&ge; 9.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Seborinos/NCutYX">https://github.com/Seborinos/NCutYX</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Seborinos/NCutYX/issues">https://github.com/Seborinos/NCutYX/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-02-09 16:43:40 UTC; sebastianteranhidalgo</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-02-09 18:27:31 UTC</td>
</tr>
</table>
<hr>
<h2 id='ancut'>Cluster the Columns of Y into K Groups with the Help of External Features X.</h2><span id='topic+ancut'></span>

<h3>Description</h3>

<p>This function will output K clusters of the columns of Y using the help of
X.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ancut(Y, X, K = 2, B = 3000, L = 1000, alpha = 0.5, nlambdas = 100,
  sampling = "equal", ncv = 5, dist = "correlation", sigma = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ancut_+3A_y">Y</code></td>
<td>
<p>is a n x p matrix of p variables and n observations. The columns of
Y will be clustered into K groups.</p>
</td></tr>
<tr><td><code id="ancut_+3A_x">X</code></td>
<td>
<p>is a n x q matrix of q variables and n observations.</p>
</td></tr>
<tr><td><code id="ancut_+3A_k">K</code></td>
<td>
<p>is the number of clusters.</p>
</td></tr>
<tr><td><code id="ancut_+3A_b">B</code></td>
<td>
<p>is the number of iterations in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="ancut_+3A_l">L</code></td>
<td>
<p>is the temperature coefficient in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="ancut_+3A_alpha">alpha</code></td>
<td>
<p>is the coefficient of the elastic net penalty.</p>
</td></tr>
<tr><td><code id="ancut_+3A_nlambdas">nlambdas</code></td>
<td>
<p>is the number of tuning parameters in the elastic net.</p>
</td></tr>
<tr><td><code id="ancut_+3A_sampling">sampling</code></td>
<td>
<p>if 'equal' then the sampling probabilities is the same during
the simulated annealing algorithm, if 'size' the probabilites are proportional
the the sizes of the clusters in the current iterations.</p>
</td></tr>
<tr><td><code id="ancut_+3A_ncv">ncv</code></td>
<td>
<p>is the number of cross-validations in the elastic net.</p>
</td></tr>
<tr><td><code id="ancut_+3A_dist">dist</code></td>
<td>
<p>is the type of distance metric for the construction of the similarity matrix.
Options are 'gaussian', 'euclidean' and 'correlation', the latter being the default.</p>
</td></tr>
<tr><td><code id="ancut_+3A_sigma">sigma</code></td>
<td>
<p>is the parameter for the gaussian kernel distance which is ignored if 'gaussian' is
not chosen as distance measure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm minimizes a modified version of NCut through simulated annealing.
The modified NCut uses in the numerator the similarity matrix of the original data <code>Y</code>
and the denominator uses the similarity matrix of the prediction of <code>Y</code> using <code>X</code>.
The clusters correspond to partitions that minimize this objective function.
The external information of <code>X</code> is incorporated by using elastic net to predict <code>Y</code>.
</p>


<h3>Value</h3>

<p>A list with the final value of the objective function,
the clusters and the lambda penalty chosen through cross-validation.
</p>
<p>A list with the following components:
</p>

<dl>
<dt>loss</dt><dd><p>a vector of length <code>N</code> which contains the loss
at each iteration of the simulated annealing algorithm.</p>
</dd>
<dt>cluster</dt><dd><p>a matrix representing the clustering result of dimension <code>p</code> times
<code>K</code>, where <code>p</code> is the number of columns of <code>Y</code>.</p>
</dd>
<dt>lambda.min</dt><dd><p>is the optimal lambda chosen through cross-validation for the elastic net for
predicting <code>Y</code> with <code>Y</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Sebastian Jose Teran Hidalgo and Shuangge Ma. Maintainer: Sebastian Jose Teran Hidalgo.
<a href="sebastianteranhidalgo@gmail.com">sebastianteranhidalgo@gmail.com</a>.
</p>


<h3>References</h3>

<p>Hidalgo, Sebastian J. Teran, Mengyun Wu, and Shuangge Ma.
Assisted clustering of gene expression data using ANCut. BMC genomics 18.1 (2017): 623.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This sets up the initial parameters for the simulation.
library(MASS)#for mvrnorm
library(fields)
n=30 #Sample size
B=50 #Number of iterations in the simulated annealing algorithm.
L=10000 #Temperature coefficient.
p=50 #Number of columns of Y.
q=p #Number of columns of X.
h1=0.15
h2=0.25

S=matrix(0.2,q,q)
S[1:(q/2),(q/2+1):q]=0
S[(q/2+1):q,1:(q/2)]=0
S=S-diag(diag(S))+diag(q)

mu=rep(0,q)

W0=matrix(1,p,p)
W0[1:(p/2),1:(p/2)]=0
W0[(p/2+1):p,(p/2+1):p]=0
Denum=sum(W0)

B2=matrix(0,q,p)
for (i in 1:(p/2)){
   B2[1:(q/2),i]=runif(q/2,h1,h2)
   in1=sample.int(q/2,6)
   B2[-in1,i]=0
}

for (i in (p/2+1):p){
   B2[(q/2+1):q,i]=runif(q/2,h1,h2)
   in2=sample(seq(q/2+1,q),6)
   B2[-in2,i]=0
}

X=mvrnorm(n, mu, S)
Z=X%*%B2
Y=Z+matrix(rnorm(n*p,0,1),n,p)
#Our method
Res=ancut(Y=Y,X=X,B=B,L=L,alpha=0,ncv=3)
Cx=Res[[2]]
f11=matrix(Cx[,1],p,1)
f12=matrix(Cx[,2],p,1)

errorL=sum((f11%*%t(f11))*W0)/Denum+sum((f12%*%t(f12))*W0)/Denum
#This is the true error of the clustering solution.
errorL

par(mfrow=c(1,2))
#Below is a plot of the simulated annealing path.
plot(Res[[1]],type='l',ylab='')
#Cluster found by ANCut
image.plot(Cx)
</code></pre>

<hr>
<h2 id='awncut'>Cluster the Rows of X into K Clusters Using the AWNCut Method.</h2><span id='topic+awncut'></span>

<h3>Description</h3>

<p>Builds similarity matrices for the rows of X and the rows of an assisted dataset Z.
Clusters them into K groups while conducting feature selection based on the AWNCut method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>awncut(X, Z, K, lambda, Tau, B = 500, L = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="awncut_+3A_x">X</code></td>
<td>
<p>is an n x p1 matrix of n observations and p1 variables.</p>
</td></tr>
<tr><td><code id="awncut_+3A_z">Z</code></td>
<td>
<p>is an n x p2 matrix of n observations and p2 variables. Z is the assistant dataset.</p>
</td></tr>
<tr><td><code id="awncut_+3A_k">K</code></td>
<td>
<p>is the number of clusters.</p>
</td></tr>
<tr><td><code id="awncut_+3A_lambda">lambda</code></td>
<td>
<p>is a vector of tuning parameter lambda in the objective function.</p>
</td></tr>
<tr><td><code id="awncut_+3A_tau">Tau</code></td>
<td>
<p>is a vector of tuning parameters tau to be used in the objective function.</p>
</td></tr>
<tr><td><code id="awncut_+3A_b">B</code></td>
<td>
<p>is the number of iterations in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="awncut_+3A_l">L</code></td>
<td>
<p>is the temperature coefficient in the simulated annealing algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm maximizes a sum of the weighed NCut measure for X and assisted dataset Z,
with the addition of a correlation measure between the two datasets. Feature selection
is implemented by using the average correlation of each feature as a criterion.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>

<dl>
<dt>lambda</dt><dd><p>the value of tuning parameter lambda for the result</p>
</dd>
<dt>tau</dt><dd><p>the value of tuning parameter tau for the result</p>
</dd>
<dt>Cs</dt><dd><p>a matrix of the clustering result</p>
</dd>
<dt>ws</dt><dd><p>a vector of the feature selection result</p>
</dd>
<dt>OP.value</dt><dd><p>the value of the objective function</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Ruofan Bie. Maintainer: Sebastian Jose Teran Hidalgo
<a href="sebastianteranhidalgo@gmail.com">sebastianteranhidalgo@gmail.com</a>.
</p>


<h3>References</h3>

<p>Li, Yang; Bie, Ruofan; Teran Hidalgo, Sebastian; Qin, Yinchen; Wu, Mengyun; Ma, Shuangge.
Assisted gene expression-based clustering with AWNCut. (Submitted.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123456)
#This sets up the initial parameters for the simulation.
lambda &lt;- seq(2,6,1) #Tuning parameter lambda
Tau    &lt;- seq(0.2,0.8,0.2) #Tuning parameter tau

n=30; n1=10; n2=10; n3=n-n1-n2 #Sample size
p1=10; p2=10; r1=8; r2=8; #Number of variables and noises in each dataset

K=3; #Number of clusters

mu=1; #Mean of the marginal distribution
u1=0.5; #Range of enties in the coefficient matrix

library(mvtnorm)
epsilon &lt;- matrix(rnorm(n*(p1-r1),0,1), n, (p1-r1)) # Generation of random error

Sigma1 &lt;- matrix(rep(0.8,(p1-r1)^2),(p1-r1),(p1-r1)) # Generation of the covariance matrix
diag(Sigma1) &lt;- 1

# Generation of the original distribution of the three clusters
T1 &lt;- matrix(rmvnorm(n1,mean=rep(-mu,(p1-r1)),sigma=Sigma1),n1,(p1-r1))
T2 &lt;- matrix(rmvnorm(n2,mean=rep(0,(p1-r1)),sigma=Sigma1),n2,(p1-r1))
T3 &lt;- matrix(rmvnorm(n3,mean=rep(mu,(p1-r1)),sigma=Sigma1),n3,(p1-r1))

X1 &lt;- sign(T1)*(exp(abs(T1))) #Generation of signals in X
X2 &lt;- sign(T2)*(exp(abs(T2)))
X3 &lt;- sign(T3)*(exp(abs(T3)))
ep1 &lt;- (matrix(rnorm(n*r1,0,1),n,r1)) #Generation of noises in X
X &lt;- rbind(X1,X2,X3)

beta1 &lt;- matrix(runif((p1-r1)*(p2-r2),-u1,u1),(p1-r1),(p2-r2)) #Generation of the coefficient matrix
Z     &lt;- X%*%beta1+epsilon #Generation of signals in Z
ep2   &lt;- (matrix(rnorm(n*r2,0.5,1),n,r2)) #Generation of noises in Z

X &lt;- cbind(X,ep1)
Z &lt;- cbind(Z,ep2)
#our method
Tune1         &lt;- awncut.selection(X, Z, K, lambda, Tau, B = 20, L = 1000)
awncut.result &lt;- awncut(X, Z, 3, Tune1$lam, Tune1$tau, B = 20, L = 1000)
ErrorRate(awncut.result[[1]]$Cs, n1, n2)
</code></pre>

<hr>
<h2 id='awncut.selection'>This Function Outputs the Selection of Tuning Parameters for the AWNCut Method.</h2><span id='topic+awncut.selection'></span>

<h3>Description</h3>

<p>This Function Outputs the Selection of Tuning Parameters for the AWNCut Method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>awncut.selection(X, Z, K, lambda, Tau, B = 500, L = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="awncut.selection_+3A_x">X</code></td>
<td>
<p>is an n x p1 matrix of n observations and p1 variables.</p>
</td></tr>
<tr><td><code id="awncut.selection_+3A_z">Z</code></td>
<td>
<p>is an n x p2 matrix of n observations and p2 variables. Z is the assistant dataset.</p>
</td></tr>
<tr><td><code id="awncut.selection_+3A_k">K</code></td>
<td>
<p>is the number of clusters.</p>
</td></tr>
<tr><td><code id="awncut.selection_+3A_lambda">lambda</code></td>
<td>
<p>is a vector of tuning parameter lambda in the objective function.</p>
</td></tr>
<tr><td><code id="awncut.selection_+3A_tau">Tau</code></td>
<td>
<p>is a vector of tuning parameter tau in the objective function.</p>
</td></tr>
<tr><td><code id="awncut.selection_+3A_b">B</code></td>
<td>
<p>is the number of iterations in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="awncut.selection_+3A_l">L</code></td>
<td>
<p>is the temperature coefficient in the simulated annealing algorithm.
#' @return  A list with the following components:
</p>

<dl>
<dt>num</dt><dd><p>is the position of the max DBI</p>
</dd>
<dt>Table</dt><dd><p>is the Table of the DBI for all possible combination of the parameters</p>
</dd>
<dt>lam</dt><dd><p>is the best choice of tuning parameter lambda</p>
</dd>
<dt>tau</dt><dd><p>is the best choice of tuning parameter lambda</p>
</dd>
<dt>DBI</dt><dd><p>is the max DBI</p>
</dd>
</dl>
</td></tr>
</table>


<h3>References</h3>

<p>Li, Yang; Bie, Ruofan; Teran Hidalgo, Sebastian; Qin, Yinchen; Wu, Mengyun; Ma, Shuangge.
Assisted gene expression-based clustering with AWNCut. (Submitted.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123456)
#This sets up the initial parameters for the simulation.
lambda &lt;- seq(2,6,1) #Tuning parameter lambda
Tau    &lt;- seq(0.2,0.8,0.2) #Tuning parameter tau

n=30; n1=10; n2=10; n3=n-n1-n2 #Sample size
p1=10; p2=10; r1=8; r2=8; #Number of variables and noises in each dataset

K=3; #Number of clusters

mu=1; #Mean of the marginal distribution
u1=0.5; #Range of enties in the coefficient matrix

library(mvtnorm)
epsilon &lt;- matrix(rnorm(n*(p1-r1),0,1), n, (p1-r1)) # Generation of random error

Sigma1 &lt;- matrix(rep(0.8,(p1-r1)^2),(p1-r1),(p1-r1)) # Generation of the covariance matrix
diag(Sigma1) &lt;- 1

# Generation of the original distribution of the three clusters
T1 &lt;- matrix(rmvnorm(n1,mean=rep(-mu,(p1-r1)),sigma=Sigma1),n1,(p1-r1))
T2 &lt;- matrix(rmvnorm(n2,mean=rep(0,(p1-r1)),sigma=Sigma1),n2,(p1-r1))
T3 &lt;- matrix(rmvnorm(n3,mean=rep(mu,(p1-r1)),sigma=Sigma1),n3,(p1-r1))

X1 &lt;- sign(T1)*(exp(abs(T1))) #Generation of signals in X
X2 &lt;- sign(T2)*(exp(abs(T2)))
X3 &lt;- sign(T3)*(exp(abs(T3)))
ep1 &lt;- (matrix(rnorm(n*r1,0,1),n,r1)) #Generation of noises in X
X &lt;- rbind(X1,X2,X3)

beta1 &lt;- matrix(runif((p1-r1)*(p2-r2),-u1,u1),(p1-r1),(p2-r2)) #Generation of the coefficient matrix
Z     &lt;- X%*%beta1+epsilon #Generation of signals in Z
ep2   &lt;- (matrix(rnorm(n*r2,0.5,1),n,r2)) #Generation of noises in Z

X &lt;- cbind(X,ep1)
Z &lt;- cbind(Z,ep2)
#our method
Tune1         &lt;- awncut.selection(X, Z, K, lambda, Tau, B = 20, L = 1000)
awncut.result &lt;- awncut(X, Z, 3, Tune1$lam, Tune1$tau, B = 20, L = 1000)
ErrorRate(awncut.result[[1]]$Cs, n1, n2)
</code></pre>

<hr>
<h2 id='brca.data.cna'>Data on copy number aberrations from breast cancer patients.</h2><span id='topic+brca.data.cna'></span>

<h3>Description</h3>

<p>A dataset containing copy number aberrations measurements from TCGA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brca.data.cna
</code></pre>


<h3>Format</h3>

<p>A data frame with 873 patients and 515 gene names.</p>


<h3>Source</h3>

<p><a href="https://cancergenome.nih.gov/">https://cancergenome.nih.gov/</a>
</p>

<hr>
<h2 id='brca.data.ge'>Data on gene expression from breast cancer patients.</h2><span id='topic+brca.data.ge'></span>

<h3>Description</h3>

<p>A dataset containing gene expression measurements from TCGA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brca.data.ge
</code></pre>


<h3>Format</h3>

<p>A data frame with 873 patients and 334 gene names.</p>


<h3>Source</h3>

<p><a href="https://cancergenome.nih.gov/">https://cancergenome.nih.gov/</a>
</p>

<hr>
<h2 id='brca.data.rppa'>Data on protein measurements from breast cancer patients.</h2><span id='topic+brca.data.rppa'></span>

<h3>Description</h3>

<p>A dataset containing protein measurements from TCGA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brca.data.rppa
</code></pre>


<h3>Format</h3>

<p>A data frame with 873 patients and 164 gene names.</p>


<h3>Source</h3>

<p><a href="https://cancergenome.nih.gov/">https://cancergenome.nih.gov/</a>
</p>

<hr>
<h2 id='cesc.data.cna'>Data on copy number aberrations from cervical cancer patients.</h2><span id='topic+cesc.data.cna'></span>

<h3>Description</h3>

<p>A dataset containing copy number aberrations from TCGA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cesc.data.cna
</code></pre>


<h3>Format</h3>

<p>A data frame with 164 patients and 488 gene names.</p>


<h3>Source</h3>

<p><a href="https://cancergenome.nih.gov/">https://cancergenome.nih.gov/</a>
</p>

<hr>
<h2 id='cesc.data.ge'>Data on gene expression from breast cancer patients.</h2><span id='topic+cesc.data.ge'></span>

<h3>Description</h3>

<p>A dataset containing gene expression measurements from TCGA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cesc.data.ge
</code></pre>


<h3>Format</h3>

<p>A data frame with 164 patients and 325 gene names.</p>


<h3>Source</h3>

<p><a href="https://cancergenome.nih.gov/">https://cancergenome.nih.gov/</a>
</p>

<hr>
<h2 id='cesc.data.rppa'>Data on protein measurements from cervical cancer patients.</h2><span id='topic+cesc.data.rppa'></span>

<h3>Description</h3>

<p>A dataset containing protein measurements from TCGA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cesc.data.rppa
</code></pre>


<h3>Format</h3>

<p>A data frame with 164 patients and 144 gene names.</p>


<h3>Source</h3>

<p><a href="https://cancergenome.nih.gov/">https://cancergenome.nih.gov/</a>
</p>

<hr>
<h2 id='ErrorRate'>This Function Calculates the True Error Rate of a Clustering Result,
Assuming that There are Three Clusters.</h2><span id='topic+ErrorRate'></span>

<h3>Description</h3>

<p>This Function Calculates the True Error Rate of a Clustering Result,
Assuming that There are Three Clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ErrorRate(X, n1, n2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ErrorRate_+3A_x">X</code></td>
<td>
<p>is a clustering result in matrix format.</p>
</td></tr>
<tr><td><code id="ErrorRate_+3A_n1">n1</code></td>
<td>
<p>is the size of the first cluster.</p>
</td></tr>
<tr><td><code id="ErrorRate_+3A_n2">n2</code></td>
<td>
<p>is the size of the second cluster.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>err is the true error rate of a clustering result.
</p>


<h3>References</h3>

<p>Li, Yang; Bie, Ruofan; Teran Hidalgo, Sebastian; Qin, Yinchen; Wu, Mengyun; Ma, Shuangge.
Assisted gene expression-based clustering with AWNCut. (Submitted.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123456)
#This sets up the initial parameters for the simulation.
lambda &lt;- seq(2,6,1) #Tuning parameter lambda
Tau    &lt;- seq(0.2,0.8,0.2) #Tuning parameter tau

n=30; n1=10; n2=10; n3=n-n1-n2 #Sample size
p1=10; p2=10; r1=8; r2=8; #Number of variables and noises in each dataset

K=3; #Number of clusters

mu=1; #Mean of the marginal distribution
u1=0.5; #Range of enties in the coefficient matrix

library(mvtnorm)
epsilon &lt;- matrix(rnorm(n*(p1-r1),0,1), n, (p1-r1)) # Generation of random error

Sigma1 &lt;- matrix(rep(0.8,(p1-r1)^2),(p1-r1),(p1-r1)) # Generation of the covariance matrix
diag(Sigma1) &lt;- 1

# Generation of the original distribution of the three clusters
T1 &lt;- matrix(rmvnorm(n1,mean=rep(-mu,(p1-r1)),sigma=Sigma1),n1,(p1-r1))
T2 &lt;- matrix(rmvnorm(n2,mean=rep(0,(p1-r1)),sigma=Sigma1),n2,(p1-r1))
T3 &lt;- matrix(rmvnorm(n3,mean=rep(mu,(p1-r1)),sigma=Sigma1),n3,(p1-r1))

X1 &lt;- sign(T1)*(exp(abs(T1))) #Generation of signals in X
X2 &lt;- sign(T2)*(exp(abs(T2)))
X3 &lt;- sign(T3)*(exp(abs(T3)))
ep1 &lt;- (matrix(rnorm(n*r1,0,1),n,r1)) #Generation of noises in X
X &lt;- rbind(X1,X2,X3)

beta1 &lt;- matrix(runif((p1-r1)*(p2-r2),-u1,u1),(p1-r1),(p2-r2)) #Generation of the coefficient matrix
Z     &lt;- X%*%beta1+epsilon #Generation of signals in Z
ep2   &lt;- (matrix(rnorm(n*r2,0.5,1),n,r2)) #Generation of noises in Z

X &lt;- cbind(X,ep1)
Z &lt;- cbind(Z,ep2)
#our method
Tune1         &lt;- awncut.selection(X, Z, K, lambda, Tau, B = 20, L = 1000)
awncut.result &lt;- awncut(X, Z, 3, Tune1$lam, Tune1$tau, B = 20, L = 1000)
ErrorRate(awncut.result[[1]]$Cs, n1, n2)
</code></pre>

<hr>
<h2 id='mlbncut'>The MLBNCut Clusters the Columns and the Rows Simultaneously of Data from 3 Different Sources.</h2><span id='topic+mlbncut'></span>

<h3>Description</h3>

<p>It clusters the columns of Z,Y and X into K clusters and the samples into R clusters by representing
each data type as one network layer.
It represents the Z layer depending on Y, and the Y layer depending on X.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbncut(Z, Y, X, K = 2, R = 2, B = 30, N = 500, q0 = 0.25,
  scale = TRUE, dist = "gaussian", sigmas = 1, sigmac = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbncut_+3A_z">Z</code></td>
<td>
<p>is a n x q matrix of q variables and n observations.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_y">Y</code></td>
<td>
<p>is a n x p matrix of p variables and n observations.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_x">X</code></td>
<td>
<p>is a n x r matrix of r variables and n observations.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_k">K</code></td>
<td>
<p>is the number of column clusters.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_r">R</code></td>
<td>
<p>is the number of row clusters.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_b">B</code></td>
<td>
<p>is the number of iterations.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_n">N</code></td>
<td>
<p>is the number of samples per iterations.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_q0">q0</code></td>
<td>
<p>is the quantiles in the cross entropy method.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_scale">scale</code></td>
<td>
<p>equals TRUE if data Y is to be scaled with mean 0 and variance 1.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_dist">dist</code></td>
<td>
<p>is the type of distance measure use in the similarity matrix.
Options are 'gaussian' and 'correlation', with 'gaussian' being the default.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_sigmas">sigmas</code></td>
<td>
<p>is the tuning parameter of the Gaussian kernel of the samples.</p>
</td></tr>
<tr><td><code id="mlbncut_+3A_sigmac">sigmac</code></td>
<td>
<p>is the tuning parameter of the Gaussian kernel of the variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will output K clusters of columns of Z, Y and X and R clusters of the samples.
</p>
<p>The algorithm minimizes the NCut through the cross entropy method.
The clusters correspond to partitions that minimize this objective function.
</p>


<h3>Value</h3>

<p>A list with the final value of the objective function and
the clusters.
</p>


<h3>References</h3>

<p>Sebastian J. Teran Hidalgo and Shuangge Ma.
Multilayer Biclustering of Omics Data using MLBNCut. (Work in progress.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This sets up the initial parameters for the simulation.
library(NCutYX)
library(MASS)
library(fields)

n   &lt;- 50
p   &lt;- 50
h   &lt;- 0.15
rho &lt;- 0.15
mu  &lt;- 1

W0 &lt;- matrix(1,p,p)
W0[1:(p/5),1:(p/5)] &lt;- 0
W0[(p/5+1):(3*p/5),(p/5+1):(3*p/5)] &lt;- 0
W0[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)] &lt;- 0
W0[(4*p/5+1):p,(4*p/5+1):p]=0
W0=cbind(W0,W0,W0)
W0=rbind(W0,W0,W0)

W1 &lt;- matrix(1,n,n)
W1[1:(n/2),1:(n/2)] &lt;- 0
W1[(n/2+1):n,(n/2+1):n] &lt;- 0

X &lt;- matrix(0,n,p)
Y &lt;- matrix(0,n,p)
Z &lt;- matrix(0,n,p)

Sigma=matrix(0,p,p)
Sigma[1:(p/5),1:(p/5)] &lt;- rho
Sigma[(p/5+1):(3*p/5),(p/5+1):(3*p/5)] &lt;- rho
Sigma[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)] &lt;- rho
Sigma[(4*p/5+1):p,(4*p/5+1):p] &lt;- rho
Sigma &lt;- Sigma - diag(diag(Sigma))
Sigma &lt;- Sigma + diag(p)

X[1:(n/2),]   &lt;- mvrnorm(n/2,rep(mu,p),Sigma)
X[(n/2+1):n,] &lt;- mvrnorm(n/2,rep(-mu,p),Sigma)

B11 &lt;- matrix(0,p,p)
B12 &lt;- matrix(0,p,p)
B21 &lt;- matrix(0,p,p)
B22 &lt;- matrix(0,p,p)

B11[1:(p/5),1:(p/5)]                     &lt;- runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.5)
B11[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]     &lt;- runif((2*p/5)^2,h/2,h)*rbinom((2*p/5)^2,1,0.5)
B11[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)] &lt;- runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.5)
B11[(4*p/5+1):p,(4*p/5+1):p]             &lt;- runif((1*p/5)^2,h/2,h)*rbinom((1*p/5)^2,1,0.5)

B12[1:(p/5),1:(p/5)]                     &lt;- runif((p/5)^2,-h,-h/2)*rbinom((p/5)^2,1,0.5)
B12[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]     &lt;- runif((2*p/5)^2,-h,-h/2)*rbinom((2*p/5)^2,1,0.5)
B12[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)] &lt;- runif((p/5)^2,-h,-h/2)*rbinom((p/5)^2,1,0.5)
B12[(4*p/5+1):p,(4*p/5+1):p]             &lt;- runif((1*p/5)^2,-h,-h/2)*rbinom((1*p/5)^2,1,0.5)

B21[1:(p/5),1:(p/5)]                     &lt;- runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.5)
B21[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]     &lt;- runif((2*p/5)^2,h/2,h)*rbinom((2*p/5)^2,1,0.5)
B21[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)] &lt;- runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.5)
B21[(4*p/5+1):p,(4*p/5+1):p]             &lt;- runif((1*p/5)^2,h/2,h)*rbinom((1*p/5)^2,1,0.5)

B22[1:(p/5),1:(p/5)]                     &lt;- runif((p/5)^2,-h,-h/2)*rbinom((p/5)^2,1,0.5)
B22[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]     &lt;- runif((2*p/5)^2,-h,-h/2)*rbinom((2*p/5)^2,1,0.5)
B22[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)] &lt;- runif((p/5)^2,-h,-h/2)*rbinom((p/5)^2,1,0.5)
B22[(4*p/5+1):p,(4*p/5+1):p]             &lt;- runif((1*p/5)^2,-h,-h/2)*rbinom((1*p/5)^2,1,0.5)

Y[1:(n/2),]   &lt;- X[1:(n/2),]%*%B11+matrix(rnorm((n/2)*p,0,0.25),n/2,p)
Y[(n/2+1):n,] &lt;- X[(n/2+1):n,]%*%B12+matrix(rnorm((n/2)*p,0,0.25),n/2,p)

Z[1:(n/2),]   &lt;- Y[1:(n/2),]%*%B21+matrix(rnorm((n/2)*p,0,0.25),n/2,p)
Z[(n/2+1):n,] &lt;- Y[(n/2+1):n,]%*%B22+matrix(rnorm((n/2)*p,0,0.25),n/2,p)

trial &lt;- mlbncut(Z,
                 Y,
                 X,
                 K=4,
                 R=2,
                 B=10,
                 N=50,
                 dist='correlation',
                 q0=0.15,
                 scale=TRUE,
                 sigmas=0.05,
                 sigmac=1)

plot(trial[[1]],type='l')
image.plot(trial[[2]])
image.plot(trial[[3]])

errorK &lt;- sum((trial[[3]][,1]%*%t(trial[[3]][,1]) +
                 trial[[3]][,2]%*%t(trial[[3]][,2]) +
                 trial[[3]][,3]%*%t(trial[[3]][,3]) +
                 trial[[3]][,4]%*%t(trial[[3]][,4]))*W0)/(3*p)^2 +
            sum((trial[[2]][,1]%*%t(trial[[2]][,1]) +
                 trial[[2]][,2]%*%t(trial[[2]][,2]))*W1)/(n)^2
errorK
</code></pre>

<hr>
<h2 id='muncut'>MuNCut Clusters the Columns of Data from 3 Different Sources.</h2><span id='topic+muncut'></span>

<h3>Description</h3>

<p>It clusters the columns of Z,Y and X into K clusters by representing each data type as one network layer.
It represents the Z layer depending on Y, and the Y layer depending on X. Elastic net can be used before the clustering
procedure by using the predictions of Z and Y instead of the actual values to improve the cluster results.
This function will output K clusters of columns of Z, Y and X.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>muncut(Z, Y, X, K = 2, B = 3000, L = 1000, alpha = 0.5, ncv = 3,
  nlambdas = 100, scale = FALSE, model = FALSE, gamma = 0.5,
  sampling = "equal", dist = "gaussian", sigma = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="muncut_+3A_z">Z</code></td>
<td>
<p>is a n x q matrix of q variables and n observations.</p>
</td></tr>
<tr><td><code id="muncut_+3A_y">Y</code></td>
<td>
<p>is a n x p matrix of p variables and n observations.</p>
</td></tr>
<tr><td><code id="muncut_+3A_x">X</code></td>
<td>
<p>is a n x r matrix of r variables and n observations.</p>
</td></tr>
<tr><td><code id="muncut_+3A_k">K</code></td>
<td>
<p>is the number of column clusters.</p>
</td></tr>
<tr><td><code id="muncut_+3A_b">B</code></td>
<td>
<p>is the number of iterations in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="muncut_+3A_l">L</code></td>
<td>
<p>is the temperature coefficient in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="muncut_+3A_alpha">alpha</code></td>
<td>
<p>is the tuning parameter in the elastic net penalty, only used when model=T.</p>
</td></tr>
<tr><td><code id="muncut_+3A_ncv">ncv</code></td>
<td>
<p>is the number of cross-validations used to choose the tuning parameter lambda in the
elastic net penalty, only used when model=T.</p>
</td></tr>
<tr><td><code id="muncut_+3A_nlambdas">nlambdas</code></td>
<td>
<p>number of tuning parameters lambda used during cross-validation, only when model=T.</p>
</td></tr>
<tr><td><code id="muncut_+3A_scale">scale</code></td>
<td>
<p>when TRUE the Z, Y and X are scaled with mean 0 and standard deviation equal 1.</p>
</td></tr>
<tr><td><code id="muncut_+3A_model">model</code></td>
<td>
<p>when TRUE the the relationship between Z and Y, and between Y and X are modeled
with the elastic net. The predictions of Z, and Y from the models are used in the clustering algorithm.</p>
</td></tr>
<tr><td><code id="muncut_+3A_gamma">gamma</code></td>
<td>
<p>is the tuning parameter of the clustering penalty. Larger values give more importance to
within layer effects and less to across layer effects.</p>
</td></tr>
<tr><td><code id="muncut_+3A_sampling">sampling</code></td>
<td>
<p>if 'equal' then the sampling distribution is discrete uniform over the
number of clusters, if 'size' the probabilities are inversely proportional to the size
of each cluster.</p>
</td></tr>
<tr><td><code id="muncut_+3A_dist">dist</code></td>
<td>
<p>is the type of distance measure use in the similarity matrix.
Options are 'gaussian' and 'correlation', with 'gaussian' being the default.</p>
</td></tr>
<tr><td><code id="muncut_+3A_sigma">sigma</code></td>
<td>
<p>is the bandwidth parameter when the dist metric chosen is gaussian.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm minimizes a modified version of NCut through simulated annealing.
The clusters correspond to partitions that minimize this objective function.
The external information of X is incorporated by using ridge regression to predict Y.
</p>


<h3>References</h3>

<p>Sebastian J. Teran Hidalgo and Shuangge Ma.
Clustering Multilayer Omics Data using MuNCut. (Revise and resubmit.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(NCutYX)
library(MASS)
library(fields) #for image.plot

#parameters#
set.seed(777)
n=50
p=50
h=0.5
rho=0.5

W0=matrix(1,p,p)
W0[1:(p/5),1:(p/5)]=0
W0[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]=0
W0[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)]=0
W0[(4*p/5+1):p,(4*p/5+1):p]=0
W0=cbind(W0,W0,W0)
W0=rbind(W0,W0,W0)

Y=matrix(0,n,p)
Z=matrix(0,n,p)
Sigma=matrix(rho,p,p)
Sigma[1:(p/5),1:(p/5)]=2*rho
Sigma[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]=2*rho
Sigma[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)]=2*rho
Sigma=Sigma-diag(diag(Sigma))
Sigma=Sigma+diag(p)

X=mvrnorm(n,rep(0,p),Sigma)
B1=matrix(0,p,p)
B2=matrix(0,p,p)

B1[1:(p/5),1:(p/5)]=runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.2)
B1[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]=runif((2*p/5)^2,h/2,h)*rbinom((2*p/5)^2,1,0.2)
B1[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)]=runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.2)

B2[1:(p/5),1:(p/5)]=runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.2)
B2[(p/5+1):(3*p/5),(p/5+1):(3*p/5)]=runif((2*p/5)^2,h/2,h)*rbinom((2*p/5)^2,1,0.2)
B2[(3*p/5+1):(4*p/5),(3*p/5+1):(4*p/5)]=runif((p/5)^2,h/2,h)*rbinom((p/5)^2,1,0.2)

Y=X%*%B1+matrix(rnorm(n*p,0,0.5),n,p)
Y2=X%*%B1

Z=Y%*%B2+matrix(rnorm(n*p,0,0.5),n,p)
Z2=Y%*%B2

#Computing our method
clust &lt;- muncut(Z,
                Y,
                X,
                K        = 4,
                B        = 10000,
                L        = 500,
                sampling = 'size',
                alpha    = 0.5,
                ncv      = 3,
                nlambdas = 20,
                sigma    = 10,
                scale    = TRUE,
                model    = FALSE,
                gamma    = 0.1)

A &lt;- clust[[2]][,1]%*%t(clust[[2]][,1])+
     clust[[2]][,2]%*%t(clust[[2]][,2])+
     clust[[2]][,3]%*%t(clust[[2]][,3])+
     clust[[2]][,4]%*%t(clust[[2]][,4])

errorK=sum(A*W0)/(3*p)^2
errorK
plot(clust[[1]],type='l')
image.plot(A)
</code></pre>

<hr>
<h2 id='ncut'>Cluster the Columns of Y into K Groups Using the NCut Graph Measure.</h2><span id='topic+ncut'></span>

<h3>Description</h3>

<p>Builds a similarity matrix for the columns of Y and clusters them into
K groups based on the NCut graph measure. Correlation, Euclidean and Gaussian distances can be used
to construct the similarity matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ncut(Y, K = 2, B = 30, N = 500, dist = "correlation", scale = TRUE,
  q = 0.1, sigma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ncut_+3A_y">Y</code></td>
<td>
<p>is a n x p matrix of p variables and n observations. The p columns of
Y will be clustered into K groups using NCut.</p>
</td></tr>
<tr><td><code id="ncut_+3A_k">K</code></td>
<td>
<p>is the number of clusters.</p>
</td></tr>
<tr><td><code id="ncut_+3A_b">B</code></td>
<td>
<p>is the number of iterations.</p>
</td></tr>
<tr><td><code id="ncut_+3A_n">N</code></td>
<td>
<p>is the number of samples per iterations.</p>
</td></tr>
<tr><td><code id="ncut_+3A_dist">dist</code></td>
<td>
<p>is the type of distance metric for the construction of the similarity matrix.
Options are 'gaussian', 'euclidean' and 'correlation', the latter being the default.</p>
</td></tr>
<tr><td><code id="ncut_+3A_scale">scale</code></td>
<td>
<p>equals TRUE if data Y is to be scaled with mean 0 and variance 1.</p>
</td></tr>
<tr><td><code id="ncut_+3A_q">q</code></td>
<td>
<p>is the quantile used for the top results at each iterations.</p>
</td></tr>
<tr><td><code id="ncut_+3A_sigma">sigma</code></td>
<td>
<p>is the bandwidth parameter when the dist metric chosen is 'gaussian' (default=0.1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm minimizes the NCut through the cross entropy method.
The edges of the graph correspond to the entries of a similarity matrix constructed based on a
correlation, euclidean or gaussian distance metric.
The clusters correspond to partitions that minimize this NCut objective function.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>

<dl>
<dt>quantile</dt><dd><p>a vector of length <code>N</code> which contains the quantiles
<code>q</code> at each iteration of the optimization algorithm.</p>
</dd>
<dt>cluster</dt><dd><p>a matrix representing the clustering result of dimension <code>p</code> times
<code>K</code>, where <code>p</code> is the number of columns of <code>Y</code>.</p>
</dd>
<dt>ncut</dt><dd><p>the NCut measure for the cluster result.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Sebastian Jose Teran Hidalgo. Maintainer: Sebastian Jose Teran Hidalgo
<a href="sebastianteranhidalgo@gmail.com">sebastianteranhidalgo@gmail.com</a>.
</p>


<h3>References</h3>

<p>Von Luxburg, Ulrike. &quot;A tutorial on spectral clustering.&quot;
Statistics and computing 17.4 (2007): 395-416.
</p>
<p>Kroese, D. P., Rubinstein, R. Y., Cohen, I., Porotsky, S., &amp; Taimre, T. (2013).
&quot;Cross-entropy method.&quot;
In Encyclopedia of Operations Research and Management Science (pp. 326-333). Springer US.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This sets up the initial parameters for the simulation.
library(MASS)
n=100 # Sample size
B=30 # Number of iterations in the simulated annealing algorithm.
p=50 # Number of columns of Y.

S=matrix(0.2,p,p)
S[1:(p/2),(p/2+1):p]=0
S[(p/2+1):p,1:(p/2)]=0
S=S-diag(diag(S))+diag(p)
mu=rep(0,p)

W0=matrix(1,p,p)
W0[1:(p/2),1:(p/2)]=0
W0[(p/2+1):p,(p/2+1):p]=0
Denum=sum(W0)

Y=mvrnorm(n, mu, S)
# NCut
Res=ncut(Y,
K=2,
B=30,
N=1000,
dist='correlation',
scale=TRUE,
q=0.2,
sigma=0.1)
Cx=Res[[2]]
f11=matrix(Cx[,1],p,1)
f12=matrix(Cx[,2],p,1)

errorL=sum((f11%*%t(f11))*W0)/Denum+sum((f12%*%t(f12))*W0)/Denum
# This is the true error of the clustering solution.
errorL
</code></pre>

<hr>
<h2 id='pwncut'>Cluster the Columns of X into K Clusters by Giving a Weighted Cluster Membership while shrinking
Weights Towards Each Other.</h2><span id='topic+pwncut'></span>

<h3>Description</h3>

<p>This function will output K channels of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwncut(X, K = 2, B = 3000, L = 1000, scale = TRUE, lambda = 1,
  epsilon = 0, nstarts = 3, start = "default", dist = "gaussian",
  sigma = 0.1, beta = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwncut_+3A_x">X</code></td>
<td>
<p>is a n x p matrix of p variables and n observations.</p>
</td></tr>
<tr><td><code id="pwncut_+3A_k">K</code></td>
<td>
<p>is the number of clusters.</p>
</td></tr>
<tr><td><code id="pwncut_+3A_b">B</code></td>
<td>
<p>is the number of iterations in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="pwncut_+3A_l">L</code></td>
<td>
<p>is the temperature coefficient in the simulated annealing algorithm.</p>
</td></tr>
<tr><td><code id="pwncut_+3A_scale">scale</code></td>
<td>
<p>equals TRUE if data X is to be scaled with mean 0 and variance 1.</p>
</td></tr>
<tr><td><code id="pwncut_+3A_lambda">lambda</code></td>
<td>
<p>the tuning parameter of the penalty. Larger values shrink the weighted
cluster membership closer together (default = 1).</p>
</td></tr>
<tr><td><code id="pwncut_+3A_epsilon">epsilon</code></td>
<td>
<p>values in the similarity matrix less than epsilon are set to 0 (default = 0).</p>
</td></tr>
<tr><td><code id="pwncut_+3A_nstarts">nstarts</code></td>
<td>
<p>the number of starting values also corresponding how many times simulated
annealing is run. Larger values provide better results but takes longer.</p>
</td></tr>
<tr><td><code id="pwncut_+3A_start">start</code></td>
<td>
<p>if it equals 'default' then the starting value for all weights is 1/K. If
'random' then weights are sampled from a uniform distribution and then scaled to sum 1
per variable.</p>
</td></tr>
<tr><td><code id="pwncut_+3A_dist">dist</code></td>
<td>
<p>specifies the distance metric used for constructing the similarity matrix.
Options are 'gaussian', 'correlation' and 'euclidean' (default = 'gaussian').</p>
</td></tr>
<tr><td><code id="pwncut_+3A_sigma">sigma</code></td>
<td>
<p>is the bandwidth parameter when the dist metric chosen is 'gaussian' (default = 0.1).</p>
</td></tr>
<tr><td><code id="pwncut_+3A_beta">beta</code></td>
<td>
<p>when dist='correlation', beta is the exponent applied to each entry of the
similarity matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm minimizes a modified version of NCut through simulated annealing.
The clusters correspond to partitions that minimize this objective function.
</p>


<h3>References</h3>

<p>Sebastian J. Teran Hidalgo, Mengyun Wu and Shuangge Ma.
Penalized and weighted clustering of gene expression data using PWNCut. (Submitted.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This sets up the initial parameters for the simulation.
n &lt;- 100 # Sample size
p &lt;- 100 # Number of columns of Y.
K &lt;- 3

C0            &lt;- matrix(0,p,K)
C0[1:25,1]    &lt;- matrix(1,25,1)
C0[26:75,1:3] &lt;- matrix(1/3,50,3)
C0[76:100,3]  &lt;- matrix(1,25,1)

A0 &lt;- C0[ ,1]%*%t(C0[ ,1]) + C0[ ,2]%*%t(C0[ ,2]) +
      C0[ ,3]%*%t(C0[ ,3])
A0 &lt;- A0 - diag(diag(A0)) + diag(p)

Z1 &lt;- rnorm(n,0,2)
Z2 &lt;- rnorm(n,0,2)
Z3 &lt;- rnorm(n,0,2)

Y &lt;- matrix(0,n,p)
Y[ ,1:25]   &lt;-  matrix(rnorm(n*25, 0, 2), n, 25) + matrix(Z1, n, 25, byrow=FALSE)
Y[ ,26:75]  &lt;-  matrix(rnorm(n*50, 0, 2), n, 50) + matrix(Z1, n, 50, byrow=FALSE) +
                matrix(Z2, n, 50, byrow=FALSE) + matrix(Z3, n, 50, byrow=FALSE)
Y[ ,76:100] &lt;-  matrix(rnorm(n*25, 0, 2), n, 25) + matrix(Z3, n, 25, byrow=FALSE)

trial &lt;- pwncut(Y,
                K       = 3,
                B       = 10000,
                L       = 1000,
                lambda  = 1.5,
                start   = 'default',
                scale   = TRUE,
                nstarts = 1,
                epsilon = 0,
                dist    = 'correlation',
                sigma   = 10)

A1 &lt;- trial[[2]][ ,1]%*%t(trial[[2]][ ,1]) +
      trial[[2]][ ,2]%*%t(trial[[2]][ ,2]) +
      trial[[2]][ ,3]%*%t(trial[[2]][ ,3])

A1 &lt;- A1 - diag(diag(A1)) + diag(p)

plot(trial[[1]], type='l')
errorL &lt;- sum(abs(A0-A1))/p^2
errorL
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
