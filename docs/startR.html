<!DOCTYPE html><html lang="en"><head><title>Help for package startR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {startR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AddStep'><p>Create the workflow with the previous defined operation and data.</p></a></li>
<li><a href='#CDORemapper'><p>CDO Remap Data Transformation for 'startR'</p></a></li>
<li><a href='#Collect'><p>Collect and merge the computation results</p></a></li>
<li><a href='#Compute'><p>Specify the execution parameters and trigger the execution</p></a></li>
<li><a href='#indices'><p>Specify dimension selectors with indices</p></a></li>
<li><a href='#NcCloser'><p>NetCDF file closer for 'startR'</p></a></li>
<li><a href='#NcDataReader'><p>NetCDF file data reader for 'startR'</p></a></li>
<li><a href='#NcDimReader'><p>NetCDF dimension reader for 'startR'</p></a></li>
<li><a href='#NcOpener'><p>NetCDF file opener for 'startR'</p></a></li>
<li><a href='#NcVarReader'><p>NetCDF variable reader for 'startR'</p></a></li>
<li><a href='#SelectorChecker'><p>Translate a set of selectors into a set of numeric indices</p></a></li>
<li><a href='#Sort'><p>Sort the coordinate variable values in a Start() call</p></a></li>
<li><a href='#Start'><p>Declare, discover, subset and retrieve multidimensional distributed data sets</p></a></li>
<li><a href='#Step'><p>Define the operation applied on declared data.</p></a></li>
<li><a href='#values'><p>Specify dimension selectors with actual values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Automatically Retrieve Multidimensional Distributed Data Sets</td>
</tr>
<tr>
<td>Version:</td>
<td>2.4.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Tool to automatically fetch, transform and arrange subsets of
    multi- dimensional data sets (collections of files) stored in local and/or
    remote file systems or servers, using multicore capabilities where possible.
    The tool provides an interface to perceive a collection of data sets as a single
    large multidimensional data array, and enables the user to request for automatic
    retrieval, processing and arrangement of subsets of the large array. Wrapper
    functions to add support for custom file formats can be plugged in/out, making
    the tool suitable for any research field where large multidimensional data sets
    are involved.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, bigmemory, future, multiApply (&ge; 2.1.0), parallel,
easyNCDF, s2dv, ClimProjDiags, PCICt, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>stats, utils, testthat, yaml</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://earth.bsc.es/gitlab/es/startR/">https://earth.bsc.es/gitlab/es/startR/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://earth.bsc.es/gitlab/es/startR/-/issues">https://earth.bsc.es/gitlab/es/startR/-/issues</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>cdo ecFlow</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-10 12:01:59 UTC; vagudets</td>
</tr>
<tr>
<td>Author:</td>
<td>Nicolau Manubens [aut],
  An-Chi Ho <a href="https://orcid.org/0000-0002-4182-5258"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Nuria Perez-Zanon <a href="https://orcid.org/0000-0001-8568-3071"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Eva Rifa [ctb],
  Victoria Agudetse [cre, ctb],
  Bruno de Paula Kinoshita [ctb],
  Javier Vegas [ctb],
  Pierre-Antoine Bretonniere [ctb],
  Roberto Serrano [ctb],
  BSC-CNS [aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Victoria Agudetse &lt;victoria.agudetse@bsc.es&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-19 22:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='AddStep'>Create the workflow with the previous defined operation and data.</h2><span id='topic+AddStep'></span>

<h3>Description</h3>

<p>The step that combines the previous declared data and operation together to 
create the complete workflow. It is the final step before data processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AddStep(inputs, step_fun, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AddStep_+3A_inputs">inputs</code></td>
<td>
<p>One or a list of objects of the class 'startR_cube' returned by 
Start(), indicating the data to be processed.</p>
</td></tr>
<tr><td><code id="AddStep_+3A_step_fun">step_fun</code></td>
<td>
<p>A startR step function as returned by Step().</p>
</td></tr>
<tr><td><code id="AddStep_+3A_...">...</code></td>
<td>
<p>Additional parameters for the inputs of function defined in 
'step_fun' by Step().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the class 'startR_workflow' containing all the objects 
needed for the data operation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = 'all',
               longitude = 'all',
               return_vars = list(latitude = 'dat',
                                  longitude = 'dat',
                                  time = 'sdate'),
               retrieve = FALSE)
 pi_short &lt;- 3.14
 fun &lt;- function(x, pi_val) {
           lat = attributes(x)$Variables$dat1$latitude
           weight = sqrt(cos(lat * pi_val / 180))
           corrected = Apply(list(x), target_dims = "latitude",
                             fun = function(x) {x * weight})
         }


 step &lt;- Step(fun = fun,
              target_dims = 'latitude',
              output_dims = 'latitude',
              use_libraries = c('multiApply'),
              use_attributes = list(data = "Variables"))
 wf &lt;- AddStep(data, step, pi_val = pi_short)

</code></pre>

<hr>
<h2 id='CDORemapper'>CDO Remap Data Transformation for 'startR'</h2><span id='topic+CDORemapper'></span>

<h3>Description</h3>

<p>This is a transform function that uses CDO software to remap longitude-latitude 
data subsets onto a specified target grid, intended for use as parameter 
'transform' in a Start() call. This function complies with the input/output 
interface required by Start() defined in the documentation for the parameter 
'transform' of function Start().<br /><br />
This function uses the function CDORemap() in the package 's2dv' to 
perform the interpolation, hence CDO is required to be installed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CDORemapper(
  data_array,
  variables,
  file_selectors = NULL,
  crop_domain = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CDORemapper_+3A_data_array">data_array</code></td>
<td>
<p>A data array to be transformed. See details in the 
documentation of the parameter 'transform' of the function Start().</p>
</td></tr>
<tr><td><code id="CDORemapper_+3A_variables">variables</code></td>
<td>
<p>A list of auxiliary variables required for the transformation, 
automatically provided by Start(). See details in the documentation of the 
parameter 'transform' of the function Start().</p>
</td></tr>
<tr><td><code id="CDORemapper_+3A_file_selectors">file_selectors</code></td>
<td>
<p>A charcter vector indicating the information of the path of
the file parameter 'data_array' comes from. See details in the documentation of
the parameter 'transform' of the function Start(). The default value is NULL.</p>
</td></tr>
<tr><td><code id="CDORemapper_+3A_crop_domain">crop_domain</code></td>
<td>
<p>A list of the transformed domain of each transform 
variable, automatically provided by Start().</p>
</td></tr>
<tr><td><code id="CDORemapper_+3A_...">...</code></td>
<td>
<p>A list of additional parameters to adjust the transform process, 
as provided in the parameter 'transform_params' in a Start() call. See details
in the documentation of the parameter 'transform' of the function Start().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An array with the same amount of dimensions as the input data array, 
potentially with different sizes, and potentially with the attribute 
'variables' with additional auxiliary data. See details in the documentation 
of the parameter 'transform' of the function Start().
</p>


<h3>See Also</h3>

<p><code><a href="s2dv.html#topic+CDORemap">CDORemap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Used in Start():
 data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011')
 ## Not run: 
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = values(list(-60, 60)),
               latitude_reorder = Sort(decreasing = TRUE),
               longitude = values(list(-120, 120)),
               longitude_reorder = CircularSort(-180, 180),
               transform = CDORemapper,
               transform_params = list(grid = 'r360x181',
                                       method = 'conservative'),
               transform_vars = c('latitude', 'longitude'),
               return_vars = list(latitude = 'dat',
                                  longitude = 'dat',
                                  time = 'sdate'),
               retrieve = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='Collect'>Collect and merge the computation results</h2><span id='topic+Collect'></span>

<h3>Description</h3>

<p>The final step of the startR workflow after the data operation. It is used when
the parameter 'wait' of Compute() is FALSE. It combines all the chunks of the
results as one data array when the execution is done. See more details on 
<a href="https://earth.bsc.es/gitlab/es/startR/-/blob/master/inst/doc/practical_guide.md">practical guide</a>.
Collect() calls Collect_ecflow() or Collect_autosubmit() according to the 
chosen workflow manager.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Collect(startr_exec, wait = TRUE, remove = TRUE, on_remote = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Collect_+3A_startr_exec">startr_exec</code></td>
<td>
<p>An R object returned by Compute() when the parameter 'wait'
of Compute() is FALSE. It can be directly from a Compute() call or read from
the RDS file.</p>
</td></tr>
<tr><td><code id="Collect_+3A_wait">wait</code></td>
<td>
<p>A logical value deciding whether the R session waits for the 
Collect() call to finish (TRUE) or not (FALSE). If TRUE, it will be a 
blocking call, in which Collect() will retrieve information from the HPC,
including signals and outputs, each polling_period seconds. The the status
can be monitored on the workflow manager GUI. Collect() will not return  
until the results of all the chunks have been received. If FALSE, Collect()
return an error if the execution has not finished, otherwise it will return
the merged array. The default value is TRUE.</p>
</td></tr>
<tr><td><code id="Collect_+3A_remove">remove</code></td>
<td>
<p>A logical value deciding whether to remove of all chunk results 
received from the HPC after data being collected, as well as the local job 
folder under 'ecflow_suite_dir' or 'autosubmit_suite_dir'. To preserve the
data and Collect() them as many times as desired, set remove to FALSE. The
default value is TRUE.</p>
</td></tr>
<tr><td><code id="Collect_+3A_on_remote">on_remote</code></td>
<td>
<p>A logical value deciding to the function is run locally and
sync the outputs back from HPC (FALSE, default), or it is run on HPC 
(TRUE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of merged data array.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = 'all',
               longitude = 'all',
               return_vars = list(latitude = 'dat',
                                  longitude = 'dat',
                                  time = 'sdate'),
               retrieve = FALSE)
 fun &lt;- function(x) {
           lat = attributes(x)$Variables$dat1$latitude
           weight = sqrt(cos(lat * pi / 180))
           corrected = Apply(list(x), target_dims = "latitude",
                             fun = function(x) {x * weight})
         }
 step &lt;- Step(fun = fun,
              target_dims = 'latitude',
              output_dims = 'latitude',
              use_libraries = c('multiApply'),
              use_attributes = list(data = "Variables"))
 wf &lt;- AddStep(data, step)
 ## Not run: 
 res &lt;- Compute(wf, chunks = list(longitude = 2, sdate = 2),
                threads_load = 1,
                threads_compute = 4,
                cluster = list(queue_host = 'nord3',
                               queue_type = 'lsf',
                               temp_dir = '/on_hpc/tmp_dir/',
                               cores_per_job = 2,
                               job_wallclock = '05:00',
                               max_jobs = 4,
                               extra_queue_params = list('#BSUB -q bsc_es'),
                               bidirectional = FALSE,
                               polling_period = 10
                ),
                ecflow_suite_dir = '/on_local_machine/username/ecflow_dir/',
                wait = FALSE)
 saveRDS(res, file = 'test_collect.Rds')
 collect_info &lt;- readRDS('test_collect.Rds')
 result &lt;- Collect(collect_info, wait = TRUE)
 
## End(Not run)

</code></pre>

<hr>
<h2 id='Compute'>Specify the execution parameters and trigger the execution</h2><span id='topic+Compute'></span>

<h3>Description</h3>

<p>The step of the startR workflow after the complete workflow is defined by 
AddStep(). This function specifies the execution parameters and triggers the
execution. The execution can be operated locally or on a remote machine. If 
it is the latter case, the configuration of the machine needs to be 
sepecified in the function, and the EC-Flow server is required to be 
installed.<br /><br />
The execution can be operated by chunks to avoid overloading the RAM memory.
After all the chunks are finished, Compute() will gather and merge them, and 
return a single data object, including one or multiple multidimensional data 
arrays and additional metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Compute(
  workflow,
  chunks = "auto",
  workflow_manager = "ecFlow",
  threads_load = 1,
  threads_compute = 1,
  cluster = NULL,
  ecflow_suite_dir = NULL,
  ecflow_server = NULL,
  autosubmit_suite_dir = NULL,
  autosubmit_server = NULL,
  silent = FALSE,
  debug = FALSE,
  wait = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Compute_+3A_workflow">workflow</code></td>
<td>
<p>A list of the class 'startR_workflow' returned by function 
AddSteop() or of class 'startR_cube' returned by function Start(). It 
contains all the objects needed for the execution.</p>
</td></tr>
<tr><td><code id="Compute_+3A_chunks">chunks</code></td>
<td>
<p>A named list of dimensions which to split the data along and 
the number of chunks to make for each. The chunked dimension can only be 
those not required as the target dimension in function Step(). The default
value is 'auto', which lists all the non-target dimensions and each one has
one chunk.</p>
</td></tr>
<tr><td><code id="Compute_+3A_workflow_manager">workflow_manager</code></td>
<td>
<p>Can be NULL, 'ecFlow' or 'Autosubmit'. The default is
'ecFlow'.</p>
</td></tr>
<tr><td><code id="Compute_+3A_threads_load">threads_load</code></td>
<td>
<p>An integer indicating the number of parallel execution
cores to use for the data retrieval stage. The default value is 1.</p>
</td></tr>
<tr><td><code id="Compute_+3A_threads_compute">threads_compute</code></td>
<td>
<p>An integer indicating the number of parallel execution
cores to use for the computation. The default value is 1.</p>
</td></tr>
<tr><td><code id="Compute_+3A_cluster">cluster</code></td>
<td>
<p>A list of components that define the configuration of the 
machine to be run on. The comoponents vary from the different machines.
Check <a href="https://earth.bsc.es/gitlab/es/startR/-/blob/master/inst/doc/practical_guide.md">Practical guide on GitLab</a> for more 
details and examples. Only needed when the computation is not run locally. 
The default value is NULL.</p>
</td></tr>
<tr><td><code id="Compute_+3A_ecflow_suite_dir">ecflow_suite_dir</code></td>
<td>
<p>A character string indicating the path to a folder in
the local workstation where to store temporary files generated for the 
automatic management of the workflow. Only needed when the execution is run
remotely. The default value is NULL.</p>
</td></tr>
<tr><td><code id="Compute_+3A_ecflow_server">ecflow_server</code></td>
<td>
<p>A named vector indicating the host and port of the 
EC-Flow server. The vector form should be 
<code>c(host = 'hostname', port = port_number)</code>. Only needed when the 
execution is run remotely. The default value is NULL.</p>
</td></tr>
<tr><td><code id="Compute_+3A_autosubmit_suite_dir">autosubmit_suite_dir</code></td>
<td>
<p>A character string indicating the path to a folder
where to store temporary files generated for the automatic management of the
workflow manager. This path should be available in local workstation as well
as autosubmit machine. The default value is NULL, and a temporary folder 
under the current working folder will be created.</p>
</td></tr>
<tr><td><code id="Compute_+3A_autosubmit_server">autosubmit_server</code></td>
<td>
<p>A character vector indicating the login node of the 
autosubmit machine. It can be &quot;bscesautosubmit01&quot; or &quot;bscesautosubmit02&quot;. 
The default value is NULL, and the node will be randomly chosen.</p>
</td></tr>
<tr><td><code id="Compute_+3A_silent">silent</code></td>
<td>
<p>A logical value deciding whether to print the computation 
progress (FALSE) on the R session or not (TRUE). It only works when the 
execution runs locally or the parameter 'wait' is TRUE. The default value
is FALSE.</p>
</td></tr>
<tr><td><code id="Compute_+3A_debug">debug</code></td>
<td>
<p>A logical value deciding whether to return detailed messages on 
the progress and operations in a Compute() call (TRUE) or not (FALSE). 
Automatically changed to FALSE if parameter 'silent' is TRUE. The default 
value is FALSE.</p>
</td></tr>
<tr><td><code id="Compute_+3A_wait">wait</code></td>
<td>
<p>A logical value deciding whether the R session waits for the 
Compute() call to finish (TRUE) or not (FALSE). If FALSE, it will return an
object with all the information of the startR execution that can be stored
in your disk. After that, the R session can be closed and the results can
be collected later with the Collect() function. The default value is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of data arrays for the output returned by the last step in the
specified workflow (wait = TRUE), or an object with information about the 
startR execution (wait = FALSE). The configuration details and profiling 
information are attached as attributes to the returned list of arrays.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = 'all',
               longitude = 'all',
               return_vars = list(latitude = 'dat',
                                  longitude = 'dat',
                                  time = 'sdate'),
               retrieve = FALSE)
 fun &lt;- function(x) {
           lat = attributes(x)$Variables$dat1$latitude
           weight = sqrt(cos(lat * pi / 180))
           corrected = Apply(list(x), target_dims = "latitude",
                             fun = function(x) {x * weight})
         }
 step &lt;- Step(fun = fun,
              target_dims = 'latitude',
              output_dims = 'latitude',
              use_libraries = c('multiApply'),
              use_attributes = list(data = "Variables"))
 wf &lt;- AddStep(data, step)
 res &lt;- Compute(wf, chunks = list(longitude = 4, sdate = 2))

</code></pre>

<hr>
<h2 id='indices'>Specify dimension selectors with indices</h2><span id='topic+indices'></span>

<h3>Description</h3>

<p>This is a helper function used in a Start() call to define the desired range
of dimensions. It selects the indices of the coordinate variable from 
original data. See details in the documentation of the parameter <code>...</code>
'indices to take' of the function Start().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indices(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="indices_+3A_x">x</code></td>
<td>
<p>A numeric vector or a list with two nemerics to take all the
elements between the two specified indices (both extremes inclusive).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Same as input, but with additional attribute 'indices', 'values', and
'chunk'.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+values">values</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Used in Start():
 data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = indices(1:2),
               longitude = indices(list(2, 14)),
               return_vars = list(latitude = 'dat', 
                                  longitude = 'dat', 
                                  time = 'sdate'),
               retrieve = FALSE)
</code></pre>

<hr>
<h2 id='NcCloser'>NetCDF file closer for 'startR'</h2><span id='topic+NcCloser'></span>

<h3>Description</h3>

<p>This is a file closer function for NetCDF files, intended for use as 
parameter 'file_closer' in a Start() call. This function complies with the 
input/output interface required by Start() defined in the documentation for 
the parameter 'file_closer'.<br /><br />
This function uses the function NcClose() in the package 'easyNCDF',
which in turn uses nc_close() in the package 'ncdf4'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NcCloser(file_object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NcCloser_+3A_file_object">file_object</code></td>
<td>
<p>An open connection to a NetCDF file, optionally with 
additional header information. See details in the documentation of the 
parameter 'file_closer' of the function Start().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns NULL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NcOpener">NcOpener</a></code> <code><a href="#topic+NcDataReader">NcDataReader</a></code> 
<code><a href="#topic+NcDimReader">NcDimReader</a></code> <code><a href="#topic+NcVarReader">NcVarReader</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_path &lt;- system.file('extdata', package = 'startR')
path_obs &lt;- file.path(data_path, 'obs/monthly_mean/tos/tos_200011.nc') 
connection &lt;- NcOpener(path_obs)
NcCloser(connection)
</code></pre>

<hr>
<h2 id='NcDataReader'>NetCDF file data reader for 'startR'</h2><span id='topic+NcDataReader'></span>

<h3>Description</h3>

<p>This is a data reader function for NetCDF files, intended for use as parameter 
file_data_reader in a Start() call. This function complies with the 
input/output interface required by Start() defined in the documentation for 
the parameter 'file_data_reader'.<br /><br />
This function uses the function NcToArray() in the package 'easyNCDF', which 
in turn uses nc_var_get() in the package 'ncdf4'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NcDataReader(
  file_path = NULL,
  file_object = NULL,
  file_selectors = NULL,
  inner_indices = NULL,
  synonims
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NcDataReader_+3A_file_path">file_path</code></td>
<td>
<p>A character string indicating the path to the data file to 
read. See details in the documentation of the parameter 'file_data_reader' 
of the function Start(). The default value is NULL.</p>
</td></tr>
<tr><td><code id="NcDataReader_+3A_file_object">file_object</code></td>
<td>
<p>An open connection to a NetCDF file, optionally with 
additional header information. See details in the documentation of the 
parameter 'file_data_reader' of the function Start(). The default value is 
NULL.</p>
</td></tr>
<tr><td><code id="NcDataReader_+3A_file_selectors">file_selectors</code></td>
<td>
<p>A named list containing the information of the path of 
the file to read data from. It is automatically provided by Start(). See 
details in the documentation of the parameter 'file_data_reader' of the 
function Start(). The default value is NULL.</p>
</td></tr>
<tr><td><code id="NcDataReader_+3A_inner_indices">inner_indices</code></td>
<td>
<p>A named list of numeric vectors indicating the indices 
to take from each of the inner dimensions in the requested file. It is 
automatically provided by Start(). See details in the documentation of the 
parameter 'file_data_reader' of the function Start(). The default value is 
NULL.</p>
</td></tr>
<tr><td><code id="NcDataReader_+3A_synonims">synonims</code></td>
<td>
<p>A named list indicating the synonims for the dimension names 
to look for in the requested file, exactly as provided in the parameter 
'synonims' in a Start() call. See details in the documentation of the 
parameter 'file_data_reader' of the function Start().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A multidimensional data array with the named dimensions and indices 
requested in 'inner_indices', potentially with the attribute 'variables' 
with additional auxiliary data. See details in the documentation of the 
parameter 'file_data_reader' of the function Start().
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NcOpener">NcOpener</a></code> <code><a href="#topic+NcDimReader">NcDimReader</a></code> 
<code><a href="#topic+NcCloser">NcCloser</a></code> <code><a href="#topic+NcVarReader">NcVarReader</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR', mustWork = TRUE)
 file_to_open &lt;- file.path(data_path, 'obs/monthly_mean/tos/tos_200011.nc')
 file_selectors &lt;- c(dat = 'dat1', var = 'tos', sdate = '200011')
 first_round_indices &lt;- list(time = 1, latitude = 1:8, longitude = 1:16)
 synonims &lt;- list(dat = 'dat', var = 'var', sdate = 'sdate', time = 'time',
                  latitude = 'latitude', longitude = 'longitude')
 sub_array &lt;- NcDataReader(file_to_open, NULL, file_selectors,
                           first_round_indices, synonims)
</code></pre>

<hr>
<h2 id='NcDimReader'>NetCDF dimension reader for 'startR'</h2><span id='topic+NcDimReader'></span>

<h3>Description</h3>

<p>A dimension reader function for NetCDF files, intended for use as parameter 
'file_dim_reader' in a Start() call. It complies with the input/output 
interface required by Start() defined in the documentation for the parameter 
'file_dim_reader' of that function.<br /><br />
This function uses the function NcReadDims() in the package 'easyNCDF'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NcDimReader(
  file_path = NULL,
  file_object = NULL,
  file_selectors = NULL,
  inner_indices = NULL,
  synonims
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NcDimReader_+3A_file_path">file_path</code></td>
<td>
<p>A character string indicating the path to the data file to 
read. See details in the documentation of the parameter 'file_dim_reader' 
of the function Start(). The default value is NULL.</p>
</td></tr>
<tr><td><code id="NcDimReader_+3A_file_object">file_object</code></td>
<td>
<p>An open connection to a NetCDF file, optionally with 
additional header information. See details in the documentation of the 
parameter 'file_dim_reader' of the function Start(). The default value is 
NULL.</p>
</td></tr>
<tr><td><code id="NcDimReader_+3A_file_selectors">file_selectors</code></td>
<td>
<p>A named list containing the information of the path of 
the file to read data from. It is automatically provided by Start(). See 
details in the documentation of the parameter 'file_dim_reader' of the 
function Start(). The default value is NULL.</p>
</td></tr>
<tr><td><code id="NcDimReader_+3A_inner_indices">inner_indices</code></td>
<td>
<p>A named list of numeric vectors indicating the indices 
to take from each of the inner dimensions in the requested file. It is 
automatically provided by Start(). See details in the documentation of the 
parameter 'file_dim_reader' of the function Start(). The default value is 
NULL.</p>
</td></tr>
<tr><td><code id="NcDimReader_+3A_synonims">synonims</code></td>
<td>
<p>A named list indicating the synonims for the dimension names 
to look for in the requested file, exactly as provided in the parameter 
'synonims' in a Start() call. See details in the documentation of the 
parameter 'file_dim_reader' of the function Start().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named numeric vector with the names and sizes of the dimensions of 
the requested file.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NcOpener">NcOpener</a></code> <code><a href="#topic+NcDataReader">NcDataReader</a></code> 
<code><a href="#topic+NcCloser">NcCloser</a></code> <code><a href="#topic+NcVarReader">NcVarReader</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR')
 file_to_open &lt;- file.path(data_path, 'obs/monthly_mean/tos/tos_200011.nc')
 file_selectors &lt;- c(dat = 'dat1', var = 'tos', sdate = '200011')
 first_round_indices &lt;- list(time = 1, latitude = 1:8, longitude = 1:16)
 synonims &lt;- list(dat = 'dat', var = 'var', sdate = 'sdate', time = 'time',
                  latitude = 'latitude', longitude = 'longitude')
 dim_of_file &lt;- NcDimReader(file_to_open, NULL, file_selectors,
                            first_round_indices, synonims)
</code></pre>

<hr>
<h2 id='NcOpener'>NetCDF file opener for 'startR'</h2><span id='topic+NcOpener'></span>

<h3>Description</h3>

<p>This is a file opener function for NetCDF files, intended for use as parameter 
'file_opener' in a Start() call. This function complies with the input/output 
interface required by Start() defined in the documentation for the parameter 
'file_opener'.<br /><br />
This function uses the function NcOpen() in the package 'easyNCDF', which in 
turn uses nc_open() in the package 'ncdf4'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NcOpener(file_path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NcOpener_+3A_file_path">file_path</code></td>
<td>
<p>A character string indicating the path to the data file to 
read. See details in the documentation of the parameter 'file_opener' of the 
function Start().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An open connection to a NetCDF file with additional header 
information as returned by nc_open() in the package 'ncdf4'. See details in 
the documentation of the parameter 'file_opener' of the function Start().
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NcDimReader">NcDimReader</a></code> <code><a href="#topic+NcDataReader">NcDataReader</a></code> 
<code><a href="#topic+NcCloser">NcCloser</a></code> <code><a href="#topic+NcVarReader">NcVarReader</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_path &lt;- system.file('extdata', package = 'startR')
path_obs &lt;- file.path(data_path, 'obs/monthly_mean/tos/tos_200011.nc')
connection &lt;- NcOpener(path_obs)
NcCloser(connection)
</code></pre>

<hr>
<h2 id='NcVarReader'>NetCDF variable reader for 'startR'</h2><span id='topic+NcVarReader'></span>

<h3>Description</h3>

<p>This is an auxiliary variable reader function for NetCDF files, intended for 
use as parameter 'file_var_reader' in a Start() call. It complies with the 
input/output interface required by Start() defined in the documentation for 
the parameter 'file_var_reader' of that function.<br /><br />
This function uses the function NcDataReader() in the package 'startR', 
which in turn uses NcToArray() in the package 'easyNCDF', which in turn uses 
nc_var_get() in the package 'ncdf4'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NcVarReader(
  file_path = NULL,
  file_object = NULL,
  file_selectors = NULL,
  var_name = NULL,
  synonims
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NcVarReader_+3A_file_path">file_path</code></td>
<td>
<p>A character string indicating the path to the data file to 
read the variable from. See details in the documentation of the parameter 
'file_var_reader' of the function Start(). The default value is NULL.</p>
</td></tr>
<tr><td><code id="NcVarReader_+3A_file_object">file_object</code></td>
<td>
<p>An open connection to a NetCDF file, optionally with 
additional header information. See details in the documentation of the 
parameter 'file_var_reader' of the function Start(). The default value is 
NULL.</p>
</td></tr>
<tr><td><code id="NcVarReader_+3A_file_selectors">file_selectors</code></td>
<td>
<p>A named list containing the information of the path of 
the file to read data from. It is automatically provided by Start(). See 
details in the documentation of the parameter 'file_var_reader' of the 
function Start(). The default value is NULL.</p>
</td></tr>
<tr><td><code id="NcVarReader_+3A_var_name">var_name</code></td>
<td>
<p>A character string with the name of the variable to be read.
The default value is NULL.</p>
</td></tr>
<tr><td><code id="NcVarReader_+3A_synonims">synonims</code></td>
<td>
<p>A named list indicating the synonims for the dimension names 
to look for in the requested file, exactly as provided in the parameter 
'synonims' in a Start() call. See details in the documentation of the 
parameter 'file_var_reader' of the function Start().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A multidimensional data array with the named dimensions, potentially 
with the attribute 'variables' with additional auxiliary data. See details 
in the documentation of the parameter 'file_var_reader' of the function 
Start().
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NcOpener">NcOpener</a></code> <code><a href="#topic+NcDataReader">NcDataReader</a></code> 
<code><a href="#topic+NcCloser">NcCloser</a></code> <code><a href="#topic+NcDimReader">NcDimReader</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR')
 file_to_open &lt;- file.path(data_path, 'obs/monthly_mean/tos/tos_200011.nc')
 file_selectors &lt;- c(dat = 'dat1', var = 'tos', sdate = '200011')
 synonims &lt;- list(dat = 'dat', var = 'var', sdate = 'sdate', time = 'time',
                  latitude = 'latitude', longitude = 'longitude')
 var &lt;- NcVarReader(file_to_open, NULL, file_selectors,
                     'tos', synonims)
</code></pre>

<hr>
<h2 id='SelectorChecker'>Translate a set of selectors into a set of numeric indices</h2><span id='topic+SelectorChecker'></span>

<h3>Description</h3>

<p>This is a selector checker function intended for use as parameter 
'selector_checker' in a Start() call. It translates a set of selectors which
is the value for one dimension into a set of numeric indices corresponding to
the coordinate variable. The function complies with the input/output interface 
required by Start() defined in the documentation for the parameter 
'selector_checker' of Start().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectorChecker(selectors, var = NULL, return_indices = TRUE, tolerance = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SelectorChecker_+3A_selectors">selectors</code></td>
<td>
<p>A vector or a list of two of numeric indices or variable 
values to be retrieved for a dimension, automatically provided by Start(). 
See details in the documentation of the parameters 'selector_checker' and 
'...' of the function Start().</p>
</td></tr>
<tr><td><code id="SelectorChecker_+3A_var">var</code></td>
<td>
<p>A vector of values of a coordinate variable for which to search 
matches with the provided indices or values in the parameter 'selectors', 
automatically provided by Start(). See details in the documentation of the 
parameters 'selector_checker' and '...' of the function Start(). The 
default value is NULL. When not specified, SelectorChecker() simply returns
the input indices.</p>
</td></tr>
<tr><td><code id="SelectorChecker_+3A_return_indices">return_indices</code></td>
<td>
<p>A logical value automatically configured by Start(), 
telling whether to return the numeric indices or coordinate variable values 
after the matching. The default value is TRUE.</p>
</td></tr>
<tr><td><code id="SelectorChecker_+3A_tolerance">tolerance</code></td>
<td>
<p>A numeric value indicating a tolerance value to be used in 
the matching of 'selectors' and 'var'. See documentation on 
'&lt;dim_name&gt;_tolerance' in <code>...</code> in the documentation of the function
Start(). The default value is NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of either the indices of the matching values (if 
return_indices = TRUE) or the matching values themselves (if return_indices
= FALSE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get the latitudes from 10 to 20 degree
sub_array_of_selectors &lt;- list(10, 20)
# The latitude values from original file
sub_array_of_values &lt;- seq(90, -90, length.out = 258)[2:257]
SelectorChecker(sub_array_of_selectors, sub_array_of_values)

</code></pre>

<hr>
<h2 id='Sort'>Sort the coordinate variable values in a Start() call</h2><span id='topic+Sort'></span><span id='topic+CircularSort'></span>

<h3>Description</h3>

<p>The reorder function intended for use as parameter '&lt;dim_name&gt;_reorder'
in a call to the function Start(). This function complies with the 
input/output interface required by Start() defined in the documentation 
for the parameter <code>...</code> of that function.<br /><br />
The coordinate applied to Sort() consists of an increasing or decreasing 
sort of the values. It is useful for adjusting the latitude order.<br /><br />
The coordinate applied to CircularSort() consists of a circular sort of 
values, where any values beyond the limits specified in the parameters 
'start' and 'end' is applied a modulus to fall in the specified 
range. This is useful for circular coordinates such as the Earth longitudes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sort(...)

CircularSort(start, end, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Sort_+3A_...">...</code></td>
<td>
<p>Additional parameters to adjust the reorderig. See function
sort() for more details.</p>
</td></tr>
<tr><td><code id="Sort_+3A_start">start</code></td>
<td>
<p>A numeric indicating the lower bound of the circular range.</p>
</td></tr>
<tr><td><code id="Sort_+3A_end">end</code></td>
<td>
<p>A numeric indicating the upper bound of the circular range.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of 2 containing:
</p>
<table role = "presentation">
<tr><td><code>$x</code></td>
<td>

<p>The reordered values.
</p>
</td></tr>
<tr><td><code>$ix</code></td>
<td>

<p>The permutation indices of $x in the original coordinate.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Used in Start():
 data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = values(list(-60, 60)),
               latitude_reorder = Sort(decreasing = TRUE),
               longitude = values(list(-120, 120)),
               longitude_reorder = CircularSort(-180, 180),
               return_vars = list(latitude = 'dat',
                                  longitude = 'dat',
                                  time = 'sdate'),
               retrieve = FALSE)

</code></pre>

<hr>
<h2 id='Start'>Declare, discover, subset and retrieve multidimensional distributed data sets</h2><span id='topic+Start'></span>

<h3>Description</h3>

<p>See the <a href="https://earth.bsc.es/gitlab/es/startR">startR documentation and
tutorial</a> for a step-by-step explanation on how to use Start().<br /><br />
Nowadays in the era of big data, large multidimensional data sets from 
diverse sources need to be combined and processed. Analysis of big data in any
field is often highly complex and time-consuming. Taking subsets of these data
sets and processing them efficiently become an indispensable practice. This 
technique is also known as Domain Decomposition, Map Reduce or, more commonly,
'chunking'.<br /><br />
startR (Subset, TrAnsform, ReTrieve, arrange and process large 
multidimensional data sets in R) is an R project started at BSC with the aim 
to develop a tool that allows the user to automatically process large 
multidimensional distributed data sets. It is an open source project that is 
open to external collaboration and funding, and will continuously evolve to 
support as many data set formats as possible while maximizing its efficiency.<br /><br />
startR provides a framework under which a data set (collection of one 
or multiple data files, potentially distributed over various remote servers) 
are perceived as if they all were part of a single large multidimensional 
array. Once such multidimensional array is declared, any user-defined function
can be applied to the data in a <code>apply</code>-like fashion, where startR
transparently implements the Map Reduce paradigm. The steps to follow in order
to process a collection of big data sets are as follows:<br />
</p>

<ul>
<li>
<p>Declaring the data set, i.e. declaring the distribution of the data files 
involved, the dimensions and shape of the multidimensional array, and the 
boundaries of the target data. This step can be performed with the 
Start() function. Numeric indices or coordinate values can be used when
fixing the boundaries. It is common having the need to apply transformations, 
pre-processing or reordering to the data. Start() accepts user-defined 
transformation or reordering functions to be applied for such purposes. Once a
data set is declared, a list of involved files, dimension lengths, memory size
and other metadata is made available. Optionally, the data set can be 
retrieved and loaded onto the current R session if it is small enough. 

</p>
</li>
<li>
<p>Declaring the workflow of operations to perform on the involved data set(s).
This step can be performed with the Step() and AddStep() functions.

</p>
</li>
<li>
<p>Defining the computation settings. The mandatory settings include a) how many
subsets to divide the data sets into and along which dimensions; b) which 
platform to perform the workflow of operations on (local machine or remote 
machine/HPC?), how to communicate with it (unidirectional or bidirectional 
connection? shared or separate file systems?), which queuing system it uses 
(slurm, PBS, LSF, none?); and c) how many parallel jobs and execution threads
per job to use when running the calculations. This step can be performed when 
building up the call to the Compute() function.

</p>
</li>
<li>
<p>Running the computation. startR transparently implements the Map Reduce 
paradigm, according to the settings in the previous steps. The progress can 
optionally be monitored with the EC-Flow workflow management tool. When the 
computation ends, a report of performance timings is displayed. This step can 
be triggered with the Compute() function.

</p>
</li></ul>

<p>startR is not bound to a specific file format. Interface functions to
custom file formats can be provided for Start() to read them. As this
version, startR includes interface functions to the following file formats:
</p>

<ul>
<li>
<p>NetCDF

</p>
</li></ul>

<p>Metadata and auxilliary data is also preserved and arranged by Start()
in the measure that it is retrieved by the interface functions for a specific 
file format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Start(
  ...,
  return_vars = NULL,
  synonims = NULL,
  file_opener = NcOpener,
  file_var_reader = NcVarReader,
  file_dim_reader = NcDimReader,
  file_data_reader = NcDataReader,
  file_closer = NcCloser,
  transform = NULL,
  transform_params = NULL,
  transform_vars = NULL,
  transform_extra_cells = 2,
  apply_indices_after_transform = FALSE,
  pattern_dims = NULL,
  metadata_dims = NULL,
  selector_checker = SelectorChecker,
  merge_across_dims = FALSE,
  merge_across_dims_narm = TRUE,
  split_multiselected_dims = FALSE,
  path_glob_permissive = FALSE,
  largest_dims_length = FALSE,
  retrieve = FALSE,
  num_procs = 1,
  ObjectBigmemory = NULL,
  silent = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Start_+3A_...">...</code></td>
<td>
<p>A selection of custemized parameters depending on the data 
format. When we retrieve data from one or a collection of data sets, 
the involved data can be perceived as belonging to a large multi-dimensional 
array. For instance, let us consider an example case. We want to retrieve data
from a source, which contains data for the number of monthly sales of various 
items, and also for their retail price each month. The data on source is 
stored as follows:<br /><br />
<code>
<br /> #  /data/
<br /> #    |-&gt; sales/
<br /> #    |    |-&gt; electronics
<br /> #    |    |    |-&gt; item_a.data
<br /> #    |    |    |-&gt; item_b.data
<br /> #    |    |    |-&gt; item_c.data
<br /> #    |    |-&gt; clothing
<br /> #    |         |-&gt; item_d.data
<br /> #    |         |-&gt; idem_e.data
<br /> #    |         |-&gt; idem_f.data
<br /> #    |-&gt; prices/
<br /> #         |-&gt; electronics
<br /> #         |    |-&gt; item_a.data
<br /> #         |    |-&gt; item_b.data
<br /> #         |    |-&gt; item_c.data
<br /> #         |-&gt; clothing
<br /> #              |-&gt; item_d.data
<br /> #              |-&gt; item_e.data
<br /> #              |-&gt; item_f.data
</code><br /><br />
Each item file contains data, stored in whichever format, for the sales or 
prices over a time period, e.g. for the past 24 months, registered at 100 
different stores over the world. Whichever the format it is stored in, each 
file can be perceived as a container of a data array of 2 dimensions, time and
store. Let us assume the '.data' format allows to keep a name for each of 
these dimensions, and the actual names are 'time' and 'store'.<br /><br />
The different item files for sales or prices can be perceived as belonging to 
an 'item' dimension of length 3, and the two groups of three items to a 
'section' dimension of length 2, and the two groups of two sections (one with
the sales and the other with the prices) can be perceived as belonging also to
another dimension 'variable' of length 2. Even the source can be perceived as 
belonging to a dimension 'source' of length 1.<br /><br />
All in all, in this example, the whole data could be perceived as belonging to
a multidimensional 'large array' of dimensions<br />
<code>
<br /> #  source variable  section      item    store    month
<br /> #       1        2        2         3      100       24
</code>
<br /><br />
The dimensions of this 'large array' can be classified in two types. The ones 
that group actual files (the file dimensions) and the ones that group data 
values inside the files (the inner dimensions). In the example, the file 
dimensions are 'source', 'variable', 'section' and 'item', whereas the inner 
dimensions are 'store' and 'month'.
<br /><br />
Having the dimensions of our target sources in mind, the parameter <code>...</code> 
expects to receive information on:
</p>

<ul>
<li>
<p>The names of the expected dimensions of the 'large dataset' we want to 
retrieve data from

</p>
</li>
<li>
<p>The indices to take from each dimension (and other constraints)

</p>
</li>
<li>
<p>How to reorder the dimension if needed

</p>
</li>
<li>
<p>The location and organization of the files of the data sets

</p>
</li></ul>

<p>For each dimension, the 3 first information items can be specified with a set
of parameters to be provided through <code>...</code>. For a given dimension 
'dimname', six parameters can be specified:<br />
<code>
<br /> # dimname = &lt;indices_to_take&gt;,  # 'all' / 'first' / 'last' /
<br /> #                               # indices(c(1, 10, 20)) /
<br /> #                               # indices(c(1:20)) /
<br /> #                               # indices(list(1, 20)) /
<br /> #                               # c(1, 10, 20) / c(1:20) /
<br /> #                               # list(1, 20)
<br /> # dimname_var = &lt;name_of_associated_coordinate_variable&gt;,
<br /> # dimname_tolerance = &lt;tolerance_value&gt;,
<br /> # dimname_reorder = &lt;reorder_function&gt;,
<br /> # dimname_depends = &lt;name_of_another_dimension&gt;,
<br /> # dimname_across = &lt;name_of_another_dimension&gt;
</code>
<br /><br />
The <b>indices to take</b> can be specified in three possible formats (see 
code comments above for examples). The first format consists in using 
character tags, such as 'all' (take all the indices available for that 
dimension), 'first' (take only the first) and 'last' (only the last). The 
second format consists in using numeric indices, which have to be wrapped in a
call to the indices() helper function. For the second format, either a
vector of numeric indices can be provided, or a list with two numeric indices 
can be provided to take all the indices in the range between the two specified
indices (both extremes inclusive). The third format consists in providing a 
vector character strings (for file dimensions) or of values of whichever type
(for inner dimensions). For the file dimensions, the provided character 
strings in the third format will be used as components to build up the final 
path to the files (read further). For inner dimensions, the provided values in
the third format will be compared to the values of an associated coordinate 
variable (must be specified in '&lt;dimname&gt;_reorder', read further), and the 
indices of the closest values will be retrieved. When using the third format, 
a list with two values can also be provided to take all the indices of the 
values within the specified range.
<br /><br />
The <b>name of the associated coordinate variable</b> must be a character 
string with the name of an associated coordinate variable to be found in the 
data files (in all* of them). For this to work, a 'file_var_reader' 
function must be specified when calling Start() (see parameter 
'file_var_reader'). The coordinate variable must also be requested in the 
parameter 'return_vars' (see its section for details). This feature only 
works for inner dimensions.
<br /><br />
The <b>tolerance value</b> is useful when indices for an inner dimension are 
specified in the third format (values of whichever type). In that case, the 
indices of the closest values in the coordinate variable are seeked. However 
the closest value might be too distant and we would want to consider no real 
match exists for such provided value. This is possible via the tolerance,
which allows to specify a threshold beyond which not to seek for matching 
values and mark that index as missing value.
<br /><br />
The <b>reorder_function</b> is useful when indices for an inner dimension are
specified in the third fromat, and the retrieved indices need to be reordered 
in function of their provided associated variable values. A function can be 
provided, which receives as input a vector of values, and returns as outputs a
list with the components <code>$x</code> with the reordered values, and <code>$ix</code> 
with the permutation indices. Two reordering functions are included in 
startR, the Sort() and the CircularSort().
<br /><br />
The <b>name of another dimension</b> to be specified in &lt;dimname&gt;_depends,
only available for file dimensions, must be a character string with the name 
of another requested <b>file dimension</b> in <code>...</code>, and will make 
Start() aware that the path components of a file dimension can vary in
function of the path component of another file dimension. For instance, in the
example above, specifying <code>item_depends = 'section'</code> will make 
Start() aware that the item names vary in function of the section, i.e.
section 'electronics' has items 'a', 'b' and 'c' but section 'clothing' has 
items 'd', 'e', 'f'. Otherwise Start() would expect to find the same 
item names in all the sections.
If values() is used to define dimensions, it is possible to provide different 
values of the depending dimension for each depended dimension values. For 
example, if <code>section = c('electronics', 'clothing')</code>, we can use
<code>item = list(electronics = c('a', 'b', 'c'), clothing = c('d', 'e', 'f'))</code>.
<br /><br />
The <b>name of another dimension</b> to be specified in '&lt;dimname&gt;_across',
only available for inner dimensions, must be a character string with the name 
of another requested <b>inner dimension</b> in <code>...</code>, and will make 
Start() aware that an inner dimension extends along multiple files. For
instance, let us imagine that in the example above, the records for each item 
are so large that it becomes necessary to split them in multiple files each 
one containing the registers for a different period of time, e.g. in 10 files 
with 100 months each ('item_a_period1.data', 'item_a_period2.data', and so on).
In that case, the data can be perceived as having an extra file dimension, the 
'period' dimension. The inner dimension 'month' would extend across multiple 
files, and providing the parameter <code>month = indices(1, 300)</code> would make 
Start() crash because it would perceive we have made a request out of 
bounds (each file contains 100 'month' indices, but we requested 1 to 300). 
This can be solved by specifying the parameter <code>month_across = period</code> (a
long with the full specification of the dimension 'period').
<br /><br />
<b>Defining the path pattern</b>
<br />
As mentioned above, the parameter ... also expects to receive information 
with the location of the data files. In order to do this, a special dimension 
must be defined. In that special dimension, in place of specifying indices to 
take, a path pattern must be provided. The path pattern is a character string 
that encodes the way the files are organized in their source. It must be a 
path to one of the data set files in an accessible local or remote file system,
or a URL to one of the files provided by a local or remote server. The regions
of this path that vary across files (along the file dimensions) must be 
replaced by wildcards. The wildcards must match any of the defined file 
dimensions in the call to Start() and must be delimited with heading 
and trailing '$'. Shell globbing expressions can be used in the path pattern. 
See the next code snippet for an example of a path pattern.
<br /><br />
All in all, the call to Start() to load the entire data set in the 
example of store item sales, would look as follows:
<br />
<code>
<br /> # data &lt;- Start(source = paste0('/data/$variable$/',
<br /> #                               '$section$/$item$.data'),
<br /> #               variable = 'all',
<br /> #               section = 'all',
<br /> #               item = 'all',
<br /> #               item_depends = 'section',
<br /> #               store = 'all',
<br /> #               month = 'all')
</code>
<br /><br />
Note that in this example it would still be pending to properly define the 
parameters 'file_opener', 'file_closer', 'file_dim_reader', 
'file_var_reader' and 'file_data_reader' for the '.data' file format
(see the corresponding sections).
<br /><br />
The call to Start() will return a multidimensional R array with the 
following dimensions:
<br />
<code>
<br /> #  source variable  section      item    store    month
<br /> #       1        2        2         3      100       24
</code>
<br />
The dimension specifications in the <code>...</code> do not have to follow any 
particular order. The returned array will have the dimensions in the same order
as they have been specified in the call. For example, the following call:
<br />
<code>
<br /> # data &lt;- Start(source = paste0('/data/$variable$/',
<br /> #                               '$section$/$item$.data'),
<br /> #               month = 'all',
<br /> #               store = 'all',
<br /> #               item = 'all',
<br /> #               item_depends = 'section',
<br /> #               section = 'all',
<br /> #               variable = 'all')
</code>
<br /><br />
would return an array with the following dimensions:
<br />
<code>
<br /> #  source    month    store      item  section variable
<br /> #       1       24      100         3        2        2
</code>
<br /><br />
Next, a more advanced example to retrieve data for only the sales records, for
the first section ('electronics'), for the 1st and 3rd items and for the 
stores located in Barcelona (assuming the files contain the variable 
'store_location' with the name of the city each of the 100 stores are located 
at):
<br />
<code>
<br /> # data &lt;- Start(source = paste0('/data/$variable$/',
<br /> #                               '$section$/$item$.data'),
<br /> #               variable = 'sales',
<br /> #               section = 'first',
<br /> #               item = indices(c(1, 3)),
<br /> #               item_depends = 'section',
<br /> #               store = 'Barcelona',
<br /> #               store_var = 'store_location',
<br /> #               month = 'all',
<br /> #               return_vars = list(store_location = NULL))
</code>
<br /><br />
The defined names for the dimensions do not necessarily have to match the 
names of the dimensions inside the file. Lists of alternative names to be 
seeked can be defined in the parameter 'synonims'.
<br /><br />
If data from multiple sources (not necessarily following the same structure) 
has to be retrieved, it can be done by providing a vector of character strings
with path pattern specifications, or, in the extended form, by providing a 
list of lists with the components 'name' and 'path', and the name of the 
dataset and path pattern as values, respectively. For example:
<br />
<code>
<br /> # data &lt;- Start(source = list(
<br /> #                 list(name = 'sourceA',
<br /> #                      path = paste0('/sourceA/$variable$/',
<br /> #                                    '$section$/$item$.data')),
<br /> #                 list(name = 'sourceB',
<br /> #                      path = paste0('/sourceB/$section$/',
<br /> #                                    '$variable$/$item$.data'))
<br /> #               ),
<br /> #               variable = 'sales',
<br /> #               section = 'first',
<br /> #               item = indices(c(1, 3)),
<br /> #               item_depends = 'section',
<br /> #               store = 'Barcelona',
<br /> #               store_var = 'store_location',
<br /> #               month = 'all',
<br /> #               return_vars = list(store_location = NULL))
</code>
<br /></p>
</td></tr>
<tr><td><code id="Start_+3A_return_vars">return_vars</code></td>
<td>
<p>A named list where the names are the names of the 
variables to be fetched in the files, and the values are vectors of 
character strings with the names of the file dimension which to retrieve each
variable for, or NULL if the variable has to be retrieved only once 
from any (the first) of the involved files.<br /><br />
Apart from retrieving a multidimensional data array, retrieving auxiliary 
variables inside the files can also be needed. The parameter 
'return_vars' allows for requesting such variables, as long as a 
'file_var_reader' function is also specified in the call to 
Start() (see documentation on the corresponding parameter). 
<br /><br />
In the case of the the item sales example (see documentation on parameter 
<code>...)</code>, the store location variable is requested with the parameter<br /> 
<code>return_vars = list(store_location = NULL)</code>.<br /> This will cause 
Start() to fetch once the variable 'store_location' and return it in 
the component<br /> <code>$Variables$common$store_location</code>,<br /> and will be an 
array of character strings with the location names, with the dimensions 
<code>c('store' = 100)</code>. Although useless in this example, we could ask 
Start() to fetch and return such variable for each file along the 
items dimension as follows: <br /> 
<code>return_vars = list(store_location = c('item'))</code>.<br /> In that case, the 
variable will be fetched once from a file of each of the items, and will be 
returned as an array with the dimensions <code>c('item' = 3, 'store' = 100)</code>.
<br /><br />
If a variable is requested along a file dimension that contains path pattern 
specifications ('source' in the example), the fetched variable values will be 
returned in the component<br /> <code>$Variables$&lt;dataset_name&gt;$&lt;variable_name&gt;</code>.<br /> 
For example:
<br />
<code>
<br /> # data &lt;- Start(source = list(
<br /> #                 list(name = 'sourceA',
<br /> #                      path = paste0('/sourceA/$variable$/',
<br /> #                                    '$section$/$item$.data')),
<br /> #                 list(name = 'sourceB',
<br /> #                      path = paste0('/sourceB/$section$/',
<br /> #                                    '$variable$/$item$.data'))
<br /> #               ),
<br /> #               variable = 'sales',
<br /> #               section = 'first',
<br /> #               item = indices(c(1, 3)),
<br /> #               item_depends = 'section',
<br /> #               store = 'Barcelona',
<br /> #               store_var = 'store_location',
<br /> #               month = 'all',
<br /> #               return_vars = list(store_location = c('source',
<br /> #                                                     'item')))
<br /> # # Checking the structure of the returned variables
<br /> # str(found_data$Variables)
<br /> # Named list
<br /> # ..$common: NULL
<br /> # ..$sourceA: Named list
<br /> # .. ..$store_location: char[1:18(3d)] 'Barcelona' 'Barcelona' ...
<br /> # ..$sourceB: Named list
<br /> # .. ..$store_location: char[1:18(3d)] 'Barcelona' 'Barcelona' ...
<br /> # # Checking the dimensions of the returned variable
<br /> # # for the source A
<br /> # dim(found_data$Variables$sourceA)
<br /> #     item   store
<br /> #        3       3
</code>
<br /><br />
The names of the requested variables do not necessarily have to match the 
actual variable names inside the files. A list of alternative names to be 
seeked can be specified via the parameter 'synonims'.</p>
</td></tr>
<tr><td><code id="Start_+3A_synonims">synonims</code></td>
<td>
<p>A named list where the names are the requested variable or 
dimension names, and the values are vectors of character strings with 
alternative names to seek for such dimension or variable.<br /><br />
In some requests, data from different sources may follow different naming 
conventions for the dimensions or variables, or even files in the same source
could have varying names. This parameter is in order for Start() to 
properly identify the dimensions or variables with different names.
<br /><br />
In the example used in parameter 'return_vars', it may be the case that 
the two involved data sources follow slightly different naming conventions. 
For example, source A uses 'sect' as name for the sections dimension, whereas 
source B uses 'section'; source A uses 'store_loc' as variable name for the 
store locations, whereas source B uses 'store_location'. This can be taken 
into account as follows:
<br />
<code>
<br /> # data &lt;- Start(source = list(
<br /> #                 list(name = 'sourceA',
<br /> #                      path = paste0('/sourceA/$variable$/',
<br /> #                                    '$section$/$item$.data')),
<br /> #                 list(name = 'sourceB',
<br /> #                      path = paste0('/sourceB/$section$/',
<br /> #                                    '$variable$/$item$.data'))
<br /> #               ),
<br /> #               variable = 'sales',
<br /> #               section = 'first',
<br /> #               item = indices(c(1, 3)),
<br /> #               item_depends = 'section',
<br /> #               store = 'Barcelona',
<br /> #               store_var = 'store_location',
<br /> #               month = 'all',
<br /> #               return_vars = list(store_location = c('source',
<br /> #                                                     'item')),
<br /> #               synonims = list(
<br /> #                 section = c('sec', 'section'),
<br /> #                 store_location = c('store_loc',
<br /> #                                    'store_location')
<br /> #               ))
</code>
<br /></p>
</td></tr>
<tr><td><code id="Start_+3A_file_opener">file_opener</code></td>
<td>
<p>A function that receives as a single parameter 
'file_path' a character string with the path to a file to be opened, 
and returns an object with an open connection to the file (optionally with 
header information) on success, or returns NULL on failure.
<br /><br />
This parameter takes by default NcOpener() (an opener function for NetCDF
files).
<br /><br />
See NcOpener() for a template to build a file opener for your own file 
format.</p>
</td></tr>
<tr><td><code id="Start_+3A_file_var_reader">file_var_reader</code></td>
<td>
<p>A function with the header <code>file_path = NULL</code>, 
<code>file_object = NULL</code>, <code>file_selectors = NULL</code>, <code>var_name</code>, 
<code>synonims</code> that returns an array with auxiliary data (i.e. data from a
variable) inside a file. Start() will provide automatically either a 
'file_path' or a 'file_object' to the 'file_var_reader'
function (the function has to be ready to work whichever of these two is 
provided). The parameter 'file_selectors' will also be provided 
automatically to the variable reader, containing a named list where the 
names are the names of the file dimensions of the queried data set (see 
documentation on <code>...</code>) and the values are single character strings 
with the components used to build the path to the file being read (the one 
provided in 'file_path' or 'file_object'). The parameter 'var_name'
will be filled in automatically by Start() also, with the name of one
of the variales to be read. The parameter 'synonims' will be filled in 
with exactly the same value as provided in the parameter 'synonims' in 
the call to Start(), and has to be used in the code of the variable 
reader to check for alternative variable names inside the target file. The 
'file_var_reader' must return a (multi)dimensional array with named 
dimensions, and optionally with the attribute 'variales' with other 
additional metadata on the retrieved variable.
<br /><br />
Usually, the 'file_var_reader' should be a degenerate case of the 
'file_data_reader' (see documentation on the corresponding parameter), 
so it is recommended to code the 'file_data_reder' in first place.
<br /><br />
This parameter takes by default NcVarReader() (a variable reader function
for NetCDF files).
<br /><br />
See NcVarReader() for a template to build a variale reader for your own 
file format.</p>
</td></tr>
<tr><td><code id="Start_+3A_file_dim_reader">file_dim_reader</code></td>
<td>
<p>A function with the header <code>file_path = NULL</code>, 
<code>file_object = NULL</code>, <code>file_selectors = NULL</code>, <code>synonims</code> 
that returns a named numeric vector where the names are the names of the 
dimensions of the multidimensional data array in the file and the values are
the sizes of such dimensions. Start() will provide automatically 
either a 'file_path' or a 'file_object' to the 
'file_dim_reader' function (the function has to be ready to work 
whichever of these two is provided). The parameter 'file_selectors'
will also be provided automatically to the dimension reader, containing a
named list where the names are the names of the file dimensions of the 
queried data set (see documentation on <code>...</code>) and the values are 
single character strings with the components used to build the path to the 
file being read (the one provided in 'file_path' or 'file_object'). 
The parameter 'synonims' will be filled in with exactly the same value 
as provided in the parameter 'synonims' in the call to Start(), 
and can optionally be used in advanced configurations.
<br /><br />
This parameter takes by default NcDimReader() (a dimension reader 
function for NetCDF files).
<br /><br />
See NcDimReader() for (an advanced) template to build a dimension reader
for your own file format.</p>
</td></tr>
<tr><td><code id="Start_+3A_file_data_reader">file_data_reader</code></td>
<td>
<p>A function with the header <code>file_path = NULL</code>, 
<code>file_object = NULL</code>, <code>file_selectors = NULL</code>, 
<code>inner_indices = NULL</code>, <code>synonims</code> that returns a subset of the 
multidimensional data array inside a file (even if internally it is not an 
array). Start() will provide automatically either a 'file_path'
or a 'file_object' to the 'file_data_reader' function (the 
function has to be ready to work whichever of these two is provided). The
parameter 'file_selectors' will also be provided automatically to the
data reader, containing a named list where the names are the names of the
file dimensions of the queried data set (see documentation on <code>...</code>)
and the values are single character strings with the components used to 
build the path to the file being read (the one provided in 'file_path' or 
'file_object'). The parameter 'inner_indices' will be filled in 
automatically by Start() also, with a named list of numeric vectors, 
where the names are the names of all the expected inner dimensions in a file
to be read, and the numeric vectors are the indices to be taken from the 
corresponding dimension (the indices may not be consecutive nor in order).
The parameter 'synonims' will be filled in with exactly the same value 
as provided in the parameter 'synonims' in the call to Start(), 
and has to be used in the code of the data reader to check for alternative 
dimension names inside the target file. The 'file_data_reader' must 
return a (multi)dimensional array with named dimensions, and optionally with
the attribute 'variables' with other additional metadata on the retrieved 
data.
<br /><br />
Usually, 'file_data_reader' should use 'file_dim_reader'
(see documentation on the corresponding parameter), so it is recommended to 
code 'file_dim_reder' in first place.
<br /><br />
This parameter takes by default NcDataReader() (a data reader function 
for NetCDF files).
<br /><br />
See NcDataReader() for a template to build a data reader for your own 
file format.</p>
</td></tr>
<tr><td><code id="Start_+3A_file_closer">file_closer</code></td>
<td>
<p>A function that receives as a single parameter 
'file_object' an open connection (as returned by 'file_opener') 
to one of the files to be read, optionally with header information, and 
closes the open connection. Always returns NULL.
<br /><br />
This parameter takes by default NcCloser() (a closer function for NetCDF 
files).
<br /><br />
See NcCloser() for a template to build a file closer for your own file 
format.</p>
</td></tr>
<tr><td><code id="Start_+3A_transform">transform</code></td>
<td>
<p>A function with the header <code>dara_array</code>, 
<code>variables</code>, <code>file_selectors = NULL</code>, <code>...</code>. It receives as
input, through the parameter <code>data_array</code>, a subset of a 
multidimensional array (as returned by 'file_data_reader'), applies a 
transformation to it and returns it, preserving the amount of dimensions but
potentially modifying their size. This transformation may require data from 
other auxiliary variables, automatically provided to 'transform' 
through the parameter 'variables', in the form of a named list where
the names are the variable names and the values are (multi)dimensional
arrays. Which variables need to be sent to 'transform' can be specified
with the parameter 'transform_vars' in Start(). The parameter 
'file_selectors' will also be provided automatically to 
'transform', containing a named list where the names are the names of 
the file dimensions of the queried data set (see documentation on 
<code>...</code>) and the values are single character strings with the 
components used to build the path to the file the subset being processed 
belongs to. The parameter <code>...</code> will be filled in with other 
additional parameters to adjust the transformation, exactly as provided in 
the call to Start() via the parameter 'transform_params'.</p>
</td></tr>
<tr><td><code id="Start_+3A_transform_params">transform_params</code></td>
<td>
<p>A named list with additional parameters to be sent to 
the 'transform' function (if specified). See documentation on parameter
'transform' for details.</p>
</td></tr>
<tr><td><code id="Start_+3A_transform_vars">transform_vars</code></td>
<td>
<p>A vector of character strings with the names of 
auxiliary variables to be sent to the 'transform' function (if 
specified). All the variables to be sent to 'transform' must also 
have been requested as return variables in the parameter 'return_vars' 
of Start().</p>
</td></tr>
<tr><td><code id="Start_+3A_transform_extra_cells">transform_extra_cells</code></td>
<td>
<p>An integer of extra indices to retrieve from the 
data set, beyond the requested indices in <code>...</code>, in order for 
'transform' to dispose of additional information to properly apply 
whichever transformation (if needed). As many as 
'transform_extra_cells' will be retrieved beyond each of the limits for
each of those inner dimensions associated to a coordinate variable and sent 
to 'transform' (i.e. present in 'transform_vars'). After 
'transform' has finished, Start() will take again and return a 
subset of the result, for the returned data to fall within the specified 
bounds in <code>...</code>. The default value is 2.</p>
</td></tr>
<tr><td><code id="Start_+3A_apply_indices_after_transform">apply_indices_after_transform</code></td>
<td>
<p>A logical value indicating when a 
'transform' is specified in Start() and numeric indices are 
provided for any of the inner dimensions that depend on coordinate variables,
these numeric indices can be made effective (retrieved) before applying the 
transformation or after. The boolean flag allows to adjust this behaviour. 
It takes FALSE by default (numeric indices are applied before sending
data to 'transform').</p>
</td></tr>
<tr><td><code id="Start_+3A_pattern_dims">pattern_dims</code></td>
<td>
<p>A character string indicating the name of the dimension 
with path pattern specifications (see <code>...</code> for details). If not  
specified, Start() assumes the first provided dimension is the pattern 
dimension, with a warning.</p>
</td></tr>
<tr><td><code id="Start_+3A_metadata_dims">metadata_dims</code></td>
<td>
<p>A vector of character strings with the names of the file 
dimensions which to return metadata for. As noted in 'file_data_reader', 
the data reader can optionally return auxiliary data via the attribute 
'variables' of the returned array. Start() by default returns the 
auxiliary data read for only the first file of each source (or data set) in 
the pattern dimension (see <code>...</code> for info on what the pattern 
dimension is). However it can be configured to return the metadata for all 
the files along any set of file dimensions. The default value is NULL, and
it will be assigned automatically as parameter 'pattern_dims'.</p>
</td></tr>
<tr><td><code id="Start_+3A_selector_checker">selector_checker</code></td>
<td>
<p>A function used internaly by Start() to 
translate a set of selectors (values for a dimension associated to a 
coordinate variable) into a set of numeric indices. It takes by default 
SelectorChecker() and, in principle, it should not be required to 
change it for customized file formats. The option to replace it is left open
for more versatility. See the code of SelectorChecker() for details on
the inputs, functioning and outputs of a selector checker.</p>
</td></tr>
<tr><td><code id="Start_+3A_merge_across_dims">merge_across_dims</code></td>
<td>
<p>A logical value indicating whether to merge 
dimensions across which another dimension extends (according to the 
'&lt;dimname&gt;_across' parameters). Takes the value FALSE by default. For 
example, if the dimension 'time' extends across the dimension 'chunk' and 
<code>merge_across_dims = TRUE</code>, the resulting data array will only contain
only the dimension 'time' as long as all the chunks together.</p>
</td></tr>
<tr><td><code id="Start_+3A_merge_across_dims_narm">merge_across_dims_narm</code></td>
<td>
<p>A logical value indicating whether to remove
the additional NAs from data when parameter 'merge_across_dims' is TRUE.
It is helpful when the length of the to-be-merged dimension is different 
across another dimension. For example, if the dimension 'time' extends 
across dimension 'chunk', and the time length along the first chunk is 2 
while along the second chunk is 10. Setting this parameter as TRUE can 
remove the additional 8 NAs at position 3 to 10. The default value is TRUE,
but will be automatically turned to FALSE if 'merge_across_dims = FALSE'.</p>
</td></tr>
<tr><td><code id="Start_+3A_split_multiselected_dims">split_multiselected_dims</code></td>
<td>
<p>A logical value indicating whether to split a 
dimension that has been selected with a multidimensional array of selectors
into as many dimensions as present in the selector array. The default value
is FALSE.</p>
</td></tr>
<tr><td><code id="Start_+3A_path_glob_permissive">path_glob_permissive</code></td>
<td>
<p>A logical value or an integer specifying how many
folder levels in the path pattern, beginning from the end, the shell glob
expressions must be preserved and worked out for each file. The default 
value is FALSE, which is equivalent to 0. TRUE is equivalent to 1.<br /><br />
When specifying a path pattern for a dataset, it might contain shell glob 
experissions. For each dataset, the first file matching the path pattern is 
found, and the found file is used to work out fixed values for the glob 
expressions that will be used for all the files of the dataset. However, in 
some cases, the values of the shell glob expressions may not be constant for 
all files in a dataset, and they need to be worked out for each file 
involved.<br /><br />
For example, a path pattern could be as follows: <br />
<code>'/path/to/dataset/$var$_*/$date$_*_foo.nc'</code>. <br /> Leaving 
<code>path_glob_permissive = FALSE</code> will trigger automatic seek of the 
contents to replace the asterisks (e.g. the first asterisk matches with 
<code>'bar'</code> and the second with <code>'baz'</code>. The found contents will be 
used for all files in the dataset (in the example, the path pattern will be
fixed to<br /> <code>'/path/to/dataset/$var$_bar/$date$_baz_foo.nc'</code>. However, if
any of the files in the dataset have other contents in the position of the
asterisks, Start() will not find them (in the example, a file like <br />
<code>'/path/to/dataset/precipitation_bar/19901101_bin_foo.nc'</code> would not be
found). Setting <code>path_glob_permissive = 1</code> would preserve global
expressions in the latest level (in the example, the fixed path pattern
would be<br /> <code>'/path/to/dataset/$var$_bar/$date$_*_foo.nc'</code>, and the
problematic file mentioned before would be found), but of course this would
slow down the Start() call if the dataset involves a large number of
files. Setting <code>path_glob_permissive = 2</code> would leave the original path
pattern with the original glob expressions in the 1st and 2nd levels (in the
example, both asterisks would be preserved, thus would allow Start()
to recognize files such as <br />
<code>'/path/to/dataset/precipitation_zzz/19901101_yyy_foo.nc'</code>).<br /><br />
Note that each glob expression can only represent one possibility (Start() 
chooses the first). Because <code>*</code> is not the tag, which means it cannot
be a dimension of the output array. Therefore, only one possibility can be
adopted. For example, if <br />
<code>'/path/to/dataset/precipitation_*/19901101_*_foo.nc'</code><br />
has two matches:<br />
<code>'/path/to/dataset/precipitation_xxx/19901101_yyy_foo.nc'</code> and<br />
<code>'/path/to/dataset/precipitation_zzz/19901101_yyy_foo.nc'</code>,<br />
only the first found file will be used.</p>
</td></tr>
<tr><td><code id="Start_+3A_largest_dims_length">largest_dims_length</code></td>
<td>
<p>A logical value or a named integer vector
indicating if Start() should examine all the files to get the largest 
length of the inner dimensions (TRUE) or use the first valid file of each 
dataset as the returned dimension length (FALSE). Since examining all the 
files could be time-consuming, a vector can be used to explicitly specify
the expected length of the inner dimensions. For those inner dimensions not
specified, the first valid file will be used. The default value is FALSE.<br /><br />
This parameter is useful when the required files don't have consistent 
inner dimension. For example, there are 10 required experimental data files
of a series of start dates. The data only contain 25 members for the first
2 years while 51 members for the later years. If <code>'largest_dims_length = FALSE'</code>,
the returned member dimension length will be 25 only. The 26th to 51st 
members in the later 8 years will be discarded. If <code>'largest_dims_length = TRUE'</code>,
the returned member dimension length will be 51. To save the resource,
<code>'largest_dims_length = c(member = 51)'</code> can also be used.</p>
</td></tr>
<tr><td><code id="Start_+3A_retrieve">retrieve</code></td>
<td>
<p>A logical value indicating whether to retrieve the data
defined in the Start() call or to explore only its dimension lengths 
and names, and the values for the file and inner dimensions. The default
value is FALSE.</p>
</td></tr>
<tr><td><code id="Start_+3A_num_procs">num_procs</code></td>
<td>
<p>An integer of number of processes to be created for the
parallel execution of the retrieval/transformation/arrangement of the
multiple involved files in a call to Start(). If set to NULL,
takes the number of available cores (as detected by future::availableCores).
The default value is 1 (no parallel execution).</p>
</td></tr>
<tr><td><code id="Start_+3A_objectbigmemory">ObjectBigmemory</code></td>
<td>
<p>a character string to be included as part of the 
bigmemory object name. This parameter is thought to be used internally by the
chunking capabilities of startR.</p>
</td></tr>
<tr><td><code id="Start_+3A_silent">silent</code></td>
<td>
<p>A logical value of whether to display progress messages (FALSE)
or not (TRUE). The default value is FALSE.</p>
</td></tr>
<tr><td><code id="Start_+3A_debug">debug</code></td>
<td>
<p>A logical value of whether to return detailed messages on the
progress and operations in a Start() call (TRUE) or not (FALSE). The
default value is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>retrieve = TRUE</code> the involved data is loaded into RAM memory
and an object of the class 'startR_cube' with the following components is
returned:<br />
</p>
<table role = "presentation">
<tr><td><code>Data</code></td>
<td>

<p>Multidimensional data array with named dimensions, with the data values
requested via <code>...</code> and other parameters. This array can potentially 
contain metadata in the attribute 'variables'.
</p>
</td></tr>
<tr><td><code>Variables</code></td>
<td>

<p>Named list of 1 + N components, containing lists of retrieved variables (as
requested in 'return_vars') common to all the data sources (in the 1st
component, <code>$common</code>), and for each of the N dara sources (named after 
the source name, as specified in ..., or, if not specified, <code>$dat1</code>,
<code>$dat2</code>, ..., <code>$datN</code>). Each of the variables are contained in a
multidimensional array with named dimensions, and potentially with the
attribute 'variables' with additional auxiliary data.
</p>
</td></tr>
<tr><td><code>Files</code></td>
<td>

<p>Multidimensonal character string array with named dimensions. Its dimensions
are the file dimensions (as requested in <code>...</code>). Each cell in this
array contains a path to a retrieved file, or NULL if the corresponding
file was not found.
</p>
</td></tr>
<tr><td><code>NotFoundFiles</code></td>
<td>

<p>Array with the same shape as <code>$Files</code> but with NULL in the
positions for which the corresponding file was found, and a path to the
expected file in the positions for which the corresponding file was not
found.
</p>
</td></tr>
<tr><td><code>FileSelectors</code></td>
<td>

<p>Multidimensional character string array with named dimensions, with the same
shape as <code>$Files</code> and <code>$NotFoundFiles</code>, which contains the
components used to build up the paths to each of the files in the data
sources.
</p>
</td></tr>
<tr><td><code>PatternDim</code></td>
<td>

<p>Character string containing the name of the file pattern dimension.
</p>
</td></tr>
</table>
<p>If <code>retrieve = FALSE</code> the involved data is not loaded into RAM memory and
an object of the class 'startR_header' with the following components is
returned:<br />
</p>
<table role = "presentation">
<tr><td><code>Dimensions</code></td>
<td>

<p>Named vector with the dimension lengths and names of the data involved in
the Start() call.
</p>
</td></tr>
<tr><td><code>Variables</code></td>
<td>

<p>Named list of 1 + N components, containing lists of retrieved variables (as
requested in 'return_vars') common to all the data sources (in the 1st
component, <code>$common</code>), and for each of the N dara sources (named after
the source name, as specified in ..., or, if not specified, <code>$dat1</code>,
<code>$dat2</code>, ..., <code>$datN</code>). Each of the variables are contained in a
multidimensional array with named dimensions, and potentially with the
attribute 'variables' with additional auxiliary data.
</p>
</td></tr>
<tr><td><code>ExpectedFiles</code></td>
<td>

<p>Multidimensonal character string array with named dimensions. Its dimensions
are the file dimensions (as requested in ...). Each cell in this array
contains a path to a file to be retrieved (which may exist or not).
</p>
</td></tr>
<tr><td><code>FileSelectors</code></td>
<td>

<p>Multidimensional character string array with named dimensions, with the same
shape as <code>$Files</code> and <code>$NotFoundFiles</code>, which contains the
components used to build up the paths to each of the files in the data
sources.
</p>
</td></tr>
<tr><td><code>PatternDim</code></td>
<td>

<p>Character string containing the name of the file pattern dimension.
</p>
</td></tr>
<tr><td><code>StartRCall</code></td>
<td>

<p>List of parameters sent to the Start() call, with the parameter
'retrieve' set to TRUE. Intended for calling in order to
retrieve the associated data a posteriori with a call to do.call().
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = 'all',
               longitude = 'all',
               return_vars = list(latitude = 'dat', 
                                  longitude = 'dat', 
                                  time = 'sdate'),
               retrieve = FALSE)

</code></pre>

<hr>
<h2 id='Step'>Define the operation applied on declared data.</h2><span id='topic+Step'></span>

<h3>Description</h3>

<p>The step of the startR workflow after declaring data by Start() call. It 
identifies the operation (i.e., function) and the target and output 
dimensions of data array for the function. Ideally, it expects the dimension
name to be in the same order as the one requested in the Start() call. 
If a different order is specified, startR will reorder the subset dimension 
to the expected order for this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Step(
  fun,
  target_dims,
  output_dims,
  use_libraries = NULL,
  use_attributes = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Step_+3A_fun">fun</code></td>
<td>
<p>A function in R format defining the operation to be applied to the 
data declared by a Start() call. It should only work on the essential 
dimensions rather than all the data dimensions. Since the function will be
called numerous times through all the non-essential dimensions, it is 
recommended to keep them as light as possible.</p>
</td></tr>
<tr><td><code id="Step_+3A_target_dims">target_dims</code></td>
<td>
<p>A vector for single input array or a list of vectors for 
multiple input arrays indicating the names of the dimensions 'fun' to be 
applied along.</p>
</td></tr>
<tr><td><code id="Step_+3A_output_dims">output_dims</code></td>
<td>
<p>A vector for single returned array or a list of vectors 
for multiple returned arrays indicating the dimension names of the function
output.</p>
</td></tr>
<tr><td><code id="Step_+3A_use_libraries">use_libraries</code></td>
<td>
<p>A vector of character string indicating the R library 
names to be used in 'fun'. Only used when the jobs are run on HPCs; if the 
jobs are run locally, load the necessary libraries by <code>library()</code>
directly. The default value is NULL.</p>
</td></tr>
<tr><td><code id="Step_+3A_use_attributes">use_attributes</code></td>
<td>
<p>One or more lists of vectors of character string 
indicating the data attributes to be used in 'fun'. The list name should be
consistent with the list name of 'data' in AddStep(). The default value is 
NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A closure that contains all the objects assigned. It serves as the
input of Addstep().
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = 'all',
               longitude = 'all',
               return_vars = list(latitude = 'dat', 
                                  longitude = 'dat', 
                                  time = 'sdate'),
               retrieve = FALSE)
 fun &lt;- function(x) {
           lat = attributes(x)$Variables$dat1$latitude
           weight = sqrt(cos(lat * pi / 180))
           corrected = Apply(list(x), target_dims = "latitude",
                             fun = function(x) {x * weight})
         }
 step &lt;- Step(fun = fun,
              target_dims = 'latitude',
              output_dims = 'latitude',
              use_libraries = c('multiApply'),
              use_attributes = list(data = "Variables"))
 wf &lt;- AddStep(data, step)

</code></pre>

<hr>
<h2 id='values'>Specify dimension selectors with actual values</h2><span id='topic+values'></span>

<h3>Description</h3>

<p>This is a helper function used in a Start() call to define the desired range
of dimensions. It specifies the actual value to be matched with the 
coordinate variable. See details in the documentation of the parameter 
<code>...</code> 'indices to take' of the function Start().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>values(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="values_+3A_x">x</code></td>
<td>
<p>A numeric vector or a list with two nemerics to take all the element 
between the two specified values (both extremes inclusive).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Same as input, but with additional attribute 'indices', 'values', and
'chunk'.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+indices">indices</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Used in Start():
 data_path &lt;- system.file('extdata', package = 'startR')
 path_obs &lt;- file.path(data_path, 'obs/monthly_mean/$var$/$var$_$sdate$.nc')
 sdates &lt;- c('200011', '200012')
 data &lt;- Start(dat = list(list(path = path_obs)),
               var = 'tos',
               sdate = sdates,
               time = 'all',
               latitude = values(seq(-80, 80, 20)),
               latitude_reorder = Sort(),
               longitude = values(list(10, 300)),
               longitude_reorder = CircularSort(0, 360),
               return_vars = list(latitude = 'dat', 
                                  longitude = 'dat', 
                                  time = 'sdate'),
               retrieve = FALSE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
