<!DOCTYPE html><html><head><title>Help for package CVThresh</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CVThresh}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cvimpute.by.wavelet'><p>Imputation by wavelet</p></a></li>
<li><a href='#cvimpute.image.by.wavelet'><p>Imputation for two-dimensional data by wavelet</p></a></li>
<li><a href='#CVThresh'><p>Level-Dependent Cross-Validation Approach for Wavelet Thresholding</p></a></li>
<li><a href='#cvtype'><p>Generating test dataset index for cross-validation</p></a></li>
<li><a href='#cvtype.image'><p>Generating test dataset index of two-dimensional data for cross-validation</p></a></li>
<li><a href='#cvwavelet'><p>Wavelet reconstruction by level-dependent Cross-Validation</p></a></li>
<li><a href='#cvwavelet.after.impute'><p>Cross-Validation Wavelet Shrinkage after imputation</p></a></li>
<li><a href='#cvwavelet.image'><p>Wavelet reconstruction of image by level-dependent Cross-Validation</p></a></li>
<li><a href='#cvwavelet.image.after.impute'><p>Cross-Validation Wavelet Shrinkage for two-dimensional data after imputation</p></a></li>
<li><a href='#dopp'><p>Doppler function</p></a></li>
<li><a href='#fg1'><p>fg1 function</p></a></li>
<li><a href='#heav'><p>Heavisine function</p></a></li>
<li><a href='#ipd'><p>Inductance plethysmography data</p></a></li>
<li><a href='#ppoly'><p>Piecewise polynomial function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Level-Dependent Cross-Validation Thresholding</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-05-02</td>
</tr>
<tr>
<td>Author:</td>
<td>Donghoh Kim &lt;donghoh.kim@gmail.com&gt;,
        Hee-Seok Oh &lt;heeseok@stats.snu.ac.kr&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Donghoh Kim &lt;donghoh.kim@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.15.1), wavethresh (&ge; 4.6.1), EbayesThresh (&ge; 1.3.2)</td>
</tr>
<tr>
<td>Description:</td>
<td>The level-dependent cross-validation method is implemented
        for the selection of thresholding
        value in wavelet shrinkage. This procedure is implemented
        by coupling a conventional cross validation with an
        imputation method due to a limitation of data length,
        a power of 2. It can be easily applied to classical
        leave-one-out and k-fold cross validation.
        Since the procedure is computationally fast,
        a level-dependent cross validation can be performed for
        wavelet shrinkage of various data such as a data
        with correlated errors.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-02 03:00:08 UTC; donghohkim</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-02 03:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cvimpute.by.wavelet'>Imputation by wavelet</h2><span id='topic+cvimpute.by.wavelet'></span>

<h3>Description</h3>

<p>This function performs imputation for test dataset of cross-validation
given test dataset index and initial values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvimpute.by.wavelet(y, impute.index, impute.tol=0.1^3, 
    impute.maxiter=100, impute.vscale="independent",
    filter.number=10, family="DaubLeAsymm", ll=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvimpute.by.wavelet_+3A_y">y</code></td>
<td>
<p>observation</p>
</td></tr>
<tr><td><code id="cvimpute.by.wavelet_+3A_impute.index">impute.index</code></td>
<td>
<p>test dataset index for cross-validation</p>
</td></tr>
<tr><td><code id="cvimpute.by.wavelet_+3A_impute.tol">impute.tol</code></td>
<td>
<p>tolerance for imputation</p>
</td></tr>
<tr><td><code id="cvimpute.by.wavelet_+3A_impute.maxiter">impute.maxiter</code></td>
<td>
<p>maximum iteration for imputation</p>
</td></tr>
<tr><td><code id="cvimpute.by.wavelet_+3A_impute.vscale">impute.vscale</code></td>
<td>
<p>specifies whether variance is adjusted level-by-level or not. &ldquo;level&quot; or &ldquo;independent&quot;</p>
</td></tr>
<tr><td><code id="cvimpute.by.wavelet_+3A_filter.number">filter.number</code></td>
<td>
<p>specifies the smoothness of wavelet in the decomposition (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvimpute.by.wavelet_+3A_family">family</code></td>
<td>
<p>specifies the family of wavelets &ldquo;DaubExPhase&quot; or &ldquo;DaubLeAsymm&quot; (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvimpute.by.wavelet_+3A_ll">ll</code></td>
<td>
<p>specifies the lowest level to be thresholded</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In wavelet context, test dataset of cross-validation is missing values.
Based on h-likelihood concept and penalized least squares,
this function performs imputation by wavelet for missing dataset, given the missing dataset.
Lee and Nelder (1996, 2001) introduced the hierarchical likelihood as an extended likelihood
for general models that include unobserved random variables such as missing.
Following Lee and Nelder (1996, 2001), treat the missing values as random parameters
and it has been known that a wavelet shrinkage estimator can be formulated by penalized
least squares problem (Antoniadis and Fan, 2001). This arguments lead to the iterative
algorithm for imputing the missing values based on wavelet shrinkage.
</p>


<h3>Value</h3>

<p>Imputed values according to cross-validation scheme.
</p>


<h3>References</h3>

<p>Antoniadis, A. and Fan, J. (2001) Regularization of wavelet approximations. 
<em>Journal of the American Statistical Association</em>, <b>96</b>, 939&ndash;962.
</p>
<p>Lee, Y. and Nelder, J.A. (1996) Hierarchical generalised linear models (with discussion). 
<em>Journal of the Royal Statistical Society Ser. B</em>, <b>58</b>, 619&ndash;678.
</p>
<p>Lee, Y. and Nelder, J.A. (2001) Hierarchical generalised linear models: A synthesis of generalised
linear models, random-effect models and structured dispersions. <em>Biometrika</em>, <b>88</b>, 987&ndash;1006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvwavelet">cvwavelet</a></code>, <code><a href="#topic+cvtype">cvtype</a></code>, <code><a href="#topic+cvwavelet.after.impute">cvwavelet.after.impute</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 8-fold cross-validation scheme with block size 2
set.seed(1)
cv.index &lt;- cvtype(n=1024, cv.bsize=2, cv.kfold=8, cv.random=TRUE)$cv.index

# Generate 1024 observation from Heavisine function
snr &lt;- 5
testdata &lt;- heav(1024)
x &lt;- testdata$x
y &lt;- testdata$meanf + rnorm(1024, 0, testdata$sdf / snr)

# Impute by wavelet
yimpute &lt;- cvimpute.by.wavelet(y=y, impute.index=cv.index)$yimpute

# Compare imputed values and observations
par(mar=0.1+c(4,4,2,1))
plot(y, yimpute, xlab="Observations", ylab="Imputed Values",
     main="Piecewise Polynomial", cex=0.5);abline(0,1)
</code></pre>

<hr>
<h2 id='cvimpute.image.by.wavelet'>Imputation for two-dimensional data by wavelet</h2><span id='topic+cvimpute.image.by.wavelet'></span>

<h3>Description</h3>

<p>This function performs imputation for two-dimensional test dataset of cross-validation
given test dataset index and initial values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvimpute.image.by.wavelet(images, impute.index1, impute.index2, 
   impute.tol=0.1^3, impute.maxiter=100, filter.number=2, ll=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvimpute.image.by.wavelet_+3A_images">images</code></td>
<td>
<p>noisy image</p>
</td></tr>
<tr><td><code id="cvimpute.image.by.wavelet_+3A_impute.index1">impute.index1</code></td>
<td>
<p>test dataset row index according to cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvimpute.image.by.wavelet_+3A_impute.index2">impute.index2</code></td>
<td>
<p>test dataset column index according to cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvimpute.image.by.wavelet_+3A_impute.tol">impute.tol</code></td>
<td>
<p>tolerance for imputation</p>
</td></tr>
<tr><td><code id="cvimpute.image.by.wavelet_+3A_impute.maxiter">impute.maxiter</code></td>
<td>
<p>maximum iteration for imputation</p>
</td></tr>
<tr><td><code id="cvimpute.image.by.wavelet_+3A_filter.number">filter.number</code></td>
<td>
<p>specifies the smoothness of wavelet in the decomposition (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvimpute.image.by.wavelet_+3A_ll">ll</code></td>
<td>
<p>specifies the lowest level to be thresholded</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In wavelet context, test dataset of cross-validation is missing values.
Based on h-likelihood concept and penalized least squares,
this function performs imputation by wavelet for missing dataset, given the missing dataset.
Lee and Nelder (1996, 2001) introduced the hierarchical likelihood as an extended likelihood
for general models that include unobserved random variables such as missing.
Following Lee and Nelder (1996, 2001), treat the missing values as random parameters
and it has been known that a wavelet shrinkage estimator can be formulated by penalized
least squares problem (Antoniadis and Fan, 2001). This arguments lead to the iterative
algorithm for imputing the missing values based on wavelet shrinkage.
</p>


<h3>Value</h3>

<p>Imputed values according to cross-validation scheme.
</p>


<h3>References</h3>

<p>Antoniadis, A. and Fan, J. (2001) Regularization of wavelet approximations. 
<em>Journal of the American Statistical Association</em>, <b>96</b>, 939&ndash;962.
</p>
<p>Lee, Y. and Nelder, J.A. (1996) Hierarchical generalised linear models (with discussion). 
<em>Journal of the Royal Statistical Society Ser. B</em>, <b>58</b>, 619&ndash;678.
</p>
<p>Lee, Y. and Nelder, J.A. (2001) Hierarchical generalised linear models: A synthesis of generalised
linear models, random-effect models and structured dispersions. <em>Biometrika</em>, <b>88</b>, 987&ndash;1006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvtype.image">cvtype.image</a></code>, <code><a href="#topic+cvwavelet">cvwavelet</a></code>, <code><a href="#topic+cvimpute.by.wavelet">cvimpute.by.wavelet</a></code>, 
</p>
<p><code><a href="#topic+cvwavelet.after.impute">cvwavelet.after.impute</a></code>, <code><a href="#topic+cvwavelet.image">cvwavelet.image</a></code>, 
</p>
<p><code><a href="#topic+cvwavelet.image.after.impute">cvwavelet.image.after.impute</a></code>
</p>

<hr>
<h2 id='CVThresh'>Level-Dependent Cross-Validation Approach for Wavelet Thresholding</h2><span id='topic+CVThresh-package'></span><span id='topic+CVThresh'></span>

<h3>Description</h3>

<p>This package carries out level-dependent
cross-validation method for the selection of thresholding
value in wavelet shrinkage. This procedure is implemented
by coupling a conventional cross validation with an
imputation method due to a limitation of data length,
a power of 2. It can be easily applied to classical
leave-one-out and k-fold cross validation.
Since the procedure is computationally fast,
a level-dependent cross validation can be performed for
wavelet shrinkage of various data such as a data
with correlated errors.
</p>

<hr>
<h2 id='cvtype'>Generating test dataset index for cross-validation</h2><span id='topic+cvtype'></span>

<h3>Description</h3>

<p>This function generates test dataset index for cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvtype(n, cv.bsize=1, cv.kfold, cv.random=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvtype_+3A_n">n</code></td>
<td>
<p>the number of observation</p>
</td></tr>
<tr><td><code id="cvtype_+3A_cv.bsize">cv.bsize</code></td>
<td>
<p>block size of cross-validation</p>
</td></tr>
<tr><td><code id="cvtype_+3A_cv.kfold">cv.kfold</code></td>
<td>
<p>the number of fold of cross-validation</p>
</td></tr>
<tr><td><code id="cvtype_+3A_cv.random">cv.random</code></td>
<td>
<p>whether or not random cross-validation scheme should be used. Set cv.random=TRUE
for random cross-validation scheme</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides index of test dataset according to various cross-validation scheme.
One may construct K test datasets in a way that each testset consists of blocks of b
consecutive data. Set <code>cv.bsize = b</code> for this. 
To select each fold at random, set <code>cv.random = TRUE</code>.
</p>


<h3>Value</h3>

<p>matrix of which row is test dataset index for cross-validation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvwavelet">cvwavelet</a></code>,
<code><a href="#topic+cvimpute.by.wavelet">cvimpute.by.wavelet</a></code>,
<code><a href="#topic+cvwavelet.after.impute">cvwavelet.after.impute</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Traditional 4-fold cross-validation for 100 observations
cvtype(n=100, cv.bsize=1, cv.kfold=4, cv.random=FALSE)
# Random 4-fold cross-validation with block size 2 for 100 observations
cvtype(n=100, cv.bsize=2, cv.kfold=4, cv.random=TRUE)
</code></pre>

<hr>
<h2 id='cvtype.image'>Generating test dataset index of two-dimensional data for cross-validation</h2><span id='topic+cvtype.image'></span>

<h3>Description</h3>

<p>This function generates test dataset index of two-dimensional data for cross-validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvtype.image(n, cv.bsize=c(1,1), cv.kfold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvtype.image_+3A_n">n</code></td>
<td>
<p>the size of image</p>
</td></tr>
<tr><td><code id="cvtype.image_+3A_cv.bsize">cv.bsize</code></td>
<td>
<p>two-dimensional block size of cross-validation</p>
</td></tr>
<tr><td><code id="cvtype.image_+3A_cv.kfold">cv.kfold</code></td>
<td>
<p>the number of fold of cross-validation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides indexes of two-dimensional cross-validation scheme. 
Only random cross-validation scheme is provided.
</p>


<h3>Value</h3>

<p>Two matrix representing test dataset index of each dimension for cross-validation.
</p>
<table>
<tr><td><code>cv.index1</code></td>
<td>
<p>each row is test dataset index of one dimension</p>
</td></tr>
<tr><td><code>cv.index2</code></td>
<td>
<p>each row is test dataset index of the other dimension</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+cvtype">cvtype</a></code>, <code><a href="#topic+cvwavelet">cvwavelet</a></code>, <code><a href="#topic+cvimpute.by.wavelet">cvimpute.by.wavelet</a></code>, 
</p>
<p><code><a href="#topic+cvwavelet.after.impute">cvwavelet.after.impute</a></code>, <code><a href="#topic+cvwavelet.image">cvwavelet.image</a></code>, 
</p>
<p><code><a href="#topic+cvimpute.image.by.wavelet">cvimpute.image.by.wavelet</a></code>, <code><a href="#topic+cvwavelet.image.after.impute">cvwavelet.image.after.impute</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Two-dimensional 4-fold cross-validation with block size 2*2
out &lt;- cvtype.image(n=c(256,256), cv.bsize=c(2,2), cv.kfold=4)
</code></pre>

<hr>
<h2 id='cvwavelet'>Wavelet reconstruction by level-dependent Cross-Validation</h2><span id='topic+cvwavelet'></span>

<h3>Description</h3>

<p>This function reconstructs the noise data by level-dependent cross-validation wavelet shrinkage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvwavelet(y=y, ywd=ywd, cv.optlevel, cv.bsize=1, cv.kfold, 
    cv.random=TRUE, cv.tol=0.1^3, cv.maxiter=100,
    impute.vscale="independent", impute.tol=0.1^3, impute.maxiter=100,
    filter.number=10, family="DaubLeAsymm", thresh.type ="soft", ll=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvwavelet_+3A_y">y</code></td>
<td>
<p>observation</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_ywd">ywd</code></td>
<td>
<p>DWT object</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_cv.optlevel">cv.optlevel</code></td>
<td>
<p>thresholding levels</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_cv.bsize">cv.bsize</code></td>
<td>
<p>block size of cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_cv.kfold">cv.kfold</code></td>
<td>
<p>the number of fold of cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_cv.random">cv.random</code></td>
<td>
<p>whether or not random cross-validation scheme should be used. Set cv.random=TRUE
for random cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_cv.tol">cv.tol</code></td>
<td>
<p>tolerance for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_cv.maxiter">cv.maxiter</code></td>
<td>
<p> maximum iteration for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_impute.vscale">impute.vscale</code></td>
<td>
<p>specifies whether variance is adjusted level-by-level or not. &ldquo;level&quot; or &ldquo;independent&quot;</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_impute.tol">impute.tol</code></td>
<td>
<p>tolerance for imputation</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_impute.maxiter">impute.maxiter</code></td>
<td>
<p>maximum iteration for imputation</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_filter.number">filter.number</code></td>
<td>
<p>specifies the smoothness of wavelet in the decomposition (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_family">family</code></td>
<td>
<p>specifies the family of wavelets &ldquo;DaubExPhase&quot; or &ldquo;DaubLeAsymm&quot; (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_thresh.type">thresh.type</code></td>
<td>
<p>specifies the type of thresholding &ldquo;hard&quot; or &ldquo;soft&quot; (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet_+3A_ll">ll</code></td>
<td>
<p>specifies the lowest level to be thresholded</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs level-dependent cross-validation wavelet shrinkage.
</p>


<h3>Value</h3>

<table>
<tr><td><code>y</code></td>
<td>
<p>observations</p>
</td></tr>
<tr><td><code>yimpute</code></td>
<td>
<p>imputed values by provided cross-validation scheme</p>
</td></tr>
<tr><td><code>yc</code></td>
<td>
<p>reconstruction by level-dependent cross-validation wavelet shrinkage</p>
</td></tr>
<tr><td><code>cvthresh</code></td>
<td>
<p>threshold values by level-dependent cross-validation</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+cvtype">cvtype</a></code>, <code><a href="#topic+cvimpute.by.wavelet">cvimpute.by.wavelet</a></code>, <code><a href="#topic+cvwavelet.after.impute">cvwavelet.after.impute</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ipd)
y &lt;- as.numeric(ipd); n &lt;- length(y); nlevel &lt;- log2(n)
ywd &lt;- wd(y)
#out &lt;- cvwavelet(y=y, ywd=ywd, cv.optlevel=c(3:(nlevel-1)), 
#                     cv.bsize=2, cv.kfold=4)

#ts.plot(ts(out$yc, start=1229.98, deltat=0.02, frequency=50),
#   main="Level-dependent Cross Validation", xlab = "Seconds", ylab="")
</code></pre>

<hr>
<h2 id='cvwavelet.after.impute'>Cross-Validation Wavelet Shrinkage after imputation</h2><span id='topic+cvwavelet.after.impute'></span>

<h3>Description</h3>

<p>This function performs level-dependent cross-validation wavelet shrinkage 
given the cross-validation scheme and imputation values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvwavelet.after.impute(y, ywd, yimpute,
    cv.index, cv.optlevel, cv.tol=0.1^3, cv.maxiter=100,
    filter.number=10, family="DaubLeAsymm", thresh.type="soft", ll=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvwavelet.after.impute_+3A_y">y</code></td>
<td>
<p>observation</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_ywd">ywd</code></td>
<td>
<p>DWT object</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_yimpute">yimpute</code></td>
<td>
<p>imputed values according to cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_cv.index">cv.index</code></td>
<td>
<p>test dataset index according to cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_cv.optlevel">cv.optlevel</code></td>
<td>
<p>thresholding levels</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_cv.tol">cv.tol</code></td>
<td>
<p>tolerance for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_cv.maxiter">cv.maxiter</code></td>
<td>
<p>maximum iteration for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_filter.number">filter.number</code></td>
<td>
<p>specifies the smoothness of wavelet in the decomposition (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_family">family</code></td>
<td>
<p>specifies the family of wavelets &ldquo;DaubExPhase&quot; or &ldquo;DaubLeAsymm&quot; (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_thresh.type">thresh.type</code></td>
<td>
<p>specifies the type of thresholding &ldquo;hard&quot; or &ldquo;soft&quot; (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet.after.impute_+3A_ll">ll</code></td>
<td>
<p>specifies the lowest level to be thresholded</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculating the threshold values and reconstructing noisy data <code class="reqn">y</code>, given the index of each testdata,
imputed values according to cross-validation scheme and discrete wavelet transform of <code class="reqn">y</code>.
</p>


<h3>Value</h3>

<p>Reconstruction and thresholding values by level-dependent cross-validation
</p>
<table>
<tr><td><code>yc</code></td>
<td>
<p>reconstruction</p>
</td></tr>
<tr><td><code>cvthresh</code></td>
<td>
<p>thresholding values by level-dependent cross-validation</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+cvwavelet">cvwavelet</a></code>, <code><a href="#topic+cvtype">cvtype</a></code>, <code><a href="#topic+cvimpute.by.wavelet">cvimpute.by.wavelet</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ipd)
y &lt;- as.numeric(ipd); n &lt;- length(y); nlevel &lt;- log2(n)

set.seed(1)
cv.index &lt;- cvtype(n=n, cv.bsize=2, cv.kfold=4, cv.random=TRUE)$cv.index
yimpute &lt;- cvimpute.by.wavelet(y=y, impute.index=cv.index)$yimpute

ywd &lt;- wd(y)

#out &lt;- cvwavelet.after.impute(y=y, ywd=ywd, yimpute=yimpute,
#cv.index=cv.index, cv.optlevel=c(3:(nlevel-1)))

#ts.plot(ts(out$yc, start=1229.98, deltat=0.02, frequency=50),
#   main="Level-dependent Cross Validation", xlab = "Seconds", ylab="")

##### Specifying thresholding structure
# cv.optlevel &lt;- c(3) # Threshold (level 3 to finest level) at the same time.
# cv.optlevel &lt;- c(3, 5) # Threshold two groups of resolution levels,
                         # (level 3, 4) and  (level 5 to finest level).
# cv.optlevel &lt;- c(3,4,5,6,7,8) # Threshold each resolution level 3 to 8.
</code></pre>

<hr>
<h2 id='cvwavelet.image'>Wavelet reconstruction of image by level-dependent Cross-Validation</h2><span id='topic+cvwavelet.image'></span>

<h3>Description</h3>

<p>This function reconstructs image by level-dependent cross-validation wavelet shrinkage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvwavelet.image(images, imagewd,
    cv.optlevel, cv.bsize=c(1,1), cv.kfold, cv.tol=0.1^3, cv.maxiter=100,
    impute.tol=0.1^3, impute.maxiter=100, filter.number=2, ll=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvwavelet.image_+3A_images">images</code></td>
<td>
<p>noisy image</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_imagewd">imagewd</code></td>
<td>
<p>two-dimensional wavelet transform</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_cv.optlevel">cv.optlevel</code></td>
<td>
<p>thresholding level</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_cv.bsize">cv.bsize</code></td>
<td>
<p>block size of cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_cv.kfold">cv.kfold</code></td>
<td>
<p>the number of fold of cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_cv.tol">cv.tol</code></td>
<td>
<p>tolerance for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_cv.maxiter">cv.maxiter</code></td>
<td>
<p>maximum iteration for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_impute.tol">impute.tol</code></td>
<td>
<p>tolerance for imputation</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_impute.maxiter">impute.maxiter</code></td>
<td>
<p>maximum iteration for imputation</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_filter.number">filter.number</code></td>
<td>
<p>specifies the smoothness of wavelet in the decomposition (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet.image_+3A_ll">ll</code></td>
<td>
<p>specifies the lowest level to be thresholded</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs level-dependent cross-validation wavelet shrinkage for two-dimensional data.
</p>


<h3>Value</h3>

<table>
<tr><td><code>imagecv</code></td>
<td>
<p>reconstruction of image by level-dependent cross-validation wavelet shrinkage</p>
</td></tr>
<tr><td><code>cvthresh</code></td>
<td>
<p>threshold values by level-dependent cross-validation</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+cvtype.image">cvtype.image</a></code>, <code><a href="#topic+cvimpute.image.by.wavelet">cvimpute.image.by.wavelet</a></code>, <br />
<code><a href="#topic+cvwavelet.image.after.impute">cvwavelet.image.after.impute</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
# Generate Noisy Lennon Image
data(lennon)
sdimage &lt;- sd(as.numeric(lennon))
nlennon &lt;- ncol(lennon); nlevel &lt;- log2(ncol(lennon))
optlevel &lt;- c(3:(nlevel-1))
set.seed(55)
lennonnoise &lt;- lennon+matrix(rnorm(nlennon^2, 0, sdimage), nlennon, nlennon)

# Level-dependent Cross-validation Thresholding
lennonwd &lt;- imwd(lennonnoise)
#lennoncv &lt;- cvwavelet.image(images=lennonnoise, imagewd=lennonwd,
#      cv.optlevel=optlevel, cv.bsize=c(1,1), cv.kfold=10)$imagecv
#image(lennoncv, axes=FALSE, col=gray(100:0/100), 
#   main="Level-dependent CV")
</code></pre>

<hr>
<h2 id='cvwavelet.image.after.impute'>Cross-Validation Wavelet Shrinkage for two-dimensional data after imputation</h2><span id='topic+cvwavelet.image.after.impute'></span>

<h3>Description</h3>

<p>This function performs level-dependent cross-validation wavelet shrinkage for two-dimensional data 
given the cross-validation scheme and imputation values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvwavelet.image.after.impute(images, imagewd, imageimpute,
   cv.index1=cv.index1, cv.index2=cv.index2,
   cv.optlevel=cv.optlevel, cv.tol=cv.tol, cv.maxiter=cv.maxiter,
   filter.number=2, ll=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvwavelet.image.after.impute_+3A_images">images</code></td>
<td>
<p>noisy image</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_imagewd">imagewd</code></td>
<td>
<p>two-dimensional wavelet transform</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_imageimpute">imageimpute</code></td>
<td>
<p>two-dimensional imputed values according to cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_cv.index1">cv.index1</code></td>
<td>
<p>test dataset row index according to cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_cv.index2">cv.index2</code></td>
<td>
<p>test dataset column index according to cross-validation scheme</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_cv.optlevel">cv.optlevel</code></td>
<td>
<p>thresholding levels</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_cv.tol">cv.tol</code></td>
<td>
<p>tolerance for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_cv.maxiter">cv.maxiter</code></td>
<td>
<p>maximum iteration for cross-validation</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_filter.number">filter.number</code></td>
<td>
<p>specifies the smoothness of wavelet in the decomposition (argument of WaveThresh)</p>
</td></tr>
<tr><td><code id="cvwavelet.image.after.impute_+3A_ll">ll</code></td>
<td>
<p>specifies the lowest level to be thresholded</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculating thresholding values and reconstructing noisy image
given cross-validation scheme and imputation.
</p>


<h3>Value</h3>

<p>Reconstruction of images and thresholding values by level-dependent cross-validation
</p>
<table>
<tr><td><code>imagecv</code></td>
<td>
<p>reconstruction of images</p>
</td></tr>
<tr><td><code>cvthresh</code></td>
<td>
<p>thresholding values by level-dependent cross-validation</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+cvwavelet.image">cvwavelet.image</a></code>, <code><a href="#topic+cvtype.image">cvtype.image</a></code>, <code><a href="#topic+cvimpute.image.by.wavelet">cvimpute.image.by.wavelet</a></code>.
</p>

<hr>
<h2 id='dopp'>Doppler function</h2><span id='topic+dopp'></span>

<h3>Description</h3>

<p>This function generates Doppler function values for <code class="reqn">n</code> equally spaced points in <code class="reqn">[0,1]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dopp(norx=1024)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dopp_+3A_norx">norx</code></td>
<td>
<p>the number of data or x values in [0, 1]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Doppler function is introduced by Donoho and Johnstone (1994) and is useful test function
evaluating a wavelet shrinkage method.
</p>


<h3>Value</h3>

<p>Doppler function values <code class="reqn">f(\frac{i}{n}), i=1,\ldots,n</code> and its variability
<code class="reqn">||f|| = \frac{\sum_{i=1}^n (f_i - \bar f)^2}{n-1}</code>
where <code class="reqn">\bar f = \frac{\sum_{i=1}^n f_i}{n}</code>.
</p>


<h3>References</h3>

<p>Donoho, D.L. and Johnstone, I.M. (1994) Ideal spatial adaptation by wavelet shrinkage. 
<em>Biometrika</em>, <b>81</b>, 425&ndash;455.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+heav">heav</a></code>, <code><a href="#topic+ppoly">ppoly</a></code>, <code><a href="#topic+fg1">fg1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testdopp &lt;- dopp(1024)
plot(testdopp$x, testdopp$meanf, xlab="", ylab="", 
     main="Plot of Doppler function", type="l")
</code></pre>

<hr>
<h2 id='fg1'>fg1 function</h2><span id='topic+fg1'></span>

<h3>Description</h3>

<p>This function generates fg1 function values for <code class="reqn">n</code> equally spaced points in <code class="reqn">[0,1]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fg1(norx=1024)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fg1_+3A_norx">norx</code></td>
<td>
<p>the number of data or x values in [0, 1]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A smooth function fg1 is introduced by Fan and Gijbels (1995) and is useful test function
evaluating a wavelet shrinkage method.
</p>


<h3>Value</h3>

<p>fg1 function values <code class="reqn">f(\frac{i}{n}), i=1,\ldots,n</code> and its variability
<code class="reqn">||f|| = \frac{\sum_{i=1}^n (f_i - \bar f)^2}{n-1}</code>
where <code class="reqn">\bar f = \frac{\sum_{i=1}^n f_i}{n}</code>.
</p>


<h3>References</h3>

<p>Fan, J. and Gijbels, I. (1995)  Data-driven bandwidth selection in local polynomial fitting: Variable
bandwidth and spatial adaptation. <em>Journal of the Royal Statistical Society Ser. B</em> <b>57</b>, 371&ndash;394.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dopp">dopp</a></code>, <code><a href="#topic+heav">heav</a></code>, <code><a href="#topic+ppoly">ppoly</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testfg1 &lt;- fg1(1024)
plot(testfg1$x, testfg1$meanf, xlab="", ylab="", 
     main="Plot of fg1 function", type="l")
</code></pre>

<hr>
<h2 id='heav'>Heavisine function</h2><span id='topic+heav'></span>

<h3>Description</h3>

<p>This function generates Heavisine function values for <code class="reqn">n</code> equally spaced points in <code class="reqn">[0,1]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heav(norx=1024)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heav_+3A_norx">norx</code></td>
<td>
<p>the number of data or x values in [0, 1]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Heavisine function is introduced by Donoho and Johnstone (1994) and is useful test function
evaluating a wavelet shrinkage method.
</p>


<h3>Value</h3>

<p>Heavisine function values <code class="reqn">f(\frac{i}{n}), i=1,\ldots,n</code> and its variability
<code class="reqn">||f|| = \frac{\sum_{i=1}^n (f_i - \bar f)^2}{n-1}</code>
where <code class="reqn">\bar f = \frac{\sum_{i=1}^n f_i}{n}</code>.
</p>


<h3>References</h3>

<p>Donoho, D.L. and Johnstone, I.M. (1994) Ideal spatial adaptation by wavelet shrinkage. 
<em>Biometrika</em>, <b>81</b>, 425&ndash;455.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dopp">dopp</a></code>, <code><a href="#topic+ppoly">ppoly</a></code>, <code><a href="#topic+fg1">fg1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testheav &lt;- heav(1024)
plot(testheav$x, testheav$meanf, xlab="", ylab="", 
     main="Plot of Heavisine function", type="l")
</code></pre>

<hr>
<h2 id='ipd'>Inductance plethysmography data</h2><span id='topic+ipd'></span>

<h3>Description</h3>

<p>4,096 observations of
inductance plethysmography data regularly sampled at 50Hz starting at 1229.98 seconds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ipd)
</code></pre>


<h3>Format</h3>

<p>time series.
</p>


<h3>Source</h3>

<p>This data set contains 4,096 observations of
inductance plethysmography data regularly sampled at 50Hz starting at 1229.98 seconds. The data
were collected in an investigation of the recovery of patients after general anesthesia.
</p>
<p>The data set was used in Nason (1996) to illustrate cross-validation method for threshold selection. 
See the reference; Nason, G.P. (1996) Wavelet shrinkage by cross-validation. <em>Journal of the Royal Statistical
Society Ser. B</em> <b>58</b>, 463&ndash;479.
</p>

<hr>
<h2 id='ppoly'>Piecewise polynomial function</h2><span id='topic+poly'></span><span id='topic+ppoly'></span>

<h3>Description</h3>

<p>This function generates Piecewise polynomial function values for <code class="reqn">n</code> equally spaced points in <code class="reqn">[0,1]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppoly(norx=1024)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ppoly_+3A_norx">norx</code></td>
<td>
<p>the number of data or x values in [0, 1]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Piecewise polynomial function with the discontinuity is introduced by Nason and Silverman (1994) and
is useful test function evaluating a wavelet shrinkage method.
</p>


<h3>Value</h3>

<p>Piecewise polynomial function values <code class="reqn">f(\frac{i}{n}), i=1,\ldots,n</code> and its variability
<code class="reqn">||f|| = \frac{\sum_{i=1}^n (f_i - \bar f)^2}{n-1}</code>
where <code class="reqn">\bar f = \frac{\sum_{i=1}^n f_i}{n}</code>.
</p>


<h3>References</h3>

<p>Nason, G.P. and Silverman, B.W. (1994) The discrete wavelet transform in S. 
<em>Journal of Computational and Graphical Statistics</em>, <b>3</b>, 163&ndash;191.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dopp">dopp</a></code>, <code><a href="#topic+heav">heav</a></code>, <code><a href="#topic+fg1">fg1</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testpoly &lt;- ppoly(1024)
plot(testpoly$x, testpoly$meanf, xlab="", ylab="", 
     main="Plot of Piecewise polynomial function", type="l")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
