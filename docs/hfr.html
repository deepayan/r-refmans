<!DOCTYPE html><html><head><title>Help for package hfr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hfr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.hfr'><p>Cross validation for a hierarchical feature regression</p></a></li>
<li><a href='#hfr'><p>Fit a hierarchical feature regression</p></a></li>
<li><a href='#plot.cv.hfr'><p>Plot the dendrogram of an HFR model</p></a></li>
<li><a href='#plot.hfr'><p>Plot the dendrogram of an HFR model</p></a></li>
<li><a href='#predict.cv.hfr'><p>Model predictions</p></a></li>
<li><a href='#predict.hfr'><p>Model predictions</p></a></li>
<li><a href='#print.cv.hfr'><p>Print an HFR model</p></a></li>
<li><a href='#print.hfr'><p>Print an HFR model</p></a></li>
<li><a href='#se.avg'><p>Calculate approximate standard errors for a fitted HFR model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimate Hierarchical Feature Regression Models</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-27</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Johann Pfitzinger [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Johann Pfitzinger &lt;johann.pfitzinger@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for the estimation, plotting, predicting and cross-validation of hierarchical feature regression models as described in Pfitzinger (2024). Cluster Regularization via a Hierarchical Feature Regression. Econometrics and Statistics (in press). &lt;<a href="https://doi.org/10.1016%2Fj.ecosta.2024.01.003">doi:10.1016/j.ecosta.2024.01.003</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>quadprog, stats, dendextend, RColorBrewer, corpcor</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://hfr.residualmetrics.com">https://hfr.residualmetrics.com</a>,
<a href="https://github.com/jpfitzinger/hfr">https://github.com/jpfitzinger/hfr</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-27 16:37:12 UTC; johann</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-27 19:40:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.hfr'>Cross validation for a hierarchical feature regression</h2><span id='topic+cv.hfr'></span>

<h3>Description</h3>

<p>HFR is a regularized regression estimator that decomposes a least squares
regression along a supervised hierarchical graph, and shrinks the edges of the
estimated graph to regularize parameters. The algorithm leads to group shrinkage in the
regression parameters and a reduction in the effective model degrees of freedom.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.hfr(
  x,
  y,
  weights = NULL,
  kappa = seq(0, 1, by = 0.1),
  q = NULL,
  intercept = TRUE,
  standardize = TRUE,
  nfolds = 10,
  foldid = NULL,
  partial_method = c("pairwise", "shrinkage"),
  l2_penalty = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.hfr_+3A_x">x</code></td>
<td>
<p>Input matrix or data.frame, of dimension <code class="reqn">(N\times p)</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_y">y</code></td>
<td>
<p>Response variable.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting process. Should be NULL or a numeric vector. If non-NULL, weighted least squares is used for the level-specific regressions.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_kappa">kappa</code></td>
<td>
<p>A vector of target effective degrees of freedom of the regression.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_q">q</code></td>
<td>
<p>Thinning parameter representing the quantile cut-off (in terms of contributed variance) above which to consider levels in the hierarchy. This can used to reduce the number of levels in high-dimensional problems. Default is no thinning.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept be fitted. Default is <code>intercept=TRUE</code>.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for <code>x</code> variable standardization prior to fitting the model. The coefficients are always returned on the original scale. Default is <code>standardize=TRUE</code>.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds for k-fold cross validation. Default is <code>nfolds=10</code>.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_foldid">foldid</code></td>
<td>
<p>An optional vector of values between <code>1</code> and <code>nfolds</code> identifying what fold each observation is in. If supplied, <code>nfolds</code> can be missing.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_partial_method">partial_method</code></td>
<td>
<p>Indicate whether to use pairwise partial correlations, or shrinkage partial correlations.</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_l2_penalty">l2_penalty</code></td>
<td>
<p>Optional penalty for level-specific regressions (useful in high-dimensional case)</p>
</td></tr>
<tr><td><code id="cv.hfr_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>hclust</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits an HFR to a grid of <code>kappa</code> hyperparameter values. The result is a
matrix of coefficients with one column for each hyperparameter. By evaluating all hyperparameters
in a single function, the speed of the cross-validation procedure is improved substantially (since
level-specific regressions are estimated only once).
</p>
<p>When <code>nfolds &gt; 1</code>, a cross validation is performed with shuffled data. Alternatively,
test slices can be passed to the function using the <code>foldid</code> argument. The result
of the cross validation is given by <code>best_kappa</code> in the output object.
</p>


<h3>Value</h3>

<p>A 'cv.hfr' regression object.
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>References</h3>

<p>Pfitzinger, Johann (2024). Cluster Regularization via a Hierarchical Feature Regression. _Econometrics and Statistics_ (in press). URL https://doi.org/10.1016/j.ecosta.2024.01.003.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hfr">hfr</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code> and <code><a href="stats.html#topic+predict">predict</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = cv.hfr(x, y, kappa = seq(0, 1, by = 0.1))
coef(fit)

</code></pre>

<hr>
<h2 id='hfr'>Fit a hierarchical feature regression</h2><span id='topic+hfr'></span>

<h3>Description</h3>

<p>HFR is a regularized regression estimator that decomposes a least squares
regression along a supervised hierarchical graph, and shrinks the edges of the
estimated graph to regularize parameters. The algorithm leads to group shrinkage in the
regression parameters and a reduction in the effective model degrees of freedom.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hfr(
  x,
  y,
  weights = NULL,
  kappa = 1,
  q = NULL,
  intercept = TRUE,
  standardize = TRUE,
  partial_method = c("pairwise", "shrinkage"),
  l2_penalty = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hfr_+3A_x">x</code></td>
<td>
<p>Input matrix or data.frame, of dimension <code class="reqn">(N\times p)</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="hfr_+3A_y">y</code></td>
<td>
<p>Response variable.</p>
</td></tr>
<tr><td><code id="hfr_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting process. Should be NULL or a numeric vector. If non-NULL, weighted least squares is used for the level-specific regressions.</p>
</td></tr>
<tr><td><code id="hfr_+3A_kappa">kappa</code></td>
<td>
<p>The target effective degrees of freedom of the regression as a percentage of <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="hfr_+3A_q">q</code></td>
<td>
<p>Thinning parameter representing the quantile cut-off (in terms of contributed variance) above which to consider levels in the hierarchy. This can used to reduce the number of levels in high-dimensional problems. Default is no thinning.</p>
</td></tr>
<tr><td><code id="hfr_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept be fitted. Default is <code>intercept=TRUE</code>.</p>
</td></tr>
<tr><td><code id="hfr_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for x variable standardization prior to fitting the model. The coefficients are always returned on the original scale. Default is <code>standardize=TRUE</code>.</p>
</td></tr>
<tr><td><code id="hfr_+3A_partial_method">partial_method</code></td>
<td>
<p>Indicate whether to use pairwise partial correlations, or shrinkage partial correlations.</p>
</td></tr>
<tr><td><code id="hfr_+3A_l2_penalty">l2_penalty</code></td>
<td>
<p>Optional penalty for level-specific regressions (useful in high-dimensional case)</p>
</td></tr>
<tr><td><code id="hfr_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>hclust</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Shrinkage can be imposed by targeting an explicit effective degrees of freedom.
Setting the argument <code>kappa</code> to a value between <code>0</code> and <code>1</code> controls
the effective degrees of freedom of the fitted object as a percentage of <code class="reqn">p</code>.
When <code>kappa</code> is <code>1</code> the result is equivalent to the result from an ordinary
least squares regression (no shrinkage). Conversely, <code>kappa</code> set to <code>0</code>
represents maximum shrinkage.
</p>
<p>When <code class="reqn">p &gt; N</code> <code>kappa</code> is a percentage of <code class="reqn">(N - 2)</code>.
</p>
<p>If no <code>kappa</code> is set, a linear regression with <code>kappa = 1</code> is
estimated.
</p>
<p>Hierarchical clustering is performed using <code>hclust</code>. The default is set to
ward.D2 clustering but can be overridden by passing a method argument to <code>...</code>.
</p>
<p>For high-dimensional problems, the hierarchy becomes very large. Setting <code>q</code> to a value below 1
reduces the number of levels used in the hierarchy. <code>q</code> represents a quantile-cutoff of the amount of
variation contributed by the levels. The default (<code>q = NULL</code>) considers all levels.
</p>
<p>When data exhibits multicollinearity it can be useful to include a penalty on the l2 norm in the level-specific regressions.
This can be achieved by setting the <code>l2_penalty</code> parameter.
</p>


<h3>Value</h3>

<p>An 'hfr' regression object.
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>References</h3>

<p>Pfitzinger, Johann (2024). Cluster Regularization via a Hierarchical Feature Regression. _Econometrics and Statistics_ (in press). URL https://doi.org/10.1016/j.ecosta.2024.01.003.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.hfr">cv.hfr</a></code>, <code><a href="#topic+se.avg">se.avg</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="graphics.html#topic+plot">plot</a></code> and <code><a href="stats.html#topic+predict">predict</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = hfr(x, y, kappa = 0.5)
coef(fit)

</code></pre>

<hr>
<h2 id='plot.cv.hfr'>Plot the dendrogram of an HFR model</h2><span id='topic+plot.cv.hfr'></span>

<h3>Description</h3>

<p>Plots the dendrogram of a fitted <code>cv.hfr</code> model. The heights of the
levels in the dendrogram are given by a shrinkage vector, with a maximum (unregularized)
overall graph height of <code class="reqn">p</code> (the number of covariates in the regression).
Stronger shrinkage leads to a shallower hierarchy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.hfr'
plot(x, kappa = NULL, show_details = TRUE, max_leaf_size = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.hfr_+3A_x">x</code></td>
<td>
<p>Fitted 'cv.hfr' model.</p>
</td></tr>
<tr><td><code id="plot.cv.hfr_+3A_kappa">kappa</code></td>
<td>
<p>The hyperparameter used for plotting. If empty, the optimal value is used.</p>
</td></tr>
<tr><td><code id="plot.cv.hfr_+3A_show_details">show_details</code></td>
<td>
<p>print model details on the plot.</p>
</td></tr>
<tr><td><code id="plot.cv.hfr_+3A_max_leaf_size">max_leaf_size</code></td>
<td>
<p>maximum size of the leaf nodes. Default is <code>max_leaf_size=3</code>.</p>
</td></tr>
<tr><td><code id="plot.cv.hfr_+3A_...">...</code></td>
<td>
<p>additional methods passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dendrogram is generated using hierarchical clustering and modified
so that the height differential between any two splits is the shrinkage weight of
the lower split (ranging between <code>0</code> and <code>1</code>). With no shrinkage, all shrinkage weights
are equal to <code>1</code> and the dendrogram has a height of <code class="reqn">p</code>. With shrinkage
the dendrogram has a height of <code class="reqn">(\kappa \times p)</code>.
</p>
<p>The leaf nodes are colored to indicate the coefficient sign, with the size indicating
the absolute magnitude of the coefficients.
</p>
<p>A color bar on the right indicates the relative contribution of each level to the
coefficient of determination, with darker hues representing a larger contribution.
</p>


<h3>Value</h3>

<p>A plotted dendrogram.
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.hfr">cv.hfr</a></code>, <code><a href="stats.html#topic+predict">predict</a></code> and <code><a href="stats.html#topic+coef">coef</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = cv.hfr(x, y, kappa = seq(0, 1, by = 0.1))
plot(fit, kappa = 0.5)

</code></pre>

<hr>
<h2 id='plot.hfr'>Plot the dendrogram of an HFR model</h2><span id='topic+plot.hfr'></span>

<h3>Description</h3>

<p>Plots the dendrogram of a fitted <code>hfr</code> model. The heights of the
levels in the dendrogram are given by a shrinkage vector, with a maximum (unregularized)
overall graph height of <code class="reqn">p</code> (the number of covariates in the regression).
Stronger shrinkage leads to a shallower hierarchy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hfr'
plot(x, show_details = TRUE, confidence_level = 0, max_leaf_size = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.hfr_+3A_x">x</code></td>
<td>
<p>Fitted 'hfr' model.</p>
</td></tr>
<tr><td><code id="plot.hfr_+3A_show_details">show_details</code></td>
<td>
<p>print model details on the plot.</p>
</td></tr>
<tr><td><code id="plot.hfr_+3A_confidence_level">confidence_level</code></td>
<td>
<p>coefficients with a lower approximate statistical confidence are highlighted in the plot, see details. Default is <code>confidence_level=0</code>.</p>
</td></tr>
<tr><td><code id="plot.hfr_+3A_max_leaf_size">max_leaf_size</code></td>
<td>
<p>maximum size of the leaf nodes. Default is <code>max_leaf_size=3</code>.</p>
</td></tr>
<tr><td><code id="plot.hfr_+3A_...">...</code></td>
<td>
<p>additional methods passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dendrogram is generated using hierarchical clustering and modified
so that the height differential between any two splits is the shrinkage weight of
the lower split (ranging between <code>0</code> and <code>1</code>). With no shrinkage, all shrinkage weights
are equal to <code>1</code> and the dendrogram has a height of <code class="reqn">p</code>. With shrinkage
the dendrogram has a height of <code class="reqn">(\kappa \times p)</code>.
</p>
<p>The leaf nodes are colored to indicate the coefficient sign, with the size indicating
the absolute magnitude of the coefficients.
</p>
<p>The average standard errors along the branch of each coefficient can be used
to highlight coefficients that are not statistically significant. When
<code>confidence_level &gt; 0</code>, branches with a lower confidence are plotted
as dotted lines.
</p>
<p>A color bar on the right indicates the relative contribution of each level to the
coefficient of determination, with darker hues representing a larger contribution.
</p>


<h3>Value</h3>

<p>A plotted dendrogram.
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hfr">hfr</a></code>, <code><a href="#topic+se.avg">se.avg</a></code>, <code><a href="stats.html#topic+predict">predict</a></code> and <code><a href="stats.html#topic+coef">coef</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = hfr(x, y, kappa = 0.5)
plot(fit)

</code></pre>

<hr>
<h2 id='predict.cv.hfr'>Model predictions</h2><span id='topic+predict.cv.hfr'></span>

<h3>Description</h3>

<p>Predict values using a fitted <code>cv.hfr</code> model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.hfr'
predict(object, newdata = NULL, kappa = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.hfr_+3A_object">object</code></td>
<td>
<p>Fitted 'cv.hfr' model.</p>
</td></tr>
<tr><td><code id="predict.cv.hfr_+3A_newdata">newdata</code></td>
<td>
<p>Matrix or data.frame of new values for <code>x</code> at which predictions are to be made.</p>
</td></tr>
<tr><td><code id="predict.cv.hfr_+3A_kappa">kappa</code></td>
<td>
<p>The hyperparameter used for prediction. If empty, the optimal value is used.</p>
</td></tr>
<tr><td><code id="predict.cv.hfr_+3A_...">...</code></td>
<td>
<p>additional methods passed to <code>predict</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predictions are made by multiplying the <code>newdata</code> object with the estimated coefficients.
The chosen hyperparameter value to use for predictions can be passed to
the <code>kappa</code> argument.
</p>


<h3>Value</h3>

<p>A vector of predicted values.
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hfr">hfr</a></code>, <code><a href="#topic+cv.hfr">cv.hfr</a></code> and <code><a href="stats.html#topic+coef">coef</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = cv.hfr(x, y, kappa = seq(0, 1, by = 0.1))
predict(fit, kappa = 0.1)

</code></pre>

<hr>
<h2 id='predict.hfr'>Model predictions</h2><span id='topic+predict.hfr'></span>

<h3>Description</h3>

<p>Predict values using a fitted <code>hfr</code> model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hfr'
predict(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.hfr_+3A_object">object</code></td>
<td>
<p>Fitted 'hfr' model.</p>
</td></tr>
<tr><td><code id="predict.hfr_+3A_newdata">newdata</code></td>
<td>
<p>Matrix or data.frame of new values for <code>x</code> at which predictions are to be made.</p>
</td></tr>
<tr><td><code id="predict.hfr_+3A_...">...</code></td>
<td>
<p>additional methods passed to <code>predict</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predictions are made by multiplying the <code>newdata</code> object with the estimated coefficients.
</p>


<h3>Value</h3>

<p>A vector of predicted values.
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hfr">hfr</a></code>, <code><a href="#topic+cv.hfr">cv.hfr</a></code> and <code><a href="stats.html#topic+coef">coef</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = hfr(x, y, kappa = 0.5)
predict(fit)

</code></pre>

<hr>
<h2 id='print.cv.hfr'>Print an HFR model</h2><span id='topic+print.cv.hfr'></span>

<h3>Description</h3>

<p>Print summary statistics for a fitted <code>cv.hfr</code> model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.hfr'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.cv.hfr_+3A_x">x</code></td>
<td>
<p>Fitted <code>cv.hfr</code> model.</p>
</td></tr>
<tr><td><code id="print.cv.hfr_+3A_...">...</code></td>
<td>
<p>additional methods passed to <code>print</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The call that produced the object <code>x</code> is printed, following by a
<code>data.frame</code> of summary statistics, including the effective degrees of freedom
of the model, the R.squared and the regularization parameter.
</p>


<h3>Value</h3>

<p>Summary statistics of HFR model
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hfr">hfr</a></code>, <code><a href="#topic+cv.hfr">cv.hfr</a></code> and <code><a href="stats.html#topic+coef">coef</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = cv.hfr(x, y, kappa = seq(0, 1, by = 0.1))
print(fit)

</code></pre>

<hr>
<h2 id='print.hfr'>Print an HFR model</h2><span id='topic+print.hfr'></span>

<h3>Description</h3>

<p>Print summary statistics for a fitted <code>hfr</code> model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'hfr'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.hfr_+3A_x">x</code></td>
<td>
<p>Fitted <code>hfr</code> model.</p>
</td></tr>
<tr><td><code id="print.hfr_+3A_...">...</code></td>
<td>
<p>additional methods passed to <code>print</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The call that produced the object <code>x</code> is printed, following by a
<code>data.frame</code> of summary statistics, including the effective degrees of freedom
of the model, the R.squared and the regularization parameter.
</p>


<h3>Value</h3>

<p>Summary statistics of HFR model
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hfr">hfr</a></code>, <code><a href="#topic+cv.hfr">cv.hfr</a></code> and <code><a href="stats.html#topic+coef">coef</a></code> methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = hfr(x, y, kappa = 0.5)
print(fit)

</code></pre>

<hr>
<h2 id='se.avg'>Calculate approximate standard errors for a fitted HFR model</h2><span id='topic+se.avg'></span>

<h3>Description</h3>

<p>This function computes the weighted average standard errors across
levels using Burnham &amp; Anderson (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>se.avg(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="se.avg_+3A_object">object</code></td>
<td>
<p>Fitted <code>hfr</code> model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The HFR computes linear regressions over several levels of an estimated
hierarchy. By averaging the standard errors across hierarchical levels, an
indication can be obtained about the average significance of the variables.
</p>
<p>Standard errors are understated, since the uncertainty in the hierarchy estimation
is not reflected.
</p>


<h3>Value</h3>

<p>A vector of standard errors.
</p>


<h3>Author(s)</h3>

<p>Johann Pfitzinger
</p>


<h3>References</h3>

<p>Pfitzinger, J. (2022).
Cluster Regularization via a Hierarchical Feature Regression.
arXiv 2107.04831[statML]
</p>
<p>Burnham, K. P. and Anderson, D. R. (2004).
Multimodel inference - understanding AIC and BIC in model selection.
Sociological Methods &amp; Research 33(2): 261-304.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hfr">hfr</a></code> method
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit = hfr(x, y, kappa = 0.5)
se.avg(fit)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
