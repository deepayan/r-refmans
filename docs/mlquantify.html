<!DOCTYPE html><html lang="en"><head><title>Help for package mlquantify</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlquantify}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ACC'><p>Adjusted Classify and Count</p></a></li>
<li><a href='#aeAegypti'><p>Males and Females Aedes Aegypti data from Maletzke (2019)</p></a></li>
<li><a href='#CC'><p>Classify and Count</p></a></li>
<li><a href='#DyS'><p>DyS Framework</p></a></li>
<li><a href='#EMQ'><p>Expectation-Maximization Quantification</p></a></li>
<li><a href='#getTPRandFPRbyThreshold'><p>Estimates true and false positive rates</p></a></li>
<li><a href='#HDy_LP'><p>HDy with Laplace smoothing</p></a></li>
<li><a href='#KUIPER'><p>Quantification method based on Kuiper's test</p></a></li>
<li><a href='#MAX'><p>Threshold selection method</p></a></li>
<li><a href='#MKS'><p>Mixable Kolmogorov Smirnov</p></a></li>
<li><a href='#MS'><p>Median Sweep</p></a></li>
<li><a href='#MS2'><p>Threshold selection method. Median Sweep</p></a></li>
<li><a href='#PACC'><p>Probabilistic Adjusted Classify and Count</p></a></li>
<li><a href='#PCC'><p>Probabilistic Classify and Count</p></a></li>
<li><a href='#PWK'><p>Proportion-weighted k-nearest neighbor</p></a></li>
<li><a href='#SMM'><p>Sample Mean Matching</p></a></li>
<li><a href='#SORD'><p>Sample ORD Dissimilarity</p></a></li>
<li><a href='#T50'><p>Threshold selection method</p></a></li>
<li><a href='#X'><p>Threshold selection method</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Algorithms for Class Distribution Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andre Maletzke &lt;andregustavom@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Quantification is a prominent machine learning task that has received an 
    increasing amount of attention in the last years. The objective is to predict the 
    class distribution of a data sample. This package is a collection of machine learning 
    algorithms for class distribution estimation. This package include algorithms from
    different paradigms of quantification. These methods are described in the paper: 
    A. Maletzke, W. Hassan, D. dos Reis, and G. Batista. The importance of the test set 
    size in quantification assessment. In Proceedings of the Twenty-Ninth International 
    Joint Conference on Artificial Intelligence, IJCAI20, pages 2640–2646, 2020.
    &lt;<a href="https://doi.org/10.24963%2Fijcai.2020%2F366">doi:10.24963/ijcai.2020/366</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Author:</td>
<td>Andre Maletzke [aut, cre],
  Everton Cherman [ctb],
  Denis dos Reis [ctb],
  Gustavo Batista [ths]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/andregustavom/mlquantify/issues">https://github.com/andregustavom/mlquantify/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/andregustavom/mlquantify">https://github.com/andregustavom/mlquantify</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, randomForest, stats, FNN</td>
</tr>
<tr>
<td>Suggests:</td>
<td>CORElearn</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-20 12:57:28 UTC; andregustavom</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-20 14:02:41 UTC</td>
</tr>
</table>
<hr>
<h2 id='ACC'>Adjusted Classify and Count</h2><span id='topic+ACC'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores using the Adjusted Classify
and Count (ACC) method. ACC is an extension of CC, applying a correction
rate based on the true and false positive rates (<code>tpr</code> and <code>fpr</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ACC(test, TprFpr, thr=0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ACC_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
<tr><td><code id="ACC_+3A_tprfpr">TprFpr</code></td>
<td>
<p>a <code>data.frame</code> of true positive (<code>tpr</code>) and false positive (<code>fpr</code>)
rates estimated on training set, using the function <code>getTPRandFPRbyThreshold()</code>.</p>
</td></tr>
<tr><td><code id="ACC_+3A_thr">thr</code></td>
<td>
<p>threshold value according to the <code>tpr</code> and <code>fpr</code> were learned.
Default is <code>0.5</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Forman, G. (2006, August). Quantifying trends accurately despite classifier
error and class imbalance. In ACM SIGKDD international conference on Knowledge discovery
and data mining (pp. 157-166).&lt;doi.org/10.1145/1150402.1150423&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
ACC(test = test.scores[,1], TprFpr = TprFpr)
</code></pre>

<hr>
<h2 id='aeAegypti'>Males and Females Aedes Aegypti data from Maletzke (2019)</h2><span id='topic+aeAegypti'></span>

<h3>Description</h3>

<p>Contains events generated by a laser sensor to capture the flight dynamism of insects. It is a binary dataset compose by events from <em>Aedes Aegypti</em> Female and Male.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(aeAegypti)
</code></pre>


<h3>Format</h3>

<p>The data set aeAegypti is a data frame of 1800 observations of 9 variables. Each event is described by the wing beat frequency (wbf), and the frequencies of the first six harmonics obtained when either female or male <em>Aedes Aegypti</em> mosquito cross an optical sensor's line-of-sigh. Both male (class = 2) and female (class = 1) of class factor.
</p>


<h3>Details</h3>

<p>The <code>aeAegypti</code> dataset is a subset of widely data collection effort involving more than one million instances from 20 different insect species. The dataset was collected varying the temperature and humidity. An observation is associated with a temperature range that varies from 23ºC to 35ºC.
</p>


<h3>Author(s)</h3>

<p>Andre Maletzke &lt;andregustavom@gmail.com&gt;
</p>


<h3>References</h3>

<p>Maletzke, A. G. (2019). Binary quantification in non-stationary scenarios. Doctoral Thesis, Instituto de Ciências Matemáticas e de Computação, University of São Paulo, São Carlos. Retrieved 2020-07-21, from www.teses.usp.br. &lt;doi.org/10.11606/T.55.2020.tde-19032020-091709&gt;
</p>
<p>Moreira dos Reis, D., Maletzke, A., Silva, D. F., &amp; Batista, G. E. (2018). Classifying and counting with recurrent contexts. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (pp. 1983-1992). &lt;doi.org/10.1145/3219819.3220059&gt;
</p>

<hr>
<h2 id='CC'>Classify and Count</h2><span id='topic+CC'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying the Classify and Count (CC). CC is the simplest
quantification method that derives from classification (Forman, 2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CC(test, thr=0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CC_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from each
test set instance.</p>
</td></tr>
<tr><td><code id="CC_+3A_thr">thr</code></td>
<td>
<p>a numeric value indicating the decision threshold. A value between 0 and 1 (default = <code>0.5</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Forman, G. (2005). Counting positives accurately despite inaccurate
classification. In European Conference on Machine Learning. Springer, Berlin,
Heidelberg.&lt;doi.org/10.1007/11564096_55&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 2)
tr &lt;- aeAegypti[cv$Fold1,]
ts &lt;- aeAegypti[cv$Fold2,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
CC(test = test.scores[,1])
</code></pre>

<hr>
<h2 id='DyS'>DyS Framework</h2><span id='topic+DyS'></span>

<h3>Description</h3>

<p>DyS is a framework for quantification data based on mixture models method. It quantifies
events based on testing scores, applying the DyS framework proposed by Maletzke et al. (2019).
It also works with several similarity functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DyS(p.score, n.score, test, measure="topsoe", bins=seq(2,20,2), err=1e-5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DyS_+3A_p.score">p.score</code></td>
<td>
<p>a numeric <code>vector</code> of positive scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="DyS_+3A_n.score">n.score</code></td>
<td>
<p>a numeric <code>vector</code> of negative scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="DyS_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
<tr><td><code id="DyS_+3A_measure">measure</code></td>
<td>
<p>measure used to compare the mixture histogram against the
histogram obtained from the test set. Several functions can be used (Default:
<code>"topsoe"</code>, <code>"euclidean"</code>, <code>"jensen_difference"</code>, <code>"prob_symm"</code>,
<code>"taneja"</code>, <code>"ord"</code>).</p>
</td></tr>
<tr><td><code id="DyS_+3A_bins">bins</code></td>
<td>
<p>a numeric <code>vector</code> of number of bins used to construct the histogram for
representing the score distribution. (default: <code>seq(2,20,2)</code>).</p>
</td></tr>
<tr><td><code id="DyS_+3A_err">err</code></td>
<td>
<p>a numeric value defining the accepted error for the ternary search
(default: <code>1e5</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Maletzke, A., Reis, D., Cherman, E., &amp; Batista, G. (2019). DyS: a Framework
for Mixture Models in Quantification. in Proceedings of the The Thirty-Third AAAI
Conference on Artificial Intelligence, ser. AAAI’19, 2019. &lt;doi.org/10.1609/aaai.v33i01.33014552&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
DyS(p.score = scores[scores[,3]==1,1], n.score = scores[scores[,3]==2,1],
test = test.scores[,1])
</code></pre>

<hr>
<h2 id='EMQ'>Expectation-Maximization Quantification</h2><span id='topic+EMQ'></span>

<h3>Description</h3>

<p>This method is an instance of the well-known algorithm for finding maximum-likelihood
estimates of the model's parameters. It quantifies events based on testing scores,
applying the Expectation Maximization for Quantification (EMQ) method proposed by
Saerens et al. (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMQ(train, test, it=5, e=1e-4)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EMQ_+3A_train">train</code></td>
<td>
<p>a <code>data.frame</code> of the labeled set.</p>
</td></tr>
<tr><td><code id="EMQ_+3A_test">test</code></td>
<td>
<p>a numeric <code>matrix</code> of scores predicted from each test set instance.
First column must be the positive score.</p>
</td></tr>
<tr><td><code id="EMQ_+3A_it">it</code></td>
<td>
<p>maximum number of iteration steps (default <code>5</code>).</p>
</td></tr>
<tr><td><code id="EMQ_+3A_e">e</code></td>
<td>
<p>a numeric value for the stop threshold (default <code>1e-4</code>). If the
difference between two consecutive steps is lower or equal than <code>e</code>, the
iterative process will be stopped. If <code>e</code> is null then the iteration
phase is defined by the <code>it</code> parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Saerens, M., Latinne, P., &amp; Decaestecker, C. (2002). Adjusting
the outputs of a classifier to new a priori probabilities: a simple procedure.
Neural computation.&lt;doi.org/10.1162/089976602753284446&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 2)
tr &lt;- aeAegypti[cv$Fold1,]
ts &lt;- aeAegypti[cv$Fold2,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
EMQ(train=tr, test=test.scores)
</code></pre>

<hr>
<h2 id='getTPRandFPRbyThreshold'>Estimates true and false positive rates</h2><span id='topic+getTPRandFPRbyThreshold'></span>

<h3>Description</h3>

<p>This function provides the true and false positive rates (<code>tpr</code> and <code>fpr</code>) for a range of thresholds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTPRandFPRbyThreshold(validation_scores, label_pos = 1, thr_range = seq(0,1,0.01))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTPRandFPRbyThreshold_+3A_validation_scores">validation_scores</code></td>
<td>
<p><code>data.frame</code> scores estimated from the training set.
It should be comprised of three columns (1. positive scores; 2. negative
scores; 3.class).</p>
</td></tr>
<tr><td><code id="getTPRandFPRbyThreshold_+3A_label_pos">label_pos</code></td>
<td>
<p>numeric value or factor indicating the positive label.</p>
</td></tr>
<tr><td><code id="getTPRandFPRbyThreshold_+3A_thr_range">thr_range</code></td>
<td>
<p>a numerical <code>vector</code> of thresholds, ranged between 0 and 1. Default:
<code>seq(0.01,0.99,0.01)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data.frame</code> where each row has both (<code>tpr</code> and <code>fpr</code>) rates for
each threshold value. This function varies the threshold from 0.01 to 0.99 with
increments 0.01.
</p>


<h3>Author(s)</h3>

<p>Everton Cherman &lt;evertoncherman@gmail.com&gt;
</p>
<p>Andre Maletzke &lt;andregustavom@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 2)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
</code></pre>

<hr>
<h2 id='HDy_LP'>HDy with Laplace smoothing</h2><span id='topic+HDy_LP'></span>

<h3>Description</h3>

<p>It computes the class distribution using the HDy algorithm proposed by González-Castro et al. (2013)
with Laplace smoothing (Maletzke et al. (2019)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HDy_LP(p.score, n.score, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HDy_LP_+3A_p.score">p.score</code></td>
<td>
<p>a numeric <code>vector</code> of positive scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="HDy_LP_+3A_n.score">n.score</code></td>
<td>
<p>a numeric <code>vector</code> of negative scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="HDy_LP_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>Author(s)</h3>

<p>Andre Maletzke &lt;andregustavom@gmail.com&gt;
</p>


<h3>References</h3>

<p>González-Castro, V., Alaíz-Rodriguez, R., &amp; Alegre, E. (2013). Class
distribution estimation based on the Hellinger distance. Information Sciences.&lt;doi.org/10.1016/j.ins.2012.05.028&gt;
</p>
<p>Maletzke, A., Reis, D., Cherman, E., &amp; Batista, G. (2019). DyS: a
Framework for Mixture Models in Quantification. in Proceedings of the The
Thirty-Third AAAI Conference on Artificial Intelligence, ser. AAAI’19, 2019.
&lt;doi.org/10.1609/aaai.v33i01.33014552&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
HDy_LP(p.score = scores[scores[,3]==1,1], n.score=scores[scores[,3]==2,1],
test=test.scores[,1])
</code></pre>

<hr>
<h2 id='KUIPER'>Quantification method based on Kuiper's test</h2><span id='topic+KUIPER'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying an adaptation of the
Kuiper's test for quantification problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KUIPER(p.score, n.score, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KUIPER_+3A_p.score">p.score</code></td>
<td>
<p>a numeric <code>vector</code> of positive scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="KUIPER_+3A_n.score">n.score</code></td>
<td>
<p>a numeric <code>vector</code> of negative scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="KUIPER_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>Author(s)</h3>

<p>Denis dos Reis &lt;denismr@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
KUIPER(p.score = scores[scores[,3]==1,1], n.score = scores[scores[,3]==2,1],
test = test.scores[,1])
</code></pre>

<hr>
<h2 id='MAX'>Threshold selection method</h2><span id='topic+MAX'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying MAX method, according to
Forman (2006). Same as T50, but it sets the threshold where <code>tpr</code>–<code>fpr</code>
is maximized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAX(test, TprFpr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MAX_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
<tr><td><code id="MAX_+3A_tprfpr">TprFpr</code></td>
<td>
<p>a <code>data.frame</code> of true positive (<code>tpr</code>) and false positive (<code>fpr</code>)
rates estimated on training set, using the function <code>getTPRandFPRbyThreshold()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Forman, G. (2006, August). Quantifying trends accurately despite classifier
error and class imbalance. In Proceedings of the 12th ACM SIGKDD international conference
on Knowledge discovery and data mining (pp. 157-166).&lt;doi.org/10.1145/1150402.1150423&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
MAX(test=test.scores[,1], TprFpr=TprFpr)
</code></pre>

<hr>
<h2 id='MKS'>Mixable Kolmogorov Smirnov</h2><span id='topic+MKS'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying the Mixable Kolmogorov
Smirnov (MKS) method proposed by Maletzke et al. (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MKS(p.score, n.score, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MKS_+3A_p.score">p.score</code></td>
<td>
<p>a numeric <code>vector</code> of positive scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="MKS_+3A_n.score">n.score</code></td>
<td>
<p>a numeric <code>vector</code> of negative scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="MKS_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Maletzke, A., Reis, D., Cherman, E., &amp; Batista, G. (2019). DyS:
a Framework for Mixture Models in Quantification. in Proceedings of the The
Thirty-Third AAAI Conference on Artificial Intelligence, ser. AAAI’19, 2019.&lt;doi.org/10.1609/aaai.v33i01.33014552&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
MKS(p.score = scores[scores[,3]==1,1], n.score = scores[scores[,3]==2,1],
test = test.scores)
</code></pre>

<hr>
<h2 id='MS'>Median Sweep</h2><span id='topic+MS'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying Median Sweep (MS) method, according to
Forman (2006).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MS(test, TprFpr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MS_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
<tr><td><code id="MS_+3A_tprfpr">TprFpr</code></td>
<td>
<p>a <code>data.frame</code> of true positive (<code>tpr</code>) and false positive
(<code>fpr</code>) rates estimated on training set, using the function
<code>getTPRandFPRbyThreshold()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Forman, G. (2006, August). Quantifying trends accurately despite
classifier error and class imbalance. In Proceedings of the 12th ACM SIGKDD
international conference on Knowledge discovery and data mining (pp. 157-166).&lt;doi.org/10.1145/1150402.1150423&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
MS(test = test.scores[,1], TprFpr = TprFpr)
</code></pre>

<hr>
<h2 id='MS2'>Threshold selection method. Median Sweep</h2><span id='topic+MS2'></span>

<h3>Description</h3>

<p>It quantifies events using a modified version of the MS method that considers
only thresholds where the denominator (<code>tpr</code>-<code>fpr</code>) is greater than 0.25.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MS2(test, TprFpr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MS2_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
<tr><td><code id="MS2_+3A_tprfpr">TprFpr</code></td>
<td>
<p>a <code>data.frame</code> of true positive (<code>tpr</code>) and false positive (<code>fpr</code>)
rates estimated on training set, using the function <code>getTPRandFPRbyThreshold()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Forman, G. (2006, August). Quantifying trends accurately despite classifier
error and class imbalance. In Proceedings of the 12th ACM SIGKDD international conference
on Knowledge discovery and data mining (pp. 157-166).&lt;doi.org/10.1145/1150402.1150423&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
MS2(test = test.scores[,1], TprFpr = TprFpr)
</code></pre>

<hr>
<h2 id='PACC'>Probabilistic Adjusted Classify and Count</h2><span id='topic+PACC'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying the Probabilistic Adjusted
Classify and Count (PACC) method. This method is also called Scaled Probability
Average (SPA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PACC(test, TprFpr, thr=0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PACC_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance. (NOTE: It requires calibrated scores. See <a href="CORElearn.html#topic+calibrate">calibrate</a>
from <span class="pkg">CORElearn</span>).</p>
</td></tr>
<tr><td><code id="PACC_+3A_tprfpr">TprFpr</code></td>
<td>
<p>a <code>data.frame</code> of true positive (<code>tpr</code>) and false positive
(<code>fpr</code>) rates estimated on training set, using the function
<code>getTPRandFPRbyThreshold()</code>.</p>
</td></tr>
<tr><td><code id="PACC_+3A_thr">thr</code></td>
<td>
<p>threshold value according to the <code>tpr</code> and <code>fpr</code> were learned.
Default is <code>0.5</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Bella, A., Ferri, C., Hernández-Orallo, J., &amp; Ramírez-Quintana, M. J. (2010).
Quantification via probability estimators. In IEEE International Conference on Data Mining
(pp. 737–742). Sidney.&lt;doi.org/10.1109/ICDM.2010.75&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))[,1]

# -- PACC requires calibrated scores. Be aware of doing this before using PACC --
# -- You can make it using calibrate function from the CORElearn package --
# if(requireNamespace("CORElearn")){
#    cal_tr &lt;- CORElearn::calibrate(as.factor(scores[,3]), scores[,1], class1=1,
#    method="isoReg",assumeProbabilities=TRUE)
#    test.scores &lt;- CORElearn::applyCalibration(test.scores, cal_tr)
#}
PACC(test = test.scores, TprFpr = TprFpr)
</code></pre>

<hr>
<h2 id='PCC'>Probabilistic Classify and Count</h2><span id='topic+PCC'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying the Probabilistic Classify
and Count (PCC) method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PCC(test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PCC_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance. (NOTE: It requires calibrated scores. See <a href="CORElearn.html#topic+calibrate">calibrate</a>
from <span class="pkg">CORElearn</span>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Bella, A., Ferri, C., Hernández-Orallo, J., &amp; Ramírez-Quintana,
M. J. (2010). Quantification via probability estimators. In IEEE International
Conference on Data Mining (pp. 737–742). Sidney.&lt;doi.org/10.1109/ICDM.2010.75&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))[,1]

# -- PCC requires calibrated scores. Be aware of doing this before using PCC --
# -- You can make it using calibrate function from the CORElearn package --
# if(requireNamespace("CORElearn")){
#   cal_tr &lt;- CORElearn::calibrate(as.factor(scores[,3]), scores[,1], class1=1,
#   method="isoReg",assumeProbabilities=TRUE)
#   test.scores &lt;- CORElearn::applyCalibration(test.scores, cal_tr)
# }
PCC(test=test.scores)
</code></pre>

<hr>
<h2 id='PWK'>Proportion-weighted k-nearest neighbor</h2><span id='topic+PWK'></span>

<h3>Description</h3>

<p>It is a nearest-neighbor classifier adapted for working over quantification problems. This
method applies a weighting scheme, reducing the weight on neighbors from the majority class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PWK(train, y, test, alpha=1, n_neighbors=10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PWK_+3A_train">train</code></td>
<td>
<p>a <code>data.frame</code> containing the training data.</p>
</td></tr>
<tr><td><code id="PWK_+3A_y">y</code></td>
<td>
<p>a <code>vector</code> containing the target values.</p>
</td></tr>
<tr><td><code id="PWK_+3A_test">test</code></td>
<td>
<p>a <code>data.frame</code> containing the test data.</p>
</td></tr>
<tr><td><code id="PWK_+3A_alpha">alpha</code></td>
<td>
<p>a numeric value defining the proportion-weighted k-nearest neighbor algorithm
as proposed by Barranquero et al., (2012). (Default: <code>1</code>).</p>
</td></tr>
<tr><td><code id="PWK_+3A_n_neighbors">n_neighbors</code></td>
<td>
<p>a integer value defining the number of neighbors to use by default for
nearest neighbor queries (Default: <code>10</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Barranquero, J., González, P., Díez, J., &amp; Del Coz, J. J. (2013). On the study
of nearest neighbor algorithms for prevalence estimation in binary problems. Pattern Recognition,
46(2), 472-482.&lt;doi.org/10.1016/j.patcog.2012.07.022&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(caret)
library(FNN)
cv &lt;- createFolds(aeAegypti$class, 2)
tr &lt;- aeAegypti[cv$Fold1,]
ts &lt;- aeAegypti[cv$Fold2,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
PWK(train=tr[,-which(names(tr)=="class")], y=tr[,"class"], test= ts[,-which(names(ts)=="class")])
</code></pre>

<hr>
<h2 id='SMM'>Sample Mean Matching</h2><span id='topic+SMM'></span>

<h3>Description</h3>

<p>SMM is a member of the DyS framework that uses simple means scores to represent the score distribution
for positive, negative, and unlabelled scores. Therefore, the class distribution is given by a
closed-form equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SMM(p.score, n.score, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SMM_+3A_p.score">p.score</code></td>
<td>
<p>a numeric <code>vector</code> of positive scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="SMM_+3A_n.score">n.score</code></td>
<td>
<p>a numeric <code>vector</code> of negative scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="SMM_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Hassan, W., Maletzke, A., Batista, G. (2020). Accurately Quantifying a Billion Instances
per Second. In IEEE International Conference on Data Science and Advanced Analytics (DSAA).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
SMM(p.score = scores[scores[,3]==1,1], n.score = scores[scores[,3]==2,1],
test = test.scores[,1])
</code></pre>

<hr>
<h2 id='SORD'>Sample ORD Dissimilarity</h2><span id='topic+SORD'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores applying the framework DyS with the
Sample ORD Dissimilarity (SORD) proposed by Maletzke et al. (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SORD(p.score, n.score, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SORD_+3A_p.score">p.score</code></td>
<td>
<p>a numeric <code>vector</code> of positive scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="SORD_+3A_n.score">n.score</code></td>
<td>
<p>a numeric <code>vector</code> of negative scores estimated either from a
validation set or from a cross-validation method.</p>
</td></tr>
<tr><td><code id="SORD_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Maletzke, A., Reis, D., Cherman, E., &amp; Batista, G. (2019). DyS: a
Framework for Mixture Models in Quantification. in Proceedings of the The
Thirty-Third AAAI Conference on Artificial Intelligence, ser. AAAI’19, 2019.&lt;doi.org/10.1609/aaai.v33i01.33014552&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
SORD(p.score = scores[scores[,3]==1,1], n.score = scores[scores[,3]==2,1],
test = test.scores[,1])
</code></pre>

<hr>
<h2 id='T50'>Threshold selection method</h2><span id='topic+T50'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying T50 method proposed by
Forman (2006). It sets the decision threshold of Binary Classifier where
<code>tpr</code> = 50%.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T50(test, TprFpr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="T50_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
<tr><td><code id="T50_+3A_tprfpr">TprFpr</code></td>
<td>
<p>a <code>data.frame</code> of true positive (<code>tpr</code>) and false positive
(<code>fpr</code>) rates estimated on training set, using the function
<code>getTPRandFPRbyThreshold()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Forman, G. (2006, August). Quantifying trends accurately despite
classifier error and class imbalance. In Proceedings of the 12th ACM SIGKDD
international conference on Knowledge discovery and data mining (pp. 157-166).&lt;doi.org/10.1145/1150402.1150423&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]
# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
T50(test=test.scores[,1], TprFpr=TprFpr)
</code></pre>

<hr>
<h2 id='X'>Threshold selection method</h2><span id='topic+X'></span>

<h3>Description</h3>

<p>It quantifies events based on testing scores, applying the X method (Forman, 2006).
Same as T50, but set the threshold where (<code>1</code> - <code>tpr</code>) = <code>fpr</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X(test, TprFpr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="X_+3A_test">test</code></td>
<td>
<p>a numeric <code>vector</code> containing the score estimated for the positive class from
each test set instance.</p>
</td></tr>
<tr><td><code id="X_+3A_tprfpr">TprFpr</code></td>
<td>
<p>a <code>data.frame</code> of true positive (<code>tpr</code>) and false positive
(<code>fpr</code>) rates estimated on training set, using the function
<code>getTPRandFPRbyThreshold()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the class distribution estimated from the test set.
</p>


<h3>References</h3>

<p>Forman, G. (2006, August). Quantifying trends accurately despite classifier
error and class imbalance. In Proceedings of the 12th ACM SIGKDD international conference
on Knowledge discovery and data mining (pp. 157-166).&lt;doi.org/10.1145/1150402.1150423&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(randomForest)
library(caret)
cv &lt;- createFolds(aeAegypti$class, 3)
tr &lt;- aeAegypti[cv$Fold1,]
validation &lt;- aeAegypti[cv$Fold2,]
ts &lt;- aeAegypti[cv$Fold3,]

# -- Getting a sample from ts with 80 positive and 20 negative instances --
ts_sample &lt;- rbind(ts[sample(which(ts$class==1),80),],
                   ts[sample(which(ts$class==2),20),])
scorer &lt;- randomForest(class~., data=tr, ntree=500)
scores &lt;- cbind(predict(scorer, validation, type = c("prob")), validation$class)
TprFpr &lt;- getTPRandFPRbyThreshold(scores)
test.scores &lt;- predict(scorer, ts_sample, type = c("prob"))
X(test=test.scores[,1], TprFpr=TprFpr)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
