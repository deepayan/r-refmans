<!DOCTYPE html><html><head><title>Help for package latentFactoR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {latentFactoR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#latentFactoR-package'><p>latentFactoR&ndash;package</p></a></li>
<li><a href='#add_cross_loadings'><p>Adds (Substantial) Cross-loadings to <code>simulate_factors</code> Data</p></a></li>
<li><a href='#add_local_dependence'><p>Adds Local Dependence to <code>simulate_factors</code> Data</p></a></li>
<li><a href='#add_method_factors'><p>Adds Methods Factors to <code>simulate_factors</code> Data</p></a></li>
<li><a href='#add_population_error'><p>Adds Population Error to <code>simulate_factors</code> Data</p></a></li>
<li><a href='#add_wording_effects'><p>Adds Wording Effects to <code>simulate_factors</code> Data</p></a></li>
<li><a href='#categorize'><p>Categorize Continuous Data</p></a></li>
<li><a href='#data_to_zipfs'><p>Transforms <code>simulate_factors</code> Data to Zipf's Distribution</p></a></li>
<li><a href='#EKC'><p>Estimate Number of Dimensions using Empirical Kaiser Criterion</p></a></li>
<li><a href='#ESEM'><p>Estimates Exploratory Structural Equation Model</p></a></li>
<li><a href='#estimate_dimensions'><p>Estimates Dimensions using Several State-of-the-art Methods</p></a></li>
<li><a href='#factor_forest'><p>Estimate Number of Dimensions using Factor Forest</p></a></li>
<li><a href='#NEST'><p>Estimate Number of Dimensions using Next Eigenvalue Sufficiency Test</p></a></li>
<li><a href='#obtain_zipfs_parameters'><p>Obtain Zipf's Distribution Parameters from Data</p></a></li>
<li><a href='#simulate_factors'><p>Simulates Latent Factor Data</p></a></li>
<li><a href='#skew_tables'><p>Skew Tables</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Data Simulation Based on Latent Factors</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-04-17</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Generates data based on latent factor models. Data can be continuous, polytomous, dichotomous, or mixed. Skews, cross-loadings, wording effects, population errors, and local dependencies can be added. All parameters can be manipulated. Data categorization is based on Garrido, Abad, and Ponsoda (2011) &lt;<a href="https://doi.org/10.1177%2F0013164410389489">doi:10.1177/0013164410389489</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3.0)</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>BBmisc, EGAnet, fspe, googledrive, ineq, lavaan, Matrix,
methods, mlr, mvtnorm, psych, rstudioapi, xgboost</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-18 20:35:05 UTC; alextops</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexander Christensen
    <a href="https://orcid.org/0000-0002-9798-7037"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Luis Eduardo Garrido
    <a href="https://orcid.org/0000-0001-8932-6063"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Maria Dolores Nieto Canaveras [aut],
  Hudson Golino <a href="https://orcid.org/0000-0002-1601-1447"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Marcos Jimenez [aut],
  Francisco Abad [ctb],
  Eduardo Garcia-Garzon [ctb],
  Vithor Franco [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-18 21:23:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='latentFactoR-package'>latentFactoR&ndash;package</h2><span id='topic+latentFactoR'></span><span id='topic+latentFactoR-package'></span>

<h3>Description</h3>

<p>Generates data based on latent factor models.
Data can be continuous, polytomous, dichotomous, or mixed.
Skew, cross-loadings, and population error can be added.
All parameters can be manipulated. Data categorization is based on Garrido, Abad, and Ponsoda (2011).
</p>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Maria Dolores Nieto Canaveras &lt;mnietoca@nebrija.es&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Christensen, A. P., Garrido, L. E., &amp; Golino, H. (2022). <br />
Unique variable analysis: A network psychometrics method to detect local dependence. <br />
<em>PsyArXiv</em>
</p>
<p>Garrido, L. E., Abad, F. J., &amp; Ponsoda, V. (2011). <br />
Performance of Velicer’s minimum average partial factor retention method with categorical variables. <br />
<em>Educational and Psychological Measurement</em>, <em>71</em>(3), 551-570.
</p>
<p>Golino, H., Shi, D., Christensen, A. P., Garrido, L. E., Nieto, M. D., Sadana, R., ... &amp; Martinez-Molina, A. (2020).
Investigating the performance of exploratory graph analysis and traditional techniques to identify the number of latent factors: A simulation and tutorial.
<em>Psychological Methods</em>, <em>25</em>(3), 292-320.
</p>

<hr>
<h2 id='add_cross_loadings'>Adds (Substantial) Cross-loadings to <code><a href="#topic+simulate_factors">simulate_factors</a></code> Data</h2><span id='topic+add_cross_loadings'></span>

<h3>Description</h3>

<p>Intended to add substantial cross-loadings to simulated data from <code><a href="#topic+simulate_factors">simulate_factors</a></code>. 
See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_cross_loadings(
  lf_object,
  proportion_cross_loadings,
  proportion_cross_loadings_range = NULL,
  magnitude_cross_loadings,
  magnitude_cross_loadings_range = NULL,
  leave_cross_loadings = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_cross_loadings_+3A_lf_object">lf_object</code></td>
<td>
<p>Data object from <code><a href="#topic+simulate_factors">simulate_factors</a></code></p>
</td></tr>
<tr><td><code id="add_cross_loadings_+3A_proportion_cross_loadings">proportion_cross_loadings</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code>).
Proportion of variables that should be cross-loaded randomly onto
one other factor. Accepts number of variables to 
cross-load onto one other factor as well</p>
</td></tr>
<tr><td><code id="add_cross_loadings_+3A_proportion_cross_loadings_range">proportion_cross_loadings_range</code></td>
<td>
<p>Numeric (length = 2).
Range of proportion of variables that should be cross-loaded randomly onto
one other factor. Accepts number of variables to 
cross-load onto one other factor as well</p>
</td></tr>
<tr><td><code id="add_cross_loadings_+3A_magnitude_cross_loadings">magnitude_cross_loadings</code></td>
<td>
<p>Numeric (length = 1, <code>factors</code>, or total number of variables to cross-load across all factors).
The magnitude or size of the cross-loadings.
Must range between <code>-1</code> and <code>1</code>.</p>
</td></tr>
<tr><td><code id="add_cross_loadings_+3A_magnitude_cross_loadings_range">magnitude_cross_loadings_range</code></td>
<td>
<p>Numeric (length = 2).
The range of the magnitude or size of the cross-loadings.
Defaults to <code>NULL</code></p>
</td></tr>
<tr><td><code id="add_cross_loadings_+3A_leave_cross_loadings">leave_cross_loadings</code></td>
<td>
<p>Boolean.
Should cross-loadings be kept?
Defaults to <code>FALSE</code>.
Convergence problems can arise if cross-loadings are kept,
so setting them to zero is the default. Only set to <code>TRUE</code>
with careful consideration of the structure. Make sure to perform
additional checks that the data are adequate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the same parameters as the original
<code>lf_object</code> but with updated <code>data</code>, <code>population_correlation</code>,
and <code>parameters</code> (specifically, <code>loadings</code> matrix). Also returns
original <code>lf_object</code> in <code>original_results</code>
</p>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Christensen, A. P., Garrido, L. E., &amp; Golino, H. (2022).
Unique variable analysis: A network psychometrics method to detect local dependence.
<em>PsyArXiv</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Add substantial cross-loadings
two_factor_CL &lt;- add_cross_loadings(
  lf_object = two_factor,
  proportion_cross_loadings = 0.25,
  magnitude_cross_loadings = 0.35
)

# Randomly vary proportions
two_factor_CL &lt;- add_cross_loadings(
  lf_object = two_factor,
  proportion_cross_loadings_range = c(0, 0.25),
  magnitude_cross_loadings = 0.35
)

# Randomly vary magnitudes
two_factor_CL &lt;- add_cross_loadings(
  lf_object = two_factor,
  proportion_cross_loadings = 0.25,
  magnitude_cross_loadings_range = c(0.35, 0.45)
)

# Set number of cross-loadings per factor (rather than proportion)
two_factor_CL &lt;- add_cross_loadings(
  lf_object = two_factor,
  proportion_cross_loadings = 2,
  magnitude_cross_loadings = 0.35
)

</code></pre>

<hr>
<h2 id='add_local_dependence'>Adds Local Dependence to <code><a href="#topic+simulate_factors">simulate_factors</a></code> Data</h2><span id='topic+add_local_dependence'></span>

<h3>Description</h3>

<p>Adds local dependence to simulated data from <code><a href="#topic+simulate_factors">simulate_factors</a></code>.
See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_local_dependence(
  lf_object,
  method = c("correlate_residuals", "minor_factors", "threshold_shifts"),
  proportion_LD,
  proportion_LD_range = NULL,
  add_residuals = NULL,
  add_residuals_range = NULL,
  allow_multiple = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_local_dependence_+3A_lf_object">lf_object</code></td>
<td>
<p>Data object from <code><a href="#topic+simulate_factors">simulate_factors</a></code></p>
</td></tr>
<tr><td><code id="add_local_dependence_+3A_method">method</code></td>
<td>
<p>Character (length = 1).
Method to generate local dependence between variables.
Only <code>"correlate_residuals"</code> at the moment.
Future developments will include minor factor
and threshold-shift methods. Description of methods:
</p>

<ul>
<li> <p><code>"correlate_residuals"</code> &mdash; Adds residuals directly to the population
correlation matrix prior to data generation (uses population correlation matrix
from <code><a href="#topic+simulate_factors">simulate_factors</a></code>)
</p>
</li>
<li> <p><code>"minor_factors"</code> &mdash; Coming soon...
</p>
</li>
<li> <p><code>"threshold_shifts"</code> &mdash; Coming soon...
</p>
</li></ul>
</td></tr>
<tr><td><code id="add_local_dependence_+3A_proportion_ld">proportion_LD</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code>).
Proportion of variables that should be locally dependent across all
or each factor. Accepts number of locally dependent values as well</p>
</td></tr>
<tr><td><code id="add_local_dependence_+3A_proportion_ld_range">proportion_LD_range</code></td>
<td>
<p>Numeric (length = 2).
Range of proportion of variables that are randomly selected from
a random uniform distribution. Accepts number of locally dependent values as well.
Defaults to <code>NULL</code></p>
</td></tr>
<tr><td><code id="add_local_dependence_+3A_add_residuals">add_residuals</code></td>
<td>
<p>Numeric (length = 1, <code>factors</code>, or total number of locally dependent variables).
Amount of residual to add to the population correlation matrix between two variables.
Only used when <code>method = "correlated_residuals"</code>. Magnitudes are drawn from
a random uniform distribution using +/- 0.05 of value input.
Can also be specified directly (same length as total number of locally dependent variables).
General effect sizes range from small (0.20), moderate (0.30), to large (0.40)</p>
</td></tr>
<tr><td><code id="add_local_dependence_+3A_add_residuals_range">add_residuals_range</code></td>
<td>
<p>Numeric (length = 2).
Range of the residuals to add to the correlation matrix are randomly selected from
a random uniform distribution.
Defaults to <code>NULL</code></p>
</td></tr>
<tr><td><code id="add_local_dependence_+3A_allow_multiple">allow_multiple</code></td>
<td>
<p>Boolean.
Whether a variable should be allowed to be locally dependent with
more than one other variable.
Defaults to <code>FALSE</code>.
Set to <code>TRUE</code> for more complex locally dependence patterns</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Simulated data from the specified factor model</p>
</td></tr>
<tr><td><code>population_correlation</code></td>
<td>
<p>Population correlation matrix with local dependence added</p>
</td></tr>
<tr><td><code>original_correlation</code></td>
<td>
<p>Original population correlation matrix <em>before</em>
local dependence was added</p>
</td></tr>
<tr><td><code>correlated_residuals</code></td>
<td>
<p>A data frame with the first two columns specifying
the variables that are locally dependent and the third column specifying the
magnitude of the added residual for each locally dependent pair</p>
</td></tr>
<tr><td><code>original_results</code></td>
<td>
<p>Original <code>lf_object</code> input into function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Christensen, A. P., Garrido, L. E., &amp; Golino, H. (2023).
Unique variable analysis: A network psychometrics method to detect local dependence.
<em>Multivariate Behavioral Research</em>, 1–18.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Add local dependence
two_factor_LD &lt;- add_local_dependence(
  lf_object = two_factor,
  proportion_LD = 0.25,
  add_residuals = 0.20,
  allow_multiple = FALSE
)

# Randomly vary proportions
two_factor_LD &lt;- add_local_dependence(
  lf_object = two_factor,
  proportion_LD_range = c(0.10, 0.50),
  add_residuals = 0.20,
  allow_multiple = FALSE
)

# Randomly vary residuals
two_factor_LD &lt;- add_local_dependence(
  lf_object = two_factor,
  proportion_LD = 0.25,
  add_residuals_range = c(0.20, 0.40),
  allow_multiple = FALSE
)

# Randomly vary proportions, residuals, and allow multiple
two_factor_LD &lt;- add_local_dependence(
  lf_object = two_factor,
  proportion_LD_range = c(0.10, 0.50),
  add_residuals_range = c(0.20, 0.40),
  allow_multiple = TRUE
)

</code></pre>

<hr>
<h2 id='add_method_factors'>Adds Methods Factors to <code><a href="#topic+simulate_factors">simulate_factors</a></code> Data</h2><span id='topic+add_method_factors'></span>

<h3>Description</h3>

<p>Adds methods factors to simulated data from <code><a href="#topic+simulate_factors">simulate_factors</a></code>.
See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_method_factors(
  lf_object,
  proportion_negative = 0.5,
  proportion_negative_range = NULL,
  methods_factors,
  methods_loadings,
  methods_loadings_range = 0,
  methods_correlations,
  methods_correlations_range = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_method_factors_+3A_lf_object">lf_object</code></td>
<td>
<p>Data object from <code><a href="#topic+simulate_factors">simulate_factors</a></code>.
Data <strong>must</strong> be categorical. If data are not categorical, then
there function with throw an error</p>
</td></tr>
<tr><td><code id="add_method_factors_+3A_proportion_negative">proportion_negative</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code>).
Proportion of variables that should have negative (or flipped) dominant loadings across all
or each factor. Accepts number of variables as well.
The first variables on each factor, up to the corresponding proportion, will be
flipped. Set to <code>0</code> to not have any loadings flipped.
Defaults to <code>0.50</code></p>
</td></tr>
<tr><td><code id="add_method_factors_+3A_proportion_negative_range">proportion_negative_range</code></td>
<td>
<p>Numeric (length = 2).
Range of proportion of variables that are randomly selected from
a uniform distribution. Accepts number of number of variables as well.
Defaults to <code>NULL</code></p>
</td></tr>
<tr><td><code id="add_method_factors_+3A_methods_factors">methods_factors</code></td>
<td>
<p>Numeric</p>
</td></tr>
<tr><td><code id="add_method_factors_+3A_methods_loadings">methods_loadings</code></td>
<td>
<p>Numeric</p>
</td></tr>
<tr><td><code id="add_method_factors_+3A_methods_loadings_range">methods_loadings_range</code></td>
<td>
<p>Numeric</p>
</td></tr>
<tr><td><code id="add_method_factors_+3A_methods_correlations">methods_correlations</code></td>
<td>
<p>Numeric</p>
</td></tr>
<tr><td><code id="add_method_factors_+3A_methods_correlations_range">methods_correlations_range</code></td>
<td>
<p>Numeric</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Biased data simulated data from the specified factor model</p>
</td></tr>
<tr><td><code>unbiased_data</code></td>
<td>
<p>The corresponding unbiased data prior to replacing values
to generate the (biased) <code>data</code></p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>Bias-adjusted parameters of the <code>lf_object</code> input into function</p>
</td></tr>
<tr><td><code>original_results</code></td>
<td>
<p>Original <code>lf_object</code> input into function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Garcia-Pardina, A., Abad, F. J., Christensen, A. P., Golino, H., &amp; Garrido, L. E. (2024).
Dimensionality assessment in the presence of wording effects: A network psychometric and factorial approach.
<em>Behavior Research Methods</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000, # number of cases = 1000
  variable_categories = 5 # 5-point Likert scale
)

# Add methods factors
two_factor_methods_effect &lt;- add_method_factors(
  lf_object = two_factor,
  proportion_negative = 0.50,
  methods_loadings = 0.20,
  methods_loadings_range = 0.10
)

</code></pre>

<hr>
<h2 id='add_population_error'>Adds Population Error to <code><a href="#topic+simulate_factors">simulate_factors</a></code> Data</h2><span id='topic+add_population_error'></span>

<h3>Description</h3>

<p>Adds population error to simulated data from <code><a href="#topic+simulate_factors">simulate_factors</a></code>.
See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_population_error(
  lf_object,
  cfa_method = c("minres", "ml"),
  fit = c("cfi", "rmsea", "rmsr", "raw"),
  misfit = c("close", "acceptable"),
  error_method = c("cudeck", "yuan"),
  tolerance = 0.01,
  convergence_iterations = 10,
  leave_cross_loadings = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_population_error_+3A_lf_object">lf_object</code></td>
<td>
<p>Data object from <code><a href="#topic+simulate_factors">simulate_factors</a></code></p>
</td></tr>
<tr><td><code id="add_population_error_+3A_cfa_method">cfa_method</code></td>
<td>
<p>Character (length = 1).
Method to generate population error.
Defaults to <code>"minres"</code>.
Available options:
</p>

<ul>
<li> <p><code>"minres"</code> &mdash; Minimum residual
</p>
</li>
<li> <p><code>"ml"</code> &mdash; Maximum likelihood
</p>
</li></ul>
</td></tr>
<tr><td><code id="add_population_error_+3A_fit">fit</code></td>
<td>
<p>Character (length = 1).
Fit index to control population error.
Defaults to <code>"rmsr"</code>.
Available options:
</p>

<ul>
<li> <p><code>"cfi"</code> &mdash; Comparative fit index
</p>
</li>
<li> <p><code>"rmsea"</code> &mdash; Root mean square error of approximation
</p>
</li>
<li> <p><code>"rmsr"</code> &mdash; Root mean square residuals
</p>
</li>
<li> <p><code>"raw"</code> &mdash; Direct application of error
</p>
</li></ul>
</td></tr>
<tr><td><code id="add_population_error_+3A_misfit">misfit</code></td>
<td>
<p>Character or numeric (length = 1).
Magnitude of error to add.
Defaults to <code>"close"</code>.
Available options:
</p>

<ul>
<li> <p><code>"close"</code> &mdash; Slight deviations from original population correlation matrix
</p>
</li>
<li> <p><code>"acceptable"</code> &mdash; Moderate deviations from original population correlation matrix
</p>
</li></ul>

<p>While numbers can be used, they are <strong>not</strong> recommended. They can be
used to specify misfit but the level of misfit will vary depending
on the factor structure</p>
</td></tr>
<tr><td><code id="add_population_error_+3A_error_method">error_method</code></td>
<td>
<p>Character (length = 1).
Method to control population error.
Defaults to <code>"cudeck"</code>.
Description of methods:
</p>

<ul>
<li> <p><code>"cudeck"</code> &mdash; Description coming soon... see Cudeck &amp; Browne, 1992
for more details
</p>
</li>
<li> <p><code>"yuan"</code> &mdash; Description coming soon...
</p>
</li></ul>
</td></tr>
<tr><td><code id="add_population_error_+3A_tolerance">tolerance</code></td>
<td>
<p>Numeric (length = 1).
Tolerance of SRMR difference between population error
correlation matrix and the original population correlation
matrix. Ensures that appropriate population error
was added. Similarly, verifies that the MAE of the
loadings are not greater than the specified amount,
ensuring proper convergence.
Defaults to <code>0.01</code></p>
</td></tr>
<tr><td><code id="add_population_error_+3A_convergence_iterations">convergence_iterations</code></td>
<td>
<p>Numeric (length = 1).
Number of iterations to reach parameter convergence
within the specified 'tolerance'.
Defaults to <code>10</code></p>
</td></tr>
<tr><td><code id="add_population_error_+3A_leave_cross_loadings">leave_cross_loadings</code></td>
<td>
<p>Boolean.
Should cross-loadings be kept?
Defaults to <code>FALSE</code>.
Convergence problems can arise if cross-loadings are kept,
so setting them to zero is the default. Only set to <code>TRUE</code>
with careful consideration of the structure. Make sure to perform
additional checks that the data are adequate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Simulated data from the specified factor model</p>
</td></tr>
<tr><td><code>population_correlation</code></td>
<td>
<p>Population correlation matrix with local dependence added</p>
</td></tr>
<tr><td><code>population_error</code></td>
<td>

<p>A list containing the parameters used to generate population error:
</p>

<ul>
<li> <p><code>error_correlation</code> &mdash; Correlation matrix with population
error added (same as <code>population_correlation</code>)
</p>
</li>
<li> <p><code>fit</code> &mdash; Fit measure used to control population error
</p>
</li>
<li> <p><code>delta</code> &mdash; Minimum of the objective function corresponding
to the misfit value
</p>
</li>
<li> <p><code>misfit</code> &mdash; Specified misfit value
</p>
</li>
<li> <p><code>loadings</code> &mdash; Estiamted CFA loadings after error has been added
</p>
</li></ul>

</td></tr>
<tr><td><code>original_results</code></td>
<td>
<p>Original <code>lf_object</code> input into function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p><code><a href="psych.html#topic+bifactor">bifactor</a></code> authors <br />
Marcos Jimenez,
Francisco J. Abad,
Eduardo Garcia-Garzon,
Vithor R. Franco,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>
<p><code><a href="#topic+latentFactoR">latentFactoR</a></code> authors <br />
Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;,
Marcos Jimenez,
Francisco J. Abad,
Eduardo Garcia-Garzon,
Vithor R. Franco
</p>


<h3>References</h3>

<p>Cudeck, R., &amp; Browne, M.W. (1992).
Constructing a covariance matrix that yields a specified minimizer and a specified minimum discrepancy function value.
<em>Psychometrika</em>, <em>57</em>, 357–369.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Add small population error using Cudeck method
two_factor_Cudeck &lt;- add_population_error(
  lf_object = two_factor,
  cfa_method = "minres",
  fit = "rmsr", misfit = "close",
  error_method = "cudeck"
)

# Add small population error using Yuan method
two_factor_Yuan &lt;- add_population_error(
  lf_object = two_factor,
  cfa_method = "minres",
  fit = "rmsr", misfit = "close",
  error_method = "yuan"
)

</code></pre>

<hr>
<h2 id='add_wording_effects'>Adds Wording Effects to <code><a href="#topic+simulate_factors">simulate_factors</a></code> Data</h2><span id='topic+add_wording_effects'></span>

<h3>Description</h3>

<p>Adds wording effects to simulated data from <code><a href="#topic+simulate_factors">simulate_factors</a></code>.
See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_wording_effects(
  lf_object,
  method = c("acquiescence", "difficulty", "random_careless", "straight_line", "mixed"),
  proportion_negative = 0.5,
  proportion_negative_range = NULL,
  proportion_biased_cases = 0.1,
  proportion_biased_variables = 1,
  proportion_biased_variables_range = NULL,
  proportion_biased_person = 1,
  proportion_biased_person_range = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_wording_effects_+3A_lf_object">lf_object</code></td>
<td>
<p>Data object from <code><a href="#topic+simulate_factors">simulate_factors</a></code>.
Data <strong>must</strong> be categorical. If data are not categorical, then
there function with throw an error</p>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_method">method</code></td>
<td>
<p>Character (length = 1).
Method to generate wording effect to add to the data.
Description of methods:
</p>

<ul>
<li> <p><code>"acquiescence"</code> &mdash;Generates new data with flipped dominant loadings
(based on <code>proportion_negative</code>) and ensures a bias
such that variables have a restricted range of responding
(e.g., only 4s and 5s on a 5-point Likert scale)
</p>
</li>
<li> <p><code>"difficulty"</code> &mdash; Generates new data with flipped dominant loadings
(based on <code>proportion_negative</code>) and uses this data
as the data without wording effects. Then, the signs of the
dominant loadings are obtained and the dominant loadings are
made to be absolute. Finally, the skews are multiplied by
the signs of the original dominant loadings when generating
the data with the wording effects
</p>
</li>
<li> <p><code>"random_careless"</code> &mdash; Number of cases up to <code>proportion_biased_cases</code>
are sampled and replaced by values from a random uniform distribution ranging
between the lowest and highest response category for each variable.
These values then replace the values in the original data
</p>
</li>
<li> <p><code>"straight_line"</code> &mdash; Coming soon...
</p>
</li></ul>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_proportion_negative">proportion_negative</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code>).
Proportion of variables that should have negative (or flipped) dominant loadings across all
or each factor. Accepts number of variables as well.
The first variables on each factor, up to the corresponding proportion, will be
flipped. Set to <code>0</code> to not have any loadings flipped.
Defaults to <code>0.50</code></p>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_proportion_negative_range">proportion_negative_range</code></td>
<td>
<p>Numeric (length = 2).
Range of proportion of variables that are randomly selected from
a uniform distribution. Accepts number of number of variables as well.
Defaults to <code>NULL</code></p>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_proportion_biased_cases">proportion_biased_cases</code></td>
<td>
<p>Numeric (length = 1).
Proportion of cases that should be biased with wording effects.
Also accepts number of cases to be biased. The first <em>n</em> number of cases,
up to the corresponding proportion, will be biased.
Defaults to <code>0.10</code> or 10 percent of cases.</p>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_proportion_biased_variables">proportion_biased_variables</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code>).
Proportion of variables that should be biased with wording effects.
For <code>method = "difficulty"</code>, proportion of biased variables will only
count for the negative variables.
For <code>method = "acquiescence"</code>, proportion of biased variables will only
count for variables below the mid-point of the <code>variable_categories</code>.
Defaults to <code>1</code> or all possible variables</p>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_proportion_biased_variables_range">proportion_biased_variables_range</code></td>
<td>
<p>Numeric (length = 2).
Range of proportion of variables that should be biased with wording effects.
Values are drawn randomly from a uniform distribution.
Defaults to <code>NULL</code></p>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_proportion_biased_person">proportion_biased_person</code></td>
<td>
<p>Numeric (length = 1 or <code>proportion_biased_cases</code> x <code>sample_size</code>).
Person-specific parameter of how many much bias the <code>proportion_biased_cases</code> will
have over the possible biased variables. This parameter interacts with
<code>proportion_biased_variables</code>. Parameter specifies the proportion of variables
that should have bias per person.
If one value is provided, then all biased cases will have the same proportion of variables biased.
Individual values are possible by providing values for each biased case
(<code>round(nrow(lf_object$data) * proportion_biased_cases)</code>). Setting individual
values for each biased case is not recommended
(use <code>proportion_biased_person_range</code> instead).
Defaults to <code>1</code> or all possible biased variables for all biased cases</p>
</td></tr>
<tr><td><code id="add_wording_effects_+3A_proportion_biased_person_range">proportion_biased_person_range</code></td>
<td>
<p>Numeric (length = 2).
Range to randomly draw bias from a uniform distribution. Allows for random
person-specific bias to be obtained.
Defaults to <code>NULL</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Biased data simulated data from the specified factor model</p>
</td></tr>
<tr><td><code>unbiased_data</code></td>
<td>
<p>The corresponding unbiased data prior to replacing values
to generate the (biased) <code>data</code></p>
</td></tr>
<tr><td><code>biased_sample_size</code></td>
<td>
<p>The number of cases that have biased data</p>
</td></tr>
<tr><td><code>adjusted_results</code></td>
<td>
<p>Bias-adjusted <code>lf_object</code> input into function</p>
</td></tr>
<tr><td><code>original_results</code></td>
<td>
<p>Original <code>lf_object</code> input into function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Garcia-Pardina, A., Abad, F. J., Christensen, A. P., Golino, H., &amp; Garrido, L. E. (2022).
Dimensionality assessment in the presence of wording effects: A network psychometric and factorial approach.
<em>PsyArXiv</em>.
</p>
<p>Garrido, L. E., Golino, H., Christensen, A. P., Martinez-Molina, A., Arias, V. B., Guerra-Pena, K., ... &amp; Abad, F. J. (2022).
A systematic evaluation of wording effects modeling under the exploratory structural equation modeling framework.
<em>PsyArXiv</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000, # number of cases = 1000
  variable_categories = 5 # 5-point Likert scale
)

# Add wording effects using acquiescence method
two_factor_acquiescence &lt;- add_wording_effects(
  lf_object = two_factor,
  proportion_negative = 0.50,
  proportion_biased_cases = 0.10,
  method = "acquiescence"
)

# Add wording effects using difficulty method
two_factor_difficulty &lt;- add_wording_effects(
  lf_object = two_factor,
  proportion_negative = 0.50,
  proportion_biased_cases = 0.10,
  method = "difficulty"
)

# Add wording effects using random careless method
two_factor_random_careless &lt;- add_wording_effects(
  lf_object = two_factor,
  proportion_negative = 0.50,
  proportion_biased_cases = 0.10,
  method = "random_careless"
)

# Add wording effects using straight line method
two_factor_random_careless &lt;- add_wording_effects(
  lf_object = two_factor,
  proportion_negative = 0.50,
  proportion_biased_cases = 0.10,
  method = "straight_line"
)

# Add wording effects using mixed method
two_factor_mixed &lt;- add_wording_effects(
  lf_object = two_factor,
  proportion_negative = 0.50,
  proportion_biased_cases = 0.10,
  method = "mixed"
)

# Add wording effects using acquiescence and straight line method
two_factor_multiple &lt;- add_wording_effects(
  lf_object = two_factor,
  proportion_negative = 0.50,
  proportion_biased_cases = 0.10,
  method = c("acquiescence", "straight_line")
)

</code></pre>

<hr>
<h2 id='categorize'>Categorize Continuous Data</h2><span id='topic+categorize'></span>

<h3>Description</h3>

<p>Categorizes continuous data based on Garrido, Abad and Ponsoda (2011; see references).
Categorical data with 2 to 6 categories can include skew between -2 to 2 in
increments of 0.05
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categorize(data, categories, skew_value = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categorize_+3A_data">data</code></td>
<td>
<p>Numeric (length = n).
A vector of continuous data with <em>n</em> values.
For matrices, use <code>apply</code></p>
</td></tr>
<tr><td><code id="categorize_+3A_categories">categories</code></td>
<td>
<p>Numeric (length = 1).
Number of categories to create.
Between 2 and 6 categories can be used with skew</p>
</td></tr>
<tr><td><code id="categorize_+3A_skew_value">skew_value</code></td>
<td>
<p>Numeric (length = 1).
Value of skew.
Ranges between -2 to 2 in increments of 0.05.
Skews not in this sequence will be converted to
the nearest value in this sequence.
Defaults to <code>0</code> or no skew</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric vector of the categorize data
</p>


<h3>Author(s)</h3>

<p>Maria Dolores Nieto Canaveras &lt;mnietoca@nebrija.es&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>References</h3>

<p>Garrido, L. E., Abad, F. J., &amp; Ponsoda, V. (2011). <br />
Performance of Velicer’s minimum average partial factor retention method with categorical variables. <br />
<em>Educational and Psychological Measurement</em>, <em>71</em>(3), 551-570.
</p>
<p>Golino, H., Shi, D., Christensen, A. P., Garrido, L. E., Nieto, M. D., Sadana, R., ... &amp; Martinez-Molina, A. (2020).
Investigating the performance of exploratory graph analysis and traditional techniques to identify the number of latent factors: A simulation and tutorial.
<em>Psychological Methods</em>, <em>25</em>(3), 292-320.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Dichotomous data (no skew)
dichotomous &lt;- categorize(
  data = rnorm(1000),
  categories = 2
)

# Dichotomous data (with positive skew)
dichotomous_skew &lt;- categorize(
  data = rnorm(1000),
  categories = 2,
  skew_value = 1.25
)

# 5-point Likert scale (no skew)
five_likert &lt;- categorize(
  data = rnorm(1000),
  categories = 5 
)

# 5-point Likert scale (negative skew)
five_likert &lt;- categorize(
  data = rnorm(1000),
  categories = 5,
  skew_value = -0.45
)

</code></pre>

<hr>
<h2 id='data_to_zipfs'>Transforms <code><a href="#topic+simulate_factors">simulate_factors</a></code> Data to Zipf's Distribution</h2><span id='topic+data_to_zipfs'></span>

<h3>Description</h3>

<p>Zipf's distribution is commonly found for text data. Closely related to the
Pareto and power-law distributions, the Zipf's distribution produces
highly skewed data. This transformation is intended to mirror the data
generating process of Zipf's law seen in semantic network and topic
modeling data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_to_zipfs(lf_object, beta = 2.7, alpha = 1, dichotomous = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data_to_zipfs_+3A_lf_object">lf_object</code></td>
<td>
<p>Data object from <code><a href="#topic+simulate_factors">simulate_factors</a></code></p>
</td></tr>
<tr><td><code id="data_to_zipfs_+3A_beta">beta</code></td>
<td>
<p>Numeric (length = 1).
Sets the shift in rank.
Defaults to <code>2.7</code></p>
</td></tr>
<tr><td><code id="data_to_zipfs_+3A_alpha">alpha</code></td>
<td>
<p>Numeric (length = 1).
Sets the power of the rank.
Defaults to <code>1</code></p>
</td></tr>
<tr><td><code id="data_to_zipfs_+3A_dichotomous">dichotomous</code></td>
<td>
<p>Boolean (length = 1).
Whether data should be dichotomized rather
than frequencies (e.g., semantic network analysis).
Defaults to <code>FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula used to transform data is (Piantadosi, 2014):
</p>
<p><em>f(r) proportional to 1 / (r + beta)^alpha</em>
</p>
<p>where <em>f(r)</em> is the <em>r</em>th most frequency,
<em>r</em> is the rank-order of the data, <em>beta</em>
is a shift in the rank (following Mandelbrot, 1953, 1962),
and <em>alpha</em> is the power of the rank with greater
values suggesting greater differences between the largest
frequency to the next, and so forth.
</p>
<p>The function will transform continuous data output from <code><a href="#topic+simulate_factors">simulate_factors</a></code>. 
See examples to get started
</p>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Simulated data that has been transform to follow Zipf's distribution</p>
</td></tr>
<tr><td><code>RMSE</code></td>
<td>
<p>A vector of root mean square errors for transformed data and data
assumed to follow theoretical Zipf's distribution and Spearman's correlation
matrix of the transformed data compared to the original population correlation
matrix</p>
</td></tr>
<tr><td><code>spearman_correlation</code></td>
<td>
<p>Spearman's correlation matrix of the transformed data</p>
</td></tr>
<tr><td><code>original_correlation</code></td>
<td>
<p>Original population correlation matrix <em>before</em>
the data were transformed</p>
</td></tr>
<tr><td><code>original_results</code></td>
<td>
<p>Original <code>lf_object</code> input into function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Mandelbrot, B. (1953).
An informational theory of the statistical structure of language.
<em>Communication Theory</em>, <em>84</em>, 486–502.
</p>
<p>Mandelbrot, B. (1962).
On the theory of word frequencies and on related Markovian models of discourse.
<em>Structure of Language and its Mathematical Aspects</em>, 190–219.
</p>
<p>Piantadosi, S. T. (2014).
Zipf’s word frequency law in natural language: A critical review and future directions.
<em>Psychonomic Bulletin &amp; Review</em>, <em>21</em>(5), 1112-1130.
</p>
<p>Zipf, G. (1936).
<em>The psychobiology of language</em>.
London, UK: Routledge.
</p>
<p>Zipf, G. (1949).
<em>Human behavior and the principle of least effort</em>. 
New York, NY: Addison-Wesley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Transform data to Mandelbrot's Zipf's
two_factor_zipfs &lt;- data_to_zipfs(
  lf_object = two_factor,
  beta = 2.7,
  alpha = 1
)

# Transform data to Mandelbrot's Zipf's (dichotomous)
two_factor_zipfs_binary &lt;- data_to_zipfs(
  lf_object = two_factor,
  beta = 2.7,
  alpha = 1,
  dichotomous = TRUE
)

</code></pre>

<hr>
<h2 id='EKC'>Estimate Number of Dimensions using Empirical Kaiser Criterion</h2><span id='topic+EKC'></span>

<h3>Description</h3>

<p>Estimates the number of dimensions in data using
Empirical Kaiser Criterion (Braeken &amp; Van Assen, 2017).
See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EKC(data, sample_size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EKC_+3A_data">data</code></td>
<td>
<p>Matrix or data frame.
Either a dataset with all numeric values
(rows = cases, columns = variables) or
a symmetric correlation matrix</p>
</td></tr>
<tr><td><code id="EKC_+3A_sample_size">sample_size</code></td>
<td>
<p>Numeric (length = 1).
If input into <code>data</code> is a correlation matrix,
then specifying the sample size is required</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>dimensions</code></td>
<td>
<p>Number of dimensions identified</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>Eigenvalues</p>
</td></tr>
<tr><td><code>reference</code></td>
<td>
<p>Reference values compared against eigenvalues</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Braeken, J., &amp; Van Assen, M. A. (2017).
An empirical Kaiser criterion.
<em>Psychological Methods</em>, <em>22</em>(3), 450–466.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Perform Empirical Kaiser Criterion
EKC(two_factor$data)

</code></pre>

<hr>
<h2 id='ESEM'>Estimates Exploratory Structural Equation Model</h2><span id='topic+ESEM'></span>

<h3>Description</h3>

<p>A general function to estimate an Exploratory Structural
Equation Model (ESEM) using the <code><a href="lavaan.html#topic+lavaan">lavaan</a></code> package.
With <code><a href="#topic+latentFactoR">latentFactoR</a></code> objects,
the function requires fewer inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ESEM(
  data,
  factors,
  variables,
  estimator = c("MLR", "WLSMV"),
  fit_measures = NULL,
  variable_polarity = NULL,
  wording_factor = c("none", "CTCM1", "CTCM1_each", "RI", "RI_each"),
  CTCM1_polarity = c("negative", "positive"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ESEM_+3A_data">data</code></td>
<td>
<p>Numeric matrix, data frame, or <code><a href="#topic+latentFactoR">latentFactoR</a></code> object</p>
</td></tr>
<tr><td><code id="ESEM_+3A_factors">factors</code></td>
<td>
<p>Numeric (length = 1).
Number of ESEM factors to estimate</p>
</td></tr>
<tr><td><code id="ESEM_+3A_variables">variables</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code>).
Number of variables per factor. A vector the length of the
number of factors can be specified to allow varying
number of variables on each factor (necessary for some
<code>wording_factor</code> arguments)</p>
</td></tr>
<tr><td><code id="ESEM_+3A_estimator">estimator</code></td>
<td>
<p>Character.
Estimator to be used in <code><a href="lavaan.html#topic+cfa">cfa</a></code>.
Default options are <code>"MLR"</code> for continuous data
and <code>"WLSMV"</code> for categorical data</p>
</td></tr>
<tr><td><code id="ESEM_+3A_fit_measures">fit_measures</code></td>
<td>
<p>Character.
Fit measures to be computed using <code><a href="lavaan.html#topic+fitMeasures">fitMeasures</a></code>.
Defaults to: <code>"chisq"</code>, <code>"df"</code>, <code>"pvalue"</code>, <code>"cfi"</code>,
<code>"tli"</code>, <code>"rmsea"</code>, <code>"rmsea.ci.lower"</code>,
<code>"rmsea.ci.upper"</code>, <code>"rmsea.pvalue"</code>, and <code>"srmr"</code>.
Other measures can be added but these measures will always be produced.
</p>
<p>If scaled values are available (not <code>NA</code>), then scaled fit measures
will be used.</p>
</td></tr>
<tr><td><code id="ESEM_+3A_variable_polarity">variable_polarity</code></td>
<td>
<p>Numeric/character (length = 1 or total variables).
Whether all (length = 1) or each variable (length = total variables) are
positive (<code>1</code>, <code>"p"</code>, <code>"pos"</code>, <code>"positive"</code>) or
negative (<code>-1</code>, <code>"n"</code>, <code>"neg"</code>, <code>"negative"</code>)
polarity on the factor</p>
</td></tr>
<tr><td><code id="ESEM_+3A_wording_factor">wording_factor</code></td>
<td>
<p>Character (length = 1).
Whether wording factor(s) should be estimated.
Defaults to <code>"none"</code>.
Options include:
</p>

<ul>
<li> <p><code>"CTCM1"</code> &mdash; Description coming soon...
</p>
</li>
<li> <p><code>"CTCM1_each"</code> &mdash; Description coming soon...
</p>
</li>
<li> <p><code>"RI"</code> &mdash; Description coming soon...
</p>
</li>
<li> <p><code>"RI_each"</code> &mdash; Description coming soon...
</p>
</li></ul>
</td></tr>
<tr><td><code id="ESEM_+3A_ctcm1_polarity">CTCM1_polarity</code></td>
<td>
<p>Character.
Polarity of the CTCM1 wording factor(s).
Defaults to <code>"negative"</code> for negative
polarity variables</p>
</td></tr>
<tr><td><code id="ESEM_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed on to
<code><a href="lavaan.html#topic+cfa">cfa</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>Estimated ESEM model</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>Fit measures of estimated ESEM model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000, # number of cases = 1000
  variable_categories = 5 # 5-point Likert scale
)

## Not run: 
# Estimate ESEM model with no wording effects
esem_no_wording_effects &lt;- ESEM(
  data = two_factor,
  estimator = "WLSMV"
)

# Add wording effects using acquiescence method
two_factor_acquiescence &lt;- add_wording_effects(
  lf_object = two_factor,
  proportion_negative = 0.50,
  proportion_biased_cases = 0.10,
  method = "acquiescence"
)

# Estimate ESEM model with wording effects
esem_wording_effects &lt;- ESEM(
  data = two_factor_acquiescence,
  estimator = "WLSMV",
  wording_factor = "RI"
)
## End(Not run)

</code></pre>

<hr>
<h2 id='estimate_dimensions'>Estimates Dimensions using Several State-of-the-art Methods</h2><span id='topic+estimate_dimensions'></span>

<h3>Description</h3>

<p>Estimates dimensions using Exploratory Graph Analysis
(<code><a href="EGAnet.html#topic+EGA">EGA</a></code>),
Empirical Kaiser Criterion (<code><a href="#topic+EKC">EKC</a></code>),
Factor Forest (<code><a href="#topic+factor_forest">factor_forest</a></code>),
Exploratory Factor Analysis with out-of-sample prediction (<code><a href="fspe.html#topic+fspe">fspe</a></code>),
Next Eigenvalue Sufficiency Test (<code><a href="#topic+NEST">NEST</a></code>), and
parallel analysis (<code><a href="psych.html#topic+fa.parallel">fa.parallel</a></code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_dimensions(
  data,
  sample_size,
  EGA_args = list(corr = "auto", uni.method = "louvain", model = "glasso",
    consensus.method = "most_common", plot.EGA = FALSE),
  FF_args = list(maximum_factors = 8, PA_correlation = "cor"),
  FSPE_args = list(maxK = 8, rep = 1, method = "PE", pbar = FALSE),
  NEST_args = list(iterations = 1000, maximum_iterations = 500, alpha = 0.05, convergence
    = 0.00001),
  PA_args = list(fm = "minres", fa = "both", cor = "cor", n.iter = 20, sim = FALSE, plot
    = FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_dimensions_+3A_data">data</code></td>
<td>
<p>Matrix or data frame.
Either a dataset with all numeric values
(rows = cases, columns = variables) or
a symmetric correlation matrix</p>
</td></tr>
<tr><td><code id="estimate_dimensions_+3A_sample_size">sample_size</code></td>
<td>
<p>Numeric (length = 1).
If input into <code>data</code> is a correlation matrix,
then specifying the sample size is required</p>
</td></tr>
<tr><td><code id="estimate_dimensions_+3A_ega_args">EGA_args</code></td>
<td>
<p>List.
List of arguments to be passed along to
<code><a href="EGAnet.html#topic+EGA">EGA</a></code>.
Defaults are listed</p>
</td></tr>
<tr><td><code id="estimate_dimensions_+3A_ff_args">FF_args</code></td>
<td>
<p>List.
List of arguments to be passed along to
<code><a href="#topic+factor_forest">factor_forest</a></code>.
Defaults are listed</p>
</td></tr>
<tr><td><code id="estimate_dimensions_+3A_fspe_args">FSPE_args</code></td>
<td>
<p>List.
List of arguments to be passed along to
<code><a href="fspe.html#topic+fspe">fspe</a></code>.
Defaults are listed</p>
</td></tr>
<tr><td><code id="estimate_dimensions_+3A_nest_args">NEST_args</code></td>
<td>
<p>List.
List of arguments to be passed along to
<code><a href="#topic+NEST">NEST</a></code>.
Defaults are listed</p>
</td></tr>
<tr><td><code id="estimate_dimensions_+3A_pa_args">PA_args</code></td>
<td>
<p>List.
List of arguments to be passed along to
<code><a href="psych.html#topic+fa.parallel">fa.parallel</a></code>.
Defaults are listed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>dimensions</code></td>
<td>
<p>Dimensions estimated from each method</p>
</td></tr>
</table>
<p>A list of each methods output (see their respective functions for their outputs)
</p>


<h3>Author(s)</h3>

<p>Maria Dolores Nieto Canaveras &lt;mnietoca@nebrija.es&gt;,
Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

## Not run: 
# Estimate dimensions
estimate_dimensions(two_factor$data)
## End(Not run)

</code></pre>

<hr>
<h2 id='factor_forest'>Estimate Number of Dimensions using Factor Forest</h2><span id='topic+factor_forest'></span>

<h3>Description</h3>

<p>Estimates the number of dimensions in data using the
pre-trained Random Forest model from Goretzko and Buhner
(2020, 2022). See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factor_forest(
  data,
  sample_size,
  maximum_factors = 8,
  PA_correlation = c("cor", "poly", "tet")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factor_forest_+3A_data">data</code></td>
<td>
<p>Matrix or data frame.
Either a dataset with all numeric values
(rows = cases, columns = variables) or
a symmetric correlation matrix</p>
</td></tr>
<tr><td><code id="factor_forest_+3A_sample_size">sample_size</code></td>
<td>
<p>Numeric (length = 1).
If input into <code>data</code> is a correlation matrix,
then specifying the sample size is required</p>
</td></tr>
<tr><td><code id="factor_forest_+3A_maximum_factors">maximum_factors</code></td>
<td>
<p>Numeric (length = 1).
Maximum number of factors to search over.
Defaults to <code>8</code></p>
</td></tr>
<tr><td><code id="factor_forest_+3A_pa_correlation">PA_correlation</code></td>
<td>
<p>Character (length = 1).
Type of correlation used in <code><a href="psych.html#topic+fa.parallel">fa.parallel</a></code>.
Must be set:
</p>

<ul>
<li> <p><code>"cor"</code> &mdash; Pearson's correlation
</p>
</li>
<li> <p><code>"poly"</code> &mdash; Polychoric correlation
</p>
</li>
<li> <p><code>"tet"</code> &mdash; Tetrachoric correlation
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>dimensions</code></td>
<td>
<p>Number of dimensions identified</p>
</td></tr>
<tr><td><code>probabilities</code></td>
<td>
<p>Probability that the number of dimensions
is most likely</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p># Authors of Factor Forest <br />
David Goretzko and Markus Buhner
</p>
<p># Authors of {latentFactoR} <br />
Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Goretzko, D., &amp; Buhner, M. (2022).
Factor retention using machine learning with ordinal data.
<em>Applied Psychological Measurement</em>, 01466216221089345.
</p>
<p>Goretzko, D., &amp; Buhner, M. (2020).
One model to rule them all? Using machine learning
algorithms to determine the number of factors
in exploratory factor analysis.
<em>Psychological Methods</em>, <em>25</em>(6), 776-786.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

## Not run: 
# Perform Factor Forest
factor_forest(two_factor$data)
## End(Not run)

</code></pre>

<hr>
<h2 id='NEST'>Estimate Number of Dimensions using Next Eigenvalue Sufficiency Test</h2><span id='topic+NEST'></span>

<h3>Description</h3>

<p>Estimates the number of dimensions in data using NEST (Achim, 2017).
See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NEST(
  data,
  sample_size,
  iterations = 1000,
  maximum_iterations = 500,
  alpha = 0.05,
  convergence = 0.00001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NEST_+3A_data">data</code></td>
<td>
<p>Matrix or data frame.
Either a dataset with all numeric values
(rows = cases, columns = variables) or
a symmetric correlation matrix</p>
</td></tr>
<tr><td><code id="NEST_+3A_sample_size">sample_size</code></td>
<td>
<p>Numeric (length = 1).
If input into <code>data</code> is a correlation matrix,
then specifying the sample size is required</p>
</td></tr>
<tr><td><code id="NEST_+3A_iterations">iterations</code></td>
<td>
<p>Numeric (length = 1).
Number of iterations to estimate rank.
Defaults to <code>1000</code></p>
</td></tr>
<tr><td><code id="NEST_+3A_maximum_iterations">maximum_iterations</code></td>
<td>
<p>Numeric (length = 1).
Maximum umber of iterations to obtain convergence
of eigenvalues.
Defaults to <code>500</code></p>
</td></tr>
<tr><td><code id="NEST_+3A_alpha">alpha</code></td>
<td>
<p>Numeric (length = 1).
Significance level for determine sufficient eigenvalues.
Defaults to <code>0.05</code></p>
</td></tr>
<tr><td><code id="NEST_+3A_convergence">convergence</code></td>
<td>
<p>Numeric (length = 1).
Value necessary to be less than or equal to
when establishing convergence of eigenvalues</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>dimensions</code></td>
<td>
<p>Number of dimensions identified</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>Loading matrix</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Whether estimation converged. If <code>FALSE</code>,
then results are reported from last convergence point. Interpret
results with caution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Achim, A. (2017).
Testing the number of required dimensions in
exploratory factor analysis.
<em>The Quantitative Methods for Psychology</em>, <em>13</em>(1), 64–74.
</p>
<p>Brandenburg, N., &amp; Papenberg, M. (2022).
Reassessment of innovative methods to determine the number
of factors: A simulation-Based comparison of Exploratory
Graph Analysis and Next Eigenvalue Sufficiency Test.
<em>Psychological Methods</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

## Not run: 
# Perform NEST
NEST(two_factor$data)
## End(Not run)

</code></pre>

<hr>
<h2 id='obtain_zipfs_parameters'>Obtain Zipf's Distribution Parameters from Data</h2><span id='topic+obtain_zipfs_parameters'></span>

<h3>Description</h3>

<p>Zipf's distribution is commonly found for text data. Closely related to the
Pareto and power-law distributions, the Zipf's distribution produces
highly skewed data. This function obtains the best fitting parameters
to Zipf's distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obtain_zipfs_parameters(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="obtain_zipfs_parameters_+3A_data">data</code></td>
<td>
<p>Numeric vector, matrix, or data frame.
Numeric data to determine Zipf's distribution parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The best parameters are optimized by minimizing the aboslute
difference between the original frequencies and the frequencies obtained
by the <em>beta</em> and <em>alpha</em> parameters in the following
formula (Piantadosi, 2014):
</p>
<p><em>f(r) proportional to 1 / (r + beta)^alpha</em>
</p>
<p>where <em>f(r)</em> is the <em>r</em>th most frequency,
<em>r</em> is the rank-order of the data, <em>beta</em>
is a shift in the rank (following Mandelbrot, 1953, 1962),
and <em>alpha</em> is the power of the rank with greater
values suggesting greater differences between the largest
frequency to the next, and so forth.
</p>


<h3>Value</h3>

<p>Returns a vector containing the estimated <code>beta</code> and
<code>alpha</code> parameters. Also contains <code>zipfs_sse</code> which corresponds
to the sum of square error between frequencies based
on the parameter values estimated and the original data frequencies
</p>


<h3>Author(s)</h3>

<p>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Mandelbrot, B. (1953).
An informational theory of the statistical structure of language.
<em>Communication Theory</em>, <em>84</em>, 486–502.
</p>
<p>Mandelbrot, B. (1962).
On the theory of word frequencies and on related Markovian models of discourse.
<em>Structure of Language and its Mathematical Aspects</em>, 190–219.
</p>
<p>Piantadosi, S. T. (2014).
Zipf’s word frequency law in natural language: A critical review and future directions.
<em>Psychonomic Bulletin &amp; Review</em>, <em>21</em>(5), 1112-1130.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Transform data to Mandelbrot's Zipf's
two_factor_zipfs &lt;- data_to_zipfs(
  lf_object = two_factor,
  beta = 2.7,
  alpha = 1
)

# Obtain Zipf's distribution parameters
obtain_zipfs_parameters(two_factor_zipfs$data)

</code></pre>

<hr>
<h2 id='simulate_factors'>Simulates Latent Factor Data</h2><span id='topic+simulate_factors'></span>

<h3>Description</h3>

<p>Simulates data from a latent factor model based on many
manipulable parameters. Parameters do not have default values and
must each be set. See examples to get started
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_factors(
  factors,
  variables,
  variables_range = NULL,
  loadings,
  loadings_range = NULL,
  cross_loadings,
  cross_loadings_range = NULL,
  correlations,
  correlations_range = NULL,
  sample_size,
  variable_categories = Inf,
  categorical_limit = 7,
  skew = 0,
  skew_range = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_factors_+3A_factors">factors</code></td>
<td>
<p>Numeric (length = 1).
Number of factors</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_variables">variables</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code>).
Number of variables per factor.
Can be a single value or as many values as there are factors.
Minimum three variables per factor</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_variables_range">variables_range</code></td>
<td>
<p>Numeric (length = 2).
Range of variables to randomly select from a random uniform distribution.
Minimum three variables per factor</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_loadings">loadings</code></td>
<td>
<p>Numeric or matrix (length = 1, <code>factors</code>, total number of variables (<code>factors</code> x <code>variables</code>), or <code>factors</code> x total number of variables.
Loadings drawn from a random uniform distribution using +/- 0.10 of value input.
Can be a single value or as many values as there are factors (corresponding to the factors).
Can also be a loading matrix. Columns must match factors and rows must match total variables (<code>factors</code> x <code>variables</code>)
General effect sizes range from small (0.40), moderate (0.55), to large (0.70)</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_loadings_range">loadings_range</code></td>
<td>
<p>Numeric (length = 2).
Range of loadings to randomly select from a random uniform distribution.
General effect sizes range from small (0.40), moderate (0.55), to large (0.70)</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_cross_loadings">cross_loadings</code></td>
<td>
<p>Numeric or matrix(length = 1, <code>factors</code>, or <code>factors</code> x total number of variables.
Cross-loadings drawn from a random normal distribution with a mean of 0 and standard deviation of value input.
Can be a single value or as many values as there are factors (corresponding to the factors).
Can also be a loading matrix. Columns must match factors and rows must match total variables (<code>factors</code> x <code>variables</code>)</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_cross_loadings_range">cross_loadings_range</code></td>
<td>
<p>Numeric (length = 2).
Range of cross-loadings to randomly select from a random uniform distribution</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_correlations">correlations</code></td>
<td>
<p>Numeric (length = 1 or <code>factors</code> x <code>factors</code>).
Can be a single value that will be used for all correlations between factors.
Can also be a square matrix (<code>factors</code> x <code>factors</code>).
General effect sizes range from orthogonal (0.00), small (0.30), moderate (0.50), to large (0.70)</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_correlations_range">correlations_range</code></td>
<td>
<p>Numeric (length = 2).
Range of correlations to randomly select from a random uniform distribution.
General effect sizes range from orthogonal (0.00), small (0.30), moderate (0.50), to large (0.70)</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_sample_size">sample_size</code></td>
<td>
<p>Numeric (length = 1).
Number of cases to generate from a random multivariate normal distribution using
<code><a href="mvtnorm.html#topic+rmvnorm">rmvnorm</a></code></p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_variable_categories">variable_categories</code></td>
<td>
<p>Numeric (length = 1 or total variables (<code>factors</code> x <code>variables</code>)).
Number of categories for each variable. <code>Inf</code> is used for continuous variables; otherwise,
values reflect number of categories</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_categorical_limit">categorical_limit</code></td>
<td>
<p>Numeric (length = 1).
Values greater than input value are considered continuous.
Defaults to <code>7</code> meaning that 8 or more categories are considered continuous
(i.e., variables are <em>not</em> categorized from continuous to categorical)</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_skew">skew</code></td>
<td>
<p>Numeric (length = 1 or categorical variables).
Skew to be included in categorical variables. It is randomly sampled from provided values.
Can be a single value or as many values as there are (total) variables.
Current skew implementation is between -2 and 2 in increments of 0.05.
Skews that are not in this sequence will be converted to their nearest
value in the sequence. Not recommended to use with <code>variables_range</code>.
Future versions will incorporate finer skews</p>
</td></tr>
<tr><td><code id="simulate_factors_+3A_skew_range">skew_range</code></td>
<td>
<p>Numeric (length = 2).
Randomly selects skews within in the range.
Somewhat redundant with <code>skew</code> but more flexible.
Compatible with <code>variables_range</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>Simulated data from the specified factor model</p>
</td></tr>
<tr><td><code>population_correlation</code></td>
<td>
<p>Population correlation matrix</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>

<p>A list containing the parameters used to generate the data:
</p>

<ul>
<li> <p><code>factors</code> &mdash; Number of factors
</p>
</li>
<li> <p><code>variables</code> &mdash; Variables on each factor
</p>
</li>
<li> <p><code>loadings</code> &mdash; Loading matrix
</p>
</li>
<li> <p><code>factor_correlations</code> &mdash; Correlations between factors
</p>
</li>
<li> <p><code>categories</code> &mdash; Categories for each variable
</p>
</li>
<li> <p><code>skew</code> &mdash; Skew for each variable
</p>
</li></ul>

</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maria Dolores Nieto Canaveras &lt;mnietoca@nebrija.es&gt;,
Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;,
Hudson Golino &lt;hfg9s@virginia.edu&gt;,
Luis Eduardo Garrido &lt;luisgarrido@pucmm.edu&gt;
</p>


<h3>References</h3>

<p>Garrido, L. E., Abad, F. J., &amp; Ponsoda, V. (2011). <br />
Performance of Velicer’s minimum average partial factor retention method with categorical variables. <br />
<em>Educational and Psychological Measurement</em>, <em>71</em>(3), 551-570.
</p>
<p>Golino, H., Shi, D., Christensen, A. P., Garrido, L. E., Nieto, M. D., Sadana, R., ... &amp; Martinez-Molina, A. (2020).
Investigating the performance of exploratory graph analysis and traditional techniques to identify the number of latent factors: A simulation and tutorial.
<em>Psychological Methods</em>, <em>25</em>(3), 292-320.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate factor data
two_factor &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Randomly vary loadings
two_factor_loadings &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings_range = c(0.30, 0.80), # loadings between = 0.30 to 0.80
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000 # number of cases = 1000
)

# Generate dichotomous data
two_factor_dichotomous &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000, # number of cases = 1000
  variable_categories = 2 # dichotomous data
)

# Generate dichotomous data with skew
two_factor_dichotomous_skew &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000, # number of cases = 1000
  variable_categories = 2, # dichotomous data
  skew = 1 # all variables with have a skew of 1
)

# Generate dichotomous data with variable skew
two_factor_dichotomous_skew &lt;- simulate_factors(
  factors = 2, # factors = 2
  variables = 6, # variables per factor = 6
  loadings = 0.55, # loadings between = 0.45 to 0.65
  cross_loadings = 0.05, # cross-loadings N(0, 0.05)
  correlations = 0.30, # correlation between factors = 0.30
  sample_size = 1000, # number of cases = 1000
  variable_categories = 2, # dichotomous data
  skew_range = c(-2, 2) # skew = -2 to 2 (increments of 0.05)
)

</code></pre>

<hr>
<h2 id='skew_tables'>Skew Tables</h2><span id='topic+skew_tables'></span>

<h3>Description</h3>

<p>Tables for skew based on the number of categories (2, 3, 4, 5, or 6) in the data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(skew_tables)
</code></pre>


<h3>Format</h3>

<p>A list (length = 5)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("skew_tables")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
