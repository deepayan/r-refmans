<!DOCTYPE html><html><head><title>Help for package simtrial</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {simtrial}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#simtrial-package'><p>simtrial: Clinical Trial Simulation</p></a></li>
<li><a href='#counting_process'><p>Process survival data into counting process format</p></a></li>
<li><a href='#cut_data_by_date'><p>Cut a dataset for analysis at a specified date</p></a></li>
<li><a href='#cut_data_by_event'><p>Cut a dataset for analysis at a specified event count</p></a></li>
<li><a href='#early_zero_weight'><p>Zero early weight for weighted logrank tests</p></a></li>
<li><a href='#ex1_delayed_effect'><p>Time-to-event data example 1 for non-proportional hazards working group</p></a></li>
<li><a href='#ex2_delayed_effect'><p>Time-to-event data example 2 for non-proportional hazards working group</p></a></li>
<li><a href='#ex3_cure_with_ph'><p>Time-to-event data example 3 for non-proportional hazards working group</p></a></li>
<li><a href='#ex4_belly'><p>Time-to-event data example 4 for non-proportional hazards working group</p></a></li>
<li><a href='#ex5_widening'><p>Time-to-event data example 5 for non-proportional hazards working group</p></a></li>
<li><a href='#ex6_crossing'><p>Time-to-event data example 6 for non-proportional hazards working group</p></a></li>
<li><a href='#fh_weight'><p>Fleming-Harrington weighted logrank tests</p></a></li>
<li><a href='#fit_pwexp'><p>Piecewise exponential survival estimation</p></a></li>
<li><a href='#get_analysis_date'><p>Get the analysis date under multiple conditions</p></a></li>
<li><a href='#get_cut_date_by_event'><p>Get date at which an event count is reached</p></a></li>
<li><a href='#mb_delayed_effect'><p>Simulated survival dataset with delayed treatment effect</p></a></li>
<li><a href='#mb_weight'><p>Magirr and Burman modestly weighted logrank tests</p></a></li>
<li><a href='#pvalue_maxcombo'><p>MaxCombo p-value</p></a></li>
<li><a href='#randomize_by_fixed_block'><p>Permuted fixed block randomization</p></a></li>
<li><a href='#rpwexp'><p>The piecewise exponential distribution</p></a></li>
<li><a href='#rpwexp_enroll'><p>Generate piecewise exponential enrollment</p></a></li>
<li><a href='#sim_fixed_n'><p>Simulation of fixed sample size design for time-to-event endpoint</p></a></li>
<li><a href='#sim_pw_surv'><p>Simulate a stratified time-to-event outcome randomized trial</p></a></li>
<li><a href='#to_sim_pw_surv'><p>Convert enrollment and failure rates from <code>sim_fixed_n()</code> to</p>
<code>sim_pw_surv()</code> format</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Clinical Trial Simulation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides some basic routines for simulating a
    clinical trial. The primary intent is to provide some tools to
    generate trial simulations for trials with time to event outcomes.
    Piecewise exponential failure rates and piecewise constant
    enrollment rates are the underlying mechanism used to simulate
    a broad range of scenarios such as those presented in
    Lin et al. (2020) &lt;<a href="https://doi.org/10.1080%2F19466315.2019.1697738">doi:10.1080/19466315.2019.1697738</a>&gt;.
    However, the basic generation of data is done using pipes to allow
    maximum flexibility for users to meet different needs.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://merck.github.io/simtrial/">https://merck.github.io/simtrial/</a>,
<a href="https://github.com/Merck/simtrial">https://github.com/Merck/simtrial</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Merck/simtrial/issues">https://github.com/Merck/simtrial/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, data.table, doFuture, foreach, future, methods, mvtnorm,
stats, survival, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Matrix, bshazard, covr, dplyr, ggplot2, gsDesign, gsDesign2,
knitr, rmarkdown, survMisc, testthat, tidyr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-09 01:09:25 UTC; xiaonan4</td>
</tr>
<tr>
<td>Author:</td>
<td>Keaven Anderson [aut],
  Yilong Zhang [aut],
  Yujie Zhao [ctb, cre],
  Nan Xiao [ctb],
  Jianxiao Yang [ctb],
  Lili Ling [ctb],
  Xintong Li [ctb],
  Ruixue Wang [ctb],
  Yi Cui [ctb],
  Ping Yang [ctb],
  Yalin Zhu [ctb],
  Heng Zhou [ctb],
  Amin Shirazi [ctb],
  Cole Manschot [ctb],
  John Blischak [ctb],
  Merck &amp; Co., Inc., Rahway, NJ, USA and its affiliates [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yujie Zhao &lt;yujie.zhao@merck.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-11 15:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='simtrial-package'>simtrial: Clinical Trial Simulation</h2><span id='topic+simtrial'></span><span id='topic+simtrial-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Provides some basic routines for simulating a clinical trial. The primary intent is to provide some tools to generate trial simulations for trials with time to event outcomes. Piecewise exponential failure rates and piecewise constant enrollment rates are the underlying mechanism used to simulate a broad range of scenarios such as those presented in Lin et al. (2020) <a href="https://doi.org/10.1080/19466315.2019.1697738">doi:10.1080/19466315.2019.1697738</a>. However, the basic generation of data is done using pipes to allow maximum flexibility for users to meet different needs.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Yujie Zhao <a href="mailto:yujie.zhao@merck.com">yujie.zhao@merck.com</a> [contributor]
</p>
<p>Authors:
</p>

<ul>
<li><p> Keaven Anderson <a href="mailto:keaven_anderson@merck.com">keaven_anderson@merck.com</a>
</p>
</li>
<li><p> Yilong Zhang <a href="mailto:elong0527@gmail.com">elong0527@gmail.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Nan Xiao [contributor]
</p>
</li>
<li><p> Jianxiao Yang [contributor]
</p>
</li>
<li><p> Lili Ling [contributor]
</p>
</li>
<li><p> Xintong Li [contributor]
</p>
</li>
<li><p> Ruixue Wang [contributor]
</p>
</li>
<li><p> Yi Cui [contributor]
</p>
</li>
<li><p> Ping Yang [contributor]
</p>
</li>
<li><p> Yalin Zhu [contributor]
</p>
</li>
<li><p> Heng Zhou [contributor]
</p>
</li>
<li><p> Amin Shirazi [contributor]
</p>
</li>
<li><p> Cole Manschot [contributor]
</p>
</li>
<li><p> John Blischak [contributor]
</p>
</li>
<li><p> Merck &amp; Co., Inc., Rahway, NJ, USA and its affiliates [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://merck.github.io/simtrial/">https://merck.github.io/simtrial/</a>
</p>
</li>
<li> <p><a href="https://github.com/Merck/simtrial">https://github.com/Merck/simtrial</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/Merck/simtrial/issues">https://github.com/Merck/simtrial/issues</a>
</p>
</li></ul>


<hr>
<h2 id='counting_process'>Process survival data into counting process format</h2><span id='topic+counting_process'></span>

<h3>Description</h3>

<p>Produces a data frame that is sorted by stratum and time.
Included in this is only the times at which one or more event occurs.
The output dataset contains stratum, tte (time-to-event),
at risk count and count of events at the specified tte
sorted by stratum and tte.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>counting_process(x, arm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="counting_process_+3A_x">x</code></td>
<td>
<p>A data frame with no missing values and contain variables:
</p>

<ul>
<li> <p><code>stratum</code>: Stratum.
</p>
</li>
<li> <p><code>treatment</code>: Treatment group.
</p>
</li>
<li> <p><code>tte</code>: Observed time.
</p>
</li>
<li> <p><code>event</code>: Binary event indicator, <code>1</code> represents event,
<code>0</code> represents censoring.
</p>
</li></ul>
</td></tr>
<tr><td><code id="counting_process_+3A_arm">arm</code></td>
<td>
<p>Value in the input <code>treatment</code> column that indicates
treatment group value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function only considered two group situation.
</p>
<p>The tie is handled by the Breslow's Method.
</p>


<h3>Value</h3>

<p>A data frame grouped by <code>stratum</code> and sorted within stratum by <code>tte</code>.
Remain rows with at least one event in the population, at least one subject
is at risk in both treatment group and control group.
Other variables in this represent the following within each stratum at
each time at which one or more events are observed:
</p>

<ul>
<li> <p><code>events</code>: Total number of events
</p>
</li>
<li> <p><code>n_event_tol</code>: Total number of events at treatment group
</p>
</li>
<li> <p><code>n_risk_tol</code>: Number of subjects at risk
</p>
</li>
<li> <p><code>n_risk_trt</code>: Number of subjects at risk in treatment group
</p>
</li>
<li> <p><code>S</code>: Left-continuous Kaplan-Meier survival estimate
</p>
</li>
<li> <p><code>o_minus_e</code>: In treatment group, observed number of events minus expected
number of events. The expected number of events is estimated by assuming
no treatment effect with hypergeometric distribution with parameters total
number of events, total number of events at treatment group and number of
events at a time. (Same assumption of log-rank test under the null
hypothesis)
</p>
</li>
<li> <p><code>var_o_minus_e</code>: Variance of <code>o_minus_e</code> under the same assumption.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Example 1
x &lt;- data.frame(
  stratum = c(rep(1, 10), rep(2, 6)),
  treatment = rep(c(1, 1, 0, 0), 4),
  tte = 1:16,
  event = rep(c(0, 1), 8)
)
counting_process(x, arm = 1)

# Example 2
x &lt;- sim_pw_surv(n = 400)
y &lt;- cut_data_by_event(x, 150) |&gt; counting_process(arm = "experimental")
# Weighted logrank test (Z-value and 1-sided p-value)
z &lt;- sum(y$o_minus_e) / sqrt(sum(y$var_o_minus_e))
c(z, pnorm(z))
</code></pre>

<hr>
<h2 id='cut_data_by_date'>Cut a dataset for analysis at a specified date</h2><span id='topic+cut_data_by_date'></span>

<h3>Description</h3>

<p>Cut a dataset for analysis at a specified date
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cut_data_by_date(x, cut_date)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cut_data_by_date_+3A_x">x</code></td>
<td>
<p>A time-to-event dataset, for example, generated by <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>.</p>
</td></tr>
<tr><td><code id="cut_data_by_date_+3A_cut_date">cut_date</code></td>
<td>
<p>Date relative to start of randomization
(<code>cte</code> from input dataset) at which dataset is to be cut off for analysis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataset ready for survival analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use default enrollment and event rates and
# cut at calendar time 5 after start of randomization
sim_pw_surv(n = 20) |&gt; cut_data_by_date(5)
</code></pre>

<hr>
<h2 id='cut_data_by_event'>Cut a dataset for analysis at a specified event count</h2><span id='topic+cut_data_by_event'></span>

<h3>Description</h3>

<p>Takes a time-to-event data set and cuts the data at which an
event count is reached.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cut_data_by_event(x, event)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cut_data_by_event_+3A_x">x</code></td>
<td>
<p>A time-to-event dataset, for example, generated by <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>.</p>
</td></tr>
<tr><td><code id="cut_data_by_event_+3A_event">event</code></td>
<td>
<p>Event count at which data cutoff is to be made.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame ready for survival analysis, including columns
time to event (<code>tte</code>), <code>event</code>, the <code>stratum</code>, and the <code>treatment</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use default enrollment and event rates at cut at 100 events
x &lt;- sim_pw_surv(n = 200) |&gt; cut_data_by_event(100)
table(x$event, x$treatment)
</code></pre>

<hr>
<h2 id='early_zero_weight'>Zero early weight for weighted logrank tests</h2><span id='topic+early_zero_weight'></span>

<h3>Description</h3>

<p>Zero early weight for weighted logrank tests
</p>


<h3>Usage</h3>

<pre><code class='language-R'>early_zero_weight(x, early_period = 4, fail_rate = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="early_zero_weight_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+counting_process">counting_process()</a></code>-class data frame with a counting process dataset.</p>
</td></tr>
<tr><td><code id="early_zero_weight_+3A_early_period">early_period</code></td>
<td>
<p>The initial delay period where weights increase;
after this, weights are constant at the final weight in the delay period.</p>
</td></tr>
<tr><td><code id="early_zero_weight_+3A_fail_rate">fail_rate</code></td>
<td>
<p>A data frame record the failure rate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame. The column <code>weight</code> contains the weights for the
early zero weighted logrank test for the data in <code>x</code>.
</p>


<h3>References</h3>

<p>Xu, Z., Zhen, B., Park, Y., &amp; Zhu, B. (2017).
&quot;Designing therapeutic cancer vaccine trials with delayed treatment effect.&quot;
<em>Statistics in Medicine</em>, 36(4), 592&ndash;605.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(gsDesign2)

# Example 1: Unstratified
sim_pw_surv(n = 200) |&gt;
  cut_data_by_event(125) |&gt;
  counting_process(arm = "experimental") |&gt;
  early_zero_weight(early_period = 2) |&gt;
  filter(row_number() %in% seq(5, 200, 40))

# Example 2: Stratified
n &lt;- 500
# Two strata
stratum &lt;- c("Biomarker-positive", "Biomarker-negative")
prevalence_ratio &lt;- c(0.6, 0.4)

# Enrollment rate
enroll_rate &lt;- define_enroll_rate(
  stratum = rep(stratum, each = 2),
  duration = c(2, 10, 2, 10),
  rate = c(c(1, 4) * prevalence_ratio[1], c(1, 4) * prevalence_ratio[2])
)
enroll_rate$rate &lt;- enroll_rate$rate * n / sum(enroll_rate$duration * enroll_rate$rate)

# Failure rate
med_pos &lt;- 10 # Median of the biomarker positive population
med_neg &lt;- 8 # Median of the biomarker negative population
hr_pos &lt;- c(1, 0.7) # Hazard ratio of the biomarker positive population
hr_neg &lt;- c(1, 0.8) # Hazard ratio of the biomarker negative population
fail_rate &lt;- define_fail_rate(
  stratum = rep(stratum, each = 2),
  duration = c(3, 1000, 4, 1000),
  fail_rate = c(log(2) / c(med_pos, med_pos, med_neg, med_neg)),
  hr = c(hr_pos, hr_neg),
  dropout_rate = 0.01
)

# Simulate data
temp &lt;- to_sim_pw_surv(fail_rate) # Convert the failure rate
set.seed(2023)

sim_pw_surv(
  n = n, # Sample size
  # Stratified design with prevalence ratio of 6:4
  stratum = tibble(stratum = stratum, p = prevalence_ratio),
  # Randomization ratio
  block = c("control", "control", "experimental", "experimental"),
  enroll_rate = enroll_rate, # Enrollment rate
  fail_rate = temp$fail_rate, # Failure rate
  dropout_rate = temp$dropout_rate # Dropout rate
) |&gt;
  cut_data_by_event(125) |&gt;
  counting_process(arm = "experimental") |&gt;
  early_zero_weight(early_period = 2, fail_rate = fail_rate) |&gt;
  filter(row_number() %in% seq(5, 200, 40))
</code></pre>

<hr>
<h2 id='ex1_delayed_effect'>Time-to-event data example 1 for non-proportional hazards working group</h2><span id='topic+ex1_delayed_effect'></span>

<h3>Description</h3>

<p>Survival objects reverse-engineered datasets from published Kaplan-Meier
curves.
Individual trials are de-identified since the data are only
approximations of the actual data.
Data are intended to evaluate methods and designs for trials where
non-proportional hazards may be anticipated for outcome data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ex1_delayed_effect)
</code></pre>


<h3>Format</h3>

<p>Data frame with 4 variables:
</p>

<ul>
<li> <p><code>id</code>: Sequential numbering of unique identifiers.
</p>
</li>
<li> <p><code>month</code>: Time-to-event.
</p>
</li>
<li> <p><code>event</code>: 1 for event, 0 for censored.
</p>
</li>
<li> <p><code>trt</code>: 1 for experimental, 0 for control.
</p>
</li></ul>



<h3>References</h3>

<p>Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu,
Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo,
Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang,
Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona &amp;
Cross-Pharma Non-proportional Hazards Working Group. 2020.
Alternative analysis methods for time to event endpoints under
nonproportional hazards: A comparative analysis.
<em>Statistics in Biopharmaceutical Research</em> 12(2): 187&ndash;198.
</p>


<h3>See Also</h3>

<p><a href="#topic+ex2_delayed_effect">ex2_delayed_effect</a>,
<a href="#topic+ex3_cure_with_ph">ex3_cure_with_ph</a>,
<a href="#topic+ex4_belly">ex4_belly</a>,
<a href="#topic+ex5_widening">ex5_widening</a>,
<a href="#topic+ex6_crossing">ex6_crossing</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)

data(ex1_delayed_effect)
km1 &lt;- with(ex1_delayed_effect, survfit(Surv(month, evntd) ~ trt))
km1
plot(km1)
with(subset(ex1_delayed_effect, trt == 1), survfit(Surv(month, evntd) ~ trt))
with(subset(ex1_delayed_effect, trt == 0), survfit(Surv(month, evntd) ~ trt))
</code></pre>

<hr>
<h2 id='ex2_delayed_effect'>Time-to-event data example 2 for non-proportional hazards working group</h2><span id='topic+ex2_delayed_effect'></span>

<h3>Description</h3>

<p>Survival objects reverse-engineered datasets from published Kaplan-Meier
curves.
Individual trials are de-identified since the data are only
approximations of the actual data.
Data are intended to evaluate methods and designs for trials where
non-proportional hazards may be anticipated for outcome data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ex2_delayed_effect)
</code></pre>


<h3>Format</h3>

<p>Data frame with 4 variables:
</p>

<ul>
<li> <p><code>id</code>: Sequential numbering of unique identifiers.
</p>
</li>
<li> <p><code>month</code>: Time-to-event.
</p>
</li>
<li> <p><code>event</code>: 1 for event, 0 for censored.
</p>
</li>
<li> <p><code>trt</code>: 1 for experimental, 0 for control.
</p>
</li></ul>



<h3>References</h3>

<p>Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu,
Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo,
Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang,
Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona &amp;
Cross-Pharma Non-proportional Hazards Working Group. 2020.
Alternative analysis methods for time to event endpoints under
nonproportional hazards: A comparative analysis.
<em>Statistics in Biopharmaceutical Research</em> 12(2): 187&ndash;198.
</p>


<h3>See Also</h3>

<p><a href="#topic+ex1_delayed_effect">ex1_delayed_effect</a>,
<a href="#topic+ex3_cure_with_ph">ex3_cure_with_ph</a>,
<a href="#topic+ex4_belly">ex4_belly</a>,
<a href="#topic+ex5_widening">ex5_widening</a>,
<a href="#topic+ex6_crossing">ex6_crossing</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)

data(ex2_delayed_effect)
km1 &lt;- with(ex2_delayed_effect, survfit(Surv(month, evntd) ~ trt))
km1
plot(km1)
with(subset(ex2_delayed_effect, trt == 1), survfit(Surv(month, evntd) ~ trt))
with(subset(ex2_delayed_effect, trt == 0), survfit(Surv(month, evntd) ~ trt))
</code></pre>

<hr>
<h2 id='ex3_cure_with_ph'>Time-to-event data example 3 for non-proportional hazards working group</h2><span id='topic+ex3_cure_with_ph'></span>

<h3>Description</h3>

<p>Survival objects reverse-engineered datasets from published Kaplan-Meier
curves.
Individual trials are de-identified since the data are only
approximations of the actual data.
Data are intended to evaluate methods and designs for trials where
non-proportional hazards may be anticipated for outcome data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ex3_cure_with_ph)
</code></pre>


<h3>Format</h3>

<p>Data frame with 4 variables:
</p>

<ul>
<li> <p><code>id</code>: Sequential numbering of unique identifiers.
</p>
</li>
<li> <p><code>month</code>: Time-to-event.
</p>
</li>
<li> <p><code>event</code>: 1 for event, 0 for censored.
</p>
</li>
<li> <p><code>trt</code>: 1 for experimental, 0 for control.
</p>
</li></ul>



<h3>References</h3>

<p>Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu,
Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo,
Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang,
Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona &amp;
Cross-Pharma Non-proportional Hazards Working Group. 2020.
Alternative analysis methods for time to event endpoints under
nonproportional hazards: A comparative analysis.
<em>Statistics in Biopharmaceutical Research</em> 12(2): 187&ndash;198.
</p>


<h3>See Also</h3>

<p><a href="#topic+ex1_delayed_effect">ex1_delayed_effect</a>,
<a href="#topic+ex2_delayed_effect">ex2_delayed_effect</a>,
<a href="#topic+ex4_belly">ex4_belly</a>,
<a href="#topic+ex5_widening">ex5_widening</a>,
<a href="#topic+ex6_crossing">ex6_crossing</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)

data(ex3_cure_with_ph)
km1 &lt;- with(ex3_cure_with_ph, survfit(Surv(month, evntd) ~ trt))
km1
plot(km1)
</code></pre>

<hr>
<h2 id='ex4_belly'>Time-to-event data example 4 for non-proportional hazards working group</h2><span id='topic+ex4_belly'></span>

<h3>Description</h3>

<p>Survival objects reverse-engineered datasets from published Kaplan-Meier
curves.
Individual trials are de-identified since the data are only
approximations of the actual data.
Data are intended to evaluate methods and designs for trials where
non-proportional hazards may be anticipated for outcome data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ex4_belly)
</code></pre>


<h3>Format</h3>

<p>Data frame with 4 variables:
</p>

<ul>
<li> <p><code>id</code>: Sequential numbering of unique identifiers.
</p>
</li>
<li> <p><code>month</code>: Time-to-event.
</p>
</li>
<li> <p><code>event</code>: 1 for event, 0 for censored.
</p>
</li>
<li> <p><code>trt</code>: 1 for experimental, 0 for control.
</p>
</li></ul>



<h3>References</h3>

<p>Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu,
Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo,
Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang,
Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona &amp;
Cross-Pharma Non-proportional Hazards Working Group. 2020.
Alternative analysis methods for time to event endpoints under
nonproportional hazards: A comparative analysis.
<em>Statistics in Biopharmaceutical Research</em> 12(2): 187&ndash;198.
</p>


<h3>See Also</h3>

<p><a href="#topic+ex1_delayed_effect">ex1_delayed_effect</a>,
<a href="#topic+ex2_delayed_effect">ex2_delayed_effect</a>,
<a href="#topic+ex3_cure_with_ph">ex3_cure_with_ph</a>,
<a href="#topic+ex5_widening">ex5_widening</a>,
<a href="#topic+ex6_crossing">ex6_crossing</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)

data(ex4_belly)
km1 &lt;- with(ex4_belly, survfit(Surv(month, evntd) ~ trt))
km1
plot(km1)
</code></pre>

<hr>
<h2 id='ex5_widening'>Time-to-event data example 5 for non-proportional hazards working group</h2><span id='topic+ex5_widening'></span>

<h3>Description</h3>

<p>Survival objects reverse-engineered datasets from published Kaplan-Meier
curves.
Individual trials are de-identified since the data are only
approximations of the actual data.
Data are intended to evaluate methods and designs for trials where
non-proportional hazards may be anticipated for outcome data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ex5_widening)
</code></pre>


<h3>Format</h3>

<p>Data frame with 4 variables:
</p>

<ul>
<li> <p><code>id</code>: Sequential numbering of unique identifiers.
</p>
</li>
<li> <p><code>month</code>: Time-to-event.
</p>
</li>
<li> <p><code>event</code>: 1 for event, 0 for censored.
</p>
</li>
<li> <p><code>trt</code>: 1 for experimental, 0 for control.
</p>
</li></ul>



<h3>References</h3>

<p>Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu,
Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo,
Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang,
Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona &amp;
Cross-Pharma Non-proportional Hazards Working Group. 2020.
Alternative analysis methods for time to event endpoints under
nonproportional hazards: A comparative analysis.
<em>Statistics in Biopharmaceutical Research</em> 12(2): 187&ndash;198.
</p>


<h3>See Also</h3>

<p><a href="#topic+ex1_delayed_effect">ex1_delayed_effect</a>,
<a href="#topic+ex2_delayed_effect">ex2_delayed_effect</a>,
<a href="#topic+ex3_cure_with_ph">ex3_cure_with_ph</a>,
<a href="#topic+ex4_belly">ex4_belly</a>,
<a href="#topic+ex6_crossing">ex6_crossing</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)

data(ex5_widening)
km1 &lt;- with(ex5_widening, survfit(Surv(month, evntd) ~ trt))
km1
plot(km1)
</code></pre>

<hr>
<h2 id='ex6_crossing'>Time-to-event data example 6 for non-proportional hazards working group</h2><span id='topic+ex6_crossing'></span>

<h3>Description</h3>

<p>Survival objects reverse-engineered datasets from published Kaplan-Meier
curves.
Individual trials are de-identified since the data are only
approximations of the actual data.
Data are intended to evaluate methods and designs for trials where
non-proportional hazards may be anticipated for outcome data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ex6_crossing)
</code></pre>


<h3>Format</h3>

<p>Data frame with 4 variables:
</p>

<ul>
<li> <p><code>id</code>: Sequential numbering of unique identifiers.
</p>
</li>
<li> <p><code>month</code>: Time-to-event.
</p>
</li>
<li> <p><code>event</code>: 1 for event, 0 for censored.
</p>
</li>
<li> <p><code>trt</code>: 1 for experimental, 0 for control.
</p>
</li></ul>



<h3>References</h3>

<p>Lin, Ray S., Ji Lin, Satrajit Roychoudhury, Keaven M. Anderson, Tianle Hu,
Bo Huang, Larry F Leon, Jason J.Z. Liao, Rong Liu, Xiaodong Luo,
Pralay Mukhopadhyay, Rui Qin, Kay Tatsuoka, Xuejing Wang,
Yang Wang, Jian Zhu, Tai-Tsang Chen, Renee Iacona &amp;
Cross-Pharma Non-proportional Hazards Working Group. 2020.
Alternative analysis methods for time to event endpoints under
nonproportional hazards: A comparative analysis.
<em>Statistics in Biopharmaceutical Research</em> 12(2): 187&ndash;198.
</p>


<h3>See Also</h3>

<p><a href="#topic+ex1_delayed_effect">ex1_delayed_effect</a>,
<a href="#topic+ex2_delayed_effect">ex2_delayed_effect</a>,
<a href="#topic+ex3_cure_with_ph">ex3_cure_with_ph</a>,
<a href="#topic+ex4_belly">ex4_belly</a>,
<a href="#topic+ex5_widening">ex5_widening</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)

data(ex6_crossing)
km1 &lt;- with(ex6_crossing, survfit(Surv(month, evntd) ~ trt))
km1
plot(km1)
</code></pre>

<hr>
<h2 id='fh_weight'>Fleming-Harrington weighted logrank tests</h2><span id='topic+fh_weight'></span>

<h3>Description</h3>

<p>With output from the function <code><a href="#topic+counting_process">counting_process()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fh_weight(
  x = counting_process(cut_data_by_event(sim_pw_surv(n = 200), 150), arm =
    "experimental"),
  rho_gamma = data.frame(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1)),
  return_variance = FALSE,
  return_corr = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fh_weight_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+counting_process">counting_process()</a></code>-class data frame with a counting process
dataset.</p>
</td></tr>
<tr><td><code id="fh_weight_+3A_rho_gamma">rho_gamma</code></td>
<td>
<p>A data frame with variables <code>rho</code> and <code>gamma</code>, both greater
than equal to zero, to specify one Fleming-Harrington weighted logrank test
per row; Default: <code>data.frame(rho = c(0, 0, 1, 1), gamma = c(0, 1, 0, 1))</code>.</p>
</td></tr>
<tr><td><code id="fh_weight_+3A_return_variance">return_variance</code></td>
<td>
<p>A logical flag that, if <code>TRUE</code>, adds columns
estimated variance for weighted sum of observed minus expected;
see details; Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fh_weight_+3A_return_corr">return_corr</code></td>
<td>
<p>A logical flag that, if <code>TRUE</code>, adds columns
estimated correlation for weighted sum of observed minus expected;
see details; Default: <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input value <code>x</code> produced by <code><a href="#topic+counting_process">counting_process()</a></code> produces a
counting process dataset grouped by stratum and sorted within stratum
by increasing times where events occur.
</p>

<ul>
<li> <p><code class="reqn">z</code> - Standardized normal Fleming-Harrington weighted logrank test.
</p>
</li>
<li> <p><code class="reqn">i</code> - Stratum index.
</p>
</li>
<li> <p><code class="reqn">d_i</code> - Number of distinct times at which events occurred in
stratum <code class="reqn">i</code>.
</p>
</li>
<li> <p><code class="reqn">t_{ij}</code> - Ordered times at which events in stratum
<code class="reqn">i</code>, <code class="reqn">j = 1, 2, \ldots, d_i</code> were observed;
for each observation, <code class="reqn">t_{ij}</code> represents the time post study entry.
</p>
</li>
<li> <p><code class="reqn">O_{ij.}</code> - Total number of events in stratum <code class="reqn">i</code> that occurred
at time <code class="reqn">t_{ij}</code>.
</p>
</li>
<li> <p><code class="reqn">O_{ije}</code> - Total number of events in stratum <code class="reqn">i</code> in the
experimental treatment group that occurred at time <code class="reqn">t_{ij}</code>.
</p>
</li>
<li> <p><code class="reqn">N_{ij.}</code> - Total number of study subjects in stratum <code class="reqn">i</code>
who were followed for at least duration.
</p>
</li>
<li> <p><code class="reqn">E_{ije}</code> - Expected observations in experimental treatment group
given random selection of <code class="reqn">O_{ij.}</code> from those in
stratum <code class="reqn">i</code> at risk at time <code class="reqn">t_{ij}</code>.
</p>
</li>
<li> <p><code class="reqn">V_{ije}</code> - Hypergeometric variance for <code class="reqn">E_{ije}</code> as
produced in <code>Var</code> from <code><a href="#topic+counting_process">counting_process()</a></code>.
</p>
</li>
<li> <p><code class="reqn">N_{ije}</code> - Total number of study subjects in
stratum <code class="reqn">i</code> in the experimental treatment group
who were followed for at least duration <code class="reqn">t_{ij}</code>.
</p>
</li>
<li> <p><code class="reqn">E_{ije}</code> - Expected observations in experimental group in
stratum <code class="reqn">i</code> at time <code class="reqn">t_{ij}</code> conditioning on the overall number
of events and at risk populations at that time and sampling at risk
observations without replacement:
</p>
<p style="text-align: center;"><code class="reqn">E_{ije} = O_{ij.} N_{ije}/N_{ij.}</code>
</p>

</li>
<li> <p><code class="reqn">S_{ij}</code> - Kaplan-Meier estimate of survival in combined
treatment groups immediately prior to time <code class="reqn">t_{ij}</code>.
</p>
</li>
<li> <p><code class="reqn">\rho, \gamma</code> - Real parameters for Fleming-Harrington test.
</p>
</li>
<li> <p><code class="reqn">X_i</code> - Numerator for signed logrank test in stratum <code class="reqn">i</code>
</p>
<p style="text-align: center;"><code class="reqn">X_i = \sum_{j=1}^{d_{i}} S_{ij}^\rho(1-S_{ij}^\gamma)(O_{ije}-E_{ije})</code>
</p>

</li>
<li> <p><code class="reqn">V_{ij}</code> - Variance used in denominator for Fleming-Harrington
weighted logrank tests
</p>
<p style="text-align: center;"><code class="reqn">V_i = \sum_{j=1}^{d_{i}} (S_{ij}^\rho(1-S_{ij}^\gamma))^2V_{ij})</code>
</p>

<p>The stratified Fleming-Harrington weighted logrank test is then computed as:
</p>
<p style="text-align: center;"><code class="reqn">z = \sum_i X_i/\sqrt{\sum_i V_i}.</code>
</p>

</li></ul>



<h3>Value</h3>

<p>A data frame with <code>rho_gamma</code> as input and the FH test statistic
for the data in <code>x</code>. (<code>z</code>, a directional square root of the usual
weighted logrank test); if variance calculations are specified
(for example, to be used for covariances in a combination test),
then this will be returned in the column <code>Var</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)

# Example 1
# Use default enrollment and event rates at cut at 100 events
x &lt;- sim_pw_surv(n = 200) |&gt;
  cut_data_by_event(100) |&gt;
  counting_process(arm = "experimental")

# Compute logrank FH(0, 1)
fh_weight(x, rho_gamma = data.frame(rho = 0, gamma = 1))
fh_weight(x, rho_gamma = data.frame(rho = 0, gamma = 1), return_variance = TRUE)

# Compute the corvariance between FH(0, 0), FH(0, 1) and FH(1, 0)
fh_weight(x, rho_gamma = data.frame(rho = c(0, 0, 1), gamma = c(0, 1, 0)))
fh_weight(x, rho_gamma = data.frame(rho = c(0, 0, 1), gamma = c(0, 1, 0)), return_variance = TRUE)
fh_weight(x, rho_gamma = data.frame(rho = c(0, 0, 1), gamma = c(0, 1, 0)), return_corr = TRUE)

# Example 2
# Use default enrollment and event rates at cut of 100 events
set.seed(123)
x &lt;- sim_pw_surv(n = 200) |&gt;
  cut_data_by_event(100) |&gt;
  counting_process(arm = "experimental") |&gt;
  fh_weight(rho_gamma = data.frame(rho = c(0, 0), gamma = c(0, 1)), return_corr = TRUE)

# Compute p-value for MaxCombo
library(mvtnorm)
1 - pmvnorm(
  lower = rep(min(x$z), nrow(x)),
  corr = data.matrix(select(x, -c(rho, gamma, z))),
  algorithm = GenzBretz(maxpts = 50000, abseps = 0.00001)
)[1]

# Check that covariance is as expected
x &lt;- sim_pw_surv(n = 200) |&gt;
  cut_data_by_event(100) |&gt;
  counting_process(arm = "experimental")

x |&gt; fh_weight(
  rho_gamma = data.frame(
    rho = c(0, 0),
    gamma = c(0, 1)
  ),
  return_variance = TRUE
)

# Off-diagonal element should be variance in following
x |&gt; fh_weight(
  rho_gamma = data.frame(
    rho = 0,
    gamma = .5
  ),
  return_variance = TRUE
)

# Compare off diagonal result with fh_weight()
x |&gt; fh_weight(rho_gamma = data.frame(rho = 0, gamma = .5))
</code></pre>

<hr>
<h2 id='fit_pwexp'>Piecewise exponential survival estimation</h2><span id='topic+fit_pwexp'></span>

<h3>Description</h3>

<p>Computes survival function, density function, -2 * log-likelihood based
on input dataset and intervals for piecewise constant failure rates.
Initial version assumes observations are right censored or events only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_pwexp(
  srv = Surv(time = ex1_delayed_effect$month, event = ex1_delayed_effect$evntd),
  intervals = array(3, 3)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_pwexp_+3A_srv">srv</code></td>
<td>
<p>Input survival object (see <code><a href="survival.html#topic+Surv">survival::Surv()</a></code>);
note that only 0 = censored, 1 = event for <code><a href="survival.html#topic+Surv">survival::Surv()</a></code>.</p>
</td></tr>
<tr><td><code id="fit_pwexp_+3A_intervals">intervals</code></td>
<td>
<p>Vector containing positive values indicating
interval lengths where the exponential rates are assumed.
Note that a final infinite interval is added if any events occur
after the final interval specified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with rows containing interval length, estimated rate,
-2 * log-likelihood for each interval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use default arguments for delayed effect example dataset (ex1_delayed_effect)
library(survival)

# Example 1
rateall &lt;- fit_pwexp()
rateall

# Example 2
# Estimate by treatment effect
rate1 &lt;- with(subset(ex1_delayed_effect, trt == 1), fit_pwexp(Surv(month, evntd)))
rate0 &lt;- with(subset(ex1_delayed_effect, trt == 0), fit_pwexp(Surv(month, evntd)))

rate1
rate0
rate1$rate / rate0$rate

# Chi-square test for (any) treatment effect (8 - 4 parameters = 4 df)
pchisq(sum(rateall$m2ll) - sum(rate1$m2ll + rate0$m2ll),
  df = 4,
  lower.tail = FALSE
)

# Compare with logrank
survdiff(formula = Surv(month, evntd) ~ trt, data = ex1_delayed_effect)

# Example 3
# Simple model with 3 rates same for each for 3 months,
# different for each treatment after months
rate1a &lt;- with(subset(ex1_delayed_effect, trt == 1), fit_pwexp(Surv(month, evntd), 3))
rate0a &lt;- with(subset(ex1_delayed_effect, trt == 0), fit_pwexp(Surv(month, evntd), 3))
rate1a$rate / rate0a$rate

m2ll0 &lt;- rateall$m2ll[1] + rate1a$m2ll[2] + rate0a$m2ll[2]
m2ll1 &lt;- sum(rate0$m2ll) + sum(rate1$m2ll)

# As a measure of strength, chi-square examines improvement in likelihood
pchisq(m2ll0 - m2ll1, df = 5, lower.tail = FALSE)
</code></pre>

<hr>
<h2 id='get_analysis_date'>Get the analysis date under multiple conditions</h2><span id='topic+get_analysis_date'></span>

<h3>Description</h3>

<p>Get the analysis date under multiple conditions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_analysis_date(
  data,
  planned_calendar_time = NA,
  target_event_overall = NA,
  target_event_per_stratum = NA,
  max_extension_for_target_event = NA,
  previous_analysis_date = 0,
  min_time_after_previous_analysis = NA,
  min_n_overall = NA,
  min_n_per_stratum = NA,
  min_followup = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_analysis_date_+3A_data">data</code></td>
<td>
<p>A simulated data generated by <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_planned_calendar_time">planned_calendar_time</code></td>
<td>
<p>A numerical value specifying the
planned calendar time for the analysis.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_target_event_overall">target_event_overall</code></td>
<td>
<p>A numerical value specifying the
targeted events for the overall population.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_target_event_per_stratum">target_event_per_stratum</code></td>
<td>
<p>A numerical vector specifying the
targeted events per stratum.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_max_extension_for_target_event">max_extension_for_target_event</code></td>
<td>
<p>A numerical value specifying the
maximum time extension to reach targeted events.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_previous_analysis_date">previous_analysis_date</code></td>
<td>
<p>A numerical value specifying the
previous analysis date.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_min_time_after_previous_analysis">min_time_after_previous_analysis</code></td>
<td>
<p>A numerical value specifying the
planned minimum time after the previous analysis.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_min_n_overall">min_n_overall</code></td>
<td>
<p>A numerical value specifying the
minimal overall sample size enrolled to kick off the analysis.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_min_n_per_stratum">min_n_per_stratum</code></td>
<td>
<p>A numerical value specifying the
minimal sample size enrolled per stratum to kick off the analysis.</p>
</td></tr>
<tr><td><code id="get_analysis_date_+3A_min_followup">min_followup</code></td>
<td>
<p>A numerical value specifying the
minimal follow-up time after specified enrollment fraction in
<code>min_n_overall</code> or <code>min_n_per_stratum</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numerical value of the analysis date.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(gsDesign2)
library(simtrial)

alpha &lt;- 0.025
ratio &lt;- 3
n &lt;- 500
info_frac &lt;- c(0.7, 1)
prevalence_ratio &lt;- c(0.4, 0.6)
study_duration &lt;- 48

# Two strata
stratum &lt;- c("Biomarker-positive", "Biomarker-negative")

prevalence_ratio &lt;- c(0.6, 0.4)
# enrollment rate
enroll_rate &lt;- define_enroll_rate(
  stratum = rep(stratum, each = 2),
  duration = c(2, 10, 2, 10),
  rate = c(c(1, 4) * prevalence_ratio[1], c(1, 4) * prevalence_ratio[2])
)
enroll_rate$rate &lt;- enroll_rate$rate * n / sum(enroll_rate$duration * enroll_rate$rate)

# Failure rate
med_pos &lt;- 10 # Median of the biomarker positive population
med_neg &lt;- 8 # Median of the biomarker negative population
hr_pos &lt;- c(1, 0.7) # Hazard ratio of the biomarker positive population
hr_neg &lt;- c(1, 0.8) # Hazard ratio of the biomarker negative population
fail_rate &lt;- define_fail_rate(
  stratum = rep(stratum, each = 2),
  duration = 1000,
  fail_rate = c(log(2) / c(med_pos, med_pos, med_neg, med_neg)),
  hr = c(hr_pos, hr_neg),
  dropout_rate = 0.01
)

# Simulate data
temp &lt;- to_sim_pw_surv(fail_rate) # Convert the failure rate
set.seed(2023)
simulated_data &lt;- sim_pw_surv(
  n = n, # Sample size
  # Stratified design with prevalence ratio of 6:4
  stratum = data.frame(stratum = stratum, p = prevalence_ratio),
  # Randomization ratio
  block = c("control", "control", "experimental", "experimental"),
  enroll_rate = enroll_rate, # Enrollment rate
  fail_rate = temp$fail_rate, # Failure rate
  dropout_rate = temp$dropout_rate # Dropout rate
)

# Example 1: Cut for analysis at the 24th month.
get_analysis_date(
  simulated_data,
  planned_calendar_time = 24
)

# Example 2: Cut for analysis when there are 300 events in the overall population.
get_analysis_date(
  simulated_data,
  target_event_overall = 300
)

# Example 3: Cut for analysis at the 24th month and there are 300 events
# in the overall population, whichever arrives later.
get_analysis_date(
  simulated_data,
  planned_calendar_time = 24,
  target_event_overall = 300
)

# Example 4a: Cut for analysis when there are at least 100 events
# in the biomarker-positive population, and at least 200 events
# in the biomarker-negative population, whichever arrives later.
get_analysis_date(
  simulated_data,
  target_event_per_stratum = c(100, 200)
)
# Example 4b: Cut for analysis when there are at least 100 events
# in the biomarker-positive population, but we don't have a requirement
# for the biomarker-negative population.
get_analysis_date(
  simulated_data,
  target_event_overall = 150,
  target_event_per_stratum = c(100, NA)
)

# Example 5: Cut for analysis when there are at least 100 events
# in the biomarker positive population, and at least 200 events
# in the biomarker negative population, whichever arrives later.
# But will stop at the 30th month if events are fewer than 100/200.
get_analysis_date(
  simulated_data,
  target_event_per_stratum = c(100, 200),
  max_extension_for_target_event = 30
)

# Example 6: Cut for analysis after 12 months followup when 80%
# of the patients are enrolled in the overall population.
get_analysis_date(
  simulated_data,
  min_n_overall = n * 0.8,
  min_followup = 12
)

# Example 7a: Cut for analysis when 12 months after at least 200/160 patients
# are enrolled in the biomarker positive/negative population.
get_analysis_date(
  simulated_data,
  min_n_per_stratum = c(200, 160),
  min_followup = 12
)
# Example 7b: Cut for analysis when 12 months after at least 200 patients
# are enrolled in the biomarker positive population, but we don't have a
# specific requirement for the biomarker negative population.
get_analysis_date(
  simulated_data,
  min_n_per_stratum = c(200, NA),
  min_followup = 12
)
# Example 7c: Cut for analysis when 12 months after at least 200 patients
# are enrolled in the biomarker-positive population, but we don't have a
# specific requirement for the biomarker-negative population. We also want
# there are at least 80% of the patients enrolled in the overall population.
get_analysis_date(
  simulated_data,
  min_n_overall = n * 0.8,
  min_n_per_stratum = c(200, NA),
  min_followup = 12
)
</code></pre>

<hr>
<h2 id='get_cut_date_by_event'>Get date at which an event count is reached</h2><span id='topic+get_cut_date_by_event'></span>

<h3>Description</h3>

<p>Get date at which an event count is reached
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_cut_date_by_event(x, event)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_cut_date_by_event_+3A_x">x</code></td>
<td>
<p>A time-to-event dataset, for example, generated by <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>.</p>
</td></tr>
<tr><td><code id="get_cut_date_by_event_+3A_event">event</code></td>
<td>
<p>Event count at which dataset is to be cut off for analysis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value with the <code>cte</code> from the input dataset
at which the targeted event count is reached, or if the final event count
is never reached, the final <code>cte</code> at which an event occurs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)

# Use default enrollment and calendar cut date
# for 50 events in the "Positive" stratum
x &lt;- sim_pw_surv(
  n = 200,
  stratum = data.frame(
    stratum = c("Positive", "Negative"),
    p = c(.5, .5)
  ),
  fail_rate = data.frame(
    stratum = rep(c("Positive", "Negative"), 2),
    period = rep(1, 4),
    treatment = c(rep("control", 2), rep("experimental", 2)),
    duration = rep(1, 4),
    rate = log(2) / c(6, 9, 9, 12)
  ),
  dropout_rate = data.frame(
    stratum = rep(c("Positive", "Negative"), 2),
    period = rep(1, 4),
    treatment = c(rep("control", 2), rep("experimental", 2)),
    duration = rep(1, 4),
    rate = rep(.001, 4)
  )
)

d &lt;- get_cut_date_by_event(x |&gt; filter(stratum == "Positive"), event = 50)

y &lt;- cut_data_by_date(x, cut_date = d)
table(y$stratum, y$event)
</code></pre>

<hr>
<h2 id='mb_delayed_effect'>Simulated survival dataset with delayed treatment effect</h2><span id='topic+mb_delayed_effect'></span>

<h3>Description</h3>

<p>Magirr and Burman (2019) considered several scenarios for their
modestly weighted logrank test.
One of these had a delayed treatment effect with a hazard ratio
of 1 for 6 months followed by a hazard ratio of 1/2 thereafter.
The scenario enrolled 200 patients uniformly over 12 months and
cut data for analysis 36 months after enrollment was opened.
This dataset was generated by the <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code> function
under the above scenario.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mb_delayed_effect
</code></pre>


<h3>Format</h3>

<p>A data frame with 200 rows and 4 columns:
</p>

<ul>
<li> <p><code>tte</code>: Time to event.
</p>
</li></ul>



<h3>References</h3>

<p>Magirr, Dominic, and Carl‐Fredrik Burman. 2019.
&quot;Modestly weighted logrank tests.&quot;
<em>Statistics in Medicine</em> 38 (20): 3782&ndash;3790.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
library(dplyr)

fit &lt;- survfit(Surv(tte, event) ~ treatment, data = mb_delayed_effect)

# Plot survival
plot(fit, lty = 1:2)
legend("topright", legend = c("control", "experimental"), lty = 1:2)

# Set up time, event, number of event dataset for testing
# with arbitrary weights
ten &lt;- mb_delayed_effect |&gt; counting_process(arm = "experimental")
head(ten)

# MaxCombo with logrank, FH(0,1), FH(1,1)
ten |&gt;
  fh_weight(rho_gamma = data.frame(rho = c(0, 0, 1), gamma = c(0, 1, 1)), return_corr = TRUE) |&gt;
  pvalue_maxcombo()

# Magirr-Burman modestly down-weighted rank test with 6 month delay
# First, add weights
ten &lt;- ten |&gt; mb_weight(6)
head(ten)

# Now compute test based on these weights
ten |&gt;
  summarize(
    S = sum(o_minus_e * mb_weight),
    V = sum(var_o_minus_e * mb_weight^2),
    Z = S / sqrt(V)
  ) |&gt;
  mutate(p = pnorm(Z))

# Create 0 weights for first 6 months
ten &lt;- ten |&gt; mutate(w6 = 1 * (tte &gt;= 6))
ten |&gt;
  summarize(
    S = sum(o_minus_e * w6),
    V = sum(var_o_minus_e * w6^2),
    Z = S / sqrt(V)
  ) |&gt;
  mutate(p = pnorm(Z))

# Generate another dataset
ds &lt;- sim_pw_surv(
  n = 200,
  enroll_rate = data.frame(rate = 200 / 12, duration = 12),
  fail_rate = data.frame(
    stratum = c("All", "All", "All"),
    period = c(1, 1, 2),
    treatment = c("control", "experimental", "experimental"),
    duration = c(42, 6, 36),
    rate = c(log(2) / 15, log(2) / 15, log(2) / 15 * 0.6)
  ),
  dropout_rate = data.frame(
    stratum = c("All", "All"),
    period = c(1, 1),
    treatment = c("control", "experimental"),
    duration = c(42, 42),
    rate = c(0, 0)
  )
)
# Cut data at 24 months after final enrollment
mb_delayed_effect_2 &lt;- ds |&gt; cut_data_by_date(max(ds$enroll_time) + 24)
</code></pre>

<hr>
<h2 id='mb_weight'>Magirr and Burman modestly weighted logrank tests</h2><span id='topic+mb_weight'></span>

<h3>Description</h3>

<p>Computes Magirr-Burman weights and adds them to a dataset created by
<code><a href="#topic+counting_process">counting_process()</a></code>.
These weights can then be used to compute a z-statistic for the
modestly weighted logrank test proposed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mb_weight(x, delay = 4, w_max = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mb_weight_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+counting_process">counting_process()</a></code>-class data frame with a counting process
dataset.</p>
</td></tr>
<tr><td><code id="mb_weight_+3A_delay">delay</code></td>
<td>
<p>The initial delay period where weights increase;
after this, weights are constant at the final weight in the delay period.</p>
</td></tr>
<tr><td><code id="mb_weight_+3A_w_max">w_max</code></td>
<td>
<p>Maximum weight to be returned.
Set <code>delay = Inf</code>, <code>w_max = 2</code> to be consistent with recommendation of
Magirr (2021).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Magirr and Burman (2019) proposed a weighted logrank test to have better
power than the logrank test when the treatment effect is delayed,
but to still maintain good power under a proportional hazards assumption.
In Magirr (2021), (the equivalent of) a maximum weight was proposed
as opposed to a fixed time duration over which weights would increase.
The weights for some early interval specified by the user are the inverse
of the combined treatment group empirical survival distribution; see details.
After this initial period, weights are constant at the maximum of the
previous weights. Another advantage of the test is that under strong
null hypothesis that the underlying survival in the control group is
greater than or equal to underlying survival in the experimental group,
Type I error is controlled as the specified level.
</p>
<p>We define <code class="reqn">t^*</code> to be the input variable <code>delay</code>.
This specifies an initial period during which weights increase.
We also set a maximum weight <code class="reqn">w_{\max}</code>.
To define specific weights, we let <code class="reqn">S(t)</code> denote the Kaplan-Meier
survival estimate at time <code class="reqn">t</code> for the combined data
(control plus experimental treatment groups).
The weight at time <code class="reqn">t</code> is then defined as
</p>
<p style="text-align: center;"><code class="reqn">w(t)=\min(w_{\max}, S(\min(t, t^*))^{-1}).</code>
</p>



<h3>Value</h3>

<p>A data frame. The column <code>mb_weight</code> contains the weights for the
Magirr-Burman weighted logrank test for the data in <code>x</code>.
</p>


<h3>References</h3>

<p>Magirr, Dominic, and Carl‐Fredrik Burman. 2019.
&quot;Modestly weighted logrank tests.&quot;
<em>Statistics in Medicine</em> 38 (20): 3782&ndash;3790.
</p>
<p>Magirr, Dominic. 2021.
&quot;Non‐proportional hazards in immuno‐oncology: Is an old perspective needed?&quot;
<em>Pharmaceutical Statistics</em> 20 (3): 512&ndash;527.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)

# Use default enrollment and event rates at cut at 100 events
# For transparency, may be good to set either `delay` or `w_max` to `Inf`
x &lt;- sim_pw_surv(n = 200) |&gt;
  cut_data_by_event(125) |&gt;
  counting_process(arm = "experimental")

# Example 1
# Compute Magirr-Burman weights with `delay = 6`
ZMB &lt;- x |&gt;
  mb_weight(delay = 6, w_max = Inf) |&gt;
  summarize(
    S = sum(o_minus_e * mb_weight),
    V = sum(var_o_minus_e * mb_weight^2),
    z = S / sqrt(V)
  )

# Compute p-value of modestly weighted logrank of Magirr-Burman
pnorm(ZMB$z)

# Example 2
# Now compute with maximum weight of 2 as recommended in Magirr, 2021
ZMB2 &lt;- x |&gt;
  mb_weight(delay = Inf, w_max = 2) |&gt;
  summarize(
    S = sum(o_minus_e * mb_weight),
    V = sum(var_o_minus_e * mb_weight^2),
    z = S / sqrt(V)
  )

# Compute p-value of modestly weighted logrank of Magirr-Burman
pnorm(ZMB2$z)
</code></pre>

<hr>
<h2 id='pvalue_maxcombo'>MaxCombo p-value</h2><span id='topic+pvalue_maxcombo'></span>

<h3>Description</h3>

<p>Computes p-values for the MaxCombo test based on output from <code><a href="#topic+fh_weight">fh_weight()</a></code>.
This is still in an experimental stage and is intended for use with
the <code><a href="#topic+sim_fixed_n">sim_fixed_n()</a></code> trial simulation routine.
However, it can also be used to analyze clinical trial data such as
that provided in the ADaM ADTTE format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvalue_maxcombo(
  z,
  algorithm = mvtnorm::GenzBretz(maxpts = 50000, abseps = 1e-05)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvalue_maxcombo_+3A_z">z</code></td>
<td>
<p>A dataset output from <code><a href="#topic+fh_weight">fh_weight()</a></code>; see examples.</p>
</td></tr>
<tr><td><code id="pvalue_maxcombo_+3A_algorithm">algorithm</code></td>
<td>
<p>This is passed directly to the <code>algorithm</code> argument
in <code><a href="mvtnorm.html#topic+pmvnorm">mvtnorm::pmvnorm()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric p-value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)

# Example 1
x &lt;- sim_fixed_n(
  n_sim = 1,
  timing_type = 5,
  rho_gamma = data.frame(
    rho = c(0, 0, 1),
    gamma = c(0, 1, 1)
  )
)
head(x)
pvalue_maxcombo(x)

# Example 2
# Only use cuts for events, events + min follow-up
xx &lt;- sim_fixed_n(
  n_sim = 100,
  timing_type = 5,
  rho_gamma = data.frame(
    rho = c(0, 0, 1),
    gamma = c(0, 1, 1)
  )
)
head(xx)

# MaxCombo power estimate for cutoff at max of targeted events, minimum follow-up
p &lt;- xx |&gt;
  group_by(sim) |&gt;
  group_map(~ pvalue_maxcombo(.x)) |&gt;
  unlist()
mean(p &lt; .025)
</code></pre>

<hr>
<h2 id='randomize_by_fixed_block'>Permuted fixed block randomization</h2><span id='topic+randomize_by_fixed_block'></span>

<h3>Description</h3>

<p>Fixed block randomization. The <code>block</code> input should repeat each
treatment code the number of times it is to be included within each block.
The final block will be a partial block if <code>n</code> is not an exact multiple
of the block length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomize_by_fixed_block(n = 10, block = c(0, 0, 1, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randomize_by_fixed_block_+3A_n">n</code></td>
<td>
<p>Sample size to be randomized.</p>
</td></tr>
<tr><td><code id="randomize_by_fixed_block_+3A_block">block</code></td>
<td>
<p>Vector of treatments to be included in each block.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A treatment group sequence (vector) of length <code>n</code> with
treatments from <code>block</code> permuted within each block having
block size equal to the length of <code>block</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)

# Example 1
# 2:1 randomization with block size 3, treatments "A" and "B"
data.frame(x = 1:10) |&gt; mutate(Treatment = randomize_by_fixed_block(block = c("A", "B", "B")))

# Example 2
# Stratified randomization
data.frame(stratum = c(rep("A", 10), rep("B", 10))) |&gt;
  group_by(stratum) |&gt;
  mutate(Treatment = randomize_by_fixed_block())
</code></pre>

<hr>
<h2 id='rpwexp'>The piecewise exponential distribution</h2><span id='topic+rpwexp'></span>

<h3>Description</h3>

<p>The piecewise exponential distribution allows a simple method to specify
a distribution where the hazard rate changes over time.
It is likely to be useful for conditions where failure rates change,
but also for simulations where there may be a delayed treatment effect
or a treatment effect that that is otherwise changing
(for example, decreasing) over time.
<code>rpwexp()</code> is to support simulation of both the Lachin and Foulkes (1986)
sample size method for (fixed trial duration) as well as the
Kim and Tsiatis (1990) method (fixed enrollment rates and either
fixed enrollment duration or fixed minimum follow-up);
see <code><a href="gsDesign.html#topic+nSurv">gsDesign::nSurv()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpwexp(n = 100, fail_rate = data.frame(duration = c(1, 1), rate = c(10, 20)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpwexp_+3A_n">n</code></td>
<td>
<p>Number of observations to be generated.</p>
</td></tr>
<tr><td><code id="rpwexp_+3A_fail_rate">fail_rate</code></td>
<td>
<p>A data frame containing <code>duration</code> and <code>rate</code> variables.
<code>rate</code> specifies failure rates during the corresponding interval duration
specified in <code>duration</code>. The final interval is extended to be infinite
to ensure all observations are generated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the <code>cumulative = TRUE</code> option, enrollment times that piecewise
constant over time can be generated.
</p>


<h3>Value</h3>

<p>The generated random numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
# Exponential failure times
x &lt;- rpwexp(
  n = 10000,
  fail_rate = data.frame(rate = 5, duration = 1)
)
plot(sort(x), (10000:1) / 10001,
  log = "y", main = "Exponential simulated survival curve",
  xlab = "Time", ylab = "P{Survival}"
)

# Example 2

# Get 10k piecewise exponential failure times.
# Failure rates are 1 for time 0 to 0.5, 3 for time 0.5 to 1, and 10 for &gt; 1.
# Intervals specifies duration of each failure rate interval
# with the final interval running to infinity.
x &lt;- rpwexp(
  n = 1e4,
  fail_rate = data.frame(rate = c(1, 3, 10), duration = c(.5, .5, 1))
)
plot(sort(x), (1e4:1) / 10001,
  log = "y", main = "PW Exponential simulated survival curve",
  xlab = "Time", ylab = "P{Survival}"
)
</code></pre>

<hr>
<h2 id='rpwexp_enroll'>Generate piecewise exponential enrollment</h2><span id='topic+rpwexp_enroll'></span>

<h3>Description</h3>

<p>With piecewise exponential enrollment rate generation any enrollment rate
distribution can be easily approximated.
<code>rpwexp_enroll()</code> is to support simulation of both the Lachin and Foulkes (1986)
sample size method for (fixed trial duration) as well as the
Kim and Tsiatis(1990) method (fixed enrollment rates and either
fixed enrollment duration or fixed minimum follow-up);
see <code><a href="gsDesign.html#topic+nSurv">gsDesign::nSurv()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpwexp_enroll(
  n = NULL,
  enroll_rate = data.frame(duration = c(1, 2), rate = c(2, 5))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpwexp_enroll_+3A_n">n</code></td>
<td>
<p>Number of observations.
Default of <code>NULL</code> yields random enrollment size.</p>
</td></tr>
<tr><td><code id="rpwexp_enroll_+3A_enroll_rate">enroll_rate</code></td>
<td>
<p>A data frame containing period duration (<code>duration</code>)
and enrollment rate (<code>rate</code>). for specified enrollment periods.
If necessary, last period will be extended to ensure enrollment
of specified <code>n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of random enrollment times.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
# Piecewise uniform (piecewise exponential inter-arrival times) for 10k patients enrollment
# Enrollment rates of 5 for time 0-100, 15 for 100-300, and 30 thereafter
x &lt;- rpwexp_enroll(
  n = 1e5,
  enroll_rate = data.frame(
    rate = c(5, 15, 30),
    duration = c(100, 200, 100)
  )
)
plot(x, 1:1e5,
  main = "Piecewise uniform enrollment simulation",
  xlab = "Time",
  ylab = "Enrollment"
)

# Example 2
# Exponential enrollment
x &lt;- rpwexp_enroll(
  n = 1e5,
  enroll_rate = data.frame(rate = .03, duration = 1)
)
plot(x, 1:1e5,
  main = "Simulated exponential inter-arrival times",
  xlab = "Time",
  ylab = "Enrollment"
)
</code></pre>

<hr>
<h2 id='sim_fixed_n'>Simulation of fixed sample size design for time-to-event endpoint</h2><span id='topic+sim_fixed_n'></span>

<h3>Description</h3>

<p><code>sim_fixed_n()</code> provides simulations of a single endpoint two-arm trial
where the enrollment, hazard ratio, and failure and dropout rates change
over time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_fixed_n(
  n_sim = 1000,
  sample_size = 500,
  target_event = 350,
  stratum = data.frame(stratum = "All", p = 1),
  enroll_rate = data.frame(duration = c(2, 2, 10), rate = c(3, 6, 9)),
  fail_rate = data.frame(stratum = "All", duration = c(3, 100), fail_rate = log(2)/c(9,
    18), hr = c(0.9, 0.6), dropout_rate = rep(0.001, 2)),
  total_duration = 30,
  block = rep(c("experimental", "control"), 2),
  timing_type = 1:5,
  rho_gamma = data.frame(rho = 0, gamma = 0)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_fixed_n_+3A_n_sim">n_sim</code></td>
<td>
<p>Number of simulations to perform.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_sample_size">sample_size</code></td>
<td>
<p>Total sample size per simulation.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_target_event">target_event</code></td>
<td>
<p>Targeted event count for analysis.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_stratum">stratum</code></td>
<td>
<p>A data frame with stratum specified in <code>stratum</code>,
probability (incidence) of each stratum in <code>p</code>.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_enroll_rate">enroll_rate</code></td>
<td>
<p>Piecewise constant enrollment rates by time period.
Note that these are overall population enrollment rates and the <code>stratum</code>
argument controls the random distribution between stratum.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_fail_rate">fail_rate</code></td>
<td>
<p>Piecewise constant control group failure rates, hazard ratio
for experimental vs. control, and dropout rates by stratum and time period.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_total_duration">total_duration</code></td>
<td>
<p>Total follow-up from start of enrollment to data cutoff.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_block">block</code></td>
<td>
<p>As in <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>. Vector of treatments to be included
in each block.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_timing_type">timing_type</code></td>
<td>
<p>A numeric vector determining data cutoffs used;
see details. Default is to include all available cutoff methods.</p>
</td></tr>
<tr><td><code id="sim_fixed_n_+3A_rho_gamma">rho_gamma</code></td>
<td>
<p>As in <code><a href="#topic+fh_weight">fh_weight()</a></code>. A data frame with variables
<code>rho</code> and <code>gamma</code>, both greater than equal to zero,
to specify one Fleming-Harrington weighted logrank test per row.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>timing_type</code> has up to 5 elements indicating different options
for data cutoff:
</p>

<ul>
<li> <p><code>1</code>: Uses the planned study duration.
</p>
</li>
<li> <p><code>2</code>: The time the targeted event count is achieved.
</p>
</li>
<li> <p><code>3</code>: The planned minimum follow-up after enrollment is complete.
</p>
</li>
<li> <p><code>4</code>: The maximum of planned study duration and targeted event count cuts
(1 and 2).
</p>
</li>
<li> <p><code>5</code>: The maximum of targeted event count and minimum follow-up cuts
(2 and 3).
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame including columns:
</p>

<ul>
<li> <p><code>event</code>: Event count.
</p>
</li>
<li> <p><code>ln_hr</code>: Log-hazard ratio.
</p>
</li>
<li> <p><code>z</code>: Normal test statistic; &lt; 0 favors experimental.
</p>
</li>
<li> <p><code>cut</code>: Text describing cutoff used.
</p>
</li>
<li> <p><code>duration</code>: Duration of trial at cutoff for analysis.
</p>
</li>
<li> <p><code>sim</code>: Sequential simulation ID.
</p>
</li></ul>

<p>One row per simulated dataset per cutoff specified in <code>timing_type</code>,
per test statistic specified.
If multiple Fleming-Harrington tests are specified in <code>rho_gamma</code>,
then columns <code>rho</code> and <code>gamma</code> are also included.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(future)

# Example 1
# Show output structure
sim_fixed_n(n_sim = 3)

# Example 2
# Example with 2 tests: logrank and FH(0,1)
sim_fixed_n(n_sim = 1, rho_gamma = data.frame(rho = 0, gamma = c(0, 1)))


# Example 3
# Power by test
# Only use cuts for events, events + min follow-up
xx &lt;- sim_fixed_n(
  n_sim = 100,
  timing_type = c(2, 5),
  rho_gamma = data.frame(rho = 0, gamma = c(0, 1))
)
# Get power approximation for FH, data cutoff combination
xx |&gt;
  group_by(cut, rho, gamma) |&gt;
  summarize(mean(z &lt;= qnorm(.025)))

# MaxCombo power estimate for cutoff at max of targeted events, minimum follow-up
p &lt;- xx |&gt;
  filter(cut != "Targeted events") |&gt;
  group_by(sim) |&gt;
  group_map(~ pvalue_maxcombo(.x)) |&gt;
  unlist()

mean(p &lt; .025)

# MaxCombo estimate for targeted events cutoff
p &lt;- xx |&gt;
  filter(cut == "Targeted events") |&gt;
  group_by(sim) |&gt;
  group_map(~ pvalue_maxcombo(.x)) |&gt;
  unlist()

mean(p &lt; .025)

# Example 4
# Use two cores
set.seed(2023)
plan("multisession", workers = 2)
sim_fixed_n(n_sim = 10)
plan("sequential")

</code></pre>

<hr>
<h2 id='sim_pw_surv'>Simulate a stratified time-to-event outcome randomized trial</h2><span id='topic+sim_pw_surv'></span>

<h3>Description</h3>

<p><code>sim_pw_surv()</code> enables simulation of a clinical trial with
essentially arbitrary patterns of enrollment, failure rates and censoring.
The piecewise exponential distribution allows a simple method to specify
a distribution and enrollment pattern where the enrollment, failure,
and dropout rate changes over time.
While the main purpose may be to generate a trial that can be analyzed
at a single point in time or using group sequential methods,
the routine can also be used to simulate an adaptive trial design.
Enrollment, failure, and dropout rates are specified by treatment group,
stratum and time period.
Fixed block randomization is used; blocks must include treatments provided
in failure and dropout specification.
Default arguments are set up to allow very simple implementation of
a non-proportional hazards assumption for an unstratified design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_pw_surv(
  n = 100,
  stratum = data.frame(stratum = "All", p = 1),
  block = c(rep("control", 2), rep("experimental", 2)),
  enroll_rate = data.frame(rate = 9, duration = 1),
  fail_rate = data.frame(stratum = rep("All", 4), period = rep(1:2, 2), treatment =
    c(rep("control", 2), rep("experimental", 2)), duration = rep(c(3, 1), 2), rate =
    log(2)/c(9, 9, 9, 18)),
  dropout_rate = data.frame(stratum = rep("All", 2), period = rep(1, 2), treatment =
    c("control", "experimental"), duration = rep(100, 2), rate = rep(0.001, 2))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_pw_surv_+3A_n">n</code></td>
<td>
<p>Number of observations.
If length(n) &gt; 1, the length is taken to be the number required.</p>
</td></tr>
<tr><td><code id="sim_pw_surv_+3A_stratum">stratum</code></td>
<td>
<p>A data frame with stratum specified in <code>stratum</code>,
probability (incidence) of each stratum in <code>p</code>.</p>
</td></tr>
<tr><td><code id="sim_pw_surv_+3A_block">block</code></td>
<td>
<p>Vector of treatments to be included in each block.</p>
</td></tr>
<tr><td><code id="sim_pw_surv_+3A_enroll_rate">enroll_rate</code></td>
<td>
<p>Enrollment rates; see details and examples.</p>
</td></tr>
<tr><td><code id="sim_pw_surv_+3A_fail_rate">fail_rate</code></td>
<td>
<p>Failure rates; see details and examples;
note that treatments need to be the same as input in block.</p>
</td></tr>
<tr><td><code id="sim_pw_surv_+3A_dropout_rate">dropout_rate</code></td>
<td>
<p>Dropout rates; see details and examples;
note that treatments need to be the same as input in block.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with the following variables for each observation:
</p>

<ul>
<li> <p><code>stratum</code>.
</p>
</li>
<li> <p><code>enroll_time</code>: Enrollment time for the observation.
</p>
</li>
<li> <p><code>Treatment</code>: Treatment group; this will be one of the values
in the input <code>block</code>.
</p>
</li>
<li> <p><code>fail_time</code>: Failure time generated using <code><a href="#topic+rpwexp">rpwexp()</a></code>.
</p>
</li>
<li> <p><code>dropout_time</code>: Dropout time generated using <code><a href="#topic+rpwexp">rpwexp()</a></code>.
</p>
</li>
<li> <p><code>cte</code>: Calendar time of enrollment plot the minimum of
failure time and dropout time.
</p>
</li>
<li> <p><code>fail</code>: Indicator that <code>cte</code> was set using failure time;
i.e., 1 is a failure, 0 is a dropout.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)

# Example 1
sim_pw_surv(n = 20)

# Example 2
# 3:1 randomization
sim_pw_surv(
  n = 20,
  block = c(rep("experimental", 3), "control")
)

# Example 3
# Simulate 2 stratum; will use defaults for blocking and enrollRates
sim_pw_surv(
  n = 20,
  # 2 stratum,30% and 70% prevalence
  stratum = data.frame(stratum = c("Low", "High"), p = c(.3, .7)),
  fail_rate = data.frame(
    stratum = c(rep("Low", 4), rep("High", 4)),
    period = rep(1:2, 4),
    treatment = rep(c(
      rep("control", 2),
      rep("experimental", 2)
    ), 2),
    duration = rep(c(3, 1), 4),
    rate = c(.03, .05, .03, .03, .05, .08, .07, .04)
  ),
  dropout_rate = data.frame(
    stratum = c(rep("Low", 2), rep("High", 2)),
    period = rep(1, 4),
    treatment = rep(c("control", "experimental"), 2),
    duration = rep(1, 4),
    rate = rep(.001, 4)
  )
)
# Example 4
# If you want a more rectangular entry for a data.frame
fail_rate &lt;- bind_rows(
  data.frame(stratum = "Low", period = 1, treatment = "control", duration = 3, rate = .03),
  data.frame(stratum = "Low", period = 1, treatment = "experimental", duration = 3, rate = .03),
  data.frame(stratum = "Low", period = 2, treatment = "experimental", duration = 3, rate = .02),
  data.frame(stratum = "High", period = 1, treatment = "control", duration = 3, rate = .05),
  data.frame(stratum = "High", period = 1, treatment = "experimental", duration = 3, rate = .06),
  data.frame(stratum = "High", period = 2, treatment = "experimental", duration = 3, rate = .03)
)

dropout_rate &lt;- bind_rows(
  data.frame(stratum = "Low", period = 1, treatment = "control", duration = 3, rate = .001),
  data.frame(stratum = "Low", period = 1, treatment = "experimental", duration = 3, rate = .001),
  data.frame(stratum = "High", period = 1, treatment = "control", duration = 3, rate = .001),
  data.frame(stratum = "High", period = 1, treatment = "experimental", duration = 3, rate = .001)
)

sim_pw_surv(
  n = 12,
  stratum = data.frame(stratum = c("Low", "High"), p = c(.3, .7)),
  fail_rate = fail_rate,
  dropout_rate = dropout_rate
)
</code></pre>

<hr>
<h2 id='to_sim_pw_surv'>Convert enrollment and failure rates from <code>sim_fixed_n()</code> to
<code>sim_pw_surv()</code> format</h2><span id='topic+to_sim_pw_surv'></span>

<h3>Description</h3>

<p><code>to_sim_pw_surv()</code> converts failure rates and dropout rates entered in
the simpler format for <code><a href="#topic+sim_fixed_n">sim_fixed_n()</a></code> to that used for <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>.
The <code>fail_rate</code> argument for <code><a href="#topic+sim_fixed_n">sim_fixed_n()</a></code> requires enrollment rates,
failure rates hazard ratios and dropout rates by stratum for a 2-arm trial,
<code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code> is in a more flexible but less obvious but more flexible
format. Since <code><a href="#topic+sim_fixed_n">sim_fixed_n()</a></code> automatically analyzes data and <code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>
just produces a simulation dataset, the latter provides additional options
to analyze or otherwise evaluate individual simulations in ways that
<code><a href="#topic+sim_fixed_n">sim_fixed_n()</a></code> does not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>to_sim_pw_surv(
  fail_rate = data.frame(stratum = "All", duration = c(3, 100), fail_rate = log(2)/c(9,
    18), hr = c(0.9, 0.6), dropout_rate = rep(0.001, 2))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="to_sim_pw_surv_+3A_fail_rate">fail_rate</code></td>
<td>
<p>Piecewise constant control group failure rates,
hazard ratio for experimental vs. control,
and dropout rates by stratum and time period.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two data frame components formatted for
<code><a href="#topic+sim_pw_surv">sim_pw_surv()</a></code>: <code>fail_rate</code> and <code>dropout_rate</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
# Convert standard input
to_sim_pw_surv()

# Stratified example
fail_rate &lt;- data.frame(
  stratum = c(rep("Low", 3), rep("High", 3)),
  duration = rep(c(4, 10, 100), 2),
  fail_rate = c(
    .04, .1, .06,
    .08, .16, .12
  ),
  hr = c(
    1.5, .5, 2 / 3,
    2, 10 / 16, 10 / 12
  ),
  dropout_rate = .01
)

x &lt;- to_sim_pw_surv(fail_rate)

# Do a single simulation with the above rates
# Enroll 300 patients in ~12 months at constant rate
sim &lt;- sim_pw_surv(
  n = 300,
  stratum = data.frame(stratum = c("Low", "High"), p = c(.6, .4)),
  enroll_rate = data.frame(duration = 12, rate = 300 / 12),
  fail_rate = x$fail_rate,
  dropout_rate = x$dropout_rate
)

# Cut after 200 events and do a stratified logrank test
dat &lt;- sim |&gt;
  cut_data_by_event(200) |&gt; # Cut data
  counting_process(arm = "experimental") |&gt; # Convert format for fh_weight()
  fh_weight(rho_gamma = data.frame(rho = 0, gamma = 0)) # Stratified logrank
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
