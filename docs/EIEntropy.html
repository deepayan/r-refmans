<!DOCTYPE html><html lang="en"><head><title>Help for package EIEntropy</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EIEntropy}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ei_gce'><p>Ecologic Inference applying entropy</p></a></li>
<li><a href='#ei_gme'><p>Ecologic Inference applying entropy</p></a></li>
<li><a href='#financial'><p>Randomly Generated Data</p></a></li>
<li><a href='#plot.kl'><p>Generate a Plot</p></a></li>
<li><a href='#plot.shannon'><p>Generate a Plot</p></a></li>
<li><a href='#social'><p>Randomly Generated Data</p></a></li>
<li><a href='#summary.kl'><p>Summary</p></a></li>
<li><a href='#summary.shannon'><p>Summary</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Ecological Inference Applying Entropy</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1.4</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Silvia María Franco Anaya &lt;sfrana@unileon.es&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements two estimations related to the foundations of info metrics applied to ecological inference. These methodologies assess the lack of disaggregated data and provide an approach to obtaining disaggregated territorial-level data. For more details, see the following references: Fernández-Vázquez, E., Díaz-Dapena, A., Rubiera-Morollón, F. et al. (2020) "Spatial Disaggregation of Social Indicators: An Info-Metrics Approach." &lt;<a href="https://doi.org/10.1007%2Fs11205-020-02455-z">doi:10.1007/s11205-020-02455-z</a>&gt;. Díaz-Dapena, A., Fernández-Vázquez, E., Rubiera-Morollón, F., &amp; Vinuela, A. (2021) "Mapping poverty at the local level in Europe: A consistent spatial disaggregation of the AROPE indicator for France, Spain, Portugal and the United Kingdom." &lt;<a href="https://doi.org/10.1111%2Frsp3.12379">doi:10.1111/rsp3.12379</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, magrittr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>devtools, knitr, rmarkdown, here</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Author:</td>
<td>Alberto Díaz-Dapena [aut, cph],
  Esteban Fernández-Vázquez [aut, cph],
  Silvia María Franco Anaya [aut, cre, cph]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-17 22:30:54 UTC; pc</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-17 23:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ei_gce'>Ecologic Inference applying entropy</h2><span id='topic+ei_gce'></span>

<h3>Description</h3>

<p>The function ei_gce defines the Kullback-Leibler function which
minimises the distance between the distribution of probabilities P and the
distribution Q. The distribution Q is based on prior information that we have
of our variable of interest previous to the analysis. The function will set
the optimization parameters and, using the &quot;nlminb&quot;
function, an optimal solution is obtained.
The function defines the independent variables in the two databases
needed, which we call dataA with &quot;n_A&quot; observations and dataB with &quot;n_B&quot;
observations; and the function of the variable of interest y. Then the
weights of each observation for the two databases used are defined, if there
are not weights available it will be 1 by default. The errors are calculated
pondering the support vector of dimension <code>var, 0, -var</code>. This support vector
can be specified by the user. The default support vector is based on variance.
We recommend a wider interval with v(1,0,-1) as the maximum.
The restrictions are defined in order to guarantee consistency. The
minimization of Kullback_Leibler distance is solved with &quot;nlminb&quot; function
with maximum number of iterations 1000 and with tolerance
defined by the user. If the user did not define tolerance it will be 1e-10 by
default. For additional details about the methodology see Fernández-Vazquez, et al. (2020)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ei_gce(fn, dataA, dataB, q, weights = NULL, v, tol, iter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ei_gce_+3A_fn">fn</code></td>
<td>
<p>Is the formula that represents the dependent variable in the optimization.
In the context of this function, 'fn' is used to define the dependent variable
to be optimized by the Kullback-Leibler divergence function.
Note: If the dependent variable is categorical the sorting criterion for the columns, and therefore for J, is alphabetical order.</p>
</td></tr>
<tr><td><code id="ei_gce_+3A_dataa">dataA</code></td>
<td>
<p>The data where the variable of interest y is available and also the independent variables.
Note: The variables and weights used as independent variables must have the same name in 'dataA' and in 'dataB'</p>
</td></tr>
<tr><td><code id="ei_gce_+3A_datab">dataB</code></td>
<td>
<p>The data which contains information on the independent variables at a disaggregated level.
Note: The variables and weights used as independent variables must have the same name in 'dataA' and in 'dataB'. The variables in both databases need to match up in content.</p>
</td></tr>
<tr><td><code id="ei_gce_+3A_q">q</code></td>
<td>
<p>The prior distribution Q</p>
</td></tr>
<tr><td><code id="ei_gce_+3A_weights">weights</code></td>
<td>
<p>A character string specifying the column name to be used as weights in both 'dataA'  and 'dataB' datasets.
If the argument <code>weights</code> is provided and present in both datasets,  the weights in each dataset will be normalized by the sum of the weights within that dataset.
If <code>weights</code> is NULL or the specified column does not exist in both datasets, equal weights are applied across all observations.</p>
</td></tr>
<tr><td><code id="ei_gce_+3A_v">v</code></td>
<td>
<p>The support vector</p>
</td></tr>
<tr><td><code id="ei_gce_+3A_tol">tol</code></td>
<td>
<p>The tolerance to be applied in the optimization function. If the tolerance is not specified, the default tolerance has been set in 1e-10</p>
</td></tr>
<tr><td><code id="ei_gce_+3A_iter">iter</code></td>
<td>
<p>The maximum number of iterations allowed for the optimization algorithm to run
Increasing the number of iterations may improve the likelihood of finding an optimal solution,
but can also increases computation time.If the maximum number of iterations is not specified, it will default to 1000</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To solve the optimization upper and lower bounds for p and w are settled, specifically, p and w must be above 0 and lower than 1.
In addition, the initial values of p are settled as the defined prior and the errors (w) as 1/L.
</p>


<h3>Value</h3>

<p>The function will provide you a dataframe called estimations with the next information:
</p>

<ul>
<li> <p><strong>weights</strong> The weights used in the optimization process.
</p>
</li>
<li> <p><strong>predictions</strong>  The prediction for each individual is calculated as the sum of the probability plus the error.
</p>
</li>
<li> <p><strong>probabilities</strong>  Probabilities for each individual to each possibility <code>j</code> of the variable of interest <code>y</code>.
</p>
</li>
<li> <p><strong>errors</strong>  Errors calculated to the <code>j</code> possibilities of <code>y</code>.
The function provides information about the optimization process as:
</p>
</li>
<li> <p><strong>divergencekl</strong> The Kullback-Leibler divergence value resulting from the optimization.
</p>
</li>
<li> <p><strong>iterations</strong> Indicates the times the objective function and the gradient has been evaluated during the optimization process,if any.
</p>
</li>
<li> <p><strong>message</strong> Indicates the message if it has been generated in the process of optimization.
</p>
</li>
<li> <p><strong>q</strong> Indicates prior implemented in the optimization.
</p>
</li>
<li> <p><strong>tol</strong> Indicates the tolerance of the optimization process.
</p>
</li>
<li> <p><strong>v</strong> Indicates the support vector used in the function.
The function provides a dataframe containing the information about lambda:
</p>
</li>
<li>  <p><strong>lambda</strong> The estimated lambda values.
It is provided an object with the restrictions checked which should be zero.
</p>
</li>
<li>  <p><strong>check restrictions</strong> Being  <code>g1</code>  the restriction related to the unit probability constraint, <code>g2</code>  to the error unit sum constraint, and <code>g3</code>  to the consistency restriction that implies that the difference between the cross moment in both datasets must be zero.
The restriction g3 can be checked thoroughly with the objects by separate.
</p>
</li>
<li>  <p><strong>cross moments A</strong> Cross moments in <code>dataA</code>.
</p>
</li>
<li>  <p><strong>cross moments B</strong> Cross moments in <code>dataB</code>.
</p>
</li></ul>



<h3>References</h3>

<p>Fernandez-Vazquez, E., Diaz-Dapena, A., Rubiera-Morollon, F., Viñuela, A., (2020) Spatial Disaggregation of Social Indicators: An Info-Metrics Approach. Social Indicators Research, 152(2), 809–821. https://doi.org/10.1007/s11205-020-02455-z.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#In this example we use the data of this package
dataA &lt;- financial()
dataB &lt;- social()
# Setting up our function for the dependent variable.
fn               &lt;- dataA$poor_liq ~ Dcollege+Totalincome+Dunemp
#In this case we know that the mean probability of being poor is 0.35.With this function
#we can add the information as information a priori. This information a priori correspond to the
#Q distribution and in this function is called q for the sake of simplicity:
q&lt;- c(0.35,0.65)
v&lt;- matrix(c(0.2,0,-0.2))
#Applying the function ei_gce to our databases. In this case dataA is the
#dataA where we have our variable of interest
#dataB is the data where we have the information for the disaggregation.
#w can be included if we have weights in both surveys
result  &lt;- ei_gce(fn,dataA,dataB,q=q,weights="w",v=v)
</code></pre>

<hr>
<h2 id='ei_gme'>Ecologic Inference applying entropy</h2><span id='topic+ei_gme'></span>

<h3>Description</h3>

<p>The function ei_gme defines the Shannon entropy function which takes a vector of probabilities as input and returns the negative
sum of p times the natural logarithm of p.The function will set the optimization parameters and using the &quot;nlminb&quot; function an optimal
solution is obtained.
The function defines the independent variables in the two databases needed, which we call dataA with &quot;n_A&quot; observations and dataB
with &quot;n_B&quot; observations; and the function of the binary variable of interest y. Then the weights of each observation for the two
databases used are defined, if there are no weights available it will be 1.
The errors are calculated pondering the support vector of dimension <code>var, 0, -var</code>. This support vector can be specified by the user.
The default support vector is based on variance.We recommend a wider interval with v(1,0,-1) as the maximum.
The restrictions are defined to guarantee consistency.
The optimization of the Shannon entropy function is solved with &quot;nlminb&quot; function
with maximum number of iterations 1000 and with tolerance
defined by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ei_gme(fn, dataA, dataB, weights = NULL, tol, v, iter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ei_gme_+3A_fn">fn</code></td>
<td>
<p>Is the formula that represents the dependent variable in the optimization.
In the context of this function, 'fn' is used to define the dependent variable
to be optimized by the entropy function.
Note: If the dependent variable is categorical the sorting criterion for the columns, and therefore for J, is alphabetical order.</p>
</td></tr>
<tr><td><code id="ei_gme_+3A_dataa">dataA</code></td>
<td>
<p>The data where the variable of interest y is available and also the independent variables.
Note: The variables and weights used as independent variables must have the same name in 'dataA' and in 'dataB'
The variables in both databases need to match up in content.</p>
</td></tr>
<tr><td><code id="ei_gme_+3A_datab">dataB</code></td>
<td>
<p>The data which contains information on the independent variables at a disaggregated level.
Note: The variables and weights used as independent variables must be the same and must have the same name in 'dataA' and in 'dataB'</p>
</td></tr>
<tr><td><code id="ei_gme_+3A_weights">weights</code></td>
<td>
<p>A character string specifying the column name to be used as weights in both 'dataA' and 'dataB' datasets.
If the argument <code>weights</code> is provided and present in both datasets,  the weights in each dataset will be normalized by the sum of the weights within that dataset.
If <code>weights</code> is NULL or the specified column does not exist in both datasets, equal weights are applied across all observations.</p>
</td></tr>
<tr><td><code id="ei_gme_+3A_tol">tol</code></td>
<td>
<p>The tolerance to be applied in the optimization function. If the tolerance is not specified, the default tolerance has been set in 1e-10</p>
</td></tr>
<tr><td><code id="ei_gme_+3A_v">v</code></td>
<td>
<p>The support vector</p>
</td></tr>
<tr><td><code id="ei_gme_+3A_iter">iter</code></td>
<td>
<p>The maximum number of iterations allowed for the optimization algorithm to run
Increasing the number of iterations may improve the likelihood of finding an optimal solution,
but can also increases computation time.If the maximum number of iterations is not specified, it will default to 1000</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To solve the optimization upper and lower bounds for p and w are settled, specifically, p and w must be above 0 and lower than 1.
In addition, the initial values of p are settled as a uniform distribution and the errors (w) as 1/L.
</p>


<h3>Value</h3>

<p>The function will provide you a dataframe called table with the next information:
</p>

<ul>
<li> <p><strong>weights</strong> The weights used in the optimization process.
</p>
</li>
<li> <p><strong>predictions</strong>  The prediction for each individual is calculated as the sum of the probability plus the error.
</p>
</li>
<li> <p><strong>probabilities</strong>  Probabilities for each individual to each possibility <code>j</code> of the variable of interest <code>y</code>.
</p>
</li>
<li> <p><strong>errors</strong>  Errors calculated to the <code>j</code> possibilities of <code>y</code>.
The function provides information about the optimization process as :
</p>
</li>
<li> <p><strong>value_of_entropy</strong> The value of entropy resulting from the optimization.
</p>
</li>
<li> <p><strong>iterations</strong> Indicates the times the objective function and the gradient has been evaluated during the optimization process
</p>
</li>
<li> <p><strong>message</strong> Indicates the message if it has been generated in the process of optimization
</p>
</li>
<li> <p><strong>tol</strong> Indicates the tolerance used in the optimization
</p>
</li>
<li> <p><strong>v</strong> Indicates the vector of support used in the function
The function provides a dataframe containing the information about lambda:
</p>
</li>
<li>  <p><strong>lambda</strong> The estimated lambda values.
It is provided an object with the restrictions checked which should be approximately zero.
</p>
</li>
<li>  <p><strong>check restrictions</strong> Being  g1 the restriction related to the unit probability constraint, g2 to the error unit sum constraint, and g3 to the consistency restriction that implies that the difference between the cross moment in both datasets must be zero.
</p>
</li></ul>

<p>The restriction g3 can be checked thoroughly with the objects by separate.
</p>

<ul>
<li>  <p><strong>cross moments A</strong> Cross moments in <code>dataA</code>.
</p>
</li>
<li>  <p><strong>cross moments B</strong> Cross moments in <code>dataB</code>.</p>
</li></ul>



<h3>References</h3>

<p>Fernandez-Vazquez, E., Díaz-Dapena, A., Rubiera-Morollon, F., Viñuela, A., (2020) Spatial Disaggregation of Social Indicators: An Info-Metrics Approach. Social Indicators Research, 152(2), 809–821. https://doi.org/10.1007/s11205-020-02455-z.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#In this example we use the data of this package
dataA &lt;- financial()
dataB &lt;- social()
# Setting up our function for the dependent variable.
fn               &lt;- dataA$poor_liq ~ Dcollege+Totalincome+Dunemp
#Applying the function ei_gme to our databases. In this case dataA
#is the data where we have our variable of interest dataB is the data
# where we have the information for the disaggregation.
#w can be included if we have weights in both surveys
#Tolerance in this example is fixed in 1e-10 and v will be (1,0,-1)
v=matrix(c(1, 0, -1), nrow = 1)
result  &lt;- ei_gme(fn=fn,dataA=dataA,dataB=dataB,weights="w",v=v)
</code></pre>

<hr>
<h2 id='financial'>Randomly Generated Data</h2><span id='topic+financial'></span>

<h3>Description</h3>

<p>This dataset contains 100 observations of 6 variables. The data was
generated randomly for the purpose of exemplifying a database that could
potentially be used with this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>financial()
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations of 6 variables called financial
</p>


<h3>Value</h3>

<p>A data frame containing the loaded &quot;financial&quot; data from the .rds file.
</p>

<ul>
<li> <p><code>Dcollege</code>: Dummy variable indicating college education.
</p>
</li>
<li> <p><code>Dunemp</code>: Dummy variable indicating unemployment.
</p>
</li>
<li> <p><code>Totalincome</code>: Total income of each observation.
</p>
</li>
<li> <p><code>poor_liq</code>: Dummy variable indicating liquid poverty.
</p>
</li>
<li> <p><code>w</code>: Weights for each observation.
</p>
</li>
<li> <p><code>n</code>: Identifier for observations.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(financial)
head(financial)


</code></pre>

<hr>
<h2 id='plot.kl'>Generate a Plot</h2><span id='topic+plot.kl'></span>

<h3>Description</h3>

<p>This function generates a descriptive plot using the results obtained in ei_gce. It illustrates the mean and the confidence interval by disaggregated territorial unit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kl'
plot(x, reg, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kl_+3A_x">x</code></td>
<td>
<p>The output produced by ei_gce</p>
</td></tr>
<tr><td><code id="plot.kl_+3A_reg">reg</code></td>
<td>
<p>The data column containing the disaggregated territorial units</p>
</td></tr>
<tr><td><code id="plot.kl_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the plotting function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function provides a graph representing the weighted mean and confidence interval of each disaggregated territorial unit
</p>

<hr>
<h2 id='plot.shannon'>Generate a Plot</h2><span id='topic+plot.shannon'></span>

<h3>Description</h3>

<p>This  function generates a descriptive plot using the result obtained in ei_gme.
It illustrates the mean and the confidence interval by disaggregated territorial unit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'shannon'
plot(x, reg, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.shannon_+3A_x">x</code></td>
<td>
<p>The output produced by ei_gme</p>
</td></tr>
<tr><td><code id="plot.shannon_+3A_reg">reg</code></td>
<td>
<p>The data column containing the disaggregated territorial units</p>
</td></tr>
<tr><td><code id="plot.shannon_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the plotting function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function provides a graph representing the weighted mean and confidence interval of each disaggregated territorial unit
</p>

<hr>
<h2 id='social'>Randomly Generated Data</h2><span id='topic+social'></span>

<h3>Description</h3>

<p>This dataset contains 200 observations of 6 variables. The data was
generated randomly for the purpose of exemplifying a database that could
potentially be used with this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>social()
</code></pre>


<h3>Format</h3>

<p>A data frame with 200 observations of 6 variables called social
</p>


<h3>Value</h3>

<p>A data frame containing the loaded &quot;social&quot; data from the .rds file.
</p>

<ul>
<li> <p><code>Dcollege</code>: Dummy variable indicating college education.
</p>
</li>
<li> <p><code>Dunemp</code>: Dummy variable indicating unemployment.
</p>
</li>
<li> <p><code>Totalincome</code>: Total income of each observation.
</p>
</li>
<li> <p><code>reg</code>:Variable indicating the region of the observation.
</p>
</li>
<li> <p><code>w</code>: Weights for each observation.
</p>
</li>
<li> <p><code>n</code>: Identifier for observations.
</p>
</li></ul>

<p>#' @examples
data(social)
head(social)
</p>

<hr>
<h2 id='summary.kl'>Summary</h2><span id='topic+summary.kl'></span>

<h3>Description</h3>

<p>This function provides a summary of the output obtained with the function ei_gce.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kl'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.kl_+3A_object">object</code></td>
<td>
<p>The output obtained from ei_gce</p>
</td></tr>
<tr><td><code id="summary.kl_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the summary function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This summary function returns the Kullback-Leibler divergence value and the last iteration in the optimization process.
A dataframe with the means of the estimations for each characteristic j with the predictions the probabilities and the error estimated.
A dataframe with the lambda estimated for each k.
</p>

<ul>
<li> <p><code>Iterations</code>:Indicates the times the objective function and the gradient has been evaluated during the optimization process
</p>
</li>
<li> <p><code>divergencekl value</code>:The Kullback-Leibler divergence value resulting from the optimization.
</p>
</li>
<li> <p><code>mean_estimations</code>:The weighted mean of predictions, probabilities, and the errors for each category j of the variable y
</p>
</li>
<li> <p><code>lambda</code>:The estimated lambda values.
</p>
</li></ul>


<hr>
<h2 id='summary.shannon'>Summary</h2><span id='topic+summary.shannon'></span>

<h3>Description</h3>

<p>This function provides a summary of the output obtained with the function ei_gme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'shannon'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.shannon_+3A_object">object</code></td>
<td>
<p>The output obtained from ei_gme</p>
</td></tr>
<tr><td><code id="summary.shannon_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to the summary function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This summary function returns the entropy value and the last iteration in the optimization process.
A dataframe with the means of the estimations for each characteristic j with the predictions the probabilities and the error estimated.
A dataframe with the lambda estimated for each k.
</p>

<ul>
<li> <p><code>Iterations</code>:Indicates the times the objective function and the gradient has been evaluated during the optimization process
</p>
</li>
<li> <p><code>Entropy value</code>:The value of entropy resulting from the optimization.
</p>
</li>
<li> <p><code>mean_estimations</code>: The weighted mean of predictions, p_dual, and the error for each category j of the variable y
</p>
</li>
<li> <p><code>lambda</code>:The estimated lambda values.
</p>
</li></ul>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
