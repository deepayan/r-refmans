<!DOCTYPE html><html><head><title>Help for package gfpop</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gfpop}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dataGenerator'><p>Data Generator</p></a></li>
<li><a href='#Edge'><p>Edge generation</p></a></li>
<li><a href='#gfpop'><p>Graph-Constrained Functional Pruning Optimal Partitioning (gfpop)</p></a></li>
<li><a href='#graph'><p>Graph generation</p></a></li>
<li><a href='#itergfpop'><p>Graph-constrained functional pruning optimal partitioning iterated</p></a></li>
<li><a href='#Node'><p>Node Values</p></a></li>
<li><a href='#paperGraph'><p>Graphs of our paper in JSS</p></a></li>
<li><a href='#plot.gfpop'><p>plot.gfpop</p></a></li>
<li><a href='#print.gfpop'><p>print.gfpop</p></a></li>
<li><a href='#sdDiff'><p>sdDiff</p></a></li>
<li><a href='#StartEnd'><p>Start and End nodes for the graph</p></a></li>
<li><a href='#summary.gfpop'><p>summary.gfpop</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Graph-Constrained Functional Pruning Optimal Partitioning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Vincent Runge &lt;vincent.runge@univ-evry.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Penalized parametric change-point detection by functional pruning dynamic programming algorithm. The successive means are constrained using a graph structure with edges defining the nature of the changes These changes can be unconstrained (type std), up or down constrained (type up and down) or constrained by a minimal size jump (type abs). The type null means that the graph allows us to stay on the same segment. To each edge we can associate some additional properties: a minimal gap size, a penalty, some robust parameters (K,a) for biweight (K) and Huber losses (K and a). The user can also constrain the inferred means to lie between some minimal and maximal values. Data is modeled by a cost with possible use of a robust loss, biweight and Huber (see edge parameters K and a). These costs should have a quadratic, log-linear or a log-log representation. This includes quadratic Gaussian cost (type = 'mean'), log-linear cost (type = 'variance', 'poisson' or 'exp') and log-log cost (type = 'negbin'). More details in the paper published in the Journal of Statistical Software: &lt;<a href="https://doi.org/10.18637%2Fjss.v106.i06">doi:10.18637/jss.v106.i06</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>devtools, knitr, data.table, testthat, rmarkdown, ggplot2,
penaltyLearning</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-27 08:45:24 UTC; vrunge</td>
</tr>
<tr>
<td>Author:</td>
<td>Vincent Runge [aut, cre],
  Toby Hocking [aut],
  Guillem Rigaill [aut],
  Daniel Grose [aut],
  Gaetano Romano [aut],
  Fatemeh Afghah [aut],
  Paul Fearnhead [aut],
  Michel Koskas [ctb],
  Arnaud Liehrmann [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-27 09:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dataGenerator'>Data Generator</h2><span id='topic+dataGenerator'></span>

<h3>Description</h3>

<p>Generating data with a given model = changepoint relative positions + parameters + type of cost + (standard deviation + gamma decay)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataGenerator(
  n,
  changepoints,
  parameters,
  type = "mean",
  sigma = 1,
  gamma = 1,
  size = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataGenerator_+3A_n">n</code></td>
<td>
<p>number of data points to generate</p>
</td></tr>
<tr><td><code id="dataGenerator_+3A_changepoints">changepoints</code></td>
<td>
<p>vector of positions of the changepoints in (0,1] (last element is always 1).</p>
</td></tr>
<tr><td><code id="dataGenerator_+3A_parameters">parameters</code></td>
<td>
<p>vector of means for the consecutive segments (same length as changepoints)</p>
</td></tr>
<tr><td><code id="dataGenerator_+3A_type">type</code></td>
<td>
<p>a string defining the cost model to use: <code>"mean"</code>, <code>"variance"</code>, <code>"poisson"</code>, <code>"exp"</code>, <code>"negbin"</code></p>
</td></tr>
<tr><td><code id="dataGenerator_+3A_sigma">sigma</code></td>
<td>
<p>a positive number = the standard deviation of the data</p>
</td></tr>
<tr><td><code id="dataGenerator_+3A_gamma">gamma</code></td>
<td>
<p>a number between 0 and 1 : the coefficient of the exponential decay (by default = 1 for piecewise constant signals)</p>
</td></tr>
<tr><td><code id="dataGenerator_+3A_size">size</code></td>
<td>
<p>parameter of the <code>rnbinom</code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of size n generated by the chosen model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataGenerator(500, c(0.3, 0.6, 1), c(1, 2, 3), type = "mean", sigma = 0.5)

dataGenerator(1000, c(0.2, 0.33,0.5, 1), c(4, 0.2, 3,0.5), type = "variance")

dataGenerator(800, c(0.4, 0.8, 1), c(15, 5, 8), type = "mean", gamma  = 0.95, sigma = 0.4)

dataGenerator(400, c(0.4, 0.9, 1), c(2, 1.5, 3), type = "poisson")

dataGenerator(1000, c(0.44, 0.86, 1), c(0.5, 0.2, 0.4), type = "negbin", size = 3)
</code></pre>

<hr>
<h2 id='Edge'>Edge generation</h2><span id='topic+Edge'></span>

<h3>Description</h3>

<p>Edge creation for gfpop-R-Package graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Edge(
  state1,
  state2,
  type = "null",
  decay = 1,
  gap = 0,
  penalty = 0,
  K = Inf,
  a = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Edge_+3A_state1">state1</code></td>
<td>
<p>a string defining the starting state of the edge</p>
</td></tr>
<tr><td><code id="Edge_+3A_state2">state2</code></td>
<td>
<p>a string defining the ending state of the edge</p>
</td></tr>
<tr><td><code id="Edge_+3A_type">type</code></td>
<td>
<p>a string equal to <code>"null"</code>, <code>"std"</code>, <code>"up"</code>, <code>"down"</code> or <code>"abs"</code>. Default type is <code>"null"</code>,
the transition to stay on the same segment.</p>
</td></tr>
<tr><td><code id="Edge_+3A_decay">decay</code></td>
<td>
<p>a nonnegative number to give the strength of the exponential decay into the segment</p>
</td></tr>
<tr><td><code id="Edge_+3A_gap">gap</code></td>
<td>
<p>a nonnegative number to constrain the size of the gap in the change of state</p>
</td></tr>
<tr><td><code id="Edge_+3A_penalty">penalty</code></td>
<td>
<p>a nonnegative number. The penality associated to this state transition</p>
</td></tr>
<tr><td><code id="Edge_+3A_k">K</code></td>
<td>
<p>a positive number. Threshold for the Biweight robust loss</p>
</td></tr>
<tr><td><code id="Edge_+3A_a">a</code></td>
<td>
<p>a positive number. Slope for the Huber robust loss</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a one-row dataframe with 9 variables
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Edge("Dw", "Up", "up", gap = 1, penalty = 10, K = 3)

Edge(0, 1, "abs", penalty = 2, gap = 1)

Edge(0, 0, "null", penalty = 0, K = 2, a = 1)

Edge("Dw", "Dw", type = "null", decay = 0.997)
</code></pre>

<hr>
<h2 id='gfpop'>Graph-Constrained Functional Pruning Optimal Partitioning (gfpop)</h2><span id='topic+gfpop'></span>

<h3>Description</h3>

<p>Functional pruning optimal partitioning with a graph structure to take
into account constraints on consecutive segment parameters. The user has to specify
the graph he wants to use (see the graph function) and a type of cost function.
This is the main function of the gfpop package. Its result can be plotted using
the S3 gfpop function <code><a href="#topic+plot.gfpop">gfpop::plot()</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gfpop(data, mygraph, type = "mean", weights = NULL, testMode = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gfpop_+3A_data">data</code></td>
<td>
<p>vector of data to segment. For simulation studies, Data can be generated using gfpop package function <code><a href="#topic+dataGenerator">gfpop::dataGenerator()</a></code></p>
</td></tr>
<tr><td><code id="gfpop_+3A_mygraph">mygraph</code></td>
<td>
<p>dataframe of class &quot;graph&quot; to constrain the changepoint inference, see <code><a href="#topic+graph">gfpop::graph()</a></code></p>
</td></tr>
<tr><td><code id="gfpop_+3A_type">type</code></td>
<td>
<p>a string defining the cost model to use: <code>"mean"</code>, <code>"variance"</code>, <code>"poisson"</code>, <code>"exp"</code>, <code>"negbin"</code></p>
</td></tr>
<tr><td><code id="gfpop_+3A_weights">weights</code></td>
<td>
<p>vector of weights (positive numbers), same size as data</p>
</td></tr>
<tr><td><code id="gfpop_+3A_testmode">testMode</code></td>
<td>
<p>boolean. <code>FALSE</code> by default. Used to debug the code</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constrained optimization problem for n data points takes the following general form:
</p>
<p style="text-align: center;"><code class="reqn">Q_n = min (with constraints) (\sum_{t=1}^n (\gamma(e[t])(y[t], \mu[t]) + \beta(e[t]))</code>
</p>

<p>with data points <code class="reqn">y[t]</code>, edges <code class="reqn">e[t]</code>, edge-dependent penalties <code class="reqn">\beta(e[t])</code> and cost functions <code class="reqn">\gamma</code>.
The cost function can take three different forms for parameter x and constants (A, B, C):
</p>

<ul>
<li> <p><em>quadratic</em>, with representation <code class="reqn">Ax^2 + Bx +C</code> with  <code class="reqn">x</code> in R
</p>
</li>
<li> <p><em>log-linear</em>, with representation <code class="reqn">Ax  - B log(x) +C</code> with  <code class="reqn">x \ge 0</code>
</p>
</li>
<li> <p><em>log-log</em>, with representation <code class="reqn">- A log(x) - B log(1-x) +C</code> with  <code class="reqn">0 \le x \le 1</code>
</p>
</li></ul>

<p>For each optimization problem, we consider a unique cost representation.
However, the User can define robustness values (K and a) specific to each edge, making the cost function edge-dependent.
We give the atomic form of each of the five available types (for one data point of value y with weight w)
</p>

<ul>
<li> <p><code>"mean"</code> :  <code class="reqn">A = w</code>, <code class="reqn">B = -2wy</code>, <code class="reqn">C = wy^2</code>
</p>
</li>
<li> <p><code>"variance"</code> : <code class="reqn">A = wy^2</code>, <code class="reqn">B = w</code>, <code class="reqn">C = 0</code>
</p>
</li>
<li> <p><code>"poisson"</code> : <code class="reqn">A = w</code>, <code class="reqn">B = wy</code>, <code class="reqn">C = 0</code>
</p>
</li>
<li> <p><code>"exp"</code> : <code class="reqn">A = wy</code>, <code class="reqn">B = w</code>, <code class="reqn">C = 0</code>
</p>
</li>
<li> <p><code>"negbin"</code> : <code class="reqn">A = w</code>, <code class="reqn">B = wy</code>, <code class="reqn">C = 0</code>
</p>
</li></ul>



<h3>Value</h3>

<p>a gfpop object = (<code>changepoints, states, forced, parameters, globalCost</code>)
</p>

<dl>
<dt><code>changepoints</code></dt><dd><p>is the vector of changepoints (we give the last element of each segment)</p>
</dd>
<dt><code>states</code></dt><dd><p>is the vector giving the state of each segment</p>
</dd>
<dt><code>forced</code></dt><dd><p>is the vector specifying whether the constraints of the graph are active (<code>= TRUE</code>) or not (<code>= FALSE</code>)</p>
</dd>
<dt><code>parameters</code></dt><dd><p>is the vector of successive parameters of each segment</p>
</dd>
<dt><code>globalCost</code></dt><dd><p>is a number equal to the total loss: the minimal cost for the optimization problem with all penalty values excluded</p>
</dd>
</dl>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+dataGenerator">gfpop::dataGenerator()</a></code> to generate data for multiple change-point simulations
</p>
</li>
<li> <p><code><a href="#topic+graph">gfpop::graph()</a></code> to create graphs complying with the gfpop function
</p>
</li>
<li> <p><code><a href="#topic+plot.gfpop">gfpop::plot()</a></code> to plot the gfpop object and visualize inferred changepoints and parameters
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000 #data length
### EXAMPLE 1 ### updown graph + poisson loss
 myData &lt;- dataGenerator(n, c(0.1, 0.3, 0.5, 0.8, 1), c(1, 2, 1, 3, 1), type = "poisson")
 myGraph &lt;- graph(penalty = 2 * sdDiff(myData)^2 * log(n), type = "updown")
 gfpop(data = myData, mygraph = myGraph, type = "poisson")

### EXAMPLE 2 ### relevant graph with min gap = 2 + poisson loss
 myData &lt;- dataGenerator(n, c(0.1, 0.3, 0.5, 0.8, 1), c(1, 2, 3, 5, 3), type = "poisson")
 myGraph &lt;- graph(type = "relevant", penalty = 2 * log(n), gap = 2)
 gfpop(data =  myData, mygraph = myGraph, type = "poisson")

### EXAMPLE 3 ### std graph with robust loss + variance loss
 myData &lt;- dataGenerator(n, c(0.1, 0.3, 0.5, 0.8, 1), c(1, 5, 1, 5, 1), type = "variance")
 outliers &lt;- 5 * rbinom(n, 1, 0.05) - 5 * rbinom(n, 1, 0.05)
### with robust parameter K
 myGraph &lt;- graph(type = "std", penalty = 2 * log(n), K = 10)
 gfpop(data =  myData + outliers, mygraph = myGraph, type = "variance")
### no K
 myGraph &lt;- graph(type = "std", penalty = 2 * log(n))
 gfpop(data =  myData, mygraph = myGraph, type = "variance")

### EXAMPLE 4 ###  3-segment graph with mean (Gaussian) loss
 myData &lt;- dataGenerator(n, c(0.12, 0.31, 0.53, 0.88, 1), c(1, 2, 0, 1, 2), type = "mean")
 outliers &lt;- 5 * rbinom(n, 1, 0.05) - 5 * rbinom(n, 1, 0.05)
 gfpop(data =  myData + outliers, mygraph = paperGraph(8, penalty = 2 * log(n)), type = "mean")
</code></pre>

<hr>
<h2 id='graph'>Graph generation</h2><span id='topic+graph'></span>

<h3>Description</h3>

<p>Graph creation using component functions <code>Edge</code>, <code>StartEnd</code> and <code>Node</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph(
  ...,
  type = "empty",
  decay = 1,
  gap = 0,
  penalty = 0,
  K = Inf,
  a = 0,
  all.null.edges = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="graph_+3A_...">...</code></td>
<td>
<p>This is a list of edges definied by functions <code>Edge</code>, <code>StartEnd</code> and <code>Node</code>. See gfpop functions <code><a href="#topic+Edge">gfpop::Edge()</a></code>, <code><a href="#topic+StartEnd">gfpop::StartEnd()</a></code> and  <code><a href="#topic+Node">gfpop::Node()</a></code></p>
</td></tr>
<tr><td><code id="graph_+3A_type">type</code></td>
<td>
<p>a string equal to <code>"std"</code>, <code>"isotonic"</code>, <code>"updown"</code> or <code>"relevant"</code> to build a predefined classic graph</p>
</td></tr>
<tr><td><code id="graph_+3A_decay">decay</code></td>
<td>
<p>a nonnegative number to give the strength of the exponential decay into the segment</p>
</td></tr>
<tr><td><code id="graph_+3A_gap">gap</code></td>
<td>
<p>a nonnegative number to constrain the size of the gap in the change of state</p>
</td></tr>
<tr><td><code id="graph_+3A_penalty">penalty</code></td>
<td>
<p>a nonnegative number equals to the common penalty to use for all edges</p>
</td></tr>
<tr><td><code id="graph_+3A_k">K</code></td>
<td>
<p>a positive number. Threshold for the Biweight robust loss</p>
</td></tr>
<tr><td><code id="graph_+3A_a">a</code></td>
<td>
<p>a positive number. Slope for the Huber robust loss</p>
</td></tr>
<tr><td><code id="graph_+3A_all.null.edges">all.null.edges</code></td>
<td>
<p>a boolean. Add null edges to all nodes automatically</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a dataframe with 9 variables :
columns are named <code>"state1"</code>, <code>"state2"</code>, <code>"type"</code>, <code>"parameter"</code>, <code>"penalty"</code>, <code>"K"</code>, <code>"a"</code>, <code>"min"</code>, <code>"max"</code> with additional <code>"graph"</code> class.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>graph(type = "updown", gap = 1.3, penalty = 5)

graph(Edge("Dw","Dw"),
      Edge("Up","Up"),
      Edge("Dw","Up","up", gap = 0.5, penalty = 10),
      Edge("Up","Dw","down"),
      StartEnd("Dw","Dw"),
      Node("Dw",0,1),
      Node("Up",0,1))

graph(Edge("1", "2", type = "std"),
      Edge("2", "3", type = "std"),
      Edge("3", "4", type = "std"),
      StartEnd(start = "1", end = "4"),
      all.null.edges = TRUE)
</code></pre>

<hr>
<h2 id='itergfpop'>Graph-constrained functional pruning optimal partitioning iterated</h2><span id='topic+itergfpop'></span>

<h3>Description</h3>

<p>Functional pruning optimal partitioning with a graph structure to take into account constraints on consecutive segment parameters.
This is an iterated version of the main gfpop function using a Birgé Massart like penalty
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itergfpop(
  data,
  mygraph,
  type = "mean",
  weights = NULL,
  iter.max = 100,
  D.init = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itergfpop_+3A_data">data</code></td>
<td>
<p>vector of data to segment. For simulation studies, Data can be generated using gfpop package function <code><a href="#topic+dataGenerator">gfpop::dataGenerator()</a></code></p>
</td></tr>
<tr><td><code id="itergfpop_+3A_mygraph">mygraph</code></td>
<td>
<p>dataframe of class &quot;graph&quot; to constrain the changepoint inference, see <code><a href="#topic+graph">gfpop::graph()</a></code></p>
</td></tr>
<tr><td><code id="itergfpop_+3A_type">type</code></td>
<td>
<p>a string defining the cost model to use: <code>"mean"</code>, <code>"variance"</code>, <code>"poisson"</code>, <code>"exp"</code>, <code>"negbin"</code></p>
</td></tr>
<tr><td><code id="itergfpop_+3A_weights">weights</code></td>
<td>
<p>vector of weights (positive numbers), same size as data</p>
</td></tr>
<tr><td><code id="itergfpop_+3A_iter.max">iter.max</code></td>
<td>
<p>maximal number of iteration of the gfpop function</p>
</td></tr>
<tr><td><code id="itergfpop_+3A_d.init">D.init</code></td>
<td>
<p>initialisation of the number of segments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a gfpop object = (<code>changepoints, states, forced, parameters, globalCost</code>)
</p>

<dl>
<dt><code>changepoints</code></dt><dd><p>is the vector of changepoints (we give the last element of each segment)</p>
</dd>
<dt><code>states</code></dt><dd><p>is the vector giving the state of each segment</p>
</dd>
<dt><code>forced</code></dt><dd><p>is the vector specifying whether the constraints of the graph are active (<code>= TRUE</code>) or not (<code>= FALSE</code>)</p>
</dd>
<dt><code>parameters</code></dt><dd><p>is the vector of successive parameters of each segment</p>
</dd>
<dt><code>globalCost</code></dt><dd><p>is a number equal to the total loss: the minimal cost for the optimization problem with all penalty values excluded</p>
</dd>
<dt><code>Dvect</code></dt><dd><p>is a vector of integers. The successive tested D in the Birgé Massart penalty until convergence</p>
</dd>
</dl>


<hr>
<h2 id='Node'>Node Values</h2><span id='topic+Node'></span>

<h3>Description</h3>

<p>Constrain the range of values to consider at a node
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Node(state = NULL, min = -Inf, max = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Node_+3A_state">state</code></td>
<td>
<p>a string defining the state to constrain</p>
</td></tr>
<tr><td><code id="Node_+3A_min">min</code></td>
<td>
<p>minimal value for the inferred parameter</p>
</td></tr>
<tr><td><code id="Node_+3A_max">max</code></td>
<td>
<p>maximal value for the inferred parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a dataframe with 9 variables with only <code>state1</code>, <code>min</code> and <code>max</code> defined (not <code>NA</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Node(state = "s0", min = 0, max = 2)

Node(state = 0, min = -1, max = 1)

Node(state = "positive", min = 0)

Node(state = "mu0", min = 0.5, max = 0.5)
</code></pre>

<hr>
<h2 id='paperGraph'>Graphs of our paper in JSS</h2><span id='topic+paperGraph'></span>

<h3>Description</h3>

<p>Graphs of our paper in JSS (Journal of Statistical Software)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paperGraph(nb, penalty = 0, decay = 1, gap = 0, oneValue = 0, K = Inf, a = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paperGraph_+3A_nb">nb</code></td>
<td>
<p>the number of the Figure in paper</p>
</td></tr>
<tr><td><code id="paperGraph_+3A_penalty">penalty</code></td>
<td>
<p>the penalty to use for change-point</p>
</td></tr>
<tr><td><code id="paperGraph_+3A_decay">decay</code></td>
<td>
<p>a nonnegative number to give the strength of the exponential decay into the segment</p>
</td></tr>
<tr><td><code id="paperGraph_+3A_gap">gap</code></td>
<td>
<p>a nonnegative number to constrain the size of the gap in the change of state</p>
</td></tr>
<tr><td><code id="paperGraph_+3A_onevalue">oneValue</code></td>
<td>
<p>the value for parameter when we consider the collective anomalies problem</p>
</td></tr>
<tr><td><code id="paperGraph_+3A_k">K</code></td>
<td>
<p>a positive number. Threshold for the Biweight robust loss</p>
</td></tr>
<tr><td><code id="paperGraph_+3A_a">a</code></td>
<td>
<p>a positive number. Slope for the Huber robust loss</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a dataframe with 9 variables :
columns are named <code>"state1"</code>, <code>"state2"</code>, <code>"type"</code>, <code>"parameter"</code>, <code>"penalty"</code>, <code>"K"</code>, <code>"a"</code>, <code>"min"</code>, <code>"max"</code> with additional <code>"graph"</code> class.
</p>

<hr>
<h2 id='plot.gfpop'>plot.gfpop</h2><span id='topic+plot.gfpop'></span>

<h3>Description</h3>

<p>Plotting inferred segment parameters (the result of gfpop) and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gfpop'
plot(x, ..., data, multiple = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gfpop_+3A_x">x</code></td>
<td>
<p>a gfpop class object</p>
</td></tr>
<tr><td><code id="plot.gfpop_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
<tr><td><code id="plot.gfpop_+3A_data">data</code></td>
<td>
<p>the data from which we get the gfpop result</p>
</td></tr>
<tr><td><code id="plot.gfpop_+3A_multiple">multiple</code></td>
<td>
<p>if <code>TRUE</code> we plot data and the model on different graphs.
Only with <code>"mean"</code> and <code>"poisson"</code> cost functions (as in that case the parameter
values represent the data mean value over each segment) we allow the User
to plot signal and data on a single graph.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot data and the inferred gfpop segments
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000 #data length
data &lt;- dataGenerator(n, c(0.3, 0.4, 0.7, 0.95, 1), c(1, 3, 1, -1, 4), "mean", sigma = 3)
myGraph &lt;- graph(type = "relevant", gap = 0.5, penalty = 2 * sdDiff(data) ^ 2 * log(n))
g &lt;- gfpop(data, myGraph, type = "mean")
plot(x = g, data = data, multiple = FALSE)

data &lt;- dataGenerator(n, c(0.4, 0.8, 1), c(1, 1.7, 2.3), "exp")
g &lt;- gfpop(data,graph(type = "isotonic", penalty = 2 * sdDiff(data) ^ 2 * log(n)), type = "exp")
plot(x = g, data = data, multiple = TRUE)

data &lt;- dataGenerator(n, c(0.22, 0.75, 1), c(1.4,1,0.8), "poisson")
g &lt;- gfpop(data, paperGraph(8), type = "poisson")
plot(x = g, data = data, multiple = TRUE)
</code></pre>

<hr>
<h2 id='print.gfpop'>print.gfpop</h2><span id='topic+print.gfpop'></span>

<h3>Description</h3>

<p>Printing the resulting change-point model found by gfpop function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gfpop'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.gfpop_+3A_x">x</code></td>
<td>
<p>a gfpop class object</p>
</td></tr>
<tr><td><code id="print.gfpop_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>print the gfpop object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000 #data length
data &lt;- dataGenerator(n, c(0.3, 0.4, 0.7, 0.95, 1), c(1, 3, 1, -1, 4), "mean", sigma = 3)
myGraph &lt;- graph(type = "relevant", gap = 0.5, penalty = 2 * sdDiff(data) ^ 2 * log(n))
g &lt;- gfpop(data, myGraph, type = "mean")
print(g)
</code></pre>

<hr>
<h2 id='sdDiff'>sdDiff</h2><span id='topic+sdDiff'></span>

<h3>Description</h3>

<p>sdDiff is a function based on the difference operator (or difference order for HALL method) estimating the time-series standard deviation.
The estimation works for time-series generated by Gaussian
random variables with constant standard deviation and multiple changes in mean.
Three estimators are available:
</p>

<ul>
<li> <p><code>HALL</code> : the so-called HALL-estimator of order 3. For more details see: <em>(1990) Asymptotically optimal difference-based estimation of variance in nonparametric regression. Authors: Hall, Peter and Kay, JW and Titterinton, DM. Biometrika, pages 521&ndash;528</em>
</p>
</li>
<li> <p><code>MAD</code> : the median absolute deviation estimator computed on <code>diff(x)/sqrt(2)</code> with x the vector of datapoints
</p>
</li>
<li> <p><code>SD</code> : the standard deviation estimator (function sd) computed on <code>diff(x)/sqrt(2)</code> with x the vector of datapoints
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>sdDiff(x, method = "HALL")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdDiff_+3A_x">x</code></td>
<td>
<p>vector of datapoints</p>
</td></tr>
<tr><td><code id="sdDiff_+3A_method">method</code></td>
<td>
<p>Three available methods: <code>"HALL"</code>, <code>"MAD"</code> and <code>"SD"</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a value equal to the estimated standard deviation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- dataGenerator(300, seq(0.1,1,0.1), sample(10), sigma = 2)
sdDiff(data, method = "HALL")
sdDiff(data, method = "MAD")
sdDiff(data, method = "SD")
</code></pre>

<hr>
<h2 id='StartEnd'>Start and End nodes for the graph</h2><span id='topic+StartEnd'></span>

<h3>Description</h3>

<p>Defining the beginning and ending states of a graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StartEnd(start = NULL, end = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StartEnd_+3A_start">start</code></td>
<td>
<p>a vector of states. The beginning nodes for the changepoint inference</p>
</td></tr>
<tr><td><code id="StartEnd_+3A_end">end</code></td>
<td>
<p>a vector of states. The ending nodes for the changepoint inference</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataframe with 9 variables with only <code>state1</code> and <code>type = "start"</code> or <code>"end"</code> defined (not <code>NA</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StartEnd(start = "A", end = c("A","B"))

StartEnd(start = 0)

StartEnd(start = 1, end = 1)

StartEnd(start = "v0", end = "v3")

StartEnd(end = "s0")
</code></pre>

<hr>
<h2 id='summary.gfpop'>summary.gfpop</h2><span id='topic+summary.gfpop'></span>

<h3>Description</h3>

<p>Returns all information contains in gfpop object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gfpop'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.gfpop_+3A_object">object</code></td>
<td>
<p>a gfpop class object</p>
</td></tr>
<tr><td><code id="summary.gfpop_+3A_...">...</code></td>
<td>
<p>Other parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>summary of gfpop object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000 #data length
data &lt;- dataGenerator(n, c(0.3, 0.4, 0.7, 0.95, 1), c(1, 3, 1, -1, 4), "mean", sigma = 3)
myGraph &lt;- graph(type = "relevant", gap = 0.5, penalty = 2 * sdDiff(data) ^ 2 * log(n))
g &lt;- gfpop(data, myGraph, type = "mean")
summary(g)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
