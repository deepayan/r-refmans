<!DOCTYPE html><html lang="en"><head><title>Help for package sgs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sgs}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#sgs-package'><p>sgs: Sparse-Group SLOPE: Adaptive Bi-Level Selection with FDR Control</p></a></li>
<li><a href='#arma_mv'><p>Matrix Product in RcppArmadillo.</p></a></li>
<li><a href='#arma_sparse'><p>Matrix Product in RcppArmadillo.</p></a></li>
<li><a href='#as_sgs'><p>Fits the adaptively scaled SGS model (AS-SGS).</p></a></li>
<li><a href='#atos'><p>Adaptive three operator splitting (ATOS).</p></a></li>
<li><a href='#coef.sgs'><p>Extracts coefficients for one of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p></a></li>
<li><a href='#fit_goscar'><p>Fit a gOSCAR model.</p></a></li>
<li><a href='#fit_goscar_cv'><p>Fit a gOSCAR model using k-fold cross-validation.</p></a></li>
<li><a href='#fit_gslope'><p>Fit a gSLOPE model.</p></a></li>
<li><a href='#fit_gslope_cv'><p>Fit a gSLOPE model using k-fold cross-validation.</p></a></li>
<li><a href='#fit_sgo'><p>Fit an SGO model.</p></a></li>
<li><a href='#fit_sgo_cv'><p>Fit an SGO model using k-fold cross-validation.</p></a></li>
<li><a href='#fit_sgs'><p>Fit an SGS model.</p></a></li>
<li><a href='#fit_sgs_cv'><p>Fit an SGS model using k-fold cross-validation.</p></a></li>
<li><a href='#gen_pens'><p>Generate penalty sequences for SGS.</p></a></li>
<li><a href='#gen_toy_data'><p>Generate toy data.</p></a></li>
<li><a href='#plot.sgs'><p>Plot models of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p></a></li>
<li><a href='#predict.sgs'><p>Predict using one of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p></a></li>
<li><a href='#print.sgs'><p>Prints information for one of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p></a></li>
<li><a href='#scaled_sgs'><p>Fits a scaled SGS model.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Sparse-Group SLOPE: Adaptive Bi-Level Selection with FDR Control</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-04</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fabio Feser &lt;ff120@ic.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of Sparse-group SLOPE (SGS) (Feser and Evangelou (2023) &lt;<a href="https://doi.org/10.48550%2FarXiv.2305.09467">doi:10.48550/arXiv.2305.09467</a>&gt;) models. Linear and logistic regression models are supported, both of which can be fit using k-fold cross-validation. Dense and sparse input matrices are supported. In addition, a general Adaptive Three Operator Splitting (ATOS) (Pedregosa and Gidel (2018) &lt;<a href="https://doi.org/10.48550%2FarXiv.1804.02339">doi:10.48550/arXiv.1804.02339</a>&gt;) implementation is provided. Group SLOPE (gSLOPE) (Brzyski et al. (2019) &lt;<a href="https://doi.org/10.1080%2F01621459.2017.1411269">doi:10.1080/01621459.2017.1411269</a>&gt;) and group-based OSCAR models (Feser and Evangelou (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2405.15357">doi:10.48550/arXiv.2405.15357</a>&gt;) are also implemented. All models are available with strong screening rules (Feser and Evangelou (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2405.15357">doi:10.48550/arXiv.2405.15357</a>&gt;) for computational speed-up.</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, MASS, caret, grDevices, graphics, methods, stats,
SLOPE, Rlab, Rcpp (&ge; 1.0.10)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Suggests:</td>
<td>SGL, gglasso, glmnet, testthat, knitr, grpSLOPE, rmarkdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ff1201/sgs">https://github.com/ff1201/sgs</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ff1201/sgs/issues">https://github.com/ff1201/sgs/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-04 16:03:00 UTC; ff120</td>
</tr>
<tr>
<td>Author:</td>
<td>Fabio Feser <a href="https://orcid.org/0009-0007-3088-9727"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-04 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='sgs-package'>sgs: Sparse-Group SLOPE: Adaptive Bi-Level Selection with FDR Control</h2><span id='topic+sgs'></span><span id='topic+sgs-package'></span>

<h3>Description</h3>

<p>Implementation of Sparse-group SLOPE (SGS) (Feser and Evangelou (2023) <a href="https://doi.org/10.48550/arXiv.2305.09467">doi:10.48550/arXiv.2305.09467</a>) models. Linear and logistic regression models are supported, both of which can be fit using k-fold cross-validation. Dense and sparse input matrices are supported. In addition, a general Adaptive Three Operator Splitting (ATOS) (Pedregosa and Gidel (2018) <a href="https://doi.org/10.48550/arXiv.1804.02339">doi:10.48550/arXiv.1804.02339</a>) implementation is provided. Group SLOPE (gSLOPE) (Brzyski et al. (2019) <a href="https://doi.org/10.1080/01621459.2017.1411269">doi:10.1080/01621459.2017.1411269</a>) and group-based OSCAR models (Feser and Evangelou (2024) <a href="https://doi.org/10.48550/arXiv.2405.15357">doi:10.48550/arXiv.2405.15357</a>) are also implemented. All models are available with strong screening rules (Feser and Evangelou (2024) <a href="https://doi.org/10.48550/arXiv.2405.15357">doi:10.48550/arXiv.2405.15357</a>) for computational speed-up.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Fabio Feser <a href="mailto:ff120@ic.ac.uk">ff120@ic.ac.uk</a> (<a href="https://orcid.org/0009-0007-3088-9727">ORCID</a>)
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/ff1201/sgs">https://github.com/ff1201/sgs</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/ff1201/sgs/issues">https://github.com/ff1201/sgs/issues</a>
</p>
</li></ul>


<hr>
<h2 id='arma_mv'>Matrix Product in RcppArmadillo.</h2><span id='topic+arma_mv'></span>

<h3>Description</h3>

<p>Matrix Product in RcppArmadillo.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arma_mv(m, v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="arma_mv_+3A_m">m</code></td>
<td>
<p>numeric matrix</p>
</td></tr>
<tr><td><code id="arma_mv_+3A_v">v</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix product of m and v
</p>

<hr>
<h2 id='arma_sparse'>Matrix Product in RcppArmadillo.</h2><span id='topic+arma_sparse'></span>

<h3>Description</h3>

<p>Matrix Product in RcppArmadillo.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>arma_sparse(m, v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="arma_sparse_+3A_m">m</code></td>
<td>
<p>numeric sparse matrix</p>
</td></tr>
<tr><td><code id="arma_sparse_+3A_v">v</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix product of m and v
</p>

<hr>
<h2 id='as_sgs'>Fits the adaptively scaled SGS model (AS-SGS).</h2><span id='topic+as_sgs'></span>

<h3>Description</h3>

<p>Fits an SGS model using the noise estimation procedure, termed adaptively scaled SGS (Algorithm 2 from Feser and Evangelou (2023)).
This adaptively estimates <code class="reqn">\lambda</code> and then fits the model using the estimated value. It is an alternative approach to
cross-validation (<code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>). The approach is only compatible with the SGS penalties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_sgs(
  X,
  y,
  groups,
  type = "linear",
  pen_method = 2,
  alpha = 0.95,
  vFDR = 0.1,
  gFDR = 0.1,
  standardise = "l2",
  intercept = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="as_sgs_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_pen_method">pen_method</code></td>
<td>
<p>The type of penalty sequences to use.
</p>

<ul>
<li> <p><code>"1"</code> uses the vMean and gMean SGS sequences.
</p>
</li>
<li> <p><code>"2"</code> uses the vMax and gMax SGS sequences.
</p>
</li></ul>
</td></tr>
<tr><td><code id="as_sgs_+3A_alpha">alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between SLOPE and gSLOPE. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_vfdr">vFDR</code></td>
<td>
<p>Defines the desired variable false discovery rate (FDR) level, which determines the shape of the variable penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_gfdr">gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the group penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="as_sgs_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="as_sgs_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type <code>"sgs"</code> containing model fit information (see <code><a href="#topic+fit_sgs">fit_sgs()</a></code>).
</p>


<h3>References</h3>

<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scaled_sgs">scaled_sgs()</a></code>
</p>
<p>Other model-selection: 
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>

<hr>
<h2 id='atos'>Adaptive three operator splitting (ATOS).</h2><span id='topic+atos'></span>

<h3>Description</h3>

<p>Function for fitting adaptive three operator splitting (ATOS) with general convex penalties. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>atos(
  X,
  y,
  type = "linear",
  prox_1,
  prox_2,
  pen_prox_1 = 0.5,
  pen_prox_2 = 0.5,
  max_iter = 5000,
  backtracking = 0.7,
  max_iter_backtracking = 100,
  tol = 1e-05,
  prox_1_opts = NULL,
  prox_2_opts = NULL,
  standardise = "l2",
  intercept = TRUE,
  x0 = NULL,
  u = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="atos_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package)</p>
</td></tr>
<tr><td><code id="atos_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> needs to be continuous and for <code>type="logistic"</code> needs to be a binary variable.</p>
</td></tr>
<tr><td><code id="atos_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="atos_+3A_prox_1">prox_1</code></td>
<td>
<p>The proximal operator for the first function, <code class="reqn">h(x)</code>.</p>
</td></tr>
<tr><td><code id="atos_+3A_prox_2">prox_2</code></td>
<td>
<p>The proximal operator for the second function, <code class="reqn">g(x)</code>.</p>
</td></tr>
<tr><td><code id="atos_+3A_pen_prox_1">pen_prox_1</code></td>
<td>
<p>The penalty for the first proximal operator. For the lasso, this would be the sparsity parameter, <code class="reqn">\lambda</code>. If operator does not include a penalty, set to 1.</p>
</td></tr>
<tr><td><code id="atos_+3A_pen_prox_2">pen_prox_2</code></td>
<td>
<p>The penalty for the second proximal operator.</p>
</td></tr>
<tr><td><code id="atos_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="atos_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="atos_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="atos_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="atos_+3A_prox_1_opts">prox_1_opts</code></td>
<td>
<p>Optional argument for first proximal operator. For the group lasso, this would be the group IDs. Note: this must be inserted as a list.</p>
</td></tr>
<tr><td><code id="atos_+3A_prox_2_opts">prox_2_opts</code></td>
<td>
<p>Optional argument for second proximal operator.</p>
</td></tr>
<tr><td><code id="atos_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="atos_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="atos_+3A_x0">x0</code></td>
<td>
<p>Optional initial vector for <code class="reqn">x_0</code>.</p>
</td></tr>
<tr><td><code id="atos_+3A_u">u</code></td>
<td>
<p>Optional initial vector for <code class="reqn">u</code>.</p>
</td></tr>
<tr><td><code id="atos_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>atos()</code> solves convex minimization problems of the form
</p>
<p style="text-align: center;"><code class="reqn">
  f(x) + g(x) + h(x),
</code>
</p>

<p>where <code class="reqn">f</code> is convex and differentiable with <code class="reqn">L_f</code>-Lipschitz gradient, and <code class="reqn">g</code> and <code class="reqn">h</code> are both convex.
The algorithm is not symmetrical, but usually the difference between variations are only small numerical values, which are filtered out.
However, both variations should be checked regardless, by looking at <code>x</code> and <code>u</code>. An example for the sparse-group lasso (SGL) is given.
</p>


<h3>Value</h3>

<p>An object of class <code>"atos"</code> containing:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>The fitted values from the regression. Taken to be the more stable fit between <code>x</code> and <code>u</code>, which is usually the former.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The solution to the original problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The solution to the dual problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>The updated values from applying the first proximal operator (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td></tr>
<tr><td><code>success</code></td>
<td>
<p>Logical flag indicating whether ATOS converged, according to <code>tol</code>.</p>
</td></tr>
<tr><td><code>num_it</code></td>
<td>
<p>Number of iterations performed. If convergence is not reached, this will be <code>max_iter</code>.</p>
</td></tr>
<tr><td><code>certificate</code></td>
<td>
<p>Final value of convergence criteria.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Logical flag indicating whether an intercept was fit.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Pedregosa, F., Gidel, G. (2018). <em>Adaptive Three Operator Splitting</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>

<hr>
<h2 id='coef.sgs'>Extracts coefficients for one of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</h2><span id='topic+coef.sgs'></span>

<h3>Description</h3>

<p>Print the coefficients using model fitted with one of the following functions: <code><a href="#topic+fit_sgs">fit_sgs()</a></code>, <code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>, <code><a href="#topic+fit_gslope">fit_gslope()</a></code>, <code><a href="#topic+fit_gslope_cv">fit_gslope_cv()</a></code>, <code><a href="#topic+fit_sgo">fit_sgo()</a></code>, <code><a href="#topic+fit_sgo_cv">fit_sgo_cv()</a></code>, <code><a href="#topic+fit_goscar">fit_goscar()</a></code>, <code><a href="#topic+fit_goscar_cv">fit_goscar_cv()</a></code>.
The predictions are calculated for each <code>"lambda"</code> value in the path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgs'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.sgs_+3A_object">object</code></td>
<td>
<p>Object of one of the following classes: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p>
</td></tr>
<tr><td><code id="coef.sgs_+3A_...">...</code></td>
<td>
<p>further arguments passed to stats function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The fitted coefficients
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_sgs">fit_sgs()</a></code>, <code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>, <code><a href="#topic+fit_gslope">fit_gslope()</a></code>, <code><a href="#topic+fit_gslope_cv">fit_gslope_cv()</a></code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>
<p>Other gSLOPE-methods: 
<code><a href="#topic+fit_goscar">fit_goscar</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope">fit_gslope</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGS 
model = fit_sgs(X = data$X, y = data$y, groups = groups, type="linear", lambda = 1, alpha=0.95, 
vFDR=0.1, gFDR=0.1, standardise = "l2", intercept = TRUE, verbose=FALSE)
# use predict function
model_coef = coef(model)
</code></pre>

<hr>
<h2 id='fit_goscar'>Fit a gOSCAR model.</h2><span id='topic+fit_goscar'></span>

<h3>Description</h3>

<p>Group OSCAR (gOSCAR) main fitting function. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_goscar(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  max_iter = 5000,
  backtracking = 0.7,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_goscar_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>min_frac</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_goscar_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/\sqrt{n}</code>.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/n</code>.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_goscar_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_goscar_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code>. To void this behaviour, set <code class="reqn">\lambda = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fit_goscar()</code> fits a gOSCAR model (Feser and Evangelou (2024)) using adaptive three operator splitting (ATOS). gOSCAR uses the same model set-up as for gSLOPE, but with different weights (see Bao et al. (2020) and Feser and Evangelou (2024)).
The penalties are given by (for a group <code class="reqn">g</code> with <code class="reqn">m</code> groups):
</p>
<p style="text-align: center;"><code class="reqn">
 w_g = \sigma_1 + \sigma_3(m-g),
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
     \sigma_1 = d_i\|X^\intercal y\|_\infty, \; \sigma_3 = \sigma_1/m.
</code>
</p>



<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>The fitted values from the regression. Taken to be the more stable fit between <code>x</code> and <code>z</code>, which is usually the former. A filter is applied to remove very small values, where ATOS has not been able to shrink exactly to zero. Check this against <code>x</code> and <code>z</code>.</p>
</td></tr>
<tr><td><code>group_effects</code></td>
<td>
<p>The group values from the regression. Taken by applying the <code class="reqn">\ell_2</code> norm within each group on <code>beta</code>.</p>
</td></tr>
<tr><td><code>selected_var</code></td>
<td>
<p>A list containing the indicies of the active/selected variables for each <code>"lambda"</code> value. Index 1 corresponds to the first column in X.</p>
</td></tr>
<tr><td><code>selected_grp</code></td>
<td>
<p>A list containing the indicies of the active/selected groups for each <code>"lambda"</code> value. Index 1 corresponds to the first group in the <code>groups</code> vector. You can see the group order by running <code>unique(groups)</code>.</p>
</td></tr>
<tr><td><code>num_it</code></td>
<td>
<p>Number of iterations performed. If convergence is not reached, this will be <code>max_iter</code>.</p>
</td></tr>
<tr><td><code>success</code></td>
<td>
<p>Logical flag indicating whether ATOS converged, according to <code>tol</code>.</p>
</td></tr>
<tr><td><code>certificate</code></td>
<td>
<p>Final value of convergence criteria.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The solution to the original problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The solution to the dual problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>The updated values from applying the first proximal operator (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>screen_set</code></td>
<td>
<p>List of groups that were kept after screening step for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{S}</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>epsilon_set</code></td>
<td>
<p>List of groups that were used for fitting after screening for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{E}</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>kkt_violations</code></td>
<td>
<p>List of groups that violated the KKT conditions each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{K}</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>pen_gslope</code></td>
<td>
<p>Vector of the group penalty sequence.</p>
</td></tr>
<tr><td><code>screen</code></td>
<td>
<p>Logical flag indicating whether screening was applied.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Logical flag indicating whether an intercept was fit.</p>
</td></tr>
<tr><td><code>standardise</code></td>
<td>
<p>Type of standardisation used.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Value(s) of <code class="reqn">\lambda</code> used to fit the model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bao, R., Gu B., Huang, H. (2020). <em>Fast OSCAR and OWL Regression via Safe Screening Rules</em>, <a href="https://proceedings.mlr.press/v119/bao20b">https://proceedings.mlr.press/v119/bao20b</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>
<p>Pedregosa, F., Gidel, G. (2018). <em>Adaptive Three Operator Splitting</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p>Other gSLOPE-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope">fit_gslope</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run gOSCAR 
model = fit_goscar(X = data$X, y = data$y, groups = groups, type="linear", path_length = 5, 
standardise = "l2", intercept = TRUE, verbose=FALSE)
</code></pre>

<hr>
<h2 id='fit_goscar_cv'>Fit a gOSCAR model using k-fold cross-validation.</h2><span id='topic+fit_goscar_cv'></span>

<h3>Description</h3>

<p>Function to fit a pathwise solution of group OSCAR (gOSCAR) models using k-fold cross-validation. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_goscar_cv(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  nfolds = 10,
  backtracking = 0.7,
  max_iter = 5000,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  error_criteria = "mse",
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_goscar_cv_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to use in cross-validation.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_error_criteria">error_criteria</code></td>
<td>
<p>The criteria used to discriminate between models along the path. Supported values are: <code>"mse"</code> (mean squared error) and <code>"mae"</code> (mean absolute error).</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_goscar_cv_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code>. To void this behaviour, set <code class="reqn">\lambda = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fits gOSCAR models under a pathwise solution using adaptive three operator splitting (ATOS), picking the 1se model as optimum. Warm starts are implemented.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>errors</code></td>
<td>
<p>A table containing fitting information about the models on the path.</p>
</td></tr>
<tr><td><code>all_models</code></td>
<td>
<p>Fitting information for all models fit on the path, which is a <code>"gslope"</code> object type.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>The 1se chosen model, which is a <code>"gslope"</code> object type.</p>
</td></tr>
<tr><td><code>best_lambda</code></td>
<td>
<p>The value of <code class="reqn">\lambda</code> which generated the chosen model.</p>
</td></tr>
<tr><td><code>best_lambda_id</code></td>
<td>
<p>The path index for the chosen model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bao, R., Gu B., Huang, H. (2020). <em>Fast OSCAR and OWL Regression via Safe Screening Rules</em>, <a href="https://proceedings.mlr.press/v119/bao20b">https://proceedings.mlr.press/v119/bao20b</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_goscar">fit_goscar()</a></code>
</p>
<p>Other gSLOPE-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_goscar">fit_goscar</a>()</code>,
<code><a href="#topic+fit_gslope">fit_gslope</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>
<p>Other model-selection: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run gOSCAR with cross-validation
cv_model = fit_goscar_cv(X = data$X, y = data$y, groups=groups, type = "linear", path_length = 5, 
nfolds=5, min_frac = 0.05, standardise="l2",intercept=TRUE,verbose=TRUE)
</code></pre>

<hr>
<h2 id='fit_gslope'>Fit a gSLOPE model.</h2><span id='topic+fit_gslope'></span>

<h3>Description</h3>

<p>Group SLOPE (gSLOPE) main fitting function. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_gslope(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  gFDR = 0.1,
  pen_method = 1,
  max_iter = 5000,
  backtracking = 0.7,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_gslope_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_gslope_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_gfdr">gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the group penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_pen_method">pen_method</code></td>
<td>
<p>The type of penalty sequences to use (see Brzyski et al. (2019)):
</p>

<ul>
<li> <p><code>"1"</code> uses the gMean gSLOPE sequence.
</p>
</li>
<li> <p><code>"2"</code> uses the gMax gSLOPE sequence.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_gslope_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/\sqrt{n}</code>.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/n</code>.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_gslope_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_gslope_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the penalties from <code>pen_method</code> if specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code>. To void this behaviour, set <code class="reqn">\lambda = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fit_gslope()</code> fits a gSLOPE model (Brzyski et al. (2019)) using adaptive three operator splitting (ATOS). gSLOPE is a sparse-group method, so that it selects both variables and groups. Unlike group selection approaches, not every variable within a group is set as active.
It solves the convex optimisation problem given by
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{2n} f(b ; y, \mathbf{X}) + \lambda \sum_{g=1}^{m}w_g \sqrt{p_g} \|b^{(g)}\|_2,
</code>
</p>

<p>where the penalty sequences are sorted and <code class="reqn">f(\cdot)</code> is the loss function. In the case of the linear model, the loss function is given by the mean-squared error loss:
</p>
<p style="text-align: center;"><code class="reqn">
 f(b; y, \mathbf{X}) = \left\|y-\mathbf{X}b \right\|_2^2.
</code>
</p>

<p>In the logistic model, the loss function is given by
</p>
<p style="text-align: center;"><code class="reqn">
f(b;y,\mathbf{X})=-1/n \log(\mathcal{L}(b; y, \mathbf{X})).
</code>
</p>

<p>where the log-likelihood is given by
</p>
<p style="text-align: center;"><code class="reqn">
 \mathcal{L}(b; y, \mathbf{X}) = \sum_{i=1}^{n}\left\{y_i b^\intercal x_i - \log(1+\exp(b^\intercal x_i)) \right\}.
</code>
</p>

<p>The penalty parameters in gSLOPE are sorted so that the largest group effects are matched with the largest penalties, to reduce the group FDR.
The gMean sequence (<code>pen_method=1</code>) is given by
</p>
<p style="text-align: center;"><code class="reqn">
 w_i^\text{mean} = \overline{F}^{-1}_{\chi_{p_j}} (1-q_gi/m),  \; i = 1,\dots,m,
\text{where} \; \overline{F}_{\chi_{p_j}}(x):= \frac{1}{m}\sum_{j=1}^{m}F_{\chi_{p_j}}(\sqrt{p_j}x),
</code>
</p>

<p>where <code class="reqn">F_{\chi_{p_j}}</code> is the cumulative distribution function of a <code class="reqn">\chi</code> distribution with <code class="reqn">p_j</code> degrees of freedom. The gMax sequence (<code>pen_method=2</code>) is given by
</p>
<p style="text-align: center;"><code class="reqn">
 w_i^{\text{max}} = \max_{j=1,\ldots,m} \left\{ \frac{1}{\sqrt{p_j}} F^{-1}_{\chi_{p_j}} \left( 1 - \frac{q_g i}{m} \right) \right\},
</code>
</p>

<p>where <code class="reqn">F_{\chi_{p_j}}</code> is the cumulative distribution function of a <code class="reqn">\chi</code> distribution with <code class="reqn">p_j</code> degrees of freedom.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>The fitted values from the regression. Taken to be the more stable fit between <code>x</code> and <code>z</code>, which is usually the former. A filter is applied to remove very small values, where ATOS has not been able to shrink exactly to zero. Check this against <code>x</code> and <code>z</code>.</p>
</td></tr>
<tr><td><code>group_effects</code></td>
<td>
<p>The group values from the regression. Taken by applying the <code class="reqn">\ell_2</code> norm within each group on <code>beta</code>.</p>
</td></tr>
<tr><td><code>selected_var</code></td>
<td>
<p>A list containing the indicies of the active/selected variables for each <code>"lambda"</code> value. Index 1 corresponds to the first column in X.</p>
</td></tr>
<tr><td><code>selected_grp</code></td>
<td>
<p>A list containing the indicies of the active/selected groups for each <code>"lambda"</code> value. Index 1 corresponds to the first group in the <code>groups</code> vector. You can see the group order by running <code>unique(groups)</code>.</p>
</td></tr>
<tr><td><code>num_it</code></td>
<td>
<p>Number of iterations performed. If convergence is not reached, this will be <code>max_iter</code>.</p>
</td></tr>
<tr><td><code>success</code></td>
<td>
<p>Logical flag indicating whether ATOS converged, according to <code>tol</code>.</p>
</td></tr>
<tr><td><code>certificate</code></td>
<td>
<p>Final value of convergence criteria.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The solution to the original problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The solution to the dual problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>The updated values from applying the first proximal operator (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>screen_set</code></td>
<td>
<p>List of groups that were kept after screening step for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{S}</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>epsilon_set</code></td>
<td>
<p>List of groups that were used for fitting after screening for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{E}</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>kkt_violations</code></td>
<td>
<p>List of groups that violated the KKT conditions each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{K}</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>pen_gslope</code></td>
<td>
<p>Vector of the group penalty sequence.</p>
</td></tr>
<tr><td><code>screen</code></td>
<td>
<p>Logical flag indicating whether screening was applied.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Logical flag indicating whether an intercept was fit.</p>
</td></tr>
<tr><td><code>standardise</code></td>
<td>
<p>Type of standardisation used.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Value(s) of <code class="reqn">\lambda</code> used to fit the model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Brzyski, D., Gossmann, A., Su, W., Bodgan, M. (2019). <em>Group SLOPE  Adaptive Selection of Groups of Predictors</em>, <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269">https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>
<p>Pedregosa, F., Gidel, G. (2018). <em>Adaptive Three Operator Splitting</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p>Other gSLOPE-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_goscar">fit_goscar</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run gSLOPE
model = fit_gslope(X = data$X, y = data$y, groups = groups, type="linear", path_length = 5,
gFDR=0.1, standardise = "l2", intercept = TRUE, verbose=FALSE)
</code></pre>

<hr>
<h2 id='fit_gslope_cv'>Fit a gSLOPE model using k-fold cross-validation.</h2><span id='topic+fit_gslope_cv'></span>

<h3>Description</h3>

<p>Function to fit a pathwise solution of group SLOPE (gSLOPE) models using k-fold cross-validation. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_gslope_cv(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  nfolds = 10,
  gFDR = 0.1,
  pen_method = 1,
  backtracking = 0.7,
  max_iter = 5000,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  error_criteria = "mse",
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_gslope_cv_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to use in cross-validation.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_gfdr">gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_pen_method">pen_method</code></td>
<td>
<p>The type of penalty sequences to use (see Brzyski et al. (2019)):
</p>

<ul>
<li> <p><code>"1"</code> uses the gMean gSLOPE sequence.
</p>
</li>
<li> <p><code>"2"</code> uses the gMax gSLOPE sequence.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_error_criteria">error_criteria</code></td>
<td>
<p>The criteria used to discriminate between models along the path. Supported values are: <code>"mse"</code> (mean squared error) and <code>"mae"</code> (mean absolute error).</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_gslope_cv_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the penalties from <code>pen_method</code> if specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code>. To void this behaviour, set <code class="reqn">\lambda = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fits gSLOPE models under a pathwise solution using adaptive three operator splitting (ATOS), picking the 1se model as optimum. Warm starts are implemented.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>errors</code></td>
<td>
<p>A table containing fitting information about the models on the path.</p>
</td></tr>
<tr><td><code>all_models</code></td>
<td>
<p>Fitting information for all models fit on the path, which is a <code>"gslope"</code> object type.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>The 1se chosen model, which is a <code>"gslope"</code> object type.</p>
</td></tr>
<tr><td><code>best_lambda</code></td>
<td>
<p>The value of <code class="reqn">\lambda</code> which generated the chosen model.</p>
</td></tr>
<tr><td><code>best_lambda_id</code></td>
<td>
<p>The path index for the chosen model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Brzyski, D., Gossmann, A., Su, W., Bodgan, M. (2019). <em>Group SLOPE  Adaptive Selection of Groups of Predictors</em>, <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269">https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_gslope">fit_gslope()</a></code>
</p>
<p>Other gSLOPE-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_goscar">fit_goscar</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope">fit_gslope</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>
<p>Other model-selection: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run gSLOPE with cross-validation
cv_model = fit_gslope_cv(X = data$X, y = data$y, groups=groups, type = "linear", path_length = 5, 
nfolds=5, gFDR = 0.1, min_frac = 0.05, standardise="l2",intercept=TRUE,verbose=TRUE)
</code></pre>

<hr>
<h2 id='fit_sgo'>Fit an SGO model.</h2><span id='topic+fit_sgo'></span>

<h3>Description</h3>

<p>Sparse-group OSCAR (SGO) main fitting function. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_sgo(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  alpha = 0.95,
  max_iter = 5000,
  backtracking = 0.7,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL,
  v_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_sgo_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgo_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_alpha">alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between OSCAR and gOSCAR. Must be between 0 and 1. Recommended value is 0.95.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/\sqrt{n}</code>.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/n</code>.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"noBaone"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgo_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">1-\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td></tr>
<tr><td><code id="fit_sgo_+3A_v_weights">v_weights</code></td>
<td>
<p>Optional vector for the variable penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fit_sgo()</code> fits an SGO model (Feser and Evangelou (2024)) using adaptive three operator splitting (ATOS). SGO uses the same model set-up as for SGS, but with different weights (see Bao et al. (2020) and Feser and Evangelou (2024)).
The penalties are given by (for a group <code class="reqn">g</code> and variable <code class="reqn">i</code>, with <code class="reqn">p</code> variables and <code class="reqn">m</code> groups):
</p>
<p style="text-align: center;"><code class="reqn">
  v_i = \sigma_1 + \sigma_2(p-i), \; w_g = \sigma_1 + \sigma_3(m-g),
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
     \sigma_1 = d_i\|X^\intercal y\|_\infty, \; \sigma_2 = \sigma_1/p, \; \sigma_3 = \sigma_1/m, \; d_i = i \times \exp{(-2)}. 
</code>
</p>



<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>The fitted values from the regression. Taken to be the more stable fit between <code>x</code> and <code>z</code>, which is usually the former. A filter is applied to remove very small values, where ATOS has not been able to shrink exactly to zero. Check this against <code>x</code> and <code>z</code>.</p>
</td></tr>
<tr><td><code>group_effects</code></td>
<td>
<p>The group values from the regression. Taken by applying the <code class="reqn">\ell_2</code> norm within each group on <code>beta</code>.</p>
</td></tr>
<tr><td><code>selected_var</code></td>
<td>
<p>A list containing the indicies of the active/selected variables for each <code>"lambda"</code> value. Index 1 corresponds to the first column in X.</p>
</td></tr>
<tr><td><code>selected_grp</code></td>
<td>
<p>A list containing the indicies of the active/selected groups for each <code>"lambda"</code> value. Index 1 corresponds to the first group in the <code>groups</code> vector. You can see the group order by running <code>unique(groups)</code>.</p>
</td></tr>
<tr><td><code>num_it</code></td>
<td>
<p>Number of iterations performed. If convergence is not reached, this will be <code>max_iter</code>.</p>
</td></tr>
<tr><td><code>success</code></td>
<td>
<p>Logical flag indicating whether ATOS converged, according to <code>tol</code>.</p>
</td></tr>
<tr><td><code>certificate</code></td>
<td>
<p>Final value of convergence criteria.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The solution to the original problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>The updated values from applying the first proximal operator (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The solution to the dual problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>screen_set_var</code></td>
<td>
<p>List of variables that were kept after screening step for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{S}_v</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>screen_set_grp</code></td>
<td>
<p>List of groups that were kept after screening step for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{S}_g</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>epsilon_set_var</code></td>
<td>
<p>List of variables that were used for fitting after screening for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{E}_v</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>epsilon_set_grp</code></td>
<td>
<p>List of groups that were used for fitting after screening for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{E}_g</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>kkt_violations_var</code></td>
<td>
<p>List of variables that violated the KKT conditions each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{K}_v</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>kkt_violations_grp</code></td>
<td>
<p>List of groups that violated the KKT conditions each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{K}_g</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>pen_slope</code></td>
<td>
<p>Vector of the variable penalty sequence.</p>
</td></tr>
<tr><td><code>pen_gslope</code></td>
<td>
<p>Vector of the group penalty sequence.</p>
</td></tr>
<tr><td><code>screen</code></td>
<td>
<p>Logical flag indicating whether screening was performed.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Logical flag indicating whether an intercept was fit.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Value(s) of <code class="reqn">\lambda</code> used to fit the model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bao, R., Gu B., Huang, H. (2020). <em>Fast OSCAR and OWL Regression via Safe Screening Rules</em>, <a href="https://proceedings.mlr.press/v119/bao20b">https://proceedings.mlr.press/v119/bao20b</a>
</p>
<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://arxiv.org/abs/2405.15357">https://arxiv.org/abs/2405.15357</a>
</p>
<p>Pedregosa, F., Gidel, G. (2018). <em>Adaptive Three Operator Splitting</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGO
model = fit_sgo(X = data$X, y = data$y, groups = groups, type="linear", path_length = 5, 
alpha=0.95, standardise = "l2", intercept = TRUE, verbose=FALSE)
</code></pre>

<hr>
<h2 id='fit_sgo_cv'>Fit an SGO model using k-fold cross-validation.</h2><span id='topic+fit_sgo_cv'></span>

<h3>Description</h3>

<p>Function to fit a pathwise solution of sparse-group SLOPE (SGO) models using k-fold cross-validation. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_sgo_cv(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  alpha = 0.95,
  nfolds = 10,
  backtracking = 0.7,
  max_iter = 5000,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  error_criteria = "mse",
  screen = TRUE,
  verbose = FALSE,
  v_weights = NULL,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_sgo_cv_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_alpha">alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between OSCAR and gOSCAR. Must be between 0 and 1. Recommended value is 0.95.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to use in cross-validation.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_error_criteria">error_criteria</code></td>
<td>
<p>The criteria used to discriminate between models along the path. Supported values are: <code>"mse"</code> (mean squared error) and <code>"mae"</code> (mean absolute error).</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_v_weights">v_weights</code></td>
<td>
<p>Optional vector for the variable penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td></tr>
<tr><td><code id="fit_sgo_cv_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the OSCAR penalties when specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">1-\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fits SGO models under a pathwise solution using adaptive three operator splitting (ATOS), picking the 1se model as optimum. Warm starts are implemented.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>all_models</code></td>
<td>
<p>A list of all the models fitted along the path.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>The 1se chosen model, which is a <code>"sgs"</code> object type.</p>
</td></tr>
<tr><td><code>best_lambda</code></td>
<td>
<p>The value of <code class="reqn">\lambda</code> which generated the chosen model.</p>
</td></tr>
<tr><td><code>best_lambda_id</code></td>
<td>
<p>The path index for the chosen model.</p>
</td></tr>
<tr><td><code>errors</code></td>
<td>
<p>A table containing fitting information about the models on the path.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bao, R., Gu B., Huang, H. (2020). <em>Fast OSCAR and OWL Regression via Safe Screening Rules</em>, <a href="https://proceedings.mlr.press/v119/bao20b">https://proceedings.mlr.press/v119/bao20b</a>
</p>
<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://arxiv.org/abs/2405.15357">https://arxiv.org/abs/2405.15357</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_sgo">fit_sgo()</a></code>
</p>
<p>Other model-selection: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGO with cross-validation
cv_model = fit_sgo_cv(X = data$X, y = data$y, groups=groups, type = "linear", 
path_length = 5, nfolds=5, alpha = 0.95, min_frac = 0.05, 
standardise="l2",intercept=TRUE,verbose=TRUE)
</code></pre>

<hr>
<h2 id='fit_sgs'>Fit an SGS model.</h2><span id='topic+fit_sgs'></span>

<h3>Description</h3>

<p>Sparse-group SLOPE (SGS) main fitting function. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_sgs(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  alpha = 0.95,
  vFDR = 0.1,
  gFDR = 0.1,
  pen_method = 1,
  max_iter = 5000,
  backtracking = 0.7,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  screen = TRUE,
  verbose = FALSE,
  w_weights = NULL,
  v_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_sgs_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgs_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_alpha">alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between SLOPE and gSLOPE. Must be between 0 and 1. Recommended value is 0.95.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_vfdr">vFDR</code></td>
<td>
<p>Defines the desired variable false discovery rate (FDR) level, which determines the shape of the variable penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_gfdr">gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the group penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_pen_method">pen_method</code></td>
<td>
<p>The type of penalty sequences to use (see Feser and Evangelou (2023)):
</p>

<ul>
<li> <p><code>"1"</code> uses the vMean SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"2"</code> uses the vMax SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"3"</code> uses the BH SLOPE and gMean gSLOPE sequences, also known as SGS Original.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgs_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/\sqrt{n}</code>.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one. When using this <code>"lambda"</code> is scaled internally by <code class="reqn">1/n</code>.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgs_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the penalties from <code>pen_method</code> if specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">1-\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td></tr>
<tr><td><code id="fit_sgs_+3A_v_weights">v_weights</code></td>
<td>
<p>Optional vector for the variable penalty weights. Overrides the penalties from <code>pen_method</code> if specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fit_sgs()</code> fits an SGS model (Feser and Evangelou (2023)) using adaptive three operator splitting (ATOS). SGS is a sparse-group method, so that it selects both variables and groups. Unlike group selection approaches, not every variable within a group is set as active.
It solves the convex optimisation problem given by
</p>
<p style="text-align: center;"><code class="reqn">
  \frac{1}{2n} f(b ; y, \mathbf{X}) + \lambda \alpha \sum_{i=1}^{p}v_i |b|_{(i)} + \lambda (1-\alpha)\sum_{g=1}^{m}w_g \sqrt{p_g} \|b^{(g)}\|_2,
</code>
</p>

<p>where <code class="reqn">f(\cdot)</code> is the loss function and <code class="reqn">p_g</code> are the group sizes. The penalty parameters in SGS are sorted so that the largest coefficients are matched with the largest penalties, to reduce the FDR.
For the variables: <code class="reqn">|\beta|_{(1)}\geq \ldots \geq |\beta|_{(p)}</code> and <code class="reqn">v_1 \geq \ldots \geq v_p \geq 0</code>.
For the groups: <code class="reqn">\sqrt{p_1}\|\beta^{(1)}\|_2 \geq \ldots\geq \sqrt{p_m}\|\beta^{(m)}\|_2</code> and <code class="reqn">w_1\geq \ldots \geq w_g \geq 0</code>.
In the case of the linear model, the loss function is given by the mean-squared error loss:
</p>
<p style="text-align: center;"><code class="reqn">
 f(b; y, \mathbf{X}) = \left\|y-\mathbf{X}b \right\|_2^2.
</code>
</p>

<p>In the logistic model, the loss function is given by
</p>
<p style="text-align: center;"><code class="reqn">
f(b;y,\mathbf{X})=-1/n \log(\mathcal{L}(b; y, \mathbf{X})).
</code>
</p>

<p>where the log-likelihood is given by
</p>
<p style="text-align: center;"><code class="reqn">
 \mathcal{L}(b; y, \mathbf{X}) = \sum_{i=1}^{n}\left\{y_i b^\intercal x_i - \log(1+\exp(b^\intercal x_i)) \right\}.
</code>
</p>

<p>SGS can be seen to be a convex combination of SLOPE and gSLOPE, balanced through <code>alpha</code>, such that it reduces to SLOPE for <code>alpha = 1</code> and to gSLOPE for <code>alpha = 0</code>.
The penalty parameters in SGS are sorted so that the largest coefficients are matched with the largest penalties, to reduce the FDR.
For the group penalties, see <code><a href="#topic+fit_gslope">fit_gslope()</a></code>. For the variable penalties, the vMean SGS sequence (<code>pen_method=1</code>) (Feser and Evangelou (2023)) is given by
</p>
<p style="text-align: center;"><code class="reqn">
v_i^{\text{mean}} = \overline{F}_{\mathcal{N}}^{-1} \left( 1 - \frac{q_v i}{2p} \right), \; \text{where} \; \overline{F}_{\mathcal{N}}(x) := \frac{1}{m} \sum_{j=1}^{m} F_{\mathcal{N}} \left( \alpha x + \frac{1}{3} (1-\alpha) a_j w_j \right),\; i = 1,\ldots,p,
</code>
</p>

<p>where <code class="reqn">F_\mathcal{N}</code> is the cumulative distribution functions of a standard Gaussian distribution. The vMax SGS sequence (<code>pen_method=2</code>) (Feser and Evangelou (2023)) is given by
</p>
<p style="text-align: center;"><code class="reqn">
v_i^{\text{max}} = \max_{j=1,\dots,m} \left\{ \frac{1}{\alpha} F_{\mathcal{N}}^{-1} \left(1 - \frac{q_v i}{2p}\right) - \frac{1}{3\alpha}(1-\alpha) a_j w_j \right\},
</code>
</p>

<p>The BH SLOPE sequence (<code>pen_method=3</code>) (Bogdan et al. (2015)) is given by
</p>
<p style="text-align: center;"><code class="reqn">
v_i = z(1-i q_v/2p),
</code>
</p>

<p>where <code class="reqn">z</code> is the quantile function of a standard normal distribution.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>The fitted values from the regression. Taken to be the more stable fit between <code>x</code> and <code>z</code>, which is usually the former. A filter is applied to remove very small values, where ATOS has not been able to shrink exactly to zero. Check this against <code>x</code> and <code>z</code>.</p>
</td></tr>
<tr><td><code>group_effects</code></td>
<td>
<p>The group values from the regression. Taken by applying the <code class="reqn">\ell_2</code> norm within each group on <code>beta</code>.</p>
</td></tr>
<tr><td><code>selected_var</code></td>
<td>
<p>A list containing the indicies of the active/selected variables for each <code>"lambda"</code> value. Index 1 corresponds to the first column in X.</p>
</td></tr>
<tr><td><code>selected_grp</code></td>
<td>
<p>A list containing the indicies of the active/selected groups for each <code>"lambda"</code> value. Index 1 corresponds to the first group in the <code>groups</code> vector. You can see the group order by running <code>unique(groups)</code>.</p>
</td></tr>
<tr><td><code>num_it</code></td>
<td>
<p>Number of iterations performed. If convergence is not reached, this will be <code>max_iter</code>.</p>
</td></tr>
<tr><td><code>success</code></td>
<td>
<p>Logical flag indicating whether ATOS converged, according to <code>tol</code>.</p>
</td></tr>
<tr><td><code>certificate</code></td>
<td>
<p>Final value of convergence criteria.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The solution to the original problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>The updated values from applying the first proximal operator (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>The solution to the dual problem (see Pedregosa and Gidel (2018)).</p>
</td></tr>
<tr><td><code>screen_set_var</code></td>
<td>
<p>List of variables that were kept after screening step for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{S}_v</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>screen_set_grp</code></td>
<td>
<p>List of groups that were kept after screening step for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{S}_g</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>epsilon_set_var</code></td>
<td>
<p>List of variables that were used for fitting after screening for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{E}_v</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>epsilon_set_grp</code></td>
<td>
<p>List of groups that were used for fitting after screening for each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{E}_g</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>kkt_violations_var</code></td>
<td>
<p>List of variables that violated the KKT conditions each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{K}_v</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>kkt_violations_grp</code></td>
<td>
<p>List of groups that violated the KKT conditions each <code>"lambda"</code> value. (corresponds to <code class="reqn">\mathcal{K}_g</code> in Feser and Evangelou (2024)).</p>
</td></tr>
<tr><td><code>pen_slope</code></td>
<td>
<p>Vector of the variable penalty sequence.</p>
</td></tr>
<tr><td><code>pen_gslope</code></td>
<td>
<p>Vector of the group penalty sequence.</p>
</td></tr>
<tr><td><code>screen</code></td>
<td>
<p>Logical flag indicating whether screening was performed.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Logical flag indicating whether an intercept was fit.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Value(s) of <code class="reqn">\lambda</code> used to fit the model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bogdan, M., van den Berg, E., Sabatti, C., Candes, E. (2015). <em>SLOPE - Adaptive variable selection via convex optimization</em>, <a href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/SLOPEAdaptive-variable-selection-via-convex-optimization/10.1214/15-AOAS842.full">https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/SLOPEAdaptive-variable-selection-via-convex-optimization/10.1214/15-AOAS842.full</a>
</p>
<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://arxiv.org/abs/2405.15357">https://arxiv.org/abs/2405.15357</a>
</p>
<p>Pedregosa, F., Gidel, G. (2018). <em>Adaptive Three Operator Splitting</em>, <a href="https://proceedings.mlr.press/v80/pedregosa18a.html">https://proceedings.mlr.press/v80/pedregosa18a.html</a>
</p>


<h3>See Also</h3>

<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGS 
model = fit_sgs(X = data$X, y = data$y, groups = groups, type="linear", path_length = 5, 
alpha=0.95, vFDR=0.1, gFDR=0.1, standardise = "l2", intercept = TRUE, verbose=FALSE)
</code></pre>

<hr>
<h2 id='fit_sgs_cv'>Fit an SGS model using k-fold cross-validation.</h2><span id='topic+fit_sgs_cv'></span>

<h3>Description</h3>

<p>Function to fit a pathwise solution of sparse-group SLOPE (SGS) models using k-fold cross-validation. Supports both linear and logistic regression, both with dense and sparse matrix implementations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_sgs_cv(
  X,
  y,
  groups,
  type = "linear",
  lambda = "path",
  path_length = 20,
  min_frac = 0.05,
  alpha = 0.95,
  vFDR = 0.1,
  gFDR = 0.1,
  pen_method = 1,
  nfolds = 10,
  backtracking = 0.7,
  max_iter = 5000,
  max_iter_backtracking = 100,
  tol = 1e-05,
  standardise = "l2",
  intercept = TRUE,
  error_criteria = "mse",
  screen = TRUE,
  verbose = FALSE,
  v_weights = NULL,
  w_weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_sgs_cv_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_lambda">lambda</code></td>
<td>
<p>The regularisation parameter. Defines the level of sparsity in the model. A higher value leads to sparser models:
</p>

<ul>
<li> <p><code>"path"</code> computes a path of regularisation parameters of length <code>"path_length"</code>. The path will begin just above the value at which the first predictor enters the model and will terminate at the value determined by <code>"min_frac"</code>.
</p>
</li>
<li><p> User-specified single value or sequence. Internal scaling is applied based on the type of standardisation. The returned <code>"lambda"</code> value will be the original unscaled value(s).
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_path_length">path_length</code></td>
<td>
<p>The number of <code class="reqn">\lambda</code> values to fit the model for. If <code>"lambda"</code> is user-specified, this is ignored.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_min_frac">min_frac</code></td>
<td>
<p>Smallest value of <code class="reqn">\lambda</code> as a fraction of the maximum value. That is, the final <code class="reqn">\lambda</code> will be <code>"min_frac"</code> of the first <code class="reqn">\lambda</code> value.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_alpha">alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between SLOPE and gSLOPE. Must be between 0 and 1. Recommended value is 0.95.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_vfdr">vFDR</code></td>
<td>
<p>Defines the desired variable false discovery rate (FDR) level, which determines the shape of the variable penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_gfdr">gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the group penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_pen_method">pen_method</code></td>
<td>
<p>The type of penalty sequences to use (see Feser and Evangelou (2023)):
</p>

<ul>
<li> <p><code>"1"</code> uses the vMean SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"2"</code> uses the vMax SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"3"</code> uses the BH SLOPE and gMean gSLOPE sequences, also known as SGS Original.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to use in cross-validation.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_backtracking">backtracking</code></td>
<td>
<p>The backtracking parameter, <code class="reqn">\tau</code>, as defined in Pedregosa and Gidel (2018).</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of ATOS iterations to perform.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_max_iter_backtracking">max_iter_backtracking</code></td>
<td>
<p>Maximum number of backtracking line search iterations to perform per global iteration.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance for the stopping criteria.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_error_criteria">error_criteria</code></td>
<td>
<p>The criteria used to discriminate between models along the path. Supported values are: <code>"mse"</code> (mean squared error) and <code>"mae"</code> (mean absolute error).</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_screen">screen</code></td>
<td>
<p>Logical flag for whether to apply screening rules (see Feser and Evangelou (2024)). Screening discards irrelevant groups before fitting, greatly improving speed.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_v_weights">v_weights</code></td>
<td>
<p>Optional vector for the variable penalty weights. Overrides the penalties from pen_method if specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code></p>
</td></tr>
<tr><td><code id="fit_sgs_cv_+3A_w_weights">w_weights</code></td>
<td>
<p>Optional vector for the group penalty weights. Overrides the penalties from pen_method if specified. When entering custom weights, these are multiplied internally by <code class="reqn">\lambda</code> and <code class="reqn">1-\alpha</code>. To void this behaviour, set <code class="reqn">\lambda = 2</code> and <code class="reqn">\alpha = 0.5</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fits SGS models under a pathwise solution using adaptive three operator splitting (ATOS), picking the 1se model as optimum. Warm starts are implemented.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>all_models</code></td>
<td>
<p>A list of all the models fitted along the path.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>The 1se chosen model, which is a <code>"sgs"</code> object type.</p>
</td></tr>
<tr><td><code>best_lambda</code></td>
<td>
<p>The value of <code class="reqn">\lambda</code> which generated the chosen model.</p>
</td></tr>
<tr><td><code>best_lambda_id</code></td>
<td>
<p>The path index for the chosen model.</p>
</td></tr>
<tr><td><code>errors</code></td>
<td>
<p>A table containing fitting information about the models on the path.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Indicates which type of regression was performed.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>
<p>Feser, F., Evangelou, M. (2024). <em>Strong screening rules for group-based SLOPE models</em>, <a href="https://arxiv.org/abs/2405.15357">https://arxiv.org/abs/2405.15357</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_sgs">fit_sgs()</a></code>
</p>
<p>Other model-selection: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGS with cross-validation
cv_model = fit_sgs_cv(X = data$X, y = data$y, groups=groups, type = "linear", 
path_length = 5, nfolds=5, alpha = 0.95, vFDR = 0.1, gFDR = 0.1, min_frac = 0.05, 
standardise="l2",intercept=TRUE,verbose=TRUE)
</code></pre>

<hr>
<h2 id='gen_pens'>Generate penalty sequences for SGS.</h2><span id='topic+gen_pens'></span>

<h3>Description</h3>

<p>Generates variable and group penalties for SGS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_pens(gFDR, vFDR, pen_method, groups, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_pens_+3A_gfdr">gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the group penalties.</p>
</td></tr>
<tr><td><code id="gen_pens_+3A_vfdr">vFDR</code></td>
<td>
<p>Defines the desired variable false discovery rate (FDR) level, which determines the shape of the variable penalties.</p>
</td></tr>
<tr><td><code id="gen_pens_+3A_pen_method">pen_method</code></td>
<td>
<p>The type of penalty sequences to use (see Feser and Evangelou (2023)):
</p>

<ul>
<li> <p><code>"1"</code> uses the vMean SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"2"</code> uses the vMax SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"3"</code> uses the BH SLOPE and gMean gSLOPE sequences, also known as SGS Original.
</p>
</li>
<li> <p><code>"4"</code> uses the gMax gSLOPE sequence. For a gSLOPE model only.
</p>
</li></ul>
</td></tr>
<tr><td><code id="gen_pens_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="gen_pens_+3A_alpha">alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, defines the convex balance between SLOPE and gSLOPE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vMean and vMax SGS sequences are variable sequences derived specifically to give variable false discovery rate (FDR) control for SGS under orthogonal designs (see Feser and Evangelou (2023)).
The BH SLOPE sequence is derived in Bodgan et al. (2015) and has links to the Benjamini-Hochberg critical values. The sequence provides variable FDR-control for SLOPE under orthogonal designs.
The gMean gSLOPE sequence is derived in Brzyski et al. (2015) and provides group FDR-control for gSLOPE under orthogonal designs.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>pen_slope_org</code></td>
<td>
<p>A vector of the variable penalty sequence.</p>
</td></tr>
<tr><td><code>pen_gslope_org</code></td>
<td>
<p>A vector of the group penalty sequence.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bogdan, M., Van den Berg, E., Sabatti, C., Su, W., Candes, E. (2015). <em>SLOPE  Adaptive variable selection via convex optimization</em>, <a href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/SLOPEAdaptive-variable-selection-via-convex-optimization/10.1214/15-AOAS842.full">https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/SLOPEAdaptive-variable-selection-via-convex-optimization/10.1214/15-AOAS842.full</a>
</p>
<p>Brzyski, D., Gossmann, A., Su, W., Bodgan, M. (2019). <em>Group SLOPE  Adaptive Selection of Groups of Predictors</em>, <a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269">https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1411269</a>
</p>
<p>Feser, F., Evangelou, M. (2023). <em>Sparse-group SLOPE: adaptive bi-level selection with FDR-control</em>, <a href="https://arxiv.org/abs/2305.09467">https://arxiv.org/abs/2305.09467</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(rep(1:20, each=3),
          rep(21:40, each=4),
          rep(41:60, each=5),
          rep(61:80, each=6),
          rep(81:100, each=7))
# generate sequences
sequences = gen_pens(gFDR=0.1, vFDR=0.1, pen_method=1, groups=groups, alpha=0.5)

</code></pre>

<hr>
<h2 id='gen_toy_data'>Generate toy data.</h2><span id='topic+gen_toy_data'></span>

<h3>Description</h3>

<p>Generates different types of datasets, which can then be fitted using sparse-group SLOPE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_toy_data(
  p,
  n,
  rho = 0,
  seed_id = 2,
  grouped = TRUE,
  groups,
  noise_level = 1,
  group_sparsity = 0.1,
  var_sparsity = 0.5,
  orthogonal = FALSE,
  data_mean = 0,
  data_sd = 1,
  signal_mean = 0,
  signal_sd = sqrt(10)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_toy_data_+3A_p">p</code></td>
<td>
<p>The number of input variables.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_rho">rho</code></td>
<td>
<p>Correlation coefficient. Must be in range <code class="reqn">[0,1]</code>.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_seed_id">seed_id</code></td>
<td>
<p>Seed to be used to generate the data matrix <code class="reqn">X</code>.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_grouped">grouped</code></td>
<td>
<p>A logical flag indicating whether grouped data is required.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_groups">groups</code></td>
<td>
<p>If <code>grouped=TRUE</code>, the grouping structure is required. Each input variable should have a group id.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_noise_level">noise_level</code></td>
<td>
<p>Defines the level of noise (<code class="reqn">\sigma</code>) to be used in generating the response vector <code class="reqn">y</code>.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_group_sparsity">group_sparsity</code></td>
<td>
<p>Defines the level of group sparsity. Must be in the range <code class="reqn">[0,1]</code>.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_var_sparsity">var_sparsity</code></td>
<td>
<p>Defines the level of variable sparsity. Must be in the range <code class="reqn">[0,1]</code>. If <code>grouped=TRUE</code>, this defines the level of sparsity within each group, not globally.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_orthogonal">orthogonal</code></td>
<td>
<p>Logical flag as to whether the input matrix should be orthogonal.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_data_mean">data_mean</code></td>
<td>
<p>Defines the mean of input predictors.</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_data_sd">data_sd</code></td>
<td>
<p>Defines the standard deviation of the signal (<code class="reqn">\beta</code>).</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_signal_mean">signal_mean</code></td>
<td>
<p>Defines the mean of the signal (<code class="reqn">\beta</code>).</p>
</td></tr>
<tr><td><code id="gen_toy_data_+3A_signal_sd">signal_sd</code></td>
<td>
<p>Defines the standard deviation of the signal (<code class="reqn">\beta</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data is generated under a Gaussian linear model. The generated data can be grouped and sparsity can be provided at both a group and/or variable level.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>The input matrix.</p>
</td></tr>
<tr><td><code>true_beta</code></td>
<td>
<p>The true values of <code class="reqn">\beta</code> used to generate the response.</p>
</td></tr>
<tr><td><code>true_grp_id</code></td>
<td>
<p>Indices of which groups are non-zero in <code>true_beta</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(rep(1:20, each=3),
          rep(21:40, each=4),
          rep(41:60, each=5),
          rep(61:80, each=6),
          rep(81:100, each=7))
# generate data
data =  gen_toy_data(p=500, n=400, groups = groups, seed_id=3)

</code></pre>

<hr>
<h2 id='plot.sgs'>Plot models of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</h2><span id='topic+plot.sgs'></span>

<h3>Description</h3>

<p>Plots the pathwise solution of a cross-validation fit, from a call to one of the following: <code><a href="#topic+fit_sgs">fit_sgs()</a></code>, <code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>, <code><a href="#topic+fit_gslope">fit_gslope()</a></code>, <code><a href="#topic+fit_gslope_cv">fit_gslope_cv()</a></code>, <code><a href="#topic+fit_sgo">fit_sgo()</a></code>, <code><a href="#topic+fit_sgo_cv">fit_sgo_cv()</a></code>, <code><a href="#topic+fit_goscar">fit_goscar()</a></code>, <code><a href="#topic+fit_goscar_cv">fit_goscar_cv()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgs'
plot(x, how_many = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.sgs_+3A_x">x</code></td>
<td>
<p>Object of one of the following classes: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p>
</td></tr>
<tr><td><code id="plot.sgs_+3A_how_many">how_many</code></td>
<td>
<p>Defines how many predictors to plot. Plots the predictors in decreasing order of largest absolute value.</p>
</td></tr>
<tr><td><code id="plot.sgs_+3A_...">...</code></td>
<td>
<p>further arguments passed to base function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>response</code></td>
<td>
<p>The predicted response. In the logistic case, this represents the predicted class probabilities.</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>The predicted class assignments. Only returned if type = &quot;logistic&quot; in the model object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fit_sgs">fit_sgs()</a></code>, <code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>, <code><a href="#topic+fit_gslope">fit_gslope()</a></code>, <code><a href="#topic+fit_gslope_cv">fit_gslope_cv()</a></code>, <code><a href="#topic+fit_sgo">fit_sgo()</a></code>, <code><a href="#topic+fit_sgo_cv">fit_sgo_cv()</a></code>, <code><a href="#topic+fit_goscar">fit_goscar()</a></code>, <code><a href="#topic+fit_goscar_cv">fit_goscar_cv()</a></code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>
<p>Other gSLOPE-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_goscar">fit_goscar</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope">fit_gslope</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,2,2,3)
# generate data
data =  gen_toy_data(p=5, n=4, groups = groups, seed_id=3,signal_mean=20,group_sparsity=1)
# run SGS 
model = fit_sgs(X = data$X, y = data$y, groups=groups, type = "linear", 
path_length = 20, alpha = 0.95, vFDR = 0.1, gFDR = 0.1, 
min_frac = 0.05, standardise="l2",intercept=TRUE,verbose=FALSE)
plot(model, how_many = 10)
</code></pre>

<hr>
<h2 id='predict.sgs'>Predict using one of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</h2><span id='topic+predict.sgs'></span>

<h3>Description</h3>

<p>Performs prediction from one of the following fits: <code><a href="#topic+fit_sgs">fit_sgs()</a></code>, <code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>, <code><a href="#topic+fit_gslope">fit_gslope()</a></code>, <code><a href="#topic+fit_gslope_cv">fit_gslope_cv()</a></code>, <code><a href="#topic+fit_sgo">fit_sgo()</a></code>, <code><a href="#topic+fit_sgo_cv">fit_sgo_cv()</a></code>, <code><a href="#topic+fit_goscar">fit_goscar()</a></code>, <code><a href="#topic+fit_goscar_cv">fit_goscar_cv()</a></code>. The predictions are calculated for each <code>"lambda"</code> value in the path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgs'
predict(object, x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.sgs_+3A_object">object</code></td>
<td>
<p>Object of one of the following classes: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p>
</td></tr>
<tr><td><code id="predict.sgs_+3A_x">x</code></td>
<td>
<p>Input data to use for prediction.</p>
</td></tr>
<tr><td><code id="predict.sgs_+3A_...">...</code></td>
<td>
<p>further arguments passed to stats function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>response</code></td>
<td>
<p>The predicted response. In the logistic case, this represents the predicted class probabilities.</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>The predicted class assignments. Only returned if type = &quot;logistic&quot; in the model object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fit_sgs">fit_sgs()</a></code>, <code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>, <code><a href="#topic+fit_gslope">fit_gslope()</a></code>, <code><a href="#topic+fit_gslope_cv">fit_gslope_cv()</a></code>, <code><a href="#topic+fit_sgo">fit_sgo()</a></code>, <code><a href="#topic+fit_sgo_cv">fit_sgo_cv()</a></code>, <code><a href="#topic+fit_goscar">fit_goscar()</a></code>, <code><a href="#topic+fit_goscar_cv">fit_goscar_cv()</a></code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>
<p>Other gSLOPE-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_goscar">fit_goscar</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope">fit_gslope</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,1,2,2,3,3,3,4,4)
# generate data
data =  gen_toy_data(p=10, n=5, groups = groups, seed_id=3,group_sparsity=1)
# run SGS 
model = fit_sgs(X = data$X, y = data$y, groups = groups, type="linear", lambda = 1, alpha=0.95, 
vFDR=0.1, gFDR=0.1, standardise = "l2", intercept = TRUE, verbose=FALSE)
# use predict function
model_predictions = predict(model, x = data$X)
</code></pre>

<hr>
<h2 id='print.sgs'>Prints information for one of the following object types: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</h2><span id='topic+print.sgs'></span>

<h3>Description</h3>

<p>Prints out useful metric from a model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgs'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.sgs_+3A_x">x</code></td>
<td>
<p>Object of one of the following classes: <code>"sgs"</code>, <code>"sgs_cv"</code>, <code>"gslope"</code>, <code>"gslope_cv"</code>.</p>
</td></tr>
<tr><td><code id="print.sgs_+3A_...">...</code></td>
<td>
<p>further arguments passed to base function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of the model fit(s).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_sgs">fit_sgs()</a></code>, <code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>, <code><a href="#topic+fit_gslope">fit_gslope()</a></code>, <code><a href="#topic+fit_gslope_cv">fit_gslope_cv()</a></code>, <code><a href="#topic+fit_sgo">fit_sgo()</a></code>, <code><a href="#topic+fit_sgo_cv">fit_sgo_cv()</a></code>, <code><a href="#topic+fit_goscar">fit_goscar()</a></code>, <code><a href="#topic+fit_goscar_cv">fit_goscar_cv()</a></code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+scaled_sgs">scaled_sgs</a>()</code>
</p>
<p>Other gSLOPE-methods: 
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_goscar">fit_goscar</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope">fit_gslope</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(rep(1:20, each=3),
          rep(21:40, each=4),
          rep(41:60, each=5),
          rep(61:80, each=6),
          rep(81:100, each=7))
# generate data
data =  gen_toy_data(p=500, n=400, groups = groups, seed_id=3)
# run SGS 
model = fit_sgs(X = data$X, y = data$y, groups = groups, type="linear", lambda = 1, alpha=0.95, 
vFDR=0.1, gFDR=0.1, standardise = "l2", intercept = TRUE, verbose=FALSE)
# print model
print(model)
</code></pre>

<hr>
<h2 id='scaled_sgs'>Fits a scaled SGS model.</h2><span id='topic+scaled_sgs'></span>

<h3>Description</h3>

<p>Fits an SGS model using the noise estimation procedure (Algorithm 5 from Bogdan et al. (2015)). This estimates <code class="reqn">\lambda</code> and then fits the model using the estimated value. It is an alternative approach to cross-validation (<code><a href="#topic+fit_sgs_cv">fit_sgs_cv()</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaled_sgs(
  X,
  y,
  groups,
  type = "linear",
  pen_method = 1,
  alpha = 0.95,
  vFDR = 0.1,
  gFDR = 0.1,
  standardise = "l2",
  intercept = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scaled_sgs_+3A_x">X</code></td>
<td>
<p>Input matrix of dimensions <code class="reqn">n \times p</code>. Can be a sparse matrix (using class <code>"sparseMatrix"</code> from the <code>Matrix</code> package).</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_y">y</code></td>
<td>
<p>Output vector of dimension <code class="reqn">n</code>. For <code>type="linear"</code> should be continuous and for <code>type="logistic"</code> should be a binary variable.</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_groups">groups</code></td>
<td>
<p>A grouping structure for the input data. Should take the form of a vector of group indices.</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_type">type</code></td>
<td>
<p>The type of regression to perform. Supported values are: <code>"linear"</code> and <code>"logistic"</code>.</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_pen_method">pen_method</code></td>
<td>
<p>The type of penalty sequences to use.
</p>

<ul>
<li> <p><code>"1"</code> uses the vMean SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"2"</code> uses the vMax SGS and gMean gSLOPE sequences.
</p>
</li>
<li> <p><code>"1"</code> uses the BH SLOPE and gMean gSLOPE sequences, also known as SGS Original.
</p>
</li></ul>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_alpha">alpha</code></td>
<td>
<p>The value of <code class="reqn">\alpha</code>, which defines the convex balance between SLOPE and gSLOPE. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_vfdr">vFDR</code></td>
<td>
<p>Defines the desired variable false discovery rate (FDR) level, which determines the shape of the variable penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_gfdr">gFDR</code></td>
<td>
<p>Defines the desired group false discovery rate (FDR) level, which determines the shape of the group penalties. Must be between 0 and 1.</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_standardise">standardise</code></td>
<td>
<p>Type of standardisation to perform on <code>X</code>:
</p>

<ul>
<li> <p><code>"l2"</code> standardises the input data to have <code class="reqn">\ell_2</code> norms of one.
</p>
</li>
<li> <p><code>"l1"</code> standardises the input data to have <code class="reqn">\ell_1</code> norms of one.
</p>
</li>
<li> <p><code>"sd"</code> standardises the input data to have standard deviation of one.
</p>
</li>
<li> <p><code>"none"</code> no standardisation applied.
</p>
</li></ul>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_intercept">intercept</code></td>
<td>
<p>Logical flag for whether to fit an intercept.</p>
</td></tr>
<tr><td><code id="scaled_sgs_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag for whether to print fitting information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type <code>"sgs"</code> containing model fit information (see <code><a href="#topic+fit_sgs">fit_sgs()</a></code>).
</p>


<h3>References</h3>

<p>Bogdan, M., Van den Berg, E., Sabatti, C., Su, W., Candes, E. (2015). <em>SLOPE  Adaptive variable selection via convex optimization</em>, <a href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/SLOPEAdaptive-variable-selection-via-convex-optimization/10.1214/15-AOAS842.full">https://projecteuclid.org/journals/annals-of-applied-statistics/volume-9/issue-3/SLOPEAdaptive-variable-selection-via-convex-optimization/10.1214/15-AOAS842.full</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as_sgs">as_sgs()</a></code>
</p>
<p>Other model-selection: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+fit_goscar_cv">fit_goscar_cv</a>()</code>,
<code><a href="#topic+fit_gslope_cv">fit_gslope_cv</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>
</p>
<p>Other SGS-methods: 
<code><a href="#topic+as_sgs">as_sgs</a>()</code>,
<code><a href="#topic+coef.sgs">coef.sgs</a>()</code>,
<code><a href="#topic+fit_sgo">fit_sgo</a>()</code>,
<code><a href="#topic+fit_sgo_cv">fit_sgo_cv</a>()</code>,
<code><a href="#topic+fit_sgs">fit_sgs</a>()</code>,
<code><a href="#topic+fit_sgs_cv">fit_sgs_cv</a>()</code>,
<code><a href="#topic+plot.sgs">plot.sgs</a>()</code>,
<code><a href="#topic+predict.sgs">predict.sgs</a>()</code>,
<code><a href="#topic+print.sgs">print.sgs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># specify a grouping structure
groups = c(1,1,2,2,3)
# generate data
data =  gen_toy_data(p=5, n=4, groups = groups, seed_id=3,
signal_mean=20,group_sparsity=1,var_sparsity=1)
# run noise estimation 
model = scaled_sgs(X=data$X, y=data$y, groups=groups, pen_method=1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
