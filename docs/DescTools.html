<!DOCTYPE html><html><head><title>Help for package DescTools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DescTools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DescTools-package'><p> Tools for Descriptive Statistics and Exploratory Data Analysis</p></a></li>
<li><a href='#+25c+25'><p>Concatenates Two Strings Without Any Separator</p></a></li>
<li><a href='#+25like+25'><p>Like Operator</p></a></li>
<li><a href='#+25nin+25'>
<p>Find Matching (or Non-Matching) Elements</p></a></li>
<li><a href='#+25overlaps+25'><p>Determines If And How Extensively Two Date Ranges Overlap</p></a></li>
<li><a href='#ABCCoords'><p>Coordinates for &quot;bottomright&quot;, etc.</p></a></li>
<li><a href='#Abind'><p>Combine Multidimensional Arrays</p></a></li>
<li><a href='#Abstract'><p>Display Compact Abstract of a Data Frame</p></a></li>
<li><a href='#AddMonths'><p>Add a Month to a Date</p></a></li>
<li><a href='#Agree'><p>Raw Simple And Extended Percentage Agreement</p></a></li>
<li><a href='#AllDuplicated'><p> Index Vector of All Values Involved in Ties</p>
</p></a></li>
<li><a href='#AllIdentical'><p>Test Multiple Objects for Exact Equality</p></a></li>
<li><a href='#AndersonDarlingTest'>
<p>Anderson-Darling Test of Goodness-of-Fit</p></a></li>
<li><a href='#Append'><p>Append Elements to Objects</p></a></li>
<li><a href='#Arrow'><p>Insert an Arrow Into a Plot</p></a></li>
<li><a href='#as.matrix.xtabs'><p>Convert xtabs To matrix</p></a></li>
<li><a href='#as.ym'><p>A Class for Dealing with the Yearmonth Format</p></a></li>
<li><a href='#AscToChar'><p>Convert ASCII Codes to Characters and Vice Versa</p></a></li>
<li><a href='#Asp'><p>Get Aspect Ratio of the Current Plot</p></a></li>
<li><a href='#Association+20measures'>
<p>Cramer's V, Pearson's Contingency Coefficient and Phi Coefficient<br /></p>
Yule's Q and Y, Tschuprow's T</a></li>
<li><a href='#Assocs'><p>Association Measures</p></a></li>
<li><a href='#Atkinson'><p>Atkinson Index - A Measure of Inequality.</p></a></li>
<li><a href='#AUC'><p>Area Under the Curve</p></a></li>
<li><a href='#AxisBreak'><p> Place a Break Mark on an Axis</p></a></li>
<li><a href='#axTicks.POSIXct'><p>Compute Axis Tickmark Locations (For POSIXct Axis)</p></a></li>
<li><a href='#BarnardTest'><p> Barnard's Unconditional Test</p></a></li>
<li><a href='#BartelsRankTest'>
<p>Bartels Rank Test of Randomness</p></a></li>
<li><a href='#BarText'><p>Place Value Labels on a Barplot</p></a></li>
<li><a href='#Base+20Conversions'><p>Converts Numbers From Binmode, Octmode or Hexmode to Decimal and Vice Versa</p></a></li>
<li><a href='#Benford'><p> Benford's Distribution</p></a></li>
<li><a href='#Between+2C+20Outside'><p>Operators To Check, If a Value Lies Within Or Outside a Given Range</p></a></li>
<li><a href='#Bg'><p>Background of a Plot</p></a></li>
<li><a href='#BhapkarTest'><p>Bhapkar Marginal Homogeneity Test</p></a></li>
<li><a href='#BinomCI'><p> Confidence Intervals for Binomial Proportions</p></a></li>
<li><a href='#BinomCIn'><p>Sample Size for a Given Width of a Binomial Confidence Interval</p></a></li>
<li><a href='#BinomDiffCI'><p>Confidence Interval for a Difference of Binomials</p></a></li>
<li><a href='#BinomRatioCI'>
<p>Confidence Intervals for the Ratio of Binomial Proportions</p></a></li>
<li><a href='#BinTree'><p>Binary Tree</p></a></li>
<li><a href='#BootCI'><p>Simple Bootstrap Confidence Intervals</p></a></li>
<li><a href='#BoxCox'><p>Box Cox Transformation</p></a></li>
<li><a href='#BoxCoxLambda'><p>Automatic Selection of Box Cox Transformation Parameter</p></a></li>
<li><a href='#BoxedText'><p>Add Text in a Box to a Plot</p></a></li>
<li><a href='#BreslowDayTest'><p>Breslow-Day Test for Homogeneity of the Odds Ratios</p></a></li>
<li><a href='#BreuschGodfreyTest'><p>Breusch-Godfrey Test</p></a></li>
<li><a href='#BrierScore'><p>Brier Score for Assessing Prediction Accuracy</p></a></li>
<li><a href='#BubbleLegend'><p> Add a Legend to a Bubble Plot</p></a></li>
<li><a href='#Canvas'><p>Canvas for Geometric Plotting</p></a></li>
<li><a href='#CartToPol'><p>Transform Cartesian to Polar/Spherical Coordinates and Vice Versa</p></a></li>
<li><a href='#CatTable'>
<p>Function to write a table</p></a></li>
<li><a href='#CCC'>
<p>Concordance Correlation Coefficient</p></a></li>
<li><a href='#Clockwise'><p>Calculates Begin and End Angle From a List of Given Angles in Clockwise Mode</p></a></li>
<li><a href='#Closest'><p>Find the Closest Value</p></a></li>
<li><a href='#Coalesce'><p>Return the First Element Not Being NA</p></a></li>
<li><a href='#CochranArmitageTest'><p>Cochran-Armitage Test for Trend</p></a></li>
<li><a href='#CochranQTest'>
<p>Cochran's Q test</p></a></li>
<li><a href='#CoefVar'><p>Coefficient of Variation</p></a></li>
<li><a href='#CohenD'><p>Cohen's Effect Size</p></a></li>
<li><a href='#CohenKappa'><p>Cohen's Kappa and Weighted Kappa</p>
</p></a></li>
<li><a href='#CollapseTable'><p>Collapse Levels of a Table</p></a></li>
<li><a href='#ColorLegend'><p> Add a ColorLegend to a Plot</p></a></li>
<li><a href='#ColToGrey'><p>Convert Colors to Grey/Grayscale</p></a></li>
<li><a href='#ColToHex'><p>Convert a Color or a RGB-color Into Hex String</p></a></li>
<li><a href='#ColToHsv'><p>R Color to HSV Conversion</p>
</p></a></li>
<li><a href='#ColToOpaque'><p>Equivalent Opaque Color for Transparent Color</p></a></li>
<li><a href='#ColToRgb'><p>Color to RGB Conversion</p>
</p></a></li>
<li><a href='#ColumnWrap'><p>Column Wrap</p></a></li>
<li><a href='#CombPairs'><p>Get All Pairs Out of One or Two Sets of Elements</p></a></li>
<li><a href='#CompleteColumns'><p>Find Complete Columns</p></a></li>
<li><a href='#ConDisPairs'><p>Concordant and Discordant Pairs</p></a></li>
<li><a href='#Conf'><p>Confusion Matrix And Associated Statistics</p></a></li>
<li><a href='#ConnLines'><p>Add Connection Lines to a Barplot</p></a></li>
<li><a href='#ConoverTest'><p>Conover's Test of Multiple Comparisons</p></a></li>
<li><a href='#Contrasts'><p>Pairwise Contrasts</p></a></li>
<li><a href='#ConvUnit'><p>Unit Conversion and Metrix Prefixes</p></a></li>
<li><a href='#Cor'><p>Covariance and Correlation (Matrices)</p></a></li>
<li><a href='#CorPart'><p>Find the Correlations for a Set x of Variables With Set y Removed</p></a></li>
<li><a href='#CorPolychor'><p>Polychoric Correlation</p></a></li>
<li><a href='#CountCompCases'><p>Count Complete Cases</p></a></li>
<li><a href='#CountWorkDays'><p>Count Work Days Between Two Dates</p></a></li>
<li><a href='#CourseData'><p>Get HWZ Datasets</p></a></li>
<li><a href='#CramerVonMisesTest'><p>Cramer-von Mises Test for Normality</p></a></li>
<li><a href='#CronbachAlpha'><p>Cronbach's Coefficient Alpha</p></a></li>
<li><a href='#Cross'><p>Vector Cross Product</p></a></li>
<li><a href='#CrossN'><p>n-dimensional Vector Cross Product</p></a></li>
<li><a href='#Cstat'><p>C Statistic (Area Under the ROC Curve)</p></a></li>
<li><a href='#CutAge'><p>Create a Factor Variable by Cutting an Age Variable</p></a></li>
<li><a href='#CutQ'><p>Create a Factor Variable Using the Quantiles of a Continuous Variable</p></a></li>
<li><a href='#d.countries'><p>ISO 3166-1 Country Codes</p></a></li>
<li><a href='#d.diamonds'><p> Data diamonds</p></a></li>
<li><a href='#d.periodic'><p>Periodic Table of Elements</p></a></li>
<li><a href='#d.pizza'><p>Data pizza</p></a></li>
<li><a href='#d.whisky'><p>Classification of Scotch Single Malts</p></a></li>
<li><a href='#Datasets+20for+20Simulation'><p>Datasets for Probabilistic Simulation</p></a></li>
<li><a href='#Date+20Functions'><p>Basic Date Functions</p></a></li>
<li><a href='#day.name'><p>Build-in Constants Extension</p></a></li>
<li><a href='#DegToRad'><p>Convert Degrees to Radians and Vice Versa</p></a></li>
<li><a href='#Depreciation'><p>Several Methods of Depreciation of an Asset</p></a></li>
<li><a href='#Desc'><p>Describe Data</p>
</a></li>
<li><a href='#DescTools+20Aliases'><p>Some Aliases Set for Convenience</p></a></li>
<li><a href='#DescTools+20Palettes'><p>Some Custom Palettes</p></a></li>
<li><a href='#DescToolsOptions'><p>DescTools Options</p></a></li>
<li><a href='#DigitSum'><p>Calculate Digit Sum</p></a></li>
<li><a href='#DivCoef'><p>Rao's Diversity Coefficient</p></a></li>
<li><a href='#DivCoefMax'><p>Maximal value of Rao's diversity coefficient also called</p>
quadratic entropy</a></li>
<li><a href='#Divisors'><p>Calculate Divisors</p></a></li>
<li><a href='#DoBy'><p>Evaluates a Function Groupwise</p></a></li>
<li><a href='#DoCall'><p>Fast Alternative To The Internal <code>do.call</code></p></a></li>
<li><a href='#Dot'><p>Scalar Product</p></a></li>
<li><a href='#DrawArc'><p>Draw Elliptic Arc(s)</p></a></li>
<li><a href='#DrawBand'><p>Draw Confidence Band</p></a></li>
<li><a href='#DrawBezier'><p>Draw a Bezier Curve</p></a></li>
<li><a href='#DrawCircle'><p>Draw a Circle</p></a></li>
<li><a href='#DrawEllipse'><p>Draw an Ellipse</p></a></li>
<li><a href='#DrawRegPolygon'><p>Draw Regular Polygon(s)</p></a></li>
<li><a href='#Dummy'><p>Generate Dummy Codes for a Factor</p></a></li>
<li><a href='#DunnettTest'><p>Dunnett's Test for Comparing Several Treatments With a Control</p></a></li>
<li><a href='#DunnTest'><p>Dunn's Test of Multiple Comparisons</p></a></li>
<li><a href='#DurbinWatsonTest'><p>Durbin-Watson Test</p></a></li>
<li><a href='#Entropy'><p>Shannon Entropy and Mutual Information</p></a></li>
<li><a href='#Eps'><p>Greenhouse-Geisser And Huynh-Feldt Epsilons</p></a></li>
<li><a href='#ErrBars'><p>Add Error Bars to an Existing Plot</p></a></li>
<li><a href='#EtaSq'><p>Effect Size Calculations for ANOVAs</p></a></li>
<li><a href='#EX'><p>Expected Value and Variance</p></a></li>
<li><a href='#ExpFreq'><p>Expected Frequencies</p></a></li>
<li><a href='#Extremes'><p>Kth Smallest/Largest Values</p></a></li>
<li><a href='#ExtrVal'><p>Distributions of Maxima and Minima</p></a></li>
<li><a href='#Factorize'><p>Prime Factorization of Integers</p></a></li>
<li><a href='#FctArgs'><p>Retrieve a Function's Arguments</p></a></li>
<li><a href='#Fibonacci'>
<p>Fibonacci Numbers</p></a></li>
<li><a href='#FindColor'><p>Get Color on a Defined Color Range</p></a></li>
<li><a href='#FindCorr'><p>Determine Highly Correlated Variables</p></a></li>
<li><a href='#FisherZ'><p>Fisher-Transformation for Correlation to z-Score</p></a></li>
<li><a href='#FixToTable'><p>Convert a Text to a Table</p></a></li>
<li><a href='#Format'><p>Format Numbers and Dates</p></a></li>
<li><a href='#Frac'><p>Fractional Part and Maximal Digits of a Numeric Value</p></a></li>
<li><a href='#Frechet'><p>The Frechet Distribution</p></a></li>
<li><a href='#Freq'>
<p>Frequency Table for a Single Variable</p></a></li>
<li><a href='#Freq2D'><p>Bivariate (Two-Dimensional) Frequency Distribution</p></a></li>
<li><a href='#GCD+2C+20LCM'><p>Greatest Common Divisor and Least Common Multiple</p></a></li>
<li><a href='#GenExtrVal'><p>The Generalized Extreme Value Distribution</p></a></li>
<li><a href='#GenPareto'><p>The Generalized Pareto Distribution</p></a></li>
<li><a href='#GenRandGroups'><p>Generate Random Groups</p></a></li>
<li><a href='#GeomSn'><p>Geometric Series</p></a></li>
<li><a href='#GeomTrans'><p>Geometric Transformations</p></a></li>
<li><a href='#GetCalls'><p>Return All Used Functions Within a Function</p></a></li>
<li><a href='#GetCurrWrd'><p>Get a Handle to a Running Word/Excel Instance</p></a></li>
<li><a href='#GetNewWrd'>
<p>Create a New Word Instance</p></a></li>
<li><a href='#GetNewXL'><p>Create a New Excel Instance</p></a></li>
<li><a href='#Gini'><p>Gini Coefficient</p></a></li>
<li><a href='#GiniSimpson'><p>Gini-Simpson Coefficient, Gini-Deltas coefficient and Hunter-Gaston Index</p></a></li>
<li><a href='#Gmean'><p>Geometric Mean and Standard Deviation</p></a></li>
<li><a href='#Gompertz'><p>The Gompertz distribution</p></a></li>
<li><a href='#GoodmanKruskalGamma'><p>Goodman Kruskal's Gamma</p></a></li>
<li><a href='#GoodmanKruskalTau'><p>Goodman Kruskal's Tau</p></a></li>
<li><a href='#GTest'><p>G-Test for Count Data</p></a></li>
<li><a href='#Gumbel'><p>The Gumbel Distribution</p></a></li>
<li><a href='#Herfindahl'><p>Concentration Measures</p></a></li>
<li><a href='#HexToCol'><p>Identify Closest Match to a Color Given by a Hexadecimal String</p></a></li>
<li><a href='#HexToRgb'><p>Convert a Hexstring Color to a Matrix With Three Red/Green/Blue Rows</p></a></li>
<li><a href='#Hmean'><p>Harmonic Mean and Its Confidence Interval</p></a></li>
<li><a href='#HmsToSec'><p>Convert h:m:s To/From Seconds</p></a></li>
<li><a href='#HodgesLehmann'><p> Hodges-Lehmann Estimator of Location</p></a></li>
<li><a href='#HoeffD'>
<p>Matrix of Hoeffding's D Statistics</p></a></li>
<li><a href='#HosmerLemeshowTest'>
<p>Hosmer-Lemeshow Goodness of Fit Tests</p></a></li>
<li><a href='#HotellingsT2Test'><p>Hotelling's T2 Test</p></a></li>
<li><a href='#HuberM'><p>Safe (generalized) Huber M-Estimator of Location</p></a></li>
<li><a href='#ICC'><p> Intraclass Correlations (ICC1, ICC2, ICC3 From Shrout and Fleiss)</p></a></li>
<li><a href='#identify.formula'><p>Identify Points In a Plot Using a Formula</p></a></li>
<li><a href='#IdentifyA'><p>Identify Points in Plot Lying Within a Rectangle or Polygon</p></a></li>
<li><a href='#ImputeKnn'>
<p>Fill in NA values with the values of the nearest neighbours</p></a></li>
<li><a href='#InDots'><p>Is a Specific Argument in the Dots-Arguments?</p></a></li>
<li><a href='#IQRw'><p>The (weighted) Interquartile Range</p></a></li>
<li><a href='#IsDate'><p>Check If an Object Is of Type Date</p></a></li>
<li><a href='#IsDichotomous'><p>Test If a Variable Contains Only Two Unique Values</p></a></li>
<li><a href='#IsEuclid'><p>Is a Distance Matrix Euclidean?</p></a></li>
<li><a href='#IsOdd'><p>Checks If An Integer Is Even Or Odd</p></a></li>
<li><a href='#IsPrime'><p>IsPrime Property</p></a></li>
<li><a href='#IsValidHwnd'><p>Check Windows Pointer</p></a></li>
<li><a href='#JarqueBeraTest'><p>(Robust) Jarque Bera Test</p></a></li>
<li><a href='#JonckheereTerpstraTest'><p>Exact Version of Jonckheere-Terpstra Test</p></a></li>
<li><a href='#KappaM'><p>Kappa for m Raters</p></a></li>
<li><a href='#KendallTauA'><p>Kendall's <code class="reqn">\tau_{a}</code></p></a></li>
<li><a href='#KendallTauB'><p>Kendall's <code class="reqn">\tau_{b}</code></p></a></li>
<li><a href='#KendallW'><p>Kendall's Coefficient of Concordance W</p></a></li>
<li><a href='#Keywords'><p>List Keywords For R Manual Pages</p></a></li>
<li><a href='#KrippAlpha'><p>Krippendorff's Alpha Reliability Coefficient</p></a></li>
<li><a href='#Label+2C+20Unit'><p>Label, Unit Attribute of an Object</p></a></li>
<li><a href='#Lambda'><p>Goodman Kruskal Lambda</p></a></li>
<li><a href='#Lc'><p>Lorenz Curve</p></a></li>
<li><a href='#LehmacherTest'><p>Lehmacher's Test for Marginal Homogenity</p></a></li>
<li><a href='#LeveneTest'><p>Levene's Test for Homogeneity of Variance</p></a></li>
<li><a href='#LillieTest'><p>Lilliefors (Kolmogorov-Smirnov) Test for Normality</p></a></li>
<li><a href='#lines.lm'><p>Add a Linear Regression Line</p></a></li>
<li><a href='#lines.loess'>
<p>Add a Loess or a Spline Smoother</p></a></li>
<li><a href='#LineToUser'><p>Convert Line Coordinates To User Coordinates</p></a></li>
<li><a href='#LinScale'><p>Linear Scaling</p></a></li>
<li><a href='#List+20Variety+20Of+20Objects'><p>List Objects, Functions Or Data in a Package</p></a></li>
<li><a href='#LOCF'><p>Last Observation Carried Forward</p></a></li>
<li><a href='#LOF'><p> Local Outlier Factor</p></a></li>
<li><a href='#Logit'><p>Generalized Logit and Inverse Logit Function</p></a></li>
<li><a href='#LogSt'><p>Started Logarithmic Transformation and Its Inverse</p></a></li>
<li><a href='#MAD'><p>Median Absolute Deviation</p></a></li>
<li><a href='#MADCI'><p>Confidence Intervals for Median Absolute Deviations</p></a></li>
<li><a href='#Mar+20and+20Mgp'><p>Set Plot Margins and Distances</p></a></li>
<li><a href='#matpow'><p>Matrix Power</p></a></li>
<li><a href='#Mean'><p>(Weighted) Arithmetic Mean</p></a></li>
<li><a href='#MeanAD'><p>Mean Absolute Deviation From a Center Point</p></a></li>
<li><a href='#MeanCI'>
<p>Confidence Intervals for the Mean</p></a></li>
<li><a href='#MeanCIn'><p>Sample Size for a Given Width of a Confidence Interval for a Mean</p></a></li>
<li><a href='#MeanDiffCI'><p>Confidence Interval For Difference of Means</p></a></li>
<li><a href='#MeanSE'><p>Standard Error of Mean</p></a></li>
<li><a href='#Measures+20of+20Accuracy'><p>Measures of Accuracy</p></a></li>
<li><a href='#Measures+20of+20Shape'>
<p>Skewness and Kurtosis</p></a></li>
<li><a href='#Median'><p>(Weighted) Median Value</p></a></li>
<li><a href='#MedianCI'>
<p>Confidence Interval for the Median</p></a></li>
<li><a href='#Mgsub'><p>Multiple Gsub</p></a></li>
<li><a href='#MHChisqTest'><p>Mantel-Haenszel Chi-Square Test</p></a></li>
<li><a href='#Midx'><p>Find the Midpoints of a Numeric Vector</p></a></li>
<li><a href='#MixColor'><p>Compute the Convex Combination of Two Colors</p></a></li>
<li><a href='#Mode'><p>Mode, Most Frequent Value(s)</p></a></li>
<li><a href='#MosesTest'><p>Moses Test of Extreme Reactions</p></a></li>
<li><a href='#MoveAvg'><p>Moving Average</p></a></li>
<li><a href='#MultinomCI'><p>Confidence Intervals for Multinomial Proportions</p></a></li>
<li><a href='#MultMerge'><p>Merge Multiple Data Frames</p></a></li>
<li><a href='#NALevel'><p>Replace NAs in a Factor by a Given Level</p></a></li>
<li><a href='#NemenyiTest'><p>Nemenyi Test</p></a></li>
<li><a href='#Nf'><p>As Numeric Factor</p></a></li>
<li><a href='#NPV'><p>Short Selection of Financial Mathematical Functions</p></a></li>
<li><a href='#OddsRatio'><p>Odds Ratio Estimation and Confidence Intervals</p></a></li>
<li><a href='#Order'><p>Distributions of Order Statistics</p></a></li>
<li><a href='#ORToRelRisk'><p> Transform Odds Ratio to Relative Risk</p></a></li>
<li><a href='#Outlier'><p>Outlier</p></a></li>
<li><a href='#PageTest'><p>Exact Page Test for Ordered Alternatives</p></a></li>
<li><a href='#PairApply'><p>Pairwise Calculations</p></a></li>
<li><a href='#ParseFormula'><p>Parse a Formula and Create a Model Frame</p></a></li>
<li><a href='#ParseSASDatalines'><p>Parse a SAS Dataline Command</p></a></li>
<li><a href='#PasswordDlg'><p>Password Dialog</p></a></li>
<li><a href='#PDFManual'><p>Get PDF Manual of a Package From CRAN</p></a></li>
<li><a href='#PearsonTest'><p>Pearson Chi-Square Test for Normality</p></a></li>
<li><a href='#PercentRank'><p>Percent Ranks</p></a></li>
<li><a href='#PercTable'><p>Percentage Table</p></a></li>
<li><a href='#Permn'><p>Number and Samples for Permutations or Combinations of a Set</p></a></li>
<li><a href='#Phrase'><p>Phrasing Results of t-Test</p></a></li>
<li><a href='#PlotACF'><p>Combined Plot of a Time Series and Its ACF and PACF</p></a></li>
<li><a href='#PlotArea'><p>Create an Area Plot</p></a></li>
<li><a href='#PlotBag'><p>Bivariate Boxplot</p></a></li>
<li><a href='#PlotBubble'><p>Draw a Bubble Plot</p></a></li>
<li><a href='#PlotCandlestick'><p>Plot Candlestick Chart</p></a></li>
<li><a href='#PlotCashFlow'><p>Cash Flow Plot</p></a></li>
<li><a href='#PlotCirc'><p>Plot Circular Plot</p></a></li>
<li><a href='#PlotConDens'><p>Plot Conditional Densities</p></a></li>
<li><a href='#PlotCorr'><p>Plot a Correlation Matrix</p></a></li>
<li><a href='#PlotDot'><p>Cleveland's Dot Plots</p></a></li>
<li><a href='#PlotECDF'><p>Empirical Cumulative Distribution Function</p></a></li>
<li><a href='#PlotFaces'><p>    Chernoff Faces</p></a></li>
<li><a href='#PlotFdist'><p>Frequency Distribution Plot</p></a></li>
<li><a href='#PlotFun'><p>Plot a Function</p></a></li>
<li><a href='#PlotLinesA'><p>Plot Lines</p></a></li>
<li><a href='#PlotLog'><p>Logarithmic Plot</p></a></li>
<li><a href='#PlotMarDens'><p>Scatterplot With Marginal Densities</p></a></li>
<li><a href='#PlotMiss'><p>Plot Missing Data</p></a></li>
<li><a href='#PlotMonth'><p>Cycle Plot for Seasonal Effects of an Univariate Time Series</p></a></li>
<li><a href='#PlotMosaic'><p>Mosaic Plots</p></a></li>
<li><a href='#PlotMultiDens'><p>Plot Multiple Density Curves</p></a></li>
<li><a href='#PlotPairs'><p>Extended Scatterplot Matrices</p></a></li>
<li><a href='#PlotPolar'><p>Plot Values on a Circular Grid</p></a></li>
<li><a href='#PlotProbDist'><p>Plot Probability Distribution</p></a></li>
<li><a href='#PlotPyramid'><p>Draw a Back To Back Pyramid Plot</p></a></li>
<li><a href='#PlotQQ'><p>QQ-Plot for Any Distribution</p></a></li>
<li><a href='#PlotTernary'><p>Ternary or Triangular Plots</p></a></li>
<li><a href='#PlotTreemap'><p>Create a Treemap</p></a></li>
<li><a href='#PlotVenn'><p>Plot a Venn Diagram</p></a></li>
<li><a href='#PlotViolin'><p> Plot Violins Instead of Boxplots</p></a></li>
<li><a href='#PlotWeb'><p>Plot a Web of Connected Points</p></a></li>
<li><a href='#PMT'><p>Periodic Payment of an Annuity.</p></a></li>
<li><a href='#PoissonCI'><p>Poisson Confidence Interval</p></a></li>
<li><a href='#PolarGrid'><p>Plot a Grid in Polar Coordinates</p></a></li>
<li><a href='#PostHocTest'><p>Post-Hoc Tests</p></a></li>
<li><a href='#power.chisq.test'><p>Power Calculations for ChiSquared Tests</p></a></li>
<li><a href='#PowerPoint+20Interface'><p>Add Slides, Insert Texts and Plots to PowerPoint</p></a></li>
<li><a href='#pRevGumbel'><p>&quot;Reverse&quot; Gumbel Distribution Functions</p></a></li>
<li><a href='#Primes'><p>Find All Primes Less Than n</p></a></li>
<li><a href='#PseudoR2'><p>Pseudo R2 Statistics</p>
</a></li>
<li><a href='#PtInPoly'><p>Point in Polygon</p></a></li>
<li><a href='#Quantile'><p>(Weighted) Sample Quantiles</p></a></li>
<li><a href='#QuantileCI'><p>Confidence Interval for Any Quantile</p></a></li>
<li><a href='#Quot'><p>Lagged Quotients</p></a></li>
<li><a href='#Range'><p>(Robust) Range</p></a></li>
<li><a href='#Rank'><p>Fast Sample Ranks</p></a></li>
<li><a href='#Recode'><p>Recode a Factor</p></a></li>
<li><a href='#Recycle'><p>Recyle a List of Elements</p></a></li>
<li><a href='#RelRisk'><p>Relative Risk</p></a></li>
<li><a href='#Rename'><p>Change Names of a Named Object</p></a></li>
<li><a href='#reorder.factor'><p>Reorder the Levels of a Factor</p></a></li>
<li><a href='#Rev'><p>Reverse Elements of a Vector, a Matrix, a Table, an Array or a Data.frame</p></a></li>
<li><a href='#RevCode'><p>Reverse Codes</p></a></li>
<li><a href='#RevWeibull'><p>The Reverse Weibull Distribution</p></a></li>
<li><a href='#RgbToCmy'><p>Conversion Between RGB and CMYK</p></a></li>
<li><a href='#RgbToCol'><p>Find the Nearest Named R-Color to a Given RGB-Color</p></a></li>
<li><a href='#RndPairs'><p>Create Pairs of Correlated Random Numbers</p></a></li>
<li><a href='#RobScale'><p>Robust Scaling With Median and Mad</p></a></li>
<li><a href='#RomanToInt'><p>Convert Roman Numerals to Integers</p></a></li>
<li><a href='#Rotate'><p>Rotate a Geometric Structure</p></a></li>
<li><a href='#RoundTo'><p>Round to Multiple</p></a></li>
<li><a href='#RSessionAlive'><p>How Long Has the RSession Been Running?</p></a></li>
<li><a href='#rSum21'><p>Random Numbers Adding Up to 1</p></a></li>
<li><a href='#RunsTest'><p>Runs Test for Randomness</p></a></li>
<li><a href='#Sample'><p>Random Samples and Permutations</p></a></li>
<li><a href='#SampleTwins'><p>Sample Twins</p></a></li>
<li><a href='#SaveAs'><p>Saves an R Object Under a Different Name</p></a></li>
<li><a href='#ScheffeTest'><p>Scheffe Test for Pairwise and Otherwise Comparisons</p></a></li>
<li><a href='#SD'><p>(Weighted) Standard Deviation</p></a></li>
<li><a href='#SendOutlookMail'><p>Send a Mail Using Outlook as Mail Client</p></a></li>
<li><a href='#SetAlpha'><p>Add an Alpha Channel To a Color</p></a></li>
<li><a href='#SetNames'><p>Set the Names in an Object</p></a></li>
<li><a href='#Shade'><p>Produce a Shaded Curve</p></a></li>
<li><a href='#ShapiroFranciaTest'><p>Shapiro-Francia Test for Normality</p></a></li>
<li><a href='#SiegelTukeyTest'><p>Siegel-Tukey Test For Equality In Variability</p></a></li>
<li><a href='#SignTest'><p>Sign Test</p></a></li>
<li><a href='#SmoothSpline'><p>Formula Interface For <code>smooth.spline</code></p></a></li>
<li><a href='#Some'>
<p>Return Some Randomly Chosen Elements of an Object</p></a></li>
<li><a href='#Some+20numeric+20checks'>
<p>Check a Vector For Being Numeric, Zero Or a Whole Number</p></a></li>
<li><a href='#SomersDelta'><p>Somers' Delta</p></a></li>
<li><a href='#Sort'><p>Sort a Vector, a Matrix, a Table or a Data.frame</p></a></li>
<li><a href='#SortMixed'><p>Sort Strings with Embedded Numbers Based on Their Numeric</p>
Order</a></li>
<li><a href='#SpearmanRho'><p>Spearman Rank Correlation</p></a></li>
<li><a href='#split.formula'><p>Formula Interface for Split</p></a></li>
<li><a href='#SplitAt'><p>Split a Vector Into Several Pieces at Given Positions</p></a></li>
<li><a href='#SplitPath'><p>Split Path In Drive, Path, Filename</p></a></li>
<li><a href='#SplitToCol'><p>Split Data Frame String Column Into Multiple Columns</p></a></li>
<li><a href='#SplitToDummy'><p>Split Strings of a Vector and Provide Dummy Codes for Found Pieces</p></a></li>
<li><a href='#SpreadOut'><p>Spread Out a Vector of Numbers To a Minimum Interval</p></a></li>
<li><a href='#Stamp'><p>Date/Time/Directory Stamp the Current Plot</p></a></li>
<li><a href='#StdCoef'><p>Standardized Model Coefficients</p></a></li>
<li><a href='#Str'><p>Compactly Display the Structure of any R Object</p></a></li>
<li><a href='#StrAbbr'><p>String Abbreviation</p></a></li>
<li><a href='#StrAlign'><p>String Alignment</p></a></li>
<li><a href='#Strata'><p>Stratified Sampling</p></a></li>
<li><a href='#StrCap'><p> Capitalize the First Letter of a String</p></a></li>
<li><a href='#StrChop'><p>Split a String into a Number of Sections of Defined Length</p></a></li>
<li><a href='#StrCountW'><p>Count Words in a String</p></a></li>
<li><a href='#StrDist'><p>Compute Distances Between Strings</p></a></li>
<li><a href='#StrExtract'><p>Extract Part of a String</p></a></li>
<li><a href='#StripAttr'><p>Remove Attributes from an Object</p></a></li>
<li><a href='#StrIsNumeric'><p>Does a String Contain Only Numeric Data</p></a></li>
<li><a href='#StrLeft+2C+20StrRight'><p>Returns the Left Or the Right Part Of a String</p></a></li>
<li><a href='#StrPad'><p>Pad a String With Justification</p></a></li>
<li><a href='#StrPos'><p>Find Position of First Occurrence Of a String</p></a></li>
<li><a href='#StrRev'><p>Reverse a String</p></a></li>
<li><a href='#StrSpell'><p>Spell a String Using the NATO Phonetic or the Morse Alphabet</p></a></li>
<li><a href='#StrSplit'><p>Split the Elements of a Character Vector</p></a></li>
<li><a href='#StrTrim'>
<p>Remove Leading/Trailing Whitespace From A String</p></a></li>
<li><a href='#StrTrunc'>
<p>Truncate Strings and Add Ellipses If a String is Truncated.</p></a></li>
<li><a href='#StrVal'><p>Extract All Numeric Values From a String</p></a></li>
<li><a href='#StuartMaxwellTest'><p>Stuart-Maxwell Marginal Homogeneity Test</p></a></li>
<li><a href='#StuartTauC'><p>Stuart <code class="reqn">\tau_{c}</code></p></a></li>
<li><a href='#SysInfo'><p>System Information</p></a></li>
<li><a href='#TextContrastColor'><p>Choose Textcolor Depending on Background Color</p></a></li>
<li><a href='#TextToTable'><p>Converts String To a Table</p></a></li>
<li><a href='#TheilU'><p>Theil's U Index of Inequality</p></a></li>
<li><a href='#TitleRect'><p>Plot Boxed Annotation</p></a></li>
<li><a href='#TMod'><p>Comparison Table For Linear Models</p></a></li>
<li><a href='#ToLong+2C+20ToWide'><p>Reshape a Vector From Long to Wide Shape Or Vice Versa</p></a></li>
<li><a href='#TOne'><p>Create Table One Describing Baseline Characteristics</p></a></li>
<li><a href='#ToWrd'><p>Send Objects to Word</p></a></li>
<li><a href='#ToWrdB'><p>Send Objects to Word and Bookmark Them</p></a></li>
<li><a href='#ToWrdPlot'><p>Send a Plot to Word and Bookmark it</p></a></li>
<li><a href='#Triangular'>
<p>The Triangular Distribution</p></a></li>
<li><a href='#Trim'><p>Trim a Vector</p></a></li>
<li><a href='#TTestA'><p>Student's t-Test Based on Sample Statistics</p></a></li>
<li><a href='#TukeyBiweight'><p> Calculate Tukey's Biweight Robust Mean</p></a></li>
<li><a href='#TwoGroups'><p>Describe a Variable by a Factor with Two Levels</p></a></li>
<li><a href='#UncertCoef'><p>Uncertainty Coefficient</p></a></li>
<li><a href='#UnirootAll'>
<p>Finds many (all) roots of one equation within an interval</p></a></li>
<li><a href='#Untable'><p>Recover Original Data From Contingency Table</p></a></li>
<li><a href='#Unwhich'><p>Inverse Which</p></a></li>
<li><a href='#VanWaerdenTest'><p>van der Waerden Test</p></a></li>
<li><a href='#Var'><p>Variance</p></a></li>
<li><a href='#VarCI'><p>Confidence Intervals for the Variance</p></a></li>
<li><a href='#VarTest'><p>ChiSquare Test for One Variance and F Test to Compare Two Variances</p></a></li>
<li><a href='#VecRot'><p>Vector Rotation (Shift Elements)</p></a></li>
<li><a href='#VIF'><p>Variance Inflation Factors</p></a></li>
<li><a href='#Vigenere'><p>Vigenere Cypher</p></a></li>
<li><a href='#VonNeumannTest'><p>Von Neumann's Successive Difference Test</p></a></li>
<li><a href='#wdConst'><p>Word VBA Constants</p></a></li>
<li><a href='#Winsorize'><p>Winsorize (Replace Extreme Values by Less Extreme Ones)</p></a></li>
<li><a href='#WithOptions'><p>Execute Function with Temporary Options</p></a></li>
<li><a href='#WoolfTest'><p>Woolf Test For Homogeneity in 2x2xk Tables</p></a></li>
<li><a href='#WrdBookmark'><p>Some Functions to Handle MS-Word Bookmarks</p></a></li>
<li><a href='#WrdCaption'><p>Insert Caption to Word</p></a></li>
<li><a href='#WrdCellRange'><p>Return the Cell Range Of a Word Table</p></a></li>
<li><a href='#WrdFont'><p>Get or Set the Font in Word</p></a></li>
<li><a href='#WrdFormatCells'><p>Format Cells Of a Word Table</p></a></li>
<li><a href='#WrdMergeCells'><p>Merges Cells Of a Defined Word Table Range</p></a></li>
<li><a href='#WrdPageBreak'><p>Insert a Page Break</p></a></li>
<li><a href='#WrdParagraphFormat'><p>Get or Set the Paragraph Format in Word</p></a></li>
<li><a href='#WrdPlot'><p>Insert Active Plot to Word</p></a></li>
<li><a href='#WrdSaveAs'><p>Open and Save Word Documents</p></a></li>
<li><a href='#WrdStyle'><p>Get or Set the Style in Word</p></a></li>
<li><a href='#WrdTable'><p>Insert a Table in a Word Document</p></a></li>
<li><a href='#WrdTableBorders'><p>Draw Borders to a Word Table</p></a></li>
<li><a href='#XLDateToPOSIXct'><p>Convert Excel Dates to POSIXct</p></a></li>
<li><a href='#XLGetRange'><p>Import Data Directly From Excel</p></a></li>
<li><a href='#XLSaveAs'><p>Save Excel File</p></a></li>
<li><a href='#XLView'>
<p>Use MS-Excel as Viewer for a Data.Frame</p></a></li>
<li><a href='#YuenTTest'><p> Yuen t-Test For Trimmed Means</p></a></li>
<li><a href='#ZeroIfNA'><p>Replace NAs by 0</p></a></li>
<li><a href='#Zodiac'><p>Calculate the Zodiac of a Date</p></a></li>
<li><a href='#ZTest'><p> Z Test for Known Population Standard Deviation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Descriptive Statistics</td>
</tr>
<tr>
<td>Version:</td>
<td>0.99.54</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-03</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.</td>
</tr>
<tr>
<td>Suggests:</td>
<td>RDCOMClient, tcltk, VGAM, R.rsp, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Depends:</td>
<td>base, stats, R (&ge; 4.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, methods, MASS, utils, boot, mvtnorm,
expm, Rcpp (&ge; 0.12.10), rstudioapi, Exact, gld, data.table,
readxl, httr, withr, cli</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="http://www.omegahat.net/R">http://www.omegahat.net/R</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://andrisignorell.github.io/DescTools/">https://andrisignorell.github.io/DescTools/</a>,
<a href="https://github.com/AndriSignorell/DescTools/">https://github.com/AndriSignorell/DescTools/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/AndriSignorell/DescTools/issues">https://github.com/AndriSignorell/DescTools/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-03 16:20:05 UTC; andri</td>
</tr>
<tr>
<td>Author:</td>
<td>Andri Signorell [aut, cre],
  Ken Aho [ctb],
  Andreas Alfons [ctb],
  Nanina Anderegg [ctb],
  Tomas Aragon [ctb],
  Chandima Arachchige [ctb],
  Antti Arppe [ctb],
  Adrian Baddeley [ctb],
  Kamil Barton [ctb],
  Ben Bolker [ctb],
  Hans W. Borchers [ctb],
  Frederico Caeiro [ctb],
  Stephane Champely [ctb],
  Daniel Chessel [ctb],
  Leanne Chhay [ctb],
  Nicholas Cooper [ctb],
  Clint Cummins [ctb],
  Michael Dewey [ctb],
  Harold C. Doran [ctb],
  Stephane Dray [ctb],
  Charles Dupont [ctb],
  Dirk Eddelbuettel [ctb],
  Claus Ekstrom [ctb],
  Martin Elff [ctb],
  Jeff Enos [ctb],
  Richard W. Farebrother [ctb],
  John Fox [ctb],
  Romain Francois [ctb],
  Michael Friendly [ctb],
  Tal Galili [ctb],
  Matthias Gamer [ctb],
  Joseph L. Gastwirth [ctb],
  Vilmantas Gegzna [ctb],
  Yulia R. Gel [ctb],
  Sereina Graber [ctb],
  Juergen Gross [ctb],
  Gabor Grothendieck [ctb],
  Frank E. Harrell Jr [ctb],
  Richard Heiberger [ctb],
  Michael Hoehle [ctb],
  Christian W. Hoffmann [ctb],
  Soeren Hojsgaard [ctb],
  Torsten Hothorn [ctb],
  Markus Huerzeler [ctb],
  Wallace W. Hui [ctb],
  Pete Hurd [ctb],
  Rob J. Hyndman [ctb],
  Christopher Jackson [ctb],
  Matthias Kohl [ctb],
  Mikko Korpela [ctb],
  Max Kuhn [ctb],
  Detlew Labes [ctb],
  Friederich Leisch [ctb],
  Jim Lemon [ctb],
  Dong Li [ctb],
  Martin Maechler [ctb],
  Arni Magnusson [ctb],
  Ben Mainwaring [ctb],
  Daniel Malter [ctb],
  George Marsaglia [ctb],
  John Marsaglia [ctb],
  Alina Matei [ctb],
  David Meyer [ctb],
  Weiwen Miao [ctb],
  Giovanni Millo [ctb],
  Yongyi Min [ctb],
  David Mitchell [ctb],
  Cyril Flurin Moser [ctb],
  Franziska Mueller [ctb],
  Markus Naepflin [ctb],
  Danielle Navarro [ctb],
  Henric Nilsson [ctb],
  Klaus Nordhausen [ctb],
  Derek Ogle [ctb],
  Hong Ooi [ctb],
  Nick Parsons [ctb],
  Sandrine Pavoine [ctb],
  Tony Plate [ctb],
  Luke Prendergast [ctb],
  Roland Rapold [ctb],
  William Revelle [ctb],
  Tyler Rinker [ctb],
  Brian D. Ripley [ctb],
  Caroline Rodriguez [ctb],
  Nathan Russell [ctb],
  Nick Sabbe [ctb],
  Ralph Scherer [ctb],
  Venkatraman E. Seshan [ctb],
  Michael Smithson [ctb],
  Greg Snow [ctb],
  Karline Soetaert [ctb],
  Werner A. Stahel [ctb],
  Alec Stephenson [ctb],
  Mark Stevenson [ctb],
  Ralf Stubner [ctb],
  Matthias Templ [ctb],
  Duncan Temple Lang [ctb],
  Terry Therneau [ctb],
  Yves Tille [ctb],
  Luis Torgo [ctb],
  Adrian Trapletti [ctb],
  Joshua Ulrich [ctb],
  Kevin Ushey [ctb],
  Jeremy VanDerWal [ctb],
  Bill Venables [ctb],
  John Verzani [ctb],
  Pablo J. Villacorta Iglesias [ctb],
  Gregory R. Warnes [ctb],
  Stefan Wellek [ctb],
  Hadley Wickham [ctb],
  Rand R. Wilcox [ctb],
  Peter Wolf [ctb],
  Daniel Wollschlaeger [ctb],
  Joseph Wood [ctb],
  Ying Wu [ctb],
  Thomas Yee [ctb],
  Achim Zeileis [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andri Signorell &lt;andri@signorell.net&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-03 22:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='DescTools-package'> Tools for Descriptive Statistics and Exploratory Data Analysis
</h2><span id='topic+DescTools-package'></span><span id='topic+DescTools'></span>

<h3>Description</h3>

<p>DescTools is an extensive collection of miscellaneous basic statistics functions and comfort wrappers not available in the R basic system for efficient description of data.
The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. Special attention was paid to the integration of various approaches to the calculation of confidence intervals. For most basic statistics functions, variants are included that allow the use of weights. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. <br />
A considerable part of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, <code>NA</code> handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'CamelStyle' was consequently applied to functions borrowed from contributed R packages as well.
<br />
</p>
<p>Feedback, feature requests, bugreports and other suggestions are welcome! Please report problems to Stack Overflow using tag [desctools] or directly to the maintainer.
</p>


<h3>Details</h3>

<p>A grouped list of the functions:
</p>

<table>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<strong>Operators, calculus, transformations:</strong></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic++25+28+29+25">%()%</a>    </td><td style="text-align: left;">      Between operators determine if a value lies within a range [a,b] </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic++25+29+28+25">%)(%</a>    </td><td style="text-align: left;">      Outside operators: %)(%, %](%, %)[%, %][% </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic++25nin+25">%nin%</a>    </td><td style="text-align: left;">     "not in" operator </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic++25overlaps+25">%overlaps%</a>    </td><td style="text-align: left;">     Do two collections have common elements? </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic++25like+25">%like%</a>, <a href="#topic++25like+20any+25">%like any%</a>    </td><td style="text-align: left;">     Simple operator to search for a specified pattern </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic++25+5E+25">%^%</a>    </td><td style="text-align: left;">     Powers of matrices </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Interval">Interval</a>       </td><td style="text-align: left;">    The number of days of the overlapping part </td>
</tr>
<tr>
 <td style="text-align: left;">
             </td><td style="text-align: left;"> of two date periods </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+AUC">AUC</a>        </td><td style="text-align: left;">      Area under the curve </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Primes">Primes</a>     </td><td style="text-align: left;">      Find all primes less than n </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Factorize">Factorize</a>  </td><td style="text-align: left;">      Prime factorization of integers </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Divisors">Divisors</a>  </td><td style="text-align: left;">      All divisors of an integer</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+GCD">GCD</a>      </td><td style="text-align: left;">    Greatest common divisor</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LCM">LCM</a>      </td><td style="text-align: left;">    Least common multiple</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Permn">Permn</a>      </td><td style="text-align: left;">      Determine all possible permutations of a set </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Fibonacci">Fibonacci</a>  </td><td style="text-align: left;">      Generates single Fibonacci numbers or a Fibonacci sequence</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DigitSum">DigitSum</a>  </td><td style="text-align: left;">      Digit sum of a number</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Frac">Frac</a>       </td><td style="text-align: left;">      Return the fractional part of a numeric value </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Ndec">Ndec</a>       </td><td style="text-align: left;">      Count decimal places of a number </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MaxDigits">MaxDigits</a>       </td><td style="text-align: left;">      Maximum used digits for a vector of numbers </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Prec">Prec</a>       </td><td style="text-align: left;">      Precision of a number </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BoxCox">BoxCox</a>, <a href="#topic+BoxCoxInv">BoxCoxInv</a>     </td><td style="text-align: left;">      Box Cox transformation and its inverse transformation </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BoxCoxLambda">BoxCoxLambda</a>       </td><td style="text-align: left;">      Return the optimal lambda for a BoxCox transformation </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LogSt">LogSt</a>, <a href="#topic+LogStInv">LogStInv</a>      </td><td style="text-align: left;">      Calculate started logarithmic transformation and it's inverse</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Logit">Logit</a>, <a href="#topic+LogitInv">LogitInv</a>      </td><td style="text-align: left;">      Generalized logit and inverse logit function </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LinScale">LinScale</a>       </td><td style="text-align: left;">      Simple linear scaling of a vector x </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Winsorize">Winsorize</a>  </td><td style="text-align: left;">      Data cleaning by winsorization </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Trim">Trim</a>  </td><td style="text-align: left;">      Trim data by omitting outlying observations </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CutQ">CutQ</a>       </td><td style="text-align: left;">     Cut a numeric variable into quartiles or other quantiles </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Recode">Recode</a>      </td><td style="text-align: left;">            Recode a factor with altered levels  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Rename">Rename</a>      </td><td style="text-align: left;">            Change name(s) of a named object </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Sort">Sort</a>      </td><td style="text-align: left;">            Sort extension for matrices and data.frames </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SortMixed">SortMixed</a>, <a href="#topic+OrderMixed">OrderMixed</a>    </td><td style="text-align: left;"> Mixed sort order </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Rank">Rank</a>       </td><td style="text-align: left;">      Calculate ranks including dense type for ties  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PercentRank">PercentRank</a>       </td><td style="text-align: left;">      Calculate the percent rank </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+RoundTo">RoundTo</a>       </td><td style="text-align: left;"> Round to a multiple </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Large">Large</a>, <a href="#topic+Small">Small</a>  </td><td style="text-align: left;">    Returns the kth largest, resp. smallest values</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HighLow">HighLow</a> </td><td style="text-align: left;"> Combines <code>Large</code> and <code>Small</code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Rev">Rev</a>      </td><td style="text-align: left;">            Reverses the order of rows and/or columns of a matrix or a data.frame </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Untable">Untable</a>      </td><td style="text-align: left;">            Recreates original list based on a n-dimensional frequency table </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CollapseTable">CollapseTable</a>       </td><td style="text-align: left;">      Collapse some rows/columns in a table. </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Dummy">Dummy</a>      </td><td style="text-align: left;">      Generate dummy codes for a factor </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+FisherZ">FisherZ</a>, <a href="#topic+FisherZInv">FisherZInv</a>      </td><td style="text-align: left;">      Fisher's z-transformation and its inverse </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Midx">Midx</a>       </td><td style="text-align: left;"> Calculate sequentially the midpoints of the elements of a vector</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Unwhich">Unwhich</a>       </td><td style="text-align: left;">   Inverse function to <code><a href="base.html#topic+which">which</a></code>, create a logical vector/matrix from indices </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Vigenere">Vigenere</a>       </td><td style="text-align: left;">      Implements a Vigenere cypher, both encryption and decryption  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BinTree">BinTree</a>, <a href="#topic+PlotBinTree">PlotBinTree</a>       </td><td style="text-align: left;">      Create and plot a binary tree structure with a given length </td>
</tr>
<tr>
 <td style="text-align: left;">

</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Information and manipulation functions:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+AllDuplicated">AllDuplicated</a>       </td><td style="text-align: left;"> Find all values involved in ties </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Closest">Closest</a>       </td><td style="text-align: left;"> Return the value in a vector being closest to a given one</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Coalesce">Coalesce</a>       </td><td style="text-align: left;">      Return the first value in a vector not being <code>NA</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ZeroIfNA">ZeroIfNA</a>, <a href="#topic+NAIfZero">NAIfZero</a>       </td><td style="text-align: left;">   Replace NAs by 0, resp. vice versa </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Impute">Impute</a>       </td><td style="text-align: left;">   Replace NAs by the median or another value </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LOCF">LOCF</a>      </td><td style="text-align: left;">         Imputation of datapoints following the "last observation </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> carried forward" rule </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CombN">CombN</a>       </td><td style="text-align: left;">      Returns the number of subsets out of a list of elements </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CombSet">CombSet</a>       </td><td style="text-align: left;">      Generates all possible subsets out of a list of elements </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CombPairs">CombPairs</a>      </td><td style="text-align: left;">            Generates all pairs out of one or two sets of elements </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SampleTwins">SampleTwins</a>       </td><td style="text-align: left;">   Create sample using stratifying groups </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+RndPairs">RndPairs</a>       </td><td style="text-align: left;">      Create pairs of correlated random numbers </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+RndWord">RndWord</a>       </td><td style="text-align: left;">      Produce random combinations of characters </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsNumeric">IsNumeric</a>       </td><td style="text-align: left;">      Check a vector for being numeric, zero Or a whole number </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsWhole">IsWhole</a>      </td><td style="text-align: left;">            Is x a whole number? </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsDichotomous">IsDichotomous</a>       </td><td style="text-align: left;">   Check if x contains exactly 2 values </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsOdd">IsOdd</a>       </td><td style="text-align: left;">    Is x even or odd? </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsPrime">IsPrime</a>       </td><td style="text-align: left;">  Is x a prime number? </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsZero">IsZero</a>       </td><td style="text-align: left;">   Is numeric(x) == 0, say x &lt; machine.eps? </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsEuclid">IsEuclid</a>       </td><td style="text-align: left;">     Check if a distance matrix is euclidean</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Label">Label</a>, <a href="#topic+Unit">Unit</a>    </td><td style="text-align: left;">            Get or set the <code>label</code>, resp. <code>unit</code>, attribute of an object </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Abind">Abind</a>  </td><td style="text-align: left;">  Bind matrices to n-dimensional arrays     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Append">Append</a>  </td><td style="text-align: left;">  Append elements to several classes of objects     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+VecRot">VecRot</a>, <a href="#topic+VecShift">VecShift</a>  </td><td style="text-align: left;">  Shift the elements of a vector in a circular mode to the right </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> or to the left by n characters.     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Clockwise">Clockwise</a>       </td><td style="text-align: left;">      Transform angles from counter clock into clockwise mode </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+split.formula">split.formula</a>       </td><td style="text-align: left;">      A formula interface for the base function split </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+reorder.factor">reorder.factor</a>       </td><td style="text-align: left;">      Reorder the levels of a factor </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ToLong">ToLong</a>, <a href="#topic+ToWide">ToWide</a>     </td><td style="text-align: left;"> Simple reshaping of a vector </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SetNames">SetNames</a>       </td><td style="text-align: left;">      Set the names, rownames or columnnames in an object and return it</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Some">Some</a>       </td><td style="text-align: left;">      Return some randomly chosen elements of an object </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SplitAt">SplitAt</a>       </td><td style="text-align: left;">      Split a vector into several pieces at given positions </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SplitToCol">SplitToCol</a>       </td><td style="text-align: left;">      Splits the columns of a data frame using a split character</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SplitPath">SplitPath</a>       </td><td style="text-align: left;">      Split a path string in drive, path, filename </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Str">Str</a>       </td><td style="text-align: left;">      Compactly display the structure of any R object </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TextToTable">TextToTable</a>       </td><td style="text-align: left;">      Converts a string to a table </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>String functions:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrCountW">StrCountW</a>      </td><td style="text-align: left;">            Count the words in a string </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrTrim">StrTrim</a>       </td><td style="text-align: left;">      Delete white spaces from a string </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrTrunc">StrTrunc</a>   </td><td style="text-align: left;">      Truncate string on a given length and add ellipses if it really </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> was truncated  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrLeft">StrLeft</a>, <a href="#topic+StrRight">StrRight</a>      </td><td style="text-align: left;">      Returns the left/right part or the a string. </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrAlign">StrAlign</a>       </td><td style="text-align: left;">      Align strings to the left/right/center or to a given character </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrAbbr">StrAbbr</a>       </td><td style="text-align: left;">      Abbreviates a string </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrCap">StrCap</a>      </td><td style="text-align: left;">            Capitalize the first letter of a string  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrPad">StrPad</a>       </td><td style="text-align: left;">      Fill a string with defined characters to fit a given length</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrRev">StrRev</a>      </td><td style="text-align: left;">            Reverse a string </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrChop">StrChop</a>      </td><td style="text-align: left;">          Split a string by a fixed number of characters. </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrExtract">StrExtract</a>       </td><td style="text-align: left;">      Extract a part of a string, defined as regular expression. </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrVal">StrVal</a>      </td><td style="text-align: left;">          Extract numeric values from a string </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrIsNumeric">StrIsNumeric</a>       </td><td style="text-align: left;">    Check whether a string does only contain numeric data </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrPos">StrPos</a>       </td><td style="text-align: left;">      Find position of first occurrence of a string in another one </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StrDist">StrDist</a>      </td><td style="text-align: left;">            Compute Levenshtein or Hamming distance between strings </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+FixToTable">FixToTable</a>       </td><td style="text-align: left;">      Create table out of a running text, by using columns of spaces as delimiter </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Conversion functions:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+AscToChar">AscToChar</a>, <a href="#topic+CharToAsc">CharToAsc</a>       </td><td style="text-align: left;">      Converts ASCII codes to characters and vice versa  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DecToBin">DecToBin</a>, <a href="#topic+BinToDec">BinToDec</a>   </td><td style="text-align: left;">      Converts numbers from binmode to decimal and vice versa  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DecToHex">DecToHex</a>, <a href="#topic+HexToDec">HexToDec</a>   </td><td style="text-align: left;">      Converts numbers from hexmode to decimal and vice versa  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DecToOct">DecToOct</a>, <a href="#topic+OctToDec">OctToDec</a>   </td><td style="text-align: left;">      Converts numbers from octmode to decimal and vice versa  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DegToRad">DegToRad</a>, <a href="#topic+RadToDeg">RadToDeg</a>      </td><td style="text-align: left;">            Convert degrees to radians and vice versa  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CartToPol">CartToPol</a>, <a href="#topic+PolToCart">PolToCart</a>     </td><td style="text-align: left;">            Transform cartesian to polar coordinates and vice versa </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CartToSph">CartToSph</a>, <a href="#topic+SphToCart">SphToCart</a>     </td><td style="text-align: left;">            Transform cartesian to spherical coordinates and vice versa </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+RomanToInt">RomanToInt</a>    </td><td style="text-align: left;">    Convert roman numerals to integers</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+RgbToLong">RgbToLong</a>, <a href="#topic+LongToRgb">LongToRgb</a>       </td><td style="text-align: left;"> Convert a rgb color to a long number and vice versa</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ColToGray">ColToGray</a>, <a href="#topic+ColToGrey">ColToGrey</a>  </td><td style="text-align: left;">  Convert colors to gcrey/grayscale     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ColToHex">ColToHex</a>, <a href="#topic+HexToCol">HexToCol</a>  </td><td style="text-align: left;">   Convert a color into hex string    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HexToRgb">HexToRgb</a> </td><td style="text-align: left;">  Convert a hexnumber to an RGB-color</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ColToHsv">ColToHsv</a>  </td><td style="text-align: left;">   R color to HSV conversion  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ColToRgb">ColToRgb</a>, <a href="#topic+RgbToCol">RgbToCol</a>  </td><td style="text-align: left;">    Color to RGB conversion and back   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ConvUnit">ConvUnit</a>       </td><td style="text-align: left;">      Return the most common unit conversions </td>
</tr>
<tr>
 <td style="text-align: left;">

</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Colors:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SetAlpha">SetAlpha</a>   </td><td style="text-align: left;">  Add transperancy (alpha channel) to a color.     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ColorLegend">ColorLegend</a>  </td><td style="text-align: left;">   Add a color legend to a plot    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+FindColor">FindColor</a>  </td><td style="text-align: left;">   Get color on a defined color range    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MixColor">MixColor</a>  </td><td style="text-align: left;">   Get the mix of two colors  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TextContrastColor">TextContrastColor</a> </td><td style="text-align: left;">   Choose textcolor depending on background color    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Pal">Pal</a> </td><td style="text-align: left;">   Some custom color palettes    </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Plots (low level):</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Canvas">Canvas</a>  </td><td style="text-align: left;">    Canvas for geometric plotting   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Mar">Mar</a>  </td><td style="text-align: left;">    Set margins more comfortably.  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Asp">Asp</a>       </td><td style="text-align: left;">      Return aspect ratio of the current plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LineToUser">LineToUser</a>       </td><td style="text-align: left;">      Convert line coordinates to user coordinates </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+lines.loess">lines.loess</a>   </td><td style="text-align: left;">    Add a loess smoother and its CIs to an existing plot   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+lines.lm">lines.lm</a>       </td><td style="text-align: left;">    Add the prediction of linear model and its CIs to a plot</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+lines.smooth.spline">lines.smooth.spline</a>       </td><td style="text-align: left;">  Add the prediction of a smooth.spline and its CIs to a plot   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BubbleLegend">BubbleLegend</a>       </td><td style="text-align: left;">      Add a legend for bubbles to a bubble plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TitleRect">TitleRect</a>       </td><td style="text-align: left;">      Add a main title to a plot surrounded by a rectangular box </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BarText">BarText</a>       </td><td style="text-align: left;">      Add the value labels to a barplot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ErrBars">ErrBars</a>   </td><td style="text-align: left;">    Add horizontal or vertical error bars to an existing plot   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DrawArc">DrawArc</a>, <a href="#topic+DrawRegPolygon">DrawRegPolygon</a>  </td><td style="text-align: left;">  Draw elliptic, circular arc(s) or regular polygon(s)     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DrawCircle">DrawCircle</a>, <a href="#topic+DrawEllipse">DrawEllipse</a>  </td><td style="text-align: left;">  Draw a circle, a circle annulus or a sector or an annulus   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DrawBezier">DrawBezier</a>  </td><td style="text-align: left;">    Draw a Bezier curve   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DrawBand">DrawBand</a>    </td><td style="text-align: left;">  Draw confidence band  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BoxedText">BoxedText</a>  </td><td style="text-align: left;">   Add text surrounded by a box to a plot    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Rotate">Rotate</a>  </td><td style="text-align: left;">  Rotate a geometric structure     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SpreadOut">SpreadOut</a>  </td><td style="text-align: left;">  Spread out a vector of numbers so that there is a minimum </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> interval between any two elements. This can be used </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> to place textlabels in a plot so that they do not overlap.</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IdentifyA">IdentifyA</a>  </td><td style="text-align: left;">  Helps identifying all the points in a specific area.     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+identify.formula">identify.formula</a>  </td><td style="text-align: left;">  Formula interface for <code><a href="graphics.html#topic+identify">identify</a></code>.     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PtInPoly">PtInPoly</a>  </td><td style="text-align: left;">  Identify all the points within a polygon. </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ConnLines">ConnLines</a>       </td><td style="text-align: left;">   Calculate and insert connecting lines in a barplot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+AxisBreak">AxisBreak</a>       </td><td style="text-align: left;">      Place a break mark on an axis </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Shade">Shade</a>       </td><td style="text-align: left;">      Produce a shaded curve </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Stamp">Stamp</a>       </td><td style="text-align: left;">      Stamp the current plot with Date/Time/Directory or any other expression </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Plots (high level):</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotACF">PlotACF</a>, <a href="#topic+PlotGACF">PlotGACF</a> </td><td style="text-align: left;">  Create a combined plot of a time series including its </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> autocorrelation and partial autocorrelation</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotMonth">PlotMonth</a> </td><td style="text-align: left;">     Plot seasonal effects of a univariate time series</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotArea">PlotArea</a>    </td><td style="text-align: left;">  Create an area plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotBag">PlotBag</a>    </td><td style="text-align: left;">  Create a two-dimensional boxplot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotBagPairs">PlotBagPairs</a>       </td><td style="text-align: left;">      Produce pairwise 2-dimensional boxplots (bagplot) </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotBubble">PlotBubble</a>    </td><td style="text-align: left;">  Draw a bubble plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotCandlestick">PlotCandlestick</a>    </td><td style="text-align: left;">  Plot candlestick chart </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotCirc">PlotCirc</a>    </td><td style="text-align: left;">  Create a circular plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotCorr">PlotCorr</a>    </td><td style="text-align: left;"> Plot a correlation matrix  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotDot">PlotDot</a>    </td><td style="text-align: left;">  Plot a dotchart with confidence intervals </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotFaces">PlotFaces</a>    </td><td style="text-align: left;">  Produce a plot of Chernoff faces  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotFdist">PlotFdist</a>    </td><td style="text-align: left;">  Frequency distribution plot, combination of histogram, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> boxplot and ecdf.plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotMarDens">PlotMarDens</a>    </td><td style="text-align: left;"> Scatterplot with marginal densities  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotMultiDens">PlotMultiDens</a>    </td><td style="text-align: left;">  Plot multiple density curves </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotPolar">PlotPolar</a>    </td><td style="text-align: left;"> Plot values on a circular grid </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotFun">PlotFun</a>    </td><td style="text-align: left;"> Plot mathematical expression or a function </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PolarGrid">PolarGrid</a>    </td><td style="text-align: left;">  Plot a grid in polar coordinates </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotPyramid">PlotPyramid</a>    </td><td style="text-align: left;">  Pyramid plot (back-back histogram) </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotTreemap">PlotTreemap</a>    </td><td style="text-align: left;">   Plot of a treemap.</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotVenn">PlotVenn</a>    </td><td style="text-align: left;">  Plot a Venn diagram </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotViolin">PlotViolin</a>    </td><td style="text-align: left;">   Plot violins instead of boxplots </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotQQ">PlotQQ</a>    </td><td style="text-align: left;">  QQ-plot for an optional distribution</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotWeb">PlotWeb</a>    </td><td style="text-align: left;">  Create a web plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotTernary">PlotTernary</a>    </td><td style="text-align: left;">  Create a triangle or ternary plot </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotMiss">PlotMiss</a>    </td><td style="text-align: left;">  Plot missing values </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotECDF">PlotECDF</a>       </td><td style="text-align: left;">     Plot empirical cumulative distribution function </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotLinesA">PlotLinesA</a>       </td><td style="text-align: left;">      Plot the columns of one matrix against the columns of another </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotLog">PlotLog</a>       </td><td style="text-align: left;">     Create a plot with logarithmic axis and log grid  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PlotMosaic">PlotMosaic</a>       </td><td style="text-align: left;">    Plots a mosaic describing a  contingency table in array form </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Distributions:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
_Benf   </td><td style="text-align: left;">      Benford distribution, including <a href="#topic+qBenf">qBenf</a>, <a href="#topic+dBenf">dBenf</a>, <a href="#topic+rBenf">rBenf</a></td>
</tr>
<tr>
 <td style="text-align: left;">
_ExtrVal       </td><td style="text-align: left;">      Extreme value distribution (<a href="#topic+dExtrVal">dExtrVal</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_Frechet       </td><td style="text-align: left;">      Frechet distribution (<a href="#topic+dFrechet">dFrechet</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_GenExtrVal       </td><td style="text-align: left;">       Generalized Extreme Value Distribution (<a href="#topic+dGenExtrVal">dGenExtrVal</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_GenPareto       </td><td style="text-align: left;">       Generalized Pareto Distribution (<a href="#topic+dGenPareto">dGenPareto</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_Gompertz       </td><td style="text-align: left;">      Gompertz distribution (<a href="#topic+dGompertz">dGompertz</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_Gumbel       </td><td style="text-align: left;">      Gumbel distribution (<a href="#topic+dGumbel">dGumbel</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_NegWeibull   </td><td style="text-align: left;">      Negative Weibull distribution (<a href="#topic+dNegWeibull">dNegWeibull</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_Order       </td><td style="text-align: left;">      Distributions of Order Statistics (<a href="#topic+dOrder">dOrder</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
_RevGumbel       </td><td style="text-align: left;">      Reverse Gumbel distribution (<a href="#topic+dRevGumbel">dRevGumbel</a>),</td>
</tr>
<tr>
 <td style="text-align: left;">
_RevGumbelExp   </td><td style="text-align: left;">      Expontial reverse Gumbel distribution (quantile only)</td>
</tr>
<tr>
 <td style="text-align: left;">
_RevWeibull   </td><td style="text-align: left;">      Reverse Weibull distribution (<a href="#topic+dRevWeibull">dRevWeibull</a>)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Statistics:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Freq">Freq</a>  </td><td style="text-align: left;">    Univariate frequency table   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PercTable">PercTable</a>  </td><td style="text-align: left;">    Bivariate percentage table   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Margins">Margins</a>       </td><td style="text-align: left;">      (Extended) margin tables of a table </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ExpFreq">ExpFreq</a>       </td><td style="text-align: left;">      Expected frequencies of a n-dimensional table </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Mode">Mode</a>  </td><td style="text-align: left;">     Mode, the most frequent value (including frequency)   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Gmean">Gmean</a>, <a href="#topic+Gsd">Gsd</a>  </td><td style="text-align: left;">  Geometric mean and geometric standard deviation     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Hmean">Hmean</a>  </td><td style="text-align: left;">    Harmonic Mean   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Median">Median</a>       </td><td style="text-align: left;">   Extended median function supporting weights and ordered factors </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HuberM">HuberM</a>, <a href="#topic+TukeyBiweight">TukeyBiweight</a>  </td><td style="text-align: left;">    Huber M-estimator of location and Tukey's biweight robust mean   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HodgesLehmann">HodgesLehmann</a>       </td><td style="text-align: left;"> the Hodges-Lehmann estimator</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HoeffD">HoeffD</a>       </td><td style="text-align: left;">   Hoeffding's D statistic </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MeanSE">MeanSE</a>  </td><td style="text-align: left;">   Standard error of mean    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MeanCI">MeanCI</a>, <a href="#topic+MedianCI">MedianCI</a>  </td><td style="text-align: left;">    Confidence interval for the mean and median   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MeanDiffCI">MeanDiffCI</a>  </td><td style="text-align: left;">    Confidence interval for the difference of two means </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MoveAvg">MoveAvg</a>       </td><td style="text-align: left;">  Moving average </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MeanAD">MeanAD</a>  </td><td style="text-align: left;">    Mean absolute deviation   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+VarCI">VarCI</a>  </td><td style="text-align: left;">    Confidence interval for the variance   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CoefVar">CoefVar</a> </td><td style="text-align: left;"> Coefficient of variation and its confidence interval </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+RobScale">RobScale</a>  </td><td style="text-align: left;">   Robust data standardization  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Range">Range</a>  </td><td style="text-align: left;">   (Robust) range  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BinomCI">BinomCI</a>, <a href="#topic+MultinomCI">MultinomCI</a>  </td><td style="text-align: left;">   Confidence intervals for binomial and multinomial proportions    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BinomDiffCI">BinomDiffCI</a>  </td><td style="text-align: left;">   Calculate confidence interval for a risk difference  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BinomRatioCI">BinomRatioCI</a>  </td><td style="text-align: left;">   Calculate confidence interval for the ratio of binomial proportions.  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PoissonCI">PoissonCI</a>       </td><td style="text-align: left;">  Confidence interval for a Poisson lambda </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Skew">Skew</a>, <a href="#topic+Kurt">Kurt</a> </td><td style="text-align: left;">   Skewness and kurtosis    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+YuleQ">YuleQ</a>, <a href="#topic+YuleY">YuleY</a>  </td><td style="text-align: left;">  Yule's Q and Yule's Y      </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TschuprowT">TschuprowT</a>  </td><td style="text-align: left;">  Tschuprow's T     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Phi">Phi</a>, <a href="#topic+ContCoef">ContCoef</a>, <a href="#topic+CramerV">CramerV</a>  </td><td style="text-align: left;">   Phi, Pearson's Contingency Coefficient and Cramer's V    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a>  </td><td style="text-align: left;">  Goodman Kruskal's gamma     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+KendallTauA">KendallTauA</a>  </td><td style="text-align: left;">  Kendall's tau-a     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+KendallTauB">KendallTauB</a>  </td><td style="text-align: left;">  Kendall's tau-b     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StuartTauC">StuartTauC</a>  </td><td style="text-align: left;">  Stuart's tau-c     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SomersDelta">SomersDelta</a>  </td><td style="text-align: left;">  Somers' delta     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Lambda">Lambda</a>  </td><td style="text-align: left;">  Goodman Kruskal's lambda     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+GoodmanKruskalTau">GoodmanKruskalTau</a>  </td><td style="text-align: left;">  Goodman Kruskal's tau    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+UncertCoef">UncertCoef</a>  </td><td style="text-align: left;">  Uncertainty coefficient    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Entropy">Entropy</a>, <a href="#topic+MutInf">MutInf</a>  </td><td style="text-align: left;">  Shannon's entropy, mutual information     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DivCoef">DivCoef</a>, <a href="#topic+DivCoefMax">DivCoefMax</a>    </td><td style="text-align: left;">   Rao's diversity coefficient ("quadratic entropy")</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TheilU">TheilU</a> </td><td style="text-align: left;">  Theil's U1 and U2 coefficient     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Assocs">Assocs</a>       </td><td style="text-align: left;">  Combines the association measures above.  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+OddsRatio">OddsRatio</a>, <a href="#topic+RelRisk">RelRisk</a>  </td><td style="text-align: left;">   Odds ratio and relative risk    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ORToRelRisk">ORToRelRisk</a>       </td><td style="text-align: left;">      Transform odds ratio to relative risk </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CohenKappa">CohenKappa</a>, <a href="#topic+KappaM">KappaM</a>  </td><td style="text-align: left;"> Cohen's Kappa, weighted Kappa and Kappa for </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> more than 2 raters      </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CronbachAlpha">CronbachAlpha</a>  </td><td style="text-align: left;">  Cronbach's alpha     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ICC">ICC</a>  </td><td style="text-align: left;">  Intraclass correlations   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+KrippAlpha">KrippAlpha</a>   </td><td style="text-align: left;">  Return Kripp's alpha coefficient </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+KendallW">KendallW</a>     </td><td style="text-align: left;">  Compute the Kendall coefficient of concordance </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Lc">Lc</a>  </td><td style="text-align: left;">   Calculate and plot Lorenz curve    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Gini">Gini</a>, <a href="#topic+Atkinson">Atkinson</a>  </td><td style="text-align: left;">   Gini- and Atkinson coefficient    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Herfindahl">Herfindahl</a>, <a href="#topic+Rosenbluth">Rosenbluth</a>  </td><td style="text-align: left;">  Herfindahl- and Rosenbluth coefficient      </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+GiniSimpson">GiniSimpson</a>       </td><td style="text-align: left;">      Compute Gini-Simpson Coefficient </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CorCI">CorCI</a>  </td><td style="text-align: left;">    Confidence interval for Pearson's correlation coefficient </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CorPart">CorPart</a>       </td><td style="text-align: left;">      Find the correlations for a set x of variables with set y removed </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CorPolychor">CorPolychor</a>  </td><td style="text-align: left;">    Polychoric correlation coefficient </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SpearmanRho">SpearmanRho</a>       </td><td style="text-align: left;">      Spearman rank correlation and its confidence intervals </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ConDisPairs">ConDisPairs</a>       </td><td style="text-align: left;">  Return concordant and discordant pairs of two vectors </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+FindCorr">FindCorr</a>       </td><td style="text-align: left;">      Determine highly correlated variables </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CohenD">CohenD</a>       </td><td style="text-align: left;">      Cohen's Effect Size </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+EtaSq">EtaSq</a>       </td><td style="text-align: left;">      Effect size calculations for ANOVAs </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Contrasts">Contrasts</a>       </td><td style="text-align: left;">      Generate pairwise contrasts for using in a post-hoc test </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Strata">Strata</a>       </td><td style="text-align: left;">      Stratified sampling with equal/unequal probabilities </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Outlier">Outlier</a>  </td><td style="text-align: left;">   Outliers following Tukey's boxplot definition  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LOF">LOF</a>  </td><td style="text-align: left;">  Local outlier factor  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BrierScore">BrierScore</a>       </td><td style="text-align: left;">       Brier score, assessing the quality of predictions of binary events </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Cstat">Cstat</a>       </td><td style="text-align: left;">       C statistic, equivalent to the area under the ROC curve) </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CCC">CCC</a>       </td><td style="text-align: left;">      Lin's concordance correlation coef for agreement on a continuous measure </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MAE">MAE</a>       </td><td style="text-align: left;">      Mean absolute error  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MAPE">MAPE</a>, <a href="#topic+SMAPE">SMAPE</a>       </td><td style="text-align: left;">      Mean absolute and symmetric mean absolute percentage error  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MSE">MSE</a>, <a href="#topic+RMSE">RMSE</a>       </td><td style="text-align: left;">       Mean squared error and root mean squared error</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+NMAE">NMAE</a>, <a href="#topic+NMSE">NMSE</a>     </td><td style="text-align: left;">      Normalized mean absolute and mean squared error </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Conf">Conf</a>       </td><td style="text-align: left;">      Confusion matrix, a cross-tabulation of observed and predicted classes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> with associated statistics </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Sens">Sens</a>, <a href="#topic+Spec">Spec</a>       </td><td style="text-align: left;">     Sensitivity and specificity </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PseudoR2">PseudoR2</a>       </td><td style="text-align: left;"> Variants of pseudo R squared statistics: McFadden, Aldrich-Nelson,</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Nagelkerke, CoxSnell, Effron, McKelvey-Zavoina, Tjur </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Mean">Mean</a>, <a href="#topic+SD">SD</a>, <a href="#topic+Var">Var</a>, <a href="#topic+IQRw">IQRw</a>  </td><td style="text-align: left;">      Variants of base statistics, allowing to define weights: Mean, </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Quantile">Quantile</a>, <a href="#topic+MAD">MAD</a>, <a href="#topic+Cor">Cor</a>    </td><td style="text-align: left;"> standard deviation, variance, quantile, mad, correlation </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+VIF">VIF</a>, <a href="#topic+StdCoef">StdCoef</a>       </td><td style="text-align: left;">      Variance inflation factors and standardised coefficents for linear models </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Tests:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SignTest">SignTest</a>    </td><td style="text-align: left;">  Signtest to test whether two groups are equally sized</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ZTest">ZTest</a>    </td><td style="text-align: left;">   Z--test for known population variance </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TTestA">TTestA</a>       </td><td style="text-align: left;">      Student's t-test based on sample statistics </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+JonckheereTerpstraTest">JonckheereTerpstraTest</a>    </td><td style="text-align: left;">  Jonckheere-Terpstra trend test for medians</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PageTest">PageTest</a>    </td><td style="text-align: left;">  Page test for ordered alternatives</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CochranQTest">CochranQTest</a>    </td><td style="text-align: left;">  Cochran's Q-test to find differences in matched sets </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> of three or more frequencies or proportions.</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+VarTest">VarTest</a>       </td><td style="text-align: left;">      ChiSquare test for one variance and F test for two variances </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SiegelTukeyTest">SiegelTukeyTest</a>    </td><td style="text-align: left;">  Siegel-Tukey test for equality in variability </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SiegelTukeyRank">SiegelTukeyRank</a>     </td><td style="text-align: left;"> Calculate Siegel-Tukey's ranks (auxiliary function)</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LeveneTest">LeveneTest</a>    </td><td style="text-align: left;">  Levene's test for homogeneity of variance</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MosesTest">MosesTest</a>    </td><td style="text-align: left;">  Moses Test of extreme reactions</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+RunsTest">RunsTest</a>    </td><td style="text-align: left;">  Runs test for detecting non-randomness</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DurbinWatsonTest">DurbinWatsonTest</a>    </td><td style="text-align: left;">  Durbin-Watson test for autocorrelation</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BartelsRankTest">BartelsRankTest</a>    </td><td style="text-align: left;">  Bartels rank test for randomness</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+JarqueBeraTest">JarqueBeraTest</a>    </td><td style="text-align: left;">  Jarque-Bera Test for normality</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+AndersonDarlingTest">AndersonDarlingTest</a>    </td><td style="text-align: left;">  Anderson-Darling test for normality</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CramerVonMisesTest">CramerVonMisesTest</a>    </td><td style="text-align: left;">  Cramer-von Mises test for normality</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LillieTest">LillieTest</a>    </td><td style="text-align: left;">  Lilliefors (Kolmogorov-Smirnov) test for normality</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PearsonTest">PearsonTest</a>    </td><td style="text-align: left;">  Pearson chi-square test for normality</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ShapiroFranciaTest">ShapiroFranciaTest</a>    </td><td style="text-align: left;">  Shapiro-Francia test for normality</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+MHChisqTest">MHChisqTest</a>    </td><td style="text-align: left;">  Mantel-Haenszel Chisquare test</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+StuartMaxwellTest">StuartMaxwellTest</a>    </td><td style="text-align: left;">  Stuart-Maxwell marginal homogeneity test</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LehmacherTest">LehmacherTest</a>    </td><td style="text-align: left;">  Lehmacher marginal homogeneity test</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CochranArmitageTest">CochranArmitageTest</a>    </td><td style="text-align: left;">  Cochran-Armitage test for trend in binomial proportions</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BreslowDayTest">BreslowDayTest</a>, <a href="#topic+WoolfTest">WoolfTest</a>   </td><td style="text-align: left;">  Test for homogeneity on 2x2xk tables over strata</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PostHocTest">PostHocTest</a>    </td><td style="text-align: left;">  Post hoc tests by Scheffe, LSD, Tukey for a aov-object</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ScheffeTest">ScheffeTest</a>   </td><td style="text-align: left;">  Multiple comparisons Scheffe test</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DunnTest">DunnTest</a>   </td><td style="text-align: left;">  Dunn's test of multiple comparisons</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DunnettTest">DunnettTest</a>   </td><td style="text-align: left;">  Dunnett's test of multiple comparisons</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ConoverTest">ConoverTest</a>       </td><td style="text-align: left;">      Conover's test of multiple comparisons (following a kruskal test)</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+NemenyiTest">NemenyiTest</a>       </td><td style="text-align: left;">      Nemenyi's test of multiple comparisons </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HotellingsT2Test">HotellingsT2Test</a>   </td><td style="text-align: left;">  Hotelling's T2 test for the one and two sample case</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+YuenTTest">YuenTTest</a>       </td><td style="text-align: left;"> Yuen's robust t-Test with trimmed means and winsorized variances</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BarnardTest">BarnardTest</a>       </td><td style="text-align: left;"> Barnard's test for 2x2 tables</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+BreuschGodfreyTest">BreuschGodfreyTest</a>       </td><td style="text-align: left;">      Breusch-Godfrey test for higher-order serial correlation. </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+GTest">GTest</a>       </td><td style="text-align: left;">      Chi-squared contingency table test and goodness-of-fit test </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HosmerLemeshowTest">HosmerLemeshowTest</a>       </td><td style="text-align: left;">      Hosmer-Lemeshow goodness of fit tests </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+VonNeumannTest">VonNeumannTest</a>       </td><td style="text-align: left;">      Von Neumann's successive difference test </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Date functions:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+day.name">day.name</a>, <a href="#topic+day.abb">day.abb</a> </td><td style="text-align: left;"> Defined names of the days </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+AddMonths">AddMonths</a> </td><td style="text-align: left;">  Add a number of months to a given date     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsDate">IsDate</a> </td><td style="text-align: left;">  Check whether x is a date object     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsWeekend">IsWeekend</a> </td><td style="text-align: left;">  Check whether x falls on a weekend     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsLeapYear">IsLeapYear</a> </td><td style="text-align: left;">  Check whether x is a leap year     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LastDayOfMonth">LastDayOfMonth</a>       </td><td style="text-align: left;"> Return the last day of the month of the date x </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DiffDays360">DiffDays360</a>       </td><td style="text-align: left;">  Calculate the difference of two dates using the 360-days system </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="base.html#topic+Date">Date</a>  </td><td style="text-align: left;">     Create a date from numeric representation of year, month, day   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Day">Day</a>, <a href="#topic+Month">Month</a>, <a href="#topic+Year">Year</a>  </td><td style="text-align: left;">     Extract part of a date  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Hour">Hour</a>, <a href="#topic+Minute">Minute</a>, <a href="#topic+Second">Second</a>  </td><td style="text-align: left;">     Extract part of time   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Week">Week</a>, <a href="#topic+Weekday">Weekday</a>  </td><td style="text-align: left;">    Returns ISO week and weekday of a date   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Quarter">Quarter</a>  </td><td style="text-align: left;">  Quarter of a date     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Timezone">Timezone</a>  </td><td style="text-align: left;">  Timezone of a POSIXct/POSIXlt date     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+YearDay">YearDay</a>, <a href="#topic+YearMonth">YearMonth</a>  </td><td style="text-align: left;">  The day in the year of a date     </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Now">Now</a>, <a href="#topic+Today">Today</a>  </td><td style="text-align: left;">     Get current date or date-time  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+HmsToSec">HmsToSec</a>, <a href="#topic+SecToHms">SecToHms</a>  </td><td style="text-align: left;">   Convert h:m:s times to seconds and vice versa  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Overlap">Overlap</a>       </td><td style="text-align: left;">      Determine if and how extensively two date ranges overlap </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Zodiac">Zodiac</a>  </td><td style="text-align: left;">  The zodiac sign of a date :-)   </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Finance functions:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+OPR">OPR</a>  </td><td style="text-align: left;">  One period returns (simple and log returns)</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+NPV">NPV</a>  </td><td style="text-align: left;">  Net present value</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+NPVFixBond">NPVFixBond</a>       </td><td style="text-align: left;">      Net present value for fix bonds</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IRR">IRR</a> </td><td style="text-align: left;">  Internal rate of return</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+YTM">YTM</a>       </td><td style="text-align: left;">     Return yield to maturity for a bond </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SLN">SLN</a>, <a href="#topic+DB">DB</a>, <a href="#topic+SYD">SYD</a>       </td><td style="text-align: left;">     Several methods of depreciation of an asset </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>GUI-Helpers:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PasswordDlg">PasswordDlg</a>    </td><td style="text-align: left;">  Display a dialog containing an edit field, showing only ***. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Reporting, InOut:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+CatTable">CatTable</a>  </td><td style="text-align: left;">  Print a table with the option to have controlled linebreaks </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Format">Format</a>, <a href="#topic+Fmt">Fmt</a>  </td><td style="text-align: left;">  Easy format for numbers and dates      </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Desc">Desc</a>  </td><td style="text-align: left;">   Produce a rich description of an object    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Abstract">Abstract</a>  </td><td style="text-align: left;">   Display compact overview of the structure of a data frame   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TMod">TMod</a>  </td><td style="text-align: left;">  Create comparison table for (general) linear models    </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+TOne">TOne</a>  </td><td style="text-align: left;">   Create "Table One"" describing baseline characteristics   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+GetNewWrd">GetNewWrd</a>, <a href="#topic+GetNewXL">GetNewXL</a>, <a href="#topic+GetNewPP">GetNewPP</a>     </td><td style="text-align: left;">   Create a new Word, Excel or PowerPoint Instance  </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+GetCurrWrd">GetCurrWrd</a>, <a href="#topic+GetCurrXL">GetCurrXL</a>, <a href="#topic+GetCurrPP">GetCurrPP</a>    </td><td style="text-align: left;">  Get a handle to a running Word, Excel or PowerPoint instance </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdKill">WrdKill</a>, <a href="#topic+XLKill">XLKill</a>       </td><td style="text-align: left;">      Ends a (possibly hidden) Word/Excel process </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+IsValidHwnd">IsValidHwnd</a>       </td><td style="text-align: left;">  Check if the handle to a MS Office application is valid or outdated </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdCaption">WrdCaption</a>    </td><td style="text-align: left;"> Insert a title in Word   </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdFont">WrdFont</a>   </td><td style="text-align: left;">  Get and set the font for the current selection in Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdParagraphFormat">WrdParagraphFormat</a>    </td><td style="text-align: left;"> Get and set the paragraph format </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdTable">WrdTable</a>       </td><td style="text-align: left;">      Create a table in Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdCellRange">WrdCellRange</a>       </td><td style="text-align: left;">   Select a cell range of a table in Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdMergeCells">WrdMergeCells</a>       </td><td style="text-align: left;">      Merge cells of a table in Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdFormatCells">WrdFormatCells</a>       </td><td style="text-align: left;">      Format selected cells of a table in word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdTableBorders">WrdTableBorders</a>       </td><td style="text-align: left;">    Set or edit table border style of a table in Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ToWrd">ToWrd</a>, <a href="#topic+ToXL">ToXL</a>    </td><td style="text-align: left;">  Mord flexible wrapper to send diverse objects to Word, resp. Excel </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdPlot">WrdPlot</a>    </td><td style="text-align: left;">   Insert the active plot to Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdInsertBookmark">WrdInsertBookmark</a>    </td><td style="text-align: left;"> Insert a new bookmark in a Word document </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdDeleteBookmark">WrdDeleteBookmark</a>    </td><td style="text-align: left;"> Delete an existing bookmark in a Word document </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdGoto">WrdGoto</a>    </td><td style="text-align: left;"> Place cursor to a specific bookmark, or another text position. </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdUpdateBookmark">WrdUpdateBookmark</a>    </td><td style="text-align: left;"> Update the text of a bookmark's range</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdSaveAs">WrdSaveAs</a>     </td><td style="text-align: left;">      Saves documents in Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+WrdStyle">WrdStyle</a>     </td><td style="text-align: left;">      Get and set the style of a paragraph in Word </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+XLDateToPOSIXct">XLDateToPOSIXct</a>       </td><td style="text-align: left;">      Convert XL-Date format to POSIXct format </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+XLGetRange">XLGetRange</a>    </td><td style="text-align: left;">  Get the values of one or several cell range(s) in Excel </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+XLGetWorkbook">XLGetWorkbook</a>    </td><td style="text-align: left;">  Get the values of all sheets of an Excel workbook </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+XLView">XLView</a>    </td><td style="text-align: left;">   Use Excel as viewer for a data.frame </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PpPlot">PpPlot</a>    </td><td style="text-align: left;">   Insert active plot to PowerPoint </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PpAddSlide">PpAddSlide</a>       </td><td style="text-align: left;">      Adds a slide to a PowerPoint presentation </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PpText">PpText</a>       </td><td style="text-align: left;">      Adds a textbox with text to a PP-presentation </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ParseSASDatalines">ParseSASDatalines</a>       </td><td style="text-align: left;">      Parse a SAS "datalines" statement to read data </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Tools:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PairApply">PairApply</a>       </td><td style="text-align: left;">  Helper for calculating functions pairwise </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+LsFct">LsFct</a>, <a href="#topic+LsObj">LsObj</a>      </td><td style="text-align: left;">  List the functions (or the data, all objects) of a package </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+FctArgs">FctArgs</a>      </td><td style="text-align: left;">            Retrieve the arguments of a functions </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+InDots">InDots</a>       </td><td style="text-align: left;">  Check if an argument is contained in ... argument and return it's value </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+ParseFormula">ParseFormula</a>      </td><td style="text-align: left;">     Parse a formula and return the splitted parts of if </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Recycle">Recycle</a>       </td><td style="text-align: left;">      Recycle a list of elements to the maximal found dimension </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+Keywords">Keywords</a>    </td><td style="text-align: left;">  Get the keywords of a man page</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+SysInfo">SysInfo</a>    </td><td style="text-align: left;">  Get some more information about system and environment</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+DescToolsOptions">DescToolsOptions</a>    </td><td style="text-align: left;">  Get the DescTools specific options</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+PDFManual">PDFManual</a>       </td><td style="text-align: left;">      Get the pdf-manual of any package on CRAN and open it</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Data:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+d.pizza">d.pizza</a>       </td><td style="text-align: left;">  Synthetic dataset created for testing the description </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+d.whisky">d.whisky</a>      </td><td style="text-align: left;">   of Scotch Single Malts</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Reference Data:</b></td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+d.units">d.units</a>,  <a href="#topic+d.prefix">d.prefix</a>    </td><td style="text-align: left;">  Unit conversion factors and metric prefixes</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+d.periodic">d.periodic</a>      </td><td style="text-align: left;">  Periodic table of elements</td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+d.countries">d.countries</a>      </td><td style="text-align: left;"> ISO 3166-1 country codes </td>
</tr>
<tr>
 <td style="text-align: left;">
<a href="#topic+roulette">roulette</a>, <a href="#topic+cards">cards</a>,  <a href="#topic+tarot">tarot</a>     </td><td style="text-align: left;">   Datasets for probabilistic simulation</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Warning</h3>

<p>This package is still under development. Although the code seems meanwhile quite stable, until release of version 1.0 (which is expected in hmm: near future?) you should be aware that everything in the package might be subject to change. Backward compatibility is not yet guaranteed. Functions may be deleted or renamed and new syntax may be inconsistent with earlier versions. By release of version 1.0 the &quot;deprecated-defunct process&quot; will be installed.
</p>


<h3>MS-Office</h3>

<p>To make use of MS-Office features you must have Office in one of its variants installed, as well as the package <b>RDCOMClient</b>. This package uses the COM interface to control the Office applications. There is no direct equivalent to COM interface for Mac or Linux, hence the use of these functions is restricted to Windows systems. All <code>Wrd*</code>, <code>XL*</code> and <code>Pp*</code> functions require this basis to run.
</p>
<p><b>RDCOMClient</b> can be installed with: <br />
</p>
<pre>install.packages("RDCOMClient", repos="http://www.omegahat.net/R")</pre>
<p>The omegahat repository does not benefit from the same update service as CRAN. So you may be forced to install a package compiled with an earlier version, which usually is no problem. For R 4.2 you can use:<br />
</p>
<pre>
url &lt;- "http://www.omegahat.net/R/bin/windows/contrib/4.2/RDCOMClient_0.96-1.zip"
install.packages(url, repos=NULL, type="binary")</pre>
<p><b>RDCOMClient</b> does not exist for Mac or Linux, sorry.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell<br />
Helsana Versicherungen AG, Health Sciences, Zurich<br />
HWZ University of Applied Sciences in Business Administration Zurich.<br />
</p>
<p>R is a community project. This can also be seen in this package, which contains R source code and/or documentation previously published elsewhere by (in alphabetical order): <br />
</p>
<p>Ken Aho, Andreas Alfons, Nanina Anderegg, Tomas Aragon, Antti Arppe, Adrian Baddeley, Kamil Barton, Ben Bolker, Hans W. Borchers, Frederico Caeiro, Stephane Champely, Daniel Chessel, Leanne Chhay, Clint Cummins, Michael Dewey, Harold C. Doran, Stephane Dray, Charles Dupont, Dirk Eddelbuettel, Jeff Enos, Claus Ekstrom, Martin Elff, Kamil Erguler, Richard W. Farebrother, John Fox, Romain Francois, Michael Friendly, Tal Galili, Matthias Gamer, Joseph L. Gastwirth, Yulia R. Gel, Juergen Gross, Gabor Grothendieck, Frank E. Harrell Jr, Richard Heiberger, Michael Hoehle, Christian W. Hoffmann, Soeren Hojsgaard, Torsten Hothorn, Markus Huerzeler, Wallace W. Hui, Pete Hurd, Rob J. Hyndman, Pablo J. Villacorta Iglesias, Christopher Jackson, Matthias Kohl, Mikko Korpela, Max Kuhn, Detlew Labes, Duncan Temple Lang, Friederich Leisch, Jim Lemon, Dong Li, Martin Maechler, Arni Magnusson, Daniel Malter, George Marsaglia, John Marsaglia, Alina Matei, David Meyer, Weiwen Miao, Giovanni Millo, Yongyi Min, David Mitchell, Franziska Mueller, Markus Naepflin, Danielle Navarro, Henric Nilsson, Klaus Nordhausen, Derek Ogle, Hong Ooi, Nick Parsons, Sandrine Pavoine, Tony Plate, Roland Rapold, William Revelle, Tyler Rinker, Brian D. Ripley, Caroline Rodriguez, Nathan Russell, Nick Sabbe, Venkatraman E. Seshan, Greg Snow, Michael Smithson, Karline Soetaert, Werner A. Stahel, Alec Stephenson, Mark Stevenson, Matthias Templ, Terry Therneau, Yves Tille, Adrian Trapletti, Joshua Ulrich, Kevin Ushey, Jeremy VanDerWal, Bill Venables, John Verzani, Gregory R. Warnes, Stefan Wellek, Hadley Wickham, Rand R. Wilcox, Peter Wolf, Daniel Wollschlaeger, Thomas Yee, Achim Zeileis
</p>
<p>Special thanks go to Beat Bruengger, Mathias Frueh, Daniel Wollschlaeger, Vilmantas Gegzna for their valuable contributions and testing.
</p>
<p>The good things come from all these guys, any problems are likely due to my tweaking.
Thank you all! <br />
</p>
<p>Maintainer: Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ******************************************************
# There are no examples defined here. But see the demos:
#
# demo(describe)
# demo(plots))
#
# ******************************************************
</code></pre>

<hr>
<h2 id='+25c+25'>Concatenates Two Strings Without Any Separator
</h2><span id='topic++25c+25'></span><span id='topic+Concatenate+20Strings'></span>

<h3>Description</h3>

<p>%c% is just a short operator implementation for paste(x, y, separator=&quot;&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %c% y

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25c+2B25_+3A_x">x</code></td>
<td>
<p>first string
</p>
</td></tr>
<tr><td><code id="+2B25c+2B25_+3A_y">y</code></td>
<td>
<p>second string, which will be pasted behind the first one.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>R-Core does not consider it a good idea to use + as an operator not being commutative. So we use c here.
<br />
See the discussion:
<a href="https://stat.ethz.ch/pipermail/r-devel/2006-August/039013.html">https://stat.ethz.ch/pipermail/r-devel/2006-August/039013.html</a><br />
and <a href="https://stackoverflow.com/questions/1319698/why-doesnt-operate-on-characters-in-r?lq=1">https://stackoverflow.com/questions/1319698/why-doesnt-operate-on-characters-in-r?lq=1</a><br />
</p>
<p>Still the paste syntax seems sometimes clumsy in daily life and so %c% might spare some keys.
</p>


<h3>Value</h3>

<p> returns the concatenation as string.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Between">Between</a></code>, <code><a href="#topic++25like+25">%like%</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>"foo" %c% "bar"

# works with numerics as well
345 %c% 457
</code></pre>

<hr>
<h2 id='+25like+25'>Like Operator
</h2><span id='topic++25like+25'></span><span id='topic++25like+20any+25'></span>

<h3>Description</h3>

<p>The like operator is a simple wrapper for <code><a href="base.html#topic+grep">grep</a>(..., value=TRUE)</code>, whose complexity is hard to crack for R-newbies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %like% pattern

x %like any% pattern
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25like+2B25_+3A_x">x</code></td>
<td>
<p>a vector, typically of character or factor type
</p>
</td></tr>
<tr><td><code id="+2B25like+2B25_+3A_pattern">pattern</code></td>
<td>
<p>simple character string to be matched in the given character vector.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Follows the logic of simple SQL or basic commands.
</p>


<h3>Value</h3>

<p> a vector (numeric, character, factor), matching the mode of <code>x</code>
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+match">match</a></code>, <code><a href="base.html#topic+pmatch">pmatch</a></code>, <code><a href="base.html#topic+grep">grep</a></code>, <code><a href="#topic++25+5B+5D+25">%[]%</a></code>, <code><a href="#topic++25overlaps+25">%overlaps%</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># find names ending on "or"
names(d.pizza) %like% "%or"

# find names starting with "d"
names(d.pizza) %like% "d%"

# ... containing er?
names(d.pizza) %like% "%er%"

# and combined, search for a name containing "un", ending on "or"
# or beginning with "F"
levels(d.pizza$driver) %like any% c("%un%", "%or", "F%")

# the positions on the vector
match(names(d.pizza) %like% "%er%", names(d.pizza))
</code></pre>

<hr>
<h2 id='+25nin+25'>
Find Matching (or Non-Matching) Elements
</h2><span id='topic++25nin+25'></span>

<h3>Description</h3>

<p><code>%nin%</code> is a binary operator, which returns a logical vector indicating
if there is a match or not for its left operand. A true vector element
indicates no match in left operand, false indicates a match.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %nin% table
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25nin+2B25_+3A_x">x</code></td>
<td>

<p>a vector (numeric, character, factor)
</p>
</td></tr>
<tr><td><code id="+2B25nin+2B25_+3A_table">table</code></td>
<td>

<p>a vector (numeric, character, factor), matching the mode of <code>x</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of logical values with length equal to length of <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Frank E Harrell Jr &lt;f.harrell@vanderbilt.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+match">match</a></code>, <code><a href="base.html#topic++25in+25">%in%</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>c('a','b','c') %nin% c('a','b')
</code></pre>

<hr>
<h2 id='+25overlaps+25'>Determines If And How Extensively Two Date Ranges Overlap
</h2><span id='topic++25overlaps+25'></span><span id='topic+Interval'></span><span id='topic+Overlap'></span>

<h3>Description</h3>

<p>%overlaps% determines if two date ranges overlap at all and returns a logical value.
Interval returns the number of days of the overlapping part of the
two date periods. Inspired by the eponymous SQL-functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %overlaps% y

Overlap(x, y)

Interval(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25overlaps+2B25_+3A_x">x</code></td>
<td>
<p>range 1, vector of 2 numeric values or matrix with 2 columns, the first defining the left point the second the right point of the range.
</p>
</td></tr>
<tr><td><code id="+2B25overlaps+2B25_+3A_y">y</code></td>
<td>
<p>range 2, vector of 2 numeric values or matrix with 2 columns, the first defining the left point the second the right point of the range.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>%overlaps%</code> returns <code>TRUE</code> or <code>FALSE</code> depending on if the two ranges overlap. The function <code>Overlap</code> returns the range of the overlapping region as numeric value. This will be 0, if the ranges do not overlap. <br />
<code>Interval</code> returns the width of the empty space between 2 ranges. Again this will be 0 if the ranges overlap.
</p>
<p>To handle overlapping ranges there are 4 cases to consider:
</p>
<pre>
range a:     |--------------|
range b:  |-----|
range c:              |--------|
range d:           |-----|
          1  2  3  4  5  6  7  8</pre>
<p>Ranges a and b overlap, the function <code>Overlap</code> will return the absolute value of the overlapping region (which will be 3 - 2 = 1 in this case). The result will be the same for <code>Overlap(a, b)</code> and <code>Overlap(b, a)</code>.<br /> <code>Interval</code> will have a direction. Ranges b and c do not overlap, <code>Overlap</code> will return 0, <code>%overlaps%</code> FALSE. <code>Interval</code> will return 2 for the case <code>Interval(a, b)</code> and -2 for <code>Interval(b, a)</code>.
</p>
<p>This functions can be of value, if one has to decide, whether confidence intervals overlap or not.
</p>


<h3>Value</h3>

<p> returns a logical vector (match or not for each element of x). <br />
Interval and Overlap return a numeric vector.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p>similar operators: <code><a href="#topic+Between">Between</a></code>, <code><a href="#topic++25like+25">%like%</a></code> <br />
for calculating the overlapping time: <code><a href="base.html#topic+difftime">difftime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as.Date(c("2012-01-03", "2012-02-03")) %overlaps%
  as.Date(c("2012-03-01", "2012-03-03"))
as.Date(c("2012-01-03", "2012-02-03")) %overlaps%
  as.Date(c("2012-01-15", "2012-01-21"))

Interval(as.Date(c("2012-01-03", "2012-02-03")), as.Date(c("2012-03-01", "2012-03-03")))


# both ranges are recyled if necessary
as.Date("2012-01-03") %overlaps% as.Date(c("2012-03-01", "2012-03-03"))

# works with numerics as well
c(1, 18) %overlaps% c(10, 45)
</code></pre>

<hr>
<h2 id='ABCCoords'>Coordinates for &quot;bottomright&quot;, etc.
</h2><span id='topic+ABCCoords'></span>

<h3>Description</h3>

<p>Return the xy.coordinates for the literal positions &quot;bottomright&quot;, etc. as used to place legends.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ABCCoords(x = "topleft", region = "figure", cex = NULL, linset = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ABCCoords_+3A_x">x</code></td>
<td>
<p>one out of <code>"bottomright"</code>, <code>"bottom"</code>, <code>"bottomleft"</code>,
<code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, <code>"topright"</code>, <code>"right"</code>, <code>"center"</code>
</p>
</td></tr>
<tr><td><code id="ABCCoords_+3A_region">region</code></td>
<td>
<p>one out of <code>plot</code> or  <code>figure</code>
</p>
</td></tr>
<tr><td><code id="ABCCoords_+3A_cex">cex</code></td>
<td>
<p>the character extension for the text.
</p>
</td></tr>
<tr><td><code id="ABCCoords_+3A_linset">linset</code></td>
<td>
<p>line inset in lines of text.
</p>
</td></tr>
<tr><td><code id="ABCCoords_+3A_...">...</code></td>
<td>
<p>the dots are passed to the <code>strwidth()</code> and <code>strheight()</code> functions in case there where more specific text formats.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The same logic as for the legend can be useful for placing texts, too.
This function returns the coordinates for the text, which can be used in the specific text functions.
</p>


<h3>Value</h3>

<p>nothing returned
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+text">text</a></code>, <code><a href="#topic+BoxedText">BoxedText</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(x = rnorm(10), type="n", xlab="", ylab="")
# note that plot.new() has to be called before we can grab the geometry
ABCCoords("bottomleft")

lapply(c("bottomleft", "left"), ABCCoords)

plot(x = rnorm(10), type="n", xlab="", ylab="")
text(x=(xy &lt;- ABCCoords("bottomleft", region = "plot"))$xy, 
     labels = "My Maybe Long Text", adj = xy$adj, xpd=NA)

text(x=(xy &lt;- ABCCoords("topleft", region = "figure"))$xy, 
     labels = "My Maybe Long Text", adj = xy$adj, xpd=NA)

plot(x = rnorm(10), type="n", xlab="", ylab="")
sapply(c("topleft", "top", "topright", "left", "center", 
         "right", "bottomleft", "bottom", "bottomright"), 
       function(x) 
         text(x=(xy &lt;- ABCCoords(x, region = "plot", linset=1))$xy, 
              labels = "MyMarginText", adj = xy$adj, xpd=NA)
)


plot(x = rnorm(100), type="n", xlab="", ylab="",
     panel.first={Bg(c("red", "lightyellow"))
             grid()})
xy &lt;- ABCCoords("topleft", region = "plot")
par(xpd=NA)
BoxedText(x=xy$xy$x, y=xy$xy$y, xpad = 1, ypad = 1,
          labels = "My Maybe Long Text", adj = xy$adj, col=SetAlpha("green", 0.8))
</code></pre>

<hr>
<h2 id='Abind'>Combine Multidimensional Arrays</h2><span id='topic+Abind'></span>

<h3>Description</h3>

<p>Base R functions <code>cbind</code> and <code>rbind</code> bind columns and rows, but there's no built-in function for binding higher dimensional datastructures like matrices. <code>Abind</code> takes a sequence of
vectors, matrices, or arrays and produces a single array of
the same or higher dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Abind(..., along = N, rev.along = NULL, new.names = NULL, force.array = TRUE,
      make.names = FALSE, use.first.dimnames = FALSE, hier.names = FALSE,
      use.dnns = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Abind_+3A_...">...</code></td>
<td>
<p> Any number of vectors, matrices, arrays, or data frames.
The dimensions of all the arrays must match, except on one dimension
(specified by <code>along=</code>).  If these arguments are named, the name
will be used for the name of the dimension along which the arrays are
joined.  Vectors are treated as having a dim attribute of length one.
</p>
<p>Alternatively, there can be one (and only one) list argument supplied,
whose components are the objects to be bound together.  Names of the
list components are treated in the same way as argument names.
</p>
</td></tr>
<tr><td><code id="Abind_+3A_along">along</code></td>
<td>
<p>The dimension along which to bind the arrays.
The default is the last dimension, i.e., the maximum length of the dim
attribute of the supplied arrays.  <code>along=</code> can take any
non-negative value up to the minimum length of the dim attribute of
supplied arrays plus one.  When <code>along=</code> has a fractional value, a
value less than 1, or a value greater than N (N is the maximum of the
lengths of the dim attribute of the objects to be bound together), a new
dimension is created in the result.  In these cases, the dimensions of
all arguments must be identical.  </p>
</td></tr>
<tr><td><code id="Abind_+3A_rev.along">rev.along</code></td>
<td>

<p>Alternate way to specify the dimension along which to bind the arrays:
<code>along = N + 1 - rev.along</code>.  This is provided mainly to allow easy
specification of <code>along = N + 1</code> (by supplying
<code>rev.along=0</code>).  If both <code>along</code> and <code>rev.along</code> are
supplied, the supplied value of <code>along</code> is ignored.
</p>
</td></tr>
<tr><td><code id="Abind_+3A_new.names">new.names</code></td>
<td>

<p>If new.names is a list, it is the first choice for the
dimnames attribute of the result.  It should have the same
structure as a dimnames attribute.  If the names for a
particular dimension are <code>NULL</code>, names for this dimension are
constructed in other ways.
</p>
<p>If <code>new.names</code> is a character vector, it is used for dimension
names in the same way as argument names are used.  Zero
length (&quot;&quot;) names are ignored.
</p>
</td></tr>
<tr><td><code id="Abind_+3A_force.array">force.array</code></td>
<td>
<p>  If <code>FALSE</code>, rbind or cbind are
called when possible, i.e., when the arguments are all vectors, and
along is not 1, or when the arguments are vectors or matrices or data
frames and along is 1 or 2.  If rbind or cbind are used, they will
preserve the data.frame classes (or any other class that r/cbind
preserve).  Otherwise, Abind will convert objects to class array.  Thus,
to guarantee that an array object is returned, supply the argument
<code>force.array=TRUE</code>.  Note that the use of rbind or cbind introduces
some subtle changes in the way default dimension names are constructed:
see the examples below.  </p>
</td></tr>
<tr><td><code id="Abind_+3A_make.names">make.names</code></td>
<td>

<p>If <code>TRUE</code>, the last resort for dimnames for the along
dimension will be the deparsed versions of anonymous
arguments.  This can result in cumbersome names when
arguments are expressions. The default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="Abind_+3A_use.first.dimnames">use.first.dimnames</code></td>
<td>

<p>When dimension names are present on more than one
argument, should dimension names for the result be take from
the first available (the default is to take them from the
last available, which is the same behavior as
<code>rbind</code> and <code>cbind</code>.)
</p>
</td></tr>
<tr><td><code id="Abind_+3A_hier.names">hier.names</code></td>
<td>

<p>If <code>TRUE</code>, dimension names on the concatenated dimension will be
composed of the argument name and the dimension names of the objects
being bound.  If a single list argument is supplied, then the names of
the components serve as the argument names.  <code>hier.names</code> can
also have values <code>"before"</code> or <code>"after"</code>; these determine
the order in which the argument name and the dimension name are put
together (<code>TRUE</code> has the same effect as <code>"before"</code>).</p>
</td></tr>
<tr><td><code id="Abind_+3A_use.dnns">use.dnns</code></td>
<td>
<p> (default <code>FALSE</code>) Use names on dimensions, e.g.,
so that <code>names(dimnames(x))</code> is non-empty.  When there are
multiple possible sources for names of dimnames, the value of
<code>use.first.dimnames</code> determines the result.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dimensions of the supplied vectors or arrays do not need
to be identical, e.g., arguments can be a mixture of vectors
and matrices.  <code>Abind</code> coerces arguments by the addition
of one dimension in order to make them consistent with other
arguments and <code>along=</code>.  The extra dimension is
added in the place specified by <code>along=</code>.
</p>
<p>The default action of Abind is to concatenate on the last
dimension, rather than increase the number of dimensions.
For example, the result of calling Abind with vectors is a
longer vector (see first example below).  This differs from
the action of <code>rbind</code> and cbind which is to return a matrix when
called with vectors.  Abind can be made to behave like cbind
on vectors by specifying <code>along=2</code>, and like rbind by
specifying <code>along=0</code>.
</p>
<p>The dimnames of the returned object are pieced together
from the dimnames of the arguments, and the names of the
arguments.  Names for each dimension are searched for in the
following order: new.names, argument name, dimnames (or
names) attribute of last argument, dimnames (or names)
attribute of second last argument, etc.  (Supplying the
argument <code>use.first.dimnames=TRUE</code> changes this to
cause <code>Abind</code> to use dimnames or names from the
first argument first.  The default behavior is the same as
for <code>rbind</code> and <code>cbind</code>: use dimnames
from later arguments.)  If some names are supplied for the
along dimension (either as argument names or dimnames in
arguments), names are constructed for anonymous arguments
unless <code>maken.ames=FALSE</code>.
</p>


<h3>Value</h3>

<p>An array with a dim attribute calculated as follows.
</p>
<p>Let <code>rMin=min(sapply(list(...), function(x) length(dim(x))))</code> and <br />
<code>rMax=max(sapply(list(...), function(x) length(dim(x))))</code> (where
the length of the dimensions of a vector are taken to be 1).  Then <code>rMax</code> should be
equal to or one greater than <code>rMin</code>.
</p>
<p>If <code>along</code> refers to an existing dimension, then the length of
the dim attribute of the result is <code>rMax</code>.  If <code>along</code> does
not refer to an existing dimension, then <code>rMax</code> should equal
<code>rMin</code> and the length of the dim attribute of the result will be <code>rMax+1</code>.
</p>
<p><code>rbind</code> or <code>cbind</code> are
called to compute the result if (a)
<code>force.array=FALSE</code>; and (b) the result will be a
two-dimensional object.
</p>


<h3>Note</h3>

<p>It would be nice to make <code>Abind()</code> an S3 generic, but S3 generics
cannot dispatch off anonymous arguments.
</p>
<p>The ability of <code>Abind()</code> to accept a single list argument removes
much of the need for constructs like <code>do.call("Abind",
  list.of.arrays)</code>.  Instead, just do <code>Abind(list.of.arrays)</code>.  The
direct construct is preferred because <code>do.call()</code> construct can
sometimes consume more memory during evaluation.
</p>


<h3>Author(s)</h3>

<p>Tony Plate &lt;tplate@acm.org&gt; and Richard Heiberger </p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+rbind">rbind</a></code>, <code><a href="base.html#topic+cbind">cbind</a></code>, <code><a href="base.html#topic+array">array</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Five different ways of binding together two matrices
x &lt;- matrix(1:12, 3, 4)
y &lt;- x + 100
dim(Abind(x, y, along=0))     # binds on new dimension before first
dim(Abind(x, y, along=1))     # binds on first dimension
dim(Abind(x, y, along=1.5))
dim(Abind(x, y, along=2))
dim(Abind(x, y, along=3))
dim(Abind(x, y, rev.along=1)) # binds on last dimension
dim(Abind(x, y, rev.along=0)) # binds on new dimension after last

# Unlike cbind or rbind in that the default is to bind
# along the last dimension of the inputs, which for vectors
# means the result is a vector (because a vector is
# treated as an array with length(dim(x))==1).
Abind(x=1:4, y=5:8)

# Like cbind
Abind(x=1:4, y=5:8, along=2)
Abind(x=1:4, matrix(5:20, nrow=4), along=2)
Abind(1:4, matrix(5:20, nrow=4), along=2)

# Like rbind
Abind(x=1:4, matrix(5:20, nrow=4), along=1)
Abind(1:4, matrix(5:20, nrow=4), along=1)

# Create a 3-d array out of two matrices
Abind(x=matrix(1:16, nrow=4), y=matrix(17:32, nrow=4), along=3)

# Use of hier.names
Abind(x=cbind(a=1:3, b=4:6), y=cbind(a=7:9, b=10:12), hier.names=TRUE)

# Use a list argument
Abind(list(x=x, y=x), along=3)
# Use lapply(..., get) to get the objects
an &lt;- c('x', 'y')
names(an) &lt;- an
Abind(lapply(an, get), along=3)
</code></pre>

<hr>
<h2 id='Abstract'>Display Compact Abstract of a Data Frame
</h2><span id='topic+Abstract'></span>

<h3>Description</h3>

<p>Compactly display the content and structure of a data.frame, including variable labels. <code>str</code> is optimised for lists and its output is relatively technical, when it comes to e.g. attributes. <code>summary</code> on the other side already calculates some basic statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Abstract(x, sep = ", ", zero.form = ".", maxlevels = 5, trunc = TRUE, list.len = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Abstract_+3A_x">x</code></td>
<td>
<p>a <code>data.frame</code> to be described
</p>
</td></tr>
<tr><td><code id="Abstract_+3A_sep">sep</code></td>
<td>
<p>the separator for concatenating the levels of a factor
</p>
</td></tr>
<tr><td><code id="Abstract_+3A_zero.form">zero.form</code></td>
<td>
<p>a symbol to be used, when a variable has zero NAs.
</p>
</td></tr>
<tr><td><code id="Abstract_+3A_maxlevels">maxlevels</code></td>
<td>
<p>integer, defining how many factor levels are to be displayed. Default is 12. Set this to Inf, if all levels are needed.</p>
</td></tr>
<tr><td><code id="Abstract_+3A_trunc">trunc</code></td>
<td>
<p>logical, defining if level names excceeding the column with should be truncated. Default ist <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="Abstract_+3A_list.len">list.len</code></td>
<td>
<p>numeric; maximum number of list elements to display.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The levels of a factor and describing variable labels (as created by <code><a href="#topic+Label">Label</a></code>) will be wrapped within the columns.
</p>
<p>The first 4 columns are printed with the needed fix width, the last 2 (Levels and Labels) are wrapped within the column. The width is calculated depending on the width of the screen as given by <code>getOption("width")</code>.
</p>
<p>ToWord has an interface for the class <code>abstract</code>.
</p>


<h3>Value</h3>

<p>an object of class <code>abstract</code>, essentially a character matrix with 5 or 6 columns
containing a sequential nr (Nr), the name of the column (ColName), the class (Class), the number of NAs (NAs), the levels if the variable is a factor (Levels) and - if there are any - descriptive labels for the column (Labels).
. </p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+str">str</a></code>, <code><a href="base.html#topic+summary">summary</a></code>, <code><a href="#topic+ColumnWrap">ColumnWrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.mydata &lt;- d.pizza
# let's use some labels
Label(d.mydata) &lt;- "Lorem ipsum dolor sit amet, consetetur sadipscing elitr,
sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat,
sed diam voluptua. At vero eos et accusam."

Label(d.mydata$temperature) &lt;- "Amet, consetetur sadipscing elitr, sed diam nonumy "

Abstract(d.mydata)
</code></pre>

<hr>
<h2 id='AddMonths'>Add a Month to a Date
</h2><span id='topic+AddMonths'></span>

<h3>Description</h3>

<p>Clueless adding numbers of months to a date will in some cases lead to invalid dates, think of e.g. 2012-01-30 + 1 month. <br /> AddMonths ensures that the result is always a valid date, e.g.
<code>as.Date("2013-01-31") + 1 month</code> will be <code>"2013-02-28"</code>. If number <code>n</code> is negative, the months will be subtracted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AddMonths(x, n, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AddMonths_+3A_x">x</code></td>
<td>
<p>a Date object (or something which can be coerced by <code><a href="base.html#topic+as.Date">as.Date</a></code>(x, ...) to such an object)
to which a number of months has to be added.
</p>
</td></tr>
<tr><td><code id="AddMonths_+3A_n">n</code></td>
<td>
<p>the number of months to be added. If n is negative the months will be subtracted.
</p>
</td></tr>
<tr><td><code id="AddMonths_+3A_...">...</code></td>
<td>
<p>the dots are passed to <code><a href="base.html#topic+as.Date">as.Date</a></code>, e.g. for supplying <code>origin</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All parameters will be recyled if necessary.
</p>


<h3>Value</h3>

<p>a vector of class <code>Date</code> with the same dimension as <code>x</code>, containing the transformed dates.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, based on code by Roland Rapold and Antonio
</p>


<h3>References</h3>

<p>Thanks to Antonio: <a href="https://stackoverflow.com/questions/14169620/add-a-month-to-a-date">https://stackoverflow.com/questions/14169620/add-a-month-to-a-date</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as.ym">as.ym</a></code>; Date functions: <code><a href="#topic+Year">Year</a></code>, <code><a href="#topic+Month">Month</a></code>, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># characters will be coerced to Date
AddMonths("2013-01-31", 1)

# negative n
AddMonths(as.Date("2013-03-31"), -1)

# Arguments will be recycled
# (with warning if the longer is not a multiple of length of shorter)
AddMonths(c("2013-01-31", "2013-03-31", "2013-10-31", "2013-12-31"), c(1,-1))


x &lt;- as.POSIXct(c("2015-01-31", "2015-08-31"))
n &lt;- c(1, 3)
AddMonths(x, n)

# mind the origin if x supplied as numeric ...
x &lt;- as.numeric(as.Date(x))
AddMonths(x, n, origin=as.Date("1970-01-01"))
</code></pre>

<hr>
<h2 id='Agree'>Raw Simple And Extended Percentage Agreement</h2><span id='topic+Agree'></span>

<h3>Description</h3>

<p>Computes raw simple and extended percentage agreement among raters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Agree(x, tolerance = 0, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Agree_+3A_x">x</code></td>
<td>
<p>a data.frame or a <code class="reqn">k \times m</code> matrix, k subjects (in rows) m raters (in columns).</p>
</td></tr>
<tr><td><code id="Agree_+3A_tolerance">tolerance</code></td>
<td>
<p>number of successive rating categories that should be regarded as rater agreement (see details).</p>
</td></tr>
<tr><td><code id="Agree_+3A_na.rm">na.rm</code></td>
<td>

<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. If set to <code>TRUE</code> only the complete cases of the ratings will be used. Defaults to <code>FALSE</code>.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using extended percentage agreement (<code>tolerance != 0</code>) is only possible for numerical values. If tolerance equals 1, for example, raters differing by one scale degree are interpreted as agreeing.
</p>


<h3>Value</h3>

<p>numeric value of coefficient of interrater reliability
</p>
<p>The number of finally (potentially after omitting missing values) used subjects and raters are returned as attributes:
</p>
<table>
<tr><td><code>subjects</code></td>
<td>
<p>the number of subjects examined.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>the number of raters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Gamer &lt;m.gamer@uke.uni-hamburg.de&gt;, <br /> some editorial amendments Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+CohenKappa">CohenKappa</a></code>, <code><a href="#topic+KappaM">KappaM</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>categ &lt;- c("V", "N", "P")
lvls  &lt;- factor(categ, levels=categ)
rtr1  &lt;- rep(lvls, c(60, 30, 10))
rtr2  &lt;- rep(rep(lvls, nlevels(lvls)), c(53,5,2, 11,14,5, 1,6,3))
rtr3  &lt;- rep(rep(lvls, nlevels(lvls)), c(48,8,3, 15,10,7, 3,4,2))

Agree(cbind(rtr1, rtr2))       # Simple percentage Agreement
Agree(data.frame(rtr1, rtr2))  # can be a data.frame
Agree(cbind(rtr1, rtr2, rtr3)) # Simple percentage Agreement

Agree(cbind(rtr1, rtr2), 1)    # Extended percentage Agreement
</code></pre>

<hr>
<h2 id='AllDuplicated'> Index Vector of All Values Involved in Ties
</h2><span id='topic+AllDuplicated'></span>

<h3>Description</h3>

<p>The function <code><a href="base.html#topic+duplicated">duplicated</a></code> returns a logical vector indicating which elements x are duplicates, but will not include the very first appearance of subsequently duplicated elements. <code>AllDuplicated</code> returns an index vector of ALL the values in <code>x</code> which are involved in ties. <br />
So <code>!AllDuplicated</code> can be used to determine all elements of x, which
appear exactly once (thus with frequency 1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AllDuplicated(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AllDuplicated_+3A_x">x</code></td>
<td>
<p>vector of any type.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector of the same dimension as x.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+unique">unique</a></code> returns a unique list of all values in x<br />
<code><a href="base.html#topic+duplicated">duplicated</a></code> returns an index vector flagging all elements, which appeared more than once (leaving out the first appearance!)<br />
<code><a href="base.html#topic+union">union</a></code>(A, B) returns a list with the unique values from A and B<br />
<code><a href="base.html#topic+intersect">intersect</a></code> returns all elements which appear in A and in B<br />
<code><a href="base.html#topic+setdiff">setdiff</a></code>(A, B) returns all elements appearing in A but not in B <br />
<code><a href="base.html#topic+setequal">setequal</a></code>(A, B) returns <code>TRUE</code> if A contains exactly the same elements as B<br />
<code><a href="base.html#topic+split">split</a></code>(A, A) returns a list with all the tied values in A (see examples)<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1:10, 4:6)

AllDuplicated(x)

# compare to:
duplicated(x)

x[!AllDuplicated(x)]

# union, intersect and friends...
A &lt;- c(sort(sample(1:20, 9)),NA)
B &lt;- c(sort(sample(3:23, 7)),NA)

# all elements from A and B (no duplicates)
union(A, B)
# all elements appearing in A and in B
intersect(A, B)
# elements in A, but not in B
setdiff(A, B)
# elements in B, but not in A
setdiff(B, A)
# Does A contain the same elements as B?
setequal(A, B)


# Find ties in a vector x
x &lt;- sample(letters[1:10], 20, replace=TRUE)
ties &lt;- split(x, x)

# count tied groups
sum(sapply(ties, length) &gt; 1)

# length of tied groups
(x &lt;- sapply(ties, length))[x&gt;1]

# by means of table
tab &lt;- table(x)
tab[tab&gt;1]

# count elements involved in ties
sum(tab&gt;1)
# count tied groups
sum(tab[tab&gt;1])
</code></pre>

<hr>
<h2 id='AllIdentical'>Test Multiple Objects for Exact Equality
</h2><span id='topic+AllIdentical'></span>

<h3>Description</h3>

<p>The function <code><a href="base.html#topic+identical">identical</a>()</code> is the safe and reliable way to test two objects for being exactly equal. But it is restricted to the comparison of two objects. <code>AllIdentical()</code> allows the input of multiple objects and returns <code>TRUE</code> in the case that all of them are exactly equal, <code>FALSE</code> in every other case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AllIdentical(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AllIdentical_+3A_...">...</code></td>
<td>
<p>any <code>R</code> objects</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function checks the first object against all others, so if the first object is identical to the second and to the third, then also the second and the third are identical.
(If A=B and A=C then is B=C)
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+identical">identical</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- LETTERS[1:5]
B &lt;- LETTERS[1:5]
C &lt;- LETTERS[1:5]
D &lt;- LETTERS[1:5]
E &lt;- factor(LETTERS[1:5])

# all ok
AllIdentical(A, B, C, D)

# at least one odd man
AllIdentical(A, B, C, D, E)
</code></pre>

<hr>
<h2 id='AndersonDarlingTest'>
Anderson-Darling Test of Goodness-of-Fit
</h2><span id='topic+AndersonDarlingTest'></span>

<h3>Description</h3>

<p>Performs the Anderson-Darling test
of goodness-of-fit to a specified continuous univariate
probability distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AndersonDarlingTest(x, null = "punif", ..., nullname)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AndersonDarlingTest_+3A_x">x</code></td>
<td>

<p>numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="AndersonDarlingTest_+3A_null">null</code></td>
<td>

<p>a function, or a character string giving the name of a function,
to compute the cumulative distribution function for the
null distribution.
</p>
</td></tr>
<tr><td><code id="AndersonDarlingTest_+3A_...">...</code></td>
<td>

<p>additional arguments for the cumulative distribution function.
</p>
</td></tr>
<tr><td><code id="AndersonDarlingTest_+3A_nullname">nullname</code></td>
<td>

<p>optional character string describing the null distribution.<br />
The default is <code>"uniform distribution"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This command performs the Anderson-Darling test
of goodness-of-fit to the distribution specified by the argument
<code>null</code>. It is assumed that the values in <code>x</code> are
independent and identically distributed random values, with some
cumulative distribution function <code class="reqn">F</code>.
The null hypothesis is that <code class="reqn">F</code> is the function
specified by the argument <code>null</code>, while the alternative
hypothesis is that <code class="reqn">F</code> is some other function.
</p>
<p>The procedures currently implemented are for the case of a SIMPLE null hypothesis, that is, where all the parameters of the distribution are known. Note that other packages such as 'normtest' support the test of a COMPOSITE null hypothesis where some or all of the parameters are unknown leading to different results concerning the test statistic and the p-value. Thus in 'normtest' you can test whether the data come from a normal distribution with some mean and variance (which will be estimated from the same data).
</p>
<p>The discrepancies can be large if you don't have a lot of data (say less than 1000 observations).
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code> representing the result of
the hypothesis test.
</p>


<h3>Author(s)</h3>

<p>Original C code by George Marsaglia and John Marsaglia.
<span class="rlang"><b>R</b></span> interface by Adrian Baddeley.
</p>


<h3>References</h3>

<p>Anderson, T.W. and Darling, D.A. (1952)
Asymptotic theory of certain 'goodness-of-fit' criteria based
on stochastic processes.
<em>Annals of Mathematical Statistics</em> <b>23</b>, 193&ndash;212.
</p>
<p>Anderson, T.W. and Darling, D.A. (1954)
A test of goodness of fit.
<em>Journal of the American Statistical Association</em> <b>49</b>, 765&ndash;769.
</p>
<p>Marsaglia, G. and Marsaglia, J. (2004)
Evaluating the Anderson-Darling Distribution.
<em>Journal of Statistical Software</em> <b>9</b> (2), 1&ndash;5.
February 2004.
<a href="https://www.jstatsoft.org/v09/i02">https://www.jstatsoft.org/v09/i02</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> and all other tests for normality.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(10, mean=2, sd=1)
AndersonDarlingTest(x, "pnorm", mean=2, sd=1)
</code></pre>

<hr>
<h2 id='Append'>Append Elements to Objects
</h2><span id='topic+Append'></span><span id='topic+Append.matrix'></span><span id='topic+Append.data.frame'></span><span id='topic+Append.default'></span>

<h3>Description</h3>

<p>Append elements to a number of various objects as vectors, matrices, data.frames and lists. In a matrix either rows or columns can be inserted at any position. In data frames any vectors can be inserted. <code>values</code> will be recycled to the necessary length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Append(x, values, after = NULL, ...)

## S3 method for class 'matrix'
Append(x, values, after = NULL, rows = FALSE, names = NULL, ...)
## S3 method for class 'data.frame'
Append(x, values, after = NULL, rows = FALSE, names = NULL, ...)
## Default S3 method:
Append(x, values, after = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Append_+3A_x">x</code></td>
<td>
<p>object for the elements to be inserted
</p>
</td></tr>
<tr><td><code id="Append_+3A_values">values</code></td>
<td>
<p>the elements to be inserted
</p>
</td></tr>
<tr><td><code id="Append_+3A_after">after</code></td>
<td>
<p>a subscript, after which the values are to be appended. If it's missing the values will be appended after the last element (or column/row).
</p>
</td></tr>
<tr><td><code id="Append_+3A_rows">rows</code></td>
<td>
<p>logical, defining if vector should be added as row or as column. Default is column (<code>rows</code>=<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="Append_+3A_names">names</code></td>
<td>
<p>the dimension names for the inserted elements(s)
</p>
</td></tr>
<tr><td><code id="Append_+3A_...">...</code></td>
<td>
<p>further arguments (not used here)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector <code>x</code> will be recycled to a length of the next multiple of the number of rows (or columns) of the matrix <code>m</code> and will be inserted such that the first inserted row (column) has the index <code>i</code>. If the dimnames are given, they will be used no matter if the matrix m has already dimnames defined or not.
</p>


<h3>Value</h3>

<p>An object containing the values in x with the elements of values appended after the specified element of x.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+rbind">rbind</a></code>, <code><a href="base.html#topic+cbind">cbind</a></code>, <code><a href="base.html#topic+append">append</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Append(1:5, 0:1, after = 3)    # the same as append

# Insert columns and rows
x &lt;- matrix(runif(25), 5)

Append(x, values=1:10, after=2, names = c("X","Y"))
Append(x, values=1:10, after=2)

Append(x, values=1:10, after=2, names = c("X","Y"))
Append(x, values=1:10, after=2)

# append to a data.frame
d.frm &lt;- data.frame("id"   = c(1,2,3),
                    "code" = c("AAA", "BBB", "CCC"),
                    "val"  = c(111, 222, 333))
z &lt;- c(10, 20, 30)

Append(d.frm, z, after=2, names="ZZZ")
</code></pre>

<hr>
<h2 id='Arrow'>Insert an Arrow Into a Plot
</h2><span id='topic+Arrow'></span>

<h3>Description</h3>

<p>Places an arrow into a plot. Two additional arrow heads are implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Arrow(x0, y0, x1, y1, col = par("bg"), border = par("fg"), head = 1,
      cex = 1, lwd = 1, lty = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Arrow_+3A_x0">x0</code>, <code id="Arrow_+3A_y0">y0</code></td>
<td>
<p>coordinates of points <b>from</b> which to draw.
</p>
</td></tr>
<tr><td><code id="Arrow_+3A_x1">x1</code>, <code id="Arrow_+3A_y1">y1</code></td>
<td>
<p>coordinates of points <b>to</b> which to draw. At least one must the supplied.
</p>
</td></tr>
<tr><td><code id="Arrow_+3A_col">col</code></td>
<td>
<p>the color of the line and background color of the arrow head.
</p>
</td></tr>
<tr><td><code id="Arrow_+3A_border">border</code></td>
<td>
<p>color of the arrow head.
</p>
</td></tr><tr><td><code id="Arrow_+3A_head">head</code></td>
<td>
<p>type of head, can be one out of 1:3.
</p>
</td></tr>
<tr><td><code id="Arrow_+3A_cex">cex</code></td>
<td>
<p>extension factor for the arrow head.
</p>
</td></tr>
<tr><td><code id="Arrow_+3A_lwd">lwd</code></td>
<td>
<p>line width
</p>
</td></tr>
<tr><td><code id="Arrow_+3A_lty">lty</code></td>
<td>
<p>line type
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing returned
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+arrows">arrows</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Canvas()
Arrow(1, 1, 0, 0)
</code></pre>

<hr>
<h2 id='as.matrix.xtabs'>Convert xtabs To matrix
</h2><span id='topic+as.matrix.xtabs'></span>

<h3>Description</h3>

<p>This function converts an <code>xtabs</code> object to a <code>matrix</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'xtabs'
as.matrix(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.xtabs_+3A_x">x</code></td>
<td>
<p>an object of class <code>xtabs</code>
</p>
</td></tr>
<tr><td><code id="as.matrix.xtabs_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to or from methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An <code><a href="stats.html#topic+xtabs">xtabs</a></code> object is indeed already a matrix, but won't be converted to a pure matrix by <code>as.matrix.default</code> function, as its class definition will remain unchanged. Some functions expecting a pure matrix may fail, when fed with a <code>xtabs</code> object.
<code>as.matrix.xtabs</code> will drop the classes and the call attribute. <br />
Note that <code><a href="base.html#topic+unclass">unclass</a></code> would as well discard the classes <code>xtabs</code> and <code>table</code>, but retain the <code>"call"</code> attribute.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+as.matrix">as.matrix</a></code>, <code><a href="stats.html#topic+xtabs">xtabs</a></code>, <code><a href="base.html#topic+unclass">unclass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- xtabs( ~ driver + operator, data=d.pizza)

str(tab)
class(tab)

str(as.matrix(tab))
class(as.matrix(tab))
</code></pre>

<hr>
<h2 id='as.ym'>A Class for Dealing with the Yearmonth Format
</h2><span id='topic+as.ym'></span><span id='topic+as.Date.ym'></span><span id='topic+AddMonths.ym'></span>

<h3>Description</h3>

<p>The representation of year and month information in YYYYYMM format as an integer is often handy and a useful and efficient data structure. Adding a number of months to such a date is not quite catchy, however, since the date structure is to be retained. For example, 201201 - 2 [months] is expected to result in 201111 instead of 201199. AddMonthsYM does this job.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
as.ym(x)
## S3 method for class 'ym'
as.Date(x, d = 1, ...)

## S3 method for class 'ym'
AddMonths(x, n, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.ym_+3A_x">x</code></td>
<td>
<p>a vector of integers, representing the dates in the format YYYYMM, to which a number of months has to be added. YYYY must lie in the range of 1000-3000, MM in 1-12.
</p>
</td></tr>
<tr><td><code id="as.ym_+3A_d">d</code></td>
<td>
<p>the day to be used for converting a yearmonth to a date. Default is 1. 
</p>
</td></tr>
<tr><td><code id="as.ym_+3A_n">n</code></td>
<td>
<p>the number of months to be added. If n is negative the months will be subtracted.
</p>
</td></tr>
<tr><td><code id="as.ym_+3A_...">...</code></td>
<td>
<p>further arguments (not used here).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All parameters will be recyled if necessary. The therefore used function <code><a href="base.html#topic+mapply">mapply</a></code> will display a warning, if the longer argument is not a multiple of the length of the shorter one.
</p>


<h3>Value</h3>

<p>a vector of class <code>integer</code> with the same dimension as x, containing the transformed dates.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, originally based on code by Roland Rapold
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AddMonths">AddMonths</a></code>; Date functions, like <code><a href="#topic+Year">Year</a></code>, <code><a href="#topic+Month">Month</a></code>, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Month(as.ym(202408))
Year(as.ym(202408))

Year(as.Date("2024-12-05"))
Year(as.ym(202412))

Month(as.Date("2024-12-05"), fmt = "mm")
Month(as.ym(202412), fmt="mm")

AddMonths(201511, 5)

AddMonths(c(201511, 201302), c(5, 15))
AddMonths(c(201511, 201302), c(5, -4))
</code></pre>

<hr>
<h2 id='AscToChar'>Convert ASCII Codes to Characters and Vice Versa
</h2><span id='topic+AscToChar'></span><span id='topic+CharToAsc'></span>

<h3>Description</h3>

<p>AscToChar returns a character for each ASCII code (integer) supplied.<br />
CharToAsc returns integer codes in <code>0:255</code> for each (one byte) character in all strings in <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AscToChar(i)
CharToAsc(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AscToChar_+3A_i">i</code></td>
<td>
<p>numeric (integer) vector of values in <code>1:255</code>.
</p>
</td></tr>
<tr><td><code id="AscToChar_+3A_x">x</code></td>
<td>
<p>vector of strings.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Only codes in <code>1:127</code> make up the ASCII encoding which should be
identical for all <span class="rlang"><b>R</b></span> versions, whereas the <em>&lsquo;upper&rsquo;</em> half
is often determined from the ISO-8859-1 (aka &ldquo;ISO-Latin 1)&rdquo;
encoding, but may well differ, depending on the locale setting, see
also <code><a href="base.html#topic+Sys.setlocale">Sys.setlocale</a></code>.
</p>
<p>Note that <code>0</code> is no longer allowed since, <span class="rlang"><b>R</b></span> does not allow
<code>\0</code> aka <code>nul</code> characters in a string anymore.
</p>


<h3>Value</h3>

<p><code>AscToChar</code> returns a vector of the same length as i.
<code>CharToAsc</code> returns a list of numeric vectors of character length of each string in x.
</p>


<h3>Author(s)</h3>

<p>unknown guy out there, help text partly taken from M. Maechler's <span class="pkg">sfsmisc</span>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+charToRaw">charToRaw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>(x &lt;- CharToAsc("Silvia"))

# will be pasted together
AscToChar(x)

# use strsplit if the single characters are needed
strsplit(AscToChar(x), split=NULL)

# this would be an alternative, but the latter would be of class raw
DecToHex(CharToAsc("Silvia"))
charToRaw("Silvia")
</code></pre>

<hr>
<h2 id='Asp'>Get Aspect Ratio of the Current Plot
</h2><span id='topic+Asp'></span>

<h3>Description</h3>

<p>Returns the aspect ratio of the current plot in user coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Asp()</code></pre>


<h3>Details</h3>

<p>The aspect ratio of the plot is calculated as
</p>
<pre>
w   &lt;- par("pin")[1] / diff(par("usr")[1:2])
h   &lt;- par("pin")[2] / diff(par("usr")[3:4])
asp &lt;- w/h
</pre>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>Asp()
</code></pre>

<hr>
<h2 id='Association+20measures'>
Cramer's V, Pearson's Contingency Coefficient and Phi Coefficient<br />
Yule's Q and Y, Tschuprow's T
</h2><span id='topic+Phi'></span><span id='topic+ContCoef'></span><span id='topic+CramerV'></span><span id='topic+YuleQ'></span><span id='topic+YuleY'></span><span id='topic+TschuprowT'></span>

<h3>Description</h3>

<p>Calculate Cramer's V, Pearson's contingency coefficient and phi,
Yule's Q and Y and Tschuprow's T of <code>x</code>, if <code>x</code> is a table. If both, <code>x</code> and <code>y</code> are given, then the according table will be built first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Phi(x, y = NULL, ...)
ContCoef(x, y = NULL, correct = FALSE, ...)
CramerV(x, y = NULL, conf.level = NA,
        method = c("ncchisq", "ncchisqadj", "fisher", "fisheradj"), 
        correct = FALSE, ...)

YuleQ(x, y = NULL, ...)
YuleY(x, y = NULL, ...)
TschuprowT(x, y = NULL, correct = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Association+2B20measures_+3A_x">x</code></td>
<td>
<p>can be a numeric vector, a matrix or a table.
</p>
</td></tr>
<tr><td><code id="Association+2B20measures_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="Association+2B20measures_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. This is only implemented for Cramer's V. If set to <code>NA</code> (which is the       default) no confidence interval will be calculated. <br />
See examples for calculating bootstrap intervals.
</p>
</td></tr>
<tr><td><code id="Association+2B20measures_+3A_method">method</code></td>
<td>
<p>string defining the method to calculate confidence intervals for Cramer's V. One out of <code>"ncchisq"</code> (using noncentral chisquare), <code>"ncchisqadj"</code>, <code>"fisher"</code> (using fisher z transformation), <code>"fisheradj"</code> (using fisher z transformation and bias correction). Default is <code>"ncchisq"</code>.</p>
</td></tr>
<tr><td><code id="Association+2B20measures_+3A_correct">correct</code></td>
<td>
<p>logical. Applying to <code>ContCoef</code> this indicates, whether the Sakoda's adjusted Pearson's C should be returned. For <code>CramerV()</code> and <code>TschuprowT()</code> it defines, whether a bias correction should be applied or not. Default is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="Association+2B20measures_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set <code>useNA</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For x either a matrix or two vectors <code>x</code> and <code>y</code> are expected. In latter case <code>table(x, y, ...)</code> is calculated.
The function handles <code>NAs</code> the same way the <code>table</code> function does, so tables are by default calculated with <code>NAs</code> omitted. <br /><br />
A provided matrix is interpreted as a contingency table, which seems in the case of frequency data the natural interpretation
(this is e.g. also what <code><a href="stats.html#topic+chisq.test">chisq.test</a></code> expects). <br /><br />
Use the function <code><a href="#topic+PairApply">PairApply</a></code> (pairwise apply) if the measure should be calculated pairwise for all columns.
This allows matrices of association measures to be calculated the same way <code>cor</code> does. <code>NAs</code> are by default omitted pairwise,
which corresponds to the <code>pairwise.complete</code> option of <code><a href="stats.html#topic+cor">cor</a></code>.
Use <code><a href="stats.html#topic+complete.cases">complete.cases</a></code>, if only the complete cases of a <code>data.frame</code> are to be used. (see examples)
</p>
<p>The maximum value for Phi is <code class="reqn">\sqrt(min(r, c) - 1)</code>. The contingency coefficient goes from 0 to <code class="reqn">\sqrt(\frac{min(r, c) - 1}{min(r, c)})</code>. For the corrected contingency coefficient and for Cramer's V the range is 0 to 1. <br /> A Cramer's V in the range of [0, 0.3] is considered as weak, [0.3,0.7] as medium and &gt; 0.7 as strong.
The minimum value for all is 0 under statistical independence.
</p>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested,<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, <br />
Michael Smithson &lt;michael.smithson@anu.edu.au&gt;  (confidence intervals for Cramer V)
</p>


<h3>References</h3>

<p>Yule, G. Uday (1912) On the methods of measuring association between two attributes. <em>Journal of the Royal Statistical Society, LXXV</em>, 579-652
</p>
<p>Tschuprow, A. A. (1939) <em>Principles of the Mathematical Theory of Correlation</em>, translated by M. Kantorowitsch. W. Hodge &amp; Co.
</p>
<p>Cramer, H. (1946) <em>Mathematical Methods of Statistics</em>. Princeton University Press
</p>
<p>Agresti, Alan (1996) <em>Introduction to categorical data analysis</em>. NY: John Wiley and Sons
</p>
<p>Sakoda, J.M. (1977) Measures of Association for Multivariate Contingency Tables,
<em>Proceedings of the Social Statistics Section of the American Statistical Association</em> (Part III), 777-780.
</p>
<p>Smithson, M.J. (2003) <em>Confidence Intervals, Quantitative Applications in the Social Sciences Series</em>, No. 140. Thousand Oaks, CA: Sage. pp. 39-41
</p>
<p>Bergsma, W. (2013) A bias-correction for Cramer's V and Tschuprow's T
<em>Journal of the Korean Statistical Society</em> 42(3) DOI: 10.1016/j.jkss.2012.10.002
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+table">table</a></code>, <code><a href="#topic+PlotCorr">PlotCorr</a></code>, <code><a href="#topic+PairApply">PairApply</a></code>, <code><a href="#topic+Assocs">Assocs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- table(d.pizza$driver, d.pizza$wine_delivered)
Phi(tab)
ContCoef(tab)
CramerV(tab)
TschuprowT(tab)

# just x and y
CramerV(d.pizza$driver, d.pizza$wine_delivered)

# data.frame
PairApply(d.pizza[,c("driver","operator","area")], CramerV, symmetric = TRUE)


# useNA is passed to table
PairApply(d.pizza[,c("driver","operator","area")], CramerV,
          useNA="ifany", symmetric = TRUE)

d.frm &lt;- d.pizza[,c("driver","operator","area")]
PairApply(d.frm[complete.cases(d.frm),], CramerV, symmetric = TRUE)


m &lt;- as.table(matrix(c(2,4,1,7), nrow=2))
YuleQ(m)
YuleY(m)


# Bootstrap confidence intervals for Cramer's V
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf, p. 1821

tab &lt;- as.table(rbind(
  c(26,26,23,18, 9),
  c( 6, 7, 9,14,23)))
d.frm &lt;- Untable(tab)

n &lt;- 1000
idx &lt;- matrix(sample(nrow(d.frm), size=nrow(d.frm) * n, replace=TRUE), ncol=n, byrow=FALSE)
v &lt;- apply(idx, 2, function(x) CramerV(d.frm[x,1], d.frm[x,2]))
quantile(v, probs=c(0.025,0.975))

# compare this to the analytical ones
CramerV(tab, conf.level=0.95)
</code></pre>

<hr>
<h2 id='Assocs'>Association Measures
</h2><span id='topic+Assocs'></span><span id='topic+print.Assocs'></span>

<h3>Description</h3>

<p>Collects a number of association measures for nominal and ordinal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Assocs(x, conf.level = 0.95, verbose = NULL)

## S3 method for class 'Assocs'
print(x, digits = 4, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Assocs_+3A_x">x</code></td>
<td>
<p>a 2 dimensional contingency table or a matrix.
</p>
</td></tr>
<tr><td><code id="Assocs_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> no confidence interval will be calculated. Default is 0.95.
</p>
</td></tr>
<tr><td><code id="Assocs_+3A_verbose">verbose</code></td>
<td>
<p>integer out of <code>c(2, 1, 3)</code> defining the verbosity of the reported results. 2 (default) means medium, 1 less and 3 extensive results. <br /> Applies only to tables and is ignored else.
</p>
</td></tr>
<tr><td><code id="Assocs_+3A_digits">digits</code></td>
<td>
<p>integer which determines the number of digits used in formatting the measures of association.
</p>
</td></tr>
<tr><td><code id="Assocs_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function wraps the association measures phi, contingency coefficient, Cramer's V, Goodman Kruskal's Gamma, Kendall's Tau-b,
Stuart's Tau-c, Somers' Delta, Pearson and Spearman correlation, Guttman's Lambda, Theil's Uncertainty Coefficient and the mutual information.
</p>


<h3>Value</h3>

<p> numeric matrix, dimension [1:17, 1:3]<br />
the first column contains the estimate, the second the lower confidence interval, the third the upper one.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Phi">Phi</a></code>, <code><a href="#topic+ContCoef">ContCoef</a></code>, <code><a href="#topic+CramerV">CramerV</a></code>, <code><a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a></code>, <code><a href="#topic+KendallTauB">KendallTauB</a></code>, <code><a href="#topic+StuartTauC">StuartTauC</a></code>,
<code><a href="#topic+SomersDelta">SomersDelta</a></code>, <code><a href="#topic+SpearmanRho">SpearmanRho</a></code>, <code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(scipen=8)

# Example taken from: SAS/STAT(R) 9.2 User's Guide, Second Edition, The FREQ Procedure
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# Hair-Eye-Color pp. 1816

tob &lt;- as.table(matrix(c(
  69, 28, 68, 51,  6,
  69, 38, 55, 37,  0,
  90, 47, 94, 94, 16
), nrow=3, byrow=TRUE,
   dimnames=list(eye=c("blue","green","brown"),
                 hair=c("fair","red","medium","dark","black")) ))
Desc(tob)
Assocs(tob)

# Example taken from: http://www.math.wpi.edu/saspdf/stat/chap28.pdf
# pp. 1349

pain &lt;- as.table(matrix(c(
   26,  6,
   26,  7,
   23,  9,
   18, 14,
    9, 23
   ), ncol=2, byrow=TRUE))

Desc(pain)
Assocs(pain)
</code></pre>

<hr>
<h2 id='Atkinson'>Atkinson Index - A Measure of Inequality. </h2><span id='topic+Atkinson'></span>

<h3>Description</h3>

<p>The Atkinson index is an inequality measure and is useful in determining which end of the distribution contributed most to the observed inequality. </p>


<h3>Usage</h3>

<pre><code class='language-R'>Atkinson(x, n = rep(1, length(x)), parameter = 0.5, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Atkinson_+3A_x">x</code></td>
<td>
<p>a vector containing at least non-negative elements.</p>
</td></tr>
<tr><td><code id="Atkinson_+3A_n">n</code></td>
<td>
<p>a vector of frequencies, must be same length as x.</p>
</td></tr>
<tr><td><code id="Atkinson_+3A_parameter">parameter</code></td>
<td>
<p>parameter of the inequality measure (if set to <code>NULL</code>
the default parameter of the respective measure is used).</p>
</td></tr>
<tr><td><code id="Atkinson_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to FALSE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the value of the Akinson Index.
</p>


<h3>Note</h3>

<p>This function was previously published as <code>ineq()</code> in the  <span class="pkg">ineq</span> package and has been
integrated here without logical changes, but with some extensions for <code>NA</code>-handling and the use of weights.
</p>


<h3>Author(s)</h3>

<p>Achim Zeileis &lt;Achim.Zeileis@R-project.org&gt;</p>


<h3>References</h3>

<p>Cowell, F. A. (2000) Measurement of Inequality in Atkinson, A. B. / Bourguignon, F. (Eds): <em>Handbook of Income Distribution</em>. Amsterdam.
</p>
<p>Cowell, F. A. (1995) <em>Measuring Inequality</em> Harvester Wheatshef: Prentice Hall.
</p>
<p>Marshall, Olkin (1979) <em>Inequalities: Theory of Majorization and Its
Applications</em>. New York: Academic Press.
</p>
<p>Atkinson, A. B. (1970): On the Measurment of Inequality, <em>Journal of Economic Theory</em>, Vol. 2(3), pp. 244-263.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Herfindahl">Herfindahl</a></code>, <code><a href="#topic+Rosenbluth">Rosenbluth</a></code> for concentration measures and
<code><a href="ineq.html#topic+ineq">ineq</a>()</code> in the package <span class="pkg">ineq</span> for additional inequality measures</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate vector (of incomes)
x &lt;- c(541, 1463, 2445, 3438, 4437, 5401, 6392, 8304, 11904, 22261)

# compute Atkinson coefficient with parameter=1
Atkinson(x, parameter=1)
</code></pre>

<hr>
<h2 id='AUC'>Area Under the Curve
</h2><span id='topic+AUC'></span>

<h3>Description</h3>

<p>Calculate the area under the curve with a naive algorithm and with a more elaborated spline approach. The curve must be given by vectors of xy-coordinates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC(x, y, from = min(x, na.rm = TRUE), to = max(x, na.rm = TRUE), 
    method = c("trapezoid", "step", "spline", "linear"), 
    absolutearea = FALSE, subdivisions = 100, na.rm = FALSE, ...) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_+3A_x">x</code>, <code id="AUC_+3A_y">y</code></td>
<td>
<p>the xy-points of the curve
</p>
</td></tr>
<tr><td><code id="AUC_+3A_method">method</code></td>
<td>

<p>The type of interpolation. Can be <code>"trapezoid"</code> (default), <code>"step"</code>, <code>"linear"</code> or <code>"spline"</code>.
The value &quot;spline&quot; results in the area under the natural cubic spline interpolation.
</p>
</td></tr>
<tr><td><code id="AUC_+3A_from">from</code></td>
<td>
<p>The value from where to start calculating the area under the
curve. Defaults to the smallest x value.</p>
</td></tr>
<tr><td><code id="AUC_+3A_to">to</code></td>
<td>
<p>The value from where to end the calculation of the area under the
curve. Defaults to the greatest x value.</p>
</td></tr>
<tr><td><code id="AUC_+3A_absolutearea">absolutearea</code></td>
<td>
<p>A logical value that determines if negative
areas should be added to the total area under the curve.  By
default the auc function subtracts areas that have negative y
values. Set <code>absolutearea=TRUE</code> to _add_ the absolute value of the negative areas to the total area. Ignored if <code>method</code> is not <code>spline</code>.</p>
</td></tr>
<tr><td><code id="AUC_+3A_subdivisions">subdivisions</code></td>
<td>
<p>an integer telling how many subdivisions should be used for integrate (for non-linear approximations). Ignored if <code>method</code> is not <code>spline</code>.</p>
</td></tr>
<tr><td><code id="AUC_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. In this case only the complete.cases of x and y will be used. <code>na.rm</code> defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="AUC_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to approx (for linear approximations). In particular rule can be set to determine how values outside the range of x is handled.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If method is set to <code>"trapezoid"</code> then the curve is formed by connecting all points by a direct line (composite trapezoid rule). If <code>"step"</code> is chosen then a stepwise connection of two points is used.
</p>
<p>For linear interpolation the <code>AUC()</code> function computes the area under the curve
using the composite trapezoid rule.  For area under a spline interpolation,
<code>AUC()</code> uses the splinefun function in combination with the integrate to
calculate a numerical integral. 
</p>
<p>The <code>AUC()</code> function can handle unsorted time
values (by sorting x), missing observations, ties for the x values (by ignoring duplicates), and integrating over
part of the area or even outside the area.
</p>


<h3>Value</h3>

<p>Numeric value of the area under the curve.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, spline part by Claus Ekstrom &lt;claus@rprimer.dk&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+integrate">integrate</a></code>, <code><a href="stats.html#topic+splinefun">splinefun</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>AUC(x=c(1,3), y=c(1,1))

AUC(x=c(1,2,3), y=c(1,2,4), method="trapezoid")
AUC(x=c(1,2,3), y=c(1,2,4), method="step")

plot(x=c(1,2,2.5), y=c(1,2,4), type="l", col="blue", ylim=c(0,4))
lines(x=c(1,2,2.5), y=c(1,2,4), type="s", col="red")

x &lt;- seq(0, pi, length.out=200)
AUC(x=x, y=sin(x)) 
AUC(x=x, y=sin(x), method="spline") 
</code></pre>

<hr>
<h2 id='AxisBreak'> Place a Break Mark on an Axis </h2><span id='topic+AxisBreak'></span>

<h3>Description</h3>

<p>Places a break mark on an axis on an existing plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> AxisBreak(axis = 1, breakpos = NULL, pos = NA, bgcol = "white", 
           breakcol = "black", style = "slash", brw = 0.02)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AxisBreak_+3A_axis">axis</code></td>
<td>
<p>which axis to break.</p>
</td></tr>
<tr><td><code id="AxisBreak_+3A_breakpos">breakpos</code></td>
<td>
<p>where to place the break in user units.</p>
</td></tr>
<tr><td><code id="AxisBreak_+3A_pos">pos</code></td>
<td>
<p>position of the axis (see <a href="graphics.html#topic+axis">axis</a>).</p>
</td></tr>
<tr><td><code id="AxisBreak_+3A_bgcol">bgcol</code></td>
<td>
<p>the color of the plot background.</p>
</td></tr>
<tr><td><code id="AxisBreak_+3A_breakcol">breakcol</code></td>
<td>
<p>the color of the &quot;break&quot; marker.</p>
</td></tr>
<tr><td><code id="AxisBreak_+3A_style">style</code></td>
<td>
<p>Either &lsquo;<span class="samp">&#8288;gap&#8288;</span>&rsquo;, &lsquo;<span class="samp">&#8288;slash&#8288;</span>&rsquo; or &lsquo;<span class="samp">&#8288;zigzag&#8288;</span>&rsquo;.</p>
</td></tr>
<tr><td><code id="AxisBreak_+3A_brw">brw</code></td>
<td>
<p>break width relative to plot width.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &lsquo;<span class="samp">&#8288;pos&#8288;</span>&rsquo; argument is not needed unless the user has specified a
different position from the default for the axis to be broken.
</p>


<h3>Note</h3>

<p>There is some controversy about the propriety of using discontinuous
coordinates for plotting, and thus axis breaks. Discontinuous coordinates
allow widely separated groups of values or outliers to appear without
devoting too much of the plot to empty space. <br />
The major objection seems 
to be that the reader will be misled by assuming continuous coordinates.
The &lsquo;<span class="samp">&#8288;gap&#8288;</span>&rsquo; style that clearly separates the two sections of the plot
is probably best for avoiding this.
</p>


<h3>Author(s)</h3>

<p>Jim Lemon and Ben Bolker</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(3:10, main="Axis break test")

# put a break at the default axis and position
AxisBreak()
AxisBreak(2, 2.9, style="zigzag")
</code></pre>

<hr>
<h2 id='axTicks.POSIXct'>Compute Axis Tickmark Locations (For POSIXct Axis)
</h2><span id='topic+axTicks.POSIXct'></span><span id='topic+axTicks.Date'></span>

<h3>Description</h3>

<p>Compute pretty tickmark locations, the same way as R does internally. By default, gives the at values which axis.POSIXct(side, x) would use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>axTicks.POSIXct(side, x, at, format, labels = TRUE, ...)

axTicks.Date(side = 1, x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="axTicks.POSIXct_+3A_side">side</code></td>
<td>
<p>See <a href="graphics.html#topic+axis">axis</a>.
</p>
</td></tr>
<tr><td><code id="axTicks.POSIXct_+3A_x">x</code>, <code id="axTicks.POSIXct_+3A_at">at</code></td>
<td>
<p>A date-time or date object.
</p>
</td></tr>
<tr><td><code id="axTicks.POSIXct_+3A_format">format</code></td>
<td>
<p>See strptime.
</p>
</td></tr>
<tr><td><code id="axTicks.POSIXct_+3A_labels">labels</code></td>
<td>
<p>Either a logical value specifying whether annotations are to be made at the tickmarks, or a vector of character strings to be placed at the tickpoints.
</p>
</td></tr>
<tr><td><code id="axTicks.POSIXct_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed from or to other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="graphics.html#topic+axTicks">axTicks</a> has no implementation for POSIXct axis. This function fills the gap.
</p>


<h3>Value</h3>

<p>numeric vector of coordinate values at which axis tickmarks can be drawn.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; simply copying R-Core code
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+axTicks">axTicks</a></code>, <code><a href="graphics.html#topic+axis.POSIXct">axis.POSIXct</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>with(beaver1, {
  time &lt;- strptime(paste(1990, day, time %/% 100, time %% 100),
                   "%Y %j %H %M")
  plot(time, temp, type = "l") # axis at 4-hour intervals.
  # now label every hour on the time axis
  plot(time, temp, type = "l", xaxt = "n")
  r &lt;- as.POSIXct(round(range(time), "hours"))
  axis.POSIXct(1, at = seq(r[1], r[2], by = "hour"), format = "%H")
  # place the grid
  abline(v=axTicks.POSIXct(1, at = seq(r[1], r[2], by = "hour"), format = "%H"),
         col="grey", lty="dotted")
})

</code></pre>

<hr>
<h2 id='BarnardTest'> Barnard's Unconditional Test</h2><span id='topic+BarnardTest'></span>

<h3>Description</h3>

<p>Barnard's unconditional test for superiority applied to <code class="reqn">2 \times 2</code> contingency tables
using Score or Wald statistics for the difference between two binomial proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BarnardTest(x, y = NULL, alternative = c("two.sided", "less", "greater"),
            method = c("csm", "csm approximate", "z-pooled", "z-unpooled",
                       "boschloo", "santner and snell"), 
            fixed = 1, useStoredCSM = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BarnardTest_+3A_x">x</code></td>
<td>
<p>a numeric vector or a two-dimensional contingency table in matrix form. <code>x</code> and <code>y</code> can also both be factors. </p>
</td></tr>
<tr><td><code id="BarnardTest_+3A_y">y</code></td>
<td>
<p>a factor object; ignored if <code>x</code> is a matrix.</p>
</td></tr>
<tr><td><code id="BarnardTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.  You can specify just the initial
letter.</p>
</td></tr>
<tr><td><code id="BarnardTest_+3A_method">method</code></td>
<td>
<p>Indicates the method for finding the more extreme tables: must be either <code>"Zpooled"</code>, <code>"Z-unpooled"</code>, <code>"Santner and Snell"</code>, <code>"Boschloo"</code>, <code>"CSM"</code>, or <code>"CSM approximate"</code>. CSM tests cannot be calculated for multinomial models.</p>
</td></tr>
<tr><td><code id="BarnardTest_+3A_fixed">fixed</code></td>
<td>
<p>indicates which margins are fixed. <code>1</code> stands for row, <code>2</code> for columns, <code>NA</code> for none of both. </p>
</td></tr>
<tr><td><code id="BarnardTest_+3A_usestoredcsm">useStoredCSM</code></td>
<td>
<p>logical, use a stored ordering matrix for the CSM test to greatly reduce the computation time (default is <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="BarnardTest_+3A_...">...</code></td>
<td>
<p>the dots are passed on to the <code>Exact::exact.test()</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two fundamentally different exact tests for comparing the equality of two binomial probabilities - Fisher's exact test (Fisher, 1925), and Barnard's exact test (Barnard, 1945). Fisher's exact test (Fisher, 1925) is the more popular of the two. In fact, Fisher was bitterly critical of Barnard's proposal for esoteric reasons that we will not go into here. For 2 x 2 tables, Barnard's test is more powerful than Fisher's, as Barnard noted in his 1945 paper, much to Fisher's chagrin. Anyway, perhaps due to its computational difficulty the Barnard's is not widely used. (Mehta et.al., 2003)
</p>
<p>Unconditional exact tests can be performed for binomial or multinomial models. The binomial model assumes the row or column margins (but not both) are known in advance, while the multinomial model assumes only the total sample size is known beforehand. 
For the binomial model, the user needs to specify which margin is fixed (default is rows). Conditional tests (e.g., Fisher's exact test) have both row and column margins fixed, but this is a very uncommon design. (See Calhoun (2019) for more details.)
</p>
<p>If <code>x</code> is a matrix, it is taken as a two-dimensional contingency
table, and hence its entries should be nonnegative integers.
Otherwise, both <code>x</code> and <code>y</code> must be vectors of the same
length.  Incomplete cases are removed, the vectors are coerced into
factor objects, and the contingency table is computed from these.
</p>
<p>For a 2x2 contingency table, such as <code class="reqn">X=[n_1,n_2;n_3,n_4]</code>, the normalized difference in proportions between the two categories, given in each column, can be written with pooled variance (Score statistic) as
</p>
<p style="text-align: center;"><code class="reqn">T(X)=\frac{\hat{p}_2-\hat{p}_1}{\sqrt{\hat{p}(1-\hat{p})(\frac{1}{c_1}+\frac{1}{c_2})}},</code>
</p>

<p>where <code class="reqn">\hat{p}=(n_1+n_3)/(n_1+n_2+n_3+n_4)</code>, <code class="reqn">\hat{p}_2=n_2/(n_2+n_4)</code>, <code class="reqn">\hat{p}_1=n_1/(n_1+n_3)</code>, <code class="reqn">c_1=n_1+n_3</code> and <code class="reqn">c_2=n_2+n_4</code>. Alternatively, with unpooled variance (Wald statistic), the difference in proportions can we written as
</p>
<p style="text-align: center;"><code class="reqn">T(X)=\frac{\hat{p}_2-\hat{p}_1}{\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{c_1}+\frac{\hat{p}_2(1-\hat{p}_2)}{c_2}}}.</code>
</p>

<p>The probability of observing <code class="reqn">X</code> is
</p>
<p style="text-align: center;"><code class="reqn">P(X)=\frac{c_1!c_2!}{n_1!n_2!n_3!n_4!}p^{n_1+n_2}(1-p)^{n_3+n_4},</code>
</p>

<p>where <code class="reqn">p</code> is the unknown nuisance parameter.
</p>
<p>Barnard's test considers all tables with category sizes <code class="reqn">c_1</code> and <code class="reqn">c_2</code> for a given <code class="reqn">p</code>. The p-value is the sum of probabilities of the tables having a score in the rejection region, e.g. having significantly large difference in proportions for a two-sided test. The p-value of the test is the maximum p-value calculated over all <code class="reqn">p</code> between 0 and 1.
</p>
<p>If <code>useStoredCSM</code> is set to <code>TRUE</code> a companion data package called <span class="pkg">ExactData</span> must be installed from GitHub.  
</p>
<p>The author states:
<em>&quot;The CSM test is computationally intensive due to iteratively maximizing the p-value calculation to order the tables. The CSM ordering matrix has been stored for all possible sample sizes less than or equal to 100 (i.e., max(n1,n2)&lt;=100). Thus, using the useStoredCSM = TRUE can greatly improve computation time. However, the stored ordering matrix was computed with npNumbers=100 and it is possible that the ordering matrix was not optimal for larger npNumbers. Increasing npNumbers and setting useStoredCSM = FALSE ensures the p-value is correctly calculated at the expense of
significantly greater computation time. The stored ordering matrix is not used in the calculation of confidence intervals or non-inferiority tests, so CSM can still be very computationally intensive.&quot;</em>
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>an estimate of the nuisance parameter where the p-value is maximized.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string
<code>"Barnards Unconditional 2x2-test"</code>.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
<tr><td><code>statistic.table</code></td>
<td>
<p>The contingency tables considered in the analysis represented by <code>n1</code> and <code>n2</code>, their scores, and whether they are included in the one-sided (<code>1</code>), two-sided (<code>2</code>) tests, or not included at all (<code>0</code>)</p>
</td></tr>
<tr><td><code>nuisance.matrix</code></td>
<td>
<p>Nuisance parameters, <code>p</code>, and the corresponding p-values for both one- and two-sided tests</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Calhoun &lt;calhoun.peter@gmail.com&gt;, Andri Signorell &lt;andri@signorell.net&gt; (interface)
</p>


<h3>References</h3>

<p>Barnard, G.A. (1945) A new test for 2x2 tables. <em>Nature</em>, 156:177.
</p>
<p>Barnard, G.A. (1947) Significance tests for 2x2 tables. <em>Biometrika</em>, 34:123-138.
</p>
<p>Suissa, S. and Shuster, J. J. (1985), Exact Unconditional Sample Sizes for the 2x2 Binomial Trial, <em>Journal of the Royal Statistical Society</em>, Ser. A, 148, 317-327.
</p>
<p>Cardillo G. (2009) MyBarnard: a very compact routine for Barnard's exact test on 2x2 matrix. <a href="https://ch.mathworks.com/matlabcentral/fileexchange/25760-mybarnard">https://ch.mathworks.com/matlabcentral/fileexchange/25760-mybarnard</a>
</p>
<p>Galili T. (2010) <a href="https://www.r-statistics.com/2010/02/barnards-exact-test-a-powerful-alternative-for-fishers-exact-test-implemented-in-r/">https://www.r-statistics.com/2010/02/barnards-exact-test-a-powerful-alternative-for-fishers-exact-test-implemented-in-r/</a>
</p>
<p>Lin C.Y., Yang M.C. (2009) Improved p-value tests for comparing two independent binomial proportions. <em>Communications in Statistics-Simulation and Computation</em>, 38(1):78-91.
</p>
<p>Trujillo-Ortiz, A., R. Hernandez-Walls, A. Castro-Perez, L. Rodriguez-Cardozo N.A. Ramos-Delgado and R. Garcia-Sanchez. (2004). Barnardextest:Barnard's Exact Probability Test. A MATLAB file. [WWW document]. <a href="https://www.mathworks.com/">https://www.mathworks.com/</a>
</p>
<p>Mehta, C.R., Senchaudhuri, P. (2003) Conditional versus unconditional exact tests for comparing two binomials. <a href="https://www.researchgate.net/publication/242179503_Conditional_versus_Unconditional_Exact_Tests_for_Comparing_Two_Binomials">https://www.researchgate.net/publication/242179503_Conditional_versus_Unconditional_Exact_Tests_for_Comparing_Two_Binomials</a>
</p>
<p>Calhoun, P. (2019) Exact: Unconditional Exact Test. R package version
2.0. <br /> <a href="https://CRAN.R-project.org/package=Exact">https://CRAN.R-project.org/package=Exact</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fisher.test">fisher.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- as.table(matrix(c(8, 14, 1, 3), nrow=2,
                dimnames=list(treat=c("I","II"), out=c("I","II"))))
BarnardTest(tab)

# Plotting the search for the nuisance parameter for a one-sided test
bt &lt;- BarnardTest(tab)

# Plotting the tables included in the p-value
ttab &lt;- as.table(matrix(c(40, 14, 10, 30), nrow=2,
                 dimnames=list(treat=c("I","II"), out=c("I","II"))))


bt &lt;- BarnardTest(ttab)
bts &lt;- bt$statistic.table


# Mehta et. al (2003)
tab &lt;- as.table(matrix(c(7, 12, 8, 3), nrow=2,
                       dimnames=list(treat=c("vaccine","placebo"),
                                     infection=c("yes","no"))))
BarnardTest(tab, alternative="less")
</code></pre>

<hr>
<h2 id='BartelsRankTest'>
Bartels Rank Test of Randomness
</h2><span id='topic+BartelsRankTest'></span>

<h3>Description</h3>

<p>Performs the Bartels rank test of randomness, which tests if a sample is sampled randomly from an underlying population. Data must at least be measured on an ordinal scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BartelsRankTest(x, alternative = c("two.sided", "trend", "oscillation"),
                method = c("normal", "beta", "auto"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BartelsRankTest_+3A_x">x</code></td>
<td>
<p>a numeric vector containing the observations</p>
</td></tr>
<tr><td><code id="BartelsRankTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of &quot;<code>two.sided</code>&quot; (default), &quot;<code>trend</code>&quot; or &quot;<code>oscillation</code>&quot;. </p>
</td></tr>
<tr><td><code id="BartelsRankTest_+3A_method">method</code></td>
<td>
<p>a character string specifying the method used to compute the p-value. Must be one of <code>normal</code> (default), <code>beta</code> or <code>auto</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RVN test statistic is
</p>
<p style="text-align: center;"><code class="reqn">RVN=\frac{\sum_{i=1}^{n-1}(R_i-R_{i+1})^2}{\sum_{i=1}^{n}\left(R_i-(n+1)/2\right)^2}</code>
</p>

<p>where <code class="reqn">R_i=rank(X_i), i=1,\dots, n</code>. It is known that <code class="reqn">(RVN-2)/\sigma</code> is asymptotically standard normal, where <code class="reqn">\sigma^2=\frac{4(n-2)(5n^2-2n-9)}{5n(n+1)(n-1)^2}</code>.
</p>
<p>By using the alternative &quot;<code>trend</code>&quot; the null hypothesis of randomness is tested against a trend. By using the alternative &quot;<code>oscillation</code>&quot; the null hypothesis of randomness is tested against a systematic oscillation.
</p>
<p>Missing values are silently removed.
</p>
<p>Bartels test is a rank version of von Neumann's test.
</p>


<h3>Value</h3>

<p>A list with class &quot;htest&quot; containing the components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the normalized statistic test.</p>
</td></tr>
<tr><td><code>parameter</code>, <code>n</code></td>
<td>
<p>the size of the data, after the remotion of consecutive duplicate values.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the test performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
<tr><td><code>rvn</code></td>
<td>
<p>the value of the RVN statistic (not show on screen).</p>
</td></tr>
<tr><td><code>nm</code></td>
<td>
<p>the value of the NM statistic, the numerator of RVN (not show on screen).</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>the mean value of the RVN statistic (not show on screen).</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>the variance of the RVN statistic (not show on screen).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Frederico Caeiro &lt;fac@fct.unl.pt&gt;</p>


<h3>References</h3>

<p>Bartels, R. (1982) The Rank Version of von Neumann's Ratio Test for Randomness, <em>Journal of the American Statistical Association</em>, <b>77</b> (377), 40-46.
</p>
<p>Gibbons, J.D. and Chakraborti, S. (2003) <em>Nonparametric Statistical Inference</em>, 4th ed. (pp. 97-98).
URL: <a href="http://books.google.pt/books?id=dPhtioXwI9cC&amp;lpg=PA97&amp;ots=ZGaQCmuEUq">http://books.google.pt/books?id=dPhtioXwI9cC&amp;lpg=PA97&amp;ots=ZGaQCmuEUq</a>
</p>
<p>von Neumann, J. (1941) Distribution of the ratio of the mean square successive difference to the variance.
<em>Annals of Mathematical Statistics</em> <b>12</b>, 367-395.
</p>


<h3>See Also</h3>

<p><code><a href="randtests.html#topic+rank.test">rank.test</a></code>, <code><a href="#topic+RunsTest">RunsTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 5.1 in Gibbons and Chakraborti (2003), p.98.
## Annual data on total number of tourists to the United States for 1970-1982.

years &lt;- 1970:1982
tourists &lt;- c(12362, 12739, 13057, 13955, 14123,  15698, 17523, 18610, 19842,
      20310, 22500, 23080, 21916)
plot(years, tourists, pch=20)

BartelsRankTest(tourists, alternative="trend", method="beta")

#  Bartels Ratio Test
#
# data:  tourists
# statistic = -3.6453, n = 13, p-value = 1.21e-08
# alternative hypothesis: trend


## Example in Bartels (1982).
## Changes in stock levels for 1968-1969 to 1977-1978 (in $A million), deflated by the
## Australian gross domestic product (GDP) price index (base 1966-1967).
x &lt;- c(528, 348, 264, -20, - 167, 575, 410, -4, 430, - 122)

BartelsRankTest(x, method="beta")
</code></pre>

<hr>
<h2 id='BarText'>Place Value Labels on a Barplot
</h2><span id='topic+BarText'></span>

<h3>Description</h3>

<p>It can sometimes make sense to display data values directly on the bars in a barplot. There are a handful of obvious alternatives for placing the labels, either on top of the bars, right below the upper end, in the middle or at the bottom. Determining the required geometry - although not difficult - is cumbersome and the code is distractingly long within an analysis code. The present function offers a short way to solve the task. It can place text either in the middle of the stacked bars, on top or on the bottom of a barplot (side by side or stacked). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BarText(height, b, labels = height, beside = FALSE, horiz = FALSE,
        cex = par("cex"), adj = NULL, 
        pos = c("topout", "topin", "mid", "bottomin", "bottomout"), 
        offset = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BarText_+3A_height">height</code></td>
<td>
<p>either a vector or matrix of values describing the bars which make up the plot exactly as used for creating the barplot.
</p>
</td></tr>
<tr><td><code id="BarText_+3A_b">b</code></td>
<td>
<p>the returned mid points as returned by <code>b &lt;- barplot(...)</code>.
</p>
</td></tr>
<tr><td><code id="BarText_+3A_labels">labels</code></td>
<td>
<p>the labels to be placed on the bars.
</p>
</td></tr>
<tr><td><code id="BarText_+3A_beside">beside</code></td>
<td>
<p>a logical value. If <code>FALSE</code>, the columns of height are portrayed as stacked bars, and if <code>TRUE</code> the columns are portrayed as juxtaposed bars.
</p>
</td></tr>
<tr><td><code id="BarText_+3A_horiz">horiz</code></td>
<td>
<p>a logical value. If <code>FALSE</code>, the bars are drawn vertically with the first bar to the left. If <code>TRUE</code>, the bars are drawn horizontally with the first at the bottom.
</p>
</td></tr>
<tr><td><code id="BarText_+3A_cex">cex</code></td>
<td>
<p>numeric character expansion factor; multiplied by <code><a href="graphics.html#topic+par">par</a></code><code>("cex")</code> yields the final character size. <code>NULL</code> and <code>NA</code> are equivalent to <code>1.0</code>.</p>
</td></tr>
<tr><td><code id="BarText_+3A_adj">adj</code></td>
<td>
<p>one or two values in [0, 1] which specify the x (and optionally y) adjustment of the labels. On most devices values outside that interval will also work.</p>
</td></tr>
<tr><td><code id="BarText_+3A_pos">pos</code></td>
<td>
<p>one of <code>"topout"</code>, <code>"topin"</code>, <code>"mid"</code>, <code>"bottomin"</code>, <code>"bottomout"</code>, 
defining if the labels should be placed on top of the bars (inside or outside) or at the bottom of the bars (inside or outside).</p>
</td></tr>
<tr><td><code id="BarText_+3A_offset">offset</code></td>
<td>
<p>a vector indicating how much the bars should be shifted relative to the x axis.</p>
</td></tr>
<tr><td><code id="BarText_+3A_...">...</code></td>
<td>
<p>the dots are passed to the <code><a href="#topic+BoxedText">BoxedText</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The x coordinates of the labels can be found by using <code><a href="graphics.html#topic+barplot">barplot</a>()</code> result, if they are to be centered at the top of each bar. <code>BarText()</code> calculates the rest.
</p>
<p><img src="../help/figures/bartext.png" alt="Positions for the text" />
</p>
<p>Notice that when the labels are placed on top of the bars, they may be clipped. This can be avoided by setting <code>xpd=TRUE</code>.
</p>


<h3>Value</h3>

<p>returns the geometry of the labels invisibly</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BoxedText">BoxedText</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple vector
x &lt;- c(353, 44, 56, 34)
b &lt;- barplot(x)
BarText(x, b, x)

# more complicated
b &lt;- barplot(VADeaths, horiz = FALSE, col=hblue, beside = TRUE)
BarText(VADeaths, b=b, horiz = FALSE, beside = TRUE, cex=0.8)
BarText(VADeaths, b=b, horiz = FALSE, beside = TRUE, cex=0.8, pos="bottomin",
        col="white", font=2)

b &lt;- barplot(VADeaths, horiz = TRUE, col=hblue, beside = TRUE)
BarText(VADeaths, b=b, horiz = TRUE, beside = TRUE, cex=0.8)

b &lt;- barplot(VADeaths)
BarText(VADeaths, b=b)

b &lt;- barplot(VADeaths, horiz = TRUE)
BarText(VADeaths, b=b, horiz = TRUE, col="red", cex=1.5)


# position of the text
old &lt;- par(mfrow=c(3,2), xpd=NA)
off &lt;- c(10, 4, 1, 20, -15)

for(pos in eval(formals(BarText)$pos)) {
  b &lt;- barplot(x, offset=off, 
  main=gettextf("Textposition pos = '%s'", pos), horiz=TRUE)
  abline(h=0)
  BarText(x, b, x, offset = off, pos=pos, cex=1.5, horiz=TRUE)
}
par(old)
</code></pre>

<hr>
<h2 id='Base+20Conversions'>Converts Numbers From Binmode, Octmode or Hexmode to Decimal and Vice Versa
</h2><span id='topic+BinToDec'></span><span id='topic+DecToBin'></span><span id='topic+OctToDec'></span><span id='topic+DecToOct'></span><span id='topic+HexToDec'></span><span id='topic+DecToHex'></span>

<h3>Description</h3>

<p>These functions convert numbers from one base to another.
There are several solutions for this problem out there, but the naming is quite heterogeneous and so
consistent function names might be helpful.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinToDec(x)
DecToBin(x)
OctToDec(x)
DecToOct(x)
HexToDec(x)
DecToHex(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Base+2B20Conversions_+3A_x">x</code></td>
<td>
<p> a vector of numbers, resp. alphanumerical representation of numbers (hex), to be converted.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>BinToDec converts numbers from binary mode into decimal values. DecToBin does it the other way round.<br />
Oct means octal system and hex hexadecimal.
</p>


<h3>Value</h3>

<p>A numeric or character vector of the same length as x containing the converted values.
Binary, octal and decimal values are numeric, hex-values are returned as class <code>hexmode</code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strtoi">strtoi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>DecToBin(c(17, 25))
BinToDec(c(101, 11101))

DecToOct(c(17, 25))
OctToDec(c(11, 77))

DecToHex(c(17, 25))
HexToDec(c("FF", "AA", "ABC"))
</code></pre>

<hr>
<h2 id='Benford'> Benford's Distribution </h2><span id='topic+Benford'></span><span id='topic+dBenf'></span><span id='topic+pBenf'></span><span id='topic+qBenf'></span><span id='topic+rBenf'></span>

<h3>Description</h3>

<p>Density, distribution function,
quantile function,
and random generation
for Benford's distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dBenf(x, ndigits = 1, log = FALSE)
pBenf(q, ndigits = 1, log.p = FALSE)
qBenf(p, ndigits = 1)
rBenf(n, ndigits = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Benford_+3A_x">x</code>, <code id="Benford_+3A_q">q</code></td>
<td>

<p>Vector of quantiles.
See <code>ndigits</code>.
</p>
</td></tr>
<tr><td><code id="Benford_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Benford_+3A_n">n</code></td>
<td>
<p>number of observations. A single positive integer.
Else if <code>length(n) &gt; 1</code> then the length is
taken to be the number required.
</p>
</td></tr>
<tr><td><code id="Benford_+3A_ndigits">ndigits</code></td>
<td>

<p>Number of leading digits, either 1 or 2.
If 1 then the support of the distribution is {1,...,9}, else
{10,...,99}.
</p>
</td></tr>
<tr><td><code id="Benford_+3A_log">log</code>, <code id="Benford_+3A_log.p">log.p</code></td>
<td>

<p>Logical.
If <code>log.p = TRUE</code> then all probabilities <code>p</code> are
given as <code>log(p)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Benford's Law (aka <em>the significant-digit law</em>) is the
empirical observation that in many naturally occuring tables of
numerical data, the leading significant (nonzero) digit
is not uniformly distributed in <code class="reqn">\{1,2,\ldots,9\}</code>.
Instead, the leading significant digit (<code class="reqn">=D</code>, say)
obeys the law
</p>
<p style="text-align: center;"><code class="reqn">P(D=d) = \log_{10} \left( 1 + \frac1d \right)</code>
</p>

<p>for <code class="reqn">d=1,\ldots,9</code>.
This means
the probability the first significant digit is 1 is
approximately <code class="reqn">0.301</code>, etc.
</p>
<p>Benford's Law was apparently first discovered in 1881
by astronomer/mathematician
S. Newcombe. It started by the observation
that the pages of a book of logarithms were dirtiest at the
beginning and progressively cleaner throughout.
In 1938, a General Electric physicist called F. Benford
rediscovered the law on this same observation. Over
several years he collected data from different sources
as different as atomic weights, baseball statistics,
numerical data from <em>Reader's Digest</em>,
and drainage areas of rivers.
</p>
<p>Applications of Benford's Law has been as diverse as
to the area of
fraud detection in accounting  and the design computers.
</p>


<h3>Value</h3>

<p><code>dBenf</code> gives the density,
<code>pBenf</code> gives the distribution function, and
<code>qBenf</code> gives the quantile function, and
<code>rBenf</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p> T. W. Yee </p>


<h3>Source</h3>

<p> These functions were previously published as <code>dbenf()</code> etc. in the  <span class="pkg">VGAM</span> package and have been
integrated here without logical changes. 
</p>


<h3>References</h3>

 
<p>Benford, F. (1938)
The Law of Anomalous Numbers.
<em>Proceedings of the American Philosophical Society</em>,
<b>78</b>, 551&ndash;572.
</p>
<p>Newcomb, S. (1881)
Note on the Frequency of Use of the Different Digits in Natural Numbers.
<em>American Journal of Mathematics</em>,
<b>4</b>, 39&ndash;40.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dBenf(x &lt;- c(0:10, NA, NaN, -Inf, Inf))
pBenf(x)

## Not run: 
xx &lt;- 1:9
barplot(dBenf(xx), col = "lightblue", las = 1, xlab = "Leading digit",
        ylab = "Probability", names.arg = as.character(xx),
        main = paste("Benford's distribution",  sep = ""))

hist(rBenf(n = 1000), border = "blue", prob = TRUE,
     main = "1000 random variates from Benford's distribution",
     xlab = "Leading digit", sub="Red is the true probability",
     breaks = 0:9 + 0.5, ylim = c(0, 0.35), xlim = c(0, 10.0))
lines(xx, dBenf(xx), col = "red", type = "h")
points(xx, dBenf(xx), col = "red")

## End(Not run)
</code></pre>

<hr>
<h2 id='Between+2C+20Outside'>Operators To Check, If a Value Lies Within Or Outside a Given Range
</h2><span id='topic+Between'></span><span id='topic++25+28+29+25'></span><span id='topic++25+28+5D+25'></span><span id='topic++25+5B+29+25'></span><span id='topic++25+5B+5D+25'></span><span id='topic++25+5D+5B+25'></span><span id='topic++25+29+5B+25'></span><span id='topic++25+5D+28+25'></span><span id='topic++25+29+28+25'></span><span id='topic++25+3A+25'></span><span id='topic++25+3A+3A+25'></span>

<h3>Description</h3>

<p>The between and outside operators are used to check, whether a vector of given values x lie within a defined range (or outside respectively). The values can be numbers, text or dates.
Ordered factors are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %()% rng
x %(]% rng
x %[)% rng
x %[]% rng

x %][% rng
x %](% rng
x %)[% rng
x %)(% rng

x %:% rng
x %::% rng
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Between+2B2C+2B20Outside_+3A_x">x</code></td>
<td>

<p>is a variable with at least ordinal scale, usually a numeric value, but can be an ordered factor or a text as well. Texts would be treated alphabetically.
</p>
</td></tr>
<tr><td><code id="Between+2B2C+2B20Outside_+3A_rng">rng</code></td>
<td>

<p>a vector of two values or a matrix with 2 columns, defining the minimum and maximum of the range for x. <br /> If rng is a matrix, x or rng will be recycled.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;BETWEEN&quot; operators basically combine two conditional statements into one and simplify the query process.<br />
They are merely a wrapper for:   <code>x &gt;= rng[1] &amp; x &lt;= rng[2]</code>,
where the round bracket  <code>(</code>  means <em>strictly greater (&gt;)</em> and the square bracket  <code>[</code>  means <em>greater or equal (&gt;=)</em>.  Numerical values of x will be handled by C-code, which is significantly faster than two comparisons in R (especially when x is huge).
.<br />
<code>%][%</code> is the negation of <code>%()%</code>, meaning all values lying outside the given range. Elements on the limits will return <code>TRUE</code>.
</p>
<p>Both arguments, <code>x</code> and <code>rng</code>, will be recycled to the highest dimension, which is either the length of the vector (<code>x</code>) or the number of rows of the matrix (<code>rng</code>).<br />
See also the routines used to check, whether two ranges overlap (<code><a href="#topic+Overlap">Overlap</a></code>, <code><a href="#topic+Interval">Interval</a></code>).
</p>
<p><code>%:%</code> returns all the elements of a vector between the (first found) element <code>rng[1]</code> and <code>rng[2]</code>. If no match is found it returns <code>NA</code>. If <code>rng[2]</code> occurs before <code>rng[1]</code> in the vector the elements will be returned in reverse order (which is the same behaviour as the <code>:</code> operator).
<br />
<code>%::%</code> does the same in greedy mood. It uses the first match for <code>from</code> and the last match for <code>to</code>.
<br />
</p>


<h3>Value</h3>

<p>A logical vector of the same length as x.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; based on C-code by Kevin Ushey &lt;kevinushey@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+if">if</a></code>, <code><a href="base.html#topic+ifelse">ifelse</a></code>, <code><a href="base.html#topic+Comparison">Comparison</a></code>,
<code><a href="#topic+Overlap">Overlap</a></code>, <code><a href="#topic+Interval">Interval</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:9
x %[]% c(3,5)

# outside
x &lt;- 1:9
x %][% c(3,5)

c(x,NA) %[]% c(3,5)

x %(]% c(3,5)

# no result when from &gt; to:
x %[]% c(5,3)
x %(]% c(5,5)

# no problem:
ordered(x) %[]% c(3,5)

# not meaningful:
factor(x) %[]% c(3,5)

# characters
letters[letters %(]% c("d","h")]

data(d.pizza)
x &lt;- levels(d.pizza$driver)
x %[]% c("C","G")

# select diamonds with a price between 2400 and 2510
data(d.diamonds)
d.diamonds[d.diamonds$price %[]% c(2400,2510),]

# use it with an ordered factor and select all diamonds with
#   symmetry between G (included) and X (excluded).
mean(d.diamonds[d.diamonds$symmetry %[)% c("G","X"),"price"])


# use multiple ranges
2 %[]% cbind(1:4,2:5)

# both arguments are recycled
c(2,3) %[]% cbind(1:4,2:5)


# between operator for vector positions
set.seed(4)
(x &lt;- sample(LETTERS, size=10, replace=TRUE))
# [1] "X" "K" "S" "C" "G" "L" "S" "V" "U" "Z"

# return all elements between "S" and "L" 
x %:% c("S","L")
# [1] "S" "C" "G" "L"
 
x %:% c("S","A")
# [1] "S" "C" "G" "L" "S" "V" "U" "Z"
 
x %:% c("A","S")
# [1] "X" "K" "S"

# reverted matches return the elements in reverse order
x %:% c("G","X")
# [1] "G" "C" "S" "K" "X"

# no match results in NA
x %:% c("Y","B")

(x &lt;- c("B", "A", "X", "K", "S", "K", "G", "L", "K", "V", "K", "Z"))
# lazy
x %:% c("A", "K")
# greedy
x %::% c("A", "K")
</code></pre>

<hr>
<h2 id='Bg'>Background of a Plot
</h2><span id='topic+Bg'></span>

<h3>Description</h3>

<p>Paints the background of the plot, using either the figure region, the plot region or both. It can sometimes be cumbersome to elaborate the coordinates and base R does not provide a simple function for that.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bg(col = "grey", region = c("plot", "figure"), border = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bg_+3A_col">col</code></td>
<td>
<p>the color of the background, if two colors are provided, the first is used for the plot region and the second for the figure region.
</p>
</td></tr>
<tr><td><code id="Bg_+3A_region">region</code></td>
<td>
<p>either <code>"plot"</code> or <code>"figure"</code>
</p>
</td></tr>
<tr><td><code id="Bg_+3A_border">border</code></td>
<td>
<p>color for rectangle border(s). Default is <code>NA</code> for no borders.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+rect">rect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use two different colors for the figure region and the plot region
plot(x = rnorm(100), col="blue", cex=1.2, pch=16,
     panel.first={Bg(c("red", "lightyellow"))
                  grid()})
</code></pre>

<hr>
<h2 id='BhapkarTest'>Bhapkar Marginal Homogeneity Test 
</h2><span id='topic+BhapkarTest'></span>

<h3>Description</h3>

<p>Bhapkar (1966) tested marginal homogeneity by exploiting the asymptotic normality of marginal proportion, and so this test is also called Bhapkar's test. The idea of constructing test statistic is similar to the
one of generalized McNemar's test statistic used in <code><a href="#topic+StuartMaxwellTest">StuartMaxwellTest</a></code>, and the major difference lies in the calculation of elements in
variance-covariance matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BhapkarTest(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BhapkarTest_+3A_x">x</code></td>
<td>
<p>either a 2-way <code class="reqn">k \times  k</code> contingency table in matrix form, or a factor.
</p>
</td></tr>
<tr><td><code id="BhapkarTest_+3A_y">y</code></td>
<td>
<p>a factor with the same levels as <code>x</code>; ignored if <code>x</code> is a matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Although the Bhapkar and Stuart-Maxwell tests are asymptotically equivalent (Keefe, 1982). Generally,
the Bhapkar (1966) test is a more powerful alternative to the Stuart-Maxwell test. With a large N, both
will produce the same Chi-square value. As the Bhapkar test is more powerful, it is preferred.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Bhapkar V.P. (1966) A note on the equivalence of two test criteria for hypotheses in categorical data.
<em>Journal of the American Statistical Association</em>, 61: 228-235.
</p>
<p>Ireland C.T., Ku H.H., and Kullback S. (1969) Symmetry and marginal homogeneity of an r x r contingency table. <em>Journal of the American Statistical Association</em>, 64: 1323-1341.
</p>
<p>Keefe T.J. (1982) On the relationship between two tests for homogeneity of the marginal distributions in a two-way classification. <em>Biometrika</em>, 69: 683-684.
</p>
<p>Sun X., Yang Z. (2008) Generalized McNemar's Test for Homogeneity of the Marginal Distributions. <em>SAS Global Forum 2008: Statistics and Data Analysis</em>, Paper 382-208.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+StuartMaxwellTest">StuartMaxwellTest</a></code>, <code><a href="stats.html#topic+mcnemar.test">mcnemar.test</a></code>, <code><a href="stats.html#topic+chisq.test">chisq.test</a></code>, <code><a href="#topic+MHChisqTest">MHChisqTest</a></code>,
<code><a href="#topic+BreslowDayTest">BreslowDayTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Source: http://www.john-uebersax.com/stat/mcnemar.htm#stuart
mc &lt;- as.table(matrix(c(20,3,0,10,30,5,5,15,40), nrow=3))

BhapkarTest(mc)
</code></pre>

<hr>
<h2 id='BinomCI'> Confidence Intervals for Binomial Proportions </h2><span id='topic+BinomCI'></span>

<h3>Description</h3>

<p>Compute confidence intervals for binomial proportions following the most popular methods.<br />
(Wald, Wilson, Agresti-Coull, Jeffreys, Clopper-Pearson etc.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinomCI(x, n, conf.level = 0.95, sides = c("two.sided", "left", "right"),
        method = c("wilson", "wald", "waldcc", "agresti-coull", "jeffreys",
                   "modified wilson", "wilsoncc","modified jeffreys",
                   "clopper-pearson", "arcsine", "logit", "witting", "pratt", 
                   "midp", "lik", "blaker"),
        rand = 123, tol = 1e-05, std_est = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BinomCI_+3A_x">x</code></td>
<td>
<p> number of successes. </p>
</td></tr>
<tr><td><code id="BinomCI_+3A_n">n</code></td>
<td>
<p> number of trials. </p>
</td></tr>
<tr><td><code id="BinomCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level, defaults to 0.95. </p>
</td></tr>
<tr><td><code id="BinomCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default),
<code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of
<code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="BinomCI_+3A_method">method</code></td>
<td>
<p> character string specifing which method to use; this can be one out of:
<code>"wald"</code>, <code>"wilson"</code>, <code>"wilsoncc"</code>, <code>"agresti-coull"</code>, <code>"jeffreys"</code>,
<code>"modified wilson"</code>, <code>"modified jeffreys"</code>, <code>"clopper-pearson"</code>,
<code>"arcsine"</code>, <code>"logit"</code>, <code>"witting"</code>, <code>"pratt"</code>, <code>"midp"</code>, <code>"lik"</code> and <code>"blaker"</code>. Defaults to <code>"wilson"</code>.
Abbreviation of method is accepted. See details. </p>
</td></tr>
<tr><td><code id="BinomCI_+3A_rand">rand</code></td>
<td>
<p> seed for random number generator; see details. </p>
</td></tr>
<tr><td><code id="BinomCI_+3A_tol">tol</code></td>
<td>
<p>tolerance for method <code>"blaker"</code>.</p>
</td></tr>
<tr><td><code id="BinomCI_+3A_std_est">std_est</code></td>
<td>
<p>logical, specifying if the standard point estimator for the proportion value <code>x/n</code> should be returned (<code>TRUE</code>, default) or the method-specific internally used alternative point estimate (<code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All arguments are being recycled.
</p>
<p>The <b>Wald </b> interval is obtained by inverting the acceptance region of the Wald
large-sample normal test.
</p>
<p>The <b>Wald with continuity correction </b> interval is obtained by adding the term 1/(2*n) to the Wald interval.
</p>
<p>The <b>Wilson</b> interval, which is the default, was introduced by Wilson (1927) and is
the inversion of the CLT approximation to the family of equal tail tests of p = p0.
The Wilson interval is recommended by Agresti and Coull (1998) as well as by
Brown et al (2001).
</p>
<p>The <b>Agresti-Coull</b> interval was proposed by Agresti and Coull (1998) and is a slight
modification of the Wilson interval. The Agresti-Coull intervals are never shorter
than the Wilson intervals; cf. Brown et al (2001). The internally used point estimator p-tilde is returned as attribute.
</p>
<p>The <b>Jeffreys</b> interval is an implementation of the equal-tailed Jeffreys prior interval
as given in Brown et al (2001).
</p>
<p>The <b>modified Wilson</b> interval is a modification of the Wilson interval for x close to 0
or n as proposed by Brown et al (2001).
</p>
<p>The <b>Wilson cc</b> interval is a modification of the Wilson interval adding a continuity correction term.
</p>
<p>The <b>modified Jeffreys</b> interval is a modification of the Jeffreys interval for
<code>x == 0 | x == 1</code> and <code>x == n-1 | x == n</code> as proposed by
Brown et al (2001).
</p>
<p>The <b>Clopper-Pearson</b> interval is based on quantiles of corresponding beta
distributions. This is sometimes also called exact interval.
</p>
<p>The <b>arcsine</b> interval is based on the variance stabilizing distribution for the binomial
distribution.
</p>
<p>The <b>logit</b> interval is obtained by inverting the Wald type interval for the log odds.
</p>
<p>The <b>Witting</b> interval (cf. Beispiel 2.106 in Witting (1985)) uses randomization to
obtain uniformly optimal lower and upper confidence bounds (cf. Satz 2.105 in
Witting (1985)) for binomial proportions.
</p>
<p>The <b>Pratt</b> interval is obtained by extremely accurate normal approximation. (Pratt 1968)
</p>
<p>The <b>Mid-p</b> approach is used to reduce the conservatism of the Clopper-Pearson, which is known to be very pronounced. The method midp accumulates the tail areas. 
The lower bound <code class="reqn">p_l</code> is found as the solution to the equation
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{2} f(x;n,p_l) + (1-F(x;m,p_l)) = \frac{\alpha}{2}</code>
</p>

<p>where <code class="reqn">f(x;n,p)</code> denotes the probability mass function (pmf) and
<code class="reqn">F(x;n,p)</code> the (cumulative) distribution function of the binomial
distribution with size <code class="reqn">n</code> and proportion <code class="reqn">p</code> evaluated at
<code class="reqn">x</code>. 
The upper bound <code class="reqn">p_u</code> is found as the solution to the equation
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{2} f(x;n,p_u) + F(x-1;m,p_u) = \frac{\alpha}{2}</code>
</p>

<p>In case x=0 then the lower bound is
zero and in case x=n then the upper bound is 1.
</p>
<p>The <b>Likelihood-based</b> approach is said to be theoretically appealing. Confidence intervals are based on profiling the binomial deviance in the neighbourhood of the
MLE.
</p>
<p>For the <b>Blaker</b> method refer to Blaker (2000).
</p>
<p>For more details we refer to Brown et al (2001) as well as Witting (1985).
</p>
<p>Some approaches for the confidence intervals are capable of violating the [0, 1] boundaries and potentially yield negative results or values beyond 1. These would be truncated such as not to exceed the valid range of [0, 1].
</p>
<p>And now, which interval should we use? The Wald interval often has inadequate coverage, particularly for small n and values of p close to 0 or 1. Conversely, the Clopper-Pearson Exact method is very conservative and tends to produce wider intervals than necessary. Brown et al. recommends the Wilson or Jeffreys methods for small n and Agresti-Coull, Wilson, or Jeffreys, for larger n as providing more reliable coverage than the alternatives. 
</p>
<p>For the methods <code>"wilson"</code>, <code>"wilsoncc"</code>, <code>"modified wilson"</code>, <code>"agresti-coull"</code> and <code>"arcsine"</code> the internally used alternative point estimator for the proportion value can be returned (by setting <code>std_est = FALSE</code>). The point estimate typically is slightly shifted towards 0.5 compared to the standard estimator. See the literature for the more details.
</p>


<h3>Value</h3>

<p>A vector with 3 elements for estimate, lower confidence intervall and upper for the upper one.
</p>
<p>For more than one argument each, a 3-column matrix is returned.
</p>


<h3>Note</h3>

<p> The base of this function once was <code>binomCI()</code> from the <span class="pkg">SLmisc</span> package. In the meantime, the code has been updated on several occasions and it has undergone numerous extensions and bug fixes.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl &lt;Matthias.Kohl@stamats.de&gt;,
Rand R. Wilcox (Pratt's method), Michael Hoehle &lt;hoehle@math.su.se&gt; (Mid-p),
Ralph Scherer &lt;shearer.ra76@gmail.com&gt; (Blaker), 
Andri Signorell &lt;andri@signorell.net&gt; (interface issues and all the rest) </p>


<h3>References</h3>

<p>Agresti A. and Coull B.A. (1998) Approximate is better than &quot;exact&quot; for interval
estimation of binomial proportions.
<em>American Statistician</em>, <b>52</b>, pp. 119-126.
</p>
<p>Brown L.D., Cai T.T. and Dasgupta A. (2001) Interval estimation for a binomial
proportion <em>Statistical Science</em>, <b>16</b>(2), pp. 101-133.
</p>
<p>Witting H. (1985) <em>Mathematische Statistik I</em>. Stuttgart: Teubner.
</p>
<p>Pratt J. W. (1968) A normal approximation for binomial, F, Beta, and other
common, related tail probabilities <em>Journal of the American Statistical Association</em>, 63, 1457-
1483.
</p>
<p>Wilcox, R. R. (2005) <em>Introduction to robust estimation and hypothesis testing</em>. Elsevier Academic Press
</p>
<p>Newcombe, R. G. (1998) Two-sided confidence intervals for the single proportion: comparison of seven methods, <em>Statistics in Medicine</em>, 17:857-872
https://pubmed.ncbi.nlm.nih.gov/16206245/
</p>
<p>Blaker, H. (2000) Confidence curves and improved exact confidence intervals for discrete distributions, <em>Canadian Journal of Statistics</em> 28 (4), 783-798
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+binom.test">binom.test</a></code>, <code><a href="Hmisc.html#topic+binconf">binconf</a></code>, <code><a href="#topic+MultinomCI">MultinomCI</a></code>,  <code><a href="#topic+BinomDiffCI">BinomDiffCI</a></code>, <code><a href="#topic+BinomRatioCI">BinomRatioCI</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>BinomCI(x=37, n=43, 
        method=eval(formals(BinomCI)$method))   # return all methods

# the confidence interval computed by binom.test
#   corresponds to the Clopper-Pearson interval
BinomCI(x=42, n=43, method="clopper-pearson")
binom.test(x=42, n=43)$conf.int


# all arguments are being recycled:
BinomCI(x=c(42, 35, 23, 22), n=43, method="wilson")
BinomCI(x=c(42, 35, 23, 22), n=c(50, 60, 70, 80), method="jeffreys")

# example Table I in Newcombe (1998)
do.call(cbind, lapply(1:4, 
  function(i){
    Format(BinomCI(x      = c(81, 15, 0, 1)[i], 
                   n      = c(263, 148, 20, 29)[i], 
                   method = c("wald", "waldcc", "wilson","wilsoncc", 
                              "clopper-pearson", "midp", "lik"))[, -1], 
           digits=4)
}))

# returning p.tilde for agresti-coull ci
BinomCI(x=81, n=263, meth="agresti-coull", std_est = c(TRUE, FALSE))
</code></pre>

<hr>
<h2 id='BinomCIn'>Sample Size for a Given Width of a Binomial Confidence Interval
</h2><span id='topic+BinomCIn'></span>

<h3>Description</h3>

<p>Returns the necessary sample size to achieve a given width of a binomial confidence interval, as calculated by <code><a href="#topic+BinomCI">BinomCI</a>()</code>. The function uses <code><a href="stats.html#topic+uniroot">uniroot</a>()</code> to find a numeric solution. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinomCIn(p = 0.5, width, interval = c(1, 100000), 
         conf.level = 0.95, sides = "two.sided", method = "wilson")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BinomCIn_+3A_p">p</code></td>
<td>
<p>probability for success, defaults to <code>0.5</code>.
</p>
</td></tr>
<tr><td><code id="BinomCIn_+3A_width">width</code></td>
<td>
<p>the width of the confidence interval
</p>
</td></tr>
<tr><td><code id="BinomCIn_+3A_interval">interval</code></td>
<td>
<p>a vector containing the end-points of the interval to be searched for the root. The defaults are set to <code>c(1, 100000)</code>.
</p>
</td></tr>
<tr><td><code id="BinomCIn_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level, defaults to <code>0.95</code>. </p>
</td></tr>
<tr><td><code id="BinomCIn_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default),
<code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of
<code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="BinomCIn_+3A_method">method</code></td>
<td>
<p> character string specifing which method to use; this can be one out of:
<code>"wald"</code>, <code>"wilson"</code>, <code>"wilsoncc"</code>, <code>"agresti-coull"</code>, <code>"jeffreys"</code>,
<code>"modified wilson"</code>, <code>"modified jeffreys"</code>, <code>"clopper-pearson"</code>,
<code>"arcsine"</code>, <code>"logit"</code>, <code>"witting"</code> or <code>"pratt"</code>. Defaults to <code>"wilson"</code>.
Abbreviation of method are accepted. See details in <code><a href="#topic+BinomCI">BinomCI</a>()</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The required sample sizes for a specific width of confidence interval depends on the proportion in the population. This value might be unknown right from the start when a study is planned.
In such cases the sample size needed for a given level of accuracy can be estimated using the worst case percentage which is p=50%. When a better estimate is available you can you can use it to get a smaller interval.
</p>


<h3>Value</h3>

<p>a numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BinomCI">BinomCI</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BinomCIn(p=0.1, width=0.05, method="pratt")
</code></pre>

<hr>
<h2 id='BinomDiffCI'>Confidence Interval for a Difference of Binomials
</h2><span id='topic+BinomDiffCI'></span>

<h3>Description</h3>

<p>Several confidence intervals for the difference between proportions are available, but they can produce markedly different results. Traditional approaches, such as the Wald interval do not perform well unless the sample size is large. Better intervals are available. These include the Agresti/Caffo method (2000), Newcombe Score method (1998) and more computing intensive ones as by Miettinen and Nurminen (1985) or Mee (1984). The latter ones are favoured by Newcombe (when forced to choose between a rock and a hard place).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinomDiffCI(x1, n1, x2, n2, conf.level = 0.95, sides = c("two.sided","left","right"),
            method = c("ac", "wald", "waldcc", "score", "scorecc", "mn",
                       "mee", "blj", "ha", "hal", "jp"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BinomDiffCI_+3A_x1">x1</code></td>
<td>
<p> number of successes for the first group. </p>
</td></tr>
<tr><td><code id="BinomDiffCI_+3A_n1">n1</code></td>
<td>
<p> number of trials for the first group. </p>
</td></tr>
<tr><td><code id="BinomDiffCI_+3A_x2">x2</code></td>
<td>
<p> number of successes for the second group. </p>
</td></tr>
<tr><td><code id="BinomDiffCI_+3A_n2">n2</code></td>
<td>
<p> number of trials for the second group. </p>
</td></tr>
<tr><td><code id="BinomDiffCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level, defaults to 0.95. </p>
</td></tr>
<tr><td><code id="BinomDiffCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default),
<code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of
<code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="BinomDiffCI_+3A_method">method</code></td>
<td>
<p> one of <code>"wald"</code>, <code>"waldcc"</code>, <code>"ac"</code>, <code>"score"</code>, <code>"scorecc"</code>, <code>"mn"</code>, <code>"mee"</code>, <code>"blj"</code>, <code>"ha"</code>, <code>"hal"</code>, <code>"jp"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All arguments are being recycled.
</p>
<p>We estimate the difference between proportions using the sample proportions:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\delta} =\hat{p}_1 - \hat{p}_2 = \frac{x_1}{n_1} - \frac{x_2}{n_2}</code>
</p>

<p>The traditional <b>Wald </b> confidence interval for the difference of two proportions <code class="reqn">\delta</code> is based on the asymptotic normal distribution of <code class="reqn">\hat{\delta}</code>.
</p>
<p>The <b>Corrected Wald</b> interval uses a continuity correction included in the test statistic. The continuity correction is subtracted from the numerator of the test statistic if the numerator is greater than zero; otherwise, the continuity correction is added to the numerator. The value of the continuity correction is (1/n1 + 1/n2)/2.
</p>
<p>The <b>Agresti-Caffo</b> (code <code>"ac"</code>) is equal to the Wald interval with the adjustment according to Agresti, Caffo (2000) for difference in proportions and independent samples. It adds 1 to x1 and x2 and adds 2 to n1 and n2 and performs surpringly well.
</p>
<p><b>Newcombe</b> (code <code>"scorecc"</code>) proposed a confidence interval for the difference based on the Wilson score confidence interval for a single proportion. A variant uses a continuity correction for the Wilson interval (code <code>"scorecc"</code>).
</p>
<p><b>Miettinen and Nurminen</b> showed that the restricted maximum likelihood estimates for p1 and p2 can
be obtained by solving a cubic equation and gave unique closed-form expressions for them. The Miettinen-Nurminen confidence interval is returned with code <code>"mn"</code>.
</p>
<p>The <b>Mee</b> (code <code>"mee"</code>) interval proposed by Mee (1984) and Farrington-Manning (1990) is using the same maximum likelihood estimators as Miettinen-Nurminen but with another correcting factor.
</p>
<p>The <b>Brown, Li's Jeffreys</b> (code <code>"blj"</code>) interval was proposed by Brown, Li's Jeffreys (2005).
</p>
<p>The <b>Hauck-Anderson</b> (code <code>"ha"</code>) interval was proposed by Hauck-Anderson (1986).
</p>
<p>The <b>Haldane</b> (code <code>"hal"</code>) interval is described in Newcombe (1998) and so is
the <b>Jeffreys-Perks</b> (code <code>"jp"</code>).
</p>
<p>Some approaches for the confidence intervals can potentially yield negative results or values beyond [-1, 1]. These would be reset such as not to exceed the range of [-1, 1].
</p>
<p>Which of the methods to use is currently still the subject of lively discussion and has not yet been conclusively clarified. See e.g. Fagerland (2011).
</p>
<p>The general consensus is that the most widely taught method <code>method="wald"</code> is inappropriate in many situations and should not be used. Recommendations seem to converge around the Miettinen-Nurminen based methods (<code>method="mn"</code>). 
</p>


<h3>Value</h3>

<p>A matrix with 3 columns containing the estimate, the lower and the upper confidence intervall.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A, Caffo, B (2000) Simple and effective confidence intervals for proportions and difference of proportions result from adding two successes and two failures. <em>The American Statistician</em> 54 (4), 280-288.
</p>
<p>Beal, S L (1987) Asymptotic Confidence Intervals for the Difference Between Two Binomial Parameters for Use with Small Samples;  <em>Biometrics</em>, 43, 941-950.
</p>
<p>Brown L, Li X (2005) Confidence intervals for two sample binomial distribution, <em>Journal of Statistical Planning and Inference</em>, 130(1), 359-375.
</p>
<p>Hauck WW, Anderson S. (1986) A comparison of large-sample confidence interval methods for the difference of two binomial probabilities <em>The American Statistician</em> 40(4): 318-322.
</p>
<p>Farrington, C. P. and Manning, G. (1990) Test Statistics and Sample Size Formulae for Comparative Binomial Trials with Null Hypothesis of Non-zero Risk Difference or Non-unity Relative Risk <em>Statistics in Medicine</em>, 9, 1447-1454.
</p>
<p>Mee RW (1984) Confidence bounds for the difference between two probabilities, <em>Biometrics</em> 40:1175-1176 .
</p>
<p>Miettinen OS, Nurminen M. (1985) Comparative analysis of two rates. <em>Statistics in Medicine</em> 4, 213-226.
</p>
<p>Newcombe, R G (1998). Interval Estimation for the Difference Between Independent Proportions: Comparison of Eleven Methods. <em>Statistics in Medicine</em>, 17, 873&ndash;890.
</p>
<p>Fagerland M W, Lydersen S and Laake P (2011) Recommended confidence intervals for two independent binomial proportions, <em>Statistical Methods in Medical Research</em> 0(0) 1-31
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+BinomCI">BinomCI</a></code>,  <code><a href="#topic+MultinomCI">MultinomCI</a></code>,  <code><a href="stats.html#topic+binom.test">binom.test</a></code>,
<code><a href="stats.html#topic+prop.test">prop.test</a></code>, <code><a href="#topic+BinomRatioCI">BinomRatioCI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- 56; n1 &lt;- 70; x2 &lt;- 48; n2 &lt;- 80
xci &lt;- BinomDiffCI(x1, n1, x2, n2, method=c("wald", "waldcc", "ac", "score",
            "scorecc", "mn", "mee", "blj", "ha"))
Format(xci[,-1], digits=4)

x1 &lt;- 9; n1 &lt;- 10; x2 &lt;- 3; n2 &lt;- 10
yci &lt;- BinomDiffCI(x1, n1, x2, n2, method=c("wald", "waldcc", "ac", "score",
            "scorecc", "mn", "mee", "blj", "ha"))
Format(yci[, -1], digits=4)

# https://www.lexjansen.com/wuss/2016/127_Final_Paper_PDF.pdf, page 9
SetNames(round(
  BinomDiffCI(56, 70, 48, 80, 
              method=c("wald", "waldcc", "hal", 
                       "jp", "mee",
                       "mn", "score", "scorecc", 
                       "ha", "ac", "blj"))[,-1], 4),
  rownames=c("1. Wald, no CC", "2. Wald, CC", "3. Haldane", "4. Jeffreys-Perks",
             "5. Mee", "6. Miettinen-Nurminen", "10. Score, no CC", "11. Score, CC",
             "12. Hauck-Andersen", "13. Agresti-Caffo", "16. Brown-Li"))

</code></pre>

<hr>
<h2 id='BinomRatioCI'>
Confidence Intervals for the Ratio of Binomial Proportions
</h2><span id='topic+BinomRatioCI'></span>

<h3>Description</h3>

<p>A number of methods have been develeloped for obtaining confidence intervals for the ratio of two binomial proportions. These include the Wald/Katz-log method (Katz et al. 1978), 
adjusted-log (Walter 1975, Pettigrew et al. 1986), Koopman asymptotic score (Koopman 1984), Inverse hyperbolic sine transformation (Newman 2001), the Bailey method (Bailey (1987), 
and the Noether (1957) procedure. Koopman results are found iteratively for most intervals using root finding.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinomRatioCI(x1, n1, x2, n2, conf.level = 0.95, 
             sides = c("two.sided", "left", "right"), 
             method = c("katz.log", "adj.log", "bailey", "koopman", "noether", 
                        "sinh-1", "boot"),
             tol = .Machine$double.eps^0.25, R = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BinomRatioCI_+3A_x1">x1</code></td>
<td>
<p>number of successes for the ratio numerator. </p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_n1">n1</code></td>
<td>
<p>number of trials for the ratio numerator. </p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_x2">x2</code></td>
<td>
<p>number of successes for the ratio denominator. </p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_n2">n2</code></td>
<td>
<p>number of successes for the ratio denominator. </p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level, defaults to 0.95. </p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default),
<code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of
<code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_method">method</code></td>
<td>

<p>confidence interval method, one of <code>"katz.log"</code> (default), <code>"adj.log"</code>, <code>"bailey"</code>,  
<code>"boot"</code>, <code>"koopman"</code>, <code>"noether"</code> or <code>"sinh-1"</code>. Can be abbreviated.
</p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_tol">tol</code></td>
<td>
<p>The desired accuracy (convergence tolerance) for the iterative root finding procedure when finding Koopman intevals. The default is taken to be the smallest positive floating-point number of the workstation implementing the function, raised to the 0.25 power, and will normally be approximately 0.0001.
</p>
</td></tr>
<tr><td><code id="BinomRatioCI_+3A_r">R</code></td>
<td>
<p>If method <code>"boot"</code> is chosen, the number of bootstrap iterations.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All arguments are being recycled.
</p>
<p>Let <code class="reqn">Y_1</code> and <code class="reqn">Y_2</code> be multinomial random variables with parameters <code class="reqn">n_1, \pi_{1i}</code>,  and  <code class="reqn">n_2, \pi_{2i}</code>, respectively; where <code class="reqn">i = \{1, 2, 3, \dots, r\}</code>.  This encompasses the binomial case in which <code class="reqn">r = 1</code>. We define the true selection ratio for the <em>i</em>th resource of <em>r</em> total resources to be:
</p>
<p style="text-align: center;"><code class="reqn">\theta_{i}=\frac{\pi _{1i}}{\pi _{2i}}</code>
</p>

<p>where <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> represent the proportional use and availability of the <em>i</em>th resource, respectively. Note that if <code class="reqn">r = 1</code> the selection ratio becomes relative risk.  The maximum likelihood estimators for <code class="reqn">\pi_{1i}</code> and <code class="reqn">\pi_{2i}</code> are the sample proportions: 
</p>
<p style="text-align: center;"><code class="reqn">{{\hat{\pi }}_{1i}}=\frac{{{y}_{1i}}}{{{n}_{1}}},</code>
</p>
<p> and
</p>
<p style="text-align: center;"><code class="reqn">{{\hat{\pi }}_{2i}}=\frac{{{y}_{2i}}}{{{n}_{2}}}</code>
</p>

<p>where <code class="reqn">y_{1i}</code> and <code class="reqn">y_{2i}</code> are the observed counts for use and availability for the <em>i</em>th resource.  The estimator for <code class="reqn">\theta_i</code> is:
</p>
<p style="text-align: center;"><code class="reqn">\hat{\theta}_{i}=\frac{\hat{\pi}_{1i}}{\hat{\pi }_{2i}}.</code>
</p>


<table>
<tr>
 <td style="text-align: left;">
Method </td><td style="text-align: left;"> Algorithm </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;"> 

Katz-log </td><td style="text-align: left;"> <code class="reqn">\hat\theta_i\times</code> exp<code class="reqn">(\pm z_1-\alpha/2\hat{\sigma}_W)</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> where <code class="reqn">\hat\sigma_W^2=\frac{(1-\hat{\pi} _{1i})}{\hat{\pi}_{1i}n_1}+\frac{(1-\hat{\pi}_{2i})}{\hat{\pi}_{2i}n_2}</code>.  </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">

Adjusted-log </td><td style="text-align: left;"> <code class="reqn">\hat{\theta}_{Ai}\times</code> exp<code class="reqn">(\pm z_1-\alpha /2\hat{\sigma}_A)</code>, </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> where <code class="reqn">\hat{\theta}_{Ai}=\frac{y_{1i}+0.5/n_1+0.5}{y_{2i}+0.5/n_2+0.5}</code>, </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code class="reqn">\hat{\sigma}_A^2=\frac{1}{y_1+0.5}-\frac{1}{n_1+0.5}+\frac{1}{y_2+0.5}-\frac{1}{n_2+0.5}</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">

Bailey </td><td style="text-align: left;"> <code class="reqn">\hat{\theta} _i\left[\frac{1\pm z_1-\left( \alpha /2 \right)\left( \hat{\pi}_{1i}'/y_{1i}+\hat{\pi}_{2i}'/y_{2i}-z_1-\left(\alpha/2 \right)^2\hat{\pi} _{1i}'\hat{\pi}_{2i}'/9y_{1i}y_{2i} \right)^{1/2}/3}{1-z_{1-\left(\alpha/2 \right)^2}\hat{\pi} _{2i}'/9y_{2i}} \right]^3</code>,</td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> where <code class="reqn">\hat{\pi_{1i}}'</code> = 1 - <code class="reqn">\hat{\pi}_{1i}</code>, and <code class="reqn">\hat{\pi}_{2i}'</code> = 1 - <code class="reqn">\hat{\pi}_{2i}</code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">

Inv. hyperbolic sine </td><td style="text-align: left;"> <code class="reqn">\ln({{\hat{\theta }}_{i}})\pm \left[ 2sin{{h}^{-1}}\left( \frac{{{z}_{(1-\alpha /2)}}}{2}\sqrt{\frac{1}{{{y}_{1i}}}-\frac{1}{{{n}_{1}}}+\frac{1}{{{y}_{2i}}}-\frac{1}{{{n}_{2}}}} \right) \right]</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> 

Koopman </td><td style="text-align: left;"> Find <code class="reqn">X^2(\theta_0)</code> = <code class="reqn">\chi _1^2(1 - \alpha)</code>, where </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;">  <code class="reqn">{{\tilde{\pi }}_{1i}}=\frac{{{\theta }_{0}}({{n}_{1}}+{{y}_{2i}})+{{y}_{1i}}+{{n}_{2}}-{{[{{\{{{\theta }_{0}}({{n}_{1}}+{{y}_{2i}})+{{y}_{1i}}+
{{n}_{2}}\}}^{2}}-4{{\theta }_{0}}({{n}_{1}}+{{n}_{2}})({{y}_{1i}}+{{y}_{2i}})]}^{0.5}}}{2({{n}_{1}}+{{n}_{2}})}</code>, </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> <code class="reqn">{{\tilde{\pi }}_{2i}}=\frac{{{{\tilde{\pi }}}_{1i}}}{{{\theta }_{0}}}, and {{X}^{2}}({{\theta}_{0}})=\frac{{{\left( {{y}_{1i}}-{{n}_{1}}{{{\tilde{\pi }}}_{1i}} \right)}^{2}}}
{{{n}_{1}}{{{\tilde{\pi }}}_{1i}}(1-{{{\tilde{\pi }}}_{1i}})}\left\{ 1+\frac{{{n}_{1}}({{\theta}_{0}}-{{{\tilde{\pi }}}_{1i}})}{{{n}_{2}}(1-{\tilde{\pi}_{1i}})} \right\}</code>. </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Noether </td><td style="text-align: left;"> <code class="reqn">\hat{\theta}_i\pm z_1-\alpha/2\hat{\sigma}_N</code>,   </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> where <code class="reqn">\hat{\sigma }_{N}^{2}=\hat{\theta }_{i}^{2}\left( \frac{1}{{{y}_{1i}}}-\frac{1}{{{n}_{1}}}+\frac{1}{{{y}_{2i}}}-\frac{1}{{{n}_{2}}} \right)</code>.  
</td>
</tr>

</table>

<p>Exception handling strategies are generally necessary in the cases <code class="reqn">x_1</code> = 0, <code class="reqn">n_1</code> = <code class="reqn">x_1</code>, <code class="reqn">x_2</code> = 0, and <code class="reqn">n_2</code> = <code class="reqn">x_2</code> (see Aho and Bowyer, in review).  
</p>
<p>The bootstrap method currently employs percentile confidence intervals.
</p>


<h3>Value</h3>

<p>A matrix with 3 columns containing the estimate, the lower and the upper confidence intervall.
</p>


<h3>Author(s)</h3>

<p>Ken Aho &lt;kenaho1@gmail.com&gt;, some tweaks Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A., Min, Y. (2001) On small-sample confidence intervals for parameters in discrete distributions.  <em>Biometrics</em> 57: 963-97.
</p>
<p>Aho, K., and Bowyer, T. (In review) Confidence intervals for ratios of multinomial proportions: implications for selection ratios. <em>Methods in Ecology and Evolution</em>.
</p>
<p>Bailey, B.J.R. (1987) Confidence limits to the risk ratio.  <em>Biometrics</em> 43(1): 201-205.
</p>
<p>Katz, D., Baptista, J., Azen, S. P., and Pike, M. C. (1978) Obtaining confidence intervals for the risk ratio in cohort studies. <em>Biometrics</em> 34: 469-474
</p>
<p>Koopman, P. A. R. (1984) Confidence intervals for the ratio of two binomial proportions. <em>Biometrics</em> 40:513-517.
</p>
<p>Manly, B. F., McDonald, L. L., Thomas, D. L., McDonald, T. L. and Erickson, W.P. (2002)  <em>Resource Selection by Animals: Statistical Design and Analysis for Field Studies.  2nd  edn.</em>  Kluwer, New York, NY
</p>
<p>Newcombe, R. G. (2001)  Logit confidence intervals and the inverse sinh transformation.  <em>The American Statistician</em> 55: 200-202.
</p>
<p>Pettigrew H. M., Gart, J. J., Thomas, D. G. (1986)  The bias and higher cumulants of the logarithm of a
binomial variate.  <em>Biometrika</em> 73(2): 425-435.
</p>
<p>Walter, S. D. (1975) The distribution of Levins measure of attributable risk. <em>Biometrika</em> 62(2): 371-374.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BinomCI">BinomCI</a>, <a href="#topic+BinomDiffCI">BinomDiffCI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># From Koopman (1984)

BinomRatioCI(x1 = 36, n1 = 40, x2 = 16, n2 = 80, method = "katz")
BinomRatioCI(x1 = 36, n1 = 40, x2 = 16, n2 = 80, method = "koop")
</code></pre>

<hr>
<h2 id='BinTree'>Binary Tree
</h2><span id='topic+BinTree'></span><span id='topic+PlotBinTree'></span>

<h3>Description</h3>

<p>Create a binary tree of a given number of nodes <code>n</code>. Can be used to organize a sorted numeric vector as  a binary tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinTree(n)

PlotBinTree(x, main="Binary tree", horiz=FALSE, cex=1.0, col=1, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BinTree_+3A_n">n</code></td>
<td>
<p>integer, size of the tree
</p>
</td></tr>
<tr><td><code id="BinTree_+3A_x">x</code></td>
<td>
<p>numeric vector to be organized as binary tree.
</p>
</td></tr>
<tr><td><code id="BinTree_+3A_main">main</code></td>
<td>
<p>main title of the plot.
</p>
</td></tr>
<tr><td><code id="BinTree_+3A_horiz">horiz</code></td>
<td>
<p>logical, should the plot be oriented horizontally or vertically. The latter is default.</p>
</td></tr>
<tr><td><code id="BinTree_+3A_cex">cex</code></td>
<td>
<p>character extension factor for the labels.
</p>
</td></tr>
<tr><td><code id="BinTree_+3A_col">col</code></td>
<td>
<p>color of the linesegments of the plot.
</p>
</td></tr>
<tr><td><code id="BinTree_+3A_...">...</code></td>
<td>
<p>the dots are sent to <code><a href="#topic+Canvas">Canvas</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If we index the nodes of the tree as 1 for the top, 2&ndash;3 for the next
horizontal row, 4&ndash;7 for the next, ... then the parent-child
traversal becomes particularly easy.
The basic idea is that the rows of the tree start at indices 1, 2, 4, ....
</p>
<p>BinTree(13) yields the vector
<code>c(8, 4, 9, 2, 10, 5, 11, 1, 12, 6, 13, 3, 7)</code> meaning that the smallest element
will be in position 8 of the tree, the next smallest in position 4, etc.
</p>


<h3>Value</h3>

<p>an integer vector of length n
</p>


<h3>Author(s)</h3>

<p>Terry Therneau &lt;therneau.terry@mayo.edu&gt;<br />
Andri Signorell &lt;andri@signorell.net&gt; (plot)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BinTree(12)

x &lt;- sort(sample(100, 24))
z &lt;- PlotBinTree(x, cex=0.8)


# Plot example - Titanic data, for once from a somwhat different perspective
tab &lt;- apply(Titanic, c(2,3,4), sum)
cprob &lt;- c(1, prop.table(apply(tab, 1, sum))
           , as.vector(aperm(prop.table(apply(tab, c(1,2), sum), 1), c(2, 1)))
           , as.vector(aperm(prop.table(tab, c(1,2)), c(3,2,1)))
)

PlotBinTree(round(cprob[BinTree(length(cprob))],2), horiz=TRUE, cex=0.8,
            main="Titanic")
text(c("sex","age","survived"), y=0, x=c(1,2,3)+1)
</code></pre>

<hr>
<h2 id='BootCI'>Simple Bootstrap Confidence Intervals
</h2><span id='topic+BootCI'></span>

<h3>Description</h3>

<p>Convenience wrapper for calculating bootstrap confidence intervals for univariate and bivariate statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BootCI(x, y = NULL, FUN, ..., bci.method = c("norm", "basic", "stud", "perc", "bca"),
       conf.level = 0.95, sides = c("two.sided", "left", "right"), R = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BootCI_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="BootCI_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>, when a bivariate statistic is used.
</p>
</td></tr>
<tr><td><code id="BootCI_+3A_fun">FUN</code></td>
<td>
<p>the function to be used </p>
</td></tr>
<tr><td><code id="BootCI_+3A_bci.method">bci.method</code></td>
<td>
<p>A vector of character strings representing the type of intervals required. The value should be any subset of the values <code>"norm"</code>, <code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code>, <code>"bca"</code>, as it is passed on as <code>method</code> to <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>.
</p>
</td></tr>
<tr><td><code id="BootCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.
</p>
</td></tr>
<tr><td><code id="BootCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="BootCI_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code>FUN</code>.
</p>
</td></tr>
<tr><td><code id="BootCI_+3A_r">R</code></td>
<td>
<p>The number of bootstrap replicates. Usually this will be a single positive integer. For importance resampling,
some resamples may use one set of weights and others use a different set of weights. In this case <code>R</code> would be a vector
of integers where each component gives the number of resamples from each of the rows of weights.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named numeric vector with 3 elements:
</p>
<table>
<tr><td><code>est</code></td>
<td>
<p>the specific estimate, as calculated by <code>FUN</code></p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MeanCI">MeanCI</a></code>, <code><a href="#topic+MedianCI">MedianCI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1984)
BootCI(d.pizza$temperature, FUN=mean, na.rm=TRUE, bci.method="basic")
BootCI(d.pizza$temperature, FUN=mean, trim=0.1, na.rm=TRUE, bci.method="basic")

BootCI(d.pizza$temperature, FUN=Skew, na.rm=TRUE, bci.method="basic")

BootCI(d.pizza$operator, d.pizza$area, FUN=CramerV)

spearman &lt;- function(x,y) cor(x, y, method="spearman", use="p")
BootCI(d.pizza$temperature, d.pizza$delivery_min, FUN=spearman)
</code></pre>

<hr>
<h2 id='BoxCox'>Box Cox Transformation</h2><span id='topic+BoxCox'></span><span id='topic+BoxCoxInv'></span>

<h3>Description</h3>

<p><code>BoxCox()</code> returns a transformation of the input variable using a Box-Cox transformation.<br />
<code>BoxCoxInv()</code> reverses the transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BoxCox(x, lambda)
BoxCoxInv(x, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BoxCox_+3A_x">x</code></td>
<td>
<p>a numeric vector </p>
</td></tr>
<tr><td><code id="BoxCox_+3A_lambda">lambda</code></td>
<td>
<p>transformation parameter</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Box-Cox transformation is given by
</p>
<p style="text-align: center;"><code class="reqn">f_\lambda(x) =
  \left\{\begin{array}{ll}
     \frac{x^\lambda - 1}{\lambda} &amp;\textup{for }\lambda \neq 0\\
     log(x) &amp;\textup{for }\lambda = 0
  \end{array}\right.
</code>
</p>



<h3>Value</h3>

<p>a numeric vector of the same length as x.
</p>


<h3>Note</h3>

<p>These two functions are borrowed from <code>library(forecast)</code>.</p>


<h3>Author(s)</h3>

<p>Rob J Hyndman &lt;rob.hyndman@monash.edu&gt;</p>


<h3>References</h3>

<p>Box, G. E. P. and Cox, D. R. (1964) An analysis of transformations. <em>JRSS B</em> <b>26</b> 211&ndash;246.
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+BoxCoxLambda">BoxCoxLambda</a></code> or <code><a href="MASS.html#topic+boxcox">boxcox</a></code> in <code>library(MASS)</code> to find optimal lambda values. </p>


<h3>Examples</h3>

<pre><code class='language-R'># example by Greg Snow
x &lt;- rlnorm(500, 3, 2)

par(mfrow=c(2,2))
qqnorm(x, main="Lognormal")
qqnorm(BoxCox(x, 1/2), main="BoxCox(lambda=0.5)")
qqnorm(BoxCox(x, 0), main="BoxCox(lambda=0)")

PlotFdist(BoxCox(x, 0))

bx &lt;- BoxCox(x, lambda = BoxCoxLambda(x) )
</code></pre>

<hr>
<h2 id='BoxCoxLambda'>Automatic Selection of Box Cox Transformation Parameter</h2><span id='topic+BoxCoxLambda'></span>

<h3>Description</h3>

<p>An automatic selection of the Box Cox transformation parameter is estimated with two methods.<br /> 
Guerrero's (1993) method yields a lambda which minimizes the coefficient of variation for subseries of <code>x</code>. 
For method <code>"loglik"</code>, the value of lambda is chosen to maximize the profile log likelihood of a linear model fitted to <code>x</code>. 
For non-seasonal data, a linear time trend is fitted while for seasonal data, a linear time trend with seasonal dummy variables is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BoxCoxLambda(x, method = c("guerrero", "loglik"), lower = -1, upper = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BoxCoxLambda_+3A_x">x</code></td>
<td>
<p>a numeric vector or time series</p>
</td></tr>
<tr><td><code id="BoxCoxLambda_+3A_method">method</code></td>
<td>
<p>method to be used in calculating lambda. Can be either &quot;guerrero&quot; (default) or &quot;loglik&quot;.</p>
</td></tr>
<tr><td><code id="BoxCoxLambda_+3A_lower">lower</code></td>
<td>
<p>lower limit for possible lambda values, default is -1.</p>
</td></tr>
<tr><td><code id="BoxCoxLambda_+3A_upper">upper</code></td>
<td>
<p>upper limit for possible lambda values, default is 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number indicating the Box-Cox transformation parameter.
</p>


<h3>Note</h3>

<p> This function was previously published as <code>BoxCox.lambda()</code> in the  <span class="pkg">forecast</span> package and has been integrated here without logical changes. 
</p>


<h3>Author(s)</h3>

<p>Leanne Chhay and Rob J Hyndman</p>


<h3>References</h3>

<p>Box, G. E. P. and Cox, D. R. (1964) An analysis of transformations. <em>JRSS B</em> <b>26</b> 211&ndash;246.
</p>
<p>Guerrero, V.M. (1993) Time-series analysis supported by power transformations. <em>Journal of Forecasting</em>, <b>12</b>, 37&ndash;48.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BoxCox">BoxCox</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
lambda &lt;- BoxCoxLambda(AirPassengers, lower=0)

</code></pre>

<hr>
<h2 id='BoxedText'>Add Text in a Box to a Plot
</h2><span id='topic+BoxedText'></span><span id='topic+BoxedText.default'></span>

<h3>Description</h3>

<p>BoxedText draws the strings given in the vector labels at the coordinates given by x and y, surrounded by a rectangle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BoxedText(x, ...)

## Default S3 method:
BoxedText(x, y = NULL, labels = seq_along(x), adj = NULL, pos = NULL, offset = 0.5, 
          vfont = NULL, cex = 1, col = NULL, font = NULL, srt = 0, 
          xpad = 0.2, ypad = 0.2, density = NULL, angle = 45, bg = NA, 
          border = par("fg"), lty = par("lty"), lwd = par("lwd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BoxedText_+3A_x">x</code>, <code id="BoxedText_+3A_y">y</code></td>
<td>
<p>numeric vectors of coordinates where the text labels should be written. If the length of x and y differs, the shorter one is recycled.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_labels">labels</code></td>
<td>
<p>a character vector or expression specifying the text to be written. 
An attempt is made to coerce other language objects (names and calls) to expressions, and vectors and other 
classed objects to character vectors by as.character. If labels is longer than x and y, the coordinates are recycled to the length of labels.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_adj">adj</code></td>
<td>
<p>The value of adj determines the way in which text strings are justified. 
A value of 0 produces left-justified text, 0.5 (the default) centered text and 1 right-justified text. 
(Any value in [0, 1] is allowed, and on most devices values outside that interval will also work.) 
Note that the adj argument of text also allows adj = c(x, y) for different adjustment in x- and y- directions. 
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_pos">pos</code></td>
<td>
<p>a position specifier for the text. If specified this overrides any adj value given. Values of 1, 2, 3 and 4, respectively indicate positions below, to the left of, above and to the right of the specified coordinates.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_offset">offset</code></td>
<td>
<p>when pos is specified, this value gives the offset of the label from the specified coordinate in fractions of a character width.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_vfont">vfont</code></td>
<td>
<p><code>NULL</code> for the current font family, or a character vector of length 2 for Hershey vector fonts. The first element of the vector 
selects a typeface and the second element selects a style. Ignored if labels is an expression.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_cex">cex</code></td>
<td>
<p>numeric character expansion factor; multiplied by <code>par("cex")</code> yields the final character size. <code>NULL</code> and <code>NA</code> are equivalent to 1.0.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_col">col</code>, <code id="BoxedText_+3A_font">font</code></td>
<td>
<p>the color and (if vfont = NULL) font to be used, possibly vectors. These default to the values of the global graphical parameters in <code>par()</code>.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_srt">srt</code></td>
<td>
<p>The string rotation in degrees. 
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_xpad">xpad</code>, <code id="BoxedText_+3A_ypad">ypad</code></td>
<td>
<p>The proportion of the rectangles to the extent of the text within.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_density">density</code></td>
<td>
<p>the density of shading lines, in lines per inch. The default value of <code>NULL</code> means that no shading lines are drawn. 
A zero value of density means no shading lines whereas negative values (and NA) suppress shading (and so allow color filling).
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_angle">angle</code></td>
<td>
<p>angle (in degrees) of the shading lines.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_bg">bg</code></td>
<td>
<p>color(s) to fill or shade the rectangle(s) with. The default <code>NA</code> (or also NULL) means do not fill, 
i.e., draw transparent rectangles, unless density is specified.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_border">border</code></td>
<td>
<p>color for rectangle border(s). The default is <code>par("fg")</code>. Use <code>border = NA</code> to omit borders 
(this is the default). 
If there are shading lines, <code>border = TRUE</code> means use the same colour for the border as for the shading lines.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_lty">lty</code></td>
<td>
<p>line type for borders and shading; defaults to <code>"solid"</code>.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and shading. Note that the use of <code>lwd = 0</code> (as in the examples) is device-dependent.
</p>
</td></tr>
<tr><td><code id="BoxedText_+3A_...">...</code></td>
<td>
<p>additional arguments are passed to the text function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SpreadOut">SpreadOut</a></code>, similar function in package <span class="pkg">plotrix</span> <code><a href="plotrix.html#topic+boxed.labels">boxed.labels</a></code> (lacking rotation option)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Canvas(xpd=TRUE)

BoxedText(0, 0, adj=0, label="This is boxed text", srt=seq(0,360,20), xpad=.3, ypad=.3)
points(0,0, pch=15)
</code></pre>

<hr>
<h2 id='BreslowDayTest'>Breslow-Day Test for Homogeneity of the Odds Ratios
</h2><span id='topic+BreslowDayTest'></span>

<h3>Description</h3>

<p> Calculates the Breslow-Day test of homogeneity for a
<code class="reqn">2 \times 2 \times k</code> table, in order to investigate if
all <code class="reqn">k</code> strata have the same OR.
If OR is not given, the Mantel-Haenszel estimate is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BreslowDayTest(x, OR = NA, correct = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BreslowDayTest_+3A_x">x</code></td>
<td>
<p>a <code class="reqn">2 \times 2 \times k</code> table.
</p>
</td></tr>
<tr><td><code id="BreslowDayTest_+3A_or">OR</code></td>
<td>
<p>the odds ratio to be tested against. If left undefined (default) the Mantel-Haenszel estimate will be used.
</p>
</td></tr>
<tr><td><code id="BreslowDayTest_+3A_correct">correct</code></td>
<td>
<p>If TRUE, the Breslow-Day test with Tarone's adjustment is computed, which subtracts an adjustment factor to make the resulting statistic asymptotically chi-square.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the Breslow-Day test to be valid, the sample size should be relatively large in each stratum, and at least 80% of the expected cell counts should be greater than 5. Note that this is a stricter sample size requirement than the requirement for the Cochran-Mantel-Haenszel test for  tables, in that each stratum sample size (not just the overall sample size) must be relatively large. Even when the Breslow-Day test is valid, it might not be very powerful against certain alternatives, as discussed in Breslow and Day (1980).
</p>
<p>Alternatively, it might be better to cast the entire inference problem
into the setting of a logistic regression model. Here, the underlying
question of the Breslow-Day test can be answered by investigating whether an
interaction term with the strata variable is necessary (e.g. using a
likelihood ratio test using the <code>anova</code> function).
</p>


<h3>Author(s)</h3>

<p>Michael Hoehle &lt;hoehle@math.su.se&gt;
</p>


<h3>References</h3>

<p>Breslow, N. E., N. E. Day (1980) The Analysis of Case-Control Studies <em>Statistical Methods in Cancer Research: Vol. 1</em>. Lyon, France, IARC Scientific Publications.
</p>
<p>Tarone, R.E. (1985) On heterogeneity tests based on efficient scores, <em>Biometrika</em>, 72, pp. 91-95.
</p>
<p>Jones, M. P., O'Gorman, T. W., Lemka, J. H., and Woolson, R. F. (1989) A Monte Carlo Investigation of Homogeneity Tests of the Odds Ratio Under Various Sample Size Configurations <em>Biometrics</em>, 45, 171-181
<br />
</p>
<p>Breslow, N. E. (1996) Statistics in Epidemiology: The Case-Control Study <em>Journal of the American Statistical Association</em>, 91, 14-26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WoolfTest">WoolfTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>migraine &lt;- xtabs(freq ~ .,
            cbind(expand.grid(treatment=c("active", "placebo"),
                              response =c("better", "same"),
                              gender   =c("female", "male")),
                  freq=c(16, 5, 11, 20, 12, 7, 16, 19))
            )

# get rid of gender
tab &lt;- xtabs(Freq ~ treatment + response, migraine)
Desc(tab)

# only the women
female &lt;- migraine[,, 1]
Desc(female)

# .. and the men
male &lt;- migraine[,, 2]
Desc(male)

BreslowDayTest(migraine)
BreslowDayTest(migraine, correct = TRUE)


salary &lt;- array(
      c(38, 12, 102, 141, 12, 9, 136, 383),
      dim=c(2, 2, 2),
      dimnames=list(exposure=c("exposed", "not"),
                    disease =c("case", "control"),
                    salary  =c("&lt;1000", "&gt;=1000"))
                    )

# common odds ratio = 4.028269
BreslowDayTest(salary, OR = 4.02)
</code></pre>

<hr>
<h2 id='BreuschGodfreyTest'>Breusch-Godfrey Test</h2><span id='topic+BreuschGodfreyTest'></span>

<h3>Description</h3>

<p><code>BreuschGodfreyTest</code> performs the Breusch-Godfrey test for higher-order
serial correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BreuschGodfreyTest(formula, order = 1, order.by = NULL, type = c("Chisq", "F"),
                   data = list(), fill = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BreuschGodfreyTest_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be tested
(or a fitted <code>"lm"</code> object).</p>
</td></tr>
<tr><td><code id="BreuschGodfreyTest_+3A_order">order</code></td>
<td>
<p>integer. maximal order of serial correlation to be tested.</p>
</td></tr>
<tr><td><code id="BreuschGodfreyTest_+3A_order.by">order.by</code></td>
<td>
<p>Either a vector <code>z</code> or a formula with a single explanatory
variable like <code>~ z</code>. The observations in the model
are ordered by the size of <code>z</code>. If set to <code>NULL</code> (the
default) the observations are assumed to be ordered (e.g., a
time series).</p>
</td></tr>
<tr><td><code id="BreuschGodfreyTest_+3A_type">type</code></td>
<td>
<p>the type of test statistic to be returned. Either
<code>"Chisq"</code> for the Chi-squared test statistic or
<code>"F"</code> for the F test statistic.</p>
</td></tr>
<tr><td><code id="BreuschGodfreyTest_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model. By default the variables are taken from the environment
which <code>BreuschGodfreyTest</code> is called from.</p>
</td></tr>
<tr><td><code id="BreuschGodfreyTest_+3A_fill">fill</code></td>
<td>
<p>starting values for the lagged residuals in the auxiliary
regression. By default <code>0</code> but can also be set to <code>NA</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Under <code class="reqn">H_0</code> the test statistic is asymptotically Chi-squared with
degrees of freedom as given in <code>parameter</code>.
If <code>type</code> is set to <code>"F"</code> the function returns
a finite sample version of the test statistic, employing an <code class="reqn">F</code>
distribution with degrees of freedom as given in <code>parameter</code>.
</p>
<p>By default, the starting values for the lagged residuals in the auxiliary
regression are chosen to be 0 (as in Godfrey 1978) but could also be
set to <code>NA</code> to omit them.
</p>
<p><code>BreuschGodfreyTest</code> also returns the coefficients and estimated covariance
matrix from the auxiliary regression that includes the lagged residuals.
Hence, <code>CoefTest</code> (package: RegClassTools) can be used to inspect the results. (Note,
however, that standard theory does not always apply to the standard errors
and t-statistics in this regression.)
</p>


<h3>Value</h3>

<p>A list with class <code>"BreuschGodfreyTest"</code> inheriting from <code>"htest"</code> containing the
following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>degrees of freedom.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of test was
performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>coefficient estimates from the auxiliary regression.</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>corresponding covariance matrix estimate.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> This function was previously published as <code>bgtest</code> in the  <span class="pkg">lmtest</span> package and has been integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>David Mitchell &lt;david.mitchell@dotars.gov.au&gt;, Achim Zeileis</p>


<h3>References</h3>

<p>Johnston, J. (1984): <em>Econometric Methods</em>, Third Edition, McGraw Hill
Inc.
</p>
<p>Godfrey, L.G. (1978): 'Testing Against General Autoregressive and
Moving Average Error Models when the Regressors Include Lagged
Dependent Variables', <em>Econometrica</em>, 46, 1293-1302.
</p>
<p>Breusch, T.S. (1979): 'Testing for Autocorrelation in Dynamic Linear
Models', <em>Australian Economic Papers</em>, 17, 334-355.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DurbinWatsonTest">DurbinWatsonTest</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate a stationary and an AR(1) series
x &lt;- rep(c(1, -1), 50)

y1 &lt;- 1 + x + rnorm(100)

## Perform Breusch-Godfrey test for first-order serial correlation:
BreuschGodfreyTest(y1 ~ x)

## or for fourth-order serial correlation
BreuschGodfreyTest(y1 ~ x, order = 4)

## Compare with Durbin-Watson test results:
DurbinWatsonTest(y1 ~ x)

y2 &lt;- stats::filter(y1, 0.5, method = "recursive")
BreuschGodfreyTest(y2 ~ x)
</code></pre>

<hr>
<h2 id='BrierScore'>Brier Score for Assessing Prediction Accuracy
</h2><span id='topic+BrierScore'></span><span id='topic+BrierScore.glm'></span><span id='topic+BrierScore.default'></span>

<h3>Description</h3>

<p>Calculate Brier score for assessing the quality of the probabilistic predictions of binary events.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BrierScore(...)

## S3 method for class 'glm'
BrierScore(x, scaled = FALSE, ...)

## Default S3 method:
BrierScore(resp, pred, scaled = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BrierScore_+3A_x">x</code></td>
<td>
<p>a glm object
</p>
</td></tr>
<tr><td><code id="BrierScore_+3A_resp">resp</code></td>
<td>
<p>the response variable
</p>
</td></tr>
<tr><td><code id="BrierScore_+3A_pred">pred</code></td>
<td>
<p>the predicted values
</p>
</td></tr>
<tr><td><code id="BrierScore_+3A_scaled">scaled</code></td>
<td>
<p>logical, defining if scaled or not. Default is FALSE.
</p>
</td></tr>
<tr><td><code id="BrierScore_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to other functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Brier score is a proper score function that measures the accuracy of probabilistic predictions. It is applicable to tasks in which predictions must assign probabilities to a set of mutually exclusive discrete outcomes. The set of possible outcomes can be either binary or categorical in nature, and the probabilities assigned to this set of outcomes must sum to one (where each individual probability is in the range of 0 to 1).
</p>
<p>It's calculated as
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \cdot \sum_{i=1}^{n}\left ( p_{i}-o_{i} \right )^2  \; \; \; \textup{where} \;
p_{i} predicted probability \; \textup{and} \; o_{i} observed value out of (0,1)</code>
</p>

<p>The lower the Brier score is for a set of predictions, the better the predictions are calibrated. Note that the Brier score, in its most common formulation, takes on a value between zero and one, since this is the largest possible difference between a predicted probability (which must be between zero and one) and the actual outcome (which can take on values of only 0 and 1).
(In the original (1950) formulation of the Brier score, the range is double, from zero to two.)
</p>


<h3>Value</h3>

<p>a numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Brier, G. W. (1950) Verification of forecasts expressed in terms of probability. <em>Monthly Weather Review, 78</em>, 1-3.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Conf">Conf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r.glm &lt;- glm(Survived ~ ., data=Untable(Titanic), family=binomial)

BrierScore(r.glm)
</code></pre>

<hr>
<h2 id='BubbleLegend'> Add a Legend to a Bubble Plot
</h2><span id='topic+BubbleLegend'></span>

<h3>Description</h3>

<p>Add a legend for bubbles to a bubble plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BubbleLegend(x, y = NULL, area, cols, labels = NULL, cols.lbl = "black",
             width = NULL, xjust = 0, yjust = 1, inset = 0, border = "black",
             frame = TRUE, adj = c(0.5, 0.5), cex = 1, cex.names = 1,
             bg = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BubbleLegend_+3A_x">x</code></td>
<td>
<p>the left x-coordinate to be used to position the legend. See 'Details'. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_y">y</code></td>
<td>
<p>the top y-coordinate to be used to position the legend. See 'Details'. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_area">area</code></td>
<td>
<p>the area(s) for the bubbles in bubble legend.</p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_cols">cols</code></td>
<td>
<p>the color appearing in the legend.</p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_labels">labels</code></td>
<td>
<p>a vector of labels to be placed at the right side of the legend.</p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_cols.lbl">cols.lbl</code></td>
<td>
<p>the textcolor for the labels of the bubbles.</p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_width">width</code></td>
<td>
<p>the width of the legend.</p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_xjust">xjust</code></td>
<td>
<p>how the legend is to be justified relative to the legend x location.
A value of 0 means left justified, 0.5 means centered and 1 means right justified. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_yjust">yjust</code></td>
<td>
<p>the same as <code>xjust</code> for the legend y location. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_inset">inset</code></td>
<td>
<p>inset distance(s) from the margins as a fraction of the plot region when legend is placed by keyword. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_border">border</code></td>
<td>
<p>defines the bordor color of each rectangle. Default is none (<code>NA</code>).</p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_frame">frame</code></td>
<td>
<p>defines the bordor color of the frame around the whole legend. Default is none (<code>NA</code>). </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_adj">adj</code></td>
<td>
<p>text alignment, horizontal and vertical. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_cex">cex</code></td>
<td>
<p>extension factor for the area, default 1.0. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_cex.names">cex.names</code></td>
<td>
<p>character extension for the labels, default 1.0. </p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_bg">bg</code></td>
<td>
<p>the background color for the bubble legend.</p>
</td></tr>
<tr><td><code id="BubbleLegend_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code>text</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The labels are placed in the middle of the legend.
<br /><br />
The location of the legend may be specified by setting x to a single keyword from the list <code>"bottomright"</code>, <code>"bottom"</code>, <code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, <code>"topright"</code>, <code>"right"</code> and <code>"center"</code>. This places the legend on the inside of the plot frame at the given location. Partial argument matching is used. The optional inset argument specifies how far the legend is inset from the plot margins. If a single value is given, it is used for both margins; if two values are given, the first is used for x- distance, the second for y-distance. This is the same behaviour as it's implemented in <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+legend">legend</a></code>, <code><a href="#topic+FindColor">FindColor</a></code>, <code><a href="graphics.html#topic+legend">legend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotBubble(x=d.pizza$delivery_min, y=d.pizza$temperature, area=d.pizza$price,
           xlab="delivery time", ylab="temperature",
           col=SetAlpha(as.numeric(d.pizza$area)+2, .5), border="darkgrey",
           na.rm=TRUE, main="Price-Bubbles", panel.first=grid())

BubbleLegend("bottomleft", area=c(1500, 1000, 500), frame=TRUE,
             cols=SetAlpha("steelblue",0.5), bg="green",
             labels=c(1500, 1000, 500), cex=0.8,
             cols.lbl=c("yellow", "red","blue"))
</code></pre>

<hr>
<h2 id='Canvas'>Canvas for Geometric Plotting
</h2><span id='topic+Canvas'></span>

<h3>Description</h3>

<p>This is just a wrapper for creating an empty plot with suitable defaults for plotting geometric shapes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Canvas(xlim = NULL, ylim = xlim, main = NULL, xpd = par("xpd"),
       mar=c(5.1,5.1,5.1,5.1), asp = 1, bg = par("bg"), usrbg = "white", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Canvas_+3A_xlim">xlim</code>, <code id="Canvas_+3A_ylim">ylim</code></td>
<td>
<p>the xlims and ylims for the plot. Default is c(-1, 1).
</p>
</td></tr>
<tr><td><code id="Canvas_+3A_xpd">xpd</code></td>
<td>
<p>expand drawing area, defaults to <code>par("xpd")</code>.
</p>
</td></tr>
<tr><td><code id="Canvas_+3A_main">main</code></td>
<td>
<p>the main title on top of the plot.
</p>
</td></tr>
<tr><td><code id="Canvas_+3A_mar">mar</code></td>
<td>
<p>set margins. Defaults to c(5.1,5.1,5.1,5.1).
</p>
</td></tr>
<tr><td><code id="Canvas_+3A_asp">asp</code></td>
<td>
<p>numeric, giving the aspect ratio y/x. (See <code><a href="graphics.html#topic+plot.window">plot.window</a></code> for details. Default is 1.
</p>
</td></tr>
<tr><td><code id="Canvas_+3A_bg">bg</code></td>
<td>
<p>the background color of the plot, defaults to par(&quot;bg&quot;), which usually will be &quot;white&quot;.
</p>
</td></tr>
<tr><td><code id="Canvas_+3A_usrbg">usrbg</code></td>
<td>
<p>the color of the user space of the plot, defaults to &quot;white&quot;.
</p>
</td></tr>
<tr><td><code id="Canvas_+3A_...">...</code></td>
<td>
<p>additional arguments are passed to the <code>plot()</code> command.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot is created with these settings:<br />
<code>asp = 1, xaxt = "n", yaxt = "n", xlab = "", ylab = "", frame.plot = FALSE</code>.
</p>


<h3>Value</h3>

<p>a list of all the previous values of the parameters changed (returned invisibly)
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Canvas(7)
text(0, 0, "Hello world!", cex=5)
</code></pre>

<hr>
<h2 id='CartToPol'>Transform Cartesian to Polar/Spherical Coordinates and Vice Versa
</h2><span id='topic+CartToPol'></span><span id='topic+PolToCart'></span><span id='topic+CartToSph'></span><span id='topic+SphToCart'></span>

<h3>Description</h3>

<p>Transform cartesian into polar coordinates, resp. to spherical coordinates and vice versa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CartToPol(x, y)
PolToCart(r, theta)

CartToSph(x, y, z, up = TRUE)
SphToCart(r, theta, phi, up = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CartToPol_+3A_x">x</code>, <code id="CartToPol_+3A_y">y</code>, <code id="CartToPol_+3A_z">z</code></td>
<td>
<p>vectors with the xy-coordianates to be transformed.
</p>
</td></tr>
<tr><td><code id="CartToPol_+3A_r">r</code></td>
<td>
<p>a vector with the radius of the points.
</p>
</td></tr>
<tr><td><code id="CartToPol_+3A_theta">theta</code></td>
<td>
<p>a vector with the angle(s) of the points.
</p>
</td></tr>
<tr><td><code id="CartToPol_+3A_phi">phi</code></td>
<td>
<p>a vector with the angle(s) of the points.
</p>
</td></tr>
<tr><td><code id="CartToPol_+3A_up">up</code></td>
<td>
<p>logical. If set to <code>TRUE</code> (default) theta is measured from x-y plane, else theta is measured from the z-axis.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Angles are in radians, not degrees (i.e., a right angle is pi/2). Use <code><a href="#topic+DegToRad">DegToRad</a></code> to convert,
if you don't wanna do it by yourself.<br />
All parameters are recycled if necessary.
</p>


<h3>Value</h3>

<p>PolToCart returns a list of x and y coordinates of the points.<br />
CartToPol returns a list of r for the radius and theta for the angles of the given points.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, Christian W. Hoffmann &lt;christian@echoffmann.ch&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CartToPol(x=1, y=1)
CartToPol(x=c(1,2,3), y=c(1,1,1))
CartToPol(x=c(1,2,3), y=1)


PolToCart(r=1, theta=pi/2)
PolToCart(r=c(1,2,3), theta=pi/2)

CartToSph(x=1, y=2, z=3)   # r=3.741657, theta=0.930274, phi=1.107149
</code></pre>

<hr>
<h2 id='CatTable'>
Function to write a table
</h2><span id='topic+CatTable'></span>

<h3>Description</h3>

<p>CatTable helps printing a table, if is has to be broken into multiple rows. Rowlabels will be
repeated after every new break.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CatTable(tab, wcol, nrepchars, width = getOption("width"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CatTable_+3A_tab">tab</code></td>
<td>
<p>the rows of a table to be printed, pasted together in one string with constant columnwidth.
</p>
</td></tr>
<tr><td><code id="CatTable_+3A_wcol">wcol</code></td>
<td>
<p>integer, the width of the columns. All columns must have the same width.
</p>
</td></tr>
<tr><td><code id="CatTable_+3A_nrepchars">nrepchars</code></td>
<td>
<p>integer, the number of characters to be repeated with every break. This 
is typically the maximum width of the rowlabels.
</p>
</td></tr>
<tr><td><code id="CatTable_+3A_width">width</code></td>
<td>
<p>integer, the width of the whole table. Default is the width of the current command window 
(<code>getOption("width")</code>).
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+table">table</a></code>, <code><a href="base.html#topic+paste">paste</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(scipen=8)

# used in bivariate description functions
Desc(temperature ~ cut(delivery_min, breaks=40), data=d.pizza)


txt &lt;- c( 
   paste(sample(letters, 500, replace=TRUE), collapse="")
 , paste(sample(letters, 500, replace=TRUE), collapse="")
 , paste(sample(letters, 500, replace=TRUE), collapse="")
)
txt &lt;- paste(c("aaa","bbb","ccc"), txt, sep="")

CatTable(txt, nrepchars=3, wcol=5)
</code></pre>

<hr>
<h2 id='CCC'>
Concordance Correlation Coefficient
</h2><span id='topic+CCC'></span>

<h3>Description</h3>

<p>Calculates Lin's concordance correlation coefficient for agreement on a continuous measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CCC(x, y, ci = "z-transform", conf.level = 0.95, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CCC_+3A_x">x</code></td>
<td>
<p>a vector, representing the first set of measurements.</p>
</td></tr>
<tr><td><code id="CCC_+3A_y">y</code></td>
<td>
<p>a vector, representing the second set of measurements.</p>
</td></tr>
<tr><td><code id="CCC_+3A_ci">ci</code></td>
<td>
<p>a character string, indicating the method to be used. Options are <code>z-transform</code> or <code>asymptotic</code>.</p>
</td></tr>
<tr><td><code id="CCC_+3A_conf.level">conf.level</code></td>
<td>
<p>magnitude of the returned confidence interval. Must be a single number between 0 and 1.</p>
</td></tr>
<tr><td><code id="CCC_+3A_na.rm">na.rm</code></td>
<td>

<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. If set to <code>TRUE</code> only the complete cases of the ratings will be used. Defaults to <code>FALSE</code>.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes Lin's (1989, 2000) concordance correlation coefficient for agreement on a continuous measure obtained by two methods. The concordance correlation coefficient combines measures of both precision and accuracy to determine how far the observed data deviate from the line of perfect concordance (that is, the line at 45 degrees on a square scatter plot). Lin's coefficient increases in value as a function of the nearness of the data's reduced major axis to the line of perfect concordance (the accuracy of the data) and of the tightness of the data about its reduced major axis (the precision of the data).
</p>
<p>Both <code>x</code> and <code>y</code> values need to be present for a measurement pair to be included in the analysis. If either or both values are missing (i.e. coded <code>NA</code>) then the measurement pair is deleted before analysis.
</p>


<h3>Value</h3>

<p>A list containing the following:
</p>
<table>
<tr><td><code>rho.c</code></td>
<td>
<p>the concordance correlation coefficient.</p>
</td></tr>
<tr><td><code>s.shift</code></td>
<td>
<p>the scale shift.</p>
</td></tr>
<tr><td><code>l.shift</code></td>
<td>
<p>the location shift.</p>
</td></tr>
<tr><td><code>C.b</code></td>
<td>
<p>a bias correction factor that measures how far the best-fit line deviates from a line at 45 degrees. No deviation from the 45 degree line occurs when C.b = 1. See Lin (1989, page 258).</p>
</td></tr>
<tr><td><code>blalt</code></td>
<td>
<p>a data frame with two columns: <code>mean</code> the mean of each pair of measurements, <code>delta</code> vector <code>y</code> minus vector <code>x</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mark Stevenson &lt;mark.stevenson1@unimelb.edu.au&gt;</p>


<h3>References</h3>

<p>Bland J, Altman D (1986). Statistical methods for assessing agreement between two methods of clinical measurement. <em>The Lancet</em> 327: 307 - 310.
</p>
<p>Bradley E, Blackwood L (1989). Comparing paired data: a simultaneous test for means and variances. <em>American Statistician</em> 43: 234 - 235.
</p>
<p>Dunn G (2004). <em>Statistical Evaluation of Measurement Errors: Design and Analysis of Reliability Studies</em>. London: Arnold.
</p>
<p>Hsu C (1940). On samples from a normal bivariate population. <em>Annals of Mathematical Statistics</em> 11: 410 - 426.
</p>
<p>Krippendorff K (1970). Bivariate agreement coefficients for reliability of data. In: Borgatta E, Bohrnstedt G (eds)
<em>Sociological Methodology</em>. San Francisco: Jossey-Bass, pp. 139 - 150.
</p>
<p>Lin L (1989). A concordance correlation coefficient to evaluate reproducibility. <em>Biometrics</em> 45: 255 - 268.
</p>
<p>Lin L (2000). A note on the concordance correlation coefficient. <em>Biometrics</em> 56: 324 - 325.
</p>
<p>Pitman E (1939). A note on normal correlation. <em>Biometrika</em> 31: 9 - 12.
</p>
<p>Reynolds M, Gregoire T (1991). Comment on Bradley and Blackwood. <em>American Statistician</em> 45: 163 - 164.
</p>
<p>Snedecor G, Cochran W (1989). <em>Statistical Methods</em>. Ames: Iowa State University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ICC">ICC</a></code>, <code><a href="#topic+KendallW">KendallW</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Concordance correlation plot:
set.seed(seed = 1234)
method1 &lt;- rnorm(n = 100, mean = 0, sd = 1)
method2 &lt;- method1 + runif(n = 100, min = 0, max = 1)

## Introduce some missing values:
method1[50] &lt;- NA
method2[75] &lt;- NA

tmp.ccc &lt;- CCC(method1, method2, ci = "z-transform",
   conf.level = 0.95)

lab &lt;- paste("CCC: ", round(tmp.ccc$rho.c[,1], digits = 2), " (95% CI ", 
   round(tmp.ccc$rho.c[,2], digits = 2), " - ",
   round(tmp.ccc$rho.c[,3], digits = 2), ")", sep = "")
z &lt;- lm(method2 ~ method1)

par(pty = "s")
plot(method1, method2, xlim = c(0, 5), ylim = c(0,5), xlab = "Method 1", 
   ylab = "Method 2", pch = 16)
abline(a = 0, b = 1, lty = 2)
abline(z, lty = 1)
legend(x = "topleft", legend = c("Line of perfect concordance", 
   "Reduced major axis"), lty = c(2,1), lwd = c(1,1), bty = "n")
text(x = 1.55, y = 3.8, labels = lab)

## Bland and Altman plot (Figure 2 from Bland and Altman 1986):
x &lt;- c(494,395,516,434,476,557,413,442,650,433,417,656,267,
   478,178,423,427)

y &lt;- c(512,430,520,428,500,600,364,380,658,445,432,626,260,
   477,259,350,451)

tmp.ccc &lt;- CCC(x, y, ci = "z-transform", conf.level = 0.95)
tmp.mean &lt;- mean(tmp.ccc$blalt$delta)
tmp.sd &lt;- sqrt(var(tmp.ccc$blalt$delta))

plot(tmp.ccc$blalt$mean, tmp.ccc$blalt$delta, pch = 16, 
   xlab = "Average PEFR by two meters (L/min)", 
   ylab = "Difference in PEFR (L/min)", xlim = c(0,800), 
   ylim = c(-140,140)) 
abline(h = tmp.mean, lty = 1, col = "gray")
abline(h = tmp.mean - (2 * tmp.sd), lty = 2, col = "gray")
abline(h = tmp.mean + (2 * tmp.sd), lty = 2, col = "gray")
legend(x = "topleft", legend = c("Mean difference", 
   "Mean difference +/ 2SD"), lty = c(1,2), bty = "n")
legend(x = 0, y = 125, legend = c("Difference"), pch = 16, 
    bty = "n")
</code></pre>

<hr>
<h2 id='Clockwise'>Calculates Begin and End Angle From a List of Given Angles in Clockwise Mode
</h2><span id='topic+Clockwise'></span>

<h3>Description</h3>

<p>Transforms given angles in counter clock mode into clockwise angles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Clockwise(x, start = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Clockwise_+3A_x">x</code></td>
<td>
<p>a vector of angles
</p>
</td></tr>
<tr><td><code id="Clockwise_+3A_start">start</code></td>
<td>
<p>the starting angle for the transformation. Defaults to 0.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sometimes there's need for angles being defined the other way round. 
</p>


<h3>Value</h3>

<p>a data.frame with two columns, containing the start and end angles.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotPolar">PlotPolar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Clockwise( c(0, pi/4, pi/2, pi))
</code></pre>

<hr>
<h2 id='Closest'>Find the Closest Value 
</h2><span id='topic+Closest'></span>

<h3>Description</h3>

<p>Find the closest value(s) of a number in a vector x. Multiple values will be reported, if the differences are the same.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Closest(x, a, which = FALSE, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Closest_+3A_x">x</code></td>
<td>
<p>the vector to be searched in
</p>
</td></tr>
<tr><td><code id="Closest_+3A_a">a</code></td>
<td>
<p>the reference value
</p>
</td></tr>
<tr><td><code id="Closest_+3A_which">which</code></td>
<td>
<p>a logical value defining if the index position or the value should be returned. By default will the value be returned.</p>
</td></tr>
<tr><td><code id="Closest_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the value or index in x which is closest to a
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+which">which</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8)
x &lt;- sample(10, size=10, replace=TRUE)

Closest(x, 6)
Closest(x, 6, which=TRUE)


Closest(c(2, 3, 4, 5), 3.5)


</code></pre>

<hr>
<h2 id='Coalesce'>Return the First Element Not Being NA
</h2><span id='topic+Coalesce'></span>

<h3>Description</h3>

<p>Return the first element of a vector, not being NA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coalesce(..., method = c("is.na", "is.null", "is.finite"), flatten = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coalesce_+3A_...">...</code></td>
<td>
<p>the elements to be evaluated. This can either be a single vector, several
vectors of same length, a matrix, a data.frame or a list of vectors (of same length). See examples.</p>
</td></tr>
<tr><td><code id="Coalesce_+3A_method">method</code></td>
<td>
<p>one out of <code>"is.na"</code> (default), <code>"is.null"</code>  or <code>"is.finite"</code>. The <code>"is.na"</code> option allows <code>Inf</code> values to
be in the result, the second one eliminates them.
</p>
</td></tr>
<tr><td><code id="Coalesce_+3A_flatten">flatten</code></td>
<td>
<p>logical, defines whether lists are going to be flattened (default <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If several vectors are supplied, the evaluation will be elementwise, resp. rowwise if x is a data.frame or a matrix. The first element of the result
is the first non <code>NA</code> element of the first elements of all the arguments, the second element of
the result is the one of the second elements of all the arguments and so on. <br />
Shorter inputs (of non-zero length) are NOT recycled. The function will bark, if multiple vectors do not all have the same dimension.<br />
The idea is borrowed from SQL. Might sometimes be useful when preparing data in R instead of in SQL.
</p>


<h3>Value</h3>

<p>return a single vector of the first non <code>NA</code> element(s) of the given data structure.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+is.na">is.na</a></code>, <code><a href="base.html#topic+is.finite">is.finite</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Coalesce(c(NA, NA, NA, 5, 3))
Coalesce(c(NA, NULL, "a"))
Coalesce(NULL, 5, 3)

d.frm &lt;- data.frame(matrix(c(
  1, 2, NA, 4,
  NA, NA, 3, 1,
  NaN, 2, 3, 1,
  NA, Inf, 1, 1), nrow=4, byrow=TRUE)
)

Coalesce(d.frm)
Coalesce(as.matrix(d.frm))
Coalesce(d.frm$X1, d.frm$X2, d.frm$X3, d.frm$X4)
Coalesce(d.frm$X1, d.frm$X2, d.frm$X3, d.frm$X4, method="is.finite")
Coalesce(list(d.frm[,1], d.frm[,2]))

# returns the first finite element
Coalesce(d.frm, method="is.finite")

# with characters (take care, factors won't work!)
# is.finite does not make sense here...
d.frm &lt;- data.frame(matrix(c(
  "a", "b", NA, "4",
  NA, NA, "g", "m",
  NA_character_,"hfdg", "rr", "m",
  NA, Inf, 1, 1), nrow=4, byrow=TRUE)
, stringsAsFactors = FALSE)

Coalesce(d.frm$X1, d.frm$X2, d.frm$X3, d.frm$X4)
Coalesce(d.frm)
Coalesce(as.list(d.frm))
</code></pre>

<hr>
<h2 id='CochranArmitageTest'>Cochran-Armitage Test for Trend
</h2><span id='topic+CochranArmitageTest'></span>

<h3>Description</h3>

<p>Perform a Cochran Armitage test for trend in binomial proportions across the levels of a single variable. This test is appropriate only when one variable has two levels and the other variable is ordinal. The two-level variable represents the response, and the other represents an explanatory variable with ordered levels.
The null hypothesis is the hypothesis of no trend, which means that the binomial proportion is the same for all levels of the explanatory variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CochranArmitageTest(x, alternative = c("two.sided", "one.sided"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CochranArmitageTest_+3A_x">x</code></td>
<td>
<p>a frequency table or a matrix.
</p>
</td></tr>
<tr><td><code id="CochranArmitageTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of <code>"two.sided"</code> (default), <code>"one.sided"</code>. You can specify just the initial letter.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p> the z-statistic of the test.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p> the dimension of the table.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>   the p-value for the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Cochran-Armitage test for trend&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; strongly based on code from
Eric Lecoutre &lt;lecoutre@stat.ucl.ac.be&gt;<br />
<a href="https://stat.ethz.ch/pipermail/r-help/2005-July/076371.html">https://stat.ethz.ch/pipermail/r-help/2005-July/076371.html</a>
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+prop.trend.test">prop.trend.test</a></code>
</p>
<p><a href="https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/procstat/procstat_freq_details76.htm">https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/procstat/procstat_freq_details76.htm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># http://www.lexjansen.com/pharmasug/2007/sp/sp05.pdf, pp. 4
dose &lt;- matrix(c(10,9,10,7, 0,1,0,3), byrow=TRUE, nrow=2, dimnames=list(resp=0:1, dose=0:3))
Desc(dose)

CochranArmitageTest(dose)
CochranArmitageTest(dose, alternative="one.sided")


# not exactly the same as in package coin:
# independence_test(tumor ~ dose, data = lungtumor, teststat = "quad")
lungtumor &lt;- data.frame(dose = rep(c(0, 1, 2), c(40, 50, 48)),
                        tumor = c(rep(c(0, 1), c(38, 2)),
                                  rep(c(0, 1), c(43, 7)),
                                  rep(c(0, 1), c(33, 15))))
tab &lt;- table(lungtumor$dose, lungtumor$tumor)
CochranArmitageTest(tab)

# but similar to
prop.trend.test(tab[,1], apply(tab,1, sum))
</code></pre>

<hr>
<h2 id='CochranQTest'>
Cochran's Q test
</h2><span id='topic+CochranQTest'></span><span id='topic+CochranQTest.default'></span><span id='topic+CochranQTest.formula'></span>

<h3>Description</h3>

<p>Perform the Cochran's Q test for unreplicated randomized block design experiments with a 
binary response variable and paired data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CochranQTest(y, ...)

## Default S3 method:
CochranQTest(y, groups, blocks, ...)

## S3 method for class 'formula'
CochranQTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CochranQTest_+3A_y">y</code></td>
<td>

<p>either a numeric vector of data values, or a data matrix.
</p>
</td></tr>
<tr><td><code id="CochranQTest_+3A_groups">groups</code></td>
<td>

<p>a vector giving the group for the corresponding elements of y if this is a vector; ignored if y is a matrix. If not a factor object, it is coerced to one.
</p>
</td></tr>
<tr><td><code id="CochranQTest_+3A_blocks">blocks</code></td>
<td>

<p>a vector giving the block for the corresponding elements of y if this is a vector; ignored if y is a matrix. If not a factor object, it is coerced to one.</p>
</td></tr>
<tr><td><code id="CochranQTest_+3A_formula">formula</code></td>
<td>

<p>a formula of the form <code>y ~ groups | blocks</code>.</p>
</td></tr>
<tr><td><code id="CochranQTest_+3A_data">data</code></td>
<td>

<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula. By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="CochranQTest_+3A_subset">subset</code></td>
<td>

<p>an optional vector specifying a subset of observations to be used.
</p>
</td></tr>
<tr><td><code id="CochranQTest_+3A_na.action">na.action</code></td>
<td>

<p>a function which indicates what should happen when the data contain <code>NA</code>s. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="CochranQTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>CochranQTest()</code> can be used for analyzing unreplicated complete block designs (i.e., there is exactly one 
binary observation in y for each combination of levels of groups and blocks) where the normality assumption may be violated.
</p>
<p>The null hypothesis is that apart from an effect of blocks, the location parameter of y is the same in each of the groups.
</p>
<p>If y is a matrix, groups and blocks are obtained from the column and row indices, respectively. 
<code>NA</code>'s are not allowed in groups or blocks; if y contains <code>NA</code>'s, corresponding blocks are removed.
</p>
<p>Note that Cochran's Q Test is analogue to the Friedman test with 0, 1 coded response. This is used here for a simple implementation.
</p>


<h3>Value</h3>

<p>A list with class <code>htest</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of Cochran's chi-squared statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom of the approximate chi-squared distribution of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &quot;Cochran's Q-Test&quot;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Cochran, W.G. (1950) The Comparison of Percentages in Matched Samples. <em>Biometrika</em>. 37 (3/4): 256-266. doi:10.1093/biomet/37.3-4.256. JSTOR 2332378.</p>


<h3>Examples</h3>

<pre><code class='language-R'># example in: 
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. S. 1824

# use expand.grid, xtabs and Untable to create the dataset
d.frm &lt;- Untable(xtabs(c(6,2,2,6,16,4,4,6) ~ ., 
    expand.grid(rep(list(c("F","U")), times=3))), 
    colnames = LETTERS[1:3])

# rearrange to long shape    
d.long &lt;- reshape(d.frm, varying=1:3, times=names(d.frm)[c(1:3)], 
                  v.names="resp", direction="long")


# after having done the hard work of data organisation, performing the test is a piece of cake....
CochranQTest(resp ~ time | id, data=d.long)

# and let's perform a post hoc analysis using mcnemar's test
z &lt;- split(d.long, f=d.long$time)
pairwise.table(function(i, j) { 
    mcnemar.test(z[[i]]$resp, z[[j]]$resp, correct=FALSE)$p.value
  }, 
  level.names = names(z), 
  p.adjust.method = "fdr"
)
</code></pre>

<hr>
<h2 id='CoefVar'>Coefficient of Variation
</h2><span id='topic+CoefVar'></span><span id='topic+CoefVar.lm'></span><span id='topic+CoefVar.aov'></span><span id='topic+CoefVar.default'></span><span id='topic+CoefVarCI'></span>

<h3>Description</h3>

<p>Calculates the coefficient of variation and its confidence limits using various methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoefVar(x, ...)

## S3 method for class 'lm'
CoefVar(x, unbiased = FALSE, na.rm = FALSE, ...)

## S3 method for class 'aov'
CoefVar(x, unbiased = FALSE, na.rm = FALSE, ...)

## Default S3 method:
CoefVar(x, weights = NULL, unbiased = FALSE,
       na.rm = FALSE, ...)

CoefVarCI(K, n, conf.level = 0.95, 
          sides = c("two.sided", "left", "right"),
          method = c("nct","vangel","mckay","verrill","naive"))       

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoefVar_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_unbiased">unbiased</code></td>
<td>
<p>logical value determining, if a bias correction should be used (see. details). Default is FALSE. 
</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_k">K</code></td>
<td>
<p>the coefficient of variation as calculated by <code>CoefVar()</code>.
</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_n">n</code></td>
<td>
<p>the number of observations used for calculating the coefficient of variation.</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. Defaults to 0.95.
</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default),
<code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of
<code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_method">method</code></td>
<td>
<p>character string specifing the method to use for calculating the confidence intervals, can be one out of:
<code>"nct"</code> (default), <code>"vangel"</code>, <code>"mckay"</code>, <code>"verrill"</code> (currently not yet implemented) and <code>"naive"</code>. Abbreviation of method is accepted. See details.</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to FALSE.
</p>
</td></tr>
<tr><td><code id="CoefVar_+3A_...">...</code></td>
<td>
<p>further arguments (not used here).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order for the coefficient of variation to be an unbiased estimate of the true population value,
the coefficient of variation  is corrected as:   </p>
<p style="text-align: center;"><code class="reqn"> CV_{korr} = CV \cdot \left( 1 - \frac{1}{4\cdot(n-1)} + \frac{1}{n} \cdot CV^2 + \frac{1}{2 \cdot (n-1)^2} \right) </code>
</p>

<p>For determining<code style="white-space: pre;">&#8288; &#8288;</code><b>the confidence intervals</b><code style="white-space: pre;">&#8288; &#8288;</code> for the coefficient of variation a number of methods have been proposed. <code>CoefVarCI()</code> currently supports five different methods.
The details for the methods are given in the specific references.
</p>
<p>The <b>&quot;naive&quot; method</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
is based on dividing the standard confidence limit for the standard deviation by the sample mean.
</p>
<p><b>McKay's</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
approximation is asymptotically exact as n goes to infinity. McKay recommends this approximation only if the coefficient of variation is less than 0.33. Note that if the coefficient of variation is greater than 0.33, either the normality of the data is suspect or the probability of negative values in the data is non-neglible. In this case, McKay's approximation may not be valid. Also, it is generally recommended that the sample size should be at least 10 before using McKay's approximation.
</p>
<p><b>Vangel's modified McKay method</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
is more accurate than the McKay in most cases, particilarly for small samples.. According to Vangel, the unmodified McKay is only more accurate when both the coefficient of variation and alpha are large. However, if the coefficient of variation is large, then this implies either that the data contains negative values or the data does not follow a normal distribution. In this case, neither the McKay or the modified McKay should be used.
In general, the Vangel's modified McKay method is recommended over the McKay method. It generally provides good approximations as long as the data is approximately normal and the coefficient of variation is less than 0.33. This is the default method.
</p>
<p>See also: https://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/coefvacl.htm
</p>
<p><b>nct</b>   <code style="white-space: pre;">&#8288;     &#8288;</code>uses the noncentral t-distribution to calculate the confidence intervals. See Smithson (2003).
</p>


<h3>Value</h3>

<p>if no confidence intervals are requested:
the estimate as numeric value (without any name)<br /><br />
else a named numeric vector with 3 elements
</p>
<table>
<tr><td><code>est</code></td>
<td>
<p>estimate</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, <br />
Michael Smithson &lt;michael.smithson@anu.edu.au&gt; (noncentral-t)
</p>


<h3>References</h3>

<p>McKay, A. T. (1932). Distribution of the coefficient of variation and the extended
<em>t</em> distribution, <em>Journal of the Royal Statistical Society</em>, <em>95</em>, 695&ndash;698.
</p>
<p>Johnson, B. L., Welch, B. L. (1940). Applications of the non-central t-distribution. <em>Biometrika</em>, 31, 362&ndash;389.
</p>
<p>Mark Vangel (1996) Confidence Intervals for a Normal Coefficient of Variation, <em>American Statistician</em>, Vol. 15, No. 1, pp. 21-26.
</p>
<p>Kelley, K. (2007). Sample size planning for the coefcient of variation from the accuracy in parameter estimation approach. <em>Behavior Research Methods, 39</em> (4), 755-766
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1-24
</p>
<p>Smithson, M.J. (2003) <em>Confidence Intervals, Quantitative Applications in the Social Sciences Series</em>, No. 140. Thousand Oaks, CA: Sage. pp. 39-41
</p>
<p>Steve Verrill (2003) Confidence Bounds for Normal and Lognormal Distribution Coefficients of Variation, <em>Research Paper 609</em>, USDA Forest Products Laboratory, Madison, Wisconsin.
</p>
<p>Verrill, S. and Johnson, R.A. (2007) Confidence Bounds and Hypothesis Tests for Normal Distribution Coefficients of Variation, <em>Communications in Statistics Theory and Methods</em>, Volume 36, No. 12, pp 2187-2206.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mean">Mean</a></code>, <code><a href="#topic+SD">SD</a></code>,   (both supporting weights)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(15)
x &lt;- runif(100)
CoefVar(x, conf.level=0.95)

#       est    low.ci    upr.ci
# 0.5092566 0.4351644 0.6151409

# Coefficient of variation for a linear model
r.lm &lt;- lm(Fertility ~ ., swiss)
CoefVar(r.lm)

# the function is vectorized, so arguments are recyled...
# https://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/coefvacl.htm
CoefVarCI(K = 0.00246, n = 195, method="vangel", 
          sides="two.sided", conf.level = c(.5,.8,.9,.95,.99,.999))
</code></pre>

<hr>
<h2 id='CohenD'>Cohen's Effect Size
</h2><span id='topic+CohenD'></span>

<h3>Description</h3>

<p>Computes the Cohen's d and Hedges'g effect size statistics. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CohenD(x, y = NULL, pooled = TRUE, correct = FALSE, conf.level = NA, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CohenD_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="CohenD_+3A_y">y</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="CohenD_+3A_pooled">pooled</code></td>
<td>
<p>logical, indicating whether compute pooled standard deviation or the whole sample standard deviation. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="CohenD_+3A_correct">correct</code></td>
<td>
<p>logical, indicating whether to apply the Hedges correction. (Default: FALSE)
</p>
</td></tr>
<tr><td><code id="CohenD_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. Set this to NA, if no confidence intervals should be calculated. (This is the default) 
</p>
</td></tr>
<tr><td><code id="CohenD_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to FALSE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector with 3 elements:
</p>
<table>
<tr><td><code>d</code></td>
<td>
<p>the effect size d</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, William Revelle  &lt;revelle@northwestern.edu&gt; (CI) 
</p>


<h3>References</h3>

<p>Cohen, J. (1988) <em>Statistical power analysis for the behavioral sciences (2nd ed.)</em> Academic Press, New York.
</p>
<p>Hedges, L. V. &amp; Olkin, I. (1985) <em>Statistical methods for meta-analysis</em> Academic Press, Orlando, FL 
</p>
<p>Smithson, M.J. (2003) <em>Confidence Intervals, Quantitative Applications in the Social Sciences Series</em>, No. 140. Thousand Oaks, CA: Sage. pp. 39-41
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>, <code><a href="stats.html#topic+var">var</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- d.pizza$price[d.pizza$driver=="Carter"]
y &lt;- d.pizza$price[d.pizza$driver=="Miller"]

CohenD(x, y, conf.level=0.95, na.rm=TRUE)

</code></pre>

<hr>
<h2 id='CohenKappa'>Cohen's Kappa and Weighted Kappa
</h2><span id='topic+CohenKappa'></span>

<h3>Description</h3>

<p>Computes the agreement rates Cohen's kappa and weighted kappa and their confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CohenKappa(x, y = NULL, weights = c("Unweighted", "Equal-Spacing", "Fleiss-Cohen"),
           conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CohenKappa_+3A_x">x</code></td>
<td>
<p>can either be a numeric vector or a confusion matrix. In the latter case x must be a square matrix.
</p>
</td></tr>
<tr><td><code id="CohenKappa_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If <code>y</code> is provided, <code>table(x, y, ...)</code> is calculated. In order to get a square matrix, <code>x</code> and <code>y</code> are
coerced to factors with synchronized levels. (Note, that the vector interface can not be used together with weights.)
</p>
</td></tr>
<tr><td><code id="CohenKappa_+3A_weights">weights</code></td>
<td>
<p>either one out of <code>"Unweighted"</code> (default), <code>"Equal-Spacing"</code>, <code>"Fleiss-Cohen"</code>, which will calculate the weights accordingly, or a user-specified matrix having the same dimensions as x containing the weights for each cell.
</p>
</td></tr>
<tr><td><code id="CohenKappa_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence intervals will be calculated.
</p>
</td></tr>
<tr><td><code id="CohenKappa_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set <code>useNA</code>. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cohen's kappa is the diagonal sum of the (possibly weighted) relative frequencies, corrected for expected values and standardized by its maximum value. <br />
The equal-spacing weights (see Cicchetti and Allison 1971) are defined by </p>
<p style="text-align: center;"><code class="reqn">1 - \frac{|i - j|}{r - 1}</code>
</p>

<p><code>r</code> being the number of columns/rows, and the Fleiss-Cohen weights by </p>
<p style="text-align: center;"><code class="reqn">1 - \frac{(i - j)^2}{(r - 1)^2}</code>
</p>

<p>The latter attaches greater importance to closer disagreements.<br />
<br />
Data can be passed to the function either as matrix or data.frame in <code>x</code>, or as two numeric vectors <code>x</code> and <code>y</code>. In the latter case <code>table(x, y, ...)</code> is calculated. Thus <code>NA</code>s are handled the same way as <code><a href="base.html#topic+table">table</a></code> does. Note that tables are by default calculated <b>without</b> NAs. The specific argument <code>useNA</code> can be passed via the ... argument.<br />
The vector interface <code>(x, y)</code> is only supported for the calculation of unweighted kappa. This is because we cannot ensure a safe construction of a confusion table for two factors with different levels, which is independent of the order of the levels in <code>x</code> and <code>y</code>. So weights might lead to inconsistent results. The function will raise an error in this case.
</p>


<h3>Value</h3>

<p>if no confidence intervals are requested:
the estimate as numeric value<br /><br />
else a named numeric vector with 3 elements
</p>
<table>
<tr><td><code>kappa</code></td>
<td>
<p>estimate</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David Meyer &lt;david.meyer@r-project.org&gt;, some changes and tweaks Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Cohen, J. (1960) A coefficient of agreement for nominal scales. <em>Educational and Psychological Measurement</em>, 20, 37-46.
</p>
<p>Everitt, B.S. (1968), Moments of statistics kappa and weighted kappa. <em>The British Journal of Mathematical and Statistical Psychology</em>, 21, 97-103.
</p>
<p>Fleiss, J.L., Cohen, J., and Everitt, B.S. (1969), Large sample standard errors of kappa and weighted kappa. <em>Psychological Bulletin</em>, 72, 332-327.
</p>
<p>Cicchetti, D.V., Allison, T. (1971) A New Procedure for Assessing Reliability
of Scoring EEG Sleep Recordings <em>American Journal of EEG Technology</em>, 11,
101-109.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CronbachAlpha">CronbachAlpha</a></code>, <code><a href="#topic+KappaM">KappaM</a></code>, <code><a href="#topic+KrippAlpha">KrippAlpha</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># from Bortz et. al (1990) Verteilungsfreie Methoden in der Biostatistik, Springer, pp. 459
m &lt;- matrix(c(53,  5, 2,
              11, 14, 5,
               1,  6, 3), nrow=3, byrow=TRUE,
            dimnames = list(rater1 = c("V","N","P"), rater2 = c("V","N","P")) )

# confusion matrix interface
CohenKappa(m, weight="Unweighted")

# vector interface
x &lt;- Untable(m)
CohenKappa(x$rater1, x$rater2, weight="Unweighted")

# pairwise Kappa
rating &lt;- data.frame(
  rtr1 = c(4,2,2,5,2, 1,3,1,1,5, 1,1,2,1,2, 3,1,1,2,1, 5,2,2,1,1, 2,1,2,1,5),
  rtr2 = c(4,2,3,5,2, 1,3,1,1,5, 4,2,2,4,2, 3,1,1,2,3, 5,4,2,1,4, 2,1,2,3,5),
  rtr3 = c(4,2,3,5,2, 3,3,3,4,5, 4,4,2,4,4, 3,1,1,4,3, 5,4,4,4,4, 2,1,4,3,5),
  rtr4 = c(4,5,3,5,4, 3,3,3,4,5, 4,4,3,4,4, 3,4,1,4,5, 5,4,5,4,4, 2,1,4,3,5),
  rtr5 = c(4,5,3,5,4, 3,5,3,4,5, 4,4,3,4,4, 3,5,1,4,5, 5,4,5,4,4, 2,5,4,3,5),
  rtr6 = c(4,5,5,5,4, 3,5,4,4,5, 4,4,3,4,5, 5,5,2,4,5, 5,4,5,4,5, 4,5,4,3,5)
)

PairApply(rating, FUN=CohenKappa, symmetric=TRUE)

# Weighted Kappa
cats &lt;- c("&lt;10%", "11-20%", "21-30%", "31-40%", "41-50%", "&gt;50%")
m &lt;- matrix(c(5,8,1,2,4,2, 3,5,3,5,5,0, 1,2,6,11,2,1,
              0,1,5,4,3,3, 0,0,1,2,5,2, 0,0,1,2,1,4), nrow=6, byrow=TRUE,
            dimnames = list(rater1 = cats, rater2 = cats) )
CohenKappa(m, weight="Equal-Spacing")


# supply an explicit weight matrix
ncol(m)
(wm &lt;- outer(1:ncol(m), 1:ncol(m), function(x, y) {
        1 - ((abs(x-y)) / (ncol(m)-1)) } ))
CohenKappa(m, weight=wm, conf.level=0.95)


# however, Fleiss, Cohen and Everitt weight similarities
fleiss &lt;- matrix(c(
  106, 10,  4,
  22,  28, 10,
   2,  12,  6
  ), ncol=3, byrow=TRUE)

#Fleiss weights the similarities
weights &lt;- matrix(c(
 1.0000, 0.0000, 0.4444,
 0.0000, 1.0000, 0.6666,
 0.4444, 0.6666, 1.0000
 ), ncol=3)

CohenKappa(fleiss, weights)
</code></pre>

<hr>
<h2 id='CollapseTable'>Collapse Levels of a Table</h2><span id='topic+CollapseTable'></span>

<h3>Description</h3>

<p>Collapse (or re-label) variables in a
a contingency table or <code>ftable</code> object by re-assigning levels of the table variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CollapseTable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CollapseTable_+3A_x">x</code></td>
<td>
<p>A <code>table</code> or <code>ftable</code> object</p>
</td></tr>
<tr><td><code id="CollapseTable_+3A_...">...</code></td>
<td>
<p> A collection of one or more assignments of factors of the table to
a list of levels </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each of the <code>...</code> arguments must be of the form
<code>variable = levels</code>, where <code>variable</code> is the name of one of the table
dimensions, and <code>levels</code> is a character or numeric vector of length equal
to the corresponding dimension of the table. Missing argument names are allowed and will be interpreted in the order of the dimensions of the table.
</p>


<h3>Value</h3>

<p>A <code>table</code> object (even if the input was an ftable), representing the original table with
one or more of its factors collapsed or rearranged into other levels.
</p>


<h3>Author(s)</h3>

<p>Michael Friendly &lt;friendly@yorku.ca&gt;, Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Untable">Untable</a></code>
</p>
<p><code><a href="base.html#topic+margin.table">margin.table</a></code> &quot;collapses&quot; a table in a different way, by
summing over table dimensions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create some sample data in table form
sex &lt;- c("Male", "Female")
age &lt;- letters[1:6]
education &lt;- c("low", 'med', 'high')
data &lt;- expand.grid(sex=sex, age=age, education=education)
counts &lt;- rpois(36, 100)
data &lt;- cbind(data, counts)
t1 &lt;- xtabs(counts ~ sex + age + education, data=data)

Desc(t1)

##                  age   a   b   c   d   e   f
## sex    education
## Male   low           119 101 109  85  99  93
##        med            94  98 103 108  84  84
##        high           81  88  96 110 100  92
## Female low           107 104  95  86 103  96
##        med           104  98  94  95 110 106
##        high           93  85  90 109  99  86


# collapse age to 3 levels
t2 &lt;- CollapseTable(t1, age=c("A", "A", "B", "B", "C", "C"))
Desc(t2)

##                  age   A   B   C
## sex    education
## Male   low           220 194 192
##        med           192 211 168
##        high          169 206 192
## Female low           211 181 199
##        med           202 189 216
##        high          178 199 185


# collapse age to 3 levels and pool education: "low" and "med" to "low"
t3 &lt;- CollapseTable(t1, age=c("A", "A", "B", "B", "C", "C"),
    education=c("low", "low", "high"))
Desc(t3)

##                  age   A   B   C
## sex    education
## Male   low           412 405 360
##        high          169 206 192
## Female low           413 370 415
##        high          178 199 185



# change labels for levels of education to 1:3
t4 &lt;- CollapseTable(t1,  education=1:3)
Desc(t4)

##                  age   a   b   c   d   e   f
## sex    education
## Male   1             119 101 109  85  99  93
##        2              94  98 103 108  84  84
##        3              81  88  96 110 100  92
## Female 1             107 104  95  86 103  96
##        2             104  98  94  95 110 106
##        3              93  85  90 109  99  86
</code></pre>

<hr>
<h2 id='ColorLegend'> Add a ColorLegend to a Plot
</h2><span id='topic+ColorLegend'></span>

<h3>Description</h3>

<p>Add a color legend, an image of a sequence of colors, to a plot. </p>


<h3>Usage</h3>

<pre><code class='language-R'>ColorLegend(x, y = NULL, cols = rev(heat.colors(100)), labels = NULL,
            width = NULL, height = NULL, horiz = FALSE, xjust = 0, yjust = 1,
            inset = 0, border = NA, frame = NA, cntrlbl = FALSE,
            adj = ifelse(horiz, c(0.5, 1), c(1, 0.5)), cex = 1, 
            title = NULL, title.adj = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColorLegend_+3A_x">x</code></td>
<td>
<p>the left x-coordinate to be used to position the colorlegend. See 'Details'. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_y">y</code></td>
<td>
<p>the top y-coordinate to be used to position the colorlegend. See 'Details'. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_cols">cols</code></td>
<td>
<p>the color appearing in the colorlegend.</p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_labels">labels</code></td>
<td>
<p>a vector of labels to be placed at the right side of the colorlegend.</p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_width">width</code></td>
<td>
<p>the width of the colorlegend.</p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_height">height</code></td>
<td>
<p>the height of the colorlegend. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_horiz">horiz</code></td>
<td>
<p>logical indicating if the colorlegend should be horizontal; default <code>FALSE</code> means vertical alignment. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_xjust">xjust</code></td>
<td>
<p>how the colorlegend is to be justified relative to the colorlegend x location.
A value of 0 means left justified, 0.5 means centered and 1 means right justified. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_yjust">yjust</code></td>
<td>
<p>the same as <code>xjust</code> for the legend y location. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_inset">inset</code></td>
<td>
<p>inset distance(s) from the margins as a fraction of the plot region when colorlegend is placed by keyword. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_border">border</code></td>
<td>
<p>defines the bordor color of each rectangle. Default is none (<code>NA</code>).</p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_frame">frame</code></td>
<td>
<p>defines the bordor color of the frame around the whole colorlegend. Default is none (<code>NA</code>). </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_cntrlbl">cntrlbl</code></td>
<td>
<p>defines, whether the labels should be printed in the middle of the color blocks or
start at the edges of the colorlegend. Default is <code>FALSE</code>, which will print the extreme labels centered on the edges. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_adj">adj</code></td>
<td>
<p>text alignment, horizontal and vertical. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_cex">cex</code></td>
<td>
<p>character extension for the labels, default 1.0. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_title">title</code></td>
<td>
<p>a character string or length-one expression giving a title to be placed at the top of the legend. </p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_title.adj">title.adj</code></td>
<td>
<p>horizontal adjustment for title: see the help for <code><a href="graphics.html#topic+par">par</a>("adj")</code>.</p>
</td></tr>
<tr><td><code id="ColorLegend_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code>text</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The labels are placed at the right side of the colorlegend and are reparted uniformly between y and y - height.
<br /><br />
The location may also be specified by setting x to a single keyword from the list <code>"bottomright"</code>, <code>"bottom"</code>, <code>"bottomleft"</code>, <code>"left"</code>, <code>"topleft"</code>, <code>"top"</code>, <code>"topright"</code>, <code>"right"</code> and <code>"center"</code>. This places the colorlegend on the inside of the plot frame at the given location. Partial argument matching is used. The optional inset argument specifies how far the colorlegend is inset from the plot margins. If a single value is given, it is used for both margins; if two values are given, the first is used for x- distance, the second for y-distance.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+legend">legend</a></code>, <code><a href="#topic+FindColor">FindColor</a></code>, <code><a href="#topic+BubbleLegend">BubbleLegend</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(1:15,, xlim=c(0,10), type="n", xlab="", ylab="", main="Colorstrips")

# A
ColorLegend(x="right", inset=0.1, labels=c(1:10))

# B: Center the labels
ColorLegend(x=1, y=9, height=6, col=colorRampPalette(c("blue", "white", "red"),
  space = "rgb")(5), labels=1:5, cntrlbl = TRUE)

# C: Outer frame
ColorLegend(x=3, y=9, height=6, col=colorRampPalette(c("blue", "white", "red"),
  space = "rgb")(5), labels=1:4, frame="grey")

# D
ColorLegend(x=5, y=9, height=6, col=colorRampPalette(c("blue", "white", "red"),
  space = "rgb")(10), labels=sprintf("%.1f",seq(0,1,0.1)), cex=0.8)

# E: horizontal shape
ColorLegend(x=1, y=2, width=6, height=0.2, col=rainbow(500), labels=1:5,horiz=TRUE)

# F
ColorLegend(x=1, y=14, width=6, height=0.5, col=colorRampPalette(
  c("black","blue","green","yellow","red"), space = "rgb")(100), horiz=TRUE)

# G
ColorLegend(x=1, y=12, width=6, height=1, col=colorRampPalette(c("black","blue",
            "green","yellow","red"), space = "rgb")(10), horiz=TRUE, 
            border="black", title="From black to red", title.adj=0)

text(x = c(8,0.5,2.5,4.5,0.5,0.5,0.5)+.2, y=c(14,9,9,9,2,14,12), LETTERS[1:7], cex=2)

</code></pre>

<hr>
<h2 id='ColToGrey'>Convert Colors to Grey/Grayscale</h2><span id='topic+ColToGrey'></span><span id='topic+ColToGray'></span>

<h3>Description</h3>

<p>Convert colors to grey/grayscale so that you can see how your plot
will look after photocopying or printing to a non-color printer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColToGrey(col)
ColToGray(col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColToGrey_+3A_col">col</code></td>
<td>
<p> vector of any of the three kind of R colors, i.e., either a color name (an element of colors()), 
a hexadecimal string of the form &quot;#rrggbb&quot; or &quot;#rrggbbaa&quot; (see rgb), or an integer i meaning palette()[i]. 
Non-string values are coerced to integer.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Converts colors to greyscale using the formula grey = 0.3*red +
0.59*green + 0.11*blue.  This allows you to see how your color plot
will approximately look when printed on a non-color printer or photocopied.
</p>


<h3>Value</h3>

<p>A vector of colors (greys) corresponding to the input colors.
</p>


<h3>Note</h3>

<p> These function was previously published as <code>Col2Grey()</code> in the  <span class="pkg">TeachingDemos</span> package and has been integrated here without logical changes. 
</p>


<h3>Author(s)</h3>

<p> Greg Snow &lt;greg.snow@imail.org&gt; </p>


<h3>See Also</h3>

 <p><code><a href="grDevices.html#topic+grey">grey</a></code>, <code><a href="#topic+ColToRgb">ColToRgb</a></code>, dichromat package </p>


<h3>Examples</h3>

<pre><code class='language-R'>par(mfcol=c(2,2))
tmp &lt;- 1:3
names(tmp) &lt;- c('red','green','blue')

barplot(tmp, col=c('red','green','blue'))
barplot(tmp, col=ColToGrey(c('red','green','blue')))

barplot(tmp, col=c('red','#008100','#3636ff'))
barplot(tmp, col=ColToGrey(c('red','#008100','#3636ff')))
</code></pre>

<hr>
<h2 id='ColToHex'>Convert a Color or a RGB-color Into Hex String
</h2><span id='topic+ColToHex'></span><span id='topic+RgbToHex'></span>

<h3>Description</h3>

<p>Convert a color given by name, by its palette index or by rgb-values into a string of the form &quot;#rrggbb&quot; or &quot;#rrggbbaa&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColToHex(col, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColToHex_+3A_col">col</code></td>
<td>
<p>vector of any of either a color name (an element of colors()),
or an integer i meaning palette()[i].
Non-string values are coerced to integer.</p>
</td></tr>
<tr><td><code id="ColToHex_+3A_alpha">alpha</code></td>
<td>
<p>the alpha value to be used. This can be any value from 0 (fully transparent) to 1 (opaque). Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the colorvalue in #rrggbb&quot; or #rrggbbaa&quot; format. (character)
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><a href="#topic+HexToCol">HexToCol</a>, <a href="#topic+ColToRgb">ColToRgb</a>, <a href="grDevices.html#topic+colors">colors</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ColToHex(c("lightblue", "salmon"))

x &lt;- ColToRgb("darkmagenta")
x[2,] &lt;- x[2,] + 155
RgbToCol(x)

RgbToHex(c(255,0,0))
</code></pre>

<hr>
<h2 id='ColToHsv'>R Color to HSV Conversion
</h2><span id='topic+ColToHsv'></span>

<h3>Description</h3>

<p>ColToHsv transforms colors from R color into HSV space (hue/saturation/value). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColToHsv(col, alpha = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColToHsv_+3A_col">col</code></td>
<td>
<p>vector of any of the three kind of R colors, i.e., either a color name (an element of <code><a href="grDevices.html#topic+colors">colors</a></code>()), 
a hexadecimal string of the form &quot;#rrggbb&quot; or &quot;#rrggbbaa&quot;, or an integer i meaning palette()[i]. 
Non-string values are coerced to integer.
</p>
</td></tr>
<tr><td><code id="ColToHsv_+3A_alpha">alpha</code></td>
<td>
<p>logical value indicating whether alpha channel (opacity) values should be returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Converts a color first into RGB an from there into HSV space by means of the functions <code><a href="grDevices.html#topic+rgb2hsv">rgb2hsv</a></code> and <code><a href="grDevices.html#topic+col2rgb">col2rgb</a></code>.
</p>
<p>Value (brightness) gives the amount of light in the color.
Hue describes the dominant wavelength.
Saturation is the amount of Hue mixed into the color. 
</p>
<p>An HSV colorspace is relative to an RGB colorspace, which in R is sRGB, which has an implicit gamma correction. 
</p>


<h3>Value</h3>

<p>A matrix with a column for each color. The three rows of the matrix indicate hue, saturation and value and are named &quot;h&quot;, &quot;s&quot;, and &quot;v&quot; accordingly. 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="grDevices.html#topic+rgb2hsv">rgb2hsv</a></code>, <code><a href="#topic+ColToRgb">ColToRgb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ColToHsv("peachpuff")
ColToHsv(c(blu = "royalblue", reddish = "tomato")) # names kept

ColToHsv(1:8)
</code></pre>

<hr>
<h2 id='ColToOpaque'>Equivalent Opaque Color for Transparent Color 
</h2><span id='topic+ColToOpaque'></span>

<h3>Description</h3>

<p>Determine the equivalent opaque RGB color for a given partially transparent RGB color against a background of any color. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColToOpaque(col, alpha = NULL, bg = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColToOpaque_+3A_col">col</code></td>
<td>
<p>the color as hex value (use converters below if it's not available). <code>col</code> and <code>alpha</code> are recycled.
</p>
</td></tr>
<tr><td><code id="ColToOpaque_+3A_alpha">alpha</code></td>
<td>
<p>the alpha channel, if left to NULL the alpha channels of the colors are used
</p>
</td></tr>
<tr><td><code id="ColToOpaque_+3A_bg">bg</code></td>
<td>
<p>the background color to be used to calculate against (default is &quot;white&quot;)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reducing the opacity against a white background is a good way to find usable lighter and less saturated tints of a base color. For doing so, we sometimes need to get the equivalent opaque color for the transparent color.
</p>


<h3>Value</h3>

<p>An named vector with the hexcodes of the opaque colors.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ColToHex">ColToHex</a></code>, <code><a href="#topic+DecToHex">DecToHex</a></code>, <code><a href="#topic+RgbToHex">RgbToHex</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cols &lt;- c(SetAlpha("limegreen", 0.4), ColToOpaque(ColToHex("limegreen"), 0.4), "limegreen")
barplot(c(1, 1.2, 1.3), col=cols, panel.first=abline(h=0.4, lwd=10, col="grey35"))
</code></pre>

<hr>
<h2 id='ColToRgb'>Color to RGB Conversion
</h2><span id='topic+ColToRgb'></span>

<h3>Description</h3>

<p>R color to RGB (red/green/blue) conversion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColToRgb(col, alpha = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColToRgb_+3A_col">col</code></td>
<td>
<p>vector of any of the three kind of R colors, i.e., either a color name (an element of <code><a href="grDevices.html#topic+colors">colors</a></code>()),
a hexadecimal string of the form &quot;#rrggbb&quot; or &quot;#rrggbbaa&quot;, or an integer i meaning palette()[i].
Non-string values are coerced to integer.
</p>
</td></tr>
<tr><td><code id="ColToRgb_+3A_alpha">alpha</code></td>
<td>
<p>logical value indicating whether alpha channel (opacity) values should be returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is merely a wrapper to <code><a href="grDevices.html#topic+col2rgb">col2rgb</a></code>, defined in order to follow this package's naming conventions.
</p>


<h3>Value</h3>

<p>A matrix with a column for each color. The three rows of the matrix indicate red, green and blue value and are named &quot;red&quot;, &quot;green&quot;, and &quot;blue&quot; accordingly.
The matrix might have a 4th row if an alpha channel is requested.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="grDevices.html#topic+col2rgb">col2rgb</a></code>, <code><a href="#topic+RgbToCol">RgbToCol</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ColToRgb("peachpuff")
ColToRgb(c(blu = "royalblue", reddish = "tomato")) # names kept

ColToRgb(1:8)
</code></pre>

<hr>
<h2 id='ColumnWrap'>Column Wrap
</h2><span id='topic+ColumnWrap'></span>

<h3>Description</h3>

<p>Wraps text in a character matrix so, that it's displayed over more than one line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColumnWrap(x, width = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ColumnWrap_+3A_x">x</code></td>
<td>
<p>the matrix with one row
</p>
</td></tr>
<tr><td><code id="ColumnWrap_+3A_width">width</code></td>
<td>
<p>integer, the width of the columns in characters
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A data.frame containing character columns with long texts is often wrapped by columns. This can lead to a loss of overview. ColumnWrap wraps the lines within the columns.
</p>


<h3>Value</h3>

<p>a character matrix
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strwrap">strwrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Abstract(d.pizza)
</code></pre>

<hr>
<h2 id='CombPairs'>Get All Pairs Out of One or Two Sets of Elements
</h2><span id='topic+CombPairs'></span>

<h3>Description</h3>

<p>Returns all combinations of 2 out of the elements in x or x and y (if defined). Combinations of the same elements will be dropped (no replacing).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CombPairs(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CombPairs_+3A_x">x</code></td>
<td>
<p>a vector of elements
</p>
</td></tr>
<tr><td><code id="CombPairs_+3A_y">y</code></td>
<td>
<p>a vector of elements, need not be same dimension as x.
If y is not <code>NULL</code> then all combination x and y are returned.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If y = <code>NULL</code> then all combination of 2 out of x are returned. <br />
If y is defined then all combinations of x and y are calculated.
</p>


<h3>Value</h3>

<p><code>CombPairs</code> returns a data.frame with 2 columns X1 and X2.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+combn">combn</a></code>, <code><a href="base.html#topic+expand.grid">expand.grid</a></code>, <code><a href="base.html#topic+outer">outer</a></code>, <code><a href="base.html#topic+lower.tri">lower.tri</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CombPairs(letters[1:4])
CombPairs(x = letters[1:4], y = LETTERS[1:2])

# get all pairs of combinations between factors and numerics out of a data.frame
CombPairs(which(sapply(d.pizza, IsNumeric)), which(sapply(d.pizza, is.factor)))
</code></pre>

<hr>
<h2 id='CompleteColumns'>Find Complete Columns
</h2><span id='topic+CompleteColumns'></span>

<h3>Description</h3>

<p>Return either the columnnames or a logical vector indicating which columns are complete, i.e., have no missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CompleteColumns(x, which = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompleteColumns_+3A_x">x</code></td>
<td>
<p>a data.frame containing the data
</p>
</td></tr>
<tr><td><code id="CompleteColumns_+3A_which">which</code></td>
<td>
<p>logical, determining if the names of the variables should be returned or a if a logical vector indicating which columns are complete should be returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector specifying which columns have no missing values across the entire sequence.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+is.na">is.na</a></code>,  <code><a href="stats.html#topic+na.omit">na.omit</a></code>,  <code><a href="stats.html#topic+complete.cases">complete.cases</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CompleteColumns(d.pizza)
CompleteColumns(d.pizza, which=FALSE)
</code></pre>

<hr>
<h2 id='ConDisPairs'>Concordant and Discordant Pairs
</h2><span id='topic+ConDisPairs'></span>

<h3>Description</h3>

<p>This function counts concordant and discordant pairs for two variables x, y with at least ordinal scale, aggregated in a
2way table. This is the base for many association measures like Goodman Kruskal's gamma, but also all tau measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConDisPairs(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConDisPairs_+3A_x">x</code></td>
<td>
<p>a 2-dimensional table. The column and the row order must be the logical one.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The code is so far implemented in R (O(n^2)) and therefore slow for large sample sizes (&gt;5000).
</p>
<p>An O(n log(n)) implementation is available as (so far) undocumented function <code>DescTools:::.DoCount(x, y, wts)</code> returning only concorant and discordant pairs (not including standard errors to be used for calculating confidence intervals).
</p>


<h3>Value</h3>

<p>a list with the number of concordant pairs, the number of discordant pairs and
the matrix
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons,
pp. 57-59.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1954) Measures of
association for cross classifications. <em>Journal of the
American Statistical Association</em>, 49, 732-764.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1963) Measures of
association for cross classifications III: Approximate
sampling theory. <em>Journal of the American Statistical
Association</em>, 58, 310-364.
</p>


<h3>See Also</h3>

<p>Association measures: <br />
<code><a href="#topic+KendallTauA">KendallTauA</a></code> (tau-a), <code><a href="stats.html#topic+cor">cor</a></code> (method=&quot;kendall&quot;) for tau-b, <code><a href="#topic+StuartTauC">StuartTauC</a></code> (tau-c), <code><a href="#topic+SomersDelta">SomersDelta</a></code><br />
<code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+GoodmanKruskalTau">GoodmanKruskalTau</a></code> (tau), <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- as.table(rbind(c(26,26,23,18,9),c(6,7,9,14,23)))
ConDisPairs(tab)
</code></pre>

<hr>
<h2 id='Conf'>Confusion Matrix And Associated Statistics
</h2><span id='topic+Conf'></span><span id='topic+Conf.table'></span><span id='topic+Conf.default'></span><span id='topic+Conf.matrix'></span><span id='topic+Conf.rpart'></span><span id='topic+Conf.multinom'></span><span id='topic+Conf.glm'></span><span id='topic+Conf.randomForest'></span><span id='topic+Conf.svm'></span><span id='topic+Conf.regr'></span><span id='topic+plot.Conf'></span><span id='topic+print.Conf'></span><span id='topic+Sens'></span><span id='topic+Spec'></span>

<h3>Description</h3>

<p>Calculates a cross-tabulation of observed and predicted classes with associated statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Conf(x, ...)

## S3 method for class 'table'
Conf(x, pos = NULL, ...)
## S3 method for class 'matrix'
Conf(x, pos = NULL, ...)
## Default S3 method:
Conf(x, ref, pos = NULL, na.rm = TRUE, ...)

## S3 method for class 'rpart'
Conf(x, ...)
## S3 method for class 'multinom'
Conf(x, ...)
## S3 method for class 'glm'
Conf(x, cutoff = 0.5, pos = NULL, ...)
## S3 method for class 'randomForest'
Conf(x, ...)
## S3 method for class 'svm'
Conf(x, ...)
## S3 method for class 'regr'
Conf(x, ...)

## S3 method for class 'Conf'
plot(x, main = "Confusion Matrix", ...)

## S3 method for class 'Conf'
print(x, digits = max(3, getOption("digits") - 3), ...)

Sens(x, ...)
Spec(x, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Conf_+3A_x">x</code></td>
<td>
<p>a vector, normally a factor, of predicted classes or an object of following classes <code>rpart</code>, <code>randomForest</code>, <code>svm</code>, <code>C50</code>, <code>glm</code>, <code>multinom</code>, <code>reg</code>r, <code>ld</code>a, <code>qda</code> or <code><a href="base.html#topic+table">table</a></code>, resp. <code>matrix</code>. When a model is given, the predicted classes will be determined. A table or a matrix will be interpreted as a confusion matrix.
</p>
</td></tr>
<tr><td><code id="Conf_+3A_ref">ref</code></td>
<td>
<p>a vector, normally a factor, of classes to be used as the reference. This is ignored if <code>x</code> is a <code>table</code> or <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="Conf_+3A_pos">pos</code></td>
<td>
<p>a character string that defines the factor level corresponding to the &quot;positive&quot; results. Will be ignored for a <code class="reqn">n \times n</code> table n &gt; 2.</p>
</td></tr>
<tr><td><code id="Conf_+3A_cutoff">cutoff</code></td>
<td>
<p>used in logit models. The cutoff for changing classes.</p>
</td></tr>
<tr><td><code id="Conf_+3A_main">main</code></td>
<td>
<p>overall title for the plot. </p>
</td></tr>
<tr><td><code id="Conf_+3A_digits">digits</code></td>
<td>
<p>controls the number of digits to print.
</p>
</td></tr>
<tr><td><code id="Conf_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether or not missing values should be removed. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="Conf_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions require the factors to have the same levels.
</p>
<p>For two class problems, the sensitivity, specificity, positive
predictive value and negative predictive value is calculated using the
<code>positive</code> argument. Also, the prevalence of the &quot;event&quot; is computed from the
data (unless passed in as an argument), the detection rate (the rate of true events also
predicted to be events) and the detection prevalence (the prevalence of predicted events).
</p>
<p>Suppose a <code class="reqn">2 \times 2</code> table with notation
</p>

<table>
<tr>
 <td style="text-align: right;">
                    </td><td style="text-align: center;"> Reference </td><td style="text-align: center;">          </td>
</tr>
<tr>
 <td style="text-align: right;">
         Predicted  </td><td style="text-align: center;"> Event     </td><td style="text-align: center;"> No Event </td>
</tr>
<tr>
 <td style="text-align: right;">
         Event      </td><td style="text-align: center;"> A         </td><td style="text-align: center;"> B        </td>
</tr>
<tr>
 <td style="text-align: right;">
         No Event   </td><td style="text-align: center;"> C         </td><td style="text-align: center;"> D        </td>
</tr>
<tr>
 <td style="text-align: right;">
       </td>
</tr>

</table>

<p>The formulas used here are:
</p>
<p style="text-align: center;"><code class="reqn">Sensitivity = A/(A+C)</code>
</p>

<p style="text-align: center;"><code class="reqn">Specificity = D/(B+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">Prevalence = (A+C)/(A+B+C+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">PPV = (sensitivity * Prevalence)/((sensitivity*Prevalence) + ((1-specificity)*(1-Prevalence)))</code>
</p>

<p style="text-align: center;"><code class="reqn">NPV = (specificity * (1-Prevalence))/(((1-sensitivity)*Prevalence) + ((specificity)*(1-Prevalence)))</code>
</p>

<p style="text-align: center;"><code class="reqn">Detection Rate =  A/(A+B+C+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">Detection Prevalence =  (A+B)/(A+B+C+D)</code>
</p>

<p style="text-align: center;"><code class="reqn">F-val Accuracy =  2 / (1/PPV + 1/Sensitivity)</code>
</p>

<p style="text-align: center;"><code class="reqn">Matthews Cor.-Coef = (A*D-B*C)/sqrt((A+B)*(A+C)*(D+B)*(D+C)) </code>
</p>

<p>See the references for discusions of the first five formulas.
</p>
<p>For more than two classes, these results are
calculated comparing each factor level to the remaining levels
(i.e. a &quot;one versus all&quot; approach).
</p>
<p>The overall accuracy and unweighted Kappa statistic are calculated. A p-value from McNemar's test is also computed using <code><a href="stats.html#topic+mcnemar.test">mcnemar.test</a></code> (which can produce <code>NA</code> values with sparse tables).
</p>
<p>The overall accuracy rate is computed along with a 95 percent confidence interval for this rate (using <code><a href="#topic+BinomCI">BinomCI</a></code>) and a one-sided test to see if the accuracy is better than the &quot;no information rate,&quot; which is taken to be the largest class percentage in the data.
</p>
<p>The sensitivity is defined as the proportion of positive results out of the number of
samples which were actually positive. When there are no positive results, sensitivity is
not defined and a value of <code>NA</code> is returned. Similarly, when there are no negative
results, specificity is not defined and a value of <code>NA</code> is returned. Similar
statements are true for predictive values.
</p>
<p>Confidence intervals for sensitivity, specificity etc. could be calculated as binomial confidence intervals (see <code><a href="#topic+BinomCI">BinomCI</a></code>). <code>BinomCI(A, A+C)</code> yields the ci for sensitivity.
</p>


<h3>Value</h3>

<p>a list with elements
</p>
<table>
<tr><td><code>table</code></td>
<td>
<p>the results of <code>table</code> on <code>data</code> and  <code>reference</code></p>
</td></tr>
<tr><td><code>positive</code></td>
<td>
<p>the positive result level</p>
</td></tr>
<tr><td><code>overall</code></td>
<td>
<p>a numeric vector with overall accuracy and Kappa statistic values</p>
</td></tr>
<tr><td><code>byClass</code></td>
<td>
<p>the sensitivity, specificity, positive predictive value, negative predictive value, prevalence, dection rate and detection prevalence for each class. For two class systems, this is calculated once using the <code>positive</code> argument</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; <br />
rewritten based on the ideas of <code><a href="caret.html#topic+confusionMatrix">confusionMatrix</a></code> by Max Kuhn &lt;Max.Kuhn@pfizer.com&gt;
</p>


<h3>References</h3>

<p>Kuhn, M. (2008) Building predictive models in R using the caret package <em>Journal of Statistical Software</em>, (<a href="https://www.jstatsoft.org/v28/i05/">https://www.jstatsoft.org/v28/i05/</a>).
</p>
<p>Powers, David M W (2011) Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation (PDF). <em>Journal of Machine Learning Technologies</em> 2 (1): 37-63.
</p>
<p>Collett D (1999) Modelling Binary Data. <em>Chapman &amp; Hall/CRC</em>, Boca Raton Florida, pp. 24.
</p>
<p>Matthews, B. W. (1975) Comparison of the predicted and observed secondary structure of T4 phage lysozyme. <em>Biochimica et Biophysica Acta (BBA) - Protein Structure</em> 405 (2): 442-451. doi:10.1016/0005-2795(75)90109-9. PMID 1180967.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OddsRatio">OddsRatio</a></code>, <code><a href="#topic+RelRisk">RelRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># let tab be a confusion table
tab &lt;- TextToTable("
   lo hi
lo 23 13
hi 10 18 ", dimnames=c("pred", "obs"))

Conf(tab, pos="hi")


pred &lt;- Untable(tab)[,"pred"]
obs &lt;- Untable(tab)[,"obs"]

Conf(x = pred, ref = obs)
Conf(x = pred, ref = obs, pos="hi")

Sens(tab)   # Sensitivity
Spec(tab)   # Specificity


tab &lt;- TextToTable("
      terrible poor marginal clear
terrible       10    4        1     0
poor            5   10       12     2
marginal        2    4       12     5
clear           0    2        6    13
", dimnames=c("pred", "obs"))

Conf(tab)
</code></pre>

<hr>
<h2 id='ConnLines'>Add Connection Lines to a Barplot
</h2><span id='topic+ConnLines'></span>

<h3>Description</h3>

<p>Add connection lines to a stacked barplot (beside = <code>TRUE</code> is not supported). The function expects exactly the same arguments, that were
used to create the barplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConnLines(..., col = 1, lwd = 1, lty = "solid", xalign = c("mar","mid"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConnLines_+3A_...">...</code></td>
<td>
<p>the arguments used to create the barplot. (The dots are sent directly to barplot).
</p>
</td></tr>
<tr><td><code id="ConnLines_+3A_col">col</code></td>
<td>
<p>the line color of the connection lines. Defaults to black.
</p>
</td></tr>
<tr><td><code id="ConnLines_+3A_lwd">lwd</code></td>
<td>
<p>the line width for the connection lines. Default is 1.
</p>
</td></tr>
<tr><td><code id="ConnLines_+3A_lty">lty</code></td>
<td>
<p>the line type for the connection lines. Line types can either be specified as an integer
(0=blank, 1=solid (default), 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash) or as one of the
character strings <code>"blank"</code>, <code>"solid"</code>, <code>"dashed"</code>, <code>"dotted"</code>, <code>"dotdash"</code>, <code>"longdash"</code>, or <code>"twodash"</code>.
Default is <code>"solid"</code>.
</p>
</td></tr>
<tr><td><code id="ConnLines_+3A_xalign">xalign</code></td>
<td>
<p>defines where the lines should be aligned to on the x-axis. Can be set
either to the margins of the bars (&quot;mar&quot; which is the default) or to &quot;mid&quot;. The latter will lead the connecting lines to the middle of the bars.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+barplot">barplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- with(
  subset(d.pizza, driver %in% c("Carpenter","Miller","Farmer","Butcher")),
  table(factor(driver), Weekday(date, "dd", stringsAsFactor=TRUE))
)
tab

barplot(tab, beside=FALSE, space=1.2)
ConnLines(tab, beside=FALSE, space=1.2, lcol="grey50", lwd=1, lty=2)

barplot(tab, beside=FALSE, space=1.2, horiz=TRUE)
ConnLines(tab, beside=FALSE, space=1.2, horiz=TRUE, lcol="grey50", lwd=1, lty=2)


cols &lt;- Pal("Helsana")[1:4]
b &lt;- barplot(tab, beside=FALSE, horiz=FALSE, col=cols)
ConnLines(tab, beside=FALSE, horiz=FALSE, lcol="grey50", lwd=1, lty=2)

# set some labels
txt &lt;- tab
txt[] &lt;- gsub(pattern="^0", "", t(tab))       # do not print 0s
text(x=b, y=t(apply(apply(rbind(0,tab), 2, Midx), 2, cumsum)), labels=txt,
     col=(matrix(rep(TextContrastColor(cols), each=ncol(tab)),
          nrow=nrow(tab), byrow=FALSE )))

# align to the middle of the bars
barplot(tab, beside=FALSE, space=1.2)
ConnLines(tab, beside=FALSE, space=1.2, lcol="grey50", lwd=1, lty=2, method="mid")
</code></pre>

<hr>
<h2 id='ConoverTest'>Conover's Test of Multiple Comparisons</h2><span id='topic+ConoverTest'></span><span id='topic+ConoverTest.default'></span><span id='topic+ConoverTest.formula'></span>

<h3>Description</h3>

<p>Perform Conover's test of multiple comparisons using rank sums as post hoc test following a significant <code><a href="stats.html#topic+kruskal.test">kruskal.test</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConoverTest(x, ...)

## Default S3 method:
ConoverTest(x, g,
            method = c("holm", "hochberg", "hommel", "bonferroni", "BH",
                       "BY", "fdr", "none"),
            alternative = c("two.sided", "less", "greater"),
            out.list = TRUE, ...)

## S3 method for class 'formula'
ConoverTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConoverTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, or a list of numeric data
vectors.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the
corresponding elements of <code>x</code>.  Ignored if <code>x</code> is a
list.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_method">method</code></td>
<td>
<p>the method for adjusting p-values for multiple comparisons. The function is calling <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> and this parameter is directly passed through.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>. You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_out.list">out.list</code></td>
<td>
<p>logical, indicating if the results should be printed in list mode or as a square matrix. Default is list (TRUE).</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
gives the data values and <code>rhs</code> the corresponding groups.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="ConoverTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ConoverTest</code> performs the post hoc pairwise multiple comparisons procedure appropriate to follow the rejection of a Kruskal-Wallis test.
Conover's test is more powerful than Dunn's post hoc multiple comparisons test (<code><a href="#topic+DunnTest">DunnTest</a></code>). The interpretation of stochastic dominance requires an assumption that the CDF of one group does not cross the CDF of the other. <br />
ConoverTest makes m = k(k-1)/2 multiple pairwise comparisons based on the Conover-Iman t-test-statistic for the rank-sum differences:
</p>
<p style="text-align: center;"><code class="reqn">\left | \bar{R}_{i}-\bar{R}_{j} \right | &gt; t_{1-\alpha/2, n-k} \cdot \sqrt{ s^2 \cdot \left [
\frac{n-1-\hat{H}^*}{n-k} \right ] \cdot \left [ \frac{1}{n_i} + \frac{1}{n_j} \right ] } </code>
</p>

<p>with the (tie corrected) statistic of the Kruskal Wallis test
</p>
<p style="text-align: center;"><code class="reqn">\hat{H}^* = \frac{\frac{12}{n \cdot (n+1)} \cdot \sum_{i=1}^{k}\frac{R_{i}^2}{n_i} - 3\cdot(n+1) } {1-\frac{\sum_{i=1}^{r} \left ( t_i^3-t_i \right )}{n^3-n}} </code>
</p>

<p>and the <code class="reqn">s^2</code> being
</p>
<p style="text-align: center;"><code class="reqn">s^2 = \frac{1}{n-1} \cdot \left [ \sum{R_i^2} - n \cdot \frac{(n+1)^2}{4} \right ]</code>
</p>

<p>If <code>x</code> is a list, its elements are taken as the samples to be
compared, and hence have to be numeric data vectors.  In this case,
<code>g</code> is ignored, and one can simply use <code>ConoverTest(x)</code>
to perform the test.  If the samples are not yet contained in a
list, use <code>ConoverTest(list(x, ...))</code>.
</p>
<p>Otherwise, <code>x</code> must be a numeric data vector, and <code>g</code> must
be a vector or factor object of the same length as <code>x</code> giving
the group for the corresponding elements of <code>x</code>.
</p>


<h3>Value</h3>

<p>A list with class <code>"DunnTest"</code> containing the following components:
</p>
<table>
<tr><td><code>res</code></td>
<td>
<p>an array containing the mean rank differencens and the according p-values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, the interface is based on R-Core code</p>


<h3>References</h3>

<p>Conover W. J., Iman R. L. (1979) On multiple-comparisons procedures, <em>Tech. Rep.</em> LA-7677-MS, Los Alamos Scientific Laboratory.
</p>
<p>Conover, W. J. (1999) Practical Nonparametric Statistics <em>Wiley</em>, Hoboken, NJ. 3rd edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DunnTest">DunnTest</a></code>, <code><a href="#topic+NemenyiTest">NemenyiTest</a></code>, <code><a href="stats.html#topic+kruskal.test">kruskal.test</a></code>, <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>, <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Hollander &amp; Wolfe (1973), 116.
## Mucociliary efficiency from the rate of removal of dust in normal
##  subjects, subjects with obstructive airway disease, and subjects
##  with asbestosis.
x &lt;- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
y &lt;- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
z &lt;- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
ConoverTest(list(x, y, z))

## Equivalently,
x &lt;- c(x, y, z)
g &lt;- factor(rep(1:3, c(5, 4, 5)),
            labels = c("Normal subjects",
                       "Subjects with obstructive airway disease",
                       "Subjects with asbestosis"))

# do the kruskal.test first
kruskal.test(x, g)

# ...and the pairwise test afterwards
ConoverTest(x, g)

## Formula interface.
boxplot(Ozone ~ Month, data = airquality)
ConoverTest(Ozone ~ Month, data = airquality)
</code></pre>

<hr>
<h2 id='Contrasts'>Pairwise Contrasts
</h2><span id='topic+Contrasts'></span>

<h3>Description</h3>

<p>Generate all pairwise contrasts for using in a post-hoc test, e.g. ScheffeTest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Contrasts(levs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Contrasts_+3A_levs">levs</code></td>
<td>
<p>the levels to be used
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with all possible pairwise contrasts, that can be built with the given levels.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ScheffeTest">ScheffeTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Contrasts(LETTERS[1:5])

#   B-A C-A D-A E-A C-B D-B E-B D-C E-C E-D
# A  -1  -1  -1  -1   0   0   0   0   0   0
# B   1   0   0   0  -1  -1  -1   0   0   0
# C   0   1   0   0   1   0   0  -1  -1   0
# D   0   0   1   0   0   1   0   1   0  -1
# E   0   0   0   1   0   0   1   0   1   1

</code></pre>

<hr>
<h2 id='ConvUnit'>Unit Conversion and Metrix Prefixes
</h2><span id='topic+ConvUnit'></span><span id='topic+d.units'></span><span id='topic+d.prefix'></span><span id='topic+CmToPts'></span><span id='topic+PtsToCm'></span>

<h3>Description</h3>

<p>Converts a numerical vector from one measurement system to another.
Metric prefixes (as unit prefixes that precede a basic unit of measure to indicate a multiple or fraction of the unit) are respected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CmToPts(x)
PtsToCm(x)

ConvUnit(x, from, to)

data(d.units)
data(d.prefix)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConvUnit_+3A_x">x</code></td>
<td>
<p>the numeric to be converted.
</p>
</td></tr>
<tr><td><code id="ConvUnit_+3A_from">from</code></td>
<td>
<p>a character defining the original unit.
</p>
</td></tr>
<tr><td><code id="ConvUnit_+3A_to">to</code></td>
<td>
<p>a character defining the target unit.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two functions <code>CmToPts()</code> and <code>PtsToCm()</code> convert centimeters to points and vice versa. 1 cm corresponds to 28.35 points.
</p>
<p>The units as defined by the International System of Units (SI) (m, g, s, A, K, mol, cd, Hz, rad, sr, N, Pa, J, W, C, V, F, Ohm, S, Wb, T, H, lm, lx, Bq, Gy, Sv, kat, l) can be used to convert between different prefixes. The following non SI-units can be chosen for conversion between different systems. <code>NA</code> will be returned if a conversion can't be found. <br />
The function is using the conversion factors stored in the dataset <code>d.units</code>.
</p>

<table>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<b>Weight and mass</b></td><td style="text-align: left;"> </td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
Gram  </td><td style="text-align: left;"> g </td><td style="text-align: left;"> metric</td>
</tr>
<tr>
 <td style="text-align: left;">
Pound mass (avoirdupois)  </td><td style="text-align: left;"> lb </td>
</tr>
<tr>
 <td style="text-align: left;">
Ounce mass (avoirdupois)  </td><td style="text-align: left;"> oz </td>
</tr>
<tr>
 <td style="text-align: left;">
Metric ton  </td><td style="text-align: left;"> ton (or tn) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"><b>Distance</b></td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Meter  </td><td style="text-align: left;">  m </td><td style="text-align: left;"> metric </td>
</tr>
<tr>
 <td style="text-align: left;">
Statute mile  </td><td style="text-align: left;"> mi </td>
</tr>
<tr>
 <td style="text-align: left;">
Nautical mile  </td><td style="text-align: left;"> nmi </td>
</tr>
<tr>
 <td style="text-align: left;">
Inch  </td><td style="text-align: left;"> in </td>
</tr>
<tr>
 <td style="text-align: left;">
Foot  </td><td style="text-align: left;"> ft </td>
</tr>
<tr>
 <td style="text-align: left;">
Yard  </td><td style="text-align: left;"> yd </td>
</tr>
<tr>
 <td style="text-align: left;">
Angstrom  </td><td style="text-align: left;"> AA </td><td style="text-align: left;"> (accepted) metric </td>
</tr>
<tr>
 <td style="text-align: left;">
Astronomical unit  </td><td style="text-align: left;"> au </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"><b>Time</b></td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Year  </td><td style="text-align: left;"> a </td>
</tr>
<tr>
 <td style="text-align: left;">
Day  </td><td style="text-align: left;"> d </td>
</tr>
<tr>
 <td style="text-align: left;">
Hour  </td><td style="text-align: left;"> h </td>
</tr>
<tr>
 <td style="text-align: left;">
Minute  </td><td style="text-align: left;"> min </td>
</tr>
<tr>
 <td style="text-align: left;">
Second  </td><td style="text-align: left;"> s </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"><b>Pressure</b></td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Pascal  </td><td style="text-align: left;"> Pa </td>
</tr>
<tr>
 <td style="text-align: left;">
Atmosphere  </td><td style="text-align: left;"> atm </td>
</tr>
<tr>
 <td style="text-align: left;">
mm of Mercury  </td><td style="text-align: left;"> mmHg </td>
</tr>
<tr>
 <td style="text-align: left;">
bar  </td><td style="text-align: left;"> bar </td>
</tr>
<tr>
 <td style="text-align: left;">
Pound-force per quare inch  </td><td style="text-align: left;"> psi </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"><b>Energy</b></td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Joule  </td><td style="text-align: left;"> J </td><td style="text-align: left;"> metric </td>
</tr>
<tr>
 <td style="text-align: left;">
IT calorie  </td><td style="text-align: left;"> cal </td><td style="text-align: left;"> (accepted) metric </td>
</tr>
<tr>
 <td style="text-align: left;">
Electron volt  </td><td style="text-align: left;"> eV (or ev) </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"><b>Power</b></td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Horsepower (mechanical)  </td><td style="text-align: left;"> hp </td>
</tr>
<tr>
 <td style="text-align: left;">
Horsepower (metric)  </td><td style="text-align: left;"> HP</td>
</tr>
<tr>
 <td style="text-align: left;">
Watt  </td><td style="text-align: left;"> W (or w) </td><td style="text-align: left;"> metric </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"><b>Temperature</b></td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Degree Celsius  </td><td style="text-align: left;"> C </td>
</tr>
<tr>
 <td style="text-align: left;">
Degree Fahrenheit  </td><td style="text-align: left;"> F</td>
</tr>
<tr>
 <td style="text-align: left;">
Kelvin  </td><td style="text-align: left;"> K </td><td style="text-align: left;"> metric </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;"><b>Liquid measure</b></td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
Fluid ounce  </td><td style="text-align: left;"> fl oz </td>
</tr>
<tr>
 <td style="text-align: left;">
Gallon  </td><td style="text-align: left;"> gal </td>
</tr>
<tr>
 <td style="text-align: left;">
Liter  </td><td style="text-align: left;"> l (or lt) </td><td style="text-align: left;"> (accepted) metric </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Additional details can be found in the <code>d.units</code> data.frame.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ConvUnit(c(1.2, 5.4, 6.7), "in", "m")

# from kilometers to pico meters
ConvUnit(1, from="km", to="pm")

# from miles to kilometers
ConvUnit(1, from="mi", to="km")
# nautical miles
ConvUnit(1, from="nmi", to="km")
# from kilo Kelvin to Fahrenheit
ConvUnit(10, from="kK", to="F")
# from metric to more quirky units
ConvUnit(c(10, 1), from="hl", to="gal")
ConvUnit(500, from="ml", to="fl oz")

# conversion between non-SI units
ConvUnit(1000, "yd", "mi")
# ... must be the same as
ConvUnit(ConvUnit(1000, "yd", "m"), "m", "mi")
</code></pre>

<hr>
<h2 id='Cor'>Covariance and Correlation (Matrices)</h2><span id='topic+Cov'></span><span id='topic+Cor'></span>

<h3>Description</h3>

<p><code>Cov</code> and <code>Cor</code> compute the covariance or correlation of <code>x</code> and <code>y</code> if these
are vectors.   If <code>x</code> and <code>y</code> are matrices then the
covariances (or correlations) between the columns of <code>x</code> and the
columns of <code>y</code> are computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Cov(x, y = NULL, use = "everything",
    method = c("pearson", "kendall", "spearman"))

Cor(x, y = NULL, use = "everything",
    method = c("pearson", "kendall", "spearman"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cor_+3A_x">x</code></td>
<td>
<p>a numeric vector, matrix or data frame.</p>
</td></tr>
<tr><td><code id="Cor_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or a vector, matrix or data frame with
compatible dimensions to <code>x</code>.   The default is equivalent to
<code>y = x</code> (but more efficient).</p>
</td></tr>
<tr><td><code id="Cor_+3A_use">use</code></td>
<td>
<p>an optional character string giving a
method for computing covariances in the presence
of missing values.  This must be (an abbreviation of) one of the strings
<code>"everything"</code>, <code>"all.obs"</code>, <code>"complete.obs"</code>,
<code>"na.or.complete"</code>, or <code>"pairwise.complete.obs"</code>.</p>
</td></tr>
<tr><td><code id="Cor_+3A_method">method</code></td>
<td>
<p>a character string indicating which correlation
coefficient (or covariance) is to be computed.  One of
<code>"pearson"</code> (default), <code>"kendall"</code>, or <code>"spearman"</code>:
can be abbreviated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>Cov</code> and <code>Cor</code> one must <em>either</em> give a matrix or
data frame for <code>x</code> <em>or</em> give both <code>x</code> and <code>y</code>.
</p>
<p>The inputs must be numeric (as determined by <code><a href="base.html#topic+is.numeric">is.numeric</a></code>:
logical values are also allowed for historical compatibility): the
<code>"kendall"</code> and <code>"spearman"</code> methods make sense for ordered
inputs but <code><a href="base.html#topic+xtfrm">xtfrm</a></code> can be used to find a suitable prior
transformation to numbers.
</p>
<p>If <code>use</code> is <code>"everything"</code>, <code><a href="base.html#topic+NA">NA</a></code>s will
propagate conceptually, i.e., a resulting value will be <code>NA</code>
whenever one of its contributing observations is <code>NA</code>.<br />
If <code>use</code> is <code>"all.obs"</code>, then the presence of missing
observations will produce an error.  If <code>use</code> is
<code>"complete.obs"</code> then missing values are handled by casewise
deletion (and if there are no complete cases, that gives an error).
<br />
<code>"na.or.complete"</code> is the same unless there are no complete
cases, that gives <code>NA</code>.
Finally, if <code>use</code> has the value <code>"pairwise.complete.obs"</code>
then the correlation or covariance between each pair of variables is
computed using all complete pairs of observations on those variables.
This can result in covariance or correlation matrices which are not positive
semi-definite, as well as <code>NA</code> entries if there are no complete
pairs for that pair of variables.   For <code>Cov</code> and <code>Var</code>,
<code>"pairwise.complete.obs"</code> only works with the <code>"pearson"</code>
method.
Note that (the equivalent of) <code>Var(double(0), use = *)</code> gives
<code>NA</code> for <code>use = "everything"</code> and <code>"na.or.complete"</code>,
and gives an error in the other cases.
</p>
<p>The denominator <code class="reqn">n - 1</code> is used which gives an unbiased estimator
of the (co)variance for i.i.d. observations.
These functions return <code><a href="base.html#topic+NA">NA</a></code> when there is only one
observation (whereas S-PLUS has been returning <code>NaN</code>), and
fail if <code>x</code> has length zero.
</p>
<p>For <code>Cor()</code>, if <code>method</code> is <code>"kendall"</code> or
<code>"spearman"</code>, Kendall's <code class="reqn">\tau</code> or Spearman's
<code class="reqn">\rho</code> statistic is used to estimate a rank-based measure of
association.  These are more robust and have been recommended if the
data do not necessarily come from a bivariate normal distribution.<br />
For <code>Cov()</code>, a non-Pearson method is unusual but available for
the sake of completeness.  Note that <code>"spearman"</code> basically
computes <code>Cor(R(x), R(y))</code> (or <code>Cov(., .)</code>) where <code>R(u)
  := rank(u, na.last = "keep")</code>. In the case of missing values, the
ranks are calculated depending on the value of <code>use</code>, either
based on complete observations, or based on pairwise completeness with
reranking for each pair.
</p>
<p>Scaling a covariance matrix into a correlation one can be achieved in
many ways, mathematically most appealing by multiplication with a
diagonal matrix from left and right, or more efficiently by using
<code><a href="base.html#topic+sweep">sweep</a>(.., FUN = "/")</code> twice.
</p>


<h3>Value</h3>

<p>For <code>r &lt;- Cor(*, use = "all.obs")</code>, it is now guaranteed that
<code>all(abs(r) &lt;= 1)</code>.
</p>


<h3>Note</h3>

<p>Some people have noted that the code for Kendall's tau is slow for
very large datasets (many more than 1000 cases).  It rarely makes
sense to do such a computation, but see function
<code><a href="pcaPP.html#topic+cor.fk">cor.fk</a></code> in package <a href="https://CRAN.R-project.org/package=pcaPP"><span class="pkg">pcaPP</span></a>.
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor.test">cor.test</a></code> for confidence intervals (and tests).
</p>
<p><code><a href="stats.html#topic+cov.wt">cov.wt</a></code> for <em>weighted</em> covariance computation.
</p>
<p><code><a href="#topic+Var">Var</a></code>, <code><a href="#topic+SD">SD</a></code> for variance and standard deviation (vectors).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Two simple vectors
Cor(1:10, 2:11) # == 1

## Correlation Matrix of Multivariate sample:
(Cl &lt;- Cor(longley))
## Graphical Correlation Matrix:
symnum(Cl) # highly correlated

## Spearman's rho  and  Kendall's tau
symnum(clS &lt;- Cor(longley, method = "spearman"))
symnum(clK &lt;- Cor(longley, method = "kendall"))
## How much do they differ?
i &lt;- lower.tri(Cl)
Cor(cbind(P = Cl[i], S = clS[i], K = clK[i]))


##--- Missing value treatment:
C1 &lt;- Cov(swiss)
range(eigen(C1, only.values = TRUE)$values) # 6.19        1921

## swM := "swiss" with  3 "missing"s :
swM &lt;- swiss
colnames(swM) &lt;- abbreviate(colnames(swiss), min=6)
swM[1,2] &lt;- swM[7,3] &lt;- swM[25,5] &lt;- NA # create 3 "missing"

## Consider all 5 "use" cases :
(C. &lt;- Cov(swM)) # use="everything"  quite a few NA's in cov.matrix
try(Cov(swM, use = "all")) # Error: missing obs...
C2 &lt;- Cov(swM, use = "complete")
stopifnot(identical(C2, Cov(swM, use = "na.or.complete")))
range(eigen(C2, only.values = TRUE)$values) # 6.46   1930
C3 &lt;- Cov(swM, use = "pairwise")
range(eigen(C3, only.values = TRUE)$values) # 6.19   1938

## Kendall's tau doesn't change much:
symnum(Rc &lt;- Cor(swM, method = "kendall", use = "complete"))
symnum(Rp &lt;- Cor(swM, method = "kendall", use = "pairwise"))
symnum(R. &lt;- Cor(swiss, method = "kendall"))

## "pairwise" is closer componentwise,
summary(abs(c(1 - Rp/R.)))
summary(abs(c(1 - Rc/R.)))

## but "complete" is closer in Eigen space:
EV &lt;- function(m) eigen(m, only.values=TRUE)$values
summary(abs(1 - EV(Rp)/EV(R.)) / abs(1 - EV(Rc)/EV(R.)))

</code></pre>

<hr>
<h2 id='CorPart'>Find the Correlations for a Set x of Variables With Set y Removed</h2><span id='topic+CorPart'></span>

<h3>Description</h3>

<p>A straightforward application of matrix algebra to remove the effect of the variables in the y set from the x set.
Input may be either a data matrix or a correlation matrix.  Variables in x and y are specified by location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CorPart(m, x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CorPart_+3A_m">m</code></td>
<td>
<p>a data or correlation matrix.</p>
</td></tr>
<tr><td><code id="CorPart_+3A_x">x</code></td>
<td>
<p>the variable numbers associated with the X set. </p>
</td></tr>
<tr><td><code id="CorPart_+3A_y">y</code></td>
<td>
<p>the variable numbers associated with the Y set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is sometimes convenient to partial the effect of a number of variables (e.g., sex, age, education)
out of the correlations of another set of variables.  This could be done laboriously by finding the residuals of
various multiple correlations, and then correlating these residuals.  The matrix algebra alternative is to do it directly.
</p>


<h3>Value</h3>

<p>The matrix of partial correlations.
</p>


<h3>Author(s)</h3>

<p> William Revelle </p>


<h3>References</h3>

<p> Revelle, W. <em>An introduction to psychometric theory with applications in R</em> Springer. <br /> (working draft available at  <a href="http://personality-project.org/r/book/">http://personality-project.org/r/book/</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># example from Bortz, J. (1993) Statistik fuer Sozialwissenschaftler, Springer, pp. 413

abstr &lt;- c(9,11,13,13,14,9,10,11,10,8,13,7,9,13,14)
coord &lt;- c(8,12,14,13,14,8,9,12,8,9,14,7,10,12,12)
age &lt;- c(6,8,9,9,10,7,8,9,8,7,10,6,10,10,9)

# calculate the correlation of abstr and coord, after without the effect of the age
CorPart(cbind(abstr, coord, age), 1:2, 3)

# by correlation matrix m
m &lt;- cor(cbind(abstr, coord, age))
CorPart(m, 1:2, 3)

# ... which would be the same as:
lm1 &lt;- lm(abstr ~ age)
lm2 &lt;- lm(coord ~ age)

cor(resid(lm1), resid(lm2))
</code></pre>

<hr>
<h2 id='CorPolychor'>Polychoric Correlation</h2><span id='topic+CorPolychor'></span><span id='topic+print.CorPolychor'></span>

<h3>Description</h3>

<p>Computes the polychoric correlation (and its standard error)
between two ordinal variables or from their contingency table, under the 
assumption that the ordinal variables dissect continuous latent variables that are bivariate normal. Either
the maximum-likelihood estimator or a (possibly much) quicker &ldquo;two-step&rdquo; approximation is available. For the ML
estimator, the estimates of the thresholds and the covariance matrix of the estimates are also available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CorPolychor(x, y, ML = FALSE, control = list(), std.err = FALSE, maxcor=.9999)

## S3 method for class 'CorPolychor'
print(x, digits = max(3, getOption("digits") - 3), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CorPolychor_+3A_x">x</code></td>
<td>
<p>a contingency table of counts or an ordered categorical variable; the latter can be numeric, logical, a factor,
or an ordered factor, but if a factor, its levels should be in proper order.</p>
</td></tr>
<tr><td><code id="CorPolychor_+3A_y">y</code></td>
<td>
<p>if <code>x</code> is a variable, a second ordered categorical variable.</p>
</td></tr>
<tr><td><code id="CorPolychor_+3A_ml">ML</code></td>
<td>
<p>if <code>TRUE</code>, compute the maximum-likelihood estimate; if <code>FALSE</code>, the default, compute a quicker
&ldquo;two-step&rdquo; approximation.</p>
</td></tr>
<tr><td><code id="CorPolychor_+3A_control">control</code></td>
<td>
<p>optional arguments to be passed to the <code>optim</code> function.</p>
</td></tr>
<tr><td><code id="CorPolychor_+3A_std.err">std.err</code></td>
<td>
<p>if <code>TRUE</code>, return the estimated variance of the correlation (for the two-step estimator) 
or the estimated covariance matrix (for the ML estimator) of the correlation and thresholds; the default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="CorPolychor_+3A_maxcor">maxcor</code></td>
<td>
<p>maximum absolute correlation (to insure numerical stability).</p>
</td></tr>
<tr><td><code id="CorPolychor_+3A_digits">digits</code></td>
<td>
<p>integer, determining the number of digits used to format the printed result
</p>
</td></tr>
<tr><td><code id="CorPolychor_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>std.err</code> is <code>TRUE</code>, 
returns an object of class <code>"polycor"</code> with the following components:
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>set to <code>"polychoric"</code>.</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>the CorPolychoric correlation.</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>the estimated variance of the correlation, or, for the ML estimate, 
the estimated covariance matrix of the correlation and thresholds.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the number of observations on which the correlation is based.</p>
</td></tr>
<tr><td><code>chisq</code></td>
<td>
<p>chi-square test for bivariate normality.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom for the test of bivariate normality.</p>
</td></tr>
<tr><td><code>ML</code></td>
<td>
<p><code>TRUE</code> for the ML estimate, <code>FALSE</code> for the two-step estimate.</p>
</td></tr>
</table>
<p>Othewise, returns the polychoric correlation.
</p>


<h3>Note</h3>

<p>This is a verbatim copy from polchor function in the package polycor.</p>


<h3>Author(s)</h3>

<p>John Fox <a href="mailto:jfox@mcmaster.ca">jfox@mcmaster.ca</a></p>


<h3>References</h3>

<p>Drasgow, F. (1986) 
CorPolychoric and polyserial correlations. 
Pp. 68&ndash;74 in S. Kotz and N. Johnson, eds.,
<em>The Encyclopedia of Statistics, Volume 7.</em> Wiley.
</p>
<p>Olsson, U. (1979)
Maximum likelihood estimation of the CorPolychoric correlation coefficient.
<em>Psychometrika</em> <b>44</b>, 443-460.
</p>


<h3>See Also</h3>

<p><code><a href="polycor.html#topic+hetcor">hetcor</a></code>, <code><a href="polycor.html#topic+polyserial">polyserial</a></code>, <code><a href="#topic+print.CorPolychor">print.CorPolychor</a></code>, <code><a href="stats.html#topic+optim">optim</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
z &lt;- RndPairs(1000, 0.6)
x &lt;- z[,1]
y &lt;- z[,2]

cor(x, y)                                  # sample correlation
x &lt;- cut(x, c(-Inf, .75, Inf))
y &lt;- cut(y, c(-Inf, -1, .5, 1.5, Inf))

CorPolychor(x, y)                          # 2-step estimate
CorPolychor(x, y, ML=TRUE, std.err=TRUE)   # ML estimate
</code></pre>

<hr>
<h2 id='CountCompCases'>Count Complete Cases
</h2><span id='topic+CountCompCases'></span><span id='topic+print.CountCompCases'></span>

<h3>Description</h3>

<p>Return for each variable of a data frame the number of missing values and the complete cases to be expected if this variable would be omitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CountCompCases(x)

## S3 method for class 'CountCompCases'
print(x, digits=1, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CountCompCases_+3A_x">x</code></td>
<td>
<p>a data.frame containg the data.</p>
</td></tr>
<tr><td><code id="CountCompCases_+3A_digits">digits</code></td>
<td>
<p>the number of digits to be used when printing the results.</p>
</td></tr>
<tr><td><code id="CountCompCases_+3A_...">...</code></td>
<td>
<p>the dots are not further used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with three elements. The first gives the number of rows, the second the number of complete cases for the whole data frame.
The third element <code>tab</code> contains the data for the single variables.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotMiss">PlotMiss</a></code>, <code><a href="#topic+CompleteColumns">CompleteColumns</a></code>, <code><a href="stats.html#topic+complete.cases">complete.cases</a></code>, <code><a href="base.html#topic+is.na">is.na</a></code>, <code><a href="stats.html#topic+na.omit">na.omit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CountCompCases(d.pizza)
</code></pre>

<hr>
<h2 id='CountWorkDays'>Count Work Days Between Two Dates
</h2><span id='topic+CountWorkDays'></span>

<h3>Description</h3>

<p>Returns the number of work days between two dates taking into account the provided holiday dates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CountWorkDays(from, to, holiday = NULL, nonworkdays = c("Sat", "Sun"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CountWorkDays_+3A_from">from</code></td>
<td>
<p>the initial dates
</p>
</td></tr>
<tr><td><code id="CountWorkDays_+3A_to">to</code></td>
<td>
<p>the final dates
</p>
</td></tr>
<tr><td><code id="CountWorkDays_+3A_holiday">holiday</code></td>
<td>
<p>a vector with dates to be excluded.
</p>
</td></tr>
<tr><td><code id="CountWorkDays_+3A_nonworkdays">nonworkdays</code></td>
<td>
<p>a character vector containing the abbreviations of the weekdays (as in <code>day.abb</code>) to be considered non work days. Default is <code>c("Sat","Sun")</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is vectorised so that multiple initial and final dates can be supplied. The dates are recycled, if their number are different
</p>


<h3>Value</h3>

<p>an integer vector
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+weekdays">weekdays</a></code>, <code>Date Functions</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>from &lt;- as.Date("2019-01-01") + rep(0, 10)
to &lt;- as.Date("2020-01-15") + seq(0, 9)

CountWorkDays(from, to)

x &lt;- seq(from[1], from[1]+11, "days")
data.frame(
  date = x, 
  day  = Format(x, fmt="ddd"))

CountWorkDays(from = min(x), to = max(x), holiday = c("2019-01-06", "2019-01-07"))
</code></pre>

<hr>
<h2 id='CourseData'>Get HWZ Datasets
</h2><span id='topic+CourseData'></span>

<h3>Description</h3>

<p>Wrapper for didactical datasets used in statistic courses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CourseData(name, url = NULL, header = TRUE, sep = ";", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CourseData_+3A_name">name</code></td>
<td>
<p>the name of the file, usually without extension.
</p>
</td></tr>
<tr><td><code id="CourseData_+3A_url">url</code></td>
<td>
<p>a url where the data reside, should have the form <code>"http://www.mysite.net/data/"</code>. Defaults to the data folder on my site.
</p>
</td></tr>
<tr><td><code id="CourseData_+3A_header">header</code></td>
<td>
<p>a logical value indicating whether the file contains the names of the variables as its first line. If missing, the value is determined from the file format: header is set to <code>TRUE</code> if and only if the first row contains one fewer field than the number of columns.
</p>
</td></tr>
<tr><td><code id="CourseData_+3A_sep">sep</code></td>
<td>
<p>the field separator character. Values on each line of the file are separated by this character. Default is - unlike in <code><a href="utils.html#topic+read.table">read.table</a></code> - &quot;;&quot; instead of 'white space'.
</p>
</td></tr>
<tr><td><code id="CourseData_+3A_...">...</code></td>
<td>
<p>the dots are sent to <code><a href="utils.html#topic+read.table">read.table</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> containing a representation of the data in the file.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+read.table">read.table</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
d.farm &lt;- CourseData("farmer")

## End(Not run)
</code></pre>

<hr>
<h2 id='CramerVonMisesTest'>Cramer-von Mises Test for Normality</h2><span id='topic+CramerVonMisesTest'></span>

<h3>Description</h3>

<p>Performs the Cramer-von Mises test for the composite hypothesis of normality,
see e.g. Thode (2002, Sec. 5.1.3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CramerVonMisesTest(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CramerVonMisesTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, the number of
which must be greater than 7. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cramer-von Mises test is an EDF omnibus test for the composite hypothesis of normality.
The test statistic is
</p>
<p style="text-align: center;"><code class="reqn">
W = \frac{1}{12 n} + \sum_{i=1}^{n} \left (p_{(i)} - \frac{2i-1}{2n} \right),
</code>
</p>

<p>where <code class="reqn">p_{(i)} = \Phi([x_{(i)} - \overline{x}]/s)</code>. Here,
<code class="reqn">\Phi</code> is the cumulative distribution function
of the standard normal distribution, and <code class="reqn">\overline{x}</code> and <code class="reqn">s</code>
are mean and standard deviation of the data values.
The p-value is computed from the modified statistic
<code class="reqn">Z=W (1.0 + 0.5/n)</code> according to Table 4.9 in
Stephens (1986).
</p>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Cramer-von Mises statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Cramer-von Mises normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Juergen Gross &lt;gross@statistik.uni-dortmund.de&gt;</p>


<h3>References</h3>

<p>Stephens, M.A. (1986) Tests based on EDF statistics In:
D'Agostino, R.B. and Stephens, M.A., eds.: <em>Goodness-of-Fit Techniques</em>.
Marcel Dekker, New York.
</p>
<p>Thode Jr., H.C. (2002) <em>Testing for  Normality</em> Marcel Dekker, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality.
<code><a href="#topic+AndersonDarlingTest">AndersonDarlingTest</a></code>, <code><a href="#topic+LillieTest">LillieTest</a></code>,
<code><a href="#topic+PearsonTest">PearsonTest</a></code>, <code><a href="#topic+ShapiroFranciaTest">ShapiroFranciaTest</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>CramerVonMisesTest(rnorm(100, mean = 5, sd = 3))
CramerVonMisesTest(runif(100, min = 2, max = 4))
</code></pre>

<hr>
<h2 id='CronbachAlpha'>Cronbach's Coefficient Alpha</h2><span id='topic+CronbachAlpha'></span>

<h3>Description</h3>

<p>Cronbach's alpha is a measure of internal consistency and often used for validating psychometric tests. It determines the internal consistency or average correlation of items in a survey instrument to gauge its reliability. This reduces to Kuder-Richardson formula 20 (KR-20) when the columns of the data matrix are dichotomous.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CronbachAlpha(x, conf.level = NA, cond = FALSE, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CronbachAlpha_+3A_x">x</code></td>
<td>
<p><code class="reqn">n \times m</code> matrix or dataframe with item responses, k subjects (in rows) m items (in columns).  </p>
</td></tr>
<tr><td><code id="CronbachAlpha_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated.</p>
</td></tr>
<tr><td><code id="CronbachAlpha_+3A_cond">cond</code></td>
<td>
<p>logical. If set to <code>TRUE</code>, alpha is additionally calculated for the dataset with each item left out. </p>
</td></tr>
<tr><td><code id="CronbachAlpha_+3A_na.rm">na.rm</code></td>
<td>

<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. If set to <code>TRUE</code> only the complete cases of the ratings will be used. Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either a numeric value or <br />
a named vector of 3 columns if confidence levels are required (estimate, lower and upper ci) or <br />
</p>
<p>a list containing the following components, if the argument <code>cond</code> is set to <code>TRUE</code>:
</p>
<table>
<tr><td><code>unconditional</code></td>
<td>
<p>Cronbach's Alpha, either the single value only or with confidence intervals</p>
</td></tr>
<tr><td><code>condCronbachAlpha</code></td>
<td>
<p>The alpha that would be realized if the item were excluded</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, based on code of Harold C. Doran</p>


<h3>References</h3>

<p>Cohen, J. (1960), A coefficient of agreement for nominal scales. <em>Educational and Psychological Measurement</em>, 20, 37-46.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CohenKappa">CohenKappa</a></code>, <code><a href="#topic+KappaM">KappaM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
tmp &lt;- data.frame(
  item1=sample(c(0,1), 20, replace=TRUE),
  item2=sample(c(0,1), 20, replace=TRUE),
  item3=sample(c(0,1), 20, replace=TRUE),
  item4=sample(c(0,1), 20, replace=TRUE),
  item5=sample(c(0,1), 20, replace=TRUE)
  )

CronbachAlpha(tmp[,1:4], cond=FALSE, conf.level=0.95)
CronbachAlpha(tmp[,1:4], cond=TRUE, conf.level=0.95)

CronbachAlpha(tmp[,1:4], cond=FALSE)
CronbachAlpha(tmp[,1:2], cond=TRUE, conf.level=0.95)

## Not run: 
# Calculate bootstrap confidence intervals for CronbachAlpha
library(boot)
cronbach.boot &lt;- function(data,x) {CronbachAlpha(data[x,])[[3]]}
res &lt;- boot(datafile, cronbach.boot, 1000)
quantile(res$t, c(0.025,0.975))   # two-sided bootstrapped confidence interval of Cronbach's alpha
boot.ci(res, type="bca")          # adjusted bootstrap percentile (BCa) confidence interval (better)

## End(Not run)
</code></pre>

<hr>
<h2 id='Cross'>Vector Cross Product</h2><span id='topic+Cross'></span>

<h3>Description</h3>

<p>Vector or cross product
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Cross(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cross_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="Cross_+3A_y">y</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the cross (or: vector) product of vectors in 3 dimensions.
In case of matrices it takes the first dimension of length 3 and
computes the cross product between corresponding columns or rows.
</p>
<p>The more general cross product of <code>n-1</code> vectors in n-dimensional
space is realized as <code>CrossN</code>.
</p>


<h3>Value</h3>

<p>3-dim. vector if <code>x</code> and <code>&lt;</code> are vectors, a matrix of
3-dim. vectors if <code>x</code> and <code>y</code> are matrices themselves.
</p>


<h3>Author(s)</h3>

<p>Hans W. Borchers &lt;hwborchers@googlemail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Dot">Dot</a></code>, <code><a href="#topic+CrossN">CrossN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Cross(c(1, 2, 3), c(4, 5, 6))  # -3  6 -3

# Triple product can be calculated as:
va &lt;- c(1, 2, 3)
vb &lt;- c(4, 3, 0)
vc &lt;- c(5, 1, 1)

Dot(va, Cross(vb, vc))
</code></pre>

<hr>
<h2 id='CrossN'>n-dimensional Vector Cross Product</h2><span id='topic+CrossN'></span>

<h3>Description</h3>

<p>Vector cross product of <code>n-1</code> vectors in n-dimensional space
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CrossN(A)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CrossN_+3A_a">A</code></td>
<td>
<p>matrix of size <code>(n-1) x n</code> where <code>n &gt;= 2</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rows of the matrix <code>A</code> are taken as<code>(n-1)</code> vectors in
<code>n</code>-dimensional space. The cross product generates a vector in this
space that is orthogonal to all these rows in <code>A</code> and its length is
the volume of the geometric hypercube spanned by the vectors.
</p>


<h3>Value</h3>

<p>a vector of length <code>n</code>
</p>


<h3>Note</h3>

<p>The &lsquo;scalar triple product&rsquo; in <code class="reqn">R^3</code> can be defined as
</p>
<p><code>spatproduct &lt;- function(a, b, c) Dot(a, CrossN(b, c))</code>
</p>
<p>It represents the volume of the parallelepiped spanned by the three vectors.
</p>


<h3>Author(s)</h3>

<p>Hans W. Borchers &lt;hwborchers@googlemail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Cross">Cross</a></code>, <code><a href="#topic+Dot">Dot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- matrix(c(1,0,0, 0,1,0), nrow=2, ncol=3, byrow=TRUE)
CrossN(A)  #=&gt; 0 0 1

x &lt;- c(1.0, 0.0, 0.0)
y &lt;- c(1.0, 0.5, 0.0)
z &lt;- c(0.0, 0.0, 1.0)
identical(Dot(x, CrossN(rbind(y, z))), det(rbind(x, y, z)))
</code></pre>

<hr>
<h2 id='Cstat'>C Statistic (Area Under the ROC Curve)
</h2><span id='topic+Cstat'></span><span id='topic+Cstat.glm'></span><span id='topic+Cstat.default'></span>

<h3>Description</h3>

<p>Calculate the C statistic, a measure of goodness of fit for binary outcomes in a logistic regression or any other classification model. The C statistic is equivalent to the area under the ROC-curve (Receiver Operating Characteristic).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cstat(x, ...)

## S3 method for class 'glm'
Cstat(x, ...)

## Default S3 method:
Cstat(x, resp, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Cstat_+3A_x">x</code></td>
<td>
<p>the logistic model for the glm interface or the predicted probabilities of the model for the default.
</p>
</td></tr>
<tr><td><code id="Cstat_+3A_resp">resp</code></td>
<td>
<p>the response variable (coded as c(0, 1))
</p>
</td></tr>
<tr><td><code id="Cstat_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to other functions. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Values for this measure range from 0.5 to 1.0, with higher values indicating better predictive models. A value of 0.5 indicates that the model is no better than chance at making a prediction of membership in a group and a value of 1.0 indicates that the model perfectly identifies those within a group and those not. Models are typically considered reasonable when the C-statistic is higher than 0.7 and strong when C exceeds 0.8.
</p>
<p>Confidence intervals for this measure can be calculated by bootstrap.
</p>


<h3>Value</h3>

<p>numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Hosmer D.W., Lemeshow S. (2000) Applied Logistic Regression (2nd Edition). New York, NY: <em>John Wiley &amp; Sons</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BrierScore">BrierScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.titanic = Untable(Titanic)
r.glm &lt;- glm(Survived ~ ., data=d.titanic, family=binomial)
Cstat(r.glm)

# default interface
Cstat(x = predict(r.glm, method="response"), 
      resp = model.response(model.frame(r.glm)))
  
      
# calculating bootstrap confidence intervals
FUN &lt;- function(d.set, i) {
   r.glm &lt;- glm(Survived ~ ., data=d.set[i,], family=binomial)
   Cstat(r.glm)
   }
   
## Not run: 
library(boot)
boot.res &lt;- boot(d.titanic, FUN, R=999) 

# the percentile confidence intervals
boot.ci(boot.res, type="perc")

## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 999 bootstrap replicates
##
## CALL : 
## boot.ci(boot.out = res, type = "perc")
## 
## Intervals : 
## Level     Percentile     
## 95%   ( 0.7308,  0.7808 )  
## Calculations and Intervals on Original Scale

## End(Not run)   </code></pre>

<hr>
<h2 id='CutAge'>Create a Factor Variable by Cutting an Age Variable
</h2><span id='topic+CutAge'></span>

<h3>Description</h3>

<p>Dividing the range of an age variable <code>x</code> into intervals is a frequent task. The commonly used function <code><a href="base.html#topic+cut">cut</a></code> has unfavourable default values for this.
<code>CutAge()</code> is a convenient wrapper for cutting age variables in groups 
of e.g. 10 years with more suitable defaults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CutAge(x, from = 0, to = 90, by = 10, right = FALSE, ordered_result = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CutAge_+3A_x">x</code></td>
<td>
<p> continuous variable. </p>
</td></tr>
<tr><td><code id="CutAge_+3A_from">from</code>, <code id="CutAge_+3A_to">to</code></td>
<td>
<p>the starting and (maximal) end values of the sequence.
</p>
</td></tr>
<tr><td><code id="CutAge_+3A_by">by</code></td>
<td>
<p>number: increment of the sequence. Default is 10, alternatives could be 5 or 20.
</p>
</td></tr>
<tr><td><code id="CutAge_+3A_right">right</code></td>
<td>
<p>logical, indicating if the intervals should be closed on the right (and open on the left) or vice versa. Default is <code>FALSE</code> - unlike in <code><a href="base.html#topic+cut">cut</a></code>!
</p>
</td></tr>
<tr><td><code id="CutAge_+3A_ordered_result">ordered_result</code></td>
<td>
	
<p>logical: should the result be an ordered factor? Default is <code>TRUE</code> - unlike in <code><a href="base.html#topic+cut">cut</a></code>!
</p>
</td></tr>
<tr><td><code id="CutAge_+3A_...">...</code></td>
<td>
<p>the dots are passed on to the underlying function <code><a href="base.html#topic+cut">cut</a>()</code>. Use these for e.g. change the labels. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A factor is returned, unless labels = FALSE which results in an integer vector of level codes.
</p>
<p>Values which fall outside the range of breaks are coded as <code>NA</code>, as are <code>NaN</code> and <code>NA</code> values.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code>, <code><a href="base.html#topic+seq">seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Desc(CutAge(sample(100, 100)))
</code></pre>

<hr>
<h2 id='CutQ'>Create a Factor Variable Using the Quantiles of a Continuous Variable</h2><span id='topic+CutQ'></span>

<h3>Description</h3>

<p>Create a factor variable using the quantiles of a continous variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CutQ(x, breaks = quantile(x, seq(0, 1, by = 0.25), na.rm = TRUE), 
     labels = NULL, na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CutQ_+3A_x">x</code></td>
<td>
<p> continous variable. </p>
</td></tr>
<tr><td><code id="CutQ_+3A_breaks">breaks</code></td>
<td>
<p> the breaks for creating groups. By default the quartiles will be used, say <code>quantile</code> <code>seq(0, 1, by = 0.25)</code> quantiles. See <code><a href="stats.html#topic+quantile">quantile</a></code> for details. If breaks is given as a single integer it is interpreted as the intended number of groups, e.g. <code>breaks=10</code> will return x cut in deciles.</p>
</td></tr>
<tr><td><code id="CutQ_+3A_labels">labels</code></td>
<td>
<p>labels for the levels of the resulting category. By default, labels are defined as <code>Q1</code>, <code>Q2</code> to the length of breaks - 1. The parameter ist passed to <code><a href="base.html#topic+cut">cut</a></code>, so if <code>labels</code> are set to <code>FALSE</code>, simple integer codes are returned instead of a factor.
</p>
</td></tr>
<tr><td><code id="CutQ_+3A_na.rm">na.rm</code></td>
<td>
<p> Boolean indicating whether missing values should be
removed when computing quantiles.  Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="CutQ_+3A_...">...</code></td>
<td>
<p> Optional arguments passed to <code><a href="base.html#topic+cut">cut</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses <code><a href="stats.html#topic+quantile">quantile</a></code> to obtain the specified
quantiles of <code>x</code>, then calls <code><a href="base.html#topic+cut">cut</a></code> to create a factor
variable using the intervals specified by these quantiles.
</p>
<p>It properly handles cases where more than one quantile obtains the
same value, as in the second example below.  Note that in this case,
there will be fewer generated factor levels than the specified number
of quantile intervals.
</p>


<h3>Value</h3>

<p>Factor variable with one level for each quantile interval given by <code>q</code>.
</p>


<h3>Author(s)</h3>

<p>Gregory R. Warnes &lt;greg@warnes.net&gt;, some slight modifications Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+cut">cut</a></code>, <code><a href="stats.html#topic+quantile">quantile</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># create example data

x &lt;- rnorm(1000)

# cut into quartiles
quartiles &lt;- CutQ(x)
table(quartiles)

# cut into deciles
deciles &lt;- CutQ(x, breaks=10, labels=NULL)
table(deciles)

# show handling of 'tied' quantiles.
x &lt;- round(x)  # discretize to create ties
stem(x)        # display the ties
deciles &lt;- CutQ(x, breaks=10)

table(deciles) # note that there are only 5 groups (not 10) 
               # due to duplicates
</code></pre>

<hr>
<h2 id='d.countries'>ISO 3166-1 Country Codes
</h2><span id='topic+d.countries'></span>

<h3>Description</h3>

<p>Country codes published by the International Organization for Standardization (ISO) define codes for the names of countries, dependent territories, and special areas of geographical interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("d.countries")</code></pre>


<h3>Format</h3>

<p>A data frame with 249 observations on the following 4 variables.
</p>

<dl>
<dt><code>name</code></dt><dd><p>a character vector, the name of the country.</p>
</dd>
<dt><code>a2</code></dt><dd><p>a character vector, two-letter country codes (aka alpha-2) which are the most widely used of the three, and used most prominently for the Internet's country code top-level domains (with a few exceptions).</p>
</dd>
<dt><code>a3</code></dt><dd><p>a character vector, three-letter country codes (aka alpha-3) which allow a better visual association between the codes and the country names than the alpha-2 codes.</p>
</dd>
<dt><code>code</code></dt><dd><p>a numeric vector, three-digit country codes which are identical to those developed and maintained by the United Nations Statistics Division, with the advantage of script (writing system) independence, and hence useful for people or systems using non-Latin scripts.</p>
</dd>
<dt><code>region</code></dt><dd><p>the region of the country. One of &quot;East Asia &amp; Pacific&quot; (35), &quot;Europe &amp; Central Asia&quot; (52), &quot;Latin America &amp; Caribbean&quot; (41),
&quot;Middle East &amp; North Africa&quot; (20), &quot;North America&quot; (3), &quot;South Asia&quot; (8), &quot;Sub-Saharan Africa&quot; (47)
</p>
</dd>
<dt><code>pop2012</code></dt><dd><p>the population in 2012</p>
</dd>
<dt><code>gcpi2012</code></dt><dd><p>the gross national income (per capita) in dollars per country in 2012.</p>
</dd>
<dt><code>latitude</code></dt><dd><p>geographic coordinate that specifies the north–south position of a point on the Earth's surface. Latitude is an angle (defined below) which ranges from 0° at the Equator to 90° (North or South) at the poles. </p>
</dd>
<dt><code>longitude</code></dt><dd><p>geographic coordinate that specifies the east–west position of a point on the Earth's surface, or the surface of a celestial body</p>
</dd>
</dl>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/ISO_3166-1">https://en.wikipedia.org/wiki/ISO_3166-1</a><br />
<a href="https://datacatalog.worldbank.org/search/dataset/0037652">https://datacatalog.worldbank.org/search/dataset/0037652</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(d.countries)
</code></pre>

<hr>
<h2 id='d.diamonds'> Data diamonds
</h2><span id='topic+d.diamonds'></span>

<h3>Description</h3>

<p>As I suppose, an artificial dataset 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(d.diamonds)</code></pre>


<h3>Format</h3>

<p>A data frame with 440 observations on the following 10 variables.
</p>

<dl>
<dt><code>index</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>carat</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>colour</code></dt><dd><p>a factor with levels <code>D</code> <code>E</code> <code>F</code> <code>G</code> <code>H</code> <code>I</code> <code>J</code> <code>K</code> <code>L</code></p>
</dd>
<dt><code>clarity</code></dt><dd><p>an ordered factor with levels <code>I2</code> &lt; <code>I1</code> &lt; <code>SI3</code> &lt; <code>SI2</code> &lt; <code>SI1</code> &lt; <code>VS2</code> &lt; <code>VS1</code> &lt; <code>VVS2</code> &lt; <code>VVS1</code></p>
</dd>
<dt><code>cut</code></dt><dd><p>an ordered factor with levels <code>F</code> &lt; <code>G</code> &lt; <code>V</code> &lt; <code>X</code> &lt; <code>I</code></p>
</dd>
<dt><code>certification</code></dt><dd><p>a factor with levels <code>AGS</code> <code>DOW</code> <code>EGL</code> <code>GIA</code> <code>IGI</code></p>
</dd>
<dt><code>polish</code></dt><dd><p>an ordered factor with levels <code>F</code> &lt; <code>G</code> &lt; <code>V</code> &lt; <code>X</code> &lt; <code>I</code></p>
</dd>
<dt><code>symmetry</code></dt><dd><p>an ordered factor with levels <code>F</code> &lt; <code>G</code> &lt; <code>V</code> &lt; <code>X</code> &lt; <code>I</code></p>
</dd>
<dt><code>price</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>wholesaler</code></dt><dd><p>a factor with levels <code>A</code> <code>B</code> <code>C</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>P Poor
F Fair
G Good
V Very good
X Excellent
I Ideal
</p>


<h3>Source</h3>

<p>somewhere from the net... </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(d.diamonds)
str(d.diamonds)
</code></pre>

<hr>
<h2 id='d.periodic'>Periodic Table of Elements
</h2><span id='topic+d.periodic'></span>

<h3>Description</h3>

<p>This data.frame contains the most important properties of the periodic table of the elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(d.periodic)</code></pre>


<h3>Format</h3>

<p>A data frame with 110 observations on the following 24 variables.
</p>

<dl>
<dt><code>symbol</code></dt><dd><p>symbol of an element.</p>
</dd>
<dt><code>nr</code></dt><dd><p>atomic number of an atomic symbol. </p>
</dd>
<dt><code>name</code></dt><dd><p>name of an element.</p>
</dd>
<dt><code>group</code></dt><dd><p>group of an element. Possible results are: Alkali Earth, Alkali Met., Halogen, Metal, Noble Gas, Non-Metal, Rare Earth and Trans. Met. </p>
</dd>
<dt><code>weight</code></dt><dd><p>atomic weight of an element. The values are based upon carbon-12. () indicates the most stable or best known isotope.</p>
</dd>
<dt><code>meltpt</code></dt><dd><p>melting point of an element in [K].</p>
</dd>
<dt><code>boilpt</code></dt><dd><p>boiling point of an element in Kelvin [K].</p>
</dd>
<dt><code>dens</code></dt><dd><p>density of an element in [g/cm3] at 300K and 1 atm.</p>
</dd>
<dt><code>elconf</code></dt><dd><p>electron configuration of an element.</p>
</dd>
<dt><code>oxstat</code></dt><dd><p>oxidation states of an element. The most stable is indicated by a &quot;!&quot;.</p>
</dd>
<dt><code>struct</code></dt><dd><p>crystal structure of an element. Possible results are: Cubic, Cubic body centered, Cubic face centered, Hexagonal, Monoclinic, Orthorhombic, Rhombohedral, Tetragonal</p>
</dd>
<dt><code>covrad</code></dt><dd><p>covalent radius of an element in Angstroem [A].</p>
</dd>
<dt><code>arad</code></dt><dd><p>atomic radius of an element in Angstroem.</p>
</dd>
<dt><code>avol</code></dt><dd><p>atomic volume of an element in [cm3/mol].</p>
</dd>
<dt><code>spheat</code></dt><dd><p>specific heat of an element in [J/(g K)].</p>
</dd>
<dt><code>eneg</code></dt><dd><p>electronegativity (Pauling's) of an element.</p>
</dd>
<dt><code>fusheat</code></dt><dd><p>heat of fusion of an element in [kJ/mol].</p>
</dd>
<dt><code>vapheat</code></dt><dd><p>heat of vaporization of an element in [kJ/mol].</p>
</dd>
<dt><code>elcond</code></dt><dd><p>electrical conductivity of an element in [1/(Ohm cm].</p>
</dd>
<dt><code>thermcond</code></dt><dd><p>thermal conductivity of an element in [W/(cm K)].</p>
</dd>
<dt><code>ionpot1</code></dt><dd><p>first ionization potential of an element in [V].</p>
</dd>
<dt><code>ionpot2</code></dt><dd><p>second ionization potential of an element in [V].</p>
</dd>
<dt><code>ionpot3</code></dt><dd><p>third ionization potential of an element in [V].</p>
</dd>
<dt><code>discyear</code></dt><dd><p>year of discovery of the element</p>
</dd>
</dl>



<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Periodic_table">https://en.wikipedia.org/wiki/Periodic_table</a></p>

<hr>
<h2 id='d.pizza'>Data pizza
</h2><span id='topic+d.pizza'></span>

<h3>Description</h3>

<p>An artificial dataset inspired by a similar dataset pizza.sav in <em>Arbeitsbuch zur deskriptiven und induktiven Statistik</em> by Toutenburg et.al.<br />
The dataset contains data of a pizza delivery service in London, delivering pizzas to three areas. Every record defines one order/delivery and the according properties. A pizza is supposed to taste good, if its temperature is high enough, say 45 Celsius. So it might be interesting for the pizza delivery service to minimize the delivery time.<br />
The dataset is designed to be as evil as possible. As far as the description is concerned, it should pose the same difficulties that we have to deal with in everyday life. It contains the most used datatypes as numerics, factors, ordered factors, integers, logicals and a date. NAs are scattered everywhere partly systematically, partly randomly (except in the index).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(d.pizza)</code></pre>


<h3>Format</h3>

<p>A data frame with 1209 observations on the following 17 variables.
</p>

<dl>
<dt><code>index</code></dt><dd><p>a numeric vector, indexing the records (no missings here).</p>
</dd>
<dt><code>date</code></dt><dd><p>Date, the delivery date</p>
</dd>
<dt><code>week</code></dt><dd><p>integer, the weeknumber</p>
</dd>
<dt><code>weekday</code></dt><dd><p>integer, the weekday</p>
</dd>
<dt><code>area</code></dt><dd><p>factor, the three London districts: <code>Brent</code>, <code>Camden</code>, <code>Westminster</code> </p>
</dd>
<dt><code>count</code></dt><dd><p>integer, the number of pizzas delivered</p>
</dd>
<dt><code>rabate</code></dt><dd><p>logical, <code>TRUE</code> if a rabate has been given </p>
</dd>
<dt><code>price</code></dt><dd><p>numeric, the total price of delivered pizza(s) </p>
</dd>
<dt><code>operator</code></dt><dd><p>a factor with levels <code>Allanah</code> <code>Maria</code> <code>Rhonda</code></p>
</dd>
<dt><code>driver</code></dt><dd><p>a factor with levels <code>Carpenter</code> <code>Carter</code> <code>Taylor</code> <code>Butcher</code> <code>Hunter</code> <code>Miller</code> <code>Farmer</code></p>
</dd>
<dt><code>delivery_min</code></dt><dd><p>numeric, the delivery time in minutes (decimal)</p>
</dd>
<dt><code>temperature</code></dt><dd><p>numeric, the temperature of the pizza in degrees Celsius when delivered to the customer </p>
</dd>
<dt><code>wine_ordered</code></dt><dd><p>integer, 1 if wine was ordered, 0 if not</p>
</dd>
<dt><code>wine_delivered</code></dt><dd><p>integer, 1 if wine was delivered, 0 if not</p>
</dd>
<dt><code>wrongpizza</code></dt><dd><p>logical, <code>TRUE</code> if a wrong pizza was delivered </p>
</dd>
<dt><code>quality</code></dt><dd><p>ordered factor with levels <code>low</code> &lt; <code>medium</code> &lt; <code>high</code>, defining the quality of the pizza when delivered</p>
</dd>
</dl>



<h3>Details</h3>

<p>The dataset contains NAs randomly scattered.
</p>


<h3>References</h3>

<p>Toutenburg H, Schomaker M, Wissmann M, Heumann C (2009): <em>Arbeitsbuch zur deskriptiven und induktiven Statistik</em> Springer, Berlin Heidelberg
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(d.pizza)
head(d.pizza)

Desc(d.pizza)
</code></pre>

<hr>
<h2 id='d.whisky'>Classification of Scotch Single Malts
</h2><span id='topic+d.whisky'></span>

<h3>Description</h3>

<p>86 malt whiskies are scored between 0-4 for 12 different taste categories including sweetness, smoky, nutty etc. Additionally, coordinates of distilleries allow us to obtain pairwise distance information. Using a combination of these variables it is possible to look for correlations between particular attributes of taste and physical location, for example does a shared local resource have a significant effect on nearby whiskies.<br />
By using correlation analysis it may be possible to provide whisky recommendations based upon an individual's particular preferences.
By computing the Pearson correlation coefficient and specifying a threshold value between 0 and 1, we can establish an adjacency matrix where each node is a malt whisky and an edge represents a level of similarity above the threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("d.whisky")</code></pre>


<h3>Format</h3>

<p>A data frame with 86 observations on the following 16 variables.
</p>

<dl>
<dt><code>distillery</code></dt><dd><p>a character <code>Aberfeldy</code>, <code>Aberlour</code>, <code>AnCnoc</code>, <code>Ardbeg</code>, ... </p>
</dd>
<dt><code>brand</code></dt><dd><p>a grouping factor to separate the better known distilleries (<code>A</code>) from the lesser known ones (<code>B</code>). </p>
</dd>
<dt><code>region</code></dt><dd><p>a factor with levels <code>campbeltown</code>, <code>highland</code>, <code>islands</code>, <code>islay</code>, <code>lowland</code>, <code>speyside</code>.</p>
</dd>
<dt><code>body</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>sweetness</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>smoky</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>medicinal</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>tobacco</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>honey</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>spicy</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>winey</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>nutty</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>malty</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>fruity</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>floral</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>postcode</code></dt><dd><p>a character <code> AB30 1YE</code>, <code> AB35 5TB</code>, ... </p>
</dd>
<dt><code>latitude</code></dt><dd><p>a numeric vector, coordinate pairs of distilleries.</p>
</dd>
<dt><code>longitude</code></dt><dd><p>a numeric vector, coordinate pairs of distilleries.</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://www.mathstat.strath.ac.uk/outreach/nessie/nessie_whisky.html</p>


<h3>References</h3>

<p>http://www.mathstat.strath.ac.uk/outreach/nessie/index.html</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(d.whisky)

opar &lt;- par(mfrow=c(3,3), cex.main=1.8)
for(i in 1:9)
  PlotPolar(d.whisky[i, 4:15], rlim=4, type="l", col=hecru, lwd=2, fill=SetAlpha(hecru, 0.4),
            panel.first=PolarGrid(
              ntheta=ncol(d.whisky[i, 2:13]), nr = NA, col="grey",
              lty="dotted", las=1, cex=1.4, alabels=StrCap(colnames(d.whisky[i, 3:14])),
              lblradians=TRUE),
            main=d.whisky[i, "distillery"])


par(mfrow=c(3,3), cex.main=1.8, xpd=NA)
id &lt;- d.whisky$distillery %in% c("Ardbeg","Caol Ila","Cragganmore","Lagavulin","Laphroig",
                                   "Macallan","Mortlach","Talisker","Tobermory")
PlotFaces(d.whisky[id, 4:15], nr=3, nc=3, col=hecru, scale=TRUE, fill=TRUE,
          labels=d.whisky$distillery[id])

par(opar)
</code></pre>

<hr>
<h2 id='Datasets+20for+20Simulation'>Datasets for Probabilistic Simulation
</h2><span id='topic+cards'></span><span id='topic+tarot'></span><span id='topic+roulette'></span>

<h3>Description</h3>

<p>For performing elementary probability calculations in introductory statistic courses, we might want to simulate random games.
The dataset <code>roulette</code> contains the standard sample space for one spin on a roulette wheel.
<code>cards</code> contains the standard set of 52 playing cards in four colours (without Jokers). <code>tarot</code> does the same with a classic tarot deck.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cards
tarot
roulette
</code></pre>


<h3>Value</h3>

<p><code>cards</code> is a <code>data.frame</code> with three columns named <code>card</code>, <code>rank</code> and <code>suit</code>
</p>
<p><code>tarot</code> is a <code>data.frame</code> with four columns named <code>card</code>, <code>rank</code>, <code>suit</code> and <code>desc</code>
</p>
<p><code>roulette</code> is a <code>data.frame</code> with seven columns named <code>num</code> and <code>col</code>, <code>parity</code>, <code>highlow</code>, <code>dozens</code>, <code>column</code>, <code>pocketrange</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Sample">Sample</a></code>, <code><a href="base.html#topic+sample">sample</a>()</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>head(cards)
head(tarot)
head(roulette)

# drawing 5 cards
sample(cards$card, 5)

# drawing 5 cards with jokers
sample(c(cards$card, rep("Joker", 3)), 5)

# spin the wheel by using the DescTools::Sample() for sampling
# rows from a data frame
Sample(roulette, size=1)

# simulate the evening in Las Vegas with 10 games
Sample(roulette, 10, replace=TRUE)
</code></pre>

<hr>
<h2 id='Date+20Functions'>Basic Date Functions
</h2><span id='topic+Year'></span><span id='topic+Quarter'></span><span id='topic+Month'></span><span id='topic+Week'></span><span id='topic+Day'></span><span id='topic+Day+3C-'></span><span id='topic+Weekday'></span><span id='topic+YearDay'></span><span id='topic+YearMonth'></span><span id='topic+IsWeekend'></span><span id='topic+IsLeapYear'></span><span id='topic+Hour'></span><span id='topic+Minute'></span><span id='topic+Second'></span><span id='topic+Now'></span><span id='topic+Today'></span><span id='topic+DiffDays360'></span><span id='topic+LastDayOfMonth'></span><span id='topic+Timezone'></span><span id='topic+YearDays'></span><span id='topic+MonthDays'></span><span id='topic+HmsToMinute'></span><span id='topic+Month.ym'></span><span id='topic+Year.ym'></span>

<h3>Description</h3>

<p>Some more date functions for making daily life a bit easier. The first ones extract a specific part of a given date, others check some conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Year(x)
Quarter(x)
Month(x, fmt = c("m", "mm", "mmm"), lang = DescToolsOptions("lang"),
      stringsAsFactors = TRUE)
Week(x, method = c("iso", "us"))
Day(x)
Weekday(x, fmt = c("d", "dd", "ddd"), lang = DescToolsOptions("lang"),
        stringsAsFactors = TRUE)
YearDay(x)
YearMonth(x)

Day(x) &lt;- value

IsWeekend(x)
IsLeapYear(x)

Hour(x)
Minute(x)
Second(x)
Timezone(x)
HmsToMinute(x)

Now()
Today()

DiffDays360(start_d, end_d, method = c("eu", "us"))
LastDayOfMonth(x)
YearDays(x)
MonthDays(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Date+2B20Functions_+3A_x">x</code></td>
<td>
<p>the date to be evaluated.
</p>
</td></tr>
<tr><td><code id="Date+2B20Functions_+3A_fmt">fmt</code></td>
<td>
<p>format string, defines how the month or the weekday are to be formatted. Defaults to <code>"m"</code>, resp. <code>"d"</code>. Is ignored for other functions.
</p>
</td></tr>
<tr><td><code id="Date+2B20Functions_+3A_value">value</code></td>
<td>
<p>new value
</p>
</td></tr>
<tr><td><code id="Date+2B20Functions_+3A_lang">lang</code></td>
<td>
<p>optional value setting the language for the months and daynames. Can be either <code>"local"</code> for current locale or <code>"engl"</code> for english. If left to <code>NULL</code>, the option <code>"lang"</code> will be searched for and if not found <code>"local"</code> will be taken as default.
</p>
</td></tr>
<tr><td><code id="Date+2B20Functions_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>logical. Defines if the result should be coerced to a factor, using the local definitions as levels.
The result would be an ordered factor. Default is TRUE.
</p>
</td></tr>
<tr><td><code id="Date+2B20Functions_+3A_start_d">start_d</code>, <code id="Date+2B20Functions_+3A_end_d">end_d</code></td>
<td>
<p>the start, resp. end date for <code>DiffDays360</code>.
</p>
</td></tr>
<tr><td><code id="Date+2B20Functions_+3A_method">method</code></td>
<td>
<p>one out of <code>"eu", "us"</code>, setting either European or US-Method calculation mode. Default is <code>"eu"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are mainly convenience wrappers for the painful <code>format()</code> and its strange codes...<br />
Based on the requested time component, the output is as follows:<br /><br />
<code>Year</code> returns the year of the input date in yyyy format or a yearmonth yyyymm.<br />
<code>Quarter</code> returns the quarter of the year (1 to 4) for the input date. <br />
<code>Month</code> returns the month of the year (1 to 12) for the input date or for a yearmonth yyyymm. <br />
<code>Week</code> returns the week of the year for the input date (0 to 53), as defined in ISO8601. <br />
<code>Weekday</code> returns the week day of the input date. (1 - Monday, 2 - Tuesday, ... 7 - Sunday). (Names and abbreviations are either english or in the current locale!)<br />
<code>YearDay</code> returns the day of the year numbering (1 to 366). <br />
<code>Day</code> returns the day of the month (1 to 31). <br />
<code>YearMonth</code> returns the yearmonth representation (yyyymm) of a date as long integer. <br />
<code>Hour</code>, <code>Minute</code>, <code>Second</code>, <code>Timezone</code> return the hour, minute, second or timezone from a POSIXlt object. <br />
<code>HmsToMinute</code> converts the time parts of a POSIXlt object to minutes.<br />
<code>Today</code>, <code>Now</code> return the current date, resp. the current date and time.<br />
</p>
<p><code>IsWeekend</code> returns <code>TRUE</code>, if the date x falls on a weekend. <br />
<code>IsLeapYear</code> returns <code>TRUE</code>, if the year of the date x is a leap year. <br />
</p>
<p>The day can not only be extracted, but as well be defined. See examples.
</p>
<p><code>DiffDays360</code> calculates the difference between 2 dates using the 360-days convention.<br />
<code>LastDayOfMonth</code> returns the last day of the month of the given date(s).
<code>YearDays</code> returns the total number of days of the given date(s).
<code>MonthDays</code> returns the numer of days of the month of the given date(s).
</p>
<p>The language in Weekday and Moth can be set with an option as well. The functions will check for an existing option named &quot;lang&quot; and take this value if it exists. So simply set option(lang=&quot;engl&quot;) if the results should always be reported in English.
</p>


<h3>Value</h3>

<p>a vector of the same dimension as x, consisting of either numeric values or characters depending on the function used.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strptime">strptime</a></code>, <code><a href="base.html#topic+DateTimeClasses">DateTimeClasses</a></code>, <code><a href="base.html#topic+as.POSIXlt">as.POSIXlt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- Today()    # the same as Sys.Date() but maybe easier to remember..

Year(x)
Quarter(x)

Month(x)
Month(x, fmt = "mm", lang="engl")
Month(x, fmt = "mm", lang="local")
Month(x, fmt = "mmm", lang="engl")
Month(x, fmt = "mmm", lang="local")

Week(x)

Day(x)
Day(x) &lt;- 20
x

Weekday(x)
Weekday(x, fmt = "dd", lang="engl")
Weekday(x, fmt = "dd", lang="local")
Weekday(x, fmt = "ddd", lang="engl")
Weekday(x, fmt = "ddd", lang="local")

YearDay(x)

IsWeekend(x)

IsLeapYear(x)

# let's generate a time sequence by weeks
Month(seq(from=as.Date(Sys.Date()), to=Sys.Date()+150, by="weeks"), fmt="mm")

LastDayOfMonth(as.Date(c("2014-10-12","2013-01-31","2011-12-05")))

</code></pre>

<hr>
<h2 id='day.name'>Build-in Constants Extension
</h2><span id='topic+day.name'></span><span id='topic+day.abb'></span>

<h3>Description</h3>

<p>There's a small number of built-in constants in <code>R</code>. We have <code><a href="base.html#topic+month.name">month.name</a></code> and <code><a href="base.html#topic+month.abb">month.abb</a></code> but nothing similar for weekdays. Here it is.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>day.name
day.abb
</code></pre>


<h3>Details</h3>

<p>The following constants are available in DescTools:
</p>

<ul>
<li> <p><code>day.name</code>: the English names for the day of the week (Monday, Tuesday,   Wednesday, Thursday,  Friday,   Saturday, Sunday);
</p>
</li>
<li> <p><code>day.abb</code>: the three-letter abbreviations for the
English day names (Mon, Tue, Wed, Thu, Fri, Sat, Sun);
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="base.html#topic+month.name">month.name</a></code>, <code><a href="base.html#topic+month.abb">month.abb</a></code>
</p>

<hr>
<h2 id='DegToRad'>Convert Degrees to Radians and Vice Versa
</h2><span id='topic+DegToRad'></span><span id='topic+RadToDeg'></span>

<h3>Description</h3>

<p>Convert degrees to radians (and back again).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DegToRad(deg)
RadToDeg(rad)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DegToRad_+3A_deg">deg</code></td>
<td>
<p>a vector of angles in degrees.
</p>
</td></tr>
<tr><td><code id="DegToRad_+3A_rad">rad</code></td>
<td>
<p>a vector of angles in radians.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>DegToRad returns a vector of the same length as <code>deg</code> with the angles in radians.<br />
RadToDeg returns a vector of the same length as <code>rad</code> with the angles in degrees.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>DegToRad(c(90,180,270))
RadToDeg( c(0.5,1,2) * pi)
</code></pre>

<hr>
<h2 id='Depreciation'>Several Methods of Depreciation of an Asset
</h2><span id='topic+SLN'></span><span id='topic+SYD'></span><span id='topic+DB'></span><span id='topic+Depreciation'></span>

<h3>Description</h3>

<p>Return the depreciation of an asset for a specified period using different methods. <code>SLN</code> returns the straight-line depreciation
<code>DB</code> uses the fixed-declining balance method
and <code>SYD</code> returns the sum-of-years' digits depreciation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLN(cost, salvage, life)
DB(cost, salvage, life, period = 1:life)
SYD(cost, salvage, life, period = 1:life)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Depreciation_+3A_cost">cost</code></td>
<td>
<p>initial cost of the asset.
</p>
</td></tr>
<tr><td><code id="Depreciation_+3A_salvage">salvage</code></td>
<td>
<p>value at the end of the depreciation (sometimes called the salvage value of the asset).
</p>
</td></tr>
<tr><td><code id="Depreciation_+3A_life">life</code></td>
<td>
<p>number of periods over which the asset is depreciated (sometimes called the useful life of the asset).
</p>
</td></tr>
<tr><td><code id="Depreciation_+3A_period">period</code></td>
<td>
<p>period for which you want to calculate the depreciation. Period must use the same units as life.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>val
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NPV">NPV</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># depreciation allowance for each year
SLN(cost = 50000, salvage = 10000, life = 5)
DB(cost = 50000, salvage = 10000, life = 5)

50000 - c(0, cumsum(SYD(cost = 50000, salvage = 10000, life = 5)))


</code></pre>

<hr>
<h2 id='Desc'>Describe Data

</h2><span id='topic+Desc'></span><span id='topic+Desc.default'></span><span id='topic+Desc.data.frame'></span><span id='topic+Desc.list'></span><span id='topic+Desc.formula'></span><span id='topic+Desc.numeric'></span><span id='topic+Desc.integer'></span><span id='topic+Desc.factor'></span><span id='topic+Desc.ordered'></span><span id='topic+Desc.character'></span><span id='topic+Desc.logical'></span><span id='topic+Desc.Date'></span><span id='topic+Desc.table'></span><span id='topic+print.Desc'></span><span id='topic+plot.Desc'></span>

<h3>Description</h3>

<p>Produce summaries of various types of variables. Calculate descriptive statistics for x and use Word as reporting tool for the numeric results and for descriptive plots.
The appropriate statistics are chosen depending on the class of x.
The general intention is to simplify the description process for lazy typers and return a quick, but rich summary.
</p>
<p>A 2-dimensional table will be described with it's relative frequencies, a short summary containing the total cases,
the dimensions of the table, chi-square tests and some association measures as phi-coefficient, contingency coefficient and Cramer's V. <br /> Tables with higher dimensions will simply be printed as flat table, with marginal sums for the first and for the last dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Desc(x, ..., main = NULL, plotit = NULL, wrd = NULL)

## Default S3 method:
Desc(x, main = NULL, maxrows = NULL, ord = NULL,
     conf.level = 0.95, verbose = 2, rfrq = "111", margins = c(1,2),
     dprobs = NULL, mprobs = NULL, plotit = NULL, sep = NULL, digits = NULL, ...)

## S3 method for class 'data.frame'
Desc(x, main = NULL, plotit = NULL, enum = TRUE, sep = NULL, ...)

## S3 method for class 'list'
Desc(x, main = NULL, plotit = NULL, enum = TRUE, sep = NULL, ...)

## S3 method for class 'numeric'
Desc(x, main = NULL, maxrows = NULL, plotit = NULL,
     sep = NULL, digits = NULL, ...)

## S3 method for class 'integer'
Desc(x, main = NULL, maxrows = NULL, plotit = NULL,
     sep = NULL, digits = NULL, ...)

## S3 method for class 'factor'
Desc(x, main = NULL, maxrows = NULL, ord = NULL, plotit = NULL,
     sep = NULL, digits = NULL, ...)

## S3 method for class 'ordered'
Desc(x, main = NULL, maxrows = NULL, ord = NULL, plotit = NULL,
     sep = NULL, digits = NULL, ...)

## S3 method for class 'character'
Desc(x, main = NULL, maxrows = NULL, ord = NULL, plotit = NULL,
     sep = NULL, digits = NULL, ...)

## S3 method for class 'logical'
Desc(x, main = NULL, ord = NULL, conf.level = 0.95, plotit = NULL,
     sep = NULL, digits = NULL, ...)

## S3 method for class 'Date'
Desc(x, main = NULL, dprobs = NULL, mprobs = NULL, plotit = NULL,
     sep = NULL, digits = NULL, ...)

## S3 method for class 'table'
Desc(x, main = NULL, conf.level = 0.95, verbose = 2,
     rfrq = "111", margins = c(1,2), plotit = NULL, sep = NULL, digits = NULL, ...)


## S3 method for class 'formula'
Desc(formula, data = parent.frame(), subset, main = NULL,
     plotit = NULL, digits = NULL, ...)


## S3 method for class 'Desc'
print(x, digits = NULL, plotit = NULL, nolabel = FALSE,
      sep = NULL, nomain = FALSE, ...)

## S3 method for class 'Desc'
plot(x, main = NULL,  ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Desc_+3A_x">x</code></td>
<td>
<p>the object to be described. This can be a data.frame, a list, a table or a vector of the classes: numeric, integer, factor,
ordered factor, logical.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_main">main</code></td>
<td>
<p>a character vector, containing the main title(s).If this is left to <code>NULL</code>, the title will be composed as: variablename (class(es)),
resp. number - variablename (class(es)) if the <code>enum</code> option is set to TRUE.
Use <code>NA</code> if no caption should be printed at all.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a running MS Word instance, as created by <code>GetNewWrd()</code> (for a new one)
or by <code>GetCurrWrd()</code> for an existing one.
All output will then be redirected there. Default is <code>NULL</code>, which will report all results to the console.</p>
</td></tr>
<tr><td><code id="Desc_+3A_digits">digits</code></td>
<td>
<p>integer. With how many digits shoud the relative frequencies be formatted? Default can be set by <code>DescToolsOptions(digits=x)</code>. </p>
</td></tr>
<tr><td><code id="Desc_+3A_maxrows">maxrows</code></td>
<td>
<p>numeric; defines the maximum number of rows in a frequency table to be reported. For factors with many levels it is often not interesting to see
all of them. Default is set to 12 most frequent ones (resp. the first ones if <code>ord</code> is set to <code>"levels"</code> or <code>"names"</code>).<br />
For a numeric argument x <code>maxrows</code> is the minimum number of unique values needed for a numeric variable to be treated as continous. If left to its default <code>NULL</code>, x will be regarded as continuos if it has more than 12 single values. In this case the list of extreme values will be displayed and the frequency table else.<br />
If <code>maxrows</code> is &lt; 1 it will be interpreted as percentage. In this case just as many rows, as the <code>maxrows%</code> most frequent levels will be shown. Say, if maxrows is set to <code>0.8</code>, then the number of rows is fixed so, that the highest cumulative relative frequency is the first one going beyond 0.8.
</p>
<p>Setting <code>maxrows</code> to <code>Inf</code> will unconditionally report all values and also produce a plot with type &quot;h&quot; instead of a histogram.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_ord">ord</code></td>
<td>
<p>character out of <code>"name"</code> (alphabetical order), <code>"level"</code>, <code>"asc"</code> (by frequencies ascending), <code>"desc"</code> (by freqencies descending) defining the order for a frequency table as used for factors, numerics with few unique values and logicals.
Factors (and character vectors) are by default orderd by their descending frequencies, ordered factors by their natural order.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_rfrq">rfrq</code></td>
<td>
<p>a string with 3 characters, each of them being <code>1</code> or <code>0</code>, defining which percentages should be reported. The first position is interpreted as total
percentages, the second as row percentages and the third as column percentages.
&quot;<code>011</code>&quot; hence produces a table output with row and column percentages. If set to <code>NULL</code> <code>rfrq</code> is defined in
dependency of <code>verbose</code> (<code>verbose = 1</code> sets <code>rfrq</code> to <code>"000"</code> and else to <code>"111"</code>, latter meaning all percentages will be reported.) <br /> Applies only to tables and is ignored else.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_margins">margins</code></td>
<td>
<p>a vector, consisting out of 1 and/or 2. Defines the margin sums to be included.
Row margins are reported if margins is set to 1. Set it to 2 for column margins and c(1,2) for both. <br />
Default is <code>NULL</code> (none).<br /> Applies only to tables and is ignored else.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_verbose">verbose</code></td>
<td>
<p>integer out of <code>c(2, 1, 3)</code> defining the verbosity of the reported results. 2 (default) means medium, 1 less and 3 extensive results. <br /> Applies only to tables and is ignored else.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> no confidence interval will be calculated. Default is 0.95.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_dprobs">dprobs</code>, <code id="Desc_+3A_mprobs">mprobs</code></td>
<td>
<p>a vector with the probabilities for the Chi-Square test for days, resp. months, when describing a <code>Date</code> variable.
If this is left to <code>NULL</code> (default) then a uniform distribution
will be used for days and a monthdays distribution in a non leap year (p = c(31/365, 28/365, 31/365, ...)) for the months. <br /> Applies only to <code>Dates</code> and is ignored else.</p>
</td></tr>
<tr><td><code id="Desc_+3A_enum">enum</code></td>
<td>
<p>logical, determining if in data.frames and lists a sequential number should be included in the main title. Default is TRUE. The reason for this option is, that if a Word report with enumerated headings is created, the numbers may be redundant or inconsistent.</p>
</td></tr>
<tr><td><code id="Desc_+3A_plotit">plotit</code></td>
<td>
<p>boolean. Should a plot be created? The plot type will be chosen according to the classes of variables (roughly following a
numeric-numeric, numeric-categorical, categorical-categorical logic).  Default can be defined by option <code>plotit</code>,
if it does not exist then it's set to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_sep">sep</code></td>
<td>
<p>character. The separator for the title. By default a line of <code>"-"</code> for the current width of the screen
<code>(options("width"))</code> will be used.
</p>
</td></tr>
<tr><td><code id="Desc_+3A_nolabel">nolabel</code></td>
<td>
<p>logical, defining if labels (defined as attribute with the name <code>label</code>, as done by <code>Label</code>) should be plotted.

</p>
</td></tr>
<tr><td><code id="Desc_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="Desc_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="Desc_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="Desc_+3A_nomain">nomain</code></td>
<td>
<p>logical, determines if the main title of the output is printed or not, default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="Desc_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from other methods.
For the internal default method these can include:
</p>

<dl>
<dt>p</dt><dd><p>a vector of probabilities of the same length of <code>x</code>. An error is given if any entry of <code>p</code> is negative. This argument will be passed on to <code><a href="stats.html#topic+chisq.test">chisq.test</a></code>. Default is <code>rep(1/length(x), length(x))</code>.</p>
</dd>
<dt><code>add_ni</code></dt><dd><p>logical. Indicates if the group length should be displayed in the boxplot.</p>
</dd>
<dt><code>smooth</code></dt><dd><p>character, either &quot;loess&quot; or &quot;smooth.spline&quot; defining the type of smoother to be used in num ~ num plots. Default is loess for n &lt; 500 and smooth.spline else.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>Desc is a generic function. It dispatches to one of the methods above depending on the class of its first argument. Typing ?Desc
+ TAB at the prompt should present a choice of links: the help pages for each of these <code>Desc</code> methods (at least if you're using RStudio, which anyway is recommended).
You don't need to use the full name of the method although you may if you wish; i.e.,
Desc(x) is idiomatic R but you can bypass method dispatch by going direct if you wish:
Desc.numeric(x).
</p>
<p>This function produces a rich description of a factor, containing length, number of NAs, number of levels and
detailed frequencies of all levels.
The order of the frequency table can be chosen between descending/ascending frequency, labels or levels.
For ordered factors the order default is <code>"level"</code>.
Character vectors are treated as unordered factors
Desc.char converts x to a factor an processes x as factor.<br />
Desc.ordered does nothing more than changing the standard order for the frequencies to it's intrinsic order, which means order <code>"level"</code>
instead of <code>"desc"</code> in the factor case.
</p>
<p>Description interface for dates. We do here what seems reasonable for describing dates.
We start with a short summary about length, number of NAs and extreme values, before we describe the
frequencies of the weekdays and months, rounded up by a chi-square test.
</p>
<p>A 2-dimensional table will be described with it's relative frequencies, a short summary containing the total cases,
the dimensions of the table, chi-square tests and some association measures as phi-coefficient, contingency coefficient and Cramer's V. <br /> Tables with higher dimensions will simply be printed as flat table, with marginal sums for the first and for the last dimension.
</p>
<p>Note that NAs cannot be handled by this interface, as tables in general come in &quot;as.is&quot;, say basically as a matrix without any
further information about potentially previously cleared NAs.
</p>
<p>Description of a dichotomous variable. This can either be a boolean vector, a factor with two levels or a numeric variable
with only two unique values.
The confidence levels for the relative frequencies are calculated by <code><a href="#topic+BinomCI">BinomCI</a></code>, method <code>"Wilson"</code>
on a confidence level defined by <code>conf.level</code>.
Dichotomous variables can easily be condensed in one graphical representation. Desc for a set of flags (=dichotomous variables) calculates the frequencies, a binomial confidence intervall and produces a kind of dotplot with error bars.
Motivation for this function is, that dichotomous variable in general do not contain intense information. Therefore it makes sense to condense the description of sets of dichotomous variables.
</p>
<p>The formula interface accepts the formula operators <code>+</code>, <code>:</code>, <code>*</code>, <code>I()</code>, <code>1</code> and evaluates any function.
The left hand side and right hand side of the formula are evaluated the same way.
The variable pairs are processed in dependency of their classes.
</p>
<p>Word This function is not thought of being directly run by the enduser. It will normally be called automatically, when
a pointer to a Word instance is passed to the function <code><a href="#topic+Desc">Desc</a></code>.<br />
However <code>DescWrd</code> takes some more specific arguments concerning the Word output (like font or fontsize), which can make it necessary to call the function directly.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>length</code></td>
<td>
<p>the length of the vector (n + NAs).</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the valid entries (NAs are excluded)</p>
</td></tr>
<tr><td><code>NAs</code></td>
<td>
<p>number of NAs</p>
</td></tr>
<tr><td><code>unique</code></td>
<td>
<p>number of unique values. </p>
</td></tr>
<tr><td><code>0s</code></td>
<td>
<p>number of zeros</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>arithmetic mean</p>
</td></tr>
<tr><td><code>MeanSE</code></td>
<td>
<p>standard error of the mean, as calculated by <code><a href="#topic+MeanSE">MeanSE</a></code>.</p>
</td></tr>
<tr><td><code>quant</code></td>
<td>
<p>a table of quantiles, as calculated by
<code><a href="stats.html#topic+quantile">quantile</a>(x, probs = c(.05,.10,.25,.5,.75,.9,.95), na.rm = TRUE)</code>.</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>standard deviation</p>
</td></tr>
<tr><td><code>vcoef</code></td>
<td>
<p>coefficient of variation: <code>mean(x)</code> / <code>sd(x)</code> </p>
</td></tr>
<tr><td><code>mad</code></td>
<td>
<p>median absolute deviation (<code><a href="stats.html#topic+mad">mad</a></code>) </p>
</td></tr>
<tr><td><code>IQR</code></td>
<td>
<p>interquartile range </p>
</td></tr>
<tr><td><code>skew</code></td>
<td>
<p>skewness, as calculated by <code><a href="#topic+Skew">Skew</a></code>. </p>
</td></tr>
<tr><td><code>kurt</code></td>
<td>
<p>kurtosis, as calculated by <code><a href="#topic+Kurt">Kurt</a></code>.</p>
</td></tr>
<tr><td><code>highlow</code></td>
<td>
<p>the lowest and the highest values, reported with their frequencies in brackets, if &gt; 1.</p>
</td></tr>
<tr><td><code>frq</code></td>
<td>
<p>a data.frame of absolute and relative frequencies given by <code><a href="#topic+Freq">Freq</a></code> if maxlevels &gt; unique values in the vector.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;

</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+summary">summary</a></code>, <code><a href="base.html#topic+plot">plot</a></code>

</p>


<h3>Examples</h3>

<pre><code class='language-R'>opt &lt;- DescToolsOptions() 

# implemented classes:
Desc(d.pizza$wrongpizza)               # logical
Desc(d.pizza$driver)                   # factor
Desc(d.pizza$quality)                  # ordered factor
Desc(as.character(d.pizza$driver))     # character
Desc(d.pizza$week)                     # integer
Desc(d.pizza$delivery_min)             # numeric
Desc(d.pizza$date)                     # Date

Desc(d.pizza)

Desc(d.pizza$wrongpizza, main="The wrong pizza delivered", digits=5)

Desc(table(d.pizza$area))                                    # 1-dim table
Desc(table(d.pizza$area, d.pizza$operator))                  # 2-dim table
Desc(table(d.pizza$area, d.pizza$operator, d.pizza$driver))  # n-dim table

# expressions
Desc(log(d.pizza$temperature))
Desc(d.pizza$temperature &gt; 45)

# supported labels
Label(d.pizza$temperature) &lt;- "This is the temperature in degrees Celsius
measured at the time when the pizza is delivered to the client."
Desc(d.pizza$temperature)
# try as well:      Desc(d.pizza$temperature, wrd=GetNewWrd())

z &lt;- Desc(d.pizza$temperature)
print(z, digits=1, plotit=FALSE)
# plot (additional arguments are passed on to the underlying plot function)
plot(z, main="The pizza's temperature in Celsius", args.hist=list(breaks=50))


# formula interface for single variables
Desc(~ uptake + Type, data = CO2, plotit = FALSE)

# bivariate
Desc(price ~ operator, data=d.pizza)                  # numeric ~ factor
Desc(driver ~ operator, data=d.pizza)                 # factor ~ factor
Desc(driver ~ area + operator, data=d.pizza)          # factor ~ several factors
Desc(driver + area ~ operator, data=d.pizza)          # several factors ~ factor
Desc(driver ~ week, data=d.pizza)                     # factor ~ integer

Desc(driver ~ operator, data=d.pizza, rfrq="111")   # alle rel. frequencies
Desc(driver ~ operator, data=d.pizza, rfrq="000",
     verbose=3)                                  # no rel. frequencies

Desc(price ~ delivery_min, data=d.pizza)              # numeric ~ numeric
Desc(price + delivery_min ~ operator + driver + wrongpizza,
     data=d.pizza, digits=c(2,2,2,2,0,3,0,0) )

Desc(week ~ driver, data=d.pizza, digits=c(2,2,2,2,0,3,0,0))   # define digits

Desc(delivery_min + weekday ~ driver, data=d.pizza)


# without defining data-parameter
Desc(d.pizza$delivery_min ~ d.pizza$driver)


# with functions and interactions
Desc(sqrt(price) ~ operator : factor(wrongpizza), data=d.pizza)
Desc(log(price+1) ~ cut(delivery_min, breaks=seq(10,90,10)),
     data=d.pizza, digits=c(2,2,2,2,0,3,0,0))

# response versus all the rest
Desc(driver ~ ., data=d.pizza[, c("temperature","wine_delivered","area","driver")])

# all the rest versus response
Desc(. ~ driver, data=d.pizza[, c("temperature","wine_delivered","area","driver")])

# pairwise Descriptions
p &lt;- CombPairs(c("area","count","operator","driver","temperature","wrongpizza","quality"), )
for(i in 1:nrow(p))
  print(Desc(formula(gettextf("%s ~ %s", p$X1[i], p$X2[i])), data=d.pizza))


# get more flexibility, create the table first
tab &lt;- as.table(apply(HairEyeColor, c(1,2), sum))
tab &lt;- tab[,c("Brown","Hazel","Green","Blue")]

# display only absolute values, row and columnwise percentages
Desc(tab, row.vars=c(3, 1), rfrq="011", plotit=FALSE)

# do the plot by hand, while setting the colours for the mosaics
cols1 &lt;- SetAlpha(c("sienna4", "burlywood", "chartreuse3", "slategray1"), 0.6)
cols2 &lt;- SetAlpha(c("moccasin", "salmon1", "wheat3", "gray32"), 0.8)
plot(Desc(tab), col1=cols1, col2=cols2)


# use global format options for presentation
Fmt(abs=as.fmt(digits=0, big.mark=""))
Fmt(per=as.fmt(digits=2, fmt="%"))
Desc(area ~ driver, d.pizza, plotit=FALSE)

Fmt(abs=as.fmt(digits=0, big.mark="'"))
Fmt(per=as.fmt(digits=3, ldigits=0))
Desc(area ~ driver, d.pizza, plotit=FALSE)

# plot arguments can be fixed in detail
z &lt;- Desc(BoxCox(d.pizza$temperature, lambda = 1.5))
plot(z, mar=c(0, 2.1, 4.1, 2.1), args.rug=TRUE, args.hist=list(breaks=50),
     args.dens=list(from=0))

# The default description for count variables can be inappropriate,
# the density curve does not represent the variable well.
set.seed(1972)
x &lt;- rpois(n = 500, lambda = 5)
Desc(x)
# but setting maxrows to Inf gives a better plot
Desc(x, maxrows = Inf)


# Output into word document (Windows-specific example) -----------------------
# by simply setting wrd=GetNewWrd()
## Not run: 

  # create a new word instance and insert title and contents
  wrd &lt;- GetNewWrd(header=TRUE)

  # let's have a subset
  d.sub &lt;- d.pizza[,c("driver", "date", "operator", "price", "wrongpizza")]

  # do just the univariate analysis
  Desc(d.sub, wrd=wrd)

## End(Not run)

DescToolsOptions(opt) 

</code></pre>

<hr>
<h2 id='DescTools+20Aliases'>Some Aliases Set for Convenience
</h2><span id='topic+N'></span>

<h3>Description</h3>

<p>Some aliases are defined either for having shorter names or for following the Google naming convention.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>N()
</code></pre>


<h3>Details</h3>

<p><code>N()</code> is the same as <code><a href="base.html#topic+as.numeric">as.numeric</a>()</code>.<br />
<code>D()</code> is the same as <code><a href="base.html#topic+as.Date">as.Date</a>()</code>
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(N(d.pizza$driver))
</code></pre>

<hr>
<h2 id='DescTools+20Palettes'>Some Custom Palettes
</h2><span id='topic+Pal'></span><span id='topic+plot.palette'></span><span id='topic+hblue'></span><span id='topic+hred'></span><span id='topic+horange'></span><span id='topic+hgreen'></span><span id='topic+hyellow'></span><span id='topic+hecru'></span>

<h3>Description</h3>

<p>Some more custom palettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pal(pal, n = 100, alpha = 1)

## S3 method for class 'palette'
plot(x, cex = 3, ...)

hred
horange
hyellow
hecru
hblue
hgreen

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DescTools+2B20Palettes_+3A_pal">pal</code></td>
<td>
<p>name or number of the palette. One of
<code>RedToBlack (1)</code>, <code>RedBlackGreen (2)</code>, <code>SteeblueWhite (3)</code>, <code>RedWhiteGreen (4)</code>, <code>RedWhiteBlue0 (5)</code>, <code>RedWhiteBlue1 (6)</code>, <code>RedWhiteBlue2 (7)</code>, <code>RedWhiteBlue3 (8)</code>, <code>Helsana (9)</code>, <code>Tibco (10)</code>, <code>RedGreen1 (11)</code>, <code>Spring (12)</code>, <code>Soap (13)</code>, <code>Maiden (14)</code>, <code>Dark (15)</code>, <code>Accent (16)</code>, <code>Pastel (17)</code>, <code>Fragile (18)</code>, <code>Big (19)</code>, <code>Long (20)</code>, <code>Night (21)</code>, <code>Dawn (22)</code>, <code>Noon (23)</code>, <code>Light (24)</code>
</p>
</td></tr>
<tr><td><code id="DescTools+2B20Palettes_+3A_n">n</code></td>
<td>
<p>integer, number of colors for the palette.
</p>
</td></tr>
<tr><td><code id="DescTools+2B20Palettes_+3A_alpha">alpha</code></td>
<td>
<p>the alpha value to be added. This can be any value from 0 (fully transparent) to 1 (opaque). <code>NA</code> is interpreted so as to delete a potential alpha channel. Default is 0.5.
</p>
</td></tr>
<tr><td><code id="DescTools+2B20Palettes_+3A_x">x</code></td>
<td>
<p>a palette to be plotted.</p>
</td></tr>
<tr><td><code id="DescTools+2B20Palettes_+3A_cex">cex</code></td>
<td>
<p>extension for the color squares. Defaults to 3.</p>
</td></tr>
<tr><td><code id="DescTools+2B20Palettes_+3A_...">...</code></td>
<td>
<p>further arguments passed to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>hred, horange, hyellow, hecru, hblue and hgreen are constants, pointing to the according color from the palette Pal(&quot;Helsana&quot;).
</p>


<h3>Value</h3>

<p>a vector of colors
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Canvas(c(0,1))
ColorLegend(x=0, y=1, width=0.1, col=Pal(1, n=50))
ColorLegend(x=0.15, y=1, width=0.1, col=Pal(2, n=50))
ColorLegend(x=0.3, y=1, width=0.1, col=Pal(3, n=50))
ColorLegend(x=0.45, y=1, width=0.1, col=Pal(4, n=50))
ColorLegend(x=0.6, y=1, width=0.1, col=Pal(5, n=50))
ColorLegend(x=0.75, y=1, width=0.1, col=Pal(6, n=50))
ColorLegend(x=0.9, y=1, width=0.1, col=Pal(7))
ColorLegend(x=1.05, y=1, width=0.1, col=Pal(8))

text(1:8, y=1.05, x=seq(0,1.05,.15)+.05)
title(main="DescTools palettes")

par(mfrow=c(4,2), mar=c(1,1,2,1))
barplot(1:9, col=Pal("Tibco"), axes=FALSE, main="Palette 'Tibco'" )

barplot(1:7, col=Pal("Helsana"), axes=FALSE, main="Palette 'Helsana'" )
barplot(1:7, col=SetAlpha(Pal("Helsana")[c("ecru","hellgruen","hellblau")], 0.6),
        axes=FALSE, main="Palette 'Helsana' (Alpha)" )

barplot(1:10, col=Pal("RedToBlack", 10), axes=FALSE, main="Palette 'RedToBlack'" )
barplot(1:10, col=Pal("RedBlackGreen", 10), axes=FALSE, main="Palette 'RedGreenGreen'" )
barplot(1:10, col=Pal("SteeblueWhite", 10), axes=FALSE, main="Palette 'SteeblueWhite'" )
barplot(1:10, col=Pal("RedWhiteGreen", 10), axes=FALSE, main="Palette 'RedWhiteGreen'" )


</code></pre>

<hr>
<h2 id='DescToolsOptions'>DescTools Options</h2><span id='topic+DescToolsOptions'></span>

<h3>Description</h3>

<p>Get and set a variety of options which affect the way in which DescTools functions display results.</p>


<h3>Usage</h3>

<pre><code class='language-R'>DescToolsOptions(..., default = NULL, reset = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DescToolsOptions_+3A_...">...</code></td>
<td>
<p>any options can be defined, using <code>name = value</code>. However, only the ones below are used by DescTools functions.
</p>
</td></tr>
<tr><td><code id="DescToolsOptions_+3A_default">default</code></td>
<td>
<p>if the specified option is not set in the options list, this value is returned. This facilitates retrieving an option and checking whether it is set and setting it separately if not.</p>
</td></tr>
<tr><td><code id="DescToolsOptions_+3A_reset">reset</code></td>
<td>
<p>logical. If this is set to <code>TRUE</code>, the options will be overwritten with their default values. Other arguments will be ignored in this case. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Invoking <code>DescToolsOptions()</code> with no arguments returns a list with the current values of the options. Note that not all options listed below are set initially. To access the value of a single option, one can simply use <code>DescToolsOptions("plotit")</code>.<br />
To set a new value use the same rationale as with the R options:  <code>DescToolsOptions(plotit=FALSE)</code>
</p>
<p><b>Options used by DescTools</b>
</p>

<dl>
<dt><code>col</code>:</dt><dd><p>a vector of colours, defined as names or as RGB-longs (<code>"#RRGGBB"</code>). By now three colors are used in several plots as defaults. By default they're set to <code>hblue</code>, <code>hred</code> and <code>horange</code>. Change the values by defining <code>DescToolsOptions(col=c("pink", "blue", "yellow"))</code>. Any color definition can be used here.</p>
</dd>
<dt><code>digits</code>:</dt><dd><p>the number of <b>FIXED</b> digits, used throughout the print functions.</p>
</dd>
<dt><code>fixedfont</code>:</dt><dd><p>this font will be used by default, when <code>Desc</code> writes
to a Word document. Must be defined as a font object, say enumerating <code>name</code>, <code>face</code> and <code>size</code> of the font and setting the class <code>font</code>, e.g. <code>structure(list(name="Courier New", size=7), class="font")</code>.
</p>
</dd>
<dt><code>fmt</code>:</dt><dd><p>Three number format definitions are currently used in the <code>Desc</code> routines. The format used for integer values is named <code>"abs"</code>, for percentages <code>"perc"</code> and for floating point numeric values <code>"num"</code>.
The format definitions must be of class <code>"fmt"</code> and may contain any argument used in the function <code><a href="#topic+Format">Format</a></code>.<br />
Use <code><a href="#topic+Fmt">Fmt</a></code> to access and update formats (as they are organised in a nested list).</p>
</dd>
<dt><code>footnote</code>:</dt><dd><p>a character vector, containing characters to be used as footnote signs.
Any character can be defined here. This is currently used by <code><a href="#topic+TOne">TOne</a></code>.</p>
</dd>
<dt><code>lang</code>:</dt><dd><p>either <code>"engl"</code> or <code>"local"</code>, defining the language to be used for the names of weekdays and months when using <code><a href="#topic+Format">Format</a></code>.</p>
</dd>
<dt><code>plotit</code>:</dt><dd><p>logical, defining whether the <code>Desc</code>-procedures should produce plots by default. This is usually a good thing, but it may clutter up your desktop, if you're not using RStudio. Therefore it can be turned off.</p>
</dd>
<dt><code>stamp</code>:</dt><dd><p>text or expression to be placed in the right bottom corner of the <code>DescTools</code> plots. This can be useful, if some author or date information should automatically be inserted by default. Any text can be set as option, but also dynamic expressions can be used. The default would use an expression as &lt;username&gt;/&lt;date&gt;, which will use the username from the system and the current date. See defaults below. </p>
</dd>
</dl>

<p>Calling <code>DescToolsOptions(reset=TRUE)</code> will reset the options to these defaults:
</p>
<pre>
options(DescTools = list(
  col       = c(hblue="#8296C4", hred="#9A0941", horange="#F08100"),
  digits    = 3,
  fixedfont = structure(list(name = "Consolas", size = 7), class = "font"),
  fmt       = list(abs = structure(list(digits = 0, big.mark = "'"),
                     name = "abs", label = "Number format for counts", default = TRUE,
                     class = "fmt"),
                   per = structure(list(digits = 1, fmt = "%"),
                     name = "per", label = "Percentage number format", default = TRUE,
                     class = "fmt"),
                   num = structure(list(digits = 3, big.mark = "'"),
                     name = "num", label = "Number format for floats", default = TRUE,
                     class = "fmt")
              ),
  footnote  = c("'", "\"", "\"\""),
  lang      = "engl",
  plotit    = TRUE,
  stamp     = expression(gettextf("%s/%s", Sys.getenv("USERNAME"),
                                  Format(Today(), fmt = "yyyy-mm-dd")))
))
</pre>
<p>This code can as well be copied and pasted to the users' <code>RProfile</code> file, in order to have the options permanently available.
</p>


<h3>Value</h3>

<p>For a given vector of strings the current value set for option <code>x</code>, or <code>NULL</code> if the option is unset.
</p>
<p>If called with no arguments, returns all option settings in a list. Otherwise, it changes the named settings and invisibly returns their previous values.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Format">Format</a></code>, <code><a href="#topic+Pal">Pal</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>DescToolsOptions("plotit")

## Not run: 

# Get all options, defaults are attributed as such
DescToolsOptions()

# get some options
DescToolsOptions("plotit", "lang")

# get some potentially undefined option, while taking a user default and
# overriding system defaults
DescToolsOptions("stamp", default="Condor, 2016")

# get an undefined option, should return default
DescToolsOptions("stampede", default="Condor, 2016")

# set options, while getting the old values
opt &lt;- DescToolsOptions(plotit=789, lang="portugues")
DescToolsOptions()
# output the old values
opt

# just a single argument
DescToolsOptions(digits=2)

# reset the old values
DescToolsOptions(opt)
DescToolsOptions()

# reset factory defaults
DescToolsOptions(reset=TRUE)

## End(Not run)</code></pre>

<hr>
<h2 id='DigitSum'>Calculate Digit Sum
</h2><span id='topic+DigitSum'></span>

<h3>Description</h3>

<p>Calculate digit sum of a number x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DigitSum(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DigitSum_+3A_x">x</code></td>
<td>
<p>an integer number
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the digit sum
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; based on code by Julius benchmarked by Uwe
</p>


<h3>References</h3>

<p>URL: <a href="https://stackoverflow.com/questions/18675285/digit-sum-function-in-r">https://stackoverflow.com/questions/18675285/digit-sum-function-in-r</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IsPrime">IsPrime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>DigitSum(c(124, 45, 268))
# [1]  7  9 16
</code></pre>

<hr>
<h2 id='DivCoef'>Rao's Diversity Coefficient </h2><span id='topic+DivCoef'></span>

<h3>Description</h3>

<p>Calculates Rao's diversity coefficient (also known as &quot;Quadratic Entropy&quot;) within samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DivCoef(df, dis, scale)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DivCoef_+3A_df">df</code></td>
<td>
<p>a data frame with elements as rows, samples as columns,
and abundance, presence-absence or frequencies as entries</p>
</td></tr>
<tr><td><code id="DivCoef_+3A_dis">dis</code></td>
<td>
<p>an object of class <code>dist</code> containing distances or dissimilarities among elements.
If <code>dis</code> is NULL, Gini-Simpson index is performed.</p>
</td></tr>
<tr><td><code id="DivCoef_+3A_scale">scale</code></td>
<td>
<p>a logical value indicating whether or not the diversity coefficient
should be scaled by its maximal value over all frequency distributions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data frame with samples as rows and the diversity coefficient within samples as columns
</p>


<h3>Note</h3>

<p> This function was previously published as <code>divc()</code> in the  <span class="pkg">ade4</span> package and has been integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>Sandrine Pavoine <a href="mailto:pavoine@biomserv.univ-lyon1.fr">pavoine@biomserv.univ-lyon1.fr</a>
</p>


<h3>References</h3>

<p>Rao, C.R. (1982) Diversity and dissimilarity coefficients: a unified approach.
<em>Theoretical Population Biology</em>, <b>21</b>, 24&ndash;43.
</p>
<p>Gini, C. (1912) Variabilita e mutabilita. <em>Universite di Cagliari III</em>, Parte II.
</p>
<p>Simpson, E.H. (1949) Measurement of diversity. <em>Nature</em>, <b>163</b>, 688.
</p>
<p>Champely, S. and Chessel, D. (2002) Measuring biological diversity using Euclidean metrics.
<em>Environmental and Ecological Statistics</em>, <b>9</b>, 167&ndash;177.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data(ecomor)
# dtaxo &lt;- dist.taxo(ecomor$taxo)
# DivCoef(ecomor$habitat, dtaxo)

# data(humDNAm)
# DivCoef(humDNAm$samples, sqrt(humDNAm$distances))
</code></pre>

<hr>
<h2 id='DivCoefMax'>Maximal value of Rao's diversity coefficient also called 
quadratic entropy</h2><span id='topic+DivCoefMax'></span>

<h3>Description</h3>

<p>For a given dissimilarity matrix, this function calculates the 
maximal value of Rao's diversity coefficient over all frequency 
distribution. It uses an optimization technique based on Rosen's 
projection gradient algorithm and is verified using the 
Kuhn-Tucker conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DivCoefMax(dis, epsilon, comment)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DivCoefMax_+3A_dis">dis</code></td>
<td>
<p>an object of class <code>dist</code> containing distances 
or dissimilarities among elements.</p>
</td></tr>
<tr><td><code id="DivCoefMax_+3A_epsilon">epsilon</code></td>
<td>
<p>a tolerance threshold : a frequency is non null 
if it is higher than epsilon.</p>
</td></tr>
<tr><td><code id="DivCoefMax_+3A_comment">comment</code></td>
<td>
<p>a logical value indicating whether or not 
comments on the optimization technique should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list 
</p>
<table>
<tr><td><code>value</code></td>
<td>
<p>the maximal value of Rao's diversity coefficient.</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>
<p>a data frame containing four frequency 
distributions : sim is a simple distribution which is equal 
to <code class="reqn">\frac{D1}{1^tD1}</code>, pro is equal to 
<code class="reqn">\frac{z}{1^tz1}</code>, where z is the nonnegative 
eigenvector of the matrix containing the squared dissimilarities 
among the elements, met is equal to <code class="reqn">z^2</code>, num is a frequency 
vector maximizing Rao's diversity coefficient.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Stéphane Champely &lt;Stephane.Champely@univ-lyon1.fr&gt; <br />
Sandrine Pavoine &lt;pavoine@biomserv.univ-lyon1.fr&gt;
</p>


<h3>References</h3>

<p>Rao, C.R. (1982) Diversity and dissimilarity coefficients: 
a unified approach. <em>Theoretical Population Biology</em>, 
<b>21</b>, 24&ndash;43.
</p>
<p>Gini, C. (1912) Variabilita e mutabilita. 
<em>Universite di Cagliari III</em>, Parte II.
</p>
<p>Simpson, E.H. (1949) Measurement of diversity. 
<em>Nature</em>, <b>163</b>, 688.
</p>
<p>Champely, S. and Chessel, D. (2002) Measuring biological diversity 
using Euclidean metrics. <em>Environmental and Ecological Statistics</em>, 
<b>9</b>, 167&ndash;177.
</p>
<p>Pavoine, S., Ollier, S. and Pontier, D. (2005) 
Measuring diversity from dissimilarities with Rao's quadratic entropy: 
are any dissimilarities suitable? <em>Theoretical Population Biology</em>,
<b>67</b>, 231&ndash;239.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
par.safe &lt;- par()$mar
data(elec88)
par(mar = c(0.1, 0.1, 0.1, 0.1))
# Departments of France.
area.plot(elec88$area)

# Dissimilarity matrix.
d0 &lt;- dist(elec88$xy)

# Frequency distribution maximizing spatial diversity in France
# according to Rao's quadratic entropy.
France.m &lt;- DivCoefMax(d0)
w0 &lt;- France.m$vectors$num
v0 &lt;- France.m$value
(1:94) [w0 &gt; 0]

# Smallest circle including all the 94 departments.
# The squared radius of that circle is the maximal value of the
# spatial diversity.
w1 = elec88$xy[c(6, 28, 66), ]
w.c = apply(w1 * w0[c(6, 28, 66)], 2, sum)
symbols(w.c[1], w.c[2], circles = sqrt(v0), inc = FALSE, add = TRUE)
s.value(elec88$xy, w0, add.plot = TRUE)
par(mar = par.safe)


# Maximisation of Rao's diversity coefficient
# with ultrametric dissimilarities.
data(microsatt)
mic.genet &lt;- count2genet(microsatt$tab)
mic.dist &lt;- dist.genet(mic.genet, 1)
mic.phylog &lt;- hclust2phylog(hclust(mic.dist))
plot.phylog(mic.phylog)
mic.maxpond &lt;- DivCoefMax(mic.phylog$Wdist)$vectors$num
dotchart.phylog(mic.phylog, mic.maxpond)

## End(Not run)
</code></pre>

<hr>
<h2 id='Divisors'>Calculate Divisors
</h2><span id='topic+Divisors'></span>

<h3>Description</h3>

<p>Calculate divisors of positive natural numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Divisors(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Divisors_+3A_x">x</code></td>
<td>
<p>integer number for which the divisors are to be returned
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Divisibility is a mathematical relationship between two integers. An integer is divisible by another integer if there is no remainder in the division. The number 11 has only two divisors: 1 and the number 11 itself, whereas the number 12 has many divisors: 1, 2, 3, 4, 6 and 12. 
In elementary number theory, the concept of divisibility is limited to natural numbers. 
The number of its divisors can be determined with the function <code><a href="base.html#topic+length">length</a>()</code>.
</p>


<h3>Value</h3>

<p>an integer vector containg the divisors
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Primes">Primes</a></code>, <code><a href="#topic+IsPrime">IsPrime</a></code>, <code><a href="#topic+GCD">GCD</a></code>, <code><a href="#topic+LCM">LCM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Divisors(c(145, 786))
</code></pre>

<hr>
<h2 id='DoBy'>Evaluates a Function Groupwise
</h2><span id='topic+DoBy'></span><span id='topic+DoBy.formula'></span><span id='topic+DoBy.default'></span>

<h3>Description</h3>

<p>Split the vector x into partitions and apply the function to each partition separately. Computation restarts for each partition.<br />
The logic is the same as the OLAP functions in SQL, e.g. <code>SUM(x) OVER (PARTITION BY group)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DoBy(x, ...)

## S3 method for class 'formula'
DoBy(formula, data = parent.frame(), subset, na.action,
     vnames = NULL, ...)
## Default S3 method:
DoBy(x, by, FUN, vnames = NULL, collapse = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DoBy_+3A_x">x</code></td>
<td>
<p>a vector that should be operated.
</p>
</td></tr>
<tr><td><code id="DoBy_+3A_by">by</code></td>
<td>
<p>list of one or more factors, each of same length as <code>x</code>. If <code>by</code> is not a factor, the elements are coerced to factors by <code><a href="base.html#topic+as.factor">as.factor</a>()</code>.
</p>
</td></tr>
<tr><td><code id="DoBy_+3A_fun">FUN</code></td>
<td>
<p>Function to apply for each factor level combination.
</p>
</td></tr>
<tr><td><code id="DoBy_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="DoBy_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from the <code>parent.frame()</code>.</p>
</td></tr>
<tr><td><code id="DoBy_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="DoBy_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain <code>NA</code>s. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="DoBy_+3A_vnames">vnames</code></td>
<td>
<p> name for the new variables.</p>
</td></tr>
<tr><td><code id="DoBy_+3A_collapse">collapse</code></td>
<td>
<p> logical, determining if the results should be collapsed to groups. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="DoBy_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>FUN</code>: See the &quot;Note&quot; section.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is more or less the same as the function <code>ave</code>, with the arguments organized a bit different and offering more flexibility.
</p>


<h3>Value</h3>

<p>a data.frame with the same number of rows as length as <code>x</code> containing the groupwise results of <code>FUN</code> and the used group factors.<br />
The attribute <code>response</code> denotes the name of the response variable in case the formula interface was used.
</p>


<h3>Note</h3>

<p>Optional arguments to <code>FUN</code> supplied by the ... argument are not divided into cells. It is therefore inappropriate for <code>FUN</code> to expect additional arguments with the same length as <code>x</code>.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ave">ave</a></code>, <code><a href="base.html#topic+tapply">tapply</a></code>, <code><a href="stats.html#topic+aggregate">aggregate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.frm &lt;- data.frame(x=rep(1:4,3), v=sample(x=1:3, size=12, replace=TRUE),
                    g=gl(4,3,labels=letters[1:4]), m=gl(3,4,labels=LETTERS[1:3]))

# SQL-OLAP: sum() over (partition by g)
DoBy(d.frm$x, d.frm$g, FUN=sum)
# DoBy(d.frm$x, FUN=sum)

# more than 1 grouping variables are organized as list as in tapply:
DoBy(d.frm$x, list(d.frm$g, d.frm$m), mean)

# count
d.frm$count &lt;- DoBy(d.frm$x, d.frm$g, length)

# rank
d.frm$rank &lt;- DoBy(d.frm$v, d.frm$g, rank)
d.frm$dense_rank &lt;- DoBy(d.frm$v, d.frm$g, Rank, ties.method="dense")
d.frm$rank_desc &lt;- DoBy(d.frm$x, d.frm$g, function(x) rank(-x))

# row_number
d.frm$row_number &lt;- DoBy(d.frm$v, d.frm$g, function(x) order(x))
d.frm

</code></pre>

<hr>
<h2 id='DoCall'>Fast Alternative To The Internal <code>do.call</code></h2><span id='topic+DoCall'></span>

<h3>Description</h3>

<p>The <code><a href="base.html#topic+do.call">do.call</a></code> can be somewhat slow,
especially when working with large objects. This function
is based upon the suggestions from Hadley Wickham on the R
mailing list (reference not available anymore).
Also thanks to <em>Tommy</em> at StackOverflow for
<a href="https://stackoverflow.com/questions/10022436/do-call-in-combination-with">suggesting</a>
how to handle double and triple colon operators, <code>::</code>,
further enhancing the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DoCall(what, args, quote = FALSE, envir = parent.frame())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DoCall_+3A_what">what</code></td>
<td>
<p>either a function or a non-empty character
string naming the function to be called.</p>
</td></tr>
<tr><td><code id="DoCall_+3A_args">args</code></td>
<td>
<p>a <em>list</em> of arguments to the function
call.  The <code>names</code> attribute of <code>args</code> gives
the argument names.</p>
</td></tr>
<tr><td><code id="DoCall_+3A_quote">quote</code></td>
<td>
<p>a logical value indicating whether to quote
the arguments.</p>
</td></tr>
<tr><td><code id="DoCall_+3A_envir">envir</code></td>
<td>
<p>an environment within which to evaluate the
call.  This will be most useful if <code>what</code> is a
character string and the arguments are symbols or quoted
expressions.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>While the function attempts to do most of what
<code><a href="base.html#topic+do.call">do.call</a></code> can it has limitations. It
can currently not parse the example code from the
original function: <br />
<code>do.call(paste,
  list(as.name("A"), as.name("B")), quote = TRUE)</code> and the
funcitonality of <code>quote</code> has not been thoroughly
tested.
</p>


<h3>Note</h3>

<p>This is a verbatim copy from <code>Gmisc::fastDoCall.</code></p>


<h3>Author(s)</h3>

<p>Max Gordon &lt;max@gforge.se&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>DoCall("complex", list(imaginary = 1:3))

## if we already have a list (e.g. a data frame)
## we need c() to add further arguments
tmp &lt;- expand.grid(letters[1:2], 1:3, c("+", "-"))
DoCall("paste", c(tmp, sep = ""))

## examples of where objects will be found.
A &lt;- 2
f &lt;- function(x) print(x^2)
env &lt;- new.env()
assign("A", 10, envir = env)
assign("f", f, envir = env)
f &lt;- function(x) print(x)
f(A)                                         # 2
DoCall("f", list(A))                         # 2
DoCall("f", list(A), envir = env)            # 4
DoCall(f, list(A), envir = env)              # 2
DoCall("f", list(quote(A)), envir = env)     # 100
DoCall(f, list(quote(A)), envir = env)       # 10
DoCall("f", list(as.name("A")), envir = env) # 100

eval(call("f", A))                           # 2
eval(call("f", quote(A)))                    # 2
eval(call("f", A), envir = env)              # 4
eval(call("f", quote(A)), envir = env)       # 100
</code></pre>

<hr>
<h2 id='Dot'>Scalar Product</h2><span id='topic+Dot'></span>

<h3>Description</h3>

<p>'dot' or 'scalar' product of vectors or pairwise columns of matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Dot(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dot_+3A_x">x</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
<tr><td><code id="Dot_+3A_y">y</code></td>
<td>
<p>numeric vector or matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the 'dot' or 'scalar' product of vectors or columns of matrices.
Two vectors must be of same length, two matrices must be of
the same size.
If <code>x</code> and <code>y</code> are column or row vectors, their dot product
will be computed as if they were simple vectors.
</p>


<h3>Value</h3>

<p>A scalar or vector of length the number of columns of <code>x</code> and
<code>y</code>.
</p>


<h3>Author(s)</h3>

<p>Hans W. Borchers &lt;hwborchers@googlemail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Cross">Cross</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Dot(1:5, 1:5)  #=&gt; 55
# Length of space diagonal in 3-dim- cube:
sqrt(Dot(c(1,1,1), c(1,1,1)))  #=&gt; 1.732051
</code></pre>

<hr>
<h2 id='DrawArc'>Draw Elliptic Arc(s)
</h2><span id='topic+DrawArc'></span>

<h3>Description</h3>

<p> Draw one or more elliptic (or circular) arcs from <code>theta.1</code> to <code>theta.2</code> on an existing plot using classic graphics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawArc(x = 0, y = x, rx = 1, ry = rx,
        theta.1 = 0, theta.2 = 2*pi, nv = 100,
        col = par("col"), lty = par("lty"), lwd = par("lwd"),
        plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawArc_+3A_x">x</code>, <code id="DrawArc_+3A_y">y</code></td>
<td>
<p>a vector (or scalar) of xy-coordinates of the center(s) of the arc(s).
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_rx">rx</code></td>
<td>
<p>a scalar or a vector giving the semi-major axis of the ellipse for the arc(s)
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_ry">ry</code></td>
<td>
<p>a scalar or a vector giving the semi-minor axis of the ellipse for the arc(s).
Default is radius.x which will result in a circle arc with radius.x.
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_theta.1">theta.1</code></td>
<td>
<p>a scalar or a vector of starting angles in radians.
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_theta.2">theta.2</code></td>
<td>
<p>a scalar or a vector of ending angles in radians.
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_nv">nv</code></td>
<td>
<p>number of vertices used to plot the arc. Scalar or vector.
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_col">col</code></td>
<td>
<p>color for the arc(s). Scalar or vector.
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_lty">lty</code></td>
<td>
<p>line type used for drawing.
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_lwd">lwd</code></td>
<td>
<p>line width used for drawing.
</p>
</td></tr>
<tr><td><code id="DrawArc_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code> the structure will be plotted. If <code>FALSE</code> only the xy-points are calculated and returned.
Use this if you want to combine several geometric structures to a single polygon.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All parameters are recycled if necessary. <br />
Be sure to use an aspect ratio of 1 as shown in the example to avoid distortion.
</p>


<h3>Value</h3>

<p><code>DrawArc</code> invisibly returns a list of the calculated coordinates for all shapes.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DrawCircle">DrawCircle</a></code>, <code><a href="graphics.html#topic+polygon">polygon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>curve(sin(x), 0, pi, col="blue", asp=1)
DrawArc(x = pi/2, y = 0, rx = 1, theta.1 = pi/4, theta.2 = 3*pi/4, col="red")
</code></pre>

<hr>
<h2 id='DrawBand'>Draw Confidence Band
</h2><span id='topic+DrawBand'></span>

<h3>Description</h3>

<p>Draw a band using a simple syntax. Just a wrapper for the function <code>polygon()</code> typically used to draw confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawBand(x, y, col = SetAlpha("grey", 0.5), border = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawBand_+3A_x">x</code></td>
<td>
<p>a vector or a matrix with x coordinates for the band. If x is given as matrix it must be a <code class="reqn">2 \times n</code> matrix and the second column will be reversed. x will be recyled in the case y is a 2dimensional matrix.
</p>
</td></tr>
<tr><td><code id="DrawBand_+3A_y">y</code></td>
<td>
<p>a vector or a matrix with y coordinates for the band. If y is given as matrix it must be a <code class="reqn">2 \times n</code> matrix and the second column will be reversed. y will be recyled in the case x is a 2dimensional matrix.
</p>
</td></tr>
<tr><td><code id="DrawBand_+3A_col">col</code></td>
<td>
<p>the color of the band.
</p>
</td></tr>
<tr><td><code id="DrawBand_+3A_border">border</code></td>
<td>
<p>the border color of the band.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(18)
x &lt;- rnorm(15)
y &lt;- x + rnorm(15)

new &lt;- seq(-3, 3, 0.5)
pred.w.plim &lt;- predict(lm(y ~ x), newdata=data.frame(x=new), interval="prediction")
pred.w.clim &lt;- predict(lm(y ~ x), newdata=data.frame(x=new), interval="confidence")

plot(y ~ x)
DrawBand(y = c(pred.w.plim[,2], rev(pred.w.plim[,3])),
  x=c(new, rev(new)), col= SetAlpha("grey90", 0.5))

# passing y as matrix interface allows more intuitive arguments
DrawBand(y = pred.w.clim[, 2:3],
         x = new, col= SetAlpha("grey80", 0.5))

abline(lm(y~x), col="brown")
</code></pre>

<hr>
<h2 id='DrawBezier'>Draw a Bezier Curve
</h2><span id='topic+DrawBezier'></span>

<h3>Description</h3>

<p>Draw a Bezier curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawBezier(x = 0, y = x, nv = 100, col = par("col"), lty = par("lty"), 
           lwd = par("lwd"), plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawBezier_+3A_x">x</code>, <code id="DrawBezier_+3A_y">y</code></td>
<td>
<p>a vector of xy-coordinates to define the Bezier curve. Should at least contain 3 points.
</p>
</td></tr>
<tr><td><code id="DrawBezier_+3A_nv">nv</code></td>
<td>
<p>number of vertices to draw the curve.
</p>
</td></tr>
<tr><td><code id="DrawBezier_+3A_col">col</code></td>
<td>
<p>color(s) for the curve. Default is <code>par("fg")</code>. 
</p>
</td></tr>
<tr><td><code id="DrawBezier_+3A_lty">lty</code></td>
<td>
<p>line type for borders and shading; defaults to <code>"solid"</code>.
</p>
</td></tr>
<tr><td><code id="DrawBezier_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and shading.
</p>
</td></tr>
<tr><td><code id="DrawBezier_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code> the structure will be plotted. If <code>FALSE</code> only the xy-points are calculated and returned.
Use this if you want to combine several geometric structures to a single polygon.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bezier curves appear in such areas as mechanical computer aided design (CAD). 
They are named after P. Bezier, who used a closely related representation in Renault's UNISURF 
CAD system in the early 1960s (similar, unpublished, work was done by P. de Casteljau at Citroen 
in the late 1950s and early 1960s). The 1970s and 1980s saw a flowering of interest in Bezier curves, 
with many CAD systems using them, and many important developments in their theory. 
The usefulness of Bezier curves resides in their many geometric and analytical properties. 
There are elegant and efficient algorithms for evaluation, differentiation, 
subdivision of the curves, and conversion to other useful representations. (See: Farin, 1993)
</p>


<h3>Value</h3>

<p><code>DrawBezier</code> invisibly returns a list of the calculated coordinates for all shapes. 
</p>


<h3>Author(s)</h3>

<p>Frank E Harrell Jr &lt;f.harrell@vanderbilt.edu&gt;
</p>


<h3>References</h3>

<p>G. Farin (1993) <em>Curves and surfaces for computer aided geometric design. A practical guide</em>, Acad. Press
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="#topic+DrawRegPolygon">DrawRegPolygon</a></code>, <code><a href="#topic+DrawCircle">DrawCircle</a></code>, <code><a href="#topic+DrawArc">DrawArc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Canvas(xlim=c(0,1))
grid()
DrawBezier( x=c(0,0.5,1), y=c(0,0.5,0), col="blue", lwd=2)
DrawBezier( x=c(0,0.5,1), y=c(0,1,0), col="red", lwd=2)
DrawBezier( x=c(0,0.25,0.5,0.75,1), y=c(0,1,1,1,0), col="darkgreen", lwd=2)
</code></pre>

<hr>
<h2 id='DrawCircle'>Draw a Circle
</h2><span id='topic+DrawCircle'></span>

<h3>Description</h3>

<p>Draw one or several circle on an existing plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawCircle(x = 0, y = x, r.out = 1, r.in = 0,
           theta.1 = 0, theta.2 = 2*pi, border = par("fg"),
           col = NA, lty = par("lty"), lwd = par("lwd"),
           nv = 100, plot = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawCircle_+3A_x">x</code>, <code id="DrawCircle_+3A_y">y</code></td>
<td>
<p>a vector (or scalar) of xy-coordinates for the center(s) of the circle(s).
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_r.out">r.out</code></td>
<td>
<p>a vector (or scalar) of the outer radius of the circle.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_r.in">r.in</code></td>
<td>
<p>a vector (or scalar) of a potential inner radius of an annulus.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_theta.1">theta.1</code></td>
<td>
<p>a vector (or scalar) of the starting angle(s). The sectors are built counterclockwise.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_theta.2">theta.2</code></td>
<td>
<p>a vector (or scalar) of the ending angle(s).
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_nv">nv</code></td>
<td>
<p>number of vertices to draw the circle.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_border">border</code></td>
<td>
<p>color for circle borders. The default is par(&quot;fg&quot;). Use border = <code>NA</code>
to omit borders.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_col">col</code></td>
<td>
<p>color(s) to fill or shade the circle(s) with. The default <code>NA</code> (or also NULL) means
do not fill, i.e., draw transparent circles, unless density is specified.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_lty">lty</code></td>
<td>
<p>line type for borders and shading; defaults to <code>"solid"</code>.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and shading.
</p>
</td></tr>
<tr><td><code id="DrawCircle_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code> the structure will be plotted. If <code>FALSE</code> only the points are
calculated and returned. Use this option if you want to combine several geometric
structures to a polygon.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All geometric arguments will be recycled.
</p>


<h3>Value</h3>

<p>The function invisibly returns a list of the calculated coordinates for all shapes.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="#topic+DrawRegPolygon">DrawRegPolygon</a></code>, <code><a href="#topic+DrawEllipse">DrawEllipse</a></code>, <code><a href="#topic+DrawArc">DrawArc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Canvas(xlim = c(-5,5), xpd=TRUE)
cols &lt;- Pal("Helsana")[1:4]

# Draw ring
DrawCircle (r.in = 1, r.out = 5, border="darkgrey", col=SetAlpha(hyellow, 0.2), lwd=2)

# Draw circle
DrawCircle (r.in = 6, border=hgreen, lwd=3)

# Draw sectors
geom &lt;- rbind(c(-pi, 0, .25, .5), c(0, pi, 1, 2),
              c(-pi/2, pi/2, 2, 2.5), c(pi/2, 3 * pi/2, 3, 4),
              c(pi - pi/8, pi + pi/8, 1.5, 2.5))

DrawCircle (r.in = geom[,3], r.out = geom[,4],
           theta.1 = geom[,1], theta.2 = geom[,2],
           col = SetAlpha(cols, 0.6),
           border = cols, lwd=1)


# clipping
Canvas(bg="lightgrey", main="Yin ~ Yang")
DrawCircle (r.out = 1, col="white")
clip(0, 2, 2, -2)
DrawCircle(col="black")
clip(-2, 2, 2, -2)
DrawCircle (y = c(-0.5,0.5), r.out = 0.5, col=c("black", "white"), border=NA)
DrawCircle (y = c(-0.5,0.5), r.out = 0.1, col=c("white", "black"), border=NA)
DrawCircle ()


# overplotting circles
Canvas(xlim=c(-5,5))
DrawCircle (r.out=4:1, col=c("white", "steelblue2", "white", "red"), lwd=3, nv=300)


# rotation
x &lt;- seq(-3, 3, length.out=10)
y &lt;- rep(0, length.out=length(x))

Canvas(xlim=c(-5,5), bg="black")

sapply( (0:11) * pi/6, function(theta) {
  xy &lt;- Rotate(x, y=y, theta=theta)
  DrawCircle (x=xy$x, y=xy$y, r.in=2.4, border=SetAlpha("white", 0.2))
} )
</code></pre>

<hr>
<h2 id='DrawEllipse'>Draw an Ellipse
</h2><span id='topic+DrawEllipse'></span>

<h3>Description</h3>

<p>Draw one or several ellipses on an existing plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawEllipse(x = 0, y = x, radius.x = 1, radius.y = 0.5, rot = 0,
            nv = 100, border = par("fg"), col = par("bg"),
            lty = par("lty"), lwd = par("lwd"), plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawEllipse_+3A_x">x</code>, <code id="DrawEllipse_+3A_y">y</code></td>
<td>
<p>the x and y co-ordinates for the centre(s) of the ellipse(s).
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_radius.x">radius.x</code></td>
<td>
<p>a scalar or a vector giving the semi-major axis of the ellipse.
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_radius.y">radius.y</code></td>
<td>
<p>a scalar or a vector giving the semi-minor axis of the ellipse.
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_rot">rot</code></td>
<td>
<p>angle of rotation in radians.
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_nv">nv</code></td>
<td>
<p>number of vertices to draw the ellipses.
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_border">border</code></td>
<td>
<p>color for borders. The default is <code>par("fg")</code>. Use <code>border = NA</code> to omit borders.
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_col">col</code></td>
<td>
<p>color(s) to fill or shade the annulus sector with. The default <code>NA</code> (or also <code>NULL</code>)
means do not fill (say draw transparent).
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_lty">lty</code></td>
<td>
<p>line type for borders and shading; defaults to <code>"solid"</code>.
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and shading.
</p>
</td></tr>
<tr><td><code id="DrawEllipse_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code> the structure will be plotted. If <code>FALSE</code> only the points are
calculated and returned. Use this if you want to combine several geometric
structures to a single polygon.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use <code><a href="#topic+DegToRad">DegToRad</a></code> if you want to define rotation angle in degrees.
</p>


<h3>Value</h3>

<p>The function invisibly returns a list of the calculated coordinates for all shapes.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="#topic+DrawRegPolygon">DrawRegPolygon</a></code>, <code><a href="#topic+DrawCircle">DrawCircle</a></code>, <code><a href="#topic+DrawArc">DrawArc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>par(mfrow=c(1,2))

Canvas()
DrawEllipse(rot = c(1:3) * pi/3, col=SetAlpha(c("blue","red","green"), 0.5) )


plot(cars)
m &lt;- var(cars)
eig &lt;- eigen(m)
eig.val &lt;- sqrt(eig$values)
eig.vec &lt;- eig$vectors

DrawEllipse(x=mean(cars$speed), y=mean(cars$dist), radius.x=eig.val[1] , radius.y=eig.val[2]
  , rot=acos(eig.vec[1,1]), border="blue", lwd=3)
</code></pre>

<hr>
<h2 id='DrawRegPolygon'>Draw Regular Polygon(s)
</h2><span id='topic+DrawRegPolygon'></span>

<h3>Description</h3>

<p>Draw a regular polygon with n corners. This is the workhorse function for drawing regular polygons.
Drawing a circle can be done by setting the vertices to a value of say 100.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DrawRegPolygon(x = 0, y = x, radius.x = 1, radius.y = radius.x, rot = 0,
            nv = 3, border = par("fg"), col = par("bg"), lty = par("lty"),
            lwd = par("lwd"), plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DrawRegPolygon_+3A_x">x</code>, <code id="DrawRegPolygon_+3A_y">y</code></td>
<td>
<p>a vector (or scalar) of xy-coordinates of the center(s) of the regular polygon(s).
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_radius.x">radius.x</code></td>
<td>
<p>a scalar or a vector giving the semi-major axis of the ellipse for the polygon(s).
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_radius.y">radius.y</code></td>
<td>
<p>a scalar or a vector giving the semi-minor axis of the ellipse for the polygon(s). Default
is radius.x which will result in a polygon with radius.x.
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_rot">rot</code></td>
<td>
<p>angle of rotation in radians.
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_nv">nv</code></td>
<td>
<p>number of vertices to draw the polygon(s).
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_border">border</code></td>
<td>
<p>color for borders. The default is <code>par("fg")</code>. Use <code>border = NA</code> to omit borders.
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_col">col</code></td>
<td>
<p>color(s) to fill or shade the shape with. The default <code>NA</code> (or also <code>NULL</code>)
means do not fill (say draw transparent).
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_lty">lty</code></td>
<td>
<p>line type for borders and shading; defaults to <code>"solid"</code>.
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders and shading.
</p>
</td></tr>
<tr><td><code id="DrawRegPolygon_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code> the structure will be plotted. If <code>FALSE</code> only the points are
calculated and returned. Use this if you want to combine several geometric
structures to a polygon.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All geometric arguments will be recycled.
</p>


<h3>Value</h3>

<p>The function invisibly returns a list of the calculated coordinates for all shapes.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="#topic+DrawCircle">DrawCircle</a></code>, <code><a href="#topic+DrawArc">DrawArc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Draw 4 triangles (nv = 3) with different rotation angles
plot(c(0,1),c(0,1), asp=1, type="n", xaxt="n", yaxt="n", xlab="", ylab="")
DrawRegPolygon(x = 0.5, y = 0.5, rot = (1:4)*pi/6, radius.x = 0.5, nv = 3,
  col = SetAlpha("yellow",0.5))


# Draw several polygons
plot(c(0,1),c(0,1), asp=1, type="n", xaxt="n", yaxt="n", xlab="", ylab="")
DrawRegPolygon(x = 0.5, y = 0.5, radius.x=seq(50, 5, -10) * 1 /100,
  rot=0, nv = c(50, 10, 7, 4, 3), col=SetAlpha("blue",seq(0.2,0.7,0.1)))


# Combine several polygons by sorting the coordinates
# Calculate the xy-points for two concentric pentagons
d.pts &lt;- do.call("rbind", lapply(DrawRegPolygon(radius.x=c(1,0.38), nv=5,
  rot=c(pi/2, pi/2+pi/5), plot=FALSE ), data.frame))

# prepare plot
plot(c(-1,1),c(-1,1), asp=1, type="n", xaxt="n", yaxt="n", xlab="", ylab="")

# .. and draw the polygon with reordered points
polygon( d.pts[order(rep(1:6, times=2), rep(1:2, each=6)), c("x","y")], col="yellow")



# Move the center
plot(c(0,1),c(0,1), asp=1, type="n", xaxt="n", yaxt="n", xlab="", ylab="")
theta &lt;- seq(0, pi/6, length.out=5)
xy &lt;- PolToCart( exp(theta) /2, theta)
DrawRegPolygon(x=xy$x, y=xy$y + 0.5, radius.x=seq(0.5, 0.1, -0.1),
  nv=4, rot=seq(0, pi/2, length.out=5), col=rainbow(5) )


# Plot a polygon with a "hole"
plot(c(-1,1),c(-1,1), asp=1, type="n", xaxt="n", yaxt="n", xlab="", ylab="")
DrawRegPolygon(nv = 4, rot=pi/4, col="red" )
text(x=0,y=0, "Polygon", cex=6, srt=45)

# Calculate circle and hexagon, but do not plot
pts &lt;- DrawRegPolygon(radius.x=c(0.7, 0.5), nv = c(100, 6), plot=FALSE )

# combine the 2 shapes and plot the new structure
polygon(x = unlist(lapply(pts, "[", "x")),
  y=unlist(lapply(pts, "[", "y")), col="green", border=FALSE)
</code></pre>

<hr>
<h2 id='Dummy'>Generate Dummy Codes for a Factor
</h2><span id='topic+Dummy'></span>

<h3>Description</h3>

<p>Generate a matrix of dummy codes (class indicators) for a given factor. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dummy(x, method = c("treatment", "sum", "helmert", "poly", "full"),
      base = 1, levels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dummy_+3A_x">x</code></td>
<td>
<p>factor or vector of classes for cases.
</p>
</td></tr>
<tr><td><code id="Dummy_+3A_method">method</code></td>
<td>
<p>defines the method of the contrasts being formed. Can be one
out of <code>"treatment"</code>, <code>"sum"</code>, <code>"helmert"</code>, <code>"poly"</code>, <code>"full"</code>,
whereas <code>"treatment"</code> is the default one. Abbreviations are accepted.<br />
The option <code>"full"</code> returns a full set of class indicators, say a dummy factor for <b>each</b> level of x.
Note that this would be redundant for <code><a href="stats.html#topic+lm">lm</a>()</code> and friends!
</p>
</td></tr>
<tr><td><code id="Dummy_+3A_base">base</code></td>
<td>
<p>an integer specifying which group is considered the baseline group.
</p>
</td></tr>
<tr><td><code id="Dummy_+3A_levels">levels</code></td>
<td>
<p>an optional vector of the values (as character strings) that <code>x</code> might have taken.
The default is the unique set of values taken by as.character(x), sorted into increasing order of x.<br />
This is directly passed on to <code><a href="base.html#topic+factor">factor</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For reverting dummy codes see the approach in the examples below.</p>


<h3>Value</h3>

<p>a matrix with the dummy codes.
The number of rows correspond to the number of elements in <code>x</code> and the number of columns to the number of its levels - 1, respectively to the number of levels given as argument -1.
</p>
<p>When <code>method = "full"</code> is chosen the number of columns will correspond to the number of levels.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Venables, W N and Ripley, B D (2002): <em>Modern Applied Statistics with S</em>. Fourth edition. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+model.frame">model.frame</a></code>,  <code><a href="stats.html#topic+contrasts">contrasts</a></code>, <code><a href="nnet.html#topic+class.ind">class.ind</a></code> in the package <span class="pkg">nnet</span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("red","blue","green","blue","green","red","red","blue")
Dummy(x)
Dummy(x, base=2)

Dummy(x, method="sum")


y &lt;- c("Max","Max","Max","Max","Max","Bill","Bill","Bill")

Dummy(y)
Dummy(y, base="Max")

Dummy(y, base="Max", method="full")


# "Undummy" (revert the dummy coding)
m &lt;- Dummy(y, method="full")
m
z &lt;- apply(m, 1, function(x) colnames(m)[x==1])
z
identical(y, as.vector(z))

m &lt;- Dummy(y)
m
z &lt;- apply(m, 1, function(x) ifelse(sum(x)==0, attr(m,"base"), colnames(m)[x==1]))
z
</code></pre>

<hr>
<h2 id='DunnettTest'>Dunnett's Test for Comparing Several Treatments With a Control</h2><span id='topic+DunnettTest'></span><span id='topic+DunnettTest.default'></span><span id='topic+DunnettTest.formula'></span>

<h3>Description</h3>

<p>Performs Dunnett's test for comparing several treatments with a control.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DunnettTest(x, ...)

## Default S3 method:
DunnettTest(x, g, control = NULL, conf.level = 0.95, ...)

## S3 method for class 'formula'
DunnettTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DunnettTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, or a list of numeric data
vectors.</p>
</td></tr>
<tr><td><code id="DunnettTest_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the
corresponding elements of <code>x</code>.  Ignored if <code>x</code> is a
list.</p>
</td></tr>
<tr><td><code id="DunnettTest_+3A_control">control</code></td>
<td>
<p>the level of the control group against which the others should be tested. If there are multiple levels the calculation will be performed for every one. </p>
</td></tr> 
<tr><td><code id="DunnettTest_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.
</p>
</td></tr>
<tr><td><code id="DunnettTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
gives the data values and <code>rhs</code> the corresponding groups.</p>
</td></tr>
<tr><td><code id="DunnettTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="DunnettTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="DunnettTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="DunnettTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>DunnettTest</code> does the post hoc pairwise multiple comparisons procedure.
</p>
<p>If <code>x</code> is a list, its elements are taken as the samples to be
compared, and hence have to be numeric data vectors.  In this case,
<code>g</code> is ignored, and one can simply use <code>DunnettTest(x)</code>
to perform the test.  If the samples are not yet contained in a
list, use <code>DunnettTest(list(x, ...))</code>.
</p>
<p>Otherwise, <code>x</code> must be a numeric data vector, and <code>g</code> must
be a vector or factor object of the same length as <code>x</code> giving
the group for the corresponding elements of <code>x</code>.
</p>


<h3>Value</h3>

<p>A list of class <code>c("PostHocTest")</code>, containing one matrix named after the control with columns <code>diff</code> giving the difference in the observed means, <code>lwr.ci</code> giving the lower end point of the interval, <code>upr.ci</code> giving the upper end point and <code>pval</code> giving the p-value after adjustment for the multiple comparisons.
</p>
<p>There are print and plot methods for class <code>"PostHocTest"</code>. The plot method does not accept <code>xlab</code>, <code>ylab</code> or <code>main</code> arguments and creates its own values for each plot.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, the interface is based on R-Core code</p>


<h3>References</h3>

<p>Dunnett C. W. (1955) A multiple comparison procedure for comparing several treatments with a control, <em>Journal of the American Statistical Association</em>, 50:1096-1121.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PostHocTest">PostHocTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Hollander &amp; Wolfe (1973), 116.
## Mucociliary efficiency from the rate of removal of dust in normal
##  subjects, subjects with obstructive airway disease, and subjects
##  with asbestosis.
x &lt;- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
y &lt;- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
z &lt;- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis

DunnettTest(list(x, y, z))

## Equivalently,
x &lt;- c(x, y, z)
g &lt;- factor(rep(1:3, c(5, 4, 5)),
            labels = c("Normal subjects",
                       "Subjects with obstructive airway disease",
                       "Subjects with asbestosis"))

DunnettTest(x, g)

## Formula interface
boxplot(Ozone ~ Month, data = airquality)
DunnettTest(Ozone ~ Month, data = airquality)

DunnettTest(Ozone ~ Month, data = airquality, control="8", conf.level=0.9)
</code></pre>

<hr>
<h2 id='DunnTest'>Dunn's Test of Multiple Comparisons</h2><span id='topic+DunnTest'></span><span id='topic+DunnTest.default'></span><span id='topic+DunnTest.formula'></span><span id='topic+print.DunnTest'></span>

<h3>Description</h3>

<p>Performs Dunn's test of multiple comparisons using rank sums.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DunnTest(x, ...)

## Default S3 method:
DunnTest(x, g,
         method = c("holm", "hochberg", "hommel", "bonferroni", "BH",
                    "BY", "fdr", "none"),
         alternative = c("two.sided", "less", "greater"),
         out.list = TRUE, ...)

## S3 method for class 'formula'
DunnTest(formula, data, subset, na.action, ...)

## S3 method for class 'DunnTest'
print(x, digits = getOption("digits", 3), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DunnTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, or a list of numeric data
vectors.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the
corresponding elements of <code>x</code>.  Ignored if <code>x</code> is a
list.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_method">method</code></td>
<td>
<p>the method for adjusting p-values for multiple comparisons. The function is calling <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> and this parameter is directly passed through.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>. You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_out.list">out.list</code></td>
<td>
<p>logical, indicating if the results should be printed in list mode or as a square matrix. Default is list (TRUE).</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
gives the data values and <code>rhs</code> the corresponding groups.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_digits">digits</code></td>
<td>
<p>controls the number of fixed digits to print.
</p>
</td></tr>
<tr><td><code id="DunnTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>DunnTest</code> performs the post hoc pairwise multiple comparisons procedure appropriate to follow the rejection of a Kruskal-Wallis test. The Kruskal-Wallis test, being a non-parametric analog of the one-way ANOVA, is an omnibus test of the null hypothesis that none of k  groups stochastically dominate one another.
Dunn's test is constructed in part by summing jointly ranked data. The rank sum test, itself a non-parametric analog of the unpaired t-test, is possibly intuitive, but inappropriate as a post hoc pairwise test, because (1) it fails to retain the dependent ranking that produced the Kruskal-Wallis test statistic, and (2) it does not incorporate the pooled variance estimate implied by the null hypothesis of the Kruskal-Wallis test.
</p>
<p>If <code>x</code> is a list, its elements are taken as the samples to be
compared, and hence have to be numeric data vectors.  In this case,
<code>g</code> is ignored, and one can simply use <code>DunnTest(x)</code>
to perform the test.  If the samples are not yet contained in a
list, use <code>DunnTest(list(x, ...))</code>.
</p>
<p>Otherwise, <code>x</code> must be a numeric data vector, and <code>g</code> must
be a vector or factor object of the same length as <code>x</code> giving
the group for the corresponding elements of <code>x</code>.
</p>


<h3>Value</h3>

<p>A list with class <code>"DunnTest"</code> containing the following components:
</p>
<table>
<tr><td><code>res</code></td>
<td>
<p>an array containing the mean rank differencens and the according p-values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, the interface is based on R-Core code</p>


<h3>References</h3>

<p>Dunn, O. J. (1961) Multiple comparisons among means <em>Journal of the American Statistical Association</em>, 56(293):52-64.
</p>
<p>Dunn, O. J. (1964) Multiple comparisons using rank sums <em>Technometrics</em>, 6(3):241-252.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+kruskal.test">kruskal.test</a></code>, <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>, <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Hollander &amp; Wolfe (1973), 116.
## Mucociliary efficiency from the rate of removal of dust in normal
##  subjects, subjects with obstructive airway disease, and subjects
##  with asbestosis.
x &lt;- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
y &lt;- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
z &lt;- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis
DunnTest(list(x, y, z))

## Equivalently,
x &lt;- c(x, y, z)
g &lt;- factor(rep(1:3, c(5, 4, 5)),
            labels = c("Normal subjects",
                       "Subjects with obstructive airway disease",
                       "Subjects with asbestosis"))

# do the kruskal.test first
kruskal.test(x, g)

# ...and the pairwise test afterwards
DunnTest(x, g)

## Formula interface.
boxplot(Ozone ~ Month, data = airquality)
DunnTest(Ozone ~ Month, data = airquality)
</code></pre>

<hr>
<h2 id='DurbinWatsonTest'>Durbin-Watson Test</h2><span id='topic+DurbinWatsonTest'></span>

<h3>Description</h3>

<p>Performs the Durbin-Watson test for autocorrelation of disturbances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DurbinWatsonTest(formula, order.by = NULL,
                 alternative = c("greater", "two.sided", "less"),
                 iterations = 15, exact = NULL, tol = 1e-10, data = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DurbinWatsonTest_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be tested
(or a fitted <code>"lm"</code> object).</p>
</td></tr>
<tr><td><code id="DurbinWatsonTest_+3A_order.by">order.by</code></td>
<td>
<p>Either a vector <code>z</code> or a formula with a single explanatory
variable like <code>~ z</code>. The observations in the model
are ordered by the size of <code>z</code>. If set to <code>NULL</code> (the
default) the observations are assumed to be ordered (e.g., a
time series).</p>
</td></tr>
<tr><td><code id="DurbinWatsonTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis.</p>
</td></tr>
<tr><td><code id="DurbinWatsonTest_+3A_iterations">iterations</code></td>
<td>
<p>an integer specifying the number of iterations
when calculating the p-value with the &quot;pan&quot; algorithm.</p>
</td></tr>
<tr><td><code id="DurbinWatsonTest_+3A_exact">exact</code></td>
<td>
<p>logical. If set to <code>FALSE</code> a normal approximation
will be used to compute the p value, if <code>TRUE</code> the &quot;pan&quot;
algorithm is used. The default is to use &quot;pan&quot; if the sample size
is &lt; 100.</p>
</td></tr>
<tr><td><code id="DurbinWatsonTest_+3A_tol">tol</code></td>
<td>
<p>tolerance. Eigenvalues computed have to be greater than
<code>tol</code> to be treated as non-zero.</p>
</td></tr>
<tr><td><code id="DurbinWatsonTest_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model.
By default the variables are taken from the environment which <code>DurbinWatsonTest</code>
is called from.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Durbin-Watson test has the null hypothesis that the autocorrelation
of the disturbances is 0. It is possible to test against the alternative that it is
greater than, not equal to, or less than 0, respectively. This can be specified
by the <code>alternative</code> argument.
</p>
<p>Under the assumption of normally distributed disturbances, the null distribution
of the Durbin-Watson statistic is the distribution of a linear
combination of chi-squared variables. The p-value is computed using the
Fortran version of Applied Statistics Algorithm AS 153 by Farebrother
(1980, 1984). This algorithm is called &quot;pan&quot; or &quot;gradsol&quot;. For large sample
sizes the algorithm might fail to compute the p value; in that case a warning
is printed and an approximate p value will be given; this p value is computed
using a normal approximation with mean and variance of the Durbin-Watson test
statistic.
</p>
<p>Examples can not only be found on this page, but also on the help pages of the
data sets <code><a href="lmtest.html#topic+bondyield">bondyield</a></code>, <code><a href="lmtest.html#topic+currencysubstitution">currencysubstitution</a></code>,
<code><a href="lmtest.html#topic+growthofmoney">growthofmoney</a></code>, <code><a href="lmtest.html#topic+moneydemand">moneydemand</a></code>,
<code><a href="lmtest.html#topic+unemployment">unemployment</a></code>, <code><a href="lmtest.html#topic+wages">wages</a></code>.
</p>
<p>For an overview on R and econometrics see Racine &amp; Hyndman (2002).
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code> containing:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the corresponding p-value.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string with the method used.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string with the data name.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> This function was previously published as <code>dwtest</code> in the  <span class="pkg">lmtest</span> package and has been integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>Torsten Hothorn, Achim Zeileis, Richard W. Farebrother (pan.f), Clint Cummins (pan.f), Giovanni Millo, David Mitchell</p>


<h3>References</h3>

<p>J. Durbin &amp; G.S. Watson (1950),
Testing for Serial Correlation in Least Squares Regression I.
<em>Biometrika</em> <b>37</b>, 409&ndash;428.
</p>
<p>J. Durbin &amp; G.S. Watson (1951),
Testing for Serial Correlation in Least Squares Regression II.
<em>Biometrika</em> <b>38</b>, 159&ndash;178.
</p>
<p>J. Durbin &amp; G.S. Watson (1971),
Testing for Serial Correlation in Least Squares Regression III.
<em>Biometrika</em> <b>58</b>, 1&ndash;19.
</p>
<p>R.W. Farebrother (1980),
Pan's Procedure for the Tail Probabilities of the
Durbin-Watson Statistic (Corr: 81V30 p189; AS R52: 84V33 p363- 366; AS
R53: 84V33 p366- 369).
<em>Applied Statistics</em> <b>29</b>,  224&ndash;227.
</p>
<p>R. W. Farebrother (1984),
[AS R53] A Remark on Algorithms AS 106 (77V26 p92-98), AS 153 (80V29 p224-227)
and AS 155: The Distribution of a Linear Combination of <code class="reqn">\chi^2</code> Random
Variables (80V29 p323-333)
<em>Applied Statistics</em> <b>33</b>, 366&ndash;369.
</p>
<p>W. Krämer &amp; H. Sonnberger (1986),
<em>The Linear Regression Model under Test</em>. Heidelberg: Physica.
</p>
<p>J. Racine &amp; R. Hyndman (2002),
Using R To Teach Econometrics.
<em>Journal of Applied Econometrics</em> <b>17</b>, 175&ndash;189.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## generate two AR(1) error terms with parameter
## rho = 0 (white noise) and rho = 0.9 respectively
err1 &lt;- rnorm(100)

## generate regressor and dependent variable
x &lt;- rep(c(-1,1), 50)
y1 &lt;- 1 + x + err1

## perform Durbin-Watson test
DurbinWatsonTest(y1 ~ x)

err2 &lt;- stats::filter(err1, 0.9, method="recursive")
y2 &lt;- 1 + x + err2
DurbinWatsonTest(y2 ~ x)

## for a simple vector use:
e_t &lt;- c(-32.33, -26.603, 2.215, -16.967, -1.148, -2.512, -1.967, 11.669,
         -0.513, 27.032, -4.422, 40.032, 23.577, 33.94, -2.787, -8.606,
          0.575, 6.848, -18.971, -29.063)
DurbinWatsonTest(e_t ~ 1)
</code></pre>

<hr>
<h2 id='Entropy'>Shannon Entropy and Mutual Information
</h2><span id='topic+Entropy'></span><span id='topic+MutInf'></span>

<h3>Description</h3>

<p>Computes Shannon entropy and the mutual information of two variables. The entropy quantifies the expected value of the information contained in a vector. The mutual information is a quantity that measures the mutual dependence of the two random variables. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Entropy(x, y = NULL, base = 2, ...)

MutInf(x, y, base = 2, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Entropy_+3A_x">x</code></td>
<td>
<p>a vector or a matrix of numerical or categorical type. If only x is supplied it will be interpreted as 
contingency table.
</p>
</td></tr>
<tr><td><code id="Entropy_+3A_y">y</code></td>
<td>
<p>a vector with the same type and dimension as x. If y is not <code>NULL</code> then the entropy of <code>table(x, y, ...)</code> 
will be calculated.
</p>
</td></tr>
<tr><td><code id="Entropy_+3A_base">base</code></td>
<td>
<p>base of the logarithm to be used, defaults to 2.
</p>
</td></tr>
<tr><td><code id="Entropy_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set <code>useNA</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Shannon entropy equation provides a way to estimate the average minimum number of bits needed to encode a string of symbols, based on the frequency of the symbols.<br /> 
It is given by the formula <code class="reqn">H = - \sum(\pi log(\pi))</code> where <code class="reqn">\pi</code> is the 
probability of character number i showing up in a stream of characters of the given &quot;script&quot;.<br />
The entropy is ranging from 0 to Inf.
</p>


<h3>Value</h3>

<p>a numeric value.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Shannon, Claude E. (July/October 1948). A Mathematical Theory of Communication, <em>Bell System Technical Journal</em> 27 (3): 379-423.
</p>
<p>Ihara, Shunsuke (1993) <em>Information theory for continuous systems</em>, World Scientific. p. 2. ISBN 978-981-02-0985-8. 
</p>


<h3>See Also</h3>

<p>package <span class="pkg">entropy</span> which implements various estimators of entropy
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Entropy(as.matrix(rep(1/8, 8)))

# http://r.789695.n4.nabble.com/entropy-package-how-to-compute-mutual-information-td4385339.html
x &lt;- as.factor(c("a","b","a","c","b","c")) 
y &lt;- as.factor(c("b","a","a","c","c","b")) 

Entropy(table(x), base=exp(1))
Entropy(table(y), base=exp(1))
Entropy(x, y, base=exp(1))

# Mutual information is 
Entropy(table(x), base=exp(1)) + Entropy(table(y), base=exp(1)) - Entropy(x, y, base=exp(1))
MutInf(x, y, base=exp(1))

Entropy(table(x)) + Entropy(table(y)) - Entropy(x, y)
MutInf(x, y, base=2)

# http://en.wikipedia.org/wiki/Cluster_labeling
tab &lt;- matrix(c(60,10000,200,500000), nrow=2, byrow=TRUE)
MutInf(tab, base=2) 

d.frm &lt;- Untable(as.table(tab))
str(d.frm)
MutInf(d.frm[,1], d.frm[,2])

table(d.frm[,1], d.frm[,2])

MutInf(table(d.frm[,1], d.frm[,2]))


# Ranking mutual information can help to describe clusters
#
#   r.mi &lt;- MutInf(x, grp)
#   attributes(r.mi)$dimnames &lt;- attributes(tab)$dimnames
# 
#   # calculating ranks of mutual information
#   r.mi_r &lt;- apply( -r.mi, 2, rank, na.last=TRUE )
#   # show only first 6 ranks
#   r.mi_r6 &lt;- ifelse( r.mi_r &lt; 7, r.mi_r, NA) 
#   attributes(r.mi_r6)$dimnames &lt;- attributes(tab)$dimnames
#   r.mi_r6
</code></pre>

<hr>
<h2 id='Eps'>Greenhouse-Geisser And Huynh-Feldt Epsilons
</h2><span id='topic+Eps'></span>

<h3>Description</h3>

<p>Calculate Greenhouse-Geisser and Huynh-Feldt epsilons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Eps(S, p, g, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Eps_+3A_s">S</code></td>
<td>
<p>pxp covariance matrix</p>
</td></tr>
<tr><td><code id="Eps_+3A_p">p</code></td>
<td>
<p>dimension of observation vectors</p>
</td></tr>
<tr><td><code id="Eps_+3A_g">g</code></td>
<td>
<p>number of groups</p>
</td></tr>
<tr><td><code id="Eps_+3A_n">n</code></td>
<td>
<p>number of subjects</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value
</p>


<h3>Author(s)</h3>

<p>Hans Rudolf Roth &lt;hroth@retired.ethz.ch&gt;
</p>


<h3>References</h3>

<p>Vonesh, E.F., Chinchilli, V.M. (1997) <em>Linear and Nonlinear Models for the Analysis of Repeated Measurements</em> Marcel Dekker, New York, p.84-86
</p>
<p>Crowder, M.J., Hand, D.J. (1990) <em>Analysis of Repeated Measures</em>. Chapman &amp; Hall, London, p.54-55
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+aov">aov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## find!

</code></pre>

<hr>
<h2 id='ErrBars'>Add Error Bars to an Existing Plot
</h2><span id='topic+ErrBars'></span>

<h3>Description</h3>

<p>Add error bars to an existing plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ErrBars(from, to = NULL, pos = NULL, mid = NULL, horiz = FALSE, col = par("fg"),
        lty = par("lty"), lwd = par("lwd"), code = 3, length = 0.05,
        pch = NA, cex.pch = par("cex"), col.pch = par("fg"), bg.pch = par("bg"),
        ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ErrBars_+3A_from">from</code></td>
<td>
<p>coordinates of points <b>from</b> which to draw (the lower end of the error bars). If <code>to</code> is left to <code>NULL</code> and <code>from</code> is a <code class="reqn">k \times 2 </code>  dimensional matrix, the first column will be interpreted as <code>from</code> and the second as <code>to</code>.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_to">to</code></td>
<td>
<p>coordinates of points <b>to</b> which to draw (the upper end of the error bars).
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_pos">pos</code></td>
<td>
<p>numeric, position of the error bars. This will either be the x-coordinate in case of vertical error bars
and the y-coordinate in case of horizontal error bars.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_mid">mid</code></td>
<td>
<p>numeric, position of midpoints. Defaults to the mean of <code>from</code> and <code>to</code>.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_horiz">horiz</code></td>
<td>
<p>logical, determining whether horizontal error bars are needed (default is FALSE).
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_col">col</code></td>
<td>
<p>the line color.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_lty">lty</code></td>
<td>
<p>the line type.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_lwd">lwd</code></td>
<td>
<p>line width.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_code">code</code></td>
<td>
<p>integer code, determining where end lines are to be drawn. <code>code = 0</code> will draw no end lines, <code>code = 1</code> will draw an end line on the left (lower) side at (<code>x0[i]</code>, <code>y0[i]</code>), <code>code = 2</code> on the right (upper) side (<code>x1[i]</code>, <code>y1[i]</code>) and
<code>code = 3</code> (default) will draw end lines at both ends.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_length">length</code></td>
<td>
<p>the length of the end lines.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_pch">pch</code></td>
<td>
<p>plotting character for the midpoints. The position of the points is given by <code>mid</code>. If <code>mid</code> is left to <code>NULL</code> the points will be plotted in the middle of <code>from</code> and <code>to</code>. No points will be plotted if this is set to <code>NA</code>, which is the default.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_cex.pch">cex.pch</code></td>
<td>
<p>the character extension for the plotting characters. Default is <code>par("cex")</code>.</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_col.pch">col.pch</code></td>
<td>
<p>the color of the plotting characters. Default is <code>par("fg")</code>.
</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_bg.pch">bg.pch</code></td>
<td>
<p>the background color of the plotting characters (if pch is set to 21:25). Default is <code>par("bg")</code>.</p>
</td></tr>
<tr><td><code id="ErrBars_+3A_...">...</code></td>
<td>
<p>the dots are passed to the <code><a href="graphics.html#topic+arrows">arrows</a></code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A short wrapper for plotting error bars by means of <code><a href="graphics.html#topic+arrows">arrows</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+arrows">arrows</a></code>, <code><a href="#topic+lines.loess">lines.loess</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
par(mfrow=c(2,2))
b &lt;- barplot(1:5, ylim=c(0,6))
ErrBars(from=1:5-rep(0.5,5), to=1:5+rep(0.5,5), pos=b, length=0.2)

# just on one side
b &lt;- barplot(1:5, ylim=c(0,6))
ErrBars(from=1:5, to=1:5+rep(0.5,5), pos=b, length=0.2, col="red", code=2, lwd=2)

b &lt;- barplot(1:5, xlim=c(0,6), horiz=TRUE)
ErrBars(from=1:5, to=1:5+rep(0.2,5), pos=b, horiz=TRUE,  length=0.2, col="red", code=2, lwd=2)

par(xpd=FALSE)
dotchart(1:5, xlim=c(0,6))
ErrBars(from=1:5-rep(0.2,5), to=1:5+rep(0.2,5), horiz=TRUE, length=0.1)
</code></pre>

<hr>
<h2 id='EtaSq'>Effect Size Calculations for ANOVAs</h2><span id='topic+EtaSq'></span><span id='topic+EtaSq.lm'></span><span id='topic+EtaSq.aovlist'></span><span id='topic+aovlDetails'></span><span id='topic+aovlErrorTerms'></span>

<h3>Description</h3>

<p>Calculates eta-squared, partial eta-squared and generalized eta-squared
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EtaSq(x, type = 2, anova = FALSE)

## S3 method for class 'lm'
EtaSq(x, type = 2, anova = FALSE)

## S3 method for class 'aovlist'
EtaSq(x, type = 2, anova = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EtaSq_+3A_x">x</code></td>
<td>
<p>An analysis of variance (<code>aov</code>, <code>aovlist</code>) object.</p>
</td></tr>
<tr><td><code id="EtaSq_+3A_type">type</code></td>
<td>
<p>What type of sum of squares to calculate? <code>EtaSq.aovlist</code> requires <code>type=1</code>.</p>
</td></tr>
<tr><td><code id="EtaSq_+3A_anova">anova</code></td>
<td>
<p>Should the full ANOVA table be printed out in addition to the effect sizes?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the eta-squared, partial eta-squared, and generalized eta-squared measures of effect size that are commonly used in analysis of variance. The input <code>x</code> should be the analysis of variance object itself. For between-subjects designs, generalized eta-squared equals partial eta-squared. The reported generalized eta-squared for repeated-measures designs assumes that all factors are manipulated, i.e., that there are no measured factors like gender (see references).
</p>
<p>For unbalanced designs, the default in <code>EtaSq</code> is to compute Type II sums of squares (<code>type=2</code>), in keeping with the <code>Anova</code> function in the <code>car</code> package. It is possible to revert to the Type I SS values (<code>type=1</code>) to be consistent with <code>anova</code>, but this rarely tests hypotheses of interest. Type III SS values (<code>type=3</code>) can also be computed. <code>EtaSq.aovlist</code> requires <code>type=1</code>.
</p>


<h3>Value</h3>

<p>If <code>anova=FALSE</code>, the output for <code>EtaSq.lm</code> is an M x 2 matrix, for <code>EtaSq.aovlist</code> it is an M x 3 matrix. Each of the M rows corresponds to one of the terms in the ANOVA (e.g., main effect 1, main effect 2, interaction, etc), and each of the columns corresponds to a different measure of effect size. Column 1 contains the eta-squared values, and column 2 contains partial eta-squared values. Column 3 contains the generalized eta-squared values. If <code>anova=TRUE</code>, the output contains additional columns containing the sums of squares, mean squares, degrees of freedom, F-statistics and p-values. For <code>EtaSq.aovlist</code>, additional columns contain the error sum of squares and error degrees of freedom corresponding to an effect term.
</p>


<h3>Author(s)</h3>

<p>Danielle Navarro &lt;djnavarro@protonmail.com&gt;, Daniel Wollschlaeger &lt;dwoll@psychologie.uni-kiel.de&gt;</p>


<h3>References</h3>

<p>Bakeman, R. (2005). Recommended effect size statistics for repeated measures designs. Behavior Research Methods 37(3), 379-384.
</p>
<p>Olejnik, S. and Algina, J. (2003). Generalized Eta and Omega Squared Statistics: Measures of Effect Size for Some Common Research Designs. Psychological Methods 8(4), 434-447.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+aov">aov</a></code>,	<code><a href="stats.html#topic+anova">anova</a></code>, <code><a href="car.html#topic+Anova">Anova</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### Example 1: one-way ANOVA ####

outcome &lt;- c(1.4,2.1,3.0,2.1,3.2,4.7,3.5,4.5,5.4)    # data
treatment1 &lt;- factor(c(1,1,1,2,2,2,3,3,3))           # grouping variable
anova1 &lt;- aov(outcome ~ treatment1)                  # run the ANOVA
summary(anova1)                                      # print the ANOVA table
EtaSq(anova1)                                        # effect size

#### Example 2: two-way ANOVA ####

treatment2 &lt;- factor(c(1,2,3,1,2,3,1,2,3))       # second grouping variable
anova2 &lt;- aov(outcome ~ treatment1 + treatment2) # run the ANOVA
summary(anova2)                                  # print the ANOVA table
EtaSq(anova2)                                    # effect size

#### Example 3: two-way ANOVA unbalanced cell sizes ####
#### data from Maxwell &amp; Delaney, 2004              ####
#### Designing experiments and analyzing data       ####

dfMD &lt;- data.frame(IV1=factor(rep(1:3, c(3+5+7, 5+6+4, 5+4+6))),
                   IV2=factor(rep(rep(1:3, 3), c(3,5,7, 5,6,4, 5,4,6))),
                   DV=c(c(41, 43, 50), c(51, 43, 53, 54, 46), c(45, 55, 56, 60, 58, 62, 62),
                        c(56, 47, 45, 46, 49), c(58, 54, 49, 61, 52, 62), c(59, 55, 68, 63),
                        c(43, 56, 48, 46, 47), c(59, 46, 58, 54), c(55, 69, 63, 56, 62, 67)))

# use contr.sum for correct sum of squares type 3
dfMD$IV1s &lt;- C(dfMD$IV1, "contr.sum")
dfMD$IV2s &lt;- C(dfMD$IV2, "contr.sum")
dfMD$IV1t &lt;- C(dfMD$IV1, "contr.treatment")
dfMD$IV2t &lt;- C(dfMD$IV2, "contr.treatment")

EtaSq(aov(DV ~ IV1s*IV2s, data=dfMD), type=3)
EtaSq(aov(DV ~ IV1t*IV2t, data=dfMD), type=1)

#### Example 4: two-way split-plot ANOVA -&gt; EtaSq.aovlist ####

DV_t1 &lt;- round(rnorm(3*10, -0.5, 1), 2)
DV_t2 &lt;- round(rnorm(3*10,  0,   1), 2)
DV_t3 &lt;- round(rnorm(3*10,  0.5, 1), 2)
dfSPF &lt;- data.frame(id=factor(rep(1:(3*10), times=3)),
                    IVbtw=factor(rep(LETTERS[1:3], times=3*10)),
					IVwth=factor(rep(1:3, each=3*10)),
					DV=c(DV_t1, DV_t2, DV_t3))
spf &lt;- aov(DV ~ IVbtw*IVwth + Error(id/IVwth), data=dfSPF)
EtaSq(spf, type=1, anova=TRUE)
</code></pre>

<hr>
<h2 id='EX'>Expected Value and Variance 
</h2><span id='topic+EX'></span><span id='topic+VarX'></span>

<h3>Description</h3>

<p>Expected Value and Variance for the distribution of a discrete random variable.
(For didactical purposes..)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EX(x, p)
VarX(x, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EX_+3A_x">x</code></td>
<td>
<p>the values of the random variable
</p>
</td></tr>
<tr><td><code id="EX_+3A_p">p</code></td>
<td>
<p>the probabilities of the values
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EX(x=c(1:3), p=c(0.2, 0.5, 0.3))
VarX(x=c(1:3), p=c(0.2, 0.5, 0.3))
</code></pre>

<hr>
<h2 id='ExpFreq'>Expected Frequencies
</h2><span id='topic+ExpFreq'></span>

<h3>Description</h3>

<p>Calculate the expected frequencies of an n-way table assuming independence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExpFreq(x, freq = c("abs", "rel"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ExpFreq_+3A_x">x</code></td>
<td>
<p>a table.
</p>
</td></tr>
<tr><td><code id="ExpFreq_+3A_freq">freq</code></td>
<td>
<p>indicates, whether absolute or relative frenquencies should be computed. Can either
be <code>"abs"</code> or <code>"rel"</code>. Partial matching is supported.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table with either the absolute or the relative expected frequencies.
</p>


<h3>Note</h3>

<p>This is a copy of the function <code>independence_table</code> in <span class="pkg">vcd</span>.
</p>


<h3>Author(s)</h3>

<p>David Meyer &lt;David.Meyer@R-project.org&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+chisq.test">chisq.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExpFreq(Titanic)

ExpFreq(UCBAdmissions, freq="r")
</code></pre>

<hr>
<h2 id='Extremes'>Kth Smallest/Largest Values
</h2><span id='topic+Large'></span><span id='topic+Small'></span><span id='topic+HighLow'></span>

<h3>Description</h3>

<p>Find the kth smallest, resp. largest values from a vector <code>x</code> and return the values and their frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Small(x, k = 5, unique = FALSE, na.last = NA)
Large(x, k = 5, unique = FALSE, na.last = NA)

HighLow(x, nlow = 5, nhigh = nlow, na.last = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Extremes_+3A_x">x</code></td>
<td>
<p> a <code>numeric</code> vector
</p>
</td></tr>
<tr><td><code id="Extremes_+3A_k">k</code></td>
<td>
<p>an integer &gt;0 defining how many extreme values should be returned. Default is <code>k = 5</code>. If <code>k &gt; length(x)</code>, all values will be returned.
</p>
</td></tr>
<tr><td><code id="Extremes_+3A_unique">unique</code></td>
<td>
<p>logical, defining if unique values should be considered or not. If this is set to <code>TRUE</code>, a list with the <code>k</code> extreme values and their frequencies is returned. Default is <code>FALSE</code> (as unique is a rather expensive function).
</p>
</td></tr>
<tr><td><code id="Extremes_+3A_na.last">na.last</code></td>
<td>
<p>for controlling the treatment of <code>NA</code>s.
If <code>TRUE</code>, missing values in the data are put last; if
<code>FALSE</code>, they are put first; if <code>NA</code>, they are removed.</p>
</td></tr>
<tr><td><code id="Extremes_+3A_nlow">nlow</code></td>
<td>
<p>a single integer. The number of the smallest elements of a vector to be printed. Defaults to 5.
</p>
</td></tr>
<tr><td><code id="Extremes_+3A_nhigh">nhigh</code></td>
<td>
<p>a single integer. The number of the greatest elements of a vector to be printed. Defaults to the number of <code>nlow</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This does not seem to be a difficult problem at first sight. We could simply tabulate and sort the vector and finally take the first or last k values. However sorting and tabulating the whole vector when we're just interested in the few smallest values is a considerable waste of resources. This approach becomes already impracticable for medium vector lengths (~10<sup>5</sup>). There are several points and solutions of this problem discussed out there.
The present implementation is based on highly efficient C++ code and proved to be very fast.
</p>
<p>HighLow combines the two upper functions and reports the k extreme values on both sides together with their frequencies in parentheses. It is used for describing univariate variables and is interesting for checking the ends of the vector, where in real data often wrong values accumulate.
This is in essence a printing routine for the highest and the lowest values of x.
</p>


<h3>Value</h3>

<p>if <code>unique</code> is set to <code>FALSE</code>: a vector with the k most extreme values,
<br />
else: a list, containing the k most extreme values and their frequencies.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;<br />
C++ parts by Nathan Russell and Romain Francois
</p>


<h3>References</h3>

<p><a href="https://stackoverflow.com/questions/36993935/find-the-largest-n-unique-values-and-their-frequencies-in-r-and-rcpp/">https://stackoverflow.com/questions/36993935/find-the-largest-n-unique-values-and-their-frequencies-in-r-and-rcpp/</a>
</p>
<p><a href="https://gallery.rcpp.org/articles/top-elements-from-vectors-using-priority-queue/">https://gallery.rcpp.org/articles/top-elements-from-vectors-using-priority-queue/</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+max">max</a></code>, <code><a href="base.html#topic+max">max</a></code>, <code><a href="base.html#topic+sort">sort</a></code>, <code><a href="base.html#topic+rank">rank</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- sample(1:10, 1000, rep=TRUE)
Large(x, 3)
Large(x, k=3, unique=TRUE)

# works fine up to x ~ 1e6
x &lt;- runif(1000000)
Small(x, 3, unique=TRUE)
Small(x, 3, unique=FALSE)

# Both ends
cat(HighLow(d.pizza$temperature, na.last=NA))

</code></pre>

<hr>
<h2 id='ExtrVal'>Distributions of Maxima and Minima</h2><span id='topic+dExtrVal'></span><span id='topic+pExtrVal'></span><span id='topic+qExtrVal'></span><span id='topic+rExtrVal'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random generation for the maximum/minimum of a given number of
independent variables from a specified distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dExtrVal(x, densfun, distnfun, ..., distn, mlen = 1, largest = TRUE,
    log = FALSE)
pExtrVal(q, distnfun, ..., distn, mlen = 1, largest = TRUE,
    lower.tail = TRUE)
qExtrVal(p, quantfun, ..., distn, mlen = 1, largest = TRUE,
    lower.tail = TRUE)
rExtrVal(n, quantfun, ..., distn, mlen = 1, largest = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ExtrVal_+3A_x">x</code>, <code id="ExtrVal_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_densfun">densfun</code>, <code id="ExtrVal_+3A_distnfun">distnfun</code>, <code id="ExtrVal_+3A_quantfun">quantfun</code></td>
<td>
<p>Density, distribution and
quantile function of the specified distribution. The density
function must have a <code>log</code> argument (a simple wrapper
can always be constructed to achieve this).</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_...">...</code></td>
<td>
<p>Parameters of the specified distribution.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_distn">distn</code></td>
<td>
<p>A character string, optionally given as an
alternative to <code>densfun</code>, <code>distnfun</code> and <code>quantfun</code>
such that the density, distribution and quantile functions are
formed upon the addition of the prefixes <code>d</code>, <code>p</code> and
<code>q</code> respectively.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_mlen">mlen</code></td>
<td>
<p>The number of independent variables.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_largest">largest</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default) use maxima,
otherwise minima.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_log">log</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the log density is returned.</p>
</td></tr>
<tr><td><code id="ExtrVal_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default) probabilities
are P[X &lt;= x], otherwise  P[X &gt; x].</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dExtrVal</code> gives the density function, <code>pExtrVal</code> gives the
distribution function and <code>qExtrVal</code> gives the quantile function
of the maximum/minimum of <code>mlen</code> independent variables from
a specified distibution. <code>rExtrVal</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Alec Stephenson &lt;alec_stephenson@hotmail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+rGenExtrVal">rGenExtrVal</a></code>, <code><a href="#topic+rOrder">rOrder</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dExtrVal(2:4, dnorm, pnorm, mean = 0.5, sd = 1.2, mlen = 5)
dExtrVal(2:4, distn = "norm", mean = 0.5, sd = 1.2, mlen = 5)
dExtrVal(2:4, distn = "exp", mlen = 2, largest = FALSE)
pExtrVal(2:4, distn = "exp", rate = 1.2, mlen = 2)
qExtrVal(seq(0.9, 0.6, -0.1), distn = "exp", rate = 1.2, mlen = 2)
rExtrVal(5, qgamma, shape = 1, mlen = 10)
p &lt;- (1:9)/10
pexp(qExtrVal(p, distn = "exp", rate = 1.2, mlen = 1), rate = 1.2)
## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
</code></pre>

<hr>
<h2 id='Factorize'>Prime Factorization of Integers</h2><span id='topic+Factorize'></span>

<h3>Description</h3>

<p>Compute the prime factorization(s) of integer(s) <code>n</code>.
</p>









<h3>Usage</h3>

<pre><code class='language-R'>Factorize(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Factorize_+3A_n">n</code></td>
<td>
<p>vector of integers to factorize.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>works via <code><a href="#topic+Primes">Primes</a></code>, currently in a cheap way, sub-optimal
for large composite <code class="reqn">n</code>.
</p>


<h3>Value</h3>

<p>A named <code><a href="base.html#topic+list">list</a></code> of the same length as <code>n</code>,
each element a 2-column matrix with column <code>"p"</code> the prime
factors and column~<code>"m"</code> their respective exponents (or
multiplities), i.e., for a prime number <code>n</code>, the resulting matrix
is <code>cbind(p = n, m = 1)</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, Jan. 1996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GCD">GCD</a></code>,  <code><a href="#topic+LCM">LCM</a></code>, <code><a href="#topic+Primes">Primes</a></code>,   <code><a href="#topic+IsPrime">IsPrime</a></code>,   <code><a href="#topic+Divisors">Divisors</a></code>
</p>
<p>For factorization of moderately or really large numbers, see the <span class="pkg">gmp</span>
package, and its <code><a href="gmp.html#topic+factorize">factorize</a>()</code> (which is ~20x faster!).
</p>


<h3>Examples</h3>

<pre><code class='language-R'> Factorize(47)
 Factorize(seq(101, 120, by=2))
</code></pre>

<hr>
<h2 id='FctArgs'>Retrieve a Function's Arguments
</h2><span id='topic+FctArgs'></span>

<h3>Description</h3>

<p>Retrieve a function's arguments and default values in a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FctArgs(name, sort = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FctArgs_+3A_name">name</code></td>
<td>
<p>name of the function.
</p>
</td></tr>
<tr><td><code id="FctArgs_+3A_sort">sort</code></td>
<td>
<p>logical. Should the function arguments be sorted? Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with the default in the first columns and with row.names as
argument names.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="methods.html#topic+formalArgs">formalArgs</a></code>, <code><a href="base.html#topic+formals">formals</a></code>, <code><a href="base.html#topic+args">args</a></code>, <code><a href="base.html#topic+alist">alist</a></code>, <code><a href="base.html#topic+body">body</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>formalArgs(PlotFdist)
formals(PlotFdist)

# compare:
FctArgs(PlotFdist)
</code></pre>

<hr>
<h2 id='Fibonacci'>
Fibonacci Numbers
</h2><span id='topic+Fibonacci'></span>

<h3>Description</h3>

<p>Generates Fibonacci numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Fibonacci(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fibonacci_+3A_n">n</code></td>
<td>
<p>nonnegative integer or vector of nonnegative integers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generates the <code>n</code>-th Fibonacci number, whereas Fibonacci(0) = 0.
</p>


<h3>Value</h3>

<p>A single integer, or a vector of integers.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Fibonacci_number">https://en.wikipedia.org/wiki/Fibonacci_number</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>Fibonacci(0)                            # 1
Fibonacci(2)                            # 2
Fibonacci(0:3)                          # 0 1 1 2


# Golden ratio
F &lt;- Fibonacci(1:25)                    # ... 75025 121393
f25 &lt;- F[25]/F[24]                      #     1.618033989
phi &lt;- (sqrt(5) + 1)/2
abs(f25 - phi)                          # 7.945178e-11

# Fibonacci numbers without iteration
fibo &lt;- function(n) {
  phi &lt;- (sqrt(5) + 1)/2
  fib &lt;- (phi^(n+1) - (1-phi)^(n+1)) / (2*phi - 1)
  round(fib)
}
  
fibo(30:33)                             # 1346269 2178309 3524578 5702887

</code></pre>

<hr>
<h2 id='FindColor'>Get Color on a Defined Color Range
</h2><span id='topic+FindColor'></span>

<h3>Description</h3>

<p>Find a color on a defined color range depending on the value of x. This is helpful for colorcoding numeric values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FindColor(x, cols = rev(heat.colors(100)),
          min.x = NULL, max.x = NULL, all.inside = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FindColor_+3A_x">x</code></td>
<td>
<p>numeric.
</p>
</td></tr>
<tr><td><code id="FindColor_+3A_cols">cols</code></td>
<td>
<p>a vector of colors.
</p>
</td></tr>
<tr><td><code id="FindColor_+3A_min.x">min.x</code></td>
<td>
<p>the x-value to be used for the left edge of the first color. If left to the default <code>NULL</code> <code>min(pretty(x))</code> will be used.
</p>
</td></tr>
<tr><td><code id="FindColor_+3A_max.x">max.x</code></td>
<td>
<p>the x-value to be used for the right edge of the last color. If left to the default <code>NULL</code> <code>max(pretty(x))</code> will be used.
</p>
</td></tr>
<tr><td><code id="FindColor_+3A_all.inside">all.inside</code></td>
<td>
<p>logical; if true, the returned indices are coerced into <code>1, ..., N-1</code>, i.e., <code>0</code>
is mapped to <code>1</code> and <code>N</code> to <code>N-1</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the selection of colors the option <code>rightmost.closed</code> in the used function
<code><a href="base.html#topic+findInterval">findInterval</a></code> is set to TRUE.
This will ensure that all values on the right edge of the range are assigned a color.
How values outside the boundaries of min.x and max.x should be handled can be controlled by <code>all.inside</code>. Set this value to TRUE, if those values
should get the colors at the edges or set it to FALSE, if they should remain white (which is the default).
</p>
<p>Note that <code><a href="base.html#topic+findInterval">findInterval</a></code> closes the intervals on the left side, e.g. [0, 1). This option can't be changed. Consequently will x-values lying on the edge of two colors get the color of the bigger one.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+findInterval">findInterval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Canvas(7, main="Use of function FindColor()")

# get some data
x &lt;- c(23, 56, 96)
# get a color range from blue via white to red
cols &lt;- colorRampPalette(c("blue","white","red"))(100)
ColorLegend(x="bottomleft", cols=cols, labels=seq(0, 100, 10), cex=0.8)

# and now the color coding of x:
(xcols &lt;- FindColor(x, cols, min.x=0, max.x=100))

# this should be the same as
cols[x+1]

# how does it look like?
y0 &lt;- c(-5, -2, 1)
text(x=1, y=max(y0)+2, labels="Color coding of x:")
text(x=1.5, y=y0, labels=x)
DrawRegPolygon(x=3, y=y0, nv=4, rot=pi/4, col=xcols)
text(x=6, y=y0, labels=xcols)

# how does the function select colors?
Canvas(xlim = c(0,1), ylim = c(0,1))
cols &lt;- c(red="red", yellow="yellow", green="green", blue="blue")
ColorLegend(x=0, y=1, width=1, cols=rev(cols), horiz = TRUE,
            labels=Format(seq(0, 1, .25), digits=2), frame="grey", cex=0.8 )
x &lt;- c(-0.2, 0, 0.15, 0.55, .75, 1, 1.3)
arrows(x0 = x, y0 = 0.6, y1 = 0.8, angle = 15, length = .2)
text(x=x, y = 0.5, labels = x, adj = c(0.5,0.5))
text(x=x, y = 0.4, labels = names(FindColor(x, cols=cols,
   min.x = 0, max.x = 1, all.inside = TRUE)), adj = c(0.5,0.5))
text(x=x, y = 0.3, labels = names(FindColor(x, cols=cols,
   min.x = 0, max.x = 1, all.inside = FALSE)), adj = c(0.5,0.5))
</code></pre>

<hr>
<h2 id='FindCorr'>Determine Highly Correlated Variables</h2><span id='topic+FindCorr'></span>

<h3>Description</h3>

<p>This function searches through a correlation matrix and returns a vector of integers
corresponding to columns to remove to reduce pair-wise correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FindCorr(x, cutoff = .90, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FindCorr_+3A_x">x</code></td>
<td>
<p>A correlation matrix</p>
</td></tr>
<tr><td><code id="FindCorr_+3A_cutoff">cutoff</code></td>
<td>
<p>A numeric value for the pair-wise absolute correlation cutoff</p>
</td></tr>
<tr><td><code id="FindCorr_+3A_verbose">verbose</code></td>
<td>
<p>A boolean for printing the details</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The absolute values of pair-wise correlations are considered. If two variables have a high correlation,
the function looks at the mean absolute correlation of each variable and removes the variable with the
largest mean absolute correlation.
</p>
<p>There are several function in the <span class="pkg">subselect</span> package that can also be used
to accomplish the same goal. However the package was removed from CRAN and available in the archives.
</p>


<h3>Value</h3>

<p>A vector of indices denoting the columns to remove. If no correlations meet the criteria, <code>numeric(0)</code> is returned.
</p>


<h3>Author(s)</h3>

<p>Original R code by Dong Li, modified by Max Kuhn</p>


<h3>References</h3>

<p>Max Kuhn. Contributions from Jed Wing, Steve Weston, Andre Williams, Chris Keefer,
Allan Engelhardt, Tony Cooper, Zachary Mayer and the R Core Team (2014). caret:
Classification and Regression Training. R package version 6.0-35.
<a href="https://cran.r-project.org/package=caret">https://cran.r-project.org/package=caret</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>corrMatrix &lt;- diag(rep(1, 5))
corrMatrix[2, 3] &lt;- corrMatrix[3, 2] &lt;- .7
corrMatrix[5, 3] &lt;- corrMatrix[3, 5] &lt;- -.7
corrMatrix[4, 1] &lt;- corrMatrix[1, 4] &lt;- -.67

corrDF &lt;- expand.grid(row = 1:5, col = 1:5)
corrDF$correlation &lt;- as.vector(corrMatrix)
PlotCorr(xtabs(correlation ~ ., corrDF), las=1, border="grey")

FindCorr(corrMatrix, cutoff = .65, verbose = TRUE)

FindCorr(corrMatrix, cutoff = .99, verbose = TRUE)

# d.pizza example
m &lt;- cor(data.frame(lapply(d.pizza, as.numeric)), use="pairwise.complete.obs")
FindCorr(m, verbose = TRUE)
m[, FindCorr(m)]
</code></pre>

<hr>
<h2 id='FisherZ'>Fisher-Transformation for Correlation to z-Score</h2><span id='topic+FisherZ'></span><span id='topic+FisherZInv'></span><span id='topic+CorCI'></span>

<h3>Description</h3>

<p>Convert a correlation to a z score or z to r using the Fisher transformation or find the confidence intervals for a specified correlation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>FisherZ(rho)
FisherZInv(z)
CorCI(rho, n, conf.level = 0.95, alternative = c("two.sided", "less", "greater"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FisherZ_+3A_rho">rho</code></td>
<td>
<p>the Pearson's correlation coefficient</p>
</td></tr>
<tr><td><code id="FisherZ_+3A_z">z</code></td>
<td>
<p>a Fisher z transformed value</p>
</td></tr>
<tr><td><code id="FisherZ_+3A_n">n</code></td>
<td>
<p>sample size used for calculating the confidence intervals</p>
</td></tr>
<tr><td><code id="FisherZ_+3A_alternative">alternative</code></td>
<td>
<p>is a character string, one of <code>"greater"</code>,
<code>"less"</code>, or <code>"two.sided"</code>, or the initial letter of each,
indicating the specification of the alternative hypothesis.
<code>"greater"</code> corresponds to positive association, <code>"less"</code> to negative association.</p>
</td></tr>
<tr><td><code id="FisherZ_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the returned confidence
interval, restricted to lie between zero and one.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The  sampling distribution of  Pearson's r is not normally distributed. Fisher developed a transformation now called &quot;Fisher's z-transformation&quot; that converts Pearson's r to the normally distributed variable z. The formula for the transformation is:
</p>
<p style="text-align: center;"><code class="reqn">z_r = tanh^{-1}(r) = \frac{1}{2}log\left ( \frac{1+r}{1-r}\right )</code>
</p>



<h3>Value</h3>

<p>z value corresponding to r (in FisherZ) <br />
r corresponding to z (in FisherZInv) <br />
rho, lower and upper confidence intervals (CorCI) <br />
</p>


<h3>Author(s)</h3>

<p>William Revelle &lt;revelle@northwestern.edu&gt;, <br />
slight modifications Andri Signorell &lt;andri@signorell.net&gt; based on R-Core code
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor.test">cor.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>cors &lt;- seq(-.9, .9, .1)

zs &lt;- FisherZ(cors)
rs &lt;- FisherZInv(zs)
round(zs, 2)
n &lt;- 30
r &lt;- seq(0, .9, .1)
rc &lt;- t(sapply(r, CorCI, n=n))
t &lt;- r * sqrt(n-2) / sqrt(1-r^2)
p &lt;- (1 - pt(t, n-2)) / 2

r.rc &lt;- data.frame(r=r, z=FisherZ(r), lower=rc[,2], upper=rc[,3], t=t, p=p)

round(r.rc,2)
</code></pre>

<hr>
<h2 id='FixToTable'>Convert a Text to a Table
</h2><span id='topic+FixToTable'></span>

<h3>Description</h3>

<p>Convert a text to a table by using complete columns of spaces (or any other separator) as delimiting point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FixToTable(txt, sep = " ", delim = "\t", trim = TRUE, header = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FixToTable_+3A_txt">txt</code></td>
<td>
<p>the text to be partitioned. Works best, if txt is  a matrix.
</p>
</td></tr>
<tr><td><code id="FixToTable_+3A_sep">sep</code></td>
<td>
<p>the separator to use. Will frequently be &quot; &quot;.
</p>
</td></tr>
<tr><td><code id="FixToTable_+3A_delim">delim</code></td>
<td>
<p>the new delimiter to insert. (default tab)
</p>
</td></tr>
<tr><td><code id="FixToTable_+3A_trim">trim</code></td>
<td>
<p>logical. Should the separated text be trimmed from whitespace? Defaults to TRUE.
</p>
</td></tr>
<tr><td><code id="FixToTable_+3A_header">header</code></td>
<td>
<p>logical. Should the first line be interpreted as header?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only a complete appearance of the separator character in the same position over all rows will
be accepted as column delimiter.
</p>


<h3>Value</h3>

<p>a matrix of the separated text.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+StrChop">StrChop</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># let's get some tabbed text
txt &lt;- matrix(capture.output(Titanic[,,2,1]))
FixToTable(txt[-1,])
</code></pre>

<hr>
<h2 id='Format'>Format Numbers and Dates
</h2><span id='topic+Format'></span><span id='topic+Format.default'></span><span id='topic+Format.matrix'></span><span id='topic+Format.table'></span><span id='topic+Fmt'></span><span id='topic+as.fmt'></span><span id='topic+as.CDateFmt'></span>

<h3>Description</h3>

<p>Formatting numbers with base R tools often degenerates into a major intellectual challenge for us little minds down here in the valley of tears. There are a number of options available and quite often it's hard to work out which one to use, when a more uncommon setting is needed.
The <code>Format()</code> function wraps all these functions and tries to offer a simpler, less technical, but still flexible interface.
</p>
<p>There's also an easygoing interface for format templates, defined as a list consisting of any accepted format features. This enables to define templates globally and easily change or modify them later.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Format(x, digits = NULL, sci = NULL, big.mark = NULL,
       ldigits = NULL, zero.form = NULL, na.form = NULL,
       fmt = NULL, align = NULL, width = NULL, lang = NULL, 
       eps = NULL, ...)

## S3 method for class 'table'
Format(x, digits = NULL, sci = NULL, big.mark = NULL,
       ldigits = NULL, zero.form = NULL, na.form = NULL,
       fmt = NULL, align = NULL, width = NULL, lang = NULL, 
       eps = NULL, ...)

## S3 method for class 'matrix'
Format(x, digits = NULL, sci = NULL, big.mark = NULL,
       ldigits = NULL, zero.form = NULL, na.form = NULL,
       fmt = NULL, align = NULL, width = NULL, lang = NULL, 
       eps = NULL, ...)

## Default S3 method:
Format(x, digits = NULL, sci = NULL, big.mark = NULL,
       ldigits = NULL, zero.form = NULL, na.form = NULL,
       fmt = NULL, align = NULL, width = NULL, lang = NULL, 
       eps = NULL, ...)

Fmt(...)

as.fmt(...)

as.CDateFmt(fmt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Format_+3A_x">x</code></td>
<td>
<p>an atomic numerical, typically a vector of real numbers or a matrix of numerical values. Factors will be converted to strings.
</p>
</td></tr>
<tr><td><code id="Format_+3A_digits">digits</code></td>
<td>
<p>integer, the desired (fixed) number of digits after the decimal point. Unlike <code><a href="base.html#topic+formatC">formatC</a></code> you will always get this number of digits even if the last digit is 0. 
Negative numbers of digits round to a power of ten (<code>digits=-2</code> would round to the nearest hundred).
</p>
</td></tr>
<tr><td><code id="Format_+3A_sci">sci</code></td>
<td>
<p>integer. The power of 10 to be set when deciding to print numeric values in exponential notation. Fixed notation will be preferred unless the number is larger than 10^scipen. If just one value is set it will be used for the left border 10^(-scipen) as well as for the right one (10^scipen). A negative and a positive value can also be set independently. Default is
<code>getOption("scipen")</code>, whereas <code>scipen=0</code> is overridden.
</p>
</td></tr>
<tr><td><code id="Format_+3A_big.mark">big.mark</code></td>
<td>
<p>character; if not empty used as mark between every 3 decimals before the decimal point. Default is &quot;&quot; (none).
</p>
</td></tr>
<tr><td><code id="Format_+3A_ldigits">ldigits</code></td>
<td>
<p>number of leading zeros. <code>ldigits=3</code> would make sure that at least 3 digits on the left side will be printed, say <code>3.4</code> will be printed as <code>003.4</code>. Setting <code>ldigits</code> to <code>0</code> will yield results like <code>.452</code> for <code>0.452</code>. The default <code>NULL</code> will leave the numbers as they are (meaning at least one 0 digit).
</p>
</td></tr>
<tr><td><code id="Format_+3A_zero.form">zero.form</code></td>
<td>
<p>character, string specifying how zeros should be specially formatted. Useful for pretty printing 'sparse' objects.
If set to <code>NULL</code> (default) no special action will be taken.
</p>
</td></tr>
<tr><td><code id="Format_+3A_na.form">na.form</code></td>
<td>
<p>character, string specifying how <code>NA</code>s should be specially formatted.
If set to <code>NULL</code> (default) no special action will be taken.
</p>
</td></tr>
<tr><td><code id="Format_+3A_fmt">fmt</code></td>
<td>
<p>either a format string, allowing to flexibly define special formats or an object of class <code>fmt</code>, consisting of a list of <code>Format</code> arguments. See Details.
</p>
</td></tr>
<tr><td><code id="Format_+3A_align">align</code></td>
<td>
<p> the character on whose position the strings will be aligned. Left alignment can be requested by setting <code>sep = "\\l"</code>, right alignment by <code>"\\r"</code> and center alignment by <code>"\\c"</code>. Mind the backslashes, as if they are omitted, strings would be aligned to the <b>character</b> l, r or c respectively. The default is <code>NULL</code> which would just leave the strings as they are.<br />
This argument is send directly to the function <code><a href="#topic+StrAlign">StrAlign</a>()</code> as argument <code>sep</code>.
</p>
</td></tr>
<tr><td><code id="Format_+3A_width">width</code></td>
<td>
<p>integer, the defined fixed width of the strings.
</p>
</td></tr>
<tr><td><code id="Format_+3A_lang">lang</code></td>
<td>
<p>optional value setting the language for the months and daynames. Can be either <code>"local"</code> for current locale or <code>"engl"</code> for english. If left to <code>NULL</code>, the DescToolsOption <code>"lang"</code> will be searched for and if not found <code>"local"</code> will be taken as default.
</p>
</td></tr>
<tr><td><code id="Format_+3A_eps">eps</code></td>
<td>
<p>a numerical tolerance used mainly for formatting p values, those less than eps are formatted as &quot;<code>&lt; [eps]</code>&quot; (where '[eps]' stands for <code>format(eps, digits))</code>. Default is <code>.Machine$double.eps</code>.</p>
</td></tr>
<tr><td><code id="Format_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods. </p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Format()</code> is the workhorse here and formats numbers and dates. <br /><br />
The argument <code>fmt</code> is very flexible and is used to generate a variety of different formats. When <code>x</code> is a date, it can take ISO-8601-date-and-time-format codes consisting of (<code>d</code>, <code>m</code> and <code>y</code> for day, month or year) and defining the combination of day month and year representation. Repeating the specific code defines the degree of abbreviation. The format <code>'yyyy-mm-dd'</code> would yield a date as <code>2020-10-12</code>.
</p>

<table>
<tr>
 <td style="text-align: left;">
<b>Date Codes</b> </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>d </code> </td><td style="text-align: left;">  day of the month without leading zero (1 - 31) </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>dd</code> </td><td style="text-align: left;">  day of the month with leading zero (01 - 31)</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>ddd</code> </td><td style="text-align: left;"> abbreviated name for the day of the week (e.g. Mon) in the current user's language  </td>
</tr>
<tr>
 <td style="text-align: left;">
                  <code>dddd</code> </td><td style="text-align: left;">    full name for the day of the week (e.g. Monday) in the current user's language  </td>
</tr>
<tr>
 <td style="text-align: left;">
                  <code>m </code> </td><td style="text-align: left;">  month without leading zero (1 - 12) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>mm</code> </td><td style="text-align: left;">    month with leading zero (01 - 12) </td>
</tr>
<tr>
 <td style="text-align: left;">
                 <code>mmm </code>  </td><td style="text-align: left;">   abbreviated month name (e.g. Jan) in the current user's language </td>
</tr>
<tr>
 <td style="text-align: left;">
                <code>mmmm</code>  </td><td style="text-align: left;">    full month name (e.g. January) in the current user's language </td>
</tr>
<tr>
 <td style="text-align: left;">
            <code>y </code> </td><td style="text-align: left;">   year without century, without leading zero (0 - 99) </td>
</tr>
<tr>
 <td style="text-align: left;">
                 <code>yy </code> </td><td style="text-align: left;">      year without century, with leading zero (00 - 99) </td>
</tr>
<tr>
 <td style="text-align: left;">
            <code>yyyy </code>  </td><td style="text-align: left;">   year with century. For example: 2005 </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The function <code>as.CDateFmt()</code> converts ISO-8601 codes into the C-format codes used in base R.<br /> So
<code>as.CDateFmt("yyyy mm dd")</code> yields <code> "%Y %m %d"</code>.
</p>
<p>Even more variability is needed to display numeric values. For the most frequently used formats there are the following special codes available:
</p>

<table>
<tr>
 <td style="text-align: left;">
<b>Code</b> </td><td style="text-align: left;">  </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>e</code> </td><td style="text-align: left;"> scientific </td><td style="text-align: left;">  forces scientific representation of x, e.g. 3.141e-05. The number of digits,</td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> </td><td style="text-align: left;"> alignment and zero values are further respected.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">

<code>eng</code> </td><td style="text-align: left;"> engineering </td><td style="text-align: left;">  forces scientific representation of <code>x</code>, but only with powers that are a multiple of 3. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>engabb</code> </td><td style="text-align: left;"> engineering abbr. </td><td style="text-align: left;">  same as <code>eng</code>, but replaces the exponential representation by codes, </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"></td><td style="text-align: left;"> e.g. <code>M</code> for mega (1e6). See <code><a href="#topic+d.prefix">d.prefix</a></code>.</td>
</tr>
<tr>
 <td style="text-align: left;">

<code>%</code> </td><td style="text-align: left;"> percent </td><td style="text-align: left;"> will divide the given number by 100 and append the %-sign (without a separator).</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>p</code> </td><td style="text-align: left;"> p-value </td><td style="text-align: left;"> will wrap the function <code><a href="base.html#topic+format.pval">format.pval</a></code> and return a p-value format. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> </td><td style="text-align: left;"> Use <code>eps</code> to define the threshold to switch to a <code> &lt; 000 </code> representation.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>frac</code> </td><td style="text-align: left;"> fractions </td><td style="text-align: left;"> will (try to) convert numbers to fractions. So 0.1 will be displayed as 1/10. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"></td><td style="text-align: left;"> See <code><a href="MASS.html#topic+fractions">fractions</a>()</code>.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">

<code>*</code> </td><td style="text-align: left;"> significance </td><td style="text-align: left;"> will produce a significance representation of a p-value consisting of *  and .,  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td><td style="text-align: left;"> while the breaks are set according to the used defaults e.g. in <code>lm</code> as  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td><td style="text-align: left;"> [0, 0.001] = <code>***</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td><td style="text-align: left;"> (0.001, 0.01] = <code>**</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td><td style="text-align: left;"> (0.01, 0.05] = <code>*</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td><td style="text-align: left;"> (0.05, 0.1] = <code>.</code>  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> </td><td style="text-align: left;"> (0.1,1] = </td>
</tr>
<tr>
 <td style="text-align: left;">

<code>p*</code></td><td style="text-align: left;"> p-value stars</td><td style="text-align: left;"> will produce p-value and significance stars

</td>
</tr>

</table>

<p><code>fmt</code> can as well be an object of class <code>fmt</code> consisting of a list out of the arguments above.
This allows to store and manage the full format in variables or as options (in <code>DescToolsOptions()</code>) and use it as format template subsequently.  
</p>
<p>Finally <code>fmt</code> can also be a function in x, which makes formatting very flexible.
</p>
<p>New formats can be created by means of <code>as.fmt()</code>. This works quite straight on. We can use any of the arguments from <code>Format()</code> and combine them to a list. <br />
The following code will define a new format template named &quot;<code>myNumFmt</code>&quot; of the class <code>"fmt"</code>. Provided to <code>Format()</code> this will result in a number displayed with 2 fixed digits and a comma as big mark:
</p>
<pre>myNumFmt &lt;- as.fmt(digits=2, big.mark=",")
Format(12222.89345, fmt=myNumFmt) = 12,222.89</pre>
<p>The latter returns the same result as if the arguments would have been supplied directly: <br />
<code>Format(12222.89345, digits=2, big.mark=",")</code>.
</p>
<p>Many report functions (e.g. <code><a href="#topic+TOne">TOne</a>()</code>) in <b>DescTools</b> use three default formats for counts (named <code>"abs"</code>), numeric values (<code>"num"</code>) and percentages (<code>"per"</code>). These formats can be set by the user as options (see <code><a href="#topic+DescToolsOptions">DescToolsOptions</a>()</code>. For other purposes any number of any named formats can be defined. 
</p>
<p><code>Fmt()</code> is used to access and edit already defined Formats. It can directly adapt defined properties and returns the format template. <code>Fmt("num", digits=1, sci=10)</code> will use the current version of the numeric format and change the digits to 1 and the threshold to switch to scientifc presentation to numbers &gt;1e10 and &lt;1e-10.
Format templates can be altered using their names. With <code>Fmt(abs=Fmt("abs", big.mark=" "))</code> the format template for count values <code>"abs"</code> will be overwritten with the new values and stored as option for the current session.
</p>
<p>The formats can as well be organized as options. <code>DescToolsOptions("fmt")</code> would display the currently defined formats. This mechanic works analogously to the <code>options()</code> procedure of base R. So to store the current settings we can use 
</p>
<pre>opt &lt;- DescToolsOptions("fmt")
... do some stuff like redefining the global formats ...
DescToolOptions(opt)  </pre>
<p>The last command resets the options and so we have again the initial definitions for the format templates.
</p>


<h3>Value</h3>

<p>the formatted values as characters. <br />
If <code>x</code> was a <code>matrix</code>, then a the result will also be a <code>matrix</code>. (Hope this will not surprise you...)
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+format">format</a></code>, <code><a href="base.html#topic+formatC">formatC</a></code>, <code><a href="base.html#topic+prettyNum">prettyNum</a></code>, <code><a href="base.html#topic+sprintf">sprintf</a></code>, <code><a href="stats.html#topic+symnum">symnum</a></code>,<br />
<code><a href="#topic+StrAlign">StrAlign</a></code>, <code><a href="#topic+StrPad">StrPad</a></code>, <code><a href="base.html#topic+Sys.setlocale">Sys.setlocale</a></code>,<br />
<code><a href="#topic+Weekday">Weekday</a></code>, <code><a href="#topic+Month">Month</a></code>,
<code><a href="#topic+DescToolsOptions">DescToolsOptions</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Format(as.Date(c("2014-11-28", "2014-1-2")), fmt="ddd, d mmmm yyyy")
Format(as.Date(c("2014-11-28", "2014-1-2")), fmt="ddd, d mmmm yyyy", lang="engl")

x &lt;- pi * 10^(-10:10)

Format(x, digits=3, fmt="%", sci=NA)
Format(x, digits=4, sci=c(4, 6), ldigits=0, width=9, align=".")


# format a matrix
m &lt;- matrix(runif(100), nrow=10,
            dimnames=list(LETTERS[1:10], LETTERS[1:10]))

Format(m, digits=1)

# engineering format
Format(x, fmt="eng",  digits=2)
Format(x, fmt="engabb", ldigits=2, digits=2)
# combine with grams [g]
paste(Format(x, fmt="engabb", ldigits=2, digits=2), "g", sep="")

# example form symnum
pval &lt;- rev(sort(c(outer(1:6, 10^-(1:3)))))
noquote(cbind(Format(pval, fmt="p"), Format(pval, fmt="*")))

# use Fmt() to get and define new formats stored as option
Fmt()                        # all defined formats
Fmt("abs")                   # only format named "abs"
Fmt("nexist")                # only format named "nexist" (nonexisting)
Fmt("abs", "per", "nexist")
Fmt("abs", digits=3)         # get Fmt("abs") and overwrite digits
Fmt("abs", na.form="-")      # get Fmt("abs") and add user defined na.form

# define totally new format and store as option
Fmt(nob=as.fmt(digits=10, na.form="nodat"))

# overwrite an existing format
Fmt(nob=Fmt("nob", digits=5))
Fmt("nob")

# change the character to be used as the decimal point
opt &lt;- options(OutDec=",")
Format(1200, digits=2, big.mark = ".")
options(opt)
</code></pre>

<hr>
<h2 id='Frac'>Fractional Part and Maximal Digits of a Numeric Value
</h2><span id='topic+Frac'></span><span id='topic+MaxDigits'></span><span id='topic+Ndec'></span><span id='topic+Prec'></span>

<h3>Description</h3>

<p><code>Frac()</code> returns the fractional part of a numeric value.
<code>MaxDigits()</code> return the number of digits in <code>x</code>. <br />
<code>Ndec()</code> returns the number of decimals.<br />  <code>Prec()</code> returns the precision of a number <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Frac(x, dpwr = NA)
MaxDigits(x)
Ndec(x)
Prec(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Frac_+3A_x">x</code></td>
<td>
<p>the numeric value (or a vector of numerics), whose fractional part is to be calculated.
</p>
</td></tr>
<tr><td><code id="Frac_+3A_dpwr">dpwr</code></td>
<td>
<p>power of 10 for a factor z, the fractional part will be multiplied with. The result will be returned rounded to integer. Defaults to <code>NA</code> and will then be ignored.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+format.info">format.info</a></code>, <code><a href="base.html#topic+as.integer">as.integer</a></code>, <code><a href="base.html#topic+trunc">trunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(5)*100
x
Frac(x)

# multiply by 10^4
Frac(x, dpwr=4)

MaxDigits(c(1.25, 1.8, 12.0, 1.00000))

x &lt;- c("0.0000", "0", "159.283", "1.45e+10", "1.4599E+10" )
Ndec(x)
Prec(as.numeric(x))
</code></pre>

<hr>
<h2 id='Frechet'>The Frechet Distribution</h2><span id='topic+dFrechet'></span><span id='topic+pFrechet'></span><span id='topic+qFrechet'></span><span id='topic+rFrechet'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function
and random generation for the Frechet distribution with
location, scale and shape parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dFrechet(x, loc=0, scale=1, shape=1, log = FALSE)
pFrechet(q, loc=0, scale=1, shape=1, lower.tail = TRUE)
qFrechet(p, loc=0, scale=1, shape=1, lower.tail = TRUE)
rFrechet(n, loc=0, scale=1, shape=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Frechet_+3A_x">x</code>, <code id="Frechet_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="Frechet_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="Frechet_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="Frechet_+3A_loc">loc</code>, <code id="Frechet_+3A_scale">scale</code>, <code id="Frechet_+3A_shape">shape</code></td>
<td>
<p>Location, scale and shape parameters (can be
given as vectors).</p>
</td></tr>
<tr><td><code id="Frechet_+3A_log">log</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the log density is returned.</p>
</td></tr>
<tr><td><code id="Frechet_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), probabilities
are P[X &lt;= x], otherwise, P[X &gt; x]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Frechet distribution function with parameters
<code class="reqn">loc = a</code>, <code class="reqn">scale = b</code> and
<code class="reqn">shape = s</code> is
</p>
<p style="text-align: center;"><code class="reqn">G(z) = \exp\left\{-\left(\frac{z-a}{b}\right)^{-s}
  \right\}</code>
</p>

<p>for <code class="reqn">z &gt; a</code> and zero otherwise, where <code class="reqn">b &gt; 0</code> and
<code class="reqn">s &gt; 0</code>.
</p>


<h3>Value</h3>

<p><code>dFrechet</code> gives the density function, <code>pFrechet</code> gives
the distribution function, <code>qFrechet</code> gives the quantile
function, and <code>rFrechet</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Alec Stephenson &lt;alec_stephenson@hotmail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+rGenExtrVal">rGenExtrVal</a></code>, <code><a href="#topic+rGumbel">rGumbel</a></code>, <code><a href="#topic+rRevWeibull">rRevWeibull</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dFrechet(2:4, 1, 0.5, 0.8)
pFrechet(2:4, 1, 0.5, 0.8)
qFrechet(seq(0.9, 0.6, -0.1), 2, 0.5, 0.8)
rFrechet(6, 1, 0.5, 0.8)
p &lt;- (1:9)/10
pFrechet(qFrechet(p, 1, 2, 0.8), 1, 2, 0.8)
## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
</code></pre>

<hr>
<h2 id='Freq'>
Frequency Table for a Single Variable
</h2><span id='topic+Freq'></span><span id='topic+print.Freq'></span>

<h3>Description</h3>

<p>Calculates absolute and relative frequencies of a vector <code>x</code>. Continuous (numeric) variables
will be cut using the same logic as used by the function <code><a href="graphics.html#topic+hist">hist</a></code>.
Categorical variables will be aggregated by <code><a href="base.html#topic+table">table</a></code>. The result will contain single and cumulative frequencies for both, absolute values and percentages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Freq(x, breaks = hist(x, plot = FALSE)$breaks, include.lowest = TRUE,
     ord = c("level", "desc", "asc", "name"),
     useNA = c("no", "ifany", "always"), ...)

## S3 method for class 'Freq'
print(x, digits = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Freq_+3A_x">x</code></td>
<td>
<p>the variable to be described, can be any atomic type.
</p>
</td></tr>
<tr><td><code id="Freq_+3A_breaks">breaks</code></td>
<td>
<p>either a numeric vector of two or more cut points or a single number (greater than or equal to 2)
giving the number of intervals into which x is to be cut. Default taken from the function <code>hist()</code>.
This is ignored if x is not of numeric type.
</p>
</td></tr>
<tr><td><code id="Freq_+3A_include.lowest">include.lowest</code></td>
<td>
<p>logical, indicating if an x[i] equal to the lowest (or highest, for <code>right = FALSE</code>) <code>"breaks"</code> value should be included. Ignored if x is not of numeric type.
</p>
</td></tr>
<tr><td><code id="Freq_+3A_ord">ord</code></td>
<td>
<p>how should the result be ordered? Default is <code>"level"</code>, other choices are 'by frequency' (<code>"descending"</code> or <code>"ascending"</code>)
or 'by name of the levels' (<code>"name"</code>). The argument can be abbreviated. This is ignored if x is numeric.
</p>
</td></tr>
<tr><td><code id="Freq_+3A_usena">useNA</code></td>
<td>
<p>one out of <code>"no"</code>, <code>"ifany"</code>, <code>"always"</code>. Defines whether to include extra <code>NA</code> levels in the table.
Defaults to <code>"no"</code> which is the <code><a href="base.html#topic+table">table</a>()</code> default too.
</p>
</td></tr>
<tr><td><code id="Freq_+3A_digits">digits</code></td>
<td>
<p>integer, determining the number of digits used to format the relative frequencies.
</p>
</td></tr>
<tr><td><code id="Freq_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+cut">cut</a>()</code>. Use <code>dig.lab</code> to control the format of numeric group names. Use the argument <code>right</code> to define if the intervals should be closed on the right (and open on the left) or vice versa. <br />
In <code>print.Freq</code> the dots are not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default only the valid cases are considered for the frequencies, say <code>NA</code> values are excluded. (This is in accordance with the default behavior of the R function <code>table</code>, which seemed a reasonable reference.) If the <code>NA</code>s should be included you can set the <code>useNA</code>  argument to either <code>"ifany"</code> or <code>"always"</code>.
</p>
<p>For numeric variables, if <code>breaks</code> is specified as a single number, the range of the data is divided into breaks pieces of equal length,
and then the outer limits are moved away by 0.1% of the range to ensure that the extreme values both fall
within the break intervals.
(If <code>x</code> is a constant vector, equal-length intervals are created that cover the single value.) See <code><a href="base.html#topic+cut">cut</a></code>.
</p>


<h3>Value</h3>

<p>an object of type <code>"Freq"</code>, which is basically a data.frame with 5 columns (earning a specific print routine), containing the following components:
</p>
<table>
<tr><td><code>level</code></td>
<td>
<p> factor. The levels of the grouping variable.</p>
</td></tr>
<tr><td><code>freq</code></td>
<td>
<p>  integer. The absolute frequencies. </p>
</td></tr>
<tr><td><code>perc</code></td>
<td>
<p> numeric. The relative frequencies (percent).</p>
</td></tr>
<tr><td><code>cumfreq</code></td>
<td>
<p>integer. The cumulative sum of the absolute frequencies.</p>
</td></tr>
<tr><td><code>cumperc</code></td>
<td>
<p>numeric. The cumulative sum of the relative frequencies.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code>, <code><a href="graphics.html#topic+hist">hist</a></code>, <code><a href="base.html#topic+cumsum">cumsum</a></code>, <code><a href="base.html#topic+table">table</a></code>, <code><a href="base.html#topic+prop.table">prop.table</a></code>,
<code><a href="#topic+PercTable">PercTable</a></code>, <code><a href="#topic+Freq2D">Freq2D</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(d.pizza)

# result is a data.frame
d.freq &lt;- Freq(d.pizza$price)
d.freq

# it is printed by default with 3 digits for the percent values,
# but the number of digits can be defined in the print function
print(d.freq, digits=5)

# sorted by frequency
Freq(d.pizza$driver, ord="desc")

# sorted by name using all the observations, say including NAs
Freq(d.pizza$driver, ord="name", useNA="ifany")

# percentages and cumulative frequencies for a vector of count data
Freq(as.table(c(2,4,12,8)))
</code></pre>

<hr>
<h2 id='Freq2D'>Bivariate (Two-Dimensional) Frequency Distribution</h2><span id='topic+Freq2D'></span><span id='topic+Freq2D.default'></span><span id='topic+Freq2D.formula'></span>

<h3>Description</h3>

<p>Calculate a frequency distribution for two continuous variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Freq2D(x, ...)

## S3 method for class 'formula'
Freq2D(formula, data, subset, ...)

## Default S3 method:
Freq2D(x, y, n=20, pad=0, dnn=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Freq2D_+3A_x">x</code></td>
<td>
<p>a vector of x values, or a data frame whose first two columns
contain the x and y values.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_y">y</code></td>
<td>
<p>a vector of y values.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code>, such as <code>y~x</code>.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>, <code>matrix</code>, or <code>list</code> from
which the variables in <code>formula</code> should be taken.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_n">n</code></td>
<td>
<p>the desired number of bins for the output, a scalar or a
vector of length 2.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_pad">pad</code></td>
<td>
<p>number of rows and columns to add to each margin,
containing only zeros.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_dnn">dnn</code></td>
<td>
<p>the names to be given to the dimensions in the result.</p>
</td></tr>
<tr><td><code id="Freq2D_+3A_...">...</code></td>
<td>
<p>named arguments to be passed to the default method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The exact number of bins is determined by the
<code><a href="base.html#topic+pretty">pretty</a></code> function, based on the value of <code>n</code>.
</p>
<p>Padding the margins with zeros can be helpful for subsequent analysis,
such as smoothing.
</p>
<p>The <code>print</code> logical flag only has an effect when <code>layout=1</code>.
</p>


<h3>Value</h3>

<p>The <code>layout</code> argument specifies one of the following formats for
the binned frequency output:
</p>

<ol>
<li><p><code>matrix</code> that is easy to read, aligned like a
scatterplot.
</p>
</li>
<li><p><code>list</code> with three elements (x, y, matrix) that can be
passed to various plotting functions.
</p>
</li>
<li><p><code>data.frame</code> with three columns (x, y, frequency) that
can be analyzed further.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Arni Magnusson &lt;thisisarni@gmail.com&gt;&gt;</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code>, <code><a href="base.html#topic+table">table</a></code>, and <code><a href="base.html#topic+print.table">print.table</a></code>
are the basic underlying functions.<br />
<code><a href="#topic+Freq">Freq</a></code>, <code><a href="#topic+PercTable">PercTable</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Freq2D(quakes$long, quakes$lat, dnn="")
Freq2D(lat ~ long, quakes, n=c(10, 20), pad=1)

# range(Freq2D(saithe, print=FALSE))

# Layout, plot
# Freq2D(saithe, layout=2)
# Freq2D(saithe, layout=3)
# contour(Freq2D(saithe, layout=2))
# lattice::contourplot(Freq ~ Bio + HR, Freq2D(saithe,layout=3))
</code></pre>

<hr>
<h2 id='GCD+2C+20LCM'>Greatest Common Divisor and Least Common Multiple</h2><span id='topic+GCD'></span><span id='topic+LCM'></span>

<h3>Description</h3>

<p>Calculates the greatest common divisor (GCD) and least common multiple (LCM) of all the values present in its arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GCD(..., na.rm = FALSE)
LCM(..., na.rm = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GCD+2B2C+2B20LCM_+3A_...">...</code></td>
<td>
<p>integer or logical vectors.</p>
</td></tr>
<tr><td><code id="GCD+2B2C+2B20LCM_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values (including NaN) be removed?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computation is based on the Euclidean algorithm without using the extended
version.The greatest common divisor for
all numbers in the integer vector <code>x</code> will be computed (the multiple GCD).
</p>


<h3>Value</h3>

<p>A numeric (integer) value.
</p>


<h3>Note</h3>

<p>The following relation is always true:
</p>
<p><code>n * m = GCD(n, m) * LCM(n, m)</code>
</p>


<h3>Author(s)</h3>

<p>Dirk Eddelbuettel &lt;edd@debian.org&gt; (RCPP part), Andri Signorell &lt;andri@signorell.net&gt;, originally based on code in package <span class="pkg">numbers</span> by Hans W Borchers &lt;hwborchers@googlemail.com&gt; </p>


<h3>References</h3>

<p>Eddelbuettel, D. (2013). Seamless R and C++ Integration with Rcpp. New York, NY: Springer.</p>


<h3>See Also</h3>

<p><code><a href="#topic+Factorize">Factorize</a></code>, <code><a href="#topic+Primes">Primes</a></code>, <code><a href="#topic+IsPrime">IsPrime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GCD(12, 10)
GCD(144, 233)    # Fibonacci numbers are relatively prime to each other

LCM(12, 10)
LCM(144, 233)    # = 144 * 233

# all elements will be flattened by unlist
GCD(2, 3, c(5, 7) * 11)
GCD(c(2*3, 3*5, 5*7))
LCM(c(2, 3, 5, 7) * 11)
LCM(2*3, 3*5, 5*7)
</code></pre>

<hr>
<h2 id='GenExtrVal'>The Generalized Extreme Value Distribution</h2><span id='topic+dGenExtrVal'></span><span id='topic+pGenExtrVal'></span><span id='topic+qGenExtrVal'></span><span id='topic+rGenExtrVal'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random generation for the generalized Extreme value (GenExtrVal)
distribution with location, scale and shape parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dGenExtrVal(x, loc=0, scale=1, shape=0, log = FALSE)
pGenExtrVal(q, loc=0, scale=1, shape=0, lower.tail = TRUE)
qGenExtrVal(p, loc=0, scale=1, shape=0, lower.tail = TRUE)
rGenExtrVal(n, loc=0, scale=1, shape=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenExtrVal_+3A_x">x</code>, <code id="GenExtrVal_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="GenExtrVal_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="GenExtrVal_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="GenExtrVal_+3A_loc">loc</code>, <code id="GenExtrVal_+3A_scale">scale</code>, <code id="GenExtrVal_+3A_shape">shape</code></td>
<td>
<p>Location, scale and shape parameters; the
<code>shape</code> argument cannot be a vector (must have length one).</p>
</td></tr>
<tr><td><code id="GenExtrVal_+3A_log">log</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the log density is returned.</p>
</td></tr>
<tr><td><code id="GenExtrVal_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), probabilities
are P[X &lt;= x], otherwise, P[X &gt; x]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GenExtrVal distribution function with parameters
<code class="reqn">loc = a</code>, <code class="reqn">scale = b</code> and
<code class="reqn">shape = s</code> is
</p>
<p style="text-align: center;"><code class="reqn">G(z) = \exp\left[-\{1+s(z-a)/b\}^{-1/s}\right]</code>
</p>

<p>for <code class="reqn">1+s(z-a)/b &gt; 0</code>, where <code class="reqn">b &gt; 0</code>.
If <code class="reqn">s = 0</code> the distribution is defined by continuity.
If <code class="reqn">1+s(z-a)/b \leq 0</code>, the value <code class="reqn">z</code> is
either greater than the upper end point (if <code class="reqn">s &lt; 0</code>), or less
than the lower end point (if <code class="reqn">s &gt; 0</code>).
</p>
<p>The parametric form of the GenExtrVal encompasses that of the Gumbel,
Frechet and reverse Weibull distributions, which are obtained
for <code class="reqn">s = 0</code>, <code class="reqn">s &gt; 0</code> and <code class="reqn">s &lt; 0</code> respectively.
It was first introduced by Jenkinson (1955).
</p>


<h3>Value</h3>

<p><code>dGenExtrVal</code> gives the density function, <code>pGenExtrVal</code> gives the
distribution function, <code>qGenExtrVal</code> gives the quantile function,
and <code>rGenExtrVal</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Alec Stephenson &lt;alec_stephenson@hotmail.com&gt;</p>


<h3>References</h3>

<p>Jenkinson, A. F. (1955)
The frequency distribution of the annual maximum (or minimum) of
meteorological elements.
<em>Quart. J. R. Met. Soc.</em>, <b>81</b>, 158&ndash;171.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rFrechet">rFrechet</a></code>,
<code><a href="#topic+rGumbel">rGumbel</a></code>, <code><a href="#topic+rRevWeibull">rRevWeibull</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dGenExtrVal(2:4, 1, 0.5, 0.8)
pGenExtrVal(2:4, 1, 0.5, 0.8)
qGenExtrVal(seq(0.9, 0.6, -0.1), 2, 0.5, 0.8)
rGenExtrVal(6, 1, 0.5, 0.8)
p &lt;- (1:9)/10
pGenExtrVal(qGenExtrVal(p, 1, 2, 0.8), 1, 2, 0.8)
## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
</code></pre>

<hr>
<h2 id='GenPareto'>The Generalized Pareto Distribution</h2><span id='topic+dGenPareto'></span><span id='topic+pGenPareto'></span><span id='topic+qGenPareto'></span><span id='topic+rGenPareto'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random generation for the generalized Pareto distribution (GenPareto)
with location, scale and shape parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dGenPareto(x, loc=0, scale=1, shape=0, log = FALSE)
pGenPareto(q, loc=0, scale=1, shape=0, lower.tail = TRUE)
qGenPareto(p, loc=0, scale=1, shape=0, lower.tail = TRUE)
rGenPareto(n, loc=0, scale=1, shape=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenPareto_+3A_x">x</code>, <code id="GenPareto_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="GenPareto_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="GenPareto_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="GenPareto_+3A_loc">loc</code>, <code id="GenPareto_+3A_scale">scale</code>, <code id="GenPareto_+3A_shape">shape</code></td>
<td>
<p>Location, scale and shape parameters; the
<code>shape</code> argument cannot be a vector (must have length one).</p>
</td></tr>
<tr><td><code id="GenPareto_+3A_log">log</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the log density is returned.</p>
</td></tr>
<tr><td><code id="GenPareto_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), probabilities
are P[X &lt;= x], otherwise, P[X &gt; x]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generalized Pareto distribution function (Pickands, 1975) with
parameters <code class="reqn">loc = a</code>, <code class="reqn">scale = b</code> and
<code class="reqn">shape = s</code> is
</p>
<p style="text-align: center;"><code class="reqn">G(z) = 1 - \{1+s(z-a)/b\}^{-1/s}</code>
</p>

<p>for <code class="reqn">1+s(z-a)/b &gt; 0</code> and <code class="reqn">z &gt; a</code>, where <code class="reqn">b &gt; 0</code>.
If <code class="reqn">s = 0</code> the distribution is defined by continuity.
</p>


<h3>Value</h3>

<p><code>dGenPareto</code> gives the density function, <code>pGenPareto</code> gives the
distribution function, <code>qGenPareto</code> gives the quantile function,
and <code>rGenPareto</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Alec Stephenson &lt;alec_stephenson@hotmail.com&gt;</p>


<h3>References</h3>

<p>Pickands, J. (1975)
Statistical inference using Extreme Order statistics.
<em>Annals of Statistics</em>, <b>3</b>, 119&ndash;131.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rGenExtrVal">rGenExtrVal</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dGenPareto(2:4, 1, 0.5, 0.8)
pGenPareto(2:4, 1, 0.5, 0.8)
qGenPareto(seq(0.9, 0.6, -0.1), 2, 0.5, 0.8)
rGenPareto(6, 1, 0.5, 0.8)
p &lt;- (1:9)/10
pGenPareto(qGenPareto(p, 1, 2, 0.8), 1, 2, 0.8)
## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
</code></pre>

<hr>
<h2 id='GenRandGroups'>Generate Random Groups
</h2><span id='topic+GenRandGroups'></span>

<h3>Description</h3>

<p>Generates a random grouping from a given data vector, where the group sizes correspond to the numeric vector grp_n.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GenRandGroups(x, grp_n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GenRandGroups_+3A_x">x</code></td>
<td>
<p>a vector containing the objects which should be grouped
</p>
</td></tr>
<tr><td><code id="GenRandGroups_+3A_grp_n">grp_n</code></td>
<td>
<p>an integer vector with the required group sizes
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For group divisions in class, it is often useful to have a function available that randomizes these divisions. 
</p>


<h3>Value</h3>

<p>a list sized length of <code>grp_n</code> with the x elements assigned to their group.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CombN">CombN</a></code>, <code><a href="#topic+CombSet">CombSet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># say we have 12 students and want 3 groups with sizes 4,3, and 5

GenRandGroups(x=LETTERS[1:12], grp_n=c(4,3,5))
</code></pre>

<hr>
<h2 id='GeomSn'>Geometric Series
</h2><span id='topic+GeomSn'></span>

<h3>Description</h3>

<p>A geometric sequence is a sequence, such that each term is given by a multiple of q of the previous one. A geometric series consists out of the sum of all former values of a geometric sequence..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GeomSn(a1, q, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GeomSn_+3A_a1">a1</code></td>
<td>
<p>the first element of the sequence
</p>
</td></tr>
<tr><td><code id="GeomSn_+3A_q">q</code></td>
<td>
<p>the factor of the sequence
</p>
</td></tr>
<tr><td><code id="GeomSn_+3A_n">n</code></td>
<td>
<p>number of elements to include in the sum
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the sum as numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sum">sum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GeomSn(a1=3, q=2, n=5)

# calculates the sum of the first 5 elements of the sequence
(gseq &lt;- 3 * (2^(0:5)))
sum(gseq)

GeomSn(a1=3, q=2, n=0:5)
</code></pre>

<hr>
<h2 id='GeomTrans'>Geometric Transformations
</h2><span id='topic+GeomTrans'></span>

<h3>Description</h3>

<p>This function transforms geometric structures by translating, scaling and/or rotating them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GeomTrans(x, y = NULL, trans = 0, scale = 1, theta = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GeomTrans_+3A_x">x</code>, <code id="GeomTrans_+3A_y">y</code></td>
<td>
<p>vectors containing the coordinates of the vertices of the polygon
, which has to be transformed.  The coordinates can be passed in a plotting structure (a list with x and y components), a two-column matrix, .... See <code><a href="grDevices.html#topic+xy.coords">xy.coords</a></code>.
</p>
</td></tr>
<tr><td><code id="GeomTrans_+3A_trans">trans</code></td>
<td>
<p>a vector of two values for the translation in x-, resp. y-direction. If only one value is supplied it will be recycled.
</p>
</td></tr>
<tr><td><code id="GeomTrans_+3A_scale">scale</code></td>
<td>
<p>a vector of two values for the scaling factor in x-, resp. y-direction. If only one value is supplied it will be recycled.
</p>
</td></tr>
<tr><td><code id="GeomTrans_+3A_theta">theta</code></td>
<td>
<p>angle of the rotation in radians starting from 3 o'clock counterclockwise.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function invisibly returns a list of the coordinates for the transformed shape(s).
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="#topic+DrawRegPolygon">DrawRegPolygon</a></code>, <code><a href="#topic+DrawEllipse">DrawEllipse</a></code>, <code><a href="#topic+DrawArc">DrawArc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># let's have a triangle
Canvas(main="Rotation")
x &lt;- DrawRegPolygon(nv=3)[[1]]

xt &lt;- GeomTrans(x, trans=c(1, 3), scale=c(2, 2), theta=pi/4)
polygon(xt)
</code></pre>

<hr>
<h2 id='GetCalls'>Return All Used Functions Within a Function
</h2><span id='topic+GetCalls'></span>

<h3>Description</h3>

<p>For screening purposes it can be useful to get a list of all function calls our function may depend on. <code>GetCall()</code> parses the function source and return all found function calls grouped by their package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetCalls(fun, alphabetic = TRUE, package = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetCalls_+3A_fun">fun</code></td>
<td>
<p>the name of the function to be parsed
</p>
</td></tr>
<tr><td><code id="GetCalls_+3A_alphabetic">alphabetic</code></td>
<td>
<p>logic, determining the order of the result
</p>
</td></tr>
<tr><td><code id="GetCalls_+3A_package">package</code></td>
<td>
<p>name of the package, if only functions of this specific package should be returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of vectors structered by package 
</p>


<h3>Author(s)</h3>

<p>Nicholas Cooper &lt;njcooper at gmx.co.uk&gt; (in package NCmisc)
with some tweaking by Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LsFct">LsFct</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>GetCalls("t.test.default")

sapply(c("Closest", "Format"), 
       function(x) paste(unname(unlist(GetCalls(x))), collapse=", "))
</code></pre>

<hr>
<h2 id='GetCurrWrd'>Get a Handle to a Running Word/Excel Instance
</h2><span id='topic+GetCurrWrd'></span><span id='topic+GetCurrXL'></span>

<h3>Description</h3>

<p>Look for a running Word, resp. Excel instance and return its handle. If no running instance is found a new instance will be created (which will be communicated with a warning).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetCurrWrd()
GetCurrXL()
</code></pre>


<h3>Value</h3>

<p>a handle (pointer) to the running Word, resp. Excel instance. 
</p>


<h3>Note</h3>

<p>When closing an application instance, the value of the pointer in R is not somehow automatically invalidated. In such cases the corresponding variable contains an invalid address. 
Whether the pointer still refers to a valid running application instance can be checked by <code><a href="#topic+IsValidHwnd">IsValidHwnd</a></code>. </p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+IsValidHwnd">IsValidHwnd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: # Windows-specific example

# Start a new instance
GetNewWrd()

# grab the handle to this instance
wrd &lt;- GetCurrWrd()

# this should be valid
IsValidHwnd(wrd)

# close the instance
wrd$quit()

# now it should be gone and the pointer invalid
if(IsValidHwnd(wrd)){ 
  print("Ouups! Still there?")
} else {  
  print("GetCurrWrd: no running word instance found...")
}

## End(Not run)
</code></pre>

<hr>
<h2 id='GetNewWrd'>
Create a New Word Instance
</h2><span id='topic+GetNewWrd'></span><span id='topic+WrdKill'></span><span id='topic+createCOMReference'></span>

<h3>Description</h3>

<p>Start a new instance of Word and return its handle.
By means of this handle we can then control the word application. <br />
<code>WrdKill</code> ends a running MS-Word task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetNewWrd(visible = TRUE, template = "Normal", header = FALSE,
          main = "Descriptive report")

WrdKill()


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetNewWrd_+3A_visible">visible</code></td>
<td>
<p>logical, should Word made visible? Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="GetNewWrd_+3A_template">template</code></td>
<td>
<p>the name of the template to be used for creating a new document.
</p>
</td></tr>
<tr><td><code id="GetNewWrd_+3A_header">header</code></td>
<td>
<p>logical, should a caption and a list of contents be inserted? Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="GetNewWrd_+3A_main">main</code></td>
<td>
<p>the main title of the report
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The package <b>RDCOMClient</b> reveals the whole VBA-world of MS-Word. So generally speaking any VBA code can be run fully controlled by R. In practise, it might be a good idea to record a macro and rewrite the VB-code in R.<br />
</p>
<p>Here's a list of some frequently used commands. Let's assume we have a handle to the application  and a handle to the current selection defined as:
</p>
<pre>
wrd &lt;- GetNewWrd()
sel &lt;- wrd$Selection()
</pre>
<p>Then we can access the most common properties as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
new document </td><td style="text-align: left;"> <code>wrd[["Documents"]]$Add(template, FALSE, 0)</code>, template is the templatename. </td>
</tr>
<tr>
 <td style="text-align: left;">
open document </td><td style="text-align: left;"> <code>wrd[["Documents"]]$Open(Filename="C:/MyPath/MyDocument.docx")</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
save document </td><td style="text-align: left;"> <code>wrd$ActiveDocument()$SaveAs2(FileName="P:/MyFile.docx")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
quit word </td><td style="text-align: left;"> <code>wrd$quit()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
kill word task </td><td style="text-align: left;"> <code>WrdKill</code> kills a running word task (which might not be ended with quit.) </td>
</tr>
<tr>
 <td style="text-align: left;">
normal text </td><td style="text-align: left;"> Use <code><a href="#topic+ToWrd">ToWrd</a></code> which offers many arguments as fontname, size, color, alignment etc. </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;">  <code>ToWrd("Lorem ipsum dolor sit amet, consetetur", </code></td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;">    <code>font=list(name="Arial", size=10, col=wdConst$wdColorRed)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
simple text </td><td style="text-align: left;"> <code>sel$TypeText("sed diam nonumy eirmod tempor invidunt ut labore")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
heading </td><td style="text-align: left;">  <code>WrdCaption("My Word-Story", index=1)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
insert R output </td><td style="text-align: left;"> <code>ToWrd(capture.output(str(d.diamonds)))</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
pagebreak </td><td style="text-align: left;"> <code>sel$InsertBreak(wdConst$wdPageBreak)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
sectionbreak </td><td style="text-align: left;"> <code>sel$InsertBreak(wdConst$wdSectionBreakContinuous)</code> </td>
</tr>
<tr>
 <td style="text-align: left;"></td><td style="text-align: left;"> (<code>wdSectionBreakNextPage</code>) </td>
</tr>
<tr>
 <td style="text-align: left;">
move cursor right </td><td style="text-align: left;"> <code>sel$MoveRight(Unit=wdConst$wdCharacter, Count=2, Extend=wdConst$wdExtend)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
goto end </td><td style="text-align: left;"> <code>sel$EndKey(Unit=wdConst$wdStory)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
pagesetup </td><td style="text-align: left;"> <code>sel[["PageSetup"]][["Bottommargin"]] &lt;- 4 * 72</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
orientation </td><td style="text-align: left;"> <code>sel[["PageSetup"]][["Orientation"]] &lt;- wdConst$wdOrientLandscape</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
add bookmark </td><td style="text-align: left;"> <code>wrd[["ActiveDocument"]][["Bookmarks"]]$Add("myBookmark")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
goto bookmark </td><td style="text-align: left;"> <code>sel$GoTo(wdConst$wdGoToBookmark, 0, 0, "myBookmark")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
update bookmark </td><td style="text-align: left;"> <code>WrdUpdateBookmark("myBookmark", "New text for my bookmark")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
show document map </td><td style="text-align: left;"> <code> wrd[["ActiveWindow"]][["DocumentMap"]] &lt;- TRUE</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
create table </td><td style="text-align: left;">  <code><a href="#topic+WrdTable">WrdTable</a></code>() which allows to define the table's geometry </td>
</tr>
<tr>
 <td style="text-align: left;">
insert caption </td><td style="text-align: left;"> <code>sel$InsertCaption(Label="Abbildung", TitleAutoText="InsertCaption",</code></td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> <code>Title="My Title")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
tables of figures </td><td style="text-align: left;"> <code>wrd$ActiveDocument()$TablesOfFigures()$Add(Range=sel$range(),</code></td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> <code>Caption="Figure")</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
insert header
  </td><td style="text-align: left;"> <code>wview &lt;- wrd[["ActiveWindow"]][["ActivePane"]][["View"]][["SeekView"]] </code></td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;"> <code>wview &lt;- ifelse(header, wdConst$wdSeekCurrentPageHeader, wdConst$wdSeekCurrentPageFooter) </code></td>
</tr>
<tr>
 <td style="text-align: left;">
  </td><td style="text-align: left;"> <code>ToWrd(x, ..., wrd=wrd) </code></td>
</tr>
<tr>
 <td style="text-align: left;">

</td>
</tr>

</table>



<h3>Value</h3>

<p>a handle (pointer) to the created Word instance.
</p>


<h3>Note</h3>

<p>Note that the list of contents has to be refreshed by hand after inserting text (if inserted by <code>header = TRUE</code>).
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GetNewXL">GetNewXL</a></code>, <code><a href="#topic+GetNewPP">GetNewPP</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example

wrd &lt;- GetNewWrd()
Desc(d.pizza[,1:4], wrd=wrd)

wrd &lt;- GetNewWrd(header=TRUE)
Desc(d.pizza[,1:4], wrd=wrd)

# enumerate all bookmarks in active document
for(i in 1:wrd[["ActiveDocument"]][["Bookmarks"]]$count()){
  print(wrd[["ActiveDocument"]][["Bookmarks"]]$Item(i)$Name())
}

## End(Not run)
</code></pre>

<hr>
<h2 id='GetNewXL'>Create a New Excel Instance
</h2><span id='topic+GetNewXL'></span>

<h3>Description</h3>

<p>Start a new instance of Excel and return its handle.
This is needed to address the Excel application and objects afterwards.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetNewXL(visible = TRUE, newdoc = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetNewXL_+3A_visible">visible</code></td>
<td>
<p>logical, should Excel made visible? Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="GetNewXL_+3A_newdoc">newdoc</code></td>
<td>
<p>logical, determining if a new workbook should be created. Defaults to <code>TRUE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here's a list of some frequently used commands.<br />
Let's assume:
</p>
<pre>xl &lt;- GetNewXL()
</pre>

<table>
<tr>
 <td style="text-align: left;">
workbooks </td><td style="text-align: left;"> <code>xl$workbooks()$count()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
quit excel </td><td style="text-align: left;"> <code>xl$quit()</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+XLView">XLView</a></code>, <code><a href="#topic+XLGetRange">XLGetRange</a></code>, <code><a href="#topic+XLGetWorkbook">XLGetWorkbook</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example
# get a handle to a new excel instance
xl &lt;- GetNewXL()

## End(Not run)
</code></pre>

<hr>
<h2 id='Gini'>Gini Coefficient
</h2><span id='topic+Gini'></span>

<h3>Description</h3>

<p>Compute the Gini coefficient, the most commonly used measure of inequality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gini(x, weights = NULL, unbiased = TRUE,
     conf.level = NA, R = 10000, type = "bca", na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gini_+3A_x">x</code></td>
<td>
<p>a vector containing at least non-negative elements. The result will be <code>NA</code>, if x contains negative elements.
</p>
</td></tr>
<tr><td><code id="Gini_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Gini_+3A_unbiased">unbiased</code></td>
<td>
<p>logical. In order for G to be an unbiased estimate of the true population value,
calculated gini is multiplied by <code class="reqn">n/(n-1)</code>. Default is TRUE. (See Dixon, 1987)
</p>
</td></tr>
<tr><td><code id="Gini_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the confidence interval, restricted to lie between 0 and 1.
If set to <code>TRUE</code> the bootstrap confidence intervals are calculated.
If set to <code>NA</code> (default) no confidence intervals are returned.
</p>
</td></tr>
<tr><td><code id="Gini_+3A_r">R</code></td>
<td>
<p>number of bootstrap replicates. Usually this will be a single positive integer.
For importance resampling, some resamples may use one set of weights and others use a different set of weights. In this case R would be a vector of
integers where each component gives the number of resamples from each of the rows of weights.<br />
This is ignored if no confidence intervals are to be calculated.
</p>
</td></tr>
<tr><td><code id="Gini_+3A_type">type</code></td>
<td>
<p>character string representing the type of interval required.
The value should be one out of the c(<code>"norm"</code>,<code>"basic"</code>, <code>"stud"</code>,
<code>"perc"</code> or <code>"bca"</code>).<br />
This argument is ignored if no confidence intervals are to be calculated.
</p>
</td></tr>
<tr><td><code id="Gini_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The range of the Gini coefficient goes from 0 (no concentration) to <code class="reqn">\sqrt(\frac{n-1}{n})</code> (maximal concentration). The bias corrected Gini coefficient goes from 0 to 1.<br />
The small sample variance properties of the Gini coefficient are not known, and large sample approximations to the variance of the coefficient are poor (Mills and Zandvakili, 1997; Glasser, 1962; Dixon et al., 1987),
therefore confidence intervals are calculated via bootstrap re-sampling methods (Efron and Tibshirani, 1997). <br />
Two types of bootstrap confidence intervals are commonly used, these are
percentile and bias-corrected (Mills and Zandvakili, 1997; Dixon et al., 1987; Efron and Tibshirani, 1997).
The bias-corrected intervals are most appropriate for most applications. This is set as default for the <code>type</code> argument (<code>"bca"</code>).
Dixon (1987) describes a refinement of the bias-corrected method known as 'accelerated' -
this produces values very closed to conventional bias corrected intervals.<br />
(Iain Buchan (2002) <em>Calculating the Gini coefficient of inequality</em>, see: <a href="https://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm">https://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm</a>)
</p>


<h3>Value</h3>

<p>If <code>conf.level</code> is set to <code>NA</code> then the result will be
</p>
<table>
<tr><td><code>a</code></td>
<td>
<p> single numeric value</p>
</td></tr></table>
<p> and
if a <code>conf.level</code> is provided, a named numeric vector with 3 elements:
</p>
<table>
<tr><td><code>gini</code></td>
<td>
<p>Gini coefficient</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Cowell, F. A. (2000) Measurement of Inequality in Atkinson, A. B. / Bourguignon, F. (Eds): <em>Handbook of Income Distribution</em>. Amsterdam.
</p>
<p>Cowell, F. A. (1995) <em>Measuring Inequality</em> Harvester Wheatshef: Prentice Hall.
</p>
<p>Marshall, Olkin (1979) <em>Inequalities: Theory of Majorization and Its
Applications</em>. New York: Academic Press.
</p>
<p>Glasser C. (1962) Variance formulas for the mean difference and coefficient of concentration.
<em>Journal of the American Statistical Association</em> 57:648-654.
</p>
<p>Mills JA, Zandvakili A. (1997). Statistical inference via bootstrapping for measures of inequality.
<em>Journal of Applied Econometrics</em> 12:133-150.
</p>
<p>Dixon, PM, Weiner J., Mitchell-Olds T, Woodley R. (1987) Boot-strapping the Gini coefficient of inequality.
<em>Ecology</em> 68:1548-1551.
</p>
<p>Efron B, Tibshirani R. (1997) Improvements on cross-validation:
The bootstrap method. <em>Journal of the American Statistical Association</em> 92:548-560.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Herfindahl">Herfindahl</a></code>, <code><a href="#topic+Rosenbluth">Rosenbluth</a></code> for concentration measures,
<code><a href="#topic+Lc">Lc</a></code> for the Lorenz curve<br />
<code><a href="ineq.html#topic+ineq">ineq</a>()</code> in the package <span class="pkg">ineq</span> contains additional inequality measures</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate vector (of incomes)
x &lt;- c(541, 1463, 2445, 3438, 4437, 5401, 6392, 8304, 11904, 22261)

# compute Gini coefficient
Gini(x)

# working with weights
fl &lt;- c(2.5, 7.5, 15, 35, 75, 150)    # midpoints of classes
n  &lt;- c(25, 13, 10, 5, 5, 2)          # frequencies

# with confidence intervals
Gini(x=fl, weights=n, conf.level=0.95, unbiased=FALSE)

# some special cases
x &lt;- c(10, 10, 0, 0, 0)
plot(Lc(x))

Gini(x, unbiased=FALSE)

# the same with weights
Gini(x=c(10, 0), weights=c(2,3), unbiased=FALSE)

# perfect balance
Gini(c(10, 10, 10))
</code></pre>

<hr>
<h2 id='GiniSimpson'>Gini-Simpson Coefficient, Gini-Deltas coefficient and Hunter-Gaston Index
</h2><span id='topic+GiniSimpson'></span><span id='topic+GiniDeltas'></span><span id='topic+HunterGaston'></span>

<h3>Description</h3>

<p>Calculate the Gini-Simpson coefficient, the Gini variant proposed by Deltas and the Hunter-Gaston Index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GiniSimpson(x, na.rm = FALSE)
GiniDeltas(x, na.rm = FALSE)

HunterGaston(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GiniSimpson_+3A_x">x</code></td>
<td>
<p>a factor containing at least non-negative elements.</p>
</td></tr>
<tr><td><code id="GiniSimpson_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original Simpson index <code class="reqn">\lambda</code> equals the probability that two entities taken at random from the dataset of interest (with replacement) represent the same type. 
The Simpson index was introduced in 1949 by Edward H. Simpson to measure the degree of concentration when individuals are classified into types. The same index was rediscovered by Orris C. Herfindahl in 1950. The square root of the index had already been introduced in 1945 by the economist Albert O. Hirschman. As a result, the same measure is usually known as the Simpson index in ecology, and as the Herfindahl index or the Herfindahl-Hirschman index (HHI) in economics.<br />
Its transformation 1 - <code class="reqn">\lambda</code> therefore equals the probability that the two entities represent different types. 
This measure is also known in ecology as the probability of interspecific encounter (PIE) and the Gini-Simpson index.
</p>


<h3>Value</h3>

<p>a numeric value.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Cover Thomas M. and Thomas Joy A. (1991) <em>Elements of Information Theory</em>. Wiley. 
</p>
<p>Hunter, P., Gaston, A. G. (1988) Numerical Index of the Discriminatory Ability of Typing Systems:  an Application of Simpson's Index of Diversity, <em>JOURNAL OF CLINICAL MICROBIOLOGY</em>, Nov. 1988, p. 2465-2466, 0095-1137/88/112465-02$02.00/0
</p>
<p>Deltas (2003) DOI:10.1162/rest.2003.85.1.226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DivCoef">DivCoef</a></code>, <code><a href="#topic+Entropy">Entropy</a></code>, <code><a href="#topic+Gini">Gini</a></code>, <code><a href="#topic+Herfindahl">Herfindahl</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(261,29,33,15,39,28,95,5,6,28,69,8,105,38,15)

GiniSimpson(x)

# is the same as 
1 - Herfindahl(x)

GiniSimpson(c(783,121,112,70,201,153,425,19,37,126,325,51,442,193,41))
</code></pre>

<hr>
<h2 id='Gmean'>Geometric Mean and Standard Deviation
</h2><span id='topic+Gmean'></span><span id='topic+Gsd'></span>

<h3>Description</h3>

<p>Calculates the geometric mean, its confidence interval and the geometric standard deviation of a vector x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gmean(x, method = c("classic", "boot"), conf.level = NA,
      sides = c("two.sided","left","right"), na.rm = FALSE, ...)

Gsd(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gmean_+3A_x">x</code></td>
<td>
<p>a positive numeric vector. An object which is not a vector is coerced (if possible) by as.vector.
</p>
</td></tr>
<tr><td><code id="Gmean_+3A_method">method</code></td>
<td>
<p>a vector of character strings representing the type of intervals required. The value should be any subset of the values <code>"classic"</code>, <code>"boot"</code>.
See <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>.
</p>
</td></tr>
<tr><td><code id="Gmean_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. Default is <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="Gmean_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="Gmean_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="Gmean_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the <code><a href="boot.html#topic+boot">boot</a></code> function. Supported arguments are <code>type</code> (<code>"norm"</code>, <code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code>, <code>"bca"</code>), <code>parallel</code> and the number of bootstrap replicates <code>R</code>. If not defined those will be set to their defaults, being <code>"basic"</code> for <code>type</code>,  option <code>"boot.parallel"</code> (and if that is not set, <code>"no"</code>) for <code>parallel</code>
and <code>999</code> for <code>R</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The geometric mean is defined as:
</p>
<p style="text-align: center;"><code class="reqn">\sqrt[n]{x_{1}\cdot x_{2}\cdot x_{3} \ldots \cdot x_{n}}</code>
</p>

<p>The geometric mean and geometric standard deviation are restricted to positive inputs (because otherwise the answer can have an imaginary component). Hence if any argument is negative, the result will be <code>NA</code>. If any argument is zero, then the geometric mean is zero.<br />
For strict positive values the geometric mean is computed as <code>exp(MeanCI(log(x)))</code>.
</p>
<p><b>Considerations (Roenfeldt 2018)</b> <code style="white-space: pre;">&#8288;     &#8288;</code> &quot;The calculation of the geometric mean requires that all values are non-zero and positive. So what should you do if you have data that do not meet this requirement? If you have values that equal zero, you have a few options:
</p>

<ul>
<li><p> Adjust your scale so that you add 1 to every number in the data set, and then subtract 1 from the resulting geometric mean.
</p>
</li>
<li><p> Ignore zeros or missing data in your calculations.
</p>
</li>
<li><p> Convert zeros to a very small number (often called &quot;below the detection limit&quot;) that is less than the next smallest number in the data set.
</p>
</li></ul>

<p>If you have negative numbers, you will need to convert those numbers to a positive value before calculating the geometric mean. You can then assign the resulting geometric mean a negative value. If 
your data set contains both positive and negative values, you will have to separate them and find the 
geometric means for each group, and you can then find the weighted average of their individual 
geometric means to find the total geometric mean for the full data set.
If none of these options appeals to you, you are not alone! There is controversy among statisticians about 
what is the best method for dealing with these values. You may want to calculate several types of 
averages and decide what makes the most sense for you and the results you are trying to report.&quot;</p>


<h3>Value</h3>

<p>a numeric value.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Snedecor, G. W., Cochran, W. G. Cochran (1989) Statistical Methods, 8th ed. Ames, <em>IA: Iowa State University Press </em>
</p>
<p>Roenfeldt K. (2018) Better than Average: Calculating Geometric Means Using SAS, 
Henry M. Jackson Foundation for the Advancement of Military Medicine, 
<a href="https://www.lexjansen.com/wuss/2018/56_Final_Paper_PDF.pdf">https://www.lexjansen.com/wuss/2018/56_Final_Paper_PDF.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>, <code><a href="#topic+Hmean">Hmean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(5)
Gmean(x)

m &lt;- matrix(runif(50), nrow = 10)
apply(m, 2, Gmean)

sapply(as.data.frame(m), Gmean)

# ......................................................
# example in https://www.stata.com/manuals13/rameans.pdf
x &lt;- c(5,4,-4,-5,0,0,NA,7)

# positives only
Gmean(x[x&gt;0], na.rm=TRUE, conf.level=0.95)

# add 5 to original values and remove zeros
Gmean(NAIfZero(x+5), na.rm=TRUE, conf.level = 0.95)
</code></pre>

<hr>
<h2 id='Gompertz'>The Gompertz distribution</h2><span id='topic+Gompertz'></span><span id='topic+dGompertz'></span><span id='topic+pGompertz'></span><span id='topic+qGompertz'></span><span id='topic+rGompertz'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the Gompertz distribution with unrestricted shape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dGompertz(x, shape, rate = 1, log = FALSE)
pGompertz(q, shape, rate = 1, lower.tail = TRUE, log.p = FALSE)
qGompertz(p, shape, rate = 1, lower.tail = TRUE, log.p = FALSE)
rGompertz(n, shape = 1, rate = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gompertz_+3A_x">x</code>, <code id="Gompertz_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_shape">shape</code>, <code id="Gompertz_+3A_rate">rate</code></td>
<td>
<p>vector of shape and rate parameters.</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_log">log</code>, <code id="Gompertz_+3A_log.p">log.p</code></td>
<td>
<p>logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if TRUE (default), probabilities are <code class="reqn">P(X
\le x)</code>, otherwise, <code class="reqn">P(X &gt; x)</code>.</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="Gompertz_+3A_n">n</code></td>
<td>
<p>number of observations. If <code>length(n) &gt; 1</code>, the length is
taken to be the number required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gompertz distribution with <code>shape</code> parameter <code class="reqn">a</code> and
<code>rate</code> parameter <code class="reqn">b</code> has probability density function
</p>
<p style="text-align: center;"><code class="reqn">f(x | a, b) = be^{ax}\exp(-b/a (e^{ax} - 1))</code>
</p>

<p>For <code class="reqn">a=0</code> the Gompertz is equivalent to the exponential distribution
with constant hazard and rate <code class="reqn">b</code>.
</p>
<p>The probability distribution function is </p>
<p style="text-align: center;"><code class="reqn">F(x | a, b) = 1 - \exp(-b/a
(e^{ax} - 1))</code>
</p>

<p>Thus if <code class="reqn">a</code> is negative, letting <code class="reqn">x</code> tend to infinity shows that
there is a non-zero probability <code class="reqn">1 - \exp(b/a)</code> of living
forever.  On these occasions <code>qGompertz</code> and <code>rGompertz</code> will
return <code>Inf</code>.
</p>


<h3>Value</h3>

<p><code>dGompertz</code> gives the density, <code>pGompertz</code> gives the
distribution function, <code>qGompertz</code> gives the quantile function,
and <code>rGompertz</code> generates random deviates.
</p>


<h3>Note</h3>

<p>Some implementations of the Gompertz restrict <code class="reqn">a</code> to be strictly
positive, which ensures that the probability of survival decreases to zero
as <code class="reqn">x</code> increases to infinity.  The more flexible implementation given
here is consistent with <code>streg</code> in Stata.
</p>
<p>The functions <code>dGompertz</code> and similar available in the
package <span class="pkg">eha</span> label the parameters the other way round, so that what is
called the <code>shape</code> there is called the <code>rate</code> here, and what is
called <code>1 / scale</code> there is called the <code>shape</code> here. The
terminology here is consistent with the exponential <code><a href="stats.html#topic+dexp">dexp</a></code> and
Weibull <code><a href="stats.html#topic+dweibull">dweibull</a></code> distributions in R.
</p>


<h3>Author(s)</h3>

<p>Christopher Jackson &lt;chris.jackson@mrc-bsu.cam.ac.uk&gt;
</p>


<h3>References</h3>

<p>Stata Press (2007) Stata release 10 manual: Survival analysis
and epidemiological tables.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dexp">dexp</a></code>
</p>

<hr>
<h2 id='GoodmanKruskalGamma'>Goodman Kruskal's Gamma
</h2><span id='topic+GoodmanKruskalGamma'></span>

<h3>Description</h3>

<p>Calculate Goodman Kruskal's Gamma statistic, a measure of
association for ordinal factors in a two-way table.<br />
The function has interfaces for a contingency table (matrix) and for single vectors (which will then be tabulated).</p>


<h3>Usage</h3>

<pre><code class='language-R'>GoodmanKruskalGamma(x, y = NULL, conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GoodmanKruskalGamma_+3A_x">x</code></td>
<td>
<p>a numeric vector or a contingency table. A matrix will be treated as a table.
</p>
</td></tr>
<tr><td><code id="GoodmanKruskalGamma_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="GoodmanKruskalGamma_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence intervals will be calculated.
</p>
</td></tr>
<tr><td><code id="GoodmanKruskalGamma_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to control the handling of <code>NAs</code> by setting the <code>useNA</code> argument. This refers only to the vector interface, the dots are ignored if <code>x</code> is a contingency table.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimator of <code class="reqn">\gamma</code> is based only on the number of concordant and discordant pairs of observations. It ignores tied pairs (that is, pairs of observations that have equal values of X or equal values of Y). Gamma is appropriate only when both variables lie on an ordinal scale. <br />
It has the range [-1, 1]. If the two variables are independent, then the estimator of gamma tends to be close to zero.
For <code class="reqn">2 \times 2</code> tables, gamma is equivalent to Yule's Q (<code><a href="#topic+YuleQ">YuleQ</a></code>). <br />
Gamma is estimated by </p>
<p style="text-align: center;"><code class="reqn"> G = \frac{P-Q}{P+Q}</code>
</p>
<p> where P equals twice the number of concordances and Q twice the number of discordances.
</p>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested,<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons,
pp. 57-59.
</p>
<p>Brown, M.B., Benedetti, J.K.(1977) Sampling Behavior of Tests for Correlation in Two-Way Contingency Tables, <em>Journal of the American Statistical Association</em>, 72, 309-315.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1954) Measures of
association for cross classifications. <em>Journal of the
American Statistical Association</em>, 49, 732-764.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1963) Measures of
association for cross classifications III: Approximate
sampling theory. <em>Journal of the American Statistical
Association</em>, 58, 310-364.
</p>


<h3>See Also</h3>

<p>There's another implementation of gamma in <span class="pkg">vcdExtra</span> <code><a href="vcdExtra.html#topic+GKgamma">GKgamma</a></code><br />
<code><a href="#topic+ConDisPairs">ConDisPairs</a></code> yields concordant and discordant pairs <br /><br />
Other association measures: <br />
<code><a href="#topic+KendallTauA">KendallTauA</a></code> (tau-a), <code><a href="#topic+KendallTauB">KendallTauB</a></code> (tau-b), <code><a href="stats.html#topic+cor">cor</a></code> (method=&quot;kendall&quot;) for tau-b, <code><a href="#topic+StuartTauC">StuartTauC</a></code> (tau-c), <code><a href="#topic+SomersDelta">SomersDelta</a></code><br />
<code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+GoodmanKruskalTau">GoodmanKruskalTau</a></code> (tau), <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example in:
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. S. 1821 (149)

tab &lt;- as.table(rbind(
  c(26,26,23,18, 9),
  c( 6, 7, 9,14,23))
  )

GoodmanKruskalGamma(tab, conf.level=0.95)
</code></pre>

<hr>
<h2 id='GoodmanKruskalTau'>Goodman Kruskal's Tau
</h2><span id='topic+GoodmanKruskalTau'></span>

<h3>Description</h3>

<p>Calculate Goodman Kruskal's tau statistic, a measure of
association for ordinal factors in a two-way table.<br />
The function has interfaces for a table (matrix) and for single vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GoodmanKruskalTau(x, y = NULL, direction = c("row", "column"), conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GoodmanKruskalTau_+3A_x">x</code></td>
<td>
<p>a numeric vector or a table. A matrix will be treated as table.
</p>
</td></tr>
<tr><td><code id="GoodmanKruskalTau_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="GoodmanKruskalTau_+3A_direction">direction</code></td>
<td>
<p>direction of the calculation. Can be <code>"row"</code> (default) or <code>"column"</code>, where
<code>"row"</code> calculates Goodman Kruskal's tau-a (R|C) (&quot;column dependent&quot;).
</p>
</td></tr>
<tr><td><code id="GoodmanKruskalTau_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated.
</p>
</td></tr>
<tr><td><code id="GoodmanKruskalTau_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set useNA. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Goodman-Kruskal tau measures association for cross tabulations of nominal level variables.
Goodman-Kruskal tau is based on random category assignment. It measures the percentage improvement in predictability of the dependent variable (column or row variable) given the value of other variables (row or column variables). Goodman-Kruskal tau is the same as Goodman-Kruskal lambda except the calculations of the tau statistic are based on assignment probabilities specified by marginal or conditional proportions.
Misclassification probabilities are based on random category assignment with probabilities specified by marginal or conditional proportion.
</p>
<p>Goodman Kruskal tau reduces to <code class="reqn">\phi^2</code> (see: <code><a href="#topic+Phi">Phi</a></code>) in the 2x2-table case.<br />
</p>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested,<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, based on code from Antti Arppe &lt;antti.arppe@helsinki.fi&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons,
pp. 57-59.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1954) Measures of
association for cross classifications. <em>Journal of the
American Statistical Association</em>, 49, 732-764.
</p>
<p>Somers, R. H. (1962) A New Asymmetric Measure of Association for Ordinal Variables, <em>American Sociological Review</em>, 27, 799-811.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1963) Measures of
association for cross classifications III: Approximate
sampling theory. <em>Journal of the American Statistical
Association</em>, 58, 310-364.
</p>
<p>Liebetrau, A. M. (1983) <em>Measures of Association</em>, Sage University Papers Series on Quantitative Applications in the Social Sciences, 07-004. Newbury Park, CA: Sage, pp. 24&ndash;30
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ConDisPairs">ConDisPairs</a></code> yields concordant and discordant pairs <br /><br />
Other association measures: <br />
<code><a href="#topic+KendallTauA">KendallTauA</a></code> (Tau a), <code><a href="stats.html#topic+cor">cor</a></code> (method=&quot;kendall&quot;) for Tau b, <code><a href="#topic+StuartTauC">StuartTauC</a></code>, <code><a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a></code><br />
<code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example in:
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. S. 1821

tab &lt;- as.table(rbind(c(26,26,23,18,9),c(6,7,9,14,23)))

# Goodman Kruskal's tau C|R
GoodmanKruskalTau(tab, direction="column", conf.level=0.95)
# Goodman Kruskal's tau R|C
GoodmanKruskalTau(tab, direction="row", conf.level=0.95)

# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. 1814 (143)
tab &lt;- as.table(cbind(c(11,2),c(4,6)))

GoodmanKruskalTau(tab, direction="row", conf.level=0.95)
GoodmanKruskalTau(tab, direction="column", conf.level=0.95)
# reduce both to:
Phi(tab)^2


# example 1 in Liebetrau (1983)

tt &lt;- matrix(c(549,93,233,119,225,455,402,  
               212,124,78,42,41,12,132,
               54,54,33,13,46,7,153), ncol=3,
             dimnames=list(rownames=c("Gov", "Mil", "Edu", "Eco", "Intel", "Rel", "For"), 
                           colnames=c("One", "Two", "Multi")))

GoodmanKruskalTau(tt, direction = "row", conf.level = 0.95)
GoodmanKruskalTau(tt, direction = "column", conf.level = 0.95)


# SPSS
ttt &lt;- matrix(c(225,53,206,3,1,12), nrow=3,
              dimnames=list(rownames=c("right","center", "left"), 
                            colnames=c("us","ussr")))

round(GoodmanKruskalTau(ttt, direction = "r", con=0.95), d=3)
round(GoodmanKruskalTau(ttt, direction = "c"), d=3)

</code></pre>

<hr>
<h2 id='GTest'>G-Test for Count Data</h2><span id='topic+GTest'></span>

<h3>Description</h3>

<p><code>GTest</code> performs chi-squared contingency table tests
and goodness-of-fit tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GTest(x, y = NULL, correct = c("none", "williams", "yates"),
      p = rep(1/length(x), length(x)), rescale.p = FALSE) 
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GTest_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix. <code>x</code> and <code>y</code> can also
both be factors.</p>
</td></tr>
<tr><td><code id="GTest_+3A_y">y</code></td>
<td>
<p>a numeric vector; ignored if <code>x</code> is a matrix.  If
<code>x</code> is a factor, <code>y</code> should be a factor of the same length.</p>
</td></tr>
<tr><td><code id="GTest_+3A_correct">correct</code></td>
<td>
<p>one out of <code>"none"</code> (default), <code>"williams"</code>, <code>"yates"</code> . See Details. </p>
</td></tr>
<tr><td><code id="GTest_+3A_p">p</code></td>
<td>
<p>a vector of probabilities of the same length of <code>x</code>.
An error is given if any entry of <code>p</code> is negative.</p>
</td></tr>
<tr><td><code id="GTest_+3A_rescale.p">rescale.p</code></td>
<td>
	
<p>a logical scalar; if <code>TRUE</code> then p is rescaled (if necessary) to sum to 1. If rescale.p is <code>FALSE</code>, and p does not sum to 1, an error is given.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The G-test is also called &quot;Likelihood Ratio Test&quot; and is asymptotically equivalent to the Pearson ChiSquare-test but not usually used when analyzing 2x2 tables. It is used in logistic regression and loglinear modeling which involves contingency tables. The G-test is also reported in the standard summary of <code>Desc</code> for tables.
</p>
<p>If <code>x</code> is a matrix with one row or column, or if <code>x</code> is a
vector and <code>y</code> is not given, then a <em>goodness-of-fit test</em>
is performed (<code>x</code> is treated as a one-dimensional
contingency table).  The entries of <code>x</code> must be non-negative
integers.  In this case, the hypothesis tested is whether the
population probabilities equal those in <code>p</code>, or are all equal if
<code>p</code> is not given.
</p>
<p>If <code>x</code> is a matrix with at least two rows and columns, it is
taken as a two-dimensional contingency table: the entries of <code>x</code>
must be non-negative integers.  Otherwise, <code>x</code> and <code>y</code> must
be vectors or factors of the same length; cases with missing values
are removed, the objects are coerced to factors, and the contingency
table is computed from these.  Then G-test is
performed on the null hypothesis that the joint distribution of the
cell counts in a 2-dimensional contingency table is the product of the
row and column marginals.
</p>
<p>Test of independence Yates' correction taken from Mike Camann's 2x2 G-test function.
Goodness of Fit Yates' correction as described in Zar (2000).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following
components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value the chi-squared test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom of the approximate
chi-squared distribution of the test statistic, <code>NA</code> if the
p-value is computed by Monte Carlo simulation.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the type of test
performed, and whether Monte Carlo simulation or continuity
correction was used.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
<tr><td><code>observed</code></td>
<td>
<p>the observed counts.</p>
</td></tr>
<tr><td><code>expected</code></td>
<td>
<p>the expected counts under the null hypothesis.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pete Hurd &lt;phurd@ualberta.ca&gt;, Andri Signorell &lt;andri@signorell.net&gt; (tiny tweaks)</p>


<h3>References</h3>

<p>Hope, A. C. A. (1968)
A simplified Monte Carlo significance test procedure.
<em>J. Roy, Statist. Soc. B</em> <b>30</b>, 582&ndash;598.
</p>
<p>Patefield, W. M. (1981)
Algorithm AS159.  An efficient method of generating r x c tables
with given row and column totals.
<em>Applied Statistics</em> <b>30</b>, 91&ndash;97.
</p>
<p>Agresti, A. (2007)
<em>An Introduction to Categorical Data Analysis, 2nd ed.</em>,
New York: John Wiley &amp; Sons.
Page 38.
</p>
<p>Sokal, R. R., F. J. Rohlf (2012) <em>Biometry: the principles and practice of statistics in biological research</em>. 4th edition. W. H. Freeman and Co.: New York. 937 pp.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+chisq.test">chisq.test</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## From Agresti(2007) p.39
M &lt;- as.table(rbind(c(762, 327, 468), c(484,239,477)))
dimnames(M) &lt;- list(gender=c("M","F"),
                    party=c("Democrat","Independent", "Republican"))

(Xsq &lt;- GTest(M))   # Prints test summary

Xsq$observed        # observed counts (same as M)
Xsq$expected        # expected counts under the null


## Testing for population probabilities
## Case A. Tabulated data
x &lt;- c(A = 20, B = 15, C = 25)
GTest(x)
GTest(as.table(x))             # the same
x &lt;- c(89,37,30,28,2)
p &lt;- c(40,20,20,15,5)
try(
GTest(x, p = p)                # gives an error
)
# works
p &lt;- c(0.40,0.20,0.20,0.19,0.01)
# Expected count in category 5
# is 1.86 &lt; 5 ==&gt; chi square approx.
GTest(x, p = p)                # maybe doubtful, but is ok!

## Case B. Raw data
x &lt;- trunc(5 * runif(100))
GTest(table(x))                # NOT 'GTest(x)'!
</code></pre>

<hr>
<h2 id='Gumbel'>The Gumbel Distribution</h2><span id='topic+dGumbel'></span><span id='topic+pGumbel'></span><span id='topic+qGumbel'></span><span id='topic+rGumbel'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random generation for the Gumbel distribution with location and
scale parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dGumbel(x, loc=0, scale=1, log = FALSE)
pGumbel(q, loc=0, scale=1, lower.tail = TRUE)
qGumbel(p, loc=0, scale=1, lower.tail = TRUE)
rGumbel(n, loc=0, scale=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gumbel_+3A_x">x</code>, <code id="Gumbel_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_loc">loc</code>, <code id="Gumbel_+3A_scale">scale</code></td>
<td>
<p>Location and scale parameters (can be given
as vectors).</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_log">log</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the log density is returned.</p>
</td></tr>
<tr><td><code id="Gumbel_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), probabilities
are P[X &lt;= x], otherwise, P[X &gt; x]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gumbel distribution function with parameters
<code class="reqn">loc = a</code> and <code class="reqn">scale = b</code> is
</p>
<p style="text-align: center;"><code class="reqn">G(z) = \exp\left\{-\exp\left[-\left(\frac{z-a}{b}\right)
    \right]\right\}</code>
</p>

<p>for all real <code class="reqn">z</code>, where <code class="reqn">b &gt; 0</code>.
</p>


<h3>Value</h3>

<p><code>dGumbel</code> gives the density function, <code>pGumbel</code> gives
the distribution function, <code>qGumbel</code> gives the quantile
function, and <code>rGumbel</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Alec Stephenson &lt;alec_stephenson@hotmail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+rFrechet">rFrechet</a></code>, <code><a href="#topic+rGenExtrVal">rGenExtrVal</a></code>, <code><a href="#topic+rRevWeibull">rRevWeibull</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dGumbel(-1:2, -1, 0.5)
pGumbel(-1:2, -1, 0.5)
qGumbel(seq(0.9, 0.6, -0.1), 2, 0.5)
rGumbel(6, -1, 0.5)
p &lt;- (1:9)/10
pGumbel(qGumbel(p, -1, 2), -1, 2)
## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
</code></pre>

<hr>
<h2 id='Herfindahl'>Concentration Measures</h2><span id='topic+Herfindahl'></span><span id='topic+Rosenbluth'></span>

<h3>Description</h3>

<p>Computes the concentration within a vector according to the
specified concentration measure. </p>


<h3>Usage</h3>

<pre><code class='language-R'>Herfindahl(x, n = rep(1, length(x)), parameter = 1, na.rm = FALSE)
Rosenbluth(x, n = rep(1, length(x)), na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Herfindahl_+3A_x">x</code></td>
<td>
<p>a vector containing non-negative elements</p>
</td></tr>
<tr><td><code id="Herfindahl_+3A_n">n</code></td>
<td>
<p>a vector of frequencies (weights), must be same length as x.</p>
</td></tr>
<tr><td><code id="Herfindahl_+3A_parameter">parameter</code></td>
<td>
<p>parameter of the concentration measure (if set to <code>NULL</code>
the default parameter of the respective measure is used)</p>
</td></tr>
<tr><td><code id="Herfindahl_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the value of the concentration measure
</p>


<h3>Note</h3>

<p>The same measure is usually known as the Simpson index in ecology, and as the Herfindahl index or the Herfindahl-Hirschman index (HHI) in economics.
</p>


<h3>Note</h3>

<p> These functions were previously published as <code>conc()</code> in the  <span class="pkg">ineq</span> package and have been
integrated here without logical changes. <code>NA</code> and weights support were added.
</p>


<h3>Author(s)</h3>

<p>Achim Zeileis &lt;achim.zeileis@r-project.org&gt;</p>


<h3>References</h3>

<p>Cowell, F. A. (2000) Measurement of Inequality, in Atkinson, A. B., Bourguignon, F.  <em>Handbook of Income Distribution</em>. (Eds) Amsterdam
</p>
<p>Cowell, F. A. (1995) <em>Measuring Inequality</em>. Prentice Hall/Harvester Wheatshef
</p>
<p>Hall, M., Tidemann, N. (1967) <em>Measures of Concentration</em>, JASA 62, 162-168.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+Gini">Gini</a></code>, <code><a href="#topic+Atkinson">Atkinson</a></code> and <code><a href="ineq.html#topic+ineq">ineq</a>()</code> for additional inequality measures</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate vector (of sales)
x &lt;- c(541, 1463, 2445, 3438, 4437, 5401, 6392, 8304, 11904, 22261)

# compute Herfindahl coefficient with parameter 1
Herfindahl(x)

# compute coefficient of Hall/Tiedemann/Rosenbluth
Rosenbluth(x)

# Some more examples
Herfindahl(c(261,29,33,15,39,28,95,5,6,28,69,8,105,38,15))
Herfindahl(c(783,121,112,70,201,153,425,19,37,126,325,51,442,193,41))
</code></pre>

<hr>
<h2 id='HexToCol'>Identify Closest Match to a Color Given by a Hexadecimal String</h2><span id='topic+HexToCol'></span>

<h3>Description</h3>

<p>Given a color as a hex string #rrggbb, find the closest match in the
table of known (named) colors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HexToCol(hexstr, method = "rgb", metric = "euclidean")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HexToCol_+3A_hexstr">hexstr</code></td>
<td>
<p>a color or a vector of colors specified as hexadecimal string of the form &quot;#RRGGBB&quot; or &quot;#RRGGBBAA&quot;</p>
</td></tr>
<tr><td><code id="HexToCol_+3A_method">method</code></td>
<td>
<p>character string specifying the color space to be used. Can be &quot;rgb&quot; (default) or &quot;hsv&quot;.</p>
</td></tr>
<tr><td><code id="HexToCol_+3A_metric">metric</code></td>
<td>
<p>character string specifying the metric to be used for calculating distances between the colors.
Available options are &quot;euclidean&quot; (default) and &quot;manhattan&quot;. Euclidean distances are root sum-of-squares of differences, and manhattan distances are the sum of absolute differences.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Finds the color with the minimum squared distance in RGB space.
</p>


<h3>Value</h3>

<p>The colorname(s) of the closest match(es) (if more than one).
</p>


<h3>Author(s)</h3>

<p>Ben Bolker, vector support Andri Signorell &lt;andri@signorell.net&gt; </p>


<h3>See Also</h3>

<p><a href="#topic+ColToHex">ColToHex</a>, <a href="#topic+ColToRgb">ColToRgb</a>, <a href="grDevices.html#topic+colors">colors</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>ColToHex(c("lightblue", "salmon"))

HexToCol(c("#ADD8E6", "#FA1572"))
HexToCol(Pal("Helsana"))

x &lt;- ColToRgb("darkmagenta")
x[2,] &lt;- x[2,] + 155
RgbToCol(x)
</code></pre>

<hr>
<h2 id='HexToRgb'>Convert a Hexstring Color to a Matrix With Three Red/Green/Blue Rows
</h2><span id='topic+HexToRgb'></span>

<h3>Description</h3>

<p><code>HexToRgb()</code> converts a hexstring color the its red/green/blue representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HexToRgb(hex)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HexToRgb_+3A_hex">hex</code></td>
<td>
<p>a color or a vector of colors specified as hexadecimal string of the form &quot;#RRGGBB&quot; or &quot;#RRGGBBAA&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A hex color is written as a hash character, &quot;#&quot;, followed by 3 or 4 hexadecimal numbers, say 6, resp. 8, digits (0-9A-F). The first 3 pairs of digits specify the red, green and blue components. When there are 8 digits, then the last pair is interpreted as alpha channel defining transparency, where <code>00</code> represents a fully transparent color and <code>FF</code> represent a fully opaque color.<br />
The result will be returned as a matrix having 3 or 4 rows, depending on if the input contained a <code>RRGGBBAA</code> definition or not. No distinction is made between upper and lower case. A missing leading # is tolerated.</p>


<h3>Value</h3>

<p>a matrix with 3 or 4 rows.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HexToCol">HexToCol</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HexToRgb(c("#ADD8E6", "#FA1572"))

# 4-digit representation returns a 4 row matrix
HexToRgb(hex=c("#A52A2ABB","#A52A3B","C52A3B"))
</code></pre>

<hr>
<h2 id='Hmean'>Harmonic Mean and Its Confidence Interval
</h2><span id='topic+Hmean'></span>

<h3>Description</h3>

<p>Calculates the harmonic mean and its confidence interval of a vector x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hmean(x, method = c("classic", "boot"), conf.level = NA,
      sides = c("two.sided","left","right"), na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Hmean_+3A_x">x</code></td>
<td>
<p>a positive numeric vector. An object which is not a vector is coerced (if possible) by as.vector.
</p>
</td></tr>
<tr><td><code id="Hmean_+3A_method">method</code></td>
<td>
<p>a vector of character strings representing the type of intervals required. The value should be any subset of the values <code>"classic"</code>, <code>"boot"</code>.
See <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>.
</p>
</td></tr>
<tr><td><code id="Hmean_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. Default is <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="Hmean_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="Hmean_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="Hmean_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the <code><a href="boot.html#topic+boot">boot</a></code> function. Supported arguments are <code>type</code> (<code>"norm"</code>, <code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code>, <code>"bca"</code>), <code>parallel</code> and the number of bootstrap replicates <code>R</code>. If not defined those will be set to their defaults, being <code>"basic"</code> for <code>type</code>,  option <code>"boot.parallel"</code> (and if that is not set, <code>"no"</code>) for <code>parallel</code>
and <code>999</code> for <code>R</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To compute the harmonic mean, <code>1/x</code> is first calculated, before the arithmetic mean and its confidence interval are computed by <code><a href="#topic+MeanCI">MeanCI</a></code>. The harmonic mean is then the reciprocal of the arithmetic mean of the reciprocals of the values. The same applies to the confidence interval.
</p>
<p>The harmonic mean is restricted to strictly positive inputs, if any argument is negative, then the result will be <code>NA</code>.
If the lower bound of the confidence interval is not greater than zero, then the confidence interval is not defined, and thus  <code>NA</code> will be reported.
</p>
<p>Use <code><a href="base.html#topic+sapply">sapply</a></code> to calculate the measures from data frame, resp. from a matrix. <br />
</p>


<h3>Value</h3>

<p>a numeric value.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Snedecor, G. W., Cochran, W. G. (1989) Statistical Methods, 8th ed. Ames, <em>IA: Iowa State University Press </em></p>


<h3>See Also</h3>

<p><code><a href="#topic+Gmean">Gmean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(5)
Hmean(x)

m &lt;- matrix(runif(50), nrow = 10)
apply(m, 2, Hmean)

sapply(as.data.frame(m), Hmean)
</code></pre>

<hr>
<h2 id='HmsToSec'>Convert h:m:s To/From Seconds</h2><span id='topic+HmsToSec'></span><span id='topic+SecToHms'></span>

<h3>Description</h3>

<p><code>HmsToSec</code> - Converts a vector of h:m:s to seconds.
</p>
<p><code>SecToHms</code> - Converts a vector of seconds to h:m:s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HmsToSec(x)
SecToHms(x, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HmsToSec_+3A_x">x</code></td>
<td>
<p>A vector of times in h:m:s (for <code>HmsToSec</code>) or seconds (for
<code>SecToHms</code>).</p>
</td></tr>
<tr><td><code id="HmsToSec_+3A_digits">digits</code></td>
<td>
<p>the number of digits to use for potential fractions of seconds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>HmsToSec</code> - Returns a vector of times in seconds.
</p>
<p><code>SecToHms</code> - Returns a vector of times in h:m:s format.
</p>


<h3>Author(s)</h3>

<p>Tyler Rinker &lt;tyler.rinker@gmail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="chron.html#topic+times">times</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HmsToSec(c("02:00:03", "04:03:01"))
HmsToSec(SecToHms(c(222, 1234, 55)))
SecToHms(c(256, 3456, 56565))
</code></pre>

<hr>
<h2 id='HodgesLehmann'> Hodges-Lehmann Estimator of Location</h2><span id='topic+HodgesLehmann'></span>

<h3>Description</h3>

<p>Function to compute the Hodges-Lehmann estimator of location in the one and two sample case following a clever fast algorithm by John Monahan (1984). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HodgesLehmann(x, y = NULL, conf.level = NA, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HodgesLehmann_+3A_x">x</code></td>
<td>
<p> a numeric vector.</p>
</td></tr>
<tr><td><code id="HodgesLehmann_+3A_y">y</code></td>
<td>
<p>an optional numeric vector of data values: as with x non-finite values will be omitted.</p>
</td></tr>
<tr><td><code id="HodgesLehmann_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.
</p>
</td></tr>
<tr><td><code id="HodgesLehmann_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Hodges-Lehmann estimator is the median of the combined data points and Walsh averages.
It is the same as the Pseudo Median returned as a by-product of the function <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code> (which however does not calculate correctly as soon as ties are present).<br />
Note that in the two-sample case the estimator for the difference in location parameters does not estimate the difference in medians (a common misconception) but rather the median of the difference between a sample from x and a sample from y.
</p>
<p>(The calculation of the confidence intervals is not yet implemented.)
</p>


<h3>Value</h3>

<p>the Hodges-Lehmann estimator of location as a single numeric value if no confidence intervals are requested,<br /> 
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p> Cyril Flurin Moser (Cyril did the lion's share and coded Monahan's algorithm in C++), 
Andri Signorell &lt;andri@signorell.net&gt; </p>


<h3>References</h3>

 
<p>Hodges, J.L., and Lehmann, E.L. (1963), Estimates of location based on rank tests. <em>The Annals of Mathematical Statistics</em>, <b>34</b>, 598&ndash;611. 
</p>
<p>Monahan, J. (1984), Algorithm 616: Fast Computation of the Hodges-Lehmann Location Estimator, <em>ACM Transactions on Mathematical Software</em>, Vol. 10, No. 3, pp. 265-270
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>, <code><a href="stats.html#topic+median">median</a></code>, <code><a href="#topic+MedianCI">MedianCI</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
x &lt;- rt(100, df = 3)
y &lt;- rt(100, df = 5)

HodgesLehmann(x)
HodgesLehmann(x, y)

# same as
wilcox.test(x, conf.int = TRUE)$estimate
</code></pre>

<hr>
<h2 id='HoeffD'>
Matrix of Hoeffding's D Statistics
</h2><span id='topic+HoeffD'></span><span id='topic+print.HoeffD'></span>

<h3>Description</h3>

<p>Computes a matrix of Hoeffding's (1948) <code>D</code> statistics for all possible
pairs of columns of a matrix.  <code>D</code>
is a measure of the distance
between <code>F(x,y)</code> and <code>G(x)H(y)</code>, where <code>F(x,y)</code> is the joint CDF of <code>X</code> and <code>Y</code>,
and <code>G</code> and <code>H</code> are marginal CDFs. Missing values are deleted in pairs rather than deleting all rows
of <code>x</code> having any missing variables.
The <code>D</code> statistic is robust against a wide
variety of alternatives to independence, such as non-monotonic relationships.
The larger the value of <code>D</code>, the more dependent are <code>X</code> and <code>Y</code> (for many types
of dependencies).  <code>D</code> used here is 30 times Hoeffding's original <code>D</code>, and
ranges from -0.5 to 1.0 if there are no ties in the data.
<code>print.HoeffD</code> prints the information derived by <code>HoeffD</code>.  The higher
the value of <code>D</code>, the more dependent are <code>x</code> and <code>y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HoeffD(x, y)
## S3 method for class 'HoeffD'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HoeffD_+3A_x">x</code></td>
<td>

<p>a numeric matrix with at least 5 rows and at least 2 columns (if
<code>y</code> is absent), or an object created by <code>HoeffD</code>
</p>
</td></tr>
<tr><td><code id="HoeffD_+3A_y">y</code></td>
<td>

<p>a numeric vector or matrix which will be concatenated to <code>x</code>
</p>
</td></tr>
<tr><td><code id="HoeffD_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses midranks in case of ties, as described by Hollander and Wolfe.
P-values are approximated by linear interpolation on the table
in Hollander and Wolfe, which uses the asymptotically equivalent
Blum-Kiefer-Rosenblatt statistic.  For <code>P&lt;.0001</code> or <code>&gt;0.5</code>, <code>P</code> values are
computed using a well-fitting linear regression function in <code>log P</code> vs.
the test statistic.
Ranks (but not bivariate ranks) are computed using efficient
algorithms (see reference 3).
</p>


<h3>Value</h3>

<p>a list with elements <code>D</code>, the
matrix of D statistics, <code>n</code> the
matrix of number of observations used in analyzing each pair of variables,
and <code>P</code>, the asymptotic P-values.
Pairs with fewer than 5 non-missing values have the D statistic set to NA.
The diagonals of <code>n</code> are the number of non-NAs for the single variable
corresponding to that row and column.
</p>


<h3>Author(s)</h3>

<p>Frank Harrell &lt;f.harrell@vanderbilt.edu&gt;
<br />
Department of Biostatistics
<br />
Vanderbilt University
<br />
</p>


<h3>References</h3>

<p>Hoeffding W. (1948) A non-parametric test of independence.  <em>Ann Math Stat</em> 19:546&ndash;57.
</p>
<p>Hollander M., Wolfe D.A. (1973)   <em>Nonparametric Statistical Methods</em>,
pp. 228&ndash;235, 423. New York: Wiley.
</p>
<p>Press W.H., Flannery B.P., Teukolsky S.A., Vetterling, W.T. (1988) <em>Numerical
Recipes in C</em> Cambridge: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="Hmisc.html#topic+rcorr">rcorr</a></code>, <code><a href="Hmisc.html#topic+varclus">varclus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(-2, -1, 0, 1, 2)
y &lt;- c(4,   1, 0, 1, 4)
z &lt;- c(1,   2, 3, 4, NA)
q &lt;- c(1,   2, 3, 4, 5)

HoeffD(cbind(x, y, z, q))


# Hoeffding's test can detect even one-to-many dependency
set.seed(1)
x &lt;- seq(-10, 10, length=200)
y &lt;- x * sign(runif(200, -1, 1))
plot(x, y)

HoeffD(x, y)
</code></pre>

<hr>
<h2 id='HosmerLemeshowTest'>
Hosmer-Lemeshow Goodness of Fit Tests
</h2><span id='topic+HosmerLemeshowTest'></span>

<h3>Description</h3>

<p>The function computes Hosmer-Lemeshow goodness of fit tests
for C and H statistic as well as the le Cessie-van Houwelingen-Copas-Hosmer
unweighted sum of squares test for global goodness of fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HosmerLemeshowTest(fit, obs, ngr = 10, X, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HosmerLemeshowTest_+3A_fit">fit</code></td>
<td>
<p> numeric vector with fitted probabilities. </p>
</td></tr>
<tr><td><code id="HosmerLemeshowTest_+3A_obs">obs</code></td>
<td>
<p> numeric vector with observed values. </p>
</td></tr>
<tr><td><code id="HosmerLemeshowTest_+3A_ngr">ngr</code></td>
<td>
<p> number of groups for C and H statistic. </p>
</td></tr>
<tr><td><code id="HosmerLemeshowTest_+3A_x">X</code></td>
<td>
<p> covariate(s) for le Cessie-van Houwelingen-Copas-Hosmer
global goodness of fit test. </p>
</td></tr>
<tr><td><code id="HosmerLemeshowTest_+3A_verbose">verbose</code></td>
<td>
<p> logical, print intermediate results. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hosmer-Lemeshow goodness of fit tests are computed; see Lemeshow and Hosmer
(1982).
</p>
<p>If <code>X</code> is specified, the le Cessie-van Houwelingen-Copas-Hosmer
unweighted sum of squares test for global goodness of fit is additionally
determined; see Hosmer et al. (1997).
</p>


<h3>Value</h3>

<p>A list of tests.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl &lt;Matthias.Kohl@stamats.de&gt;</p>


<h3>References</h3>

<p>Lemeshow, S. Hosmer, D.W.,  (1982): A review of goodness of fit statistics
for use in the development of logistic regression models.
<em>American Journal of Epidemiology, <b>115</b>(1), 92-106.</em>
</p>
<p>Hosmer, D.W., Hosmer, T., le Cessie, S., Lemeshow, S. (1997). A comparison
of goodness-of-fit tests for the logistic regression model.
<em>Statistics in Medicine</em>, <b>16</b>, 965-980.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+glm">glm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(111)

x1 &lt;- factor(sample(1:3, 50, replace = TRUE))
x2 &lt;- rnorm(50)
obs &lt;- sample(c(0,1), 50, replace = TRUE)

fit &lt;- glm(obs ~ x1+x2, family = binomial)

HosmerLemeshowTest(fit = fitted(fit), obs = obs, X = cbind(x1, x2))
</code></pre>

<hr>
<h2 id='HotellingsT2Test'>Hotelling's T2 Test</h2><span id='topic+HotellingsT2Test'></span><span id='topic+HotellingsT2Test.default'></span><span id='topic+HotellingsT2Test.formula'></span>

<h3>Description</h3>

<p>Hotelling's T2 test is the multivariate generlisation of the Student's t test. A one-sample Hotelling's T2 test can be used to test if a set of vectors of data (which should be a sample of a single statistical population) has a mean equal to a hypothetical mean. A two-sample Hotelling's T2 test may be used to test for significant differences between the mean vectors (multivariate means) of two multivariate data sets are different.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HotellingsT2Test(x, ...)

## Default S3 method:
HotellingsT2Test(x, y = NULL, mu = NULL, test = "f", ...)

## S3 method for class 'formula'
HotellingsT2Test(formula, data, subset, na.action, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HotellingsT2Test_+3A_x">x</code></td>
<td>
<p>a numeric data frame or matrix. </p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_y">y</code></td>
<td>
<p>an optional numeric data frame or matrix for the two sample test. If <code>NULL</code> a one sample test is performed.</p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_mu">mu</code></td>
<td>
<p>a vector indicating the hypothesized value of the mean (or difference
in means if a two sample test is performed). <code>NULL</code> represents origin or no difference between the groups. </p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_test">test</code></td>
<td>
<p>if <code>"f"</code>, the decision is based on the F-distribution, if <code>"chi"</code> a chi-squared approximation is used. </p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>x ~ g</code> where <code>x</code> is a numeric matrix giving  the data values and <code>g</code> a factor
with two levels giving the corresponding groups.</p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="HotellingsT2Test_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The classical test for testing the location of a multivariate population or for testing the mean
difference for two multivariate populations. When <code>test = "f"</code> the F-distribution is used for
the test statistic and it is assumed that the data are normally distributed. If the chisquare
approximation is used, the normal assumption can be relaxed to existence of second moments.
In the two sample case both populations are assumed to have the same covariance matrix.
</p>
<p>The formula interface is only applicable for the 2-sample tests.
</p>


<h3>Value</h3>

<p>A list with class 'htest' containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the T2-statistic. (That is the scaled value of the statistic that has an
F distribution or a chisquare distribution depending on the value of <code>test</code>).</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom for the T2-statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the specified hypothesized value of the mean or mean difference
depending on whether it was a one-sample test or a two-sample test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string with the value 'two.sided'.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of test was performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data (and grouping vector).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus Nordhausen, &lt;klaus.nordhausen@uta.fi&gt;</p>


<h3>References</h3>

<p>Nordhausen K., Sirkia S., Oja H. and Tyler D. E. (2012) <em>ICSNP: Tools for
Multivariate Nonparametrics</em>. R package version 1.0-9.<br />
<a href="https://cran.r-project.org/package=ICSNP">https://cran.r-project.org/package=ICSNP</a>
</p>
<p>Anderson, T.W. (2003), <em>An introduction to
multivariate analysis</em>, New Jersey: Wiley.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>math.teach &lt;- data.frame(
  teacher = factor(rep(1:2, c(3, 6))),
  satis   = c(1, 3, 2, 4, 6, 6, 5, 5, 4),
  know    = c(3, 7, 2, 6, 8, 8, 10, 10, 6))

with(math.teach,
  HotellingsT2Test(cbind(satis, know) ~ teacher))
</code></pre>

<hr>
<h2 id='HuberM'>Safe (generalized) Huber M-Estimator of Location</h2><span id='topic+HuberM'></span>

<h3>Description</h3>

<p>(Generalized) Huber M-estimator of location with MAD scale, being
sensible also when the scale is zero where <code><a href="MASS.html#topic+huber">huber</a>()</code>
returns an error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HuberM(x, k = 1.345, mu = median(x), s = mad(x, center = mu), 
       na.rm = FALSE, conf.level = NA, ci.type = c("wald", "boot"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HuberM_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="HuberM_+3A_k">k</code></td>
<td>
<p>positive factor; the algorithm winsorizes at <code>k</code>
standard deviations.</p>
</td></tr>
<tr><td><code id="HuberM_+3A_mu">mu</code></td>
<td>
<p>initial location estimator.</p>
</td></tr>
<tr><td><code id="HuberM_+3A_s">s</code></td>
<td>
<p>scale estimator held constant through the iterations.</p>
</td></tr>
<tr><td><code id="HuberM_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="HuberM_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated. </p>
</td></tr>
<tr><td><code id="HuberM_+3A_ci.type">ci.type</code></td>
<td>
<p>The type of confidence interval required. The value should be any subset 
of the values <code>"wald"</code>, <code>"boot"</code>. 
</p>
</td></tr>
<tr><td><code id="HuberM_+3A_...">...</code></td>
<td>
<p> the dots are passed to the function <code><a href="boot.html#topic+boot">boot</a></code>, when confidence intervalls are calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard error is computed using the <code class="reqn">\tau</code> correction factor but no finite sample correction.<br /> The original function is not exported, but can be accessed as <code>DescTools::.huberM</code>.

</p>


<h3>Value</h3>

<p>If <code>conf.level</code> is set to <code>NA</code> then the result will be  
</p>
<table>
<tr><td><code>a</code></td>
<td>
<p> single numeric value</p>
</td></tr></table>
<p> and 
if a <code>conf.level</code> is provided, a named numeric vector with 3 elements:
</p>
<table>
<tr><td><code>huberm</code></td>
<td>
<p>the estimate for location</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Maechler, building on the MASS code mentioned.<br />
Andri Signorell &lt;andri@signorell.net&gt; (confidence intervals and interface)</p>


<h3>References</h3>

<p>Huber, P. J. (1981)
<em>Robust Statistics.</em>
Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+hubers">hubers</a></code> (and <code>huber</code>) in package <span class="pkg">MASS</span>;
<code><a href="stats.html#topic+mad">mad</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HuberM(c(1:9, 1000))
mad   (c(1:9, 1000))

set.seed(7)
x &lt;- c(round(rnorm(1000), 1), round(rnorm(50, m=10, sd = 10)))
HuberM(x, conf.level=0.95)


## Not run: 

# scale zero
HuberM(rep(9, 100))
mad   (rep(9, 100))

# bootstrap confidence intervals
HuberM(x, conf.level=0.95, ci.type="boot")

## End(Not run)
 
</code></pre>

<hr>
<h2 id='ICC'> Intraclass Correlations (ICC1, ICC2, ICC3 From Shrout and Fleiss) </h2><span id='topic+ICC'></span><span id='topic+print.ICC'></span>

<h3>Description</h3>

<p>The Intraclass correlation is used as a measure of association when studying the reliability of raters.  Shrout and Fleiss (1979) outline 6 different estimates, that depend upon the particular experimental design. All are implemented and given confidence limits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICC(x, type = c("all", "ICC1", "ICC2", "ICC3", "ICC1k", "ICC2k", "ICC3k"),
    conf.level = NA, na.rm = FALSE)

## S3 method for class 'ICC'
print(x, digits = 3, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICC_+3A_x">x</code></td>
<td>
<p><code class="reqn">n \times m</code> matrix or dataframe, k subjects (in rows) m raters (in columns).</p>
</td></tr>
<tr><td><code id="ICC_+3A_type">type</code></td>
<td>
<p>one out of &quot;all&quot;, &quot;ICC1&quot;, &quot;ICC2&quot;, &quot;ICC3&quot;, &quot;ICC1k&quot;, &quot;ICC2k&quot;, &quot;ICC3k&quot;. See details.</p>
</td></tr>
<tr><td><code id="ICC_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence intervals will be calculated.</p>
</td></tr>
<tr><td><code id="ICC_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. If set to <code>TRUE</code> only      the complete cases of the ratings will be used. Defaults to <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="ICC_+3A_digits">digits</code></td>
<td>
<p>number of digits to use in printing</p>
</td></tr>
<tr><td><code id="ICC_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Shrout and Fleiss (1979) consider six cases of reliability of ratings done by k raters on n targets.
</p>

<table>
<tr>
 <td style="text-align: left;">
ICC1 </td><td style="text-align: left;"> Each  target is rated by a different  judge and the judges are selected at random.</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> (This is a one-way ANOVA fixed effects model and is found by  (MSB- MSW)/(MSB+ (nr-1)*MSW)) </td>
</tr>
<tr>
 <td style="text-align: left;">

ICC2 </td><td style="text-align: left;"> A random sample of k judges rate each target.  The measure is one of absolute agreement </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> in the ratings. Found as (MSB- MSE)/(MSB + (nr-1)*MSE + nr*(MSJ-MSE)/nc) </td>
</tr>
<tr>
 <td style="text-align: left;">
ICC3 </td><td style="text-align: left;"> A fixed set of k judges rate each target. There is no generalization to a larger population </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> of judges. (MSB - MSE)/(MSB+ (nr-1)*MSE) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Then, for each of these cases, is reliability to be estimated for a single rating or for the average of k ratings?  (The 1 rating case is equivalent to the average intercorrelation, the k rating case to the Spearman Brown adjusted reliability.)
</p>
<p>ICC1 is sensitive to differences in means between raters and is a measure of absolute agreement.
</p>
<p>ICC2 and ICC3 remove mean differences between judges, but are sensitive to interactions of raters by judges.  <br />
The difference between ICC2 and ICC3 is whether raters are seen as fixed or random effects.
</p>
<p>ICC1k, ICC2k, ICC3K reflect the means of k raters.
</p>
<p>The intraclass correlation is used if raters are all of the same &ldquo;class&quot;.  That is, there is no logical way of distinguishing them.  Examples include correlations between  pairs of twins, correlations between raters.  If the variables are logically distinguishable (e.g., different items on a test), then the more typical coefficient is based upon the inter-class correlation (e.g., a Pearson r) and a statistic such as alpha or omega might be used.
</p>


<h3>Value</h3>

<p>if method is set to &quot;all&quot;, then the result will be
</p>
<table>
<tr><td><code>results</code></td>
<td>
<p>A matrix of 6 rows and 8 columns, including the ICCs, F test, p values, and confidence limits</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>
<p>The anova summary table</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>The anova statistics</p>
</td></tr>
<tr><td><code>MSW</code></td>
<td>
<p>Mean Square Within based upon the anova</p>
</td></tr>
</table>
<p>if a specific type has been defined, the function will first check, whether no confidence intervals are requested:
if so, the result will be the estimate as numeric value<br /><br />
else a named numeric vector with 3 elements
</p>
<table>
<tr><td><code>ICCx</code></td>
<td>
<p>estimate (name is the selected type of coefficient)</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper confidence interval</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The results for the lower and upper Bounds for ICC(2,k) do not match those of SPSS 9 or 10, but do match the definitions of Shrout and Fleiss.  SPSS  seems to have been using the  formula in McGraw and Wong, but not the errata on p 390.  They seem to have fixed it in more recent releases (15). </p>


<h3>Author(s)</h3>

<p>William Revelle &lt;revelle@northwestern.edu&gt;, some editorial amendments Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p> Shrout, P. E., Fleiss, J. L. (1979) Intraclass correlations: uses in assessing rater reliability. <em> Psychological Bulletin</em>, 86, 420-3428.
</p>
<p>McGraw, K. O., Wong, S. P. (1996) Forming inferences about some intraclass correlation coefficients.  <em> Psychological Methods</em>, 1, 30-46. + errata on page 390.
</p>
<p>Revelle, W. (in prep) <em> An introduction to psychometric theory with applications in R</em>  Springer. (working draft available at  <a href="http://personality-project.org/r/book/">http://personality-project.org/r/book/</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>sf &lt;- matrix(c(
      9, 2, 5, 8,
      6, 1, 3, 2,
      8, 4, 6, 8,
      7, 1, 2, 6,
      10,5, 6, 9,
      6, 2, 4, 7),
      ncol=4, byrow=TRUE,
      dimnames=list(paste("S", 1:6, sep=""), paste("J", 1:4, sep=""))
)

sf  #example from Shrout and Fleiss (1979)
ICC(sf)
</code></pre>

<hr>
<h2 id='identify.formula'>Identify Points In a Plot Using a Formula</h2><span id='topic+identify.formula'></span>

<h3>Description</h3>

<p>The function <code><a href="graphics.html#topic+identify">identify</a></code> reads the position of the graphics pointer when
the (first) mouse button is pressed. It then searches the
coordinates given in x and y for the point closest to the
pointer. If this point is close enough to the pointer,
its index will be returned as part of the value of the
call.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'formula'
 identify(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="identify.formula_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="identify.formula_+3A_data">data</code></td>
<td>
<p>The data frame from which the formula should
be evaluated.</p>
</td></tr>
<tr><td><code id="identify.formula_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="identify.formula_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="identify.formula_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to
<code><a href="graphics.html#topic+identify">identify</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is meant to make it easier to call
<code><a href="graphics.html#topic+identify">identify</a></code> after <code><a href="base.html#topic+plot">plot</a></code> has been called
using a formula and the <code>data</code> argument.
</p>
<p>A two dimensional plot must be active and the vectors in
<code>x</code> and data frame in <code>data</code> must correspond to
the x- and y-axes and the data of the plot.
</p>


<h3>Value</h3>

<p>If <code>pos</code> is <code>FALSE</code>, an integer vector containing the
indices of the identified points, in the order they were identified.
If <code>pos</code> is <code>TRUE</code>, a list containing a component
<code>ind</code>, indicating which points were identified and a component
<code>pos</code>, indicating where the labels were placed relative to the
identified points (1=below, 2=left, 3=above, 4=right and 0=no offset,
used if <code>atpen = TRUE</code>).
</p>


<h3>Author(s)</h3>

<p>Derek Ogle &lt;dogle@northland.edu&gt;</p>


<h3>See Also</h3>

<p><code>identify</code>, <code><a href="graphics.html#topic+locator">locator</a></code>, <code><a href="graphics.html#topic+text">text</a></code><br />
<a href="https://www.rforge.net/NCStats/files/">https://www.rforge.net/NCStats/files/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Copy and try in an interactive R session
plot(dist ~ speed, data = cars, subset = speed &lt; 17)
identify(dist ~ speed, data = cars, subset = speed &lt; 17)

## End(Not run)
</code></pre>

<hr>
<h2 id='IdentifyA'>Identify Points in Plot Lying Within a Rectangle or Polygon
</h2><span id='topic+IdentifyA'></span><span id='topic+IdentifyA.default'></span><span id='topic+IdentifyA.formula'></span>

<h3>Description</h3>

<p>Find all the points lying either in a rectangle area spanned by an upper left and a bottom-right point or by a polygon area consisting of any number of points defined by point and click.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IdentifyA(x, ...)

## S3 method for class 'formula'
 IdentifyA(formula, data, subset, poly = FALSE, ...)
## Default S3 method:
 IdentifyA(x, y = NULL, poly = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IdentifyA_+3A_x">x</code>, <code id="IdentifyA_+3A_y">y</code></td>
<td>
<p>x and y values of the points used to create the plot.</p>
</td></tr>
<tr><td><code id="IdentifyA_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code>, such as <code>y ~ x</code> specifying x and y values. <br />
Here the formula must be entered that was used to create the scatterplot.
</p>
</td></tr>
<tr><td><code id="IdentifyA_+3A_data">data</code></td>
<td>
<p>a data frame (or list) from which the variables in
<code>formula</code> should be taken.
</p>
</td></tr>
<tr><td><code id="IdentifyA_+3A_subset">subset</code></td>
<td>
<p> an optional vector specifying a subset of observations
to be used.
</p>
</td></tr>
<tr><td><code id="IdentifyA_+3A_poly">poly</code></td>
<td>
<p>logical. Defines if a polygon or a rectangle should be used to select the points. Default is rectangle.
If a polygon should be used, set this argument to <code>TRUE</code> and select all desired points. The polygon will be closed
automatically when finished.
</p>
</td></tr>
<tr><td><code id="IdentifyA_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>IdentifyA</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Index vector with the points lying within the selected area.
The coordinates are returned as text in the attribute <code>"cond"</code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+identify">identify</a></code>, <code><a href="graphics.html#topic+locator">locator</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# run the example via copy and paste

plot(temperature ~ delivery_min, data=d.pizza)
idx &lt;- IdentifyA(temperature ~ delivery_min, data=d.pizza)

# you selected the following points
d.pizza[idx,]
points(temperature ~ delivery_min, data = d.pizza[idx,], col="green")

# use the attr("cond") for subsets in code
attr(idx, "cond")

# create a group variable for the found points
d.pizza$grp &lt;- seq(nrow(d.pizza)) %in% idx

# try the polygon option
idx &lt;- IdentifyA(temperature ~ delivery_min, data=d.pizza, poly=TRUE)
points(temperature ~ delivery_min, data = d.pizza[idx,], col="red")

## End(Not run)
</code></pre>

<hr>
<h2 id='ImputeKnn'>
Fill in NA values with the values of the nearest neighbours
</h2><span id='topic+ImputeKnn'></span>

<h3>Description</h3>

<p>Function that fills in all NA values using the k Nearest
Neighbours of each case with NA values.
By default it uses the values of the neighbours and 
obtains an weighted (by the distance to the case) average
of their values to fill in the unknows.
If meth='median' it uses the median/most frequent value,
instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ImputeKnn(data, k = 10, scale = TRUE, meth = "weighAvg", distData = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ImputeKnn_+3A_data">data</code></td>
<td>

<p>A data frame with the data set
</p>
</td></tr>
<tr><td><code id="ImputeKnn_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to use (defaults to 10)
</p>
</td></tr>
<tr><td><code id="ImputeKnn_+3A_scale">scale</code></td>
<td>

<p>Boolean setting if the data should be scale before finding the nearest neighbours (defaults
to TRUE)
</p>
</td></tr>
<tr><td><code id="ImputeKnn_+3A_meth">meth</code></td>
<td>

<p>String indicating the method used to calculate the value to fill in each
NA. Available values are 'median' or 'weighAvg' (the default).
</p>
</td></tr>
<tr><td><code id="ImputeKnn_+3A_distdata">distData</code></td>
<td>

<p>Optionally you may sepecify here a data frame containing the data set
that should be used to find the neighbours. This is usefull when
filling in NA values on a test set, where you should use only
information from the training set. This defaults to NULL, which means
that the neighbours will be searched in <code>data</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the k-nearest neighbours to fill in the unknown (NA)
values in a data set. For each case with any NA value it will search for
its k most similar cases and use the values of these cases to fill in
the unknowns.
</p>
<p>If <code>meth='median'</code>  the function will use either the median (in
case of numeric variables) or the most frequent value (in case of
factors), of the neighbours to fill in the NAs. If
<code>meth='weighAvg'</code> the function will use a weighted average of the
values of the neighbours. The weights are given by <code>exp(-dist(k,x)</code>
where <code>dist(k,x)</code> is the euclidean distance between the case with
NAs (x) and the neighbour k.
</p>


<h3>Value</h3>

<p>A data frame without NA values
</p>


<h3>Author(s)</h3>

<p> Luis Torgo <a href="mailto:ltorgo@dcc.fc.up.pt">ltorgo@dcc.fc.up.pt</a> </p>


<h3>References</h3>

<p>Torgo, L. (2010) <em>Data Mining using R: learning with case studies</em>,
CRC Press (ISBN: 9781439810187).
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+complete.cases">complete.cases</a></code>, <code><a href="stats.html#topic+na.omit">na.omit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cleanPizza &lt;- ImputeKnn(d.pizza[, -2])   # no dates allowed
summary(cleanPizza)
</code></pre>

<hr>
<h2 id='InDots'>Is a Specific Argument in the Dots-Arguments?
</h2><span id='topic+InDots'></span>

<h3>Description</h3>

<p>Returns the value of a specific named argument if it was comprised in the dots or a default value, if it wasn't.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InDots(..., arg, default)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InDots_+3A_...">...</code></td>
<td>
<p>the dots arguments to be checked.
</p>
</td></tr>
<tr><td><code id="InDots_+3A_arg">arg</code></td>
<td>
<p>the name of argument to test for.
</p>
</td></tr>
<tr><td><code id="InDots_+3A_default">default</code></td>
<td>
<p>the default value to return, if the argument <code>arg</code> does not exist in the dots.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the value of the argument, if it exists else the specified default value.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>

<hr>
<h2 id='IQRw'>The (weighted) Interquartile Range
</h2><span id='topic+IQRw'></span>

<h3>Description</h3>

<p>computes interquartile range of the x values. Weights are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IQRw(x, weights = NULL, na.rm = FALSE, type = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IQRw_+3A_x">x</code></td>
<td>
<p>a numeric vector.
</p>
</td></tr>
<tr><td><code id="IQRw_+3A_weights">weights</code></td>
<td>
<p>an optional numeric vector giving the sample weights.
</p>
</td></tr>
<tr><td><code id="IQRw_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?
</p>
</td></tr>
<tr><td><code id="IQRw_+3A_type">type</code></td>
<td>
<p>an integer selecting one of the many quantile algorithms, see <code><a href="#topic+Quantile">Quantile</a>()</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation is based on <code><a href="#topic+Quantile">Quantile</a>()</code> function, which allows to define weights.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Median">Median</a>()</code>, <code><a href="#topic+Quantile">Quantile</a>()</code>, <code><a href="stats.html#topic+IQR">IQR</a>()</code>, <code><a href="stats.html#topic+quantile">quantile</a>()</code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(3.7,3.3,3.5,2.8)
w &lt;- c(5, 5, 4, 1)/15

IQRw(x=x, weights=w)
</code></pre>

<hr>
<h2 id='IsDate'>Check If an Object Is of Type Date
</h2><span id='topic+IsDate'></span>

<h3>Description</h3>

<p>Check if the given x is of any known Date type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsDate(x, what = c("either", "both", "timeVaries"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IsDate_+3A_x">x</code></td>
<td>
<p>a vector or values to be checked.
</p>
</td></tr>
<tr><td><code id="IsDate_+3A_what">what</code></td>
<td>
<p>can be any value out of &quot;<code>either</code>&quot; (default), &quot;<code>both</code>&quot; or &quot;<code>timeVaries</code>&quot;.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This checks for many known Date and Time classes: &quot;POSIXt&quot;, &quot;POSIXct&quot;, &quot;dates&quot;, &quot;times&quot;, &quot;chron&quot;, &quot;Date&quot;.
</p>


<h3>Value</h3>

<p>logical vector of the same dimension as x.
</p>


<h3>Author(s)</h3>

<p>Frank E Harrell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Year">Year</a></code>, <code><a href="#topic+Month">Month</a></code>, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>IsDate(as.Date("2013-04-10"))

IsDate(31002)
</code></pre>

<hr>
<h2 id='IsDichotomous'>Test If a Variable Contains Only Two Unique Values
</h2><span id='topic+IsDichotomous'></span><span id='topic+Flags'></span>

<h3>Description</h3>

<p>Test if a variable contains only two values. The variable does not need to be a numerical value, factors and logicals are supported as well. <code>NA</code>s can be skipped by setting <code>na.rm</code> to <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsDichotomous(x, strict = FALSE, na.rm = FALSE)

Flags(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IsDichotomous_+3A_x">x</code></td>
<td>
<p>a numeric or integer vector, a logical vector or a factor (ordered and unordered)</p>
</td></tr>
<tr><td><code id="IsDichotomous_+3A_strict">strict</code></td>
<td>
<p>logical. If set to <code>TRUE</code>, the result will only be <code>TRUE</code>, if x contains exactly 2 levels. If set to <code>FALSE</code> the result will be <code>TRUE</code> for 1 and for 2 levels.</p>
</td></tr>
<tr><td><code id="IsDichotomous_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>IsDichotomous tests a single variable. Flags returns the names of all the dichotomous variables in a list or data.frame.</p>


<h3>Value</h3>

<p><code>TRUE</code> if <code>x</code> contains only two unique values, <code>FALSE</code> else
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>IsDichotomous(sample(10, 5, replace=TRUE))
</code></pre>

<hr>
<h2 id='IsEuclid'>Is a Distance Matrix Euclidean?</h2><span id='topic+IsEuclid'></span><span id='topic+summary.dist'></span>

<h3>Description</h3>

<p>Confirmation of the Euclidean nature of a distance matrix by the Gower's theorem.<br />
<code>IsEuclid</code> is used in <code>summary.dist</code>.<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsEuclid(distmat, plot = FALSE, print = FALSE, tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IsEuclid_+3A_distmat">distmat</code></td>
<td>
<p>an object of class 'dist'</p>
</td></tr>
<tr><td><code id="IsEuclid_+3A_plot">plot</code></td>
<td>
<p>a logical value indicating whether the eigenvalues bar plot of the matrix of the term <code class="reqn">-\frac{1}{2} {d_{ij}^2}</code> centred by rows and columns should be diplayed</p>
</td></tr>
<tr><td><code id="IsEuclid_+3A_print">print</code></td>
<td>
<p>a logical value indicating whether the eigenvalues of the matrix of the term <code class="reqn">-\frac{1}{2} {d_{ij}^2}</code> centred by rows and columns should be printed</p>
</td></tr>
<tr><td><code id="IsEuclid_+3A_tol">tol</code></td>
<td>
<p>a tolerance threshold : an eigenvalue is considered positive if it is larger than <code>-tol*lambda1</code> where <code>lambda1</code> is the largest eigenvalue.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a logical value indicating if all the eigenvalues are positive or equal to zero
</p>


<h3>Author(s)</h3>

<p>Daniel Chessel  <br />
Stephane Dray <a href="mailto:dray@biomserv.univ-lyon1.fr">dray@biomserv.univ-lyon1.fr</a>
</p>


<h3>References</h3>

<p>Gower, J.C. and Legendre, P. (1986) Metric and Euclidean properties of dissimilarity coefficients. <em>Journal of Classification</em>, <b>3</b>, 5&ndash;48.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>w &lt;- matrix(runif(10000), 100, 100)
w &lt;- dist(w)
summary(w)
IsEuclid (w) # TRUE
</code></pre>

<hr>
<h2 id='IsOdd'>Checks If An Integer Is Even Or Odd
</h2><span id='topic+IsOdd'></span>

<h3>Description</h3>

<p>Checks if the elements of an integer vector <code>x</code> are even or odd.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsOdd(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IsOdd_+3A_x">x</code></td>
<td>
<p>vector of integers
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a logic vector
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+IsWhole">IsWhole</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>IsOdd(1:10)
</code></pre>

<hr>
<h2 id='IsPrime'>IsPrime Property</h2><span id='topic+IsPrime'></span>

<h3>Description</h3>

<p>Returns for a vector or matrix of positive integers a logical object of the same dimension(s) containing <code>TRUE</code> for the elements that are prime and <code>FALSE</code> otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsPrime(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IsPrime_+3A_x">x</code></td>
<td>
<p>vector or matrix of nonnegative integers</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a vector or a matrix of positive integers returns a vector of the same size
of <code>FALSE</code> and <code>TRUE</code>. Use <code>which(IsPrime(1:21))</code> to get the positions.
</p>


<h3>Value</h3>

<p>logical vector
</p>


<h3>Author(s)</h3>

<p>Hans W. Borchers &lt;hwborchers@googlemail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Factorize">Factorize</a>, <a href="#topic+Primes">Primes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(1:10, nrow=10, ncol=10, byrow=TRUE)
x * IsPrime(x)

# Find first prime number octett:
octett &lt;- c(0, 2, 6, 8, 30, 32, 36, 38) - 19
while (TRUE) {
    octett &lt;- octett + 210
    if (all(IsPrime(octett))) {
        cat(octett, "\n", sep="  ")
        break
    }
}
</code></pre>

<hr>
<h2 id='IsValidHwnd'>Check Windows Pointer
</h2><span id='topic+IsValidHwnd'></span>

<h3>Description</h3>

<p>Check if a pointer points to a valid and running MS-Office instance. The function does this by first checking for <code>NULL</code> and <code>nil</code> pointer and then
trying to get the current selection of the application.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsValidHwnd(hwnd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IsValidHwnd_+3A_hwnd">hwnd</code></td>
<td>
<p>the pointer to a word instance as created by <code>GetNewWrd()</code> or <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical value, <code>TRUE</code> if hwnd is a valid pointer to a running application
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+GetCurrWrd">GetCurrWrd</a></code>(), <code><a href="#topic+GetCurrXL">GetCurrXL</a></code>(), <code><a href="#topic+GetCurrPP">GetCurrPP</a></code>()
</p>

<hr>
<h2 id='JarqueBeraTest'>(Robust) Jarque Bera Test</h2><span id='topic+JarqueBeraTest'></span>

<h3>Description</h3>

<p>This function performs the Jarque-Bera tests of normality either the robust or the classical way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JarqueBeraTest(x, robust = TRUE, method = c("chisq", "mc"),
               N = 0, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="JarqueBeraTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values.</p>
</td></tr>
<tr><td><code id="JarqueBeraTest_+3A_robust">robust</code></td>
<td>
<p>defines, whether the robust version should be used.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="JarqueBeraTest_+3A_method">method</code></td>
<td>
<p>a character string out of <code>chisq</code> or <code>mc</code>, specifying how the critical
values should be obtained. Default is approximated by the
chisq-distribution or empirically via Monte Carlo.</p>
</td></tr>
<tr><td><code id="JarqueBeraTest_+3A_n">N</code></td>
<td>
<p>number of Monte Carlo simulations for the empirical critical values</p>
</td></tr>
<tr><td><code id="JarqueBeraTest_+3A_na.rm">na.rm</code></td>
<td>
<p>defines if <code>NAs</code> should be omitted. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test is based on a joint statistic using skewness and kurtosis
coefficients. The robust Jarque-Bera (RJB) version of utilizes
the robust standard deviation (namely the mean absolute deviation
from the median, as provided e. g. by <code><a href="#topic+MeanAD">MeanAD</a>(x, FUN=median)</code>) to estimate sample kurtosis and skewness. For more details see Gel and Gastwirth (2006).
<br />
Setting <code>robust</code> to <code>FALSE</code> will perform the original Jarque-Bera test (see
Jarque, C. and Bera, A (1980)).
</p>


<h3>Value</h3>

<p>A list with class <code>htest</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>type of test was performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is melted from the <code>jarque.bera.test</code> (in <code>tseries</code> package) and the <code>rjb.test</code> from the package <code>lawstat</code>.</p>


<h3>Author(s)</h3>

<p>W. Wallace Hui, Yulia R. Gel, Joseph L. Gastwirth, Weiwen Miao</p>


<h3>References</h3>

<p>Gastwirth, J. L.(1982) <em>Statistical Properties of A Measure
of Tax Assessment Uniformity</em>, Journal of Statistical Planning
and Inference 6, 1-12.<br />
</p>
<p>Gel, Y. R. and Gastwirth, J. L. (2008) <em>A robust modification of
the Jarque-Bera test of normality</em>, Economics Letters 99, 30-32.<br />
</p>
<p>Jarque, C. and Bera, A. (1980) <em>Efficient tests for
normality, homoscedasticity and serial independence of regression
residuals</em>, Economics Letters 6, 255-259.
</p>


<h3>See Also</h3>

<p>Alternative tests for normality as
<code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code>,
<code><a href="#topic+AndersonDarlingTest">AndersonDarlingTest</a></code>, <code><a href="#topic+CramerVonMisesTest">CramerVonMisesTest</a></code>, <code><a href="#topic+LillieTest">LillieTest</a></code>, <code><a href="#topic+PearsonTest">PearsonTest</a></code>, <code><a href="#topic+ShapiroFranciaTest">ShapiroFranciaTest</a></code>
</p>
<p><code><a href="stats.html#topic+qqnorm">qqnorm</a></code>, <code><a href="stats.html#topic+qqline">qqline</a></code> for producing a normal quantile-quantile plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100)    # null hypothesis
JarqueBeraTest(x)

x &lt;- runif(100)    # alternative hypothesis
JarqueBeraTest(x, robust=TRUE)
</code></pre>

<hr>
<h2 id='JonckheereTerpstraTest'>Exact Version of Jonckheere-Terpstra Test</h2><span id='topic+JonckheereTerpstraTest'></span><span id='topic+JonckheereTerpstraTest.default'></span><span id='topic+JonckheereTerpstraTest.formula'></span>

<h3>Description</h3>

<p>Jonckheere-Terpstra test to test for ordered differences among classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JonckheereTerpstraTest(x, ...)

## Default S3 method:
JonckheereTerpstraTest(x, g, alternative = c("two.sided", "increasing", "decreasing"), 
                       nperm = NULL, exact = NULL, ...)

## S3 method for class 'formula'
JonckheereTerpstraTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="JonckheereTerpstraTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, or a list of numeric data vectors.</p>
</td></tr>
<tr><td><code id="JonckheereTerpstraTest_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the corresponding elements of x. Ignored if x is a list.</p>
</td></tr>
<tr><td><code id="JonckheereTerpstraTest_+3A_alternative">alternative</code></td>
<td>
<p>means are monotonic (<code>two.sided</code>), <code>increasing</code>, or
<code>decreasing</code></p>
</td></tr>
<tr><td><code id="JonckheereTerpstraTest_+3A_nperm">nperm</code></td>
<td>
<p>number of permutations for the reference distribution.
The default is <code>NULL</code> in which case the permutation p-value is not
computed. It's recommended to set <code>nperm</code> to 1000 or higher if permutation p-value is desired.</p>
</td></tr>
<tr><td><code id="JonckheereTerpstraTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>  
<tr><td><code id="JonckheereTerpstraTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>. 
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>  
<tr><td><code id="JonckheereTerpstraTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>  
<tr><td><code id="JonckheereTerpstraTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>  
<tr><td><code id="JonckheereTerpstraTest_+3A_exact">exact</code></td>
<td>
<p>logical, defining if the exact test should be calculated. If left to <code>NULL</code>, the function uses the exact test up to a samplesize of 100 and falls back to normal approximation for larger samples. The exact procedure can not be applied to samples containing ties. </p>
</td></tr>
<tr><td><code id="JonckheereTerpstraTest_+3A_...">...</code></td>
<td>
<p>further argument to be passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>JonckheereTerpstraTest is the exact (permutation) version of the
Jonckheere-Terpstra test.  It uses the statistic
</p>
<p style="text-align: center;"><code class="reqn">\sum_{k&lt;l} \sum_{ij} I(X_{ik} &lt; X_{jl}) + 0.5 I(X_{ik} =
    X_{jl}),</code>
</p>
<p> where <code class="reqn">i, j</code> are observations in groups <code class="reqn">k</code> and
<code class="reqn">l</code> respectively.  The asymptotic version is equivalent to
<code>cor.test(x, g, method="k")</code>. The exact calculation requires that there
be no ties and that the sample size is less than 100. When data are
tied and sample size is at most 100 permutation p-value is returned.<br />
</p>
<p>If x is a list, its elements are taken as the samples to be compared, and hence have to be numeric data vectors. 
In this case, g is ignored, and one can simply use JonckheereTerpstraTest(x) to perform the test. 
If the samples are not yet contained in a list, use JonckheereTerpstraTest(list(x, ...)). <br />
</p>
<p>Otherwise, <code>x</code> must be a numeric data vector, and <code>g</code> must be a vector or factor object of the 
same length as <code>x</code> giving the group for the corresponding elements of <code>x</code>. 
</p>


<h3>Note</h3>

<p> The function was previously published as <code>jonckheere.test()</code> in the  <span class="pkg">clinfun</span> package and has been
integrated here without logical changes. Some argument checks and a formula interface were added.
</p>


<h3>Author(s)</h3>

<p>Venkatraman E. Seshan &lt;seshanv@mskcc.org&gt;, minor adaptations Andri Signorell</p>


<h3>References</h3>

<p>Jonckheere, A. R. (1954). A distribution-free k-sample test again
ordered alternatives. <em>Biometrika</em> 41:133-145.
</p>
<p>Terpstra, T. J. (1952). The asymptotic normality and consistency of
Kendall's test against trend, when ties are present in one ranking.
<em>Indagationes Mathematicae</em> 14:327-333.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
g &lt;- ordered(rep(1:5, rep(10,5)))
x &lt;- rnorm(50) + 0.3 * as.numeric(g)

JonckheereTerpstraTest(x, g)

x[1:2] &lt;- mean(x[1:2]) # tied data

JonckheereTerpstraTest(x, g)
JonckheereTerpstraTest(x, g, nperm=5000)

# Duller, S. 222
coffee &lt;- list(
  c_4=c(447,396,383,410),
  c_2=c(438,521,468,391,504,472),
  c_0=c(513,543,506,489,407))  

# the list interface:
JonckheereTerpstraTest(coffee)

# the formula interface
breaking &lt;- data.frame(
  speed=c(20,25,25,25,25,30,30,30,35,35),
  distance=c(48,33,59,48,56,60,101,67,85,107))

JonckheereTerpstraTest(distance ~ speed, breaking, alternative="increasing")

</code></pre>

<hr>
<h2 id='KappaM'>Kappa for m Raters</h2><span id='topic+KappaM'></span>

<h3>Description</h3>

<p>Computes kappa as an index of interrater agreement between m raters on categorical data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KappaM(x, method = c("Fleiss", "Conger", "Light"), conf.level = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KappaM_+3A_x">x</code></td>
<td>
<p><code class="reqn">n \times m</code> matrix or dataframe, n subjects m raters.</p>
</td></tr>
<tr><td><code id="KappaM_+3A_method">method</code></td>
<td>
<p>a logical indicating whether the exact Kappa (Conger, 1980), the Kappa described by Fleiss (1971) or Light's Kappa (1971) should be computed.</p>
</td></tr>
<tr><td><code id="KappaM_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence intervals will be calculated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Missing data are omitted in a listwise way.<br />
The coefficient described by Fleiss (1971) does not reduce to Cohen's Kappa (unweighted) for m=2 raters. Therefore, the exact Kappa coefficient, which is slightly higher in most cases, was proposed by Conger (1980).<br />
Light's Kappa equals the average of all possible combinations of bivariate Kappas between raters.<br />
The confidence levels can only be reported using Fleiss' formulation of Kappa.
</p>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested,<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Note</h3>

<p> This function was previously published as <code>kappam.fleiss()</code> in the  <span class="pkg">irr</span> package and has been integrated here with some changes in the interface.
</p>


<h3>Author(s)</h3>

<p>Matthias Gamer, with some modifications by Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>Conger, A.J. (1980): Integration and generalisation of Kappas for multiple raters. <em>Psychological Bulletin</em>, 88, 322-328
</p>
<p>Fleiss, J.L. (1971): Measuring nominal scale agreement among many raters <em>Psychological Bulletin</em>, 76, 378-382
</p>
<p>Fleiss, J.L., Levin, B., &amp; Paik, M.C. (2003): <em>Statistical Methods for Rates and Proportions</em>, 3rd Edition. New York: John Wiley &amp; Sons
</p>
<p>Light, R.J. (1971): Measures of response agreement for qualitative data: Some generalizations and alternatives. <em>Psychological Bulletin</em>, 76, 365-377.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CohenKappa">CohenKappa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>statement &lt;- data.frame(
  A=c(2,3,1,3,1,2,1,2,3,3,3,3,3,2,1,3,3,2,2,1,
      2,1,3,3,2,2,1,2,1,1,2,3,3,3,3,3,1,2,1,1),
  B=c(2,2,2,1,1,2,1,2,3,3,2,3,1,3,1,1,3,2,1,2,
      2,1,3,2,2,2,3,2,1,1,2,2,3,3,3,3,2,2,2,3),
  C=c(2,2,2,1,1,2,1,2,3,3,2,3,3,3,3,2,2,2,2,3,
      2,2,3,3,2,2,3,2,2,2,2,3,3,3,3,3,3,2,2,2),
  D=c(2,2,2,1,1,2,1,2,3,3,2,3,3,3,3,3,2,2,2,2,
      3,1,3,2,2,2,1,2,2,1,2,3,3,3,3,3,3,2,2,1),
  E=c(2,2,2,3,3,2,3,1,3,3,2,3,3,3,3,3,2,2,2,3,
      2,3,3,2,2,2,3,2,1,3,2,3,3,1,3,3,3,2,2,1)
)

KappaM(statement)

KappaM(statement, method="Conger")   # Exact Kappa
KappaM(statement, conf.level=0.95)   # Fleiss' Kappa and confidence intervals

KappaM(statement, method="Light")   # Exact Kappa
</code></pre>

<hr>
<h2 id='KendallTauA'>Kendall's <code class="reqn">\tau_{a}</code>
</h2><span id='topic+KendallTauA'></span>

<h3>Description</h3>

<p>Calculate Kendall's tau-a statistic, a measure of
association for ordinal factors in a two-way table.<br />
The function has interfaces for a table (matrix) and for single vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KendallTauA(x, y = NULL, direction = c("row", "column"), conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KendallTauA_+3A_x">x</code></td>
<td>
<p>a numeric vector or a table. A matrix will be treated as table.
</p>
</td></tr>
<tr><td><code id="KendallTauA_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="KendallTauA_+3A_direction">direction</code></td>
<td>
<p>direction of the calculation. Can be <code>"row"</code> (default) or <code>"column"</code>, where
<code>"row"</code> calculates Kendall's tau-a (R|C) (&quot;column dependent&quot;).
</p>
</td></tr>
<tr><td><code id="KendallTauA_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated.
</p>
</td></tr>
<tr><td><code id="KendallTauA_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set useNA. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kendall's tau coefficient (sometimes called &quot;Kendall rank correlation coefficient&quot;), is a statistic used to measure the association between two measured quantities. It is a measure of rank correlation: the similarity of the orderings of the data when ranked by each of the quantities.
<br />
Kendall's tau-a is computed as </p>
<p style="text-align: center;"><code class="reqn"> \tau_a(C|R) = \frac{P-Q}{\frac{1}{2} \cdot n \cdot (n-1)}</code>
</p>

<p>where P equals twice the number of concordances and Q twice the number of discordances. Its range is [-1, 1].<br />
(Note that Kendall tau-a does not take into consideration any ties, which makes it unpractical. Consider using <code><a href="#topic+KendallTauB">KendallTauB</a></code> (Tau-b) when ties are present.)
</p>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested,<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons,
pp. 57-59.
</p>
<p>Hollander, M, Wolfe, D. A., Chicken, E. (2014) <em>Nonparametric Statistical Methods</em>, Third edition, Wiley,
</p>
<p>Liebetrau, A. M. (1983) <em>Measures of Association</em>, Sage University Papers Series on Quantitative Applications in the Social Sciences, 07-004. Newbury Park, CA: Sage, pp. 49-56
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ConDisPairs">ConDisPairs</a></code> yields concordant and discordant pairs <br /><br />
Other association measures: <br />
<code><a href="stats.html#topic+cor">cor</a> (method="kendall")</code> for Tau b, <code><a href="#topic+StuartTauC">StuartTauC</a></code>, <code><a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a></code><br />
<code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example in:
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. S. 1821

tab &lt;- as.table(rbind(c(26,26,23,18,9),c(6,7,9,14,23)))

# Kendall's tau-a C|R
KendallTauA(tab, direction="column", conf.level=0.95)
# Kendall's tau-a R|C
KendallTauA(tab, direction="row", conf.level=0.95)

# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. 1814 (143)
tab &lt;- as.table(cbind(c(11,2),c(4,6)))

KendallTauA(tab, direction="row", conf.level=0.95)
KendallTauA(tab, direction="column", conf.level=0.95)

# Liebetrau, pp. 52
x &lt;- c(1,2,2,3,3,3,4,5)
y &lt;- c(1,3,2,1,5,3,4,5)

ConDisPairs(table(x, y))
KendallTauA(x, y, conf.level=0.95)
</code></pre>

<hr>
<h2 id='KendallTauB'>Kendall's <code class="reqn">\tau_{b}</code>
</h2><span id='topic+KendallTauB'></span>

<h3>Description</h3>

<p>Calculate Kendall's tau-b. The estimator could also be calculated with <code>cor(..., method="kendall")</code>.
The calculation of confidence intervals however would not be found there.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KendallTauB(x, y = NULL, conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KendallTauB_+3A_x">x</code></td>
<td>
<p>a numeric vector, matrix or data.frame.
</p>
</td></tr>
<tr><td><code id="KendallTauB_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="KendallTauB_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated.
</p>
</td></tr>
<tr><td><code id="KendallTauB_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set useNA. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested,<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons,
pp. 57-59.
</p>
<p>Kendall, M. (1955) <em>Rank Correlation Methods</em>, Second Edition, London: Charles Griffin and Co.
</p>
<p>Brown, M.B.andBenedetti, J.K.(1977) Sampling Behavior of Tests for Correlation in Two-Way Contingency Tables, <em>Journal of the American Statistical Association</em>, 72, 309-315.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ConDisPairs">ConDisPairs</a></code> yields concordant and discordant pairs <br /><br />
Other association measures: <br />
<code><a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a></code>, <code><a href="#topic+KendallTauA">KendallTauA</a></code> (tau-a), <code><a href="stats.html#topic+cor">cor</a></code> (method=&quot;kendall&quot;) for tau-b, <code><a href="#topic+StuartTauC">StuartTauC</a></code> (tau-c), <code><a href="#topic+SomersDelta">SomersDelta</a></code><br />
<code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+GoodmanKruskalTau">GoodmanKruskalTau</a></code>, <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example in:
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. S. 1821

tab &lt;- as.table(rbind(c(26,26,23,18,9),c(6,7,9,14,23)))

KendallTauB(tab, conf.level=0.95)
</code></pre>

<hr>
<h2 id='KendallW'>Kendall's Coefficient of Concordance W</h2><span id='topic+KendallW'></span>

<h3>Description</h3>

<p>Computes Kendall's coefficient of concordance,  a popular measure of association. It is  an index of interrater reliability of ordinal data. The coefficient could be corrected for ties within raters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KendallW(x, correct = FALSE, test = FALSE, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KendallW_+3A_x">x</code></td>
<td>
<p><code class="reqn">n \times m</code> matrix or dataframe, k subjects (in rows) m raters (in columns).</p>
</td></tr>
<tr><td><code id="KendallW_+3A_correct">correct</code></td>
<td>
<p>a logical indicating whether the coefficient should be corrected for ties within raters.</p>
</td></tr>
<tr><td><code id="KendallW_+3A_test">test</code></td>
<td>
<p>a logical indicating whether the test statistic and p-value should be reported.</p>
</td></tr>
<tr><td><code id="KendallW_+3A_na.rm">na.rm</code></td>
<td>

<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. If set to <code>TRUE</code> only the complete cases of the ratings will be used. Defaults to <code>FALSE</code>.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test for Kendall's W is completely equivalent to <code><a href="stats.html#topic+friedman.test">friedman.test</a></code>. The only advantage of this test over Friedman's is that Kendall's W has an interpretation as the coefficient of concordance. The test itself is only valid for large samples.<br />
Kendall's W should be corrected for ties, if raters did not use a true ranking order for the subjects.
</p>


<h3>Value</h3>

<p>Either a single value if test is set to <code>FALSE</code> or else <br />
</p>
<p>a list with class &ldquo;htest&rdquo; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the chi-square statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Kendall's coefficient of concordance W&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the coefficient of concordance.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom df, the number of subjects examined and the number of raters.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function was previously published as <code>kendall()</code> in the  <span class="pkg">irr</span> package and has been
integrated here without logical changes, but with some adaptations in the result structure.
</p>


<h3>Author(s)</h3>

<p>Matthias Gamer &lt;m.gamer@uke.uni-hamburg.de&gt;</p>


<h3>References</h3>

<p>Kendall, M.G. (1948) <em>Rank correlation methods</em>. London: Griffin.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="#topic+KappaM">KappaM</a></code>, <code><a href="#topic+CronbachAlpha">CronbachAlpha</a></code>, <code><a href="#topic+ICC">ICC</a></code>, <code><a href="stats.html#topic+friedman.test">friedman.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>anxiety &lt;- data.frame(rater1=c(3,3,3,4,5,5,2,3,5,2,2,6,1,5,2,2,1,2,4,3),
                      rater2=c(3,6,4,6,2,4,2,4,3,3,2,3,3,3,2,2,1,3,3,4),
                      rater3=c(2,1,4,4,3,2,1,6,1,1,1,2,3,3,1,1,3,3,2,2))

KendallW(anxiety, TRUE)

# with test results
KendallW(anxiety, TRUE, test=TRUE)

# example from Siegel and Castellan (1988)
d.att &lt;- data.frame(
  id        = c(4,21,11),
  airfare   = c(5,1,4),
  climate   = c(6,7,5),
  season    = c(7,6,1),
  people    = c(1,2,3),
  program   = c(2,3,2),
  publicity = c(4,5,7),
  present   = c(3,4,6),
  interest  = c(8,8,8)
)

KendallW(t(d.att[, -1]), test = TRUE)

# which is perfectly the same as
friedman.test(y=as.matrix(d.att[,-1]), groups = d.att$id)
</code></pre>

<hr>
<h2 id='Keywords'>List Keywords For R Manual Pages</h2><span id='topic+Keywords'></span>

<h3>Description</h3>

<p>List the keywords for specific R man pages or return a list of valid R keywords.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Keywords(topic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Keywords_+3A_topic">topic</code></td>
<td>
<p>optional, object or man page topic</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>topic</code> is provided, return a list of the Keywords associated
with <code>topic</code>.  Otherwise, display the list of valid R Keywords
from the R doc/Keywords file.
</p>


<h3>Author(s)</h3>

<p>Gregory R. Warnes <a href="mailto:greg@warnes.net">greg@warnes.net</a></p>


<h3>See Also</h3>

 <p><code><a href="utils.html#topic+help">help</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Show all valid R Keywords
Keywords()

## Show Keywords associated with the 'merge' function
Keywords(merge)
Keywords("merge")
</code></pre>

<hr>
<h2 id='KrippAlpha'>Krippendorff's Alpha Reliability Coefficient</h2><span id='topic+KrippAlpha'></span>

<h3>Description</h3>

<p>Calculate the alpha coefficient of reliability proposed by Krippendorff.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> KrippAlpha(x, method=c("nominal", "ordinal", "interval", "ratio"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KrippAlpha_+3A_x">x</code></td>
<td>
<p>classifier x object matrix of classifications or scores</p>
</td></tr>
<tr><td><code id="KrippAlpha_+3A_method">method</code></td>
<td>
<p>data level of x</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with class '&quot;irrlist&quot;' containing the following components: 
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>a character string describing the method.</p>
</td></tr>
<tr><td><code>subjects</code></td>
<td>
<p>the number of data objects.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>the number of raters.</p>
</td></tr>
<tr><td><code>irr.name</code></td>
<td>
<p>a character string specifying the name of the coefficient.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>value of alpha.</p>
</td></tr>
<tr><td><code>stat.name</code></td>
<td>
<p>here &quot;nil&quot; as there is no test statistic.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic (NULL).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the probability of the test statistic (NULL).</p>
</td></tr>
<tr><td><code>cm</code></td>
<td>
<p>the concordance/discordance matrix used in the calculation of alpha</p>
</td></tr>
<tr><td><code>data.values</code></td>
<td>
<p>a character vector of the unique data values</p>
</td></tr>
<tr><td><code>levx</code></td>
<td>
<p>the unique values of the ratings</p>
</td></tr>
<tr><td><code>nmatchval</code></td>
<td>
<p>the count of matches, used in calculation</p>
</td></tr>
<tr><td><code>data.level</code></td>
<td>
<p>the data level of the ratings (&quot;nominal&quot;,&quot;ordinal&quot;,
&quot;interval&quot;,&quot;ratio&quot;)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Krippendorff's alpha coefficient is particularly useful where
the level of measurement of classification data is higher than nominal
or ordinal.
https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-016-0200-9
</p>


<h3>Note</h3>

<p>This function was previously published as <code>kripp.alpha()</code> in the  <span class="pkg">irr</span> package and has been
integrated here without logical changes, but with some adaptations in the result structure.
</p>


<h3>Author(s)</h3>

<p>Jim Lemon &lt;jim@bitwrit.com.au&gt;</p>


<h3>References</h3>

<p>Krippendorff, K. (1980) <em>Content analysis: An introduction to its methodology</em>. Beverly Hills, CA: Sage.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CronbachAlpha">CronbachAlpha</a></code>, <code><a href="#topic+KappaM">KappaM</a></code>, <code><a href="#topic+CohenKappa">CohenKappa</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># the "C" data from Krippendorff
 nmm &lt;- matrix(c(1,1,NA,1,2,2,3,2,3,3,3,3,3,3,3,3,2,2,2,2,1,2,3,4,4,4,4,4,
                 1,1,2,1,2,2,2,2,NA,5,5,5,NA,NA,1,1,NA,NA,3,NA), nrow=4)
 
 # first assume the default nominal classification
 KrippAlpha(nmm)
 
 # now use the same data with the other three methods
 KrippAlpha(nmm, "ordinal")
 KrippAlpha(nmm, "interval")
 KrippAlpha(nmm, "ratio") 
</code></pre>

<hr>
<h2 id='Label+2C+20Unit'>Label, Unit Attribute of an Object
</h2><span id='topic+Label'></span><span id='topic+Label+3C-'></span><span id='topic+Labels'></span><span id='topic+Labels+3C-'></span><span id='topic+Unit'></span><span id='topic+Unit+3C-'></span>

<h3>Description</h3>

<p> Set and retrieve the <code>label</code>, resp. <code>unit</code> attribute of <code>x</code>. This can be helpful for documenting the specific meaning of a variable, of an entire data.frame or any other object. For single vectors it can be useful to store the unit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Label(x)
Label(x) &lt;- value

Labels(x)
Labels(x) &lt;- value

Unit(x)
Unit(x) &lt;- value

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Label+2B2C+2B20Unit_+3A_x">x</code></td>
<td>
<p>any object
</p>
</td></tr>
<tr><td><code id="Label+2B2C+2B20Unit_+3A_value">value</code></td>
<td>
<p>a single string describing the object
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The label should consist of a single text (length of 1). The text may contain line feeds.
It can be deleted by setting the label to <code>NULL</code>.
</p>
<p><code>Labels()</code> can be used to retrieve and assign vectorized labels to data.frames or lists.
</p>


<h3>Value</h3>

<p><code>Label</code> and <code>Unit</code> return the label attribute of x, if any; otherwise, NULL.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p>A more elaborated label version can be found in package <span class="pkg">Hmisc</span> <code><a href="Hmisc.html#topic+label">label</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># add a descriptive label to a variable
Label(d.diamonds$colour) &lt;- "The rating scale applied to diamonds ranges from colorless
to yellow, as any other color is extremely rare."

# technically just appending the text as attribute to the variable
attributes(d.diamonds$colour)

# label is supported while describing data
Desc(d.diamonds$colour)

# The label can be deleted by setting it to NULL
Label(d.diamonds$colour) &lt;- NULL

# Labelling the columns of a data.frame is best done with a loop
# (all so far seen *apply aproaches lead to more complicated code...)
lbl &lt;-  RndWord(16, 7)
for(i in seq_along(lbl))
  Label(d.pizza[, i]) &lt;- lbl[i]

Str(d.pizza)
</code></pre>

<hr>
<h2 id='Lambda'>Goodman Kruskal Lambda
</h2><span id='topic+Lambda'></span>

<h3>Description</h3>

<p>Calculate symmetric and asymmetric Goodman Kruskal lambda and their confidence intervals. Lamdba is a measure of proportional reduction in error in cross tabulation analysis. For any sample with a nominal independent variable and dependent variable (or ones that can be treated nominally), it indicates the extent to which the modal categories and frequencies for each value of the independent variable differ from the overall modal category and frequency, i.e. for all values of the independent variable together
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lambda(x, y = NULL, direction = c("symmetric", "row", "column"), conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lambda_+3A_x">x</code></td>
<td>
<p>a numeric vector, a matrix or a table.
</p>
</td></tr>
<tr><td><code id="Lambda_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or a vector with compatible dimensions to x. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="Lambda_+3A_direction">direction</code></td>
<td>
<p>type of lambda. Can be one out of <code>"symmetric"</code> (default), <code>"row"</code>, <code>"column"</code> (abbreviations are allowed).
If direction is set to <code>"row"</code> then Lambda(R|C) (column dependent) will be reported. See details.
</p>
</td></tr>
<tr><td><code id="Lambda_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the returned confidence interval, restricted to lie between 0 and 1.
</p>
</td></tr>
<tr><td><code id="Lambda_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set <br /> <code>useNA = c("no", "ifany", "always")</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Asymmetric lambda is interpreted as the probable improvement in predicting the column variable Y given knowledge of the row variable X.<br />
The nondirectional lambda is the average of the two asymmetric lambdas, Lambda(C|R) and Lambda(R|C).
Lambda (asymmetric and symmetric) has a scale ranging from 0 to 1.
<br /><br />
Data can be passed to the function either as matrix or data.frame in <code>x</code>, or as two numeric vectors <code>x</code> and <code>y</code>. In the latter case <code>table(x, y, ...)</code> is calculated. Thus <code>NA</code>s are handled the same way as <code><a href="base.html#topic+table">table</a></code> does. Note that tables are by default calculated <b>without</b> NAs (which breaks the package's law to in general not omit NAs silently). The specific argument <code>useNA</code> can be passed via the ... argument.<br />
<code><a href="#topic+PairApply">PairApply</a></code> can be used to calculate pairwise lambdas.
</p>


<h3>Value</h3>

<p>if no confidence intervals are requested:
the estimate as numeric value<br /><br />
else a named numeric vector with 3 elements
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>estimate</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; based on code from Antti Arppe &lt;antti.arppe@helsinki.fi&gt;, <br /> Nanina Anderegg (confidence interval symmetric lambda)
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons
</p>
<p>Goodman, L. A., Kruskal W. H. (1979) Measures of Association for Cross Classifications. New
York: Springer-Verlag (contains articles appearing in <em>J. Amer. Statist. Assoc.</em> in 1954,
1959, 1963, 1972).<br />
http://www.nssl.noaa.gov/users/brooks/public_html/feda/papers/goodmankruskal1.pdf (might be outdated)
</p>
<p>Liebetrau, A. M. (1983) <em>Measures of Association</em>, Sage University Papers Series on Quantitative Applications in the Social Sciences, 07-004. Newbury Park, CA: Sage, pp. 17&ndash;24
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GoodmanKruskalTau">GoodmanKruskalTau</a></code>, <code><a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a></code>, <code><a href="#topic+KendallTauA">KendallTauA</a></code>, <code><a href="#topic+KendallTauB">KendallTauB</a></code>, <code><a href="#topic+StuartTauC">StuartTauC</a></code>, <code><a href="#topic+SomersDelta">SomersDelta</a></code>, <code><a href="stats.html#topic+cor">cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example from Goodman Kruskal (1954)
m &lt;- as.table(cbind(c(1768,946,115), c(807,1387,438), c(189,746,288), c(47,53,16)))
dimnames(m) &lt;- list(paste("A", 1:3), paste("B", 1:4))
m

# direction default is "symmetric"
Lambda(m)
Lambda(m, conf.level=0.95)

Lambda(m, direction="row")
Lambda(m, direction="column")
</code></pre>

<hr>
<h2 id='Lc'>Lorenz Curve</h2><span id='topic+Lc'></span><span id='topic+Lorenz+20curve'></span><span id='topic+Lc.default'></span><span id='topic+Lc.formula'></span><span id='topic+plot.Lc'></span><span id='topic+plot.Lclist'></span><span id='topic+lines.Lc'></span><span id='topic+predict.Lc'></span>

<h3>Description</h3>

<p>Lc computes the (empirical) ordinary and generalized Lorenz curve of a vector x. Desc calculates some key figures for a Lorenz curve and produces a quick description.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Lc(x, ...)

## Default S3 method:
Lc(x, n = rep(1, length(x)), na.rm = FALSE, ...)

## S3 method for class 'formula'
Lc(formula, data, subset, na.action, ...)

## S3 method for class 'Lc'
plot(x, general = FALSE, lwd = 2, type = "l", xlab = "p", ylab = "L(p)",
     main = "Lorenz curve", las = 1, pch = NA, ...)

## S3 method for class 'Lclist'
plot(x, col = 1, lwd = 2, lty = 1, main = "Lorenz curve",
     xlab = "p", ylab = "L(p)", ...)

## S3 method for class 'Lc'
lines(x, general = FALSE, lwd = 2, conf.level = NA, args.cband = NULL, ...)

## S3 method for class 'Lc'
predict(object, newdata, conf.level=NA, general=FALSE, n=1000, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lc_+3A_x">x</code></td>
<td>
<p>a vector containing non-negative elements, or a Lc-object for plot and lines.</p>
</td></tr>
<tr><td><code id="Lc_+3A_n">n</code></td>
<td>
<p>a vector of frequencies, must be same length as <code>x</code>.</p>
</td></tr>
<tr><td><code id="Lc_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="Lc_+3A_general">general</code></td>
<td>
<p>logical. If <code>TRUE</code> the empirical Lorenz curve will be plotted.</p>
</td></tr>
<tr><td><code id="Lc_+3A_col">col</code></td>
<td>
<p>color of the curve</p>
</td></tr>
<tr><td><code id="Lc_+3A_lwd">lwd</code></td>
<td>
<p>the linewidth of the curve</p>
</td></tr>
<tr><td><code id="Lc_+3A_lty">lty</code></td>
<td>
<p>the linetype of the curve</p>
</td></tr>
<tr><td><code id="Lc_+3A_type">type</code></td>
<td>
<p>type of the plot, default is line (<code>"l"</code>).</p>
</td></tr>
<tr><td><code id="Lc_+3A_xlab">xlab</code>, <code id="Lc_+3A_ylab">ylab</code></td>
<td>
<p>label of the x-, resp. y-axis.</p>
</td></tr>
<tr><td><code id="Lc_+3A_pch">pch</code></td>
<td>
<p>the point character (default is <code>NA</code>, meaning no points will be drawn)</p>
</td></tr>
<tr><td><code id="Lc_+3A_main">main</code></td>
<td>
<p>main title of the plot.</p>
</td></tr>
<tr><td><code id="Lc_+3A_las">las</code></td>
<td>
<p>las of the axis.</p>
</td></tr>
<tr><td><code id="Lc_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="Lc_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="Lc_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="Lc_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="Lc_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the bootstrap confidence interval. Set this to <code>NA</code>, if no confidence band should be plotted.
Default is <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="Lc_+3A_args.cband">args.cband</code></td>
<td>
<p>list of arguments for the confidence band, such as color or border (see <code><a href="#topic+DrawBand">DrawBand</a></code>).
</p>
</td></tr>
<tr><td><code id="Lc_+3A_object">object</code></td>
<td>
<p>object of class inheriting from &quot;Lc&quot;</p>
</td></tr>
<tr><td><code id="Lc_+3A_newdata">newdata</code></td>
<td>
<p>an optional vector of percentages p for which to predict. If omitted, the original values of the object are used.</p>
</td></tr>
<tr><td><code id="Lc_+3A_...">...</code></td>
<td>
<p>further argument to be passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Lc(x)</code> computes the empirical ordinary Lorenz curve of <code>x</code>
as well as the generalized Lorenz curve (= ordinary Lorenz curve *
mean(x)). The result can be interpreted like this: <code>p</code>*100 percent
have <code>L(p)</code>*100 percent of <code>x</code>.
</p>
<p>If <code>n</code> is changed to anything but the default <code>x</code> is
interpreted as a vector of class means and <code>n</code> as a vector of
class frequencies: in this case <code>Lc</code> will compute the minimal
Lorenz curve (= no inequality within each group).
</p>


<h3>Value</h3>

<p>A list of class <code>"Lc"</code> with the following components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>vector of percentages</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>vector with values of the ordinary Lorenz curve</p>
</td></tr>
<tr><td><code>L.general</code></td>
<td>
<p>vector with values of the generalized Lorenz curve</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>the original x values (needed for computing confidence intervals)</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the original n values</p>
</td></tr>
</table>


<h3>Note</h3>

<p> These functions were previously published as <code>Lc()</code> in the  <span class="pkg">ineq</span> package and have been
integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>Achim Zeileis &lt;Achim.Zeileis@R-project.org&gt;, extensions Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>Arnold, B. C. (1987) Majorization and the Lorenz Order: A Brief Introduction, <em>Springer</em>
</p>
<p>Cowell, F. A. (2000) Measurement of Inequality in Atkinson, A. B. / Bourguignon, F. (Eds): <em>Handbook of Income Distribution</em>. Amsterdam.
</p>
<p>Cowell, F. A. (1995) Measuring Inequality <em>Harvester Wheatshef: Prentice Hall</em>.
</p>


<h3>See Also</h3>

<p>The original location <code><a href="ineq.html#topic+Lc">Lc</a>()</code>, <br />
inequality measures <code><a href="ineq.html#topic+Gini">Gini</a>()</code>, <code><a href="ineq.html#topic+Atkinson">Atkinson</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>priceCarpenter &lt;- d.pizza$price[d.pizza$driver=="Carpenter"]
priceMiller &lt;- d.pizza$price[d.pizza$driver=="Miller"]

# compute the Lorenz curves
Lc.p &lt;- Lc(priceCarpenter, na.rm=TRUE)
Lc.u &lt;- Lc(priceMiller, na.rm=TRUE)
plot(Lc.p)
lines(Lc.u, col=2)

# the picture becomes even clearer with generalized Lorenz curves
plot(Lc.p, general=TRUE)
lines(Lc.u, general=TRUE, col=2)

# inequality measures emphasize these results, e.g. Atkinson's measure
Atkinson(priceCarpenter, na.rm=TRUE)
Atkinson(priceMiller, na.rm=TRUE)


# income distribution of the USA in 1968 (in 10 classes)
# x vector of class means, n vector of class frequencies
x &lt;- c(541, 1463, 2445, 3438, 4437, 5401, 6392, 8304, 11904, 22261)
n &lt;- c(482, 825, 722, 690, 661, 760, 745, 2140, 1911, 1024)

# compute minimal Lorenz curve (= no inequality in each group)
Lc.min &lt;- Lc(x, n=n)
plot(Lc.min)


# input of frequency tables with midpoints of classes
fl &lt;- c(2.5,7.5,15,35,75,150)   # midpoints
n  &lt;- c(25,13,10,5,5,2)	        # frequencies

plot(Lc(fl, n),                 # Lorenz-Curve
     panel.first=grid(10, 10),
     main="Lorenzcurve Farmers",
     xlab="Percent farmers (cumulative)",
     ylab="Percent of area (%)"
)
# add confidence band
lines(Lc(fl, n), conf.level=0.95,
      args.cband=list(col=SetAlpha(DescToolsOptions("col")[2], 0.3)))

Gini(fl, n)

# find specific function values using predict
x &lt;- c(1,1,4)
lx &lt;- Lc(x)
plot(lx)

# get interpolated function value at p=0.55
y0 &lt;- predict(lx, newdata=0.55)
abline(v=0.55, h=y0$L, lty="dotted")

# and for the inverse question use approx
y0 &lt;- approx(x=lx$L, y=lx$p, xout=0.6)
abline(h=0.6, v=y0$y, col="red")

text(x=0.1, y=0.65, label=expression(L^{-1}*(0.6) == 0.8), col="red")
text(x=0.65, y=0.2, label=expression(L(0.55) == 0.275))

# input of frequency tables with midpoints of classes
fl &lt;- c(2.5,7.5,15,35,75,150)     # midpoints
n  &lt;- c(25,13,10,5,5,2)           # frequencies

# the formula interface for Lc
lst &lt;- Lc(count ~ cut(price, breaks=5), data=d.pizza)

plot(lst, col=1:length(lst), panel.first=grid(), lwd=2)
legend(x="topleft", legend=names(lst), fill=1:length(lst))

# Describe with Desc-function
lx &lt;- Lc(fl, n)
Desc(lx)

</code></pre>

<hr>
<h2 id='LehmacherTest'>Lehmacher's Test for Marginal Homogenity
</h2><span id='topic+LehmacherTest'></span><span id='topic+print.mtest'></span>

<h3>Description</h3>

<p>Performs Lehmacher's chi-squared test for marginal homogenity in a symmetric two-dimensional contingency table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LehmacherTest(x, y = NULL)

## S3 method for class 'mtest'
print(x, digits = 4L, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LehmacherTest_+3A_x">x</code></td>
<td>
<p>either a two-dimensional contingency table in matrix form, or a factor object.
</p>
</td></tr>
<tr><td><code id="LehmacherTest_+3A_y">y</code></td>
<td>
<p>a factor object; ignored if x is a matrix.
</p>
</td></tr>
<tr><td><code id="LehmacherTest_+3A_digits">digits</code></td>
<td>
<p>a non-null value for digits specifies the minimum number of significant digits to be printed in values. See details in <code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
<tr><td><code id="LehmacherTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from other methods. They are ignored in this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The null is that the probabilities of being classified into cells [i,j] and [j,i] are the same.
</p>
<p>If x is a matrix, it is taken as a two-dimensional contingency table, and hence its entries should be nonnegative integers. Otherwise, both x and y must be vectors or factors of the same length. Incomplete cases are removed, vectors are coerced into factors, and the contingency table is computed from these.
</p>


<h3>Value</h3>

<p>A list with class <code>"mtest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>a vector with the value of the test statistics.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom, which is always 1 in LehmacherTest.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>a vector with the p-values of the single tests.</p>
</td></tr>
<tr><td><code>p.value.corr</code></td>
<td>
<p>a vector with the &quot;hochberg&quot; adjusted p-values of the single tests. (See <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>)</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of test was
performed.</p>
</td></tr> 
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Lehmacher, W. (1980) Simultaneous sign tests for marginal homogeneity of square contingency tables
<em>Biometrical Journal</em>, Volume 22, Issue 8,  pages 795-798
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mcnemar.test">mcnemar.test</a></code> (resp. BowkerTest for a CxC-matrix), <code><a href="#topic+StuartMaxwellTest">StuartMaxwellTest</a></code>, <code><a href="#topic+WoolfTest">WoolfTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(c(400,40,20,10, 
              50,300,60,20, 
              10,40,120,5, 
              5,90,50,80), nrow=4, byrow=TRUE)
              
LehmacherTest(x)
</code></pre>

<hr>
<h2 id='LeveneTest'>Levene's Test for Homogeneity of Variance</h2><span id='topic+LeveneTest'></span><span id='topic+LeveneTest.formula'></span><span id='topic+LeveneTest.lm'></span><span id='topic+LeveneTest.default'></span>

<h3>Description</h3>

<p>Computes Levene's test for homogeneity of variance across groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LeveneTest(y, ...)

## S3 method for class 'formula'
LeveneTest(formula, data, ...)
## S3 method for class 'lm'
LeveneTest(y, ...)
## Default S3 method:
LeveneTest(y, group, center=median, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LeveneTest_+3A_y">y</code></td>
<td>
<p>response variable for the default method, or a <code>lm</code> or
<code>formula</code> object. If <code>y</code> is a linear-model object or a formula,
the variables on the right-hand-side of the model must all be factors and
must be completely crossed.</p>
</td></tr>
<tr><td><code id="LeveneTest_+3A_group">group</code></td>
<td>
<p>factor defining groups.</p>
</td></tr>
<tr><td><code id="LeveneTest_+3A_center">center</code></td>
<td>
<p>The name of a function to compute the center of each group;
<code>mean</code> gives the original Levene's test; the default, <code>median</code>,
provides a more robust test (Brown-Forsythe-Test). </p>
</td></tr>
<tr><td><code id="LeveneTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
gives the data values and <code>rhs</code> the corresponding groups.</p>
</td></tr>
<tr><td><code id="LeveneTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="LeveneTest_+3A_...">...</code></td>
<td>
<p>arguments to be passed down, e.g., <code>data</code> for the
<code>formula</code> and <code>lm</code> methods; can also be used to pass arguments to
the function given by <code>center</code> (e.g., <code>center=mean</code> and
<code>trim=0.1</code> specify the 10% trimmed mean).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns an object meant to be printed showing the results of the test.
</p>


<h3>Note</h3>

<p> This function was previously published as leveneTest() in the library(car)
and has been integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>John Fox <a href="mailto:jfox@mcmaster.ca">jfox@mcmaster.ca</a>; original generic version
contributed by Derek Ogle<br />
adapted from a response posted by Brian Ripley to the r-help email list.</p>


<h3>References</h3>

<p>Fox, J. (2008)
<em>Applied Regression Analysis and Generalized Linear Models</em>,
Second Edition. Sage.
</p>
<p>Fox, J. and Weisberg, S. (2011)
<em>An R Companion to Applied Regression</em>, Second Edition, Sage.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+fligner.test">fligner.test</a></code> for a rank-based (nonparametric)
<code class="reqn">k</code>-sample test for homogeneity of variances;
<code><a href="stats.html#topic+mood.test">mood.test</a></code> for another rank-based two-sample test for a
difference in scale parameters;
<code><a href="stats.html#topic+var.test">var.test</a></code> and <code><a href="stats.html#topic+bartlett.test">bartlett.test</a></code> for parametric
tests for the homogeneity in variance.
</p>
<p><code><a href="coin.html#topic+ScaleTests">ansari_test</a></code> in package <span class="pkg">coin</span>
for exact and approximate <em>conditional</em> p-values for the
Ansari-Bradley test, as well as different methods for handling ties.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example from ansari.test:
## Hollander &amp; Wolfe (1973, p. 86f):
## Serum iron determination using Hyland control sera
ramsay &lt;- c(111, 107, 100, 99, 102, 106, 109, 108, 104, 99,
            101, 96, 97, 102, 107, 113, 116, 113, 110, 98)
jung.parekh &lt;- c(107, 108, 106, 98, 105, 103, 110, 105, 104,
            100, 96, 108, 103, 104, 114, 114, 113, 108, 106, 99)

LeveneTest( c(ramsay, jung.parekh),
  factor(c(rep("ramsay",length(ramsay)), rep("jung.parekh",length(jung.parekh)))))

LeveneTest( c(rnorm(10), rnorm(10, 0, 2)), factor(rep(c("A","B"),each=10)) )

## Not run: 
# original example from package car

with(Moore, LeveneTest(conformity, fcategory))
with(Moore, LeveneTest(conformity, interaction(fcategory, partner.status)))

LeveneTest(conformity ~ fcategory * partner.status, data = Moore)
LeveneTest(conformity ~ fcategory * partner.status, data = Moore, center = mean)
LeveneTest(conformity ~ fcategory * partner.status, data = Moore, center = mean, trim = 0.1)

LeveneTest(lm(conformity ~ fcategory*partner.status, data = Moore))

## End(Not run)
</code></pre>

<hr>
<h2 id='LillieTest'>Lilliefors (Kolmogorov-Smirnov) Test for Normality</h2><span id='topic+LillieTest'></span>

<h3>Description</h3>

<p>Performs the Lilliefors (Kolmogorov-Smirnov) test for the composite hypothesis of normality,
see e.g. Thode (2002, Sec. 5.1.1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LillieTest(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LillieTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, the number of
which must be greater than 4. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lilliefors (Kolmogorov-Smirnov) test is an EDF omnibus test for the composite
hypothesis of normality. The test statistic is the maximal absolute difference
between empirical and
hypothetical cumulative distribution function. It may be computed as
<code class="reqn">D=\max\{D^{+}, D^{-}\}</code> with
</p>
<p style="text-align: center;"><code class="reqn">
D^{+} = \max_{i=1,\ldots, n}\{i/n - p_{(i)}\},
D^{-} = \max_{i=1,\ldots, n}\{p_{(i)} - (i-1)/n\},
</code>
</p>

<p>where <code class="reqn">p_{(i)} = \Phi([x_{(i)} - \overline{x}]/s)</code>. Here,
<code class="reqn">\Phi</code> is the cumulative distribution function
of the standard normal distribution, and <code class="reqn">\overline{x}</code> and <code class="reqn">s</code>
are mean and standard deviation of the data values.
The p-value is computed from the Dallal-Wilkinson (1986) formula, which is claimed to
be only reliable when the p-value is smaller than 0.1. If the Dallal-Wilkinson
p-value turns out to be greater than 0.1, then the p-value is computed from the distribution of
the modified statistic <code class="reqn">Z=D (\sqrt{n}-0.01+0.85/\sqrt{n})</code>, see Stephens (1974),
the actual p-value formula being obtained by a simulation and approximation process.</p>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Lilliefors (Kolomogorv-Smirnov) statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Lilliefors (Kolmogorov-Smirnov) normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Lilliefors (Kolomorov-Smirnov) test is the most famous EDF omnibus test for normality.
Compared to the Anderson-Darling test and the Cramer-von Mises test it is known to perform worse.
Although the test statistic obtained from <code>LillieTest(x)</code> is the same as that obtained from
<code>ks.test(x, "pnorm", mean(x), sd(x))</code>, it is not correct to use the p-value from the latter
for the composite hypothesis of normality (mean and variance unknown),
since the distribution of the test statistic is different when the parameters are estimated.
</p>
<p>The function call <code>LillieTest(x)</code> essentially produces
the same result as the S-PLUS function call <code>ks.gof(x)</code>
with the distinction that the p-value is not set to 0.5 when
the Dallal-Wilkinson approximation yields a p-value greater than 0.1. (Actually,
the alternative p-value approximation is provided for the complete range of test statistic values,
but is only used when the Dallal-Wilkinson approximation fails.)</p>


<h3>Author(s)</h3>

<p>Juergen Gross &lt;gross@statistik.uni-dortmund.de&gt;</p>


<h3>References</h3>

<p>Dallal, G.E. and Wilkinson, L. (1986)
An analytic approximation to the distribution of Lilliefors' test for normality.
<em>The American Statistician</em>, 40, 294&ndash;296.
</p>
<p>Stephens, M.A. (1974) EDF statistics for goodness of fit and some comparisons.
<em>Journal of the American Statistical Association</em>, 69, 730&ndash;737.
</p>
<p>Thode Jr., H.C. (2002) <em>Testing for  Normality</em> Marcel Dekker, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality.
<code><a href="#topic+AndersonDarlingTest">AndersonDarlingTest</a></code>, <code><a href="#topic+CramerVonMisesTest">CramerVonMisesTest</a></code>,
<code><a href="#topic+PearsonTest">PearsonTest</a></code>, <code><a href="#topic+ShapiroFranciaTest">ShapiroFranciaTest</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>LillieTest(rnorm(100, mean = 5, sd = 3))
LillieTest(runif(100, min = 2, max = 4))
</code></pre>

<hr>
<h2 id='lines.lm'>Add a Linear Regression Line
</h2><span id='topic+lines.lm'></span>

<h3>Description</h3>

<p>Add a linear regression line to an existing plot. The function first calculates the prediction of a <code>lm</code> object for a reasonable amount of points, then adds the line to the plot and inserts a polygon with the confidence and, if required, the prediction intervals.
In addition to <code><a href="graphics.html#topic+abline">abline</a></code> the function will also display polynomial models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm'
lines(x, col = Pal()[1], lwd = 2, lty = "solid",
      type = "l", n = 100, conf.level = 0.95, args.cband = NULL,
      pred.level = NA, args.pband = NULL, xpred = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lines.lm_+3A_x">x</code></td>
<td>
<p>linear model object as result from lm(y~x).
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_col">col</code></td>
<td>
<p>linecolor of the line. Default is the color returned by <code>Pal()[1]</code>.
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_lwd">lwd</code></td>
<td>
<p>line width of the line.
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_lty">lty</code></td>
<td>
<p>line type of the line.
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_type">type</code></td>
<td>
<p>character indicating the type of plotting; actually any of the <code>types</code> as in <code><a href="graphics.html#topic+plot.default">plot.default</a></code>. Type of plot, defaults to <code>"l"</code>.
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_n">n</code></td>
<td>
<p>number of points used for plotting the fit.
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the confidence interval. Set this to <code>NA</code>, if no confidence band should be plotted.
Default is <code>0.95</code>.
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_args.cband">args.cband</code></td>
<td>
<p>list of arguments for the confidence band, such as color or border (see <code><a href="#topic+DrawBand">DrawBand</a></code>).
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_pred.level">pred.level</code></td>
<td>
<p>confidence level for the prediction interval. Set this to NA, if no prediction band should be plotted.
Default is <code>0.95</code>.
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_args.pband">args.pband</code></td>
<td>
<p>list of arguments for the prediction band, such as color or border (see <code><a href="#topic+DrawBand">DrawBand</a></code>).
</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_xpred">xpred</code></td>
<td>
<p>a numeric vector <code>c(from, to)</code>,  if the x limits can't be defined based on available data, xpred can be used to provide the range where the line and especially the confidence intervals should be plotted.</p>
</td></tr>
<tr><td><code id="lines.lm_+3A_...">...</code></td>
<td>
<p>further arguments are not used specifically.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It's sometimes illuminating to plot a regression line with its prediction, resp. confidence intervals over an existing scatterplot. This only makes sense, if just a simple linear model explaining a target variable by (a function of) one single predictor is to be visualized.
</p>


<h3>Value</h3>

<p>nothing
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+lines">lines</a></code>, <code><a href="#topic+lines.loess">lines.loess</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>opar &lt;- par(mfrow=c(1,2))

plot(hp ~ wt, mtcars)
lines(lm(hp ~ wt, mtcars), col="steelblue")

# add the prediction intervals in different color
plot(hp ~ wt, mtcars)
r.lm &lt;- lm(hp ~ wt, mtcars)
lines(r.lm, col="red", pred.level=0.95, args.pband=list(col=SetAlpha("grey",0.3)) )

# works with transformations too
plot(dist ~ sqrt(speed), cars)
lines(lm(dist ~ sqrt(speed), cars), col=hred)

plot(dist ~ log(speed), cars)
lines(lm(dist ~ log(speed), cars), col=hred)

# and with more specific variables based on only one predictor
plot(dist ~ speed, cars)
lines(lm(dist ~ poly(speed, degree=2), cars), col=hred)

par(opar)
</code></pre>

<hr>
<h2 id='lines.loess'>
Add a Loess or a Spline Smoother
</h2><span id='topic+lines.loess'></span><span id='topic+lines.smooth.spline'></span><span id='topic+lines.SmoothSpline'></span>

<h3>Description</h3>

<p>Add a loess smoother to an existing plot. The function first calculates the prediction of a loess object for a reasonable amount of points, then adds the line to the plot and inserts a polygon with the confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'loess'
lines(x, col = Pal()[1], lwd = 2, lty = "solid",
      type = "l", n = 100, conf.level = 0.95, args.band = NULL, ...)

## S3 method for class 'smooth.spline'
lines(x, col = Pal()[1], lwd = 2, lty = "solid",
      type = "l", conf.level = 0.95, args.band = NULL, ...)

## S3 method for class 'SmoothSpline'
lines(x, col = Pal()[1], lwd = 2, lty = "solid",
      type = "l", conf.level = 0.95, args.band = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lines.loess_+3A_x">x</code></td>
<td>
<p>the loess or smooth.spline object to be plotted.
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_col">col</code></td>
<td>
<p>linecolor of the smoother. Default is DescTools's <code>col1</code>.
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_lwd">lwd</code></td>
<td>
<p>line width of the smoother.
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_lty">lty</code></td>
<td>
<p>line type of the smoother.
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_type">type</code></td>
<td>
<p>type of plot, defaults to <code>"l"</code>.
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_n">n</code></td>
<td>
<p>number of points used for plotting the fit.
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the confidence interval. Set this to NA, if no confidence band should be plotted.
Default is 0.95.
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_args.band">args.band</code></td>
<td>
<p>list of arguments for the confidence band, such as color or border (see <code><a href="#topic+DrawBand">DrawBand</a></code>).
</p>
</td></tr>
<tr><td><code id="lines.loess_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the smoother (<code>loess()</code> or <code>SmoothSpline()</code>).
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Loess can result in heavy computational load if there are many points!
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+loess">loess</a></code>, <code><a href="stats.html#topic+scatter.smooth">scatter.smooth</a></code>, <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>, <code><a href="#topic+SmoothSpline">SmoothSpline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>par(mfrow=c(1,2))

x &lt;- runif(100)
y &lt;- rnorm(100)
plot(x, y)
lines(loess(y~x))

plot(temperature ~ delivery_min, data=d.pizza)
lines(loess(temperature ~ delivery_min, data=d.pizza))

plot(temperature ~ delivery_min, data=d.pizza)
lines(loess(temperature ~ delivery_min, data=d.pizza), conf.level = 0.99,
            args.band = list(col=SetAlpha("red", 0.4), border="black") )

# the default values from scatter.smooth
lines(loess(temperature ~ delivery_min, data=d.pizza,
            span=2/3, degree=1, family="symmetric"), col="red")
</code></pre>

<hr>
<h2 id='LineToUser'>Convert Line Coordinates To User Coordinates
</h2><span id='topic+LineToUser'></span>

<h3>Description</h3>

<p>Functions like <code>mtext</code> or <code>axis</code> use the <code>line</code> argument to set the distance from plot. Sometimes it's useful to have the distance in user coordinates. <code>LineToUser()</code> does this nontrivial conversion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LineToUser(line, side)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LineToUser_+3A_line">line</code></td>
<td>
<p>the number of lines
</p>
</td></tr>
<tr><td><code id="LineToUser_+3A_side">side</code></td>
<td>
<p>the side of the plot
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the <code>LineToUser</code> function to work, there must be an open plot.</p>


<h3>Value</h3>

<p>the user coordinates for the given lines
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+mtext">mtext</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(1:10)
LineToUser(line=2, side=4)
</code></pre>

<hr>
<h2 id='LinScale'>Linear Scaling
</h2><span id='topic+LinScale'></span>

<h3>Description</h3>

<p>This will scale the numeric vector <code>x</code> linearly from an old scale between <code>low</code> and <code>high</code> to a new one between <code>newlow</code> and <code>newhigh</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LinScale(x, low = NULL, high = NULL, newlow = 0, newhigh = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LinScale_+3A_x">x</code></td>
<td>
<p>a numeric matrix(like object).
</p>
</td></tr>
<tr><td><code id="LinScale_+3A_low">low</code></td>
<td>
<p>numeric. The minimum value of the scale, defaults to min(x).
This is calculated columnwise by default; defined <code>low</code> or <code>high</code> arguments
will be recycled if necessary.
</p>
</td></tr>
<tr><td><code id="LinScale_+3A_high">high</code></td>
<td>
<p>numeric. The maximum value of the scale, defaults to max(x).
This is calculated columnwise by default; when a maxval is entered, it will be recycled.
</p>
</td></tr>
<tr><td><code id="LinScale_+3A_newlow">newlow</code></td>
<td>
<p>numeric. The minimum value of the new scale, defaults to 0, resulting in a 0-1 scale for x. <code>newlow</code> is recycled if necessary.
</p>
</td></tr>
<tr><td><code id="LinScale_+3A_newhigh">newhigh</code></td>
<td>
<p>numeric. The maximum value of the scale, defaults to 1.
<code>newhigh</code> is recycled if necessary.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hmm, hardly worth coding...
</p>


<h3>Value</h3>

<p>The centered and scaled matrix. The numeric centering and scalings used (if any) are returned as attributes &quot;<code>scaled:center</code>&quot; and &quot;<code>scaled:scale</code>&quot;
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+scale">scale</a></code>,  <code><a href="#topic+RobScale">RobScale</a></code>, <code><a href="base.html#topic+sweep">sweep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># transform the temperature from Celsius to Fahrenheit
LinScale(d.pizza[1:20, "temperature"], 0, 100, -17.8, 37.8 )

# and the price from Dollar to Euro
LinScale(d.pizza[1:20, "price"], 0, 1, 0, 0.76)

# together
LinScale(d.pizza[1:20, c("temperature", "price")],
  0, c(100, 1), c(-17.8, 0), c(37.8, 0.76) )


## Not run: 
par(mfrow=c(3,1), mar=c(0,5,0,3), oma=c(5,0,5,0))
plot(LinScale(d.frm[,1]), ylim=c(-2,2), xaxt="n", ylab="LinScale")
plot(RobScale(d.frm[,1]), ylim=c(-2,2), xaxt="n", ylab="RobScale")
plot(scale(d.frm[,1]), ylim=c(-2,2), ylab="scale")
title("Compare scales", outer = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='List+20Variety+20Of+20Objects'>List Objects, Functions Or Data in a Package
</h2><span id='topic+LsFct'></span><span id='topic+LsObj'></span>

<h3>Description</h3>

<p>List all the objects, functions or data in a package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LsObj(package)
LsFct(package)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="List+2B20Variety+2B20Of+2B20Objects_+3A_package">package</code></td>
<td>
<p>the name of the package
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is just a wrapper for <code><a href="base.html#topic+ls">ls</a></code>, <code><a href="utils.html#topic+ls.str">ls.str</a></code> and <code><a href="utils.html#topic+lsf.str">lsf.str</a></code> with the appropriate arguments (as I always forgot how to do the trick).
<code>LsObj()</code> lists all objects, <code>LsFct()</code> just the functions in a package.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988) <em>The New S Language</em>. Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+ls">ls</a></code>, <code><a href="utils.html#topic+ls.str">ls.str</a></code>, <code><a href="utils.html#topic+lsf.str">lsf.str</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>LsFct("DescTools")
</code></pre>

<hr>
<h2 id='LOCF'>Last Observation Carried Forward
</h2><span id='topic+LOCF'></span><span id='topic+LOCF.default'></span><span id='topic+LOCF.matrix'></span><span id='topic+LOCF.data.frame'></span>

<h3>Description</h3>

<p>In longitudinal studies it's common that individuals drop out before all responses can be obtained. Measurements obtained before the individual dropped out can be used to impute the unknown measurement(s). The last observation carried forward method is one way to impute values for the missing observations. For the last observation carried forward (LOCF) approach the missing values are replaced by the last observed value of
that variable for each individual regardless of when it occurred.
</p>
<p><code>LOCF()</code> replaces <code>NA</code>s with the most recent non-NA prior to it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LOCF(x)

## Default S3 method:
LOCF(x)
## S3 method for class 'data.frame'
LOCF(x)
## S3 method for class 'matrix'
LOCF(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LOCF_+3A_x">x</code></td>
<td>
<p>a vector, a data.frame or a matrix containing NAs.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will replace all NAs found in a vector with the last earlier value not being NA.
In data.frames each column will be treated as described.
</p>
<p>It should be noted, that the last observation carried forward approach may result in biased estimates and may underestimate
the variability.
</p>


<h3>Value</h3>

<p>a vector with the same dimension as x.
</p>


<h3>Author(s)</h3>

<p>Daniel Wollschlaeger &lt;dwoll@psychologie.uni-kiel.de&gt;</p>


<h3>See Also</h3>

<p>See also the package <span class="pkg">Hmisc</span> for less coarse imputation functions.</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.frm &lt;- data.frame(
  tag=rep(c("mo", "di", "mi", "do", "fr", "sa", "so"), 4)
, val=rep(c(runif(5), rep(NA,2)), 4) )

d.frm$locf &lt;- LOCF( d.frm$val )
d.frm
</code></pre>

<hr>
<h2 id='LOF'> Local Outlier Factor </h2><span id='topic+LOF'></span>

<h3>Description</h3>

<p> A function that finds the local outlier factor (Breunig et al.,2000) of
the matrix &quot;data&quot; using k neighbours. The local outlier factor (LOF) is a measure of outlyingness
that is calculated for each observation. The user decides whether or not an observation 
will be considered an outlier based on this measure. The LOF takes into consideration
the density of the neighborhood around the observation to determine its outlyingness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LOF(data, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LOF_+3A_data">data</code></td>
<td>
<p> The data set to be explored</p>
</td></tr>
<tr><td><code id="LOF_+3A_k">k</code></td>
<td>
<p> The kth-distance to be used to calculate the LOF's.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LOFs are calculated over a range of values, and the max local outlier factor
is determined over this range.
</p>


<h3>Value</h3>

<table>
<tr><td><code>lof</code></td>
<td>
<p> A vector with the local outlier factor of each observation</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function was originally published in the library dprep.</p>


<h3>Author(s)</h3>

<p>Caroline Rodriguez</p>


<h3>References</h3>

<p> Breuning, M., Kriegel, H., Ng, R.T, and Sander. J. (2000). 
LOF: Identifying density-based local outliers. <em>In Proceedings of the ACM SIGMOD 
International Conference on Management of Data</em></p>


<h3>Examples</h3>

<pre><code class='language-R'># Detecting the top 10 outliers using the LOF algorithm

(iris.lof &lt;- LOF(iris[,-5], 10))
</code></pre>

<hr>
<h2 id='Logit'>Generalized Logit and Inverse Logit Function</h2><span id='topic+Logit'></span><span id='topic+LogitInv'></span>

<h3>Description</h3>

<p>Compute generalized logit and generalized inverse logit functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Logit(x, min = 0, max = 1)
LogitInv(x, min = 0, max = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Logit_+3A_x">x</code></td>
<td>
<p>value(s) to be transformed</p>
</td></tr>
<tr><td><code id="Logit_+3A_min">min</code></td>
<td>
<p>lower end of logit interval</p>
</td></tr>
<tr><td><code id="Logit_+3A_max">max</code></td>
<td>
<p>upper end of logit interval</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generalized logit function takes values on [min, max] and
transforms them to span <code class="reqn">[-\infty, \infty ]</code>. <br /> It is defined as:
</p>
<p style="text-align: center;"><code class="reqn">y = log\left (\frac{p}{1-p} \right ) \;\;\;  \; \textup{where} \; \;\;  p=\frac{x-min}{max-min}</code>
</p>

<p>The generalized inverse logit function provides the inverse
transformation:
</p>
<p style="text-align: center;"><code class="reqn">x = p' \cdot (max-min) + min  \;\;\;  \; \textup{where} \; \;\;  p'=\frac{exp(y)}{1+exp(y)}</code>
</p>



<h3>Value</h3>

<p>Transformed value(s).
</p>


<h3>Author(s)</h3>

<p> Gregory R. Warnes <a href="mailto:greg@warnes.net">greg@warnes.net</a> </p>


<h3>See Also</h3>

 <p><code><a href="car.html#topic+logit">logit</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- seq(0,10, by=0.25)
xt &lt;- Logit(x, min=0, max=10)
cbind(x,xt)

y &lt;- LogitInv(xt, min=0, max=10)
cbind(x, xt, y)

</code></pre>

<hr>
<h2 id='LogSt'>Started Logarithmic Transformation and Its Inverse
</h2><span id='topic+LogSt'></span><span id='topic+LogStInv'></span>

<h3>Description</h3>

<p>Transforms the data by a log transformation, modifying small and zero observations such that the transformation is linear for <code class="reqn">x &lt;= threshold</code> and logarithmic for x &gt; threshold. So the transformation yields finite values and is continuously differentiable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogSt(x, base = 10, calib = x, threshold = NULL, mult = 1)

LogStInv(x, base = NULL, threshold = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LogSt_+3A_x">x</code></td>
<td>
<p>a vector or matrix of data, which is to be transformed
</p>
</td></tr>
<tr><td><code id="LogSt_+3A_base">base</code></td>
<td>
<p>a positive or complex number: the base with respect to which logarithms are computed. Defaults to 10. Use=exp(1) for natural log.
</p>
</td></tr>
<tr><td><code id="LogSt_+3A_calib">calib</code></td>
<td>
<p>a vector or matrix of data used to calibrate the transformation(s), i.e., to determine
the constant <code class="reqn">c</code> needed
</p>
</td></tr>
<tr><td><code id="LogSt_+3A_threshold">threshold</code></td>
<td>
<p>constant <code class="reqn">c</code> that determines the transformation. The inverse function <code>LogStInv</code> will
look for an attribute named <code>"threshold"</code> if the argument is set to <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="LogSt_+3A_mult">mult</code></td>
<td>
<p>a tuning constant affecting the transformation of small values, see <code>Details</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to avoid <code class="reqn">log(x) = -\infty</code> for <code class="reqn">x=0</code> in log-transformations there's often a constant added to the variable before taking the <code class="reqn">log</code>. This is not always a pleasable strategy.
The function
<code>LogSt</code> handles this problem based on the following ideas:
</p>

<ul>
<li><p>The modification should only affect the values for &quot;small&quot; arguments.
</p>
</li>
<li><p>What &quot;small&quot; is should be determined in connection with the non-zero values of the original variable, since it should behave well (be equivariant) with respect to a change in the &quot;unit of measurement&quot;.
</p>
</li>
<li><p>The function must remain monotone, and it should remain (weakly) convex.
</p>
</li></ul>

<p>These criteria are implemented here as follows: The shape is determined by a
threshold <code class="reqn">c</code> at which - coming from above - the log function switches to a linear function with the same slope at this point.
</p>
<p>This is obtained by
</p>
<p style="text-align: center;"><code class="reqn">g(x) =
  \left\{\begin{array}{ll}
     log_{10}(x) &amp;\textup{for }x \ge c\\
     log_{10}(c) - \frac{c - x}{c \cdot log(10)} &amp;\textup{for } x &lt; c
  \end{array}\right.
</code>
</p>

<p>Small values are determined by the threshold <code class="reqn">c</code>. If not given by the argument <code>threshold</code>, it is determined by the quartiles <code class="reqn">q_1</code> and <code class="reqn">q_3</code> of the non-zero data as those smaller than <code class="reqn">c = \frac{q_1^{1+r}}{q_3^r}</code> where <code class="reqn">r</code> can be set by the argument <code>mult</code>.
The rationale is, that, for lognormal data, this constant identifies 2 percent of the data as small.<br />
Beyond this limit, the transformation continues linear with the derivative of the log curve at this point. <br />
</p>
<p>Another idea for choosing the threshold <code class="reqn">c</code> was: median(x) / (median(x)/quantile(x, 0.25))^2.9)<br /><br />
The function chooses <code class="reqn">log_{10}</code> rather than natural logs by default because they can be backtransformed relatively easily in mind.
</p>
<p>A generalized log (see: Rocke 2003) can be calculated in order to stabilize the variance as:
</p>
<pre>function (x, a) {
 return(log((x + sqrt(x^2 + a^2)) / 2))
}</pre>


<h3>Value</h3>

<p>the transformed data. The value <code class="reqn">c</code> used for the transformation and needed for inverse transformation is returned as <code>attr(.,"threshold")</code> and the used base as  <code>attr(.,"base")</code>.
</p>


<h3>Author(s)</h3>

<p>Werner A. Stahel, ETH Zurich <br /> slight modifications Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Rocke, D M, Durbin B (2003): Approximate variance-stabilizing transformations for gene-expression microarray data, <em>Bioinformatics</em>. 22;19(8):966-72.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+log">log</a></code>, <code><a href="base.html#topic+log10">log10</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dd &lt;- c(seq(0,1,0.1), 5 * 10^rnorm(100, 0, 0.2))
dd &lt;- sort(dd)
r.dl &lt;- LogSt(dd)
plot(dd, r.dl, type="l")
abline(v=attr(r.dl, "threshold"), lty=2)

x &lt;- rchisq(df=3, n=100)
# should give 0 (or at least something small):
LogStInv(LogSt(x)) - x
</code></pre>

<hr>
<h2 id='MAD'>Median Absolute Deviation</h2><span id='topic+MAD'></span>

<h3>Description</h3>

<p>Compute the median absolute deviation, i.e., the (lo-/hi-) median of
the absolute deviations from the median, and (by default) adjust by a
factor for asymptotically normal consistency. This function wraps the specific base R function <code><a href="stats.html#topic+mad">mad</a></code> and extends it for the use of weights. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAD(x, weights = NULL, center = Median, constant = 1.4826, 
    na.rm = FALSE, low = FALSE, high = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MAD_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="MAD_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="MAD_+3A_center">center</code></td>
<td>
<p>the centre given either as numeric value or as a function to be applied to <code>x</code> (defaults to the <code>DescTools::Median(x)</code>). Note in cases when weights are defined to provide a function that also support weights. If this is not possible fall back to a numeric value.</p>
</td></tr>
<tr><td><code id="MAD_+3A_constant">constant</code></td>
<td>
<p>scale factor (default is <code>1.4826</code>)</p>
</td></tr>
<tr><td><code id="MAD_+3A_na.rm">na.rm</code></td>
<td>
<p>if <code>TRUE</code> then <code>NA</code> values are stripped
from <code>x</code> before computation takes place.</p>
</td></tr>
<tr><td><code id="MAD_+3A_low">low</code></td>
<td>
<p>if <code>TRUE</code>, compute the &lsquo;lo-median&rsquo;, i.e., for even
sample size, do not average the two middle values, but take the
smaller one.</p>
</td></tr>
<tr><td><code id="MAD_+3A_high">high</code></td>
<td>
<p>if <code>TRUE</code>, compute the &lsquo;hi-median&rsquo;, i.e., take the
larger of the two middle values for even sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The actual value calculated is <code>constant * cMedian(abs(x - center))</code>
with the default value of <code>center</code> being <code>median(x)</code>, and
<code>cMedian</code> being the usual, the &lsquo;low&rsquo; or &lsquo;high&rsquo; median, see
the arguments description for <code>low</code> and <code>high</code> above.
</p>
<p>The default <code>constant = 1.4826</code> (approximately
<code class="reqn">1/\Phi^{-1}(\frac 3 4)</code> = <code>1/qnorm(3/4)</code>)
ensures consistency, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">E[mad(X_1,\dots,X_n)] = \sigma</code>
</p>

<p>for <code class="reqn">X_i</code> distributed as <code class="reqn">N(\mu, \sigma^2)</code>
and large <code class="reqn">n</code>.
</p>
<p>If <code>na.rm</code> is <code>TRUE</code> then <code>NA</code>
values are stripped from <code>x</code> before computation takes place.
If this is not done then an <code>NA</code> value in
<code>x</code> will cause <code>MAD</code> to return <code>NA</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+IQR">IQR</a></code> which is simpler but less robust, <code><a href="#topic+IQRw">IQRw</a></code> for weights, 
<code><a href="stats.html#topic+mad">mad</a></code>, <code><a href="stats.html#topic+median">median</a></code>, <code><a href="stats.html#topic+var">var</a></code>, <code><a href="#topic+MADCI">MADCI</a></code> (confidence intervals).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MAD(c(1:9))
print(MAD(c(1:9),     constant = 1)) ==
      MAD(c(1:8, 100), constant = 1)       # = 2 ; TRUE
x &lt;- c(1,2,3,5,7,8)
sort(abs(x - median(x)))
c(MAD(x, constant = 1),
  MAD(x, constant = 1, low = TRUE),
  MAD(x, constant = 1, high = TRUE))

# use weights
x &lt;- sample(20, 30, replace = TRUE)
z &lt;- as.numeric(names(w &lt;- table(x)))

(m1 &lt;- MAD(z, weights=w))
(m2 &lt;- MAD(x))
stopifnot(identical(m1, m2))

</code></pre>

<hr>
<h2 id='MADCI'>Confidence Intervals for Median Absolute Deviations
</h2><span id='topic+MADCI'></span>

<h3>Description</h3>

<p>A function for the median absolute deviation is included in base R, <code><a href="stats.html#topic+mad">mad</a></code>, but there's no function for calculating confidence intervals. Arachchige/Prendergast introduce interval estimators of the MAD to make reliable inferences for dispersion for a single population and ratios and differences of MADs for comparing two populations. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MADCI(x, y = NULL, two.samp.diff = TRUE, gld.est = "TM", 
      conf.level = 0.95, sides = c("two.sided","left","right"), 
      na.rm = FALSE, ...)      
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MADCI_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="MADCI_+3A_y">y</code></td>
<td>
<p>a second (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="MADCI_+3A_two.samp.diff">two.samp.diff</code></td>
<td>
<p>logical, defining if the confidence intervals for the difference (mad(x)-mad(y)) (default) or for the squared ratio ((mad(x)/mad(y))^2) should be calculated. Ignored if y is not given.
</p>
</td></tr>
<tr><td><code id="MADCI_+3A_gld.est">gld.est</code></td>
<td>
<p>A character string, to select the estimation method for the generalized lambda distribution. One of: <code>ML</code> for numerical Maximum Likelihood, <code>MPS</code> or <code>MSP</code> for Maximum Spacings Product, <code>TM</code> for Titterington's Method (default), <code>SM</code> for Starship Method, <code>TL</code> for method of Trimmed L-moments, <code>Lmom</code> for method of L-moments, <code>DLA</code> for the method of Distributional Least Absolutes, or <code>Mom</code> for method of Moments. 
See <code><a href="gld.html#topic+fit.fkml">fit.fkml</a>()</code>.
</p>
</td></tr>
<tr><td><code id="MADCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.
</p>
</td></tr>
<tr><td><code id="MADCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="MADCI_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="MADCI_+3A_...">...</code></td>
<td>
<p>further arguments, not used here</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector with 3 elements:
</p>
<table>
<tr><td><code>mad</code></td>
<td>
<p>median absolute deviation</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Arachchige Chandima N. P. G., Prendergast Luke A., 
Andri Signorell &lt;andri@signorell.net&gt; (only interface)
</p>


<h3>References</h3>

<p>Arachchige Chandima N. P. G., Prendergast Luke A. (2019) Confidence intervals for median absolute deviations, arXiv:1910.00229 [math.ST]
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mad">mad</a></code>, <code><a href="#topic+MAD">MAD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rlnorm(100)
y &lt;- rlnorm(200, meanlog=1.2)

MADCI(x)                           # single sample

MADCI(x, y)                        # two sample difference
MADCI(x, y, two.samp.diff = FALSE) # two sample squared ratio 
</code></pre>

<hr>
<h2 id='Mar+20and+20Mgp'>Set Plot Margins and Distances
</h2><span id='topic+Mar'></span><span id='topic+Mgp'></span>

<h3>Description</h3>

<p>Plot margins are normally set by <code>par("mar")</code>. However one is forced to always define all margins, even if just one should be altered. The convenience function <code>Mar()</code> allows to set one single margin (or several) while leaving the others unchanged.
</p>
<p><code>Mgp()</code> does the same for the distances of axis title, labels and line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mar(bottom = NULL, left = NULL, top = NULL, right = NULL, outer = FALSE, 
    reset = FALSE)
Mgp(title = NULL, labels = NULL, line = NULL, reset = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_bottom">bottom</code></td>
<td>
<p>the bottom margin, if set to <code>NULL</code> the current value will be maintained.
</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_left">left</code></td>
<td>
<p>the left margin, if set to <code>NULL</code> the current value will be maintained.
</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_top">top</code></td>
<td>
<p>the top margin, if set to <code>NULL</code> the current value will be maintained.
</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_right">right</code></td>
<td>
<p>the right margin, if set to <code>NULL</code> the current value will be maintained.
</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_outer">outer</code></td>
<td>
<p>logical, defining if inner margins (<code>par("mar")</code>) or the outer margins (<code>par("oma")</code>) should be set. Default is <code>FALSE</code>, meaning that the inner margins will be concerned.
</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_reset">reset</code></td>
<td>
<p>if set to <code>TRUE</code> the margins are reset to the defaults (respecting <code>outer</code>). Other arguments are ignored.</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_title">title</code></td>
<td>
<p>margin line for the axis title (default 3)</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_labels">labels</code></td>
<td>
<p>margin line for the axis labels (default 1)</p>
</td></tr>
<tr><td><code id="Mar+2B20and+2B20Mgp_+3A_line">line</code></td>
<td>
<p>margin line for the axis line (default 0)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Running <code>Mar()</code> without any arguments will return the current settings, either <code>par("mar")</code>, when outer is set to <code>FALSE</code> or <code>par("oma")</code> for <code>outer = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+par">par</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># largen the left margin only
Mar(left=10.1)   # or as alternative: Mar(, 10.1)
Mgp(title=6)     # ylab must be placed a little further to the left
barplot(1:7, names=levels(d.pizza$driver), horiz=TRUE, las=1, 
        ylab="driver", col=Pal("Helsana"))
</code></pre>

<hr>
<h2 id='matpow'>Matrix Power</h2><span id='topic++25+5E+25'></span><span id='topic+matpow'></span>

<h3>Description</h3>

<p>Compute the <code class="reqn">k</code>-th power of a matrix. Whereas <code>x^k</code> computes
<em>element wise</em> powers, <code>x %^% k</code> corresponds to <code class="reqn">k -
  1</code> matrix multiplications, <code>x %*% x %*% ... %*% x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x %^% k
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matpow_+3A_x">x</code></td>
<td>
<p>a square <code><a href="base.html#topic+matrix">matrix</a></code>.</p>
</td></tr>
<tr><td><code id="matpow_+3A_k">k</code></td>
<td>
<p>an integer, <code class="reqn">k \ge 0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Argument <code class="reqn">k</code> is coerced to integer using <code><a href="base.html#topic+as.integer">as.integer</a></code>.
</p>
<p>The algorithm uses <code class="reqn">O(log_2(k))</code> matrix
multiplications.
</p>


<h3>Value</h3>

<p>A matrix of the same dimension as <code>x</code>.
</p>


<h3>Note</h3>

<p>If you think you need <code>x^k</code> for <code class="reqn">k &lt; 0</code>, then consider
instead <code>solve(x %^% (-k))</code>.
</p>


<h3>Author(s)</h3>

<p>Based on an R-help posting of Vicente Canto Casasola, and
Vincent Goulet's C implementation in <span class="pkg">actuar</span>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic++25+2A+25">%*%</a></code> for matrix multiplication.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- cbind(1, 2 * diag(3)[,-1])
A
A %^% 2
stopifnot(identical(A, A %^% 1),
          A %^% 2 == A %*% A)
</code></pre>

<hr>
<h2 id='Mean'>(Weighted) Arithmetic Mean</h2><span id='topic+Mean'></span><span id='topic+Mean.default'></span><span id='topic+Mean.Freq'></span>

<h3>Description</h3>

<p>Generic function for the (trimmed) arithmetic mean, possibly with given weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mean(x, ...)

## S3 method for class 'Freq'
Mean(x, breaks, ...)

## Default S3 method:
Mean(x, weights = NULL, trim = 0, na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mean_+3A_x">x</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> object.  Currently there are methods for
numeric/logical vectors and <a href="base.html#topic+Dates">date</a>,
<a href="base.html#topic+date-time">date-time</a> and <a href="base.html#topic+time+20interval">time interval</a> objects.  Complex vectors
are allowed for <code>trim = 0</code>, only.</p>
</td></tr>
<tr><td><code id="Mean_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Mean_+3A_trim">trim</code></td>
<td>
<p>the fraction (0 to 0.5) of observations to be
trimmed from each end of <code>x</code> before the mean is computed.
Values of trim outside that range are taken as the nearest endpoint.
</p>
</td></tr>
<tr><td><code id="Mean_+3A_breaks">breaks</code></td>
<td>
<p>breaks for calculating the mean for classified data as composed by <code><a href="#topic+Freq">Freq</a></code>.</p>
</td></tr>
<tr><td><code id="Mean_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code>
values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="Mean_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>trim</code> is zero (the default), the arithmetic mean of the
values in <code>x</code> is computed, as a numeric or complex vector of
length one.  If <code>x</code> is not logical (coerced to numeric), numeric
(including integer) or complex, <code>NA_real_</code> is returned, with a warning.
</p>
<p>If <code>trim</code> is non-zero, a symmetrically trimmed mean is computed
with a fraction of <code>trim</code> observations deleted from each end
before the mean is computed.
</p>
<p><code>trim</code> and <code>weights</code> can't be used together at the same time.
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+weighted.mean">weighted.mean</a></code>, <code><a href="base.html#topic+mean.POSIXct">mean.POSIXct</a></code>,
<code><a href="base.html#topic+colMeans">colMeans</a></code> for row and column means.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- c(0:10, 50)
  xm &lt;- Mean(x)
  c(xm, Mean(x, trim = 0.10))
</code></pre>

<hr>
<h2 id='MeanAD'>Mean Absolute Deviation From a Center Point
</h2><span id='topic+MeanAD'></span>

<h3>Description</h3>

<p>Calculates the mean absolute deviation from a center point, typically the sample mean or the median.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MeanAD(x, weights = NULL, center = Mean, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MeanAD_+3A_x">x</code></td>
<td>
<p>a vector containing the observations.
</p>
</td></tr>
<tr><td><code id="MeanAD_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="MeanAD_+3A_center">center</code></td>
<td>
<p>a single numerical value or the name of a function to be used as center. Can as well be a self defined function.
Default is <code><a href="#topic+Mean">Mean</a>()</code>.
</p>
</td></tr>
<tr><td><code id="MeanAD_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether or not missing values should be removed. Defaults to FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MeanAD function calculates the mean absolute deviation from the mean value (or from another
supplied center point) of
x, after having removed <code>NA</code> values (if requested):
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \cdot \sum_{i=1}^{n}\left | x_{i}-c \right |  \; \; \; \textup{where} \; c=mean(x) \; \textup{or} \; c=med(x)</code>
</p>

<p><br />
The function supports the use of weights. The default function for the center value <code><a href="#topic+Mean">Mean</a>()</code> has a weights arguments, too. If a user defined function is used it must be assured that it has a weights argument.
</p>


<h3>Value</h3>

<p>Numeric value.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; following an idea of Danielle Navarro (<code>aad</code> in the <span class="pkg">lsr</span> package)
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mad">mad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(100)
MeanAD(x)

speed &lt;- c(58, 88, 40, 60, 72, 66, 80, 48, NA)
MeanAD(speed)
MeanAD(speed, na.rm=TRUE)


# using the median as centerpoint
x &lt;- c(2,3,5,3,1,15,23)

MeanAD(x, center=mean)
MeanAD(x, center=median)

# define a fixed center
MeanAD(x, center=4)

# use of weights
MeanAD(x=0:6, weights=c(21,46,54,40,24,10,5))
</code></pre>

<hr>
<h2 id='MeanCI'>
Confidence Intervals for the Mean
</h2><span id='topic+MeanCI'></span>

<h3>Description</h3>

<p>Collection of several approaches to determine confidence intervals for the mean. Both, the classical way and bootstrap intervals are implemented for both, normal and trimmed means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MeanCI(x, sd = NULL, trim = 0, method = c("classic", "boot"),
       conf.level = 0.95, sides = c("two.sided", "left", "right"),
       na.rm = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MeanCI_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="MeanCI_+3A_sd">sd</code></td>
<td>
<p>the standard deviation of x. If provided it's interpreted as sd of the population and the normal quantiles will be used for constructing the confidence intervals. If left to <code>NULL</code> (default) the sample <code>sd(x)</code> will be calculated and used in combination with the t-distribution.</p>
</td></tr>
<tr><td><code id="MeanCI_+3A_trim">trim</code></td>
<td>
<p>the fraction (0 to 0.5) of observations to be trimmed from each end of <code>x</code> before the mean is computed. Values of <code>trim</code> outside that range are taken as the nearest endpoint.
</p>
</td></tr>
<tr><td><code id="MeanCI_+3A_method">method</code></td>
<td>
<p>A vector of character strings representing the type of intervals required. The value should be any subset of the values <code>"classic"</code>, <code>"boot"</code>.
See <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>.
</p>
</td></tr>
<tr><td><code id="MeanCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.
</p>
</td></tr>
<tr><td><code id="MeanCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.
You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="MeanCI_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to FALSE.
</p>
</td></tr>
<tr><td><code id="MeanCI_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the <code><a href="boot.html#topic+boot">boot</a></code> function. Supported arguments are <code>type</code> (<code>"norm"</code>, <code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code>, <code>"bca"</code>), <code>parallel</code> and the number of bootstrap replicates <code>R</code>. If not defined those will be set to their defaults, being <code>"basic"</code> for <code>type</code>,  option <code>"boot.parallel"</code> (and if that is not set, <code>"no"</code>) for <code>parallel</code>
and <code>999</code> for <code>R</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence intervals for the trimmed means use winsorized variances as described in the references.
</p>


<h3>Value</h3>

<p>a numeric vector with 3 elements:
</p>
<table>
<tr><td><code>mean</code></td>
<td>
<p>mean</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>Wilcox, R. R., Keselman  H. J. (2003) Modern robust data analysis methods: measures of central tendency <em>Psychol Methods</em>, 8(3):254-74
</p>
<p>Wilcox, R. R. (2005) <em>Introduction to robust estimation and hypothesis testing</em> Elsevier Academic Press
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code>, <code><a href="#topic+MeanDiffCI">MeanDiffCI</a></code>, <code><a href="#topic+MedianCI">MedianCI</a></code>, <code><a href="#topic+VarCI">VarCI</a></code>, <code><a href="#topic+MeanCIn">MeanCIn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- d.pizza$price[1:20]

MeanCI(x, na.rm=TRUE)
MeanCI(x, conf.level=0.99, na.rm=TRUE)

MeanCI(x, sides="left")
# same as:
t.test(x, alternative="greater")

MeanCI(x, sd=25, na.rm=TRUE)

# the different types of bootstrap confints
MeanCI(x, method="boot", type="norm", na.rm=TRUE)
MeanCI(x, trim=0.1, method="boot", type="norm", na.rm=TRUE)
MeanCI(x, trim=0.1, method="boot", type="basic", na.rm=TRUE)
MeanCI(x, trim=0.1, method="boot", type="stud", na.rm=TRUE)
MeanCI(x, trim=0.1, method="boot", type="perc", na.rm=TRUE)
MeanCI(x, trim=0.1, method="boot", type="bca", na.rm=TRUE)

MeanCI(x, trim=0.1, method="boot", type="bca", R=1999, na.rm=TRUE)

# Getting the MeanCI for more than 1 column
round(t(sapply(d.pizza[, 1:4], MeanCI, na.rm=TRUE)), 3)
</code></pre>

<hr>
<h2 id='MeanCIn'>Sample Size for a Given Width of a Confidence Interval for a Mean
</h2><span id='topic+MeanCIn'></span>

<h3>Description</h3>

<p>Returns the required sample size to obtain a given width of a confidence interval for the sample mean. The function uses <code><a href="stats.html#topic+uniroot">uniroot</a>()</code> to find a numeric solution. The t distribution is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MeanCIn(ci, sd, interval = c(2, 100000), conf.level = 0.95, 
        norm = FALSE, tol = .Machine$double.eps^0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MeanCIn_+3A_ci">ci</code></td>
<td>
<p>the left and right bound of the interval, which is presumed to be symmetric.
</p>
</td></tr>
<tr><td><code id="MeanCIn_+3A_sd">sd</code></td>
<td>
<p>the standard deviation of the sample.
</p>
</td></tr>
<tr><td><code id="MeanCIn_+3A_interval">interval</code></td>
<td>
<p>the interval for the sample size to be searched into, (default is c(2, 100000)).
</p>
</td></tr>
<tr><td><code id="MeanCIn_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level, defaults to <code>0.95</code>. </p>
</td></tr>
<tr><td><code id="MeanCIn_+3A_norm">norm</code></td>
<td>
<p>logical, determining if the t- or normaldistribution should be used.
</p>
</td></tr>
<tr><td><code id="MeanCIn_+3A_tol">tol</code></td>
<td>
<p>the desired accuracy (convergence tolerance).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The required sample sizes for a specific width of confidence interval for the mean depends recursively on the sample size, as the samplesize defines the degrees of freedom in the t-distribution. Although in most practical cases it will be sufficient to use the normal distribution, we might be interested in exact results.
</p>


<h3>Value</h3>

<p>a numeric value 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BinomCIn">BinomCIn</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MeanCIn(ci=c(25, 27), sd=5) 
</code></pre>

<hr>
<h2 id='MeanDiffCI'>Confidence Interval For Difference of Means
</h2><span id='topic+MeanDiffCI'></span><span id='topic+MeanDiffCI.formula'></span><span id='topic+MeanDiffCI.default'></span>

<h3>Description</h3>

<p>Calculates the confidence interval for the difference of two means either the classical way or with the bootstrap approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MeanDiffCI(x, ...)

## Default S3 method:
MeanDiffCI(x, y, method = c("classic", "norm", "basic", "stud", "perc", "bca"),
           conf.level = 0.95, sides = c("two.sided", "left", "right"), paired = FALSE,
           na.rm = FALSE, R = 999, ...)

## S3 method for class 'formula'
MeanDiffCI(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MeanDiffCI_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_y">y</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_method">method</code></td>
<td>
<p>a vector of character strings representing the type of intervals required. The value should be any subset of the values
<code>"classic"</code>, <code>"norm"</code>, <code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code>, <code>"bca"</code>.
See <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>.
</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.
</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_paired">paired</code></td>
<td>
<p>a logical indicating whether you want confidence intervals for a paired design. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_r">R</code></td>
<td>
<p>the number of bootstrap replicates. Usually this will be a single positive integer. For importance resampling, some resamples may use one set of weights and others use a different set of weights. In this case R would be a vector of integers where each component gives the number of resamples from each of the rows of weights.
See <code><a href="boot.html#topic+boot">boot</a></code>.
</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> is a numeric variable giving the data values and <code>rhs</code> a factor with two levels giving the corresponding groups.</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain <code>NAs</code>. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="MeanDiffCI_+3A_...">...</code></td>
<td>
<p>further argument to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects code from two sources. The classical confidence interval is calculated by means of <code><a href="stats.html#topic+t.test">t.test</a></code>.
The bootstrap intervals are strongly based on the example in <code><a href="boot.html#topic+boot">boot</a></code>.
</p>


<h3>Value</h3>

<p>a numeric vector with 3 elements:
</p>
<table>
<tr><td><code>meandiff</code></td>
<td>
<p>the difference: mean(x) - mean(y)</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+MeanCI">MeanCI</a></code>, <code><a href="#topic+VarCI">VarCI</a></code>, <code><a href="#topic+MedianCI">MedianCI</a></code>, <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- d.pizza$price[d.pizza$driver=="Carter"]
y &lt;- d.pizza$price[d.pizza$driver=="Miller"]

MeanDiffCI(x, y, na.rm=TRUE)
MeanDiffCI(x, y, conf.level=0.99, na.rm=TRUE)

# the different types of bootstrap confints
MeanDiffCI(x, y, method="norm", na.rm=TRUE)
MeanDiffCI(x, y, method="basic", na.rm=TRUE)
# MeanDiffCI(x, y, method="stud", na.rm=TRUE)
MeanDiffCI(x, y, method="perc", na.rm=TRUE)
MeanDiffCI(x, y, method="bca", na.rm=TRUE)

# the formula interface
MeanDiffCI(price ~ driver, data=d.pizza, subset=driver %in% c("Carter","Miller"))
</code></pre>

<hr>
<h2 id='MeanSE'>Standard Error of Mean
</h2><span id='topic+MeanSE'></span>

<h3>Description</h3>

<p>Calculates the standard error of mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MeanSE(x, sd = NULL, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MeanSE_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="MeanSE_+3A_sd">sd</code></td>
<td>
<p>the standard deviation of <code>x</code>. If provided it's interpreted as sd of the population. If left to <code>NULL</code> (default) the sample <code>sd(x)</code> will be used.</p>
</td></tr>
<tr><td><code id="MeanSE_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MeanSE calculates the standard error of the mean defined as: </p>
<p style="text-align: center;"><code class="reqn">\frac{\sigma}{\sqrt{n}}</code>
</p>

<p><code class="reqn">\sigma</code> being standard deviation of <code>x</code> and n the length of <code>x</code>.
</p>


<h3>Value</h3>

<p>the standard error as numeric value.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+MeanCI">MeanCI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(d.pizza)

MeanSE(d.pizza$price, na.rm=TRUE)

# evaluate data.frame
sapply(d.pizza[,1:4], MeanSE, na.rm=TRUE)
</code></pre>

<hr>
<h2 id='Measures+20of+20Accuracy'>Measures of Accuracy
</h2><span id='topic+MAE'></span><span id='topic+MAE.default'></span><span id='topic+MAE.lm'></span><span id='topic+MAPE'></span><span id='topic+MSE'></span><span id='topic+RMSE'></span><span id='topic+MAPE.default'></span><span id='topic+MSE.default'></span><span id='topic+RMSE.default'></span><span id='topic+MAPE.lm'></span><span id='topic+MSE.lm'></span><span id='topic+RMSE.lm'></span><span id='topic+NMAE'></span><span id='topic+NMSE'></span><span id='topic+SMAPE'></span><span id='topic+SMAPE.default'></span><span id='topic+SMAPE.lm'></span>

<h3>Description</h3>

<p>Some measures of model accuracy like mean absolute error (MAE), mean absolute percentage error (MAPE), symmetric mean absolute percentage error (SMAPE), mean squared error (MSE) and root mean squared error (RMSE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAE(x, ...)
## Default S3 method:
MAE(x, ref, na.rm = FALSE, ...)
## S3 method for class 'lm'
MAE(x, ...)

MAPE(x, ...)
## Default S3 method:
MAPE(x, ref, na.rm = FALSE, ...)
## S3 method for class 'lm'
MAPE(x, ...)

SMAPE(x, ...)
## Default S3 method:
SMAPE(x, ref, na.rm = FALSE, ...)
## S3 method for class 'lm'
SMAPE(x, ...)

MSE(x, ...)
## Default S3 method:
MSE(x, ref, na.rm = FALSE, ...)
## S3 method for class 'lm'
MSE(x, ...)

RMSE(x, ...)
## Default S3 method:
RMSE(x, ref, na.rm = FALSE, ...)
## S3 method for class 'lm'
RMSE(x, ...)


NMAE(x, ref, train.y)
NMSE(x, ref, train.y)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Measures+2B20of+2B20Accuracy_+3A_x">x</code></td>
<td>
<p>the predicted values of a model or a model-object itself.
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Accuracy_+3A_ref">ref</code></td>
<td>
<p>the observed true values.
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Accuracy_+3A_train.y">train.y</code></td>
<td>
<p>the observed true values in a train dataset.
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Accuracy_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether or not missing values should be removed. Defaults to FALSE.
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Accuracy_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will remove <code>NA</code> values first (if requested).<br />
MAE calculates the mean absolute error:
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \cdot \sum_{i=1}^{n}\left | ref_{i}-x_{i} \right |</code>
</p>

<p><br />
</p>
<p>MAPE calculates the mean absolute percentage error:
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \cdot \sum_{i=1}^{n}\left | \frac{ref_{i}-x_{i}}{ref_{i}} \right |</code>
</p>

<p><br />
</p>
<p>SMAPE calculates the symmetric mean absolute percentage error:
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \cdot \sum_{i=1}^{n}\frac{2 \cdot \left | ref_{i}-x_{i} \right |}{\left | ref_{i} \right | + \left | x_{i} \right |}</code>
</p>

<p><br />
</p>
<p>MSE calculates mean squared error:
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{n} \cdot \sum_{i=1}^{n}\left ( ref_{i}-x_{i} \right )^2</code>
</p>

<p><br />
</p>
<p>RMSE calculates the root mean squared error:
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{\frac{1}{n} \cdot \sum_{i=1}^{n}\left ( ref_{i}-x_{i} \right )^2}</code>
</p>

<p><br />
</p>


<h3>Value</h3>

<p>the specific numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Armstrong, J. S. (1985) <em>Long-range Forecasting: From Crystal Ball to Computer</em>, 2nd. ed. Wiley. ISBN 978-0-471-82260-8<br />
<a href="https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error">https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error</a>
</p>
<p>Torgo, L. (2010) <em>Data Mining with R: Learning with Case Studies</em>, Chapman and Hall/CRC Press
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+resid">resid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r.lm &lt;- lm(Fertility ~ ., data=swiss)

MAE(r.lm)

# the same as:
MAE(predict(r.lm), swiss$Fertility)

MAPE(r.lm)
MSE(r.lm)
RMSE(r.lm)
</code></pre>

<hr>
<h2 id='Measures+20of+20Shape'>
Skewness and Kurtosis
</h2><span id='topic+Skew'></span><span id='topic+Kurt'></span>

<h3>Description</h3>

<p><code>Skew</code> computes the skewness, <code>Kurt</code> the excess kurtosis of the values in x. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Skew(x, weights = NULL, na.rm = FALSE, method = 3, conf.level = NA, 
     ci.type = "bca", R = 1000, ...)

Kurt(x, weights = NULL, na.rm = FALSE, method = 3, conf.level = NA, 
     ci.type = "bca", R = 1000, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_x">x</code></td>
<td>

<p>a numeric vector. An object which is not a vector is coerced (if possible) by <code>as.vector</code>.
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_na.rm">na.rm</code></td>
<td>

<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to <code>FALSE</code>.

</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_method">method</code></td>
<td>

<p>integer out of 1, 2 or 3 (default). See Details.

</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated. 
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_ci.type">ci.type</code></td>
<td>
<p>The type of confidence interval required. The value should be any subset 
of the values <code>"classic"</code>, <code>"norm"</code>, <code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code> or <code>"bca"</code>  (<code>"all"</code> 
which would compute all five types of intervals, is not supported). 
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_r">R</code></td>
<td>
<p>The number of bootstrap replicates. Usually this will be a single positive integer. For importance resampling, 
some resamples may use one set of weights and others use a different set of weights. In this case <code>R</code> would be a vector 
of integers where each component gives the number of resamples from each of the rows of weights.
</p>
</td></tr>
<tr><td><code id="Measures+2B20of+2B20Shape_+3A_...">...</code></td>
<td>
<p> the dots are passed to the function <code><a href="boot.html#topic+boot">boot</a></code>, when confidence intervalls are calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Kurt()</code> returns the excess kurtosis, therefore the kurtosis calculates as <code>Kurt(x) + 3</code> if required.
</p>
<p>If <code>na.rm</code> is <code>TRUE</code> then missing values are removed before computation proceeds. <br />
</p>
<p>The methods for calculating the skewness can either be:<br />
<code>method = 1:   g_1 = m_3 / m_2^(3/2) </code> <br />
<code>method = 2:   G_1 = g_1 * sqrt(n(n-1)) / (n-2) </code><br />
<code>method = 3:   b_1 = m_3 / s^3 = g_1 ((n-1)/n)^(3/2) </code> <br />
</p>
<p>and the ones for the kurtosis:<br />
<code>method = 1:  g_2 = m_4 / m_2^2 - 3 </code>  <br />
<code>method = 2:  G_2 = ((n+1) g_2 + 6) * (n-1) / ((n-2)(n-3)) </code>  <br />
<code>method = 3:  b_2 = m_4 / s^4 - 3 = (g_2 + 3) (1 - 1/n)^2 - 3 </code> <br />
</p>
<p>method = 1 is the typical definition used in Stata and in many older textbooks.   <br />
method = 2 is used in SAS and SPSS.  <br />
method = 3 is used in MINITAB and BMDP. <br />
</p>
<p>Cramer et al. (1997) mention the asymptotic standard error of the skewness, resp. kurtosis: <br />
</p>
<pre>ASE.skew = sqrt( 6n(n-1)/((n-2)(n+1)(n+3)) )
ASE.kurt = sqrt( (n^2 - 1)/((n-3)(n+5)) )</pre><p> to be used for calculating the confidence intervals. This is implemented here with <code>ci.type="classic"</code>. However, Joanes and Gill (1998) advise against this approach, pointing out that the normal assumptions would virtually always be violated. 
They suggest using the bootstrap method. That's why the default method for the confidence interval type is set to <code>"bca"</code>.<br />  
</p>
<p>This implementation of the two functions is comparably fast, as the expensive sums are coded in C.
</p>


<h3>Value</h3>

<p>If <code>conf.level</code> is set to <code>NA</code> then the result will be  
</p>
<table>
<tr><td><code>a</code></td>
<td>
<p> single numeric value</p>
</td></tr></table>
<p> and 
if a <code>conf.level</code> is provided, a named numeric vector with 3 elements:
</p>
<table>
<tr><td><code>skew</code>, <code>kurt</code></td>
<td>
<p>the specific estimate, either skewness or kurtosis</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, David Meyer &lt;david.meyer@r-project.org&gt; (method = 3) </p>


<h3>References</h3>

<p>Cramer, D. (1997): <em>Basic Statistics for Social Research</em> Routledge.
</p>
<p>Joanes, D. N., Gill, C. A. (1998): Comparing measures of sample skewness and kurtosis. <em>The Statistician</em>, 47, 183-189.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+mean">mean</a></code>, <code><a href="stats.html#topic+sd">sd</a></code>, similar code in <code>library(e1071)</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Skew(d.pizza$price, na.rm=TRUE)
Kurt(d.pizza$price, na.rm=TRUE)

# use sapply to calculate skewness for a data.frame
sapply(d.pizza[,c("temperature","price","delivery_min")], Skew, na.rm=TRUE)

# or apply to do that columnwise with a matrix
apply(as.matrix(d.pizza[,c("temperature","price","delivery_min")]), 2, Skew, na.rm=TRUE)
</code></pre>

<hr>
<h2 id='Median'>(Weighted) Median Value</h2><span id='topic+Median'></span><span id='topic+Median.Freq'></span><span id='topic+Median.factor'></span><span id='topic+Median.default'></span>

<h3>Description</h3>

<p>Compute the sample median. The function basically wraps the function <code><a href="#topic+Quantile">Quantile</a>()</code>, which offers the option to define weights.<br />
For grouped data the median can be estimated by linear interpolation within the class containing the median, which is implemented in the interface for <code>Freq</code>-objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Median(x, ...)

## S3 method for class 'factor'
Median(x, na.rm = FALSE, ...)

## S3 method for class 'Freq'
Median(x, breaks, ...)

## Default S3 method:
Median(x, weights = NULL, na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Median_+3A_x">x</code></td>
<td>
<p>an object for which a method has been defined, or a
numeric vector containing the values whose median is to be computed.</p>
</td></tr>
<tr><td><code id="Median_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Median_+3A_breaks">breaks</code></td>
<td>
<p>breaks for calculating the mean for classified data as composed by <code><a href="#topic+Freq">Freq</a></code>.</p>
</td></tr>
<tr><td><code id="Median_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code>
values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="Median_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a generic function for which methods can be written.  However,
the default method makes use of <code>is.na</code>, <code>sort</code> and
<code>mean</code> from package <span class="pkg">base</span> all of which are generic, and so
the default method will work for most classes
(e.g., <code>"<a href="base.html#topic+Date">Date</a>"</code>) for which a median is a reasonable
concept.
</p>
<p>Calculating the median for ordered factors is not implemented in standard R, as
it's not well defined (it is not clear what to do if the median sits between two levels in factors of even length).
This function returns the high median and prints a warning if the low median would be different (which is
supposed to be a rare event).
There's a vivid discussion between experts going on whether this should be defined or not.
We'll wait for definitive results and enjoy the function's comfort so far...
</p>
<p>Note that there are alternative approaches for calculating weighted median (e.g. <code>matrixstats::weightedMedian</code>).
</p>


<h3>Value</h3>

<p>The default method returns a length-one object of the same type as
<code>x</code>, except when <code>x</code> is integer of even length, when the
result will be double.
</p>
<p>If there are no values or if <code>na.rm = FALSE</code> and there are <code>NA</code>
values the result is <code>NA</code> of the same type as <code>x</code> (or more
generally the result of <code>x[FALSE][NA]</code>).
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quantile">quantile</a></code> for general quantiles.
<a href="https://stat.ethz.ch/pipermail/r-help/2003-November/042684.html">https://stat.ethz.ch/pipermail/r-help/2003-November/042684.html</a>
</p>
<p><a href="https://stackoverflow.com/questions/7925102/idiomatic-method-of-finding-the-median-of-an-ordinal">https://stackoverflow.com/questions/7925102/idiomatic-method-of-finding-the-median-of-an-ordinal</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Median(1:4)                # = 2.5 [even number]
Median(c(1:3, 100, 1000))  # = 3 [odd, robust]

# Approximation for classified data
breaks &lt;- seq(10,70, 10)
Median(
  Freq(cut(d.pizza$temperature, breaks=breaks)),
  breaks=breaks)

# compared to
Median(d.pizza$temperature)

# starting from a classified table
# from     to  income
#    0   4000      20
# 4000   6000      42
# 6000   8000      31
# 8000  10000      12

# Freq(as.table(c(20,42,31,12)))
#    level  freq   perc  cumfreq  cumperc
# 1      A    20  19.0%       20    19.0%
# 2      B    42  40.0%       62    59.0%
# 3      C    31  29.5%       93    88.6%
# 4      D    12  11.4%      105   100.0%

Median(Freq(as.table(c(20,42,31,12))), breaks=c(0,4000,6000,8000,10000))

# use weights
x &lt;- sample(20, 30, replace = TRUE)
z &lt;- as.numeric(names(w &lt;- table(x)))

(m1 &lt;- Median(z, weights=w))
(m2 &lt;- Median(x))
stopifnot(identical(m1, m2))
</code></pre>

<hr>
<h2 id='MedianCI'>
Confidence Interval for the Median
</h2><span id='topic+MedianCI'></span>

<h3>Description</h3>

<p>Calculates the confidence interval for the median.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MedianCI(x, conf.level = 0.95, sides = c("two.sided", "left", "right"),
         na.rm = FALSE, method = c("exact", "boot"), R = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MedianCI_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="MedianCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval
</p>
</td></tr>
<tr><td><code id="MedianCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="MedianCI_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="MedianCI_+3A_method">method</code></td>
<td>
<p>defining the type of interval that should be calculated (one out of <code>"exact"</code>, <code>"boot"</code>). Default is <code>"exact"</code>. See Details.</p>
</td></tr>
<tr><td><code id="MedianCI_+3A_r">R</code></td>
<td>
<p>The number of bootstrap replicates. Usually this will be a single positive integer. See
<code><a href="boot.html#topic+boot.ci">boot.ci</a></code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;exact&quot; method is the way SAS is said to calculate the confidence interval. This is implemented in <code><a href="#topic+SignTest">SignTest</a></code> and is extracted therefrom.
The boot confidence interval type is calculated by means of <code><a href="boot.html#topic+boot.ci">boot.ci</a></code> with default type <code>"basic"</code>.<br />
Use <code><a href="base.html#topic+sapply">sapply</a></code>, resp.<code><a href="base.html#topic+apply">apply</a></code>, to get the confidence intervals from a data.frame or from a matrix.
</p>


<h3>Value</h3>

<p>a numeric vector with 3 elements:
</p>
<table>
<tr><td><code>median</code></td>
<td>
<p>median</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>, <code><a href="#topic+MeanCI">MeanCI</a></code>, <code><a href="stats.html#topic+median">median</a></code>, <code><a href="#topic+HodgesLehmann">HodgesLehmann</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MedianCI(d.pizza$price, na.rm=TRUE)
MedianCI(d.pizza$price, conf.level=0.99, na.rm=TRUE)

t(round(sapply(d.pizza[,c("delivery_min","temperature","price")], MedianCI, na.rm=TRUE), 3))

MedianCI(d.pizza$price, na.rm=TRUE, method="exact")
MedianCI(d.pizza$price, na.rm=TRUE, method="boot")
</code></pre>

<hr>
<h2 id='Mgsub'>Multiple Gsub
</h2><span id='topic+Mgsub'></span>

<h3>Description</h3>

<p>Performs multiple substitions in (a) string(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mgsub(pattern, replacement, x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mgsub_+3A_pattern">pattern</code></td>
<td>
<p>character string containing a regular expression (or character string for fixed = TRUE) to be matched in the given character vector. Coerced by as.character to a character string if possible. 
</p>
</td></tr>
<tr><td><code id="Mgsub_+3A_replacement">replacement</code></td>
<td>
<p>a replacement for matched pattern as in <code><a href="base.html#topic+sub">sub</a></code> and <code><a href="base.html#topic+gsub">gsub</a></code>.
See there for more information.
</p>
</td></tr>
<tr><td><code id="Mgsub_+3A_x">x</code></td>
<td>
<p>a character vector where matches are sought, or an object which can be coerced by as.character to a character vector. Long vectors are supported.
</p>
</td></tr>
<tr><td><code id="Mgsub_+3A_...">...</code></td>
<td>
<p>all dots are passed on to gsub.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector of the same length and with the same attributes as x (after possible coercion to character). 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+gsub">gsub</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("ABC", "BCD", "CDE")
Mgsub(pattern=c("B", "C"), replacement=c("X","Y"), x)
</code></pre>

<hr>
<h2 id='MHChisqTest'>Mantel-Haenszel Chi-Square Test
</h2><span id='topic+MHChisqTest'></span>

<h3>Description</h3>

<p>The Mantel-Haenszel chi-square statistic tests the alternative hypothesis that there is a linear association between the row variable and the column variable. Both variables must lie on an ordinal scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MHChisqTest(x, srow = 1:nrow(x), scol = 1:ncol(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MHChisqTest_+3A_x">x</code></td>
<td>
<p>a frequency table or a matrix. 
</p>
</td></tr>
<tr><td><code id="MHChisqTest_+3A_srow">srow</code></td>
<td>
<p>scores for the row variable, defaults to 1:nrow.
</p>
</td></tr>
<tr><td><code id="MHChisqTest_+3A_scol">scol</code></td>
<td>
<p>scores for the colummn variable, defaults to 1:ncol.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The statistic is computed as <code class="reqn"> Q_{MH} = (n-1) \cdot r^2</code>, where <code class="reqn">r^2</code> is the Pearson correlation between the row variable and the column variable. The Mantel-Haenszel chi-square statistic use the scores specified by srow and scol.
Under the null hypothesis of no association, <code class="reqn">Q_{MH}</code> has an asymptotic chi-square distribution with one degree of freedom. 
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following
components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value the Mantel-Haenszel chi-squared test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom of the approximate
chi-squared distribution of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the type of test
performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons, pp 86 ff.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+chisq.test">chisq.test</a></code>, 
for calculating correlation of a table: <code><a href="boot.html#topic+corr">corr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## A r x c table  Agresti (2002, p. 57) Job Satisfaction
Job &lt;- matrix(c(1,2,1,0, 3,3,6,1, 10,10,14,9, 6,7,12,11), 4, 4,
              dimnames = list(income = c("&lt; 15k", "15-25k", "25-40k", "&gt; 40k"),
                              satisfaction = c("VeryD", "LittleD", "ModerateS", "VeryS"))
       )

MHChisqTest(Job, srow=c(7.5,20,32.5,60))
</code></pre>

<hr>
<h2 id='Midx'>Find the Midpoints of a Numeric Vector
</h2><span id='topic+Midx'></span>

<h3>Description</h3>

<p>Calculate the midpoints of a sequence of numbers. This is e.g. useful for labelling stacked barplots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Midx(x, incl.zero = FALSE, cumulate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Midx_+3A_x">x</code></td>
<td>
<p>the numeric vector
</p>
</td></tr>
<tr><td><code id="Midx_+3A_incl.zero">incl.zero</code></td>
<td>
<p>should zero be appended to x before proceeding? If <code>TRUE</code> the first value will be one half of the first value of x. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Midx_+3A_cumulate">cumulate</code></td>
<td>
<p>should the result be calculated as cumulative sum? Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector with the calculated midpoins
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MoveAvg">MoveAvg</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1, 3, 6, 7)

Midx(x)
Midx(x, incl.zero = TRUE)
Midx(x, incl.zero = TRUE, cumulate = TRUE)

# an alternative to
head(MoveAvg(c(0, x), order = 2, align = "l"), n = -1)

tab &lt;- matrix(c(401,216,221,254,259,169), nrow=2, byrow=TRUE)
b &lt;- barplot(tab, beside = FALSE, horiz=TRUE)

x &lt;- t(apply(tab, 2, Midx, incl.zero=TRUE, cumulate=TRUE))
text(tab, x=x, y=b, col="red")
</code></pre>

<hr>
<h2 id='MixColor'>Compute the Convex Combination of Two Colors</h2><span id='topic+MixColor'></span>

<h3>Description</h3>

<p>This function can be used to compute the result of color
mixing (it assumes additive mixing).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MixColor(col1, col2, amount1 = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MixColor_+3A_col1">col1</code></td>
<td>
<p>the first color.</p>
</td></tr>
<tr><td><code id="MixColor_+3A_col2">col2</code></td>
<td>
<p>the second color.</p>
</td></tr>
<tr><td><code id="MixColor_+3A_amount1">amount1</code></td>
<td>
<p>the amount of color1. The amount of color2 results in (1-amount1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mixed color as hexstring
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="grDevices.html#topic+colorRamp">colorRamp</a></code>, <code><a href="grDevices.html#topic+rgb">rgb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># a mix between red and yellow with rates 3:7
MixColor("red", "yellow", 0.3)
</code></pre>

<hr>
<h2 id='Mode'>Mode, Most Frequent Value(s)
</h2><span id='topic+Mode'></span>

<h3>Description</h3>

<p>Calculate the mode, the most frequent value, of a numeric or character vector x. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mode(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mode_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="Mode_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mode is usually useful for qualitative data, sometimes still for an integer vector. For numerical vectors, it is not so much the central tendency property of the mode that is interesting as the information about conspicuous accumulation points, which  sometimes can indicate data errors. In <code>Desc()</code> it is integrated in the numeric description to draw the analyst's attention to strikingly high frequencies of a single value as soon as they exceed a certain treshold. (In a numeric vector we would in general rather expect low numbers of tied values, or we should be aware of the process properties that generates them.)
</p>
<p>The handling of <code>NA</code> values follows the standards of the package. As soon as a single <code>NA</code> value occurs, <code>NA</code> is returned as result. This approach can sometimes be conservative when calculating the mode. The mode could be determined unambiguously in cases where the number of missing values is small enough that - regardless of what value they have - they cannot alter the sample mode. The modal frequency could then be determined within a lower and upper range. In the example of <code>x=c(1,1,1,1,2,2,NA)</code> we know that the mode of x is 1 regardless of what the true value is for the one missing value; and we know that the modal frequency must be between 4 and 5. However this is not implemented in the function and further considerations in this direction are left to the user here.
</p>
<p>The mode is elsewhere often calculated in a crude and wasteful way by tabulating the frequency for all elements of the vector and returning the most frequent one. This function uses a sophisticated data structure in C++ and is limited to determining the most frequent element only. Therefore it is orders of magnitude faster than other implementations, especially for large numeric vectors with large numbers of distinct values. 
</p>
<p>You might furthermore consider using <code>density(x)$x[which.max(density(x)$y)]</code> for quantitative data or alternatively use <code>hist()</code>.<br />
Another interesting idea for a more robust estimation of the mode:<br />
</p>
<pre>
peak &lt;- optimize(function(x, model) predict(model, data.frame(x = x)),
                 c(min(x), max(x)),
                 maximum = TRUE,
                 model = y.loess) 
            
points(peak$maximum, peak$objective, pch=FILLED.CIRCLE &lt;- 19) 
</pre>


<h3>Value</h3>

<p>The most frequent value as number or character, depending of <code>class(x)</code>. If there is more than one, all are returned in a vector.<br />
The modal frequency is attached as attribute named <code>"freq"</code>.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, great Rcpp part by Joseph Wood and Ralf Stubner
</p>


<h3>References</h3>

<p>https://stackoverflow.com/questions/55212746/rcpp-fast-statistical-mode-function-with-vector-input-of-any-type/
https://stackoverflow.com/a/55213471/8416610
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+Mean">Mean</a></code>,  <code><a href="#topic+Median">Median</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># normal mode
Mode(c(0:5, 5))

Mode(5)
Mode(NA)
Mode(c(NA, NA))
Mode(c(NA, 0:5))
Mode(c(NA, 0:5), na.rm=TRUE)
Mode(c(NA, 0:5, 5), na.rm=TRUE)

# returns all encountered modes, if several exist
Mode(c(0:5, 4, 5, 6))

Mode(d.pizza$driver)
Mode(d.pizza$driver, na.rm=TRUE)
Mode(as.character(d.pizza$driver), na.rm=TRUE)

# use sapply for evaluating data.frames (resp. apply for matrices)
sapply(d.pizza[,c("driver", "temperature", "date")], Mode, na.rm=TRUE)
</code></pre>

<hr>
<h2 id='MosesTest'>Moses Test of Extreme Reactions
</h2><span id='topic+MosesTest'></span><span id='topic+MosesTest.default'></span><span id='topic+MosesTest.formula'></span>

<h3>Description</h3>

<p>Perform Moses test of extreme reactions, which is a distribution-free non-parametric test for the difference between two independent groups in the extremity of scores (in both directions) that the groups contain. 
Scores from both groups are pooled and converted to ranks, and the test statistic is the span of scores (the range plus 1) in one of the groups chosen arbitrarily. An exact probability is computed for the span and then recomputed after dropping a specified number of extreme scores from each end of its range. The exact one-tailed probability is calculated. </p>


<h3>Usage</h3>

<pre><code class='language-R'>MosesTest(x, ...)

## Default S3 method:
MosesTest(x, y, extreme = NULL, ...)

## S3 method for class 'formula'
MosesTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MosesTest_+3A_x">x</code></td>
<td>
<p>numeric vector of data values. <code>x</code> will be treated as control group. Non-finite (e.g. infinite or missing) values will be omitted.
</p>
</td></tr>
<tr><td><code id="MosesTest_+3A_y">y</code></td>
<td>
<p>numeric vector of data values. <code>y</code> will be treated as experiment group. Non-finite (e.g. infinite or missing) values will be omitted.
</p>
</td></tr>
<tr><td><code id="MosesTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="MosesTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="MosesTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="MosesTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain <code>NA</code>s. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="MosesTest_+3A_extreme">extreme</code></td>
<td>
<p>integer, defines the number of extreme values to be dropped from the control group before calculating the
span. Default (<code>NULL</code>) is the integer part of <code>0.05 * length(x)</code> or <code>1</code>, whichever is greater. If extreme is too large, it will be cut down to <code>floor(length(x)-2)/2</code>. </p>
</td></tr>
<tr><td><code id="MosesTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For two independent samples from a continuous field, this tests whether extreme values
are equally likely in both populations or if they are more likely to occur in the population
from which the sample with the larger range was drawn.
</p>
<p>Note that the ranks are calculated in decreasing mode.
</p>


<h3>Value</h3>

<p>A list with class &ldquo;htest&rdquo; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Moses Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Moses Test of Extreme Reactions&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Moses, L.E. (1952) A Two-Sample Test, <em>Psychometrika</em>, 17, 239-247.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>, <code><a href="stats.html#topic+ks.test">ks.test</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46)
y &lt;- c(1.15, 0.88, 0.90, 0.74, 1.21)

MosesTest(x, y)


set.seed(1479)
x &lt;- sample(1:20, 10, replace=TRUE)
y &lt;- sample(5:25, 6, replace=TRUE)

MosesTest(x, y)
</code></pre>

<hr>
<h2 id='MoveAvg'>Moving Average
</h2><span id='topic+MoveAvg'></span>

<h3>Description</h3>

<p>Compute a simple moving average (running mean).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MoveAvg(x, order, align = c("center", "left", "right"), 
        endrule = c("NA", "keep", "constant"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MoveAvg_+3A_x">x</code></td>
<td>
<p>univariate time series.</p>
</td></tr>
<tr><td><code id="MoveAvg_+3A_order">order</code></td>
<td>
<p>order of moving average.</p>
</td></tr>
<tr><td><code id="MoveAvg_+3A_align">align</code></td>
<td>
<p>specifies whether result should be centered (default), left-aligned or right-aligned.</p>
</td></tr>
<tr><td><code id="MoveAvg_+3A_endrule">endrule</code></td>
<td>
<p>character string indicating how the values at the
beginning and the end (of the data) should be treated.
</p>

<dl>
<dt><code>"keep"</code></dt><dd><p>keeps the first and last <code class="reqn">k_2</code> values
at both ends, where <code class="reqn">k_2</code> is the half-bandwidth <code>k2
	  = k %/% 2</code>,
i.e., <code>y[j] = x[j]</code> for <code class="reqn">j \in \{1,\ldots,k_2;
	  n-k_2+1,\ldots,n\}</code>;</p>
</dd>
<dt><code>"constant"</code></dt><dd><p>fill the ends with first and last calculated value in output array
(out[1:k2] = out[k2+1])</p>
</dd>
<dt><code>"NA"</code></dt><dd><p>the default, leaves the values to NA, as they are returned by <code><a href="stats.html#topic+filter">filter</a></code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation is using the function <code>filter</code> to calculate the moving average.</p>


<h3>Value</h3>

<p>Returns a vector of the same size and same class as x. </p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; </p>


<h3>See Also</h3>

<p>There's a faster implementation of running mean in the package <span class="pkg">caTools</span> <code><a href="caTools.html#topic+runmean">runmean</a>()</code> and a slower one in <span class="pkg">forecast</span> <code><a href="forecast.html#topic+ma">ma</a>()</code>. There's similar code in <code><a href="#topic+Midx">Midx</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MoveAvg(AirPassengers, order=5)
</code></pre>

<hr>
<h2 id='MultinomCI'>Confidence Intervals for Multinomial Proportions</h2><span id='topic+MultinomCI'></span>

<h3>Description</h3>

<p>Confidence intervals for multinomial proportions are often approximated by single binomial confidence intervals, which might in practice often yield satisfying results, but is properly speaking not correct. This function calculates simultaneous confidence intervals for multinomial proportions either according to the methods of Sison and Glaz, Goodman, Wald, Wald with continuity correction or Wilson.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultinomCI(x, conf.level = 0.95, sides = c("two.sided", "left", "right"),
           method = c("sisonglaz", "cplus1", "goodman", "wald", "waldcc", 
                      "wilson", "qh", "fs"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultinomCI_+3A_x">x</code></td>
<td>

<p>A vector of positive integers representing the number of occurrences of each class. The total number of samples equals the sum of such elements.
</p>
</td></tr>
<tr><td><code id="MultinomCI_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level, defaults to 0.95. </p>
</td></tr>
<tr><td><code id="MultinomCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default),
<code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of
<code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="MultinomCI_+3A_method">method</code></td>
<td>
<p> character string specifing which method to use; can be one out of
<code>"sisonglaz"</code>, <code>"cplus1"</code>, <code>"goodman"</code>,  <code>"wald"</code>,  <code>"waldcc"</code>, <code>"wilson"</code>,
<code>"qh"</code>, <code>"fs"</code>.
Method can be abbreviated. See details. Defaults to <code>"sisonglaz"</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a vector of observations with the number of samples falling in each class of a multinomial distribution,
builds the simultaneous confidence intervals for the multinomial probabilities according to the method proposed by the mentioned authors.
The R code for Sison and Glaz (1995) has been translated from thes SAS code written by May and Johnson (2000). See the references for the other methods (qh = Quesensberry-Hurst, fs = Fitzpatrick-Scott).<br />
Some approaches for the confidence intervals can potentially yield negative results or values beyond 1. These would be reset such as not to exceed the range of [0, 1].
</p>


<h3>Value</h3>

<p>A matrix with 3 columns:
</p>
<table>
<tr><td><code>est</code></td>
<td>
<p>estimate</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>
<p>The number of rows correspond to the dimension of x.
</p>


<h3>Author(s)</h3>

<p>Pablo J. Villacorta Iglesias &lt;pjvi@decsai.ugr.es&gt;<br />
Department of Computer Science and Artificial Intelligence, University of Granada (Spain)
(Sison-Glaz)
</p>
<p>Andri Signorell &lt;andri@signorell.net&gt;
(Goodman, Wald, Wilson, Fitzpatrick-Scott, Quesensberry-Hurst)
</p>


<h3>References</h3>

<p>Fitzpatrick, S. and Scott, A. (1987). Quick simultaneous confidence interval for multinomial proportions. <em>Journal of American Statistical Association</em> 82(399): 875-878.
</p>
<p>Glaz, J., Sison, C.P. (1999) Simultaneous confidence intervals for multinomial proportions.
<em>Journal of Statistical Planning and Inference</em> 82:251-262.
</p>
<p>Goodman, L. A. (1965) On Simultaneous Confidence Intervals for Multinomial
Proportions <em>Technometrics</em>, 7, 247-254.
</p>
<p>May, W.L., Johnson, W.D.(2000) Constructing two-sided simultaneous confidence intervals for
multinomial proportions for small counts in a large number of cells. <em>Journal of Statistical Software</em> 5(6) .
Paper and code available at <a href="https://www.jstatsoft.org/v05/i06">https://www.jstatsoft.org/v05/i06</a>.
</p>
<p>Quesensberry, C.P. and Hurst, D.C. (1964). Large Sample Simultaneous Confidence Intervals for Multinational Proportions. <em>Technometrics</em>, 6: 191-195.
</p>
<p>Sangeetha, U., Subbiah, M., Srinivasan, M. R. (2013) Mathematical Analysis of propensity of aberration on the methods for interval estimation of the multinomial proportions.
<em>IOSR Journal of Mathematics</em>, e-ISSN: 2278-5728,p-ISSN: 2319-765X, Volume 7, Issue 4 (Jul. - Aug. 2013), PP 23-28
</p>
<p>Sison, C.P and Glaz, J. (1995) Simultaneous confidence intervals and sample size determination
for multinomial proportions. <em>Journal of the American Statistical Association</em>, 90:366-369.
</p>
<p>Wald, A. Tests of statistical hypotheses concerning several parameters when the number of observations is large, <em>Trans. Am. Math. Soc.</em> 54 (1943) 426-482.
</p>
<p>Wilson, E. B. Probable inference, the law of succession and statistical inference, <em>J.Am. Stat. Assoc.</em> 22 (1927) 209-212.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Multinomial distribution with 3 classes, from which a sample of 79 elements
# were drawn: 23 of them belong to the first class, 12 to the
# second class and 44 to the third class. Punctual estimations
# of the probabilities from this sample would be 23/79, 12/79
# and 44/79 but we want to build 95% simultaneous confidence intervals
# for the true probabilities

MultinomCI(c(23, 12, 44), conf.level=0.95)


x &lt;- c(35, 74, 22, 69)

MultinomCI(x, method="goodman")
MultinomCI(x, method="sisonglaz")
MultinomCI(x, method="cplus1")
MultinomCI(x, method="wald")
MultinomCI(x, method="waldcc")
MultinomCI(x, method="wilson")

# compare to
BinomCI(x, n=sum(x))

# example in Goodman (1965)
MultinomCI(x = c(91,49,37,43),conf.level = 0.95,method="goodman")

# example from Sison, Glaz (1999) in Sangeetha (2013) - Table 2
x &lt;- c(56, 72, 73, 59, 62, 87, 58)
do.call(cbind, lapply(c("wald", "waldcc", "wilson", 
                        "qh", "goodman", "fs", "sisonglaz"),
                      function(m) round(MultinomCI(x, method=m)[,-1], 3)))
       
</code></pre>

<hr>
<h2 id='MultMerge'>Merge Multiple Data Frames
</h2><span id='topic+MultMerge'></span>

<h3>Description</h3>

<p>Merge multiple data frames by row names, or do other versions of database join operations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultMerge(..., all.x = TRUE, all.y = TRUE, by = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultMerge_+3A_...">...</code></td>
<td>
<p>data frames to be coerced to one.
</p>
</td></tr>
<tr><td><code id="MultMerge_+3A_all.x">all.x</code></td>
<td>
<p>logical; if <code>TRUE</code>, then extra rows will be added to the output, one for each row in x that has no matching row in y. These rows will have <code>NA</code>s in those columns that are usually filled with values from y. The default is <code>FALSE</code>, so that only rows with data from both x and y are included in the output.
</p>
</td></tr>
<tr><td><code id="MultMerge_+3A_all.y">all.y</code></td>
<td>
<p>logical; analogous to <code>all.x</code>.
</p>
</td></tr>
<tr><td><code id="MultMerge_+3A_by">by</code></td>
<td>
<p>column used for merging, if this is not defined rownames will be used by default. The column must be included in all the provided data frames.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame. The rows are sorted according to the appearance of previously unobserved rownames. So the rownames appearing in the first data frame are first, then the rownames in the second data frame, which have no corespondence in the first data frame and so on. The columns are the remaining columns in x1 and then those in x2 and then those in x3. The result has the row names resulting from the merge.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+merge">merge</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- SetNames(data.frame(v=letters[1:6], w=1:6), 
               rownames=c("A", "B", "C", "D", "E", "F"))
x2 &lt;- SetNames(data.frame(v=letters[1:3], ww=11:13), 
               rownames=c("B", "C", "D"))
x3 &lt;- SetNames(data.frame(v=letters[12:16], wwww=22:26), 
               rownames=c("A", "C", "E", "G", "J"))

# default is "merge by rownames" 
MultMerge(x1, x2, x3)
# ... which does not really make sense here

# merge by column v
MultMerge(x1, x2, x3, by="v")

</code></pre>

<hr>
<h2 id='NALevel'>Replace NAs in a Factor by a Given Level
</h2><span id='topic+NALevel'></span>

<h3>Description</h3>

<p>In order to replace the NAs in a factor an additional level has to be defined first. 
This function does this and replaces the NAs by the given level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NALevel(x, level)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NALevel_+3A_x">x</code></td>
<td>
<p>a vector which will be turned into a factor.
</p>
</td></tr>
<tr><td><code id="NALevel_+3A_level">level</code></td>
<td>
<p>the name for the new level
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the vector x with the NAs replaced by level
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+factor">factor</a></code>, <code><a href="base.html#topic+levels">levels</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(LETTERS[1:5], NA)
table(NALevel(x, "something else"))

</code></pre>

<hr>
<h2 id='NemenyiTest'>Nemenyi Test
</h2><span id='topic+NemenyiTest'></span><span id='topic+NemenyiTest.default'></span><span id='topic+NemenyiTest.formula'></span>

<h3>Description</h3>

<p>Performs Nemenyi's test of multiple comparisons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NemenyiTest(x, ...)

## Default S3 method:
NemenyiTest(x, g, dist = c("tukey", "chisq"), out.list = TRUE, ...)

## S3 method for class 'formula'
NemenyiTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NemenyiTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, or a list of numeric data
vectors.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the
corresponding elements of <code>x</code>.  Ignored if <code>x</code> is a
list.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_dist">dist</code></td>
<td>
<p>the distribution used for the test. Can be <code>tukey</code> (default) or <code>chisq</code>.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_out.list">out.list</code></td>
<td>
<p>logical, defining if the output should be organized in listform.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
gives the data values and <code>rhs</code> the corresponding groups.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="NemenyiTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Nemenyi proposed a test based on rank sums and the application of the family-wise error method to control Type I error inflation, if multiple comparisons are done. The Tukey and Kramer approach uses mean rank sums and can be employed for equally as well as unequally sized samples without ties.
</p>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p> Nemenyi test</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>   the p-value for the test</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>is the value of the median specified by the null hypothesis. This
equals the input argument <code>mu</code>. </p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>  the type of test applied</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Nemenyi, P. B. (1963) <em>Distribution-Free Multiple Comparisons</em> New York, State University of New York, Downstate Medical Center
</p>
<p>Hollander, M., Wolfe, D.A. (1999) <em>Nonparametric Statistical Methods</em> New York, Wiley, pp. 787
</p>
<p>Friedman, M. (1937) The use of ranks to avoid the assumption of normality implicit in the analysis of variance  <em>Journal of the American Statistical Association</em>, 32:675-701
</p>
<p>Friedman, M. (1940) A comparison of alternative tests of significance for the problem of m rankings <em>Annals of Mathematical Statistics</em>, 11:86-92
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DunnTest">DunnTest</a></code>, <code><a href="#topic+ConoverTest">ConoverTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Hollander &amp; Wolfe (1973), 116.
## Mucociliary efficiency from the rate of removal of dust in normal
##  subjects, subjects with obstructive airway disease, and subjects
##  with asbestosis.
x &lt;- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
y &lt;- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
z &lt;- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis

NemenyiTest(list(x, y, z))

## Equivalently,
x &lt;- c(x, y, z)
g &lt;- factor(rep(1:3, c(5, 4, 5)),
            labels = c("Normal subjects",
                       "Subjects with obstructive airway disease",
                       "Subjects with asbestosis"))

NemenyiTest(x, g)

## Formula interface.
boxplot(Ozone ~ Month, data = airquality)
NemenyiTest(Ozone ~ Month, data = airquality)

# Hedderich &amp; Sachs, 2012, p. 555
d.frm &lt;- data.frame(x=c(28,30,33,35,38,41, 36,39,40,43,45,50, 44,45,47,49,53,54),
                    g=c(rep(LETTERS[1:3], each=6)), stringsAsFactors=TRUE)

NemenyiTest(x~g, d.frm)
</code></pre>

<hr>
<h2 id='Nf'>As Numeric Factor
</h2><span id='topic+Nf'></span>

<h3>Description</h3>

<p>Encode a vector x to a factor and then to a numeric value. It's a simple shortcut for <code>as.numeric(factor(x, ...))</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Nf(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Nf_+3A_x">x</code></td>
<td>
	
<p>a vector of data, usually taking a small number of distinct values.
</p>
</td></tr>
<tr><td><code id="Nf_+3A_...">...</code></td>
<td>
<p>the dots are passed on to <code><a href="base.html#topic+factor">factor</a></code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+N">N</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- LETTERS[10:15]
Nf(x)

# same as ..
as.numeric(factor(x))
</code></pre>

<hr>
<h2 id='NPV'>Short Selection of Financial Mathematical Functions
</h2><span id='topic+NPV'></span><span id='topic+IRR'></span><span id='topic+OPR'></span><span id='topic+NPVFixBond'></span><span id='topic+YTM'></span>

<h3>Description</h3>

<p>Calculate the one period returns, the net present value (<code>NPV()</code>),  the internal rate of return (<code>IRR()</code>) of a sequence of payments. <code>NPVFixBond()</code> returns the netpresent value for a fixed-rate bond, <code>YTM()</code> the yield to maturity for a bond.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OPR(K, D = NULL, log = FALSE)
NPV(i, cf, t = seq(along = cf) - 1)
IRR(cf, t = seq(along = cf) - 1, interval = c(-1.5, 1.5), ...)

NPVFixBond(i, Co, RV, n)
YTM(Co, PP, RV, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NPV_+3A_i">i</code></td>
<td>
<p>the interest rate
</p>
</td></tr>
<tr><td><code id="NPV_+3A_cf">cf</code></td>
<td>
<p>numeric vector with the payments
</p>
</td></tr>
<tr><td><code id="NPV_+3A_t">t</code></td>
<td>
<p>periods
</p>
</td></tr>
<tr><td><code id="NPV_+3A_k">K</code></td>
<td>
<p>the capital at time t</p>
</td></tr>
<tr><td><code id="NPV_+3A_d">D</code></td>
<td>
<p>dividend at time t </p>
</td></tr>
<tr><td><code id="NPV_+3A_log">log</code></td>
<td>
<p>logical, determining if the simple returns (default) or log returns are to be calculated.</p>
</td></tr>
<tr><td><code id="NPV_+3A_interval">interval</code></td>
<td>
<p>a vector containing the end-points of the interval to
be searched for the root in the function <code>IRR</code>.</p>
</td></tr>
<tr><td><code id="NPV_+3A_co">Co</code></td>
<td>
<p>coupon payments of a fixed-rate bond</p>
</td></tr>
<tr><td><code id="NPV_+3A_pp">PP</code></td>
<td>
<p>purchase price for a fixed-rate bond</p>
</td></tr>
<tr><td><code id="NPV_+3A_rv">RV</code></td>
<td>
<p>redemption value</p>
</td></tr>
<tr><td><code id="NPV_+3A_n">n</code></td>
<td>
<p>the term of the bond, total number of periods</p>
</td></tr>
<tr><td><code id="NPV_+3A_...">...</code></td>
<td>
<p>the dots are passed to the <code><a href="#topic+UnirootAll">UnirootAll</a></code> function in <code>IRR</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The one period returns are calculated as
</p>
<p style="text-align: center;"><code class="reqn">r_t = \frac{D_t+K_t-K_t-1}{K_t-1}</code>
</p>



<h3>Value</h3>

<p>a numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gmean">Gmean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># one root
IRR(cf &lt;- c(-900, -250+450-90, 460-100, 500-120, 550-140))
# several IRR solutions
IRR(cf = c(-100, 500, -600))
# no solution
IRR(cf = c(-100, 400, -600))
# negative and huge solution
IRR(cf = c(-100, 1000, -600), interval = c(-1.5, 1000))
</code></pre>

<hr>
<h2 id='OddsRatio'>Odds Ratio Estimation and Confidence Intervals</h2><span id='topic+OddsRatio'></span><span id='topic+OddsRatio.glm'></span><span id='topic+OddsRatio.multinom'></span><span id='topic+OddsRatio.zeroinfl'></span><span id='topic+OddsRatio.default'></span>

<h3>Description</h3>

<p>Calculates odds ratio by unconditional maximum likelihood estimation (<code>wald</code>),
conditional maximum likelihood estimation (<code>mle</code>) or median-unbiased estimation (<code>midp</code>).
Confidence intervals are calculated using normal approximation (<code>wald</code>) and exact methods
(<code>midp</code>, <code>mle</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OddsRatio(x, conf.level = NULL, ...)

## S3 method for class 'glm'
OddsRatio(x, conf.level = NULL, digits = 3, use.profile = TRUE, ...)

## S3 method for class 'multinom'
OddsRatio(x, conf.level = NULL, digits = 3, ...)

## S3 method for class 'zeroinfl'
OddsRatio(x, conf.level = NULL, digits = 3, ...)

## Default S3 method:
OddsRatio(x, conf.level = NULL, y = NULL, method = c("wald", "mle", "midp"),
          interval = c(0, 1000), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OddsRatio_+3A_x">x</code></td>
<td>
<p>a vector or a <code class="reqn">2 \times 2</code> numeric matrix, resp. table.
</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> will be calculated.
</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_digits">digits</code></td>
<td>
<p>the number of fixed digits to be used for printing the odds ratios.</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_method">method</code></td>
<td>

<p>method for calculating odds ratio and confidence intervals. Can be one out of
&quot;<code>wald</code>&quot;, &quot;<code>mle</code>&quot;, &quot;<code>midp</code>&quot;. Default is <code>"wald"</code> (not because it is the best, but
because it is the most commonly used.)
</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level. Default is <code>NA</code> for tables and numeric vectors, meaning no confidence intervals will be reported. 0.95 is used as default for models.</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_interval">interval</code></td>
<td>

<p>interval for the function <code><a href="stats.html#topic+uniroot">uniroot</a></code> that finds the
odds ratio median-unbiased estimate and <code>midp</code> exact confidence
interval.
</p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_use.profile">use.profile</code></td>
<td>
<p>logical. Defines if profile approach should be used, which normally is a good choice. Calculating profile can however take ages for large datasets and not be necessary there. So we can fallback to normal confidence intervals. </p>
</td></tr>
<tr><td><code id="OddsRatio_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set <code>useNA</code>. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a <code class="reqn">2 \times 2</code> table is provided the following table structure is preferred:
</p>
<pre>
                    disease=0   disease=1
    exposed=0 (ref)    n00         n01
    exposed=1          n10         n11
  </pre>
<p>however, for odds ratios the following table is
equivalent:
</p>
<pre>
                    disease=1   disease=0
    exposed=1          n11         n10
    exposed=0          n01         n00
  </pre>
<p>If the table to be  provided to this function is not in the
preferred form, the function <code><a href="#topic+Rev">Rev</a>()</code> can be used to &quot;reverse&quot; the table rows, resp.
-columns. Reversing columns or rows (but not both) will lead to the inverse of the odds ratio.
</p>
<p>In case of zero entries, 0.5 will be added to the table.
</p>


<h3>Value</h3>

<p>a single numeric value if conf.level is set to <code>NA</code><br />
a numeric vector with 3 elements for estimate, lower and upper confidence interval if conf.level is provided
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, strongly based on code from Tomas Aragon, &lt;aragon@berkeley.edu&gt;</p>


<h3>References</h3>

<p>Kenneth J. Rothman and Sander Greenland (1998): <em>Modern Epidemiology</em>,
Lippincott-Raven Publishers
</p>
<p>Kenneth J. Rothman (2002): <em>Epidemiology: An Introduction</em>, Oxford
University Press
</p>
<p>Nicolas P. Jewell (2004): <em>Statistics for Epidemiology</em>, 1st Edition,
2004, Chapman &amp; Hall, pp. 73-81
</p>
<p>Agresti, Alan (2013) <em>Categorical Data Analysis</em>. NY: John Wiley and Sons, Chapt. 3.1.1
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RelRisk">RelRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Case-control study assessing whether exposure to tap water
#   is associated with cryptosporidiosis among AIDS patients

tab &lt;- matrix(c(2, 29, 35, 64, 12, 6), 3, 2, byrow=TRUE)
dimnames(tab) &lt;- list("Tap water exposure" = c("Lowest", "Intermediate", "Highest"),
                      "Outcome" = c("Case", "Control"))
tab &lt;- Rev(tab, margin=2)

OddsRatio(tab[1:2,])
OddsRatio(tab[c(1,3),])

OddsRatio(tab[1:2,], method="mle")
OddsRatio(tab[1:2,], method="midp")
OddsRatio(tab[1:2,], method="wald", conf.level=0.95)

# in case of zeros consider using glm for calculating OR
dp &lt;- data.frame (a=c(20, 7, 0, 0), b=c(0, 0, 0, 12), t=c(1, 0, 1, 0))
fit &lt;- glm(cbind(a, b) ~ t, data=dp, family=binomial)

exp(coef(fit))

# calculation of log oddsratios in a 2x2xk table
migraine &lt;- xtabs(freq ~ .,
                  cbind(expand.grid(treatment=c("active","placebo"),
                                    response=c("better","same"),
                                    gender=c("female","male")),
                        freq=c(16,5,11,20,12,7,16,19))
)

log(apply(migraine, 3, OddsRatio))

# OddsRatio table for logistic regression models
r.glm &lt;- glm(type ~ ., data=MASS::Pima.tr2, family=binomial)
OddsRatio(r.glm)

plot(OddsRatio(r.glm), xlim=c(0.5, 2), main="OddsRatio - glm", pch=NA,
     lblcolor=hred, args.errbars=list(col=horange, pch=21, col.pch=hblue,
     bg.pch=hyellow, cex.pch=1.5))
</code></pre>

<hr>
<h2 id='Order'>Distributions of Order Statistics</h2><span id='topic+dOrder'></span><span id='topic+pOrder'></span><span id='topic+rOrder'></span>

<h3>Description</h3>

<p>Density function, distribution function and random generation for
a selected Order statistic of a given number of independent variables
from a specified distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dOrder(x, densfun, distnfun, ..., distn, mlen = 1, j = 1,
      largest = TRUE, log = FALSE)
pOrder(q, distnfun, ..., distn, mlen = 1, j = 1, largest = TRUE,
      lower.tail = TRUE)
rOrder(n, quantfun, ..., distn, mlen = 1, j = 1, largest = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Order_+3A_x">x</code>, <code id="Order_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="Order_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="Order_+3A_densfun">densfun</code>, <code id="Order_+3A_distnfun">distnfun</code>, <code id="Order_+3A_quantfun">quantfun</code></td>
<td>
<p>Density, distribution and
quantile function of the specified distribution. The density
function must have a <code>log</code> argument (a simple wrapper
can always be constructed to achieve this).</p>
</td></tr>
<tr><td><code id="Order_+3A_...">...</code></td>
<td>
<p>Parameters of the specified distribution.</p>
</td></tr>
<tr><td><code id="Order_+3A_distn">distn</code></td>
<td>
<p>A character string, optionally specified as an
alternative to <code>densfun</code>, <code>distnfun</code> and <code>quantfun</code>
such that the density, distribution and quantile functions are
formed upon the addition of the prefixes <code>d</code>, <code>p</code> and
<code>q</code> respectively.</p>
</td></tr>
<tr><td><code id="Order_+3A_mlen">mlen</code></td>
<td>
<p>The number of independent variables.</p>
</td></tr>
<tr><td><code id="Order_+3A_j">j</code></td>
<td>
<p>The Order statistic, taken as the <code>j</code>th largest
(default) or smallest of <code>mlen</code>, according to the value of
<code>largest</code>.</p>
</td></tr>
<tr><td><code id="Order_+3A_largest">largest</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default) use the <code>j</code>th
largest Order statistic, otherwise use the <code>j</code>th smallest.</p>
</td></tr>
<tr><td><code id="Order_+3A_log">log</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the log density is returned.</p>
</td></tr>
<tr><td><code id="Order_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default) probabilities
are P[X &lt;= x], otherwise  P[X &gt; x].</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dOrder</code> gives the density function, <code>pOrder</code> gives the
distribution function and <code>qOrder</code> gives the quantile function
of a selected Order statistic from a sample of size <code>mlen</code>,
from a specified distibution. <code>rOrder</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Alec Stephenson &lt;alec_stephenson@hotmail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+rExtrVal">rExtrVal</a></code>, <code><a href="#topic+rGenExtrVal">rGenExtrVal</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dOrder(2:4, dnorm, pnorm, mean = 0.5, sd = 1.2, mlen = 5, j = 2)
dOrder(2:4, distn = "norm", mean = 0.5, sd = 1.2, mlen = 5, j = 2)
dOrder(2:4, distn = "exp", mlen = 2, j = 2)
pOrder(2:4, distn = "exp", rate = 1.2, mlen = 2, j = 2)
rOrder(5, qgamma, shape = 1, mlen = 10, j = 2)
</code></pre>

<hr>
<h2 id='ORToRelRisk'> Transform Odds Ratio to Relative Risk </h2><span id='topic+ORToRelRisk'></span><span id='topic+ORToRelRisk.default'></span><span id='topic+ORToRelRisk.OddsRatio'></span>

<h3>Description</h3>

<p>The odds ratio is a common measure when comparing two groups in
terms of an outcome that is either present or absent. As the odds ratio is in general poorly understood, odds ratios are often discussed in terms of risks, relying on the approximation, that odds ratio and relative risk are about the same when the outcome is rare. However the relative risk also depends on the risk of the baseline group and if the outcome is not rare there can be large differences between both measures and the odds ratio may substantially overestimate the relative risk. In fact, the same odds ratio could imply a very different relative risk for subgroups of the population with different baseline risks.
</p>
<p>The present function transforms a given odds-ratio (OR) to the respective relative risk (RR) either for simple odds ratios but also for odds ratios resulting from a logistic model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ORToRelRisk(...)

## S3 method for class 'OddsRatio'
ORToRelRisk(x, ... )
## Default S3 method:
ORToRelRisk(or, p0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ORToRelRisk_+3A_x">x</code></td>
<td>
<p>the odds ratios of a logistic model as returned by <code><a href="#topic+OddsRatio">OddsRatio</a>()</code></p>
</td></tr>
<tr><td><code id="ORToRelRisk_+3A_or">or</code></td>
<td>
<p> numeric vector, containing odds-ratios. </p>
</td></tr>
<tr><td><code id="ORToRelRisk_+3A_p0">p0</code></td>
<td>
<p> numeric vector, incidence of the outcome of interest in the
nonexposed group (&quot;baseline risk&quot;).</p>
</td></tr>
<tr><td><code id="ORToRelRisk_+3A_...">...</code></td>
<td>
<p>further arguments, are not used here.</p>
</td></tr>           
</table>


<h3>Details</h3>

<p>The function transforms a given odds-ratio (or) to the respective
relative risk (rr). It can also be used to transform the limits
of confidence intervals.
</p>
<p>The formula for converting an odds ratio to a relative risk is
</p>
<p style="text-align: center;"><code class="reqn">rr = \frac{or}{1 - p_0 + p_0 \cdot or}</code>
</p>

<p>where <code class="reqn">p_0</code> is the baseline risk.
</p>
<p>For transformation of odds ratios resulting from a logit model, we use the formula of Zhang and Yu (1998).
</p>


<h3>Value</h3>

<p>relative risk.
</p>


<h3>Author(s)</h3>

<p> Matthias Kohl &lt;matthias.kohl@stamats.de&gt;</p>


<h3>References</h3>

<p>Zhang, J. and Yu, K. F. (1998). What's the relative risk? A method of correcting the odds ratio in cohort
studies of common outcomes. <em>JAMA</em>, <b>280</b>(19):1690-1691.
</p>
<p>Grant, R. L. (2014) Converting an odds ratio to a range of plausible relative
risks for better communication of research findings. BMJ 2014;348:f7450 doi: 10.1136/bmj.f7450
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(heart &lt;- as.table(matrix(c(11, 2, 4, 6), nrow=2,
                          dimnames = list(Exposure = c("High", "Low"), 
                                          Response = c("Yes", "No")))))
RelRisk(heart)
# calculated as (11/15)/(2/8)

OddsRatio(heart)
# calculated as (11/4)/(2/6)

ORToRelRisk(OddsRatio(heart), p0 = 2/8)
# Relative risk = odds ratio / (1 - p0 + (p0 * odds ratio))
# where p0 is the baseline risk


## single OR to RR
ORToRelRisk(14.1, 0.05)

## OR and 95% confidence interval
ORToRelRisk(c(14.1, 7.8, 27.5), 0.05)

## Logistic OR and 95% confidence interval
logisticOR &lt;- rbind(c(14.1, 7.8, 27.5),
                    c(8.7, 5.5, 14.3),
                    c(27.4, 17.2, 45.8),
                    c(4.5, 2.7, 7.8),
                    c(0.25, 0.17, 0.37),
                    c(0.09, 0.05, 0.14))
colnames(logisticOR) &lt;- c("OR", "2.5%", "97.5%")
rownames(logisticOR) &lt;- c("7.4", "4.2", "3.0", "2.0", "0.37", "0.14")
logisticOR

## p0
p0 &lt;- c(0.05, 0.12, 0.32, 0.27, 0.40, 0.40)

## Compute corrected RR
## helper function
ORToRelRisk.mat &lt;- function(or, p0){
  res &lt;- matrix(NA, nrow = nrow(or), ncol = ncol(or))
  for(i in seq_len(nrow(or)))
    res[i,] &lt;- ORToRelRisk(or[i,], p0[i])
  dimnames(res) &lt;- dimnames(or)
  res
}
RR &lt;- ORToRelRisk.mat(logisticOR, p0)
round(RR, 2)

## Results are not completely identical to Zhang and Yu (1998)
## what probably is caused by the fact that the logistic OR values
## provided in the table are rounded and not true values.
</code></pre>

<hr>
<h2 id='Outlier'>Outlier</h2><span id='topic+Outlier'></span>

<h3>Description</h3>

<p>Return outliers following Tukey's boxplot and Hampel's median/mad definition.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Outlier(x, method = c("boxplot", "hampel"), value = TRUE,na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Outlier_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="Outlier_+3A_method">method</code></td>
<td>
<p>the method to be used. So far Tukey's boxplot and Hampel's rule are implemented.</p>
</td></tr>
<tr><td><code id="Outlier_+3A_value">value</code></td>
<td>
<p>logical. If <code>FALSE</code>, a vector containing the (integer) indices of the outliers is returned, and if <code>TRUE</code> (default), a vector containing the matching elements themselves is returned.</p>
</td></tr>
<tr><td><code id="Outlier_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Outlier detection is a tricky problem and should be handled with care. We implement Tukey's boxplot rule as a rough idea of spotting extreme values.
</p>
<p>Hampel considers values outside of median +/- 3 * (median absolute deviation) to be outliers.</p>


<h3>Value</h3>

<p>the values of x lying outside the whiskers in a boxplot <br />
or the indices of them </p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>Hampel F. R. (1974) The influence curve and its role in robust estimation, <em>Journal of the American Statistical Association</em>, 69, 382-393</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+boxplot">boxplot</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>Outlier(d.pizza$temperature, na.rm=TRUE)

# it's the same as the result from boxplot
sort(d.pizza$temperature[Outlier(d.pizza$temperature, value=FALSE, na.rm=TRUE)])
b &lt;- boxplot(d.pizza$temperature, plot=FALSE)
sort(b$out)

# nice to find the corresponding rows
d.pizza[Outlier(d.pizza$temperature, value=FALSE, na.rm=TRUE), ]

# compare to Hampel's rule
Outlier(d.pizza$temperature, method="hampel", na.rm=TRUE)


# outliers for the each driver
tapply(d.pizza$temperature, d.pizza$driver, Outlier, na.rm=TRUE)

# the same as:
boxplot(temperature ~ driver, d.pizza)$out
</code></pre>

<hr>
<h2 id='PageTest'>Exact Page Test for Ordered Alternatives</h2><span id='topic+PageTest'></span><span id='topic+PageTest.default'></span><span id='topic+PageTest.formula'></span>

<h3>Description</h3>

<p>Performs a Page test for ordered alternatives using an exact algorithm by Stefan Wellek (1989) 
with unreplicated blocked data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PageTest(y, ...)
  
## Default S3 method:
PageTest(y, groups, blocks, ...)
  
## S3 method for class 'formula'
PageTest(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PageTest_+3A_y">y</code></td>
<td>
<p>either a numeric vector of data values, or a data matrix.</p>
</td></tr>
<tr><td><code id="PageTest_+3A_groups">groups</code></td>
<td>
<p>a vector giving the group for the corresponding
elements of <code>y</code> if this is a vector;  ignored if <code>y</code>
is a matrix.  If not a factor object, it is coerced to one.</p>
</td></tr>
<tr><td><code id="PageTest_+3A_blocks">blocks</code></td>
<td>
<p>a vector giving the block for the corresponding
elements of <code>y</code> if this is a vector;  ignored if <code>y</code>
is a matrix.  If not a factor object, it is coerced to one.</p>
</td></tr>
<tr><td><code id="PageTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>a ~ b | c</code>, where <code>a</code>,
<code>b</code> and <code>c</code> give the data values and corresponding groups
and blocks, respectively.</p>
</td></tr>
<tr><td><code id="PageTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="PageTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="PageTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="PageTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PageTest</code> can be used for analyzing unreplicated complete
block designs (i.e., there is exactly one observation in <code>y</code>
for each combination of levels of <code>groups</code> and <code>blocks</code>)
where the normality assumption may be violated.
</p>
<p>The null hypothesis is that apart from an effect of <code>blocks</code>,
the location parameter of <code>y</code> is the same in each of the
<code>groups</code>.<br />
The implemented alternative is, that the location parameter will be monotonly greater along the groups, <br />
<code class="reqn">H_{A}: \theta_{1} \le \theta_{2} \le \theta_{3}</code> ... (where at least one inequality is strict).<br />
If the other direction is required, the order of the groups has to be reversed.
<br /><br />
The Page test for ordered alternatives is slightly more powerful than
the Friedman analysis of variance by ranks.
</p>
<p>If <code>y</code> is a matrix, <code>groups</code> and <code>blocks</code> are
obtained from the column and row indices, respectively.  <code>NA</code>'s
are not allowed in <code>groups</code> or <code>blocks</code>;  if <code>y</code>
contains <code>NA</code>'s, corresponding blocks are removed.
</p>
<p>For small values of k (methods) or N (data objects), &lsquo;<span class="samp">&#8288;PageTest&#8288;</span>&rsquo; 
will calculate the exact p-values. 
For &lsquo;<span class="samp">&#8288;k, N &gt; 15, Inf&#8288;</span>&rsquo;, a normal 
approximation is returned. Only one of these values will be returned.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the L-statistic with names attribute  &ldquo;L&rdquo;.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string <code>"Page test for ordered alternatives"</code>.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Special thanks to Prof. S. Wellek for porting old GAUSS code to R. </p>


<h3>Author(s)</h3>

<p>Stefan Wellek &lt;stefan.wellek@zi-mannheim.de&gt; (exact p-values), Andri Signorell &lt;andri@signorell.net&gt; (interface) (strongly based on R-Core code) </p>


<h3>References</h3>

<p>Page, E. (1963): Ordered hypotheses for multiple treatments: A significance test for linear ranks. <em>Journal of the American Statistical Association</em>, 58, 216-230.
</p>
<p>Siegel, S. &amp; Castellan, N. J. Jr. (1988): <em>Nonparametric
statistics for the behavioral sciences</em>. Boston, MA: McGraw-Hill.
</p>
<p>Wellek, S. (1989): Computing exact p-values in Page's nonparametric test against trend. <em>Biometrie und Informatik in Medizin und Biologie 20</em>, 163-170 
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+friedman.test">friedman.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Craig's data from Siegel &amp; Castellan, p 186
 soa.mat &lt;- matrix(c(.797,.873,.888,.923,.942,.956,
  .794,.772,.908,.982,.946,.913,
  .838,.801,.853,.951,.883,.837,
  .815,.801,.747,.859,.887,.902), nrow=4, byrow=TRUE)
 PageTest(soa.mat)
 

# Duller, pg. 236 
pers &lt;- matrix(c(
1, 72, 72, 71.5, 69, 70, 69.5, 68, 68, 67, 68,
2, 83, 81, 81, 82, 82.5, 81, 79, 80.5, 80, 81,
3, 95, 92, 91.5, 89, 89, 90.5, 89, 89, 88, 88,
4, 71, 72, 71, 70.5, 70, 71, 71, 70, 69.5, 69,
5, 79, 79, 78.5, 77, 77.5, 78, 77.5, 76, 76.5, 76,
6, 80, 78.5, 78, 77, 77.5, 77, 76, 76, 75.5, 75.5
), nrow=6, byrow=TRUE) 

colnames(pers) &lt;- c("person", paste("week",1:10))

# Alternative: week10 &lt; week9 &lt; week8 ... 
PageTest(pers[, 11:2])


# Sachs, pg. 464

pers &lt;- matrix(c(
  3,2,1,4,
  4,2,3,1,
  4,1,2,3,
  4,2,3,1,
  3,2,1,4,
  4,1,2,3,
  4,3,2,1,
  3,1,2,4,
  3,1,4,2), 
  nrow=9, byrow=TRUE, dimnames=list(1:9, LETTERS[1:4]))  

# Alternative: B &lt; C &lt; D &lt; A
PageTest(pers[, c("B","C","D","A")])


# long shape and formula interface
plng &lt;- data.frame(expand.grid(1:9, c("B","C","D","A")), 
                   as.vector(pers[, c("B","C","D","A")]))
colnames(plng) &lt;- c("block","group","x")

PageTest(plng$x, plng$group, plng$block)

PageTest(x ~ group | block, data = plng)



score &lt;- matrix(c(
  3,4,6,9,
  4,3,7,8,
  3,4,4,6,
  5,6,8,9,
  4,4,9,9,
  6,7,11,10
  ), nrow=6, byrow=TRUE) 

PageTest(score)
</code></pre>

<hr>
<h2 id='PairApply'>Pairwise Calculations
</h2><span id='topic+PairApply'></span>

<h3>Description</h3>

<p>Implements a logic to run pairwise calculations on the columns of a data.frame or a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PairApply(x, FUN = NULL, ..., symmetric = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PairApply_+3A_x">x</code></td>
<td>
<p>a list, a data.frame or a matrix with columns to be processed pairwise.
</p>
</td></tr>
<tr><td><code id="PairApply_+3A_fun">FUN</code></td>
<td>
<p>a function to be calculated. It is assumed, that the first 2 arguments denominate x and y.
</p>
</td></tr>
<tr><td><code id="PairApply_+3A_...">...</code></td>
<td>
<p>the dots are passed to FUN.
</p>
</td></tr>
<tr><td><code id="PairApply_+3A_symmetric">symmetric</code></td>
<td>
<p>logical. Does the function yield the same result for FUN(x, y) and FUN(y, x)? <br />
If <code>TRUE</code> just the lower triangular matrix is calculated and transposed. Default is FALSE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This code is based on the logic of <code>cor()</code> and extended for asymmetric functions.
</p>


<h3>Value</h3>

<p>a matrix with the results of FUN.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+outer">outer</a></code>, <code><a href="#topic+CombPairs">CombPairs</a></code>, <code><a href="stats.html#topic+pairwise.table">pairwise.table</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>PairApply(d.diamonds[,c("colour","clarity","cut","polish")], FUN = CramerV, 
          symmetric=TRUE)

# user defined functions are ok as well
PairApply(d.diamonds[,c("clarity","cut","polish","symmetry")], 
  FUN = function(x,y) wilcox.test(as.numeric(x), as.numeric(y))$p.value, symmetric=TRUE)

# asymetric measure
PairApply(d.diamonds[,c("colour", "clarity", "cut", "polish")], 
  FUN = Lambda, direction = "row")

# ... compare to:
Lambda(x=d.diamonds$colour, y=d.diamonds$clarity, direction="row")  
Lambda(x=d.diamonds$colour, y=d.diamonds$clarity, direction="column")  


# the data.frame
dfrm &lt;- d.diamonds[, c("colour","clarity","cut","polish")]
PairApply(dfrm, FUN = CramerV, symmetric=TRUE)

# the same as matrix (columnwise)
m &lt;- as.matrix(dfrm)
PairApply(m, FUN = CramerV, symmetric=TRUE)

# ... and the list interface
lst &lt;- as.list(dfrm)
PairApply(lst, FUN = CramerV, symmetric=TRUE)
</code></pre>

<hr>
<h2 id='ParseFormula'>Parse a Formula and Create a Model Frame
</h2><span id='topic+ParseFormula'></span>

<h3>Description</h3>

<p>Create a model frame for a formula object, by handling the left hand side the same way
the right hand side is handled in model.frame. Especially variables separated by + are interpreted as separate 
variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParseFormula(formula, data = parent.frame(), drop = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ParseFormula_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;formula&quot; (or one that can be coerced to that class): a symbolic description 
for the variables to be described.
</p>
</td></tr>
<tr><td><code id="ParseFormula_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object coercible by as.data.frame to a data frame) 
containing the variables in the model. If not found in data, the variables are taken from environment(formula), typically the environment from which lm is called.
</p>
</td></tr>
<tr><td><code id="ParseFormula_+3A_drop">drop</code></td>
<td>
<p>if <code>drop</code> is <code>TRUE</code>, unused factor levels are dropped from the result when creating interaction terms. 
The default is to drop all unused factor levels.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is used by <code><a href="#topic+Desc.formula">Desc.formula</a></code> for describing data by groups while remaining flexible for using
<code>I(...)</code> constructions, functions or interaction terms.
</p>


<h3>Value</h3>

<p>a list of 3 elements
</p>
<table>
<tr><td><code>formula</code></td>
<td>
<p>the formula which had to be parsed</p>
</td></tr>
<tr><td><code>lhs</code></td>
<td>
<p>  a list of 3 elements:<br />
mf:  data.frame, the model.frame of the left hand side of the formula<br />
mf.eval: data.frame, the evaluated model.frame of the left hand side of the formula<br />
vars: the names of the evaluated model.frame
</p>
</td></tr>
<tr><td><code>rhs</code></td>
<td>
<p>   a list of 3 elements:<br />
mf:   data.frame, the model.frame of the right hand side of the formula<br />
mf.eval: data.frame, the evaluated model.frame of the right hand side of the formula<br />
vars:  the names of the evaluated model.frame
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p>The functions used to handle formulas: <code><a href="stats.html#topic+model.frame">model.frame</a></code>, <code><a href="stats.html#topic+terms">terms</a></code>, <code><a href="stats.html#topic+formula">formula</a></code> <br />
Used in: <code><a href="#topic+Desc.formula">Desc.formula</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(17)
piz &lt;- d.pizza[sample(nrow(d.pizza),10), c("temperature","price","driver","weekday")]

f1 &lt;- formula(. ~ driver)
f2 &lt;- formula(temperature ~ .)
f3 &lt;- formula(temperature + price ~ .)
f4 &lt;- formula(temperature ~ . - driver)
f5 &lt;- formula(temperature + price ~ driver)
f6 &lt;- formula(temperature + price ~ driver * weekday)
f7 &lt;- formula(I(temperature^2) + sqrt(price) ~ driver + weekday)
f8 &lt;- formula(temperature + price ~ 1)
f9 &lt;- formula(temperature + price ~ driver * weekday - price)

ParseFormula(f1, data=piz)  
ParseFormula(f2, data=piz)  
ParseFormula(f3, data=piz)
ParseFormula(f4, data=piz)
ParseFormula(f5, data=piz)
ParseFormula(f6, data=piz)
ParseFormula(f7, data=piz)
ParseFormula(f8, data=piz)
</code></pre>

<hr>
<h2 id='ParseSASDatalines'>Parse a SAS Dataline Command
</h2><span id='topic+ParseSASDatalines'></span>

<h3>Description</h3>

<p>A parser for simple SAS dataline command texts. A <code>data.frame</code> is being built with the columnnames listed in the input section. The data object will be created in the given environment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParseSASDatalines(x, env = .GlobalEnv, overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ParseSASDatalines_+3A_x">x</code></td>
<td>
<p>the SAS text </p>
</td></tr>
<tr><td><code id="ParseSASDatalines_+3A_env">env</code></td>
<td>
<p>environment in which the dataset should be created.</p>
</td></tr>
<tr><td><code id="ParseSASDatalines_+3A_overwrite">overwrite</code></td>
<td>
<p>logical. If set to TRUE, the function will silently overwrite a potentially existing object in <code>env</code> with the same name as declared in the SAS <code>DATA</code> section. If set to <code>FALSE</code> (default) an error will be raised if there already exists an object with the same name. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The SAS function <code>DATA</code> is designed for quickly creating a dataset from scratch. The whole step  normally consists out of the <code>DATA</code> part defining the name of the dataset, an <code>INPUT</code> line declaring the variables and a <code>DATALINES</code> command followed by the values.<br />
The default delimiter used to separate the different variables is a space (thus each variable should be one word). The $ after the variable name indicates that the variable preceding contain character values and not numeric values. Without specific instructions, SAS assumes that variables are numeric. The function will fail, if it encounters a character in the place of an expected numeric value.<br />
Each new row in datalines will create a corresponding unique row in the dataset. Notice that a ; is not needed after every row, rather it is included at the end of the entire data step.
</p>
<p>More complex command structures, i.e. other delimiters (dlm), in the <code>INPUT</code>-section are not (yet) supported.
</p>


<h3>Value</h3>

<p>a data.frame</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+scan">scan</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- "
DATA asurvey;
INPUT id sex $ age inc r1 r2 r3 ;
DATALINES;
1   F  35 17  7 2 2
17  M  50 14  5 5 3
33  F  45  6  7 2 7
49  M  24 14  7 5 7
65  F  52  9  4 7 7
81  M  44 11  7 7 7
2   F  34 17  6 5 3
18  M  40 14  7 5 2
34  F  47  6  6 5 6
50  M  35 17  5 7 5
;
"

(d.frm &lt;- ParseSASDatalines(txt))
</code></pre>

<hr>
<h2 id='PasswordDlg'>Password Dialog
</h2><span id='topic+PasswordDlg'></span>

<h3>Description</h3>

<p>Brings up a tcltk dialog centered on the screen, designed for entering passwords while displaying only ****.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PasswordDlg(option_txt = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PasswordDlg_+3A_option_txt">option_txt</code></td>
<td>
<p>an optional text, if it is defined, there will be a checkbox added to the dialog with the label being set with <code>option_txt</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the entered password<br />
the status of the optional checkbox will be returned as attribute: 
<code>attr(pw, "option")</code>
</p>


<h3>Author(s)</h3>

<p>Markus Naepflin &lt;markus@naepfl.in&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pw &lt;- PasswordDlg()
pw
## End(Not run)
</code></pre>

<hr>
<h2 id='PDFManual'>Get PDF Manual of a Package From CRAN
</h2><span id='topic+PDFManual'></span>

<h3>Description</h3>

<p>PDF versions of the manual are usually not included as vignettes in R packages. Still this format is convenient for reading and doing full text search. <br /> This function creates the appropriate link to the pdf file on CRAN and opens the pdf manual in a browser window.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PDFManual(package)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PDFManual_+3A_package">package</code></td>
<td>
<p>name of the package.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
PDFManual(DescTools)

## End(Not run)
</code></pre>

<hr>
<h2 id='PearsonTest'>Pearson Chi-Square Test for Normality</h2><span id='topic+PearsonTest'></span>

<h3>Description</h3>

<p>Performs the Pearson chi-square test for the composite hypothesis of normality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PearsonTest(x, n.classes = ceiling(2 * (n^(2/5))), adjust = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PearsonTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values. Missing values are allowed.</p>
</td></tr>
<tr><td><code id="PearsonTest_+3A_n.classes">n.classes</code></td>
<td>
<p>The number of classes. The default is due to Moore (1986).</p>
</td></tr>
<tr><td><code id="PearsonTest_+3A_adjust">adjust</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), the p-value is computed from
a chi-square distribution with <code>n.classes</code>-3 degrees of freedom, otherwise
from a chi-square distribution with <code>n.classes</code>-1 degrees of freedom.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Pearson test statistic is <code class="reqn">P=\sum (C_{i} - E_{i})^{2}/E_{i}</code>,
where <code class="reqn">C_{i}</code> is the number of counted and <code class="reqn">E_{i}</code> is the number of expected observations
(under the hypothesis) in class <code class="reqn">i</code>. The classes are build is such a way that they are equiprobable under the hypothesis
of normality. The p-value is computed from a chi-square distribution with <code>n.classes</code>-3 degrees of freedom
if <code>adjust</code> is <code>TRUE</code> and from a chi-square distribution with <code>n.classes</code>-1
degrees of freedom otherwise. In both cases this is not (!) the correct p-value,
lying somewhere between the two, see also Moore (1986).
</p>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Pearson chi-square statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Pearson chi-square normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
<tr><td><code>n.classes</code></td>
<td>
<p>the number of classes used for the test.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the degress of freedom of the chi-square distribution used to compute the p-value.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Pearson chi-square test is usually not recommended for testing the composite hypothesis of normality
due to its inferior power properties compared to other tests. It is common practice to compute the p-value
from the chi-square distribution with <code>n.classes</code> - 3 degrees of freedom, in order to adjust for the
additional estimation of two parameters. (For the simple hypothesis of normality (mean and variance known)
the test statistic is asymptotically chi-square distributed with
<code>n.classes</code> - 1 degrees of freedom.)
This is, however, not correct as long as the parameters are estimated by <code>mean(x)</code> and <code>var(x)</code>
(or <code>sd(x)</code>), as it is usually done, see Moore (1986) for details.
Since the true p-value is somewhere between the two, it is suggested to run <code>PearsonTest</code> twice, with
<code>adjust = TRUE</code> (default) and with <code>adjust = FALSE</code>.
It is also suggested to slightly change the default number of classes, in order
to see the effect on the p-value. Eventually, it is suggested not to rely upon the result of the test.
</p>
<p>The function call <code>PearsonTest(x)</code> essentially produces
the same result as the S-PLUS function call <code>chisq.gof((x-mean(x))/sqrt(var(x)), n.param.est=2)</code>.
</p>


<h3>Author(s)</h3>

<p>Juergen Gross &lt;gross@statistik.uni-dortmund.de&gt;</p>


<h3>References</h3>

<p>Moore, D.S., (1986) Tests of the chi-squared type. In:
D'Agostino, R.B. and Stephens, M.A., eds.: <em>Goodness-of-Fit Techniques</em>.
Marcel Dekker, New York.
</p>
<p>Thode Jr., H.C., (2002) <em>Testing for  Normality</em>. Marcel Dekker, New York. Sec. 5.2
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality.
<code><a href="#topic+AndersonDarlingTest">AndersonDarlingTest</a></code>, <code><a href="#topic+CramerVonMisesTest">CramerVonMisesTest</a></code>,
<code><a href="#topic+LillieTest">LillieTest</a></code>, <code><a href="#topic+ShapiroFranciaTest">ShapiroFranciaTest</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>PearsonTest(rnorm(100, mean = 5, sd = 3))
PearsonTest(runif(100, min = 2, max = 4))
</code></pre>

<hr>
<h2 id='PercentRank'>Percent Ranks
</h2><span id='topic+PercentRank'></span>

<h3>Description</h3>

<p><code>PercentRank()</code> takes a vector <code>x</code> and returns the percentile that elements of <code>x</code> correspond to.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PercentRank(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PercentRank_+3A_x">x</code></td>
<td>
<p>a numeric, complex, character or logical vector.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of the same length as <code>x</code> with names copied from <code>x</code> (unless <code>na.last = NA</code>, when missing values are removed). The vector is of integer type unless <code>x</code> is a long vector.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rank">Rank</a></code>, <code><a href="base.html#topic+rank">rank</a></code>, <code><a href="base.html#topic+factor">factor</a></code>, <code><a href="base.html#topic+order">order</a></code>, <code><a href="base.html#topic+sort">sort</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(r1 &lt;- rank(x1 &lt;- c(3, 1, 4, 15, 92)))

x2 &lt;- c(3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5)
names(x2) &lt;- letters[1:11]
(r2 &lt;- rank(x2))        # ties are averaged

PercentRank(x2)
</code></pre>

<hr>
<h2 id='PercTable'>Percentage Table
</h2><span id='topic+PercTable'></span><span id='topic+PercTable.default'></span><span id='topic+PercTable.table'></span><span id='topic+PercTable.formula'></span><span id='topic+PercTable.matrix'></span><span id='topic+Margins'></span><span id='topic+print.PercTable'></span>

<h3>Description</h3>

<p>Prints a 2-way contingency table along with percentages, marginal, and conditional distributions.
All the frequencies are nested into one single table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## Default S3 method:
PercTable(x, y = NULL, ...)

## S3 method for class 'table'
PercTable(tab, row.vars = NULL, col.vars = NULL, justify = "right",
          freq = TRUE, rfrq = "100", expected = FALSE, residuals = FALSE,
          stdres = FALSE, margins = NULL, digits = NULL, ...)

## S3 method for class 'formula'
PercTable(formula, data, subset, na.action, ...)

## S3 method for class 'PercTable'
print(x, vsep = NULL, ...)

Margins(tab, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PercTable_+3A_x">x</code>, <code id="PercTable_+3A_y">y</code></td>
<td>
<p>objects which can be interpreted as factors (including character strings).
x and y will be tabulated via <code>table(x, y)</code>.<br />
If x is a matrix, it will be coerced to a table via as.table(x).
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_tab">tab</code></td>
<td>
<p>a r x c-contingency table
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_row.vars">row.vars</code></td>
<td>
<p>a vector of row variables (see Details).
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_col.vars">col.vars</code></td>
<td>
<p>a vector of column variables (see Details). If this is left to <code>NULL</code> the table structure will be preserved.
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_justify">justify</code></td>
<td>
<p>either <code>"left"</code> or <code>"right"</code> for defining the alignment of the table cells.
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_freq">freq</code></td>
<td>
<p>boolean. Should absolute frequencies be included? Defaults to TRUE.
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_rfrq">rfrq</code></td>
<td>
<p>a string with 3 characters, each of them being 1 or 0. The first position means total percentages,
the second means row percentages and the third column percentages. &quot;011&quot; produces a table output with row and column percentages.
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_expected">expected</code></td>
<td>
<p>the expected counts under the null hypothesis.
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_residuals">residuals</code></td>
<td>
<p>the Pearson residuals, (observed - expected) / sqrt(expected).
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_stdres">stdres</code></td>
<td>
<p>standardized residuals, (observed - expected) / sqrt(V), where V is the residual cell variance
(for the case where x is a matrix, n * p * (1 - p) otherwise).
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_margins">margins</code></td>
<td>
<p>a vector, consisting out of 1 and/or 2. Defines the margin sums to be included.
1 stands for row margins, 2 for column margins, c(1,2) for both. Default is <code>NULL</code> (none).
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_digits">digits</code></td>
<td>
<p>integer. With how many digits shoud the relative frequencies be formatted? Default can be set by <code>DescToolsOptions(digits=x)</code>. </p>
</td></tr>
<tr><td><code id="PercTable_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> will be tabled versus rhs (<code>table(lhs, rhs)</code>).</p>
</td></tr>
<tr><td><code id="PercTable_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="PercTable_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="PercTable_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="PercTable_+3A_vsep">vsep</code></td>
<td>
<p>logical, defining if an empty row should be introduced between the table rows. Default is FALSE, if only a table with one single description (either frequencies or percents) should be returned and <code>TRUE</code> in any other case.
</p>
</td></tr>
<tr><td><code id="PercTable_+3A_...">...</code></td>
<td>
<p>the dots are passed from <code>PercTable.default()</code> to <code>PercTable.table()</code> and from <code>Margins</code> to the function <code><a href="#topic+Freq">Freq</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PercTable prints a 2-dimensional table. The absolute and relative frequencies are nested into one flat table by means of <code>ftable</code>.
<code>row.vars</code>, resp. <code>col.vars</code>  can be used to define the structure of the table. <code>row.vars</code> can either be the names of
the dimensions (included percentages are named <code>"idx"</code>) or numbers (1:3, where 1 is the first dimension of the table,
2 the second and 3 the percentages). <br />
Use <code>Sort()</code> if you want to have your table sorted by rows.<br /><br />
The style in which numbers are formatted is selected by
<code><a href="#topic+Fmt">Fmt</a>()</code> from the DescTools options.
Absolute frequencies will use <code>Fmt("abs")</code> and <code>Fmt("per")</code> will do it for the percentages. The options can be changed with <code>Fmt(abs=as.fmt(...))</code> which is basically a <code>"fmt"</code>-object containing any format information used in <code><a href="#topic+Format">Format</a></code>.
</p>
<p><code>Margins()</code> returns a list containing all the one dimensional margin tables of a n-dimensional table along the given dimensions. It uses <code><a href="base.html#topic+margin.table">margin.table</a>()</code> for all the dimensions and adds the appropriate percentages.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>"ftable"</code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, Alan (2007) <em>Introduction to categorical data analysis</em>. NY: John Wiley and Sons, Section 2.4.5<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Freq">Freq</a></code>, <code><a href="base.html#topic+table">table</a></code>, <code><a href="stats.html#topic+ftable">ftable</a></code>, <code><a href="base.html#topic+prop.table">prop.table</a></code>, <code><a href="stats.html#topic+addmargins">addmargins</a></code>, <code><a href="#topic+DescToolsOptions">DescToolsOptions</a></code>, <code><a href="#topic+Fmt">Fmt</a></code><br />
There are similar functions in package <span class="pkg">sfsmisc</span> <code><a href="sfsmisc.html#topic+printTable2">printTable2</a></code> and package <span class="pkg">vcd</span> <code><a href="vcd.html#topic+table2d_summary">table2d_summary</a></code>, both
lacking some of the flexibility we needed here. <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- table(driver=d.pizza$driver, area=d.pizza$area)

PercTable(tab=tab, col.vars=2)

PercTable(tab=tab, col.vars=2, margins=c(1,2))
PercTable(tab=tab, col.vars=2, margins=2)
PercTable(tab=tab, col.vars=2, margins=1)
PercTable(tab=tab, col.vars=2, margins=NULL)

PercTable(tab=tab, col.vars=2, rfrq="000")

# just the percentages without absolute values
PercTable(tab=tab, col.vars=2, rfrq="110", freq=FALSE)

# just the row percentages in percent format (pfmt = TRUE)
PercTable(tab, freq= FALSE, rfrq="010", pfmt=TRUE, digits=1)

# just the expected frequencies and the standard residuals
PercTable(tab=tab, rfrq="000", expected = TRUE, stdres = TRUE)


# rearrange output such that freq are inserted as columns instead of rows
PercTable(tab=tab, col.vars=c(3,2), rfrq="111")

# putting the areas in rows
PercTable(tab=tab, col.vars=c(3,1), rfrq="100", margins=c(1,2))

# formula interface with subset
PercTable(driver ~ area, data=d.pizza, subset=wine_delivered==0)

# sort the table by rows, order first column (Zurich), then third, then row.names (0)
PercTable(tab=Sort(tab, ord=c(1,3,0)))

# reverse the row variables, so that absolute frequencies and percents
# are not nested together
PercTable(tab, row.vars=c(3, 1))

# the vector interface
PercTable(x=d.pizza$driver, y=d.pizza$area)
PercTable(x=d.pizza$driver, y=d.pizza$area, margins=c(1,2), rfrq="000", useNA="ifany")

# one dimensional x falls back to the function Freq()
PercTable(x=d.pizza$driver)

# the margin tables
Margins(Titanic)

</code></pre>

<hr>
<h2 id='Permn'>Number and Samples for Permutations or Combinations of a Set
</h2><span id='topic+Permn'></span><span id='topic+CombSet'></span><span id='topic+CombN'></span>

<h3>Description</h3>

<p> Return the set of permutations for a given set of values.
The values can be numeric values, characters or factors. <code>CombN</code> computes the number of combinations with and without replacement and order, whereas <code>CombSet</code> returns the value sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Permn(x, sort = FALSE)

CombN(n, m, repl = FALSE, ord = FALSE)
CombSet(x, m, repl = FALSE, ord = FALSE, as.list = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Permn_+3A_x">x</code></td>
<td>
<p>a vector of numeric values or characters. Characters need not be unique.
</p>
</td></tr>
<tr><td><code id="Permn_+3A_n">n</code></td>
<td>
<p>number of elements from which to choose.</p>
</td></tr>
<tr><td><code id="Permn_+3A_m">m</code></td>
<td>
<p>number of elements to choose. For <code>CombSet</code> can <code>m</code> be a numeric vector too.</p>
</td></tr>
<tr><td><code id="Permn_+3A_repl">repl</code></td>
<td>
<p>logical. Should repetition of the same element be allowed? Defaults to FALSE</p>
</td></tr>
<tr><td><code id="Permn_+3A_ord">ord</code></td>
<td>
<p>logical. Does the order matter? Default is FALSE.</p>
</td></tr>
<tr><td><code id="Permn_+3A_sort">sort</code></td>
<td>
<p>logical, defining if the result set should be sorted. Default is FALSE.
</p>
</td></tr>
<tr><td><code id="Permn_+3A_as.list">as.list</code></td>
<td>
<p>logical, defining if the results should be returned in a flat list, say every sample is a single element of the resulting list. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector x need not contain unique values. The permutations will
automatically be filtered for unique sets, if the same element is given twice or more.</p>


<h3>Value</h3>

<p>a matrix with all possible permutations or combinations of the values in x for <code>Permn</code> and <code>CombSet</code><br />
if m contains more than one element the result will be a list of matrices or a flat list if <code>as.list</code> is set to <code>TRUE</code>
<br />
an integer value for <code>CombN</code>
</p>


<h3>Author(s)</h3>

<p>Friederich Leisch &lt;Friedrich.Leisch@boku.ac.at&gt;<br /> Andri Signorell &lt;andri@signorell.net&gt; (CombSet, CombN)
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+combn">combn</a></code>, <code><a href="base.html#topic+choose">choose</a></code>, <code><a href="base.html#topic+factorial">factorial</a></code>, <code><a href="#topic+CombPairs">CombPairs</a></code><br />
<code>vignette("Combinatorics")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Permn(letters[2:5])
Permn(2:5)

# containing the same element more than once
Permn(c("a", "b", "c", "a"))


# only combinations of 2, but in every possible order
x &lt;- letters[1:4]
n &lt;- length(x)
m &lt;- 2

# the samples
CombSet(x, m, repl=TRUE, ord=FALSE)
CombSet(x, m, repl=TRUE, ord=TRUE)
CombSet(x, m, repl=FALSE, ord=TRUE)
CombSet(x, m, repl=FALSE, ord=FALSE)

# the number of the samples
CombN(n, m, repl=TRUE, ord=FALSE)
CombN(n, m, repl=TRUE, ord=TRUE)
CombN(n, m, repl=FALSE, ord=TRUE)
CombN(n, m, repl=FALSE, ord=FALSE)

# build all subsets of length 1, 3 and 5 and return a flat list
x &lt;- letters[1:5]
CombSet(x=x, m=c(1, 3, 5), as.list=TRUE)

</code></pre>

<hr>
<h2 id='Phrase'>Phrasing Results of t-Test
</h2><span id='topic+Phrase'></span>

<h3>Description</h3>

<p>Formulating the results of a comparison of means is quite common. This function assembles a descriptive text about the results of a t-test, describing group sizes, means, p-values and confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Phrase(x, g, glabels = NULL, xname = NULL, unit = NULL, lang = "engl", na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Phrase_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="Phrase_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the corresponding elements of x. The number of levels must equal 2.
</p>
</td></tr>
<tr><td><code id="Phrase_+3A_glabels">glabels</code></td>
<td>
<p>the labels of the two groups, if left to NULL, the levels will be used.
</p>
</td></tr>
<tr><td><code id="Phrase_+3A_xname">xname</code></td>
<td>
<p>the name of the variable to be used in the text.
</p>
</td></tr>
<tr><td><code id="Phrase_+3A_unit">unit</code></td>
<td>
<p>an optional unit for be appended to the numeric results.
</p>
</td></tr>
<tr><td><code id="Phrase_+3A_lang">lang</code></td>
<td>
<p>the language to be used. Only english (default) and german implemented (so far).
</p>
</td></tr>
<tr><td><code id="Phrase_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, should <code>NA</code>s be omitted? Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a text
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("cats", package = "MASS")
cat(Phrase(cats$Bwt, cats$Sex, xname="weight", unit="grams", glabels=c("female", "male")))

# oder auf deutsch
cat(Phrase(cats$Bwt, cats$Sex, xname="Geburtsgewicht",
           glabels=c("weiblich", "maennlich"), lang="german"))
</code></pre>

<hr>
<h2 id='PlotACF'>Combined Plot of a Time Series and Its ACF and PACF
</h2><span id='topic+PlotACF'></span><span id='topic+PlotGACF'></span>

<h3>Description</h3>

<p>Combined plot of a time Series and its autocorrelation and partial autocorrelation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotACF(series, lag.max = 10 * log10(length(series)), main = NULL, cex = NULL, ...)
PlotGACF(series, lag.max = 10 * log10(length(series)), type = "cor", ylab = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotACF_+3A_series">series</code></td>
<td>
<p>univariate time series.
</p>
</td></tr>
<tr><td><code id="PlotACF_+3A_lag.max">lag.max</code></td>
<td>
<p>integer. Defines the number of lags to be displayed. The default
is 10 * log10(length(series)).
</p>
</td></tr>
<tr><td><code id="PlotACF_+3A_main">main</code></td>
<td>
<p>an overall title for the plot</p>
</td></tr>
<tr><td><code id="PlotACF_+3A_cex">cex</code></td>
<td>
<p> numerical value giving the amount by which plotting text and symbols should be magnified relative to the default. </p>
</td></tr>
<tr><td><code id="PlotACF_+3A_type">type</code></td>
<td>
<p>character string giving the type of acf to be computed. Allowed values are <code>"cor"</code> (the default), <code>"cov"</code> or <code>"part"</code> for autocorrelation, covariance or partial correlation.
</p>
</td></tr>
<tr><td><code id="PlotACF_+3A_ylab">ylab</code></td>
<td>
<p>a title for the y axis: see <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotACF_+3A_...">...</code></td>
<td>
<p>the dots are passed to the plot command.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PlotACF plots a combination of the time series and its autocorrelation and partial autocorrelation. PlotGACF is used as
subfunction to produce the acf- and pacf-plots.
</p>


<h3>Author(s)</h3>

<p>Markus Huerzeler (ETH Zurich), some minor modifications Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotACF(AirPassengers)
</code></pre>

<hr>
<h2 id='PlotArea'>Create an Area Plot
</h2><span id='topic+PlotArea'></span><span id='topic+PlotArea.default'></span><span id='topic+PlotArea.formula'></span>

<h3>Description</h3>

<p>Produce a stacked area plot, or add polygons to an existing plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
PlotArea(x, y = NULL, prop = FALSE, add = FALSE, xlab = NULL,
         ylab = NULL, col = NULL, frame.plot = FALSE, ...)

## S3 method for class 'formula'
PlotArea(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotArea_+3A_x">x</code></td>
<td>
<p>numeric vector of x values, or if <code>y=NULL</code> a numeric
vector of y values. Can also be a 1-dimensional table (x values in
names, y values in array), matrix or 2-dimensional table (x values
in row names and y values in columns), a data frame (x values in
first column and y values in subsequent columns), or a time-series
object of class <code>ts/mts</code>.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_y">y</code></td>
<td>
<p>numeric vector of y values, or a matrix containing y values
in columns.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_prop">prop</code></td>
<td>
<p>whether data should be plotted as proportions, so stacked
areas equal 1.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_add">add</code></td>
<td>

<p>whether polygons should be added to an existing plot.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_xlab">xlab</code></td>
<td>
<p>label for x axis.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_ylab">ylab</code></td>
<td>
<p>label for y axis.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_col">col</code></td>
<td>
<p>fill color of polygon(s). The default is a vector of gray
colors.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_frame.plot">frame.plot</code></td>
<td>

<p>a logical indicating whether a box should be drawn around the plot.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code>, such as <code>y ~ x</code> or
<code>cbind(y1, y2) ~ x</code>, specifying x and y values. A dot on the
left-hand side, <code>formula = . ~ x</code>, means all variables except
the one specified on the right-hand side.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_data">data</code></td>
<td>
<p>a data frame (or list) from which the variables in
<code>formula</code> should be taken.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_subset">subset</code></td>
<td>

<p>an optional vector specifying a subset of observations
to be used.
</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain <code>NA</code> values. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="PlotArea_+3A_...">...</code></td>
<td>
<p>further arguments are passed to <code>matplot</code> and
<code>polygon</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of cumulative sums that was used for plotting.
</p>


<h3>Author(s)</h3>

<p>Arni Magnusson &lt;thisisarni@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+barplot">barplot</a></code>, <code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="areaplot.html#topic+areaplot">areaplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># PlotArea with stapled areas
tab &lt;- table( d.pizza$date, d.pizza$driver )
PlotArea(x=as.Date(rownames(tab)), y=tab, xaxt="n", xlab="Date", ylab="Pizzas delivered" )

# add x-axis and some text labels
xrng &lt;- pretty(range(as.Date(rownames(tab))))
axis(side=1, at=xrng, labels=xrng)
text( x=min(d.pizza$date + .5, na.rm=TRUE), y=cumsum(tab[2,])-2.5, label=levels(d.pizza$driver),
  adj=c(0,0.5), col=TextContrastColor(gray.colors(7)))


# formula
PlotArea(Armed.Forces~Year, data=longley)
PlotArea(cbind(Armed.Forces,Unemployed)~Year, data=longley)

# add=TRUE
plot(1940:1970, 500*runif(31), ylim=c(0,500))
PlotArea(Armed.Forces~Year, data=longley, add=TRUE)

# matrix
PlotArea(WorldPhones)
PlotArea(WorldPhones, prop=TRUE, col=rainbow(10))

# table
PlotArea(table(d.pizza$weekday))
PlotArea(table(d.pizza$weekday, d.pizza$driver))

# ts/mts
PlotArea(austres)
PlotArea(Seatbelts[,c("drivers","front","rear")],
         ylab="Killed or seriously injured")
abline(v=1983+1/12, lty=3)
</code></pre>

<hr>
<h2 id='PlotBag'>Bivariate Boxplot </h2><span id='topic+PlotBag'></span><span id='topic+PlotBagPairs'></span><span id='topic+compute.bagplot'></span><span id='topic+plot.bagplot'></span>

<h3>Description</h3>

<p><code>PlotBag()</code> creates a twodimensional boxplot called &quot;bagplot&quot; based on two numerical variables x and y. <code>plot.PlotBag()</code> is the plotting routine for a bagplot object. <code>compute.PlotBag()</code> contains the computation logic the object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotBag(x, y, factor = 3, na.rm = FALSE, approx.limit = 300,
        show.outlier = TRUE, show.whiskers = TRUE,
        show.looppoints = TRUE, show.bagpoints = TRUE,
        show.loophull = TRUE, show.baghull = TRUE,
        create.plot = TRUE, add = FALSE, pch = 16, cex = 0.4,
        dkmethod = 2, precision = 1, verbose = FALSE,
        debug.plots = "no",   col.loophull = "#aaccff",
        col.looppoints = "#3355ff", col.baghull = "#7799ff",
        col.bagpoints = "#000088", transparency = FALSE, ...
)
PlotBagPairs(dm, trim = 0.0, main, numeric.only = TRUE,
             factor = 3, approx.limit = 300, pch = 16,
             cex = 0.8, precision = 1, col.loophull = "#aaccff",
             col.looppoints = "#3355ff", col.baghull = "#7799ff",
             col.bagpoints = "#000088", ...)

compute.bagplot(x, y, factor = 3, na.rm = FALSE, approx.limit = 300,
                dkmethod = 2, precision = 1, verbose = FALSE, debug.plots = "no" )

## S3 method for class 'bagplot'
plot(x, show.outlier = TRUE, show.whiskers = TRUE,
     show.looppoints = TRUE, show.bagpoints = TRUE,
     show.loophull = TRUE, show.baghull = TRUE, add = FALSE,
     pch = 16, cex = .4, verbose = FALSE, col.loophull = "#aaccff",
     col.looppoints = "#3355ff", col.baghull = "#7799ff",
     col.bagpoints = "#000088", transparency = FALSE,...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotBag_+3A_x">x</code></td>
<td>
<p> x values of a data set;
in <code>PlotBag</code>: an object of class <code>PlotBag</code>
computed by <code>compute.PlotBag</code> </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_y">y</code></td>
<td>
<p> y values of the data set </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_factor">factor</code></td>
<td>
<p> factor defining the loop </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_na.rm">na.rm</code></td>
<td>
<p> if <code>TRUE</code> 'NA' values are removed otherwise exchanged by median</p>
</td></tr>
<tr><td><code id="PlotBag_+3A_approx.limit">approx.limit</code></td>
<td>
<p> if the number of data points exceeds
<code>approx.limit</code> a sample is used to compute
some of the quantities; default: 300 </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_show.outlier">show.outlier</code></td>
<td>
<p> if <code>TRUE</code> outlier are shown </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_show.whiskers">show.whiskers</code></td>
<td>
<p> if <code>TRUE</code> whiskers are shown </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_show.looppoints">show.looppoints</code></td>
<td>
<p> if <code>TRUE</code> loop points are plottet </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_show.bagpoints">show.bagpoints</code></td>
<td>
<p> if <code>TRUE</code> bag points are plottet </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_show.loophull">show.loophull</code></td>
<td>
<p> if <code>TRUE</code> the loop is plotted </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_show.baghull">show.baghull</code></td>
<td>
<p> if <code>TRUE</code> the bag is plotted </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_create.plot">create.plot</code></td>
<td>
<p> if <code>FALSE</code> no plot is created </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_add">add</code></td>
<td>
<p> if <code>TRUE</code> the bagplot is added to an existing plot </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_pch">pch</code></td>
<td>
<p> sets the plotting character </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_cex">cex</code></td>
<td>
<p> sets characters size</p>
</td></tr>
<tr><td><code id="PlotBag_+3A_dkmethod">dkmethod</code></td>
<td>
<p> 1 or 2, there are two method of
approximating the bag, method 1 is very rough (only based on observations </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_precision">precision</code></td>
<td>
<p> precision of approximation, default: 1 </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_verbose">verbose</code></td>
<td>
<p> automatic commenting of calculations </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_debug.plots">debug.plots</code></td>
<td>
<p> if <code>TRUE</code> additional plots describing
intermediate results are constructed </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_col.loophull">col.loophull</code></td>
<td>
<p> color of loop hull </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_col.looppoints">col.looppoints</code></td>
<td>
<p> color of the points of the loop </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_col.baghull">col.baghull</code></td>
<td>
<p> color of bag hull </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_col.bagpoints">col.bagpoints</code></td>
<td>
<p> color of the points of the bag </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_transparency">transparency</code></td>
<td>
<p> see section details </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_dm">dm</code></td>
<td>
<p> x </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_trim">trim</code></td>
<td>
<p> x </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_main">main</code></td>
<td>
<p> x </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_numeric.only">numeric.only</code></td>
<td>
<p> x </p>
</td></tr>
<tr><td><code id="PlotBag_+3A_...">...</code></td>
<td>
<p> additional graphical parameters </p>
</td></tr>
</table>


<h3>Details</h3>

<p>A bagplot is a bivariate generalization of the well known
boxplot. It has been proposed by Rousseeuw, Ruts, and Tukey.
In the bivariate case the box of the boxplot changes to a
convex polygon, the bag of bagplot. In the bag are 50 percent
of all points. The fence separates points within the fence from
points outside. It is computed by increasing the
the bag. The loop is defined as the convex hull containing
all points inside the fence.
If all points are on a straight line you get a classical
boxplot.
<code>PlotBag()</code> plots bagplots that are very similar
to the one described in Rousseeuw et al.
Remarks:
The two dimensional median is approximated.
For large data sets the error will be very small.
On the other hand it is not very wise to make a (graphical)
summary of e.g. 10 bivariate data points.
</p>
<p>In case you want to plot multiple (overlapping) bagplots,
you may want plots that are semi-transparent. For this
you can use the <code>transparency</code> flag.
If <code>transparency==TRUE</code> the alpha layer is set to '99' (hex).
This causes the bagplots to appear semi-transparent,
but ONLY if the output device is PDF and opened using:
<code>pdf(file="filename.pdf", version="1.4")</code>.
For this reason, the default is <code>transparency==FALSE</code>.
This feature as well as the arguments
to specify different colors has been proposed by Wouter Meuleman.
</p>


<h3>Value</h3>

<p><code>compute.bagplot</code> returns an object of class
<code>bagplot</code> that could be plotted by
<code>plot.bagplot()</code>.
An object of the bagplot class is a list with the following
elements: <code>center</code> is a two dimensional vector with
the coordinates of the center. <code>hull.center</code> is a
two column matrix, the rows are the coordinates of the
corners of the center region. <code>hull.bag</code> and
<code>hull.loop</code> contain the coordinates of the hull of the bag
and the hull of the loop. <code>pxy.bag</code> shows you the
coordinates of the points of the bag. <code>pxy.outer</code> is
the two column matrix of the points that are within the
fence. <code>pxy.outlier</code> represent the outliers. The vector
<code>hdepths</code> shows the depths of data points. <code>is.one.dim</code>
is <code>TRUE</code> if the data set is (nearly) one dimensional.
The dimensionality is decided by analysing the result of <code>prcomp</code>
which is stored in the element <code>prdata</code>. <code>xy</code> shows you
the data that are used for the bagplot. In the case of very large
data sets subsets of the data are used for constructing the
bagplot. A data set is very large if there are more data points
than <code>approx.limit</code>. <code>xydata</code> are the input data structured
in a two column matrix.
</p>


<h3>Note</h3>

<p>Version of bagplot: 10/2012 </p>


<h3>Author(s)</h3>

<p>Hans Peter Wolf &lt;pwolf@wiwi.uni-bielefeld.de&gt; </p>


<h3>References</h3>

<p> P. J. Rousseeuw, I. Ruts, J. W. Tukey (1999):
The bagplot: a bivariate boxplot, <em>The American
Statistician</em>, vol. 53, no. 4, 382&ndash;387 </p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+boxplot">boxplot</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># example: 100 random points and one outlier
dat &lt;- cbind(rnorm(100) + 100, rnorm(100) + 300)
dat &lt;- rbind(dat, c(105,295))

PlotBag(dat,factor=2.5,create.plot=TRUE,approx.limit=300,
   show.outlier=TRUE,show.looppoints=TRUE,
   show.bagpoints=TRUE,dkmethod=2,
   show.whiskers=TRUE,show.loophull=TRUE,
   show.baghull=TRUE,verbose=FALSE)

# example of Rousseeuw et al., see R-package rpart
cardata &lt;- structure(as.integer( c(2560,2345,1845,2260,2440,
 2285, 2275, 2350, 2295, 1900, 2390, 2075, 2330, 3320, 2885,
 3310, 2695, 2170, 2710, 2775, 2840, 2485, 2670, 2640, 2655,
 3065, 2750, 2920, 2780, 2745, 3110, 2920, 2645, 2575, 2935,
 2920, 2985, 3265, 2880, 2975, 3450, 3145, 3190, 3610, 2885,
 3480, 3200, 2765, 3220, 3480, 3325, 3855, 3850, 3195, 3735,
 3665, 3735, 3415, 3185, 3690, 97, 114, 81, 91, 113, 97, 97,
 98, 109, 73, 97, 89, 109, 305, 153, 302, 133, 97, 125, 146,
 107, 109, 121, 151, 133, 181, 141, 132, 133, 122, 181, 146,
 151, 116, 135, 122, 141, 163, 151, 153, 202, 180, 182, 232,
 143, 180, 180, 151, 189, 180, 231, 305, 302, 151, 202, 182,
 181, 143, 146, 146)), .Dim = as.integer(c(60, 2)),
 .Dimnames = list(NULL, c("Weight", "Disp.")))

PlotBag(cardata,factor=3,show.baghull=TRUE,
  show.loophull=TRUE,precision=1, dkmethod=2)

title("car data Chambers/Hastie 1992")

# points of y=x*x
PlotBag(x=1:30,y=(1:30)^2,verbose=FALSE,dkmethod=2)

# one dimensional subspace
PlotBag(x=1:50,y=1:50)

# pairwise bagplots
par(las=1)
PlotBagPairs(swiss[, 1:2],
             main="Swiss Fertility and Socioeconomic Indicators (1888) Data")
</code></pre>

<hr>
<h2 id='PlotBubble'>Draw a Bubble Plot
</h2><span id='topic+PlotBubble'></span><span id='topic+PlotBubble.default'></span><span id='topic+PlotBubble.formula'></span>

<h3>Description</h3>

<p>Draw a bubble plot, defined by a pair of coordinates x, y to place the bubbles, an area
definition configuring the dimension and a color vector setting the color of the bubbles.
The legitimation to define a new function instead of just using <code>plot(symbols(...))</code> is the automated calculation of the axis limits, ensuring that
all bubbles will be fully visible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
PlotBubble(x, ...)

## Default S3 method:
PlotBubble(x, y, area, col = NA, cex = 1, border = par("fg"),
           xlim = NULL, ylim = NULL, na.rm = FALSE, ...)

## S3 method for class 'formula'
PlotBubble(formula, data = parent.frame(), ..., subset, ylab = varnames[response])

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotBubble_+3A_x">x</code>, <code id="PlotBubble_+3A_y">y</code></td>
<td>
<p>the x and y co-ordinates for the centres of the bubbles. They can be specified in any way which is accepted by <code><a href="grDevices.html#topic+xy.coords">xy.coords</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_area">area</code></td>
<td>
<p>a vector giving the area of the bubbles.
</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_col">col</code></td>
<td>
<p>colors for the bubbles, passed to <code><a href="base.html#topic+symbol">symbol</a></code>.
The default <code>NA</code> (or also <code>NULL</code>) means do not fill, i.e., draw transparent bubbles.
</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_cex">cex</code></td>
<td>
<p>extension factor for the area.
</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_border">border</code></td>
<td>
<p>the border color fot the bubbles. The default means <code>par("fg")</code>. Use <code>border = NA</code> to omit borders.
</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_xlim">xlim</code>, <code id="PlotBubble_+3A_ylim">ylim</code></td>
<td>
<p>axes limits.
</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, should NAs be omitted? Defaults to FALSE.
</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_ylab">ylab</code></td>
<td>
<p>the y-label for the plot used in the formula interface.</p>
</td></tr>
<tr><td><code id="PlotBubble_+3A_...">...</code></td>
<td>
<p>the dots are passed to the <code><a href="base.html#topic+plot">plot</a></code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Argument <code>inches</code> controls the sizes of the symbols. If <code>TRUE</code> (the default), the symbols are scaled so that the largest dimension of any symbol is one inch. If a positive number is given the symbols are scaled to make largest dimension this size in inches (so <code>TRUE</code> and <code>1</code> are equivalent). If <code>inches</code> is <code>FALSE</code>, the units are taken to be those of the appropriate axes.
This behaviour is the same as in <code><a href="graphics.html#topic+symbols">symbols</a></code>.
</p>


<h3>Note</h3>

<p>A legend can be added with <code><a href="#topic+BubbleLegend">BubbleLegend</a></code>.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BubbleLegend">BubbleLegend</a></code>, <code><a href="graphics.html#topic+symbols">symbols</a></code>, <code><a href="graphics.html#topic+sunflowerplot">sunflowerplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotBubble(latitude ~ longitude, area=(smoky+1)*2e8,
           col=SetAlpha(1, 0.5), data=d.whisky)


cols &lt;- c("olivedrab1","orange","green","mediumturquoise","mediumorchid2","firebrick1")
PlotBubble(x = state.x77[,"Income"], y = state.x77[,"Life Exp"], cex=.00004,
           area = state.x77[,"Population"], col = cols[state.region], border="grey50",
           panel.first=grid(), xlab="Income", ylab="Life Exp.", las=1
)

BubbleLegend(x = "topright", area = c(20000, 10000, 1000), cex=.00004, frame=NA,
             cols=cols[1:3], labels = c(20000, 10000, 1000), cex.names=0.7)

legend(x="bottomright", fill=cols[1:4], legend=levels(state.region))

</code></pre>

<hr>
<h2 id='PlotCandlestick'>Plot Candlestick Chart
</h2><span id='topic+PlotCandlestick'></span>

<h3>Description</h3>

<p>Plot a candlestick chart. This is used primarily to describe price movements of a 
security, derivative, or currency over time. Candlestick charts are a visual aid for decision making 
in stock, foreign exchange, commodity, and option trading.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotCandlestick(x, y, vol = NA, xlim = NULL, ylim = NULL, 
                col = c("springgreen4","firebrick"), 
                border = NA, args.bar = NULL, args.grid = NULL, ...) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotCandlestick_+3A_x">x</code></td>
<td>
<p>a numeric vector for the x-values. Usually a date.
</p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_y">y</code></td>
<td>
<p>the y-values in a matrix (or a data.frame that can be coerced to a matrix) with 4 columns, whereas the first column contains the open price, 
the second the high, the third the lowest and the 4th the close price of daily stock prices.
</p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_vol">vol</code></td>
<td>
<p>the volume, if it should be included in the plot as separate part.</p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_xlim">xlim</code></td>
<td>
<p>the x limits (x1, x2) of the plot. The default value, <code>NULL</code>, indicates that the range of the finite values to be plotted should be used.</p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_ylim">ylim</code></td>
<td>
<p>the y limits of the plot.</p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_col">col</code></td>
<td>
<p>color for the body. To better highlight price movements, modern candlestick charts 
often replace the black or white of the candlestick body with colors such as red for a lower closing 
and blue or green for a higher closing. </p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_border">border</code></td>
<td>
<p>the border color of the rectangles. Default is NA, meaning no border will be plotted.</p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_args.grid">args.grid</code></td>
<td>
<p>the arguments of a potential grid. Default is <code>NULL</code>, which will have a grid plotted. If arguments are provided, they
have to be organized as list with the names of the arguments. (For example: ..., args.grid = list(col=&quot;red&quot;)) </p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_args.bar">args.bar</code></td>
<td>
<p>optional additional arguments for the volume barplot.</p>
</td></tr>
<tr><td><code id="PlotCandlestick_+3A_...">...</code></td>
<td>
<p>the dots are passed to <code>plot()</code> command</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Candlesticks are usually composed of the body (black or white), and an upper and a lower shadow (wick): 
the area between the open and the close is called the real body, price excursions above and below the 
real body are called shadows. The wick illustrates the highest and lowest traded prices of a security 
during the time interval represented. The body illustrates the opening and closing trades. 
If the security closed higher than it opened, the body is white or unfilled, with the opening
price at the bottom of the body and the closing price at the top. If the security closed lower than it opened, 
the body is black, with the opening price at the top and the closing price at the bottom. A candlestick need not
have either a body or a wick.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotBubble">PlotBubble</a></code>, <code><a href="graphics.html#topic+stars">stars</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nov &lt;- rbind(
 "2013-05-28"= c(70.99,71.82,70.49,71.49),
 "2013-05-29"= c(71.13,71.90,70.81,71.57),
 "2013-05-30"= c(71.25,71.53,70.90,71.01),
 "2013-05-31"= c(70.86,70.92,70.30,70.30),
 "2013-06-03"= c(70.56,70.89,70.05,70.74),
 "2013-06-04"= c(70.37,71.11,69.67,69.90),
 "2013-06-05"= c(69.76,69.76,68.92,68.99),
 "2013-06-06"= c(69.13,70.02,68.56,70.02),
 "2013-06-07"= c(70.45,70.52,69.51,70.20),
 "2013-06-10"= c(70.53,70.75,70.05,70.20),
 "2013-06-11"= c(69.36,69.66,69.01,69.17),
 "2013-06-12"= c(69.65,70.03,68.85,69.21),
 "2013-06-13"= c(69.21,70.18,69.13,70.10),
 "2013-06-14"= c(70.17,70.48,69.30,69.58),
 "2013-06-17"= c(70.14,70.96,69.98,70.44),
 "2013-06-18"= c(70.55,71.97,70.55,71.49),
 "2013-06-19"= c(71.33,72.00,70.89,70.97),
 "2013-06-20"= c(70.04,70.06,68.40,68.55),
 "2013-06-21"= c(69.15,69.27,67.68,68.21)
)
colnames(nov) &lt;- c("open","high","low","close")

PlotCandlestick(x=as.Date(rownames(nov)), y=nov, border=NA, las=1, ylab="")

# include some volume information
v &lt;- c(213,108,310,762,70,46,411,652,887,704,289,579,934,619,860,35,215,211,8)
PlotCandlestick(x=as.Date(rownames(nov)), y=nov, vol=v,
                border=NA, las=1, ylab="")
</code></pre>

<hr>
<h2 id='PlotCashFlow'>Cash Flow Plot
</h2><span id='topic+PlotCashFlow'></span>

<h3>Description</h3>

<p>A cash flow plot is a plot used in finance and allows you to graphically depict the timing of the cash flows as well as their nature as either inflows or outflows. An &quot;up&quot; arrow represents money received and a &quot;down&quot; arrow money paid out.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotCashFlow(x, y, xlim = NULL, labels = y, mar = NULL, 
             cex.per = par("cex"), cex.tck = par("cex") * 0.8, 
             cex.cash = par("cex"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotCashFlow_+3A_x">x</code></td>
<td>
<p>time period of the cashflows (in and out)
</p>
</td></tr>
<tr><td><code id="PlotCashFlow_+3A_y">y</code></td>
<td>
<p>amount of the cashflows
</p>
</td></tr>
<tr><td><code id="PlotCashFlow_+3A_xlim">xlim</code></td>
<td>
<p>range of the x-axis, defaults to <code>range(x)</code>.
</p>
</td></tr>
<tr><td><code id="PlotCashFlow_+3A_labels">labels</code></td>
<td>
<p>the labels of the cashflows will be printed outside the arrows.
</p>
</td></tr>
<tr><td><code id="PlotCashFlow_+3A_mar">mar</code></td>
<td>
<p>a vector with 4 elements, defining the margins for the plot</p>
</td></tr>
<tr><td><code id="PlotCashFlow_+3A_cex.per">cex.per</code></td>
<td>
<p>the character extension for the period labels</p>
</td></tr>
<tr><td><code id="PlotCashFlow_+3A_cex.tck">cex.tck</code></td>
<td>
<p>character extension for the ticklabels, tipically years</p>
</td></tr>
<tr><td><code id="PlotCashFlow_+3A_cex.cash">cex.cash</code></td>
<td>
<p>the character extension for the labels of the cashflows</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+NPV">NPV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotCashFlow(x=c(6:9, 13:15), y=-c(rep(40, 4), rep(50,3)),
             xlim=c(6,17), labels=c(rep(40, 4), rep(50,3)))

PlotCashFlow(x=c(6,8,9,12,17), y=c(10,30,40,50,70))
</code></pre>

<hr>
<h2 id='PlotCirc'>Plot Circular Plot
</h2><span id='topic+PlotCirc'></span>

<h3>Description</h3>

<p>This visualising scheme represents the unidirectional relationship between the rows and the columns of a contingency table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotCirc(tab, acol = rainbow(sum(dim(tab))), aborder = "darkgrey",
         rcol = SetAlpha(acol[1:nrow(tab)], 0.5), rborder = "darkgrey",
         gap = 5, main = "", labels = NULL, cex.lab = 1.0, las = 1,
         adj = NULL, dist = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotCirc_+3A_tab">tab</code></td>
<td>
<p>a table to be visualised.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_acol">acol</code></td>
<td>
<p>the colors for the peripheral annuli.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_aborder">aborder</code></td>
<td>
<p>the border colors for the peripheral annuli.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_rcol">rcol</code></td>
<td>
<p>the colors for the ribbons.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_rborder">rborder</code></td>
<td>
<p>the border colors for the ribbons.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_gap">gap</code></td>
<td>
<p>the gap between the entities in degrees.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_main">main</code></td>
<td>
<p>the main title, defaults to &quot;&quot;.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_labels">labels</code></td>
<td>
<p>the labels. Defaults to the column names and rownames of the table.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_las">las</code></td>
<td>
<p>alignment of the labels, 1 means horizontal, 2 radial and 3 vertical.
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_adj">adj</code></td>
<td>
<p>adjustments for the labels. (Left: 0, Right: 1, Mid: 0.5)
</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_dist">dist</code></td>
<td>
<p>gives the distance of the labels from the outer circle. Default is 2.</p>
</td></tr>
<tr><td><code id="PlotCirc_+3A_cex.lab">cex.lab</code></td>
<td>
<p>the character extension for the labels.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The visual scheme of representing relationships can be applied to a table, given the observation that a table cell is a relationship (with a value) between a row and column. By representing the row and columns as segments along the circle, the information in the corresponding cell can be encoded as a link between the segments.
In general, the cell represents a unidirectional relationship (e.g. row-&gt;column) - in this relationship the role of the segments is not interchangeable (e.g. (row,col) and (col,row) are different cells). To identify the role of the segment, as a row or column, the ribbon is made to terminate at the row segment but slightly away from the column segment. In this way, for a given ribbon, it is easy to identify which segment is the row and which is the column.
</p>


<h3>Value</h3>

<p>the calculated points for the labels, which can be used to place userdefined labels.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Inspired by <a href="https://circos.ca/presentations/articles/vis_tables1/">https://circos.ca/presentations/articles/vis_tables1/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotPolar">PlotPolar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- matrix(c(2,5,8,3,10,12,5,7,15), nrow=3, byrow=FALSE)
dimnames(tab) &lt;- list(c("A","B","C"), c("D","E","F"))
tab


PlotCirc( tab,
  acol = c("dodgerblue","seagreen2","limegreen","olivedrab2","goldenrod2","tomato2"),
  rcol = SetAlpha(c("red","orange","olivedrab1"), 0.5)
)

tab &lt;- table(d.pizza$weekday, d.pizza$operator)
par(mfrow=c(1,2))
PlotCirc(tab, main="weekday ~ operator")
PlotCirc(t(tab), main="operator ~ weekday")
</code></pre>

<hr>
<h2 id='PlotConDens'>Plot Conditional Densities
</h2><span id='topic+PlotConDens'></span>

<h3>Description</h3>

<p>Plot conditional densities by group. For describing how the conditional distribution of a categorical variable y changes over a numerical variable x we have the function cdplot. But if we want to compare multiple densities much work is required. PlotConDens allows to easily enter a grouping variable. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotConDens(formula, data, col = NULL, lwd = 2, lty = 1, xlim = NULL, rev = TRUE, 
            args.dens = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotConDens_+3A_formula">formula</code></td>
<td>
<p>a <code>"formula"</code> of type <code>y ~ x | g</code> with a single dependent <code>factor</code>, a single numerical explanatory variable and a grouping <code>factor</code> g.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_data">data</code></td>
<td>
<p>a data frame containing values for any variables in the formula. By default the environment where <code>PlotConDens</code> was called from is used.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_col">col</code></td>
<td>
<p>a vector of colors to be used to plot the lines. If too short, the values are recycled.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_lwd">lwd</code></td>
<td>
<p>a vector of linewidths to be used to plot the lines. If too short, the values are recycled.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_lty">lty</code></td>
<td>
<p>a vector of linetypes to be used to plot the lines. If too short, the values are recycled.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_xlim">xlim</code></td>
<td>
<p>the range for the x axis.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_rev">rev</code></td>
<td>
<p>logical, should the values of the response variable be reversed? Default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_args.dens">args.dens</code></td>
<td>
<p>additional arguments for the densitiy curves.
</p>
</td></tr>
<tr><td><code id="PlotConDens_+3A_...">...</code></td>
<td>
<p>the dots are passed on to <code>plot()</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Especially when we're modelling binary response variables we might want to know, how the binary variable behaves along some numeric predictors.
</p>


<h3>Value</h3>

<p>the functions for the curves
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+cdplot">cdplot</a></code>, <code><a href="graphics.html#topic+spineplot">spineplot</a></code>, <code><a href="stats.html#topic+density">density</a></code>, <code><a href="#topic+PlotMultiDens">PlotMultiDens</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Pima.tr2, package="MASS")
PlotConDens (type ~ age | I((npreg &gt; 0)*1L), 
             data=Pima.tr2, col=c(hblue, hred), rev=FALSE, 
             panel.first=quote(grid()))
</code></pre>

<hr>
<h2 id='PlotCorr'>Plot a Correlation Matrix
</h2><span id='topic+PlotCorr'></span>

<h3>Description</h3>

<p>This function produces a graphical display of a correlation matrix.
The cells of the matrix can be shaded or colored to show the correlation value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotCorr(x, cols = colorRampPalette(c(Pal()[2], "white",
                                      Pal()[1]), space = "rgb")(20),
         breaks = seq(-1, 1, length = length(cols) + 1),
         border = "grey", lwd = 1,
         args.colorlegend = NULL, xaxt = par("xaxt"), yaxt = par("yaxt"),
         cex.axis = 0.8, las = 2, mar = c(3, 8, 8, 8), mincor = 0,
         main = "", clust = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotCorr_+3A_x">x</code></td>
<td>
<p>x is a correlation matrix to be visualized.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_cols">cols</code></td>
<td>
<p>the colors for shading the matrix. Uses the package's option <code>"col1"</code> and <code>"col2"</code> as default.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_breaks">breaks</code></td>
<td>
<p>a set of breakpoints for the colours: must give one more breakpoint than colour. These are passed to <code>image()</code> function.
If breaks is specified then the algorithm used follows <code><a href="base.html#topic+cut">cut</a></code>, so intervals are closed on the right and open on the left except for the lowest interval.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_border">border</code></td>
<td>
<p>color for borders. The default is <code>grey</code>. Set this argument to <code>NA</code> if borders should be omitted.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_lwd">lwd</code></td>
<td>
<p>line width for borders. Default is 1.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_args.colorlegend">args.colorlegend</code></td>
<td>
<p>list of arguments for the <code><a href="#topic+ColorLegend">ColorLegend</a></code>. Use <code>NA</code> if no color legend should be painted.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_xaxt">xaxt</code></td>
<td>
<p>parameter to define, whether to draw an x-axis, defaults to <code>"n"</code>.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_yaxt">yaxt</code></td>
<td>
<p>parameter to define, whether to draw an y-axis, defaults to <code>"n"</code>.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_cex.axis">cex.axis</code></td>
<td>
<p>character extension for the axis labels.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_las">las</code></td>
<td>
<p>the style of axis labels.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_mar">mar</code></td>
<td>
<p>sets the margins, defaults to mar = c(3, 8, 8, 8) as we need a bit more room on the right.
</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_mincor">mincor</code></td>
<td>
<p>numeric value between 0 and 1, defining the smallest correlation that is to be displayed. If this is &gt;0 then all correlations with a lower value are suppressed.  </p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_main">main</code></td>
<td>
<p>character, the main title.</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_clust">clust</code></td>
<td>
<p>logical. If set to <code>TRUE</code>, the correlations will be clustered in order to aggregate similar values.</p>
</td></tr>
<tr><td><code id="PlotCorr_+3A_...">...</code></td>
<td>
<p>the dots are passed to the function <code><a href="graphics.html#topic+image">image</a></code>, which produces the plot.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no values returned.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+image">image</a></code>, <code><a href="#topic+ColorLegend">ColorLegend</a></code>, <code><a href="corrgram.html#topic+corrgram">corrgram</a>()</code>, <code><a href="#topic+PlotWeb">PlotWeb</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- cor(d.pizza[,sapply(d.pizza, IsNumeric, na.rm=TRUE)], use="pairwise.complete.obs")

PlotCorr(m, cols=colorRampPalette(c("red", "black", "green"), space = "rgb")(20))
PlotCorr(m, cols=colorRampPalette(c("red", "black", "green"), space = "rgb")(20),
         args.colorlegend=NA)

m &lt;- PairApply(d.diamonds[, sapply(d.diamonds, is.factor)], CramerV, symmetric=TRUE)
PlotCorr(m, cols = colorRampPalette(c("white", "steelblue"), space = "rgb")(20),
         breaks=seq(0, 1, length=21), border="black",
         args.colorlegend = list(labels=sprintf("%.1f", seq(0, 1, length = 11)), frame=TRUE)
)
title(main="Cramer's V", line=2)
text(x=rep(1:ncol(m),ncol(m)), y=rep(1:ncol(m),each=ncol(m)),
     label=sprintf("%0.2f", m[,ncol(m):1]), cex=0.8, xpd=TRUE)

# Spearman correlation on ordinal factors
csp &lt;- cor(data.frame(lapply(d.diamonds[,c("carat", "clarity", "cut", "polish",
                      "symmetry", "price")], as.numeric)), method="spearman")
PlotCorr(csp)

m &lt;- cor(mtcars)
PlotCorr(m, col=Pal("RedWhiteBlue1", 100), border="grey",
         args.colorlegend=list(labels=Format(seq(-1,1,.25), digits=2), frame="grey"))

# display only correlation with a value &gt; 0.7
PlotCorr(m, mincor = 0.7)
x &lt;- matrix(rep(1:ncol(m),each=ncol(m)), ncol=ncol(m))
y &lt;- matrix(rep(ncol(m):1,ncol(m)), ncol=ncol(m))
txt &lt;- Format(m, digits=3, ldigits=0)
idx &lt;- upper.tri(matrix(x, ncol=ncol(m)), diag=FALSE)

# place the text on the upper triagonal matrix
text(x=x[idx], y=y[idx], label=txt[idx], cex=0.8, xpd=TRUE)

# or let's get rid of all non significant correlations
p &lt;- PairApply(mtcars,  function(x, y) cor.test(x, y)$p.value, symmetric=TRUE)
# or somewhat more complex with outer
p0 &lt;- outer(1:ncol(m),  1:ncol(m),
           function(a, b)
             mapply(
               function(x, y) cor.test(mtcars[, x], mtcars[, y])$p.value,
               a, b))
# ok, got all the p-values, now replace &gt; 0.05 with NAs
m[p &gt; 0.05] &lt;- NA
PlotCorr(m)

# the text
n &lt;- ncol(m)
text(x=rep(seq(n), times=n),
     y=rep(rev(seq(n)), rep.int(n, n)),
     labels=Format(m, digits=2, na.form=""),
     cex=0.8, xpd=TRUE)
# the text could also be set with outer, but this function returns an error,
# based on the fact that text() does not return some kind of result
# outer(X = 1:nrow(m),  Y = ncol(m):1,
#  FUN = "text", labels = Format(m, digits=2, na.form = ""),
#  cex=0.8, xpd=TRUE)


# put similiar correlations together
PlotCorr(m, clust=TRUE)

# same as
idx &lt;- order.dendrogram(as.dendrogram(
          hclust(dist(m), method = "mcquitty")
       ))
PlotCorr(m[idx, idx])


# plot only upper triangular matrix and move legend to bottom
m &lt;- cor(mtcars)
m[lower.tri(m, diag=TRUE)] &lt;- NA

p &lt;- PairApply(mtcars,  function(x, y) cor.test(x, y)$p.value, symmetric=TRUE)
m[p &gt; 0.05] &lt;- NA

PlotCorr(m, mar=c(8,8,8,8), yaxt="n",
         args.colorlegend = list(x="bottom", inset=-.15, horiz=TRUE, 
                                 height=abs(LineToUser(line = 2.5, side = 1)), 
                                 width=ncol(m)))
mtext(text = rev(rownames(m)), side = 4, at=1:ncol(m), las=1, line = -5, cex=0.8)

text(1:ncol(m), ncol(m):1, colnames(m), xpd=NA, cex=0.8, font=2)

n &lt;- ncol(m)
text(x=rep(seq(n), times=n),
     y=rep(rev(seq(n)), rep.int(n, n)),
     labels=Format(t(m), digits=2, na.form=""),
     cex=0.8, xpd=TRUE)
</code></pre>

<hr>
<h2 id='PlotDot'>Cleveland's Dot Plots</h2><span id='topic+PlotDot'></span><span id='topic+PlotDotCI'></span>

<h3>Description</h3>

<p>Draw a Cleveland dot plot. This is an extended version of <code><a href="graphics.html#topic+dotchart">dotchart</a></code> with an added option for error bars, an <code>add</code> argument and several more options. <code>PlotCI()</code> is a small helpfunction to facilitate ci-plots of several models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotDot(x, labels = NULL, groups = NULL, gdata = NULL,
        cex = par("cex"), pch = 21, gpch = 21, bg = par("bg"),
        color = par("fg"), gcolor = par("fg"), lcolor = "gray", lblcolor = par("fg"),
        xlim = NULL, main = NULL, xlab = NULL, ylab = NULL,
        xaxt = NULL, yaxt = NULL, add = FALSE, args.errbars = NULL, 
        cex.axis = par("cex.axis"), cex.pch = 1.2, cex.gpch = 1.2, 
        gshift = 2, automar = TRUE, ...)
        
        
PlotDotCI(..., grp = 1, cex = par("cex"),
         pch = 21, gpch = 21, bg = par("bg"), color = par("fg"), gcolor = par("fg"),
         lcolor = "gray", lblcolor = par("fg"), xlim = NULL, main = NULL, 
         xlab = NULL, ylab = NULL, xaxt = NULL, yaxt = NULL,
         cex.axis = par("cex.axis"), cex.pch = 1.2, cex.gpch = 1.2, 
         gshift = 2, automar = TRUE)
        
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotDot_+3A_x">x</code></td>
<td>
<p>either a vector or matrix of numeric values (<code>NA</code>s are
allowed).  If <code>x</code> is a matrix the overall plot consists of
juxtaposed dotplots for each row.  Inputs which satisfy
<code><a href="base.html#topic+is.numeric">is.numeric</a>(x)</code> but not
<code>is.vector(x) || is.matrix(x)</code> are coerced by
<code><a href="base.html#topic+as.numeric">as.numeric</a></code>, with a warning.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_labels">labels</code></td>
<td>
<p>a vector of labels for each point.
For vectors the default is to use <code>names(x)</code> and for matrices
the row labels <code>dimnames(x)[[1]]</code>.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_groups">groups</code></td>
<td>
<p>an optional factor indicating how the elements of
<code>x</code> are grouped.
If <code>x</code> is a matrix, <code>groups</code> will default to the columns
of <code>x</code>.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_gdata">gdata</code></td>
<td>
<p>data values for the groups.
This is typically a summary such as the median or mean
of each group.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_cex">cex</code></td>
<td>
<p>the character size to be used.  Setting <code>cex</code>
to a value smaller than one can be a useful way of avoiding label
overlap.  Unlike many other graphics functions, this sets the actual
size, not a multiple of <code>par("cex")</code>.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_pch">pch</code></td>
<td>
<p>the plotting character or symbol to be used. Default is 21.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_gpch">gpch</code></td>
<td>
<p>the plotting character or symbol to be used for group
values.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_bg">bg</code></td>
<td>
<p>the background color of plotting characters or symbols to be
used; use <code><a href="graphics.html#topic+par">par</a>(bg= *)</code> to set the background color of
the whole plot.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_color">color</code></td>
<td>
<p>the color(s) to be used for points and labels.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_gcolor">gcolor</code></td>
<td>
<p>the single color to be used for group labels and
values.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_lcolor">lcolor</code></td>
<td>
<p>the color(s) to be used for the horizontal lines.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_lblcolor">lblcolor</code></td>
<td>
<p>the color(s) to be used for labels.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_xlim">xlim</code></td>
<td>
<p>horizontal range for the plot, see
<code><a href="graphics.html#topic+plot.window">plot.window</a></code>, e.g.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_main">main</code></td>
<td>
<p>overall title for the plot, see <code><a href="graphics.html#topic+title">title</a></code>.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_xlab">xlab</code>, <code id="PlotDot_+3A_ylab">ylab</code></td>
<td>
<p>axis annotations as in <code>title</code>.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_xaxt">xaxt</code></td>
<td>
<p>a character which specifies the x axis type. Specifying <code>"n"</code> suppresses plotting of the axis.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_yaxt">yaxt</code></td>
<td>
<p>a character which specifies the y axis type. Specifying <code>"n"</code> suppresses plotting of the axis.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_add">add</code></td>
<td>
<p>logical specifying if bars should be added to an already existing plot; defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_args.errbars">args.errbars</code></td>
<td>
<p>optional arguments for adding error bars. All arguments for <code><a href="#topic+ErrBars">ErrBars</a></code> can be supplied. If left to <code>NULL</code> (default), no error bars will be plotted.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to the current setting of cex.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_cex.pch">cex.pch</code></td>
<td>
<p>The magnification to be used for plot symbols relative to the current setting of cex.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_cex.gpch">cex.gpch</code></td>
<td>
<p>The magnification to be used for group symbols relative to the current setting of cex.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_gshift">gshift</code></td>
<td>
<p>the number of characters, for which the grouplabels should be shift to the left compared to the sublabels.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_automar">automar</code></td>
<td>
<p>logical (default <code>TRUE</code>), defining if the left margin should be set according to the width of the given labels, resp. grouplabels. If set to <code>FALSE</code> the margins are taken from <code>par("mar")</code>.  </p>
</td></tr>
<tr><td><code id="PlotDot_+3A_...">...</code></td>
<td>
<p><a href="graphics.html#topic+graphical+20parameters">graphical parameters</a> can also be specified as arguments.</p>
</td></tr>
<tr><td><code id="PlotDot_+3A_grp">grp</code></td>
<td>
<p>an integer, defining if the the coefficients should be grouped along the first
or the second dimension (default is 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Dot plots are a reasonable substitute for bar plots. This function is invoked to produce dotplots as described in Cleveland (1985).
</p>
<p>For <code>PlotDotCI()</code> the dots are a list of matrices with 3 columns, whereas the first is the coefficent, the second the lower and the third the upper end of the confidence interval.
</p>


<h3>Value</h3>

<p>Return the y-values used for plotting.
</p>


<h3>Author(s)</h3>

<p>R-Core with some extensions by Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>
<p>Cleveland, W. S. (1985)
<em>The Elements of Graphing Data.</em>
Monterey, CA: Wadsworth.
</p>
<p>Murrell, P. (2005) <em>R Graphics</em>. Chapman &amp; Hall/CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+dotchart">dotchart</a></code>, <code><a href="#topic+PlotDotCI">PlotDotCI</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotDot(VADeaths, main = "Death Rates in Virginia - 1940")
op &lt;- par(xaxs = "i")  # 0 -- 100%
PlotDot(t(VADeaths), xlim = c(0,100),
        main = "Death Rates in Virginia - 1940")
par(op)

# add some error bars
PlotDot(VADeaths, main="Death Rates in Virginia - 1940", col="red", pch=21,
        args.errbars = list(from=VADeaths-2, to=VADeaths+2, mid=VADeaths,
                            cex=1.4))

# add some other values
PlotDot(VADeaths+3, pch=15, col="blue", add=TRUE)

# same as PlotDotCI
xci &lt;- do.call(rbind, tapply( d.pizza$delivery_min, d.pizza$driver,
                              MeanCI, conf.level=0.99, na.rm=TRUE))

PlotDot(xci[,1], main="delivery_min ~ driver", pch=21, bg="grey80", col="black",
        args.errbars = list(from=xci[,2], to=xci[,3], mid=xci[,1], lwd=2, col="grey40", cex=1.5),
        xlim=c(15,35), panel.before=grid())

# with group data
x &lt;- with(d.pizza, tapply(temperature, list(area, driver), mean, na.rm=TRUE))

PlotDot(x, gdata = tapply(d.pizza$temperature, d.pizza$driver, mean, na.rm=TRUE),
        gpch = 15)

# special format
par(lend=1)

PlotDot(VADeaths, main="Death Rates in Virginia - 1940", pch="|", lcolor = hecru, col=hred,
        args.errbars = list(from=VADeaths-2, to=VADeaths+2, mid=VADeaths,
                            cex=1.3, lwd=8, code=0, col=hgreen))

# Error bars for binomial confidence intervals
tab &lt;- table(d.pizza$driver, d.pizza$wine_delivered)
xci &lt;- SetNames(BinomCI(tab[,1], rowSums(tab)), rownames=rownames(tab))
PlotDot(xci[,1], main="wine delivered ~ driver ", xlim=c(0,1),
        args.errbars=list(from=xci[,-1], mid=xci[,1], pch=21))


# Error bars for confidence intervals for means
xci &lt;- do.call(rbind, tapply(d.pizza$delivery_min, d.pizza$driver,
                             MeanCI, conf.level=0.99, na.rm=TRUE))

PlotDot(xci[, 1], main="delivery_min ~ driver", args.errbars=list(from=xci))


# Setting the colours
# define some error bars first
lci &lt;- sweep(x = VADeaths, MARGIN = 2, FUN = "-", 1:4)
uci &lt;- sweep(x = VADeaths, MARGIN = 1, FUN = "+", 1:5)

PlotDot(VADeaths, main="This should only show how to set the colours, not be pretty",
        pch=21, col=c("blue","grey"), bg=c("red", "yellow"),
        gcolor = c("green", "blue", "orange", "magenta"), gdata=c(10,20,30,40),
        gpch = c(15:18), lcolor = "orange",
        args.errbars = list(from=lci, to=uci, mid=VADeaths, cex=1.4))

</code></pre>

<hr>
<h2 id='PlotECDF'>Empirical Cumulative Distribution Function
</h2><span id='topic+PlotECDF'></span>

<h3>Description</h3>

<p>Faster alternative for plotting the empirical cumulative distribution function (ecdf).
The function offers the option to construct the ecdf on the base of a histogram, which makes sense, when x is large. So the plot process is much faster, without loosing much precision in the details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotECDF(x, breaks = NULL, col = Pal()[1], ylab = "", 
         lwd = 2, xlab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotECDF_+3A_x">x</code></td>
<td>
<p>numeric vector of the observations for ecdf.
</p>
</td></tr>
<tr><td><code id="PlotECDF_+3A_breaks">breaks</code></td>
<td>
<p>will be passed directly to <code><a href="graphics.html#topic+hist">hist</a></code>. If left to <code>NULL</code>, no histogram will be used.
</p>
</td></tr>
<tr><td><code id="PlotECDF_+3A_col">col</code></td>
<td>
<p>color of the line.
</p>
</td></tr>
<tr><td><code id="PlotECDF_+3A_ylab">ylab</code></td>
<td>
<p>label for the y-axis.
</p>
</td></tr>
<tr><td><code id="PlotECDF_+3A_lwd">lwd</code></td>
<td>
<p>line width.
</p>
</td></tr>
<tr><td><code id="PlotECDF_+3A_xlab">xlab</code></td>
<td>
<p>label for the x-axis.
</p>
</td></tr>
<tr><td><code id="PlotECDF_+3A_...">...</code></td>
<td>
<p>arguments to be passed to subsequent functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The stats function <code><a href="stats.html#topic+plot.ecdf">plot.ecdf</a></code> is fine for vectors that are not too large. However for n ~ 1e7 we would observe a dramatic performance breakdown (possibly in combination with the use of <code><a href="base.html#topic+do.call">do.call</a></code>).
</p>
<p><code>PlotECDF</code> is designed as alternative for quicker plotting the ecdf for larger vectors. If <code>breaks</code> are provided as argument, a histogram with that number of breaks will be calculated and the ecdf will use those frequencies instead of respecting every single point. <br /> Note that a plot will rarely need more than ~1'000 points on x to have a sufficient resolution on usual terms. <code><a href="#topic+PlotFdist">PlotFdist</a></code> will also use this number of breaks by default.
</p>


<h3>Value</h3>

<p>no value returned, use <code><a href="stats.html#topic+plot.ecdf">plot.ecdf</a></code> if any results are required.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+plot.ecdf">plot.ecdf</a></code>, <code><a href="#topic+PlotFdist">PlotFdist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotECDF(d.pizza$temperature)

# make large vector
x &lt;- rnorm(n=1e7)

# plot only 1000 points instead of 1e7
PlotECDF(x, breaks=1000)
</code></pre>

<hr>
<h2 id='PlotFaces'>    Chernoff Faces    </h2><span id='topic+PlotFaces'></span>

<h3>Description</h3>

<p>Plot Chernoff faces. The rows of a data matrix represent cases and the columns the variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotFaces(xy, which.row, fill = FALSE, nr, nc,
          scale = TRUE, byrow = FALSE, main, labels, col = "white")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotFaces_+3A_xy">xy</code></td>
<td>
   <p><code>xy</code> data matrix, rows represent individuals and columns attributes.  </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_which.row">which.row</code></td>
<td>
<p>   defines a permutation of the rows of the input matrix.   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_fill">fill</code></td>
<td>
<p>  logic. If set to <code>TRUE</code>, only the first <code>nc</code> attributes of the faces are
transformed, <code>nc</code> is the number of columns of <code>x</code>.   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_nr">nr</code></td>
<td>
<p>   number of columns of faces on graphics device   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_nc">nc</code></td>
<td>
<p>   number of rows of faces   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_scale">scale</code></td>
<td>
<p> logic. If set to <code>TRUE</code>, attributes will be normalized.   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_byrow">byrow</code></td>
<td>
   <p><code>if(byrow==TRUE)</code>, <code>x</code> will be transposed.   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_main">main</code></td>
<td>
<p>   title.   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_labels">labels</code></td>
<td>
<p>   character strings to use as names for the faces.   </p>
</td></tr>
<tr><td><code id="PlotFaces_+3A_col">col</code></td>
<td>
<p>a vector of colors used for the parts of the faces. Colors are recycled in the order: &quot;nose&quot;, &quot;eyes&quot;, &quot;hair&quot;, &quot;face&quot;, &quot;lips&quot;, &quot;ears&quot;. Default is NA, which will omit colors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The features paramters of this implementation are:
</p>

<ul>
<li><p>1  height of face
</p>
</li>
<li><p>2  width of face
</p>
</li>
<li><p>3  shape of face
</p>
</li>
<li><p>4  height of mouth
</p>
</li>
<li><p>5  width of mouth
</p>
</li>
<li><p>6  curve of smile
</p>
</li>
<li><p>7  height of eyes
</p>
</li>
<li><p>8  width of eyes
</p>
</li>
<li><p>9  height of hair
</p>
</li>
<li><p>10  width of hair
</p>
</li>
<li><p>11  styling of hair
</p>
</li>
<li><p>12  height of nose
</p>
</li>
<li><p>13  width of nose
</p>
</li>
<li><p>14  width of ears
</p>
</li>
<li><p>15  height of ears
</p>
</li></ul>

<p><img src="../help/figures/faces.png" alt="Some faces" />
</p>
<p>For details look at the literate program of <code>faces</code>
</p>


<h3>Value</h3>

<p>information about usage of variables for face elements is returned invisibly
</p>


<h3>Note</h3>

<p> based on version 12/2009 </p>


<h3>Author(s)</h3>

<p>   H. P. Wolf, some changes Andri Signorell &lt;andri@signorell.net&gt;   </p>


<h3>References</h3>

<p>  Chernoff, H. (1973) The use of faces to represent statistiscal assoziation,
<em>JASA</em>, 68, pp 361&ndash;368.<br />
</p>
<p>The smooth curves are computed by an algorithm found in:<br />
Ralston, A. and Rabinowitz, P. (1985)
<em>A first course in numerical analysis</em>, McGraw-Hill, pp 76ff.</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotFaces(rbind(1:3,5:3,3:5,5:7))

data(longley)
PlotFaces(longley[1:9,])

set.seed(17)
PlotFaces(matrix(sample(1:1000,128,), 16, 8), main="random faces")


means &lt;- lapply(iris[,-5], tapply, iris$Species, mean)
m &lt;- t(do.call(rbind, means))
m &lt;- cbind(m, matrix(rep(1, 11*3), nrow=3))

# define the colors, first for all faces the same
col &lt;- replicate(3, c("orchid1", "olivedrab", "goldenrod4",
                      "peachpuff", "darksalmon", "peachpuff3"))
rownames(col) &lt;- c("nose","eyes","hair","face","lips","ears")
# change haircolor individually for each face
col[3, ] &lt;- c("lightgoldenrod", "coral3", "sienna4")

z &lt;- PlotFaces(m, nr=1, nc=3, col=col)

# print the used coding
print(z$info, right=FALSE)
</code></pre>

<hr>
<h2 id='PlotFdist'>Frequency Distribution Plot
</h2><span id='topic+PlotFdist'></span>

<h3>Description</h3>

<p>This function is designed to give a univariate graphic representation of a numeric vectors frequency distribution.
It combines a histogram, a density curve, a boxplot and the empirical cumulative distribution function (ecdf) in one single plot. A rug as well as a model distribution curve (e.g. a normal curve) can optionally be superposed. This results in a dense and informative picture of the facts.
Still the function remains flexible as all possible arguments can be passed to the single components (<code>hist</code>, <code>boxplot</code> etc.) as a list (see examples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotFdist(x, main = deparse(substitute(x)), xlab = "", xlim = NULL,
          args.hist = NULL, args.rug = NA, args.dens = NULL,
          args.curve = NA, args.boxplot = NULL, args.ecdf = NULL,
          args.curve.ecdf = NA, heights = NULL, pdist = NULL,
          na.rm = FALSE, cex.axis = NULL, cex.main = NULL, mar = NULL, las = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotFdist_+3A_x">x</code></td>
<td>
<p>the numerical variable, whose distribution is to be plotted.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_main">main</code></td>
<td>
<p>main title of the plot.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_xlab">xlab</code></td>
<td>
<p>label of the x-axis, defaults to <code>""</code>. (The name of the variable is typically  placed in the main title and would be redundant here.)
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_xlim">xlim</code></td>
<td>
<p>range of the x-axis, defaults to a pretty <code>range(x, na.rm = TRUE)</code>.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_args.hist">args.hist</code></td>
<td>
<p>list of additional arguments to be passed to the histogram <code>hist()</code>.
The defaults chosen when setting <code>args.hist = NULL</code> are more or less the same as in <code><a href="graphics.html#topic+hist">hist</a></code>. The argument <code>type</code> defines, whether a histogram (<code>"hist"</code>) or a plot with <code>type = "h"</code> (for 'histogram' like vertical lines for <code>mass</code> representation) should be used.
The arguments for a &quot;h-plot&quot;&quot; will be <code>col</code>, <code>lwd</code>, <code>pch.col</code>, <code>pch</code>, <code>pch.bg</code> for the line and for an optional point character on top.
The default type used will be chosen on the structure of <code>x</code>. If <code>x</code> is an integer with up to 12 unique values there will be a &quot;h-plot&quot; and else a histogram!
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_args.rug">args.rug</code></td>
<td>
<p>list of additional arguments to be passed to the function <code>rug()</code>.
Use <code>args.rug = NA</code> if no rug should be added. This is the default. Use <code>args.rug = NULL</code> to add rug with reasonable default values.

</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_args.dens">args.dens</code></td>
<td>
<p>list of additional arguments to be passed to <code>density</code>.
Use <code>args.dens = NA</code> if no density curve should be drawn. The defaults are taken from <code><a href="stats.html#topic+density">density</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_args.curve">args.curve</code></td>
<td>
<p>list of additional arguments to be passed to <code><a href="graphics.html#topic+curve">curve</a></code>.
This argument allows to add a fitted distribution curve to the histogram. By default no curve will be added (<code>args.curve = NA</code>). If the argument is set to <code>NULL</code>, a normal curve with <code>mean(x)</code> and <code>sd(x)</code> will be drawn. See examples for more details.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_args.boxplot">args.boxplot</code></td>
<td>
<p>list of additional arguments to be passed to the boxplot <code>boxplot()</code>.
The defaults are pretty much the same as in <code><a href="graphics.html#topic+boxplot">boxplot</a></code>.
The two additional arguments <code>pch.mean</code> (default <code>23</code>) and <code>col.meanci</code> (default <code>"grey80"</code>) control, if the mean is displayed within the boxplot. Setting those  arguments to <code>NA</code> will prevent them from being displayed.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_args.ecdf">args.ecdf</code></td>
<td>
<p>list of additional arguments to be passed to <code>ecdf()</code>.
Use <code>args.ecdf = NA</code> if no empirical cumulation function should be included in the plot.
The defaults are taken from <code><a href="stats.html#topic+plot.ecdf">plot.ecdf</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_args.curve.ecdf">args.curve.ecdf</code></td>
<td>
<p>list of additional arguments to be passed to <code><a href="graphics.html#topic+curve">curve</a></code>.
This argument allows to add a fitted distribution curve to the cumulative distribution function. By default no curve will be added (<code>args.curve.ecdf = NA</code>). If the argument is set to <code>NULL</code>, a normal curve with <code>mean(x)</code> and <code>sd(x)</code> will be drawn. See examples for more details.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_heights">heights</code></td>
<td>
<p>heights of the plotparts, defaults to <code>c(2,0.5,1.4)</code> for the histogram, the boxplot
and the empirical cumulative distribution function, resp. to <code>c(2,1.5)</code> for a histogram and a boxplot only.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_pdist">pdist</code></td>
<td>
<p>distances of the plotparts, defaults to <code>c(0, 0)</code>, say there will be no distance between the histogram, the boxplot and the ecdf-plot. This can be useful for instance in case that the x-axis has to
be added to the histogram.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, should <code>NA</code>s be omitted? Histogram and boxplot could do without this option,
but the density-function refuses to plot with missings. Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_cex.axis">cex.axis</code></td>
<td>
<p>character extension factor for the axes.</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_cex.main">cex.main</code></td>
<td>
<p>character extension factor for the main title. Must be set in dependence of the plot parts in order to get a harmonic view.</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_mar">mar</code></td>
<td>
<p>A numerical vector of the form <code>c(bottom, left, top, right)</code> which gives the number of lines of outer margin to be specified on the four sides of the plot. The default is <code>c(0, 0, 3, 0)</code>.</p>
</td></tr>
<tr><td><code id="PlotFdist_+3A_las">las</code></td>
<td>
<p>numeric in <code>c(0,1,2,3)</code>; the orientation of axis labels. See <code><a href="graphics.html#topic+par">par</a></code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Performance has been significantly improved, but if <code>x</code> is growing large (n &gt; 1e7) the function will take its time to complete. Especially the density curve and the ecdf, but as well as the boxplot (due to the chosen alpha channel) will take their time to calculate and plot.<br />
In such cases consider taking a sample, i.e. <code>  PlotFdist(x[sample(length(x), size=5000)])</code>, the big picture of the distribution won't usually change much.
.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>, <code><a href="graphics.html#topic+boxplot">boxplot</a></code>, <code><a href="stats.html#topic+ecdf">ecdf</a></code>, <code><a href="stats.html#topic+density">density</a></code>, <code><a href="graphics.html#topic+rug">rug</a></code>, <code><a href="graphics.html#topic+layout">layout</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotFdist(x=d.pizza$delivery_min, na.rm=TRUE)

# define additional arguments for hist, dens and boxplot
# do not display the mean and its CI on the boxplot
PlotFdist(d.pizza$delivery_min, args.hist=list(breaks=50),
  args.dens=list(col="olivedrab4"), na.rm=TRUE,
  args.boxplot=list(col="olivedrab2", pch.mean=NA, col.meanci=NA))


# do a "h"-plot instead of a histogram for integers
x &lt;- sample(runif(10), 100, replace = TRUE)
PlotFdist(x, args.hist=list(type="mass"))

pp &lt;- rpois(n = 100, lambda = 3)
PlotFdist(pp, args.hist = list(type="mass", pch=21, col=horange,
          cex.pch=2.5, col.pch=hred, lwd=3, bg.pch="white"),
          args.boxplot = NULL, args.ecdf = NA, main="Probability mass function")

# special arguments for hist, density and ecdf
PlotFdist(x=faithful$eruptions,
          args.hist=list(breaks=20), args.dens=list(bw=.1),
          args.ecdf=list(cex=1.2, pch=16, lwd=1), args.rug=TRUE)

# no density curve, no ecdf but add rug instead, make boxplot a bit higher
PlotFdist(x=d.pizza$delivery_min, na.rm=TRUE, args.dens=NA, args.ecdf=NA,
  args.hist=list(xaxt="s"),  # display x-axis on the histogram
  args.rug=TRUE, heights=c(3, 2.5), pdist=2.5, main="Delivery time")

# alpha channel on rug is cool, but takes its time for being drawn...
PlotFdist(x=d.pizza$temperature, args.rug=list(col=SetAlpha("black", 0.1)), na.rm=TRUE)

# plot a normal density curve, but no boxplot nor ecdf
x &lt;- rnorm(1000)
PlotFdist(x, args.curve = NULL, args.boxplot=NA, args.ecdf=NA)

# compare with a t-distribution
PlotFdist(x, args.curve = list(expr="dt(x, df=2)", col="darkgreen"),
          args.boxplot=NA, args.ecdf=NA)
legend(x="topright", legend=c("kernel density", "t-distribution (df=2)"),
       fill=c(getOption("col1", hred), "darkgreen"), xpd=NA)

# add a gamma distribution curve to both, histogram and ecdf
ozone &lt;- airquality$Ozone; m &lt;- mean(ozone, na.rm = TRUE); v &lt;- var(ozone, na.rm = TRUE)
PlotFdist(ozone, args.hist = list(breaks=15),
  args.curve = list(expr="dgamma(x, shape = m^2/v, scale = v/m)", col=hecru),
  args.curve.ecdf = list(expr="pgamma(x, shape = m^2/v, scale = v/m)", col=hecru),
  na.rm = TRUE, main = "Airquality - Ozone")

legend(x="topright", xpd=NA,
       legend=c(expression(plain("gamma:  ") * Gamma * " " * bgroup("(", k * " = " *
           over(bar(x)^2, s^2) * " , " * theta * plain(" = ") * over(s^2, bar(x)), ")") ),
                "kernel density"),
       fill=c(hecru, getOption("col1", hred)), text.width = 0.25)
</code></pre>

<hr>
<h2 id='PlotFun'>Plot a Function
</h2><span id='topic+PlotFun'></span>

<h3>Description</h3>

<p>Plots mathematical expressions in one variable using the formula syntax.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotFun(FUN, args = NULL, from = NULL, to = NULL, by = NULL,
        xlim = NULL, ylim = NULL, polar = FALSE, type = "l",
        col = par("col"), lwd = par("lwd"), lty = par("lty"),
        pch = NA, mar = NULL, add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotFun_+3A_fun">FUN</code></td>
<td>
<p>a mathematical expression defined using the formula syntax: <code>f(x) ~ x</code>. x and y can as well be functions of a parameter t: <code>y(t) ~ x(t)</code> (see examples).
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_args">args</code></td>
<td>
<p>a list of additional parameters defined in the expression besides the independent variable.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_from">from</code>, <code id="PlotFun_+3A_to">to</code></td>
<td>
<p>the range over which the function will be plotted.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_by">by</code></td>
<td>
<p>number: increment of the sequence.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_xlim">xlim</code>, <code id="PlotFun_+3A_ylim">ylim</code></td>
<td>
<p><code>NULL</code> or a numeric vector of length 2; if non-NULL it provides the defaults for <code>c(from, to)</code> and, unless <code>add=TRUE</code>, selects the x-limits of the plot - see <code><a href="graphics.html#topic+plot.window">plot.window</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_polar">polar</code></td>
<td>
<p>logical. Should polar coordinates be used? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_type">type</code></td>
<td>
<p>plot type: see <code><a href="graphics.html#topic+plot.default">plot.default</a></code>
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_col">col</code></td>
<td>
<p>colors of the lines.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_lwd">lwd</code></td>
<td>
<p>line widths for the lines.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_lty">lty</code></td>
<td>
<p>line type of the lines.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_pch">pch</code></td>
<td>
<p>plotting 'character', i.e., symbol to use.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_mar">mar</code></td>
<td>
<p>A numerical vector of the form <code>c(bottom, left, top, right)</code> which gives the number of lines of margin to be specified on the four sides of the plot. The default is <code>c(3,3,3,3)</code>.</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_add">add</code></td>
<td>
<p>logical; if <code>TRUE</code> add to an already existing plot; if <code>NA</code> start a new plot taking the defaults for the limits and log-scaling of the x-axis from the previous plot. Taken as <code>FALSE</code> (with a warning if a different value is supplied) if no graphics device is open.
</p>
</td></tr>
<tr><td><code id="PlotFun_+3A_...">...</code></td>
<td>
<p>the dots are passed to the plot, resp. lines function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A function can be plotted with <code><a href="graphics.html#topic+curve">curve</a></code>. This function here adds some more features, one enabling to use a formula for defining the function to plot.
This enables as well a parametric equation to be entered straight forward. Parameters of a function can be set separatedly.
The aspect ratio y/x will be set to 1 by default. (See <code><a href="graphics.html#topic+plot.window">plot.window</a></code> for details.)
</p>
<p>If the argument <code>axes</code> (given in the dots) is not set to <code>FALSE</code> centered axis at a horizontal and vertical position of 0 will be drawn, containing major and minor ticks.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+curve">curve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple quadratic function y = x^2
PlotFun(x^2 ~ x)

par(mfrow=c(3,4))

# Cartesian leaf
PlotFun(3*a*z^2 /(z^3+1) ~ 3*a*z /(z^3+1+b), args=list(a=2, b=.1), from=-10, to=10, by=0.1,
        xlim=c(-5,5), ylim=c(-5,5), col="magenta", asp=1, lwd=2 )

# family of functions
PlotFun(a*exp(-x/5)*sin(n*x) ~ x, args=list(n=4, a=3), from=0, to=10, by=0.01,
        col="green")

PlotFun(a*exp(-x/5)*sin(n*x) ~ x, args=list(n=6, a=3), from=0, to=10, by=0.01,
        col="darkgreen", add=TRUE)

# cardioid
PlotFun(a*(1+cos(t)) ~ t, args=list(a=2), polar=TRUE, from=0, to=2*pi+0.1, by=0.01, asp=1)

PlotFun(13*cos(t) - 5*cos(2*t) - 2*cos(3*t) - cos(4*t) ~ 16*sin(t)^3,
        from=0, to=2*pi, by=0.01, asp=1, xlim=c(-20,20), col="red", lwd=2)


PlotFun(a*sin(2*t)*cos(2*t) ~ t, args=list(a=6), polar=TRUE, from=0, to=2*pi+0.1, by=0.01,
        col="orange")

# astroid
PlotFun(a*sin(t)^3 ~ a*cos(t)^3, args=list(a=2), from=0, to=2*pi+0.1, lwd=3, by=0.01,
        col="red")

# lemniscate of Bernoulli
PlotFun((2*a^2*cos(2*t))^2 ~ t, args=list(a=1), polar=TRUE, from=0, to=2*pi+0.1, by=0.01,
        col="darkblue")

# Cycloid
PlotFun(a*(1-cos(t)) ~ a*(t-sin(t)), args=list(a=0.5), from=0, to=30, by=0.01,
        col="orange")

# Kreisevolvente
PlotFun(a*(sin(t) - t*cos(t)) ~ a*(cos(t) + t*sin(t)), args=list(a=0.2), from=0, to=50, by=0.01,
        col="brown")


PlotFun(sin(2*t) ~ sin(t), from=0, to=2*pi, by=0.01, col="blue", lwd=2)

# multiple values for one parameter
sapply(1:3, function(a) PlotFun(sin(a*x) ~ x,
                                args=list(a=a), from=0, to=2*pi, by=0.01,
                                add=(a!=1), col=a))

PlotFun(sin(3*x) ~ x, polar=TRUE, from=0, to=pi, by=0.001, col=hred, lwd=2)


PlotFun(1 + 1/10 * sin(10*x) ~ x, polar=TRUE, from=0, to=2*pi, by=0.001, col=hred)
PlotFun(sin(x) ~ cos(x), polar=FALSE, from=0, to=2*pi, by=0.01, add=TRUE, col="blue")

</code></pre>

<hr>
<h2 id='PlotLinesA'>Plot Lines
</h2><span id='topic+PlotLinesA'></span>

<h3>Description</h3>

<p>Plot the columns of one matrix against the columns of another. Adds a legend on the right at the endpoints of lines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotLinesA(x, y, col = 1:5, lty = 1, lwd = 1, lend = par("lend"),
           xlab = NULL, ylab = NULL, xlim = NULL, ylim = NULL, xaxt = NULL, yaxt = NULL,
           cex = 1, args.legend = NULL, main = NULL, grid = TRUE, mar = NULL,
           pch = NA, pch.col = par("fg"), pch.bg = par("bg"), pch.cex = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotLinesA_+3A_x">x</code>, <code id="PlotLinesA_+3A_y">y</code></td>
<td>
<p>vectors or matrices of data for plotting. The number of rows should match. If one of them are missing, the other is taken as y and an x vector of <code>1:n</code> is used. Missing values (<code>NAs</code>) are allowed.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_col">col</code></td>
<td>
<p>vector of colors. Colors are used cyclically.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_lty">lty</code>, <code id="PlotLinesA_+3A_lwd">lwd</code>, <code id="PlotLinesA_+3A_lend">lend</code></td>
<td>
<p>vector of line types, widths, and end styles. The first element is for the first column, the second element for the second column, etc., even if lines are not plotted for all columns. Line types will be used cyclically until all plots are drawn.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_xlab">xlab</code>, <code id="PlotLinesA_+3A_ylab">ylab</code></td>
<td>
<p>titles for x and y axes, as in <a href="base.html#topic+plot">plot</a>.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_xlim">xlim</code>, <code id="PlotLinesA_+3A_ylim">ylim</code></td>
<td>
<p>ranges of x and y axes, as in <a href="base.html#topic+plot">plot</a>.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_xaxt">xaxt</code>, <code id="PlotLinesA_+3A_yaxt">yaxt</code></td>
<td>
<p>a character which specifies the x axis type. Specifying &quot;<code>n</code>&quot; suppresses plotting of the axis. The standard value is &quot;<code>s</code>&quot;, any value other than &quot;<code>n</code>&quot; implies plotting.</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_cex">cex</code></td>
<td>
<p>character expansion factor relative to current <code>par("cex")</code>.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_args.legend">args.legend</code></td>
<td>
<p>list of additional arguments for the legend; names of the list are used as argument names. If set to NA, the legend will be suppressed. See details.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_main">main</code></td>
<td>
<p>an overall title for the plot.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_grid">grid</code></td>
<td>
<p>logical adds an nx by ny rectangular grid to an existing plot.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_mar">mar</code></td>
<td>
<p>the margins of the plot.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_pch">pch</code></td>
<td>
<p>character string or vector of 1-characters or integers for plotting characters, see <code><a href="graphics.html#topic+points">points</a></code>. The first character is the plotting-character for the first plot, the second for the second, etc. The default is the digits (1 through 9, 0) then the lowercase and uppercase letters. If no points should be drawn set this argument to <code>NA</code> (this is the default).
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_pch.col">pch.col</code></td>
<td>
<p>vector of colors for the points. Colors are used cyclically. Ignored if <code>pch = NA</code>.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_pch.bg">pch.bg</code></td>
<td>
<p>vector of background (fill) colors for the open plot symbols given by <code>pch = 21:25</code> as in <code><a href="graphics.html#topic+points">points</a></code>. The default is set to <code>par("bg")</code>. Ignored if <code>pch = NA</code>.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_pch.cex">pch.cex</code></td>
<td>
<p>vector of character expansion sizes, used cyclically. This works as a multiple of <code><a href="graphics.html#topic+par">par</a>("cex")</code>. Default is 1.0. Ignored if <code>pch = NA</code>.
</p>
</td></tr>
<tr><td><code id="PlotLinesA_+3A_...">...</code></td>
<td>
<p>the dots are sent to <code><a href="graphics.html#topic+matplot">matplot</a></code></p>
</td></tr></table>
<p>.
</p>


<h3>Details</h3>

<p>This function is rather a template, than a function. It wraps <code><a href="graphics.html#topic+matplot">matplot</a></code> to generate a lines plot and adds a rather sophisticated legend on the right side, while calculating appropriate margins. A grid option is included (as <code>panel.first</code> does not work in matplot).
</p>
<p>As in matplot, the first column of x is plotted against the first column of y, the second column of x against the second column of y, etc. If one matrix has fewer columns, plotting will cycle back through the columns again. (In particular, either x or y may be a vector, against which all columns of the other argument will be plotted.)
</p>
<p>The legend can be controlled by following arguments:
</p>
<pre>list(line = c(1, 1), width = 1, y = SpreadOut(unlist(last), 
     mindist = 1.2 * strheight("M") * par("cex")), 
     labels = names(last), cex = par("cex"), col = col[ord], 
     lwd = lwd[ord], lty = lty[ord])</pre>
<p>All arguments are recycled.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+matplot">matplot</a></code>, <code><a href="graphics.html#topic+par">par</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- matrix(c(3,4,5,1,5,4,2,6,2), nrow = 3,
            dimnames = list(dose = c("A","B","C"),
                            age  = c("2010","2011","2012")))

PlotLinesA(m, col=c(Pal("Helsana")), main="Dose ~ age_grp", lwd=3, ylim=c(1, 10))


# example from MASS
shoes &lt;- list(
  A = c(13.2, 8.2, 10.9, 14.3, 10.7, 6.6, 9.5, 10.8, 8.8, 13.3),
  B = c(14, 8.8, 11.2, 14.2, 11.8, 6.4, 9.8, 11.3, 9.3, 13.6))

PlotLinesA(do.call(rbind, shoes), xlim=c(0.75,2.25), col=1, main="shoes",
           pch=21, pch.bg="white", pch.col=1, pch.cex=1.5)

# let's define some arbitrary x-coordinates
PlotLinesA(x=c(1,2,6,8,15), y=VADeaths)
</code></pre>

<hr>
<h2 id='PlotLog'>Logarithmic Plot
</h2><span id='topic+PlotLog'></span>

<h3>Description</h3>

<p>The base function <code><a href="graphics.html#topic+grid">grid</a>()</code> does not support logarithmic scales very well. Especially when more lines are required, grids have to be created manually. <code>PlotLog</code> creates a plot with at least one logarithmic axis and places a logarithmic grid in the background of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotLog(x, ..., args.grid = NULL, log = "xy")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotLog_+3A_x">x</code></td>
<td>
<p>the coordinates of points in the plot. Alternatively, a single plotting structure, function or any R object with a plot method can be provided.
</p>
</td></tr>
<tr><td><code id="PlotLog_+3A_...">...</code></td>
<td>
<p>the dots are passed on to the function <code>plot()</code>.
</p>
</td></tr>
<tr><td><code id="PlotLog_+3A_args.grid">args.grid</code></td>
<td>
<p>a list of arguments for the grid. This contains line type, line width and line color, separately for major gridlines and for minor gridlines.<br />
<code>args.grid=list(lwd=1, lty=3, col="grey85", col.min="grey60")</code> are used as default. If the argument is set to <code>NA</code>, no grid will be plotted.
</p>
</td></tr>
<tr><td><code id="PlotLog_+3A_log">log</code></td>
<td>
<p>a character string which contains &quot;<code>x</code>&quot; if the x axis is to be logarithmic, &quot;<code>y</code>&quot; if the y axis is to be logarithmic and &quot;<code>xy</code>&quot; or &quot;<code>yx</code>&quot; if both axes are to be logarithmic.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+axis">axis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotLog(brain ~ body, data=MASS::Animals, log="xy",
        xlim=c(.01, 1e5), ylim=c(.1, 1e4), main="Animal brain/body size",
        pch=21, bg="grey", cex=1.5)
</code></pre>

<hr>
<h2 id='PlotMarDens'>Scatterplot With Marginal Densities
</h2><span id='topic+PlotMarDens'></span>

<h3>Description</h3>

<p>Draw a scatter plot with marginal densities on the x- and y-axis. Groups can be defined by grp.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMarDens(x, y, grp = 1, xlim = NULL, ylim = NULL,
            col = rainbow(nlevels(factor(grp))),
            mardens = c("all","x","y"), pch = 1, pch.cex = 1,
            main = "", na.rm = FALSE, args.legend = NULL,
            args.dens = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMarDens_+3A_x">x</code></td>
<td>
<p>numeric vector of x values.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_y">y</code></td>
<td>
<p>numeric vector of y values (of same length as x).
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_grp">grp</code></td>
<td>
<p>grouping variable(s), typically factor(s), all of the same length as x.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_xlim">xlim</code></td>
<td>
<p>the x limits of the plot.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_ylim">ylim</code></td>
<td>
<p>the y limits of the plot.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_col">col</code></td>
<td>
<p>the colors for lines and points. Uses <code>rainbow()</code> colors by default.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_mardens">mardens</code></td>
<td>
<p>which marginal densities to plot. Can be set to either just x or y, or both (<code>"all"</code>, latter being the default).
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_pch">pch</code></td>
<td>
<p>a vector of plotting characters or symbols.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_pch.cex">pch.cex</code></td>
<td>
<p>magnification to be used for plotting characters relative to the current setting of cex.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_main">main</code></td>
<td>
<p>a main title for the plot, see also <a href="graphics.html#topic+title">title</a>.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, should NAs be omitted? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_args.legend">args.legend</code></td>
<td>
<p>list of additional arguments for the legend. <code>args.legend</code> set to <code>NA</code> prevents a legend from being drawn.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_args.dens">args.dens</code></td>
<td>
<p>list of additional arguments to be passed to <code>density</code>.
Use <code>args.dens = NA</code> if no density curve should be drawn. The defaults are taken from <code><a href="stats.html#topic+density">density</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotMarDens_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code>plot()</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+points">points</a></code>, <code><a href="stats.html#topic+density">density</a></code>, <code><a href="graphics.html#topic+layout">layout</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># best seen with: x11(7.5, 4.7)

# just one variable with marginal densities
PlotMarDens( y=d.pizza$temperature, x=d.pizza$delivery_min, grp=1
             , xlab="delivery_min", ylab="temperature", col=SetAlpha("brown", 0.4)
             , pch=15, lwd=3
             , panel.first= grid(), args.legend=NA
             , main="Temp ~ delivery"
)

# use a group variable
PlotMarDens( y=d.pizza$temperature, x=d.pizza$delivery_min, grp=d.pizza$area
  , xlab="delivery_min", ylab="temperature", col=c("brown","orange","lightsteelblue")
  , panel.first=list( grid() )
  , main = "temperature ~ delivery_min | area"
)
# reset layout
par(mfrow=c(1,1))
</code></pre>

<hr>
<h2 id='PlotMiss'>Plot Missing Data
</h2><span id='topic+PlotMiss'></span>

<h3>Description</h3>

<p>Takes a data frame and displays the location of missing data. The missings can be clustered and be displayed together.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMiss(x, col = hred, bg = SetAlpha(hecru, 0.3), clust = FALSE,
         main = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMiss_+3A_x">x</code></td>
<td>
<p>a data.frame to be analysed.
</p>
</td></tr>
<tr><td><code id="PlotMiss_+3A_col">col</code></td>
<td>
<p>the colour of the missings.
</p>
</td></tr>
<tr><td><code id="PlotMiss_+3A_bg">bg</code></td>
<td>
<p>the background colour of the plot.
</p>
</td></tr>
<tr><td><code id="PlotMiss_+3A_clust">clust</code></td>
<td>
<p>logical, defining if the missings should be clustered. Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="PlotMiss_+3A_main">main</code></td>
<td>
<p>the main title.
</p>
</td></tr>
<tr><td><code id="PlotMiss_+3A_...">...</code></td>
<td>
<p>the dots are passed to <code><a href="base.html#topic+plot">plot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A graphical display of the position of the missings can be help to detect dependencies or patterns within the missings.
</p>


<h3>Value</h3>

<p>if clust is set to TRUE, the new order will be returned invisibly.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, following an idea of Henk Harmsen &lt;henk@carbonmetrics.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="#topic+CountCompCases">CountCompCases</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotMiss(d.pizza, main="Missing pizza data")
</code></pre>

<hr>
<h2 id='PlotMonth'>Cycle Plot for Seasonal Effects of an Univariate Time Series
</h2><span id='topic+PlotMonth'></span>

<h3>Description</h3>

<p>Plot seasonal effects of a univariate time series following Cleveland's definition for cycle plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMonth(x, type = "l", labels, xlab = "", ylab = deparse(substitute(x)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMonth_+3A_x">x</code></td>
<td>
<p>univariate time series
</p>
</td></tr>
<tr><td><code id="PlotMonth_+3A_type">type</code></td>
<td>
<p>one out of <code>"l"</code> (line) or <code>"h"</code> (histogram), defines the plot type of the year components
</p>
</td></tr>
<tr><td><code id="PlotMonth_+3A_labels">labels</code></td>
<td>
<p>the labels for the cyclic component to be displayed on the x-axis
</p>
</td></tr>
<tr><td><code id="PlotMonth_+3A_xlab">xlab</code></td>
<td>
<p>a title for the x axis: see <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotMonth_+3A_ylab">ylab</code></td>
<td>
<p>a title for the y axis: see <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotMonth_+3A_...">...</code></td>
<td>
<p>the dots are passed to the plot command.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A cycle plot is a graphical method invented to study teh behaviour of a seasonal time series. The seasonal component of a univariate series is graphed. First the January values are graphed for successive years, then the February values and so forth. For each monthly subseries the mean of the values is portrayed by a horizontal line.
</p>


<h3>Author(s)</h3>

<p>Markus Huerzeler (ETH Zurich), slight changes Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>  Cleveland, W. S. (1985)
<em>The Elements of Graphing Data.</em>
Monterey, CA: Wadsworth.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+ts">ts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotMonth(AirPassengers)
</code></pre>

<hr>
<h2 id='PlotMosaic'>Mosaic Plots
</h2><span id='topic+PlotMosaic'></span>

<h3>Description</h3>

<p>Plots a mosaic on the current graphics device.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMosaic(x, main = deparse(substitute(x)), horiz = TRUE, cols = NULL,
           off = 0.02, mar = NULL, xlab = NULL, ylab = NULL,
           cex = par("cex"), las = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMosaic_+3A_x">x</code></td>
<td>
<p>a contingency table in array form, with optional category labels specified in the dimnames(x) attribute. The table is best created by the table() command. So far only 2-way tables are allowed.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_main">main</code></td>
<td>
<p>character string for the mosaic title.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_horiz">horiz</code></td>
<td>
<p>logical, defining the orientation of the mosaicplot. <code>TRUE</code> (default) makes a horizontal plot.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_cols">cols</code></td>
<td>
<p>the colors of the plot.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_off">off</code></td>
<td>
<p>the offset between the rectangles. Default is 0.02.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_mar">mar</code></td>
<td>
<p>the margin for the plot.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_xlab">xlab</code>, <code id="PlotMosaic_+3A_ylab">ylab</code></td>
<td>
<p>x- and y-axis labels used for the plot; by default, the first and second element of names(dimnames(X)) (i.e., the name of the first and second variable in X).
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_cex">cex</code></td>
<td>
<p>numeric character expansion factor; multiplied by <code>par("cex")</code> yields the final character size. <code>NULL</code> and <code>NA</code> are equivalent to 1.0.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_las">las</code></td>
<td>
<p>the style of axis labels. 0 - parallel to the axis, 1 - horizontal, 2 - perpendicular, 3 - vertical.
</p>
</td></tr>
<tr><td><code id="PlotMosaic_+3A_...">...</code></td>
<td>
<p>additional arguments are passed to the text function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for this function to exist are the unsatisfying labels in base mosaicplot.
</p>


<h3>Value</h3>

<p>list with the midpoints of the rectangles
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Friendly, M. (1994) Mosaic displays for multi-way contingency tables. <em>Journal of the American Statistical Association</em>, <b>89</b>, 190-200.
</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+mosaicplot">mosaicplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotMosaic(HairEyeColor[,,1])
</code></pre>

<hr>
<h2 id='PlotMultiDens'>Plot Multiple Density Curves
</h2><span id='topic+PlotMultiDens'></span><span id='topic+PlotMultiDens.default'></span><span id='topic+PlotMultiDens.formula'></span>

<h3>Description</h3>

<p>Multiple density curves are plotted on the same plot. The function
plots the density curves in the defined colors and linetypes, after having calculated the
globally appropriate xlim- and ylim-values. A legend can directly be included.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMultiDens(x, ...)

## Default S3 method:
PlotMultiDens(x, xlim = NULL, ylim = NULL, col = Pal(), lty = "solid",
              lwd = 2, fill = NA, xlab = "x", ylab = "density", args.dens = NULL,
              args.legend = NULL, na.rm = FALSE, flipxy = FALSE, ...)

## S3 method for class 'formula'
PlotMultiDens(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMultiDens_+3A_x">x</code></td>
<td>
<p>a list of vectors whose densities are to be plotted. Use <code><a href="base.html#topic+split">split</a></code> to separate a vector by groups.
(See examples)
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_xlim">xlim</code>, <code id="PlotMultiDens_+3A_ylim">ylim</code></td>
<td>
<p>xlim, ylim of the plot.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_col">col</code></td>
<td>
<p>colors of the lines, defaults to <code>Pal()</code>, returning the default palette.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_lty">lty</code></td>
<td>
<p>line type of the lines.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_lwd">lwd</code></td>
<td>
<p>line widths for the lines.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_fill">fill</code></td>
<td>
<p>colors for fill the area under the density curve. If set to <code>NA</code> (default) there will be no color.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_xlab">xlab</code>, <code id="PlotMultiDens_+3A_ylab">ylab</code></td>
<td>
<p>a title for the x, resp. y axis. Defaults to <code>"x"</code> and <code>"density"</code>.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_args.dens">args.dens</code></td>
<td>
<p>list of additional arguments to be passed to the <code>density</code> function. <br />
If set to <code>NULL</code> the defaults will be used. Those are <code>n = 4096</code> (2^12) and <code>kernel = "epanechnikov"</code>.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_args.legend">args.legend</code></td>
<td>
<p>list of additional arguments to be passed to the <code>legend</code> function.
Use <code>args.legend = NA</code> if no legend should be added.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_na.rm">na.rm</code></td>
<td>
<p>should <code>NA</code>s be omitted? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_flipxy">flipxy</code></td>
<td>
<p>logical, should x- and y-axis be flipped? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="PlotMultiDens_+3A_...">...</code></td>
<td>
<p>the dots are passed to <code>plot(...)</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All style arguments, density arguments and data list elements will be recycled if necessary.<br />
The argument <code>flipxy</code> leads to exchanged x- and y-values. This option can be used to plot density curves with a vertical orientation for displaying marginal densities.
</p>


<h3>Value</h3>

<p>data.frame with 3 columns, containing the <code>bw</code>, <code>n</code> and <code>kernel</code> parameters used for the list elements.
The number of rows correspond to the length of the list x.
</p>


<h3>Note</h3>

<p>Consider using: <br />
</p>
<pre>
  library(lattice)
  densityplot( ~ delivery_min | driver, data=d.pizza)
</pre>
<p>as alternative when not all curves should be plotted in the same plot.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotViolin">PlotViolin</a></code>, <code><a href="stats.html#topic+density">density</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(1000,0,1)
y &lt;- rnorm(1000,0,2)
z &lt;- rnorm(1000,2,1.5)

# the input of the following function MUST be a numeric list
PlotMultiDens(list(x=x,y=y,z=z))

# use area fill
PlotMultiDens(list(x=x,y=y,z=z), fill=SetAlpha(c("red","green","blue"), 0.4))


PlotMultiDens( x=split(d.pizza$delivery_min, d.pizza$driver), na.rm=TRUE
  , main="delivery time ~ driver", xlab="delivery time [min]", ylab="density"
  , lwd=1:7, lty=1:7
  , panel.first=grid())
# this example demonstrates the definition of different line types and -colors
# an is NOT thought as recommendation for good plotting practice... :-)


# the formula interface
PlotMultiDens(delivery_min ~ driver, data=d.pizza)

# recyling of the density parameters
res &lt;- PlotMultiDens(x=split(d.pizza$temperature, d.pizza$driver),
              args.dens = list(bw=c(5,2), kernel=c("rect","epanechnikov")), na.rm=TRUE)
res

# compare bandwidths
PlotMultiDens(x=split(d.pizza$temperature, d.pizza$driver)[1],
                     args.dens = list(bw=c(1:5)), na.rm=TRUE,
                     args.legend=NA, main="Compare bw")
legend(x="topright", legend=gettextf("bw = %s", 1:5), fill=rainbow(5))
</code></pre>

<hr>
<h2 id='PlotPairs'>Extended Scatterplot Matrices
</h2><span id='topic+PlotPairs'></span>

<h3>Description</h3>

<p>A matrix of scatterplots is produced.The upper triangular matrices contain nothing else than the correlation coefficient. The diagonal displays a histogram of the variable. The lower triangular matrix displays a scatterplot superposed by a smoother. It's possible to define groups to be differntiated by color and also by individual smoothers.
The used code is not much more than the <code><a href="graphics.html#topic+pairs">pairs</a>()</code> code and some examples, but condenses it to a practical amount.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotPairs(x, g = NULL, col = 1, pch = 19, col.smooth = 1, main = "", 
          upper = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotPairs_+3A_x">x</code></td>
<td>
<p>the coordinates of points given as numeric columns of a matrix or data frame. Logical and factor columns are converted to numeric in the same way that data.matrix does. Will directly be passed on to <code>pairs</code>.
</p>
</td></tr>
<tr><td><code id="PlotPairs_+3A_g">g</code></td>
<td>
<p>a group variable
</p>
</td></tr>
<tr><td><code id="PlotPairs_+3A_col">col</code></td>
<td>
<p>color for pointcharacter
</p>
</td></tr>
<tr><td><code id="PlotPairs_+3A_pch">pch</code></td>
<td>
<p>point character
</p>
</td></tr>
<tr><td><code id="PlotPairs_+3A_col.smooth">col.smooth</code></td>
<td>
<p>color for the smoother(s)
</p>
</td></tr>
<tr><td><code id="PlotPairs_+3A_main">main</code></td>
<td>
<p>the main title
</p>
</td></tr>
<tr><td><code id="PlotPairs_+3A_upper">upper</code></td>
<td>
<p>logical, determines if the correlation coefficients should be displayed in the upper triangular matrix (default) or in the lower one.</p>
</td></tr>
<tr><td><code id="PlotPairs_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>pairs</code> function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+pairs">pairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PlotPairs(iris[1:4], g=iris$Species, main = "Anderson's Iris Data -- 3 species",
          col=c(hred, hblue, hgreen), col.smooth=c("black", hred, hblue, hgreen))
</code></pre>

<hr>
<h2 id='PlotPolar'>Plot Values on a Circular Grid
</h2><span id='topic+PlotPolar'></span>

<h3>Description</h3>

<p><code>PlotPolar</code> creates a polar coordinate plot of the radius r in function of the angle theta.
0 degrees is drawn at the 3 o'clock position and angular values increase in a counterclockwise direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotPolar(r, theta = NULL, type = "p", rlim = NULL, main = "", lwd = par("lwd"),
          lty = par("lty"), col = par("col"), pch = par("pch"), fill = NA,
          cex = par("cex"), mar = c(2, 2, 5, 2), add = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotPolar_+3A_r">r</code></td>
<td>
<p>a vector of radial data.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_theta">theta</code></td>
<td>
<p>a vector of angular data specified in radians.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_type">type</code></td>
<td>
<p>one out of <code>c("p","l","h")</code>, the plot type, defined following the definition in plot type.
<code>"p"</code> means points, <code>"l"</code> will connect the points with lines and <code>"h"</code>
is used to plot radial lines from the center to the points.
<br /> Default is <code>"p"</code>.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_rlim">rlim</code></td>
<td>
<p>the r limits (r1, r2) of the plot
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_main">main</code></td>
<td>
<p>a main title for the plot, see also <code><a href="graphics.html#topic+title">title</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_lwd">lwd</code></td>
<td>
<p>a vector of line widths, see <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_lty">lty</code></td>
<td>
<p>a vector of line types, see <code><a href="graphics.html#topic+par">par</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_col">col</code></td>
<td>
<p>The colors for lines and points. Multiple colors can be specified so that each point
can be given its own color. If there are fewer colors than points they are recycled
in the standard fashion. Lines will all be plotted in the first colour specified.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_pch">pch</code></td>
<td>
<p>a vector of plotting characters or symbols: see <code><a href="graphics.html#topic+points">points</a></code>.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_fill">fill</code></td>
<td>
<p>fill color, defaults to <code>NA</code> (none).
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_cex">cex</code></td>
<td>
<p>a numerical vector giving the amount by which plotting characters and symbols should
be scaled relative to the default. This works as a multiple of <code>par("cex")</code>.
<code>NULL</code> and <code>NA</code> are equivalent to 1.0.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_mar">mar</code></td>
<td>
<p>A numerical vector of the form c(bottom, left, top, right) which gives the number of lines of
margin to be specified on the four sides of the plot.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_add">add</code></td>
<td>
<p>defines whether points should be added to an existing plot.
</p>
</td></tr>
<tr><td><code id="PlotPolar_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the plot command.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is rather flexible and can produce quite a lot of of different plots.
So is it also possible to create spider webs or radar plots.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PolarGrid">PolarGrid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testlen &lt;- c(sin(seq(0, 1.98*pi, length=100))+2+rnorm(100)/10)
testpos &lt;- seq(0, 1.98*pi, length=100)

PlotPolar(testlen, testpos, type="l", main="Test Polygon", col="blue")
PolarGrid(ntheta=9, col="grey", lty="solid", lblradians=TRUE)

# start at 12 o'clock and plot clockwise
PlotPolar(testlen, -(testpos - pi/2), type="p", main="Test Polygon",
          col="green", pch=16)

PolarGrid(ntheta = rev(seq(0, 2*pi, by=2*pi/9) + pi/2),
          alabels=Format(seq(0, 2*pi, by=2*pi/9), digits=2)[-10], col="grey",
          lty="solid", lblradians=TRUE)


# just because of it's beauty
t &lt;- seq(0,2*pi,0.01)
PlotPolar( r=sin(2*t)*cos(2*t), theta=t, type="l", lty="dashed", col="red" )
PolarGrid()


# use some filled polygons
ions &lt;- c(3.2,5,1,3.1,2.1,5)
ion.names &lt;- c("Na","Ca","Mg","Cl","HCO3","SO4")

PlotPolar(r = ions, type="l", fill="yellow")

# the same, but let's have a grid first
PlotPolar(r = ions, type="l", lwd=2, col="blue", main="Ions",
          panel.first=PolarGrid(nr=seq(0, 6, 1)) )

# leave the radial grid out
PlotPolar(r = ions, type="l", fill="yellow")
PolarGrid(nr = NA, ntheta = length(ions), alabels = ion.names,
          col = "grey", lty = "solid" )

# display radial lines
PlotPolar(r = ions, type="h", col="blue", lwd=3)
# add some points
PlotPolar(r = ions, type="p", pch=16, add=TRUE, col="red", cex=1.5)

# spiderweb (not really recommended...)
posmat &lt;- matrix(sample(2:9,30,TRUE),nrow=3)
PlotPolar(posmat, type="l", main="Spiderweb plot", col=2:4, lwd=1:3)
PolarGrid(nr=NA, ntheta=ncol(posmat), alabels=paste("X", 1:ncol(posmat), sep=""),
          col="grey", lty="solid" )

# example from: The grammar of graphics (L. Wilkinson)
data("UKgas")
m &lt;- matrix(UKgas, ncol=4, byrow=TRUE)
cols &lt;- c(SetAlpha(rep("green", 10), seq(0,1,0.1)),
          SetAlpha(rep("blue", 10), seq(0,1,0.1)),
          SetAlpha(rep("orange", 10), seq(0,1,0.1)))

PlotPolar(r=m, type="l", col=cols, lwd=2 )
PolarGrid(ntheta=4, alabels=c("Winter","Spring","Summer","Autumn"), lty="solid")
legend(x="topright", legend=c(1960,1970,1980), fill=c("green","blue","orange"))


# radarplot (same here, consider alternatives...)
data(mtcars)
d.car &lt;- scale(mtcars[1:6,1:7], center=FALSE)

# let's have a palette with transparent colors (alpha = 32)
cols &lt;- SetAlpha(colorRampPalette(c("red","yellow","blue"), space = "rgb")(6), 0.25)
PlotPolar(d.car, type="l", fill=cols, main="Cars in radar")
PolarGrid(nr=NA, ntheta=ncol(d.car), alabels=colnames(d.car), lty="solid", col="black")

# a polar barplot
x &lt;- c(4,8,2,8,2,6,5,7,3,3,5,3)
theta &lt;- (0:12) * pi / 6
PlotPolar(x, type = "n", main="Some data")
PolarGrid(nr = 0:9, ntheta = 24, col="grey", lty=1, rlabels = NA, alabels = NA)
DrawCircle(x=0, y=0, r.in=0, r.out=x,
                  theta.1 = theta[-length(theta)], theta.2 = theta[-1],
                  col=SetAlpha(rainbow(12), 0.7), border=NA)

segments(x0 = -10:10, y0 = -.2, y1=0.2)
segments(x0=-10, x1=10, y0 = 0)

segments(y0 = -10:10, x0 = -.2, x1=0.2)
segments(y0=-10, y1=10, x0 = 0)

BoxedText(x=0, y=c(0,3,6,9), labels = c(0,3,6,9), xpad = .3, ypad=.3, border="grey35")

# USJudgeRatings
PlotPolar(USJudgeRatings[1,], type="l", col=hblue, lwd=2, cex=0.8, #fill=SetAlpha("blue", 0.4),
          panel.first=PolarGrid(ntheta=ncol(USJudgeRatings), col="grey", lty="solid",
                                las=1, alabels=colnames(USJudgeRatings), lblradians=TRUE))
PlotPolar(USJudgeRatings[2,], type="l", col=hred, lwd=2, add=TRUE)
PlotPolar(USJudgeRatings[5,], type="l", col=horange, lwd=2, add=TRUE)

legend(x="topright", inset=-0.18, col = c(hblue,hred,horange), lwd=2,
       legend=rownames(USJudgeRatings)[c(1, 2, 5)])

</code></pre>

<hr>
<h2 id='PlotProbDist'>Plot Probability Distribution
</h2><span id='topic+PlotProbDist'></span>

<h3>Description</h3>

<p>Produce a plot from a probability distribution with shaded areas. This is often needed in theory texts for classes in statistics. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotProbDist(breaks, FUN, 
             blab = NULL, main = "", xlim = NULL, col = NULL, density = 7, 
             alab = LETTERS[1:(length(breaks) - 1)], 
             alab_x = NULL, alab_y = NULL, ylab = "density", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotProbDist_+3A_breaks">breaks</code></td>
<td>
<p>a numeric vector containing the breaks of different areas. The start and end must not be infinity.
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_fun">FUN</code></td>
<td>
<p>the (typically) distribution function
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_blab">blab</code></td>
<td>
<p>text for labelling the breaks
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_main">main</code></td>
<td>
<p>main title for the plot
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_xlim">xlim</code></td>
<td>
<p>the x-limits for the plot
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_col">col</code></td>
<td>
<p>the color for the shaded areas
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_density">density</code></td>
<td>
<p>the density for the shaded areas
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_alab">alab</code></td>
<td>
<p>the labels for areas
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_alab_x">alab_x</code></td>
<td>
<p>the x-coord for the area labels
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_alab_y">alab_y</code></td>
<td>
<p>the y-coord for the area labels, if left to default they will be placed in the middle of the plot
</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_ylab">ylab</code></td>
<td>
<p>the label for they y-axis</p>
</td></tr>
<tr><td><code id="PlotProbDist_+3A_...">...</code></td>
<td>
<p>further parameters passed to internally used function <code><a href="graphics.html#topic+curve">curve</a>()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function sets up a two-step plot procedure based on curve() and Shade() with additional labelling for convenience.
</p>


<h3>Value</h3>

<p>nothing returned
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Shade">Shade</a></code>, <code><a href="graphics.html#topic+curve">curve</a></code>, <code><a href="graphics.html#topic+polygon">polygon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># plot t-distribution
PlotProbDist(breaks=c(-6, -2.3, 1.5, 6), 
             function(x) dt(x, df=8), 
             blab=c("A","B"), xlim=c(-4,4), alab=NA,
             main="t-Distribution (df=8)",
             col=c(hred, hblue, horange), density=c(20, 7))

# Normal
PlotProbDist(breaks=c(-10, -1, 12), 
             function(x) dnorm(x, mean=2, sd=2), 
             blab="A", xlim=c(-7,10),
             main="Normal-Distribution N(2,2)",
             col=c(hred, hblue), density=c(20, 7))

# same for Chi-square
PlotProbDist(breaks=c(0, 15, 35), 
             function(x) dchisq(x, df=8), 
             blab="B", xlim=c(0, 30),
             main=expression(paste(chi^2-Distribution, " (df=8)")),
             col=c(hblue, hred), density=c(0, 20))
</code></pre>

<hr>
<h2 id='PlotPyramid'>Draw a Back To Back Pyramid Plot
</h2><span id='topic+PlotPyramid'></span>

<h3>Description</h3>

<p>Pyramid plots are a common way to display the distribution of age groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotPyramid(lx, rx = NA, ylab = "", ylab.x = 0,
            col = c("red", "blue"), border = par("fg"),
            main = "", lxlab = "", rxlab = "",
            xlim = NULL, gapwidth = NULL,
            xaxt = TRUE, args.grid = NULL, cex.axis = par("cex.axis"),
            cex.lab = par("cex.axis"), cex.names = par("cex.axis"),
            adj = 0.5, rev = FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotPyramid_+3A_lx">lx</code></td>
<td>
<p>either a vector or matrix of values describing the bars which make up the plot. If lx is a vector, it will be used to construct the left barplot. If lx is a matrix the first column will be plotted to the left side and the second to the right side. Other columsn are ignored. </p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_rx">rx</code></td>
<td>
<p>a vector with the values used to build the right barplot. lx and rx should be of equal length.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_ylab">ylab</code></td>
<td>
<p>a vector of names to be plotted either in the middle or at the left side of the plot. If this argument is omitted, then the names are taken from the names attribute of lx if this is a vector.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_ylab.x">ylab.x</code></td>
<td>
<p>the x-position of the y-labels.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_col">col</code></td>
<td>
<p>the color(s) of the bars. If there are more than one the colors will be recycled.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_border">border</code></td>
<td>
<p>the border color of the bars. Set this to <code>NA</code> if no border is to be plotted.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_main">main</code></td>
<td>
<p>overall title for the plot. </p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_lxlab">lxlab</code></td>
<td>
<p>a label for the left x axis.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_rxlab">rxlab</code></td>
<td>
<p>a label for the right x axis.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_xlim">xlim</code></td>
<td>
<p>limits for the x axis. The first value will determine the limit on the left, the second the one on the right.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_gapwidth">gapwidth</code></td>
<td>
<p>the width of a gap in the middle of the plot. If set to 0, no gap will be plotted. Default is NULL
which will make the gap as wide, as it is necessary to plot the longest ylab.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_xaxt">xaxt</code></td>
<td>
<p>a character which specifies the x axis type. Specifying &quot;n&quot; suppresses plotting of the axis. </p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_args.grid">args.grid</code></td>
<td>
<p>list of additional arguments for the grid. Set this argument to <code>NA</code> if no grid should be drawn. </p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_cex.axis">cex.axis</code></td>
<td>
<p>expansion factor for numeric axis labels.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_cex.lab">cex.lab</code></td>
<td>
<p>expansion factor for numeric variable labels.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_cex.names">cex.names</code></td>
<td>
<p>expansion factor for y labels (names).</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_adj">adj</code></td>
<td>
<p>one or two values in [0, 1] which specify the x (and optionally y) adjustment of the labels.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_rev">rev</code></td>
<td>
<p>logical, if set to <code>TRUE</code> the order of data series and names will be reversed.</p>
</td></tr>
<tr><td><code id="PlotPyramid_+3A_...">...</code></td>
<td>
<p>the dots are passed to the <code><a href="graphics.html#topic+barplot">barplot</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pyramid plots are a common way to display the distribution of age groups in a human population. The percentages of people within a given age category are arranged in a barplot, typically back to back. Such displays can be used to distinguish males vs. females, differences between two different countries or the distribution of age at different timepoints.
The plot type can also be used to display other types of opposed bar charts with suitable modification of the arguments.
</p>


<h3>Value</h3>

<p>A numeric vector giving the coordinates of all the bar midpoints drawn, useful for adding to the graph.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+barplot">barplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.sda &lt;- data.frame(
  kt_x =  c("ZH","BL","ZG","SG","LU","AR","SO","GL","SZ",
            "NW","TG","UR","AI","OW","GR","BE","SH","AG",
            "BS","FR","GE","JU","NE","TI","VD","VS"),
  apo_n = c(18,16,13,11,9,12,11,8,9,8,11,9,7,9,24,19,
            19,20,43,27,41,31,37,62,38,39),
  sda_n = c(235,209,200,169,166,164,162,146,128,127,
            125,121,121,110,48,34,33,0,0,0,0,0,0,0,0,0)
)

PlotPyramid(lx=d.sda[,c("apo_n","sda_n")], ylab=d.sda$kt_x,
            col=c("lightslategray", "orange2"), border = NA, ylab.x=0,
            xlim=c(-110,250),
            gapwidth = NULL, cex.lab = 0.8, cex.axis=0.8, xaxt = TRUE,
            lxlab="Drugstores", rxlab="General practitioners",
            main="Density of general practitioners and drugstores in CH (2010)",
            space=0.5, args.grid=list(lty=1))


par(mfrow=c(1,3))

m.pop&lt;-c(3.2,3.5,3.6,3.6,3.5,3.5,3.9,3.7,3.9,3.5,
         3.2,2.8,2.2,1.8,1.5,1.3,0.7,0.4)
f.pop&lt;-c(3.2,3.4,3.5,3.5,3.5,3.7,4,3.8,3.9,3.6,3.2,
         2.5,2,1.7,1.5,1.3,1,0.8)
age &lt;- c("0-4","5-9","10-14","15-19","20-24","25-29",
         "30-34","35-39","40-44","45-49","50-54",
         "55-59","60-64","65-69","70-74","75-79","80-44","85+")

PlotPyramid(m.pop, f.pop,
            ylab = age, space = 0, col = c("cornflowerblue", "indianred"),
            main="Age distribution at baseline of HELP study",
            lxlab="male", rxlab="female" )

PlotPyramid(m.pop, f.pop,
            ylab = age, space = 0, col = c("cornflowerblue", "indianred"),
            xlim=c(-5,5),
            main="Age distribution at baseline of HELP study",
            lxlab="male", rxlab="female", gapwidth=0, ylab.x=-5 )


PlotPyramid(c(1,3,5,2,0.5), c(2,4,6,1,0),
            ylab = LETTERS[1:5], space = 0.3, col = rep(rainbow(5), each=2),
            xlim=c(-10,10), args.grid=NA, cex.names=1.5, adj=1,
            lxlab="Group A", rxlab="Group B", gapwidth=0, ylab.x=-8, xaxt="n")
</code></pre>

<hr>
<h2 id='PlotQQ'>QQ-Plot for Any Distribution
</h2><span id='topic+PlotQQ'></span>

<h3>Description</h3>

<p>Create a QQ-plot for a variable of any distribution.
The assumed underlying distribution can be defined as a function of f(p), including all required parameters. Confidence bands are provided by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotQQ(x, qdist=qnorm, main = NULL, xlab = NULL, ylab = NULL, datax = FALSE, add = FALSE,
       args.qqline = NULL, conf.level = 0.95, args.cband = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotQQ_+3A_x">x</code></td>
<td>
<p>the data sample
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_qdist">qdist</code></td>
<td>
<p>the quantile function of the assumed distribution. Can either be given as simple function name or defined as own function using the required arguments. Default is <code>qnorm()</code>. See examples.
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_main">main</code></td>
<td>
<p>the main title for the plot. This will be &quot;Q-Q-Plot&quot; by default
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_xlab">xlab</code></td>
<td>
<p>the xlab for the plot
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_ylab">ylab</code></td>
<td>
<p>the ylab for the plot
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_datax">datax</code></td>
<td>
<p>logical. Should data values be on the x-axis? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_add">add</code></td>
<td>
<p>logical specifying if the points should be added to an already existing plot; defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_args.qqline">args.qqline</code></td>
<td>
<p>arguments for the qqline. This will be estimated
as a line through the 25% and 75% quantiles by default, which is the same procedure as <code><a href="stats.html#topic+qqline">qqline</a>()</code> does for normal
distribution (instead of set it to <code>abline(a = 0, b = 1))</code>. The quantiles can however be overwritten by setting the argument <code>probs</code> to some user defined values. Also the method for calculating the quantiles can be defined (default is 7, see <code><a href="stats.html#topic+quantile">quantile</a></code>). The line defaults are set to <code>col = par("fg")</code>, <code>lwd = par("lwd")</code> and <code>lty = par("lty")</code>.
No line will be plotted if <code>args.qqline</code> is set to <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the confidence interval. Set this to <code>NA</code>, if no confidence band should be plotted.
Default is <code>0.95</code>. The confidence intervals are calculated pointwise method based on a Kolmogorov-Smirnov distribution.
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_args.cband">args.cband</code></td>
<td>
<p>list of arguments for the confidence band, such as color or border (see <code><a href="#topic+DrawBand">DrawBand</a></code>).
</p>
</td></tr>
<tr><td><code id="PlotQQ_+3A_...">...</code></td>
<td>
<p>the dots are passed to the plot function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function generates a sequence of points between 0 and 1 and transforms those
into quantiles by means of the defined assumed distribution.
</p>


<h3>Note</h3>

<p> The code is inspired by the tip 10.22 &quot;Creating other Quantile-Quantile plots&quot; from R Cookbook and based on R-Core code from the function <code>qqline</code>. The calculation of confidence bands are rewritten based on an algorithm published in the package <code>BoutrosLab.plotting.general</code>.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, Ying Wu &lt;Ying.Wu@stevens.edu&gt;
</p>


<h3>References</h3>

<p>Teetor, P. (2011) <em>R Cookbook</em>. O'Reilly, pp. 254-255.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+qqnorm">qqnorm</a></code>, <code><a href="stats.html#topic+qqline">qqline</a></code>, <code><a href="stats.html#topic+qqplot">qqplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rexp(100, 1/10)
PlotQQ(y, function(p) qexp(p, rate=1/10))

w &lt;- rweibull(100, shape=2)
PlotQQ(w, qdist = function(p) qweibull(p, shape=4))

z &lt;- rchisq(100, df=5)
PlotQQ(z, function(p) qchisq(p, df=5),
       args.qqline=list(col=2, probs=c(0.1, 0.6)),
       main=expression("Q-Q plot for" ~~ {chi^2}[nu == 3]))
abline(0,1)

# add 5 random sets
for(i in 1:5){
  z &lt;- rchisq(100, df=5)
  PlotQQ(z, function(p) qchisq(p, df=5), add=TRUE, args.qqline = NA,
         col="grey", lty="dotted")
}
</code></pre>

<hr>
<h2 id='PlotTernary'>Ternary or Triangular Plots</h2><span id='topic+PlotTernary'></span>

<h3>Description</h3>

<p><code>PlotTernary</code> plots in a triangle the values of three variables. Useful for mixtures
(chemistry etc.).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotTernary(x, y = NULL, z = NULL, args.grid = NULL, lbl = NULL, main = "",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotTernary_+3A_x">x</code></td>
<td>
<p>vector of first variable. Will be placed on top of the triangle.</p>
</td></tr>
<tr><td><code id="PlotTernary_+3A_y">y</code></td>
<td>
<p>vector of second variable (the right corner).</p>
</td></tr>
<tr><td><code id="PlotTernary_+3A_z">z</code></td>
<td>
<p>vector of third variable (on the left corner).</p>
</td></tr>
<tr><td><code id="PlotTernary_+3A_args.grid">args.grid</code></td>
<td>
<p>list of additional arguments for the grid. Set this argument to <code>NA</code> if no grid should be drawn.  The usual color and linetype will be used.</p>
</td></tr>
<tr><td><code id="PlotTernary_+3A_main">main</code></td>
<td>
<p>overall title for the plot. </p>
</td></tr>
<tr><td><code id="PlotTernary_+3A_lbl">lbl</code></td>
<td>
<p>the labels for the corner points. Default to the names of x, y, z.</p>
</td></tr>
<tr><td><code id="PlotTernary_+3A_...">...</code></td>
<td>
<p>the dots are sent to <code><a href="graphics.html#topic+points">points</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; based on example code by W. N. Venables and B. D. Ripley mentioned
</p>


<h3>References</h3>

<p>J. Aitchison (1986)
<em>The Statistical Analysis of Compositional Data.</em>
Chapman and Hall, p.360.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p>example in <code><a href="MASS.html#topic+Skye">Skye</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># some random data in three variables
c1 &lt;- runif(25)
c2 &lt;- runif(25)
c3 &lt;- runif(25)

# basic plot
par(mfrow=c(1, 2))
PlotTernary(c1, c2, c3, args.grid=NA)

## Not run: 
# plot with different symbols and a grid using a dataset from MASS
data(Skye, package="MASS")

PlotTernary(Skye[c(1,3,2)], pch=15, col=hred, main="Skye",
            lbl=c("A Sodium", "F Iron", "M Magnesium"))

## End(Not run)
</code></pre>

<hr>
<h2 id='PlotTreemap'>Create a Treemap
</h2><span id='topic+PlotTreemap'></span>

<h3>Description</h3>

<p>Creates a treemap where rectangular regions of different size, color,
and groupings visualize the elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotTreemap(x, grp = NULL, labels = NULL, cex = 1, text.col = "black",
            col = rainbow(length(x)), labels.grp = NULL, cex.grp = 3,
            text.col.grp = "black", border.grp = "grey50",
            lwd.grp = 5, main = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotTreemap_+3A_x">x</code></td>
<td>
<p>a vector storing the values to be used to calculate the
areas of rectangles.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_grp">grp</code></td>
<td>
<p>a vector specifying the group (i.e. country, sector,
etc.) to which each element belongs.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_labels">labels</code></td>
<td>
<p>a vector specifying the labels.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_cex">cex</code></td>
<td>
<p>the character extension for the area labels. Default is 1.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_text.col">text.col</code></td>
<td>
<p>the text color of the area labels. Default is &quot;black&quot;.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_col">col</code></td>
<td>
<p> a vector storing the values to be used to calculate the
color of rectangles.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_labels.grp">labels.grp</code></td>
<td>
<p>a character vector specifying the labels for the groups.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_cex.grp">cex.grp</code></td>
<td>
<p>the character extension for the group labels. Default is 3.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_text.col.grp">text.col.grp</code></td>
<td>
<p>the text color of the group labels. Default is &quot;black&quot;.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_border.grp">border.grp</code></td>
<td>
<p>the border color for the group rectangles. Default is &quot;grey50&quot;. Set this to <code>NA</code> if no special border
is desired.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_lwd.grp">lwd.grp</code></td>
<td>
<p>the linewidth of the group borders. Default is 5.
</p>
</td></tr>
<tr><td><code id="PlotTreemap_+3A_main">main</code></td>
<td>
<p>a title for the plot.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A treemap is a two-dimensional visualization for quickly analyzing large, hierarchical data sets. Treemaps are unique among visualizations because they provide users with the ability to see both a high level overview of data as well as fine-grained details. Users can find outliers, notice trends, and perform comparisons using treemaps.
Each data element contained in a treemap is represented with a rectangle, or a cell. Treemap cell arrangement, size, and color are each mapped to an attribute of that element. Treemap cells can be grouped by common attributes. Within a group, larger cells are placed towards the bottom left, and smaller cells are placed at the top right.
</p>


<h3>Value</h3>

<p>returns a list with groupwise organized midpoints in x and y for the rectangles within a group and for the groups themselves.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, strongly based on code from Jeff Enos <a href="mailto:jeff@kanecap.com">jeff@kanecap.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotCirc">PlotCirc</a></code>, <code><a href="graphics.html#topic+mosaicplot">mosaicplot</a></code>, <code><a href="graphics.html#topic+barplot">barplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1789)
N &lt;- 20
area &lt;- rlnorm(N)

PlotTreemap(x=sort(area, decreasing=TRUE), labels=letters[1:20], col=Pal("RedToBlack", 20))


grp &lt;- sample(x=1:3, size=20, replace=TRUE, prob=c(0.2,0.3,0.5))

z &lt;- Sort(data.frame(area=area, grp=grp), c("grp","area"), decreasing=c(FALSE,TRUE))
z$col &lt;- SetAlpha(c("steelblue","green","yellow")[z$grp],
                  unlist(lapply(split(z$area, z$grp),
                  function(...) LinScale(..., newlow=0.1, newhigh=0.6))))

PlotTreemap(x=z$area, grp=z$grp, labels=letters[1:20], col=z$col)


b &lt;- PlotTreemap(x=z$area, grp=z$grp, labels=letters[1:20], labels.grp=NA,
                 col=z$col, main="Treemap")

# the function returns the midpoints of the areas
# extract the group midpoints from b
mid &lt;- do.call(rbind, lapply(lapply(b, "[", 1), data.frame))

# and draw some visible text
BoxedText( x=mid$grp.x, y=mid$grp.y, labels=LETTERS[1:3], cex=3, border=NA,
  col=SetAlpha("white",0.7) )
</code></pre>

<hr>
<h2 id='PlotVenn'>Plot a Venn Diagram
</h2><span id='topic+PlotVenn'></span>

<h3>Description</h3>

<p>This function produces Venn diagrams for up to 5 datasets. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotVenn(x, col = "transparent", plotit = TRUE, labels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotVenn_+3A_x">x</code></td>
<td>
<p>the list with the sets to be analysed. Those can be factors or something coercable to a factor.
</p>
</td></tr>
<tr><td><code id="PlotVenn_+3A_col">col</code></td>
<td>
<p>the colors for the sets on the plot.
</p>
</td></tr>
<tr><td><code id="PlotVenn_+3A_plotit">plotit</code></td>
<td>
<p>logical. Should a plot be produced or just the results be calculated.
</p>
</td></tr>
<tr><td><code id="PlotVenn_+3A_labels">labels</code></td>
<td>
<p>special labels for the plot. By default the names of the list x will be used. If those are missing, the LETTERS A..E will be chosen. Set this argument to NA, if no labels at all should be plotted.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates the necessary frequencies and plots the venn diagram. 
</p>


<h3>Value</h3>

<p>a list with 2 elements, the first contains a table with the observed frequencies in the given sets.
The second returns a data.frame with the xy coordinates for the labels in the venn diagram, the specific combination of factors and 
the frequency in that intersection area. The latter can be 0 as well.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Venn, J. (1880): On the Diagrammatic and Mechanical Representation of Propositions and Reasonings. 
<em>Dublin Philosophical Magazine and Journal of Science</em> 9 (59): 1-18.
</p>
<p>Edwards, A.W.F. (2004): Cogwheels of the mind: the story of Venn diagrams. <em>JHU Press</em> ISBN 978-0-8018-7434-5.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>element &lt;- function() paste(sample(LETTERS, 5, replace=TRUE), collapse="")
group &lt;- replicate(1000, element())

GroupA &lt;- sample(group, 400, replace=FALSE)
GroupB &lt;- sample(group, 750, replace=FALSE)
GroupC &lt;- sample(group, 250, replace=FALSE)
GroupD &lt;- sample(group, 300, replace=FALSE)

x &lt;- list(GroupA, GroupB, GroupC, GroupD)
x

PlotVenn(x=list(GroupA, GroupB))
PlotVenn(x=list(Set_1=GroupA, Set_2=GroupB))
PlotVenn(x=list(GroupA, GroupB), labels=c("English","Spanish"))

PlotVenn(x=x[1:3])
PlotVenn(x=x[1:4], col=SetAlpha(c("blue","red","yellow","green","lightblue"), 0.2))

r.venn &lt;- PlotVenn(x=x[1:5], col=SetAlpha(c("blue","red","yellow","green","lightblue"), 0.2))
r.venn
</code></pre>

<hr>
<h2 id='PlotViolin'> Plot Violins Instead of Boxplots </h2><span id='topic+PlotViolin'></span><span id='topic+PlotViolin.default'></span><span id='topic+PlotViolin.formula'></span>

<h3>Description</h3>

<p>This function serves the same utility as side-by-side boxplots, only
it provides more detail about the different distribution. It
plots violins instead of boxplots. That is, instead of a box, it
uses the density function to plot the density. For skewed
distributions, the results look like &quot;violins&quot;. Hence the name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotViolin(x, ...)

## Default S3 method:
PlotViolin(x, ..., horizontal = FALSE, bw = "SJ", na.rm = FALSE, 
           names = NULL, args.boxplot = NULL) 

## S3 method for class 'formula'
PlotViolin(formula, data, subset, na.action, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotViolin_+3A_x">x</code></td>
<td>
<p>Either a sequence of variable names, or a data frame, or a model formula</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_horizontal">horizontal</code></td>
<td>
<p>logical indicating if the densityplots should be horizontal; default <code>FALSE</code> means vertical arrangement.</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_bw">bw</code></td>
<td>
<p>the smoothing bandwidth (method) being used by <code><a href="stats.html#topic+density">density</a></code>. <br />
<code>bw</code> can also be a character string giving a rule to choose the bandwidth. See <code><a href="stats.html#topic+bw.nrd">bw.nrd</a></code>. 
The default, has been switched from <code>"nrd0"</code> to <code>"SJ"</code>, following the general recommendation in Venables &amp; Ripley (2002). <br />
In case of a method, the average computed bandwidth is used.</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, should NAs be omitted? The density-function can't do with missings. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_names">names</code></td>
<td>
<p>a vector of names for the groups.</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_formula">formula</code></td>
<td>
<p>a formula, such as y ~ grp, where y is a numeric vector of data values to be split into groups according to the grouping variable grp (usually a factor).</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_data">data</code></td>
<td>
<p>a data.frame (or list) from which the variables in formula should be taken.</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used for plotting.</p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>  
<tr><td><code id="PlotViolin_+3A_...">...</code></td>
<td>
<p>The dots are passed to <code><a href="graphics.html#topic+polygon">polygon</a></code>. Notably, you can set the color to red with <code>col="red"</code>, and a border color with <code>border="blue"</code></p>
</td></tr>
<tr><td><code id="PlotViolin_+3A_args.boxplot">args.boxplot</code></td>
<td>
<p>list of arguments for a boxplot to be superposed to the densityplot. By default (NULL) a 
black boxplot will be drawn. Set this to <code>NA</code> to suppress the boxplot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If a boxplot was drawn then the function returns a list with the following components:
</p>
<table>
<tr><td><code>stats</code></td>
<td>
<p>a matrix, each column contains the extreme of the lower
whisker, the lower hinge, the median, the upper hinge and the
extreme of the upper whisker for one group/plot.  If all the inputs
have the same class attribute, so will this component.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>a vector with the number of observations in each group.</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>a matrix where each column contains the lower and upper
extremes of the notch.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>the values of any data points which lie beyond the
extremes of the whiskers.</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>a vector of the same length as <code>out</code> whose elements
indicate to which group the outlier belongs.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>a vector of names for the groups.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> This function is based on <code><a href="UsingR.html#topic+violinplot">violinplot</a></code> (package <span class="pkg">UsingR</span>). 
Some adaptions were made in the interface, such as to accept the same
arguments as <code><a href="graphics.html#topic+boxplot">boxplot</a></code> does. Moreover the function was extended by the option to have a boxplot superposed.
</p>


<h3>Author(s)</h3>

<p> John Verzani, Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p> The code is based on the boxplot function from R/base.</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+boxplot">boxplot</a></code>, <code><a href="#topic+PlotMultiDens">PlotMultiDens</a></code> , <code><a href="stats.html#topic+density">density</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># make a "violin"
x &lt;- c(rnorm(100), rnorm(50,5))

PlotViolin(x, col = "brown")

par(mfrow=c(1,2))
f &lt;- factor(rep(1:5, 30))
# make a quintet. Note also choice of bandwidth
PlotViolin(x ~ f, col = SetAlpha("steelblue",0.3), bw = "SJ", main="Vertical")

# and the same, but in horizontal arrangement
PlotViolin(x ~ f, col = SetAlpha("steelblue",0.3), bw = "SJ", horizontal = TRUE, 
  las=1, main="Horizontal")


# example taken from boxplot
boxplot(count ~ spray, data = InsectSprays, col = "lightgray", main="Boxplot")
PlotViolin(count ~ spray, data = InsectSprays, col = "lightgray", main="Violinplot")


# groupwise densityplots defined the same way as in boxplot
boxplot(len ~ supp*dose, data = ToothGrowth,
        main = "Guinea Pigs' Tooth Growth",
        xlab = "Vitamin C dose mg", ylab = "tooth length",
        col=c("yellow", "orange"), lty=c(1,2)
)

b &lt;- PlotViolin(len ~ supp*dose, data = ToothGrowth,
           main = "Guinea Pigs' Tooth Growth",
           xlab = "Vitamin C dose mg", ylab = "tooth length",
           col=c("yellow", "orange"), lty=c(1,2)
)
# use points, if the medians deserve special attention
points(x=1:6, y=b$stats[3,], pch=21, bg="white", col="black", cex=1.2)
</code></pre>

<hr>
<h2 id='PlotWeb'>Plot a Web of Connected Points
</h2><span id='topic+PlotWeb'></span>

<h3>Description</h3>

<p>This plot can be used to graphically display a correlation matrix by using the linewidth between the nodes
in proportion to the correlation of two variables. It will place the elements homogenously around a circle and draw
connecting lines between the points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotWeb(m, col = c(hred, hblue), lty = NULL, lwd = NULL, args.legend=NULL,
        pch = 21, pt.cex = 2, pt.col = "black", pt.bg = "darkgrey",
        cex.lab = 1, las = 1, adj = NULL, dist = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotWeb_+3A_m">m</code></td>
<td>
<p>a symmetric matrix of numeric values
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_col">col</code></td>
<td>
<p>the color for the connecting lines
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_lty">lty</code></td>
<td>
<p>the line type for the connecting lines, the default will be <code>par("lty")</code>.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_lwd">lwd</code></td>
<td>
<p>the line widths for the connecting lines. If left to <code>NULL</code> it will be linearly scaled between the minimum and maximum value of <code>m</code>.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_args.legend">args.legend</code></td>
<td>
<p>list of additional arguments to be passed to the <code>legend</code> function.
Use <code>args.legend = NA</code> if no legend should be added.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_pch">pch</code></td>
<td>
<p>the plotting symbols appearing in the plot, as a non-negative numeric vector (see <code><a href="graphics.html#topic+points">points</a></code>, but unlike there negative values are omitted) or a vector of 1-character strings, or one multi-character string.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_pt.cex">pt.cex</code></td>
<td>
<p>expansion factor(s) for the points.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_pt.col">pt.col</code></td>
<td>
<p>the foreground color for the points, corresponding to its argument <code>col</code>.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_pt.bg">pt.bg</code></td>
<td>
<p>the background color for the points, corresponding to its argument <code>bg</code>.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_las">las</code></td>
<td>
<p>alignment of the labels, 1 means horizontal, 2 radial and 3 vertical.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_adj">adj</code></td>
<td>
<p>adjustments for the labels. (Left: 0, Right: 1, Mid: 0.5)
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_dist">dist</code></td>
<td>
<p>gives the distance of the labels from the outer circle. Default is 2.</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_cex.lab">cex.lab</code></td>
<td>
<p>the character extension for the labels.
</p>
</td></tr>
<tr><td><code id="PlotWeb_+3A_...">...</code></td>
<td>
<p>dots are passed to plot.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function uses the lower triangular matrix of <code>m</code>, so this is the order colors, linewidth etc. must be given, when the defaults are to be overrun.</p>


<h3>Value</h3>

<p>A list of x and y coordinates, giving the coordinates of all the points drawn, useful for adding other elements to the plot.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotCorr">PlotCorr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- cor(d.pizza[, which(sapply(d.pizza, IsNumeric, na.rm=TRUE))[-c(1:2)]],
         use="pairwise.complete.obs")
PlotWeb(m=m, col=c(hred, hblue), main="Pizza Correlation")


# let's describe only the significant corrs and start with a dataset
d.m &lt;- d.pizza[, which(sapply(d.pizza, IsNumeric, na.rm=TRUE))[-c(1:2)]]

# get the correlation matrix
m &lt;- cor(d.m, use="pairwise.complete.obs")

# let's get rid of all non significant correlations
ctest &lt;- PairApply(d.m,  function(x, y) cor.test(x, y)$p.value, symmetric=TRUE)

# ok, got all the p-values, now replace &gt; 0.05 with NAs
m[ctest &gt; 0.05] &lt;- NA
# How does that look like now?
Format(m, na.form = ". ", ldigits=0, digits=3, align = "right")

PlotWeb(m, las=2, cex=1.2)

# define line widths
PlotWeb(m, lwd=abs(m[lower.tri(m)] * 10))
</code></pre>

<hr>
<h2 id='PMT'>Periodic Payment of an Annuity.
</h2><span id='topic+PMT'></span><span id='topic+IPMT'></span><span id='topic+PPMT'></span><span id='topic+RBAL'></span>

<h3>Description</h3>

<p><code>PMT</code> computes the periodic payment of an annuity.
<code>IPMT</code> calculates what portion of a period payment is going towards interest in a particular period and
<code>PPMT</code> what portion of a period payment is going towards principal in a particular period. <code>RBAL</code> yields the remaining balance in a particular period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PMT(rate, nper, pv, fv = 0, type = 0)
IPMT(rate, per, nper, pv, fv = 0, type = 0)
PPMT(rate, per, nper, pv, fv = 0, type = 0)
RBAL(rate, per, nper, pv, fv = 0, type = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PMT_+3A_rate">rate</code></td>
<td>
<p>specifies the interest rate.
</p>
</td></tr>
<tr><td><code id="PMT_+3A_per">per</code></td>
<td>
<p>specifies the period of the payment to be applied to interest or to principal.
</p>
</td></tr>
<tr><td><code id="PMT_+3A_nper">nper</code></td>
<td>
<p>specifies the number of payment periods.
</p>
</td></tr>
<tr><td><code id="PMT_+3A_pv">pv</code></td>
<td>
<p>specifies the present value or the lump-sum amount that a series of future payments is worth currently. <code>pv</code> can be 0 if a positive <code>fv</code> argument is included.
</p>
</td></tr>
<tr><td><code id="PMT_+3A_fv">fv</code></td>
<td>
<p>specifies the future value or a cash balance that you want to attain after the last payment is made. Default is 0.
</p>
</td></tr>
<tr><td><code id="PMT_+3A_type">type</code></td>
<td>
<p>specifies the number 0 or 1 and indicates when payments are due. Default is 0.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+NPV">NPV</a></code>, <code><a href="#topic+SLN">SLN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># original principal:    20'000
# loan term (years):     5
# annual interest rate:  8%
# annual payment:        -4'156.847

# simple amortization schedule
cbind(
  year      = 1:5,
  payment   = PMT(rate=0.08, nper=5, pv=20000, fv=-5000, type=0),
  interest  = IPMT(rate=0.08, per=1:5, nper=5, pv=20000, fv=-5000, type=0),
  principal = PPMT(rate=0.08, per=1:5, nper=5, pv=20000, fv=-5000, type=0),
  balance   = RBAL(rate=0.08, per=1:5, nper=5, pv=20000, fv=-5000, type=0)
)

#     year   payment   interest principal   balance
# [1,]    1 -4156.847 -1600.0000 -2556.847 17443.153
# [2,]    2 -4156.847 -1395.4523 -2761.395 14681.759
# [3,]    3 -4156.847 -1174.5407 -2982.306 11699.452
# [4,]    4 -4156.847  -935.9562 -3220.891  8478.562
# [5,]    5 -4156.847  -678.2849 -3478.562  5000.000


</code></pre>

<hr>
<h2 id='PoissonCI'>Poisson Confidence Interval
</h2><span id='topic+PoissonCI'></span>

<h3>Description</h3>

<p>Computes the confidence intervals of a poisson distributed variable's lambda. Several methods are implemented, see details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoissonCI(x, n = 1, conf.level = 0.95, sides = c("two.sided","left","right"),
          method = c("exact", "score", "wald", "byar"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoissonCI_+3A_x">x</code></td>
<td>
<p>number of events. </p>
</td></tr>
<tr><td><code id="PoissonCI_+3A_n">n</code></td>
<td>
<p>time base for event count.</p>
</td></tr>
<tr><td><code id="PoissonCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level, defaults to 0.95.</p>
</td></tr>
<tr><td><code id="PoissonCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default),
<code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of
<code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="PoissonCI_+3A_method">method</code></td>
<td>
<p> character string specifing which method to use; can be one out of
<code>"wald"</code>, <code>"score"</code>,  <code>"exact"</code> or  <code>"byar"</code>.
Method can be abbreviated. See details. Defaults to <code>"score"</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Wald interval uses the asymptotic normality of the test statistic.
</p>
<p>Byar's method is quite a good approximation. Rothman and Boice (1979) mention that these limits were first proposed by Byar (unpublished).
</p>


<h3>Value</h3>

<p>A vector with 3 elements for estimate, lower confidence intervall and upper for the upper one.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. and Coull, B.A. (1998) Approximate is better than &quot;exact&quot; for interval
estimation of binomial proportions. <em>American Statistician</em>, <b>52</b>, pp. 119-126.
</p>
<p>Rothman KJ, Boice JD, Jr. (1979) Epidemiologic Analysis with a Programmable Calculator (NIH Publication 79-1649). Washington DC: US Government Printing Office.
</p>
<p>Garwood, F. (1936) Fiducial Limits for the Poisson distribution. <em>Biometrika</em> 28:437-442.
</p>
<p><a href="https://www.ine.pt/revstat/pdf/rs120203.pdf">https://www.ine.pt/revstat/pdf/rs120203.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+poisson.test">poisson.test</a></code>, <code><a href="#topic+BinomCI">BinomCI</a></code>, <code><a href="#topic+MultinomCI">MultinomCI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># the horse kick example
count &lt;- 0:4
deaths &lt;- c(144, 91, 32, 11, 2)

n &lt;- sum(deaths)
x &lt;- sum(count * deaths)

lambda &lt;- x/n

PoissonCI(x=x, n=n, method = c("exact","score", "wald", "byar"))

exp &lt;- dpois(0:4, lambda) * n

barplot(rbind(deaths, exp * n/sum(exp)), names=0:4, beside=TRUE,
  col=c(hred, hblue), main = "Deaths from Horse Kicks", xlab = "count")
legend("topright", legend=c("observed","expected"), fill=c(hred, hblue),
  bg="white")


## SMR, Welsh Nickel workers
PoissonCI(x=137, n=24.19893)
</code></pre>

<hr>
<h2 id='PolarGrid'>Plot a Grid in Polar Coordinates
</h2><span id='topic+PolarGrid'></span>

<h3>Description</h3>

<p><code>PolarGrid</code> adds a polar grid to an existing plot. The number of radial gridlines are
set by <code>ntheta</code> and the tangential lines by <code>nr</code>. Labels for the angular grid and the radial axis can be provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PolarGrid(nr = NULL, ntheta = NULL, col = "lightgray", lty = "dotted", lwd = par("lwd"),
          rlabels = NULL, alabels = NULL, lblradians = FALSE, cex.lab = 1, las = 1,
          adj = NULL, dist = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PolarGrid_+3A_nr">nr</code></td>
<td>
<p>number of circles. When NULL, as per default, the grid aligns with the tick marks on the corresponding default axis
(i.e., tickmarks as computed by axTicks). When NA, no circular grid lines are drawn.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_ntheta">ntheta</code></td>
<td>
<p>number of radial grid lines. Defaults to 12 uniformly distributed between 0 and 2*pi (each pi/3).
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_col">col</code></td>
<td>
<p>character or (integer) numeric; color of the grid lines.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_lty">lty</code></td>
<td>
<p>character or (integer) numeric; line type of the grid lines.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_lwd">lwd</code></td>
<td>
<p>non-negative numeric giving line width of the grid lines.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_rlabels">rlabels</code></td>
<td>
<p>the radius labels. Use <code>NA</code> if no labels should be to be added.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_alabels">alabels</code></td>
<td>
<p>the labels for the angles, they are printed on a circle outside the plot. Use <code>NA</code> for no angle labels.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_lblradians">lblradians</code></td>
<td>
<p>logic, defines if angle labels will be in degrees (default) or in radians.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_cex.lab">cex.lab</code></td>
<td>
<p>the character extension for the labels.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_las">las</code></td>
<td>
<p>alignment of the labels, 1 means horizontal, 2 radial and 3 vertical.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_adj">adj</code></td>
<td>
<p>adjustments for the labels. (Left: 0, Right: 1, Mid: 0.5) The default is 1 for the levels on the right side of the circle, 0 for labels on the left and 0.5 for labels exactly on north on south.
</p>
</td></tr>
<tr><td><code id="PolarGrid_+3A_dist">dist</code></td>
<td>
<p>gives the radius for the labels, in user coordinates. Default is par(&quot;usr&quot;)[2] * 1.07.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; </p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotPolar">PlotPolar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Canvas(xlim=c(-5,5), xpd=TRUE)
PolarGrid()

Canvas(xlim=c(-5,5), xpd=TRUE)
PolarGrid(nr=0:5, ntheta=6)

Canvas(xlim=c(-5,5), xpd=TRUE)
PolarGrid(ntheta=36, rlabels=NA, lblradians=TRUE)
</code></pre>

<hr>
<h2 id='PostHocTest'>Post-Hoc Tests
</h2><span id='topic+PostHocTest'></span><span id='topic+PostHocTest.aov'></span><span id='topic+PostHocTest.table'></span><span id='topic+PostHocTest.matrix'></span><span id='topic+print.PostHocTest'></span><span id='topic+plot.PostHocTest'></span>

<h3>Description</h3>

<p>A convenience wrapper for computing post-hoc test after having calculated an ANOVA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PostHocTest(x, ...)

## S3 method for class 'aov'
PostHocTest(x, which = NULL,
            method = c("hsd", "bonferroni", "lsd", "scheffe", "newmankeuls", "duncan"),
            conf.level = 0.95, ordered = FALSE, ...)

## S3 method for class 'table'
PostHocTest(x, method = c("none", "fdr", "BH", "BY", "bonferroni",
                          "holm", "hochberg", "hommel"),
            conf.level = 0.95, ...)


## S3 method for class 'PostHocTest'
print(x, digits = getOption("digits", 3), ...)
## S3 method for class 'PostHocTest'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PostHocTest_+3A_x">x</code></td>
<td>
<p>an aov object.
</p>
</td></tr>
<tr><td><code id="PostHocTest_+3A_method">method</code></td>
<td>
<p>one of <code>"hsd"</code>, <code>"bonf"</code>, <code>"lsd"</code>, <code>"scheffe"</code>, <code>"newmankeuls"</code>, defining the method for the pairwise comparisons.<br /> For the post hoc test of tables the methods of <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> can be supplied. See the detail there.
</p>
</td></tr>
<tr><td><code id="PostHocTest_+3A_which">which</code></td>
<td>
<p>a character vector listing terms in the fitted model for which the intervals should be calculated. Defaults to all the terms.
</p>
</td></tr>
<tr><td><code id="PostHocTest_+3A_conf.level">conf.level</code></td>
<td>
<p>a numeric value between zero and one giving the family-wise confidence level to use.
If this is set to NA, just a matrix with the p-values will be returned.
</p>
</td></tr>
<tr><td><code id="PostHocTest_+3A_ordered">ordered</code></td>
<td>
<p>a logical value indicating if the levels of the factor should be ordered according to increasing average in the sample before taking differences. If ordered is <code>TRUE</code> then the calculated differences in the means will all be positive. The significant differences will be those for which the lower end point is positive. <br />
This argument will be ignored if method is not either <code>hsd</code> or <code>newmankeuls</code>.
</p>
</td></tr>
<tr><td><code id="PostHocTest_+3A_digits">digits</code></td>
<td>
<p>controls the number of fixed digits to print.
</p>
</td></tr>
<tr><td><code id="PostHocTest_+3A_...">...</code></td>
<td>
<p>further arguments, not used so far.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is designed to consolidate a couple of post-hoc tests with the same interface for
input and output.
</p>
<p><b>Choosing Tests.</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
Different post hoc tests use different methods to control familywise (FW) and per experiment error rate (PE). Some tests are very conservative. Conservative tests go to great lengths to prevent the user from committing a type 1 error.  They use more stringent criterion for determining significance. Many of these tests become more and more stringent as the number of groups increases (directly limiting the FW and PE error rate). Although these tests buy you protection against type 1 error, it comes at a cost. As the tests become more stringent, you loose power (1-B).  More liberal tests, buy you power but the cost is an increased chance of type 1 error.  There is no set rule for determining which test to use, but different researchers have offered some guidelines for choosing. Mostly it is an issue of pragmatics and whether the number of comparisons exceeds k-1.
</p>
<p><b>The Fisher's LSD</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
(Least Significant Different) sets alpha level per comparison. alpha = .05 for every comparison. df = df error (i.e. df within).
This test is the most liberal of all post hoc tests. The critical t for significance is unaffected by the number of groups.
This test is appropriate when you have 3 means to compare. In general the alpha is held at .05 because of the criterion that you can't look at LSD's unless the ANOVA is significant.
This test is generally not considered appropriate if you have more than 3 means unless there is reason to believe that there is no more than one true null hypothesis hidden in the means.
</p>
<p><b>Dunn's (Bonferroni) t-test</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
is sometimes referred to as the Bonferroni t because it used the Bonferroni PE correction procedure in determining the critical value for significance. In general, this test should be used when the number of comparisons you are making exceeds the number of degrees of freedom you have between groups (e.g. k-1). This test sets alpha per experiment; alpha = (.05)/c for every comparison. df = df error (c = number of comparisons (k(k-1))/2)
This test is extremely conservative and rapidly reduces power as the number of comparisons being made increase.
</p>
<p><b>Newman-Keuls</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
is a step down procedure that is not as conservative as Dunn's t test. First, the means of the groups are ordered (ascending or descending) and then the largest and smallest means are tested for significant differences. If those means are different, then test smallest with next largest, until you reach a test that is not significant. Once you reach that point then you can only test differences between means that exceed the difference between the means that were found to be non-significant.
Newman-Keuls is perhaps one of the most common post hoc test, but it is a rather controversial test. The major problem with this test is that when there is more than one true null hypothesis in a set of means it will overestimate the FW error rate.
In general we would use this when the number of comparisons we are making is larger than k-1 and we don't want to be as conservative as the Dunn's test is.
</p>
<p><b>Tukey's HSD</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
(Honestly Significant Difference) is essentially like the Newman-Keuls, but the tests between each mean are compared to the critical value that is set for the test of the means that are furthest apart (rmax e.g. if there are 5 means we use the critical value determined for the test of X1 and X5).
This method corrects for the problem found in the Newman-Keuls where the FW is inflated when there is more than one true null hypothesis in a set of means. It buys protection against type 1 error, but again at the cost of power.
It tends to be the most common and preferred test because it is very conservative with respect to type 1 error when the null hypothesis is true. In general, HSD is preferred when you will make all the possible comparisons between a large set of means (6 or more means).
</p>
<p><b>The Scheffe test</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
is designed to protect against a type 1 error when all possible complex and simple comparisons are made. That is we are not just looking the possible combinations of comparisons between pairs of means. We are also looking at the possible combinations of comparisons between groups of means. Thus Scheffe is the most conservative of all tests.
Because this test does give us the capacity to look at complex comparisons, it essentially uses the same statistic as the linear contrasts tests. However, Scheffe uses a different critical value (or at least it makes an adjustment to the critical value of F).
This test has less power than the HSD when you are making pairwise (simple) comparisons, but it has more power than HSD when you are making complex comparisons.
In general, only use this when you want to make many post hoc complex comparisons (e.g. more than k-1).
</p>
<p><b>Tables</b> <code style="white-space: pre;">&#8288;     &#8288;</code> 
For tables pairwise chi-square test can be performed, either without correction or with correction for multiple testing following the logic in <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.
</p>


<h3>Value</h3>

<p>an object of type &quot;PostHocTest&quot;, which will either be <br />
A) a list of data.frames containing the mean difference, lower ci, upper ci and the p-value,
if a conf.level was defined (something else than NA) or <br />
B) a list of matrices with the p-values, if conf.level has been set to NA.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code>, <code><a href="stats.html#topic+aov">aov</a></code>,  <code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>,
<code><a href="#topic+ScheffeTest">ScheffeTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PostHocTest(aov(breaks ~ tension, data = warpbreaks), method = "lsd")
PostHocTest(aov(breaks ~ tension, data = warpbreaks), method = "hsd")
PostHocTest(aov(breaks ~ tension, data = warpbreaks), method = "scheffe")

r.aov &lt;- aov(breaks ~ tension, data = warpbreaks)

# compare p-values:
round(cbind(
    lsd= PostHocTest(r.aov, method="lsd")$tension[,"pval"]
  , bonf=PostHocTest(r.aov, method="bonf")$tension[,"pval"]
), 4)

# only p-values by setting conf.level to NA
PostHocTest(aov(breaks ~ tension, data = warpbreaks), method = "hsd",
            conf.level=NA)
</code></pre>

<hr>
<h2 id='power.chisq.test'>Power Calculations for ChiSquared Tests</h2><span id='topic+power.chisq.test'></span>

<h3>Description</h3>

<p>Compute power of test or determine parameters to obtain target
power (same as <code><a href="stats.html#topic+power.anova.test">power.anova.test</a></code>).</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.chisq.test(n = NULL, w = NULL, df = NULL, sig.level = 0.05, power = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.chisq.test_+3A_n">n</code></td>
<td>
<p>total number of observations.</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_w">w</code></td>
<td>
<p>effect size.</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_df">df</code></td>
<td>
<p>degree of freedom (depends on the chosen test.</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_sig.level">sig.level</code></td>
<td>
<p>Significance level (Type I error probability).</p>
</td></tr>
<tr><td><code id="power.chisq.test_+3A_power">power</code></td>
<td>
<p>Power of test (1 minus Type II error probability).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exactly one of the parameters <code>w</code>, <code>n</code>, <code>power</code> or
<code>sig.level</code> must be passed as NULL, and this parameter is
determined from the others. Note that the last one has non-NULL
default, so <code>NULL</code> must be explicitly passed, if you want to compute
it.
</p>


<h3>Value</h3>

<p>Object of class &quot;power.htest&quot;, a list of the arguments
(including the computed one) augmented with 'method' and 'note'
elements.
</p>


<h3>Note</h3>

  
<p><code><a href="stats.html#topic+uniroot">uniroot</a></code> is used to solve power equation for unknowns, so you may
see errors from it, notably about inability to bracket the root
when invalid arguments are given.
</p>


<h3>Author(s)</h3>

<p>Stephane Champely &lt;champely@univ-lyon1.fr&gt; <br />
but this is a mere copy of Peter Dalgaard's work on power.t.test</p>


<h3>References</h3>

<p>Cohen, J. (1988) <em>Statistical power analysis for the
behavioral sciences (2nd ed.)</em> Hillsdale, NJ: Lawrence Erlbaum.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+power.t.test">power.t.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Exercise 7.1 P. 249 from Cohen (1988) 
power.chisq.test(w=0.289, df=(4-1), n=100, sig.level=0.05)

## Exercise 7.3 p. 251
power.chisq.test(w=0.346, df=(2-1)*(3-1), n=140, sig.level=0.01)

## Exercise 7.8 p. 270
power.chisq.test(w=0.1, df=(5-1)*(6-1), power=0.80, sig.level=0.05)
</code></pre>

<hr>
<h2 id='PowerPoint+20Interface'>Add Slides, Insert Texts and Plots to PowerPoint
</h2><span id='topic+PpPlot'></span><span id='topic+PpText'></span><span id='topic+PpAddSlide'></span><span id='topic+GetNewPP'></span><span id='topic+GetCurrPP'></span>

<h3>Description</h3>

<p>A couple of functions to get R-stuff into MS-Powerpoint.
</p>
<p><code>GetNewPP()</code> starts a new instance of PowerPoint and returns its handle. A new presentation with one empty slide will be created thereby. The handle is needed for addressing the presentation afterwards.<br />
<code>GetCurrPP()</code> will look for a running PowerPoint instance and return its handle. <code>NULL</code> is returned if nothing's found.
<code>PpAddSlide()</code> inserts a new slide into the active
presentation.<br />
<code>PpPlot()</code> inserts the active plot into PowerPoint. The image is transferred by saving the picture to a file in R and
inserting the file in PowerPoint. The format of the plot can be selected, as well as crop options and the
size factor for inserting.<br />
<code>PpText()</code> inserts a new textbox with given text and box properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetNewPP(visible = TRUE, template = "Normal")
GetCurrPP()

PpAddSlide(pos = NULL, pp = DescToolsOptions("lastPP"))

PpPlot(type = "png", crop = c(0, 0, 0, 0), picscale = 100, x = 1, y = 1,
       height = NA, width = NA, res=200, dfact=1.6, pp = DescToolsOptions("lastPP"))

PpText(txt, x = 1, y = 1, height = 50, width = 100, fontname = "Calibri", fontsize = 18,
       bold = FALSE, italic = FALSE, col = "black", bg = "white",
       hasFrame = TRUE, pp = DescToolsOptions("lastPP"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PowerPoint+2B20Interface_+3A_visible">visible</code></td>
<td>
<p>logical, should PowerPoint made visible by <code>GetNewPP()</code>? Defaults to TRUE.
</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_template">template</code></td>
<td>
<p>the name of the template to be used for the new presentation.
</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_pos">pos</code></td>
<td>
<p>position of the new inserted slide within the presentation.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_type">type</code></td>
<td>
<p>the format for the picture file, default is <code>"png"</code>.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_crop">crop</code></td>
<td>
<p>crop options for the picture, defined by a 4-elements-vector. The first element is the bottom side, the second the left and so on.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_picscale">picscale</code></td>
<td>
<p>scale factor of the picture in percent, default ist 100.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_x">x</code>, <code id="PowerPoint+2B20Interface_+3A_y">y</code></td>
<td>
<p>left/upper xy-coordinate for the plot or for the textbox.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_height">height</code></td>
<td>
<p>height in cm, this overrides the picscale if both are given.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_width">width</code></td>
<td>
<p>width in cm, this overrides the picscale if both are given.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_res">res</code></td>
<td>
<p>resolution for the png file, defaults to 200.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_dfact">dfact</code></td>
<td>
<p>the size factor for the graphic.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_txt">txt</code></td>
<td>
<p>text to be placed in the textbox</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_fontname">fontname</code></td>
<td>
<p>used font for textbox</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_fontsize">fontsize</code></td>
<td>
<p>used fontsize for textbox</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_bold">bold</code></td>
<td>
<p>logic. Text is set bold if this is set to <code>TRUE</code> (default is FALSE).</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_italic">italic</code></td>
<td>
<p>logic. Text is set italic if this is to <code>TRUE</code> (default is FALSE).</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_col">col</code></td>
<td>
<p>font color, defaults to <code>"black"</code>.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_bg">bg</code></td>
<td>
<p>background color for textboxdefaults to <code>"white"</code>.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_hasframe">hasFrame</code></td>
<td>
<p>logical. Defines if a textbox is to be framed. Default is TRUE.</p>
</td></tr>
<tr><td><code id="PowerPoint+2B20Interface_+3A_pp">pp</code></td>
<td>
<p>the pointer to a PowerPoint instance, can be a new one, created by <code>GetNewPP()</code> or
the last created by <code>DescToolsOptions("lastPP")</code> (default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See PowerPoint-objectmodel for further informations.
</p>


<h3>Value</h3>

<p>The functions return the pointer to the created object.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WrdPlot">WrdPlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: # Windows-specific example

# let's have some graphic
plot(1,type="n", axes=FALSE, xlab="", ylab="", xlim=c(0,1), ylim=c(0,1))
rect(0,0,1,1,col="black")
segments(x0=0.5, y0=seq(0.632,0.67, length.out=100),
  y1=seq(0.5,0.6, length.out=100), x1=1, col=rev(rainbow(100)))
polygon(x=c(0.35,0.65,0.5), y=c(0.5,0.5,0.75), border="white",
  col="black", lwd=2)
segments(x0=0,y0=0.52, x1=0.43, y1=0.64, col="white", lwd=2)
x1 &lt;- seq(0.549,0.578, length.out=50)
segments(x0=0.43, y0=0.64, x1=x1, y1=-tan(pi/3)* x1 + tan(pi/3) * 0.93,
  col=rgb(1,1,1,0.35))


# get a handle to a new PowerPoint instance
pp &lt;- GetNewPP()
# insert plot with a specified height
PpPlot(pp=pp,  x=150, y=150, height=10, width=10)

PpText("Remember?\n", fontname="Arial", x=200, y=70, height=30, fontsize=14,
       bold=TRUE, pp=pp, bg="lemonchiffon", hasFrame=TRUE)

PpAddSlide(pp=pp)
# crop the picture
pic &lt;- PpPlot(pp=pp, x=1, y=200, height=10, width=10, crop=c(9,9,0,0))
pic


# some more automatic procedure
pp &lt;- GetNewPP()
PpText("Hello to my presentation", x=100, y=100, fontsize=32, bold=TRUE,
       width=300, hasFrame=FALSE, col="blue", pp=pp)

for(i in 1:4){
  barplot(1:4, col=i)
  PpAddSlide(pp=pp)
  PpPlot(height=15, width=21, x=50, y=50, pp=pp)
  PpText(gettextf("This is my barplot nr %s", i), x=100, y=10, width=300, pp=pp)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='pRevGumbel'>&quot;Reverse&quot; Gumbel Distribution Functions</h2><span id='topic+dRevGumbel'></span><span id='topic+pRevGumbel'></span><span id='topic+qRevGumbel'></span><span id='topic+qRevGumbelExp'></span><span id='topic+rRevGumbel'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random
generation for the &ldquo;Reverse&rdquo; Gumbel distribution with
parameters <code>location</code> and <code>scale</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dRevGumbel (x, location = 0, scale = 1)
pRevGumbel (q, location = 0, scale = 1)
qRevGumbel (p, location = 0, scale = 1)
rRevGumbel (n, location = 0, scale = 1)

qRevGumbelExp(p)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pRevGumbel_+3A_x">x</code>, <code id="pRevGumbel_+3A_q">q</code></td>
<td>
<p>numeric vector of abscissa (or quantile) values at which
to evaluate the density or distribution function.</p>
</td></tr>
<tr><td><code id="pRevGumbel_+3A_p">p</code></td>
<td>
<p>numeric vector of probabilities at which to evaluate the
quantile function.</p>
</td></tr>
<tr><td><code id="pRevGumbel_+3A_location">location</code></td>
<td>
<p>location of the distribution</p>
</td></tr>
<tr><td><code id="pRevGumbel_+3A_scale">scale</code></td>
<td>
<p>scale (<code class="reqn">&gt; 0</code>) of the distribution.</p>
</td></tr>
<tr><td><code id="pRevGumbel_+3A_n">n</code></td>
<td>
<p>number of random variates, i.e., <code><a href="base.html#topic+length">length</a></code> of
resulting vector of <code>rRevGumbel(..)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector, of the same length as <code>x</code>, <code>q</code>, or
<code>p</code> for the first three functions, and of length <code>n</code> for
<code>rRevGumbel()</code>.
</p>


<h3>Author(s)</h3>

<p>Werner Stahel; partly inspired by package <span class="pkg">VGAM</span>.
Martin Maechler for numeric cosmetic.
</p>


<h3>See Also</h3>

<p>the <code><a href="stats.html#topic+Weibull">Weibull</a></code> distribution functions in <span class="rlang"><b>R</b></span>'s <span class="pkg">stats</span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>curve(pRevGumbel(x, scale= 1/2), -3,2, n=1001, col=1, lwd=2,
      main = "RevGumbel(x, scale = 1/2)")
abline(h=0:1, v = 0, lty=3, col = "gray30")
curve(dRevGumbel(x, scale= 1/2),       n=1001, add=TRUE,
      col = (col.d &lt;- adjustcolor(2, 0.5)), lwd=3)
legend("left", c("cdf","pdf"), col=c("black", col.d), lwd=2:3, bty="n")

med &lt;- qRevGumbel(0.5, scale=1/2)
cat("The median is:",  format(med),"\n")
</code></pre>

<hr>
<h2 id='Primes'>Find All Primes Less Than n</h2><span id='topic+Primes'></span>

<h3>Description</h3>

<p>Find all prime numbers aka &lsquo;primes&rsquo; less than <code class="reqn">n</code>.
</p>
<p>Uses an obvious sieve method and some care, working with
logical and integers to be quite fast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Primes(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Primes_+3A_n">n</code></td>
<td>
<p>a (typically positive integer) number.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As the function only uses <code><a href="base.html#topic+max">max</a>(n)</code>, <code>n</code> can also be a
<em>vector</em> of numbers.
</p>


<h3>Value</h3>

<p>numeric vector of all prime numbers <code class="reqn">\le n</code>.
</p>


<h3>Note</h3>

<p> This function was previously published in the package <span class="pkg">sfsmisc</span> as <code><a href="sfsmisc.html#topic+primes">primes</a></code>
and has been integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>Bill Venables (<code class="reqn">\le n</code>); Martin Maechler gained another 40% speed,
working with logicals and integers.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Factorize">Factorize</a></code>,  <code><a href="#topic+GCD">GCD</a></code>,  <code><a href="#topic+LCM">LCM</a></code>, <code><a href="#topic+IsPrime">IsPrime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(p1 &lt;- Primes(100))
system.time(p1k &lt;- Primes(1000)) # still lightning ..

stopifnot(length(p1k) == 168)

</code></pre>

<hr>
<h2 id='PseudoR2'>Pseudo R2 Statistics

</h2><span id='topic+PseudoR2'></span>

<h3>Description</h3>

<p>Although there's no commonly accepted agreement on how to assess the fit of a logistic regression, there are some approaches. The goodness of fit of the logistic regression model can be expressed by some variants of pseudo R squared statistics, most of which being based on the deviance of the model.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>PseudoR2(x, which = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PseudoR2_+3A_x">x</code></td>
<td>
<p>the <code>glm</code>, <code>polr</code> or <code>multinom</code> model object to be evaluated.

</p>
</td></tr>
<tr><td><code id="PseudoR2_+3A_which">which</code></td>
<td>
<p>character, one out of <code>"McFadden"</code>, <code>"McFaddenAdj"</code>, <code>"CoxSnell"</code>,  <code>"Nagelkerke"</code>, <code>"AldrichNelson"</code>,
<code>"VeallZimmermann"</code>,  <code>"Efron"</code>, <code>"McKelveyZavoina"</code>,  <code>"Tjur"</code>, <code>"all"</code>. Partial matching is supported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cox and Snell's <code class="reqn">R^2</code> is based on the log likelihood for the model compared to the log likelihood for a baseline model. However, with categorical outcomes, it has a theoretical maximum value of less than 1, even for a &quot;perfect&quot; model.
</p>
<p>Nagelkerke's <code class="reqn">R^2</code> (also sometimes called Cragg-Uhler) is an adjusted version of the Cox and Snell's <code class="reqn">R^2</code> that adjusts the scale of the statistic to cover the full range from 0 to 1.
</p>
<p>McFadden's <code class="reqn">R^2</code> is another version, based on the log-likelihood kernels for the intercept-only model and the full estimated model.

</p>
<p>Veall and Zimmermann concluded that from a set of six widely used measures the measure suggested by McKelvey and Zavoina had the closest correspondance to ordinary least square R2. The Aldrich-Nelson pseudo-R2 with the Veall-Zimmermann correction is the best approximation of the McKelvey-Zavoina pseudo-R2. Efron, Aldrich-Nelson, McFadden and Nagelkerke approaches severely underestimate the &quot;true R2&quot;.
</p>


<h3>Value</h3>

<p>the value of the specific statistic. <code>AIC</code>, <code>LogLik</code>, <code>LogLikNull</code> and <code>G2</code> will only be reported with option <code>"all"</code>.





</p>
<table>
<tr><td><code>McFadden</code></td>
<td>
<p>McFadden pseudo-<code class="reqn">R^2</code></p>
</td></tr>
<tr><td><code>McFaddenAdj</code></td>
<td>
<p>McFadden adjusted pseudo-<code class="reqn">R^2</code></p>
</td></tr>
<tr><td><code>CoxSnell</code></td>
<td>
<p>Cox and Snell pseudo-<code class="reqn">R^2</code> (also known as ML pseudo-<code class="reqn">R^2</code>)</p>
</td></tr>
<tr><td><code>Nagelkerke</code></td>
<td>
<p>Nagelkerke pseudo<code class="reqn">R^2</code> (also known as CraggUhler <code class="reqn">R^2</code>)</p>
</td></tr>
<tr><td><code>AldrichNelson</code></td>
<td>
<p>AldrichNelson pseudo-<code class="reqn">R^2</code></p>
</td></tr>
<tr><td><code>VeallZimmermann</code></td>
<td>
<p>VeallZimmermann pseudo-<code class="reqn">R^2</code></p>
</td></tr>
<tr><td><code>McKelveyZavoina</code></td>
<td>
<p>McKelvey and Zavoina pseudo-<code class="reqn">R^2</code></p>
</td></tr>
<tr><td><code>Efron</code></td>
<td>
<p>Efron pseudo-<code class="reqn">R^2</code></p>
</td></tr>
<tr><td><code>Tjur</code></td>
<td>
<p>Tjur's pseudo-<code class="reqn">R^2</code></p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike's information criterion</p>
</td></tr>
<tr><td><code>LogLik</code></td>
<td>
<p>log-Likelihood for the fitted model (by maximum likelihood)</p>
</td></tr>
<tr><td><code>LogLikNull</code></td>
<td>
<p>log-Likelihood for the null model. The null model will include the offset, and an intercept if there is one in the model.</p>
</td></tr>
<tr><td><code>G2</code></td>
<td>
<p>differenz of the null deviance - model deviance</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; 
with contributions of Ben Mainwaring &lt;benjamin.mainwaring@yougov.com&gt; and Daniel Wollschlaeger
</p>


<h3>References</h3>

<p>Aldrich, J. H. and Nelson, F. D. (1984): Linear Probability, Logit, and probit Models, <em>Sage
University Press</em>, Beverly Hills.
</p>
<p>Cox D R &amp; Snell E J (1989) <em>The Analysis of Binary Data</em> 2nd ed. London: Chapman and Hall.
</p>
<p>Efron, B. (1978). Regression and ANOVA with zero-one data: Measures of residual variation. <em>Journal of the American Statistical Association, 73</em>(361), 113&ndash;121.
</p>
<p>Hosmer, D. W., &amp; Lemeshow, S. (2000). <em>Applied logistic regression</em> (2nd ed.). Hoboke, NJ: Wiley.
</p>
<p>McFadden D (1979). Quantitative methods for analysing travel behavior of individuals: Some recent developments. In D. A. Hensher &amp; P. R. Stopher (Eds.), <em>Behavioural travel modelling</em> (pp. 279-318). London: Croom Helm.
</p>
<p>McKelvey, R. D., &amp; Zavoina, W. (1975). A statistical model for the analysis of ordinal level dependent variables. <em>The Journal of Mathematical Sociology, 4</em>(1), 103&ndash;120
</p>
<p>Nagelkerke, N. J. D. (1991). A note on a general definition of the coefficient of determination. <em>Biometrika, 78</em>(3), 691&ndash;692.
</p>
<p>Tjur, T. (2009) Coefficients of determination in logistic regression models -
a new proposal: The coefficient of discrimination. <em>The American
Statistician</em>,
63(4): 366-372
</p>
<p>Veall, M.R., &amp; Zimmermann, K.F. (1992) Evalutating Pseudo-R2's fpr binary probit models.  <em>Quality&amp;Quantity</em>, 28, pp. 151-164
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="stats.html#topic+BIC">BIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r.glm &lt;- glm(Survived ~ ., data=Untable(Titanic), family=binomial)
PseudoR2(r.glm)

PseudoR2(r.glm, c("McFadden", "Nagel"))
</code></pre>

<hr>
<h2 id='PtInPoly'>Point in Polygon </h2><span id='topic+PtInPoly'></span>

<h3>Description</h3>

<p><code>PtInPoly</code> works out, whether XY-points lie within the boundaries of a given polygon. <br /> <br />
<b>Note:</b> Points that lie on the boundaries of the polygon or vertices are assumed to lie within the polygon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PtInPoly(pnts, poly.pnts) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PtInPoly_+3A_pnts">pnts</code></td>
<td>
<p>a 2-column matrix or dataframe defining locations of the points of interest</p>
</td></tr>
<tr><td><code id="PtInPoly_+3A_poly.pnts">poly.pnts</code></td>
<td>
<p>a 2-column matrix or dataframe defining the locations of vertices of the polygon of interest</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm implements a sum of the angles made between the test point and each pair of points making up the polygon. The point is interior if the sum is 2pi, otherwise, the point is exterior if the sum is 0. This works for simple and complex polygons (with holes) given that the hole is defined with a path made up of edges into and out of the hole. <br /> <br />
This sum of angles is not able to consistently assign points that fall on vertices or on the boundary of the polygon. The algorithm defined here assumes that points falling on a boundary or polygon vertex are part of the polygon.
</p>


<h3>Value</h3>

<p> A 3-column dataframe where the first 2 columns are the original locations of the points. The third column (names pip) is a vector of binary values where 0 represents points not with the polygon and 1 within the polygon. </p>


<h3>Author(s)</h3>

<p> Jeremy VanDerWal &lt;jjvanderwal@gmail.com&gt; </p>


<h3>Examples</h3>

<pre><code class='language-R'>#define the points and polygon
pnts &lt;- expand.grid(x=seq(1,6,0.1), y=seq(1,6,0.1))
polypnts &lt;- cbind(x=c(2,3,3.5,3.5,3,4,5,4,5,5,4,3,3,3,2,2,1,1,1,1,2),
                  y=c(1,2,2.5,2,2,1,2,3,4,5,4,5,4,3,3,4,5,4,3,2,2) )

#plot the polygon and all points to be checked
plot(rbind(polypnts, pnts))
polygon(polypnts, col='#99999990')

#create check which points fall within the polygon
out &lt;- PtInPoly(pnts, polypnts)
head(out)

#identify points not in the polygon with an X
points(out[which(out$pip==0), 1:2], pch='X')
</code></pre>

<hr>
<h2 id='Quantile'>(Weighted) Sample Quantiles</h2><span id='topic+Quantile'></span>

<h3>Description</h3>

<p>Compute weighted quantiles (Eurostat definition).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Quantile(x, weights = NULL, probs = seq(0, 1, 0.25), 
         na.rm = FALSE, names = TRUE, type = 7, digits = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Quantile_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="Quantile_+3A_weights">weights</code></td>
<td>
<p>an optional numeric vector giving the sample weights.</p>
</td></tr>
<tr><td><code id="Quantile_+3A_probs">probs</code></td>
<td>
<p>numeric vector of probabilities with values in <code class="reqn">[0,1]</code>.</p>
</td></tr>
<tr><td><code id="Quantile_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical indicating whether missing values in <code>x</code> should
be omitted.</p>
</td></tr>
<tr><td><code id="Quantile_+3A_names">names</code></td>
<td>
<p>logical; if true, the result has a <code><a href="base.html#topic+names">names</a></code> attribute. 
Set to <code>FALSE</code> for speedup with many <code>probs</code>.</p>
</td></tr>
<tr><td><code id="Quantile_+3A_type">type</code></td>
<td>
<p>an integer between 1 and 9 selecting one of the nine quantile algorithms detailed below to be used. Currently only <code>types</code> <code>5</code> and <code>7</code> (default) are implemented.</p>
</td></tr>
<tr><td><code id="Quantile_+3A_digits">digits</code></td>
<td>
<p>used only when <code>names</code> is true: the precision to use when formatting the percentages. In <code>R</code> versions up to 4.0.x, this had been set to <code>max(2, getOption("digits"))</code>, internally.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation strictly follows the Eurostat definition.
</p>


<h3>Value</h3>

<p>A named numeric vector containing the weighted quantiles of values in
<code>x</code> at probabilities <code>probs</code> is returned.  
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons, Matthias Templ, some tweaks Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Working group on Statistics on Income and Living Conditions
(2004) Common cross-sectional EU indicators based on EU-SILC; the gender pay
gap.  <em>EU-SILC 131-rev/04</em>, Eurostat.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Median">Median</a></code>, <code><a href="stats.html#topic+quantile">quantile</a></code>, <code><a href="#topic+QuantileCI">QuantileCI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Quantile(d.pizza$temperature, rep(c(1:3), length.out=nrow(d.pizza)))
</code></pre>

<hr>
<h2 id='QuantileCI'>Confidence Interval for Any Quantile
</h2><span id='topic+QuantileCI'></span>

<h3>Description</h3>

<p>Calculates the confidence interval for any quantile. Although bootstrapping might be a good approach for getting senisble confidence intervals there's sometimes need to have a nonparameteric alternative. This function offers one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QuantileCI(x, probs=seq(0, 1, .25), conf.level = 0.95, 
           sides = c("two.sided", "left", "right"),
           na.rm = FALSE, method = c("exact", "boot"), R = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QuantileCI_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="QuantileCI_+3A_probs">probs</code></td>
<td>
<p>numeric vector of probabilities with values in <em>[0,1]</em>. (Values up to <code>2e-14</code> outside that range are accepted and moved to the nearby endpoint.)</p>
</td></tr>
<tr><td><code id="QuantileCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval
</p>
</td></tr>
<tr><td><code id="QuantileCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code> (abbreviations allowed). <br /><code>"left"</code> would be analogue to a <code>"greater"</code> hypothesis in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="QuantileCI_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="QuantileCI_+3A_method">method</code></td>
<td>
<p>defining the type of interval that should be calculated (one out of <code>"exact"</code>, <code>"boot"</code>). Default is <code>"exact"</code>. See Details.</p>
</td></tr>
<tr><td><code id="QuantileCI_+3A_r">R</code></td>
<td>
<p>The number of bootstrap replicates. Usually this will be a single positive integer. See
<code><a href="boot.html#topic+boot.ci">boot.ci</a></code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>"exact"</code> method corresponds to the way the confidence interval for the median is calculated in SAS. <br />
The boot confidence interval type is calculated by means of <code><a href="boot.html#topic+boot.ci">boot.ci</a></code> with default type <code>"basic"</code>.
</p>


<h3>Value</h3>

<p>if probs was of length 1
a numeric vector with 3 elements:
</p>
<table>
<tr><td><code>est</code></td>
<td>
<p>est</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>
<p>or, if probs was a vector, a matrix with 3 columns consisting of estimate, lower ci, upper ci
<code>est, lwr.ci, upr.ci</code>
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; based on code of W Huber on StackExchange
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+Quantile">Quantile</a></code>,  <code><a href="stats.html#topic+quantile">quantile</a></code>,  <code><a href="#topic+MedianCI">MedianCI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>QuantileCI(d.pizza$price, probs=0.25, na.rm=TRUE)

QuantileCI(d.pizza$price, na.rm=TRUE)
QuantileCI(d.pizza$price, conf.level=0.99, na.rm=TRUE)

# multiple probs
QuantileCI(1:100, method="exact" , probs = c(0.25, 0.75, .80, 0.95))
QuantileCI(1:100, method="boot" , probs = c(0.25, 0.75, .80, 0.95))
</code></pre>

<hr>
<h2 id='Quot'>Lagged Quotients</h2><span id='topic+Quot'></span>

<h3>Description</h3>

<p>Returns suitably lagged and iterated quotients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Quot(x, lag = 1, quotients = 1, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Quot_+3A_x">x</code></td>
<td>
<p>a numeric vector or matrix containing the values to be
used for calculating the quotients.</p>
</td></tr>
<tr><td><code id="Quot_+3A_lag">lag</code></td>
<td>
<p>an integer indicating which lag to use.</p>
</td></tr>
<tr><td><code id="Quot_+3A_quotients">quotients</code></td>
<td>
<p>an integer indicating the order of the quotient.</p>
</td></tr>
<tr><td><code id="Quot_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="base.html#topic+NA">NA</a></code>'s propagate.
</p>


<h3>Value</h3>

<p>If <code>x</code> is a vector of length <code>n</code> and <code>quotients = 1</code>,
then the computed result is equal to the successive quotients
<code>x[(1+lag):n] - x[1:(n-lag)]</code>.
</p>
<p>If <code>quotients</code> is larger than one this algorithm is applied
recursively to <code>x</code>.
Note that the returned value is a vector which is shorter than
<code>x</code>.
</p>
<p>If <code>x</code> is a matrix then the division operations are carried out
on each column separately.
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+diff">diff</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Quot(1:10, 2)
Quot(1:10, 2, 2)
x &lt;- cumprod(cumprod(1:10))
Quot(x, lag = 2)
Quot(x, quotients = 2)
</code></pre>

<hr>
<h2 id='Range'>(Robust) Range
</h2><span id='topic+Range'></span>

<h3>Description</h3>

<p>Determines the range of the data, which can possibly be trimmed before calculating the extreme values. The robust range version is calculated on the basis of the trimmed mean and variance (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Range(x, trim = NULL, robust = FALSE, na.rm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Range_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="Range_+3A_trim">trim</code></td>
<td>
<p>the fraction (0 to 0.5) of observations to be
trimmed from each end of <code>x</code> before the mean is computed.
Values of trim outside that range are taken as the nearest endpoint. Default is 0 for <code>robust=FALSE</code> and 0.2 for <code>robust=TRUE</code>
</p>
</td></tr>
<tr><td><code id="Range_+3A_robust">robust</code></td>
<td>
<p>logical, determining whether the robust or the convential range should be returned.</p>
</td></tr>
<tr><td><code id="Range_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code>
values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="Range_+3A_...">...</code></td>
<td>
<p>the dots are sent to <code>RobRange</code> and can be used to set <code>fac</code> (See details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The R base function range returns the minimum and maximum value of a numeric object. Here we return the span of a (possibly trimmed) numeric vector, say the difference of maximum and minimum value.
</p>
<p>If robust is set to <code>TRUE</code> the function determines the trimmed mean m and then the &quot;upper trimmed mean&quot; s of absolute deviations
from m, multiplied by <code>fac</code> (fac is 3 by default). The robust minimum is then defined as m-fac*s or min(x),
whichever is larger, and similarly for the maximum.
</p>


<h3>Value</h3>

<p>If <code>trim</code> is zero (the default), the arithmetic mean of the
values in <code>x</code> is computed, as a numeric or complex vector of
length one.  If <code>x</code> is not logical (coerced to numeric), numeric
(including integer) or complex, <code>NA_real_</code> is returned, with a warning.
</p>
<p>If <code>trim</code> is non-zero, a symmetrically trimmed mean is computed
with a fraction of <code>trim</code> observations deleted from each end
before the mean is computed.
</p>


<h3>Author(s)</h3>

<p>Werner Stahel, ETH Zurich (robust range)<br />
Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+range">range</a></code>, <code><a href="base.html#topic+min">min</a></code>, <code><a href="base.html#topic+max">max</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(0:10, 50)
xm &lt;- Range(x)
c(xm, Range(x, trim = 0.10))

x &lt;- c(rnorm(20), rnorm(3, 5, 20))
Range(x, robust=TRUE)

# compared to
Range(x)
</code></pre>

<hr>
<h2 id='Rank'>Fast Sample Ranks</h2><span id='topic+Rank'></span>

<h3>Description</h3>

<p>The function <code>base::rank</code> has various weaknesses. Apart from the fact that it is not very fast, the option to calculate dense ranks is not implemented. Then, an argument for specifying the ranking direction is missing (assuming that this can be done with the ranking of the negative variables) and finally, multiple columns cannot be used in the case of ties for further ranking.
<br /> The function <code>data.table::frankv</code> provides a more elaborated interface and convinces by very performant calculations and is <em>much faster</em> than the original. 
It further accepts vectors, lists, <code>data.frame</code>s or <code>data.table</code>s as input. In addition to the <code>ties.method</code> possibilities provided by <code>base::rank</code>, it also provides <code>ties.method="dense"</code>. <br /> The present function <code>Rank</code> is merely a somewhat customized parameterization of the <code>data.table</code> function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rank(..., decreasing = FALSE, na.last = TRUE,
     ties.method = c("average", "first", "last", "random",
                     "max", "min", "dense"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rank_+3A_...">...</code></td>
<td>
<p> A vector, or list with all its elements identical in length or <code>data.frame</code> or <code>data.table</code>. </p>
</td></tr>
<tr><td><code id="Rank_+3A_decreasing">decreasing</code></td>
<td>
<p> An <code>logical</code> vector corresponding to ascending and descending order. <code>decreasing</code> is recycled to <code>length(...)</code>. </p>
</td></tr>
<tr><td><code id="Rank_+3A_na.last">na.last</code></td>
<td>
<p> Control treatment of <code>NA</code>s. If <code>TRUE</code>, missing values in the data are put last; if <code>FALSE</code>, they are put first; if <code>NA</code>, they are removed; if <code>"keep"</code> they are kept with rank <code>NA</code>. </p>
</td></tr>
<tr><td><code id="Rank_+3A_ties.method">ties.method</code></td>
<td>
<p> A character string specifying how ties are treated, see <code>Details</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>To be consistent with other <code>data.table</code> operations, <code>NA</code>s are considered identical to other <code>NA</code>s (and <code>NaN</code>s to other <code>NaN</code>s), unlike <code>base::rank</code>. Therefore, for <code>na.last=TRUE</code> and <code>na.last=FALSE</code>, <code>NA</code>s (and <code>NaN</code>s) are given identical ranks, unlike <code><a href="base.html#topic+rank">rank</a></code>.
</p>
<p><code>Rank</code> is not limited to vectors. It accepts <code>data.table</code>s (and <code>list</code>s and <code>data.frame</code>s) as well. It accepts unquoted column names (with names preceded with a <code>-</code> sign for descending order, even on character vectors), for e.g., <code>Rank(DT, a, -b, c, ties.method="first")</code> where <code>a,b,c</code> are columns in <code>DT</code>. 
</p>
<p>In addition to the <code>ties.method</code> values possible using base's <code><a href="base.html#topic+rank">rank</a></code>, it also provides another additional argument <code>"dense"</code>.
Dense ranks are consecutive integers beginning with 1. No ranks are skipped if there are ranks with multiple items. So the largest rank value is the number of unique values of x. See examples.
</p>
<p>Like <code><a href="data.table.html#topic+forder">forder</a></code>, sorting is done in &quot;C-locale&quot;; in particular, this may affect how capital/lowercase letters are ranked. See Details on <code>forder</code> for more.
</p>
<p><code>bit64::integer64</code> type is also supported.
</p>


<h3>Value</h3>

<p>A numeric vector of length equal to <code>NROW(x)</code> (unless <code>na.last = NA</code>, when missing values are removed). The vector is of integer type unless <code>ties.method = "average"</code> when it is of double type (irrespective of ties).
</p>


<h3>See Also</h3>

<p><code><a href="data.table.html#topic+frankv">frankv</a></code>, <code><a href="data.table.html#topic+data.table">data.table</a></code>, <code><a href="data.table.html#topic+setkey">setkey</a></code>, <code><a href="data.table.html#topic+setorder">setorder</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># on vectors
x &lt;- c(4, 1, 4, NA, 1, NA, 4)
# NAs are considered identical (unlike base R)
# default is average
Rank(x) # na.last=TRUE
Rank(x, na.last=FALSE)

# ties.method = min
Rank(x, ties.method="min")
# ties.method = dense
Rank(x, ties.method="dense")

# on data.frame, using both columns
d.set &lt;- data.frame(x, y=c(1, 1, 1, 0, NA, 0, 2))
Rank(d.set, na.last="keep")
Rank(d.set, ties.method="dense", na.last=NA)

# decreasing argument
Rank(d.set, decreasing=c(FALSE, TRUE), ties.method="first")
</code></pre>

<hr>
<h2 id='Recode'>Recode a Factor
</h2><span id='topic+Recode'></span>

<h3>Description</h3>

<p>Combining or rearranging a factor can be tedious if it has many levels. <code>Recode</code> supports this step by
accepting a direct definition of new levels by enumerating old levelnames as argument and adding an <code>"elselevel"</code> option. If new levels are given as integer values they will be translated in the according levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Recode(x, ..., elselevel = NA, use.empty = FALSE, num = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Recode_+3A_x">x</code></td>
<td>
<p>the factor whose levels are to be altered. If x is <code>character</code> it will be factorized (using <code>factor</code> defaults).
</p>
</td></tr>
<tr><td><code id="Recode_+3A_...">...</code></td>
<td>
<p>the old levels (combined by <code>c</code>() if there are several) named with the new level:<br />
<code>newlevel_a=c("old_a", "old_b"), </code><br /><code>newlevel_b=c("old_c", "old_d")</code><br /> See examples.
</p>
</td></tr>
<tr><td><code id="Recode_+3A_elselevel">elselevel</code></td>
<td>
<p>the value for levels, which are not matched by newlevel list.
If this is set to <code>NULL</code>, the elselevels will be left unchanged.
If set to <code>NA</code> (default) non matched levels will be set to <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="Recode_+3A_use.empty">use.empty</code></td>
<td>
<p>logical. Defines how a new level, which can't be found in x, should be handled.  Should it be left in the level's list or be dropped? The default is <code>FALSE</code>,
which drops empty levels.
</p>
</td></tr>
<tr><td><code id="Recode_+3A_num">num</code></td>
<td>
<p>logical. If set to <code>TRUE</code> the result will be numeric.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the factor having the new levels applied.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+factor">factor</a></code>, <code><a href="base.html#topic+levels">levels</a></code><br />
There's another solution in the package <b>car</b>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1984)
x &lt;- factor(sample(1:15, 20, replace=TRUE))
levels(x) &lt;- paste("old", levels(x), sep="_")

y &lt;- Recode(x,
            "new_1"   = c("old_1","old_4","old_5"),
            "new_2"   = c("old_6","old_10","old_11"),
            "new_3"   = c("old_12","old_13"),
            elselevel = "other")
data.frame(x=x, y=y)

# Coding NAs, NA is recoded to new_1
x[5:6] &lt;- NA
x &lt;- x[1:7] 

data.frame(
  x, 
  RecodeNA = Recode(x,
                    "new_1"   = c("old_4","old_8", NA),
                    elselevel = "other"),
       
  # NAs remain untouched       
  NoRecodeNA = Recode(x,
                      "new_1"   = c("old_4","old_8"),
                      elselevel = "other")
)         


x &lt;- factor(letters[1:6])

z1 &lt;- Recode(x, AB=c("a","b"), CD=c("c","d"), elselevel="none of these")
z2 &lt;- Recode(x, AB=c("a","b"), CD=c("c","d"), elselevel=NA)
z3 &lt;- Recode(x, AB=c("a","b"), CD=c("c","d"), elselevel=NULL)
z4 &lt;- Recode(x, AB=c("a","b"), GH=c("g","h"), elselevel=NA, use.empty=TRUE)
z5 &lt;- Recode(x, AB=c("a","b"), GH=c("g","h"), elselevel=NA, use.empty=FALSE)

data.frame(z1, z2, z3, z4, z5)

lapply(data.frame(z1, z2, z3, z4, z5), levels)

# empty level GH exists in z4...
table(z4, useNA="ifany")
# and is dropped in z5
table(z5, useNA="ifany")

# use integers to define the groups to collapse
set.seed(1972)
(likert &lt;- factor(sample(1:10, size=15, replace=TRUE),
                  levels=1:10, labels=gettextf("(%s)", 1:10)))
Recode(likert, det=1:6, pas=7:8, pro=9:10)

# or directly turned to numeric
Recode(likert, "1"=1:6, "2"=7:8, "5"=9:10, num=TRUE)

</code></pre>

<hr>
<h2 id='Recycle'>Recyle a List of Elements
</h2><span id='topic+Recycle'></span>

<h3>Description</h3>

<p>This function recycles all supplied elments to the maximal dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Recycle(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Recycle_+3A_...">...</code></td>
<td>
<p>a number of vectors of elements.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of the supplied elements<br />
<code>attr(,"maxdim")</code> contains the maximal dimension of the recyled list
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+rep">rep</a></code>, <code><a href="base.html#topic+replicate">replicate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Recycle(x=1:5, y=1, s=letters[1:2])

z &lt;- Recycle(x=letters[1:5], n=2:3, sep=c("-"," "))
sapply(1:attr(z, "maxdim"), function(i) paste(rep(z$x[i], times=z$n[i]), collapse=z$sep[i]))
</code></pre>

<hr>
<h2 id='RelRisk'>Relative Risk
</h2><span id='topic+RelRisk'></span>

<h3>Description</h3>

<p>Computes the relative risk and its confidence intervals. 
Confidence intervals are calculated using normal approximation (<code>"wald"</code>), (<code>"score"</code>) or by 
using odds ratio (<code>"use.or"</code>) 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RelRisk(x, y = NULL, conf.level = NA, 
        method = c("score", "wald", "use.or"), delta = 0.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RelRisk_+3A_x">x</code></td>
<td>
<p>a numeric vector or a 2x2 numeric matrix, resp. table.
</p>
</td></tr>
<tr><td><code id="RelRisk_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> will be calculated.
</p>
</td></tr>
<tr><td><code id="RelRisk_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level. Default is <code>NA</code>, meaning no confidence intervals will be
reported.
</p>
</td></tr>
<tr><td><code id="RelRisk_+3A_method">method</code></td>
<td>
<p>method for calculating the relative risk and the confidence intervals. Can be one out of
<code>"score"</code>, <code>"wald"</code>, <code>"use.or"</code>. Default is <code>"score"</code>.
</p>
</td></tr>
<tr><td><code id="RelRisk_+3A_delta">delta</code></td>
<td>
<p>small constant to be added to the numerator for calculating the log risk ratio (Wald method). Usual choice is 0.5 although there does not seem to be any 
theory behind this. (Dewey, M. 2006)
</p>
</td></tr>
<tr><td><code id="RelRisk_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set <code>useNA</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Best is to always put the outcome variable (disease yes/no) in the columns and the exposure variable in the rows. In other words, put the dependent variable – the one that describes the problem under study – in the columns. And put the independent variable – the factor assumed to cause the problem – in the rows. (Gerritsen, 2010)
</p>
<p>According to this, the function expects the following table structure:
</p>
<pre>
                     diseased=1   diseased=0
    exposed=1 (ref)     n00          n01
    exposed=0           n10          n11	
  </pre>
<p>The relative risk is then calculated as:
</p>
<pre>       (exposed &amp; diseased) / exposed
rr = ----------------------------------
     (unexposed &amp; diseased) / unexposed
</pre>
<p>If the table to be used is not in the
required shape, use the function <code><a href="#topic+Rev">Rev</a>()</code> and/or <code><a href="base.html#topic+t">t</a>()</code> to reverse rows, columns, or both, resp. to transpose the table. 
</p>


<h3>Value</h3>

<p>If <code>conf.level</code> is not <code>NA</code> then the result will be
a vector with 3 elements for estimate, lower confidence intervall and upper for the upper one.
Else the relative risk will be reported as a single value. 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, based on code of Yongyi Min and Michael Dewey
</p>


<h3>References</h3>

<p>Rothman, K. J. and Greenland, S. (1998) <em>Modern Epidemiology</em>.
Lippincott-Raven Publishers
</p>
<p>Rothman, K. J. (2002) <em>Epidemiology: An Introduction</em>. Oxford
University Press
</p>
<p>Jewell, N. P. (2004) <em>Statistics for Epidemiology</em>. 1st Edition,
2004, Chapman &amp; Hall, pp. 73-81
</p>
<p>Selvin, S. (1998) <em>Modern Applied Biostatistical Methods Using
S-Plus</em>. 1st Edition, Oxford University Press
</p>
<p>Gerritsen, A (2010) <a href="https://www.theanalysisfactor.com/cross-tabulation-in-cohort-and-case-control-studies/">https://www.theanalysisfactor.com/cross-tabulation-in-cohort-and-case-control-studies/</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+OddsRatio">OddsRatio</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- matrix(c(78,50,1422,950), 
            nrow=2, 
            dimnames = list(water=c("cont", "clean"), 
                            diarrhea=c("yes", "no")))

RelRisk(m, conf.level = 0.95)


mm &lt;- cbind(c(9,20),c(41,29))
mm
 
RelRisk(t(mm), conf.level=0.95)
RelRisk(t(mm), conf.level=0.95, method="wald")
RelRisk(t(mm), conf.level=0.95, method="use.or")
</code></pre>

<hr>
<h2 id='Rename'>Change Names of a Named Object</h2><span id='topic+Rename'></span>

<h3>Description</h3>

<p><code>Rename</code> changes the names of a named object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rename(x, ..., gsub = FALSE, fixed = TRUE, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rename_+3A_x">x</code></td>
<td>
<p>Any named object</p>
</td></tr>
<tr><td><code id="Rename_+3A_...">...</code></td>
<td>
<p>A sequence of named arguments, all of type character</p>
</td></tr>
<tr><td><code id="Rename_+3A_gsub">gsub</code></td>
<td>
<p>a logical value; if TRUE, <code><a href="base.html#topic+gsub">gsub</a></code> is used to change the
row and column labels of the resulting table.
That is, instead of substituting whole names, substrings of the
names of the object can changed.
</p>
</td></tr>
<tr><td><code id="Rename_+3A_fixed">fixed</code></td>
<td>
<p>a logical value, passed to <code><a href="base.html#topic+gsub">gsub</a></code>. If TRUE,
substitutions are by fixed strings and not by regular expressions.</p>
</td></tr>
<tr><td><code id="Rename_+3A_warn">warn</code></td>
<td>
<p>a logical value; should a warning be issued if
those names to change are not found?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function changes the names of <code>x</code> according to the
remaining arguments.
If <code>gsub</code> is FALSE, argument tags are the <em>old</em>
names, the values are the new names.
If <code>gsub</code> is TRUE, arguments are substrings of the names
that are substituted by the argument values.
</p>


<h3>Value</h3>

<p>The object <code>x</code> with new names defined by the ... arguments.
</p>


<h3>Note</h3>

<p> This function was previously published in the package <span class="pkg">memisc</span> as <code><a href="memisc.html#topic+rename">rename</a></code>
and has been integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>Martin Elff &lt;melff@essex.ac.uk&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+SetNames">SetNames</a></code>, <code><a href="#topic+Recode">Recode</a></code> for recoding of a factor (renaming or combining levels)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(a=1, b=2)
Rename(x, a="A", b="B")

str(Rename( iris,
            Sepal.Length="Sepal_Length",
            Sepal.Width ="Sepal_Width",
            Petal.Length="Petal_Length",
            Petal.Width ="Petal_Width"
            ))

str(Rename(iris, .="_", gsub=TRUE))
</code></pre>

<hr>
<h2 id='reorder.factor'>Reorder the Levels of a Factor</h2><span id='topic+reorder.factor'></span>

<h3>Description</h3>

<p>Reorder the levels of a factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factor'
reorder(x, X, FUN, ..., 
        order = is.ordered(x), new.order, sort = SortMixed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reorder.factor_+3A_x">x</code></td>
<td>
<p>factor</p>
</td></tr>
<tr><td><code id="reorder.factor_+3A_x">X</code></td>
<td>
<p>auxillary data vector</p>
</td></tr>
<tr><td><code id="reorder.factor_+3A_fun">FUN</code></td>
<td>
<p>function to be applied to subsets of <code>X</code> determined by
<code>x</code>, to determine factor order</p>
</td></tr>
<tr><td><code id="reorder.factor_+3A_...">...</code></td>
<td>
<p>optional parameters to <code>FUN</code></p>
</td></tr>
<tr><td><code id="reorder.factor_+3A_order">order</code></td>
<td>
<p>logical value indicating whether the returned
object should be an <code><a href="base.html#topic+ordered">ordered</a></code> factor</p>
</td></tr>
<tr><td><code id="reorder.factor_+3A_new.order">new.order</code></td>
<td>
<p>a vector of indexes or a vector of label names giving
the order of the new factor levels</p>
</td></tr>
<tr><td><code id="reorder.factor_+3A_sort">sort</code></td>
<td>
<p>function to use to sort the factor level names, used only
when <code>new.order</code> is missing</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function changes the order of the levels of a factor. It can do
so via three different mechanisms, depending on whether, <code>X</code>
<em>and</em> <code>FUN</code>, <code>new.order</code> or <code>sort</code> are provided.
</p>
<p>If <code>X</code> <em>and</em> <code>Fun</code> are provided: The data in <code>X</code>
is grouped by the levels of <code>x</code> and <code>FUN</code> is applied.
The groups are then sorted by this value, and the resulting order is
used for the new factor level names.
</p>
<p>If <code>new.order</code> is provided: For a numeric vector, the new factor
level names are constructed by reordering the factor levels according
to the numeric values. For vectors, <code>new.order</code> gives the list of
new factor level names. In either case levels omitted from
<code>new.order</code> will become missing (<code>NA</code>) values.
</p>
<p>If <code>sort</code> is provided (as it is by default): The new
factor level names are generated by applying the supplied function
to the existing factor level names. With <code>sort=mixedsort</code> the
factor levels are sorted so that combined numeric and character
strings are sorted in according to character rules on the character
sections (including ignoring case), and the numeric rules for the
numeric sections. See <code><a href="gtools.html#topic+mixedsort">mixedsort</a></code> for details.
</p>


<h3>Value</h3>

<p>A new factor with reordered levels
</p>


<h3>Author(s)</h3>

<p>Gregory R. Warnes <a href="mailto:greg@warnes.net">greg@warnes.net</a></p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+factor">factor</a></code> and <code><a href="stats.html#topic+reorder">reorder</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a 4 level example factor
trt &lt;- factor( sample( c("PLACEBO", "300 MG", "600 MG", "1200 MG"),
              100, replace=TRUE ) )
summary(trt)
# Note that the levels are not in a meaningful order.

# Change the order to something useful
# default "mixedsort" ordering
trt2 &lt;- reorder(trt)
summary(trt2)
# using indexes:
trt3 &lt;- reorder(trt, new.order=c(4, 2, 3, 1))
summary(trt3)
# using label names:
trt4 &lt;- reorder(trt, new.order=c("PLACEBO", "300 MG", "600 MG", "1200 MG"))
summary(trt4)
# using frequency
trt5 &lt;- reorder(trt, X=as.numeric(trt), FUN=length)
summary(trt5)

# drop out the '300 MG' level
trt6 &lt;- reorder(trt, new.order=c("PLACEBO", "600 MG", "1200 MG"))
summary(trt6)
</code></pre>

<hr>
<h2 id='Rev'>Reverse Elements of a Vector, a Matrix, a Table, an Array or a Data.frame
</h2><span id='topic+Rev'></span><span id='topic+Rev.default'></span><span id='topic+Rev.matrix'></span><span id='topic+Rev.table'></span><span id='topic+Rev.array'></span><span id='topic+Rev.data.frame'></span>

<h3>Description</h3>

<p><code>Rev</code> provides a reversed version of its argument.
Unlike the basic function, it does in higher-dimensional structures such as matrices not reverse the elements, but the order of the rows and/or columns. It further offers additional interfaces for higher dimensional arrays or tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rev(x, ...)

## S3 method for class 'matrix'
Rev(x, margin, ...)

## S3 method for class 'table'
Rev(x, margin, ...)

## S3 method for class 'array'
Rev(x, margin, ...)

## S3 method for class 'data.frame'
Rev(x, margin, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rev_+3A_x">x</code></td>
<td>
<p>a vector, a matrix or a higher dimensional table to be reversed.
</p>
</td></tr>
<tr><td><code id="Rev_+3A_margin">margin</code></td>
<td>
<p>vector of dimensions which to be reversed (1 for rows, 2 for columns, etc.). If not defined, all dimensions will be reverted.
</p>
</td></tr>
<tr><td><code id="Rev_+3A_...">...</code></td>
<td>
<p>the dots are passed to the array interface.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+rev">rev</a></code>, <code><a href="base.html#topic+order">order</a></code>, <code><a href="base.html#topic+sort">sort</a></code>, <code><a href="base.html#topic+seq">seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tab &lt;- matrix(c(1, 11, 111,
                2, 22, 222,
                3, 33, 333), 
              byrow=TRUE, nrow=3,
              dimnames=list(mar1=1:3, mar2=c("a","b","c")))

Rev(tab, margin=1)
Rev(tab, margin=2)

# reverse both dimensions
Rev(tab, margin=c(1, 2))

t(tab)

# reverse 3dimensional array
aa &lt;- Abind(tab, 2 * tab, along=3)
dimnames(aa)[[3]] &lt;- c("A","Z")

# reverse rows
Rev(aa, 1)
# reverse columns
Rev(aa, 2)
# reverse 3th dimension
Rev(aa, 3)

# reverse all dimensions
Rev(aa)
# same as
Rev(aa, margin=(1:3))
</code></pre>

<hr>
<h2 id='RevCode'>Reverse Codes</h2><span id='topic+RevCode'></span>

<h3>Description</h3>

<p>In psychology variables often need to be recoded into reverse order in cases that items are negatively worded. So it can be ensured that a high value indicate the same type of response on every item.
Let's say we have a Likert scale from 1 to 5 and we want to recode the variable so that a 5 becomes a 1, 4 a 2 and so on. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RevCode(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RevCode_+3A_x">x</code></td>
<td>
<p>a numerical or logical vector, or a factor.</p>
</td></tr>
<tr><td><code id="RevCode_+3A_...">...</code></td>
<td>
<p>the dots are sent to <code>min</code>/<code>max</code>, such as possibly to remove <code>NA</code>s before reversing numeric values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function recodes based on:
</p>
<p><code>min(x, na.rm=TRUE) + max(x, na.rm=TRUE) - x</code>
</p>


<h3>Value</h3>

<p>the recoded vector</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+Recode">Recode</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:5
data.frame(x, rev_num=RevCode(x), rev_fac=RevCode(factor(x)))

s &lt;- c(3,4,2,7,4,9,NA,10) 
RevCode(factor(s, levels=1:10))

i &lt;- c(1,0,0,0,1,1)
cbind(i, RevCode(i))

k &lt;- as.logical(c(1,0,0,0,1,1))
cbind(k, RevCode(k))

x &lt;- factor(sample(letters[1:5], 10, replace = TRUE))
RevCode(x)

# we want to set the level 5 to NA before reversing
RevCode(factor(NAIf(x, "e")))
</code></pre>

<hr>
<h2 id='RevWeibull'>The Reverse Weibull Distribution</h2><span id='topic+dRevWeibull'></span><span id='topic+pRevWeibull'></span><span id='topic+qRevWeibull'></span><span id='topic+rRevWeibull'></span><span id='topic+dNegWeibull'></span><span id='topic+pNegWeibull'></span><span id='topic+qNegWeibull'></span><span id='topic+rNegWeibull'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random generation for the reverse (or negative) Weibull
distribution with location, scale and shape parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dRevWeibull(x, loc=0, scale=1, shape=1, log = FALSE)
pRevWeibull(q, loc=0, scale=1, shape=1, lower.tail = TRUE)
qRevWeibull(p, loc=0, scale=1, shape=1, lower.tail = TRUE)
rRevWeibull(n, loc=0, scale=1, shape=1)

dNegWeibull(x, loc=0, scale=1, shape=1, log = FALSE)
pNegWeibull(q, loc=0, scale=1, shape=1, lower.tail = TRUE)
qNegWeibull(p, loc=0, scale=1, shape=1, lower.tail = TRUE)
rNegWeibull(n, loc=0, scale=1, shape=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RevWeibull_+3A_x">x</code>, <code id="RevWeibull_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
<tr><td><code id="RevWeibull_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="RevWeibull_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="RevWeibull_+3A_loc">loc</code>, <code id="RevWeibull_+3A_scale">scale</code>, <code id="RevWeibull_+3A_shape">shape</code></td>
<td>
<p>Location, scale and shape parameters (can be
given as vectors).</p>
</td></tr>
<tr><td><code id="RevWeibull_+3A_log">log</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the log density is returned.</p>
</td></tr>
<tr><td><code id="RevWeibull_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if <code>TRUE</code> (default), probabilities
are P[X &lt;= x], otherwise, P[X &gt; x]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reverse (or negative) Weibull distribution function with parameters
<code class="reqn">loc = a</code>, <code class="reqn">scale = b</code> and
<code class="reqn">shape = s</code> is
</p>
<p style="text-align: center;"><code class="reqn">G(z) = \exp\left\{-\left[-\left(\frac{z-a}{b}\right)
    \right]^s\right\}</code>
</p>

<p>for <code class="reqn">z &lt; a</code> and one otherwise, where <code class="reqn">b &gt; 0</code> and
<code class="reqn">s &gt; 0</code>.
</p>


<h3>Value</h3>

<p><code>dRevWeibull</code> and <code>dNegWeibull</code> give the density function,
<code>pRevWeibull</code> and <code>pNegWeibull</code> give the distribution function,
<code>qRevWeibull</code> and <code>qNegWeibull</code> give the quantile function,
<code>rRevWeibull</code> and <code>rNegWeibull</code> generate random deviates.
</p>


<h3>Note</h3>

<p>Within extreme value theory the reverse Weibull distibution (also
known as the negative Weibull distribution) is often referred to
as the Weibull distribution.
We make a distinction to avoid confusion with the three-parameter
distribution used in survival analysis, which is related by a
change of sign to the distribution given above.
</p>


<h3>Author(s)</h3>

<p>Alec Stephenson &lt;alec_stephenson@hotmail.com&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+rFrechet">rFrechet</a></code>, <code><a href="#topic+rGenExtrVal">rGenExtrVal</a></code>, <code><a href="#topic+rGumbel">rGumbel</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>dRevWeibull(-5:-3, -1, 0.5, 0.8)
pRevWeibull(-5:-3, -1, 0.5, 0.8)
qRevWeibull(seq(0.9, 0.6, -0.1), 2, 0.5, 0.8)
rRevWeibull(6, -1, 0.5, 0.8)
p &lt;- (1:9)/10
pRevWeibull(qRevWeibull(p, -1, 2, 0.8), -1, 2, 0.8)
## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
</code></pre>

<hr>
<h2 id='RgbToCmy'>Conversion Between RGB and CMYK
</h2><span id='topic+RgbToCmy'></span><span id='topic+CmykToCmy'></span><span id='topic+CmyToCmyk'></span><span id='topic+RgbToCmy'></span><span id='topic+CmykToRgb'></span>

<h3>Description</h3>

<p>These function convert colors between RGB and CMYK system.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RgbToCmy(col, maxColorValue = 1)
CmykToRgb(cyan, magenta, yellow, black, maxColorValue=1)
CmyToCmyk(col)
CmykToCmy(col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RgbToCmy_+3A_col">col</code></td>
<td>
<p>the matrix of the color to be converted
</p>
</td></tr>
<tr><td><code id="RgbToCmy_+3A_cyan">cyan</code></td>
<td>
<p>cyan values of the color(s) to be converted
</p>
</td></tr>
<tr><td><code id="RgbToCmy_+3A_magenta">magenta</code></td>
<td>
<p>magenta values of the color(s) to be converted
</p>
</td></tr>
<tr><td><code id="RgbToCmy_+3A_yellow">yellow</code></td>
<td>
<p>yellow values of the color(s) to be converted
</p>
</td></tr>
<tr><td><code id="RgbToCmy_+3A_black">black</code></td>
<td>
<p>black values of the color(s) to be converted
</p>
</td></tr>
<tr><td><code id="RgbToCmy_+3A_maxcolorvalue">maxColorValue</code></td>
<td>
<p> the value for the color
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the converted value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RgbToCol">RgbToCol</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>CmykToRgb(0.42, 45.23, 85.14, maxColorValue=100)
</code></pre>

<hr>
<h2 id='RgbToCol'>Find the Nearest Named R-Color to a Given RGB-Color </h2><span id='topic+RgbToCol'></span><span id='topic+RgbToLong'></span><span id='topic+LongToRgb'></span>

<h3>Description</h3>

<p>Converting a RGB-color to a named R-Color means looking for a color in the R-palette, which is nearest to the given RGB-color.
This function uses the minimum of squared distance (<code>"euclidean"</code>) or the minimum absolute distance (<code>"manhattan"</code>) as proximity measure. <br />
<code>RgbToLong()</code> converts a RGB-color to a long integer in numeric format. <code>LongToRGB()</code> does it the other way round.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RgbToCol(col, method = "rgb", metric = "euclidean")

RgbToLong(col)
LongToRgb(col)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RgbToCol_+3A_col">col</code></td>
<td>
<p>the color in rgb code, say a matrix with the red, green and blue code in the rows.  </p>
</td></tr>
<tr><td><code id="RgbToCol_+3A_method">method</code></td>
<td>
<p>character string specifying the color space to be used. Can be <code>"rgb"</code> (default) or <code>"hsv"</code>.</p>
</td></tr>
<tr><td><code id="RgbToCol_+3A_metric">metric</code></td>
<td>
<p>character string specifying the metric to be used for calculating distances between the colors.
Available options are <code>"euclidean"</code> (default) and <code>"manhattan"</code>. Euclidean distances are root sum-of-squares of
differences, and manhattan distances are the sum of absolute differences.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It may not be clear from the start which method, rgb or hsv, yield the more natural results. Trying and comparing is a recommended strategy. Moreover the shortest numerical distance will not always be the best choice, when comparing the colours visually.</p>


<h3>Value</h3>

<p>the name of the nearest found R color.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ColToRgb">ColToRgb</a></code> and the other conversion functions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RgbToCol(matrix(c(162,42,42), nrow=3))

RgbToLong(matrix(c(162,42,42), nrow=3))
</code></pre>

<hr>
<h2 id='RndPairs'>Create Pairs of Correlated Random Numbers
</h2><span id='topic+RndPairs'></span><span id='topic+RndWord'></span>

<h3>Description</h3>

<p>Create pairs of correlated random numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RndPairs(n, r, rdist1 = rnorm(n = n, mean = 0, sd = 1),
         rdist2 = rnorm(n = n, mean = 0, sd = 1), prop = NULL)

RndWord(size, length, x = LETTERS, replace = TRUE, prob = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RndPairs_+3A_n">n</code></td>
<td>
<p>number of pairs. If length(n) &gt; 1, the length is taken to be the number required.
</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_r">r</code></td>
<td>
<p>the correlation between the two sets.
</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_rdist1">rdist1</code>, <code id="RndPairs_+3A_rdist2">rdist2</code></td>
<td>
<p>the distribution of the random vector X1 and X2. Default is standard normal distribution.
</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_size">size</code></td>
<td>
<p>a non-negative integer giving the number of artificial words to build.</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_length">length</code></td>
<td>
<p>a non-negative integer giving the length of the words.</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_x">x</code></td>
<td>
<p>elements to choose from.</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_replace">replace</code></td>
<td>
<p>Should sampling be with replacement?</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_prop">prop</code></td>
<td>
<p>proportions for ordinal variable, must sum to 1.</p>
</td></tr>
<tr><td><code id="RndPairs_+3A_prob">prob</code></td>
<td>
<p>a vector of probability weights for obtaining the elements of the vector being sampled.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with 2 columns, X1 and X2 containing the random numbers
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code>, <code><a href="stats.html#topic+rnorm">rnorm</a></code>, <code><a href="base.html#topic+Random">Random</a></code> and friends
</p>


<h3>Examples</h3>

<pre><code class='language-R'># produce 100 pairs of a normal distributed random number with a correlation of 0.7
d.frm  &lt;- RndPairs(n=100, r=0.7)

plot(d.frm)
lines(lm(y ~ x,d.frm))

# change the distribution
d.frm  &lt;- RndPairs(n=100, r=0.7, rdist2 = rlnorm(n = 100, meanlog = 1, sdlog = .8))
d.frm  &lt;- RndPairs(n=100, r=0.7, rdist2 = runif(n = 100, -1, 4))

x &lt;- StrCap(sapply(sample(3:15, 10), function(i) RndWord(1, i, x=letters)))


# produce some artificial words with defined probabilities for the letters
p &lt;- c(6.51,1.89,3.06,5.08,17.4,1.66,3.01,4.76,7.55,0.27,1.21,3.44,2.53,
       9.78,2.51,0.79,0.02,7,7.27,6.15,4.35,0.67,1.89,0.03,0.04,1.13)
sapply(sample(3:15, 10), function(i) RndWord(1, i, x=letters, prob=p))

# produce associated ordinal variables
d.ord &lt;- RndPairs(500, r=0.8, prop = list(c(.15, .3, .55), 
                                      c(.3, .5, .2)))
levels(d.ord$y) &lt;- levels(d.ord$x) &lt;- LETTERS[1:3]
PlotMosaic(table(d.ord$x, d.ord$y), las=1, main="")

</code></pre>

<hr>
<h2 id='RobScale'>Robust Scaling With Median and Mad
</h2><span id='topic+RobScale'></span>

<h3>Description</h3>

<p><code>RobScale</code> is a wrapper function for robust standardization, using <code><a href="stats.html#topic+median">median</a></code>
and <code><a href="stats.html#topic+mad">mad</a></code> instead of <code><a href="base.html#topic+mean">mean</a></code> and <code><a href="stats.html#topic+sd">sd</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RobScale(x, center = TRUE, scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RobScale_+3A_x">x</code></td>
<td>
<p>a numeric matrix(like object).
</p>
</td></tr>
<tr><td><code id="RobScale_+3A_center">center</code></td>
<td>
<p>a logical value defining whether x should be centered by the median. 
Centering is done by subtracting the column medians (omitting NAs) of x from their corresponding columns.
If center is FALSE, no centering is done.
</p>
</td></tr>
<tr><td><code id="RobScale_+3A_scale">scale</code></td>
<td>
<p>a logical value defining whether x should be scaled by the mad.
Scaling is done by dividing the (centered) columns of x by their mad. 
If scale is FALSE, no scaling is done. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the centered, scaled matrix. 
The numeric centering and scalings used (if any) are returned as attributes &quot;scaled:center&quot; and &quot;scaled:scale&quot; 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code>scale</code>, <code>sweep</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- d.pizza$temperature
plot(x=seq_along(x), y=RobScale(x), xlim=c(0,100))
points(x=seq_along(x), y=scale(x), col="red" )
</code></pre>

<hr>
<h2 id='RomanToInt'>Convert Roman Numerals to Integers</h2><span id='topic+RomanToInt'></span>

<h3>Description</h3>

<p>Convert roman numerals to integers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RomanToInt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RomanToInt_+3A_x">x</code></td>
<td>
<p>character vector containing roman numerals</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functon will convert roman numerals to integers without the upper bound
imposed by R (3899), ignoring case.
</p>


<h3>Value</h3>

<p>A integer vector with the same length as <code>roman</code>.  Character
strings which are not valid roman numerals will be converted to <code>NA</code>.
</p>


<h3>Author(s)</h3>

<p>Gregory R. Warnes &lt;greg@warnes.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+as.roman">as.roman</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RomanToInt( c('I', 'V', 'X', 'C', 'L', 'D', 'M' )  )

# works regardless of case
RomanToInt( 'MMXVI' )
RomanToInt( 'mmxvi' )

# works beyond R's limit of 3899
val.3899 &lt;- 'MMMDCCCXCIX'
val.3900 &lt;- 'MMMCM'
val.4000 &lt;- 'MMMM'
as.numeric(as.roman( val.3899 ))
as.numeric(as.roman( val.3900 ))
as.numeric(as.roman( val.4000 ))

RomanToInt(val.3899)
RomanToInt(val.3900)
RomanToInt(val.4000)

</code></pre>

<hr>
<h2 id='Rotate'>Rotate a Geometric Structure
</h2><span id='topic+Rotate'></span>

<h3>Description</h3>

<p>Rotate a geometric structure by an angle theta around a centerpoint xy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rotate(x, y = NULL, mx = NULL, my = NULL, theta = pi/3, asp = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Rotate_+3A_x">x</code>, <code id="Rotate_+3A_y">y</code></td>
<td>
<p>vectors containing the coordinates of the vertices of the polygon
, which has to be rotated.  The coordinates can be passed in a plotting structure (a list with x and y components), a two-column matrix, .... See <code><a href="grDevices.html#topic+xy.coords">xy.coords</a></code>.
</p>
</td></tr>
<tr><td><code id="Rotate_+3A_mx">mx</code>, <code id="Rotate_+3A_my">my</code></td>
<td>
<p>xy-coordinates of the center of the rotation. If left to NULL, the centroid of the structure will be used.
</p>
</td></tr>
<tr><td><code id="Rotate_+3A_theta">theta</code></td>
<td>
<p>angle of the rotation
</p>
</td></tr>
<tr><td><code id="Rotate_+3A_asp">asp</code></td>
<td>
<p>the aspect ratio for the rotation. Helpful for rotate structures along an ellipse. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function invisibly returns a list of the coordinates for the rotated shape(s).
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="#topic+DrawRegPolygon">DrawRegPolygon</a></code>, <code><a href="#topic+DrawEllipse">DrawEllipse</a></code>, <code><a href="#topic+DrawArc">DrawArc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># let's have a triangle
Canvas(main="Rotation")
x &lt;- DrawRegPolygon(nv=3)[[1]]

# and rotate
sapply( (0:3) * pi/6, function(theta) {
  xy &lt;- Rotate( x=x, theta=theta )
  polygon(xy, col=SetAlpha("blue", 0.2))
} )

abline(v=0, h=0)
</code></pre>

<hr>
<h2 id='RoundTo'>Round to Multiple
</h2><span id='topic+RoundTo'></span>

<h3>Description</h3>

<p>Returns a number rounded to the nearest specified multiple.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RoundTo(x, multiple = 1, FUN = round)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RoundTo_+3A_x">x</code></td>
<td>
<p>numeric. The value to round.
</p>
</td></tr>
<tr><td><code id="RoundTo_+3A_multiple">multiple</code></td>
<td>
<p>numeric. The multiple to which the number is to be rounded. Default is 1.
</p>
</td></tr>
<tr><td><code id="RoundTo_+3A_fun">FUN</code></td>
<td>
<p>the rounding function as character or as expression. Can be one out of <code><a href="base.html#topic+trunc">trunc</a></code>, <code>ceiling</code>, <code>round</code> (default) or <code>floor</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several functions to convert to integers. <code><a href="base.html#topic+round">round</a></code> rounds to the nearest integer or to any number of digits. Using a negative number rounds to a power of ten, so that <code>round (x, -3)</code> rounds to thousands.
Each of <code><a href="base.html#topic+trunc">trunc</a></code>, <code><a href="base.html#topic+floor">floor</a></code> and <code><a href="base.html#topic+ceiling">ceiling</a></code> round in a fixed direction, towards zero, down and up respectively. <code><a href="base.html#topic+round">round</a></code> is documented to round to even, so <code>round(2.5)</code> is <code>2</code>.
</p>
<p><code><a href="#topic+RoundTo">RoundTo</a></code> uses <code>round(x/multiple)*multiple</code> to get the result. So if <code>x</code> is equally close to two multiples, the multiple with the smaller absolute value will be returned when <code>round(x/multiple)</code> is even (and the greater when it's odd).<br />
If <code>FUN</code> is set to <code>ceiling</code> it will always round up, and if set to <code>floor</code> it will always round down. See examples for comparison).
</p>


<h3>Value</h3>

<p>the rounded value
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+round">round</a></code>, <code><a href="base.html#topic+trunc">trunc</a></code>, <code><a href="base.html#topic+ceiling">ceiling</a></code>, <code><a href="base.html#topic+floor">floor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RoundTo(10, 3)     # Rounds 10 to a nearest multiple of 3 (9)
RoundTo(-10, -3)   # Rounds -10 to a nearest multiple of -3 (-9)

RoundTo(1.3, 0.2)  # Rounds 1.3 to a nearest multiple of 0.2 (1.2)
RoundTo(-1.3, 0.2) # Rounds -1.3 to a nearest multiple of 0.2 (-1.2)
RoundTo(5, -2)     # Returns an error, because -2 and 5 have different signs

# Round down
RoundTo(c(1,-1) * 1.2335, 0.05, floor)
RoundTo(c(1,-1) * 1233.5, 100, floor)

# Round up
RoundTo(c(1,-1) * 1.2335, 0.05, ceiling)
RoundTo(c(1,-1) * 1233.5, 100, ceiling)

# Round towards zero
RoundTo(c(1,-1) * 1.2335, 0.05, trunc)
RoundTo(c(1,-1) * 1233.5, 100, trunc)


x &lt;- c(-1.5,-1.3, 1.3, 1.5)
cbind(x =       x,
      round =   RoundTo(x, 0.2, FUN=round),
      trunc =   RoundTo(x, 0.2, FUN=trunc),
      ceiling = RoundTo(x, 0.2, FUN=ceiling),
      floor =   RoundTo(x, 0.2, FUN=floor)
)

x &lt;- -10:10
cbind(x =       x,
      round =   RoundTo(x, 2, FUN=round),
      trunc =   RoundTo(x, 2, FUN=trunc),
      ceiling = RoundTo(x, 2, FUN=ceiling),
      floor =   RoundTo(x, 2, FUN=floor)
)

</code></pre>

<hr>
<h2 id='RSessionAlive'>How Long Has the RSession Been Running?
</h2><span id='topic+RSessionAlive'></span><span id='topic+RTempdirAlive'></span>

<h3>Description</h3>

<p><code>RSessionAlive()</code> returns the time the R session has been running in hours. The function uses powershell in Windows and is thus restricted to run in windows only. <code>RTempdirAlive()</code> does the same for temporary directories, but runs on all systems. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSessionAlive()
RTempdirAlive()
</code></pre>


<h3>Value</h3>

<p>time in hours
</p>


<h3>Author(s)</h3>

<p>Markus Napflin &lt;markus.naepfl@in&gt;, Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+Sys.getenv">Sys.getenv</a></code>
</p>

<hr>
<h2 id='rSum21'>Random Numbers Adding Up to 1
</h2><span id='topic+rSum21'></span>

<h3>Description</h3>

<p>Generates a vector of uniformly distributed random numbers which sum to 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rSum21(size, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rSum21_+3A_size">size</code></td>
<td>
<p>a non-negative integer giving the number of numbers to generate.
</p>
</td></tr>
<tr><td><code id="rSum21_+3A_digits">digits</code></td>
<td>
<p>integer indicating the number of decimal places to be used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of length size with elements drawn 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+runif">runif</a></code>, (Dirichlet distribution)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate 5 numbers
x &lt;- rSum21(5)
sum(x)
</code></pre>

<hr>
<h2 id='RunsTest'>Runs Test for Randomness</h2><span id='topic+RunsTest'></span><span id='topic+RunsTest.formula'></span><span id='topic+RunsTest.default'></span>

<h3>Description</h3>

<p>Performs a test whether the elements of <code>x</code> are serially independent - say, whether
they occur in a random order - by counting how many runs there are above and below a threshold.
If <code>y</code> is supplied a two sample Wald-Wolfowitz-Test testing the equality of two distributions against general alternatives will be computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RunsTest(x, ...)

## Default S3 method:
RunsTest(x, y = NULL, alternative = c("two.sided", "less", "greater"),
         exact = NULL, correct = TRUE, na.rm = FALSE, ...)

## S3 method for class 'formula'
RunsTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RunsTest_+3A_x">x</code></td>
<td>
<p>a dichotomous vector of data values or a (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_y">y</code></td>
<td>
<p>an optional (non-empty) numeric vector of data values.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of <code>"two.sided"</code> (default), <code>"less"</code> or <code>"greater"</code>. </p>
</td></tr>
<tr><td><code id="RunsTest_+3A_exact">exact</code></td>
<td>
<p>a logical indicating whether an exact p-value should be computed. By default exact values will be calculated for small vectors with a total length &lt;= 30 and the normal approximation for longer ones.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_correct">correct</code></td>
<td>
<p>a logical indicating whether to apply continuity correction when computing the test statistic. Default is <code>TRUE</code>. Ignored if <code>exact</code> is set to <code>TRUE</code>. See details.</p>
</td></tr>
<tr><td><code id="RunsTest_+3A_na.rm">na.rm</code></td>
<td>
<p>defines if <code>NA</code>s should be omitted. Default is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="RunsTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>The runs test for randomness</b> <code style="white-space: pre;">&#8288;     &#8288;</code>  is used to test the hypothesis
that a series of numbers is random. <br />
</p>
<p>For a categorical variable, the number of runs correspond to the number of times the category changes, that is,
where <code class="reqn">x_{i}</code> belongs to one category and  <code class="reqn">x_{i+1}</code>  belongs to the other. The number of runs is the number of sign changes plus one.<br />
</p>
<p>For a numeric variable x containing more than two values, a run is a set of sequential values that are either all above or below a specified cutpoint, typically the median. This is not necessarily the best choice. If another threshold should be used use a code like: <code>RunsTest(x &gt; mean(x))</code>.
</p>
<p>The exact distribution of runs and the p-value based on it are described in the manual of SPSS &quot;Exact tests&quot;
<a href="https://www.sussex.ac.uk/its/pdfs/SPSS_Exact_Tests_21.pdf">https://www.sussex.ac.uk/its/pdfs/SPSS_Exact_Tests_21.pdf</a>.
</p>
<p>The normal approximation of the runs test is calculated with the expected number of runs under the null
</p>
<p style="text-align: center;"><code class="reqn">\mu_r=\frac{2 n_0 n_1}{n_0 + n_1} + 1</code>
</p>

<p>and its variance
</p>
<p style="text-align: center;"><code class="reqn">\sigma_r^2 = \frac{2 n_0 n_1 (2 n_0 n_1 - n_0 - n_1) }{(n_0 + n_1)^2 \cdot (n_0 + n_1 - 1)}</code>
</p>

<p>as
</p>
<p style="text-align: center;"><code class="reqn">\hat{z}=\frac{r - \mu_r + c}{\sigma_r}</code>
</p>

<p>where <code class="reqn">n_0, n_1</code> the number of values below/above the threshold and <code class="reqn">r</code> the number of runs.
</p>
<p>Setting the continuity correction <code>correct = TRUE</code> will yield the normal approximation as SAS (and SPSS if n &lt; 50) does it, see <a href="http://support.sas.com/kb/33/092.html">http://support.sas.com/kb/33/092.html</a>.
The c is set to <code class="reqn">c = 0.5</code> if <code class="reqn">r &lt; \frac{2 n_0 n_1}{n_0 + n_1} + 1</code>
and to <code class="reqn">c = -0.5</code> if <code class="reqn">r &gt; \frac{2 n_0 n_1}{n_0 + n_1} + 1</code>.
</p>
<p><b>The Wald-Wolfowitz test</b> <code style="white-space: pre;">&#8288;     &#8288;</code>  is a  2-sample nonparametric test to  evaluate if two continuous cumulative distributions are significantly different or not. Ideally there should be no ties in the data. In practice there is no problem with ties within a group, but if ties occur between members of the different groups then there is no unique sequence of observations. For example the data sets A: 10,14,17,19,34 and B: 12,13,17,19,22 can give four possible sequences, with two possible values for r (7 or 9). The &quot;solution&quot; to this is to list every possible combination, and calculate the test statistic for each one. If all test statistics are significant at the chosen level, then one can reject the null hypothesis. If only some are significant, then Siegel (1956) suggests that the average of the P-values is taken.
Help for finding all permutations of ties can be found at:  <a href="https://stackoverflow.com/questions/47565066/all-possible-permutations-in-factor-variable-when-ties-exist-in-r">https://stackoverflow.com/questions/47565066/all-possible-permutations-in-factor-variable-when-ties-exist-in-r</a>
</p>
<p>However this solutions seems quite coarse and in general, the test should not be used if there are more than one or two ties. We have better tests to distinguish between two samples!
</p>


<h3>Value</h3>

<p>A list with the following components.
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>z, the value of the standardized runs statistic, if not exact p-values are computed.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the number of runs, the total number of zeros (m) and ones (n)</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, exact p-values by Detlew Labes &lt;detlewlabes@gmx.de&gt;
</p>


<h3>References</h3>

<p>Wackerly, D., Mendenhall, W. Scheaffer, R. L. (1986) <em>Mathematical Statistics with Applications</em>, 3rd Ed., Duxbury Press, CA.
</p>
<p>Wald, A. and Wolfowitz, J. (1940): On a test whether two samples are from the same population,  <em>Ann. Math Statist</em>. 11, 147-162.
</p>
<p>Siegel, S. (1956) <em>Nonparametric Statistics for the Behavioural Sciences</em>, McGraw-Hill Kogakusha, Tokyo.
</p>


<h3>See Also</h3>

<p>Run Length Encoding <code><a href="base.html#topic+rle">rle</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># x will be coerced to a dichotomous variable
x &lt;- c("S","S", "T", "S", "T","T","T", "S", "T")
RunsTest(x)


x &lt;- c(13, 3, 14, 14, 1, 14, 3, 8, 14, 17, 9, 14, 13, 2, 16, 1, 3, 12, 13, 14)
RunsTest(x)
# this will be treated as
RunsTest(x &gt; median(x))

plot( (x &lt; median(x)) - 0.5, type="s", ylim=c(-1,1) )
abline(h=0)

set.seed(123)
x &lt;- sample(0:1, size=100, replace=TRUE)
RunsTest(x)
# As you would expect of values from a random number generator, the test fails to reject
# the null hypothesis that the data are random.


# SPSS example
x &lt;- c(31,23,36,43,51,44,12,26,43,75,2,3,15,18,78,24,13,27,86,61,13,7,6,8)
RunsTest(x, exact=TRUE)       # exact probability
RunsTest(x, exact=FALSE)      # normal approximation

# SPSS example small dataset
x &lt;- c(1, 1, 1, 1, 0, 0, 0, 0, 1, 1)
RunsTest(x)
RunsTest(x, exact=FALSE)

# if y is not NULL, the Wald-Wolfowitz-Test will be performed
A &lt;- c(35,44,39,50,48,29,60,75,49,66)
B &lt;- c(17,23,13,24,33,21,18,16,32)

RunsTest(A, B, exact=TRUE)
RunsTest(A, B, exact=FALSE)
</code></pre>

<hr>
<h2 id='Sample'>Random Samples and Permutations
</h2><span id='topic+Sample'></span>

<h3>Description</h3>

<p><code>Sample</code> takes a sample of the specified size from the elements of x using either with or without replacement. The function does the same as the base::sample() and offers additionally an interface for data frames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sample(x, size, replace = FALSE, prob = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sample_+3A_x">x</code></td>
<td>
<p>either a vector of one or more elements from which to choose, or a positive integer.
</p>
</td></tr>
<tr><td><code id="Sample_+3A_size">size</code></td>
<td>
<p>a positive number, the number of items to choose from.
</p>
</td></tr>
<tr><td><code id="Sample_+3A_replace">replace</code></td>
<td>
<p>a non-negative integer giving the number of items to choose.
</p>
</td></tr>
<tr><td><code id="Sample_+3A_prob">prob</code></td>
<td>
<p>should sampling be with replacement?
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sampled elements in the same structure as x
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sample">sample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample(d.pizza, size=5)
</code></pre>

<hr>
<h2 id='SampleTwins'>Sample Twins
</h2><span id='topic+SampleTwins'></span>

<h3>Description</h3>

<p>Draw a twin sample out of a population for a given recordset, by matching some strata criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SampleTwins(x, stratanames = NULL, twins, 
            method = c("srswor", "srswr", "poisson", "systematic"), 
            pik, description = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SampleTwins_+3A_x">x</code></td>
<td>
<p>the data to draw the sample from
</p>
</td></tr>
<tr><td><code id="SampleTwins_+3A_stratanames">stratanames</code></td>
<td>
<p>the stratanames to use
</p>
</td></tr>
<tr><td><code id="SampleTwins_+3A_twins">twins</code></td>
<td>
<p>the twin sample
</p>
</td></tr>
<tr><td><code id="SampleTwins_+3A_method">method</code></td>
<td>
<p>method to select units; the following methods are implemented: simple random 
sampling without replacement (srswor), simple random sampling with replacement (srswr), 
Poisson sampling (poisson), systematic sampling (systematic); if &quot;method&quot; is missing, 
the default method is &quot;srswor&quot;. See <code><a href="#topic+Strata">Strata</a></code>.</p>
</td></tr>
<tr><td><code id="SampleTwins_+3A_pik">pik</code></td>
<td>
<p>vector of inclusion probabilities or auxiliary information used to compute them; 
this argument is only used for unequal probability sampling (Poisson and systematic). If an
auxiliary information is provided, the function uses the inclusionprobabilities function for
computing these probabilities. If the method is &quot;srswr&quot; and the sample size is larger than
the population size, this vector is normalized to one.</p>
</td></tr>
<tr><td><code id="SampleTwins_+3A_description">description</code></td>
<td>
<p>a message is printed if its value is TRUE; the message gives the number 
of selected units and the number of the units in the population. 
By default, the value is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

 
<p>The function produces an object, which contains the following information:
</p>
<table>
<tr><td><code>id</code></td>
<td>
<p>the identifier of the selected units.</p>
</td></tr>
<tr><td><code>stratum</code></td>
<td>
<p>the unit stratum.</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>the final unit inclusion probability.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Strata">Strata</a></code>, <code><a href="base.html#topic+sample">sample</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- rbind(matrix(rep("nc",165), 165, 1, byrow=TRUE), 
           matrix(rep("sc", 70), 70, 1, byrow=TRUE))
m &lt;- cbind.data.frame(m, c(rep(1, 100), rep(2,50), rep(3,15), 
                           rep(1,30), rep(2,40)), 1000*runif(235))
names(m) &lt;- c("state","region","income")

# this would be our sample to be reproduced by a twin sample
d.smp &lt;- m[sample(nrow(m), size=10, replace=TRUE),]

# draw the sample
s &lt;- SampleTwins(x = m, stratanames=c("state","region"), twins = d.smp, method="srswor")

d.twin &lt;- m[s$id,]
d.twin
</code></pre>

<hr>
<h2 id='SaveAs'>Saves an R Object Under a Different Name
</h2><span id='topic+SaveAs'></span>

<h3>Description</h3>

<p>An R object cannot be saved in binary mode under a different name using the default <code>save()</code> function. <code>SaveAs()</code> extends the save function for this option. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SaveAs(x, objectname, file, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SaveAs_+3A_x">x</code></td>
<td>
<p>the object to save
</p>
</td></tr>
<tr><td><code id="SaveAs_+3A_objectname">objectname</code></td>
<td>
<p>the new name for the object.
</p>
</td></tr>
<tr><td><code id="SaveAs_+3A_file">file</code></td>
<td>
<p>a (writable binary-mode) connection or the name of the file where the data will be saved (when tilde expansion is done). 
</p>
</td></tr>
<tr><td><code id="SaveAs_+3A_...">...</code></td>
<td>
<p>the dots are passed to the save function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+save">save</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- stats::runif(20)
SaveAs(x=x, objectname="NewX", file = "NewXFile.rda")
unlink("NewXFile.rda")
</code></pre>

<hr>
<h2 id='ScheffeTest'>Scheffe Test for Pairwise and Otherwise Comparisons
</h2><span id='topic+ScheffeTest'></span><span id='topic+ScheffeTest.default'></span><span id='topic+ScheffeTest.aov'></span><span id='topic+ScheffeTest.formula'></span>

<h3>Description</h3>

<p>Scheffe's method applies to the set of estimates of all possible contrasts among the factor level means, not just the pairwise differences considered by Tukey's method. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScheffeTest(x, ...) 

## S3 method for class 'formula'
ScheffeTest(formula, data, subset, na.action, ...)
## S3 method for class 'aov'
ScheffeTest(x, which = NULL, contrasts = NULL, 
            conf.level = 0.95, ...)
## Default S3 method:
ScheffeTest(x, g = NULL, which = NULL, 
            contrasts = NULL, conf.level = 0.95, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScheffeTest_+3A_x">x</code></td>
<td>
<p>either a fitted model object, usually an <code><a href="stats.html#topic+aov">aov</a></code> fit, when g is left to <code>NULL</code> or a response variable to be evalutated by g (which mustn't be <code>NULL</code> then).
</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_g">g</code></td>
<td>
<p>the grouping variable.
</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_which">which</code></td>
<td>
<p>character vector listing terms in the fitted model for which the intervals should be calculated. Defaults to all the terms.
</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_contrasts">contrasts</code></td>
<td>
<p>a <code class="reqn">r \times c</code> matrix containing the contrasts to be computed, while <code>r</code> is the number of factor levels and <code>c</code> the number of contrasts. Each column must contain a full contrast (&quot;sum&quot;) adding up to 0. Note that the argument <code>which</code> must be defined, when non default contrasts are used.
Default value of <code>contrasts</code> is <code>NULL</code>. In this case all pairwise contrasts will be reported.
</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_conf.level">conf.level</code></td>
<td>
<p>numeric value between zero and one giving the confidence level to use.
If this is set to NA, just a matrix with the p-values will be returned.
</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
gives the data values and <code>rhs</code> the corresponding groups.</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="ScheffeTest_+3A_...">...</code></td>
<td>
<p>further arguments, currently not used.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of classes <code>c("PostHocTest")</code>, with one component for each term requested in <code>which</code>. Each component is a matrix with columns <code>diff</code> giving the difference in the observed means, <code>lwr.ci</code> giving the lower end point of the interval, <code>upr.ci</code> giving the upper end point and <code>pval</code> giving the p-value after adjustment for the multiple comparisons.
</p>
<p>There are print and plot methods for class <code>"PostHocTest"</code>. The plot method does not accept <code>xlab</code>, <code>ylab</code> or <code>main</code> arguments and creates its own values for each plot.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Robert O. Kuehl, Steel R. (2000) <em>Design of experiments</em>. Duxbury
</p>
<p>Steel R.G.D., Torrie J.H., Dickey, D.A. (1997) <em>Principles and Procedures of Statistics, A Biometrical Approach</em>. McGraw-Hill
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>, <code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fm1 &lt;- aov(breaks ~ wool + tension, data = warpbreaks)

ScheffeTest(x=fm1)
ScheffeTest(x=fm1, which="tension")

TukeyHSD(fm1)

# some special contrasts
y &lt;- c(7,33,26,27,21,6,14,19,6,11,11,18,14,18,19,14,9,12,6,
       24,7,10,1,10,42,25,8,28,30,22,17,32,28,6,1,15,9,15,
       2,37,13,18,23,1,3,4,6,2)
group &lt;- factor(c(1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,
       3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6))

r.aov &lt;- aov(y ~ group)

ScheffeTest(r.aov, contrasts=matrix( c(1,-0.5,-0.5,0,0,0,
                                       0,0,0,1,-0.5,-0.5), ncol=2) )

# just p-values:
ScheffeTest(r.aov, conf.level=NA)
</code></pre>

<hr>
<h2 id='SD'>(Weighted) Standard Deviation</h2><span id='topic+SD'></span><span id='topic+SDN'></span>

<h3>Description</h3>

<p>This function computes the standard deviation of the values in
<code>x</code>.
If <code>na.rm</code> is <code>TRUE</code> then missing values are removed before
computation proceeds. <code>SDn</code> returns the uncorrected sample standard deviation (which is biased estimator for the sample standard deviation). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SD(x, weights = NULL, na.rm = FALSE, ...)

SDN(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SD_+3A_x">x</code></td>
<td>
<p>a numeric vector or an <span class="rlang"><b>R</b></span> object which is coercible to one
by <code>as.double(x)</code>.</p>
</td></tr>
<tr><td><code id="SD_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>. </p>
</td></tr>
<tr><td><code id="SD_+3A_na.rm">na.rm</code></td>
<td>
<p>logical.  Should missing values be removed?</p>
</td></tr>
<tr><td><code id="SD_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Like <code><a href="stats.html#topic+var">var</a></code> this uses denominator <code class="reqn">n - 1</code>.
</p>
<p>The standard deviation of a zero-length vector (after removal of
<code>NA</code>s if <code>na.rm = TRUE</code>) is not defined and gives an error.
The standard deviation of a length-one vector is <code>NA</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+var">var</a></code> for its square, and <code><a href="stats.html#topic+mad">mad</a></code>, the most
robust alternative.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SD(1:2)^2
</code></pre>

<hr>
<h2 id='SendOutlookMail'>Send a Mail Using Outlook as Mail Client
</h2><span id='topic+SendOutlookMail'></span>

<h3>Description</h3>

<p>Sending emails in R can be required in some reporting tasks. As we already have RDCOMClient available we wrap the send code in a function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SendOutlookMail(to, cc = NULL, bcc = NULL, subject, body, attachment = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SendOutlookMail_+3A_to">to</code></td>
<td>
<p>a vector of recipients
</p>
</td></tr>
<tr><td><code id="SendOutlookMail_+3A_cc">cc</code></td>
<td>
<p>a vector of recipients receiving a carbon copy
</p>
</td></tr>
<tr><td><code id="SendOutlookMail_+3A_bcc">bcc</code></td>
<td>
<p>a vector of recipients receiving a blind carbon copy
</p>
</td></tr>
<tr><td><code id="SendOutlookMail_+3A_subject">subject</code></td>
<td>
<p>the subject of the mail
</p>
</td></tr>
<tr><td><code id="SendOutlookMail_+3A_body">body</code></td>
<td>
<p>the body text of the mail
</p>
</td></tr>
<tr><td><code id="SendOutlookMail_+3A_attachment">attachment</code></td>
<td>
<p>a vector of paths to attachments
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nothing is returned
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; strongly based on code of Franziska Mueller 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToXL">ToXL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
SendOutlookMail(to=c("me@microsoft.com", "you@rstudio.com"), subject = "Some Info", 
                body = "Hi all\r Find the files attached\r Regards, Andri", 
                attachment = c("C:/temp/fileA.txt", 
                               "C:/temp/fileB.txt"))

## End(Not run)
</code></pre>

<hr>
<h2 id='SetAlpha'>Add an Alpha Channel To a Color
</h2><span id='topic+SetAlpha'></span><span id='topic+Fade'></span>

<h3>Description</h3>

<p> Add transparency to a color defined by its name or number. The function first converts the
color to RGB and then appends the alpha channel. <code>Fade()</code> combines <code>ColToOpaque(SetAlpha(col))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SetAlpha(col, alpha = 0.5)
Fade(col, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SetAlpha_+3A_col">col</code></td>
<td>
<p>vector of two kind of R colors, i.e., either a color name (an element of <code>colors()</code>) or an integer i meaning <code>palette()[i]</code>.
</p>
</td></tr>
<tr><td><code id="SetAlpha_+3A_alpha">alpha</code></td>
<td>
<p>the alpha value to be added. This can be any value from 0 (fully transparent) to 1 (opaque). <code>NA</code> is interpreted so as to delete a potential alpha channel. Default is 0.5.
</p>
</td></tr>
<tr><td><code id="SetAlpha_+3A_...">...</code></td>
<td>
<p>the dots in <code>Fade</code> are passed on to <code>SetAlpha</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All arguments are recyled as necessary.
</p>


<h3>Value</h3>

<p>Vector with the same length as <code>col</code>, giving the rgb-values extended by the alpha channel as hex-number (#rrggbbaa).
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ColToHex">ColToHex</a></code>, <code><a href="grDevices.html#topic+col2rgb">col2rgb</a></code>, <code><a href="grDevices.html#topic+adjustcolor">adjustcolor</a></code>, <code><a href="#topic+ColToOpaque">ColToOpaque</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SetAlpha("yellow", 0.2)
SetAlpha(2, 0.5)   # red

Canvas(3)
DrawCircle(x=c(-1,0,1), y=c(1,-1,1), r.out=2, col=SetAlpha(2:4, 0.4))

x &lt;- rnorm(15000)
par(mfrow=c(1,2))
plot(x, type="p", col="blue" )
plot(x, type="p", col=SetAlpha("blue", .2), main="Better insight with alpha channel" )
</code></pre>

<hr>
<h2 id='SetNames'>Set the Names in an Object
</h2><span id='topic+SetNames'></span>

<h3>Description</h3>

<p>This is a convenience function that sets the names of an object and returns it including the new names. It is most useful at the end of a function definition where one is creating the object to be returned and would prefer not to store it under a name just that the names can be assigned. In addition to the function <code><a href="stats.html#topic+setNames">setNames</a></code> in base R the user can decide, whether rownames, colnames or simply the names are to be set. Names are recyled. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SetNames(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SetNames_+3A_x">x</code></td>
<td>
<p>an object for which a names attribute will be meaningful
</p>
</td></tr>
<tr><td><code id="SetNames_+3A_...">...</code></td>
<td>
<p>the names to be assigned to the object. This should be a character vector of names named <code>dimnames</code>, <code>rownames</code>, <code>colnames</code> or <code>names</code>. Setting <code>rownames=NULL</code> would remove existing rownames. All kind of names can be changed at the same time. Default would be <code>names</code>. Abbreviations are supported.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the same sort as object with the new names assigned.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;<br />
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+setNames">setNames</a></code>, <code><a href="#topic+Rename">Rename</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>SetNames(1:5, names=letters[1:5])

# the default, if no argument names are provided, is "names"
SetNames(1:5, letters[1:5])

tab &lt;- table(d.pizza$driver, d.pizza$wine_delivered)
# rownames and columnnames can be set at the same time
SetNames(BinomCI(tab[,1], rowSums(tab)), 
         rownames=rownames(tab), colnames=c("perc", "lci", "uci"))
         
# can also be used to set the names to an empty string
SetNames(diag(6), rownames="", colnames="")

# setting dimnames works as well
tab &lt;- SetNames(
  as.table(rbind(c(84,43), c(10,92))), 
    dimnames= list(
       dipstick=c("positive","negative"),
       culture=c("positive","negative")))
</code></pre>

<hr>
<h2 id='Shade'>Produce a Shaded Curve
</h2><span id='topic+Shade'></span>

<h3>Description</h3>

<p>Sometimes the area under a density curve has to be color shaded, for instance to illustrate a p-value or a specific region under the normal curve.
This function draws a curve corresponding to a function over the interval <code>[from, to]</code>. It can plot also an expression in the variable <code>xname</code>, default <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Shade(expr, col = par("fg"), breaks, density = 10, n = 101, xname = "x", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Shade_+3A_expr">expr</code></td>
<td>
<p>the name of a function, or a <code><a href="base.html#topic+call">call</a></code> or an <code><a href="base.html#topic+expression">expression</a></code> written as a function of <code>x</code> which will evaluate to an object of the same length as <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Shade_+3A_col">col</code></td>
<td>
<p>color to fill or shade the shape with. The default is taken from <code>par("fg")</code>.
</p>
</td></tr>
<tr><td><code id="Shade_+3A_breaks">breaks</code></td>
<td>
<p>numeric, a vector giving the breakpoints between the distinct areas to be shaded differently. Should be finite as there are no plots with infinite limits.
</p>
</td></tr>
<tr><td><code id="Shade_+3A_density">density</code></td>
<td>
<p>the density of the lines as needed in polygon.
</p>
</td></tr>
<tr><td><code id="Shade_+3A_n">n</code></td>
<td>
<p>integer; the number of x values at which to evaluate. Default is 101.
</p>
</td></tr>
<tr><td><code id="Shade_+3A_xname">xname</code></td>
<td>
<p>character string giving the name to be used for the x axis.</p>
</td></tr>
<tr><td><code id="Shade_+3A_...">...</code></td>
<td>
<p>the dots are passed on to <code><a href="graphics.html#topic+polygon">polygon</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Useful for shading the area under a curve as often needed for explaining significance tests.
</p>


<h3>Value</h3>

<p>A list with components <code>x</code> and <code>y</code> of the points that were drawn is returned invisibly.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="graphics.html#topic+polygon">polygon</a></code>, <code><a href="graphics.html#topic+curve">curve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>curve(dt(x, df=5), xlim=c(-6,6),
      main=paste("Student t-Distribution Probability Density Function, df = ", 5, ")", sep=""),
      type="n", las=1, ylab="probability", xlab="t")

Shade(dt(x, df=5), breaks=c(-6, qt(0.025, df=5), qt(0.975, df=5), 6),
      col=c(hred, hblue), density=c(20, 7))
</code></pre>

<hr>
<h2 id='ShapiroFranciaTest'>Shapiro-Francia Test for Normality</h2><span id='topic+ShapiroFranciaTest'></span>

<h3>Description</h3>

<p>Performs the Shapiro-Francia test for the composite hypothesis of normality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShapiroFranciaTest(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShapiroFranciaTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, the number of
which must be between 5 and 5000. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic of the Shapiro-Francia test is simply the
squared correlation between the ordered sample values and the (approximated)
expected ordered quantiles from the standard normal
distribution. The p-value is computed from the formula given by Royston (1993).
</p>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Shapiro-Francia  statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Shapiro-Francia normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Shapiro-Francia test is known to perform well,
see also the comments by Royston (1993). The expected ordered quantiles
from the standard normal distribution are approximated by
<code>qnorm(ppoints(x, a = 3/8))</code>, being slightly different from the approximation
<code>qnorm(ppoints(x, a = 1/2))</code> used for the normal quantile-quantile plot by
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for sample sizes greater than 10.</p>


<h3>Author(s)</h3>

<p>Juergen Gross &lt;gross@statistik.uni-dortmund.de&gt;</p>


<h3>References</h3>

<p>Royston, P. (1993): A pocket-calculator algorithm for the
Shapiro-Francia test for non-normality: an application to medicine.
<em>Statistics in Medicine</em>, 12, 181&ndash;184.
</p>
<p>Thode Jr., H.C. (2002): <em>Testing for  Normality</em>. Marcel Dekker, New York. (2002, Sec. 2.3.2)</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality.
<code><a href="#topic+AndersonDarlingTest">AndersonDarlingTest</a></code>, <code><a href="#topic+CramerVonMisesTest">CramerVonMisesTest</a></code>,
<code><a href="#topic+LillieTest">LillieTest</a></code>, <code><a href="#topic+PearsonTest">PearsonTest</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>ShapiroFranciaTest(rnorm(100, mean = 5, sd = 3))
ShapiroFranciaTest(runif(100, min = 2, max = 4))
</code></pre>

<hr>
<h2 id='SiegelTukeyTest'>Siegel-Tukey Test For Equality In Variability
</h2><span id='topic+SiegelTukeyTest'></span><span id='topic+SiegelTukeyRank'></span><span id='topic+SiegelTukeyTest.default'></span><span id='topic+SiegelTukeyTest.formula'></span>

<h3>Description</h3>

<p>Non-parametric Siegel-Tukey test for equality in variability.
The null hypothesis is that the variability of x is equal between two
groups. A rejection of the null hypothesis indicates that variability differs between
the two groups. <code>SiegelTukeyRank</code> returns the ranks, calculated after Siegel Tukey logic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SiegelTukeyTest(x, ...)

## Default S3 method:
SiegelTukeyTest(x, y, adjust.median = FALSE,
                alternative = c("two.sided", "less", "greater"),
                mu = 0, exact = NULL, correct = TRUE, conf.int = FALSE,
                conf.level = 0.95, ...)

## S3 method for class 'formula'
SiegelTukeyTest(formula, data, subset, na.action, ...)


SiegelTukeyRank(x, g, drop.median = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SiegelTukeyTest_+3A_x">x</code>, <code id="SiegelTukeyTest_+3A_y">y</code></td>
<td>
<p>numeric vector of data values. Non-finite (e.g. infinite or missing) values will be omitted.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the corresponding elements of x.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_adjust.median">adjust.median</code></td>
<td>
<p>Should between-group differences in medians be leveled
before performing the test? In certain cases, the Siegel-Tukey test is
susceptible to median differences and may indicate significant differences
in variability that, in reality, stem from differences in medians. Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>. You can specify just the initial letter.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_mu">mu</code></td>
<td>
<p>a number specifying an optional parameter used to form the null hypothesis. See Details.</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_exact">exact</code></td>
<td>
<p>a logical indicating whether an exact p-value should be computed. This is passed directly to <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_correct">correct</code></td>
<td>
<p>a logical indicating whether to apply continuity correction in the normal approximation for the p-value.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_conf.int">conf.int</code></td>
<td>
<p>a logical indicating whether a confidence interval should be computed.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_drop.median">drop.median</code></td>
<td>
<p>logical, defining whether the median of the combined samples should be left out, ensuring that there's an even number of elements (which is a requirement of the Siegel-Tukey test). Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="SiegelTukeyTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Siegel-Tukey test has relatively low power and may, under certain
conditions, indicate significance due to differences in medians rather than
differences in variabilities (consider using the argument <code>adjust.median</code>).
Consider also using <code><a href="stats.html#topic+mood.test">mood.test</a></code> or <code><a href="stats.html#topic+ansari.test">ansari.test</a></code>.
</p>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p> Siegel-Tukey test (Wilcoxon test on tie-adjusted Siegel-Tukey ranks, after the median adjustment if specified).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>   the p-value for the test</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>is the value of the median specified by the null hypothesis. This
equals the input argument <code>mu</code>. </p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>  the type of test applied</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Daniel Malter, Tal Galili &lt;tal.galili@gmail.com&gt;, Andri Signorell &lt;andri@signorell.net&gt;<br />
published on: <a href="https://www.r-statistics.com/2010/02/siegel-tukey-a-non-parametric-test-for-equality-in-variability-r-code/">https://www.r-statistics.com/2010/02/siegel-tukey-a-non-parametric-test-for-equality-in-variability-r-code/</a>
</p>


<h3>References</h3>

<p>Siegel, S., Tukey, J. W. (1960): A nonparametric sum of ranks procedure for relative spread in unpaired samples.
<em>Journal of the American Statistical Association</em>.
</p>
<p>Sheskin, D. J. (2004): <em>Handbook of parametric and nonparametric statistical procedures</em> 3rd edition. Chapman and Hall/CRC. Boca Raton, FL.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+mood.test">mood.test</a></code>, <code><a href="stats.html#topic+ansari.test">ansari.test</a></code>, <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>,  <code><a href="#topic+LeveneTest">LeveneTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Duller, S. 183
x &lt;- c(12, 13, 29, 30)
y &lt;- c(15, 17, 18, 24, 25, 26)
SiegelTukeyTest(x, y)
SiegelTukeyTest(x, y, alternative="greater")

# Duller, S. 323
old &lt;- c(870,930,935,1045,1050,1052,1055)
new &lt;- c(932,970,980,1001,1009,1030,1032,1040,1046)
SiegelTukeyTest(old, new, alternative = "greater")
# compare to the recommended alternatives
mood.test(old, new, alternative="greater")
ansari.test(old, new, alternative="greater")

# Bortz, S. 250
x &lt;- c(26.3,26.5,26.8,27.0,27.0,27.2,27.3,27.3,27.4,27.5,27.6,27.8,27.9)
id &lt;- c(2,2,2,1,2,2,1,2,2,1,1,1,2)-1
SiegelTukeyTest(x ~ id)


# Sachs, Angewandte Statistik, 12. Auflage, 2007, S. 314
A &lt;- c(10.1,7.3,12.6,2.4,6.1,8.5,8.8,9.4,10.1,9.8)
B &lt;- c(15.3,3.6,16.5,2.9,3.3,4.2,4.9,7.3,11.7,13.1)
SiegelTukeyTest(A, B)



### 1
x &lt;- c(4,4,5,5,6,6)
y &lt;- c(0,0,1,9,10,10)
SiegelTukeyTest(x, y)

### 2
# example for a non equal number of cases:
x &lt;- c(4,4,5,5,6,6)
y &lt;- c(0,0,1,9,10)
SiegelTukeyTest(x, y)

### 3
x &lt;- c(33, 62, 84, 85, 88, 93, 97, 4, 16, 48, 51, 66, 98)
id &lt;- c(0,0,0,0,0,0,0,1,1,1,1,1,1)
SiegelTukeyTest(x ~ id)

### 4
x &lt;- c(177,200,227,230,232,268,272,297,47,105,126,142,158,172,197,220,225,230,262,270)
id &lt;- c(rep(0,8),rep(1,12))
SiegelTukeyTest(x ~ id, adjust.median=TRUE)

### 5
x &lt;- c(33,62,84,85,88,93,97)
y &lt;- c(4,16,48,51,66,98)
SiegelTukeyTest(x, y)

### 6
x &lt;- c(0,0,1,4,4,5,5,6,6,9,10,10)
id &lt;- c(0,0,0,1,1,1,1,1,1,0,0,0)
SiegelTukeyTest(x ~ id)

### 7
x &lt;- c(85,106,96, 105, 104, 108, 86)
id &lt;- c(0,0,1,1,1,1,1)
SiegelTukeyTest(x ~ id)
</code></pre>

<hr>
<h2 id='SignTest'>Sign Test</h2><span id='topic+SignTest'></span><span id='topic+SignTest.default'></span><span id='topic+SignTest.formula'></span>

<h3>Description</h3>

<p>Performs one- and two-sample sign tests on vectors of data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SignTest(x, ...)

## Default S3 method:
SignTest(x, y = NULL, alternative = c("two.sided", "less", "greater"), 
         mu = 0, conf.level = 0.95, ... )

## S3 method for class 'formula'
SignTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SignTest_+3A_x">x</code></td>
<td>
<p>numeric vector of data values. Non-finite (e.g. infinite or missing) values will be omitted.</p>
</td></tr>
<tr><td><code id="SignTest_+3A_y">y</code></td>
<td>
<p>an optional numeric vector of data values: as with x non-finite values will be omitted.</p>
</td></tr>
<tr><td><code id="SignTest_+3A_mu">mu</code></td>
<td>
<p>a number specifying an optional parameter used to form the null hypothesis. See Details.</p>
</td></tr>
<tr><td><code id="SignTest_+3A_alternative">alternative</code></td>
<td>
<p>is a character string, one of <code>"greater"</code>,
<code>"less"</code>, or <code>"two.sided"</code>, or the initial letter of each,
indicating the specification of the alternative hypothesis. For
one-sample tests, <code>alternative</code> refers to the true
median of the parent population in relation to the hypothesized
value of the median.</p>
</td></tr>
<tr><td><code id="SignTest_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the returned confidence
interval, restricted to lie between zero and one.</p>
</td></tr>
<tr><td><code id="SignTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>  
<tr><td><code id="SignTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>. 
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>  
<tr><td><code id="SignTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>  
<tr><td><code id="SignTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>  
<tr><td><code id="SignTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula interface is only applicable for the 2-sample test. 
</p>
<p><code>SignTest</code> computes a &ldquo;Dependent-samples Sign-Test&rdquo; if both
<code>x</code> and <code>y</code> are provided.  If only <code>x</code> is provided,
the &ldquo;One-sample Sign-Test&rdquo; will be computed.
</p>
<p>For the one-sample sign-test, the null hypothesis is
that the median of the population from which <code>x</code> is drawn is <code>mu</code>.
For the two-sample dependent case, the null hypothesis is
that the median for the differences of the populations from which <code>x</code>
and <code>y</code> are drawn is <code>mu</code>.
The alternative hypothesis indicates the direction of divergence of the
population median for <code>x</code> from <code>mu</code> (i.e., <code>"greater"</code>,
<code>"less"</code>, <code>"two.sided"</code>.)
</p>
<p>The confidence levels are exact.
</p>


<h3>Value</h3>

<p>A list of class <code>htest</code>, containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p> the S-statistic (the number of positive differences
between the data and the hypothesized median), with names attribute
&ldquo;S&rdquo;.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p> the total number of valid differences.</p>
</td></tr>                  
<tr><td><code>p.value</code></td>
<td>
<p>   the p-value for the test.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>is the value of the median specified by the null hypothesis. This
equals the input argument <code>mu</code>. </p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>  the type of test applied.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>  a confidence interval for the median.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>  the sample median.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>Gibbons, J.D. and Chakraborti, S. (1992):
<em>Nonparametric Statistical Inference</em>. Marcel Dekker Inc., New York.
</p>
<p>Kitchens, L. J. (2003): <em>Basic Statistics and Data Analysis</em>. Duxbury.
</p>
<p>Conover, W. J. (1980): <em>Practical Nonparametric Statistics, 2nd ed</em>. Wiley, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code>, <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code>, <code><a href="#topic+ZTest">ZTest</a></code>, <code><a href="stats.html#topic+binom.test">binom.test</a></code>, 
<code><a href="BSDA.html#topic+SIGN.test">SIGN.test</a></code> in the package <span class="pkg">BSDA</span> (reporting approximative confidence intervals).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
y &lt;- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)

SignTest(x, y)
wilcox.test(x, y, paired = TRUE)


d.light &lt;- data.frame( 
  black = c(25.85,28.84,32.05,25.74,20.89,41.05,25.01,24.96,27.47),
  white &lt;- c(18.23,20.84,22.96,19.68,19.5,24.98,16.61,16.07,24.59),
  d &lt;- c(7.62,8,9.09,6.06,1.39,16.07,8.4,8.89,2.88)
)

d &lt;- d.light$d

SignTest(x=d, mu = 4)
wilcox.test(x=d, mu = 4, conf.int = TRUE)

SignTest(x=d, mu = 4, alternative="less")
wilcox.test(x=d, mu = 4, conf.int = TRUE, alternative="less")

SignTest(x=d, mu = 4, alternative="greater")
wilcox.test(x=d, mu = 4, conf.int = TRUE, alternative="greater")

# test die interfaces
x &lt;- runif(10)
y &lt;- runif(10)
g &lt;- rep(1:2, each=10) 
xx &lt;- c(x, y)

SignTest(x ~ group, data=data.frame(x=xx, group=g ))
SignTest(xx ~ g)
SignTest(x, y)

SignTest(x - y)
</code></pre>

<hr>
<h2 id='SmoothSpline'>Formula Interface For <code>smooth.spline</code>
</h2><span id='topic+SmoothSpline'></span><span id='topic+SmoothSpline.formula'></span><span id='topic+SmoothSpline.default'></span>

<h3>Description</h3>

<p>smooth.spline has no formula interface, which is sometimes inconvenient, if one simply wants to copy a formula of a linear model or a plot to spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
SmoothSpline(x, ...)

## Default S3 method:
SmoothSpline(x, y = NULL, w = NULL, df, spar = NULL, cv = FALSE,
             all.knots = FALSE, nknots = .nknots.smspl, keep.data = TRUE,
             df.offset = 0, penalty = 1, control.spar = list(),
             tol = 0.000001 * IQR(x), ...)

## S3 method for class 'formula'
SmoothSpline(formula, data, subset, na.action, ...)


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SmoothSpline_+3A_x">x</code></td>
<td>
<p>a vector giving the values of the predictor variable, or a
list or a two-column matrix specifying x and y. </p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_y">y</code></td>
<td>
<p>responses. If <code>y</code> is missing or <code>NULL</code>, the responses
are assumed to be specified by <code>x</code>, with <code>x</code> the index
vector.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_w">w</code></td>
<td>
<p>optional vector of weights of the same length as <code>x</code>;
defaults to all 1.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_df">df</code></td>
<td>
<p>the desired equivalent number of degrees of freedom (trace of
the smoother matrix).</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_spar">spar</code></td>
<td>
<p>smoothing parameter, typically (but not necessarily) in
<code class="reqn">(0,1]</code>. The coefficient <code class="reqn">\lambda</code> of the integral of the
squared second derivative in the fit (penalized log likelihood)
criterion is a monotone function of <code>spar</code>, see the details
below.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_cv">cv</code></td>
<td>
<p>ordinary (<code>TRUE</code>) or &lsquo;generalized&rsquo; cross-validation
(GCV) when <code>FALSE</code>; setting it to <code>NA</code> skips the evaluation
of leverages and any score.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_all.knots">all.knots</code></td>
<td>
<p>if <code>TRUE</code>, all distinct points in <code>x</code> are used as
knots. If <code>FALSE</code> (default), a subset of <code>x[]</code> is used,
specifically <code>x[j]</code> where the <code>nknots</code> indices are evenly
spaced in <code>1:n</code>, see also the next argument <code>nknots</code>.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_nknots">nknots</code></td>
<td>
<p>integer or <code><a href="base.html#topic+function">function</a></code> giving the number of
knots to use when <code>all.knots = FALSE</code>. If a function (as by
default), the number of knots is <code>nknots(nx)</code>. By default for
<code class="reqn">n_x &gt; 49</code> this is less than <code class="reqn">n_x</code>, the number
of unique <code>x</code> values, see the Note.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_keep.data">keep.data</code></td>
<td>
<p>logical specifying if the input data should be kept
in the result. If <code>TRUE</code> (as per default), fitted values and
residuals are available from the result.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_df.offset">df.offset</code></td>
<td>
<p>allows the degrees of freedom to be increased by
<code>df.offset</code> in the GCV criterion.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_penalty">penalty</code></td>
<td>
<p>the coefficient of the penalty for degrees of freedom
in the GCV criterion.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_control.spar">control.spar</code></td>
<td>
<p>optional list with named components controlling the
root finding when the smoothing parameter <code>spar</code> is computed,
i.e., missing or <code>NULL</code>, see below.
</p>
<p><b>Note</b> that this is partly <em>experimental</em> and may change
with general spar computation improvements!
</p>

<dl>
<dt>low:</dt><dd><p>lower bound for <code>spar</code>; defaults to -1.5 (used to
implicitly default to 0 in <span class="rlang"><b>R</b></span> versions earlier than 1.4).</p>
</dd>
<dt>high:</dt><dd><p>upper bound for <code>spar</code>; defaults to +1.5.</p>
</dd>
<dt>tol:</dt><dd><p>the absolute precision (<b>tol</b>erance) used; defaults
to 1e-4 (formerly 1e-3).</p>
</dd>
<dt>eps:</dt><dd><p>the relative precision used; defaults to 2e-8 (formerly
0.00244).</p>
</dd>
<dt>trace:</dt><dd><p>logical indicating if iterations should be traced.</p>
</dd>
<dt>maxit:</dt><dd><p>integer giving the maximal number of iterations;
defaults to 500.</p>
</dd>
</dl>

<p>Note that <code>spar</code> is only searched for in the interval
<code class="reqn">[low, high]</code>.
</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_tol">tol</code></td>
<td>
<p>a tolerance for same-ness or uniqueness of the <code>x</code>
values. The values are binned into bins of size <code>tol</code> and
values which fall into the same bin are regarded as the same. Must
be strictly positive (and finite).</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the                 corresponding groups.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_data">data</code></td>
<td>
<p>The data frame from which the formula should
be evaluated.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="SmoothSpline_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to
<code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>, <code><a href="#topic+lines.smooth.spline">lines.smooth.spline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(temperature ~ delivery_min, data=d.pizza)
lines(SmoothSpline(temperature ~ delivery_min, data=d.pizza))
</code></pre>

<hr>
<h2 id='Some'>
Return Some Randomly Chosen Elements of an Object
</h2><span id='topic+Some'></span><span id='topic+Some.default'></span><span id='topic+Some.data.frame'></span><span id='topic+Some.matrix'></span>

<h3>Description</h3>

<p>For displaying the first and last elements of an object there are the functions <code>head</code> and <code>tail</code>. Sometimes one might want to see more randomly scattered elements. This function returns some random parts of a vector, matrix or a data frame. The order of the elements within the object will be preserved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Some(x, n = 6L, ...)
## Default S3 method:
Some(x, n = 6L, ...)
## S3 method for class 'data.frame'
Some(x, n = 6L, ...)
## S3 method for class 'matrix'
Some(x, n = 6L, addrownums = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Some_+3A_x">x</code></td>
<td>
<p>an object</p>
</td></tr>
<tr><td><code id="Some_+3A_n">n</code></td>
<td>
<p>a single integer. If positive, size for the resulting
object: number of elements for a vector (including lists), rows for
a matrix or data frame or lines for a function. If negative, all but
the <code>n</code> last/first number of elements of <code>x</code>.</p>
</td></tr>
<tr><td><code id="Some_+3A_addrownums">addrownums</code></td>
<td>
<p>if there are no row names, create them from the row
numbers.</p>
</td></tr>
<tr><td><code id="Some_+3A_...">...</code></td>
<td>
<p>arguments to be passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For matrices, 2-dim tables and data frames, <code>Some()</code> returns
some <code>n</code> rows when <code>n &gt; 0</code> or all but the
some <code>n</code> rows when <code>n &lt; 0</code>.  <code>Some.matrix()</code> is not exported (unlike <code>head.matrix</code>).
</p>
<p>If a matrix has no row names, then <code>Some()</code> will add row names of
the form <code>"[n,]"</code> to the result, so that it looks similar to the
last lines of <code>x</code> when printed.  Setting <code>addrownums =
    FALSE</code> suppresses this behaviour.
</p>
<p>I desisted from implementing interfaces for tables, ftables and functions, as this would not make much sense.
</p>


<h3>Value</h3>

<p>An object (usually) like <code>x</code> but generally smaller.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell, basically copying and just slightly modifying Patrick Burns and R-Core code.
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+head">head</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Some(letters)
Some(letters, n = -6L)

Some(freeny.x, n = 10L)
Some(freeny.y)
</code></pre>

<hr>
<h2 id='Some+20numeric+20checks'>
Check a Vector For Being Numeric, Zero Or a Whole Number
</h2><span id='topic+IsWhole'></span><span id='topic+IsNumeric'></span><span id='topic+IsZero'></span>

<h3>Description</h3>

<p>Test if x contains only integer numbers, or if is numeric or if it is zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsWhole(x, all = FALSE, tol = sqrt(.Machine$double.eps), na.rm = FALSE)
IsZero(x, tol = sqrt(.Machine$double.eps), na.rm = FALSE)
IsNumeric(x, length.arg = Inf, integer.valued = FALSE, positive = FALSE, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Some+2B20numeric+2B20checks_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="Some+2B20numeric+2B20checks_+3A_all">all</code></td>
<td>
<p>logical, specifying if the whole vector should be checked. If set to <code>TRUE</code> the function will
return the result of <code>all(IsWhole(x))</code>. </p>
</td></tr>
<tr><td><code id="Some+2B20numeric+2B20checks_+3A_tol">tol</code></td>
<td>
<p>tolerance to be used
</p>
</td></tr>
<tr><td><code id="Some+2B20numeric+2B20checks_+3A_length.arg">length.arg</code></td>
<td>
<p>integer, the length of the vector to be checked for.</p>
</td></tr>
<tr><td><code id="Some+2B20numeric+2B20checks_+3A_integer.valued">integer.valued</code></td>
<td>
<p>logical, should x be checked as integer?</p>
</td></tr>
<tr><td><code id="Some+2B20numeric+2B20checks_+3A_positive">positive</code></td>
<td>
<p>logical, is x supposed to be positive?</p>
</td></tr>
<tr><td><code id="Some+2B20numeric+2B20checks_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>IsWhole is the suggested solution for checking for an integer value, as <code><a href="base.html#topic+is.integer">is.integer</a></code> tests for <code>class(x) == "integer"</code> and does NOT test whether x (which might be of class &quot;numeric&quot;) contains only integer numbers.
(Why not simply implement it in <span class="pkg">base</span>?)
</p>
<p>IsZero tests float numeric values for being zero.
</p>
<p>IsNumeric combines a test for numeric and integers.
</p>


<h3>Value</h3>

<p>logical vector of the same dimension as x.
</p>


<h3>Author(s)</h3>

<p>R-Core, Andri Signorell &lt;andri@signorell.net&gt;, Thomas W. Yee
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+is.integer">is.integer</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(x &lt;- seq(1,5, by=0.5))
IsWhole( x ) #--&gt;  \code{TRUE} \code{FALSE} \code{TRUE} ...


# ... These are people who live in ignorance of the Floating Point Gods.
# These pagans expect ... (Burns, 2011)" the following to be TRUE:
(.1 - .3 / 3) == 0

# they might be helped by
IsZero(.1 - .3 / 3)


</code></pre>

<hr>
<h2 id='SomersDelta'>Somers' Delta
</h2><span id='topic+SomersDelta'></span>

<h3>Description</h3>

<p>Calculate Somers' Delta statistic, a measure of
association for ordinal factors in a two-way table. The function has interfaces for a table (matrix) and for single vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SomersDelta(x, y = NULL, direction = c("row", "column"), conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SomersDelta_+3A_x">x</code></td>
<td>
<p>a numeric vector or a table. A matrix will be treated as table.
</p>
</td></tr>
<tr><td><code id="SomersDelta_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="SomersDelta_+3A_direction">direction</code></td>
<td>
<p>direction of the calculation. Can be <code>"row"</code> (default) or <code>"column"</code>, where
<code>"row"</code> calculates Somers' D (R | C) (&quot;column dependent&quot;).
</p>
</td></tr>
<tr><td><code id="SomersDelta_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated.
</p>
</td></tr>
<tr><td><code id="SomersDelta_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set useNA. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Somers' D(C|R) and Somers' D(R|C) are asymmetric modifications of <code class="reqn">\tau_b</code> and Goodman-Kruskal's Gamma. C|R indicates that
the row variable x is regarded as the independent variable and the column variable y is regarded
as dependent. Similarly, R|C indicates that the column variable y is regarded as the independent
variable and the row variable x is regarded as dependent. It is logically very similar to Gamma, but differs in that it uses a correction only for pairs that are tied on the dependent variable. As Gamma and the Taus, D is appropriate only when both variables lie on an ordinal scale.<br />
Somers' D is computed as<br />
</p>
<p style="text-align: center;"><code class="reqn"> D(C | R) = \frac{P-Q}{n^2 - \sum(n_i.^2)}</code>
</p>

<p>where P equals twice the number of concordances and Q twice the number of discordances and <code class="reqn">n_i.</code> rowSums(tab). Its range lies [-1, 1]. The interpretation of d is analogous to Gamma.
</p>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons,
pp. 57&ndash;59.
</p>
<p>Brown, M.B., Benedetti, J.K.(1977) Sampling Behavior of Tests for Correlation in Two-Way Contingency Tables, <em>Journal of the American Statistical Association</em>, 72, 309-315.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1954) Measures of
association for cross classifications. <em>Journal of the
American Statistical Association</em>, 49, 732-764.
</p>
<p>Somers, R. H. (1962) A New Asymmetric Measure of Association for Ordinal Variables, <em>American Sociological Review</em>, 27, 799&ndash;811.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1963) Measures of
association for cross classifications III: Approximate
sampling theory. <em>Journal of the American Statistical
Association</em>, 58, 310&ndash;364.
</p>


<h3>See Also</h3>

<p>There's an implementation of Somers's D in Frank Harrell's <span class="pkg">Hmisc</span> <code><a href="Hmisc.html#topic+somers2">somers2</a></code>,
which is quite fast for large sample sizes. However it is restricted to computing Somers' Dxy rank correlation between a variable x and a binary (0-1) variable y.<br />
<code><a href="#topic+ConDisPairs">ConDisPairs</a></code> yields concordant and discordant pairs <br /><br />
Other association measures: <br />
<code><a href="#topic+KendallTauA">KendallTauA</a></code> (tau-a), <code><a href="#topic+KendallTauB">KendallTauB</a></code> (tau-b), <code><a href="stats.html#topic+cor">cor</a></code> (method=&quot;kendall&quot;) for tau-b, <code><a href="#topic+StuartTauC">StuartTauC</a></code> (tau-c),
<code><a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a></code><br />
<code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+GoodmanKruskalTau">GoodmanKruskalTau</a></code>, <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example in:
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. S. 1821

tab &lt;- as.table(rbind(c(26,26,23,18,9),c(6,7,9,14,23)))

# Somers' D C|R
SomersDelta(tab, direction="column", conf.level=0.95)
# Somers' D R|C
SomersDelta(tab, direction="row", conf.level=0.95)
</code></pre>

<hr>
<h2 id='Sort'>Sort a Vector, a Matrix, a Table or a Data.frame
</h2><span id='topic+Sort'></span><span id='topic+Sort.default'></span><span id='topic+Sort.data.frame'></span><span id='topic+Sort.matrix'></span><span id='topic+Sort.table'></span>

<h3>Description</h3>

<p>Sort a vector, a matrix, a table or a data.frame. The base sort function does not have an interface for classes other than vectors and coerces the whole world to a vector. This means you get a sorted vector as result while passing a matrix to <code>sort</code>.<br />
<code>Sort</code> wraps the base sort function and adds an interface for sorting the rows of the named 2-dimensional data structures by the order of one or more of its columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sort(x, ...)

## Default S3 method:
Sort(x, ...)
## S3 method for class 'matrix'
Sort(x, ord = NULL, decreasing = FALSE, na.last = TRUE, ...)
## S3 method for class 'table'
Sort(x, ord = NULL, decreasing = FALSE, na.last = TRUE, ...)
## S3 method for class 'data.frame'
Sort(x, ord = NULL, decreasing = FALSE,
                factorsAsCharacter = TRUE, na.last = TRUE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sort_+3A_x">x</code></td>
<td>
<p>a numeric, complex. character or logical vector, a factor, a table or a data.frame to be sorted. </p>
</td></tr>
<tr><td><code id="Sort_+3A_decreasing">decreasing</code></td>
<td>
<p>logical. Should the sort be increasing or decreasing? </p>
</td></tr>

<tr><td><code id="Sort_+3A_factorsascharacter">factorsAsCharacter</code></td>
<td>
<p>logical. Should factors be sorted by the alphabetic order of their labels or by the order or their levels.
Default is <code>TRUE</code> (by labels).</p>
</td></tr>
<tr><td><code id="Sort_+3A_ord">ord</code></td>
<td>
<p>vector of integers or columnames. Defines the columns in a table, in a matrix or in a data.frame to be sorted for. <br />
0 means row.names, 1:n the columns and n+1 the marginal sum. See examples.</p>
</td></tr>
<tr><td><code id="Sort_+3A_na.last">na.last</code></td>
<td>
<p>for controlling the treatment of <code>NAs</code>. If <code>TRUE</code>, missing values in the data are put last; if <code>FALSE</code>, they are put first; if <code>NA</code>, they are removed (see <code><a href="base.html#topic+order">order</a></code>.)</p>
</td></tr>
<tr><td><code id="Sort_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sort order for factors is the order of their levels (which is particularly appropriate for ordered factors),
and usually confusing for unordered factors, whose levels may be defined in the sequence in which they appear in the data (which normally is unordered).
</p>


<h3>Value</h3>

<p>the sorted object.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sort">sort</a></code>, <code><a href="base.html#topic+order">order</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>d.frm &lt;- d.pizza[1:10, c("driver","temperature","delivery_min")]

Sort(d.frm[,1])
# Sort follows the levels by default
levels(d.frm[,1])

Sort(x=d.frm, ord="driver", decreasing=FALSE)
# set factorsAsCharacter = TRUE, if alphabetical order is required
Sort(x=d.frm, ord="driver", decreasing=FALSE, factorsAsCharacter=TRUE)

Sort(x=d.frm, ord=c("driver","delivery_min"), factorsAsCharacter = TRUE)
Sort(x=d.frm, ord=c("driver","delivery_min"), factorsAsCharacter = FALSE)

Sort(x=d.frm, ord=c("driver","delivery_min"), decreasing=c(FALSE, TRUE),
  factorsAsCharacter = FALSE)

# Sorting tables
tab &lt;- table(d.pizza$driver, d.pizza$area)

Sort(x=tab, ord=c(0,2), decreasing=c(TRUE, FALSE))
Sort(x=tab, ord=2, decreasing=TRUE)

# partial matching ok:
Sort(tab, o=1, d=TRUE)
</code></pre>

<hr>
<h2 id='SortMixed'>Sort Strings with Embedded Numbers Based on Their Numeric
Order</h2><span id='topic+SortMixed'></span><span id='topic+OrderMixed'></span>

<h3>Description</h3>

<p>These functions sort or order character strings containing embedded
numbers so that the numbers are numerically sorted rather than sorted
by character value.  I.e. &quot;Asprin 50mg&quot; will come before
&quot;Asprin 100mg&quot;.  In addition, case of character strings is ignored so
that &quot;a&quot;, will come before &quot;B&quot; and &quot;C&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SortMixed(x, decreasing=FALSE, na.last=TRUE, blank.last=FALSE,
          numeric.type=c("decimal", "roman"),
          roman.case=c("upper","lower","both") )

OrderMixed(x, decreasing=FALSE, na.last=TRUE, blank.last=FALSE,
          numeric.type=c("decimal", "roman"),
          roman.case=c("upper","lower","both") )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SortMixed_+3A_x">x</code></td>
<td>
<p>vector to be sorted.</p>
</td></tr>
<tr><td><code id="SortMixed_+3A_decreasing">decreasing</code></td>
<td>
<p>logical.  Should the sort be increasing or
decreasing? Note that <code>descending=TRUE</code> reverses the meanings of
<code>na.last</code> and <code>blanks.last</code>.</p>
</td></tr>
<tr><td><code id="SortMixed_+3A_na.last">na.last</code></td>
<td>
<p>logical, controlling the treatment of <code>NA</code> values.  If <code>TRUE</code>, missing
values in the data are put last; if <code>FALSE</code>, they are put
first; if <code>NA</code>, they are removed.</p>
</td></tr>
<tr><td><code id="SortMixed_+3A_blank.last">blank.last</code></td>
<td>
<p>logical, controlling the treatment of blank values.  If <code>TRUE</code>, blank
values in the data are put last; if <code>FALSE</code>, they are put
first; if <code>NA</code>, they are removed.</p>
</td></tr>
<tr><td><code id="SortMixed_+3A_numeric.type">numeric.type</code></td>
<td>
<p>either <code>"decimal"</code> (default) or <code>"roman"</code>.  Are numeric values represented as decimal numbers (<code>numeric.type="decimal"</code>) or as Roman numerals
(<code>numeric.type="roman"</code>)? </p>
</td></tr>
<tr><td><code id="SortMixed_+3A_roman.case">roman.case</code></td>
<td>
<p>one of <code>"upper"</code>, <code>"lower"</code>, or <code>"both"</code>.  Are roman
numerals represented using only capital letters ('IX') or lower-case
letters ('ix') or both?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>I often have character vectors (e.g. factor labels), such as compound
and dose, that contain both text and numeric data.  This function
is useful for sorting these character vectors into a logical order.
</p>
<p>It does so by splitting each character vector into a sequence of
character and numeric sections, and then sorting along these sections,
with numbers being sorted by numeric value (e.g. &quot;50&quot; comes before
&quot;100&quot;), followed by characters strings sorted by character
value (e.g. &quot;A&quot; comes before &quot;B&quot;) <em>ignoring case</em> (e.g. 'A' has
the same sort order as 'a').
</p>
<p>By default, sort order is ascending, empty strings are sorted to the front,
and <code>NA</code> values to the end.   Setting <code>descending=TRUE</code>
changes the sort order to descending and reverses the meanings of
<code>na.last</code> and <code>blank.last</code>.
</p>
<p>Parsing looks for decimal numbers unless <code>numeric.type="roman"</code>,
in which parsing looks for roman numerals, with character case
specified by <code>roman.case</code>.
</p>


<h3>Value</h3>

<p><code>OrderMixed</code> returns a vector giving the sort order of the input
elements. <code>SortMixed</code> returns the sorted vector.
</p>


<h3>Author(s)</h3>

<p> Gregory R. Warnes <a href="mailto:greg@warnes.net">greg@warnes.net</a> </p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+sort">sort</a></code>, <code><a href="base.html#topic+order">order</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## compound &amp; dose labels
Treatment &lt;- c("Control", "Asprin 10mg/day", "Asprin 50mg/day",
               "Asprin 100mg/day", "Acetomycin 100mg/day",
               "Acetomycin 1000mg/day")

## ordinary sort puts the dosages in the wrong order
sort(Treatment)

## but SortMixed does the 'right' thing
SortMixed(Treatment)

## Here is a more complex example
x &lt;- rev(c("AA 0.50 ml", "AA 1.5 ml", "AA 500 ml", "AA 1500 ml",
           "EXP 1", "AA 1e3 ml", "A A A", "1 2 3 A", "NA", NA, "1e2",
           "", "-", "1A", "1 A", "100", "100A", "Inf"))

OrderMixed(x)

SortMixed(x)  # Notice that plain numbers, including 'Inf' show up
              # before strings, NAs at the end, and blanks at the
              # beginning .


SortMixed(x, na.last=TRUE)  # default
SortMixed(x, na.last=FALSE) # push NAs to the front


SortMixed(x, blank.last=FALSE) # default
SortMixed(x, blank.last=TRUE)  # push blanks to the end

SortMixed(x, decreasing=FALSE) # default
SortMixed(x, decreasing=TRUE)  # reverse sort order

## Roman numerals
chapters &lt;- c("V. Non Sequiturs", "II. More Nonsense",
              "I. Nonsense", "IV. Nonesensical Citations",
              "III. Utter Nonsense")
SortMixed(chapters, numeric.type="roman" )

## Lower-case Roman numerals
vals &lt;- c("xix", "xii", "mcv", "iii", "iv", "dcclxxii",   "cdxcii",
          "dcxcviii",   "dcvi",   "cci")
(ordered &lt;- SortMixed(vals, numeric.type="roman", roman.case="lower"))
RomanToInt(ordered)
</code></pre>

<hr>
<h2 id='SpearmanRho'>Spearman Rank Correlation
</h2><span id='topic+SpearmanRho'></span>

<h3>Description</h3>

<p>Calculate Spearman correlation coefficient and its confidence interval. In addition to the base R function <code><a href="stats.html#topic+cor">cor</a>()</code>, frequency tables are also accepted as arguments (i.e. actually weights are used).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpearmanRho(x, y = NULL, use = c("everything", "all.obs", "complete.obs", 
            "na.or.complete","pairwise.complete.obs"), 
            conf.level = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpearmanRho_+3A_x">x</code></td>
<td>
<p>a numeric vector, an ordered factor, matrix or data frame. An ordered factor will be coerced to numeric.
</p>
</td></tr>
<tr><td><code id="SpearmanRho_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or a vector, an ordered factor, matrix or data frame with compatible dimensions to x. 
An ordered factor will be coerced to numeric.
</p>
</td></tr>
<tr><td><code id="SpearmanRho_+3A_use">use</code></td>
<td>

<p>an optional character string giving a method for computing covariances in the presence of missing values. 
This must be (an abbreviation of) one of the strings <code>"everything"</code>, <code>"all.obs"</code>, <code>"complete.obs"</code>, 
<code>"na.or.complete"</code>, or <code>"pairwise.complete.obs"</code>.
</p>
</td></tr>
<tr><td><code id="SpearmanRho_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calculates Spearman's rho statistic by means of <code>cor(..., method="spearman")</code> when two variables <code>x</code> and <code>y</code> are supplied. If a frequency table is provided an implementation based on SAS documentation is used.<br />
The confidence intervals are calculated via z-Transformation.<br />
</p>


<h3>Value</h3>

<p>Either a single numeric value, if no confidence interval is required, <br />
or a vector with 3 elements for estimate, lower and upper confidence intervall. 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Conover W. J. (1999) <em>Practical Nonparametric Statistics (3rd edition)</em>. Wiley
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pain &lt;- as.table(matrix(c(26,  6, 26, 7, 23, 
                           9, 18, 14, 9, 23), 
                           ncol=5, byrow=TRUE, 
        dimnames=list(adverse=c("no", "yes"), dose=1:5)))

SpearmanRho(pain)

SpearmanRho(pain, conf.level=0.95)
  
# must be the same as
with(Untable(pain), 
     SpearmanRho(adverse, dose, conf.level=0.95))

</code></pre>

<hr>
<h2 id='split.formula'>Formula Interface for Split
</h2><span id='topic+split.formula'></span>

<h3>Description</h3>

<p>Implementation of a simple formula interface for the <code><a href="base.html#topic+split">split</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
 split(x, f, drop = FALSE, data = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split.formula_+3A_x">x</code></td>
<td>
<p>a formula of the form <code>y ~ x</code>.</p>
</td></tr>
<tr><td><code id="split.formula_+3A_f">f</code></td>
<td>
<p>a 'factor' in the sense that <code><a href="base.html#topic+as.factor">as.factor</a>(f)</code> defines the grouping, or a list of such factors in which case their interaction is used for the grouping.</p>
</td></tr>
<tr><td><code id="split.formula_+3A_drop">drop</code></td>
<td>
<p>logical indicating if levels that do not occur should be dropped (if <code>f</code> is a <code>factor</code> or a list).
Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="split.formula_+3A_data">data</code></td>
<td>
<p>the data frame from which the formula should
be evaluated.</p>
</td></tr>
<tr><td><code id="split.formula_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to
<code><a href="base.html#topic+split">split</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+split">split</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>split(extra ~ group, data = sleep)
</code></pre>

<hr>
<h2 id='SplitAt'>Split a Vector Into Several Pieces at Given Positions
</h2><span id='topic+SplitAt'></span>

<h3>Description</h3>

<p>Split a vector into several pieces at given positions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SplitAt(x, pos)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SplitAt_+3A_x">x</code></td>
<td>
<p>the vector to be splitted.
</p>
</td></tr>
<tr><td><code id="SplitAt_+3A_pos">pos</code></td>
<td>
<p>integer vector, giving the positions at which the vector should be splitted.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the splitted parts of x.
</p>


<h3>Author(s)</h3>

<p>flodel (on StackOverflow)
</p>


<h3>References</h3>

<p><a href="https://stackoverflow.com/questions/16357962/r-split-numeric-vector-at-position">https://stackoverflow.com/questions/16357962/r-split-numeric-vector-at-position</a></p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+split">split</a></code>, <code><a href="base.html#topic+strsplit">strsplit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:10
SplitAt(x, pos=c(3, 8))
</code></pre>

<hr>
<h2 id='SplitPath'>Split Path In Drive, Path, Filename
</h2><span id='topic+SplitPath'></span>

<h3>Description</h3>

<p>Split a full path in its components. This is specifically an issue in Windows and not really interesting for other OSs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SplitPath(path, last.is.file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SplitPath_+3A_path">path</code></td>
<td>
<p>a path
</p>
</td></tr>
<tr><td><code id="SplitPath_+3A_last.is.file">last.is.file</code></td>
<td>
<p>logical, determining if the basename should be interpreted as filename or as last directory. If set to <code>NULL</code> (default), the last entry will be interpreted if the last character is either \ or / and as filename else.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list, containing the following components:
</p>
<table>
<tr><td><code>normpath</code></td>
<td>
<p> the normalized path as returned by <code><a href="base.html#topic+normalizePath">normalizePath</a></code></p>
</td></tr>
<tr><td><code>drive</code></td>
<td>
<p>the drive if the OS is Windows, <code>NA</code> else</p>
</td></tr>                  
<tr><td><code>dirname</code></td>
<td>
<p>the path without directory and without filename</p>
</td></tr>
<tr><td><code>fullfilename</code></td>
<td>
<p>the filename including extension</p>
</td></tr>
<tr><td><code>filename</code></td>
<td>
<p>the filename without extension</p>
</td></tr>
<tr><td><code>extension</code></td>
<td>
<p>  the file extension</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+dirname">dirname</a></code>, <code><a href="base.html#topic+basename">basename</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example
path &lt;- "C:/Documents/Projects/Import/eyestudy.dta"
SplitPath(path)

path &lt;- "C:/Documents/Projects/Import/"
SplitPath(path)

path &lt;- "C:/Documents/Projects/Import"
SplitPath(path)  # last entry will be taken as filename
SplitPath(path, last.is.file=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='SplitToCol'>Split Data Frame String Column Into Multiple Columns
</h2><span id='topic+SplitToCol'></span>

<h3>Description</h3>

<p>Splitting the string columns of a data frame into multiple columns requires a considerable number of codelines, which are condensed in this function for convenience.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SplitToCol(x, split = " ", fixed = TRUE, na.form = "", colnames = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SplitToCol_+3A_x">x</code></td>
<td>
<p>a data frame containing the string columns to be splitted.
</p>
</td></tr>
<tr><td><code id="SplitToCol_+3A_split">split</code></td>
<td>

<p>character vector (or object which can be coerced to such)
containing <a href="base.html#topic+regular+20expression">regular expression</a>(s) (unless <code>fixed = TRUE</code>)
to use for splitting.  If empty matches occur, in particular if
<code>split</code> has length 0, <code>x</code> is split into single characters.
If <code>split</code> has length greater than 1, it is re-cycled along
<code>x</code>.
</p>
</td></tr>
<tr><td><code id="SplitToCol_+3A_fixed">fixed</code></td>
<td>

<p>logical.  If <code>TRUE</code> match <code>split</code> exactly, otherwise
use regular expressions.  Has priority over <code>perl</code>.
</p>
</td></tr>
<tr><td><code id="SplitToCol_+3A_na.form">na.form</code></td>
<td>
<p>character, string specifying how <code>NAs</code> should be specially formatted. Default is a blank <code>""</code>.</p>
</td></tr>
<tr><td><code id="SplitToCol_+3A_colnames">colnames</code></td>
<td>
<p>columnnames for the resulting data.frame. Will be recycled. Can easily be set to <code>""</code> if no columnnames should be set. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with all the columns splitted
</p>
<p>A vector with the length of the number of columns of the data.frame containing the number of the found columns is returned as attribute namede <code>"ncols"</code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strsplit">strsplit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.frm &lt;- data.frame(res1=c("2 [-3,5] **", "5 [-2,6] ***", "9 [-3,1]"),
                    res2=c("5 [6,8] **", "7 [-2,9]", "4 [3,5] **"), 
                    stringsAsFactors=FALSE)

SplitToCol(d.frm, na.form="-", colnames=c("coef", "ci", "pval"))
</code></pre>

<hr>
<h2 id='SplitToDummy'>Split Strings of a Vector and Provide Dummy Codes for Found Pieces
</h2><span id='topic+SplitToDummy'></span>

<h3>Description</h3>

<p>Split the strings of a character vector, put together all the unique pieces and return a matrix of dummy vectors for each single value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SplitToDummy(x, split = ",", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SplitToDummy_+3A_x">x</code></td>
<td>
<p>character vector, each element of which is to be split. Other inputs, including a factor, will give an error.
</p>
</td></tr>
<tr><td><code id="SplitToDummy_+3A_split">split</code></td>
<td>
<p>character vector (or object which can be coerced to such) containing regular expression(s) (unless <code>fixed = TRUE</code>) to use for splitting. If empty matches occur, in particular if <code>split</code> has length 0, <code>x</code> is split into single characters. If <code>split</code> has length greater than 1, it is re-cycled along x.
</p>
</td></tr>
<tr><td><code id="SplitToDummy_+3A_...">...</code></td>
<td>
<p>the dots are passed on to <code><a href="base.html#topic+strsplit">strsplit</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame containing <code>x</code> and all the found dummy vectors
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strsplit">strsplit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.frm &lt;- data.frame(id=1:5, txt=c("A,C,D", "A","B,C","D","D,E"))
SplitToDummy(d.frm$txt)
</code></pre>

<hr>
<h2 id='SpreadOut'>Spread Out a Vector of Numbers To a Minimum Interval</h2><span id='topic+SpreadOut'></span>

<h3>Description</h3>

<p>Spread the numbers of a vector so that there is a minimum interval
between any two numbers (in ascending or descending order). This is helpful when we want to place textboxes on a plot and ensure, that they do not mutually overlap.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpreadOut(x, mindist = NULL, cex = 1.0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpreadOut_+3A_x">x</code></td>
<td>
<p>a numeric vector which may contain <code>NA</code>s.</p>
</td></tr>
<tr><td><code id="SpreadOut_+3A_mindist">mindist</code></td>
<td>
<p>the minimum interval between any two values. If this is left to <code>NULL</code> (default) the function will check if a plot is open and then use 90% of <code><a href="graphics.html#topic+strheight">strheight</a>()</code>.</p>
</td></tr>
<tr><td><code id="SpreadOut_+3A_cex">cex</code></td>
<td>
<p>numeric character expansion factor; multiplied by <code><a href="graphics.html#topic+par">par</a>("cex")</code> yields the final character size; the default <code>NULL</code> is equivalent to <code>1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SpreadOut()</code> starts at or near the middle of the vector and increases the
intervals between the ordered values. <code>NA</code>s are preserved. <code>SpreadOut()</code>
first tries to spread groups of values with intervals less than <code>mindist</code>
out neatly away from the mean of the group. If this doesn't entirely succeed,
a second pass that forces values away from the middle is performed.
</p>
<p><code>SpreadOut()</code> can also be used to avoid overplotting of axis tick labels
where they may be close together.
</p>


<h3>Value</h3>

<p>On success, the spread out values. If there are less than two valid values, the original vector is returned.
</p>


<h3>Note</h3>

<p> This function is based on <code>plotrix::spreadout()</code> and has been
integrated here with some minor changes.
</p>


<h3>Author(s)</h3>

<p>Jim Lemon &lt;jim@bitwrit.com.au&gt;<br />
some extensions Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+strheight">strheight</a>()</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>SpreadOut(c(1, 3, 3, 3, 3, 5), 0.2)
SpreadOut(c(1, 2.5, 2.5, 3.5, 3.5, 5), 0.2)
SpreadOut(c(5, 2.5, 2.5, NA, 3.5, 1, 3.5, NA), 0.2)

# this will almost always invoke the brute force second pass
SpreadOut(rnorm(10), 0.5)
</code></pre>

<hr>
<h2 id='Stamp'>Date/Time/Directory Stamp the Current Plot</h2><span id='topic+Stamp'></span>

<h3>Description</h3>

<p>Stamp the current plot in the extreme lower right
corner. A free text or expression can be defined as
text to the stamp.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stamp(txt = NULL, las = par("las"), cex = 0.6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Stamp_+3A_txt">txt</code></td>
<td>
<p>an optional single text string. If it is not given, the function will look for a defined option named <code>stamp</code>. If not found the current date will be taken as text. If the stamp option is defined as expression the function will evaluate it. This can be used to define dynamic texts.</p>
</td></tr>
<tr><td><code id="Stamp_+3A_las">las</code></td>
<td>
<p>numeric in <code>c(1, 3)</code>, defining direction of the text. 1 means horizontal, 3 vertical. Default is taken from <code>par("las")</code>.</p>
</td></tr>
<tr><td><code id="Stamp_+3A_cex">cex</code></td>
<td>
<p>numeric <b>c</b>haracter <b>ex</b>pansion factor; multiplied by <code>par("cex")</code> yields the final character size. Defaults to 0.6.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The text can be freely defined as option. If user and date should be included by default, the following option using an expression will help:
</p>
<pre>DescToolsOptions(stamp=expression(gettextf('%s/%s',
          Sys.getenv('USERNAME'), Format(Today(), fmt='yyyy-mm-dd') )))</pre>
<p>For <span class="rlang"><b>R</b></span> results may not be satisfactory if <code>par(mfrow=)</code> is in effect.
</p>


<h3>Author(s)</h3>

<p>Frank E Harrell Jr &lt;f.harrell@vanderbilt.edu&gt;<br />
with some amendments by Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+text">text</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(1:20)
Stamp()
</code></pre>

<hr>
<h2 id='StdCoef'>Standardized Model Coefficients</h2><span id='topic+StdCoef'></span><span id='topic+PartialSD'></span>

<h3>Description</h3>

<p>Standardize model coefficients by Standard Deviation or Partial Standard Deviation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
StdCoef(x, partial.sd = FALSE, ...)

PartialSD(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StdCoef_+3A_x">x</code></td>
<td>
<p>a fitted model object. </p>
</td></tr>
<tr><td><code id="StdCoef_+3A_partial.sd">partial.sd</code></td>
<td>
<p>logical, if set to <code>TRUE</code>, model coefficients are
multiplied by partial <abbr><span class="acronym">SD</span></abbr>, otherwise they are multiplied by the
ratio of the standard deviations of the independent variable and dependent
variable. </p>
</td></tr>
<tr><td><code id="StdCoef_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>coefTable</code>, e.g.
<code>dispersion</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standardized coefficients are meant to allow for a comparison of the importance of explanatory
variables that have different variances. Each of them shows the effect on the response of increasing
its predictor X(j) by one standard deviation, as a multiple of the response's standard deviation.
This is often a more meaningful comparison of the relevance of the input variables.
</p>
<p>Note, however, that increasing one X(j) without also changing others may not be possible in a
given application, and therefore, interpretation of coefficients can always be tricky. Furthermore,
for binary input variables, increasing the variable by one standard deviation is impossible, since an
increase can only occur from 0 to 1, and therefore, the standardized coeffient is somewhat counterintuitive in this case.
</p>
<p>Standardizing model coefficients has the same effect as centring and
scaling the input variables.
</p>
<p>&ldquo;Classical&rdquo; standardized coefficients
are calculated as
<code class="reqn">\betaᵢ* = \betaᵢ (sₓᵢ / Sᵧ)
        </code>
, where
<code class="reqn">\beta</code> is the unstandardized coefficient,
<code class="reqn">sₓᵢ</code>
is the
standard deviation of associated depenent variable
<code class="reqn">Xᵢ</code>  and
<code class="reqn">Sᵧ</code>
is <abbr><span class="acronym">SD</span></abbr> of the response variable.
</p>
<p>If the variables are intercorrelated, the standard deviation of
<code class="reqn">Xᵢ</code>
used in computing the standardized coefficients
<code class="reqn">\betaᵢ*</code> should be
replaced by a partial standard deviation of
<code class="reqn">Xᵢ</code> which is adjusted for
the multiple correlation of
<code class="reqn">Xᵢ</code>  with the other <code class="reqn">X</code> variables
included in the regression equation. The partial standard deviation is
calculated as
<code class="reqn">s*ₓᵢ = sₓᵢ √(VIFₓᵢ⁻¹) √((n-1)/(n-p))
        </code>,
where VIF is the variance inflation factor,
n is the number of observations and p number of predictors in
the model. Coefficient is then transformed as
<code class="reqn">\betaᵢ* = \betaᵢ s*ₓᵢ
        </code>.
</p>


<h3>Value</h3>

<p>A matrix with at least two columns for standardized coefficient estimate and
its standard error. Optionally, third column holds degrees of freedom
associated with the coefficients.
</p>


<h3>Author(s)</h3>

<p>Kamil Bartoń
</p>


<h3>References</h3>

<p>Cade, B.S. (2015) Model averaging and muddled multimodel inferences.
<em>Ecology</em> 96, 2370-2382.
</p>
<p>Afifi A., May S., Clark V.A. (2011) <em>Practical Multivariate Analysis</em>,
Fifth Edition. CRC Press.
</p>
<p>Bring, J. (1994). How to standardize regression coefficients. <em>The American
Statistician</em> 48, 209-213.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+coef">coef</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Fit model to original data:
fm  &lt;- lm(Fertility ~ Agriculture + Examination + Education + Catholic,
          data = swiss)

# Partial SD for the default formula:
psd &lt;- PartialSD(lm(data = swiss))[-1] # remove first element for intercept

# Standardize data:
zswiss &lt;- scale(swiss, scale = c(NA, psd), center = TRUE)
# Note: first element of 'scale' is set to NA to ignore the first column 'y'

# Coefficients of a model fitted to standardized data:
# zapsmall(coefTable(stdizeFit(fm, data = zGPA)))
# Standardized coefficients of a model fitted to original data:
# zapsmall(StdCoef(fm, partial = TRUE))


# Standardizing nonlinear models:
fam &lt;- Gamma("inverse")
fmg &lt;- glm(log(Fertility) ~ Agriculture + Examination + Education + Catholic,
           data = swiss, family = fam)

psdg &lt;- PartialSD(fmg)
# zGPA &lt;- stdize(GPA, scale = c(NA, psdg[-1]), center = FALSE)
# fmgz &lt;- glm(log(y) ~ z.x1 + z.x2 + z.x3 + z.x4, zGPA, family = fam)

# Coefficients using standardized data:
# coef(fmgz) # (intercept is unchanged because the variables haven't been
           #  centred)
# Standardized coefficients:
# coef(fmg) * psdg

</code></pre>

<hr>
<h2 id='Str'>Compactly Display the Structure of any R Object
</h2><span id='topic+Str'></span>

<h3>Description</h3>

<p>Basically a wrapper for <code><a href="utils.html#topic+str">str</a>()</code>, extended with an enumeration for the variables of a data.frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Str(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Str_+3A_x">x</code></td>
<td>
<p>any <code>R</code> object about which you want to have some information.
</p>
</td></tr>
<tr><td><code id="Str_+3A_...">...</code></td>
<td>
<p>dots are passed to <code><a href="utils.html#topic+str">str</a></code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+str">str</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Str(d.pizza)
</code></pre>

<hr>
<h2 id='StrAbbr'>String Abbreviation
</h2><span id='topic+StrAbbr'></span>

<h3>Description</h3>

<p>Abbreviate a character vector. The function includes starting from the first character 
as many characters as there are needed to result in a vector of unique values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrAbbr(x, minchar = 1, method = c("left", "fix"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrAbbr_+3A_x">x</code></td>
<td>
<p>character vector to be abbreviated
</p>
</td></tr>
<tr><td><code id="StrAbbr_+3A_minchar">minchar</code></td>
<td>
<p>integer, minimal number of characters for the abbreviations.
</p>
</td></tr>
<tr><td><code id="StrAbbr_+3A_method">method</code></td>
<td>
<p>one out of <code>left</code> or <code>fix</code>. While <code>left</code> restricts the result to as many characters 
are needed to ensure uniqueness, does <code>fix</code> yield a vector with all the elements being as long, as 
the the longest needed substring for differentiating the terms.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The abbreviated strings.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+abbreviate">abbreviate</a></code>, <code><a href="#topic+StrTrunc">StrTrunc</a></code>, <code><a href="#topic+StrTrim">StrTrim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StrAbbr(x=levels(d.pizza$driver), minchar=2)
StrAbbr(x=levels(d.pizza$driver), minchar=2, method="left")
StrAbbr(x=levels(d.pizza$driver), minchar=2, method="fix")


x &lt;- c("Aaron", "Aaramis", "Berta", "Bello", "Claudia", "Cardinale", "Doretta", "Emilia")
StrAbbr(x, minchar=2, method="left")
StrAbbr(x, minchar=2, method="fix")
</code></pre>

<hr>
<h2 id='StrAlign'>String Alignment
</h2><span id='topic+StrAlign'></span>

<h3>Description</h3>

<p>Align a vector of strings to the left, to the right, to the center or to the first occurance of a specified character, e.g. to the decimal separator. Alignment is achieved by padding the strings with empty spaces (which evidently only will have an alignment effect if the text is displayed with a monospaced font).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrAlign(x, sep = "\\r")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrAlign_+3A_x">x</code></td>
<td>
<p>a character vector to be aligned.
</p>
</td></tr>
<tr><td><code id="StrAlign_+3A_sep">sep</code></td>
<td>
<p>the character on whose position the strings will be aligned. Left alignment can be requested by setting <code>sep = "\\l"</code>, right alignment by <code>"\\r"</code> and center alignment by <code>"\\c"</code>. Mind the backslashes, as if they are omitted, strings would be aligned to the <b>character</b> l, r or c respectively. Default value is <code>"\\r"</code>, thus right alignment.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Alignment to the left or right leave no room for misinterpretation. The function will determine the maximum string size in the vector, resize all the strings to this size by padding empty spaces either at the beginning or at the end.
</p>
<pre>cbind(StrAlign(c("here", "there", "everywhere"), sep = "\r"))
[1,] "      here"
[2,] "     there"
[3,] "everywhere"</pre>
<p>When it comes to center strings, it's not clear where to place strings with an even length in case the maximum length is odd (or vice versa). We will put the shorter distance of an uneven string to the left (note the second term, that has 2 spaces on the left and 3 spaces on the right).
</p>
<pre>cbind(StrAlign(c("here", "there", "everywhere"), sep = "\c"))
[1,] "   here   "
[2,] "  there   "
[3,] "everywhere"</pre>
<p>Any specific length of the strings can be created by <code><a href="#topic+StrPad">StrPad</a></code> if required.
</p>
<p>In case of a given character as separator the strings will be aligned towards this separator. Frequently this might be the decimal separator. If a string does not contain the separator, the affected string will be aligned as if it had a separator as last character. This seems to be a good default, when integer numbers are to be aligned with numerical values. Note that the character length of the resulting strings can excceed the maximum length of the supplied strings.
</p>
<pre>z &lt;- c(" 6.0", "6.00 ", " 45.12 ", "784", NA)
cbind(StrAlign(z, sep="."))
     [,1]    
[1,] "  6.0 "
[2,] "  6.00"
[3,] " 45.12"
[4,] "784   "
[5,] NA     </pre>
<p>The character strings will not be pruned of whitespaces, if the requested alignment does not explicitly require it. <code><a href="#topic+StrTrim">StrTrim</a></code> can be used for that.
</p>


<h3>Value</h3>

<p>a character vector containing the aligned strings
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+StrTrim">StrTrim</a></code>, <code><a href="#topic+StrPad">StrPad</a></code>, <code><a href="#topic+Format">Format</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># align on (the first occuring) B
x &lt;- c("ABCDMNB", "CDGHEBK", "BCI")
cbind(StrAlign(x, sep="B"))

# align to decimal separator (here point)
z &lt;- c("    6.0", "6.00  ", " 45.12    ", "784", NA)
cbind(StrAlign(z, sep="."))

# right align, the width will be the max number of characters in x
cbind(StrAlign(x, sep="\\r"))
# left align
cbind(StrAlign(x, sep="\\l"))
# center
cbind(StrAlign(x, sep="\\c"))
</code></pre>

<hr>
<h2 id='Strata'>Stratified Sampling</h2><span id='topic+Strata'></span>

<h3>Description</h3>

<p>Stratified sampling with equal/unequal probabilities.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Strata(x, stratanames = NULL, size,
       method = c("srswor", "srswr", "poisson", "systematic"),
       pik, description = FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Strata_+3A_x">x</code></td>
<td>
<p>a data frame or a matrix; its number of rows is n, the population size.</p>
</td></tr>
<tr><td><code id="Strata_+3A_stratanames">stratanames</code></td>
<td>
<p>vector of stratification variables.</p>
</td></tr>
<tr><td><code id="Strata_+3A_size">size</code></td>
<td>
<p>vector of stratum sample sizes (in the order in which the strata are given in the input
data set).</p>
</td></tr>
<tr><td><code id="Strata_+3A_method">method</code></td>
<td>
<p>method to select units; implemented are: a) simple random
sampling without replacement (<code>"srswor"</code>), b) simple random sampling with replacement (<code>"srswr"</code>),
c) Poisson sampling (<code>"poisson"</code>), d) systematic sampling (<code>"systematic"</code>) (default is <code>"srswor"</code>).</p>
</td></tr>
<tr><td><code id="Strata_+3A_pik">pik</code></td>
<td>
<p>vector of inclusion probabilities or auxiliary information used to compute them;
this argument is only used for unequal probability sampling (Poisson and systematic). If an
auxiliary information is provided, the function uses the inclusionprobabilities function for
computing these probabilities. If the method is &quot;srswr&quot; and the sample size is larger than
the population size, this vector is normalized to one.</p>
</td></tr>
<tr><td><code id="Strata_+3A_description">description</code></td>
<td>
<p>a message is printed if its value is TRUE; the message gives the number
of selected units and the number of the units in the population.
By default, the value is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function produces an object, which contains the following information:
</p>
<table>
<tr><td><code>id</code></td>
<td>
<p>the identifier of the selected units.</p>
</td></tr>
<tr><td><code>stratum</code></td>
<td>
<p>the unit stratum.</p>
</td></tr>
<tr><td><code>prob</code></td>
<td>
<p>the final unit inclusion probability.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
<br /> rewritten based on the ideas of Yves Tille &lt;yves.tille@unine.ch&gt; and Alina Matei &lt;alina.matei@unine.ch&gt;</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+sample">sample</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Example from An and Watts (New SAS procedures for Analysis of Sample Survey Data)
# generates artificial data (a 235X3 matrix with 3 columns: state, region, income).
# the variable "state" has 2 categories ('nc' and 'sc').
# the variable "region" has 3 categories (1, 2 and 3).
# the sampling frame is stratified by region within state.
# the income variable is randomly generated

m &lt;- rbind(matrix(rep("nc",165), 165, 1, byrow=TRUE),
           matrix(rep("sc", 70), 70, 1, byrow=TRUE))
m &lt;- cbind.data.frame(m, c(rep(1, 100), rep(2,50), rep(3,15),
                      rep(1, 30), rep(2, 40)), 1000 * runif(235))
names(m) &lt;- c("state", "region", "income")

# computes the population stratum sizes
table(m$region, m$state)

# not run
#     nc  sc
#  1 100  30
#  2  50  40
#  3  15   0
# there are 5 cells with non-zero values
# one draws 5 samples (1 sample in each stratum)
# the sample stratum sizes are 10,5,10,4,6, respectively
# the method is 'srswor' (equal probability, without replacement)

s &lt;- Strata(m, c("region", "state"), size=c(10, 5, 10, 4, 6), method="srswor")

# extracts the observed data
data.frame(income=m[s$id, "income"], s)

# see the result using a contigency table
table(s$region, s$state)


# The same data as in Example 1
# the method is 'systematic' (unequal probability, without replacement)
# the selection probabilities are computed using the variable 'income'
s &lt;- Strata(m,c("region", "state"), size=c(10, 5, 10, 4, 6),
            method="systematic", pik=m$income)

# extracts the observed data
data.frame(income=m[s$id, "income"], s)

# see the result using a contigency table
table(s$region, s$state)
</code></pre>

<hr>
<h2 id='StrCap'> Capitalize the First Letter of a String</h2><span id='topic+StrCap'></span>

<h3>Description</h3>

<p>Capitalize the first letter of each element of the string vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrCap(x, method=c("first", "word", "title"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrCap_+3A_x">x</code></td>
<td>
<p> string to be capitalized. </p>
</td></tr>
<tr><td><code id="StrCap_+3A_method">method</code></td>
<td>
<p>one out of <code>"first"</code> (default), <code>"word"</code>, <code>"title"</code>. <code>"first"</code> will only capitalize the first character of a string. <code>"word"</code> will capitalize all found words and <code>"title"</code> will also capitalize wordwise, but leave out: a, an, the, at, by, for, in, of, on, to, up, and, as, but, s, or and nor.) </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of charaters with the first letter capitalized
</p>


<h3>Author(s)</h3>

<p> Charles Dupont  &lt;charles.dupont@vanderbilt.edu&gt;, Andri Signorell &lt;andri@signorell.net&gt; (methods word and title)</p>


<h3>Examples</h3>

<pre><code class='language-R'># capitalize first character
StrCap(c("Hello", "bob", "daN"))
# but not all...
StrCap(c("Hello bob, how are you?", "And you, DANIEL?"))

# wordwise
StrCap(c("Capitalize all words in titles of publications and documents",
              "but Up and UP, not all and all", NA), method="word")

# wordwise omitting the ones listed above
StrCap(c("Capitalize all words in titles of publications and documents",
         "but Up and UP, not all and all", NA), method="title")

# do not touch non alphabetic characters
z &lt;- c("Lorem ipsum dolor", "-- sit amet", "consectetur --", " adipiscing elit ",
       "sed,.--(do) / +-*eiusmod")
StrCap(z, method="title")
</code></pre>

<hr>
<h2 id='StrChop'>Split a String into a Number of Sections of Defined Length
</h2><span id='topic+StrChop'></span>

<h3>Description</h3>

<p>Splitting a string into a number of sections of defined length is needed, when we  want to split a table given as a number of lines without separator into columns. The cutting points can  either be defined by the lengths of the sections or directly by position.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrChop(x, len, pos)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrChop_+3A_x">x</code></td>
<td>
<p>the string to be cut in pieces.
</p>
</td></tr>
<tr><td><code id="StrChop_+3A_len">len</code></td>
<td>
<p>a vector with the lengths of the pieces.</p>
</td></tr>
<tr><td><code id="StrChop_+3A_pos">pos</code></td>
<td>
<p>a vector of cutting positions. Will be ignored when <code>len</code> has been defined.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If length is going over the end of the string the last part will be returned, so if the rest of the string is needed, it's possible to simply enter a big number as last partlength.
</p>
<p><code>len</code> and <code>pos</code> can't be defined simultaneously, only alternatively.
</p>
<p>Typical usages are
</p>
<pre>
StrChop(x, len)
StrChop(x, pos)
</pre>


<h3>Value</h3>

<p>a vector with the parts of the string.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FixToTable">FixToTable</a></code>, <code><a href="#topic+StrLeft">StrLeft</a></code>, <code><a href="base.html#topic+substr">substr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- paste(letters, collapse="")
StrChop(x=x, len = c(3,5,2))

# and with the rest integrated
StrChop(x=x, len = c(3, 5, 2, nchar(x)))

# cutpoints at 5th and 10th position
StrChop(x=x, pos=c(5, 10))
</code></pre>

<hr>
<h2 id='StrCountW'>Count Words in a String
</h2><span id='topic+StrCountW'></span>

<h3>Description</h3>

<p>Count the number of words that appear within a character string. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrCountW(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrCountW_+3A_x">x</code></td>
<td>
<p>a vector of strings to be parsed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is just a wrapper for a fine regexpr. It uses the expression <code>\b\W+\b</code> to separate the 
words. The code <code>\W</code> is equivalent to <code>[^[:alnum:]_])</code> wheras <code>[:alnum:]</code> contains <code>[:alpha:]</code> and <code>[:digit:]</code>.
So everything that is not an alphanumeric character, a digit or a _ (underscore) is used as separator for the words to be counted.
</p>


<h3>Value</h3>

<p>an integer defining the number of word in the string
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, based on code from Adam Bradley &lt;hisself@adambradley.net&gt;
</p>


<h3>References</h3>

<p><a href="http://stackoverflow.com/questions/8920145/count-the-number-of-words-in-a-string-in-r">http://stackoverflow.com/questions/8920145/count-the-number-of-words-in-a-string-in-r</a></p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+nchar">nchar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StrCountW("This is a true story!")

StrCountW("Just_one_word")
StrCountW("Not-just.one/word")

StrCountW("And what about numbers 8899 or special characters $$$/*?")
StrCountW("   Starting'n ending with some whitespace  ")

StrCountW(c("This is a", "text in more", "than one line."))
</code></pre>

<hr>
<h2 id='StrDist'>Compute Distances Between Strings</h2><span id='topic+StrDist'></span>

<h3>Description</h3>

<p><code>StrDist</code> computes distances between strings following to Levenshtein or Hamming method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrDist(x, y, method = "levenshtein", mismatch = 1, gap = 1, ignore.case = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrDist_+3A_x">x</code></td>
<td>
<p>character vector, first string.</p>
</td></tr>
<tr><td><code id="StrDist_+3A_y">y</code></td>
<td>
<p>character vector, second string.</p>
</td></tr>
<tr><td><code id="StrDist_+3A_method">method</code></td>
<td>
<p>character, name of the distance method. This must be
<code>"levenshtein"</code>, <code>"normlevenshtein"</code> or <code>"hamming"</code>. Default is <code>"levenshtein"</code>, the classical
Levenshtein distance.</p>
</td></tr>
<tr><td><code id="StrDist_+3A_mismatch">mismatch</code></td>
<td>
<p>numeric, distance value for a mismatch between symbols.</p>
</td></tr>
<tr><td><code id="StrDist_+3A_gap">gap</code></td>
<td>
<p>numeric, distance value for inserting a gap.</p>
</td></tr>
<tr><td><code id="StrDist_+3A_ignore.case">ignore.case</code></td>
<td>
<p>if <code>FALSE</code> (default), the distance measure will be case sensitive and if <code>TRUE</code>, case is ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the Hamming and the Levenshtein (edit) distance of two given strings
(sequences). The Hamming distance between two vectors is the number mismatches between corresponding entries.
</p>
<p>In case of the Hamming distance the two strings must have the same length.
</p>
<p>In case of the Levenshtein (edit) distance a scoring and a trace-back matrix are computed
and are saved as attributes <code>"ScoringMatrix"</code> and <code>"TraceBackMatrix"</code>.
The numbers in the trace-back matrix reflect insertion of a gap in string <code>y</code> (1),
match/missmatch (2), and insertion of a gap in string <code>x</code> (3).
</p>
<p>The edit distance is useful, but normalizing the distance to fall within the interval [0,1] is
preferred because it is somewhat diffcult to judge whether an LD of for example 4 suggests a high or low degree of similarity.
The method <code>"normlevenshtein"</code> for normalizing the LD is sensitive to this scenario.
In this implementation, the Levenshtein distance is transformed to fall in this interval as
follows:
</p>
<p style="text-align: center;"><code class="reqn">lnd = 1 - \frac{ld}{max(length(x), length(y))}</code>
</p>

<p>where <code>ld</code> is the edit distance and <code>max(length(x), length(y))</code> denotes that we divide by the length of the larger of the two character strings. This normalization, referred to as the Levenshtein normalized distance (lnd), yields a statistic where 1 indicates perfect agreement between the two strings, and a 0 denotes imperfect agreement. The closer a value is to 1, the more certain we can be that the character strings are the same; the closer to 0, the less certain.
</p>


<h3>Value</h3>

<p><code>StrDist</code> returns an object of class <code>"dist"</code>; cf. <code><a href="stats.html#topic+dist">dist</a></code>.
</p>


<h3>Note</h3>

<p>For distances between strings and for string alignments see also Bioconductor package
<span class="pkg">Biostrings</span>
</p>


<h3>Author(s)</h3>

<p>Matthias Kohl &lt;Matthias.Kohl@stamats.de&gt; </p>


<h3>References</h3>

<p>R. Merkl and S. Waack (2009) <em>Bioinformatik Interaktiv</em>. Wiley.
</p>
<p>Harold C. Doran (2010) <em>MiscPsycho. An R Package for Miscellaneous Psychometric Analyses</em>
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+adist">adist</a></code>, <code><a href="stats.html#topic+dist">dist</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- "GACGGATTATG"
y &lt;- "GATCGGAATAG"
## Levenshtein distance
d &lt;- StrDist(x, y)
d
attr(d, "ScoringMatrix")
attr(d, "TraceBackMatrix")

## Hamming distance
StrDist(x, y, method="hamming")
</code></pre>

<hr>
<h2 id='StrExtract'>Extract Part of a String
</h2><span id='topic+StrExtract'></span><span id='topic+StrExtractBetween'></span>

<h3>Description</h3>

<p>Extract a part of a string, defined as regular expression. <code>StrExtractBetween()</code> is a convenience function used to extract parts between a left and right delimiter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrExtract(x, pattern, ...)

StrExtractBetween(x, left, right, greedy = FALSE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrExtract_+3A_x">x</code></td>
<td>
<p>a character vector where matches are sought, or an object which can be coerced by <code>as.character</code> to a character vector.
</p>
</td></tr>
<tr><td><code id="StrExtract_+3A_pattern">pattern</code></td>
<td>
<p>character string containing a regular expression (or character string for <code>fixed = TRUE</code>) to be matched in the given character vector. Coerced by <code><a href="base.html#topic+as.character">as.character</a></code> to a character string if possible. If a character vector of length 2 or more is supplied, the first element is used with a warning. Missing values are not allowed.
</p>
</td></tr>
<tr><td><code id="StrExtract_+3A_left">left</code></td>
<td>
<p>left character(s) limiting the string to be extracted</p>
</td></tr>
<tr><td><code id="StrExtract_+3A_right">right</code></td>
<td>
<p>right character(s) limiting the string to be extracted</p>
</td></tr>
<tr><td><code id="StrExtract_+3A_greedy">greedy</code></td>
<td>
<p>logical, determines whether the first found match for <code>right</code> should be used (<code>FALSE</code>, default) or the last (<code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="StrExtract_+3A_...">...</code></td>
<td>
<p>the dots are passed to the the internally used function <code><a href="base.html#topic+regexpr">regexpr</a>()</code>, which allows to use e.g. Perl-like regular expressions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function wraps <code><a href="base.html#topic+regexpr">regexpr</a></code> and <code><a href="base.html#topic+regmatches">regmatches</a></code>.
</p>


<h3>Value</h3>

<p>A character vector.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+regexpr">regexpr</a></code>, <code><a href="base.html#topic+regmatches">regmatches</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- c("G1:E001", "No points here", "G2:E002", "G3:E003", NA)

# extract everything after the :
StrExtract(x=txt, pattern=":.*")

# extract everything between "left" and "right"
z &lt;- c("yBS (23A) 890", "l 89Z) 890.?/", "WS (55X) 8(90)", "123 abc", "none", NA)
# everything enclosed by spaces
StrExtractBetween(z, " ", " ")

# note to escape special characters
StrExtractBetween(z, "\\(", "\\)")
</code></pre>

<hr>
<h2 id='StripAttr'>Remove Attributes from an Object
</h2><span id='topic+StripAttr'></span><span id='topic+SetAttr'></span>

<h3>Description</h3>

<p>For convenience we sometimes want to strip some or all attributes in a oneliner. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SetAttr(x, attr, attr_val)
StripAttr(x, attr_names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StripAttr_+3A_x">x</code></td>
<td>
<p>the object whose attributes should be removed or to which an attribute should be added.
</p>
</td></tr>
<tr><td><code id="StripAttr_+3A_attr">attr</code></td>
<td>
<p>name of a new attribute</p>
</td></tr>
<tr><td><code id="StripAttr_+3A_attr_val">attr_val</code></td>
<td>
<p>value for the new attribute <code>attr</code></p>
</td></tr>
<tr><td><code id="StripAttr_+3A_attr_names">attr_names</code></td>
<td>
<p>a vector with attribute names, which will be removed. Leaving the default to <code>NULL</code> will cause all the attributes to be deleted.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the object <code>x</code> without the attributes contained in attr_names
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SetNames">SetNames</a></code>, <code><a href="base.html#topic+unname">unname</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(10)
x &lt;- SetAttr(x, 
             attr=c("some_attr", "other_attr"),
             attr_val=c("First attribute", "Second attribute"))

# strip only single
StripAttr(x, "other_attr")

# strip all attributes
StripAttr(x)
</code></pre>

<hr>
<h2 id='StrIsNumeric'>Does a String Contain Only Numeric Data
</h2><span id='topic+StrIsNumeric'></span>

<h3>Description</h3>

<p>Check whether a string does only contain numeric data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrIsNumeric(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrIsNumeric_+3A_x">x</code></td>
<td>
<p>a character vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a logical vector with the same dimension as x
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p>Other string functions, e.g. <code><a href="#topic+StrTrunc">StrTrunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("123", "-3.141", "foobar123")
StrIsNumeric(x)
</code></pre>

<hr>
<h2 id='StrLeft+2C+20StrRight'>Returns the Left Or the Right Part Of a String
</h2><span id='topic+StrRight'></span><span id='topic+StrLeft'></span>

<h3>Description</h3>

<p>Returns the left part or the right part of a string. The number of characters are defined by the argument <code>n</code>.
If <code>n</code> is negative, this number of characters will be cut off from the other side.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrLeft(x, n)
StrRight(x, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrLeft+2B2C+2B20StrRight_+3A_x">x</code></td>
<td>
<p>a vector of strings.
</p>
</td></tr>
<tr><td><code id="StrLeft+2B2C+2B20StrRight_+3A_n">n</code></td>
<td>
<p>a positive or a negative integer, the number of characters to cut. If n is negative, this number of characters will be cut off
from the right with <code>StrLeft</code> and from the right with <code>StrRight</code>. <br /> n will be recycled.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code>StrLeft</code> and  <code>StrRight</code> are simple wrappers to <code>substr</code>.</p>


<h3>Value</h3>

<p>the left (right) n characters of x
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+substr">substr</a></code>, <code><a href="#topic+StrTrim">StrTrim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StrLeft("Hello world!", n=5)
StrLeft("Hello world!", n=-5)

StrRight("Hello world!", n=6)
StrRight("Hello world!", n=-6)

StrLeft(c("Lorem", "ipsum", "dolor","sit","amet"), n=2)

StrRight(c("Lorem", "ipsum", "dolor","sit","amet"), n=c(2,3))

</code></pre>

<hr>
<h2 id='StrPad'>Pad a String With Justification</h2><span id='topic+StrPad'></span>

<h3>Description</h3>

<p><code>StrPad</code> will fill a string x with defined characters to fit a given length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrPad(x, width = NULL, pad = " ", adj = "left")</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrPad_+3A_x">x</code></td>
<td>
<p>a vector of strings to be padded.</p>
</td></tr>
<tr><td><code id="StrPad_+3A_width">width</code></td>
<td>
<p>resulting width of padded string. If x is a vector and width is left to NULL, it will be set to the length of the largest string in x.</p>
</td></tr>
<tr><td><code id="StrPad_+3A_pad">pad</code></td>
<td>
<p>string to pad with. Will be repeated as often as necessary. Default is &quot; &quot;.</p>
</td></tr>
<tr><td><code id="StrPad_+3A_adj">adj</code></td>
<td>
<p>adjustement of the old string, one of <code>"left"</code>, <code>"right"</code>, <code>"center"</code>. If set to <code>"left"</code> the old string will be adjusted on the left and the new characters will be filled in on the right side.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a string x has more characters than width, it will be chopped on the length of width.
</p>


<h3>Value</h3>

<p>the string
</p>


<h3>Author(s)</h3>

<p>Christian W. Hoffmann &lt;c-w.hoffmann@sunrise.ch&gt;<br />
some extensions Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StrPad("My string", 25, "XoX", "center")
 # [1] "XoXXoXXoMy stringXXoXXoXX"
</code></pre>

<hr>
<h2 id='StrPos'>Find Position of First Occurrence Of a String
</h2><span id='topic+StrPos'></span>

<h3>Description</h3>

<p>Returns the numeric position of the first occurrence of a substring within a string. If the search string is not found, the result will be <code>NA</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrPos(x, pattern, pos = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrPos_+3A_x">x</code></td>
<td>
<p>a character vector in which to search for the pattern, or an object which can be coerced by as.character to a character vector.
</p>
</td></tr>
<tr><td><code id="StrPos_+3A_pattern">pattern</code></td>
<td>
<p>character string (search string) containing the pattern to be matched in the given character vector. This can be a character string or a regular expression.
</p>
</td></tr>
<tr><td><code id="StrPos_+3A_pos">pos</code></td>
<td>
<p>integer, defining the start position for the search within x. The result will then be relative to the begin of the truncated string. Will be recycled.
</p>
</td></tr>
<tr><td><code id="StrPos_+3A_...">...</code></td>
<td>
<p>the dots are passed to the function <code><a href="base.html#topic+regexpr">regexpr</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is just a wrapper for the function <code><a href="base.html#topic+regexpr">regexpr</a></code>.
</p>


<h3>Value</h3>

<p>a vector of the first position of pattern in  x
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+StrChop">StrChop</a></code>, <code><a href="base.html#topic+regexpr">regexpr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StrPos(x = levels(d.pizza$driver), pattern = "t")
</code></pre>

<hr>
<h2 id='StrRev'>Reverse a String
</h2><span id='topic+StrRev'></span>

<h3>Description</h3>

<p>Returns a string in reverse order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrRev(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrRev_+3A_x">x</code></td>
<td>
<p>a string to be processed.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; solely copying R core code from strsplit example</p>


<h3>See Also</h3>

<p> String functions: 
<code><a href="base.html#topic+nchar">nchar</a></code>, <code><a href="base.html#topic+match">match</a></code>, <code><a href="base.html#topic+grep">grep</a></code>, <code><a href="base.html#topic+regexpr">regexpr</a></code>, 
<code><a href="base.html#topic+substr">substr</a></code>, <code><a href="base.html#topic+sub">sub</a></code>, <code><a href="base.html#topic+gsub">gsub</a></code>,
<code><a href="#topic+StrTrunc">StrTrunc</a></code>, <code><a href="#topic+StrDist">StrDist</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StrRev("home")
StrRev("Anna")
</code></pre>

<hr>
<h2 id='StrSpell'>Spell a String Using the NATO Phonetic or the Morse Alphabet
</h2><span id='topic+StrSpell'></span>

<h3>Description</h3>

<p>The function splits a string into single characters and returns their representation in either the NATO phonetic alphabet or the Morse alphabet. The 26 code words in the NATO phonetic alphabet are assigned to the 26 letters of the English alphabet in alphabetical order as follows: Alfa, Bravo, Charlie, Delta, Echo, Foxtrot, Golf, Hotel, India, Juliett, Kilo, Lima, Mike, November, Oscar, Papa, Quebec, Romeo, Sierra, Tango, Uniform, Victor, Whiskey, X-ray, Yankee, Zulu. Digits 0-9 are also supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrSpell(x, upr = "CAP", type = c("NATO", "Morse"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrSpell_+3A_x">x</code></td>
<td>
<p>character, the string to be encoded.
</p>
</td></tr>
<tr><td><code id="StrSpell_+3A_upr">upr</code></td>
<td>
<p>character, a shortcut to be used to characterise capital letters. Ignored if <code>type</code> is set to <code>"Morse"</code>. No distinction is made between upper and lower case if <code>upr</code> is set to <code>NA</code> or to an empty string <code>""</code>.
</p>
</td></tr>
<tr><td><code id="StrSpell_+3A_type">type</code></td>
<td>
<p>the type of phonetic alphabet, either <code>"NATO"</code> or <code>"Morse"</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector containing the code words
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/NATO_phonetic_alphabet">https://en.wikipedia.org/wiki/NATO_phonetic_alphabet</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strsplit">strsplit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ... ever had to communicate a password by phone? ;-)
StrSpell("Yailov9teb6i")

paste(StrSpell("Andri", type="Morse"), collapse="|")
</code></pre>

<hr>
<h2 id='StrSplit'>Split the Elements of a Character Vector
</h2><span id='topic+StrSplit'></span>

<h3>Description</h3>

<p>Split the elements of a character vector x into substrings according to the matches to substring split within them.<br />
This is a verbatim copy of the base R function <code><a href="base.html#topic+strsplit">strsplit</a></code>, but with a split default of <code>""</code> and returning a vector instead of a list, when x had the length 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrSplit(x, split = "", fixed = FALSE, perl = FALSE, useBytes = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrSplit_+3A_x">x</code></td>
<td>

<p>character vector, each element of which is to be split.  Other
inputs, including a factor, will give an error.
</p>
</td></tr>
<tr><td><code id="StrSplit_+3A_split">split</code></td>
<td>

<p>character vector (or object which can be coerced to such)
containing <a href="base.html#topic+regular+20expression">regular expression</a>(s) (unless <code>fixed = TRUE</code>)
to use for splitting.  If empty matches occur, in particular if
<code>split</code> has length 0, <code>x</code> is split into single characters.
If <code>split</code> has length greater than 1, it is re-cycled along
<code>x</code>.
</p>
</td></tr>
<tr><td><code id="StrSplit_+3A_fixed">fixed</code></td>
<td>

<p>logical.  If <code>TRUE</code> match <code>split</code> exactly, otherwise
use regular expressions.  Has priority over <code>perl</code>.
</p>
</td></tr>
<tr><td><code id="StrSplit_+3A_perl">perl</code></td>
<td>
<p>logical.  Should Perl-compatible regexps be used?</p>
</td></tr>
<tr><td><code id="StrSplit_+3A_usebytes">useBytes</code></td>
<td>
<p>logical.  If <code>TRUE</code> the matching is done
byte-by-byte rather than character-by-character, and inputs with
marked encodings are not converted.  This is forced (with a warning)
if any input is found which is marked as <code>"bytes"</code>
(see <code><a href="base.html#topic+Encoding">Encoding</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="base.html#topic+strsplit">strsplit</a></code> for the details.
</p>


<h3>Value</h3>

<p>A list of the same length as <code>x</code>, the <code>i</code>-th element of which
contains the vector of splits of <code>x[i]</code>.
</p>
<p>If the length x was 1 a vecotor with the splits will be returned.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+paste">paste</a></code> for the reverse,
<code><a href="base.html#topic+grep">grep</a></code> and <code><a href="base.html#topic+sub">sub</a></code> for string search and
manipulation; also <code><a href="base.html#topic+nchar">nchar</a></code>, <code><a href="base.html#topic+substr">substr</a></code>.
</p>
<p>&lsquo;<a href="base.html#topic+regular+20expression">regular expression</a>&rsquo; for the details of the pattern
specification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>noquote(StrSplit("A text I want to display with spaces"))

# the same as ...
noquote(strsplit("A text I want to display with spaces", NULL)[[1]])
</code></pre>

<hr>
<h2 id='StrTrim'>
Remove Leading/Trailing Whitespace From A String
</h2><span id='topic+StrTrim'></span>

<h3>Description</h3>

<p>The function removes whitespace characters as spaces, tabs and newlines from the beginning and end of the supplied string.
Whitespace characters occurring in the middle of the string are retained.<br />
Trimming with method <code>"left"</code> deletes only leading whitespaces, <code>"right"</code> only trailing.
Designed for users who were socialized by SQL.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrTrim(x, pattern = " \t\n", method = "both")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrTrim_+3A_x">x</code></td>
<td>

<p>the string to be trimmed.
</p>
</td></tr>
<tr><td><code id="StrTrim_+3A_pattern">pattern</code></td>
<td>

<p>the pattern of the whitespaces to be deleted, defaults to space, tab and newline: <code>" \t\n"</code>.
</p>
</td></tr>
<tr><td><code id="StrTrim_+3A_method">method</code></td>
<td>
<p>one out of <code>"both"</code> (default), <code>"left"</code>, <code>"right"</code>. Determines on which side the string should be trimmed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions are defined depending on method as<br />
<code>both:  gsub( pattern=gettextf("^[%s]+|[%s]+$", pattern, pattern), replacement="", x=x)</code><br />
<code>left:  gsub( pattern=gettextf("^[%s]+",pattern), replacement="", x=x)</code><br />
<code>right: gsub( pattern=gettextf("[%s]+$",pattern), replacement="", x=x)</code>
</p>


<h3>Value</h3>

<p>the string x without whitespaces</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p> String functions:
<code>trimws</code>, <code><a href="base.html#topic+nchar">nchar</a></code>, <code><a href="base.html#topic+match">match</a></code>, <code><a href="base.html#topic+grep">grep</a></code>, <code><a href="base.html#topic+regexpr">regexpr</a></code>, <code><a href="base.html#topic+substr">substr</a></code>, <code><a href="base.html#topic+sub">sub</a></code>, <code><a href="base.html#topic+gsub">gsub</a></code>,
<code><a href="#topic+StrTrunc">StrTrunc</a></code>, <code><a href="#topic+StrDist">StrDist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>StrTrim("  Hello world! ")

StrTrim("  Hello world! ", method="left")
StrTrim("  Hello world! ", method="right")

# user defined pattern
StrTrim(" ..Hello ... world! ", pattern=" \\.")
</code></pre>

<hr>
<h2 id='StrTrunc'>
Truncate Strings and Add Ellipses If a String is Truncated.
</h2><span id='topic+StrTrunc'></span>

<h3>Description</h3>

<p>Truncates one or more strings to a specified length, adding an ellipsis (...)
to those strings that have been truncated. The truncation can also be performed using word boundaries.
Use <code><a href="#topic+StrAlign">StrAlign</a>()</code> to justify the strings if needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrTrunc(x, maxlen = 20, ellipsis = "...", wbound = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrTrunc_+3A_x">x</code></td>
<td>
<p>a vector of strings.</p>
</td></tr>
<tr><td><code id="StrTrunc_+3A_maxlen">maxlen</code></td>
<td>
<p>the maximum length of the returned strings (NOT counting the appended ellipsis). <code>maxlen</code> is recycled.</p>
</td></tr>
<tr><td><code id="StrTrunc_+3A_ellipsis">ellipsis</code></td>
<td>
<p>the string to be appended, if the string is longer than the given maximal length. The default is <code>"..."</code>.</p>
</td></tr>
<tr><td><code id="StrTrunc_+3A_wbound">wbound</code></td>
<td>
<p>logical. Determines if the maximal length should be reduced to the next smaller word boundary and so words are not chopped. Default is <code>FALSE</code>. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The string(s) passed as &lsquo;<span class="samp">&#8288;x&#8288;</span>&rsquo; now with a maximum length of &lsquo;<span class="samp">&#8288;maxlen&#8288;</span>&rsquo; + 3 (for the ellipsis).
</p>


<h3>Author(s)</h3>

<p>Andri Signorell, <br /> once following an idea of Jim Lemon in <code><a href="prettyR.html#topic+truncString">truncString</a>()</code></p>


<h3>See Also</h3>

<p>String functions: 
<code><a href="base.html#topic+nchar">nchar</a></code>, <code><a href="base.html#topic+match">match</a></code>, <code><a href="base.html#topic+grep">grep</a></code>, <code><a href="base.html#topic+regexpr">regexpr</a></code>, <code><a href="base.html#topic+substr">substr</a></code>, <code><a href="base.html#topic+sub">sub</a></code>, <code><a href="base.html#topic+gsub">gsub</a></code>,
<code><a href="#topic+StrTrim">StrTrim</a></code>, <code><a href="#topic+StrDist">StrDist</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("this is short", "and this is a longer text", 
       "whereas this is a much longer story, which could not be told shorter")

# simple truncation on 10 characters
StrTrunc(x, maxlen=10)

# NAs remain NA
StrTrunc(c(x, NA_character_), maxlen=15, wbound=TRUE)

# using word boundaries
for(i in -5:20)
  print(StrTrunc(x, maxlen=i, wbound=TRUE))

# compare
for(i in -5:20)
  print(StrTrunc(x, maxlen=i, wbound=FALSE))
</code></pre>

<hr>
<h2 id='StrVal'>Extract All Numeric Values From a String
</h2><span id='topic+StrVal'></span>

<h3>Description</h3>

<p>Extract all numeric values from a string using a regular expression and return a list of all found values. If there are several, the values can be either pasted and/or casted from characters to numeric values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StrVal(x, paste = FALSE, as.numeric = FALSE, dec = getOption("OutDec"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StrVal_+3A_x">x</code></td>
<td>
<p>a character vector
</p>
</td></tr>
<tr><td><code id="StrVal_+3A_paste">paste</code></td>
<td>
<p>should separatetly extracted numbers be pasted together? This can be useful to reverse a prior format action. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="StrVal_+3A_as.numeric">as.numeric</code></td>
<td>
<p>logical value, determining if the extracted values should be converted to a number or be returned as characters. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="StrVal_+3A_dec">dec</code></td>
<td>
<p>character string containing a single character. The preferred character to be used as the decimal point. Defaults <code>getOption("OutDec")</code>. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are multiple numbers in the same string to paste and cast to numeric, pasting will be done first and after pasting the conversion will be performed. So if for example the numbers in <code>x = "34 way 066"</code> should be extracted <code>StrVal(x, paste = TRUE, as.numeric = TRUE)</code> will lead to <code>34066</code>. This is a useful choice for converting formatted numbers having some kind of bigmark. </p>


<h3>Value</h3>

<p>depending on the results the function will return either a character vector, in the case every element of x contained only one number, or a list of character vectors containing the found numbers.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, Markus Naepflin &lt;markus@naepfl.in&gt; provided an optimized regex
</p>


<h3>See Also</h3>

<p>other string functions in <code><a href="#topic+DescTools-package">DescTools-package</a></code>, section <code>String functions</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># a simple vector with only one number per element
StrVal(x=c("week 1", "week 3", "week 4", "week 5"))

# several numbers per element, extract each part, do not paste and return characters
StrVal(x=c("This is 1. place: 45.2", "none", "12.1 but -2.7 follow, 10.2e23 "),
       paste = FALSE, as.numeric = FALSE)

# critical are numbers combined with signs, where we sequentially extract valid numbers
StrVal(x=c("78-23-99", "1e-15-34*789+9", "- 34values"),
       paste = FALSE, as.numeric = FALSE)

# a typical use case for this function is to reverse a previously
#   applied number format

x &lt;- c(100000, 4564654632, -456463)
xf &lt;- Format(x, big.mark="'")

StrVal(xf, paste = TRUE, as.numeric = TRUE)

StrVal(xf, paste = TRUE, as.numeric = FALSE)
StrVal(xf, paste = FALSE, as.numeric = TRUE)
StrVal(xf, paste = FALSE, as.numeric = FALSE)

# use an alternative decimal point
StrVal("8 452,12", dec=",")
</code></pre>

<hr>
<h2 id='StuartMaxwellTest'>Stuart-Maxwell Marginal Homogeneity Test
</h2><span id='topic+StuartMaxwellTest'></span>

<h3>Description</h3>

<p>This function computes the marginal homogeneity test for a <code class="reqn">k \times  k</code> matrix of assignments of objects to <code>k</code> categories or two vectors <code>x</code>, <code>y</code> of category scores for <code>n</code> data objects by two raters. The statistic is distributed as <code class="reqn">\chi^2</code> with <code>k-1</code> degrees of freedom. <br />
It can be viewed as an extension of the McNemar test to <code class="reqn">k \times k</code> table. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StuartMaxwellTest(x, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StuartMaxwellTest_+3A_x">x</code></td>
<td>
<p>either a 2-way <code class="reqn">k \times  k</code> contingency table in matrix form, or a factor.
</p>
</td></tr>
<tr><td><code id="StuartMaxwellTest_+3A_y">y</code></td>
<td>
<p>a factor with the same levels as x; ignored if x is a matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The null is that the probabilities of being classified into cells [i, j] and [j, i] are the same.
</p>
<p>If <code>x</code> is a matrix, it is taken as a two-dimensional contingency table, and hence its entries should be nonnegative integers. Otherwise, both x and y must be vectors or factors of the same length and with the same levels. <br />
Incomplete cases are removed, vectors are coerced into factors, and the contingency table is computed from these.
</p>
<p>If there is perfect agreement for any category k, that category must be omitted in order to invert matrix S. 
</p>
<p>If for any category <code>k</code>, all frequencies in row <code>k</code> and column <code>k</code> are 0, except possibly for the main diagonal element (e.g., for perfect agreement for category <code>k</code>, in such cases also the corresponding row and column marginal frequencies would be equal), then the category is not included in the test and should be ignored, say the Stuart-Maxwell test is performed with respect to the remaining categories only. The degree of freedom <code>df</code> in this case can still be considered <code>k - 1</code>, where <code>k</code> is the number of original categories; this treats omitted categories as if they were included but contributed 0 to the value of <code class="reqn">\chi^2</code> - a reasonable view since such categories have equal row and column marginals. (See: <a href="https://www.john-uebersax.com/stat/mcnemar.htm#stuart">https://www.john-uebersax.com/stat/mcnemar.htm#stuart</a>)
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of test was
performed.</p>
</td></tr> 
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, based on Code from Jim Lemon
</p>


<h3>References</h3>

<p>Stuart, A (1955) A test for homogeneity of the marginal distributions in a two-way classification. <em>Biometrika</em>, 42, 412-416.
</p>
<p>Maxwell, A.E. (1970) Comparing the classification of subjects by two independent judges. <em>British Journal of Psychiatry</em>, 116, 651-655.
</p>
<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons, pp 86 ff.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BhapkarTest">BhapkarTest</a></code> for a more powerful alternative to the Stuart-Maxwell test
</p>
<p><code><a href="stats.html#topic+mcnemar.test">mcnemar.test</a></code>, <code><a href="stats.html#topic+chisq.test">chisq.test</a></code>, <code><a href="#topic+MHChisqTest">MHChisqTest</a></code>,
<code><a href="#topic+BreslowDayTest">BreslowDayTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Source: https://www.john-uebersax.com/stat/mcnemar.htm#stuart
hyp &lt;- as.table(matrix(c(20,3,0,10,30,5,5,15,40), nrow=3))
StuartMaxwellTest(hyp)

# same as defined with two vectors
d.hyp &lt;- Untable(hyp)
StuartMaxwellTest(x=d.hyp[,1], y=d.hyp[,2])


mc &lt;- as.table(matrix(c(
         732, 1524, 1575, 1577, 1602, 837, 1554, 1437, 
         1672, 1600, 841, 1363, 1385, 1484, 1524, 791), nrow=4))

StuartMaxwellTest(mc)
</code></pre>

<hr>
<h2 id='StuartTauC'>Stuart <code class="reqn">\tau_{c}</code>
</h2><span id='topic+StuartTauC'></span>

<h3>Description</h3>

<p>Calculate Stuart's <code class="reqn">\tau_{c}</code> statistic, a measure of
association for ordinal factors in a two-way table.<br />
The function has interfaces for a table (matrix) and for single vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StuartTauC(x, y = NULL, conf.level = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StuartTauC_+3A_x">x</code></td>
<td>
<p>a numeric vector or a table. A matrix will be treated as table.
</p>
</td></tr>
<tr><td><code id="StuartTauC_+3A_y">y</code></td>
<td>
<p>NULL (default) or a vector with compatible dimensions to <code>x</code>. If y is provided, <code>table(x, y, ...)</code> is calculated.
</p>
</td></tr>
<tr><td><code id="StuartTauC_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated.
</p>
</td></tr>
<tr><td><code id="StuartTauC_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set useNA. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stuart's <code class="reqn">\tau_{c}</code> makes an adjustment for table size in addition to a correction for ties. <code class="reqn">\tau_{c}</code> is
appropriate only when both variables lie on an ordinal scale. <br />
It is estimated by <br />
</p>
<p style="text-align: center;"><code class="reqn"> \tau_{c} = \frac{2 m \cdot(P-Q)}{n^2 \cdot (m-1)}</code>
</p>

<p>where P equals the number of concordances and Q the number of discordances, n is the total amount of observations and m = min(R, C). The range of <code class="reqn">\tau_{c}</code> is [-1, 1]. <br />
See <a href="http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf">http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf</a>, pp. 1739 for the estimation of the asymptotic variance.
</p>
<p>The use of Stuart's Tau-c versus Kendall's Tau-b is recommended when the two ordinal variables under consideration have different numbers of values, e.g. good, medium, bad versus high, low.
</p>


<h3>Value</h3>

<p>a single numeric value if no confidence intervals are requested,<br />
and otherwise a numeric vector with 3 elements for the estimate, the lower and the upper confidence interval
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis</em>. John Wiley &amp; Sons,
pp. 57&ndash;59.
</p>
<p>Brown, M.B., Benedetti, J.K.(1977) Sampling Behavior of Tests for Correlation in Two-Way Contingency Tables, <em>Journal of the American Statistical Association</em>, 72, 309-315.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1954) Measures of
association for cross classifications. <em>Journal of the
American Statistical Association</em>, 49, 732-764.
</p>
<p>Goodman, L. A., &amp; Kruskal, W. H. (1963) Measures of
association for cross classifications III: Approximate
sampling theory. <em>Journal of the American Statistical
Association</em>, 58, 310-364.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ConDisPairs">ConDisPairs</a></code> yields concordant and discordant pairs <br /><br />
Other association measures: <br />
<code><a href="#topic+GoodmanKruskalGamma">GoodmanKruskalGamma</a></code>, <code><a href="#topic+KendallTauA">KendallTauA</a></code> (<code class="reqn">\tau_{a}</code>), <code><a href="stats.html#topic+cor">cor</a></code> (method=&quot;kendall&quot;) for <code class="reqn">\tau_{b}</code>, <code><a href="#topic+SomersDelta">SomersDelta</a></code><br />
<code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+GoodmanKruskalTau">GoodmanKruskalTau</a></code>, <code><a href="#topic+UncertCoef">UncertCoef</a></code>, <code><a href="#topic+MutInf">MutInf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example in:
# http://support.sas.com/documentation/cdl/en/statugfreq/63124/PDF/default/statugfreq.pdf
# pp. S. 1821

tab &lt;- as.table(rbind(c(26,26,23,18,9),c(6,7,9,14,23)))

StuartTauC(tab, conf.level=0.95)
</code></pre>

<hr>
<h2 id='SysInfo'>System Information</h2><span id='topic+SysInfo'></span><span id='topic+FindRProfile'></span>

<h3>Description</h3>

<p>SysInfo is a convenience function to compile some information about the
computing system and environment used.</p>


<h3>Usage</h3>

<pre><code class='language-R'>SysInfo()
FindRProfile()
</code></pre>


<h3>Details</h3>

<p>The function <code>SysInfo</code> is mainly used to save the system environment information
in ncdf files containing the results of some calculations. <br /><br />
<code>FindRProfile</code> returns path candidates where the profile could be found.
</p>


<h3>Value</h3>

<p>character string with all version and system information of the current R system</p>


<h3>Author(s)</h3>

<p>Jannis v. Buttlar &lt;jbuttlar@bgc-jena.mpg.de&gt;, Andri Signorell &lt;andri@signorell.net&gt;</p>

<hr>
<h2 id='TextContrastColor'>Choose Textcolor Depending on Background Color
</h2><span id='topic+TextContrastColor'></span>

<h3>Description</h3>

<p>Text of a certain color when viewed against certain backgrounds can be hard to see.
<code>TextContrastColor</code> returns either black or white depending on which has the better contrast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextContrastColor(col, white = "white", black = "black", method = c("glynn", "sonego"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextContrastColor_+3A_col">col</code></td>
<td>
<p>vector of any of the three kind of R colors, i.e., either a color name (an element of <code>colors()</code>),
a hexadecimal string of the form <code>"#rrggbb"</code> or <code>"#rrggbbaa"</code> (see <code><a href="grDevices.html#topic+rgb">rgb</a></code>), or an integer i meaning <code>palette()[i]</code>.
Non-string values are coerced to integer.
</p>
</td></tr>
<tr><td><code id="TextContrastColor_+3A_white">white</code></td>
<td>
<p>the color for the dark backgrounds, default is <code>"white"</code>.</p>
</td></tr>
<tr><td><code id="TextContrastColor_+3A_black">black</code></td>
<td>
<p>the color for the bright backgrounds, default is <code>"black"</code></p>
</td></tr>
<tr><td><code id="TextContrastColor_+3A_method">method</code></td>
<td>
<p>defines the algorithm to be used. Can be one out of <code>"glynn"</code> or <code>"sonego"</code>. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple heuristic in defining a text color for a given background color, is to pick the one that
is &quot;farthest&quot; away from &quot;black&quot; or &quot;white&quot;.
The way Glynn chooses to do this is to compute the color intensity,
defined as the mean of the RGB triple, and pick &quot;black&quot; (intensity 0) for text color if the background
intensity is greater than 127, or &quot;white&quot; (intensity 255) when the background intensity is less than or equal to 127.
Sonego calculates <code>L &lt;- c(0.2, 0.6, 0) %*% col2rgb(color)/255</code> and returns &quot;black&quot; if L &gt;= 0.2 and &quot;white&quot; else.
</p>


<h3>Value</h3>

<p>a vector containing the contrast color (either black or white)
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; based on code of
Earl F. Glynn, Stowers Institute for Medical Research, 2004
</p>


<h3>Examples</h3>

<pre><code class='language-R'># works fine for grays
PlotArea( y=matrix(rep(1, times=3, each=8), ncol=8), x=1:3,
  col=gray(1:8 / 8), ylab="", xlab="", axes=FALSE )
text( x=2, y=1:8-0.5, levels(d.pizza$driver),
  col=TextContrastColor(gray(1:8 / 8)))

# and not so fine, but still ok, for colors
par(mfrow=c(1,2))
PlotArea( y=matrix(rep(1, times=3, each=12), ncol=12), x=1:3,
  col=rainbow(12), ylab="", xlab="", axes=FALSE, main="method = Glynn" )
text( x=2, y=1:12-0.5, levels(d.pizza$driver),
  col=TextContrastColor(rainbow(12)))

PlotArea( y=matrix(rep(1, times=3, each=12), ncol=12), x=1:3,
  col=rainbow(12), ylab="", xlab="", axes=FALSE, main="method = Sonego" )
text( x=2, y=1:12-0.5, levels(d.pizza$driver),
  col=TextContrastColor(rainbow(12), method="sonego"))

</code></pre>

<hr>
<h2 id='TextToTable'>Converts String To a Table
</h2><span id='topic+TextToTable'></span>

<h3>Description</h3>

<p>Try to convert a string to a table, by first creating a data frame using <code><a href="utils.html#topic+read.table">read.table</a></code>. This can then be coerced to a matrix first, and subsequently to a table. The names of the dimensions can be specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextToTable(x, dimnames = NULL, check.names = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextToTable_+3A_x">x</code></td>
<td>
<p>the string to be interpreted as table.
</p>
</td></tr>
<tr><td><code id="TextToTable_+3A_dimnames">dimnames</code></td>
<td>
<p>the names of the dimensions.
</p>
</td></tr>
<tr><td><code id="TextToTable_+3A_check.names">check.names</code></td>
<td>
<p>passed on to <code><a href="utils.html#topic+read.table">read.table</a></code> and determines, if invalid column names should be adapted to valid ones. The default here is changed to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="TextToTable_+3A_...">...</code></td>
<td>
<p>the dots will be passed to the function <code><a href="utils.html#topic+read.table">read.table</a></code> and can be used for example to specify <code>header</code>, <code>sep</code> and <code>row.names</code> arguments.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a table
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+read.table">read.table</a></code>, <code><a href="base.html#topic+as.table">as.table</a></code>, <code><a href="base.html#topic+as.matrix">as.matrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- "
    Democrat, Independent, Republican
  M, 762, 327, 468
  F, 484, 239, 477"

(tab &lt;- TextToTable(txt, header=TRUE, sep=",", dimnames=c("gender", "party")))
</code></pre>

<hr>
<h2 id='TheilU'>Theil's U Index of Inequality
</h2><span id='topic+TheilU'></span>

<h3>Description</h3>

<p>Calculate Theil's U index of inequality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TheilU(a, p, type = c(2, 1), na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TheilU_+3A_a">a</code></td>
<td>
<p>a numeric vector with the actual observed values.
</p>
</td></tr>
<tr><td><code id="TheilU_+3A_p">p</code></td>
<td>
<p>a numeric vector containing the predictions.
</p>
</td></tr>
<tr><td><code id="TheilU_+3A_type">type</code></td>
<td>
<p>defining the type of Theil's two U measures, see Details. Default is 2.
</p>
</td></tr>
<tr><td><code id="TheilU_+3A_na.rm">na.rm</code></td>
<td>

<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. If set to <code>TRUE</code> complete cases of <code>cbind(x, y)</code> will be used. Defaults to <code>FALSE</code>.

</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Theil proposed two error measures, but at different times and under the same symbol U, which has caused some confusion.
U <code>type = 1</code> is taken from Theil  (1958, pp. 31-42). The argument <code>a</code> represents the actual observations and <code>p</code> the corresponding predictions. He left it open whether <code>a</code> and <code>p</code> should be used as absolute values or as observed and predicted changes. <br />
Theil (1966, chapter 2) proposed U <code>type = 2</code> as a measure of forecast quality: <em>&quot;...where <code class="reqn">A_i</code> and <code class="reqn">P_i</code> stand for a pair of predicted and observed changes. ...&quot;</em> <br />
As <code class="reqn">U_1</code> has some serious disadvantages (see Bliemel 1973) it is recommended to use <code class="reqn">U_2</code>.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Theil, H. (1958): <em>Economic Forecasts and Policy</em>. Amsterdam: North Holland.
</p>
<p>Thiel, H. (1966): <em>Applied Economic Forecasting</em>. Chicago: Rand McNally.
</p>
<p>Bliemel, F. (1973): Theil's Forecast Accuracy Coefficient: A Clarification, <em>Journal of Marketing Research</em> Vol. 10, No. 4 (Nov., 1973), pp. 444-446
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gini">Gini</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TheilU(1:10, 2:11, type=1)
TheilU(1:10, 2:11, type=2)
</code></pre>

<hr>
<h2 id='TitleRect'>Plot Boxed Annotation
</h2><span id='topic+TitleRect'></span>

<h3>Description</h3>

<p>The function can be used to add a title to a plot surrounded by a rectangular box. This is useful for plotting several plots in narrow distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TitleRect(label, bg = "grey", border = 1, col = "black", xjust = 0.5,
          line = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TitleRect_+3A_label">label</code></td>
<td>
<p>the main title
</p>
</td></tr>
<tr><td><code id="TitleRect_+3A_bg">bg</code></td>
<td>
<p>the background color of the box.
</p>
</td></tr>
<tr><td><code id="TitleRect_+3A_border">border</code></td>
<td>
<p>the border color of the box
</p>
</td></tr>
<tr><td><code id="TitleRect_+3A_col">col</code></td>
<td>
<p>the font color of the title
</p>
</td></tr>
<tr><td><code id="TitleRect_+3A_xjust">xjust</code></td>
<td>
<p>the x-justification of the text. This can be <code>c(0, 0.5, 1)</code> for left, middle- and right alignement.
</p>
</td></tr>
<tr><td><code id="TitleRect_+3A_line">line</code></td>
<td>
<p>on which MARgin line, starting at 0 counting outwards</p>
</td></tr>
<tr><td><code id="TitleRect_+3A_...">...</code></td>
<td>
<p>the dots are passed to the <code><a href="graphics.html#topic+text">text</a></code> function, which can be used to change font and similar arguments.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing is returned
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+title">title</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(pressure)
TitleRect("pressure")
</code></pre>

<hr>
<h2 id='TMod'>Comparison Table For Linear Models
</h2><span id='topic+TMod'></span><span id='topic+ModSummary'></span><span id='topic+ModSummary.lm'></span><span id='topic+ModSummary.glm'></span><span id='topic+plot.TMod'></span><span id='topic+print.TMod'></span>

<h3>Description</h3>

<p>Collect the coefficients and some qualifying statistics of linear models and organize it in a table for comparison and reporting. The function supports linear and general linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TMod(..., FUN = NULL, order = NA)

ModSummary(x, ...)

## S3 method for class 'lm'
ModSummary(x, conf.level = 0.95, ...)
## S3 method for class 'glm'
ModSummary(x, conf.level = 0.95, use.profile = TRUE, ...)

## S3 method for class 'TMod'
plot(x, terms = NULL, intercept = FALSE, ...)
## S3 method for class 'TMod'
print(x, digits = 3, na.form = "-", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TMod_+3A_x">x</code></td>
<td>
<p>a (general) linear model object.</p>
</td></tr>
<tr><td><code id="TMod_+3A_...">...</code></td>
<td>
<p>a list of (general) linear models.</p>
</td></tr>
<tr><td><code id="TMod_+3A_conf.level">conf.level</code></td>
<td>
<p>the level for the confidence intervals.</p>
</td></tr>
<tr><td><code id="TMod_+3A_fun">FUN</code></td>
<td>
<p>function with arguments <code>est</code>, <code>se</code>, <code>tval</code>, <code>pval</code>, <code>lci</code>, <code>uci</code> to display the coefficients. The default function will display the coefficient and significance stars for the p-values.</p>
</td></tr>
<tr><td><code id="TMod_+3A_order">order</code></td>
<td>
<p>row of the results table to be used as order for the models (as typically &quot;AIC&quot;). Can be any label in the first column of the results table. Default is <code>NA</code> for no special order.</p>
</td></tr>
<tr><td><code id="TMod_+3A_terms">terms</code></td>
<td>
<p>a vector with the terms of the model formula to be plotted. By default this will be all of them.</p>
</td></tr>
<tr><td><code id="TMod_+3A_use.profile">use.profile</code></td>
<td>
<p>logical. Defines if profile approach should be used, which normally is a good choice for small datasets. Calculating profile can however take ages for large datasets and not be necessary there. So we can fallback to normal confidence intervals. </p>
</td></tr>
<tr><td><code id="TMod_+3A_intercept">intercept</code></td>
<td>
<p>logical, defining whether the intercept should be plotted (default is <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="TMod_+3A_digits">digits</code></td>
<td>
<p>integer, the desired (fixed) number of digits after the decimal point. Unlike <code><a href="base.html#topic+formatC">formatC</a></code> you will always get this number of digits even if the last digit is 0.
</p>
</td></tr>
<tr><td><code id="TMod_+3A_na.form">na.form</code></td>
<td>
<p>character, string specifying how <code>NA</code>s should be specially formatted.
If set to <code>NULL</code> (default) no special action will be taken.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to compare the coefficients of linear models, the user is left to his own devices. R offers no support in this respect. <code>TMod()</code> jumps into the breach and displays the coefficients of several models in tabular form. For this purpose, different quality indicators for the models are displayed, so that a comprehensive comparison of the models is possible. In particular, it is easy to see the effect that adding or omitting variables has on forecast quality.
</p>
<p>A plot function for a <code>TMod</code> object will produce a dotchart with the coefficients and their confidence intervals.
</p>


<h3>Value</h3>

<p>character table
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+help">help</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r.full &lt;- lm(Fertility ~ . , swiss)
r.nox &lt;- lm(Fertility ~ . -Examination - Catholic, swiss)
r.grp &lt;- lm(Fertility ~ . -Education - Catholic + CutQ(Catholic), swiss)
r.gam &lt;- glm(Fertility ~ . , swiss, family=Gamma(link="identity"))
r.gama &lt;- glm(Fertility ~ .- Agriculture , swiss, family=Gamma(link="identity"))
r.gaml &lt;- glm(Fertility ~ . , swiss, family=Gamma(link="log"))

TMod(r.full, r.nox, r.grp, r.gam, r.gama, r.gaml)

# display confidence intervals
TMod(r.full, r.nox, r.gam, FUN = function(est, se, tval, pval, lci, uci){
  gettextf("%s [%s, %s]",
           Format(est, fmt=Fmt("num")),
           Format(lci, digits=3),
           Format(uci, digits=2)
           )
})


# cbind interface is not supported!!
# d.titanic &lt;- reshape(as.data.frame(Titanic),
#                       idvar = c("Class","Sex","Age"),
#                       timevar="Survived",
#                       direction = "wide")
#
# r.glm0 &lt;- glm(cbind(Freq.Yes, Freq.No) ~ 1, data=d.titanic, family="binomial")
# r.glm1 &lt;- glm(cbind(Freq.Yes, Freq.No) ~ Class, data=d.titanic, family="binomial")
# r.glm2 &lt;- glm(cbind(Freq.Yes, Freq.No) ~ ., data=d.titanic, family="binomial")

d.titanic &lt;- Untable(Titanic)

r.glm0 &lt;- glm(Survived ~ 1, data=d.titanic, family="binomial")
r.glm1 &lt;- glm(Survived ~ Class, data=d.titanic, family="binomial")
r.glm2 &lt;- glm(Survived ~ ., data=d.titanic, family="binomial")

TMod(r.glm0, r.glm1, r.glm2)

# plot OddsRatios
d.pima &lt;- MASS::Pima.tr2

r.a &lt;- glm(type ~ npreg + bp + skin + bmi + ped + age, data=d.pima, family=binomial)
r.b &lt;- glm(type ~ npreg + glu + bp + skin, data=d.pima, family=binomial)
r.c &lt;- glm(type ~ npreg + age, data=d.pima, family=binomial)

or.a &lt;- OddsRatio(r.a)
or.b &lt;- OddsRatio(r.b)
or.c &lt;- OddsRatio(r.c)


# create the model table
tm &lt;- TMod(m_A=or.a, m_B=or.b, m_C=or.c)
# .. and plotit
plot(tm, main="ORs for Models A, B, C", intercept=FALSE,
     pch=15, col=c(hred, hblue, horange), 
     panel.first=abline(v=1, col="grey30"))
</code></pre>

<hr>
<h2 id='ToLong+2C+20ToWide'>Reshape a Vector From Long to Wide Shape Or Vice Versa
</h2><span id='topic+ToWide'></span><span id='topic+ToLong'></span>

<h3>Description</h3>

<p>Simple reshaping a vector from long to wide or from wide to long shape by means of a single factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ToLong(x, varnames = NULL)
ToWide(x, g, by = NULL, varnames = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ToLong+2B2C+2B20ToWide_+3A_x">x</code></td>
<td>
<p>the vector to be reshaped
</p>
</td></tr>
<tr><td><code id="ToLong+2B2C+2B20ToWide_+3A_g">g</code></td>
<td>
<p>the grouping vector to be used for the new columns. The resulting <code>data.frame</code> will return one column per grouplevel.
</p>
</td></tr>
<tr><td><code id="ToLong+2B2C+2B20ToWide_+3A_by">by</code></td>
<td>
<p>a vector to be used to merge the pieces of <code>x</code>. If this is left to <code>NULL</code> the pieces will be merged by rownames in the order they are supplied.
</p>
</td></tr>
<tr><td><code id="ToLong+2B2C+2B20ToWide_+3A_varnames">varnames</code></td>
<td>
<p>the variable names if not the grouping levels should be used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ToLong</code> expects x as a matrix or a data.frame and reshapes it to a (long) factor representation.
<code>ToWide</code> expects the vectors x, g, by, wheras x being the variable, g the splitting factor and by a vector for rowwise merging.
</p>


<h3>Value</h3>

<p>the reshaped object
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+reshape">reshape</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.x &lt;- read.table(header=TRUE, text="
AA BB CC DD EE FF GG
7.9 18.1 13.3 6.2 9.3 8.3 10.6
9.8 14.0 13.6 7.9 2.9 9.1 13.0
6.4 17.4 16.0 10.9 8.6 11.7 17.5
")

ToLong(d.x)

# ToWide by row numbers (by = NULL)
ToWide(PlantGrowth$weight, PlantGrowth$group)

# To wide aligned by key
set.seed(41)
PlantGrowth$nr &lt;- c(sample(12, 10), sample(12, 10), sample(12, 10))
head(PlantGrowth)

ToWide(PlantGrowth$weight, PlantGrowth$group, by=PlantGrowth$nr)
</code></pre>

<hr>
<h2 id='TOne'>Create Table One Describing Baseline Characteristics
</h2><span id='topic+TOne'></span>

<h3>Description</h3>

<p>Create a table summarizing continuous, categorical and dichotomous variables, optionally stratified by one or more variables, while performing adequate statistical tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TOne(x, grp = NA, add.length = TRUE, colnames = NULL, vnames = NULL, 
     total = TRUE, align = "\\l", 
     FUN = NULL, TEST = NULL, intref = "high",
     fmt = list(abs = Fmt("abs"), num  = Fmt("num"), per = Fmt("per"),
                pval = as.fmt(fmt = "*", na.form = "   ")) )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TOne_+3A_x">x</code></td>
<td>
<p>a data.frame containing all the variables to be included in the table.
</p>
</td></tr>
<tr><td><code id="TOne_+3A_grp">grp</code></td>
<td>
<p>the grouping variable.
</p>
</td></tr>
<tr><td><code id="TOne_+3A_add.length">add.length</code></td>
<td>
<p>logical. If set to <code>TRUE</code> (default), a row with the group sizes will be inserted as first row of the table.
</p>
</td></tr>
<tr><td><code id="TOne_+3A_colnames">colnames</code></td>
<td>
<p>a vector of column names for the result table.
</p>
</td></tr>
<tr><td><code id="TOne_+3A_vnames">vnames</code></td>
<td>
<p>a vector of variable names to be placed in the first column instead of the real names.
</p>
</td></tr>
<tr><td><code id="TOne_+3A_total">total</code></td>
<td>
<p>logical (default <code>TRUE</code>), defines whether the results should also be displayed for the whole, ungrouped variable.</p>
</td></tr>
<tr><td><code id="TOne_+3A_align">align</code></td>
<td>
<p>the character on whose position the strings will be aligned. Left alignment can be requested by setting <code>sep = "\\l"</code>, right alignment by <code>"\\r"</code> and center alignment by <code>"\\c"</code>. Mind the backslashes, as if they are omitted, strings would be aligned to the <b>character</b> <b>l</b>, <b>r</b> or <b>c</b> respectively. Default value is <code>"\\l"</code>, thus left alignment.
</p>
</td></tr>
<tr><td><code id="TOne_+3A_fun">FUN</code></td>
<td>
<p>the function to be used as location and dispersion measure for numeric (including integer) variables (<code>mean</code>/<code>sd</code> is default, alternatives as <code>median</code>/<code>IQR</code> are possible by defining a function). See examples.</p>
</td></tr>
<tr><td><code id="TOne_+3A_test">TEST</code></td>
<td>
<p>a list of functions to be used to test the variables. Must be named as <code>"num"</code>, <code>"cat"</code> and <code>"dich"</code> and be defined as function with arguments <code>(x, g)</code>, generating something similar to a p-value. Use <code>TEST=NA</code> to suppress test. (See examples.) </p>
</td></tr>
<tr><td><code id="TOne_+3A_intref">intref</code></td>
<td>
<p>one out of <code>"high"</code> (default) or <code>"low"</code>, defining which value of a dichotomous numeric or logical variable should be reported. Usually this will be <code>1</code> or <code>TRUE</code>. Setting it to <code>"low"</code> will report the lower value <code>0</code> or <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="TOne_+3A_fmt">fmt</code></td>
<td>
<p>format codes for absolute, numeric and percentage values, and for the p-values of the tests. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>In research the characteristics of study populations are often characterised through some kind of a &quot;Table 1&quot;, containing descriptives of the used variables, as mean/standard deviation for continuous variables, and proportions for categorical variables. In many cases, a comparison is made between groups within the framework of the scientific question. 
</p>
<pre>
  var             Brent           Camden          Westminster                    
  n                 474 (39.5%)     344 (28.7%)     381 (31.8%)                  
  temperature      51.1 (8.7)      47.4 (10.1)     44.3 (9.8)     *** '          
  driver                                                          *** "'          
    Butcher          72 (15.2%)       1 (0.3%)       22 (5.8%)                   
    Carpenter        29 (6.1%)       19 (5.6%)      221 (58.2%)                  
    Carter          177 (37.4%)      47 (13.8%)       5 (1.3%)                   
    Farmer           19 (4.0%)       87 (25.5%)      11 (2.9%)                   
    Hunter          128 (27.1%)       4 (1.2%)       24 (6.3%)                   
    Miller            6 (1.3%)       41 (12.0%)      77 (20.3%)                  
    Taylor           42 (8.9%)      142 (41.6%)      20 (5.3%)                   
  rabate (= TRUE)   235 (50.3%)     172 (50.3%)     184 (48.7%)       "'          
  ---
  ') Kruskal-Wallis test, ") Fisher exact test, "') Chi-Square test
  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
</pre>
<p>Creating such a table can be very time consuming and there's a need for a flexible function that helps us to solve the task. <code>TOne()</code> is designed to be easily used with sensible defaults, and yet flexible enough to allow free definition of the essential design elements.
</p>
<p>This is done by breaking down the descriptive task to three types of variables: quantitative (numeric, integer), qualitative (factor, characters) and dichotomous variables (the latter having exactly two values or levels). Depending on the variable type, the descriptives and the according sensible tests are chosen. By default mean/sd are chosen to describe numeric variables. 
</p>
<pre>  FUN = function(x) gettextf("%s / %s",
                             Format(mean(x, na.rm = TRUE), digits = 1),
                             Format(sd(x, na.rm = TRUE), digits = 3)) 
</pre>
<p>Their difference is tested with the Kruskal-Wallis test. For categorical variables the absolute and relative frequencies are calculated and tested with a chi-square test. <br /> The tests can be changed with the argument <code>TEST</code>. These must be organised as list containing elements named <code>"num"</code>, <code>"cat"</code> and <code>"dich"</code>. Each of them must be a function with arguments <code>(x, g)</code>, returning something similar to a p-value. 
</p>
<pre>  TEST = list(
            num  = list(fun = function(x, g){summary(aov(x ~ g))[[1]][1, "Pr(&gt;F)"]},
                        lbl = "ANOVA"),
            cat  = list(fun = function(x, g){chisq.test(table(x, g))$p.val},
                        lbl = "Chi-Square test"),
            dich = list(fun = function(x, g){fisher.test(table(x, g))$p.val},
                        lbl = "Fisher exact test"))
</pre>
<p>The legend text of the test, which is appended to the table together with the significance codes, can be set with the variable <code>lbl</code>.
</p>
<p>Great importance was attached to the free definition of the number formats. By default, the optionally definable format templates of <b>DescTools</b> are used. Deviations from this can be freely passed as arguments to the function. Formats can be defined for integers, floating point numbers, percentages and for the p-values of statistical tests. All options of the function <code><a href="#topic+Format">Format</a>()</code> are available and can be provided as a list. See examples which show several different implementations.
</p>
<pre>  fmt = list(abs  = Fmt("abs"), 
             num  = Fmt("num"), 
             per  = Fmt("per"),
             pval = as.fmt(fmt = "*", na.form = "   ")) 
</pre>
<p>The function returns a character matrix as result, which can easily be subset or combined with other matrices. An interface for <code><a href="#topic+ToWrd">ToWrd</a>()</code> is available such that the matrix can be transferred to MS-Word. Both font and alignment are freely selectable in the Word table. 
</p>


<h3>Value</h3>

<p>a character matrix
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+WrdTable">WrdTable</a>()</code>, <code><a href="#topic+ToWrd.TOne">ToWrd.TOne</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(scipen = 8)
opt &lt;- DescToolsOptions()

# define some special formats for count data, percentages and numeric results
# (those will be supported by TOne)
Fmt(abs = as.fmt(digits = 0, big.mark = "'"))   # counts
Fmt(per = as.fmt(digits = 1, fmt = "%"))        # percentages
Fmt(num = as.fmt(digits = 1, big.mark = "'"))   # numeric

TOne(x = d.pizza[, c("temperature", "delivery_min", "driver", "wine_ordered")],
  grp = d.pizza$quality)

# the same but no groups now...
TOne(x = d.pizza[, c("temperature", "delivery_min", "driver", "wine_ordered")])

# define median/IQR as describing functions for the numeric variables
TOne(iris[, -5], iris[, 5],
  FUN = function(x) {
    gettextf("%s / %s",
      Format(median(x, na.rm = TRUE), digits = 1), 
      Format(IQR(x, na.rm = TRUE), digits = 3))
  }
)

# replace kruskal.test by ANOVA and report the p.value
# Change tests for all the types
TOne(x = iris[, -5], grp = iris[, 5],
     FUN = function(x) gettextf("%s / %s",
            Format(mean(x, na.rm = TRUE), digits = 1),
            Format(sd(x, na.rm = TRUE), digits = 3)), 

     TEST = list(
       num = list(fun = function(x, g){summary(aov(x ~ g))[[1]][1, "Pr(&gt;F)"]},
                        lbl = "ANOVA"),
               cat = list(fun = function(x, g){chisq.test(table(x, g))$p.val},
                        lbl = "Chi-Square test"),
               dich = list(fun = function(x, g){fisher.test(table(x, g))$p.val},
                         lbl = "Fisher exact test")),
       fmt = list(abs = Fmt("abs"), num  = Fmt("num"), per = Fmt("per"),
                pval = as.fmt(fmt = "*", na.form = "   ")) 
)

t1 &lt;- TOne(x     = d.pizza[,c("temperature", "driver", "rabate")], 
           grp   = d.pizza$area, 
           align = " ", 
           total = FALSE,
            
           FUN = function(x) gettextf("%s / %s (%s)",
                                      Format(mean(x, na.rm = TRUE), digits = 1),
                                      Format(sd(x, na.rm = TRUE), digits = 3),
                                      Format(median(x, na.rm = TRUE), digits = 1)),
           
           TEST = NA,
            
           fmt = list(abs  = as.fmt(big.mark = " ", digits=0), 
                      num  = as.fmt(big.mark = " ", digits=1), 
                      per  = as.fmt(fmt=function(x) 
                          StrPad(Format(x, fmt="%", d=1), width=5, adj = "r")), 
                      pval = as.fmt(fmt = "*", na.form = "   ")) 
)
# add a userdefined legend
attr(t1, "legend") &lt;- "numeric: mean / sd (median)), factor: n (n%)"

t1


# dichotomous integer or logical values can be reported by the high or low value
x &lt;- sample(x = c(0, 1), size = 100, prob = c(0.3, 0.7), replace = TRUE)
y &lt;- sample(x = c(0, 1), size = 100, prob = c(0.3, 0.7), replace = TRUE) == 1
z &lt;- factor(sample(x = c(0, 1), size = 100, prob = c(0.3, 0.7), replace = TRUE))
g &lt;- sample(x = letters[1:4], size = 100, replace = TRUE)
d.set &lt;- data.frame(x = x, y = y, z = z, g = g)

TOne(d.set[1:3], d.set$g, intref = "low")

TOne(d.set[1:3], d.set$g, intref = "high")

# intref would not control factors, use relevel to change reported value
TOne(data.frame(z = relevel(z, "1")), g)

TOne(data.frame(z = z), g)

options(opt)


## Not run:   
  
# Send the whole stuff to Word
wrd &lt;- GetNewWrd()
ToWrd(
  TOne(x   = d.pizza[, c("temperature", "delivery_min", "driver", "wine_ordered")],
       grp = d.pizza$quality,
       fmt = list(num=Fmt("num", digits=1))
       ),
  font = list(name="Arial narrow", size=8),
  align = c("l","r")      # this will be recycled: left-right-left-right ...
)

## End(Not run)
</code></pre>

<hr>
<h2 id='ToWrd'>Send Objects to Word
</h2><span id='topic+ToWrd'></span><span id='topic+ToWrd.table'></span><span id='topic+ToWrd.ftable'></span><span id='topic+ToWrd.character'></span><span id='topic+ToWrd.lm'></span><span id='topic+ToWrd.TOne'></span><span id='topic+ToWrd.TMod'></span><span id='topic+ToWrd.Freq'></span><span id='topic+ToWrd.default'></span><span id='topic+ToWrd.data.frame'></span>

<h3>Description</h3>

<p>Send objects like tables, ftables, lm tables, TOnes or just simple texts to a MS-Word document.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ToWrd(x, font = NULL, ..., wrd = DescToolsOptions("lastWord"))

## S3 method for class 'Freq'
ToWrd(x, font = NULL, main = NULL, ..., wrd = DescToolsOptions("lastWord"))

## S3 method for class 'table'
ToWrd(x, font = NULL, main = NULL, align = NULL,
      tablestyle = NULL, autofit = TRUE,
      row.names = FALSE, col.names = TRUE, ..., wrd = DescToolsOptions("lastWord"))

## S3 method for class 'data.frame'
ToWrd(x, font = NULL, main = NULL, row.names = NULL, ...,
      wrd = DescToolsOptions("lastWord"))

## S3 method for class 'ftable'
ToWrd(x, font = NULL, main = NULL, align = NULL,
      method = "compact", ..., wrd = DescToolsOptions("lastWord"))

## S3 method for class 'TOne'
ToWrd(x, font = NULL, para = NULL, main = NULL, align = NULL,
      autofit = TRUE, ..., wrd = DescToolsOptions("lastWord"))

## S3 method for class 'TMod'
ToWrd(x, font = NULL, para = NULL, main = NULL, align = NULL, 
      split = " ", fixed=TRUE, autofit = TRUE, digits = 3, na.form = "-", ..., 
      wrd = DescToolsOptions("lastWord")) 

## S3 method for class 'lm'
ToWrd(x, font = NULL, ..., wrd = DescToolsOptions("lastWord"))

## S3 method for class 'character'
ToWrd(x, font = NULL, para = NULL, style = NULL, bullet = FALSE,
      ..., wrd = DescToolsOptions("lastWord"))

## Default S3 method:
ToWrd(x, font = NULL, ..., wrd = DescToolsOptions("lastWord"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ToWrd_+3A_x">x</code></td>
<td>
<p>the object to be transferred to Word.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_font">font</code></td>
<td>
<p>the font to be used to the output. This should be defined as a list containing fontname, fontsize, bold and italic flags:<br /> <code>list(name="Arial", size=10, bold=FALSE, italic=TRUE)</code>.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_para">para</code></td>
<td>
<p>list containing paragraph format properties to be applied to the inserted text. For right align the paragraph one can set: <br />
<code>list(alignment="r", LineBefore=0.5)</code>. See details for the full set of properties.</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_main">main</code></td>
<td>
<p>a caption for a table. This will be inserted by <code><a href="#topic+WrdCaption">WrdCaption</a></code> in Word and can be listed afterwards in a specific index. Default is <code>NULL</code>, which will insert nothing. Ignored if <code>x</code> is not a table.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_align">align</code></td>
<td>
<p>character vector giving the alignment of the table columns. <code>"l"</code> means left, <code>"r"</code> right and <code>"c"</code> center alignement. The code will be recyled to the length of thenumber of columns.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_method">method</code></td>
<td>
<p>string specifying how the <code>"ftable"</code> object is formatted
(and printed if used as in <code>write.ftable()</code> or the <code>print</code>
method).  Can be abbreviated.  Available methods are (see the examples):
</p>

<dl>
<dt><code>"non.compact"</code></dt><dd><p>the default representation of an
<code>"ftable"</code> object.</p>
</dd>
<dt><code>"row.compact"</code></dt><dd><p>a row-compact version without empty cells
below the column labels.</p>
</dd>
<dt><code>"col.compact"</code></dt><dd><p>a column-compact version without empty cells
to the right of the row labels.</p>
</dd>
<dt><code>"compact"</code></dt><dd><p>a row- and column-compact version.  This may imply
a row and a column label sharing the same cell.  They are then
separated by the string <code>lsep</code>.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="ToWrd_+3A_autofit">autofit</code></td>
<td>
<p>logical, defining if the columns of table should be fitted to the length of their content.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_row.names">row.names</code></td>
<td>
<p>logical, defining whether the row.names should be included in the output. Default is <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_col.names">col.names</code></td>
<td>
<p>logical, defining whether the col.names should be included in the output. Default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_tablestyle">tablestyle</code></td>
<td>
<p>either the name of a defined Word tablestyle or its index.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_style">style</code></td>
<td>
<p>character, name of a style to be applied to the inserted text.</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_bullet">bullet</code></td>
<td>
<p>logical, defines if the text should be formatted as bullet points.</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_split">split</code></td>
<td>
<p>character vector (or object which can be coerced to such) containing regular expression(s) (unless <code>fixed = TRUE</code>) to use for splitting. If empty matches occur, in particular if <code>split</code> has length 0, x is split into single characters. If <code>split</code> has length greater than 1, it is re-cycled along x.</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_fixed">fixed</code></td>
<td>
<p>logical. If TRUE match split exactly, otherwise use regular expressions. Has priority over perl.</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_digits">digits</code></td>
<td>
<p>integer, the desired (fixed) number of digits after the decimal point. Unlike <code><a href="base.html#topic+formatC">formatC</a></code> you will always get this number of digits even if the last digit is 0.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_na.form">na.form</code></td>
<td>
<p>character, string specifying how <code>NA</code>s should be specially formatted.
If set to <code>NULL</code> (default) no special action will be taken.
</p>
</td></tr>
<tr><td><code id="ToWrd_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The paragraph format can be defined by means of these properties:
</p>
<p><code>LeftIndent</code>, <code>RightIndent</code>, <code>SpaceBefore</code>, <code>SpaceBeforeAuto</code>, <code>SpaceAfter</code>, <code>SpaceAfterAuto</code>, <code>LineSpacingRule</code>,
<code>Alignment</code>, <code>WidowControl</code>, <code>KeepWithNext</code>, <code>KeepTogether</code>, <code>PageBreakBefore</code>, <code>NoLineNumber</code>, <code>Hyphenation</code>,
<code>FirstLineIndent</code>, <code>OutlineLevel</code>, <code>CharacterUnitLeftIndent</code>, <code>CharacterUnitRightIndent</code>, <code>CharacterUnitFirstLineIndent</code>,
<code>LineUnitBefore</code>, <code>LineUnitAfter</code>, <code>MirrorIndents</code>.
</p>


<h3>Value</h3>

<p>if <code>x</code> is a table a pointer to the table will be returned
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GetNewWrd">GetNewWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# we can't get this through the CRAN test - run it with copy/paste to console

wrd &lt;- GetNewWrd()
ToWrd("This is centered Text in Arial Black\n",
      para=list(Alignment=wdConst$wdAlignParagraphCenter,
                SpaceBefore=3, SpaceAfter=6),
      font=list(name="Arial Black", size=14),
      wrd=wrd)

sel &lt;- wrd$Selection()$Borders(wdConst$wdBorderBottom)
sel[["LineStyle"]] &lt;- wdConst$wdLineStyleSingle


t1 &lt;- TOne(x = d.pizza[, c("temperature","delivery_min","driver","wine_ordered")],
           grp=d.pizza$wine_delivered)

ToWrd(t1, font=list(name="Algerian"), wrd=wrd)


tab &lt;- table(d.pizza$driver, d.pizza$area)

tab &lt;- table(d.pizza$driver, d.pizza$area)
ToWrd(tab, font = list(size=15, name="Arial"), row.names = TRUE, col.names = TRUE,
      main= "my Title", wrd=wrd)
ToWrd(tab, font = list(size=10, name="Arial narrow"),
      row.names = TRUE, col.names=FALSE, wrd=wrd)
ToWrd(tab, font = list(size=15, name="Arial"), align="r",
      row.names = FALSE, col.names=TRUE, wrd=wrd)
ToWrd(tab, font = list(size=15, name="Arial"),
      row.names = FALSE, col.names=FALSE, wrd=wrd)

ToWrd(tab, tablestyle = "Mittlere Schattierung 2 - Akzent 4",
      row.names=TRUE, col.names=TRUE, wrd=wrd)

ToWrd(Format(tab, big.mark = "'", digits=0), wrd=wrd)

zz &lt;- ToWrd(Format(tab, big.mark = "'", digits=0), wrd=wrd)
zz$Rows(1)$Select()
WrdFont(wrd = wrd) &lt;- list(name="Algerian", size=14, bold=TRUE)


# Send a TMod table to Word using a split to separate columns
r.ols &lt;- lm(Fertility ~ . , swiss)
r.gam &lt;- glm(Fertility ~ . , swiss, family=Gamma(link="identity"))

# Build the model table for some two models, creating a user defined
# reporting function (FUN) with | as column splitter
tm &lt;- TMod(OLS=r.ols, Gamma=r.gam, 
           FUN=function(est, se, tval, pval, lci, uci){
              gettextf("%s|[%s, %s]|%s",
                       Format(est, fmt=Fmt("num"), digits=2),
                       Format(lci, fmt=Fmt("num"), digits=2), 
                       Format(uci, fmt=Fmt("num"), digits=2),
                       Format(pval, fmt="*")
              )})

# send it to Word, where we get a table with 3 columns per model
# coef | confint | p-val
wrd &lt;- GetNewWrd()
ToWrd(tm, split="|", align=StrSplit("lrclrcl"))
)

## End(Not run)
</code></pre>

<hr>
<h2 id='ToWrdB'>Send Objects to Word and Bookmark Them
</h2><span id='topic+ToWrdB'></span>

<h3>Description</h3>

<p>Send objects like tables, ftables, lm tables, TOnes or just simple texts to a MS-Word document and place a bookmark on them. This has the advantage, that objects in a Word document can be updated later, provided the bookmark name has been stored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ToWrdB(x, font = NULL, ..., wrd = DescToolsOptions("lastWord"), 
        bookmark = gettextf("bmt%s", round(runif(1, min = 0.1) * 1e+09)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ToWrdB_+3A_x">x</code></td>
<td>
<p>the object to be transferred to Word.
</p>
</td></tr>
<tr><td><code id="ToWrdB_+3A_font">font</code></td>
<td>
<p>the font to be used to the output. This should be defined as a list containing fontname, fontsize, bold and italic flags:<br /> <code>list(name="Arial", size=10, bold=FALSE, italic=TRUE)</code>.
</p>
</td></tr>
<tr><td><code id="ToWrdB_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.
</p>
</td></tr>
<tr><td><code id="ToWrdB_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.
</p>
</td></tr>
<tr><td><code id="ToWrdB_+3A_bookmark">bookmark</code></td>
<td>
<p>the name of the bookmark.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function encapsulates <code><a href="#topic+ToWrd">ToWrd</a></code>, by placing a bookmark over the complete inserted results.
The given name can be questioned with <code>bm$name()</code>.
</p>


<h3>Value</h3>

<p>a handle to the set bookmark
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToWrd">ToWrd</a></code>, <code><a href="#topic+WrdInsertBookmark">WrdInsertBookmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# we can't get this through the CRAN test - run it with copy/paste to console

wrd &lt;- GetNewWrd()
bm &lt;- ToWrdB("This is text to be possibly replaced later.")

# get the automatically created name of the bookmark
bm$name()

WrdGoto(bm$name())
UpdateBookmark(...)

## End(Not run)
</code></pre>

<hr>
<h2 id='ToWrdPlot'>Send a Plot to Word and Bookmark it
</h2><span id='topic+ToWrdPlot'></span>

<h3>Description</h3>

<p>Evaluate given plot code to a <code><a href="grDevices.html#topic+tiff">tiff</a>()</code> device and imports the created plot in the currently open MS-Word document. The imported plot is marked with a bookmark that can later be used for a potential update (provided the bookmark name has been stored).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ToWrdPlot(plotcode, width = NULL, height = NULL, scale = 100,
          pointsize = 12, res = 300, crop = 0, title = NULL,  
          wrd = DescToolsOptions("lastWord"), 
          bookmark = gettextf("bmp%s", round(runif(1, min = 0.1) * 1e+09)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ToWrdPlot_+3A_plotcode">plotcode</code></td>
<td>
<p>code chunk needed for producing the plot
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_bookmark">bookmark</code></td>
<td>
<p>character, the name of the bookmark
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_width">width</code></td>
<td>
<p>the width in cm of the plot in the Word document (default 15)
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_height">height</code></td>
<td>
<p>the height in cm of the plot in the Word document (default 9.3)
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_scale">scale</code></td>
<td>
<p>the scale of the plot (default 100) 
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_pointsize">pointsize</code></td>
<td>
<p>the default pointsize of plotted text, interpreted as big points (1/72 inch) at <code>res</code> ppi. (default is 12) 
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_res">res</code></td>
<td>
<p>the resolution for the graphic (default 300)
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_crop">crop</code></td>
<td>
<p>a vector of 4 elements, the crop factor for all 4 sides of a picture in cm (default all 0)
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_title">title</code></td>
<td>
<p>character, the title of the plot to be inserted in the word document
</p>
</td></tr>
<tr><td><code id="ToWrdPlot_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An old and persistent problem that has existed for a long time is that as results  once were loaded into a Word document the connection broke so that no update was possible. It was only recently that I realized that bookmarks in Word could be a solution for this.
The present function evaluates some given plot code chunk using a tiff device and imports the created plot in a word document. The imported plot is given a bookmark, that can be used afterwards for changing or updating the plot. 
</p>
<p>This function is designed for use with the <b>DescToolsAddIns</b> functions <code>ToWrdPlotWithBookmark()</code> and <code>ToWrdWithBookmark()</code> allowing to assign keyboard shortcuts. The two functions will also insert the newly defined bookmark in the source file in a format, which can be interpreted by the function <code>UpdateBookmark()</code>.
</p>


<h3>Value</h3>

<p>a list
</p>
<table>
<tr><td><code>plot_hwnd</code></td>
<td>
<p>a windows handle to the inserted plot</p>
</td></tr>
<tr><td><code>bookmark</code></td>
<td>
<p>a windows handle to the bookmark</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToWrdB">ToWrdB</a></code>, <code><a href="#topic+WrdInsertBookmark">WrdInsertBookmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# we can't get this through the CRAN test - run it with copy/paste to console

wrd &lt;- GetNewWrd()
bm &lt;- ToWrdB("This is text to be possibly replaced later.")

# get the automatically created name of the bookmark
bm$name()

WrdGoto(bm$name())
UpdateBookmark(...)

## End(Not run)
</code></pre>

<hr>
<h2 id='Triangular'>
The Triangular Distribution
</h2><span id='topic+Triangular'></span><span id='topic+dTri'></span><span id='topic+pTri'></span><span id='topic+qTri'></span><span id='topic+rTri'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, and random generation 
for the triangular distribution with parameters <code>min</code>, <code>max</code>, 
and <code>mode</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  dTri(x, min = 0, max = 1, mode = 1/2)
  pTri(q, min = 0, max = 1, mode = 1/2)
  qTri(p, min = 0, max = 1, mode = 1/2)
  rTri(n, min = 0, max = 1, mode = 1/2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Triangular_+3A_x">x</code></td>
<td>

<p>vector of quantiles.  Missing values (<code>NA</code>s) are allowed.
</p>
</td></tr>
<tr><td><code id="Triangular_+3A_q">q</code></td>
<td>

<p>vector of quantiles.  Missing values (<code>NA</code>s) are allowed.
</p>
</td></tr>
<tr><td><code id="Triangular_+3A_p">p</code></td>
<td>

<p>vector of probabilities between 0 and 1.  Missing values (<code>NA</code>s) are allowed.
</p>
</td></tr>
<tr><td><code id="Triangular_+3A_n">n</code></td>
<td>

<p>sample size.  If <code>length(n)</code> is larger than 1, then <code>length(n)</code> 
random values are returned.
</p>
</td></tr>
<tr><td><code id="Triangular_+3A_min">min</code></td>
<td>

<p>vector of minimum values of the distribution of the random variable.  
The default value is <code>min=0</code>.
</p>
</td></tr>
<tr><td><code id="Triangular_+3A_max">max</code></td>
<td>

<p>vector of maximum values of the random variable.  
The default value is <code>max=1</code>.
</p>
</td></tr>
<tr><td><code id="Triangular_+3A_mode">mode</code></td>
<td>

<p>vector of modes of the random variable.  
The default value is <code>mode=1/2</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">X</code> be a triangular random variable with parameters <code>min=</code><code class="reqn">a</code>, 
<code>max=</code><code class="reqn">b</code>, and <code>mode=</code><code class="reqn">c</code>.
</p>
<p><em>Probability Density and Cumulative Distribution Function</em> <br />
The density function of <code class="reqn">X</code> is given by:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code class="reqn">f(x; a, b, c) =</code>  </td><td style="text-align: left;">  <code class="reqn">\frac{2(x-a)}{(b-a)(c-a)}</code>  </td><td style="text-align: left;"> for <code class="reqn">a \le x \le c</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
                           </td><td style="text-align: left;">  <code class="reqn">\frac{2(b-x)}{(b-a)(b-c)}</code>  </td><td style="text-align: left;"> for <code class="reqn">c \le x \le b</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>where <code class="reqn">a &lt; c &lt; b</code>.
</p>
<p>The cumulative distribution function of <code class="reqn">X</code> is given by:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code class="reqn">F(x; a, b, c) =</code>  </td><td style="text-align: left;">  <code class="reqn">\frac{(x-a)^2}{(b-a)(c-a)}</code>  </td><td style="text-align: left;"> for <code class="reqn">a \le x \le c</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
                           </td><td style="text-align: left;">  <code class="reqn">1 - \frac{(b-x)^2}{(b-a)(b-c)}</code>  </td><td style="text-align: left;"> for <code class="reqn">c \le x \le b</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>where <code class="reqn">a &lt; c &lt; b</code>.
</p>
<p><em>Quantiles</em> <br />
The <code class="reqn">p^th</code> quantile of <code class="reqn">X</code> is given by:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code class="reqn">x_p =</code>  </td><td style="text-align: left;">  <code class="reqn">a + \sqrt{(b-a)(c-a)p}</code>    </td><td style="text-align: left;"> for <code class="reqn">0 \le p \le F(c)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
                 </td><td style="text-align: left;">  <code class="reqn">b - \sqrt{(b-a)(b-c)(1-p}</code> </td><td style="text-align: left;"> for <code class="reqn">F(c) \le p \le 1</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>where <code class="reqn">0 \le p \le 1</code>.
</p>
<p><em>Random Numbers</em> <br />
Random numbers are generated using the inverse transformation method:
</p>
<p style="text-align: center;"><code class="reqn">x = F^{-1}(u)</code>
</p>

<p>where <code class="reqn">u</code> is a random deviate from a uniform <code class="reqn">[0, 1]</code> distribution. 
</p>
<p><em>Mean and Variance</em> <br />
The mean and variance of <code class="reqn">X</code> are given by:
</p>
<p style="text-align: center;"><code class="reqn">E(X) = \frac{a + b + c}{3}</code>
</p>

<p style="text-align: center;"><code class="reqn">Var(X) = \frac{a^2 + b^2 + c^2 - ab - ac - bc}{18}</code>
</p>



<h3>Value</h3>

<p><code>dTri</code> gives the density, <code>pTri</code> gives the distribution function, 
<code>qTri</code> gives the quantile function, and <code>rTri</code> generates random 
deviates. 
</p>


<h3>Note</h3>

<p>The triangular distribution is so named because of the shape of its probability 
density function.  The average of two independent identically distributed 
uniform random variables with parameters <code>min=</code><code class="reqn">\alpha</code> and 
<code>max=</code><code class="reqn">\beta</code> has a triangular distribution with parameters 
<code>min=</code><code class="reqn">\alpha</code>, <code>max=</code><code class="reqn">\beta</code>, and 
<code>mode=</code><code class="reqn">(\beta-\alpha)/2</code>.
</p>
<p>The triangular distribution is sometimes used as an input distribution in 
probability risk assessment.
</p>


<h3>Author(s)</h3>

<p>Steven P. Millard (<a href="mailto:EnvStats@ProbStatInfo.com">EnvStats@ProbStatInfo.com</a>)
</p>


<h3>References</h3>

<p>Forbes, C., M. Evans, N. Hastings, and B. Peacock. (2011).  Statistical Distributions. 
Fourth Edition. John Wiley and Sons, Hoboken, NJ.
</p>
<p>Johnson, N. L., S. Kotz, and N. Balakrishnan. (1995). 
<em>Continuous Univariate Distributions, Volume 2</em>. 
Second Edition. John Wiley and Sons, New York.
</p>


<h3>See Also</h3>

<p><a href="stats.html#topic+Uniform">Uniform</a>,   
Probability Distributions and Random Numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Density of a triangular distribution with parameters 
  # min=10, max=15, and mode=12, evaluated at 12, 13 and 14: 

  dTri(12:14, 10, 15, 12) 
  #[1] 0.4000000 0.2666667 0.1333333

  #----------

  # The cdf of a triangular distribution with parameters 
  # min=2, max=7, and mode=5, evaluated at 3, 4, and 5: 

  pTri(3:5, 2, 7, 5) 
  #[1] 0.06666667 0.26666667 0.60000000

  #----------

  # The 25'th percentile of a triangular distribution with parameters 
  # min=1, max=4, and mode=3: 

  qTri(0.25, 1, 4, 3) 
  #[1] 2.224745

  #----------

  # A random sample of 4 numbers from a triangular distribution with 
  # parameters min=3 , max=20, and mode=12. 
  # (Note: the call to set.seed simply allows you to reproduce this example.)

  set.seed(10) 
  rTri(4, 3, 20, 12) 
  #[1] 11.811593  9.850955 11.081885 13.539496
</code></pre>

<hr>
<h2 id='Trim'>Trim a Vector
</h2><span id='topic+Trim'></span>

<h3>Description</h3>

<p>Clean data by means of trimming, i.e., by omitting
outlying observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Trim(x, trim = 0.1, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Trim_+3A_x">x</code></td>
<td>
<p>a numeric vector to be trimmed.
</p>
</td></tr>
<tr><td><code id="Trim_+3A_trim">trim</code></td>
<td>
<p>the fraction (0 to 0.5) of observations to be trimmed from each end of x. Values of trim outside that range (and &lt; 1) are taken as the nearest endpoint.
If <code>trim</code> is set to a value &gt;1 it's interpreted as the number of elements to be cut off at each tail of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Trim_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code> values should be stripped before the computation proceeds.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A symmetrically trimmed vector <code>x</code> with a fraction of trim observations (resp. the given number) deleted from each end will be returned. If <code>trim</code> is set to a value &gt;0.5 or to an integer value &gt; n/2 then the result will be <code>NA</code>. </p>


<h3>Value</h3>

<p>The trimmed vector <code>x</code>. The indices of the trimmed values will be attached as attribute named <code>"trim"</code>.
</p>


<h3>Note</h3>

<p>This function is basically an excerpt from the base function <code><a href="base.html#topic+mean">mean</a></code>, which allows the vector <code>x</code> to be trimmed before calculating the mean. But what if a trimmed standard deviation is needed?</p>


<h3>Author(s)</h3>

<p>R-Core (function mean), Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Winsorize">Winsorize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data
set.seed(1234)     # for reproducibility
x &lt;- rnorm(10)     # standard normal
x[1] &lt;- x[1] * 10  # introduce outlier

## Trim data
x
Trim(x, trim=0.1)

## Trim fixed number, say cut the 3 extreme elements from each end
Trim(x, trim=3)

## check function
s &lt;- sample(10:20)
s.tr &lt;- Trim(s, trim = 2)
setequal(c(s[attr(s.tr, "trim")], s.tr), s)
</code></pre>

<hr>
<h2 id='TTestA'>Student's t-Test Based on Sample Statistics</h2><span id='topic+TTestA'></span>

<h3>Description</h3>

<p>Performs one and two sample t-tests based on user supplied summary information instead of data as in <code>t.test()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TTestA(mx, sx, nx, my = NULL, sy = NULL, ny = NULL,
       alternative = c("two.sided", "less", "greater"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TTestA_+3A_mx">mx</code></td>
<td>
<p>a single number representing the sample mean of x.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_my">my</code></td>
<td>
<p>an optional single number representing the sample mean of y.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_sx">sx</code></td>
<td>
<p>a single number representing the sample standard deviation of x.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_sy">sy</code></td>
<td>
<p>an optional single number representing the sample standard deviation of y.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_nx">nx</code></td>
<td>
<p>a single number representing the sample size of x.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_ny">ny</code></td>
<td>
<p>an optional single number representing the sample size of y.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.  You can specify just the initial
letter.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_mu">mu</code></td>
<td>
<p>a number indicating the true value of the mean (or
difference in means if you are performing a two sample test).</p>
</td></tr>
<tr><td><code id="TTestA_+3A_paired">paired</code></td>
<td>
<p>paired = <code>TRUE</code> is not supported here and only present for consistency of arguments. Use the one-sample-test for the differences instead.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_var.equal">var.equal</code></td>
<td>
<p>a logical variable indicating whether to treat the
two variances as being equal. If <code>TRUE</code> then the pooled
variance is used to estimate the variance otherwise the Welch
(or Satterthwaite) approximation to the degrees of freedom is used.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.</p>
</td></tr>
<tr><td><code id="TTestA_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>alternative = "greater"</code> is the alternative that <code>x</code> has a
larger mean than <code>y</code>.
</p>
<p>The option <code>paired</code> is not supported here, as the variance of the differences can't be calculated on the base of the variances of the two samples. However, for calculating the paired test we can simply supply the mean and standard deviation of the differences and use the one-sample test with <code>mu = 0</code>. 
</p>
<p>If
<code>var.equal</code> is <code>TRUE</code> then the pooled estimate of the
variance is used.  By default, if <code>var.equal</code> is <code>FALSE</code>
then the variance is estimated separately for both groups and the
Welch modification to the degrees of freedom is used.
</p>
<p>If the input data are effectively constant (compared to the larger of the
two means) an error is generated.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the t-statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom for the t-statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the mean appropriate to the
specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated mean or difference in means depending on
whether it was a one-sample test or a two-sample test.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the specified hypothesized value of the mean or mean
difference depending on whether it was a one-sample test or a
two-sample test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of t-test was
performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+t.test">t.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Classical example: Student's sleep data
mx &lt;- 0.75
my &lt;- 2.33
sx &lt;- 1.789010
sy &lt;- 2.002249
nx &lt;- ny &lt;- 10
TTestA(mx=mx, my=my, sx=sx, sy=sy, nx=nx, ny=ny)

# compare to
with(sleep, t.test(extra[group == 1], extra[group == 2]))

# use the one sample test for the differences instead of paired=TRUE option
x &lt;- with(sleep, extra[group == 1])
y &lt;- with(sleep, extra[group == 2])

TTestA(mx=mean(x-y), sx=sd(x-y), nx=length(x-y))

# compared to 
t.test(x, y, paired = TRUE)
</code></pre>

<hr>
<h2 id='TukeyBiweight'> Calculate Tukey's Biweight Robust Mean </h2><span id='topic+TukeyBiweight'></span>

<h3>Description</h3>

<p>This calculates a robust average that is unaffected by outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TukeyBiweight(x, const = 9, na.rm = FALSE,
              conf.level = NA, ci.type = "bca", R=1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TukeyBiweight_+3A_x">x</code></td>
<td>
<p> a <code>numeric</code> vector </p>
</td></tr>
<tr><td><code id="TukeyBiweight_+3A_const">const</code></td>
<td>
<p> a constant. <code><var>const</var></code> is preassigned a value of 9
according to the Cook reference below but other values are
possible. </p>
</td></tr>
<tr><td><code id="TukeyBiweight_+3A_na.rm">na.rm</code></td>
<td>
<p>logical, indicating whether <code>NA</code> values should be stripped before the computation proceeds. Defaults to FALSE.
</p>
</td></tr>
<tr><td><code id="TukeyBiweight_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated.
</p>
</td></tr>
<tr><td><code id="TukeyBiweight_+3A_ci.type">ci.type</code></td>
<td>
<p>The type of confidence interval required. The value should be any subset
of the values <code>"basic"</code>, <code>"stud"</code>, <code>"perc"</code>, <code>"bca"</code> or simply <code>"all"</code>
which will compute all four types of intervals.
</p>
</td></tr>
<tr><td><code id="TukeyBiweight_+3A_r">R</code></td>
<td>
<p>The number of bootstrap replicates. Usually this will be a single positive integer. For importance resampling,
some resamples may use one set of weights and others use a different set of weights. In this case <code>R</code> would be a vector
of integers where each component gives the number of resamples from each of the rows of weights.
</p>
</td></tr>
<tr><td><code id="TukeyBiweight_+3A_...">...</code></td>
<td>
<p>the dots are passed to the function <code><a href="boot.html#topic+boot">boot</a></code>, when confidence intervalls are calculated.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a one step computation that follows the Affy whitepaper below,
see page 22. <code><var>const</var></code> determines the point at which
outliers are given a weight of 0 and therefore do not contribute to
the calculation of the mean.  <code><var>const</var> = 9</code> sets values roughly
+/-6 standard deviations to 0. <code><var>const</var> = 6</code> is also used in
tree-ring chronology development. Cook and Kairiukstis (1990) have
further details.
</p>
<p>An exact summation algorithm (Shewchuk 1997) is used. When some
assumptions about the rounding of floating point numbers and
conservative compiler optimizations hold, summation error is
completely avoided.  Whether the assumptions hold depends on the
platform, i.e. compiler and <abbr><span class="acronym">CPU</span></abbr>.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> mean.
</p>


<h3>Author(s)</h3>

<p> Mikko Korpela &lt;mikko.korpela@aalto.fi&gt; </p>


<h3>References</h3>

<p>Statistical Algorithms Description Document, 2002, Affymetrix.
</p>
<p>Cook, E. R. and Kairiukstis, L. A. (1990) <em>Methods of
Dendrochronology: Applications in the Environmental Sciences</em>.
Springer.  <abbr><span class="acronym">ISBN-13</span></abbr>: 978-0792305866.
</p>
<p>Mosteller, F. and Tukey, J. W. (1977) <em>Data Analysis and
Regression: a second course in statistics</em>.  Addison-Wesley.
<abbr><span class="acronym">ISBN-13</span></abbr>: 978-0201048544.
</p>
<p>Shewchuk, J. R. (1997) Adaptive Precision Floating-Point Arithmetic
and Fast Robust Geometric Predicates.  <em>Discrete and
Computational Geometry</em>, 18(3):305-363. Springer.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+HuberM">HuberM</a></code>, <code><a href="#topic+Range">Range</a></code>, <code><a href="#topic+RobScale">RobScale</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>TukeyBiweight(rnorm(100))
</code></pre>

<hr>
<h2 id='TwoGroups'>Describe a Variable by a Factor with Two Levels
</h2><span id='topic+TwoGroups'></span><span id='topic+TwoGroups.default'></span><span id='topic+TwoGroups.formula'></span><span id='topic+ToWrd.TwoGroups'></span>

<h3>Description</h3>

<p>This function describes a numeric variable by a grouping factor with two levels. First, a descriptive text listing the frequencies and means of the two groups and the results of the significance test is generated. The results of <code>Desc(x~g)</code> are reported as they are provided by the function, followed by a plot consisting of a density plot and a box plot.
This description makes sense, for example, if the age distribution of a collective is to be represented for both sexes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
TwoGroups(x, ..., plotit = TRUE)

## Default S3 method:
TwoGroups(x, g, main = NULL, vname = NULL, ..., plotit = TRUE)

## S3 method for class 'formula'
TwoGroups(formula, data, subset, na.action, ...)

## S3 method for class 'TwoGroups'
ToWrd(x, font = NULL, ..., wrd = DescToolsOptions("lastWord"))

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TwoGroups_+3A_x">x</code></td>
<td>
<p>the numeric variable to describe.
</p>
</td></tr>
<tr><td><code id="TwoGroups_+3A_g">g</code></td>
<td>
<p>the grouping factor (preferably with two levels.)
</p>
</td></tr>
<tr><td><code id="TwoGroups_+3A_main">main</code></td>
<td>
<p>the main title.
</p>
</td></tr>
<tr><td><code id="TwoGroups_+3A_vname">vname</code></td>
<td>
<p>the variable names used in the description text.
</p>
</td></tr>
<tr><td><code id="TwoGroups_+3A_plotit">plotit</code></td>
<td>
<p>boolean. Should a plot be created? Default can be defined by <code>DescToolsOptions(plotit=TRUE/FALSE)</code>, if it does not exist then it's set to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="TwoGroups_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>  
<tr><td><code id="TwoGroups_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>. 
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>  
<tr><td><code id="TwoGroups_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>  
<tr><td><code id="TwoGroups_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>  
<tr><td><code id="TwoGroups_+3A_font">font</code></td>
<td>
<p>the first font will be chosen for the introducing text, when sending the output to Word, the second for the description.
</p>
</td></tr>
<tr><td><code id="TwoGroups_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a running MS Word instance, as created by GetNewWrd() (for a new one) or by GetCurrWrd() for an existing one. Default is <code>NULL</code>, which will report all results to the console.
</p>
</td></tr>
<tr><td><code id="TwoGroups_+3A_...">...</code></td>
<td>
<p>the dots are sent to the internally used function <code><a href="#topic+Phrase">Phrase</a>()</code>. They can be used to choose the language (<code>lang</code>) or provide variable name (<code>xname</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the results calculated by the used functions
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Desc">Desc</a></code>, <code><a href="#topic+PlotMultiDens">PlotMultiDens</a></code>, <code><a href="#topic+Phrase">Phrase</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- d.pizza$temperature
g &lt;- factor(d.pizza$rabate)

# we can change the colors for the plot by setting the DescToolsOptions
DescToolsOptions(col=c(horange, hgreen))
TwoGroups(x, g, main="Temperature ~ Rebate")

# for an output to Word simply define the wrd argument
# wrd &lt;- GetNewWrd()
# TwoGroups(x, g, font.desc=list(name="Consolas", size=8),
#           main="Temperature ~ Rebate", wrd=wrd)
</code></pre>

<hr>
<h2 id='UncertCoef'>Uncertainty Coefficient
</h2><span id='topic+UncertCoef'></span>

<h3>Description</h3>

<p>The uncertainty coefficient U(C|R) measures the proportion of uncertainty (entropy) in the column
variable Y that is explained by the row variable X. The function has interfaces for a table, a matrix, a data.frame and for single vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UncertCoef(x, y = NULL, direction = c("symmetric", "row", "column"), 
           conf.level = NA, p.zero.correction = 1/sum(x)^2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UncertCoef_+3A_x">x</code></td>
<td>
<p>a numeric vector, a factor, matrix or data frame. 
</p>
</td></tr>
<tr><td><code id="UncertCoef_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or a vector, an ordered factor, matrix or data frame with compatible dimensions to x. 
</p>
</td></tr>
<tr><td><code id="UncertCoef_+3A_direction">direction</code></td>
<td>
<p>direction of the calculation. Can be <code>"row"</code> (default) or <code>"column"</code>, where
<code>"row"</code> calculates UncertCoef (R|C) (&quot;column dependent&quot;).
</p>
</td></tr>
<tr><td><code id="UncertCoef_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval. If set to <code>NA</code> (which is the default) no confidence interval will be calculated. 
</p>
</td></tr>
<tr><td><code id="UncertCoef_+3A_p.zero.correction">p.zero.correction</code></td>
<td>
<p>slightly nudge zero values so that their logarithm can be calculated 
</p>
</td></tr>
<tr><td><code id="UncertCoef_+3A_...">...</code></td>
<td>
<p>further arguments are passed to the function <code><a href="base.html#topic+table">table</a></code>, allowing i.e. to set useNA. This refers only to the vector interface.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The uncertainty coefficient is computed as </p>
<p style="text-align: center;"><code class="reqn">U(C|R) = \frac{H(X) + H(Y) - H(XY)}{H(Y)} </code>
</p>
<p> and 
ranges from [0, 1]. <br />
</p>


<h3>Value</h3>

<p>Either a single numeric value, if no confidence interval is required, <br />
or a vector with 3 elements for estimate, lower and upper confidence intervall. 
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; strongly based on code from Antti Arppe &lt;antti.arppe@helsinki.fi&gt;
</p>


<h3>References</h3>

<p>Theil, H. (1972), <em>Statistical Decomposition Analysis</em>, Amsterdam: North-Holland Publishing Company.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Entropy">Entropy</a></code>, <code><a href="#topic+Lambda">Lambda</a></code>, <code><a href="#topic+Assocs">Assocs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example from Goodman Kruskal (1954)

m &lt;- as.table(cbind(c(1768,946,115), c(807,1387,438), c(189,746,288), c(47,53,16)))
dimnames(m) &lt;- list(paste("A", 1:3), paste("B", 1:4))
m

# direction default is "symmetric"
UncertCoef(m)
UncertCoef(m, conf.level=0.95)

UncertCoef(m, direction="row")
UncertCoef(m, direction="column")
</code></pre>

<hr>
<h2 id='UnirootAll'>
Finds many (all) roots of one equation within an interval
</h2><span id='topic+UnirootAll'></span>

<h3>Description</h3>

<p>The function <code>UnirootAll</code> searches the interval from lower to upper
for several roots (i.e., zero's) of a function <code>f</code> with respect to
its first argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UnirootAll(f, interval, lower = min(interval), upper = max(interval),
            tol = .Machine$double.eps^0.5, maxiter = 1000, n = 100, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UnirootAll_+3A_f">f</code></td>
<td>
<p>the function for which the root is sought.
</p>
</td></tr>
<tr><td><code id="UnirootAll_+3A_interval">interval</code></td>
<td>
<p>a vector containing the end-points of the interval to
be searched for the root.
</p>
</td></tr>
<tr><td><code id="UnirootAll_+3A_lower">lower</code></td>
<td>
<p>the lower end point of the interval to be searched.
</p>
</td></tr>
<tr><td><code id="UnirootAll_+3A_upper">upper</code></td>
<td>
<p>the upper end point of the interval to be searched.
</p>
</td></tr>
<tr><td><code id="UnirootAll_+3A_tol">tol</code></td>
<td>
<p>the desired accuracy (convergence tolerance).
</p>
</td></tr>
<tr><td><code id="UnirootAll_+3A_maxiter">maxiter</code></td>
<td>
<p>the maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="UnirootAll_+3A_n">n</code></td>
<td>
<p>number of subintervals in which the root is sought.
</p>
</td></tr>
<tr><td><code id="UnirootAll_+3A_...">...</code></td>
<td>
<p>additional named or unnamed arguments to be passed to <code>f</code>
(but beware of partial matching to other arguments).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>f</code> will be called as <code>f(x, ...)</code> for a numeric value of <code>x</code>.
</p>
<p>Run <code>demo(Jacobandroots)</code> for an example of the use of <code>UnirootAll</code>
for steady-state analysis.
</p>
<p>See also second example of <code>gradient</code>
This example is discussed in the book by Soetaert and Herman (2009).
</p>


<h3>Value</h3>

<p>a vector with the roots found in the interval
</p>


<h3>Note</h3>

<p>This is a verbatim copy from rootSolve::uniroot.all (v. 1.7).</p>


<h3>Note</h3>

<p>The function calls <code>uniroot</code>, the basic R-function.
</p>
<p>It is not guaranteed that all roots will be recovered.
</p>
<p>This will depend on <code>n</code>, the number of subintervals in which the
interval is divided.
</p>
<p>If the function &quot;touches&quot; the X-axis (i.e. the root is a saddle point),
then this root will generally not be retrieved.
(but chances of this are pretty small).
</p>
<p>Whereas <code>unitroot</code> passes values one at a time to the function,
<code>UnirootAll</code> passes a vector of values to the function.
Therefore <code>f</code> should be written such that it can handle a vector of values.
See last example.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+uniroot">uniroot</a></code> for more information about input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## =======================================================================
##   Mathematical examples
## =======================================================================

# a well-behaved case...
fun &lt;- function (x) cos(2*x)^3

curve(fun(x), 0, 10,main = "UnirootAll")

All &lt;- UnirootAll(fun, c(0, 10))
points(All, y = rep(0, length(All)), pch = 16, cex = 2)

# a difficult case...
f &lt;- function (x) 1/cos(1+x^2)
AA &lt;- UnirootAll(f, c(-5, 5))
curve(f(x), -5, 5, n = 500, main = "UnirootAll")
points(AA, rep(0, length(AA)), col = "red", pch = 16)

f(AA)  # !!!


## =======================================================================
## Vectorisation:
## =======================================================================
# from R-help Digest, Vol 130, Issue 27
# https://stat.ethz.ch/pipermail/r-help/2013-December/364799.html

integrand1 &lt;- function(x) 1/x*dnorm(x)
integrand2 &lt;- function(x) 1/(2*x-50)*dnorm(x)
integrand3 &lt;- function(x, C) 1/(x+C)

res &lt;- function(C) {
  integrate(integrand1, lower = 1, upper = 50)$value +
  integrate(integrand2, lower = 50, upper = 100)$value -
  integrate(integrand3, C = C, lower = 1, upper = 100)$value
}

# uniroot passes one value at a time to the function, so res can be used as such
uniroot(res, c(1, 1000))

# Need to vectorise the function to use UnirootAll:
res &lt;- Vectorize(res)
UnirootAll(res, c(1,1000))

</code></pre>

<hr>
<h2 id='Untable'>Recover Original Data From Contingency Table</h2><span id='topic+Untable'></span><span id='topic+Untable.default'></span><span id='topic+Untable.data.frame'></span>

<h3>Description</h3>

<p>Recreates the data.frame out of a contingency table x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Untable(x, ...)

## S3 method for class 'data.frame'
Untable(x, freq = "Freq", rownames = NULL, ...)

## Default S3 method:
Untable(x, dimnames = NULL, type = NULL, rownames = NULL, colnames = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Untable_+3A_x">x</code></td>
<td>
<p>a numeric vector, a matrix, a table or a data.frame. If x is a vector, a matrix or a table it is  interpreted as frequencies which are to be inflated to the original list. <br /> If x is a data.frame it is interpreted as a table in frequency form (containing one or more factors and a frequency variable).
</p>
</td></tr>
<tr><td><code id="Untable_+3A_dimnames">dimnames</code></td>
<td>
<p>the dimension names of x to be used for expanding. Can be used to expand a weight vector to its original values. If set to <code>NULL</code> (default) the dimnames of x will be used.</p>
</td></tr>
<tr><td><code id="Untable_+3A_type">type</code></td>
<td>
<p>defines the data type generated. This allows to directly define factors or ordered factors, but also numeric values. See examples.
</p>
</td></tr>
<tr><td><code id="Untable_+3A_rownames">rownames</code></td>
<td>
<p>A names vector for the rownames of the resulting data.frame. If set to <code>NULL</code> (default) the 
names will be defined according to the table's dimnames.
</p>
</td></tr>
<tr><td><code id="Untable_+3A_colnames">colnames</code></td>
<td>
<p>A names vector for the colnames of the resulting data.frame. If set to <code>NULL</code> (default) the 
names will be defined according to the table's dimnames.
</p>
</td></tr>
<tr><td><code id="Untable_+3A_freq">freq</code></td>
<td>
<p>character, the name of the frequency variable in case x is a data.frame.</p>
</td></tr>
<tr><td><code id="Untable_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from functions (not used here).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For x being a vector this reduces to <code>rep(..., n)</code> with n as vector (which is not supported by <code>rep()</code>). <code>NA</code>s in the table will be treated as 0 without raising an error.
</p>


<h3>Value</h3>

<p>a data.frame with the detailed data 
(even if x was a 1-dimensional table)
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+expand.grid">expand.grid</a></code>, <code><a href="base.html#topic+rep">rep</a></code>, <code><a href="base.html#topic+gl">gl</a></code>, <code><a href="stats.html#topic+xtabs">xtabs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d.titanic &lt;- Untable(Titanic)
str(d.titanic)

# ... not the same as:
data.frame(Titanic)


tab &lt;- table(set1=sample(letters[1:5], size=40, replace=TRUE), 
             set2=sample(letters[11:15], size=40, replace=TRUE))
Untable(tab)


# return a numeric vector by setting type and coerce to a vector by [,]
Untable(c(6,2,2), type="as.numeric")[,]


# how to produce the original list based on frequencies, given as a data.frame
d.freq &lt;- data.frame(xtabs(Freq ~ Sex + Survived, data=Titanic))

# a data list with each individual
d.data &lt;- Untable( xtabs(c(1364, 126, 367, 344) ~ ., 
             expand.grid(levels(d.freq$Sex),levels(d.freq$Survived)))) 
head(d.data)

# expand a weights vector
Untable(c(1,4,5), dimnames=list(c("Zurich","Berlin","London")))

# and the same with a numeric vector 
Untable(c(1,4,5), dimnames=list(c(5,10,15)), type="as.numeric")[,]
# ... which again is nothing else than
rep(times=c(1,4,5), x=c(5,10,15))

# the data.frame interface
d.freq &lt;- data.frame(f1=c("A","A","B","B"), f2=c("C","D","C","D"), Freq=c(1,2,3,4))
Untable(d.freq)
</code></pre>

<hr>
<h2 id='Unwhich'>Inverse Which
</h2><span id='topic+Unwhich'></span>

<h3>Description</h3>

<p>The inverse function to <code><a href="base.html#topic+which">which</a></code> creates a logical
vector/matrix from indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Unwhich(idx, n, useNames = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Unwhich_+3A_idx">idx</code></td>
<td>
<p>the indices as returned by <code><a href="base.html#topic+which">which</a></code>.
</p>
</td></tr>
<tr><td><code id="Unwhich_+3A_n">n</code></td>
<td>
<p>integer, the length of the original vector.
</p>
</td></tr>
<tr><td><code id="Unwhich_+3A_usenames">useNames</code></td>
<td>
<p>logical, determining if the names of the indices should be preserved.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a logical vector of the length n, with <code>TRUE</code> on the positions <code>i</code>.
</p>


<h3>Author(s)</h3>

<p>Nick Sabbe
</p>


<h3>References</h3>

<p><a href="https://stackoverflow.com/questions/7659833/inverse-of-which">https://stackoverflow.com/questions/7659833/inverse-of-which</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+which">which</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ll &lt;- c(TRUE, FALSE, TRUE, NA, FALSE, FALSE, TRUE)
names(ll) &lt;- letters[seq(ll)]
i &lt;- which(ll)
# back again (loosing the names of the FALSEs)
Unwhich(i, length(ll))
</code></pre>

<hr>
<h2 id='VanWaerdenTest'>van der Waerden Test</h2><span id='topic+VanWaerdenTest'></span><span id='topic+VanWaerdenTest.default'></span><span id='topic+VanWaerdenTest.formula'></span>

<h3>Description</h3>

<p>Performs a van der Waerden normal scores test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VanWaerdenTest(x, ...)
  
## Default S3 method:
VanWaerdenTest(x, g, ...)

## S3 method for class 'formula'
VanWaerdenTest(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VanWaerdenTest_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, or a list of numeric data
vectors.  Non-numeric elements of a list will be coerced, with a
warning.</p>
</td></tr>
<tr><td><code id="VanWaerdenTest_+3A_g">g</code></td>
<td>
<p>a vector or factor object giving the group for the
corresponding elements of <code>x</code>.  Ignored with a warning if
<code>x</code> is a list.</p>
</td></tr>
<tr><td><code id="VanWaerdenTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>response ~ group</code> where
<code>response</code> gives the data values and <code>group</code> a vector or
factor of the corresponding groups.</p>
</td></tr> 
<tr><td><code id="VanWaerdenTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="VanWaerdenTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="VanWaerdenTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="VanWaerdenTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>VanWaerdenTest</code> performs a van der Waerden test of the
null that the location parameters of the distribution of <code>x</code>
are the same in each group (sample). The alternative is that they
differ in at least one.
</p>
<p>The van der Waerden rank scores are defined  as the ranks of data, i.e., <code class="reqn">R[i], i = 1, 2, ..., n</code>, divided by <code class="reqn">1 + n</code> transformed to a normal score by applying the inverse of the normal distribution function, i.e., <code class="reqn">\Phi^(-1)(R[i]/(1 + n))</code>. The ranks of data are obtained by ordering the observations from all groups (the same way as <code><a href="stats.html#topic+kruskal.test">kruskal.test</a></code> does it).
</p>
<p>If <code>x</code> is a list, its elements are taken as the samples to be
compared, and hence have to be numeric data vectors.  In this case,
<code>g</code> is ignored, and one can simply use <code>VanWaerdenTest(x)</code>
to perform the test.  If the samples are not yet contained in a
list, use <code>VanWaerdenTest(list(x, ...))</code>.
</p>
<p>Otherwise, <code>x</code> must be a numeric data vector, and <code>g</code> must
be a vector or factor object of the same length as <code>x</code> giving
the group for the corresponding elements of <code>x</code>.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the van der Waerden statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom of the approximate
chi-squared distribution of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string <code>"van-der-Waerden normal scores test"</code>.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Conover, W. J., Iman, R. L. (1979). On multiple-comparisons procedures, Tech. Rep. LA-7677-MS, Los Alamos Scientific Laboratory.
</p>
<p>Conover, W. J. (1999). <em>Practical Nonparameteric Statistics</em> (Third Edition ed.). Wiley. pp. 396406. 
</p>


<h3>See Also</h3>

<p><code><a href="coin.html#topic+LocationTests">normal_test</a></code> in package
<a href="https://CRAN.R-project.org/package=coin"><span class="pkg">coin</span></a> where the test is implemented in a more general context (but has a quite unpractical interface).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Hollander &amp; Wolfe (1973), 116.
## Mucociliary efficiency from the rate of removal of dust in normal
##  subjects, subjects with obstructive airway disease, and subjects
##  with asbestosis.
x &lt;- c(2.9, 3.0, 2.5, 2.6, 3.2) # normal subjects
y &lt;- c(3.8, 2.7, 4.0, 2.4)      # with obstructive airway disease
z &lt;- c(2.8, 3.4, 3.7, 2.2, 2.0) # with asbestosis

VanWaerdenTest(list(x, y, z))

## Equivalently,
x &lt;- c(x, y, z)
g &lt;- factor(rep(1:3, c(5, 4, 5)),
            labels = c("Normal subjects",
                       "Subjects with obstructive airway disease",
                       "Subjects with asbestosis"))
VanWaerdenTest(x, g)

## Formula interface.
require(graphics)
boxplot(Ozone ~ Month, data = airquality)
VanWaerdenTest(Ozone ~ Month, data = airquality)
</code></pre>

<hr>
<h2 id='Var'>Variance</h2><span id='topic+Var'></span><span id='topic+Var.default'></span><span id='topic+Var.Freq'></span><span id='topic+VarN'></span>

<h3>Description</h3>

<p><code>Var()</code> computes the variance of <code>x</code>.  If <code>x</code> is a matrix variances of the columns of <code>x</code> are computed. <code>Varn</code> returns the uncorrected sample variance (which is biased estimator for the sample variance). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Var(x, ...)

## S3 method for class 'Freq'
Var(x, breaks, ...)

## Default S3 method:
Var(x, weights = NULL, na.rm = FALSE, method = c("unbiased",  "ML"), ...)

VarN(x, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Var_+3A_x">x</code></td>
<td>
<p>a numeric vector, matrix or data frame.</p>
</td></tr>
<tr><td><code id="Var_+3A_weights">weights</code></td>
<td>
<p>a numerical vector of weights the same length as <code>x</code> giving the weights to use for elements of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="Var_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed?</p>
</td></tr>
<tr><td><code id="Var_+3A_method">method</code></td>
<td>
<p>determines the estimator type; if <code>"unbiased"</code> (the default) then the usual unbiased estimate (using Bessel's correction) is returned, if <code>"ML"</code> then it is the maximum likelihood estimate for a Gaussian distribution. Uses stats:cov.wt for both methods.</p>
</td></tr>
<tr><td><code id="Var_+3A_breaks">breaks</code></td>
<td>
<p>breaks for calculating the variance for classified data as composed by <code><a href="#topic+Freq">Freq</a></code>.</p>
</td></tr>
<tr><td><code id="Var_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Var</code> is just another interface to <code>Cov</code>.
</p>
<p>The denominator <code class="reqn">n - 1</code> is used which gives an unbiased estimator
of the (co)variance for i.i.d. observations.
These functions return <code><a href="base.html#topic+NA">NA</a></code> when there is only one
observation (whereas S-PLUS has been returning <code>NaN</code>), and
fail if <code>x</code> has length zero.
</p>


<h3>Value</h3>

<p>For <code>r &lt;- Cor(*, use = "all.obs")</code>, it is now guaranteed that
<code>all(abs(r) &lt;= 1)</code>.
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
<em>The New S Language</em>.
Wadsworth &amp; Brooks/Cole.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, <code><a href="stats.html#topic+cov">cov</a></code> for covariance and correlation matrices
</p>
<p><code><a href="stats.html#topic+cor.test">cor.test</a></code> for confidence intervals (and tests).
</p>
<p><code><a href="stats.html#topic+cov.wt">cov.wt</a></code> for <em>weighted</em> covariance computation.
</p>
<p><code><a href="stats.html#topic+sd">sd</a></code> for standard deviation (vectors).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Var(1:10)  # 9.166667

Var(1:5, 1:5) # 2.5

# weighted Variance
set.seed(45)
(z &lt;- as.numeric(names(w &lt;- table(x &lt;- sample(-10:20, size=50, replace=TRUE)))))
Var(z, w=w)

# check!
all.equal(Var(x), Var(z, w=w))


# Variance for frequency tables
Var(Freq(as.table(c(6,16,24,25,17))),
     breaks=c(0, 10, 20, 30, 40, 50))
     
</code></pre>

<hr>
<h2 id='VarCI'>Confidence Intervals for the Variance
</h2><span id='topic+VarCI'></span>

<h3>Description</h3>

<p>Calculates confidence intervals for the variance. Available approachs are the classical one using the ChiSquare distribution, a more robust version proposed by Bonett and the bootstrap options available in the package <code>boot</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VarCI(x, method = c("classic", "bonett", "norm", "basic", "stud", "perc", "bca"),
      conf.level = 0.95, sides = c("two.sided", "left", "right"),
      na.rm = FALSE, R = 999)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarCI_+3A_x">x</code></td>
<td>
<p>a (non-empty) numeric vector of data values.
</p>
</td></tr>
<tr><td><code id="VarCI_+3A_method">method</code></td>
<td>
<p>vector of character strings representing the type of intervals required. The value should be any subset of the values <code>"classic"</code>, <code>"bonett"</code>, <code>"norm"</code>, <code>"basic"</code>,  <code>"stud"</code>,  <code>"perc"</code>,  <code>"bca"</code>.
See <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>.
</p>
</td></tr>
<tr><td><code id="VarCI_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the interval.
</p>
</td></tr>
<tr><td><code id="VarCI_+3A_sides">sides</code></td>
<td>
<p>a character string specifying the side of the confidence interval, must be one of <code>"two.sided"</code> (default), <code>"left"</code> or <code>"right"</code>. You can specify just the initial letter. <code>"left"</code> would be analogue to a hypothesis of <code>"greater"</code> in a <code>t.test</code>.</p>
</td></tr>
<tr><td><code id="VarCI_+3A_na.rm">na.rm</code></td>
<td>
<p>logical. Should missing values be removed? Defaults to FALSE.
</p>
</td></tr>
<tr><td><code id="VarCI_+3A_r">R</code></td>
<td>
<p>number of bootstrap replicates. Usually this will be a single positive integer. For importance resampling, some resamples may use one set of weights and others use a different set of weights. In this case R would be a vector of integers where each component gives the number of resamples from each of the rows of weights.
See <code><a href="boot.html#topic+boot">boot</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence interval for the variance is very sensitive to non-normality in the data. Bonett (2006) has proposed an interval that is nearly exact when the data is normally distributed and provides good performance for moderately non-normal data.
See the references for the details.</p>


<h3>Value</h3>

<p>a numeric vector with 3 elements:
</p>
<table>
<tr><td><code>var</code></td>
<td>
<p>variance</p>
</td></tr>
<tr><td><code>lwr.ci</code></td>
<td>
<p>lower bound of the confidence interval</p>
</td></tr>
<tr><td><code>upr.ci</code></td>
<td>
<p>upper bound of the confidence interval</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>References</h3>

<p>Bonett (2006) Approximate Confidence Interval for Standard Deviation of Nonnormal Distributions, <em>Computational Statistics and Data Analysis</em>, Vol. 50, pp. 775 - 782.<br />
https://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/sdconfli.htm (might be outdated)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MeanCI">MeanCI</a></code>, <code><a href="#topic+MedianCI">MedianCI</a></code>, <code><a href="#topic+VarTest">VarTest</a></code>, <code><a href="#topic+Var">Var</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>VarCI(d.pizza$price, na.rm=TRUE)
VarCI(d.pizza$price, conf.level=0.99, na.rm=TRUE)

x &lt;- c(14.816, 14.863, 14.814, 14.998, 14.965, 14.824, 14.884, 14.838, 14.916,
       15.021, 14.874, 14.856, 14.860, 14.772, 14.980, 14.919)
VarCI(x, conf.level=0.9)

# and for the standard deviation
sqrt(VarCI(x, conf.level=0.9))


# from Bonett's paper
# expected results:
# ------------------------------------
#  conf.lvl       sd      lci      uci
# ------------------------------------
#      90.0   0.5168   0.3592   0.9359
#      95.0   0.5168   0.3263   1.0841
#      99.0   0.5168   0.2607   1.5109

p &lt;- c(15.83, 16.01, 16.24, 16.42, 15.33, 15.44, 16.88, 16.31)
sqrt(VarCI(p, method="bonett", conf.level=0.9))
sqrt(VarCI(p, method="bonett"))
sqrt(VarCI(p, method="bonett", conf.level=0.99))

# some bootstrap intervals
VarCI(x, method="norm")
VarCI(x, method="perc")
VarCI(x, method="bca")
</code></pre>

<hr>
<h2 id='VarTest'>ChiSquare Test for One Variance and F Test to Compare Two Variances</h2><span id='topic+VarTest'></span><span id='topic+VarTest.default'></span><span id='topic+VarTest.formula'></span>

<h3>Description</h3>

<p>Performs either a one sample chi-squared test to compare the variance of a vector with a given value or an F test to compare the variances of two samples from normal populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VarTest(x, ...)

## Default S3 method:
VarTest(x, y,
        alternative = c("two.sided", "less", "greater"),
        ratio = 1, sigma.squared = 1,
        conf.level = 0.95, ...)

## S3 method for class 'formula'
VarTest(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarTest_+3A_x">x</code>, <code id="VarTest_+3A_y">y</code></td>
<td>
<p>numeric vectors of data values.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.  You can specify just the initial
letter.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_ratio">ratio</code></td>
<td>
<p>the hypothesized ratio of the population variances of
<code>x</code> and <code>y</code>.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_sigma.squared">sigma.squared</code></td>
<td>
<p>a number indicating the true value of the variance, if one sample test is requested.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level for the returned confidence
interval.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code>
is a numeric variable giving the data values and <code>rhs</code> a factor
with two levels giving the corresponding groups.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see
<code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the
formula <code>formula</code>.  By default the variables are taken from
<code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  Defaults to
<code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="VarTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula interface is only applicable for the 2-sample tests.
</p>
<p>The null hypothesis is that the ratio of the variances of the
populations from which <code>x</code> and <code>y</code> were drawn, or in the
data to which the linear models <code>x</code> and <code>y</code> were fitted, is
equal to <code>ratio</code>.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the F test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of the freedom of the F distribution of
the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the ratio of the population
variances.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the ratio of the sample variances of <code>x</code> and
<code>y</code>.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the ratio of population variances under the null.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string
<code>"F test to compare two variances"</code>.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the names of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; (One sample test)<br />
Two Sample test and help text from R-Core.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+var.test">var.test</a></code>, <code><a href="stats.html#topic+bartlett.test">bartlett.test</a></code> for testing homogeneity of variances in
more than two samples from normal distributions;
<code><a href="stats.html#topic+ansari.test">ansari.test</a></code> and <code><a href="stats.html#topic+mood.test">mood.test</a></code> for two rank
based (nonparametric) two-sample tests for difference in scale.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(50, mean = 0, sd = 2)

# One sample test
VarTest(x, sigma.squared = 2.5)

# two samples
y &lt;- rnorm(30, mean = 1, sd = 1)
VarTest(x, y)                  # Do x and y have the same variance?
VarTest(lm(x ~ 1), lm(y ~ 1))  # The same.
</code></pre>

<hr>
<h2 id='VecRot'>Vector Rotation (Shift Elements)
</h2><span id='topic+VecRot'></span><span id='topic+VecShift'></span>

<h3>Description</h3>

<p>Shift the elements of a vector in circular mode by <code>k</code> elements to the right (for positive k) or to the left (for negative k), such that the first element is at the (k+1)th position of the new vector and the last k elements are appended to the beginning.<br /> <code>VecShift</code> does not attach the superfluous elements on one side to the other, but fills the resulting gaps with <code>NA</code>s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VecRot(x, k = 1)
VecShift(x, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VecRot_+3A_x">x</code></td>
<td>
<p>a vector of any type.
</p>
</td></tr>
<tr><td><code id="VecRot_+3A_k">k</code></td>
<td>
<p>the number of elements to shift.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will repeat the vector two times and select the appropriate number of elements from the required shift on.
</p>


<h3>Value</h3>

<p>the shifted vector in the same dimensions as x.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic++5B">[</a></code>, <code><a href="base.html#topic+rep">rep</a></code>, <code><a href="stats.html#topic+lag">lag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>VecRot(c(1,1,0,0,3,4,8), 3)

VecRot(letters[1:10], 3)
VecRot(letters[1:10], -3)

VecShift(letters[1:10], 3)
VecShift(letters[1:10], -3)

</code></pre>

<hr>
<h2 id='VIF'>Variance Inflation Factors</h2><span id='topic+VIF'></span>

<h3>Description</h3>

<p>Calculates variance-inflation and generalized variance-inflation factors
for linear and generalized linear models. It's a measure describing how much the variance of an estimated coefficient is increased because of collinearity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VIF(mod)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VIF_+3A_mod">mod</code></td>
<td>
<p>an object that responds to <code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>, and
<code><a href="stats.html#topic+model.matrix">model.matrix</a></code>, such as an <code>lm</code> or <code>glm</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If all terms in an unweighted linear model have 1 df, then the usual variance-inflation
factors are calculated.
</p>
<p>The vif are defined as
</p>
<p style="text-align: center;"><code class="reqn">vif_j=\frac{1}{1-R_j^2}</code>
</p>

<p>where <code class="reqn">R_j^2</code> equals the coefficient of determination for regressing the explanatory variable <code>j</code> in question on the other terms in the model. This is one of the well-known collinearity diagnostics.
</p>
<p>If any terms in an unweighted linear model have more than 1 df, then generalized variance-inflation factors
(Fox and Monette, 1992) are calculated. These are interpretable as the inflation
in size of the confidence ellipse or ellipsoid for the coefficients of the term in
comparison with what would be obtained for orthogonal data.
</p>
<p>The generalized vifs
are invariant with respect to the coding of the terms in the model (as long as
the subspace of the columns of the model matrix pertaining to each term is
invariant). To adjust for the dimension of the confidence ellipsoid, the function
also prints <code class="reqn">GVIF^{1/(2\times df)}</code> where <code class="reqn">df</code> is the degrees of freedom
associated with the term.
</p>
<p>Through a further generalization, the implementation here is applicable as well to other sorts of models,
in particular weighted linear models and  generalized linear models.
</p>
<p>Values of vif up to 5 are usually interpreted as uncritical, values above 5 denote a considerable multicollinearity.
</p>


<h3>Value</h3>

<p>A vector of vifs, or a matrix containing one row for each term in the model, and
columns for the GVIF, df, and <code class="reqn">GVIF^{1/(2\times df)}</code>.
</p>


<h3>Note</h3>

<p>This is a verbatim copy from the function <code>car::vif</code>.</p>


<h3>Author(s)</h3>

<p>Henric Nilsson and John Fox <a href="mailto:jfox@mcmaster.ca">jfox@mcmaster.ca</a></p>


<h3>References</h3>

<p>Fox, J. and Monette, G. (1992)
Generalized collinearity diagnostics.
<em>JASA</em>, <b>87</b>, 178&ndash;183.
</p>
<p>Fox, J. (2008)
<em>Applied Regression Analysis and Generalized Linear Models</em>,
Second Edition. Sage.
</p>
<p>Fox, J. and Weisberg, S. (2011)
<em>An R Companion to Applied Regression</em>, Second Edition, Sage.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>VIF(lm(Fertility ~ Agriculture + Education, data=swiss))
VIF(lm(Fertility ~ ., data=swiss))
</code></pre>

<hr>
<h2 id='Vigenere'>Vigenere Cypher</h2><span id='topic+Vigenere'></span>

<h3>Description</h3>

<p>Implements a Vigenere cypher, both encryption and decryption. The function handle keys and text of unequal length and discards non-alphabetic characters. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Vigenere(x, key = NULL, decrypt = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Vigenere_+3A_x">x</code></td>
<td>
<p>the text to be encrypted
</p>
</td></tr>
<tr><td><code id="Vigenere_+3A_key">key</code></td>
<td>
<p>the key to be used. If this remains to <code>NULL</code> the PasswordDlg will be presented and the key can be entered there.
</p>
</td></tr>
<tr><td><code id="Vigenere_+3A_decrypt">decrypt</code></td>
<td>
<p>boolean defining if the text should be encrypted or decrypted.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All characters beside charlist = c(LETTERS, letters, 0:9) will be discarded from the text and from the key.
</p>


<h3>Value</h3>

<p>the encrypted, resp. decrypted text
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;<br />
strongly based on code found at <a href="https://rosettacode.org/wiki/Vigen%C3%A8re_cipher#R">https://rosettacode.org/wiki/Vigen%C3%A8re_cipher#R</a> (credits to the unknown soldier)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>key &lt;- "My FavoriteKey452"
(xenc &lt;- Vigenere("Beware the Jabberwock, my son! The jaws that bite, the claws that catch!", key))

Vigenere(xenc, key, decrypt = TRUE)
# note that everything besides the characters in the list will be discarded
</code></pre>

<hr>
<h2 id='VonNeumannTest'>Von Neumann's Successive Difference Test
</h2><span id='topic+VonNeumannTest'></span>

<h3>Description</h3>

<p>A popular statistic to test for independence is the von Neumann ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VonNeumannTest(x, alternative = c("two.sided", "less", "greater"), unbiased = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VonNeumannTest_+3A_x">x</code></td>
<td>
<p>a numeric vector containing the observations</p>
</td></tr>
<tr><td><code id="VonNeumannTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>. You can specify just the initial letter.
</p>
</td></tr>
<tr><td><code id="VonNeumannTest_+3A_unbiased">unbiased</code></td>
<td>
<p>logical. In order for VN to be an unbiased estimate of the true population value, the calculated value is multiplied by <code class="reqn">n/(n-1)</code>. Default is TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The VN test statistic is in the unbiased case
</p>
<p style="text-align: center;"><code class="reqn">VN=\frac{\sum_{i=1}^{n-1}(x_i-x_{i+1})^2 \cdot n}{\sum_{i=1}^{n}\left(x_i-\bar{x}\right)^2 \cdot (n-1)} </code>
</p>

<p>It is known that <code class="reqn">(VN-\mu)/\sigma</code> is asymptotically standard normal, where <code class="reqn">\mu=\frac{2n}{n-1}</code> and <code class="reqn">\sigma^2=4\cdot n^2 \frac{(n-2)}{(n+1)(n-1)^3}</code>.
</p>
<p>The VN test statistic is in the original (biased) case
</p>
<p style="text-align: center;"><code class="reqn">VN=\frac{\sum_{i=1}^{n-1}(x_i-x_{i+1})^2}{\sum_{i=1}^{n}\left(x_i-\bar{x}\right)^2}</code>
</p>

<p>The test statistic <code class="reqn">(VN-2)/\sigma</code> is asymptotically standard normal, where <code class="reqn">\sigma^2=\frac{4\cdot(n-2)}{(n+1)(n-1)}</code>.
</p>
<p>Missing values are silently removed.
</p>


<h3>Value</h3>

<p>A list with class &quot;htest&quot; containing the components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the VN statistic and the normalized statistic test.</p>
</td></tr>
<tr><td><code>parameter</code>, <code>n</code></td>
<td>
<p>the size of the data, after the remotion of consecutive duplicate values.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the test performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>References</h3>

<p>von Neumann, J. (1941) Distribution of the ratio of the mean square successive difference to the variance.
<em>Annals of Mathematical Statistics</em> <b>12</b>, 367-395.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BartelsRankTest">BartelsRankTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>VonNeumannTest(d.pizza$temperature)
</code></pre>

<hr>
<h2 id='wdConst'>Word VBA Constants
</h2><span id='topic+wdConst'></span><span id='topic+xlConst'></span>

<h3>Description</h3>

<p>This is a list with all VBA constants for MS Word 2010, which is useful for writing R functions based on recorded macros in Word.
This way the constants need not be replaced by their numeric values and can only be complemented with the list's name,
say the VBA-constant <code>wd10Percent</code> for example can be replaced by <code>wdConst$wd10Percent</code>.
A handful constants for Excel are consolidated in <code>xlConst</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wdConst)
data(xlConst)</code></pre>


<h3>Format</h3>

<p>The format is:<br />
List of 2755<br />
$ wd100Words:    num -4<br />
$ wd10Percent:   num -6<br />
$ wd10Sentences: num -2<br />
...<br />
</p>


<h3>Source</h3>

<p>Microsoft
</p>

<hr>
<h2 id='Winsorize'>Winsorize (Replace Extreme Values by Less Extreme Ones) </h2><span id='topic+Winsorize'></span>

<h3>Description</h3>

<p>Winsorizing a vector means that
a predefined quantum of the smallest and/or the largest values are replaced by less extreme values. Thereby the substitute values are the most extreme retained values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Winsorize(x, minval = NULL, maxval = NULL, probs = c(0.05, 0.95),
          na.rm = FALSE, type = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Winsorize_+3A_x">x</code></td>
<td>
<p>a numeric vector to be winsorized.</p>
</td></tr>
<tr><td><code id="Winsorize_+3A_minval">minval</code></td>
<td>
<p>the low border, all values being lower than this will be replaced by this value.
The default is set to the 5%-quantile of x.</p>
</td></tr>
<tr><td><code id="Winsorize_+3A_maxval">maxval</code></td>
<td>
<p>the high border, all values being larger than this will be replaced by this value.
The default is set to the 95%-quantile of x.</p>
</td></tr>
<tr><td><code id="Winsorize_+3A_probs">probs</code></td>
<td>
<p>numeric vector of probabilities with values in [0,1] as used in <code><a href="stats.html#topic+quantile">quantile</a></code>.  </p>
</td></tr>
<tr><td><code id="Winsorize_+3A_na.rm">na.rm</code></td>
<td>
<p>should NAs be omitted to calculate the quantiles? <br />
Note that NAs in x are preserved and left unchanged anyway. </p>
</td></tr>
<tr><td><code id="Winsorize_+3A_type">type</code></td>
<td>
<p>an integer between 1 and 9 selecting one of the nine quantile algorithms detailed in <code><a href="stats.html#topic+quantile">quantile</a></code> to be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The winsorized vector is obtained by
</p>
<p style="text-align: center;"><code class="reqn">g(x) =
  \left\{\begin{array}{ll}
      -c &amp;\textup{for }x \le -c\\
      x  &amp;\textup{for } |x| &lt; c\\
      c &amp;\textup{for }x \ge c
  \end{array}\right.
</code>
</p>

<p>You may also want to consider standardizing (possibly robustly) the data before you perform a winsorization.
</p>


<h3>Value</h3>

<p>A vector of the same length as the original data
<code>x</code> containing the winsorized data.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt; 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Winsorize">Winsorize</a></code> from the package <code>robustHD</code> contains an option to winsorize multivariate data
</p>
<p><code><a href="base.html#topic+scale">scale</a></code>, <code><a href="#topic+RobScale">RobScale</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate data
set.seed(1234)     # for reproducibility
x &lt;- rnorm(10)     # standard normal
x[1] &lt;- x[1] * 10  # introduce outlier

## Winsorize data
x
Winsorize(x)

# use Large and Small, if a fix number of values should be winsorized (here k=3):
Winsorize(x, minval=tail(Small(x, k=3), 1), maxval=head(Large(x, k=3), 1))
</code></pre>

<hr>
<h2 id='WithOptions'>Execute Function with Temporary Options
</h2><span id='topic+WithOptions'></span>

<h3>Description</h3>

<p>Setting and resetting options is lengthy in command mode. <code>WithOptions()</code> allows to evaluate a function with temporary set options. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WithOptions(optlist, expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WithOptions_+3A_optlist">optlist</code></td>
<td>
<p>a list with new option settings.
</p>
</td></tr>
<tr><td><code id="WithOptions_+3A_expr">expr</code></td>
<td>
<p>the expression to be evaluated
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the function result 
</p>


<h3>Author(s)</h3>

<p>Thomas Lumley &lt;t.lumley@auckland.ac.nz&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+options">options</a></code>, <code><a href="base.html#topic+getOption">getOption</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># original:
print((1:10)^-1)

# with new options
WithOptions(list(digits=3), print((1:10)^-1))
</code></pre>

<hr>
<h2 id='WoolfTest'>Woolf Test For Homogeneity in 2x2xk Tables</h2><span id='topic+WoolfTest'></span>

<h3>Description</h3>

<p>Test for homogeneity on <code class="reqn">2 \times 2 \times k</code> tables
over strata (i.e., whether the log odds ratios are the same in all
strata).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WoolfTest(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WoolfTest_+3A_x">x</code></td>
<td>
<p>a <code class="reqn">2 \times 2 \times k</code> table, where the last dimension refers to the strata. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>"htest"</code> containing the following
components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the chi-squared test statistic.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>degrees of freedom of the approximate chi-squared
distribution of the test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p><code class="reqn">p</code>-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating the type of test
performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
<tr><td><code>observed</code></td>
<td>
<p>the observed counts.</p>
</td></tr>
<tr><td><code>expected</code></td>
<td>
<p>the expected counts under the null hypothesis.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> This function was previously published as <code>woolf_test()</code> in the  <span class="pkg">vcd</span> package and has been integrated here without logical changes.
</p>


<h3>Author(s)</h3>

<p>David Meyer, Achim Zeileis, Kurt Hornik, Michael Friendly</p>


<h3>References</h3>

<p>Woolf, B. 1955: On estimating the relation between blood group and
disease. <em>Ann. Human Genet.</em> (London) <b>19</b>, 251-253.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mantelhaen.test">mantelhaen.test</a></code>, <code><a href="#topic+BreslowDayTest">BreslowDayTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>migraine &lt;- xtabs(freq ~ .,
            cbind(expand.grid(treatment=c("active","placebo"),
                               response=c("better","same"),
                               gender=c("female","male")),
                  freq=c(16,5,11,20,12,7,16,19))
            )

WoolfTest(migraine)
</code></pre>

<hr>
<h2 id='WrdBookmark'>Some Functions to Handle MS-Word Bookmarks
</h2><span id='topic+WrdInsertBookmark'></span><span id='topic+WrdDeleteBookmark'></span><span id='topic+WrdGoto'></span><span id='topic+WrdBookmark'></span><span id='topic+WrdUpdateBookmark'></span>

<h3>Description</h3>

<p>Accessing bookmarks by name is only possible by browsing the bookmark names. <code>WrdBookmark</code> returns a handle to a bookmark by taking its name as argument. <code>WrdInsertBookmark</code>, <code>WrdDeleteBookmark</code> inserts/deletes a bookmark in a Word document. <code>WrdGotoBookmark</code> allows to place the cursor on the bookmark and <code>WrdUpdateBookmark</code> replaces the content within the range of the bookmark in a Word document with the given text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdBookmark(name, wrd = DescToolsOptions("lastWord"))

WrdInsertBookmark(name, wrd = DescToolsOptions("lastWord"))
WrdDeleteBookmark(name, wrd = DescToolsOptions("lastWord"))

WrdGoto(name, what = wdConst$wdGoToBookmark, wrd = DescToolsOptions("lastWord"))

WrdUpdateBookmark(name, text, what = wdConst$wdGoToBookmark,
                  wrd = DescToolsOptions("lastWord"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdBookmark_+3A_name">name</code></td>
<td>
<p>the name of the bookmark.
</p>
</td></tr>
<tr><td><code id="WrdBookmark_+3A_text">text</code></td>
<td>
<p>the text of the bookmark.
</p>
</td></tr>
<tr><td><code id="WrdBookmark_+3A_what">what</code></td>
<td>
<p>a word constant, defining the type of object to be used to place the cursor.
</p>
</td></tr>
<tr><td><code id="WrdBookmark_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bookmarks are useful to build structured documents, which can be updated later.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WrdFont">WrdFont</a></code>, <code><a href="#topic+WrdPlot">WrdPlot</a></code>, <code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+GetCurrWrd">GetCurrWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # we can't get this through the CRAN test - run it with copy/paste to console
wrd &lt;- GetNewWrd()
WrdText("a)\n\n\nb)", fontname=WrdGetFont()$name, fontsize=WrdGetFont()$size)
WrdInsertBookmark("chap_b")
WrdText("\n\n\nc)\n\n\n", fontname=WrdGetFont()$name, fontsize=WrdGetFont()$size)

WrdGoto("chap_b")
WrdUpdateBookmark("chap_b", "Goto chapter B and set text")

WrdInsertBookmark("mybookmark")
ToWrd("A longer text\n\n\n")

# Now returning the bookmark
bm &lt;- WrdBookmark("mybookmark")

# get the automatically created name of the bookmark
bm$name()

## End(Not run)</code></pre>

<hr>
<h2 id='WrdCaption'>Insert Caption to Word</h2><span id='topic+WrdCaption'></span>

<h3>Description</h3>

<p>Insert a caption in a given level to a Word document. The caption is inserted at the current cursor position.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdCaption(x, index = 1, wrd = DescToolsOptions("lastWord"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdCaption_+3A_x">x</code></td>
<td>
<p>the text of the caption.
</p>
</td></tr>
<tr><td><code id="WrdCaption_+3A_index">index</code></td>
<td>
<p>integer from 1 to 9, defining the number of the heading style.
</p>
</td></tr>
<tr><td><code id="WrdCaption_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToWrd">ToWrd</a></code>, <code><a href="#topic+WrdPlot">WrdPlot</a></code>, <code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+GetCurrWrd">GetCurrWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example
wrd &lt;- GetNewWrd()

# insert a title in level 1
WrdCaption("My First Caption level 1", index=1, wrd=wrd)

# works as well for several levels
sapply(1:5, function(i)
  WrdCaption(gettextf("My First Caption level %s",i), index=i, wrd=wrd)
)

## End(Not run)
</code></pre>

<hr>
<h2 id='WrdCellRange'>Return the Cell Range Of a Word Table
</h2><span id='topic+WrdCellRange'></span>

<h3>Description</h3>

<p>Return a handle of a cell range of a word table. This is useful for
formating the cell range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdCellRange(wtab, from, to)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdCellRange_+3A_wtab">wtab</code></td>
<td>
<p>a handle to the word table as returned i.g. by  <code><a href="#topic+WrdTable">WrdTable</a></code>
</p>
</td></tr>
<tr><td><code id="WrdCellRange_+3A_from">from</code></td>
<td>
<p>a vector containing row- and column number of the left/upper cell of the cell range.
</p>
</td></tr>
<tr><td><code id="WrdCellRange_+3A_to">to</code></td>
<td>
<p>a vector containing row- and column number of the right/lower cell of the cell range.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cell range selecting might be complicated. This function makes it easy.
</p>


<h3>Value</h3>

<p>a handle to the range.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+WrdTable">WrdTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Windows-specific example
wrd &lt;- GetNewWrd()
WrdTable(nrow=3, ncol=3, wrd=wrd)
crng &lt;- WrdCellRange(from=c(1,2), to=c(2,3))
crng$Select()

## End(Not run)
</code></pre>

<hr>
<h2 id='WrdFont'>Get or Set the Font in Word
</h2><span id='topic+WrdFont'></span><span id='topic+WrdFont+3C-'></span>

<h3>Description</h3>

<p><code>WrdFont</code> can be used to get and set the font in Word for the text to be inserted. <code>WrdFont</code> returns the font at the current cursor position.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdFont(wrd = DescToolsOptions("lastWord"))
WrdFont(wrd) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdFont_+3A_value">value</code></td>
<td>
<p>the font to be used to the output. This should be defined as a list containing fontname, fontsize, bold and italic flags:<br /> <code>list(name="Arial", size=10, bold=FALSE, italic=TRUE, color=wdConst$wdColorBlack)</code>.
</p>
</td></tr>
<tr><td><code id="WrdFont_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The font color can be defined by a Word constant beginning with <code>wdConst$wdColor</code>.
The defined colors can be listed with <code>grep("wdColor", names(wdConst), val=TRUE)</code>.
</p>


<h3>Value</h3>

<p>a list of the attributes of the font in the current cursor position:
</p>
<table>
<tr><td><code>name</code></td>
<td>
<p>the fontname</p>
</td></tr>
<tr><td><code>size</code></td>
<td>
<p>the fontsize</p>
</td></tr>
<tr><td><code>bold</code></td>
<td>
<p>bold</p>
</td></tr>
<tr><td><code>italic</code></td>
<td>
<p>italic</p>
</td></tr>
<tr><td><code>color</code></td>
<td>
<p>the fontcolor</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToWrd">ToWrd</a></code>, <code><a href="#topic+WrdPlot">WrdPlot</a></code>, <code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+GetCurrWrd">GetCurrWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example

wrd &lt;- GetNewWrd()

for(i in seq(10, 24, 2))
  ToWrd(gettextf("This is Arial size %s \n", i), font=list(name="Arial", size=i))

for(i in seq(10, 24, 2))
  ToWrd(gettextf("This is Times size %s \n", i), font=list(name="Times", size=i))

## End(Not run)</code></pre>

<hr>
<h2 id='WrdFormatCells'>Format Cells Of a Word Table
</h2><span id='topic+WrdFormatCells'></span>

<h3>Description</h3>

<p>Format cells of a Word table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdFormatCells(wtab, rstart, rend, col = NULL, bg = NULL,
               font = NULL, border = NULL, align = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdFormatCells_+3A_wtab">wtab</code></td>
<td>
<p>a handle to the word table as returned i.g. by  <code><a href="#topic+WrdTable">WrdTable</a></code>
</p>
</td></tr>
<tr><td><code id="WrdFormatCells_+3A_rstart">rstart</code></td>
<td>
<p>the left/upper cell of the cell range
</p>
</td></tr>
<tr><td><code id="WrdFormatCells_+3A_rend">rend</code></td>
<td>
<p>the right/lower cell of the cell range
</p>
</td></tr>
<tr><td><code id="WrdFormatCells_+3A_col">col</code></td>
<td>
<p>the foreground colour
</p>
</td></tr>
<tr><td><code id="WrdFormatCells_+3A_bg">bg</code></td>
<td>
<p>the background colour
</p>
</td></tr>
<tr><td><code id="WrdFormatCells_+3A_font">font</code></td>
<td>
<p>the font to be used to the output. This should be defined as a list containing fontname, fontsize, bold and italic flags:<br /> <code>list(name="Arial", size=10, bold=FALSE, italic=TRUE, color=wdConst$wdColorBlack)</code>.
</p>
</td></tr>
<tr><td><code id="WrdFormatCells_+3A_border">border</code></td>
<td>
<p>the border of the cell range, defined as a list containing arguments for
border, linestyle, linewidth and color. <code>border</code> is a vector containing the parts of the border defined by the Word constants <code>wdConst$wdBorder...</code>,  being
$wdBorderBottom, $wdBorderLeft, $wdBorderTop, $wdBorderRight, $wdBorderHorizontal,
$wdBorderVertical, $wdBorderDiagonalUp, $wdBorderDiagonalDown. linestyle, linewidth and color will be recycled to the required dimension.
</p>
</td></tr>
<tr><td><code id="WrdFormatCells_+3A_align">align</code></td>
<td>
<p>a character out of <code>"l"</code>, <code>"c"</code>, <code>"r"</code> setting the horizontal alignment of the cell range.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cell range selecting might be complicated. This function makes it easy.
</p>


<h3>Value</h3>

<p>a handle to the range.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+WrdTable">WrdTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:    # Windows-specific example

m &lt;- matrix(rnorm(12)*100, nrow=4,
            dimnames=list(LETTERS[1:4], c("Variable","Value","Remark")))

wrd &lt;- GetNewWrd()
wt &lt;- ToWrd(m)

WrdFormatCells(wt, rstart=c(3,1), rend=c(4,3),
               bg=wdConst$wdColorGold, font=list(name="Arial Narrow", bold=TRUE),
               align="c", border=list(color=wdConst$wdColorTeal,
                                      linewidth=wdConst$wdLineWidth300pt))


## End(Not run)
</code></pre>

<hr>
<h2 id='WrdMergeCells'>Merges Cells Of a Defined Word Table Range
</h2><span id='topic+WrdMergeCells'></span>

<h3>Description</h3>

<p>Merges a cell range of a word table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdMergeCells(wtab, rstart, rend)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdMergeCells_+3A_wtab">wtab</code></td>
<td>
<p>a handle to the word table as returned i.g. by  <code><a href="#topic+WrdTable">WrdTable</a></code>
</p>
</td></tr>
<tr><td><code id="WrdMergeCells_+3A_rstart">rstart</code></td>
<td>
<p>the left/upper cell of the cell range.
</p>
</td></tr>
<tr><td><code id="WrdMergeCells_+3A_rend">rend</code></td>
<td>
<p>the right/lower cell of the cell range.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+WrdTable">WrdTable</a></code>, <code><a href="#topic+WrdCellRange">WrdCellRange</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Windows-specific example
wrd &lt;- GetNewWrd()
wtab &lt;- WrdTable(nrow=3, ncol=3, wrd=wrd)
WrdMergeCells(wtab, rstart=c(1,2), rend=c(2,3))

## End(Not run)
</code></pre>

<hr>
<h2 id='WrdPageBreak'>Insert a Page Break
</h2><span id='topic+WrdPageBreak'></span>

<h3>Description</h3>

<p>Insert a page break in a MS-Word (R) document at the position of the cursor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdPageBreak(wrd = DescToolsOptions("lastWord"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdPageBreak_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WrdFont">WrdFont</a></code>, <code><a href="#topic+WrdPlot">WrdPlot</a></code>, <code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+GetCurrWrd">GetCurrWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example
wrd &lt;- GetNewWrd()
WrdText("This is text on page 1.\n\n")
WrdPageBreak()
WrdText("This is text on another page.\n\n")

## End(Not run)</code></pre>

<hr>
<h2 id='WrdParagraphFormat'>Get or Set the Paragraph Format in Word
</h2><span id='topic+WrdParagraphFormat'></span><span id='topic+WrdParagraphFormat+3C-'></span>

<h3>Description</h3>

<p><code>WrdParagraphFormat</code> can be used to get and set the font in Word for the text to be inserted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdParagraphFormat(wrd = DescToolsOptions("lastWord"))
WrdParagraphFormat(wrd) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdParagraphFormat_+3A_value">value</code></td>
<td>

<p>a list defining the paragraph format.
This can contain any combination of:
<code>LeftIndent</code>, <code>RightIndent</code>, <code>SpaceBefore</code>, <code>SpaceBeforeAuto</code>, <code>SpaceAfter</code>, <code>SpaceAfterAuto</code>,
<code>LineSpacingRule</code>, <code>Alignment</code>, <code>WidowControl</code>, <code>KeepWithNext</code>, <code>KeepTogether</code>, <code>PageBreakBefore</code>,
<code>NoLineNumber</code>, <code>Hyphenation</code>, <code>FirstLineIndent</code>, <code>OutlineLevel</code>, <code>CharacterUnitLeftIndent</code>,
<code>CharacterUnitRightIndent</code>, <code>CharacterUnitFirstLineIndent</code>, <code>LineUnitBefore</code>, <code>LineUnitAfter</code> and/or <code>MirrorIndents</code>.
The possible values of the arguments are found in the Word constants with the respective name. <br /> The alignment for example can be set to <code>wdAlignParagraphLeft</code>, <code>wdAlignParagraphRight</code>, <code>wdAlignParagraphCenter</code> and so on.
<br /> Left alignment with indentation would be set as:<br /> <code>list(Alignment=wdConst$wdAlignParagraphLeft, LeftIndent=42.55)</code>.
</p>
</td></tr>
<tr><td><code id="WrdParagraphFormat_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object with the class <code>paragraph</code>, basically a list with the attributes of the paragraph in the current cursor position:
</p>
<table>
<tr><td><code>LeftIndent</code></td>
<td>
<p>left indentation in (in points) for the specified paragraphs.</p>
</td></tr>
<tr><td><code>RightIndent</code></td>
<td>
<p>right indent (in points) for the specified paragraphs.</p>
</td></tr>
<tr><td><code>SpaceBefore</code></td>
<td>
<p>spacing (in points) before the specified paragraphs.</p>
</td></tr>
<tr><td><code>SpaceBeforeAuto</code></td>
<td>
<p><code>TRUE</code> if Microsoft Word automatically sets the amount of spacing before the specified paragraphs.</p>
</td></tr>
<tr><td><code>SpaceAfter</code></td>
<td>
<p>amount of spacing (in points) after the specified paragraph or text column.</p>
</td></tr>
<tr><td><code>SpaceAfterAuto</code></td>
<td>
<p><code>TRUE</code> if Microsoft Word automatically sets the amount of spacing after the specified paragraphs.</p>
</td></tr>
<tr><td><code>LineSpacingRule</code></td>
<td>
<p>line spacing for the specified paragraph formatting. Use <code>wdLineSpaceSingle</code>, <code>wdLineSpace1pt5</code>, or <code>wdLineSpaceDouble</code> to set the line spacing to one of these values. To set the line spacing to an exact number of points or to a multiple number of lines, you must also set the <code>LineSpacing</code> property.</p>
</td></tr>
<tr><td><code>Alignment</code></td>
<td>
<p><code>WdParagraphAlignment</code> constant that represents the alignment for the specified paragraphs.</p>
</td></tr>
<tr><td><code>WidowControl</code></td>
<td>
<p><code>TRUE</code> if the first and last lines in the specified paragraph remain on the same page as the rest of the paragraph when Word repaginates the document. Can be <code>TRUE</code>, <code>FALSE</code> or <code>wdUndefined</code>.</p>
</td></tr>
<tr><td><code>KeepWithNext</code></td>
<td>
<p><code>TRUE</code> if the specified paragraph remains on the same page as the paragraph that follows it when Microsoft Word repaginates the document. Read/write Long.</p>
</td></tr>
<tr><td><code>KeepTogether</code></td>
<td>
<p><code>TRUE</code> if all lines in the specified paragraphs remain on the same page when Microsoft Word repaginates the document.</p>
</td></tr>
<tr><td><code>PageBreakBefore</code></td>
<td>
<p><code>TRUE</code> if a page break is forced before the specified paragraphs. Can be <code>TRUE</code>, <code>FALSE</code>, or <code>wdUndefined</code>.</p>
</td></tr>
<tr><td><code>NoLineNumber</code></td>
<td>
<p><code>TRUE</code> if line numbers are repressed for the specified paragraphs. Can be <code>TRUE</code>, <code>FALSE</code>, or <code>wdUndefined</code>.</p>
</td></tr>
<tr><td><code>Hyphenation</code></td>
<td>
<p><code>TRUE</code> if the specified paragraphs are included in automatic hyphenation. <code>FALSE</code> if the specified paragraphs are to be excluded from automatic hyphenation.</p>
</td></tr>
<tr><td><code>FirstLineIndent</code></td>
<td>
<p>value (in points) for a first line or hanging indent. Use a positive value to set a first-line indent, and use a negative value to set a hanging indent.</p>
</td></tr>
<tr><td><code>OutlineLevel</code></td>
<td>
<p>outline level for the specified paragraphs.</p>
</td></tr>
<tr><td><code>CharacterUnitLeftIndent</code></td>
<td>
<p>left indent value (in characters) for the specified paragraphs.</p>
</td></tr>
<tr><td><code>CharacterUnitRightIndent</code></td>
<td>
<p>right indent value (in characters) for the specified paragraphs. </p>
</td></tr>
<tr><td><code>LineUnitBefore</code></td>
<td>
<p>amount of spacing (in gridlines) before the specified paragraphs. </p>
</td></tr>
<tr><td><code>LineUnitAfter</code></td>
<td>
<p>amount of spacing (in gridlines) after the specified paragraphs.</p>
</td></tr>
<tr><td><code>MirrorIndents</code></td>
<td>
<p>Long that represents whether left and right indents are the same width. Can be <code>TRUE</code>, <code>FALSE</code>, or <code>wdUndefined</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToWrd">ToWrd</a></code>, <code><a href="#topic+WrdPlot">WrdPlot</a></code>, <code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+GetCurrWrd">GetCurrWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Windows-specific example
wrd &lt;- GetNewWrd()  # get the handle to a new word instance

WrdParagraphFormat(wrd=wrd) &lt;- list(Alignment=wdConst$wdAlignParagraphLeft,
                                    LeftIndent=42.55)

ToWrd("Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy
eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.
At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd
gubergren, no sea takimata sanctus est.\n", wrd=wrd)

# reset
WrdParagraphFormat(wrd=wrd) &lt;- list(LeftIndent=0)

## End(Not run)
</code></pre>

<hr>
<h2 id='WrdPlot'>Insert Active Plot to Word</h2><span id='topic+WrdPlot'></span>

<h3>Description</h3>

<p>This function inserts the plot on the active plot device to Word. The image is transferred
by saving the picture to a file in R and inserting the file in Word.
The format of the plot can be selected, as well as crop options and the size factor for inserting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdPlot(type = "png", append.cr = TRUE, crop = c(0, 0, 0, 0), main = NULL,
        picscale = 100, height = NA, width = NA, res = 300,
        dfact = 1.6, wrd = DescToolsOptions("lastWord"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdPlot_+3A_type">type</code></td>
<td>
<p>the format for the picture file, default is <code>"png"</code>.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_append.cr">append.cr</code></td>
<td>
<p>should a carriage return be appended? Default is TRUE.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_crop">crop</code></td>
<td>
<p>crop options for the picture, defined by a 4-elements-vector. The first element is the bottom side, the second the left and so on.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_main">main</code></td>
<td>
<p>a caption for the plot. This will be inserted by InserCaption in Word. Default is NULL, which will insert nothing.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_picscale">picscale</code></td>
<td>
<p>scale factor of the picture in percent, default ist 100.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_height">height</code></td>
<td>
<p>height in cm, this overrides the picscale if both are given.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_width">width</code></td>
<td>
<p>width in cm, this overrides the picscale if both are given.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_res">res</code></td>
<td>
<p>resolution for the png file, defaults to 300.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_dfact">dfact</code></td>
<td>
<p>the size factor for the graphic.</p>
</td></tr>
<tr><td><code id="WrdPlot_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a pointer to the inserted picture.</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToWrd">ToWrd</a></code>, <code><a href="#topic+WrdCaption">WrdCaption</a></code>, <code><a href="#topic+GetNewWrd">GetNewWrd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example
# let's have some graphics
plot(1,type="n", axes=FALSE, xlab="", ylab="", xlim=c(0,1), ylim=c(0,1), asp=1)
rect(0,0,1,1,col="black")
segments(x0=0.5, y0=seq(0.632,0.67, length.out=100),
  y1=seq(0.5,0.6, length.out=100), x1=1, col=rev(rainbow(100)))
polygon(x=c(0.35,0.65,0.5), y=c(0.5,0.5,0.75), border="white",
  col="black", lwd=2)
segments(x0=0,y0=0.52, x1=0.43, y1=0.64, col="white", lwd=2)
x1 &lt;- seq(0.549,0.578, length.out=50)
segments(x0=0.43, y0=0.64, x1=x1, y1=-tan(pi/3)* x1 + tan(pi/3) * 0.93,
  col=rgb(1,1,1,0.35))


# get a handle to a new word instance
wrd &lt;- GetNewWrd()
# insert plot with a specified height
WrdPlot(wrd=wrd, height=5)
ToWrd("Remember?\n", fontname="Arial", fontsize=14, bold=TRUE, wrd=wrd)
# crop the picture
WrdPlot(wrd=wrd, height=5, crop=c(9,9,0,0))


wpic &lt;- WrdPlot(wrd=wrd, height=5, crop=c(9,9,0,0))
wpic

## End(Not run)
</code></pre>

<hr>
<h2 id='WrdSaveAs'>Open and Save Word Documents
</h2><span id='topic+WrdSaveAs'></span><span id='topic+WrdOpenFile'></span>

<h3>Description</h3>

<p>Open and save MS-Word documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdOpenFile(fn, wrd = DescToolsOptions("lastWord"))
WrdSaveAs(fn, fileformat = "docx", wrd = DescToolsOptions("lastWord"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdSaveAs_+3A_fn">fn</code></td>
<td>
<p>filename and -path for the document.
</p>
</td></tr>
<tr><td><code id="WrdSaveAs_+3A_fileformat">fileformat</code></td>
<td>
<p>file format, one out of <code>"doc"</code>, <code>"htm"</code>, <code>"pdf"</code>.
</p>
</td></tr>
<tr><td><code id="WrdSaveAs_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing returned
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GetNewWrd">GetNewWrd</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#   Windows-specific example
wrd &lt;- GetNewWrd()
WrdCaption("A Report")
WrdSaveAs(fn="report", fileformat="htm")

## End(Not run)</code></pre>

<hr>
<h2 id='WrdStyle'>Get or Set the Style in Word
</h2><span id='topic+WrdStyle'></span><span id='topic+WrdStyle+3C-'></span>

<h3>Description</h3>

<p><code>WrdStyle</code> can be used to get and set the style in Word for the text to be inserted. <code>WrdStyle</code> returns the style at the current cursor position.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdStyle(wrd = DescToolsOptions("lastWord"))
WrdStyle(wrd) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdStyle_+3A_value">value</code></td>
<td>
<p>the name of the style to be used to the output. This should be defined an existing name.
</p>
</td></tr>
<tr><td><code id="WrdStyle_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character, name of the style
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ToWrd">ToWrd</a></code>, <code><a href="#topic+WrdPlot">WrdPlot</a></code>, <code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+GetCurrWrd">GetCurrWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example

wrd &lt;- GetNewWrd()
# the current stlye
WrdStyle(wrd)

## End(Not run)</code></pre>

<hr>
<h2 id='WrdTable'>Insert a Table in a Word Document
</h2><span id='topic+WrdTable'></span>

<h3>Description</h3>

<p>Create a table with a specified number of rows and columns in a Word document at the current position of the cursor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdTable(nrow = 1, ncol = 1, heights = NULL, widths = NULL, main = NULL,
         wrd = DescToolsOptions("lastWord"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdTable_+3A_nrow">nrow</code></td>
<td>
<p>number of rows.
</p>
</td></tr>
<tr><td><code id="WrdTable_+3A_ncol">ncol</code></td>
<td>
<p>number of columns.
</p>
</td></tr>
<tr><td><code id="WrdTable_+3A_heights">heights</code></td>
<td>
<p>a vector of the row heights (in [cm]). If set to <code>NULL</code> (which is the default) the Word defaults will be used. The values will be recyled, if necessary.
</p>
</td></tr>
<tr><td><code id="WrdTable_+3A_widths">widths</code></td>
<td>
<p>a vector of the column widths (in [cm]). If set to <code>NULL</code> (which is the default) the Word defaults will be used. The values will be recyled, if necessary.
</p>
</td></tr>
<tr><td><code id="WrdTable_+3A_main">main</code></td>
<td>
<p>a caption for the plot. This will be inserted by InserCaption in Word. Default is NULL, which will insert nothing.</p>
</td></tr>
<tr><td><code id="WrdTable_+3A_wrd">wrd</code></td>
<td>
<p>the pointer to a word instance. Can be a new one, created by <code>GetNewWrd()</code>
or an existing one, created by <code>GetCurrWrd()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastWord")</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A pointer to the inserted table.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GetNewWrd">GetNewWrd</a></code>, <code><a href="#topic+ToWrd">ToWrd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example
wrd &lt;- GetNewWrd()
WrdTable(nrow=3, ncol=3, wrd=wrd)

## End(Not run)
</code></pre>

<hr>
<h2 id='WrdTableBorders'>Draw Borders to a Word Table
</h2><span id='topic+WrdTableBorders'></span>

<h3>Description</h3>

<p>Drawing borders in a Word table is quite tedious. This function allows to select any range and draw border lines around it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WrdTableBorders(wtab, from = NULL, to = NULL, border = NULL,
                lty = wdConst$wdLineStyleSingle, col = wdConst$wdColorBlack,
                lwd = wdConst$wdLineWidth050pt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WrdTableBorders_+3A_wtab">wtab</code></td>
<td>
<p>a pointer to a Word table as returned by <code><a href="#topic+WrdTable">WrdTable</a></code> or <code><a href="#topic+TOne">TOne</a></code>.
</p>
</td></tr>
<tr><td><code id="WrdTableBorders_+3A_from">from</code></td>
<td>
<p>integer, a vector with two elements specifying the left upper bound of the cellrange.
</p>
</td></tr>
<tr><td><code id="WrdTableBorders_+3A_to">to</code></td>
<td>
<p>integer, a vector with two elements specifying the right bottom of the cellrange.
</p>
</td></tr>
<tr><td><code id="WrdTableBorders_+3A_border">border</code></td>
<td>
<p>a Word constant (<code>wdConst$wdBorder...</code>) defining the side of the border.
</p>
</td></tr>
<tr><td><code id="WrdTableBorders_+3A_lty">lty</code></td>
<td>
<p>a Word constant (<code>wdConst$wdLineStyle...</code>) defining the line type.
</p>
</td></tr>
<tr><td><code id="WrdTableBorders_+3A_col">col</code></td>
<td>
<p>a Word constant (<code>wdConst$wdColor...</code>) defining the color of the border. See examples for converting R colors to Word colors.
</p>
</td></tr>
<tr><td><code id="WrdTableBorders_+3A_lwd">lwd</code></td>
<td>
<p>a Word constant (<code>wdConst$wdLineWidth...pt</code>) defining the line width.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WrdTable">WrdTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# create table
tab &lt;- table(op=d.pizza$operator, area=d.pizza$area)

# send it to Word
wrd &lt;- GetNewWrd()
wtab &lt;- ToWrd(tab, wrd=wrd, tablestyle = NA)

# draw borders
WrdTableBorders(wtab, from=c(2,2), to=c(3,3), border=wdConst$wdBorderBottom, wrd=wrd)
WrdTableBorders(wtab, from=c(2,2), to=c(3,3), border=wdConst$wdBorderDiagonalUp, wrd=wrd)

# demonstrate linewidth and color
wtab &lt;- ToWrd(tab, wrd=wrd, tablestyle = NA)
WrdTableBorders(wtab, col=RgbToLong(ColToRgb("olivedrab")),
                lwd=wdConst$wdLineWidth150pt, wrd=wrd)

WrdTableBorders(wtab, border=wdConst$wdBorderBottom,
                col=RgbToLong(ColToRgb("dodgerblue")),
                lwd=wdConst$wdLineWidth300pt, wrd=wrd)

# use an R color in Word
RgbToLong(ColToRgb("olivedrab"))

# find a similar R-color for a Word color
ColToRgb(RgbToCol(LongToRgb(wdConst$wdColorAqua)))

## End(Not run)
</code></pre>

<hr>
<h2 id='XLDateToPOSIXct'>Convert Excel Dates to POSIXct
</h2><span id='topic+XLDateToPOSIXct'></span>

<h3>Description</h3>

<p>As I repeatedly forgot how to convert Excel dates to POSIX here's the specific function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XLDateToPOSIXct(x, tz = "GMT", xl1904 = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XLDateToPOSIXct_+3A_x">x</code></td>
<td>
<p>the integer vector to be converted.
</p>
</td></tr>
<tr><td><code id="XLDateToPOSIXct_+3A_tz">tz</code></td>
<td>
<p>a time zone specification to be used for the conversion, if one is required. See <code><a href="base.html#topic+as.POSIXct">as.POSIXct</a></code>.
</p>
</td></tr>
<tr><td><code id="XLDateToPOSIXct_+3A_xl1904">xl1904</code></td>
<td>
<p>logical, defining if the unspeakable 1904-system should be used. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+XLGetRange">XLGetRange</a></code> will return dates as integer values, because XL stores them as integers. An Excel date can be converted with the (unusual) origin of
<code>as.Date(myDate, origin="1899-12-30")</code>, which is implemented here.
</p>
<p>Microsoft Excel supports two different date systems, the 1900 date system and the 1904 date system. In the 1900 date system, the first day that is supported is January 1, 1900. A date is converted into a serial number that represents the number of elapsed days since January 1, 1900. In the 1904 date system, the first day that is supported is January 1, 1904. By default, Microsoft Excel for the Macintosh uses the 1904 date system, Excel for Windows the 1900 system.
See also: https://support.microsoft.com/en-us/kb/214330.
</p>


<h3>Value</h3>

<p>return an object of the class POSIXct. Date-times known to be invalid will be returned as NA.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+as.POSIXct">as.POSIXct</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>XLDateToPOSIXct(41025)
XLDateToPOSIXct(c(41025.23, 41035.52))
</code></pre>

<hr>
<h2 id='XLGetRange'>Import Data Directly From Excel
</h2><span id='topic+XLGetRange'></span><span id='topic+XLGetWorkbook'></span><span id='topic+XLCurrReg'></span><span id='topic+XLNamedReg'></span>

<h3>Description</h3>

<p>The package <code>RDCOMClient</code> is used to open an Excel workbook and return the content (value) of one (or several) given range(s)
in a specified sheet. This is helpful, whenever pathologically scattered data on an Excel sheet, which can't simply be saved as CSV-file, has to be imported in R.<br /><br />
<code>XLGetWorkbook()</code> does the same for all the sheets in an Excel workbook.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XLGetRange(file = NULL, sheet = NULL, range = NULL, as.data.frame = TRUE,
           header = FALSE, stringsAsFactors = FALSE, echo = FALSE,
           na.strings = NULL, skip = 0)

XLGetWorkbook(file, compactareas = TRUE)

XLCurrReg(cell)
XLNamedReg(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XLGetRange_+3A_file">file</code></td>
<td>
<p>the fully specified path and filename of the workbook. If it is left as <code>NULL</code>, the
function will look for a running Excel-Application and use its current sheet. The parameter <code>sheet</code> will be
ignored in this case.
</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_sheet">sheet</code></td>
<td>
<p>the name of the sheet containing the range(s) of interest.
</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_range">range</code></td>
<td>
<p>a scalar or a vector with the address(es) of the range(s) to be returned (characters).
Use &quot;A1&quot;-address mode to specify the ranges, for example <code>"A1:F10"</code>. <br /> If set to <code>NULL</code> (which is the default), the function will look for a selection that contains more than one cell. If
found, the function will use this selection. If there is no selection then the current region of the selected cell will be used. Use <code>XLCurrReg()</code> if the current region of a cell, which is currently not selected, should be used. Range names can be provided with <code>XLNamedReg("name")</code>.
</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical. Determines if the cellranges should be coerced into data.frames. Defaults to <code>TRUE</code>,
as this is probably the common use of this function.</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_header">header</code></td>
<td>
<p>a logical value indicating whether the range contains the names of the variables as its first line. Default is <code>FALSE</code>. <code>header</code> is ignored if <code>as.data.frame</code> has been set to <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>logical. Should character columns be coerced to factors? The default is <code>FALSE</code>, which will return character vectors.</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_echo">echo</code></td>
<td>
<p>logical. If set to <code>TRUE</code>, the function will print the full command used, such that it can be copied into the R-script for future use.</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_na.strings">na.strings</code></td>
<td>
<p>a character vector of strings which are to be interpreted as <code>NA</code> values. Blank fields are always considered to be missing values. Default is <code>NULL</code>, meaning none.</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_compactareas">compactareas</code></td>
<td>
<p>logical, defining if areas should be returned by <code>XLGetWorkbook</code> as list or as matrix (latter is default).</p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_cell">cell</code></td>
<td>
<p>range of the left uppe cell, when current region should be used. </p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_x">x</code></td>
<td>
<p>the name or the index of the XL-name to be used. </p>
</td></tr>
<tr><td><code id="XLGetRange_+3A_skip">skip</code></td>
<td>
<p>the number of lines of the data file to skip before beginning to read data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The result consists of a list of lists, if <code>as.data.frame</code> is set to <code>FALSE</code>.
Be then prepared to encounter <code>NULL</code> values. Those will prevent from easily being able to coerce
the square data structure to a data.frame.
</p>
<p>The following code will replace the <code>NULL</code> values by <code>NA</code> and coerce the data to a data.frame.
</p>
<pre>
  # get the range D1:J69 from an excel file
  xlrng &lt;- XLGetRange(file="myfile.xlsx", sheet="Tabelle1",
                      range="D1:J69", as.data.frame=FALSE)

  # replace NULL values by NA
  xlrng[unlist(lapply(xlrng, is.null))] &lt;- NA

  # coerce the square data structure to a data.frame
  d.lka &lt;- data.frame(lapply(data.frame(xlrng), unlist))
</pre>
<p>This of course can be avoided by setting <code>as.data.frame</code> = <code>TRUE</code>.
</p>
<p>The function will return dates as integers, because MS-Excel stores them internally as integers.
Such a date can subsequently be converted with the (unusual) origin of
<code>as.Date(myDate, origin="1899-12-30")</code>. See also <code><a href="#topic+XLDateToPOSIXct">XLDateToPOSIXct</a></code>, which does the job. The conversion can directly be performed by <code>XLGetRange()</code> if <code>datecols</code> is used and contains the date columns in the sheet data.
</p>


<h3>Value</h3>

<p>If <code>as.data.frame</code> is set to <code>TRUE</code>, a single data.frame or a list of data.frames will be returned.
If set to <code>FALSE</code> a list of the cell values in the specified Excel range, resp. a list of lists will be returned.
</p>
<p><code>XLGetWorkbook()</code> returns a list of lists of the values in the given workbook.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GetNewXL">GetNewXL</a></code>, <code><a href="#topic+GetCurrXL">GetCurrXL</a></code>, <code><a href="#topic+XLView">XLView</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  # Windows-specific example

XLGetRange(file="C:/My Documents/data.xls",
           sheet="Sheet1",
           range=c("A2:B5","M6:X23","C4:D40"))


# if the current region has to be read (incl. a header), place the cursor in the interesting region
# and run:
d.set &lt;- XLGetRange(header=TRUE)

# Get XL nameslist
nm &lt;- xl$ActiveWorkbook()$names()

lst &lt;- list()
for(i in 1:nm$count())
  lst[[i]] &lt;- c(name=nm[[i]]$name(), 
                address=nm[[i]]$refersToRange()$Address())
  
# the defined names
as.data.frame(do.call(rbind, lst), stringsAsFactors = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='XLSaveAs'>Save Excel File
</h2><span id='topic+XLSaveAs'></span>

<h3>Description</h3>

<p>Save the current workbook under the given name and format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XLSaveAs(fn, file_format = xlConst$XlFileFormat$xlWorkbookNormal, 
         xl = DescToolsOptions("lastXL"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XLSaveAs_+3A_fn">fn</code></td>
<td>
<p>the filename
</p>
</td></tr>
<tr><td><code id="XLSaveAs_+3A_file_format">file_format</code></td>
<td>
<p>the file format using the xl constant.
</p>
</td></tr>
<tr><td><code id="XLSaveAs_+3A_xl">xl</code></td>
<td>
<p>the pointer to a MS-Excel instance. An new instance can be created with <code>GetNewXL()</code>, returning the appropriate handle. A handle to an already running instance is returned by <code>GetCurrXL()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastXL")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns <code>TRUE</code> if the save operation has been successful
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+XLView">XLView</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: # Windows-specific example
XLView(d.diamonds)
XLSaveAs("Diamonds")
xl$quit()

## End(Not run)</code></pre>

<hr>
<h2 id='XLView'>
Use MS-Excel as Viewer for a Data.Frame
</h2><span id='topic+XLView'></span><span id='topic+XLKill'></span><span id='topic+ToXL'></span><span id='topic+ToXL.data.frame'></span><span id='topic+ToXL.matrix'></span><span id='topic+ToXL.default'></span>

<h3>Description</h3>

<p><code>XLView</code> can be used to view and edit a data.frame directly in MS-Excel, resp. to create a new data.frame in MS-Excel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XLView(x, col.names = TRUE, row.names = FALSE, na = "", 
       preserveStrings = FALSE, sep = ";")

ToXL(x, at, ..., xl=DescToolsOptions("lastXL"))
## S3 method for class 'data.frame'
ToXL(x, at, ..., xl=DescToolsOptions("lastXL"))
## S3 method for class 'matrix'
ToXL(x, at, ..., xl=DescToolsOptions("lastXL"))
## Default S3 method:
ToXL(x, at, byrow = FALSE, ..., xl=DescToolsOptions("lastXL"))

XLKill()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="XLView_+3A_x">x</code></td>
<td>
<p> is a data.frame to be transferred to MS-Excel. If data is missing a new file will be created.
</p>
</td></tr>
<tr><td><code id="XLView_+3A_row.names">row.names</code></td>
<td>
<p> either a logical value indicating whether the row names of x are to be written along with x, or
a character vector of row names to be written.</p>
</td></tr>
<tr><td><code id="XLView_+3A_col.names">col.names</code></td>
<td>
<p>either a logical value indicating whether the column names of x are to be written
along with x, or a character vector of column names to be written.
See the section on 'CSV files' <code><a href="utils.html#topic+write.table">write.table</a></code> for the meaning of <code>col.names = NA</code>. </p>
</td></tr>
<tr><td><code id="XLView_+3A_na">na</code></td>
<td>
<p>the string to use for missing values in the data.</p>
</td></tr>
<tr><td><code id="XLView_+3A_preservestrings">preserveStrings</code></td>
<td>
<p>logical, will preserve strings from being converted to numerics when imported in MS-Excel. See details. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="XLView_+3A_sep">sep</code></td>
<td>
<p>the field separator string used for export of the object. Values within each row of x are separated by this string.</p>
</td></tr>
<tr><td><code id="XLView_+3A_at">at</code></td>
<td>
<p>can be a range adress as character (e.g. <code>"A1"</code>), a vector of 2 integers (e.g <code>c(1,1)</code>) or a cell object as it is returned by <code>xl$Cells(1,1)</code>, denominating the left upper cell, where the data.frame will be placed in the MS-Excel sheet.</p>
</td></tr>
<tr><td><code id="XLView_+3A_byrow">byrow</code></td>
<td>
<p>logical, defines if the vector should be inserted by row or by column (default).</p>
</td></tr>
<tr><td><code id="XLView_+3A_xl">xl</code></td>
<td>
<p>the pointer to a MS-Excel instance. An new instance can be created with <code>GetNewXL()</code>, returning the appropriate handle. A handle to an already running instance is returned by <code>GetCurrXL()</code>.
Default is the last created pointer stored in <code>DescToolsOptions("lastXL")</code>.</p>
</td></tr>
<tr><td><code id="XLView_+3A_...">...</code></td>
<td>
<p>further arguments are not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data.frame will be exported in CSV format and then imported in MS-Excel. When importing data, MS-Excel will potentially change characters to numeric values. If this seems undesirable (maybe we're loosing leading zeros) then you should enclose the text in quotes and preset a =.
x &lt;- <code>gettextf('="%s"', x)</code> would do the trick.   <br /><br />
Take care: Changes to the data made in MS-Excel will NOT automatically be updated in the original data.frame.
The user will have to read the csv-file into R again.
See examples how to get this done.<br />
</p>
<p><code>ToXL()</code> is used to export data frames or vectors directly to MS-Excel, without export the data to a csv-file and import it on the XL side. So it it possible to export several data.frames into one Workbook and edit the tables after ones needs.
</p>
<p><code>XLKill</code> will kill a running XL instance (which might be invisible). Background is the fact, that the simple XL$quit() command
would not terminate a running XL task, but only set it invisible (observe the TaskManager). This ghost version may sometimes confuse XLView and hinder to create a new instance. In such cases you have to do the garbage collection...
</p>


<h3>Value</h3>

<p>the name/path of the temporary file edited in MS-Excel.
</p>


<h3>Note</h3>

<p>The function works only in Windows and requires <b>RDCOMClient</b> to be installed (see: Additional_repositories in DESCRIPTION of the package).
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, <code>ToXL()</code> is based on code of Duncan Temple Lang &lt;duncan@r-project.org&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GetNewXL">GetNewXL</a></code>, <code><a href="#topic+XLGetRange">XLGetRange</a></code>, <code><a href="#topic+XLGetWorkbook">XLGetWorkbook</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Windows-specific example
XLView(d.diamonds)

# edit an existing data.frame in MS-Excel, make changes and save there, return the filename
fn &lt;- XLView(d.diamonds)
# read the changed file and store in new data.frame
d.frm &lt;- read.table(fn, header=TRUE, quote="", sep=";")

# Create a new file, edit it in MS-Excel...
fn &lt;- XLView()
# ... and read it into a data.frame when in R again
d.set &lt;- read.table(fn, header=TRUE, quote="", sep=";")

# Export a ftable object, quite elegant...
XLView(format(ftable(Titanic), quote=FALSE), row.names = FALSE, col.names = FALSE)


# Export a data.frame directly to XL, combined with subsequent formatting

xl &lt;- GetNewXL()
owb &lt;- xl[["Workbooks"]]$Add()
sheet &lt;- xl$Sheets()$Add()
sheet[["name"]] &lt;- "pizza"

ToXL(d.pizza[1:10, 1:10], xl$Cells(1,1))

obj &lt;- xl$Cells()$CurrentRegion()
obj[["VerticalAlignment"]] &lt;- xlConst$xlTop

row &lt;- xl$Cells()$CurrentRegion()$rows(1)
# does not work:   row$font()[["bold"]] &lt;- TRUE
# works:
obj &lt;- row$font()
obj[["bold"]] &lt;- TRUE

obj &lt;- row$borders(xlConst$xlEdgeBottom)
obj[["linestyle"]] &lt;- xlConst$xlContinuous

cols &lt;- xl$Cells()$CurrentRegion()$columns(1)
cols[["HorizontalAlignment"]] &lt;- xlConst$xlLeft

xl$Cells()$CurrentRegion()[["EntireColumn"]]$AutoFit()
cols &lt;- xl$Cells()$CurrentRegion()$columns(4)
cols[["WrapText"]] &lt;- TRUE
cols[["ColumnWidth"]] &lt;- 80
xl$Cells()$CurrentRegion()[["EntireRow"]]$AutoFit()

sheet &lt;- xl$Sheets()$Add()
sheet[["name"]] &lt;- "whisky"
ToXL(d.whisky[1:10, 1:10], xl$Cells(1,1))
## End(Not run)
</code></pre>

<hr>
<h2 id='YuenTTest'> Yuen t-Test For Trimmed Means</h2><span id='topic+YuenTTest'></span><span id='topic+YuenTTest.default'></span><span id='topic+YuenTTest.formula'></span>

<h3>Description</h3>

<p>Performs one and two sample Yuen t-tests for trimmed means on vectors of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
YuenTTest(x, ...)

## Default S3 method:
YuenTTest(x, y = NULL, alternative = c("two.sided", "less", "greater"), 
          mu = 0, paired = FALSE, conf.level = 0.95, trim = 0.2, ... )

## S3 method for class 'formula'
YuenTTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="YuenTTest_+3A_x">x</code></td>
<td>
<p>numeric vector of data values. Non-finite (e.g. infinite or missing) values will be omitted.</p>
</td></tr>
<tr><td><code id="YuenTTest_+3A_y">y</code></td>
<td>
<p>an optional numeric vector of data values: as with x non-finite values will be omitted.</p>
</td></tr>
<tr><td><code id="YuenTTest_+3A_alternative">alternative</code></td>
<td>
<p>is a character string, one of <code>"greater"</code>,
<code>"less"</code>, or <code>"two.sided"</code>, or the initial letter of each,
indicating the specification of the alternative hypothesis. For
one-sample tests, <code>alternative</code> refers to the true
median of the parent population in relation to the hypothesized
value of the mean.</p>
</td></tr>
<tr><td><code id="YuenTTest_+3A_paired">paired</code></td>
<td>
<p>a logical indicating whether you want a paired z-test.</p>
</td></tr>
<tr><td><code id="YuenTTest_+3A_mu">mu</code></td>
<td>
<p>a number specifying the hypothesized mean of the population. </p>
</td></tr>
<tr><td><code id="YuenTTest_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level for the interval computation. </p>
</td></tr>
<tr><td><code id="YuenTTest_+3A_trim">trim</code></td>
<td>
<p>the fraction (0 to 0.5) of observations to be trimmed from each end of x before the mean is computed. Values of trim outside that range are taken as the nearest endpoint.</p>
</td></tr>
<tr><td><code id="YuenTTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and rhs the corresponding groups.</p>
</td></tr>  
<tr><td><code id="YuenTTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>. 
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>  
<tr><td><code id="YuenTTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>  
<tr><td><code id="YuenTTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain NAs. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>  
<tr><td><code id="YuenTTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>htest</code> containing the following components: 
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the t-statistic.</p>
</td></tr> 
<tr><td><code>parameter</code></td>
<td>
<p>the degrees of freedom for the t-statistic and the trim percentage used.</p>
</td></tr> 
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr> 
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the trimmed mean appropriate to the specified alternative hypothesis.</p>
</td></tr> 
<tr><td><code>estimate</code></td>
<td>
<p>the estimated trimmed mean or difference in trimmed means depending on whether it was a one-sample test or a two-sample test.
</p>
</td></tr> 
<tr><td><code>null.value</code></td>
<td>
<p>the specified hypothesized value of the trimmed mean or trimmed mean difference depending on whether it was a one-sample test or a two-sample test.</p>
</td></tr> 
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string indicating what type of test was performed.</p>
</td></tr> 
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Andri Signorell &lt;andri@signorell.net&gt;, based on R-Core code of <code><a href="stats.html#topic+t.test">t.test</a></code>
</p>


<h3>References</h3>

<p>Wilcox, R. R. (2005) Introduction to robust estimation and hypothesis testing. <em>Academic Press</em>.<br />
Yuen, K. K. (1974) The two-sample trimmed t for unequal population variances. <em>Biometrika</em>, 61, 165-170.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+t.test">t.test</a></code>, <code><a href="stats.html#topic+print.htest">print.htest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(25, 100, 5)
YuenTTest(x, mu=99)

# the classic interface
with(sleep, YuenTTest(extra[group == 1], extra[group == 2]))

# the formula interface
YuenTTest(extra ~ group, data = sleep)


# Stahel (2002), pp. 186, 196  
d.tyres &lt;- data.frame(A=c(44.5,55,52.5,50.2,45.3,46.1,52.1,50.5,50.6,49.2),
                      B=c(44.9,54.8,55.6,55.2,55.6,47.7,53,49.1,52.3,50.7))
with(d.tyres, YuenTTest(A, B, paired=TRUE))


d.oxen &lt;- data.frame(ext=c(2.7,2.7,1.1,3.0,1.9,3.0,3.8,3.8,0.3,1.9,1.9),
                     int=c(6.5,5.4,8.1,3.5,0.5,3.8,6.8,4.9,9.5,6.2,4.1))
with(d.oxen, YuenTTest(int, ext, paired=FALSE))
</code></pre>

<hr>
<h2 id='ZeroIfNA'>Replace NAs by 0
</h2><span id='topic+ZeroIfNA'></span><span id='topic+NAIfZero'></span><span id='topic+BlankIfNA'></span><span id='topic+NAIfBlank'></span><span id='topic+NAIf'></span><span id='topic+Impute'></span>

<h3>Description</h3>

<p>Replace NAs in a numeric vector x with 0. This function has the same logic as the zeroifnull function in SQL. <code>NAIfZero()</code> does replace zeros with <code>NA</code>.
<code>BlankIfNA()</code> and <code>NAIfBlank()</code> do the same, but for character vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ZeroIfNA(x)
NAIfZero(x)
NAIf(x, what)

BlankIfNA(x, blank="")
NAIfBlank(x)

Impute(x, FUN = function(x) median(x, na.rm = TRUE))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ZeroIfNA_+3A_x">x</code></td>
<td>
<p>the vector x, whose NAs should be overwritten with 0s.
</p>
</td></tr>
<tr><td><code id="ZeroIfNA_+3A_blank">blank</code></td>
<td>
<p>a character to be used for &quot;blank&quot;. Default is an empty string (&quot;&quot;).
</p>
</td></tr>
<tr><td><code id="ZeroIfNA_+3A_what">what</code></td>
<td>
<p>a vector of elements to be set to <code>NA</code> in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ZeroIfNA_+3A_fun">FUN</code></td>
<td>
<p>the name of a function to be used as imputation. Can as well be a self defined function or a constant value.
Default is <code><a href="stats.html#topic+median">median</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the edited vector x
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+replace">replace</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z &lt;- c(8, NA, 9, NA, 3)

ZeroIfNA(z)
# [1] 8 0 9 0 3

# set 8 and 9 to NA
NAIf(ZeroIfNA(z), what=c(8, 9))


Impute(z)
# [1] 8 8 9 8 3


z &lt;- c("a", NA, "", NA, "k")

BlankIfNA(z)
# [1] "a" "" "" "" "k"

</code></pre>

<hr>
<h2 id='Zodiac'>Calculate the Zodiac of a Date
</h2><span id='topic+Zodiac'></span>

<h3>Description</h3>

<p>Calculate the sign of zodiac of a date.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Zodiac(x, lang = c("engl", "deu"), stringsAsFactors = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Zodiac_+3A_x">x</code></td>
<td>
<p>the date to be transformed.</p>
</td></tr>
<tr><td><code id="Zodiac_+3A_lang">lang</code></td>
<td>
<p>the language of the zodiac names, can be english (default) or german (<code>"deu"</code>).</p>
</td></tr>
<tr><td><code id="Zodiac_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>logical. If set to <code>TRUE</code> (default) the result will consist of a factor with zodiac signs as levels.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The really relevant things can sometimes hardly be found. You just discovered such a function... ;-)
</p>
<p>The following rule to determine zodiac symbols is implemented:
</p>
<pre>Dec. 22  - Jan. 19  : Capricorn 
Jan. 20  - Feb. 17  : Aquarius 
Feb. 18  - Mar. 19  : Pisces 
March 20 - April 19 : Aries 
April 20 - May 19   : Taurus 
May 20   - June 20  : Gemini 
June 21  - July 21  : Cancer 
July 22  - Aug. 22  : Leo 
Aug 23   - Sept. 21 : Virgo 
Sept. 22 - Oct. 22  : Libran 
Oct. 23  - Nov. 21  : Scorpio 
Nov. 22  - Dec. 21  : Sagittarius
</pre>


<h3>Value</h3>

<p>character vector or factor with the zodiac.
</p>


<h3>Author(s)</h3>

<p>Andri Signorell &lt;andri@signorell.net&gt;, based on code from Markus Naepflin
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Year">Year</a></code> and other date functions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Zodiac(as.Date(c("1937-07-28", "1936-06-01", "1966-02-25",
                 "1964-11-17", "1972-04-25")), lang="deu")

d &lt;- sample(seq(as.Date("2015-01-01"), as.Date("2015-12-31"), 1), 120)
z &lt;- Zodiac(d)
Desc(z)
</code></pre>

<hr>
<h2 id='ZTest'> Z Test for Known Population Standard Deviation </h2><span id='topic+ZTest'></span><span id='topic+ZTest.default'></span><span id='topic+ZTest.formula'></span>

<h3>Description</h3>

<p>Compute the test of hypothesis and compute confidence interval on the
mean of a population when the standard deviation of the population is known.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ZTest(x, ...)

## Default S3 method:
ZTest(x, y = NULL, alternative = c("two.sided", "less", "greater"),
      paired = FALSE, mu = 0, sd_pop, conf.level = 0.95, ... )

## S3 method for class 'formula'
ZTest(formula, data, subset, na.action, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ZTest_+3A_x">x</code></td>
<td>
<p>numeric vector of data values. Non-finite (e.g. infinite or missing) values will be omitted.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_y">y</code></td>
<td>
<p>an optional numeric vector of data values: as with x non-finite values will be omitted.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_mu">mu</code></td>
<td>
<p>a number specifying the hypothesized mean of the population. </p>
</td></tr>
<tr><td><code id="ZTest_+3A_sd_pop">sd_pop</code></td>
<td>
<p>a number specifying the known standard deviation of the population. </p>
</td></tr>
<tr><td><code id="ZTest_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative
hypothesis, must be one of <code>"two.sided"</code> (default),
<code>"greater"</code> or <code>"less"</code>.  You can specify just the initial
letter. <br /> For
one-sample tests, <code>alternative</code> refers to the true
mean of the parent population in relation to the hypothesized
value of the mean.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_paired">paired</code></td>
<td>
<p>a logical indicating whether you want a paired z-test.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level for the interval computation. </p>
</td></tr>
<tr><td><code id="ZTest_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>lhs ~ rhs</code> where <code>lhs</code> gives the data values and <code>rhs</code>
a factor with two levels giving the corresponding groups.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_data">data</code></td>
<td>
<p>an optional matrix or data frame (or similar: see <code><a href="stats.html#topic+model.frame">model.frame</a></code>) containing the variables in the formula <code>formula</code>.
By default the variables are taken from <code>environment(formula)</code>.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data contain <code>NA</code>s. Defaults to <code>getOption("na.action")</code>.</p>
</td></tr>
<tr><td><code id="ZTest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most introductory statistical texts introduce inference by using the z-test
and z-based confidence intervals based on knowing the population
standard deviation. However statistical packages often do not include
functions to do z-tests since the t-test is usually more appropriate
for real world situations. This function is meant to be used during
that short period of learning when the student is learning about
inference using z-procedures, but has not learned the t-based
procedures yet.  Once the student has learned about the
t-distribution the <code>t.test()</code> function should be used instead of this
one (but the syntax is very similar, so this function should be an
appropriate introductory step to learning <code>t.test()</code>).
</p>
<p>The formula interface is only applicable for the 2-sample tests.
</p>


<h3>Value</h3>

<p>A list with class &quot;<code>htest</code>&quot; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p> the value of the z-statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>   the p-value for the test</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>
<p>a confidence interval for the mean appropriate to the specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>the estimated mean or difference in means depending on whether it was a one-sample test or a two-sample test.</p>
</td></tr>
<tr><td><code>null.value</code></td>
<td>
<p>the specified hypothesized value of the mean or mean difference depending on whether it was a one-sample test or a two-sample test.</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>a character string describing the alternative hypothesis.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>  a character string indicating what type of test was performed.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Andri Signorell &lt;andri@signorell.net&gt;, based on R-Core code of <code><a href="stats.html#topic+t.test">t.test</a></code>,<br />
documentation partly from Greg Snow &lt;greg.snow@imail.org&gt;</p>


<h3>References</h3>

<p>Stahel, W. (2002) <em>Statistische Datenanalyse, 4th ed</em>, vieweg
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+t.test">t.test</a></code>, <code><a href="stats.html#topic+print.htest">print.htest</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(25, 100, 5)
ZTest(x, mu=99, sd_pop=5)

# the classic interface
with(sleep, ZTest(extra[group == 1], extra[group == 2], sd_pop=2))

# the formula interface
ZTest(extra ~ group, data = sleep, sd_pop=2)


# Stahel (2002), pp. 186, 196

d.tyres &lt;- data.frame(A=c(44.5,55,52.5,50.2,45.3,46.1,52.1,50.5,50.6,49.2),
                      B=c(44.9,54.8,55.6,55.2,55.6,47.7,53,49.1,52.3,50.7))
with(d.tyres, ZTest(A, B, sd_pop=3, paired=TRUE))


d.oxen &lt;- data.frame(ext=c(2.7,2.7,1.1,3.0,1.9,3.0,3.8,3.8,0.3,1.9,1.9),
                     int=c(6.5,5.4,8.1,3.5,0.5,3.8,6.8,4.9,9.5,6.2,4.1))
with(d.oxen, ZTest(int, ext, sd_pop=1.8, paired=FALSE))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
