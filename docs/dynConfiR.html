<!DOCTYPE html><html lang="en"><head><title>Help for package dynConfiR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dynConfiR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dynConfiR-package'><p>The dynConfiR Package</p></a></li>
<li><a href='#ConfidenceOrientation'><p>Confidence and response time data</p></a></li>
<li><a href='#d2DSD'><p>Pleskac and Busemeyer's 2DSD Model for Decision Confidence</p></a></li>
<li><a href='#dDDMConf'><p>Drift Diffusion Model with time-dependent confidence</p></a></li>
<li><a href='#dynaViTE'><p>Dynamical visibility, time, and evidence model (dynaViTE) and Dynamical weighted evidence and visibility model (dynWEV)</p></a></li>
<li><a href='#fitRTConf'><p>Function for fitting sequential sampling confidence models</p></a></li>
<li><a href='#fitRTConfModels'><p>Function for fitting several sequential sampling confidence models in parallel</p></a></li>
<li><a href='#LogLikRM'><p>Log-Likelihood functions for the independent and partially anti-correlated race models of confidence</p></a></li>
<li><a href='#LogLikWEV'><p>Log-Likelihood functions for the dynWEV and 2DSD models of confidence</p></a></li>
<li><a href='#PDFtoQuantiles'><p>Get Quantiles from vectors of PDF or CDF values</p></a></li>
<li><a href='#predictDDMConf'><p>Prediction of Confidence Rating and Reaction Time Distribution in the drift diffusion confidence model</p></a></li>
<li><a href='#predictRM'><p>Prediction of Confidence Rating and Reaction Time Distribution in race models of confidence</p></a></li>
<li><a href='#predictRTConf'><p>Prediction of confidence rating and response time distribution for sequential sampling confidence models</p></a></li>
<li><a href='#predictRTConfModels'><p>Prediction of confidence and RT distributions for several sequential</p>
sampling confidence models and parameter constellations in parallel</a></li>
<li><a href='#predictWEV'><p>Prediction of Confidence Rating and Response Time Distribution in dynaViTE,</p>
dynWEV, and 2DSD confidence models</a></li>
<li><a href='#RaceModels'><p>Independent and partially anti-correlated Race Model for Decision Confidence</p></a></li>
<li><a href='#rLCA'><p>Simulation of confidence ratings and RTs in leaky competing accumulator model</p></a></li>
<li><a href='#simulateRM'><p>Simulation of confidence ratings and RTs in race confidence models</p></a></li>
<li><a href='#simulateRTConf'><p>Simulation of confidence ratings and RTs in sequential sampling confidence models</p></a></li>
<li><a href='#simulateWEV'><p>Simulation of confidence ratings and RTs in dynWEV and 2DSD confidence models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Dynamic Models for Confidence and Response Time Distributions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian Hellmann &lt;sebastian.hellmann@ku.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides density functions for the joint distribution of
    choice, response time and confidence for discrete confidence judgments
    as well as functions for parameter fitting, prediction and simulation
    for various dynamical models of decision confidence.  All models are
    explained in detail by Hellmann et al.  (2023;
    Preprint available at <a href="https://osf.io/9jfqr/">https://osf.io/9jfqr/</a>, published version: &lt;<a href="https://doi.org/10.1037%2Frev0000411">doi:10.1037/rev0000411</a>&gt;).  Implemented models are the dynaViTE model, 
    dynWEV model, the 2DSD model (Pleskac &amp; Busemeyer, 2010, &lt;<a href="https://doi.org/10.1037%2Fa0019737">doi:10.1037/a0019737</a>&gt;),
    and various race models.  C++ code for dynWEV and 2DSD is based on the
    'rtdists' package by Henrik Singmann.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/SeHellmann/dynConfiR">https://github.com/SeHellmann/dynConfiR</a>,
<a href="https://sehellmann.github.io/dynConfiR/">https://sehellmann.github.io/dynConfiR/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/SeHellmann/dynConfiR">https://github.com/SeHellmann/dynConfiR</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, magrittr, minqa, parallel, progress, Rcpp, rlang, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, ggplot2, Hmisc, knitr, logger, rmarkdown, testthat (&ge;
3.0.0), tidyr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-29 18:10:02 UTC</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-29 17:50:05 UTC; PPA859</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Sebastian Hellmann
    <a href="https://orcid.org/0000-0002-3621-6343"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Manuel Rausch <a href="https://orcid.org/0000-0002-5805-5544"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, fnd]</td>
</tr>
</table>
<hr>
<h2 id='dynConfiR-package'>The dynConfiR Package</h2><span id='topic+dynConfiR-package'></span>

<h3>Description</h3>

<p>Dynamic Models for Confidence and Response Time Distributions
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> dynConfiR</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.0.4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-04-20</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 4.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=3)</td>
</tr>
<tr>
 <td style="text-align: left;">
URL: </td><td style="text-align: left;"> https://github.com/SeHellmann/dynConfiR</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Provides response time and confidence distributions (density/PDF) for following models: dynaViTE,dynWEV, 2DSD, 2DSDT, IRM and PCRM
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann
</p>

<hr>
<h2 id='ConfidenceOrientation'>Confidence and response time data</h2><span id='topic+ConfidenceOrientation'></span>

<h3>Description</h3>

<p>A data set containing results from an orientation discrimination experiment
with confidence judgments. The data set includes results from 16 participants
and 3 sessions. The task was to identify the orientation (horizontal or vertical)
of a grid that was briefly visible and then covered by a mask in form of a
checkerboard pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ConfidenceOrientation)
</code></pre>


<h3>Format</h3>

<p>A data frame with 25920 rows and 12 variables:
</p>

<dl>
<dt>participant</dt><dd><p>integer values as unique participant identifier</p>
</dd>
<dt>session</dt><dd><p>session identifier ranging from 1 to 3</p>
</dd>
<dt>gender</dt><dd><p>gender of the participant: &quot;w&quot; for female; &quot;m&quot; for male participants</p>
</dd>
<dt>age</dt><dd><p>the age of participants in years</p>
</dd>
<dt>SOA</dt><dd><p>stimulus-onset-asynchrony in ms (i.e. time between stimulus and mask onset)</p>
</dd>
<dt>orientation</dt><dd><p>orientation of the target stimulus (0: vertical, 90: horizontal)</p>
</dd>
<dt>stimulus</dt><dd><p>stimulus identity (&quot;senkrecht&quot;: vertical, &quot;waagrecht&quot;: horizontal)</p>
</dd>
<dt>response</dt><dd><p>response for the discrimination task (see stimulus column)</p>
</dd>
<dt>correct</dt><dd><p>0-1 column indicating whether the discrimination response was correct (1) or not (0)</p>
</dd>
<dt>rt</dt><dd><p>response time for the discrimination response in sec</p>
</dd>
<dt>cont_rating</dt><dd><p>confidence rating as registered (continuous values ranging from -1 (unsure) to 1 (sure))</p>
</dd>
<dt>disc_rating</dt><dd><p>confidence rating discretized in 5 steps using equidistant breaks</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/SeHellmann/SeqSamplingConfidenceModels">https://github.com/SeHellmann/SeqSamplingConfidenceModels</a>
</p>

<hr>
<h2 id='d2DSD'>Pleskac and Busemeyer's 2DSD Model for Decision Confidence</h2><span id='topic+d2DSD'></span><span id='topic+2DSD'></span><span id='topic+two-stage'></span><span id='topic+r2DSD'></span>

<h3>Description</h3>

<p>Likelihood function and random number generator for a generalization of the
2DSD Model presented by Pleskac &amp; Busemeyer (2010). It includes following
parameters:
DDM parameters: <code>a</code> (threshold separation), <code>z</code>
(starting point; relative), <code>v</code> (drift rate), <code>t0</code> (non-decision time/
response time constant), <code>d</code> (differences in speed of response execution),
<code>sv</code> (inter-trial-variability of drift), <code>st0</code> (inter-trial-variability
of non-decisional components), <code>sz</code> (inter-trial-variability of relative
starting point), <code>s</code> (diffusion constant).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d2DSD(rt, response = "upper", th1, th2, a, v, t0 = 0, z = 0.5, d = 0,
  sz = 0, sv = 0, st0 = 0, tau = 1, lambda = 0, s = 1,
  simult_conf = FALSE, precision = 1e-05, z_absolute = FALSE,
  stop_on_error = TRUE, stop_on_zero = FALSE)

r2DSD(n, a, v, t0 = 0, z = 0.5, d = 0, sz = 0, sv = 0, st0 = 0,
  tau = 1, lambda = 0, s = 1, delta = 0.01, maxrt = 15,
  simult_conf = FALSE, z_absolute = FALSE, stop_on_error = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="d2DSD_+3A_rt">rt</code></td>
<td>
<p>a vector of RTs. Or for convenience also a <code>data.frame</code> with columns
<code>rt</code> and <code>response</code>.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_response">response</code></td>
<td>
<p>character vector, indicating the decision, i.e. which boundary was
met first. Possible values are <code>c("upper", "lower")</code> (possibly abbreviated) and
<code>"upper"</code> being the default. Alternatively, a numeric vector with values 1=lower
and 2=upper or -1=lower and 1=upper, respectively. For convenience, <code>response</code> is
converted via <code>as.numeric</code> also
allowing factors. Ignored if the first argument is a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_th1">th1</code></td>
<td>
<p>together with <code>th2</code>: scalars or numerical vectors giving the lower and upper
bound of the interval, in which the accumulator should end at the time of the
confidence judgment (i.e. at time <code>rt</code>+<code>tau</code>). Only values with
<code>th2</code>&gt;=<code>th1</code> are accepted.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_th2">th2</code></td>
<td>
<p>(see <code>th1</code>)</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_a">a</code></td>
<td>
<p>threshold separation. Amount of information that is considered for a decision.
Large values indicate a conservative decisional style. Typical range: 0.5 &lt; <code>a</code> &lt; 2</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_v">v</code></td>
<td>
<p>drift rate. Average slope of the information accumulation process. The drift
gives information about the speed and direction of the accumulation of information.
Large (absolute) values of drift indicate a good performance. If received information
supports the response linked to the upper threshold the sign will be positive and vice
versa. Typical range: -5 &lt; <code>v</code> &lt; 5</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_t0">t0</code></td>
<td>
<p>non-decision time or response time constant (in seconds). Lower bound for the
duration of all non-decisional processes (encoding and response execution). Typical
range: 0.1 &lt; <code>t0</code> &lt; 0.5. Default is 0.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_z">z</code></td>
<td>
<p>(by default relative) starting point. Indicator of an a priori bias in decision
making. When the relative starting point <code>z</code> deviates from <code>0.5</code>, the amount
of information necessary for a decision differs between response alternatives. Default
is <code>0.5</code> (i.e., no bias).</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_d">d</code></td>
<td>
<p>differences in speed of response execution (in seconds). Positive values
indicate that response execution is faster for responses linked to the upper threshold
than for responses linked to the lower threshold. Typical range: -0.1 &lt; <code>d</code> &lt; 0.1.
Default is 0.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_sz">sz</code></td>
<td>
<p>inter-trial-variability of starting point. Range of a uniform distribution
with mean <code>z</code> describing the distribution of actual starting points from specific
trials. Values different from 0 can predict fast errors (but can slow computation
considerably). Typical range: 0 &lt; <code>sz</code> &lt; 0.2. Default is 0. (Given in relative
range i.e. bounded by 2*min(z, 1-z))</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_sv">sv</code></td>
<td>
<p>inter-trial-variability of drift rate. Standard deviation of a normal
distribution with mean <code>v</code> describing the distribution of actual drift rates
from specific trials. Values different from 0 can predict slow errors.
Typical range: 0 &lt; <code>sv</code> &lt; 2. Default is 0.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_st0">st0</code></td>
<td>
<p>inter-trial-variability of non-decisional components. Range of a uniform
distribution with mean <code>t0 + st0/2</code> describing the distribution of actual
<code>t0</code> values across trials. Accounts for response times below <code>t0</code>.
Reduces skew of predicted RT distributions. Values different from 0 can slow computation
considerably. Typical range: 0 &lt; <code>st0</code> &lt; 0.2. Default is 0.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_tau">tau</code></td>
<td>
<p>post-decisional accumulation time. The length of the time period after the
decision was made until the confidence judgment is made. Range: <code>tau</code>&gt;0.
Default: <code>tau</code>=1.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_lambda">lambda</code></td>
<td>
<p>power for judgment time in the division of the confidence measure
by the judgment time (Default: 0, i.e. no division which is the version of
2DSD proposed by Pleskac and Busemeyer)</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_s">s</code></td>
<td>
<p>diffusion constant. Standard deviation of the random noise of the diffusion
process (i.e., within-trial variability), scales <code>a</code>, <code>v</code>, <code>sv</code>,
and <code>th</code>'s. Needs to be fixed to a constant in most applications. Default is 1.
Note that the default used by Ratcliff and in other applications is often 0.1.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical. Whether in the experiment confidence was reported
simultaneously with the decision, as then decision and confidence judgment are
assumed to have happened subsequent before response and computations are different,
when there is an observable interjudgment time (then <code>simult_conf</code> should be <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_precision">precision</code></td>
<td>
<p><code>numerical</code> scalar value. Precision of calculation. Corresponds
to the stepsize of integration w.r.t. <code>z</code> and <code>t0</code>. Default is 1e-5.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_z_absolute">z_absolute</code></td>
<td>
<p>logical. Determines whether <code>z</code> is treated as absolute start point
(<code>TRUE</code>) or relative (<code>FALSE</code>; default) to <code>a</code>.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_stop_on_error">stop_on_error</code></td>
<td>
<p>Should the diffusion functions return 0 if the parameters values
are outside the allowed range (= <code>FALSE</code>) or produce an error in this case
(= <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_stop_on_zero">stop_on_zero</code></td>
<td>
<p>Should the computation of densities stop as soon as a density value of 0 occurs.
This may save a lot of time if the function is used for a likelihood function. Default: FALSE</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_n">n</code></td>
<td>
<p>integer. The number of samples generated.</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_delta">delta</code></td>
<td>
<p>numeric. Discretization step size for simulations in the stochastic process</p>
</td></tr>
<tr><td><code id="d2DSD_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. Maximum decision time returned. If the simulation of the stochastic
process exceeds a decision time of <code>maxrt</code>, the <code>response</code> will be set to 0 and the <code>maxrt</code>
will be returned as <code>rt</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For confidence: <code>tau</code> (post-decisional accumulation time), <code>lambda</code>
the exponent of judgment time for the division by judgment time in the confidence measure,
<code>th1</code> and <code>th2</code> (lower and upper thresholds for confidence interval).
</p>
<p><strong>Note that the parameterization or defaults of non-decision time variability
<code>st0</code> and diffusion constant <code>s</code> differ from what is often found in the
literature.</strong>
</p>
<p>The drift diffusion model (DDM; Ratcliff
and McKoon, 2008) is a mathematical model for two-choice discrimination tasks. It is
based on the assumption that information is accumulated continuously until one of two
decision thresholds is hit. For introduction see Ratcliff and McKoon (2008).
</p>
<p>The 2DSD is an extension of the DDM to explain confidence judgments based
on the preceding decision. It assumes a post decisional period where the process
continues the accumulation of information. At the end of the period a confidence
judgment (i.e. a judgment of the probability that the decision was correct) is made
based on the state of the process. Here, we use a given interval, given by <code>th1</code>
and <code>th2</code>, assuming that the data is given with discrete judgments and
pre-processed, s.t. these discrete ratings are translated to the respective intervals.
The 2DSD Model was proposed by Pleskac and Busemeyer (2010).
</p>
<p>All functions are fully vectorized across all parameters
as well as the response to match the length or <code>rt</code> (i.e., the output
is always of length equal to <code>rt</code>).
This allows for trial wise parameters for each model parameter.
</p>
<p>For convenience, the function allows that the first argument is a <code>data.frame</code>
containing the information of the first and second argument in two columns (i.e.,
<code>rt</code> and <code>response</code>). Other columns (as well as passing <code>response</code>
separately argument) will be ignored.
</p>


<h3>Value</h3>

<p><code>d2DSD</code> gives the density/likelihood/probability of the diffusion process
producing a decision of <code>response</code> at time <code>rt</code> and a confidence
judgment corresponding to the interval [ <code>th1</code>, <code>th2</code>].
The value will be a numeric vector of the same length as <code>rt</code>.
</p>
<p><code>r2DSD</code> returns a <code>data.frame</code> with three columns and <code>n</code> rows. Column names are <code>rt</code> (response
time), <code>response</code> (-1 (lower) or 1 (upper), indicating which bound was hit), and <code>conf</code> (the
value of the confidence measure; not discretized!).
</p>
<p>The distribution parameters (as well as <code>response</code>, <code>tau</code>, <code>th1</code>
and <code>th2</code>) are recycled to the length of the result. In other words, the functions
are completely vectorized for all parameters and even the response boundary.
</p>


<h3>Note</h3>

<p>The parameterization of the non-decisional components, <code>t0</code> and <code>st0</code>,
differs from the parameterization sometimes used in the literature.
In the present case <code>t0</code> is the lower bound of the uniform distribution of length
<code>st0</code>, but <em>not</em> its midpoint. The parameterization employed here is in line
with the functions in the <code>rtdists</code> package.
</p>
<p>The default diffusion constant <code>s</code> is 1 and not 0.1 as in most applications of
Roger Ratcliff and others. Usually <code>s</code> is not specified as the other parameters:
<code>a</code>, <code>v</code>, and <code>sv</code>, may be scaled to produce the same distributions
(as is done in the code).
</p>
<p>The function code is basically an extension of the <code>ddiffusion</code> function from the
package <code>rtdists</code> for the Ratcliff diffusion model.
</p>


<h3>Author(s)</h3>

<p>For the original <code>rtdists</code> package: Underlying C code by Jochen Voss and Andreas Voss. Porting and R wrapping by Matthew Gretton, Andrew Heathcote, Scott Brown, and Henrik Singmann. <code>qdiffusion</code> by Henrik Singmann. For the <code>d2DSD</code> function the C code was extended by Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Pleskac, T. J., &amp; Busemeyer, J. R. (2010). Two-Stage Dynamic Signal Detection: A Theory of Choice, Decision Time, and Confidence, <em>Psychological Review</em>, 117(3), 864-901. doi:10.1037/a0019737
</p>
<p>Ratcliff, R., &amp; McKoon, G. (2008). The diffusion decision model: Theory and data for two-choice decision tasks. <em>Neural Computation</em>, 20(4), 873-922.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot rt distribution ignoring confidence
curve(d2DSD(x, "upper", -Inf, Inf, tau=1, a=2, v=0.4, sz=0.2, sv=0.9), xlim=c(0, 2), lty=2)
curve(d2DSD(x, "lower", -Inf, Inf, tau=1, a=2, v=0.4, sz=0.2, sv=0.9), col="red", lty=2, add=TRUE)
curve(d2DSD(x, "upper", -Inf, Inf, tau=1, a=2, v=0.4),add=TRUE)
curve(d2DSD(x, "lower", -Inf, Inf, tau=1, a=2, v=0.4), col="red", add=TRUE)
# Generate a random sample
dfu &lt;- r2DSD(5000, a=2,v=0.5,t0=0,z=0.5,d=0,sz=0,sv=0, st0=0,  tau=1, s=1)
# Same RT distribution but upper and lower responses changed
dfl &lt;- r2DSD(50, a=2,v=-0.5,t0=0,z=0.5,d=0,sz=0,sv=0, st0=0,  tau=1, s=1)
head(dfu)

d2DSD(dfu, th1=-Inf, th2=Inf, a=2, v=.5)[1:5]
# Scaling diffusion parameters leads do same density values
s &lt;- 2
d2DSD(dfu, th1=-Inf, th2=Inf, a=2*s, v=.5*s, s=2)[1:5]
if (requireNamespace("ggplot2", quietly = TRUE)) {
  require(ggplot2)
  ggplot(dfu, aes(x=rt, y=conf))+
    stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE) +
    facet_wrap(~response)
}
boxplot(conf~response, data=dfu)

# Restricting to specific confidence region
dfu &lt;- dfu[dfu$conf &gt;0 &amp; dfu$conf &lt;1,]
d2DSD(dfu, th1=0, th2=1, a=2, v=0.5)[1:5]

# If lower confidence threshold is higher than the upper, the function throws an error,
# except when stop_on_error is FALSE
d2DSD(dfu[1:5,], th1=1, th2=0, a=2, v=0.5, stop_on_error = FALSE)

</code></pre>

<hr>
<h2 id='dDDMConf'>Drift Diffusion Model with time-dependent confidence</h2><span id='topic+dDDMConf'></span><span id='topic+DDMConf'></span><span id='topic+rDDMConf'></span>

<h3>Description</h3>

<p>Likelihood function and random number generator for the Drift Diffusion Model
with confidence computed as decision time. It includes following parameters:
DDM parameters: <code>a</code> (threshold separation), <code>z</code>
(starting point; relative), <code>v</code> (drift rate), <code>t0</code> (non-decision time/
response time constant), <code>d</code> (differences in speed of response execution),
<code>sv</code> (inter-trial-variability of drift), <code>st0</code> (inter-trial-variability
of non-decision components), <code>sz</code> (inter-trial-variability of relative
starting point), <code>s</code> (diffusion constant).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dDDMConf(rt, response = "upper", th1, th2, a, v, t0 = 0, z = 0.5,
  d = 0, sz = 0, sv = 0, st0 = 1, s = 1, precision = 1e-05,
  z_absolute = FALSE, stop_on_error = TRUE, stop_on_zero = FALSE,
  st0stepsize = 0.001)

rDDMConf(n, a, v, t0 = 0, z = 0.5, d = 0, sz = 0, sv = 0, st0 = 2,
  s = 1, delta = 0.01, maxrt = 15, z_absolute = FALSE,
  stop_on_error = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dDDMConf_+3A_rt">rt</code></td>
<td>
<p>a vector of RTs. Or for convenience also a <code>data.frame</code> with columns
<code>rt</code> and <code>response</code>.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_response">response</code></td>
<td>
<p>character vector, indicating the decision, i.e. which boundary was
met first. Possible values are <code>c("upper", "lower")</code> (possibly abbreviated) and
<code>"upper"</code> being the default. Alternatively, a numeric vector with values 1=lower
and 2=upper or -1=lower and 1=upper, respectively. For convenience, <code>response</code> is
converted via <code>as.numeric</code> also
allowing factors. Ignored if the first argument is a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_th1">th1</code></td>
<td>
<p>together with <code>th2</code>: scalars or numerical vectors giving the lower and upper
bound of the interval, in which the accumulator should end at the time of the
confidence judgment (i.e. at time <code>rt</code>+<code>tau</code>). Only values with
<code>th2</code>&gt;=<code>th1</code> are accepted.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_th2">th2</code></td>
<td>
<p>(see <code>th1</code>)</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_a">a</code></td>
<td>
<p>threshold separation. Amount of information that is considered for a decision.
Large values indicate a conservative decisional style. Typical range: 0.5 &lt; <code>a</code> &lt; 2</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_v">v</code></td>
<td>
<p>drift rate. Average slope of the information accumulation process. The drift
gives information about the speed and direction of the accumulation of information.
Large (absolute) values of drift indicate a good performance. If received information
supports the response linked to the upper threshold the sign will be positive and vice
versa. Typical range: -5 &lt; <code>v</code> &lt; 5</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_t0">t0</code></td>
<td>
<p>non-decision time or response time constant (in seconds). Lower bound for the
duration of all non-decisional processes (encoding and response execution). Typical
range: 0.1 &lt; <code>t0</code> &lt; 0.5. Default is 0.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_z">z</code></td>
<td>
<p>(by default relative) starting point. Indicator of an a priori bias in decision
making. When the relative starting point <code>z</code> deviates from <code>0.5</code>, the amount
of information necessary for a decision differs between response alternatives. Default
is <code>0.5</code> (i.e., no bias).</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_d">d</code></td>
<td>
<p>differences in speed of response execution (in seconds). Positive values
indicate that response execution is faster for responses linked to the upper threshold
than for responses linked to the lower threshold. Typical range: -0.1 &lt; <code>d</code> &lt; 0.1.
Default is 0.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_sz">sz</code></td>
<td>
<p>inter-trial-variability of starting point. Range of a uniform distribution
with mean <code>z</code> describing the distribution of actual starting points from specific
trials. Values different from 0 can predict fast errors (but can slow computation
considerably). Typical range: 0 &lt; <code>sz</code> &lt; 0.2. Default is 0. (Given in relative
range i.e. bounded by 2*min(z, 1-z))</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_sv">sv</code></td>
<td>
<p>inter-trial-variability of drift rate. Standard deviation of a normal
distribution with mean <code>v</code> describing the distribution of actual drift rates
from specific trials. Values different from 0 can predict slow errors.
Typical range: 0 &lt; <code>sv</code> &lt; 2. Default is 0.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_st0">st0</code></td>
<td>
<p>inter-trial-variability of non-decisional components. Range of a uniform
distribution with mean <code>t0 + st0/2</code> describing the distribution of actual
<code>t0</code> values across trials. Accounts for response times below <code>t0</code>.
Reduces skew of predicted RT distributions. Values different from 0 can slow computation
considerably. Typical range: 0 &lt; <code>st0</code> &lt; 0.2. Default is 0.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_s">s</code></td>
<td>
<p>diffusion constant. Standard deviation of the random noise of the diffusion
process (i.e., within-trial variability), scales <code>a</code>, <code>v</code>, <code>sv</code>,
and <code>th</code>'s. Needs to be fixed to a constant in most applications. Default is 1.
Note that the default used by Ratcliff and in other applications is often 0.1.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_precision">precision</code></td>
<td>
<p><code>numerical</code> scalar value. Precision of calculation. Corresponds
to the stepsize of integration w.r.t. <code>z</code>. Default is 1e-5.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_z_absolute">z_absolute</code></td>
<td>
<p>logical. Determines whether <code>z</code> is treated as absolute start point
(<code>TRUE</code>) or relative (<code>FALSE</code>; default) to <code>a</code>.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_stop_on_error">stop_on_error</code></td>
<td>
<p>Should the diffusion functions return 0 if the parameters values
are outside the allowed range (= <code>FALSE</code>) or produce an error in this case
(= <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_stop_on_zero">stop_on_zero</code></td>
<td>
<p>Should the computation of densities stop as soon as a density value of 0 occurs.
This may save a lot of time if the function is used for a likelihood function. Default: <code>FALSE</code></p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_st0stepsize">st0stepsize</code></td>
<td>
<p>numerical scalar value. Stepsize for integration over <code>t0</code>.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_n">n</code></td>
<td>
<p>integer. The number of samples generated.</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_delta">delta</code></td>
<td>
<p>numeric. Discretization step size for simulations in the stochastic process</p>
</td></tr>
<tr><td><code id="dDDMConf_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. Maximum decision time returned. If the simulation of the stochastic
process exceeds a decision time of <code>maxrt</code>, the <code>response</code> will be set to 0 and the <code>maxrt</code>
will be returned as <code>rt</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the confidence part: <code>th1</code> and <code>th2</code> (lower and upper
thresholds for decision time interval).
</p>
<p><strong>Note that the parameterization or defaults of non-decision time variability
<code>st0</code> and diffusion constant <code>s</code> differ from what is often found in the
literature.</strong>
</p>
<p>The Ratcliff diffusion model (Ratcliff
and McKoon, 2008) is a mathematical model for two-choice discrimination tasks. It is
based on the assumption that information is accumulated continuously until one of two
decision thresholds is hit. For introduction see Ratcliff and McKoon (2008).
</p>
<p>This model incorporates the idea, that the decision time T is informative for
stimulus difficulty and thus confidence is computed as a monotone function
of <code class="reqn">\frac{1}{\sqrt{T}}</code>. In this implementation, confidence is the decision
time, directly. Here, we use an interval, given by <code>th1</code>
and <code>th2</code>, assuming that the data is given with discrete judgments and
pre-processed, s.t. these discrete ratings are translated to the respective intervals.
</p>
<p>All functions are fully vectorized across all parameters as well as the response to
match the length or <code>rt</code> (i.e., the output is always of length equal to <code>rt</code>).
This allows for trial wise parameters for each model parameter.
</p>
<p>For convenience, the function allows that the first argument is a <code>data.frame</code>
containing the information of the first and second argument in two columns (i.e.,
<code>rt</code> and <code>response</code>). Other columns (as well as passing <code>response</code>
separately argument) will be ignored.
</p>


<h3>Value</h3>

<p><code>dDDMConf</code> gives the density/likelihood/probability of the diffusion process
producing a decision of <code>response</code> at time <code>rt</code> and a confidence
judgment corresponding to the interval [ <code>th1</code>, <code>th2</code>].
The value will be a numeric vector of the same length as <code>rt</code>.
</p>
<p><code>rDDMConf</code> returns a <code>data.frame</code> with three columns and <code>n</code> rows. Column names are <code>rt</code> (response
time), <code>response</code> (-1 (lower) or 1 (upper), indicating which bound was hit),
<code>conf</code> for the decision time (without non-decision time component; not discretized!).
</p>
<p>The distribution parameters (as well as <code>response</code>, <code>th1</code>
and <code>th2</code>) are recycled to the length of the result. In other words, the functions
are completely vectorized for all parameters and even the response boundary.
</p>


<h3>Note</h3>

<p>The parameterization of the non-decisional components, <code>t0</code> and <code>st0</code>,
differs from the parameterization sometimes used in the literature.
In the present case <code>t0</code> is the lower bound of the uniform distribution of length
<code>st0</code>, but <em>not</em> its midpoint. The parameterization employed here is in line
with the functions in the <code>rtdists</code> package.
</p>
<p>The default diffusion constant <code>s</code> is 1 and not 0.1 as in most applications of
Roger Ratcliff and others. Usually <code>s</code> is not specified as the other parameters:
<code>a</code>, <code>v</code>, and <code>sv</code>, may be scaled to produce the same distributions
(as is done in the code).
</p>
<p>The function code is basically an extension of the <code>ddiffusion</code> function from the
package <code>rtdists</code> for the Ratcliff diffusion model.
</p>


<h3>Author(s)</h3>

<p>For the original <code>rtdists</code> package: Underlying C code by Jochen Voss and Andreas Voss. Porting and R wrapping by Matthew Gretton, Andrew Heathcote, Scott Brown, and Henrik Singmann. <code>qdiffusion</code> by Henrik Singmann. For the <code>dDDMConf</code> function the C code was extended by Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Ratcliff, R., &amp; McKoon, G. (2008). The diffusion decision model: Theory and data for two-choice decision tasks. <em>Neural Computation</em>, 20(4), 873-922.
</p>
<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot rt distribution ignoring confidence
curve(dDDMConf(x, "upper", 0, Inf, a=2, v=0.4, sz=0.2, sv=0.9), xlim=c(0, 2), lty=2)
curve(dDDMConf(x, "lower", 0, Inf, a=2, v=0.4, sz=0.2, sv=0.9), col="red", lty=2, add=TRUE)
curve(dDDMConf(x, "upper", 0, Inf, a=2, v=0.4),add=TRUE)
curve(dDDMConf(x, "lower", 0, Inf, a=2, v=0.4), col="red", add=TRUE)
# Generate a random sample
dfu &lt;- rDDMConf(5000, a=2,v=0.5,t0=0,z=0.5,d=0,sz=0,sv=0, st0=2, s=1)
# Same RT distribution but upper and lower responses changed
dfl &lt;- rDDMConf(50, a=2,v=-0.5,t0=0,z=0.5,d=0,sz=0,sv=0, st0=2, s=1)
head(dfu)

dDDMConf(dfu, th1=0.5, th2=2.5, a=2, v=.5, st0=2)[1:5]
# Scaling diffusion parameters leads do same density values
s &lt;- 2
dDDMConf(dfu, th1=0.5, th2=2.5, a=2*s, v=.5*s, s=2, st0=2)[1:5]
if (requireNamespace("ggplot2", quietly = TRUE)) {
  require(ggplot2)
  ggplot(dfu, aes(x=rt, y=conf))+
    stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE) +
    facet_wrap(~response)
}
boxplot(conf~response, data=dfu)

# Restricting to specific confidence region
dfu &lt;- dfu[dfu$conf &gt;0 &amp; dfu$conf &lt;1,]
dDDMConf(dfu, th1=0, th2=1, a=2, v=0.5, st0=2)[1:5]

# If lower confidence threshold is higher than the upper, the function throws an error,
# except when stop_on_error is FALSE
dDDMConf(dfu[1:5,], th1=1, th2=0, a=2, v=0.5, stop_on_error = FALSE)

</code></pre>

<hr>
<h2 id='dynaViTE'>Dynamical visibility, time, and evidence model (dynaViTE) and Dynamical weighted evidence and visibility model (dynWEV)</h2><span id='topic+dynaViTE'></span><span id='topic+dWEV'></span><span id='topic+WEVmodel'></span><span id='topic+ddynWEV'></span><span id='topic+rWEV'></span><span id='topic+dynWEV'></span>

<h3>Description</h3>

<p>Likelihood function and random number generator for the dynaViTE and dynWEV model
(Hellmann et al., 2023).
It includes following parameters from the drift diffusion model:
<code>a</code> (threshold separation),
<code>z</code> (starting point; relative),
<code>v</code> (drift rate),
<code>t0</code> (non-decision time/response time constant),
<code>d</code> (differences in speed of response execution),
<code>sv</code> (inter-trial-variability of drift),
<code>st0</code> (inter-trial-variability of non-decisional components),
<code>sz</code> (inter-trial-variability of relative starting point) and
<code>s</code> (diffusion constant).
For the computation of confidence following parameters were added:
<code>tau</code> (post-decisional accumulation time),
<code>w</code> (weight on the decision evidence (weight on visibility is (1-w))),
<code>muvis</code> (mean drift rate of visibility process),
<code>svis</code> (diffusion constant of visibility process),
<code>sigvis</code> (variability in drift rate of visibility accumulator),
<code>th1</code> and <code>th2</code> (lower and upper thresholds for confidence interval).
<code>lambda</code> for dynaViTE only, the exponent of judgment time for the division by judgment time in the confidence measure, and
<strong>Note that the parametrization or defaults of non-decision time variability
<code>st0</code> and diffusion constant <code>s</code> differ from what is often found in the literature.</strong>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dWEV(rt, response = "upper", th1, th2, a, v, t0 = 0, z = 0.5, d = 0,
  sz = 0, sv = 0, st0 = 0, tau = 1, w = 0.5, muvis = NULL,
  sigvis = 0, svis = 1, lambda = 0, s = 1, simult_conf = FALSE,
  precision = 1e-05, z_absolute = FALSE, stop_on_error = TRUE,
  stop_on_zero = FALSE)

rWEV(n, a, v, t0 = 0, z = 0.5, d = 0, sz = 0, sv = 0, st0 = 0,
  tau = 1, w = 0.5, muvis = NULL, sigvis = 0, svis = 1, lambda = 0,
  s = 1, delta = 0.01, maxrt = 15, simult_conf = FALSE,
  z_absolute = FALSE, stop_on_error = TRUE, process_results = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dynaViTE_+3A_rt">rt</code></td>
<td>
<p>a vector of RTs. Or for convenience also a <code>data.frame</code> with columns <code>rt</code>
and <code>response</code>.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_response">response</code></td>
<td>
<p>character vector, indicating the decision, i.e. which boundary was
met first. Possible values are <code>c("upper", "lower")</code> (possibly abbreviated) and
<code>"upper"</code> being the default. Alternatively, a numeric vector with values 1=lower
and 2=upper or -1=lower and 1=upper, respectively. For convenience, <code>response</code> is
converted via <code>as.numeric</code> also
allowing factors. Ignored if the first argument is a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_th1">th1</code></td>
<td>
<p>together with <code>th2</code>: scalars or numerical vectors giving the lower and upper bound of the
interval of the confidence measure (see Details). Only values with <code>th2</code>&gt;=<code>th1</code> are accepted.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_th2">th2</code></td>
<td>
<p>(see <code>th1</code>)</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_a">a</code></td>
<td>
<p>threshold separation. Amount of information that is considered for a decision. Large values
indicate a conservative decisional style. Typical range: 0.5 &lt; <code>a</code> &lt; 2</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_v">v</code></td>
<td>
<p>drift rate of decision process. Average slope of the information accumulation
process. The drift gives information about the speed and direction of the accumulation of information.
Large (absolute) values of drift indicate a good performance. If received information supports the
response linked to the upper threshold the sign will be positive and vice versa.
Typical range: -5 &lt; <code>v</code> &lt; 5</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_t0">t0</code></td>
<td>
<p>non-decision time or response time constant (in seconds). Lower bound for the duration of all
non-decisional processes (encoding and response execution).
Typical range: 0.1 &lt; <code>t0</code> &lt; 0.5. Default is 0.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_z">z</code></td>
<td>
<p>(by default relative) starting point of decision process. Indicator of an a priori bias in decision
making. When the relative starting point <code>z</code> deviates from <code>0.5</code>, the amount
of information necessary for a decision differs between response alternatives. Default
is <code>0.5</code> (i.e., no bias).</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_d">d</code></td>
<td>
<p>differences in speed of response execution (in seconds). Positive values indicate that
response execution is faster for responses linked to the upper threshold than for responses linked to
the lower threshold. Typical range: -0.1 &lt; <code>d</code> &lt; 0.1. Default is 0.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_sz">sz</code></td>
<td>
<p>inter-trial-variability of starting point. Range of a uniform distribution with mean
<code>z</code> describing the distribution of actual starting points from specific trials. Values different
from 0 can predict fast errors (but can slow computation considerably). Typical range:
0 &lt; <code>sz</code> &lt; 0.2. Default is 0. (Given in relative range i.e. bounded by 2*min(z, 1-z))</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_sv">sv</code></td>
<td>
<p>inter-trial-variability of drift rate of decision process. Standard deviation of a normal
distribution with mean <code>v</code> describing the distribution of actual drift rates from specific trials.
Values different from 0 can predict slow errors. Typical range: 0 &lt; <code>sv</code> &lt; 2. Default is 0.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_st0">st0</code></td>
<td>
<p>inter-trial-variability of non-decisional components. Range of a uniform distribution with
mean <code>t0 + st0/2</code> describing the distribution of actual <code>t0</code> values across trials.
Accounts for response times below <code>t0</code>. Reduces skew of predicted RT distributions.
Values different from 0 can slow computation considerably. Typical range: 0 &lt; <code>st0</code> &lt; 0.2.
Default is 0.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_tau">tau</code></td>
<td>
<p>post-decisional accumulation time; the length of the time period after the decision was
made until the confidence judgment is made. Range: <code>tau</code>&gt;0. Default: <code>tau</code>=1.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_w">w</code></td>
<td>
<p>weight put on the final state of the decision accumulator for confidence computation.
1-w is the weight on the visibility accumulator. Range: 0&lt;<code>w</code>&lt;1. Default: <code>w</code>=0.5.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_muvis">muvis</code></td>
<td>
<p>mean drift of visibility process. If <code>NULL</code> (default), <code>muvis</code> will be set to the
absolute value of <code>v</code>.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_sigvis">sigvis</code></td>
<td>
<p>the variability in drift rate of the visibility process (which varies independently
from the drift rate in decision process). Range: <code>sigvis</code>&gt;=0. Default: <code>sigvis</code>=0.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_svis">svis</code></td>
<td>
<p>diffusion constant of visibility process. Range: <code>svis</code>&gt;0. Default: <code>svis</code>=1.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_lambda">lambda</code></td>
<td>
<p>power for judgment time in the division of the confidence measure
by the judgment time (Default: 0, i.e. no division which is the version of
dynWEV proposed by Hellmann et al., 2023)</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_s">s</code></td>
<td>
<p>diffusion constant of decision process; standard deviation of the random noise of the
diffusion process (i.e., within-trial variability), scales other parameters (see Note). Needs to
be fixed to a constant in most applications. Default is 1. Note that the default used by Ratcliff
and in other applications is often 0.1.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical. Whether in the experiment confidence was reported simultaneously
with the decision. If that is the case decision and confidence judgment are assumed to have happened
subsequent before the response. Therefore <code>tau</code> is included in the response time. If the decision was
reported before the confidence report, <code>simul_conf</code> should be <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_precision">precision</code></td>
<td>
<p>numerical scalar value. Precision of calculation. Corresponds to the
step size of integration w.r.t. <code>z</code> and <code>t0</code>. Default is 1e-5.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_z_absolute">z_absolute</code></td>
<td>
<p>logical. Determines whether <code>z</code> is treated as absolute start point
(<code>TRUE</code>) or relative (<code>FALSE</code>; default) to <code>a</code>.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_stop_on_error">stop_on_error</code></td>
<td>
<p>Should the diffusion functions return 0 if the parameters values are
outside the allowed range (= <code>FALSE</code>) or produce an error in this case (= <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_stop_on_zero">stop_on_zero</code></td>
<td>
<p>Should the computation of densities stop as soon as a density value of 0 occurs.
This may save a lot of time if the function is used for a likelihood function. Default: FALSE</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_n">n</code></td>
<td>
<p>integer. The number of samples generated.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_delta">delta</code></td>
<td>
<p>numeric. Discretization step size for simulations in the stochastic process</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. Maximum decision time returned. If the simulation of the stochastic
process exceeds a decision time of <code>maxrt</code>, the <code>response</code> will be set to 0 and the <code>maxrt</code>
will be returned as <code>rt</code>.</p>
</td></tr>
<tr><td><code id="dynaViTE_+3A_process_results">process_results</code></td>
<td>
<p>logical. Whether the output simulations should contain the final
state of the decision (and visibility) process as additional column. Default is FALSE, meaning that
no additional columns for the final process states are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dynamical visibility, time, and evidence (dynaViTE) model
and the weighted evidence and visibility model are extensions of the 2DSD model
for decision confidence (see <code><a href="#topic+d2DSD">d2DSD</a></code>). It assumes that the decision follows a drift
diffusion model with two additional assumptions to account for confidence. First, there is a
post-decisional period of further evidence accumulation <code>tau</code>. Second, another accumulation process
accrues information about stimulus reliability (the visibility process) including also evidence
about decision irrelevant features. See Hellmann et al. (2023) for more information.
The measure for confidence is then a weighted sum of the final state of the decision process X
and the visibility process V over a power-function of total accumulation time,
i.e. for a decision time T (which is not the response time), the confidence variable is
</p>
<p style="text-align: center;"><code class="reqn">conf = \frac{wX(T+\tau) + (1-w) V(T+\tau)}{(T+\tau)^\lambda}.</code>
</p>

<p>The dynWEV model is a special case of dynaViTE, with the parameter <code>lambda=0</code>.
</p>
<p>All functions are fully vectorized across all parameters as well as the response to match the
length or <code>rt</code> (i.e., the output is always of length equal to <code>rt</code>). This allows for
trial wise parameters for each model parameter.
</p>
<p>For convenience, the function allows that the first argument is a <code>data.frame</code> containing
the information of the first and second argument in two columns (i.e., <code>rt</code> and <code>response</code>).
Other columns (as well as passing <code>response</code> separately argument) will be ignored.
</p>


<h3>Value</h3>

<p><code>dWEV</code> gives the density/likelihood/probability of the diffusion process producing
a decision of <code>response</code> at time <code>rt</code> and a confidence judgment corresponding to the
interval [ <code>th1</code>, <code>th2</code>]. The value will be a numeric vector of the same length as
<code>rt</code>.
</p>
<p><code>rWEV</code> returns a <code>data.frame</code> with three columns and <code>n</code> rows. Column names are <code>rt</code> (response
time), <code>response</code> (-1 (lower) or 1 (upper), indicating which bound was hit), and <code>conf</code> (the
value of the confidence measure; not discretized!).
</p>
<p>The distribution parameters (as well as <code>response</code>, <code>tau</code>, <code>th1</code> and <code>th2</code>,
<code>w</code> and <code>sig</code>) are recycled to the length of the result. In other words, the functions
are completely vectorized for all parameters and even the response boundary.
</p>


<h3>Note</h3>

<p>The parameterization of the non-decisional components, <code>t0</code> and <code>st0</code>,
differs from the parameterization sometimes used in the literature.
In the present case <code>t0</code> is the lower bound of the uniform distribution of length
<code>st0</code>, but <em>not</em> its midpoint. The parameterization employed here is in line
with the functions in the <code>rtdists</code> package.
</p>
<p>The default diffusion constant <code>s</code> is 1 and not 0.1 as in most applications of
Roger Ratcliff and others. Usually <code>s</code> is not specified as the other parameters:
<code>a</code>, <code>v</code>, <code>sv</code>, <code>muvis</code>, <code>sigvis</code>, and <code>svis</code> respectively,
may be scaled to produce the same distributions (as is done in the code).
</p>
<p>The function code is basically an extension of the <code>ddiffusion</code> function from the
package <code>rtdists</code> for the Ratcliff diffusion model.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot rt distribution ignoring confidence
curve(dWEV(x, "upper", -Inf, Inf, tau=1, a=2, v=0.4, sz=0.2, sv=0.9), xlim=c(0, 2), lty=2)
curve(dWEV(x, "lower", -Inf, Inf,tau=1, a=2, v=0.4, sz=0.2, sv=0.9), col="red", lty=2, add=TRUE)
curve(dWEV(x, "upper", -Inf, Inf,  tau=1, a=2, v=0.4),add=TRUE)
curve(dWEV(x, "lower", -Inf, Inf, tau=1, a=2, v=0.4), col="red", add=TRUE)
# Generate a random sample
df1 &lt;- rWEV(5000, a=2,v=0.5,t0=0,z=0.5,d=0,sz=0,sv=0, st0=0,  tau=1, s=1, w=0.9)
# Same RT and response distribution but different confidence distribution
df2 &lt;- rWEV(5000, a=2,v=0.5,t0=0,z=0.5,d=0,sz=0,sv=0, st0=0,  tau=1, s=1, w=0.1)
head(df1)

# Scaling diffusion parameters leads do same density values
dWEV(df1[1:5,], th1=-Inf, th2=Inf, a=2, v=.5)[1:5]
s &lt;- 2
dWEV(df1[1:5,], th1=-Inf, th2=Inf, a=2*s, v=.5*s, s=2)[1:5]

# Diffusion constant also scales confidence parameters
dWEV(df1[1:5,], th1=0.2, th2=1, a=2, v=.5, sv=0.2, w=0.5, sigvis = 0.2, svis = 1)[1:5]
s &lt;- 2
dWEV(df1[1:5,], th1=0.2*s, th2=1*s, a=2*s, v=.5*s, s=2,
     sv=0.2*s, w=0.5, sigvis=0.2*s, svis=1*s)[1:5]


two_samples &lt;- rbind(cbind(df1, w="high"),
                     cbind(df2, w="low"))
# no difference in RT distributions
boxplot(rt~w+response, data=two_samples)
# but different confidence distributions
boxplot(conf~w+response, data=two_samples)
if (requireNamespace("ggplot2", quietly = TRUE)) {
  require(ggplot2)
  ggplot(two_samples, aes(x=rt, y=conf))+
    stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE) +
    xlim(c(0, 2))+ ylim(c(-1.5, 4))+
    facet_grid(cols=vars(w), rows=vars(response), labeller = "label_both")
}

# Restricting to specific confidence region
df1 &lt;- df1[df1$conf &gt;0 &amp; df1$conf &lt;1,]
dWEV(df1[1:5,], th1=0, th2=1, a=2, v=0.5)[1:5]

# If lower confidence threshold is higher than the upper, the function throws an error,
# except when stop_on_error is FALSE
dWEV(df1[1:5,], th1=1, th2=0, a=2, v=0.5, stop_on_error = FALSE)

</code></pre>

<hr>
<h2 id='fitRTConf'>Function for fitting sequential sampling confidence models</h2><span id='topic+fitRTConf'></span><span id='topic+fitSeqSampConf'></span><span id='topic+fitConfModel'></span><span id='topic+fitConf'></span><span id='topic+fitConfRT'></span>

<h3>Description</h3>

<p>Fits the parameters of different models of response time and confidence, including
the 2DSD model (Pleskac &amp; Busemeyer, 2010), dynWEV, DDMConf, and various
flavors of race models (Hellmann et al., 2023). Which model to fit is
specified by the argument <code>model</code>.
Only a ML method is implemented.
See <code><a href="#topic+dWEV">dWEV</a></code>, <code><a href="#topic+d2DSD">d2DSD</a></code>, and <code><a href="#topic+dRM">dRM</a></code> for more
information about the parameters and Details for not-fitted parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitRTConf(data, model = "dynWEV", fixed = list(sym_thetas = FALSE),
  init_grid = NULL, grid_search = TRUE, data_names = list(),
  nRatings = NULL, restr_tau = Inf, precision = 1e-05, logging = FALSE,
  opts = list(), optim_method = "bobyqa", useparallel = FALSE,
  n.cores = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitRTConf_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> where each row is one trial, containing following
variables (column names can be changed by passing additional arguments of
the form <code>condition="contrast"</code>):
</p>

<ul>
<li> <p><code>condition</code> (not necessary; for different levels of stimulus quality, will be transformed to a factor),
</p>
</li>
<li> <p><code>rating</code> (discrete confidence judgments, should be given as integer vector; otherwise will be transformed to integer),
</p>
</li>
<li> <p><code>rt</code> (giving the reaction times for the decision task),
</p>
</li>
<li><p> either 2 of the following (see details for more information about the accepted formats):
</p>

<ul>
<li> <p><code>stimulus</code> (encoding the stimulus category in a binary choice task),
</p>
</li>
<li> <p><code>response</code> (encoding the decision response),
</p>
</li>
<li> <p><code>correct</code> (encoding whether the decision was correct; values in 0, 1)
</p>
</li></ul>

</li>
<li> <p><code>sbj</code> or <code>participant</code> (optional; giving the subject ID; only relevant if <code>logging = TRUE</code>;
if unique the ID is used in saved files with interim results
and logging messages;
if non-unique or missing and <code>logging =TRUE</code>, 999 will be used then)
</p>
</li></ul>
</td></tr>
<tr><td><code id="fitRTConf_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;dynWEV&quot;, &quot;2DSD&quot;, &quot;IRM&quot;, &quot;PCRM&quot;, &quot;IRMt&quot;, &quot;PCRMt&quot;, or &quot;DDMConf&quot; for the model to be fit.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_fixed">fixed</code></td>
<td>
<p>list. List with parameter-value pairs for parameters that should not be fitted. See Details.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_init_grid">init_grid</code></td>
<td>
<p>data.frame or <code>NULL</code>. Grid for the initial parameter search. Each row is one parameter constellation.
See details for more information. If <code>NULL</code> a default grid will be used.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_grid_search">grid_search</code></td>
<td>
<p>logical. If <code>FALSE</code>, the grid search before the optimization
algorithm is omitted. The fitting is then started with a mean parameter set
from the default grid (if <code>init_grid=NULL</code>) or directly with the rows from
<code>init_grid</code>, if not <code>NULL</code>. (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_data_names">data_names</code></td>
<td>
<p>named list (e.g. <code>c(rating="confidence")</code>). Alternative
possibility of giving other column names for the variables in the data. By default
column names are identical to the ones given in the data argument description.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_nratings">nRatings</code></td>
<td>
<p>integer. Number of rating categories. If <code>NULL</code>, the maximum of
<code>rating</code> and <code>length(unique(rating))</code> is used. This argument is especially
important for data sets where not the whole range of rating categories is realized.
If given, ratings has to be given as factor or integer.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_restr_tau">restr_tau</code></td>
<td>
<p>numerical or <code>Inf</code> or <code>"simult_conf"</code>. For 2DSD and dynWEV only.
Upper bound for tau. Fits will be in the interval (0,<code>restr_tau</code>). If FALSE tau will be unbound.
For <code>"simult_conf"</code>, see the documentation of <code><a href="#topic+d2DSD">d2DSD</a></code> and <code><a href="#topic+dWEV">dWEV</a></code></p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_precision">precision</code></td>
<td>
<p>numerical scalar. For 2DSD and dynWEV only. Precision of calculation.
(in the respective models) for the density functions (see <code><a href="#topic+dWEV">dWEV</a></code> for more information).</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_logging">logging</code></td>
<td>
<p>logical. If <code>TRUE</code>, a folder 'autosave/fit<strong>model</strong>' is created and
messages about the process are printed in a logging file and to console (depending
on OS). Additionally intermediate results are saved in a <code>.RData</code> file with the
participant ID in the name.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_opts">opts</code></td>
<td>
<p>list. A list for more control options in the optimization routines
(depending on the <code>optim_method</code>). See details for more information.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_optim_method">optim_method</code></td>
<td>
<p>character. Determines which optimization function is used for
the parameter estimation. Either <code>"bobyqa"</code> (default), <code>"L-BFGS-B"</code> or <code>"Nelder-Mead"</code>.
<code>"bobyqa"</code> uses a box-constrained optimization with quadratic interpolation.
(See <code><a href="minqa.html#topic+bobyqa">bobyqa</a></code> for more information.) The first two use a
box-constraint optimization. For Nelder-Mead a transfinite function rescaling is used
(i.e. the constrained arguments are suitably transformed to the whole real line).</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_useparallel">useparallel</code></td>
<td>
<p>logical. If <code>TRUE</code> the grid search in the beginning is done with a
parallel back-end, using the <code>parallel</code> package.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_n.cores">n.cores</code></td>
<td>
<p>integer or <code>NULL</code>. Number of cores used for parallelization. If <code>NULL</code>
(default) the number of available cores -1 is used.</p>
</td></tr>
<tr><td><code id="fitRTConf_+3A_...">...</code></td>
<td>
<p>Possibility of giving alternative variable names in data frame
(in the form <code>condition = "SOA"</code>, or <code>response="pressedKey"</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fitting involves a first grid search through computation of the
likelihood on an initial grid with possible sets of parameters to start the
optimization routine. Then the best <code>nAttempts</code> parameter sets are
chosen for an optimization, which is done with an algorithm, depending on the
argument <code>optim-method</code>. The Nelder-Mead algorithm uses the R function
<code><a href="stats.html#topic+optim">optim</a></code>. The optimization routine is restarted
<code>nRestarts</code> times with the starting parameter set equal to the
best parameters from the previous routine.
</p>
<p><strong>stimulus, response and correct</strong>. Two of these columns must be given in
data. If all three are given, correct will have no effect (and will be not checked!).
stimulus can always be given in numerical format with values -1 and 1. response
can always be given as a character vector with &quot;lower&quot; and &quot;upper&quot; as values.
Correct must always be given as a 0-1-vector. If the stimulus column is given
together with a response column and they both do not match the above format,
they need to have the same values/levels (if <code>factor</code>).
In the case that only stimulus/response is given in any other format together with
correct, the unique values will be sorted increasingly and
the first value will be encoded as &quot;lower&quot;/-1 and the second as &quot;upper&quot;/+1.
</p>
<p><strong>fixed</strong>. Parameters that should not be fitted but kept constant. These will
be dropped from the initial grid search
but will be present in the output, to keep all parameters for prediction in the result.
Includes the possibility for symmetric confidence thresholds for both alternative
(<code>sym_thetas</code>=logical). Other examples are
<code>z =.5</code>, <code>sv=0</code>, <code>st0=0</code>, <code>sz=0</code>. For race models, the possibility
of setting <code>a='b'</code> (or vice versa)
leads to identical upper bounds on the decision processes, which is the equivalence for
<code>z=.5</code> in a diffusion process.
</p>
<p><strong>Parameters not fitted</strong>. The models get developed continuously and not
all changes are adopted in the fitting function instantly. Following parameters
are currently not included in the fitting routine:
</p>

<ul>
<li><p> in race models: <code>sza</code>, <code>szb</code>, <code>smu1</code>, and <code>smu2</code>
</p>
</li></ul>

<p><strong><code>init_grid</code></strong>. Each row should be one parameter set to check. The column names
should include the parameters of the desired model, which are the following for 2DSD:
<code>a</code>, <code>vmin</code> and <code>vmax</code> (will be equidistantly spanned across conditions), <code>sv</code>, <code>z</code> (as the
relative starting point between 0 and <code>a</code>), <code>sz</code> (also in relative terms), <code>t0</code>, <code>st0</code>, <code>theta0</code>
(minimal threshold), <code>thetamax</code> (maximal threshold; the others will be equidistantly
spanned symmetrically for both decisions), and <code>tau</code>. For dynWEV,
additionally <code>w</code> , <code>svis</code>, and <code>sigvis</code> are required. For the race models the parameters
are: <code>vmin</code>, <code>vmax</code> (will be equidistantly
spanned across conditions), <code>a</code> and <code>b</code> (decision thresholds), <code>t0</code>, <code>st0</code>, <code>theta0</code>
(minimal threshold), <code>thetamax</code> (maximal threshold;
the others will be equidistantly spanned symmetrically for both decisions), and for
time-dependent confidence race models
additionally <code>wrt</code> and <code>wint</code> (as weights compared to <code>wx=1</code>).
</p>
<p><strong>opts</strong>. A list with numerical values. Possible options are listed below
(together with the optimization method they are used for).
</p>

<ul>
<li> <p><code>nAttempts</code> (all) number of best performing initial parameter sets used for
optimization; default 5, if <code>grid_search</code> is <code>TRUE</code>.
If <code>grid_search</code> is <code>FALSE</code> and <code>init_grid</code> is <code>NULL</code>, then <code>nAttempts</code> will be set to 1 (and
any input will be ignored).
If <code>grid_search</code> is <code>FALSE</code> and <code>init_grid</code> is not <code>NULL</code>, the rows of <code>init_grid</code> will be used
from top to bottom
(since no initial grid search is done) with not more than <code>nAttempts</code> rows used.
</p>
</li>
<li> <p><code>nRestarts</code> (all) number of successive <code>optim</code> routines for each of the starting parameter sets; default 5,
</p>
</li>
<li> <p><code>maxfun</code> (<code>'bobyqa'</code>) maximum number of function evaluations; default: 5000,
</p>
</li>
<li> <p><code>maxit</code> (<code>'Nelder-Mead' and 'L-BFGS-B'</code>) maximum iterations; default: 2000,
</p>
</li>
<li> <p><code>reltol</code> (<code>'Nelder-Mead'</code>) relative tolerance; default:  1e-6),
</p>
</li>
<li> <p><code>factr</code> (<code>'L-BFGS-B'</code>) tolerance in terms of reduction factor of the objective, default: 1e-10)
</p>
</li></ul>



<h3>Value</h3>

<p>Gives a one-row data frame with columns for the different parameters as
fitted result as well as additional information about the fit (<code>negLogLik</code> (for
final parameters), <code>k</code> (number of parameters), <code>N</code> (number of data rows),
<code>BIC</code>, <code>AICc</code> and <code>AIC</code>) and the column <code>fixed</code>, which includes all information
about fixed and not fitted parameters.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>
<p><a href="https://nashjc.wordpress.com/2016/11/10/why-optim-is-out-of-date/">https://nashjc.wordpress.com/2016/11/10/why-optim-is-out-of-date/</a>
</p>
<p><a href="https://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf">https://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We use one of the implemented models, "dynWEV"
# 1. Generate data
# data with positive drift (stimulus = "upper")
data &lt;- rWEV(20, a=2,v=0.5,t0=0.2,z=0.5, sz=0.1,sv=0.1, st0=0,  tau=4, s=1, w=0.3)
data$stimulus &lt;- "upper"
# data with negtive drift (stimulus = "lower") but same intensity
data2 &lt;- rWEV(100, a=2,v=-0.5,t0=0.2,z=0.5,sz=0.1,sv=0.1, st0=0,  tau=4, s=1, w=0.3)
data2$stimulus &lt;- "lower"
data &lt;- rbind(data, data2)
# Transfer response column and add dummy condition column
data$response &lt;- ifelse(data$response==1, "upper", "lower")
data$condition &lt;- 1
# Take some confidence thresholds for discrete ratings
threshs &lt;- c(-Inf, 1, 2, Inf)
data$rating &lt;- as.numeric(cut(data$conf, breaks = threshs, include.lowest = TRUE))
head(data)

# 2. Use fitting function
# Fitting the model with these opts results in a pretty bad fit
# (especially because of omitting the grid_search)

   fitRTConf(data, "dynWEV", fixed=list(sym_thetas=TRUE, z=0.5, st0=0),
            grid_search = FALSE, logging=FALSE,
            opts = list(nAttempts=1, nRestarts=2, maxfun=2000))
 

</code></pre>

<hr>
<h2 id='fitRTConfModels'>Function for fitting several sequential sampling confidence models in parallel</h2><span id='topic+fitRTConfModels'></span>

<h3>Description</h3>

<p>This function is a wrapper of the function <code><a href="#topic+fitConfModel">fitConfModel</a></code> (see
there for more information). It calls the function for every possible combination
of model and participant in <code>model</code> and <code>data</code> respectively.
Also, see <code><a href="#topic+dWEV">dWEV</a></code>, <code><a href="#topic+d2DSD">d2DSD</a></code>, <code><a href="#topic+dDDMConf">dDDMConf</a></code>,
and <code><a href="#topic+dRM">dRM</a></code> for more
information about the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitRTConfModels(data, models = c("dynaViTE", "2DSD", "PCRMt"),
  nRatings = NULL, fixed = list(sym_thetas = FALSE), restr_tau = Inf,
  grid_search = TRUE, opts = list(), optim_method = "bobyqa",
  logging = FALSE, precision = 1e-05, parallel = TRUE, n.cores = NULL,
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitRTConfModels_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> where each row is one trial, containing following
variables (column names can be changed by passing additional arguments of
the form <code>condition="contrast"</code>):
</p>

<ul>
<li> <p><code>condition</code> (not necessary; for different levels of stimulus quality, will be transformed to a factor),
</p>
</li>
<li> <p><code>rating</code> (discrete confidence judgments, should be given as integer vector; otherwise will be transformed to integer),
</p>
</li>
<li> <p><code>rt</code> (giving the reaction times for the decision task),
</p>
</li>
<li><p> either 2 of the following (see details for more information about the accepted formats):
</p>

<ul>
<li> <p><code>stimulus</code> (encoding the stimulus category in a binary choice task),
</p>
</li>
<li> <p><code>response</code> (encoding the decision response),
</p>
</li>
<li> <p><code>correct</code> (encoding whether the decision was correct; values in 0, 1)
</p>
</li></ul>

</li>
<li> <p><code>sbj</code> (giving the subject ID; the models given in the second argument are fitted for each
subject individually. (Furthermore, if <code>logging = TRUE</code>, the ID is used in files
saved with interim results and logging messages.))
</p>
</li></ul>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_models">models</code></td>
<td>
<p>character vector with following possible elements &quot;dynWEV&quot;, &quot;2DSD&quot;, &quot;IRM&quot;, &quot;PCRM&quot;, &quot;IRMt&quot;, and &quot;PCRMt&quot;  for the models to be fit.</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_nratings">nRatings</code></td>
<td>
<p>integer. Number of rating categories. If <code>NULL</code>, the maximum of
<code>rating</code> and <code>length(unique(rating))</code> is used. This argument is especially
important for data sets where not the whole range of rating categories is realized.
If given, ratings has to be given as factor or integer.</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_fixed">fixed</code></td>
<td>
<p>list. List with parameter value pairs for parameters that should not be fitted. (see Details).</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_restr_tau">restr_tau</code></td>
<td>
<p>numerical or <code>Inf</code> or <code>"simult_conf"</code>. Used for 2DSD and dynWEV only. Upper bound for tau.
Fits will be in the interval (0,<code>restr_tau</code>). If <code>FALSE</code> tau will be unbound. For <code>"simult_conf"</code>, see the documentation of
<code><a href="#topic+d2DSD">d2DSD</a></code> and <code><a href="#topic+dWEV">dWEV</a></code></p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_grid_search">grid_search</code></td>
<td>
<p>logical. If <code>FALSE</code>, the grid search before the optimization
algorithm is omitted. The fitting is then started with a mean parameter set
from the default grid. (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_opts">opts</code></td>
<td>
<p>list. A list for more control options in the optimization routines
(depending on the <code>optim_method</code>). See details for more information.</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_optim_method">optim_method</code></td>
<td>
<p>character. Determines which optimization function is used for
the parameter estimation. Either <code>"bobyqa"</code> (default), <code>"L-BFGS-B"</code> or <code>"Nelder-Mead"</code>.
<code>"bobyqa"</code> uses a box-constrained optimization with quadratic interpolation.
(See <code><a href="minqa.html#topic+bobyqa">bobyqa</a></code> for more information.) The first two use a
box-constraint optimization. For Nelder-Mead a transfinite function rescaling is used
(i.e. the constrained arguments are suitably transformed to the whole real line).</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_logging">logging</code></td>
<td>
<p>logical. If <code>TRUE</code>, a folder 'autosave/fit<strong>model</strong>' is created and
messages about the process are printed in a logging file and to console (depending
on OS). Additionally intermediate results are saved in a <code>.RData</code> file with the
participant ID in the name.</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_precision">precision</code></td>
<td>
<p>numerical scalar. For 2DSD and dynWEV only. Precision of calculation.
(in the respective models) for the density functions (see <code><a href="#topic+dWEV">dWEV</a></code> for more information).</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_parallel">parallel</code></td>
<td>
<p>&quot;models&quot;, &quot;single&quot;, &quot;both&quot; or <code>FALSE</code>. If <code>FALSE</code> no parallelization
is used in the fitting process. If &quot;models&quot; the fitting process is parallelized over
participants and models (i.e. over the calls for fitting functions). If &quot;single&quot;
parallelization is used within the fitting processes (over initial grid search and
optimization processes for different start points, but see <code><a href="#topic+fitRTConf">fitRTConf</a></code>).
If &quot;both&quot;, parallelization is done hierarchical. For small number of
models and participants &quot;single&quot; or &quot;both&quot; is preferable. Otherwise, you may use &quot;models&quot;.</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_n.cores">n.cores</code></td>
<td>
<p>integer vector or <code>NULL</code>. If <code>parallel</code> is &quot;models&quot; or &quot;single&quot;, a single
integer for the number of cores used for parallelization is required. If
<code>parallel</code> is &quot;both&quot;, two values are required. The first for the number of parallel
model-participant combinations and the second for the parallel processes within the
fitting procedures (this may be specified
to match the <code>nAttemps</code>-Value in the <code>opts</code> argument. If <code>NULL</code> (default)
the number of available cores -1 is used.
If <code>NULL</code> and <code>parallel</code> is &quot;both&quot;, the cores will be used for
model-participant-parallelization, only.</p>
</td></tr>
<tr><td><code id="fitRTConfModels_+3A_...">...</code></td>
<td>
<p>Possibility of giving alternative variable names in data frame
(in the form <code>condition = "SOA"</code>, or <code>response="pressedKey"</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fitting involves a first grid search through an initial grid. Then the best <code>nAttempts</code>
parameter sets are chosen for an optimization, which is done with an algorithm, depending on the argument
<code>optim-method</code>. The Nelder-Mead algorithm uses the R function <code><a href="stats.html#topic+optim">optim</a></code>.
The optimization routine is restarted <code>nRestarts</code> times with the starting parameter set equal to the
best parameters from the previous routine.
</p>
<p><strong>stimulus, response and correct</strong>. Two of these columns must be given in data. If all three are given, correct will have no effect (and will be not checked!).
stimulus can always be given in numerical format with values -1 and 1. response can always be given as a character vector with &quot;lower&quot; and &quot;upper&quot; as values.
Correct must always be given as a 0-1-vector. If stimulus is given together with response and they both do not match the above format, they need to have the same values/levels (if factor).
In the case that only stimulus/response is given in any other format together with correct, the unique values will be sorted increasingly and
the first value will be encoded as &quot;lower&quot;/-1 and the second as &quot;upper&quot;/+1.
</p>
<p><strong>fixed</strong>. Parameters that should not be fitted but kept constant. These will be dropped from the initial grid search
but will be present in the output, to keep all parameters for prediction in the result. Includes the
possibility for symmetric confidence thresholds for both alternative (<code>sym_thetas</code>=logical). Other examples are
<code>z =.5</code>, <code>sv=0</code>, <code>st0=0</code>, <code>sz=0</code>. For race models, the possibility of setting <code>a='b'</code> (or vice versa)
leads to identical upper bounds on the decision processes, which is the equivalence for <code>z=.5</code> in a diffusion process
</p>
<p><strong>opts</strong>. A list with numerical values. Possible options are listed below (together with the optimization method they are used for).
</p>

<ul>
<li> <p><code>nAttempts</code> (all) number of best performing initial parameter sets used for optimization; default 5
</p>
</li>
<li> <p><code>nRestarts</code> (all) number of successive <code>optim</code> routines for each of the starting parameter sets; default 5,
</p>
</li>
<li> <p><code>maxfun</code> (<code>'bobyqa'</code>) maximum number of function evaluations; default: 5000,
</p>
</li>
<li> <p><code>maxit</code> (<code>'Nelder-Mead' and 'L-BFGS-B'</code>) maximum iterations; default: 2000,
</p>
</li>
<li> <p><code>reltol</code> (<code>'Nelder-Mead'</code>) relative tolerance; default:  1e-6),
</p>
</li>
<li> <p><code>factr</code> (<code>'L-BFGS-B'</code>) tolerance in terms of reduction factor of the objective, default: 1e-10)
</p>
</li></ul>



<h3>Value</h3>

<p>Gives data frame with rows for each model-participant combination and columns for the different parameters
as fitted result as well as additional information about the fit (<code>negLogLik</code> (for final parameters),
<code>k</code> (number of parameters), <code>N</code> (number of data rows), <code>BIC</code>, <code>AICc</code> and <code>AIC</code>)
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann, <a href="mailto:sebastian.hellmann@ku.de">sebastian.hellmann@ku.de</a>
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Generate data from two artificial participants
# Get random drift direction (i.e. stimulus category) and
# stimulus discriminability (two steps: hard, easy)
stimulus &lt;- sample(c(-1, 1), 400, replace=TRUE)
discriminability &lt;- sample(c(1, 2), 400, replace=TRUE)

# generate data for participant 1
data &lt;- rWEV(400, a=2, v=stimulus*discriminability*0.5,
             t0=0.2, z=0.5, sz=0.1, sv=0.1, st0=0,  tau=4, s=1, w=0.3)
# discretize confidence ratings (only 2 steps: unsure vs. sure)
data$rating &lt;- as.numeric(cut(data$conf, breaks = c(-Inf, 1, Inf), include.lowest = TRUE))
data$participant = 1
data$stimulus &lt;- stimulus
data$discriminability &lt;- discriminability
# generate data for participant 2
data2 &lt;- rWEV(400, a=2.5, v=stimulus*discriminability*0.7,
             t0=0.1, z=0.7, sz=0, sv=0.2, st0=0,  tau=2, s=1, w=0.5)
data2$rating &lt;- as.numeric(cut(data$conf, breaks = c(-Inf, 0.3, Inf), include.lowest = TRUE))
data2$participant = 2
data2$stimulus &lt;- stimulus
data2$discriminability &lt;- discriminability

# bind data from participants
data &lt;- rbind(data, data2)
data &lt;- data[data$response!=0, ] # drop not finished decision processes
data &lt;- data[,-3] # drop conf measure (unobservable variable)
head(data)


# 2. Use fitting function
## Not run: 
  # Fitting takes very long to run and uses multiple (6) cores with this
  # call:
  fitRTConfModels(data, models=c("dynWEV", "PCRM"), nRatings = 2,
                logging=FALSE, parallel="both",
                n.cores = c(2,3), # fit two participant-model combination in parallel
                condition="discriminability")# tell which column is "condition"

## End(Not run)


</code></pre>

<hr>
<h2 id='LogLikRM'>Log-Likelihood functions for the independent and partially anti-correlated race models of confidence</h2><span id='topic+LogLikRM'></span><span id='topic+LLRM'></span><span id='topic+LogLikIRM'></span><span id='topic+LogLikPCRM'></span>

<h3>Description</h3>

<p>Computes the Log-likelihood for given data and parameters in the IRM and PCRM with or without time-scaled
confidence measure. It is a wrapped version of the respective densities <code><a href="#topic+dIRM">dIRM</a></code> and <code><a href="#topic+dPCRM">dPCRM</a></code>,
where one can find more information about the parameters. It restricts the rates of accumulation to be the negative
of each other, though (a common assumption in perceptual decision tasks).
The function is mainly used inside <code><a href="#topic+fitRTConf">fitRTConf</a></code> for race models but exported
for individual usage in other contexts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogLikRM(data, paramDf, model = "IRM", time_scaled = FALSE,
  data_names = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LogLikRM_+3A_data">data</code></td>
<td>
<p>a dataframe where each row is one trial. Containing following variables:
</p>

<ul>
<li><p> condition    (not necessary; convertible to integer (e.g. factor); for different levels of stimulus quality),
</p>
</li>
<li><p> rating            (convertible to integer (e.g. factor); discrete confidence judgments),
</p>
</li>
<li><p> rt                    (numeric; giving reaction times for decision task),
</p>
</li>
<li><p> stimulus     (values at least convertible to c(1,2), i.e. integer or factor; stimulus category (index of accumulator with higher drift))
</p>
</li>
<li><p> response     (values at least convertible to c(1,2); direction of decision; (index of accumulator reaching the boundary first))
</p>
</li></ul>
</td></tr>
<tr><td><code id="LogLikRM_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or data frame with one row. Column names should match the names of
<a href="#topic+RaceModels">RaceModels</a> parameter names (only <code>mu1</code> and <code>mu2</code> are not used in this context but
replaced by the parameter <code>v</code>). For different stimulus quality/mean
drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,....
Different <code>s</code> parameters are possible with <code>s1</code>, <code>s2</code>, <code>s3</code>,... with equally many steps as for drift rates. Additionally, the confidence
thresholds should be given by names with <code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,.... (see Details for the correspondence to the data)</p>
</td></tr>
<tr><td><code id="LogLikRM_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;IRM&quot; or &quot;PCRM&quot;. (&quot;IRMt&quot; and &quot;PCRMt&quot; will also be accepted. In that case,
time_scaled is set to TRUE.)</p>
</td></tr>
<tr><td><code id="LogLikRM_+3A_time_scaled">time_scaled</code></td>
<td>
<p>logical. Whether the confidence measure should be scaled by 1/sqrt(rt). Default: TRUE.</p>
</td></tr>
<tr><td><code id="LogLikRM_+3A_data_names">data_names</code></td>
<td>
<p>list. Possibility of giving alternative column names for the variables in the data. By default column names are identical to the
ones given in the data argument description.</p>
</td></tr>
<tr><td><code id="LogLikRM_+3A_...">...</code></td>
<td>
<p>Another possibility of giving alternative variable names in data frame (in the form <code>condition = "SOA"</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note, that the requirements on the format of the columns for the likelihood functions are much stricter, than in <code><a href="#topic+fitRTConf">fitRTConf</a></code>.
This is because the function is very frequently called in the optimization routines of the fitting process and the preprocessing steps are
therefore included in the other function.
</p>
<p><strong>rating, condition</strong>. If integer, values should range from 1
to number of possible ratings/conditions. If factor,
the number of levels should be equal to number of possible
ratings/conditions. This should be consistent with the
parameter vector. The confidence thresholds should be named as
<code>thetaUpper1</code>, <code>thetaLower1</code>,.... (or <code>theta1</code>,... for symmetric
thresholds), with the number of ratings -1 and the mean drift rates
(and possibly the standard deviation in drift rates)
should be denoted as <code>v1</code>, <code>v2</code>,...
(and <code>s1</code>, <code>s2</code>,...) with the number equal to the number of conditions.
If only one condition is used <code>v</code> will be accepted as well as <code>v1</code>.
</p>
<p><strong>stimulus, response</strong>. stimulus and response should always
be given in numerical format with values 1 and 2.
Stimulus determines which of two accumulators has positive drift.
The other has negative drift with the same absolute
value. Response gives the index of the accumulator that reaches the
boundary first.
</p>


<h3>Value</h3>

<p>Numeric scalar. The summed Log-likelihood of the data given the parameters in the respective model. If one or more row-wise probabilities is &lt;=0,
the function returns -1e+12.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Generate data from an artificial participants
# Get random index for accumulator with positive
# drift (i.e. stimulus category) and
# stimulus discriminability (two steps: hard, easy)
stimulus &lt;- sample(c(1, 2), 200, replace=TRUE)
discriminability &lt;- sample(c(1, 2), 200, replace=TRUE)
# generate data for participant 1
data &lt;- rPCRM(200, mu1=ifelse(stimulus==1, 1, -1)*discriminability*0.5,
              mu2=ifelse(stimulus==1, -1, 1)*discriminability*0.5,
             a=2, b=1.8, t0=0.2, st0=0, wx=0.7, wint=0.3, wrt=0)
# discretize confidence ratings (only 2 steps: unsure vs. sure)
data$rating &lt;- as.numeric(cut(data$conf, breaks = c(0, 3, Inf), include.lowest = TRUE))
data$participant = 1
data$stimulus &lt;- stimulus
data$discriminability &lt;- discriminability
data &lt;- data[data$response!=0, ] # drop not finished decision processes
data &lt;- data[,-c(3,4)] # drop xl and conf measure (unobservable variable)
head(data)

# 2. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=2,b=2, v1=0.5, v2=1, t0=0.1,st0=0,
                      wx=0.6, wint=0.2, wrt=0.2,
                      theta1=4)

# 3. Compute log likelihood for parameter and data
LogLikRM(data, paramDf, model="PCRMt", condition="discriminability")
# same result
LogLikRM(data, paramDf, model="PCRM", time_scaled=TRUE,condition="discriminability")
# different
LogLikRM(data, paramDf, model="PCRM", condition="discriminability")

# same parameters used for IRM model
LogLikRM(data, paramDf, model="IRMt", condition="discriminability")

</code></pre>

<hr>
<h2 id='LogLikWEV'>Log-Likelihood functions for the dynWEV and 2DSD models of confidence</h2><span id='topic+LogLikWEV'></span><span id='topic+LLWEV'></span><span id='topic+LLdynWEV'></span><span id='topic+LL2DSD'></span><span id='topic+LogLikdynWEV'></span><span id='topic+LogLikWEV2DSD'></span>

<h3>Description</h3>

<p>Computes the Log-likelihood for given data and parameters in the
dynWEV model (Hellmann et al., 2023) and the 2DSD model
(Pleskac &amp; Busemeyer, 2010). It is a wrapped version of the
respective densities <code><a href="#topic+dWEV">dWEV</a></code> and <code><a href="#topic+d2DSD">d2DSD</a></code>,
where one can find more information about the parameters
(<code>z</code> is always given relatively, in the likelihood).
The function is mainly used in <code><a href="#topic+fitRTConf">fitRTConf</a></code> but
exported for individual usage in other contexts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogLikWEV(data, paramDf, model = "dynaViTE", simult_conf = FALSE,
  precision = 1e-05, stop_on_error = TRUE, data_names = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LogLikWEV_+3A_data">data</code></td>
<td>
<p>a dataframe where each row is one trial. Containing following variables:
</p>

<ul>
<li><p> condition    (not necessary; convertible to integer (e.g. factor); for different levels of stimulus quality),
</p>
</li>
<li><p> rating       (convertible to integer (e.g. factor); discrete confidence judgments),
</p>
</li>
<li><p> rt           (numeric; giving reaction times for decision task),
</p>
</li>
<li><p> stimulus     (values at least convertible to c(-1,1); stimulus category (direction of evidence accumulation))
</p>
</li>
<li><p> response     (characters in <code>"upper"</code>, <code>"lower"</code> (or convertible to); direction of decision; correct answers are &quot;lower&quot; for stimulus=-1; and &quot;upper&quot; for stimulus=1),
</p>
</li></ul>
</td></tr>
<tr><td><code id="LogLikWEV_+3A_paramdf">paramDf</code></td>
<td>
<p>list or data.frame with one row. Names should match the names of
<a href="#topic+dynaViTE">dynaViTE</a> and <a href="#topic+2DSD">2DSD</a> model specific parameter names. For different
stimulus quality/mean drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,....
Different <code>sv</code> and/or <code>s</code> parameters are possible with <code>sv1</code>, <code>sv2</code>, <code>sv3</code>... (<code>s1</code>, <code>s2</code>, <code>s3</code>,...
respectively) with equally many steps as for drift rates. Additionally, the confidence
thresholds should be given by names with <code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,...
(see Details for the correspondence to the data)</p>
</td></tr>
<tr><td><code id="LogLikWEV_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;dynWEV&quot; or &quot;2DSD&quot; for the model to fit.</p>
</td></tr>
<tr><td><code id="LogLikWEV_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical. Whether in the experiment confidence was reported simultaneously
with the decision, as then decision and confidence judgment are assumed to have happened
subsequent before response and computations are different, when there is an observable
interjudgment time (then <code>simult_conf</code> should be <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="LogLikWEV_+3A_precision">precision</code></td>
<td>
<p>numerical scalar. Precision of calculation for integration over z and t0.</p>
</td></tr>
<tr><td><code id="LogLikWEV_+3A_stop_on_error">stop_on_error</code></td>
<td>
<p>logical. If TRUE an error in the function will be returned in case of
invalid parameters. Otherwise, the output will be 0 without error.</p>
</td></tr>
<tr><td><code id="LogLikWEV_+3A_data_names">data_names</code></td>
<td>
<p>list. Possibility of giving alternative column names for the variables
in the data. By default column names are identical to the
ones given in the data argument description.</p>
</td></tr>
<tr><td><code id="LogLikWEV_+3A_...">...</code></td>
<td>
<p>Possibility of giving alternative variable names in data frame
(in the form <code>condition = "SOA"</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note, that the requirements on the format of the columns for the likelihood functions
are much stricter, than in <code><a href="#topic+fitRTConf">fitRTConf</a></code>.
This is because the function is very frequently calls in the optimization routines of the
fitting process and the preprocessing steps are
therefore included in that function.
</p>
<p><strong>rating, condition</strong>. If integer, values should range from 1 to number of possible
ratings/conditions. If a factor, the number of levels should be
equal to number of possible ratings/conditions. This should be consistent with the
parameter vector. The confidence thresholds should be named
as <code>thetaUpper1</code>, <code>thetaLower1</code>,.... (or <code>theta1</code>,... for symmetric thresholds), with the
number of ratings -1 and the mean drift rates (and possibly the
standard deviation in drift rates) should be denoted as <code>v1</code>, <code>v2</code>,...
(and <code>sv1</code>, <code>sv2</code>,.../<code>s1</code>, <code>s2</code>, ...) with the number equal to the number of conditions.
If only one condition is used <code>v</code> will be accepted as well as <code>v1</code>.
</p>
<p><strong>stimulus, response</strong>. stimulus should always be given in numerical format with values -1 and 1.
response should always be given as a character vector with <code>"lower"</code> and <code>"upper"</code> as values.
This corresponds to the situation of Ratcliff's diffusion model (Ratcliff, 1978), where stimulus is the sign of the mean drift direction and
the response is the <code>"upper"</code> or <code>"lower"</code> boundary that is first hit by the evidence accumulation. A correct decision is therefore <code>"lower"</code>,
if stimulus is -1, and <code>"upper"</code>, if stimulus is 1.
</p>


<h3>Value</h3>

<p>Numeric scalar. The summed Log-likelihood of the data given the parameters in the respective model. If one or more row-wise probabilities is &lt;=0,
the function returns -1e+12.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Generate data from an artificial participants
# Get random drift direction (i.e. stimulus category) and
# stimulus discriminability (two steps: hard, easy)
stimulus &lt;- sample(c(-1, 1), 200, replace=TRUE)
discriminability &lt;- sample(c(1, 2), 200, replace=TRUE)
# generate data for participant 1
data &lt;- rWEV(200, a=2,v=stimulus*discriminability*0.5,
             t0=0.2,z=0.5, sz=0.1,sv=0.1, st0=0,  tau=4, s=1, w=0.3)
# discretize confidence ratings (only 2 steps: unsure vs. sure)
data$rating &lt;- as.numeric(cut(data$conf, breaks = c(-Inf, 1, Inf), include.lowest = TRUE))
data$participant = 1
data$stimulus &lt;- stimulus
data$discriminability &lt;- discriminability
data &lt;- data[data$response!=0, ] # drop not finished decision processes
data &lt;- data[,-3] # drop conf measure (unobservable variable)
head(data)

# 2. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=2.5,v1=0.5, v2=1, t0=0.1,z=0.7,
                      sz=0,sv=0.2, st0=0,  tau=3, w=0.3,
                      theta1=0.8, svis=0.5, sigvis=0.8)

# 3. Compute log likelihood for parameter and data
LogLikWEV(data, paramDf, model="dynWEV", condition="discriminability")
# adding the hypothetical interjudgment time to response times
# results in the same log likelihood as before when simult_conf=TRUE
data$rt &lt;- data$rt + paramDf$tau
LogLikWEV(data, paramDf, model="dynWEV", condition="discriminability", simult_conf=TRUE)

# the same function for "2DSD" model
paramDf &lt;- data.frame(a=2.5,v1=0.5, v2=1, t0=0.1,z=0.7,
                      sz=0,sv=0.2, st0=0,  tau=3, theta1=0.8)
LogLikWEV(data, paramDf, model="2DSD", condition="discriminability", simult_conf=TRUE)
# this results in the same log likelihood as before

</code></pre>

<hr>
<h2 id='PDFtoQuantiles'>Get Quantiles from vectors of PDF or CDF values</h2><span id='topic+PDFtoQuantiles'></span><span id='topic+getquantiles'></span><span id='topic+getRTquantiles'></span><span id='topic+RTDensityToQuantiles'></span><span id='topic+CDFtoQuantiles'></span>

<h3>Description</h3>

<p><code>CDFtoQuantiles</code> computes quantiles for a given CDF.
<code>PDFtoQuantiles</code> computes the quantiles for given PDF values within
groups of other variables, if available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PDFtoQuantiles(pdf_df, p = c(0.1, 0.3, 0.5, 0.7, 0.9), agg_over = NULL,
  scaled = FALSE)

CDFtoQuantiles(cdf, x = NULL, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PDFtoQuantiles_+3A_pdf_df">pdf_df</code></td>
<td>
<p>dataframe. Should have at least two columns:
</p>

<ul>
<li> <p><code>rt</code> (for reaction times) or <code>x</code> for the support values of the pdf
</p>
</li>
<li> <p><code>dens</code> or <code>pdf</code> for the pdf values
</p>
</li>
<li><p> All other columns will be used as grouping factors, for which separate quantiles will be returned.
</p>
</li></ul>
</td></tr>
<tr><td><code id="PDFtoQuantiles_+3A_p">p</code></td>
<td>
<p>numeric vector. Probabilities for returned quantiles. Default:
c(.1, .3, .5, .7, .9).</p>
</td></tr>
<tr><td><code id="PDFtoQuantiles_+3A_agg_over">agg_over</code></td>
<td>
<p>character. Names of columns in <code>pdf_df</code> to aggregate over (using the mean of
densities, which is valid only, if groups occur with equal probabilities) before
computing the quantiles.</p>
</td></tr>
<tr><td><code id="PDFtoQuantiles_+3A_scaled">scaled</code></td>
<td>
<p>logical. Indicating whether the pdf values are from a proper probability
distribution. Non-scaled pdfs will scaled to 1. If <code>scaled</code> is TRUE, this may cause
problems with high probabilities. In any case we strongly recommend to cover the most
probability mass with the values in the support vector.</p>
</td></tr>
<tr><td><code id="PDFtoQuantiles_+3A_cdf">cdf</code></td>
<td>
<p>numeric. A increasing vector of the same length as <code>x</code> giving the CDF for respective x-Values.
Dataframe inputs are accepted. If a column <code>x</code> is available there, this will be used as support values.</p>
</td></tr>
<tr><td><code id="PDFtoQuantiles_+3A_x">x</code></td>
<td>
<p>numeric. A increasing vector of same length as <code>cdf</code>. Can also be specified as column of <code>cdf</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a reasonable accuracy the number of steps in the support column (<code>rt</code>/<code>x</code>)
should be high, i.e. the distance between values small.
We recommend, to ensure that the support vector in the input to be equidistant,
i.e. the difference between consecutive support values should be constant, though
this is not required.
If both column names <code>x</code> and <code>rt</code> are present in <code>pdf_df</code>, <code>rt</code> will be preferred.
Attention should be given to the columns of <code>pdf_df</code> other than <code>rt</code>/<code>x</code>
and <code>dens</code>/<code>pdf</code>.
</p>
<p>The column for the pdf may be scaled to integrate to 1 but do not have to.
</p>


<h4>Quantile computation in the <code>dynConfiR</code> package</h4>

<p>As argument <code>pdf_df</code>, the outputs of <code>predictRT</code> and <code>predictRTModels</code> from the
<code>dynConfiR</code> package can be used. In the context of confidence models grouping factors
often used are conditions, correct/incorrect answers and confidence ratings.
</p>



<h3>Value</h3>

<p><code>PDFtoQuantiles</code> returns a <code>tibble</code> with columns p and q indicating
probabilities and respective quantiles. Furthermore, the output has grouping columns
identical to the additional columns in the input (without <code>rt</code>/<code>x</code>, <code>dens</code> and <code>densscaled</code>),
but without the ones in the <code>agg_over</code> argument. <code>CDFtoQuantiles</code>
returns only a <code>data.frame</code> with columns <code>p</code> and <code>q</code>.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Demonstrate PDFtoQuantiles
pred &lt;- expand.grid(model = c("dynWEV", "PCRMt"),
                    rt =  seq(0, 15, length.out=1200),
                    condition = c(1,2,3),
                    rating = c(1,2))
pred$dens &lt;- dchisq(pred$rt, 3) # pdf may also be used as column name
head(pred)
res &lt;- PDFtoQuantiles(pred, p=c(0.3, 0.5, 0.7))
head(res)
nrow(res) #= 3(quantiles)*2(models)*3(conditions)*2(rating)
# Compare to true quantiles of Chi-square distribution
qchisq(p=c(0.3, 0.5, 0.7), 3)
res$q[1:3]


res2 &lt;- PDFtoQuantiles(pred, p=c(0.3, 0.5, 0.7), agg_over = "model")
nrow(res2) #=18 because res aggregated over models


  pred$pdf &lt;- dchisq(pred$rt, 3)
  head(pred)
  # following call throws a warning, because both columns pdf and dens are present
  PDFtoQuantiles(pred, p=c(0.3, 0.5, 0.7), agg_over = "model")



  pred2 &lt;- data.frame(rt=seq(0, 7, length.out=100))
  pred2$dens &lt;- dchisq(pred2$rt, 5)
  # following call throws a warning, because density is assumed to be scaled (scaled=TRUE), i.e.
  # integrate to 1, but the .95 quantile is not reached in the rt column
  PDFtoQuantiles(pred2, p=c(0.3, 0.5, 0.95), scaled=TRUE) # Gives a warning


## Demonstrate CDFtoQuantiles
X &lt;- seq(-2, 2, length.out=300)
pdf_values &lt;- pnorm(X)
CDFtoQuantiles(pdf_values, X, p=c(0.2, 0.5, 0.8))
qnorm(c(0.2, 0.5, 0.8))
</code></pre>

<hr>
<h2 id='predictDDMConf'>Prediction of Confidence Rating and Reaction Time Distribution in the drift diffusion confidence model</h2><span id='topic+predictDDMConf'></span><span id='topic+predictDDMConf_Conf'></span><span id='topic+predictDDMConf_RT'></span>

<h3>Description</h3>

<p><code>predictDDMConf_Conf</code> predicts the categorical response distribution of
decision and confidence ratings, <code>predictDDMConf_RT</code> computes the
RT distribution (density) in the drift diffusion confidence model
(Hellmann et al., 2023), given specific parameter
constellations. See <code><a href="#topic+dDDMConf">dDDMConf</a></code> for more information about the model
and parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictDDMConf_Conf(paramDf, maxrt = 15, subdivisions = 100L,
  stop.on.error = FALSE, .progress = TRUE)

predictDDMConf_RT(paramDf, maxrt = 9, subdivisions = 100L, minrt = NULL,
  scaled = FALSE, DistConf = NULL, .progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictDDMConf_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or data frame with one row. Column names should match the names of
<a href="#topic+DDMConf">DDMConf</a> model parameter names. For different stimulus quality/mean
drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,....
Different <code>sv</code> and/or <code>s</code> parameters are possible with <code>sv1</code>, <code>sv2</code>, <code>sv3</code>... (<code>s1</code>, <code>s2</code>, <code>s3</code>,...
respectively) with equally many steps as for drift rates. Additionally, the confidence
thresholds should be given by names with <code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,....</p>
</td></tr>
<tr><td><code id="predictDDMConf_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. The maximum RT for the
integration/density computation. Default: 15 (for <code>predictDDMConf_Conf</code>
(integration)), 9 (for <code>predictDDMConf_RT</code>).</p>
</td></tr>
<tr><td><code id="predictDDMConf_+3A_subdivisions">subdivisions</code></td>
<td>
<p><code>integer</code> (default: 100).
For <code>predictDDMConf_Conf</code> it is used as argument for the inner integral routine.
For <code>predictDDMConf_RT</code> it is the number of points for which the density is computed.</p>
</td></tr>
<tr><td><code id="predictDDMConf_+3A_stop.on.error">stop.on.error</code></td>
<td>
<p>logical. Argument directly passed on to integrate. Default is <code>FALSE</code>,
since the densities invoked may lead to slow convergence of the integrals (which are still
quite accurate) which causes R to throw an error.</p>
</td></tr>
<tr><td><code id="predictDDMConf_+3A_.progress">.progress</code></td>
<td>
<p>logical. If <code>TRUE</code> (default) a progress bar is drawn to the console.</p>
</td></tr>
<tr><td><code id="predictDDMConf_+3A_minrt">minrt</code></td>
<td>
<p>numeric or <code>NULL</code>(default). The minimum rt for the density computation.</p>
</td></tr>
<tr><td><code id="predictDDMConf_+3A_scaled">scaled</code></td>
<td>
<p>logical. For <code>predictDDMConf_RT</code>. Whether the computed density
should be scaled to integrate to one (additional column <code>densscaled</code>). Otherwise the output
contains only the defective density (i.e. its integral is equal to the probability of a
response and not 1). If <code>TRUE</code>, the argument <code>DistConf</code> should be given, if available.
Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predictDDMConf_+3A_distconf">DistConf</code></td>
<td>
<p><code>NULL</code> or <code>data.frame</code>. A <code>data.frame</code> or <code>matrix</code> with column
names, giving the distribution of response and rating choices for
different conditions and stimulus categories in the form of the output of
<code>predictDDMConf_Conf</code>. It is only necessary, if <code>scaled=TRUE</code>, because these
probabilities are used for scaling. If <code>scaled=TRUE</code> and <code>DistConf=NULL</code>, it will be computed
with the function <code>predictDDMConf_Conf</code>, which takes some time and the function will
throw a message. Default: <code>NULL</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>predictDDMConf_Conf</code> consists merely of an integration of
the response time density, <code><a href="#topic+dDDMConf">dDDMConf</a></code>, over the
response time in a reasonable interval (0 to <code>maxrt</code>). The function
<code>predictDDMConf_RT</code> wraps these density
functions to a parameter set input and a <code>data.frame</code> output.
For the argument <code>paramDf</code>, the output of the fitting function <code><a href="#topic+fitRTConf">fitRTConf</a></code>
with the DDMConf model may be used.
</p>


<h3>Value</h3>

<p><code>predictDDMConf_Conf</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>p</code>, <code>info</code>, <code>err</code>. <code>p</code> is the predicted probability of a response
and <code>rating</code>, given the stimulus category and condition. <code>info</code> and <code>err</code> refer to the
respective outputs of the integration routine used for the computation.
<code>predictDDMConf_RT</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>rt</code> and <code>dens</code> (and <code>densscaled</code>, if <code>scaled=TRUE</code>).
</p>


<h3>Note</h3>

<p>Different parameters for different conditions are only allowed for drift rate
<code>v</code>, drift rate variability <code>sv</code>, and process variability <code>s</code>. Otherwise, <code>s</code> is
not required in <code>paramDf</code> but set to 1 by default. All other parameters are used for all
conditions.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=2,v1=0.5, v2=1, t0=0.1,z=0.55,
                      sz=0,sv=0.2, st0=0, theta1=0.8)

# 2. Predict discrete Choice x Confidence distribution:
preds_Conf &lt;- predictDDMConf_Conf(paramDf,  maxrt = 15)
head(preds_Conf)

# 3. Compute RT density
preds_RT &lt;- predictDDMConf_RT(paramDf, maxrt=4, subdivisions=200) #(scaled=FALSE)
# same output with scaled density column:
preds_RT &lt;- predictDDMConf_RT(paramDf, maxrt=4, subdivisions=200,
                              scaled=TRUE, DistConf = preds_Conf)
head(preds_RT)


  # Example of visualization
  library(ggplot2)
  preds_Conf$rating &lt;- factor(preds_Conf$rating, labels=c("unsure", "sure"))
  preds_RT$rating &lt;- factor(preds_RT$rating, labels=c("unsure", "sure"))
  ggplot(preds_Conf, aes(x=interaction(rating, response), y=p))+
    geom_bar(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")
  ggplot(preds_RT, aes(x=rt, color=interaction(rating, response), y=dens))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")+
    theme(legend.position = "bottom")
  ggplot(aggregate(densscaled~rt+correct+rating+condition, preds_RT, mean),
         aes(x=rt, color=rating, y=densscaled))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(condition), rows=vars(correct), labeller = "label_both")+
    theme(legend.position = "bottom")

# Use PDFtoQuantiles to get predicted RT quantiles
head(PDFtoQuantiles(preds_RT, scaled = FALSE))

</code></pre>

<hr>
<h2 id='predictRM'>Prediction of Confidence Rating and Reaction Time Distribution in race models of confidence</h2><span id='topic+predictRM'></span><span id='topic+predictRM_Conf'></span><span id='topic+predictIRM'></span><span id='topic+predictPCRM'></span><span id='topic+predictRM_RT'></span>

<h3>Description</h3>

<p><code>predictRM_Conf</code> predicts the categorical response distribution of
decision and confidence ratings, <code>predictRM_RT</code> computes the
RT distribution (density) in the independent and partially anti-correlated
race models  (Hellmann et al., 2023), given specific parameter
constellations. See <a href="#topic+RaceModels">RaceModels</a> for more information about the models
and parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictRM_Conf(paramDf, model = "IRM", time_scaled = FALSE, maxrt = 15,
  subdivisions = 100L, stop.on.error = FALSE, .progress = TRUE)

predictRM_RT(paramDf, model = "IRM", time_scaled = FALSE, maxrt = 9,
  subdivisions = 100L, minrt = NULL, scaled = FALSE, DistConf = NULL,
  .progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictRM_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or data frame with one row. Column names should match the names of
<a href="#topic+RaceModels">RaceModels</a> parameter names (only <code>mu1</code> and <code>mu2</code> are not used in this context but
replaced by the parameter <code>v</code>). For different stimulus quality/mean
drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,....
Different <code>s</code> parameters are possible with <code>s1</code>, <code>s2</code>, <code>s3</code>,... with equally many steps as for drift rates. Additionally, the confidence
thresholds should be given by names with <code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,....</p>
</td></tr>
<tr><td><code id="predictRM_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;IRM&quot; or &quot;PCRM&quot;. (&quot;IRMt&quot; and &quot;PCRMt&quot; will also be accepted. In that case,
time_scaled is set to TRUE.)</p>
</td></tr>
<tr><td><code id="predictRM_+3A_time_scaled">time_scaled</code></td>
<td>
<p>logical. Whether the confidence measure should be scaled by 1/sqrt(rt). Default: FALSE.
(It is set to TRUE, if model is &quot;IRMt&quot; or &quot;PCRMt&quot;)</p>
</td></tr>
<tr><td><code id="predictRM_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. The maximum RT for the
integration/density computation. Default: 15 (for <code>predictRM_Conf</code>
(integration)), 9 (for <code>predictRM_RT</code>).</p>
</td></tr>
<tr><td><code id="predictRM_+3A_subdivisions">subdivisions</code></td>
<td>
<p><code>integer</code> (default: 100).
For <code>predictRM_Conf</code> it is used as argument for the inner integral routine.
For <code>predictRM_RT</code> it is the number of points for which the density is computed.</p>
</td></tr>
<tr><td><code id="predictRM_+3A_stop.on.error">stop.on.error</code></td>
<td>
<p>logical. Argument directly passed on to integrate. Default is FALSE,
since the densities invoked may lead to slow convergence of the integrals (which are still
quite accurate) which causes R to throw an error.</p>
</td></tr>
<tr><td><code id="predictRM_+3A_.progress">.progress</code></td>
<td>
<p>logical. If TRUE (default) a progress bar is drawn to the console.</p>
</td></tr>
<tr><td><code id="predictRM_+3A_minrt">minrt</code></td>
<td>
<p>numeric or NULL(default). The minimum rt for the density computation.</p>
</td></tr>
<tr><td><code id="predictRM_+3A_scaled">scaled</code></td>
<td>
<p>logical. For <code>predictRM_RT</code>. Whether the computed density
should be scaled to integrate to one (additional column <code>densscaled</code>). Otherwise the output
contains only the defective density (i.e. its integral is equal to the probability of a
response and not 1). If <code>TRUE</code>, the argument <code>DistConf</code> should be given, if available.
Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predictRM_+3A_distconf">DistConf</code></td>
<td>
<p><code>NULL</code> or <code>data.frame</code>. A <code>data.frame</code> or <code>matrix</code> with column
names, giving the distribution of response and rating choices for
different conditions and stimulus categories in the form of the output of
<code>predictRM_Conf</code>. It is only necessary, if <code>scaled=TRUE</code>, because these
probabilities are used for scaling. If <code>scaled=TRUE</code> and <code>DistConf=NULL</code>, it will be computed
with the function <code>predictRM_Conf</code>, which takes some time and the function will
throw a message. Default: <code>NULL</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>predictRM_Conf</code> consists merely of an integration of
the response time density, <code><a href="#topic+dIRM">dIRM</a></code> and <code><a href="#topic+dPCRM">dPCRM</a></code>, over the
response time in a reasonable interval (0 to <code>maxrt</code>). The function
<code>predictRM_RT</code> wraps these density
functions to a parameter set input and a data.frame output.
For the argument <code>paramDf</code>, the output of the fitting function <code><a href="#topic+fitRTConf">fitRTConf</a></code>
with the respective model may be used.
</p>
<p>The drift rate parameters differ from those used in <code><a href="#topic+dIRM">dIRM</a></code>/<code><a href="#topic+dPCRM">dPCRM</a></code>
since in many perceptual decision experiments the drift on one accumulator is assumed to
be the negative of the other. The drift rate of the correct accumulator is <code>v</code> (<code>v1</code>, <code>v2</code>,
... respectively) in <code>paramDf</code>.
</p>


<h3>Value</h3>

<p><code>predictRM_Conf</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>p</code>, <code>info</code>, <code>err</code>. <code>p</code> is the predicted probability of a response
and <code>rating</code>, given the stimulus category and condition. <code>info</code> and <code>err</code> refer to the
respective outputs of the integration routine used for the computation.
<code>predictRM_RT</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>rt</code> and <code>dens</code> (and <code>densscaled</code>, if <code>scaled=TRUE</code>).
</p>


<h3>Note</h3>

<p>Different parameters for different conditions are only allowed for drift rate,
<code>v</code>, and process variability <code>s</code>. All other parameters are used for all
conditions.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples for "PCRM" model (equivalent applicable for "IRM" model)
# 1. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=2,b=2, v1=0.5, v2=1, t0=0.1,st0=0,
                      wx=0.6, wint=0.2, wrt=0.2,
                      theta1=4)

# 2. Predict discrete Choice x Confidence distribution:
preds_Conf &lt;- predictRM_Conf(paramDf, "PCRM", time_scaled=TRUE)
# equivalent:
preds_Conf &lt;- predictRM_Conf(paramDf, "PCRMt")
head(preds_Conf)

# 3. Compute RT density
preds_RT &lt;- predictRM_RT(paramDf, "PCRMt", maxrt=7, subdivisions=50)
# same output with scaled density column:
preds_RT &lt;- predictRM_RT(paramDf, "PCRMt", maxrt=7, subdivisions=50,
                         scaled=TRUE, DistConf = preds_Conf)
head(preds_RT)

  # produces a warning, if scaled=TRUE and DistConf missing
  preds_RT &lt;- predictRM_RT(paramDf, "PCRMt", maxrt=7, subdivisions=50,
                           scaled=TRUE)



  # Example of visualization
  library(ggplot2)
  preds_Conf$rating &lt;- factor(preds_Conf$rating, labels=c("unsure", "sure"))
  preds_RT$rating &lt;- factor(preds_RT$rating, labels=c("unsure", "sure"))
  ggplot(preds_Conf, aes(x=interaction(rating, response), y=p))+
    geom_bar(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")
  ggplot(preds_RT, aes(x=rt, color=interaction(rating, response), y=dens))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")+
    theme(legend.position = "bottom")
  ggplot(aggregate(densscaled~rt+correct+rating+condition, preds_RT, mean),
         aes(x=rt, color=rating, y=densscaled))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(condition), rows=vars(correct), labeller = "label_both")+
    theme(legend.position = "bottom")


  # Use PDFtoQuantiles to get predicted RT quantiles
  # (produces warning because of few rt steps (--&gt; inaccurate calculations))
  PDFtoQuantiles(preds_RT, scaled = FALSE)


</code></pre>

<hr>
<h2 id='predictRTConf'>Prediction of confidence rating and response time distribution for sequential sampling confidence models</h2><span id='topic+predictRTConf'></span><span id='topic+predictConf'></span><span id='topic+predictRT'></span>

<h3>Description</h3>

<p><code>predictConf</code> predicts the categorical response distribution of
decision and confidence ratings, <code>predictRT</code> computes the predicted
RT distribution (density) for the sequential sampling confidence model
specified by the argument <code>model</code>, given specific parameter constellations.
This function calls the respective functions for diffusion based
models (dynWEV and 2DSD: <code><a href="#topic+predictWEV">predictWEV</a></code>) and race models (IRM, PCRM,
IRMt, and PCRMt: <code><a href="#topic+predictRM">predictRM</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictConf(paramDf, model = NULL, maxrt = 15, subdivisions = 100L,
  simult_conf = FALSE, stop.on.error = FALSE, .progress = TRUE)

predictRT(paramDf, model = NULL, maxrt = 9, subdivisions = 100L,
  minrt = NULL, simult_conf = FALSE, scaled = FALSE, DistConf = NULL,
  .progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictRTConf_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or dataframe with one row. Column names should match the
names of the respective model parameters. For different stimulus
quality/mean drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,.... Different <code>s</code> parameters
are possible with <code>s1</code>, <code>s2</code>, <code>s3</code>... with equally many steps as for drift rates (same
for <code>sv</code> parameter in dynWEV and 2DSD).
Additionally, the confidence thresholds should be given by names with
<code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,....</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;2DSD&quot;, &quot;dynWEV&quot;, &quot;IRM&quot;, &quot;PCRM&quot;, &quot;IRMt&quot;, or &quot;PCRMt&quot;.</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. The maximum RT for the
integration/density computation. Default: 15 (for <code>predictConf</code> (integration)),
9 (for <code>predictRT</code>).</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_subdivisions">subdivisions</code></td>
<td>
<p><code>integer</code> (default: 100).
For <code>predictConf</code> it is used as argument for the inner integral routine.
For <code>predictRT</code> it is the number of points for which the density is computed.</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical, only relevant for dynWEV and 2DSD. Whether in the experiment
confidence was reported simultaneously with the decision, as then decision and confidence
judgment are assumed to have happened subsequent before response and computations are
different, when there is an observable interjudgment time (then <code>simult_conf</code> should be FALSE).</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_stop.on.error">stop.on.error</code></td>
<td>
<p>logical. Argument directly passed on to integrate. Default is FALSE,
since the densities invoked may lead to slow convergence of the integrals (which are still
quite accurate) which causes R to throw an error.</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_.progress">.progress</code></td>
<td>
<p>logical. If TRUE (default) a progress bar is drawn to the console.</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_minrt">minrt</code></td>
<td>
<p>numeric or NULL(default). The minimum rt for the density computation.</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_scaled">scaled</code></td>
<td>
<p>logical. For <code>predictRT</code>. Whether the computed density
should be scaled to integrate to one (additional column <code>densscaled</code>). Otherwise the output
contains only the defective density (i.e. its integral is equal to the probability of a
response and not 1). If <code>TRUE</code>, the argument <code>DistConf</code> should be given, if available.
Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predictRTConf_+3A_distconf">DistConf</code></td>
<td>
<p><code>NULL</code> or <code>data.frame</code>. A <code>data.frame</code> or <code>matrix</code> with column
names, giving the distribution of response and rating choices for
different conditions and stimulus categories in the form of the output of
<code>predictConf</code>. It is only necessary, if <code>scaled=TRUE</code>, because these
probabilities are used for scaling. If <code>scaled=TRUE</code> and <code>DistConf=NULL</code>, it will be computed
with the function <code>predictRM_Conf</code>, which takes some time and the function will
throw a message. Default: <code>NULL</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>predictConf</code> consists merely of an integration of
the reaction time density of the given model, <code>{d*model*}</code>, over the response
time in a reasonable interval (0 to <code>maxrt</code>). The function <code>predictRT</code> wraps
these density functions to a parameter set input and a data.frame output.
For the argument <code>paramDf</code>, the output of the fitting function <code><a href="#topic+fitRTConf">fitRTConf</a></code>
with the respective model may be used.
</p>


<h3>Value</h3>

<p><code>predictConf</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>p</code>, <code>info</code>, <code>err</code>. <code>p</code> is the predicted probability of a response
and <code>rating</code>, given the stimulus category and condition. <code>info</code> and <code>err</code> refer to the
respective outputs of the integration routine used for the computation.
<code>predictRT</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>rt</code> and <code>dens</code> (and <code>densscaled</code>, if <code>scaled=TRUE</code>).
</p>


<h3>Note</h3>

<p>Different parameters for different conditions are only allowed for drift rate,
<code>v</code>, drift rate variability, <code>sv</code> (in dynWEV and 2DSD), and process variability
<code>s</code>. All other parameters are used for all conditions.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples for "dynWEV" model (equivalent applicable for
# all other models (with different parameters!))

# 1. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=1.5,v1=0.2, v2=1, t0=0.1,z=0.52,
                      sz=0.3,sv=0.4, st0=0,  tau=3, w=0.5,
                      theta1=1, svis=0.5, sigvis=0.8)

# 2. Predict discrete Choice x Confidence distribution:
preds_Conf &lt;- predictConf(paramDf, "dynWEV", maxrt = 25, simult_conf=TRUE)
head(preds_Conf)


# 3. Compute RT density
preds_RT &lt;- predictRT(paramDf, "dynWEV") #(scaled=FALSE)
# same output with default rt-grid and without scaled density column:
preds_RT &lt;- predictRT(paramDf, "dynWEV", maxrt=5, subdivisions=200,
                      minrt=paramDf$tau+paramDf$t0, simult_conf = TRUE,
                      scaled=TRUE, DistConf = preds_Conf)
head(preds_RT)

  # produces a warning, if scaled=TRUE and DistConf missing
  preds_RT &lt;- predictRT(paramDf, "dynWEV",
                           scaled=TRUE)



  # Example of visualization
  library(ggplot2)
  preds_Conf$rating &lt;- factor(preds_Conf$rating, labels=c("unsure", "sure"))
  preds_RT$rating &lt;- factor(preds_RT$rating, labels=c("unsure", "sure"))
  ggplot(preds_Conf, aes(x=interaction(rating, response), y=p))+
    geom_bar(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")
  ggplot(preds_RT, aes(x=rt, color=interaction(rating, response), y=densscaled))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")+
    theme(legend.position = "bottom")+ ggtitle("Scaled Densities")
  ggplot(aggregate(dens~rt+correct+rating+condition, preds_RT, mean),
         aes(x=rt, color=rating, y=dens))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(condition), rows=vars(correct), labeller = "label_both")+
    theme(legend.position = "bottom")+ ggtitle("Non-Scaled Densities")

# Use PDFtoQuantiles to get predicted RT quantiles
head(PDFtoQuantiles(preds_RT, scaled = FALSE))

</code></pre>

<hr>
<h2 id='predictRTConfModels'>Prediction of confidence and RT distributions for several sequential
sampling confidence models and parameter constellations in parallel</h2><span id='topic+predictRTConfModels'></span><span id='topic+predictConfModels'></span><span id='topic+predictRTModels'></span>

<h3>Description</h3>

<p>This function is a wrapper around the functions <code><a href="#topic+predictRTConf">predictRTConf</a></code> (see
there for more information). It calls the respective function for predicting the
response distribution (discrete decision and rating outcomes) and the rt density
(density for decision, rating and response time) for every model and
participant combination in <code>paramDf</code>.
Also, see <code><a href="#topic+dWEV">dWEV</a></code>, <code><a href="#topic+d2DSD">d2DSD</a></code>, and <code><a href="#topic+dRM">dRM</a></code> for more
information about the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictConfModels(paramDf, maxrt = 15, subdivisions = 100L,
  simult_conf = FALSE, stop.on.error = FALSE, .progress = TRUE,
  parallel = FALSE, n.cores = NULL)

predictRTModels(paramDf, maxrt = 9, subdivisions = 100L, minrt = NULL,
  simult_conf = FALSE, scaled = FALSE, DistConf = NULL,
  .progress = TRUE, parallel = FALSE, n.cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictRTConfModels_+3A_paramdf">paramDf</code></td>
<td>
<p>a dataframe with one row per combination of model and
participant/parameter set. Columns may include a <code>participant</code> (<code>sbj</code>, or
<code>subject</code>) column, and must include a <code>model</code> column and the names of the model parameters.
For different stimulus
quality/mean drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,.... Different <code>s</code> parameters
are possible with <code>s1</code>, <code>s2</code>, <code>s3</code>... with equally many steps as for drift rates (same
for <code>sv</code> parameter in dynWEV and 2DSD).
Additionally, the confidence thresholds should be given by names with
<code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,....</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. The maximum RT for the
integration/density computation. Default: 15 (for <code>predictConfModels</code> (integration)) and
9 (for <code>predictRTModels</code>).</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_subdivisions">subdivisions</code></td>
<td>
<p><code>integer</code> (default: 100).
For <code>predictConfModels</code> it is used as argument for the inner integral routine.
For <code>predictRTModels</code> it is the number of points for which the density is computed.</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical, only relevant for dynWEV and 2DSD. Whether in the experiment
confidence was reported simultaneously with the decision, as then decision and confidence
judgment are assumed to have happened subsequent before response and computations are
different, when there is an observable interjudgment time (then <code>simult_conf</code> should be FALSE).</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_stop.on.error">stop.on.error</code></td>
<td>
<p>logical. Argument directly passed on to integrate. Default is FALSE,
since the densities invoked may lead to slow convergence of the integrals (which are still
quite accurate) which causes R to throw an error.</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_.progress">.progress</code></td>
<td>
<p>logical. If TRUE (default) a progress bar is drawn to the console. (Works
for some OS only when <code>parallel=FALSE</code>.)</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_parallel">parallel</code></td>
<td>
<p>logical. If TRUE, prediction is parallelized over participants and models
(i.e. over the calls for the respective <code><a href="#topic+predictRTConf">predictRTConf</a></code> functions).</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_n.cores">n.cores</code></td>
<td>
<p>integer. If <code>parallel</code> is TRUE, the number of cores used for
parallelization is required. If <code>NULL</code> (default) the number of available cores -1 is used.</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_minrt">minrt</code></td>
<td>
<p>numeric or <code>NULL</code>(default). The minimum rt for the density computation.
If <code>NULL</code>, the minimal possible response time possible with given parameters will be used (min(t0)).</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_scaled">scaled</code></td>
<td>
<p>logical. Whether the computed density
should be scaled to integrate to one (additional column <code>densscaled</code>). Otherwise the output
contains only the defective density (i.e. its integral is equal to the probability of a
response and not 1). If <code>TRUE</code>, the argument <code>DistConf</code> should be given, if available.
Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predictRTConfModels_+3A_distconf">DistConf</code></td>
<td>
<p><code>NULL</code> or <code>data.frame</code>. A <code>data.frame</code> with participant
and model columns and columns, giving the distribution of response and rating choices for
different conditions and stimulus categories in the form of the output of
<code>predictConfModels</code>. It is only necessary if <code>scaled=TRUE</code>, because these
probabilities are used for scaling. If <code>scaled=TRUE</code> and <code>DistConf=NULL</code>, it will be computed
with the function <code>predictConfModels</code>, which takes some time and the function will
throw a message. Default: <code>NULL</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions merely split the input data frame by model participants combinations,
call the equivalent <code><a href="#topic+predictRTConf">predictRTConf</a></code> functions for the individual parameter sets
and bind the outputs together. They are included for convenience and the easy parallelization,
which facilitates speeding up computations considerably. For the argument
<code>paramDf</code>, the output of the fitting function <code><a href="#topic+fitRTConfModels">fitRTConfModels</a></code> with the
respective models and participants may be used.
</p>
<p>The function <code><a href="#topic+predictConf">predictConf</a></code> (called by <code>predictConfModels</code>)
consists merely of an integration of the reaction time density or the given model,
<code>{d*model*}</code>, over the reaction time in a reasonable interval (0 to <code>maxrt</code>).
The function <code><a href="#topic+predictRT">predictRT</a></code> (called by <code>predictRTModels</code>) wraps these
density functions to a parameter set input and a data.frame output. '
Note, that the encoding for stimulus identity is different between diffusion based models
(2DSD, dynWEV) and race models (IRM(t), PCRM(t)). Therefore, in the columns stimulus and
response there will be a mix of encodings: -1/1 for diffusion based models and 1/2 for
race models. This, usually is not important, since for further aggregation models will
not be mixed.
</p>


<h3>Value</h3>

<p><code>predictConfModels</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>participant</code> (or <code>sbj</code>,
subject depending on the input), <code>model</code>, <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>p</code>, <code>info</code>, <code>err</code>. <code>p</code> is the predicted probability of a response
and <code>rating</code>, given the stimulus category and condition. <code>info</code> and <code>err</code> refer to the
respective outputs of the integration routine used for the computation.
<code>predictRTModels</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>participant</code> (or <code>sbj</code>,
subject depending on the input), <code>model</code>, <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>rt</code> and <code>dens</code> (and <code>densscaled</code>, if <code>scaled=TRUE</code>).
</p>


<h3>Note</h3>

<p>Different parameters for different conditions are only allowed for drift rate
<code>v</code>, drift rate variability <code>sv</code> (only dynWEV and 2DSD), and process variability
<code>s</code>. All other parameters are used for all conditions.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># First example for 2 participant and the "dynWEV" model
# (equivalent applicable for
# all other models (with different parameters!))
# 1. Define two parameter sets from different participants
paramDf &lt;- data.frame(participant = c(1,2), model="dynWEV",
                      a=c(1.5, 2),v1=c(0.2,0.1), v2=c(1, 1.5),
                      t0=c(0.1, 0.2),z=c(0.52,0.45),
                      sz=c(0.0,0.3),sv=c(0.4,0.7), st0=c(0,0.01),
                      tau=c(2,3), w=c(0.5,0.2),
                      theta1=c(1,1.5), svis=c(0.5,0.1), sigvis=c(0.8, 1.2))
paramDf
# 2. Predict discrete Choice x Confidence distribution:
# model is not an extra argument but must be a column of paramDf
preds_Conf &lt;- predictConfModels(paramDf, maxrt = 15, simult_conf=TRUE,
                                .progress=TRUE, parallel = FALSE)
# 3. Compute RT density
preds_RT &lt;- predictRTModels(paramDf, maxrt=6, subdivisions=100,
                      scaled=TRUE, DistConf = preds_Conf,
                      parallel=FALSE, .progress = TRUE)
head(preds_RT)

  # produces a warning, if scaled=TRUE and DistConf missing
  preds_RT &lt;- predictRTModels(paramDf, scaled=TRUE)

# Use PDFtoQuantiles to get predicted RT quantiles
head(PDFtoQuantiles(preds_RT, scaled = FALSE))

# Second Example: only one parameter set but for two different models

  paramDf1 &lt;- data.frame(model="dynWEV", a=1.5,v1=0.2, v2=1, t0=0.1,z=0.52,
                        sz=0.3,sv=0.4, st0=0,  tau=3, w=0.5,
                        theta1=1, svis=0.5, sigvis=0.8)
  paramDf2 &lt;- data.frame(model="PCRMt", a=2,b=2, v1=0.5, v2=1, t0=0.1,st0=0,
                        wx=0.6, wint=0.2, wrt=0.2, theta1=4)
  paramDf &lt;- dplyr::full_join(paramDf1, paramDf2)
  paramDf  # each model parameters sets hat its relevant parameters
  predictConfModels(paramDf, parallel=FALSE, .progress=TRUE)


</code></pre>

<hr>
<h2 id='predictWEV'>Prediction of Confidence Rating and Response Time Distribution in dynaViTE,
dynWEV, and 2DSD confidence models</h2><span id='topic+predictWEV'></span><span id='topic+predictWEV_Conf'></span><span id='topic+predictdynWEV'></span><span id='topic+predict2DSD'></span><span id='topic+predictWEV_RT'></span>

<h3>Description</h3>

<p><code>predictWEV_Conf</code> predicts the categorical response distribution of
decision and confidence ratings, <code>predictWEV_RT</code> computes the predicted
RT distribution (density) in the 2DSD Model (Pleskac &amp; Busemeyer, 2010) and the
dynWEV model (Hellmann et al., 2023), given specific parameter constellations.
See <code><a href="#topic+dWEV">dWEV</a></code> and <code><a href="#topic+d2DSD">d2DSD</a></code> for more information about parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictWEV_Conf(paramDf, model = "dynaViTE", maxrt = 15,
  subdivisions = 100L, simult_conf = FALSE, stop.on.error = FALSE,
  precision = 1e-05, .progress = TRUE)

predictWEV_RT(paramDf, model = NULL, maxrt = 9, subdivisions = 100L,
  minrt = NULL, simult_conf = FALSE, scaled = FALSE, DistConf = NULL,
  precision = 1e-05, .progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictWEV_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or dataframe with one row. Column names should match the names
of <a href="#topic+dynaViTE">dynaViTE</a> and <a href="#topic+2DSD">2DSD</a> model specific parameter names.
For different stimulus quality/mean drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,....
Different <code>sv</code> and/or <code>s</code> parameters are possible with <code>sv1</code>, <code>sv2</code>, <code>sv3</code>... (<code>s1</code>, <code>s2</code>, <code>s3</code>,...
respectively) with equally many steps as for drift rates. Additionally, the confidence
thresholds should be given by names with <code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,....</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;dynaViTE&quot;, &quot;dynWEV&quot;, or &quot;2DSD&quot;.</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. The maximum RT for the integration/density computation.
Default: 15 (for <code>predictWEV_Conf</code> (integration)), 9 (for <code>predictWEV_RT</code>).</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_subdivisions">subdivisions</code></td>
<td>
<p>integer (default: 100).
For <code>predictWEV_Conf</code> it is used as argument for the inner integral routine.
For <code>predictWEV_RT</code> it is the number of points for which the density is computed.</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical. Whether in the experiment confidence was reported simultaneously
with the decision, as then decision and confidence judgment are assumed to have happened
subsequent before response and computations are different, when there is an observable
interjudgment time (then <code>simult_conf</code> should be FALSE).</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_stop.on.error">stop.on.error</code></td>
<td>
<p>logical. Argument directly passed on to integrate. Default is FALSE,
since the densities invoked may lead to slow convergence of the integrals (which are still
quite accurate) which causes R to throw an error.</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_precision">precision</code></td>
<td>
<p>numerical scalar value. Precision of calculation. Corresponds to the
step size of integration w.r.t. <code>z</code> and <code>t0</code>. Default is 1e-5.</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_.progress">.progress</code></td>
<td>
<p>logical. if TRUE (default) a progress bar is drawn to the console.</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_minrt">minrt</code></td>
<td>
<p>numeric or NULL(default). The minimum rt for the density computation.</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_scaled">scaled</code></td>
<td>
<p>logical. For <code>predictWEV_RT</code>. Whether the computed density
should be scaled to integrate to one (additional column <code>densscaled</code>). Otherwise the output
contains only the defective density (i.e. its integral is equal to the probability of a
response and not 1). If <code>TRUE</code>, the argument <code>DistConf</code> should be given, if available.
Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="predictWEV_+3A_distconf">DistConf</code></td>
<td>
<p><code>NULL</code> or <code>data.frame</code>. A <code>data.frame</code> or <code>matrix</code> with column
names, giving the distribution of response and rating choices for
different conditions and stimulus categories in the form of the output of
<code>predictWEV_Conf</code>. It is only necessary, if <code>scaled=TRUE</code>, because these
probabilities are used for scaling. If <code>scaled=TRUE</code> and <code>DistConf=NULL</code>, it will be computed
with the function <code>predictWEV_Conf</code>, which takes some time and the function will
throw a message. Default: <code>NULL</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>predictWEV_Conf</code> consists merely of an integration of
the response time density, <code><a href="#topic+dWEV">dWEV</a></code> and <code><a href="#topic+d2DSD">d2DSD</a></code>, over the response time in a reasonable
interval (<code>t0</code> to <code>maxrt</code>). The function <code>predictWEV_RT</code> wraps these density
functions to a parameter set input and a data.frame output.
For the argument <code>paramDf</code>, the output of the fitting function <code><a href="#topic+fitRTConf">fitRTConf</a></code>
with the respective model may be used.
</p>


<h3>Value</h3>

<p><code>predictWEV_Conf</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>p</code>, <code>info</code>, <code>err</code>. <code>p</code> is the predicted probability of a response
and <code>rating</code>, given the stimulus category and condition. <code>info</code> and <code>err</code> refer to the
respective outputs of the integration routine used for the computation.
<code>predictWEV_RT</code> returns a <code>data.frame</code>/<code>tibble</code> with columns: <code>condition</code>, <code>stimulus</code>,
<code>response</code>, <code>rating</code>, <code>correct</code>, <code>rt</code> and <code>dens</code> (and <code>densscaled</code>, if <code>scaled=TRUE</code>).
</p>


<h3>Note</h3>

<p>Different parameters for different conditions are only allowed for drift rate
<code>v</code>, drift rate variability <code>sv</code>, and process variability <code>s</code>. Otherwise, <code>s</code> is
not required in <code>paramDf</code> but set to 1 by default. All other parameters are used for all
conditions.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>
<p>Pleskac, T. J., &amp; Busemeyer, J. R. (2010). Two-Stage Dynamic Signal Detection:
A Theory of Choice, Decision Time, and Confidence, <em>Psychological Review</em>, 117(3),
864-901. doi:10.1037/a0019737
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples for "dynWEV" model (equivalent applicable for "2DSD" model (with less parameters))
# 1. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=2.5,v1=0.5, v2=1, t0=0.1,z=0.55,
                      sz=0,sv=0.2, st0=0,  tau=3, w=0.3,
                      theta1=0.8, svis=0.5, sigvis=0.8)

# 2. Predict discrete Choice x Confidence distribution:
preds_Conf &lt;- predictWEV_Conf(paramDf, "dynWEV", maxrt = 15)
head(preds_Conf)

  # To set simult_conf=TRUE makes a minor difference in the discrete distribution,
  # because we integrate over response times (we just adapt maxrt for comparison)
  preds_Conf2 &lt;- predictWEV_Conf(paramDf, "dynWEV", simult_conf = TRUE, maxrt = 15+paramDf$tau)
  summary(preds_Conf$p-preds_Conf2$p) # difference in predicted probabilities


# 3. Compute RT density
preds_RT &lt;- predictWEV_RT(paramDf, "dynWEV", maxrt=4, subdivisions=200) #(scaled=FALSE)
# same output with scaled density column:
preds_RT &lt;- predictWEV_RT(paramDf, "dynWEV", maxrt=4, subdivisions=200,
                         scaled=TRUE, DistConf = preds_Conf)
head(preds_RT)

  # produces a warning, if scaled=TRUE and DistConf missing
  preds_RT &lt;- predictWEV_RT(paramDf, "dynWEV", maxrt=4, subdivisions=200,
                           scaled=TRUE)



  # Example of visualization
  library(ggplot2)
  preds_Conf$rating &lt;- factor(preds_Conf$rating, labels=c("unsure", "sure"))
  preds_RT$rating &lt;- factor(preds_RT$rating, labels=c("unsure", "sure"))
  ggplot(preds_Conf, aes(x=interaction(rating, response), y=p))+
    geom_bar(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")
  ggplot(preds_RT, aes(x=rt, color=interaction(rating, response), y=dens))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(stimulus), rows=vars(condition), labeller = "label_both")+
    theme(legend.position = "bottom")
  ggplot(aggregate(densscaled~rt+correct+rating+condition, preds_RT, mean),
         aes(x=rt, color=rating, y=densscaled))+
    geom_line(stat="identity")+
    facet_grid(cols=vars(condition), rows=vars(correct), labeller = "label_both")+
    theme(legend.position = "bottom")

# Use PDFtoQuantiles to get predicted RT quantiles
head(PDFtoQuantiles(preds_RT, scaled = FALSE))

</code></pre>

<hr>
<h2 id='RaceModels'>Independent and partially anti-correlated Race Model for Decision Confidence</h2><span id='topic+RaceModels'></span><span id='topic+dIRM'></span><span id='topic+dPCRM'></span><span id='topic+rRM'></span><span id='topic+dRM'></span><span id='topic+rIRM'></span><span id='topic+rPCRM'></span><span id='topic+racemodels'></span><span id='topic+dIRM2'></span>

<h3>Description</h3>

<p>Probability densities and random number generators for response times,
decisions and confidence judgments in the independent Race Model
(<code>dIRM</code>/<code>rIRM</code>) or partially (anti-)correlated Race Model (<code>dPCRM</code>/<code>rPCRM</code>),
i.e. the probability of a given response (response: winning accumulator
(1 or 2)) at a given time (rt) and the confidence measure in the interval
between <code>th1</code> and <code>th2</code> (Hellmann et al., 2023). The definition of the
confidence measure depends on the argument <code>time_scaled</code> (see Details).
The computations are based on Moreno-Bote (2010).
The parameters for the models are <code>mu1</code> and <code>mu2</code> for the drift
rates, <code>a</code>, <code>b</code> for the upper thresholds of the two accumulators
and <code>s</code> for the incremental standard deviation of the processes and
<code>t0</code> and <code>st0</code> for the  minimum and range of uniformly distributed
non-decision times (including encoding and motor time).
For the computation of confidence judgments, the parameters <code>th1</code> and
<code>th2</code> for the lower and upper bound of the interval for confidence
measure and if <code>time_scaled</code> is <code>TRUE</code> the weight parameters <code>wx</code>, <code>wrt</code>,
<code>wint</code> for the computation of the confidence measure are required (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dIRM(rt, response = 1, mu1, mu2, a, b, th1, th2, wx = 1, wrt = 0,
  wint = 0, t0 = 0, st0 = 0, s1 = 1, s2 = 1, s = NULL,
  time_scaled = TRUE, step_width = NULL)

dIRM2(rt, response = 1, mu1, mu2, a, b, th1, th2, wx = 1, wrt = 0,
  wint = 0, t0 = 0, st0 = 0, s1 = 1, s2 = 1, smu1 = 0, smu2 = 0,
  sza = 0, szb = 0, s = NULL, time_scaled = TRUE, step_width = NULL)

dPCRM(rt, response = 1, mu1, mu2, a, b, th1, th2, wx = 1, wrt = 0,
  wint = 0, t0 = 0, st0 = 0, s1 = 1, s2 = 1, s = NULL,
  time_scaled = TRUE, step_width = NULL)

rIRM(n, mu1, mu2, a, b, wx = 1, wrt = 0, wint = 0, t0 = 0, st0 = 0,
  s1 = 1, s2 = 1, s = NULL, smu1 = 0, smu2 = 0, sza = 0, szb = 0,
  time_scaled = TRUE, step_width = NULL, delta = 0.01, maxrt = 15)

rPCRM(n, mu1, mu2, a, b, wx = 1, wrt = 0, wint = 0, t0 = 0, st0 = 0,
  s1 = 1, s2 = 1, s = NULL, smu1 = 0, smu2 = 0, sza = 0, szb = 0,
  time_scaled = TRUE, step_width = NULL, delta = 0.01, maxrt = 15)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RaceModels_+3A_rt">rt</code></td>
<td>
<p>a numeric vector of RTs. For convenience also a <code>data.frame</code> with
columns <code>rt</code> and <code>response</code> is possible.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_response">response</code></td>
<td>
<p>numeric vector with values in <code>c(1, 2)</code>, giving the accumulator that hit its
boundary first.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_mu1">mu1</code></td>
<td>
<p>numeric. Drift rate for the first accumulator</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_mu2">mu2</code></td>
<td>
<p>numeric. Drift rate for the second accumulator</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_a">a</code></td>
<td>
<p>positive numeric. Distance from starting point to boundary of the first accumulator.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_b">b</code></td>
<td>
<p>positive numeric. Distance from starting point to boundary of the second accumulator.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_th1">th1</code></td>
<td>
<p>numeric. Lower bound of interval range for the confidence measure.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_th2">th2</code></td>
<td>
<p>numeric. Upper bound of interval range for the confidence measure.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_wx">wx</code></td>
<td>
<p>numeric. Weight on losing accumulator for the computation of the confidence measure.
(Used only if <code>time_scale=TRUE</code>,  1)</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_wrt">wrt</code></td>
<td>
<p>numeric. Weight on reaction time for the computation of the confidence measure.
(Used only if <code>time_scale=TRUE</code>, Default 0)</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_wint">wint</code></td>
<td>
<p>numeric. Weight on the interaction of losing accumulator and reaction time for
the computation of the confidence measure. (Used only if <code>time_scale=TRUE</code>,
Default 0)</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_t0">t0</code></td>
<td>
<p>numeric. Lower bound of non-decision time component in observable response times.
Range: <code>t0&gt;=0</code>. Default: 0.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_st0">st0</code></td>
<td>
<p>numeric. Range of a uniform distribution for non-decision time. Range: <code>st0&gt;=0</code>.
Default: 0.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_s1">s1</code></td>
<td>
<p>numeric. Diffusion constant of the first accumulator.  Usually fixed to 1 for most
purposes as it scales other parameters (see Details). Range: <code>s1&gt;0</code>, Default: 1.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_s2">s2</code></td>
<td>
<p>numeric. Diffusion constant of the second accumulator.  Usually fixed to 1 for most
purposes as it scales other parameters (see Details). Range: <code>s2&gt;0</code>, Default: 1.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_s">s</code></td>
<td>
<p>numeric. Alternative way to specify diffusion constants, if both are assumed to be equal.
If both (<code>s1</code>, <code>s2</code> and <code>s</code>) are given, only <code>s1</code> and <code>s2</code> will be used.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_time_scaled">time_scaled</code></td>
<td>
<p>logical. Whether the confidence measure should be time-dependent. See Details.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_step_width">step_width</code></td>
<td>
<p>numeric. Step size for the integration in t0 (motor time). Default: 1e-6.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_smu1">smu1</code></td>
<td>
<p>numeric. Between-trial variability in the drift rate of the first accumulator.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_smu2">smu2</code></td>
<td>
<p>numeric. Between-trial variability in the drift rate of the second accumulator.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_sza">sza</code></td>
<td>
<p>numeric. Between-trial variability in starting point of the first accumulator.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_szb">szb</code></td>
<td>
<p>numeric. Between-trial variability in starting point of the second accumulator.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_n">n</code></td>
<td>
<p>integer. The number of samples generated.</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_delta">delta</code></td>
<td>
<p>numeric. Discretization step size for simulations in the stochastic process</p>
</td></tr>
<tr><td><code id="RaceModels_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. Maximum decision time returned. If the simulation of the stochastic
process exceeds a decision time of <code>maxrt</code>, the <code>response</code> will be set to 0 and the <code>maxrt</code>
will be returned as <code>rt</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters are formulated, s.t. both accumulators start at 0 and trigger a decision at their
positive boundary <code>a</code> and <code>b</code> respectively. That means, both parameters have to be positive.
Internally the computations adapt the parametrization of Moreno-Bote (2010).
</p>
<p><code>time_scaled</code> determines whether the confidence measure is computed in accordance to the
Balance of Evidence hypothesis (if <code>time_scaled=FALSE</code>), i.e. if <code>response</code> is 1 at time T and
<code class="reqn">X_2</code> is the second accumulator, then
</p>
<p style="text-align: center;"><code class="reqn">conf = b - X_2(T)</code>
</p>
<p>.
Otherwise, if <code>time_scaled=TRUE</code> (default), confidence is computed as linear combination of
Balance of Evidence, decision time, and an interaction term, i.e.
</p>
<p style="text-align: center;"><code class="reqn">conf = wx (b-X_2 (T)) + wrt\frac{1}{\sqrt{T}} + wint\frac{b-X_2(T)}{\sqrt{T}}.</code>
</p>

<p>Usually the weights (<code>wx</code>, <code>wrt</code>, <code>wint</code>) should sum to 1, as the confidence thresholds
(<code>th1</code> and <code>th2</code>) may be scaled according to their sum. If this is not the case, they will be scaled
accordingly internally! Usually, this formula results in lower confidence when the reaction time is
longer but the state of the second accumulator is held constant. It is based on the optimal decision
confidence in Moreno-Bote (2010).
</p>
<p>For convenience, the likelihood function allows that the first argument is a <code>data.frame</code> containing the
information of the first and second argument in the columns
(i.e., <code>rt</code> and <code>response</code>). Other columns (as well as passing
<code>response</code> separately as argument) will be ignored.
</p>
<p>The simulations are done by simulating normal variables in discretized steps until
one process reaches the boundary. If no boundary is met within the maximum time, response is
set to 0.
</p>


<h3>Value</h3>

<p><code>dIRM</code> and <code>dPCRM</code> return the numerical value of the probability density in a numerical vector of the same
length as <code>rt</code>.
</p>
<p><code>rIRM</code> and <code>dPCRM</code> return a <code>data.frame</code> with four columns and <code>n</code> rows. Column names are <code>rt</code> (response
time), <code>response</code> (1 or 2, indicating which accumulator hit its boundary first),
<code>xl</code> (the final state of the loosing accumulator), and <code>conf</code> (the
value of the confidence measure; not discretized!).
</p>
<p>The race parameters (as well as <code>response</code>, <code>th1</code>,
and <code>th2</code>) are recycled to the length of the result (either <code>rt</code> or <code>n</code>).
In other words, the functions are completely vectorized for all parameters
and even the response.
</p>


<h3>Note</h3>

<p>Similarly to the drift diffusion models (like <code>ddiffusion</code> and
<code><a href="#topic+dWEV">dWEV</a></code>), <code>s1</code> and <code>s2</code> are scaling factors (<code>s1</code> scales: <code>mu1</code> and  <code>a</code>,
<code>s2</code> scales: <code>mu2</code> and <code>b</code>, and depending on response: if <code>response=2</code>, <code>s1</code> scales
<code>th1</code>,<code>th2</code>,and <code>wrt</code>), otherwise <code>s2</code> is the scaling factor. It is sometimes
assumed (Moreno-Bote, 2010), that both noise terms are equal, then they should definitely be
fixed for fitting.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>
<p>Moreno-Bote, R. (2010). Decision confidence and uncertainty in diffusion models with partially
correlated neuronal integrators. Neural Computation, 22(7), 1786–1811. doi:10.1162/neco.2010.12-08-930
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot rt distribution ignoring confidence
curve(dPCRM(x, 1, mu1=0.5, mu2=-0.5, a=1, b=1, th1=-Inf, th2=Inf, t0=0.1), xlim=c(0,2.5))
curve(dPCRM(x, 2, mu1=0.5, mu2=-0.5, a=1, b=1, th1=-Inf, th2=Inf, t0=0.1), col="red", add=TRUE)
curve(dIRM(x, 1, mu1=0.5, mu2=-0.5, a=1, b=1, th1=-Inf, th2=Inf, t0=0.1), lty=2,add=TRUE)
curve(dIRM(x, 2, mu1=0.5, mu2=-0.5, a=1, b=1, th1=-Inf, th2=Inf, t0=0.1),
      col="red", lty=2, add=TRUE)
# t0 indicates minimal response time possible
abline(v=0.1)
## Following example may be equivalently used for the IRM model functions.
# Generate a random sample
df1 &lt;- rPCRM(5000,  mu1=0.2, mu2=-0.2, a=1, b=1, t0=0.1,
            wx = 1) # Balance of Evidence
# Same RT and response distribution but different confidence distribution
df2 &lt;- rPCRM(5000,  mu1=0.2, mu2=-0.2, a=1, b=1, t0=0.1,
             wint = 0.2, wrt=0.8)
head(df1)

# Compute density with rt and response as separate arguments
dPCRM(seq(0, 2, by =0.4), response= 2, mu1=0.2, mu2=-0.2, a=1, b=1, th1=0.5,
         th2=2, wx = 0.3, wint=0.4, wrt=0.1, t0=0.1)
# Compute density with rt and response in data.frame argument
df1 &lt;- subset(df1, response !=0) # drop trials where no accumulation hit its boundary
dPCRM(df1[1:5,], mu1=0.2, mu2=-0.2, a=1, b=1, th1=0, th2=Inf, t0=0.1)
# s1 and s2 scale other decision relevant parameters
 s &lt;- 2  # common (equal) standard deviation
dPCRM(df1[1:5,], mu1=0.2*s, mu2=-0.2*s, a=1*s, b=1*s, th1=0, th2=Inf, t0=0.1, s1=s, s2=s)
s1 &lt;- 2  # different standard deviations
s2 &lt;- 1.5
dPCRM(df1[1:5,], mu1=0.2*s1, mu2=-0.2*s2, a=1*s1, b=1*s2, th1=0, th2=Inf, t0=0.1, s1=s1, s2=s2)


# s1 and s2 scale also confidence parameters
df1[1:5,]$response &lt;- 2   # set response to 2
# for confidence it is important to scale confidence parameters with
# the right variation parameter (the one of the loosing accumulator)
dPCRM(df1[1:5,], mu1=0.2, mu2=-0.2, a=1, b=1,
     th1=0.5, th2=2, wx = 0.3, wint=0.4, wrt=0.1, t0=0.1)
dPCRM(df1[1:5,], mu1=0.2*s1, mu2=-0.2*s2, a=1*s1, b=1*s2,
      th1=0.5, th2=2, wx = 0.3/s1, wint = 0.4/s1, wrt = 0.1, t0=0.1, s1=s1, s2=s2)
dPCRM(df1[1:5,], mu1=0.2*s1, mu2=-0.2*s2, a=1*s1, b=1*s2,
      th1=0.5*s1, th2=2*s1, wx = 0.3, wint = 0.4, wrt = 0.1*s1, t0=0.1, s1=s1, s2=s2)

two_samples &lt;- rbind(cbind(df1, ws="BoE"),
                   cbind(df2, ws="RT"))
# drop not finished decision processes
two_samples &lt;- two_samples[two_samples$response!=0,]
# no difference in RT distributions
boxplot(rt~ws+response, data=two_samples)
# but different confidence distributions
boxplot(conf~ws+response, data=two_samples)
if (requireNamespace("ggplot2", quietly = TRUE)) {
require(ggplot2)
ggplot(two_samples, aes(x=rt, y=conf))+
  stat_density_2d(aes(fill = after_stat(density)),
                  geom = "raster", contour = FALSE, h=c(0.3, 0.7)) +
  xlim(c(0.2, 1.3))+ ylim(c(0, 2.5))+
  facet_grid(cols=vars(ws), rows=vars(response), labeller = "label_both")
}
# Restricting to specific confidence region
df1 &lt;- df1[df1$conf &gt;0 &amp; df1$conf &lt;1,]
dPCRM(df1[1:5,], th1=0, th2=1,mu1=0.2, mu2=-0.2, a=1, b=1, t0=0.1,wx = 1 )

</code></pre>

<hr>
<h2 id='rLCA'>Simulation of confidence ratings and RTs in leaky competing accumulator model</h2><span id='topic+rLCA'></span><span id='topic+simulateLCA'></span>

<h3>Description</h3>

<p>Simulates the decision responses, reaction times and state of the loosing accumulator
together with a confidence measure in the leaky competing accumulator model.
Optionally, there is a post-decisional accumulation period, where the processes continues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rLCA(n, mu1, mu2, th1, th2, k = 0, beta = 0, SPV = 0, tau = 0,
  wx = 1, wrt = 0, wint = 0, t0 = 0, st0 = 0, pi = 0, sig = 1,
  time_scaled = TRUE, simult_conf = FALSE, delta = 0.01, maxrt = 15)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rLCA_+3A_n">n</code></td>
<td>
<p>integer. number of samples.</p>
</td></tr>
<tr><td><code id="rLCA_+3A_mu1">mu1</code></td>
<td>
<p>mean momentary evidence for alternative 1</p>
</td></tr>
<tr><td><code id="rLCA_+3A_mu2">mu2</code></td>
<td>
<p>mean momentary evidence for alternative 2</p>
</td></tr>
<tr><td><code id="rLCA_+3A_th1">th1</code></td>
<td>
<p>decision threshold for alternative 1</p>
</td></tr>
<tr><td><code id="rLCA_+3A_th2">th2</code></td>
<td>
<p>decision threshold for alternative 2</p>
</td></tr>
<tr><td><code id="rLCA_+3A_k">k</code></td>
<td>
<p>leakage (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_beta">beta</code></td>
<td>
<p>inhibition  (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_spv">SPV</code></td>
<td>
<p>variation in starting points  (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_tau">tau</code></td>
<td>
<p>fixed post decisional accumulation period  (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_wx">wx</code></td>
<td>
<p>weight on balance of evidence in confidence measure  (default: 1)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_wrt">wrt</code></td>
<td>
<p>weight on RT in confidence measure  (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_wint">wint</code></td>
<td>
<p>weight on interaction of evidence and RT in confidence measure (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_t0">t0</code></td>
<td>
<p>minimal non-decision time (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_st0">st0</code></td>
<td>
<p>range of uniform distribution of non-decision time (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_pi">pi</code></td>
<td>
<p>factor for input dependent noise of infinitesimal variance of processes (default: 0)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_sig">sig</code></td>
<td>
<p>input independent component of infinitesimal variance of processes (default: 1)</p>
</td></tr>
<tr><td><code id="rLCA_+3A_time_scaled">time_scaled</code></td>
<td>
<p>logical. Whether a time_scaled transformation for the confidence measure should
be used.</p>
</td></tr>
<tr><td><code id="rLCA_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical. Whether in the experiment confidence was reported simultaneously
with the decision. If that is the case decision and confidence judgment are assumed to have happened
subsequent before the response. Therefore <code>tau</code> is included in the response time. If the decision was
reported before the confidence report, <code>simul_conf</code> should be <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="rLCA_+3A_delta">delta</code></td>
<td>
<p>numerical. Size of steps for the discretized simulation (see details).</p>
</td></tr>
<tr><td><code id="rLCA_+3A_maxrt">maxrt</code></td>
<td>
<p>numerical. Maximum reaction time to be simulated (see details). Default: 15.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulation is done by simulating discretized steps until one process reaches
the boundary with an update rule:
</p>
<p style="text-align: center;"><code class="reqn">\delta X_i(t) = \max (0, X_i(t) + \delta_t ((k-1)X_i(t)-\beta X_{j=i} (t) + \mu_i + \varepsilon_i (t)),</code>
</p>

<p>with <code class="reqn">\varepsilon_i(t) \sim N(0, (\pi \mu_i)^2 + \sigma^2 )</code>. If no boundary is met within the maximum time, response is
set to 0. After the decision, the accumulation continues for a time period (tau), until
the final state is used for the computation of confidence.
</p>


<h3>Value</h3>

<p>Returns a <code>data.frame</code> with three columns and <code>n</code> rows. Column names are <code>rt</code> (response
time), <code>response</code> (1 or 2, indicating which accumulator hit its boundary first), and <code>conf</code> (the
value of the confidence measure; not discretized!).
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># minimal arguments
simus&lt;- rLCA(n=20, mu1=1, mu2=-0.5, th1=1, th2=0.8)
head(simus)

# specifying all relevant parameters
simus &lt;- rLCA(n=1000, mu1 = 2.5, mu2=1, th1=1.5, th2=1.6,
               k=0.1, beta=0.1, SPV=0.2, tau=0.1,
               wx=0.8, wrt=0.2, wint=0, t0=0.2, st0=0.1,
               pi=0.2, sig=1)
if (requireNamespace("ggplot2", quietly = TRUE)) {
  require(ggplot2)
  ggplot(simus, aes(x=rt, y=conf))+
    stat_density_2d(aes(fill = after_stat(density)), geom = "raster", contour = FALSE) +
    facet_wrap(~response)
}
boxplot(conf~response, data=simus)

</code></pre>

<hr>
<h2 id='simulateRM'>Simulation of confidence ratings and RTs in race confidence models</h2><span id='topic+simulateRM'></span><span id='topic+simulateIRM'></span><span id='topic+simulatePCRM'></span><span id='topic+rRM_Kiani'></span>

<h3>Description</h3>

<p>Simulates the decision responses, reaction times and state of the loosing accumulator
together with a discrete confidence judgment  in the independent and partially anti-correlated
race model (IRM and PCRM) (Hellmann et al., 2023), given specific parameter constellations.
See <a href="#topic+RaceModels">RaceModels</a> for more information about
parameters. Also computes the Gamma rank correlation between the confidence
ratings and condition (task difficulty), reaction times and accuracy in the
simulated output. Basically, this function is a wrapper for <code><a href="#topic+rIRM">rIRM</a></code>
and <code><a href="#topic+rPCRM">rPCRM</a></code> for application in confidence experiments with
manipulation of specific parameters.
<code>rRM_Kiani</code> simulates a different version of race models, presented in
Kiani et al. (2014), but without a confidence measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateRM(paramDf, n = 10000, model = "IRM", time_scaled = FALSE,
  gamma = FALSE, agg_simus = FALSE, stimulus = c(1, 2), delta = 0.01,
  maxrt = 15, seed = NULL)

rRM_Kiani(paramDf, n = 10000, time_scaled = FALSE, gamma = FALSE,
  agg_simus = FALSE, stimulus = c(1, 2), delta = 0.01, maxrt = 15,
  seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateRM_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or data frame with one row. Column names should match the names of
<a href="#topic+RaceModels">RaceModels</a> parameter names (only <code>mu1</code> and <code>mu2</code> are not used in this context but
replaced by the parameter <code>v</code>). For different stimulus quality/mean
drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,....
Different <code>s</code> parameters are possible with <code>s1</code>, <code>s2</code>, <code>s3</code>,... with equally many steps as for drift rates. Additionally, the confidence
thresholds should be given by names with <code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,....</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_n">n</code></td>
<td>
<p>integer. The number of samples (per condition and stimulus direction) generated.
Total number of samples is <code>n*nConditions*length(stimulus)</code>.</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;IRM&quot; or &quot;PCRM&quot;. (&quot;IRMt&quot; and &quot;PCRMt&quot; will also be accepted. In that case,
time_scaled is set to TRUE.)</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_time_scaled">time_scaled</code></td>
<td>
<p>logical. Whether a time_scaled transformation for the confidence measure should
be used.</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_gamma">gamma</code></td>
<td>
<p>logical. If TRUE, the gamma correlation between confidence ratings, rt and accuracy is
computed.</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_agg_simus">agg_simus</code></td>
<td>
<p>logical. Simulation is done on a trial basis with RTs outcome. If TRUE,
the simulations will be aggregated over RTs to return only the distribution of response and
confidence ratings. Default: FALSE.</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_stimulus">stimulus</code></td>
<td>
<p>numeric vector. Either 1, 2 or c(1, 2) (default).
Together with condition represents the experimental situation. In a binary decision task the presented
stimulus belongs to one of two categories. In the default setting trials with
both categories presented are simulated but one can choose to simulate only trials with the
stimulus coming from one category (each associated with positive drift in one of two accumulators).</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_delta">delta</code></td>
<td>
<p>numerical. Size of steps for the discretized simulation (see details).</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_maxrt">maxrt</code></td>
<td>
<p>numerical. Maximum reaction time to be simulated (see details). Default: 15.</p>
</td></tr>
<tr><td><code id="simulateRM_+3A_seed">seed</code></td>
<td>
<p>numerical. Seeding for non-random data generation. (Also possible outside of the function.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulation is done by simulating normal variables in discretized steps until
one process reaches the boundary. If no boundary is met within the maximum time, response is
set to 0. The output of the fitting function <code><a href="#topic+fitRTConf">fitRTConf</a></code> with the respective model
fits the argument <code>paramDf</code> for simulation. The Gamma coefficients are computed separately for
correct/incorrect responses for the correlation of confidence ratings with condition and rt
and separately for conditions for the correlation of accuracy and confidence. The resulting
data frames in the output thus have two columns. One for the grouping variable and one for the
Gamma coefficient.
</p>


<h3>Value</h3>

<p>Depending on <code>gamma</code> and <code>agg_simus</code>.
</p>
<p>If <code>gamma</code> is <code>FALSE</code>, returns a <code>data.frame</code> with columns: <code>condition</code>,
<code>stimulus</code>, <code>response</code>, <code>correct</code>, <code>rt</code>, <code>conf</code> (the continuous confidence
measure) and <code>rating</code> (the discrete confidence rating) or
(if <code>agg_simus=TRUE</code>): <code>condition</code>, <code>stimulus</code>,<code>response</code>, <code>correct</code>,
<code>rating</code> and <code>p</code> (for the probability of a response and rating, given
the condition and stimulus).
</p>
<p>If <code>gamma</code> is <code>TRUE</code>, returns a <code>list</code> with elements:
<code>simus</code> (the simulated data frame) and <code>gamma</code>, which is again a <code>list</code> with elements
<code>condition</code>, <code>rt</code> and <code>correct</code>, each a <code>tibble</code> with two columns (see details for more
information).
</p>


<h3>Note</h3>

<p>Different parameters for different conditions are only allowed for drift rate, <code>v</code>,
and process variability, <code>s</code>. All other parameters are used for all conditions.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>
<p>Kiani, R., Corthell, L., &amp; Shadlen, M.N. (2014) Choice certainty is informed
by both evidence and decision time.
Neuron, 84(6), 1329-1342. doi:10.1016/j.neuron.2014.12.015
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples for "PCRM" model (equivalent applicable for "IRM" model)
# 1. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=2,b=2, v1=0.5, v2=1, t0=0.1,st0=0,
                      wx=0.6, wint=0.2, wrt=0.2,
                      theta1=4)

# 2. Simulate trials for both stimulus categories and all conditions (2)
simus &lt;- simulateRM(paramDf, n=30,model="PCRM", time_scaled=TRUE)
head(simus)
# equivalent:
simus &lt;- simulateRM(paramDf, model="PCRMt")

  library(ggplot2)
  simus &lt;- simus[simus$response!=0,]
  simus$rating &lt;- factor(simus$rating, labels=c("unsure", "sure"))
  ggplot(simus, aes(x=rt, group=interaction(correct, rating),
                    color=as.factor(correct), linetype=rating))+
    geom_density(size=1.2)+
    facet_grid(rows=vars(condition), labeller = "label_both")


# automatically aggregate simulation distribution
# to get only accuracy x confidence rating distribution for
# all conditions
agg_simus &lt;- simulateRM(paramDf, n = 20, model="PCRMt", agg_simus = TRUE)
head(agg_simus)

  agg_simus$rating &lt;- factor(agg_simus$rating, labels=c("unsure", "sure"))
  library(ggplot2)
  ggplot(agg_simus, aes(x=rating, group=correct, fill=as.factor(correct), y=p))+
    geom_bar(stat="identity", position="dodge")+
    facet_grid(cols=vars(condition), labeller = "label_both")



  # Compute Gamma correlation coefficients between
  # confidence and other behavioral measures
  # output will be a list
  simu_list &lt;- simulateRM(paramDf, model="IRMt", gamma=TRUE)
  simu_list


</code></pre>

<hr>
<h2 id='simulateRTConf'>Simulation of confidence ratings and RTs in sequential sampling confidence models</h2><span id='topic+simulateRTConf'></span><span id='topic+rConfModel'></span><span id='topic+simulateConfModel'></span>

<h3>Description</h3>

<p>Simulates the decision responses, reaction times and confidence measure
together with a discrete confidence judgment for the sequential sampling confidence model
specified by the argument <code>model</code>, given specific parameter constellations.
This function is a wrapper that calls the respective functions for diffusion based
models (dynaViTE and 2DSD: <code><a href="#topic+simulateWEV">simulateWEV</a></code>) and race models (IRM, PCRM,
IRMt, and PCRMt: <code><a href="#topic+simulateRM">simulateRM</a></code>. It also computes the Gamma rank correlation
between the confidence ratings and
condition (task difficulty), reaction times and accuracy in the simulated output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateRTConf(paramDf, n = 10000, model = NULL, gamma = FALSE,
  agg_simus = FALSE, simult_conf = FALSE, stimulus = c(1, 2),
  delta = 0.01, maxrt = 15, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateRTConf_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or dataframe with one row with the required parameters.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_n">n</code></td>
<td>
<p>integer. The number of samples (per condition and stimulus direction) generated.
Total number of samples is <code>n*nConditions*length(stimulus)</code>.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;dynaViTE&quot;, &quot;dynWEV&quot;, &quot;2DSD&quot;, &quot;2DSDT&quot;, &quot;DDConf&quot;,
&quot;IRM&quot;, &quot;PCRM&quot;, &quot;IRMt&quot;, or &quot;PCRMt&quot;. Could also be passed as a column in the paramDf argument.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_gamma">gamma</code></td>
<td>
<p>logical. If TRUE, the gamma correlation between confidence ratings, rt and accuracy is
computed.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_agg_simus">agg_simus</code></td>
<td>
<p>logical. Simulation is done on a trial basis with RTs outcome. If TRUE,
the simulations will be aggregated over RTs to return only the distribution of response and
confidence ratings. Default: FALSE.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical. Whether in the experiment confidence was reported simultaneously
with the decision. If that is the case decision and confidence judgment are assumed to have happened
subsequent before the response. Therefore <code>tau</code> is included in the response time. If the decision was
reported before the confidence report, <code>simul_conf</code> should be <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_stimulus">stimulus</code></td>
<td>
<p>numeric vector. Either 1, 2 or c(1, 2) (default).
Together with condition represents the experimental situation. In a 2AFC task the presented
stimulus belongs to one of two categories. In the default setting trials with
both categories presented are simulated but one can choose to simulate only trials with the
stimulus coming from one category.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_delta">delta</code></td>
<td>
<p>numerical. Size of steps for the discretized simulation.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_maxrt">maxrt</code></td>
<td>
<p>numerical. Maximum reaction time to be simulated. Default: 15.</p>
</td></tr>
<tr><td><code id="simulateRTConf_+3A_seed">seed</code></td>
<td>
<p>numerical. Seeding for non-random data generation. (Also possible outside of the function.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output of the fitting function <code><a href="#topic+fitRTConf">fitRTConf</a></code> with the respective model
fits the argument <code>paramDf</code> for simulation. The function calls the respective simulation
function for diffusion based models, i.e. dynaViTE and 2DSD (<code><a href="#topic+simulateWEV">simulateWEV</a></code>) or race models,
i.e. IRM(t) and PCRM(t), (<code><a href="#topic+simulateRM">simulateRM</a></code>). See there for more information.
</p>
<p><strong>Simulation Method:</strong> The simulation is done by simulating normal variables
in discretized steps until
the processes reach the boundary. If no boundary is met within the maximum time,
response is set to 0.
</p>
<p><strong>Gamma correlations:</strong> The Gamma coefficients are computed separately for
correct/incorrect responses for the correlation of confidence ratings with condition and rt
and separately for conditions for the correlation of accuracy and confidence. The resulting
data frames in the output thus have two columns. One for the grouping variable and one for the
Gamma coefficient.
</p>


<h3>Value</h3>

<p>Depending on <code>gamma</code> and <code>agg_simus</code>.
</p>
<p>If <code>gamma</code> is <code>FALSE</code>, returns a <code>data.frame</code> with columns: <code>condition</code>,
<code>stimulus</code>, <code>response</code>, <code>correct</code>, <code>rt</code>, <code>conf</code> (the continuous confidence
measure) and <code>rating</code> (the discrete confidence rating) or
(if <code>agg_simus=TRUE</code>): <code>condition</code>, <code>stimulus</code>,<code>response</code>, <code>correct</code>,
<code>rating</code> and <code>p</code> (for the probability of a response and rating, given
the condition and stimulus).
</p>
<p>If <code>gamma</code> is <code>TRUE</code>, returns a <code>list</code> with elements:
<code>simus</code> (the simulated data frame) and <code>gamma</code>, which is again a <code>list</code> with elements
<code>condition</code>, <code>rt</code> and <code>correct</code>, each a <code>tibble</code> with two columns (see details for more
information).
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# The function is particularly useful, when having a collection
# of parameter sets for different models (e.g. output by fitRTConfModels for
# more than one model).
library(dplyr)
# 1. Generate only one parameter set but for two different models
paramDf1 &lt;- data.frame(model="dynWEV", a=1.5,v1=0.2, v2=1, t0=0.1,z=0.52,
                      sz=0.3,sv=0.4, st0=0,  tau=3, w=0.5,
                      theta1=1, svis=0.5, sigvis=0.8)
paramDf2 &lt;- data.frame(model="PCRMt", a=2,b=2, v1=0.5, v2=1, t0=0.1,st0=0,
                      wx=0.6, wint=0.2, wrt=0.2, theta1=4)
paramDf &lt;- full_join(paramDf1, paramDf2)
paramDf  # each model parameters sets hat its relevant parameters
# Split paramDf by model (maybe also other columns) and simulate data
simus &lt;- paramDf |&gt; group_by(model) |&gt;
 reframe(simulateRTConf(cbind(cur_group(), pick(everything())), n=200, simult_conf = TRUE))
head(simus)

</code></pre>

<hr>
<h2 id='simulateWEV'>Simulation of confidence ratings and RTs in dynWEV and 2DSD confidence models</h2><span id='topic+simulateWEV'></span><span id='topic+simulate2DSD'></span>

<h3>Description</h3>

<p>Simulates the decision responses and reaction times together with a
discrete confidence judgment in the dynaViTE model, the 2DSD model (Pleskac &amp; Busemeyer, 2010)
and the dynWEV model (Hellmann et al., 2023), given specific parameter constellations.
See <code><a href="#topic+dWEV">dWEV</a></code> and <code><a href="#topic+d2DSD">d2DSD</a></code> for more information about parameters.
Also computes the Gamma rank correlation between the confidence ratings and condition
(task difficulty), reaction times and accuracy in the simulated output.
Basically, this function is a wrapper for <code><a href="#topic+rWEV">rWEV</a></code> and <code><a href="#topic+r2DSD">r2DSD</a></code>
for application in confidence experiments with manipulation of specific parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateWEV(paramDf, n = 10000, model = "dynWEV", simult_conf = FALSE,
  gamma = FALSE, agg_simus = FALSE, stimulus = c(-1, 1), delta = 0.01,
  maxrt = 15, seed = NULL, process_results = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateWEV_+3A_paramdf">paramDf</code></td>
<td>
<p>a list or dataframe with one row. Column names should match the names
of <a href="#topic+dynaViTE">dynaViTE</a> and <a href="#topic+2DSD">2DSD</a> model specific parameter names. For different stimulus quality/mean
drift rates, names should be <code>v1</code>, <code>v2</code>, <code>v3</code>,....
Different <code>sv</code> and/or <code>s</code> parameters are possible with <code>sv1</code>, <code>sv2</code>, <code>sv3</code>... (<code>s1</code>, <code>s2</code>, <code>s3</code>,...
respectively) with equally many steps as for drift rates. Additionally, the confidence
thresholds should be given by names with <code>thetaUpper1</code>, <code>thetaUpper2</code>,..., <code>thetaLower1</code>,... or,
for symmetric thresholds only by <code>theta1</code>, <code>theta2</code>,....</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_n">n</code></td>
<td>
<p>integer. The number of samples (per condition and stimulus direction) generated.
Total number of samples is <code>n*nConditions*length(stimulus)</code>.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_model">model</code></td>
<td>
<p>character scalar. One of &quot;dynaViTE&quot;, &quot;dynWEV&quot;, or &quot;2DSD&quot;.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_simult_conf">simult_conf</code></td>
<td>
<p>logical. <code>TRUE</code>, if in the experiment confidence was reported simultaneously
with the decision, as then decision and confidence judgment are assumed to have happened
subsequent before response and tau is added to the simulated decision time. If <code>FALSE</code>
returned response time will only be decision time plus non-judgment time component.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_gamma">gamma</code></td>
<td>
<p>logical. If TRUE, the gamma correlation between confidence ratings, rt
and accuracy is computed.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_agg_simus">agg_simus</code></td>
<td>
<p>logical. Simulation is done on a trial basis with RTs outcome.
If TRUE, the simulations will be aggregated over RTs to return only the distribution
of response and confidence ratings. Default: FALSE.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_stimulus">stimulus</code></td>
<td>
<p>numeric vector. Either 1, -1 or c(-1, 1) (default). Together with
condition represents the experimental situation. In a binary decision task the presented
stimulus belongs to one of two categories. In the default setting trials with
both categories presented are simulated but one can choose to simulate only trials with
the stimulus coming from one category (1 for the category that is associated with positive
drift in the decision process where &quot;upper&quot;/1 responses are considered correct and -1
correspondingly for negative drifts and &quot;lower&quot;/-1 correct decisions).</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_delta">delta</code></td>
<td>
<p>numeric. Discretization steps for simulations with the stochastic process.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_maxrt">maxrt</code></td>
<td>
<p>numeric. Maximum reaction time returned.
If the simulation of the stochastic process exceeds a rt of <code>maxrt</code>,
the response will be set to 0 and <code>maxrt</code> will be returned as rt.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_seed">seed</code></td>
<td>
<p>numerical. Seeding for non-random data generation.</p>
</td></tr>
<tr><td><code id="simulateWEV_+3A_process_results">process_results</code></td>
<td>
<p>logical. Whether the output simulations should contain the final
state of the decision (and visibility) process as additional column. Default is FALSE, meaning that
no additional columns for the final process states are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simulation of response and decision times is done by simulating
normal variables in discretized steps until the lower or upper boundary
is met (or the maximal rt is reached). Afterwards, a confidence measure
is simulated according to the respective model.
</p>
<p>The confidence outputs are then binned according to the given thresholds.
The output of the fitting function <code><a href="#topic+fitRTConf">fitRTConf</a></code> with the respective model
fits the argument <code>paramDf</code> for simulation.
The Gamma coefficients are computed separately for correct/incorrect responses for the
correlation of confidence ratings with condition and rt and separately for conditions
for the correlation of accuracy and confidence. The
resulting data frames in the output thus have two columns. One for the grouping variable
and one for the Gamma coefficient.
</p>


<h3>Value</h3>

<p>Depending on <code>gamma</code> and <code>agg_simus</code>.
</p>
<p>If <code>gamma</code> is <code>FALSE</code>, returns a <code>data.frame</code> with columns: <code>condition</code>,
<code>stimulus</code>, <code>response</code>, <code>correct</code>, <code>rt</code>, <code>conf</code> (the continuous confidence
measure) and <code>rating</code> (the discrete confidence rating), and <code>dec</code> and <code>vis</code>
(only if <code>process_results=TRUE</code>) for the final states of accumulators in the
simulation or
(if <code>agg_simus=TRUE</code>): <code>condition</code>, <code>stimulus</code>,<code>response</code>, <code>correct</code>,
<code>rating</code> and <code>p</code> (for the probability of a response and rating, given
the condition and stimulus).
</p>
<p>If <code>gamma</code> is <code>TRUE</code>, returns a <code>list</code> with elements:
<code>simus</code> (the simulated data frame) and <code>gamma</code>, which is again a <code>list</code> with elements
<code>condition</code>, <code>rt</code> and <code>correct</code>, each a <code>tibble</code> with two columns (see details for more
information).
</p>


<h3>Note</h3>

<p>Different parameters for different conditions are only allowed for drift rate,
<code>v</code>, drift rate variability, <code>sv</code> and diffusion constant <code>s</code>.
All other parameters are used for all conditions.
</p>


<h3>Author(s)</h3>

<p>Sebastian Hellmann.
</p>


<h3>References</h3>

<p>Hellmann, S., Zehetleitner, M., &amp; Rausch, M. (2023). Simultaneous modeling of choice, confidence and response time in visual perception. <em>Psychological Review</em> 2023 Mar 13. doi: 10.1037/rev0000411. Epub ahead of print. PMID: 36913292.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examples for "dynWEV" model (equivalent applicable
# for "2DSD" model (with less parameters))
# 1. Define some parameter set in a data.frame
paramDf &lt;- data.frame(a=2.5,v1=0.1, v2=1, t0=0.1,z=0.55,
                      sz=0.3,sv=0.8, st0=0,  tau=3, w=0.1,
                      theta1=0.8, svis=0.5, sigvis=0.8)

# 2. Simulate trials for both stimulus categories and all conditions (2)
simus &lt;- simulateWEV(paramDf, model="dynWEV")
head(simus)

  library(ggplot2)
  simus &lt;- simus[simus$response!=0,]
  simus$rating &lt;- factor(simus$rating, labels=c("unsure", "sure"))
  ggplot(simus, aes(x=rt, group=interaction(correct, rating),
                    color=as.factor(correct), linetype=rating))+
    geom_density(size=1.2)+xlim(c(0,5))+
    facet_grid(rows=vars(condition), labeller = "label_both")


# automatically aggregate simulation distribution
# to get only accuracy x confidence rating distribution for
# all conditions
agg_simus &lt;- simulateWEV(paramDf, model="dynWEV", agg_simus = TRUE)
head(agg_simus)

  agg_simus$rating &lt;- factor(agg_simus$rating, labels=c("unsure", "sure"))
  library(ggplot2)
  ggplot(agg_simus, aes(x=rating, group=correct, fill=as.factor(correct), y=p))+
    geom_bar(stat="identity", position="dodge")+
    facet_grid(cols=vars(condition), labeller = "label_both")


  # Compute Gamma correlation coefficients between
  # confidence and other behavioral measures
  # output will be a list
  simu_list &lt;- simulateWEV(paramDf,n = 400, model="dynWEV", gamma=TRUE)
  simu_list

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
