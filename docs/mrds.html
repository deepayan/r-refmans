<!DOCTYPE html><html><head><title>Help for package mrds</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mrds}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mrds-package'><p>Mark-Recapture Distance Sampling (mrds)</p></a></li>
<li><a href='#add.df.covar.line'><p>Add covariate levels detection function plots</p></a></li>
<li><a href='#adj.check.order'><p>Check order of adjustment terms</p></a></li>
<li><a href='#AIC.ddf'><p>Akaike's An Information Criterion for detection functions</p></a></li>
<li><a href='#apex.gamma'><p>Get the apex for a gamma detection function</p></a></li>
<li><a href='#assign.default.values'><p>Assign default values to list elements that have not been already assigned</p></a></li>
<li><a href='#assign.par'><p>Extraction and assignment of parameters to vector</p></a></li>
<li><a href='#average.line'><p>Average detection function line for plotting</p></a></li>
<li><a href='#average.line.cond'><p>Average conditional detection function line for plotting</p></a></li>
<li><a href='#book.tee.data'><p>Golf tee data used in chapter 6 of Advanced Distance Sampling examples</p></a></li>
<li><a href='#calc.se.Np'><p>Find se of average p and N</p></a></li>
<li><a href='#cdf.ds'><p>Cumulative distribution function (cdf) for fitted distance sampling</p>
detection function</a></li>
<li><a href='#cds'><p>CDS function definition</p></a></li>
<li><a href='#check.bounds'><p>Check parameters bounds during optimisations</p></a></li>
<li><a href='#check.mono'><p>Check that a detection function is monotone</p></a></li>
<li><a href='#coef.ds'><p>Extract coefficients</p></a></li>
<li><a href='#compute.Nht'><p>Horvitz-Thompson estimates 1/p_i or s_i/p_i</p></a></li>
<li><a href='#covered.region.dht'><p>Covered region estimate of abundance from Horvitz-Thompson-like estimator</p></a></li>
<li><a href='#create.bins'><p>Create bins from a set of binned distances and a set of cutpoints.</p></a></li>
<li><a href='#create.command.file'><p>create.command.file</p></a></li>
<li><a href='#create.ddfobj'><p>Create detection function object</p></a></li>
<li><a href='#create.model.frame'><p>Create a model frame for ddf fitting</p></a></li>
<li><a href='#create.varstructure'><p>Creates structures needed to compute abundance and variance</p></a></li>
<li><a href='#ddf'><p>Distance Detection Function Fitting</p></a></li>
<li><a href='#ddf.ds'><p>CDS/MCDS Distance Detection Function Fitting</p></a></li>
<li><a href='#ddf.gof'><p>Goodness of fit tests for distance sampling models</p></a></li>
<li><a href='#ddf.io'><p>Mark-Recapture Distance Sampling (MRDS) IO - PI</p></a></li>
<li><a href='#ddf.io.fi'><p>Mark-Recapture Distance Sampling (MRDS) IO - FI</p></a></li>
<li><a href='#ddf.rem'><p>Mark-Recapture Distance Sampling (MRDS) Removal - PI</p></a></li>
<li><a href='#ddf.rem.fi'><p>Mark-Recapture Distance Sampling (MRDS) Removal - FI</p></a></li>
<li><a href='#ddf.trial'><p>Mark-Recapture Distance Sampling (MRDS) Trial Configuration - PI</p></a></li>
<li><a href='#ddf.trial.fi'><p>Mark-Recapture Analysis of Trial Configuration - FI</p></a></li>
<li><a href='#DeltaMethod'><p>Numeric Delta Method approximation for the variance-covariance matrix</p></a></li>
<li><a href='#det.tables'><p>Observation detection tables</p></a></li>
<li><a href='#detfct.fit'><p>Fit detection function using key-adjustment functions</p></a></li>
<li><a href='#detfct.fit.opt'><p>Fit detection function using key-adjustment functions</p></a></li>
<li><a href='#dht'><p>Density and abundance estimates and variances</p></a></li>
<li><a href='#dht.deriv'><p>Computes abundance estimates at specified parameter values using</p>
Horvitz-Thompson-like estimator</a></li>
<li><a href='#dht.se'><p>Variance and confidence intervals for density and abundance estimates</p></a></li>
<li><a href='#distpdf'><p>Detection functions</p></a></li>
<li><a href='#ds.function'><p>Distance Sampling Functions</p></a></li>
<li><a href='#flnl'><p>Log-likelihood computation for distance sampling data</p></a></li>
<li><a href='#flt.var'><p>Hessian computation for fitted distance detection function model parameters</p></a></li>
<li><a href='#g0'><p>Compute value of p(0) using a logit formulation</p></a></li>
<li><a href='#getpar'><p>Extraction and assignment of parameters to vector</p></a></li>
<li><a href='#gof.ds'><p>Compute chi-square goodness-of-fit test for ds models</p></a></li>
<li><a href='#gstdint'><p>Integral of pdf of distances</p></a></li>
<li><a href='#histline'><p>Plot histogram line</p></a></li>
<li><a href='#integratedetfct.logistic'><p>Integrate a logistic detection function</p></a></li>
<li><a href='#integratelogistic.analytic'><p>Analytically integrate logistic detection function</p></a></li>
<li><a href='#integratepdf'><p>Numerically integrate pdf of observed distances over specified ranges</p></a></li>
<li><a href='#io.glm'><p>Iterative offset GLM/GAM for fitting detection function</p></a></li>
<li><a href='#is.linear.logistic'><p>Collection of functions for logistic detection functions</p></a></li>
<li><a href='#is.logistic.constant'><p>Is a logit model constant for all observations?</p></a></li>
<li><a href='#keyfct.th1'><p>Threshold key function</p></a></li>
<li><a href='#keyfct.th2'><p>Threshold key function</p></a></li>
<li><a href='#keyfct.tpn'><p>Two-part normal key function</p></a></li>
<li><a href='#lfbcvi'><p>Black-capped vireo mark-recapture distance sampling analysis</p></a></li>
<li><a href='#lfgcwa'><p>Golden-cheeked warbler mark-recapture distance sampling analysis</p></a></li>
<li><a href='#logisticbyx'><p>Logistic as a function of covariates</p></a></li>
<li><a href='#logisticbyz'><p>Logistic as a function of distance</p></a></li>
<li><a href='#logisticdetfct'><p>Logistic detection function</p></a></li>
<li><a href='#logisticdupbyx'><p>Logistic for duplicates as a function of covariates</p></a></li>
<li><a href='#logisticdupbyx_fast'><p>Logistic for duplicates as a function of covariates (fast)</p></a></li>
<li><a href='#logit'><p>Logit function</p></a></li>
<li><a href='#logLik.ddf'><p>log-likelihood value for a fitted detection function</p></a></li>
<li><a href='#mcds'><p>MCDS function definition</p></a></li>
<li><a href='#MCDS.exe'><p>Run MCDS.exe as a backend for mrds</p></a></li>
<li><a href='#mrds_opt'><p>Tips on optimisation issues in <code>mrds</code> models</p></a></li>
<li><a href='#NCovered'><p>Compute estimated abundance in covered (sampled) region</p></a></li>
<li><a href='#nlminb_wrapper'><p>Wrapper around <code>nlminb</code></p></a></li>
<li><a href='#p.det'><p>Double-platform detection probability</p></a></li>
<li><a href='#p.dist.table'><p>Distribution of probabilities of detection</p></a></li>
<li><a href='#parse.optimx'><p>Parse optimx results and present a nice object</p></a></li>
<li><a href='#pdot.dsr.integrate.logistic'><p>Compute probability that a object was detected by at least one observer</p></a></li>
<li><a href='#plot_cond'><p>Plot conditional detection function from distance sampling model</p></a></li>
<li><a href='#plot_layout'><p>Layout for plot methods in mrds</p></a></li>
<li><a href='#plot_uncond'><p>Plot unconditional detection function from distance sampling model</p></a></li>
<li><a href='#plot.det.tables'><p>Observation detection tables</p></a></li>
<li><a href='#plot.ds'><p>Plot fit of detection functions and histograms of data from distance</p>
sampling model</a></li>
<li><a href='#plot.io'><p>Plot fit of detection functions and histograms of data from distance</p>
sampling independent observer (<code>io</code>) model</a></li>
<li><a href='#plot.io.fi'><p>Plot fit of detection functions and histograms of data from distance</p>
sampling independent observer model with full independence (<code>io.fi</code>)</a></li>
<li><a href='#plot.rem'><p>Plot fit of detection functions and histograms of data from removal distance</p>
sampling model</a></li>
<li><a href='#plot.rem.fi'><p>Plot fit of detection functions and histograms of data from removal distance</p>
sampling model</a></li>
<li><a href='#plot.trial'><p>Plot fit of detection functions and histograms of data from distance</p>
sampling trial observer model</a></li>
<li><a href='#plot.trial.fi'><p>Plot fit of detection functions and histograms of data from distance</p>
sampling trial observer model</a></li>
<li><a href='#predict.ds'><p>Predictions from <code>mrds</code> models</p></a></li>
<li><a href='#print.ddf'><p>Simple pretty printer for distance sampling analyses</p></a></li>
<li><a href='#print.ddf.gof'><p>Prints results of goodness of fit tests for detection functions</p></a></li>
<li><a href='#print.det.tables'><p>Print results of observer detection tables</p></a></li>
<li><a href='#print.dht'><p>Prints density and abundance estimates</p></a></li>
<li><a href='#print.p_dist_table'><p>Print distribution of probabilities of detection</p></a></li>
<li><a href='#print.summary.ds'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#print.summary.io'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#print.summary.io.fi'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#print.summary.rem'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#print.summary.rem.fi'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#print.summary.trial'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#print.summary.trial.fi'><p>Print summary of distance detection function model object</p></a></li>
<li><a href='#prob.deriv'><p>Derivatives for variance of average p and average p(0) variance</p></a></li>
<li><a href='#prob.se'><p>Average p and average p(0) variance</p></a></li>
<li><a href='#process.data'><p>Process data for fitting distance sampling detection function</p></a></li>
<li><a href='#pronghorn'><p>Pronghorn aerial survey data from Wyoming</p></a></li>
<li><a href='#ptdata.distance'><p>Single observer point count data example from Distance</p></a></li>
<li><a href='#ptdata.dual'><p>Simulated dual observer point count data</p></a></li>
<li><a href='#ptdata.removal'><p>Simulated removal observer point count data</p></a></li>
<li><a href='#ptdata.single'><p>Simulated single observer point count data</p></a></li>
<li><a href='#qqplot.ddf'><p>Quantile-quantile plot and goodness of fit tests for detection functions</p></a></li>
<li><a href='#rem.glm'><p>Iterative offset model fitting of mark-recapture with removal model</p></a></li>
<li><a href='#rescale_pars'><p>Calculate the parameter rescaling for parameters associated with covariates</p></a></li>
<li><a href='#sample_ddf'><p>Generate data from a fitted detection function and refit the model</p></a></li>
<li><a href='#setbounds'><p>Set parameter bounds</p></a></li>
<li><a href='#setcov'><p>Creates design matrix for covariates in detection function</p></a></li>
<li><a href='#setinitial.ds'><p>Set initial values for detection function based on distance sampling</p></a></li>
<li><a href='#sim.mix'><p>Simulation of distance sampling data via mixture models</p>
Allows one to simulate line transect distance sampling data using
a mixture of half-normal detection functions.</a></li>
<li><a href='#solvecov'><p>Invert of covariance matrices</p></a></li>
<li><a href='#stake77'><p>Wooden stake data from 1977 survey</p></a></li>
<li><a href='#stake78'><p>Wooden stake data from 1978 survey</p></a></li>
<li><a href='#summary.ds'><p>Summary of distance detection function model object</p></a></li>
<li><a href='#summary.io'><p>Summary of distance detection function model object</p></a></li>
<li><a href='#summary.io.fi'><p>Summary of distance detection function model object</p></a></li>
<li><a href='#summary.rem'><p>Summary of distance detection function model object</p></a></li>
<li><a href='#summary.rem.fi'><p>Summary of distance detection function model object</p></a></li>
<li><a href='#summary.trial'><p>Summary of distance detection function model object</p></a></li>
<li><a href='#summary.trial.fi'><p>Summary of distance detection function model object</p></a></li>
<li><a href='#survey.region.dht'><p>Extrapolate Horvitz-Thompson abundance estimates to entire surveyed region</p></a></li>
<li><a href='#test.breaks'><p>Test validity for histogram breaks(cutpoints)</p></a></li>
<li><a href='#varn'><p>Compute empirical variance of encounter rate</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Laura Marshall &lt;lhm@st-andrews.ac.uk&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Title:</td>
<td>Mark-Recapture Distance Sampling</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Author:</td>
<td>Jeff Laake &lt;jeff.laake@noaa.gov&gt;, David Borchers
    &lt;dlb@st-and.ac.uk&gt;, Len Thomas &lt;len.thomas@st-and.ac.uk&gt;, David
    Miller &lt;dave@ninepointeightone.net&gt;, Jon Bishop and Jonah McArthur</td>
</tr>
<tr>
<td>Description:</td>
<td>Animal abundance estimation via conventional, multiple covariate
    and mark-recapture distance sampling (CDS/MCDS/MRDS). Detection function
    fitting is performed via maximum likelihood. Also included are diagnostics
    and plotting for fitted detection functions. Abundance estimation is via a
    Horvitz-Thompson-like estimator.</td>
</tr>
<tr>
<td>Version:</td>
<td>2.3.0</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/DistanceDevelopment/mrds/">https://github.com/DistanceDevelopment/mrds/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/DistanceDevelopment/mrds/issues">https://github.com/DistanceDevelopment/mrds/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>optimx (&ge; 2013.8.6), mgcv, methods, numDeriv, Rsolnp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, covr, knitr, rmarkdown, bookdown</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-18 00:14:29 UTC; lhm</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-18 08:50:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='mrds-package'>Mark-Recapture Distance Sampling (mrds)</h2><span id='topic+mrds-package'></span><span id='topic+mrds'></span>

<h3>Description</h3>

<p>This package implements mark-recapture distance sampling
methods as described in D.L. Borchers, W. Zucchini and Fewster,
R.M. (1988), &quot;Mark-recapture models for line transect surveys&quot;,
Biometrics 54: 1207-1220. and Laake, J.L. (1999) &quot;Distance sampling
with independent observers: Reducing bias from heterogeneity by
weakening the conditional independence assumption.&quot; in Amstrup,
G.W., Garner, S.C., Laake, J.L., Manly, B.F.J., McDonald, L.L. and
Robertson, D.G. (eds) &quot;Marine mammal survey and assessment
methods&quot;, Balkema, Rotterdam: 137-148 and Borchers, D.L., Laake,
J.L., Southwell, C. and Paxton, C.L.G. &quot;Accommodating unmodelled
heterogeneity in double-observer distance sampling surveys&quot;. 2006.
Biometrics 62:372-378.)
</p>


<h3>Details</h3>

<p>Examples of distance sampling analyses are available at
<a href="http://examples.distancesampling.org/">http://examples.distancesampling.org/</a>.
</p>
<p>For help with distance sampling and this package, there is a Google Group
<a href="https://groups.google.com/forum/#!forum/distance-sampling">https://groups.google.com/forum/#!forum/distance-sampling</a>.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake &lt;jeff.laake@noaa.gov&gt;,
David Borchers &lt;dlb@mcs.st-and.ac.uk&gt;,
Len Thomas &lt;len@mcs.st-and.ac.uk&gt;,
David L. Miller &lt;dave@ninepointeightone.net&gt;,
Jon Bishop &lt;jonb@mcs.st-and.ac.uk&gt;
</p>

<hr>
<h2 id='add.df.covar.line'>Add covariate levels detection function plots</h2><span id='topic+add.df.covar.line'></span><span id='topic+add_df_covar_line'></span>

<h3>Description</h3>

<p>Add a line or lines to a plot of the detection function which correspond to
a a given covariate combination. These can be particularly useful when there
is a small number of factor levels or if quantiles of a continuous covariate
are specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add.df.covar.line(ddf, data, ndist = 250, pdf = FALSE, breaks = "Sturges", ...)

add_df_covar_line(ddf, data, ndist = 250, pdf = FALSE, breaks = "Sturges", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add.df.covar.line_+3A_ddf">ddf</code></td>
<td>
<p>a fitted detection function object.</p>
</td></tr>
<tr><td><code id="add.df.covar.line_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> with the covariate combination you want to
plot.</p>
</td></tr>
<tr><td><code id="add.df.covar.line_+3A_ndist">ndist</code></td>
<td>
<p>number of distances at which to evaluate the detection function.</p>
</td></tr>
<tr><td><code id="add.df.covar.line_+3A_pdf">pdf</code></td>
<td>
<p>should the line be drawn on the probability density scale;
ignored for line transects.</p>
</td></tr>
<tr><td><code id="add.df.covar.line_+3A_breaks">breaks</code></td>
<td>
<p>required to ensure that PDF lines are the right size, should
match what is supplied to original <code>plot</code> command. Defaults to
&quot;Sturges&quot; breaks, as in <code><a href="graphics.html#topic+hist">hist</a></code>. Only used if <code>pdf=TRUE</code>.</p>
</td></tr>
<tr><td><code id="add.df.covar.line_+3A_...">...</code></td>
<td>
<p>extra arguments to give to <code><a href="stats.html#topic+line">line</a></code> (<code>lty</code>,
<code>lwd</code>, <code>col</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All covariates must be specified in <code>data</code>. Plots can become quite busy
when this approach is used. It may be useful to fix some covariates at their
median level and plot set values of a covariate of interest. For example
setting weather (e.g., Beaufort) to its median and plotting levels of
observer, then creating a second plot for a fixed observer with levels of
weather.
</p>
<p>Arguments to <code><a href="graphics.html#topic+lines">lines</a></code> are supplied in ... and aesthetics like
line type (<code>lty</code>), line width (<code>lwd</code>) and colour (<code>col</code>) are
recycled. By default <code>lty</code> is used to distinguish between the lines. It
may be useful to add a <code><a href="graphics.html#topic+legend">legend</a></code> to the plot (lines are plotted
in the order of <code>data</code>).
</p>


<h3>Value</h3>

<p>invisibly, the values of detectability over the truncation range.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# fit an example model
data(book.tee.data)
egdata &lt;- book.tee.data$book.tee.dataframe
result &lt;- ddf(dsmodel = ~mcds(key = "hn", formula = ~sex),
              data = egdata[egdata$observer==1, ], method = "ds",
              meta.data = list(width = 4))

# make a base plot, showpoints=FALSE makes the plot less busy
plot(result, showpoints=FALSE)

# add lines for sex one at a time
add.df.covar.line(result, data.frame(sex=0), lty=2)
add.df.covar.line(result, data.frame(sex=1), lty=3)

# add a legend
legend(3, 1, c("Average", "sex==0", "sex==1"), lty=1:3)

# alternatively we can add both at once
# fixing line type and varying colour
plot(result, showpoints=FALSE)
add.df.covar.line(result, data.frame(sex=c(0,1)), lty=1,
                  col=c("red", "green"))
# add a legend
legend(3, 1, c("Average", "sex==0", "sex==1"), lty=1,
       col=c("black", "red", "green"))

## End(Not run)
</code></pre>

<hr>
<h2 id='adj.check.order'>Check order of adjustment terms</h2><span id='topic+adj.check.order'></span>

<h3>Description</h3>

<p>'adj.check.order' checks that the Cosine, Hermite or simple polynomials are
of the correct order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adj.check.order(adj.series, adj.order, key)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adj.check.order_+3A_adj.series">adj.series</code></td>
<td>
<p>Adjustment series used
('<code>cos</code>','<code>herm</code>','<code>poly</code>')</p>
</td></tr>
<tr><td><code id="adj.check.order_+3A_adj.order">adj.order</code></td>
<td>
<p>Integer to check</p>
</td></tr>
<tr><td><code id="adj.check.order_+3A_key">key</code></td>
<td>
<p>key function to be used with this adjustment series</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only even functions are allowed as adjustment terms, per p.47 of Buckland et
al (2001). If incorrect terms are supplied then an error is throw via
<code>stop</code>.
</p>


<h3>Value</h3>

<p>Nothing! Just calls <code>stop</code> if something goes wrong.
</p>


<h3>Author(s)</h3>

<p>David Miller
</p>


<h3>References</h3>

<p>S.T.Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake. 1993.
Robust Models. In: Distance Sampling, eds. S.T.Buckland, D.R.Anderson,
K.P. Burnham, J.L. Laake. Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjfct.cos">adjfct.cos</a></code>, <code><a href="#topic+adjfct.poly">adjfct.poly</a></code>,
<code><a href="#topic+adjfct.herm">adjfct.herm</a></code>, <code><a href="#topic+detfct">detfct</a></code>, <code><a href="#topic+mcds">mcds</a></code>,
<code><a href="#topic+cds">cds</a></code>
</p>

<hr>
<h2 id='AIC.ddf'>Akaike's An Information Criterion for detection functions</h2><span id='topic+AIC.ddf'></span><span id='topic+AIC.ds'></span><span id='topic+AIC.io'></span><span id='topic+AIC.io.fi'></span><span id='topic+AIC.rem'></span><span id='topic+AIC.rem.fi'></span><span id='topic+AIC.trial'></span><span id='topic+AIC.trial.fi'></span>

<h3>Description</h3>

<p>Extract the AIC from a fitted detection function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ddf'
AIC(object, ..., k = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AIC.ddf_+3A_object">object</code></td>
<td>
<p>a fitted detection function object</p>
</td></tr>
<tr><td><code id="AIC.ddf_+3A_...">...</code></td>
<td>
<p>optionally more fitted model objects.</p>
</td></tr>
<tr><td><code id="AIC.ddf_+3A_k">k</code></td>
<td>
<p>penalty per parameter to be used; the default <code>k = 2</code> is the
&quot;classical&quot; AIC</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='apex.gamma'>Get the apex for a gamma detection function</h2><span id='topic+apex.gamma'></span>

<h3>Description</h3>

<p>Get the apex for a gamma detection function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apex.gamma(ddfobj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apex.gamma_+3A_ddfobj">ddfobj</code></td>
<td>
<p>ddf object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the distance at which the gamma peaks
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='assign.default.values'>Assign default values to list elements that have not been already assigned</h2><span id='topic+assign.default.values'></span>

<h3>Description</h3>

<p>Assigns default values for <code>argument</code> in list <code>x</code> from
<code>argument=value</code> pairs in ... if <code>x$argument</code> doesn't already
exist
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assign.default.values(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assign.default.values_+3A_x">x</code></td>
<td>
<p>generic list</p>
</td></tr>
<tr><td><code id="assign.default.values_+3A_...">...</code></td>
<td>
<p>unspecified list of argument=value pairs that are used to
assign values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>x - list with filled values
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='assign.par'>Extraction and assignment of parameters to vector</h2><span id='topic+assign.par'></span>

<h3>Description</h3>

<p>Assigns parameters of a particular type (scale, shape, adjustments or g0
(p(0))) from the vector of parameters in <code>ddfobj</code>. All of the
parameters are kept in a single vector for optimization even though they
have very different uses. <code>assign.par</code> parses them from the vector
based on a known structure and assigns them into <code>ddfobj</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assign.par(ddfobj, fpar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assign.par_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance sampling object (see <code><a href="#topic+create.ddfobj">create.ddfobj</a></code>)</p>
</td></tr>
<tr><td><code id="assign.par_+3A_fpar">fpar</code></td>
<td>
<p>parameter vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>getpar</code> extracts the requested types from <code>ddfobj</code>.
</p>


<h3>Value</h3>

<p>if <code>index==FALSE</code>, vector of parameters that were requested or
<code>index==TRUE</code>, vector of 3 indices for scale, shape, adjustment
</p>


<h3>Note</h3>

<p>Internal functions not intended to be called by user.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p>getpar
</p>

<hr>
<h2 id='average.line'>Average detection function line for plotting</h2><span id='topic+average.line'></span>

<h3>Description</h3>

<p>For models with covariates the detection probability for each observation
can vary. This function computes an average value for a set of distances to
plot an average line to graphically represent the fitted model in plots that
compare histograms and the scatter of individual estimated detection
probabilities. Averages are calculated over the observed covariate
combinations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>average.line(finebr, obs, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="average.line_+3A_finebr">finebr</code></td>
<td>
<p>set of fine breaks in distance over which detection function
values are averaged and plotted</p>
</td></tr>
<tr><td><code id="average.line_+3A_obs">obs</code></td>
<td>
<p>value of observer for averaging (1-2 individual observers; 3
duplicates; 4 pooled observation team)</p>
</td></tr>
<tr><td><code id="average.line_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with 2 elements
</p>

<table>
<tr>
 <td style="text-align: left;"><code>xgrid</code> </td><td style="text-align: left;"> vector of gridded distance values</td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>values</code> </td><td style="text-align: left;"> vector of average detection function values at
       the <code>xgrid</code> values</td>
</tr>

</table>



<h3>Note</h3>

<p>Internal function called from plot functions for ddf objects
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='average.line.cond'>Average conditional detection function line for plotting</h2><span id='topic+average.line.cond'></span>

<h3>Description</h3>

<p>For models with covariates the detection probability for each observation
can vary.  This function computes an average value for a set of distances to
plot an average line to graphically represent the fitted model in plots that
compare histograms and the scatter of individual estimated detection
probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>average.line.cond(finebr, obs, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="average.line.cond_+3A_finebr">finebr</code></td>
<td>
<p>set of fine breaks in distance over which detection function
values are averaged and plotted</p>
</td></tr>
<tr><td><code id="average.line.cond_+3A_obs">obs</code></td>
<td>
<p>value of observer for averaging (1-2 individual observers)</p>
</td></tr>
<tr><td><code id="average.line.cond_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with 2 elements:
</p>

<table>
<tr>
 <td style="text-align: left;"><code>xgrid</code> </td><td style="text-align: left;"> vector of gridded distance values </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>values</code> </td><td style="text-align: left;"> vector of average detection function values at
   the <code>xgrid</code> values</td>
</tr>

</table>



<h3>Note</h3>

<p>Internal function called from plot functions for <code>ddf</code> objects
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='book.tee.data'>Golf tee data used in chapter 6 of Advanced Distance Sampling examples</h2><span id='topic+book.tee.data'></span>

<h3>Description</h3>

<p>Double platform data collected in a line transect survey of golf tees by 2
observers at St. Andrews. Field sex was actually colour of the golf tee: 0 -
green; 1 - yellow. Exposure was either low (0) or high(1) depending on
height of tee above the ground. size was the number of tees in an observed
cluster.
</p>


<h3>Format</h3>

<p>A list of 4 dataframes, with the list elements named: book.tee.dataframe,
book.tee.region, book.tee.samples and book.tee.obs. 
</p>
<p><strong>book.tee.dataframe</strong> is the distance sampling data 
dataframe. Used in the call to fit the detection function in <code>ddf</code>.
Contains the following columns:
</p>

<dl>
<dt>object</dt><dd><p>numeric object id</p>
</dd><dt>observer</dt><dd><p>factor representing observer
1 or 2</p>
</dd><dt>detected</dt><dd><p>numeric 1 if the animal was detected 0 otherwise</p>
</dd>
<dt>distance</dt><dd><p>numeric value for the distance the animal was detected</p>
</dd>
<dt>size</dt><dd><p>numeric value for the group size</p>
</dd><dt>sex</dt><dd><p>numeric value for
sex of animal</p>
</dd><dt>exposure</dt><dd><p>numeric value for exposure level 0 or 1</p>
</dd></dl>

<p><strong>book.tee.region</strong>: is the region table dataframe. Used to
supply the strata areas to the <code>dht</code> function. Contains the following
columns:
</p>

<dl>
<dt>Region.Label</dt><dd><p>factor giving the strata labels</p>
</dd>
<dt>Area</dt><dd><p>numeric value giving the strata areas</p>
</dd></dl>

<p><strong>book.tee.samples</strong> is the samples table dataframe to match 
the transect ids to the region ids and supply the effort. Used in the 
<code>dht</code> function. Contains the following columns:
</p>

<dl>
<dt>Sample.Label</dt><dd><p>numeric giving the sample / transect labels</p>
</dd>
<dt>Region.Label</dt><dd><p>factor giving the strata labels</p>
</dd>
<dt>Effort</dt><dd><p>numeric value giving the sample / transect lengths</p>
</dd></dl>

<p><strong>book.tee.obs</strong> is the observations table dataframe to match
the object ids in the distance data to the transect labels. Used in the 
<code>dht</code> function. Contains the following columns:
</p>

<dl>
<dt>object</dt><dd><p>numeric value object id</p>
</dd>
<dt>Region.Label</dt><dd><p>factor giving the strata labels</p>
</dd>
<dt>Sample.Label</dt><dd><p>numeric giving the sample / transect labels</p>
</dd></dl>


<hr>
<h2 id='calc.se.Np'>Find se of average p and N</h2><span id='topic+calc.se.Np'></span>

<h3>Description</h3>

<p>Find se of average p and N
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.se.Np(model, avgp, n, average.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.se.Np_+3A_model">model</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="calc.se.Np_+3A_avgp">avgp</code></td>
<td>
<p>average p function</p>
</td></tr>
<tr><td><code id="calc.se.Np_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="calc.se.Np_+3A_average.p">average.p</code></td>
<td>
<p>the average probability of detection for the model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='cdf.ds'>Cumulative distribution function (cdf) for fitted distance sampling
detection function</h2><span id='topic+cdf.ds'></span>

<h3>Description</h3>

<p>Computes cdf values of observed distances from fitted distribution. For a
set of observed x it returns the integral of f(x) for the range= (inner, x),
where inner is the innermost distance which is observable (either 0 or left
if left truncated).  In terms of g(x) this is the integral of g(x) over
range divided by the integral of g(x) over the entire range of the data
(inner, W).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdf.ds(model, newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdf.ds_+3A_model">model</code></td>
<td>
<p>fitted distance sampling model</p>
</td></tr>
<tr><td><code id="cdf.ds_+3A_newdata">newdata</code></td>
<td>
<p>new data values if computed for values other than the
original observations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of cdf values for each observation
</p>


<h3>Note</h3>

<p>This is an internal function that is not intended to be invoked
directly.  It is called by <code><a href="#topic+qqplot.ddf">qqplot.ddf</a></code> to compute values for
Kolmogorov-Smirnov and Cramer-von Mises tests and the Q-Q plot.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qqplot.ddf">qqplot.ddf</a></code>
</p>

<hr>
<h2 id='cds'>CDS function definition</h2><span id='topic+cds'></span>

<h3>Description</h3>

<p>Creates model formula list for conventional distance sampling using values
supplied in call to <code><a href="#topic+ddf">ddf</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cds(
  key = NULL,
  adj.series = NULL,
  adj.order = NULL,
  adj.scale = "width",
  adj.exp = FALSE,
  formula = ~1,
  shape.formula = ~1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cds_+3A_key">key</code></td>
<td>
<p>string identifying key function (currently either &quot;hn&quot;
(half-normal),&quot;hr&quot; (hazard-rate), &quot;unif&quot; (uniform) or &quot;gamma&quot; (gamma
distribution)</p>
</td></tr>
<tr><td><code id="cds_+3A_adj.series">adj.series</code></td>
<td>
<p>string identifying adjustment functions cos (Cosine), herm
(Hermite polynomials), poly (simple polynomials) or NULL</p>
</td></tr>
<tr><td><code id="cds_+3A_adj.order">adj.order</code></td>
<td>
<p>vector of order of adjustment terms to include</p>
</td></tr>
<tr><td><code id="cds_+3A_adj.scale">adj.scale</code></td>
<td>
<p>whether to scale the adjustment terms by &quot;width&quot; or &quot;scale&quot;</p>
</td></tr>
<tr><td><code id="cds_+3A_adj.exp">adj.exp</code></td>
<td>
<p>if TRUE uses exp(adj) for adjustment to keep f(x)&gt;0</p>
</td></tr>
<tr><td><code id="cds_+3A_formula">formula</code></td>
<td>
<p>formula for scale function (included for completeness only
only formula=~1 for cds)</p>
</td></tr>
<tr><td><code id="cds_+3A_shape.formula">shape.formula</code></td>
<td>
<p>formula for shape function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A formula list used to define the detection function model
</p>
<table>
<tr><td><code>fct</code></td>
<td>
<p>string &quot;cds&quot;</p>
</td></tr> <tr><td><code>key</code></td>
<td>
<p>key function string</p>
</td></tr>
<tr><td><code>adj.series</code></td>
<td>
<p>adjustment function string</p>
</td></tr> <tr><td><code>adj.order</code></td>
<td>
<p>adjustment
function orders</p>
</td></tr> <tr><td><code>adj.scale</code></td>
<td>
<p>adjustment function scale type</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula for scale function</p>
</td></tr> <tr><td><code>shape.formula</code></td>
<td>
<p>formula
for shape function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake; Dave Miller
</p>

<hr>
<h2 id='check.bounds'>Check parameters bounds during optimisations</h2><span id='topic+check.bounds'></span>

<h3>Description</h3>

<p>Simple internal function to check that the optimisation didn't hit bounds.
Based on code that used to live in <code>detfct.fit.opt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.bounds(lt, lowerbounds, upperbounds, ddfobj, showit, setlower, setupper)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.bounds_+3A_lt">lt</code></td>
<td>
<p>optimisation object</p>
</td></tr>
<tr><td><code id="check.bounds_+3A_lowerbounds">lowerbounds</code></td>
<td>
<p>current lower bounds</p>
</td></tr>
<tr><td><code id="check.bounds_+3A_upperbounds">upperbounds</code></td>
<td>
<p>current upper bounds</p>
</td></tr>
<tr><td><code id="check.bounds_+3A_ddfobj">ddfobj</code></td>
<td>
<p>ddf object</p>
</td></tr>
<tr><td><code id="check.bounds_+3A_showit">showit</code></td>
<td>
<p>debug level</p>
</td></tr>
<tr><td><code id="check.bounds_+3A_setlower">setlower</code></td>
<td>
<p>were lower bounds set by the user</p>
</td></tr>
<tr><td><code id="check.bounds_+3A_setupper">setupper</code></td>
<td>
<p>were upper bounds set by the user</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> if parameters are close to the bound, else <code>FALSE</code>
</p>


<h3>Author(s)</h3>

<p>Dave Miller; Jeff Laake
</p>

<hr>
<h2 id='check.mono'>Check that a detection function is monotone</h2><span id='topic+check.mono'></span>

<h3>Description</h3>

<p>Check that a fitted detection function is monotone non-increasing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.mono(
  df,
  strict = TRUE,
  n.pts = 100,
  tolerance = 1e-06,
  plot = FALSE,
  max.plots = 6
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.mono_+3A_df">df</code></td>
<td>
<p>a fitted detection function object</p>
</td></tr>
<tr><td><code id="check.mono_+3A_strict">strict</code></td>
<td>
<p>if <code>TRUE</code> (default) the detection function must be
&quot;strictly&quot; monotone, that is that (<code>g(x[i])&lt;=g(x[i-1])</code>) over the whole
range (left to right truncation points).</p>
</td></tr>
<tr><td><code id="check.mono_+3A_n.pts">n.pts</code></td>
<td>
<p>number of equally-spaced points between left and right
truncation at which to evaluate the detection function (default 100)</p>
</td></tr>
<tr><td><code id="check.mono_+3A_tolerance">tolerance</code></td>
<td>
<p>numerical tolerance for monotonicity checks (default 1e-6)</p>
</td></tr>
<tr><td><code id="check.mono_+3A_plot">plot</code></td>
<td>
<p>plot a diagnostic highlighting the non-monotonic areas (default
<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="check.mono_+3A_max.plots">max.plots</code></td>
<td>
<p>when <code>plot=TRUE</code>, what is the maximum number of plots
of non-monotone covariate combinations that should be plotted? Plotted
combinations are a random sample of the non-monotonic subset of evaluations.
No effect for non-covariate models.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Evaluates a series of points over the range of the detection function (left
to right truncation) then determines:
</p>
<p>1. If the detection function is always less than or equal to its value at
the left truncation (<code>g(x)&lt;=g(left)</code>, or usually <code>g(x)&lt;=g(0)</code>).
2. (Optionally) The detection function is always monotone decreasing
(<code>g(x[i])&lt;=g(x[i-1])</code>). This check is only performed when
<code>strict=TRUE</code> (the default).
3. The detection function is never less than 0 (<code>g(x)&gt;=0</code>).
4. The detection function is never greater than 1 (<code>g(x)&lt;=1</code>).
</p>
<p>For models with covariates in the scale parameter of the detection function is evaluated at all observed covariate combinations.
</p>
<p>Currently covariates in the shape parameter are not supported.
</p>


<h3>Value</h3>

<p><code>TRUE</code> if the detection function is monotone, <code>FALSE</code> if
it's not. <code>warning</code>s are issued to warn the user that the function is
non-monotonic.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='coef.ds'>Extract coefficients</h2><span id='topic+coef.ds'></span><span id='topic+coefficients'></span><span id='topic+coef.io'></span><span id='topic+coef.io.fi'></span><span id='topic+coef.trial'></span><span id='topic+coef.trial.fi'></span><span id='topic+coef.rem'></span><span id='topic+coef.rem.fi'></span>

<h3>Description</h3>

<p>Extract coefficients and provide a summary of parameters and estimates
from the output of <code><a href="#topic+ddf">ddf</a></code> model objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds'
coef(object,...)
       ## S3 method for class 'io'
coef(object,...)
       ## S3 method for class 'io.fi'
coef(object,...)
       ## S3 method for class 'trial'
coef(object,...)
       ## S3 method for class 'trial.fi'
coef(object,...)
       ## S3 method for class 'rem'
coef(object,...)
       ## S3 method for class 'rem.fi'
coef(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.ds_+3A_object">object</code></td>
<td>
<p>ddf model object of class <code>ds</code>, <code>io</code>, <code>io.fi</code>,
<code>trial</code>, <code>trial.fi</code>, <code>rem</code>, or <code>rem.fi</code>.</p>
</td></tr>
<tr><td><code id="coef.ds_+3A_...">...</code></td>
<td>
<p>unspecified arguments that are unused at present</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>coef.ds</code> List of data frames for coefficients (scale and exponent
(if hazard)) </p>
<table>
<tr><td><code>scale</code></td>
<td>
<p>dataframe of scale coefficient estimates and
standard errors</p>
</td></tr> <tr><td><code>exponent</code></td>
<td>
<p>dataframe with exponent estimate and
standard error if hazard detection function</p>
</td></tr>
</table>
<p>For all others Data frame containing each coefficient and standard error
</p>


<h3>Note</h3>

<p>These functions are called by the generic function <code>coef</code> for any
<code>ddf</code> model object.  It can be called directly by the user, but it is
typically safest to use <code>coef</code> which calls the appropriate function
based on the type of model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='compute.Nht'>Horvitz-Thompson estimates 1/p_i or s_i/p_i</h2><span id='topic+compute.Nht'></span>

<h3>Description</h3>

<p>Compute individual components of Horvitz-Thompson abundance estimate in
covered region for a particular subset of the data depending on value of
group = TRUE (do group abundance); FALSE(do individual abundance)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.Nht(pdot, group = TRUE, size = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute.Nht_+3A_pdot">pdot</code></td>
<td>
<p>vector of estimated detection probabilities</p>
</td></tr>
<tr><td><code id="compute.Nht_+3A_group">group</code></td>
<td>
<p>if TRUE (do group abundance); FALSE(do individual abundance)</p>
</td></tr>
<tr><td><code id="compute.Nht_+3A_size">size</code></td>
<td>
<p>vector of group size values for clustered populations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of H-T components for abundance estimate
</p>


<h3>Note</h3>

<p>Internal function called by <code><a href="#topic+covered.region.dht">covered.region.dht</a></code>
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='covered.region.dht'>Covered region estimate of abundance from Horvitz-Thompson-like estimator</h2><span id='topic+covered.region.dht'></span>

<h3>Description</h3>

<p>Computes H-T abundance within covered region by sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covered.region.dht(obs, samples, group)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covered.region.dht_+3A_obs">obs</code></td>
<td>
<p>observations table</p>
</td></tr>
<tr><td><code id="covered.region.dht_+3A_samples">samples</code></td>
<td>
<p>samples table</p>
</td></tr>
<tr><td><code id="covered.region.dht_+3A_group">group</code></td>
<td>
<p>if TRUE compute abundance of group otherwise abundance of
individuals</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nhat.by.sample - dataframe of abundance by sample
</p>


<h3>Note</h3>

<p>Internal function called by <code><a href="#topic+dht">dht</a></code> and related functions
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='create.bins'>Create bins from a set of binned distances and a set of cutpoints.</h2><span id='topic+create.bins'></span>

<h3>Description</h3>

<p>This is an internal routine and shouldn't be necessary in normal analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.bins(data, cutpoints)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.bins_+3A_data">data</code></td>
<td>
<p>'data.frame' with at least the column 'distance'.</p>
</td></tr>
<tr><td><code id="create.bins_+3A_cutpoints">cutpoints</code></td>
<td>
<p>vector of cutpoints for the bins</p>
</td></tr>
</table>


<h3>Value</h3>

<p>argument 'data' with two extra columns 'distbegin' and
'distend'.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='create.command.file'>create.command.file</h2><span id='topic+create.command.file'></span>

<h3>Description</h3>

<p>create.command.file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.command.file(dsmodel = call(), data, method, meta.data, control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.command.file_+3A_dsmodel">dsmodel</code></td>
<td>
<p>distance sampling model specification</p>
</td></tr>
<tr><td><code id="create.command.file_+3A_data">data</code></td>
<td>
<p>dataframe containing data to be analyzed</p>
</td></tr>
<tr><td><code id="create.command.file_+3A_method">method</code></td>
<td>
<p>analysis method</p>
</td></tr>
<tr><td><code id="create.command.file_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="create.command.file_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jonah McArthur
</p>

<hr>
<h2 id='create.ddfobj'>Create detection function object</h2><span id='topic+create.ddfobj'></span>

<h3>Description</h3>

<p>Creates and populates a specific list structure to define a detection
function object and its data. The <code>ddfobj</code> is used throughout the
package as a calling argument to various functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.ddfobj(model, xmat, meta.data, initial)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.ddfobj_+3A_model">model</code></td>
<td>
<p>model list with key function and possibly adjustment functions,
scale formula, and shape formula</p>
</td></tr>
<tr><td><code id="create.ddfobj_+3A_xmat">xmat</code></td>
<td>
<p>model data frame</p>
</td></tr>
<tr><td><code id="create.ddfobj_+3A_meta.data">meta.data</code></td>
<td>
<p>list of options describing data like width, etc</p>
</td></tr>
<tr><td><code id="create.ddfobj_+3A_initial">initial</code></td>
<td>
<p>named list of initial values for parameters of the detection
function (should have at least <code>"scale"</code>, maybe also have
<code>"shape"</code> and <code>"adjustments"</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Distance sampling function object list with elements that all can be
null except type: </p>
<table>
<tr><td><code>type</code></td>
<td>
<p>type of detection function
hn, hr, gamma, unif, logistic</p>
</td></tr> <tr><td><code>xmat</code></td>
<td>
<p>model data frame</p>
</td></tr>
<tr><td><code>intercept.only</code></td>
<td>
<p>TRUE if scale = ~1 and any shape formula =~1</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>sublist with elements (can be NULL i.e., unif key):formula,
parameters, design matrix (dm)</p>
</td></tr> <tr><td><code>shape</code></td>
<td>
<p>sublist with elements (power
of hazard rate or gamma) (can be NULL i.e., unif or hn key):formula,
parameters, design matrix (dm)</p>
</td></tr> <tr><td><code>adjustment</code></td>
<td>
<p>sublist with elements
(is NULL if no adjustments used):series,order,scale,parameters</p>
</td></tr>
<tr><td><code>g0</code></td>
<td>
<p>sublist with elements (not used at present):formula,parameters,
design matrix(dm), link</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Internal function not meant to be called by user
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+detfct">detfct</a></code>, <code><a href="#topic+ddf">ddf</a></code>
</p>

<hr>
<h2 id='create.model.frame'>Create a model frame for ddf fitting</h2><span id='topic+create.model.frame'></span>

<h3>Description</h3>

<p>Creates a model.frame for distance detection function fitting. It includes
some pre-specified and computed variables with those included in the model
specified by user (formula)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.model.frame(xmat, scale.formula, meta.data, shape.formula = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.model.frame_+3A_xmat">xmat</code></td>
<td>
<p>dataframe for ddf</p>
</td></tr>
<tr><td><code id="create.model.frame_+3A_scale.formula">scale.formula</code></td>
<td>
<p>user specified formula for scale of distance detection
function</p>
</td></tr>
<tr><td><code id="create.model.frame_+3A_meta.data">meta.data</code></td>
<td>
<p>user-specified meta.data (see <code><a href="#topic+ddf">ddf</a></code></p>
</td></tr>
<tr><td><code id="create.model.frame_+3A_shape.formula">shape.formula</code></td>
<td>
<p>user specified formula for shape parameter of distance
detection function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following fields are always included: detected, observer, binned, and
optionally distance (unless null), timesdetected (if present in data). If
the distance data were binned, include distbegin and distend point fields.
If the integration width varies also include int.begin and int.end and
include an offset field for an iterative glm, if used.  Beyond these fields
only fields used in the model formula are included.
</p>


<h3>Value</h3>

<p>model frame for analysis
</p>


<h3>Note</h3>

<p>Internal function and not called by user
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='create.varstructure'>Creates structures needed to compute abundance and variance</h2><span id='topic+create.varstructure'></span>

<h3>Description</h3>

<p>Creates samples and obs dataframes used to compute abundance and its
variance based on a structure of geographic regions and samples within each
region.  The intent is to generalize this routine to work with other
sampling structures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.varstructure(model, region, sample, obs, dht.se)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.varstructure_+3A_model">model</code></td>
<td>
<p>fitted ddf object</p>
</td></tr>
<tr><td><code id="create.varstructure_+3A_region">region</code></td>
<td>
<p>region table</p>
</td></tr>
<tr><td><code id="create.varstructure_+3A_sample">sample</code></td>
<td>
<p>sample table</p>
</td></tr>
<tr><td><code id="create.varstructure_+3A_obs">obs</code></td>
<td>
<p>table of object #'s and links to sample and region table</p>
</td></tr>
<tr><td><code id="create.varstructure_+3A_dht.se">dht.se</code></td>
<td>
<p>is uncertainty going to be calculated later?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function performs the following tasks: 1)tests to make sure that region
labels are unique, 2) merges sample and region tables into a samples table
and issue a warning if not all samples were used, 3) if some regions have no
samples or if some values of Area were not valid areas given then issue
error and stop, then an error is given and the code stops, 4) creates a
unique region/sample label in samples and in obs, 5) merges observations
with sample and issues a warning if not all observations were used, 6) sorts
regions by its label and merges the values with the predictions from the
fitted model based on the object number and limits it to the data that is
appropriate for the fitted detection function.
</p>


<h3>Value</h3>

<p>List with 2 elements: </p>
<table>
<tr><td><code>samples</code></td>
<td>
<p>merged dataframe containing
region and sample info - one record per sample</p>
</td></tr> <tr><td><code>obs</code></td>
<td>
<p>merged
observation data and links to region and samples</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Internal function called by <code><a href="#topic+dht">dht</a></code>
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='ddf'>Distance Detection Function Fitting</h2><span id='topic+ddf'></span>

<h3>Description</h3>

<p>Generic function for fitting detection functions for distance sampling with
single and double observer configurations. Independent observer, trial and
dependent observer (removal) configurations are included. This is a generic
function which does little other than to validate the calling arguments and
methods and then calls the appropriate <code>method</code> specific function to do
the analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddf(
  dsmodel = call(),
  mrmodel = call(),
  data,
  method = "ds",
  meta.data = list(),
  control = list(),
  call = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf_+3A_dsmodel">dsmodel</code></td>
<td>
<p>distance sampling model specification</p>
</td></tr>
<tr><td><code id="ddf_+3A_mrmodel">mrmodel</code></td>
<td>
<p>mark-recapture model specification</p>
</td></tr>
<tr><td><code id="ddf_+3A_data">data</code></td>
<td>
<p>dataframe containing data to be analyzed</p>
</td></tr>
<tr><td><code id="ddf_+3A_method">method</code></td>
<td>
<p>analysis method</p>
</td></tr>
<tr><td><code id="ddf_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf_+3A_call">call</code></td>
<td>
<p>not implemented for top level ddf function, this is set by ddf as it is passed to the other ddf generics.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fitting code has certain expectations about <code>data</code>.  It should be a
dataframe with at least the following fields named and defined as follows:
</p>

<table>
<tr>
 <td style="text-align: left;"> <code>object</code> </td><td style="text-align: left;"> object number </td>
</tr>
<tr>
 <td style="text-align: left;">
              <code>observer</code> </td><td style="text-align: left;"> observer number (1 or 2) for double
              observer; only 1 if single observer </td>
</tr>
<tr>
 <td style="text-align: left;">
              <code>detected</code> </td><td style="text-align: left;"> 1 if detected by the observer and 0 if
              missed; always 1 for single observer </td>
</tr>
<tr>
 <td style="text-align: left;">
              <code>distance</code> </td><td style="text-align: left;"> perpendicular distance</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>If the data are for clustered objects, the dataframe should also contain a
field named <code>size</code> that gives the observed number in the cluster. If
the data are for a double observer survey, then there are two records for
each observation and each should have the same object number. The code
assumes the observations are listed in the same order for each observer such
that if the data are subsetted by <code>observer</code> there will be the same
number of records in each and each subset will be in the same <code>object</code>
order. In addition to these predefined and pre-named fields, the dataframe
can have any number and type of fields that are used as covariates in the
<code>dsmodel</code> and <code>mrmodel</code>. At present, discrepancies between
observations in <code>distance</code>, <code>size</code> and any user-specified
covariates cannot be assimilated into the uncertainty of the estimate. The
code presumes the values for those fields are the same for both records
(observer=1 and observer=2) and it uses the value from observer 1. Thus it
makes sense to make the values the same for both records in each pair even
when both detect the object or when observer 1 doesn't detect the object the
data would have to be taken from observer 2 and would not be consistent.
</p>
<p>Five different fitting methods are currently available and these in turn
define whether <code>dsmodel</code> and <code>mrmodel</code> need to be defined.
</p>

<table>
<tr>
 <td style="text-align: left;">
Method          </td><td style="text-align: left;"> Single/Double </td><td style="text-align: left;"> <code>dsmodel</code> </td><td style="text-align: left;"> <code>mrmodel</code></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>ds</code>       </td><td style="text-align: left;">    Single     </td><td style="text-align: left;">      yes       </td><td style="text-align: left;">    no </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>io</code>       </td><td style="text-align: left;">    Double     </td><td style="text-align: left;">      yes       </td><td style="text-align: left;">    yes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>io.fi</code>    </td><td style="text-align: left;">    Double     </td><td style="text-align: left;">      no        </td><td style="text-align: left;">    yes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>trial</code>    </td><td style="text-align: left;">    Double     </td><td style="text-align: left;">      yes       </td><td style="text-align: left;">    yes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>trial.fi</code> </td><td style="text-align: left;">    Double     </td><td style="text-align: left;">      no        </td><td style="text-align: left;">    yes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rem</code>      </td><td style="text-align: left;">    Double     </td><td style="text-align: left;">      yes       </td><td style="text-align: left;">    yes </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>rem.fi</code>   </td><td style="text-align: left;">    Double     </td><td style="text-align: left;">      no        </td><td style="text-align: left;">    yes </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>Methods with the suffix &quot;<code>.fi</code>&quot; use the assumption of full independence
and do not use the distance sampling portion of the likelihood which is why a
<code>dsmodel</code> is not needed. An <code>mrmodel</code> is only needed for double
observer surveys and thus is not needed for method <code>ds</code>.
</p>
<p>The <code>dsmodel</code> specifies the detection function g(y) for the distance
sampling data and the models restrict g(0)=1. For single observer data g(y)
is the detection function for the single observer and if it is a double
observer survey it is the relative detection function (assuming g(0)=1) of
both observers as a team (the unique observations from both observers). In
double observer surveys, the detection function is p(y)=p(0)g(y) such that
p(0)&lt;1.  The detection function g(y) is specified by <code>dsmodel</code> and p(0)
estimated from the conditional detection functions (see <code>mrmodel</code>
below).  The value of <code>dsmodel</code> is specified using a hybrid
formula/function notation.  The model definition is prefixed with a <code>~</code>
and the remainder is a function definition with specified arguments.  At
present there are two different functions, <code><a href="#topic+cds">cds</a></code> and
<code><a href="#topic+mcds">mcds</a></code>, for conventional distance sampling and multi-covariate
distance sampling.  Both functions have the same required arguments
(<code>key</code>,<code>formula</code>).  The first specifies the key function this
can be half-normal (&quot;hn&quot;), hazard-rate (&quot;hr&quot;), gamma (&quot;gamma&quot;) or uniform
(&quot;unif&quot;). The argument <code>formula</code> specifies the formula
for the log of the scale parameter of the key function (e.g., the equivalent
of the standard deviation in the half-normal).  The variable <code>distance</code>
should not be included in the formula because the scale is for distance.
See Marques, F.F.C. and S.T. Buckland (2004) for more details on the
representation of the scale formula. For the hazard rate and gamma
functions, an additional <code>shape.formula</code> can be specified for the model
of the shape parameter.  The default will be ~1.
Adjustment terms can be specified by setting <code>adj.series</code> which can have
the values: &quot;none&quot;, &quot;cos&quot; (cosine), &quot;poly&quot; (polynomials), and &quot;herm&quot; 
(Hermite polynomials). One must also specify a vector of orders for the
adjustment terms (<code>adj.order</code>) and a scaling (<code>adj.scale</code>) which
may be &quot;width&quot; or &quot;scale&quot; (for scaling by the scale parameter). Note that 
the uniform key can only be used with adjustments (usually cosine adjustments
for a Fourier-type analysis).
</p>
<p>The <code>mrmodel</code> specifies the form of the conditional detection functions
(i.e.,probability it is seen by observer j given it was seen by observer
3-j) for each observer (j=1,2) in a double observer survey.  The value is
specified using the same mix of formula/function notation but in this case
the functions are <code>glm</code> and <code>gam</code>.  The arguments for the
functions are <code>formula</code> and <code>link</code>.  At present, only <code>glm</code>
is allowed and it is restricted to <code>link=logit</code>.  Thus, currently the
only form for the conditional detection functions is logistic as expressed
in eq 6.32 of Laake and Borchers (2004).  In contrast to <code>dsmodel</code>, the
argument <code>formula</code> will typically include <code>distance</code> and all other
covariates that affect detection probability.  For example,
<code>mrmodel=~glm(formula=~distance+size+sex)</code> constructs a conditional
detection function based on the logistic form with additive factors,
distance, size, and sex.  As another example,
<code>mrmodel=~glm(formula=~distance*size+sex)</code> constructs the same model
with an added interaction between distance and size.
</p>
<p>The argument <code>meta.data</code> is a list that enables various options about
the data to be set. These options include:
</p>

<dl>
<dt><code>point</code></dt><dd><p>if <code>TRUE</code> the data are from point counts and
<code>FALSE</code> (default) implies line transect data</p>
</dd>
<dt><code>width</code></dt><dd><p>distance specifying half-width of the transect</p>
</dd>
<dt><code>left</code></dt><dd><p>distance specifying inner truncation value</p>
</dd>
<dt><code>binned</code></dt><dd><p><code>TRUE</code> or <code>FALSE</code> to specify whether
distances should be binned for analysis</p>
</dd>
<dt><code>breaks</code></dt><dd><p>if <code>binned=TRUE</code>, this is a required sequence of
break points that are used for plotting/gof. They should match
<code>distbegin</code>, <code>distend</code> values if bins are fixed</p>
</dd>
<dt><code>int.range</code></dt><dd><p>an integration range for detection probability;
either a vector of 2 or matrix with 2 columns</p>
</dd>
<dt><code>mono</code></dt><dd><p>constrain the detection function to be weakly
monotonically decreasing (only applicable when there are no covariates in
the detection function)</p>
</dd>
<dt><code>mono.strict</code></dt><dd><p>when <code>TRUE</code> constrain the detection function
to be strictly monotonically decreasing (again, only applicable when there
are no covariates in the detection function)</p>
</dd>
</dl>

<p>Using <code>meta.data=list(int.range=c(1,10))</code> is the same as
<code>meta.data=list(left=1,width=10)</code>. If
<code>meta.data=list(binned=TRUE)</code> is used, the dataframe needs to contain
the fields distbegin and distend for each observation which specify the left
and right hand end points of the distance interval containing the
observation. This is a general data structure that allows the intervals to
change rather than being fixed as in the standard distance analysis tools.
Typically, if the intervals are changing so is the integration range.  For
example, assume that distance bins are generated using fixed angular
measurements from an aircraft in which the altitude is varying.  Because all
analyses are truncated (i.e., the last interval does not go to infinity),
the transect width (and the left truncation point if there is a blindspot
below the aircraft) can potentially change for each observation. The
argument <code>int.range</code> can also be entered as a matrix with 2 columns
(left and width) and a row for each observation.
</p>
<p>The argument <code>control</code> is a list that enables various analysis options
to be set.  It is not necessary to set any of these for most analyses.  They
were provided so the user can optionally see intermediate fitting output and
to control fitting if the algorithm doesn't converge which happens
infrequently.  The list values include:
</p>

<dl>
<dt><code>showit</code></dt><dd><p>Integer (0-3, default 0) controls the
(increasing)amount of information printed during fitting. 0 - none, &gt;=1 -
information about refitting and bound changes is printed, &gt;=2 -
information about adjustment term fitting is printed, ==3 -per-iteration
parameter estimates and log-likelihood printed.</p>
</dd>
<dt><code>estimate</code></dt><dd><p>if FALSE fits model but doesn't estimate predicted
probabilities</p>
</dd>
<dt><code>refit</code></dt><dd><p>if TRUE the algorithm will attempt multiple
optimizations at different starting values if it doesn't converge</p>
</dd>
<dt><code>nrefits</code></dt><dd><p>number of refitting attempts</p>
</dd>
<dt><code>initial</code></dt><dd><p>a named list of starting values for the dsmodel
parameters (e.g. <code>$scale</code>, <code>$shape</code>, <code>$adjustment</code>)</p>
</dd>
<dt><code>lowerbounds</code></dt><dd><p>a vector of lowerbounds for the dsmodel 
parameters in the order the ds parameters will appear in the par 
element of the ddf object, i.e. <code>fit.ddf$par</code> where <code>fit.ddf</code> 
is a fitted ddf model.</p>
</dd>
<dt><code>upperbounds</code></dt><dd><p>a vector of upperbounds for the dsmodel 
parameters in the order the ds parameters will appear in the par 
element of the ddf object, i.e. <code>fit.ddf$par</code> where <code>fit.ddf</code> 
is a fitted ddf model.</p>
</dd>
<dt><code>limit</code></dt><dd><p>if TRUE restrict analysis to observations with
<code>detected</code>=1</p>
</dd>
<dt><code>debug</code></dt><dd><p> if TRUE, if fitting fails, return an object with
fitting information</p>
</dd>
<dt><code>nofit</code></dt><dd><p>if TRUE don't fit a model, but use the starting values
and generate an object based on those values</p>
</dd>
<dt><code>optimx.method</code></dt><dd><p>one (or a vector of) string(s) giving the
optimisation method to use. If more than one is supplied, the results from
one are used as the starting values for the next. See
<code><a href="optimx.html#topic+optimx">optimx</a></code></p>
</dd>
<dt><code>optimx.maxit</code></dt><dd><p>maximum number of iterations to use in the
optimisation.</p>
</dd>
<dt><code>mono.random.start</code></dt><dd><p>By default when monotonicity constraints
are enforced, a grid of starting values are tested. Instead random
starting values can be used (uniformly distributed between the upper and
lower bounds). Set <code>TRUE</code> for random start, <code>FALSE</code> (default)
uses the grid method</p>
</dd>
<dt><code>mono.outer.iter</code></dt><dd><p>Number of outer iterations to be used by
<code>solnp</code> when fitting a monotonic model. Default 200.</p>
</dd>
<dt><code>silent</code></dt><dd><p>silences warnings within ds fitting method (helpful
for running many times without generating many warning/error messages).</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>By default this is set to 'both' for single 
observer analyses and 'R' for double observer analyses. For single 
observer analyses where optimizer = 'both', the R optimizer will be used 
and if present the MCDS optimizer will also be used. The result with the 
best likelihood value will be selected. To run only a specified optimizer 
set this value to either 'R' or 'MCDS'. The MCDS optimizer cannot currently
be used for detection function fitting with double observer analyses.  
See <code><a href="#topic+mcds_dot_exe">mcds_dot_exe</a></code> for more information.</p>
</dd>
<dt><code>winebin</code></dt><dd><p>Location of the <code>wine</code> binary used to run
<code>MCDS.exe</code>. See <a href="#topic+mcds_dot_exe">mcds_dot_exe</a> for more information.</p>
</dd>
</dl>

<p>Examples of distance sampling analyses are available at
<a href="http://examples.distancesampling.org/">http://examples.distancesampling.org/</a>.
</p>
<p>Hints and tips on fitting (particularly optimisation issues) are on the
<code><a href="#topic+mrds_opt">mrds_opt</a></code> manual page.
</p>


<h3>Value</h3>

<p>model object of class=(method, &quot;ddf&quot;)
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>
<p>Marques, F.F.C. and S.T. Buckland. 2004. Covariate models for the detection
function. In: Advanced Distance Sampling, eds. S.T. Buckland,
D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas.
Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.ds">ddf.ds</a></code>, <code><a href="#topic+ddf.io">ddf.io</a></code>,
<code><a href="#topic+ddf.io.fi">ddf.io.fi</a></code>, <code><a href="#topic+ddf.trial">ddf.trial</a></code>,
<code><a href="#topic+ddf.trial.fi">ddf.trial.fi</a></code>, <code><a href="#topic+ddf.rem">ddf.rem</a></code>, <code><a href="#topic+ddf.rem.fi">ddf.rem.fi</a></code>,
<code><a href="#topic+mrds_opt">mrds_opt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data(book.tee.data)
region &lt;- book.tee.data$book.tee.region
egdata &lt;- book.tee.data$book.tee.dataframe
samples &lt;- book.tee.data$book.tee.samples
obs &lt;- book.tee.data$book.tee.obs

# fit a half-normal detection function
result &lt;- ddf(dsmodel=~mcds(key="hn", formula=~1), data=egdata, method="ds",
              meta.data=list(width=4))

# fit an independent observer model with full independence
result.io.fi &lt;- ddf(mrmodel=~glm(~distance), data=egdata, method="io.fi",
                    meta.data=list(width = 4))

# fit an independent observer model with point independence
result.io &lt;- ddf(dsmodel=~cds(key = "hn"), mrmodel=~glm(~distance),
                 data=egdata, method="io", meta.data=list(width=4))
## Not run: 

# simulated single observer point count data (see ?ptdata.single)
data(ptdata.single)
ptdata.single$distbegin &lt;- (as.numeric(cut(ptdata.single$distance,
                            10*(0:10)))-1)*10
ptdata.single$distend &lt;- (as.numeric(cut(ptdata.single$distance,
                          10*(0:10))))*10
model &lt;- ddf(data=ptdata.single, dsmodel=~cds(key="hn"),
             meta.data=list(point=TRUE,binned=TRUE,breaks=10*(0:10)))

summary(model)

plot(model,main="Single observer binned point data - half normal")

model &lt;- ddf(data=ptdata.single, dsmodel=~cds(key="hr"),
             meta.data=list(point=TRUE, binned=TRUE, breaks=10*(0:10)))

summary(model)

plot(model, main="Single observer binned point data - hazard rate")

dev.new()

# simulated double observer point count data (see ?ptdata.dual)
# setup data
data(ptdata.dual)
ptdata.dual$distbegin &lt;- (as.numeric(cut(ptdata.dual$distance,
                          10*(0:10)))-1)*10
ptdata.dual$distend &lt;- (as.numeric(cut(ptdata.dual$distance,
                        10*(0:10))))*10

model &lt;- ddf(method="io", data=ptdata.dual, dsmodel=~cds(key="hn"),
             mrmodel=~glm(formula=~distance*observer),
             meta.data=list(point=TRUE, binned=TRUE, breaks=10*(0:10)))

summary(model)

plot(model, main="Dual observer binned point data", new=FALSE, pages=1)

model &lt;- ddf(method="io", data=ptdata.dual,
             dsmodel=~cds(key="unif", adj.series="cos", adj.order=1),
             mrmodel=~glm(formula=~distance*observer),
             meta.data=list(point=TRUE, binned=TRUE, breaks=10*(0:10)))

summary(model)

par(mfrow=c(2,3))
plot(model,main="Dual observer binned point data",new=FALSE)


## End(Not run)
</code></pre>

<hr>
<h2 id='ddf.ds'>CDS/MCDS Distance Detection Function Fitting</h2><span id='topic+ddf.ds'></span>

<h3>Description</h3>

<p>Fits a conventional distance sampling (CDS) (likelihood eq 6.6 in Laake and
Borchers 2004) or multi-covariate distance sampling (MCDS)(likelihood eq
6.14 in Laake and Borchers 2004) model for the detection function of
observed distance data.  It only uses key functions and does not incorporate
adjustment functions as in CDS/MCDS analysis engines in DISTANCE (Marques
and Buckland 2004). Distance can be grouped (binned), ungrouped (unbinned)
or mixture of the two.  This function is not called directly by the user and
is called from <code>ddf</code>,<code>ddf.io</code>, or <code>ddf.trial</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds'
ddf(
  dsmodel,
  mrmodel = NULL,
  data,
  method = "ds",
  meta.data = list(),
  control = list(),
  call
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.ds_+3A_dsmodel">dsmodel</code></td>
<td>
<p>model list with key function and scale formula if any</p>
</td></tr>
<tr><td><code id="ddf.ds_+3A_mrmodel">mrmodel</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="ddf.ds_+3A_data">data</code></td>
<td>
<p><code>data.frame</code>; see <code><a href="#topic+ddf">ddf</a></code> for details</p>
</td></tr>
<tr><td><code id="ddf.ds_+3A_method">method</code></td>
<td>
<p>analysis method; only needed if this function called from
<code>ddf.io</code> or <code>ddf.trial</code></p>
</td></tr>
<tr><td><code id="ddf.ds_+3A_meta.data">meta.data</code></td>
<td>
<p><code>list</code> containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf.ds_+3A_control">control</code></td>
<td>
<p><code>list</code> containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf.ds_+3A_call">call</code></td>
<td>
<p>original function call if this function not called directly from
<code>ddf</code> (e.g., called via <code>ddf.io</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a complete description of each of the calling arguments, see
<code><a href="#topic+ddf">ddf</a></code>.  The argument <code>model</code> in this function is the same
as <code>dsmodel</code> in <code>ddf</code>.  The argument <code>dataname</code> is the name
of the dataframe specified by the argument <code>data</code> in <code>ddf</code>. The
arguments <code>control</code>,<code>meta.data</code>,and <code>method</code> are defined the
same as in <code>ddf</code>.
</p>


<h3>Value</h3>

<p>result: a <code>ds</code> model object
</p>


<h3>Note</h3>

<p>If mixture of binned and unbinned distance, width must be set to be &gt;=
largest interval endpoint; this could be changed with a more complicated
analysis; likewise, if all binned and bins overlap, the above must also
hold; if bins don't overlap, width must be one of the interval endpoints;
same holds for left truncation Although the mixture analysis works in
principle it has not been tested via simulation.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R. Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>
<p>Marques, F.F.C. and S.T. Buckland. 2004. Covariate models for the detection
function. In: Advanced Distance Sampling, eds. S.T. Buckland,
D.R. Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas.
Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flnl">flnl</a></code>, <code><a href="#topic+summary.ds">summary.ds</a></code>, <code><a href="#topic+coef.ds">coef.ds</a></code>,
<code><a href="#topic+plot.ds">plot.ds</a></code>,<code><a href="#topic+gof.ds">gof.ds</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ddf.ds is called when ddf is called with method="ds"

data(book.tee.data)
region &lt;- book.tee.data$book.tee.region
egdata &lt;- book.tee.data$book.tee.dataframe
samples &lt;- book.tee.data$book.tee.samples
obs &lt;- book.tee.data$book.tee.obs
result &lt;- ddf(dsmodel = ~mcds(key = "hn", formula = ~1),
              data = egdata[egdata$observer==1, ], method = "ds",
              meta.data = list(width = 4))
summary(result,se=TRUE)
plot(result,main="cds - observer 1")
print(dht(result,region,samples,obs,options=list(varflag=0,group=TRUE),
          se=TRUE))
print(ddf.gof(result))

</code></pre>

<hr>
<h2 id='ddf.gof'>Goodness of fit tests for distance sampling models</h2><span id='topic+ddf.gof'></span><span id='topic+gof.io'></span><span id='topic+gof.io.fi'></span><span id='topic+gof.trial'></span><span id='topic+gof.trial.fi'></span><span id='topic+gof.rem'></span><span id='topic+gof.rem.fi'></span>

<h3>Description</h3>

<p>Generic function that computes chi-square goodness of fit test for detection
function models with binned data and Cramer-von Mises and Kolmogorov-Smirnov
(if <code>ks=TRUE</code>)tests for exact distance data. By default a Q-Q plot is
generated for exact data (and can be suppressed using the <code>qq=FALSE</code>
argument).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddf.gof(
  model,
  breaks = NULL,
  nc = NULL,
  qq = TRUE,
  nboot = 100,
  ks = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.gof_+3A_model">model</code></td>
<td>
<p>model object</p>
</td></tr>
<tr><td><code id="ddf.gof_+3A_breaks">breaks</code></td>
<td>
<p>Cutpoints to use for binning data</p>
</td></tr>
<tr><td><code id="ddf.gof_+3A_nc">nc</code></td>
<td>
<p>Number of distance classes</p>
</td></tr>
<tr><td><code id="ddf.gof_+3A_qq">qq</code></td>
<td>
<p>Flag to indicate whether quantile-quantile plot is desired</p>
</td></tr>
<tr><td><code id="ddf.gof_+3A_nboot">nboot</code></td>
<td>
<p>number of replicates to use to calculate p-values for the
Kolmogorov-Smirnov goodness of fit test statistics</p>
</td></tr>
<tr><td><code id="ddf.gof_+3A_ks">ks</code></td>
<td>
<p>perform the Kolmogorov-Smirnov test (this involves many bootstraps
so can take a while)</p>
</td></tr>
<tr><td><code id="ddf.gof_+3A_...">...</code></td>
<td>
<p>Graphics parameters to pass into qqplot function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Formal goodness of fit testing for detection function models using
Kolmogorov-Smirnov and Cramer-von Mises tests. Both tests are based on
looking at the quantile-quantile plot produced by <code><a href="#topic+qqplot.ddf">qqplot.ddf</a></code>
and deviations from the line x=y.
</p>
<p>The Kolmogorov-Smirnov test asks the question &quot;what's the largest vertical
distance between a point and the y=x line?&quot; It uses this distance as a
statistic to test the null hypothesis that the samples (EDF and CDF in our
case) are from the same distribution (and hence our model fits well). If the
deviation between the y=x line and the points is too large we reject the
null hypothesis and say the model doesn't have a good fit.
</p>
<p>Rather than looking at the single biggest difference between the y=x line
and the points in the Q-Q plot, we might prefer to think about all the
differences between line and points, since there may be many smaller
differences that we want to take into account rather than looking for one
large deviation. Its null hypothesis is the same, but the statistic it uses
is the sum of the deviations from each of the point to the line.
Note that a bootstrap procedure is required for the Kolmogorov-Smirnov test
to ensure that the p-values from the procedure are correct as the we are
comparing the cumulative distribution function (CDF) and empirical
distribution function (EDF) and we have estimated the parameters of the
detection function. The <code>nboot</code> parameter controls the number of
bootstraps to use. Set to <code>0</code> to avoid computing bootstraps (much
faster but with no Kolmogorov-Smirnov results, of course).
</p>
<p>One can change the precision of printed values by using the <code><a href="#topic+print.ddf.gof">print.ddf.gof</a></code> method's <code>digits</code> argument.
</p>


<h3>Value</h3>

<p>List of class <code>ddf.gof</code> containing </p>
<table>
<tr><td><code>chi-square</code></td>
<td>
<p>Goodness
of fit test statistic</p>
</td></tr> <tr><td><code>df</code></td>
<td>
<p>Degrees of freedom associated with test
statistic</p>
</td></tr> <tr><td><code>p-value</code></td>
<td>
<p>Significance level of test statistic</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qqplot.ddf">qqplot.ddf</a></code>
</p>

<hr>
<h2 id='ddf.io'>Mark-Recapture Distance Sampling (MRDS) IO - PI</h2><span id='topic+ddf.io'></span>

<h3>Description</h3>

<p>Mark-Recapture Distance Sampling (MRDS) Analysis of Independent Observer
Configuration and Point Independence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'io'
ddf(
  dsmodel,
  mrmodel,
  data,
  method = NULL,
  meta.data = list(),
  control = list(),
  call = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.io_+3A_dsmodel">dsmodel</code></td>
<td>
<p>distance sampling model specification; model list with key
function and scale formula if any</p>
</td></tr>
<tr><td><code id="ddf.io_+3A_mrmodel">mrmodel</code></td>
<td>
<p>mark-recapture model specification; model list with formula
and link</p>
</td></tr>
<tr><td><code id="ddf.io_+3A_data">data</code></td>
<td>
<p>analysis dataframe</p>
</td></tr>
<tr><td><code id="ddf.io_+3A_method">method</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="ddf.io_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf.io_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf.io_+3A_call">call</code></td>
<td>
<p>original function call used to call <code>ddf</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>MRDS analysis based on point independence involves two separate and
independent analyses of the mark-recapture data and the distance sampling
data.  For the independent observer configuration, the mark-recapture data
are analysed with a call to <code><a href="#topic+ddf.io.fi">ddf.io.fi</a></code> (see likelihood eq 6.8
and 6.16 in Laake and Borchers 2004) to fit conditional distance sampling
detection functions to estimate p(0), detection probability at distance zero
for the independent observer team based on independence at zero (eq 6.22 in
Laake and Borchers 2004). Independently, the distance data, the union of the
observations from the independent observers, are used to fit a conventional
distance sampling (CDS) (likelihood eq 6.6) or multi-covariate distance
sampling (MCDS) (likelihood eq 6.14) model for the detection function, g(y),
such that g(0)=1. The detection function for the observer team is then
created as p(y)=p(0)*g(y) (eq 6.28 of Laake and Borchers 2004) from which
predictions are made. <code>ddf.io</code> is not called directly by the user and
is called from <code><a href="#topic+ddf">ddf</a></code> with <code>method="io"</code>.
</p>
<p>For a complete description of each of the calling arguments, see
<code><a href="#topic+ddf">ddf</a></code>.  The argument <code>dataname</code> is the name of the
dataframe specified by the argument <code>data</code> in <code>ddf</code>. The arguments
<code>dsmodel</code>, <code>mrmodel</code>, <code>control</code> and <code>meta.data</code> are
defined the same as in <code>ddf</code>.
</p>


<h3>Value</h3>

<p>result: an io model object which is composed of io.fi and ds model
objects
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.io.fi">ddf.io.fi</a></code>,
<code><a href="#topic+ddf.ds">ddf.ds</a></code>,<code><a href="#topic+summary.io">summary.io</a></code>,<code><a href="#topic+coef.io">coef.io</a></code>,<code><a href="#topic+plot.io">plot.io</a></code>,
<code><a href="#topic+gof.io">gof.io</a></code>
</p>

<hr>
<h2 id='ddf.io.fi'>Mark-Recapture Distance Sampling (MRDS) IO - FI</h2><span id='topic+ddf.io.fi'></span>

<h3>Description</h3>

<p>Mark-Recapture Analysis of Independent Observer Configuration with Full
Independence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'io.fi'
ddf(
  dsmodel = NULL,
  mrmodel,
  data,
  method,
  meta.data = list(),
  control = list(),
  call = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.io.fi_+3A_dsmodel">dsmodel</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="ddf.io.fi_+3A_mrmodel">mrmodel</code></td>
<td>
<p>mark-recapture model specification</p>
</td></tr>
<tr><td><code id="ddf.io.fi_+3A_data">data</code></td>
<td>
<p>analysis dataframe</p>
</td></tr>
<tr><td><code id="ddf.io.fi_+3A_method">method</code></td>
<td>
<p>analysis method; only needed if this function called from
<code>ddf.io</code></p>
</td></tr>
<tr><td><code id="ddf.io.fi_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf.io.fi_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf.io.fi_+3A_call">call</code></td>
<td>
<p>original function call used to call <code>ddf</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mark-recapture data derived from an independent observer distance
sampling survey can be used to derive conditional detection functions
(p_j(y)) for both observers (j=1,2).  They are conditional detection
functions because detection probability for observer j is based on seeing or
not seeing observations made by observer 3-j. Thus, p_1(y) is estimated by
p_1|2(y).
</p>
<p>If detections by the observers are independent (full
independence) then p_1(y)=p_1|2(y),p_2(y)=p_2|1(y) and for the union, full
independence means that p(y)=p_1(y) + p_2(y) - p_1(y)*p_2(y) for each
distance y.  In fitting the detection functions the likelihood given by eq
6.8 and 6.16 in Laake and Borchers (2004) is used. That analysis does not
require the usual distance sampling assumption that perpendicular distances
are uniformly distributed based on line placement that is random relative to
animal distribution.  However, that assumption is used in computing
predicted detection probability which is averaged based on a uniform
distribution (see eq 6.11 of Laake and Borchers 2004).
</p>
<p>For a complete description of each of the calling arguments, see
<code><a href="#topic+ddf">ddf</a></code>.  The argument <code>model</code> in this function is the same
as <code>mrmodel</code> in <code>ddf</code>.  The argument <code>dataname</code> is the name
of the dataframe specified by the argument <code>data</code> in <code>ddf</code>. The
arguments <code>control</code>,<code>meta.data</code>,and <code>method</code> are defined the
same as in <code>ddf</code>.
</p>


<h3>Value</h3>

<p>result: an io.fi model object
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.io">ddf.io</a></code>,<code><a href="#topic+summary.io.fi">summary.io.fi</a></code>,<code><a href="#topic+coef.io.fi">coef.io.fi</a></code>,
<code><a href="#topic+plot.io.fi">plot.io.fi</a></code>,<code><a href="#topic+gof.io.fi">gof.io.fi</a></code>,<code><a href="#topic+io.glm">io.glm</a></code>
</p>

<hr>
<h2 id='ddf.rem'>Mark-Recapture Distance Sampling (MRDS) Removal - PI</h2><span id='topic+ddf.rem'></span>

<h3>Description</h3>

<p>Mark-Recapture Distance Sampling (MRDS) Analysis of Removal Observer
Configuration and Point Independence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rem'
ddf(
  dsmodel,
  mrmodel,
  data,
  method = NULL,
  meta.data = list(),
  control = list(),
  call = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.rem_+3A_dsmodel">dsmodel</code></td>
<td>
<p>distance sampling model specification; model list with key
function and scale formula if any</p>
</td></tr>
<tr><td><code id="ddf.rem_+3A_mrmodel">mrmodel</code></td>
<td>
<p>mark-recapture model specification; model list with formula
and link</p>
</td></tr>
<tr><td><code id="ddf.rem_+3A_data">data</code></td>
<td>
<p>analysis dataframe</p>
</td></tr>
<tr><td><code id="ddf.rem_+3A_method">method</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="ddf.rem_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf.rem_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf.rem_+3A_call">call</code></td>
<td>
<p>original function call used to call <code>ddf</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>MRDS analysis based on point independence involves two separate and
independent analyses of the mark-recapture data and the distance sampling
data.  For the removal observer configuration, the mark-recapture data are
analysed with a call to <code><a href="#topic+ddf.rem.fi">ddf.rem.fi</a></code> (see Laake and Borchers
2004) to fit conditional distance sampling detection functions to estimate
p(0), detection probability at distance zero for the primary observer based
on independence at zero (eq 6.22 in Laake and Borchers 2004). Independently,
the distance data, the observations from the primary observer, are used to
fit a conventional distance sampling (CDS) (likelihood eq 6.6) or
multi-covariate distance sampling (MCDS) (likelihood eq 6.14) model for the
detection function, g(y), such that g(0)=1. The detection function for the
primary observer is then created as p(y)=p(0)*g(y) (eq 6.28 of Laake and
Borchers 2004) from which predictions are made. <code>ddf.rem</code> is not called
directly by the user and is called from <code><a href="#topic+ddf">ddf</a></code> with
<code>method="rem"</code>.
</p>
<p>For a complete description of each of the calling arguments, see
<code><a href="#topic+ddf">ddf</a></code>.  The argument <code>data</code> is the dataframe specified by
the argument <code>data</code> in <code>ddf</code>. The arguments <code>dsmodel</code>,
<code>mrmodel</code>, <code>control</code> and <code>meta.data</code> are defined the same as
in <code>ddf</code>.
</p>


<h3>Value</h3>

<p>result: an rem model object which is composed of rem.fi and ds model
objects
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.rem.fi">ddf.rem.fi</a></code>, <code><a href="#topic+ddf.ds">ddf.ds</a></code>
</p>

<hr>
<h2 id='ddf.rem.fi'>Mark-Recapture Distance Sampling (MRDS) Removal - FI</h2><span id='topic+ddf.rem.fi'></span>

<h3>Description</h3>

<p>Mark-Recapture Distance Sampling (MRDS) Analysis of Removal Observer
Configuration with Full Independence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rem.fi'
ddf(
  dsmodel = NULL,
  mrmodel,
  data,
  method,
  meta.data = list(),
  control = list(),
  call = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.rem.fi_+3A_dsmodel">dsmodel</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="ddf.rem.fi_+3A_mrmodel">mrmodel</code></td>
<td>
<p>mark-recapture model specification</p>
</td></tr>
<tr><td><code id="ddf.rem.fi_+3A_data">data</code></td>
<td>
<p>analysis dataframe</p>
</td></tr>
<tr><td><code id="ddf.rem.fi_+3A_method">method</code></td>
<td>
<p>analysis method; only needed if this function called from
<code>ddf.io</code></p>
</td></tr>
<tr><td><code id="ddf.rem.fi_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf.rem.fi_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf.rem.fi_+3A_call">call</code></td>
<td>
<p>original function call used to call <code>ddf</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mark-recapture data derived from an removal observer distance sampling
survey can only derive conditional detection functions (p_j(y)) for both
observers (j=1) because technically it assumes that detection probability
does not vary by occasion (observer in this case).  It is a conditional
detection function because detection probability for observer 1 is
conditional on the observations seen by either of the observers. Thus,
p_1(y) is estimated by p_1|2(y).
</p>
<p>If detections by the observers are
independent (full independence) then p_1(y)=p_1|2(y) and for the union, full
independence means that p(y)=p_1(y) + p_2(y) - p_1(y)*p_2(y) for each
distance y.  In fitting the detection functions the likelihood from Laake
and Borchers (2004) are used. That analysis does not require the usual
distance sampling assumption that perpendicular distances are uniformly
distributed based on line placement that is random relative to animal
distribution.  However, that assumption is used in computing predicted
detection probability which is averaged based on a uniform distribution (see
eq 6.11 of Laake and Borchers 2004).
</p>
<p>For a complete description of each of the calling arguments, see
<code><a href="#topic+ddf">ddf</a></code>.  The argument <code>model</code> in this function is the same
as <code>mrmodel</code> in <code>ddf</code>.  The argument <code>dataname</code> is the name
of the dataframe specified by the argument <code>data</code> in <code>ddf</code>. The
arguments <code>control</code>,<code>meta.data</code>,and <code>method</code> are defined the
same as in <code>ddf</code>.
</p>


<h3>Value</h3>

<p>result: an rem.fi model object
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.io">ddf.io</a></code>,<code><a href="#topic+rem.glm">rem.glm</a></code>
</p>

<hr>
<h2 id='ddf.trial'>Mark-Recapture Distance Sampling (MRDS) Trial Configuration - PI</h2><span id='topic+ddf.trial'></span>

<h3>Description</h3>

<p>Mark-Recapture Distance Sampling (MRDS) Analysis of Trial Observer
Configuration and Point Independence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trial'
ddf(
  dsmodel,
  mrmodel,
  data,
  method = NULL,
  meta.data = list(),
  control = list(),
  call = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.trial_+3A_dsmodel">dsmodel</code></td>
<td>
<p>distance sampling model specification; model list with key
function and scale formula if any</p>
</td></tr>
<tr><td><code id="ddf.trial_+3A_mrmodel">mrmodel</code></td>
<td>
<p>mark-recapture model specification; model list with formula
and link</p>
</td></tr>
<tr><td><code id="ddf.trial_+3A_data">data</code></td>
<td>
<p>analysis <code>data.frame</code></p>
</td></tr>
<tr><td><code id="ddf.trial_+3A_method">method</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="ddf.trial_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf.trial_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf.trial_+3A_call">call</code></td>
<td>
<p>original function call used to call <code>ddf</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>MRDS analysis based on point independence involves two separate and
independent analyses of the mark-recapture data and the distance sampling
data.  For the trial configuration, the mark-recapture data are analysed
with a call to <code><a href="#topic+ddf.trial.fi">ddf.trial.fi</a></code> (see likelihood eq 6.12 and 6.17
in Laake and Borchers 2004) to fit a conditional distance sampling detection
function for observer 1 based on trials (observations) from observer 2 to
estimate p_1(0), detection probability at distance zero for observer 1.
Independently, the distance data from observer 1 are used to fit a
conventional distance sampling (CDS) (likelihood eq 6.6) or multi-covariate
distance sampling (MCDS) (likelihood eq 6.14) model for the detection
function, g(y), such that g(0)=1.  The detection function for observer 1 is
then created as p_1(y)=p_1(0)*g(y) (eq 6.28 of Laake and Borchers 2004) from
which predictions are made. <code>ddf.trial</code> is not called directly by the
user and is called from <code><a href="#topic+ddf">ddf</a></code> with <code>method="trial"</code>.
</p>
<p>For a complete description of each of the calling arguments, see
<code><a href="#topic+ddf">ddf</a></code>.  The argument <code>dataname</code> is the name of the
dataframe specified by the argument <code>data</code> in <code>ddf</code>. The arguments
<code>dsmodel</code>, <code>mrmodel</code>, <code>control</code> and <code>meta.data</code> are
defined the same as in <code>ddf</code>.
</p>


<h3>Value</h3>

<p>result: a trial model object which is composed of <code>trial.fi</code> and <code>ds</code> model objects
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.trial.fi">ddf.trial.fi</a></code>, <code><a href="#topic+ddf.ds">ddf.ds</a></code>, <code><a href="#topic+summary.trial">summary.trial</a></code>, <code><a href="#topic+coef.trial">coef.trial</a></code>, <code><a href="#topic+plot.trial">plot.trial</a></code>, <code><a href="#topic+gof.trial">gof.trial</a></code>
</p>

<hr>
<h2 id='ddf.trial.fi'>Mark-Recapture Analysis of Trial Configuration - FI</h2><span id='topic+ddf.trial.fi'></span>

<h3>Description</h3>

<p>Mark-Recapture Analysis of Trial Observer Configuration with Full
Independence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trial.fi'
ddf(
  dsmodel = NULL,
  mrmodel,
  data,
  method,
  meta.data = list(),
  control = list(),
  call = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddf.trial.fi_+3A_dsmodel">dsmodel</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="ddf.trial.fi_+3A_mrmodel">mrmodel</code></td>
<td>
<p>mark-recapture model specification</p>
</td></tr>
<tr><td><code id="ddf.trial.fi_+3A_data">data</code></td>
<td>
<p>analysis dataframe</p>
</td></tr>
<tr><td><code id="ddf.trial.fi_+3A_method">method</code></td>
<td>
<p>analysis method; only needed if this function called from
<code>ddf.trial</code></p>
</td></tr>
<tr><td><code id="ddf.trial.fi_+3A_meta.data">meta.data</code></td>
<td>
<p>list containing settings controlling data structure</p>
</td></tr>
<tr><td><code id="ddf.trial.fi_+3A_control">control</code></td>
<td>
<p>list containing settings controlling model fitting</p>
</td></tr>
<tr><td><code id="ddf.trial.fi_+3A_call">call</code></td>
<td>
<p>original function call used to call <code>ddf</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mark-recapture data derived from a trial observer distance sampling
survey can be used to derive a conditional detection function (p_1(y)) for
observer 1 based on trials (observations) from observer 2. It is a
conditional detection function because detection probability for observer 1
is based on seeing or not seeing observations made by observer 2. Thus,
p_1(y) is estimated by p_1|2(y).  If detections by the observers are
independent (full independence) then p_1(y)=p_1|2(y) for each distance y.
In fitting the detection functions the likelihood given by eq 6.12 or 6.17
in Laake and Borchers (2004) is used. That analysis does not require the
usual distance sampling assumption that perpendicular distances are
uniformly distributed based on line placement that is random relative to
animal distribution.  However, that assumption is used in computing
predicted detection probability which is averaged based on a uniform
distribution (see eq 6.13 of Laake and Borchers 2004).
</p>
<p>For a complete description of each of the calling arguments, see
<code><a href="#topic+ddf">ddf</a></code>.  The argument <code>model</code> in this function is the same
as <code>mrmodel</code> in <code>ddf</code>.  The argument <code>dataname</code> is the name
of the dataframe specified by the argument <code>data</code> in <code>ddf</code>. The
arguments <code>control</code>,<code>meta.data</code>,and <code>method</code> are defined the
same as in <code>ddf</code>.
</p>


<h3>Value</h3>

<p>result: a trial.fi model object
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Laake, J.L. and D.L. Borchers. 2004. Methods for incomplete
detection at distance zero. In: Advanced Distance Sampling, eds. S.T.
Buckland, D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L.
Thomas. Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.trial">ddf.trial</a></code>, <code><a href="#topic+summary.trial.fi">summary.trial.fi</a></code>,
<code><a href="#topic+coef.trial.fi">coef.trial.fi</a></code>, <code><a href="#topic+plot.trial.fi">plot.trial.fi</a></code>,
<code><a href="#topic+gof.trial.fi">gof.trial.fi</a></code>
</p>

<hr>
<h2 id='DeltaMethod'>Numeric Delta Method approximation for the variance-covariance matrix</h2><span id='topic+DeltaMethod'></span>

<h3>Description</h3>

<p>Computes delta method variance-covariance matrix of results of any generic
function <code>fct</code> that computes a vector of estimates as a function of a
set of estimated parameters <code>par</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DeltaMethod(par, fct, vcov, delta, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DeltaMethod_+3A_par">par</code></td>
<td>
<p>vector of parameter values at which estimates should be constructed</p>
</td></tr>
<tr><td><code id="DeltaMethod_+3A_fct">fct</code></td>
<td>
<p>function that constructs estimates from parameters <code>par</code></p>
</td></tr>
<tr><td><code id="DeltaMethod_+3A_vcov">vcov</code></td>
<td>
<p>variance-covariance matrix of the parameters</p>
</td></tr>
<tr><td><code id="DeltaMethod_+3A_delta">delta</code></td>
<td>
<p>proportional change in parameters used to numerically estimate
first derivative with central-difference formula (ignored)</p>
</td></tr>
<tr><td><code id="DeltaMethod_+3A_...">...</code></td>
<td>
<p>any additional arguments needed by <code>fct</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The delta method (aka propagation of errors is based on Taylor series
approximation - see Seber's book on Estimation of Animal Abundance). It uses
the first derivative of <code>fct</code> with respect to <code>par</code>.
It also uses the variance-covariance matrix of the estimated parameters
which is derived in estimating the parameters and is an input argument.
</p>
<p>The first argument of <code>fct</code> should be <code>par</code> which is a vector of
parameter estimates. It should return a single value (or vector) of
estimate(s).  The remaining arguments of <code>fct</code> if any can be passed to
<code>fct</code> by including them at the end of the call to <code>DeltaMethod</code> as
<code>name=value</code> pairs.
</p>


<h3>Value</h3>

<p>a list with values </p>
<table>
<tr><td><code>variance</code></td>
<td>
<p>estimated variance-covariance
matrix of estimates derived by <code>fct</code></p>
</td></tr> <tr><td><code>partial</code></td>
<td>
<p> matrix (or
vector) of partial derivatives of <code>fct</code> with respect to the parameters
<code>par</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>This is a generic function that can be used in any setting beyond the
<code>mrds</code> package. However this is an internal function for <code>mrds</code>
and the user does not need to call it explicitly.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake and David L Miller
</p>

<hr>
<h2 id='det.tables'>Observation detection tables</h2><span id='topic+det.tables'></span>

<h3>Description</h3>

<p>Creates a series of tables for dual observer data that shows the number
missed and detected for each observer within defined distance classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>det.tables(model, nc = NULL, breaks = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="det.tables_+3A_model">model</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="det.tables_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="det.tables_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list object of class &quot;det.tables&quot; </p>
<table>
<tr><td><code>Observer1</code></td>
<td>
<p>table for
observer 1</p>
</td></tr>
<tr><td><code>Observer2</code></td>
<td>
<p>table for observer 2</p>
</td></tr> <tr><td><code>Duplicates</code></td>
<td>
<p>histogram counts
for duplicates</p>
</td></tr>
<tr><td><code>Pooled</code></td>
<td>
<p>histogram counts for all observations by either observer</p>
</td></tr>
<tr><td><code>Obs1_2</code></td>
<td>
<p>table for observer 1 within subset seen by observer 2</p>
</td></tr>
<tr><td><code>Obs2_1</code></td>
<td>
<p>table for observer 2 within subset seen by observer 1</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(book.tee.data)
region &lt;- book.tee.data$book.tee.region
egdata &lt;- book.tee.data$book.tee.dataframe
samples &lt;- book.tee.data$book.tee.samples
obs &lt;- book.tee.data$book.tee.obs
xx &lt;- ddf(mrmodel=~glm(formula=~distance*observer),
          dsmodel=~mcds(key="hn", formula=~sex),
          data=egdata, method="io", meta.data=list(width=4))
tabs &lt;- det.tables(xx, breaks=c(0, 0.5, 1, 2, 3, 4))
par(mfrow=c(2, 2))
plot(tabs, new=FALSE, which=c(1, 2, 5, 6))

</code></pre>

<hr>
<h2 id='detfct.fit'>Fit detection function using key-adjustment functions</h2><span id='topic+detfct.fit'></span>

<h3>Description</h3>

<p>Fit detection function to observed distances using the key-adjustment
function approach.  If adjustment functions are included it will alternate
between fitting parameters of key and adjustment functions and then all
parameters much like the approach in the CDS and MCDS Distance FORTRAN code.
To do so it calls <code>detfct.fit.opt</code> which uses the R optim function
which does not allow non-linear constraints so inclusion of adjustments does
allow the detection function to be non-monotone.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detfct.fit(ddfobj, optim.options, bounds, misc.options)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detfct.fit_+3A_ddfobj">ddfobj</code></td>
<td>
<p>detection function object</p>
</td></tr>
<tr><td><code id="detfct.fit_+3A_optim.options">optim.options</code></td>
<td>
<p>control options for optim</p>
</td></tr>
<tr><td><code id="detfct.fit_+3A_bounds">bounds</code></td>
<td>
<p>bounds for the parameters</p>
</td></tr>
<tr><td><code id="detfct.fit_+3A_misc.options">misc.options</code></td>
<td>
<p>miscellaneous options</p>
</td></tr>
</table>


<h3>Value</h3>

<p>fitted detection function model object with the following list
structure </p>
<table>
<tr><td><code>par</code></td>
<td>
<p>final parameter vector</p>
</td></tr> <tr><td><code>value</code></td>
<td>
<p>final negative
log likelihood value</p>
</td></tr> <tr><td><code>counts</code></td>
<td>
<p>number of function evaluations</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>see codes in optim</p>
</td></tr> <tr><td><code>message</code></td>
<td>
<p>string about
convergence</p>
</td></tr> <tr><td><code>hessian</code></td>
<td>
<p>hessian evaluated at final parameter values</p>
</td></tr>
<tr><td><code>aux</code></td>
<td>
<p> a list with 20 elements </p>
 <ul>
<li><p> maxit: maximum number
of iterations allowed for optimization </p>
</li>
<li><p> lower: lower bound values for
parameters </p>
</li>
<li><p> upper: upper bound values for parameters </p>
</li>
<li><p> setlower:
TRUE if they are user set bounds </p>
</li>
<li><p> setupper: TRUE if they are user set
bounds </p>
</li>
<li><p> point: TRUE if point counts and FALSE if line transect </p>
</li>
<li>
<p>int.range: integration range values </p>
</li>
<li><p> showit: integer value that
determines information printed during iteration </p>
</li>
<li><p> silent: option 
to silence errors from detfct.fit.opt </p>
</li>
<li><p> integral.numeric
if TRUE compute logistic integrals numerically </p>
</li>
<li>
<p>breaks: breaks in distance for defined fixed bins for analysis </p>
</li>
<li>
<p>maxiter: maximum iterations used </p>
</li>
<li><p> refit: if TRUE, detection function
will be fitted more than once if parameters are at a boundary or when
convergence is not achieved </p>
</li>
<li><p> nrefits: number of refittings
</p>
</li>
<li><p> mono: if TRUE monotonicity will be enforced </p>
</li>
<li>
<p>mono.strict: if TRUE, then strict monotonicity is enforced; otherwise weak
</p>
</li>
<li><p> width: radius of point count or half-width of strip </p>
</li>
<li>
<p>standardize: if TRUE, detection function is scaled so g(0)=1 </p>
</li>
<li><p> ddfobj:
distance detection function object; see <code><a href="#topic+create.ddfobj">create.ddfobj</a></code> </p>
</li>
<li>
<p>bounded: TRUE if parameters ended up a boundary (I think) </p>
</li>
<li><p> model:
list of formulas for detection function model (probably can remove this)
</p>
</li></ul>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dave Miller; Jeff Laake
</p>

<hr>
<h2 id='detfct.fit.opt'>Fit detection function using key-adjustment functions</h2><span id='topic+detfct.fit.opt'></span>

<h3>Description</h3>

<p>Fit detection function to observed distances using the key-adjustment
function approach. If adjustment functions are included it will alternate
between fitting parameters of key and adjustment functions and then all
parameters much like the approach in the CDS and MCDS Distance FORTRAN code.
This function is called by the driver function <code>detfct.fit</code>, then
calls <code><a href="optimx.html#topic+optimx">optimx</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detfct.fit.opt(ddfobj, optim.options, bounds, misc.options, fitting = "all")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detfct.fit.opt_+3A_ddfobj">ddfobj</code></td>
<td>
<p>detection function object</p>
</td></tr>
<tr><td><code id="detfct.fit.opt_+3A_optim.options">optim.options</code></td>
<td>
<p>control options for optim</p>
</td></tr>
<tr><td><code id="detfct.fit.opt_+3A_bounds">bounds</code></td>
<td>
<p>bounds for the parameters</p>
</td></tr>
<tr><td><code id="detfct.fit.opt_+3A_misc.options">misc.options</code></td>
<td>
<p>miscellaneous options</p>
</td></tr>
<tr><td><code id="detfct.fit.opt_+3A_fitting">fitting</code></td>
<td>
<p>character string with values &quot;all&quot;,&quot;key&quot;,&quot;adjust&quot; to
determine which parameters are allowed to vary in the fitting</p>
</td></tr>
</table>


<h3>Value</h3>

<p>fitted detection function model object with the following list
structure </p>
<table>
<tr><td><code>par</code></td>
<td>
<p>final parameter vector</p>
</td></tr> <tr><td><code>value</code></td>
<td>
<p>final negative
log likelihood value</p>
</td></tr> <tr><td><code>counts</code></td>
<td>
<p>number of function evaluations</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>see codes in optim</p>
</td></tr> <tr><td><code>message</code></td>
<td>
<p>string about
convergence</p>
</td></tr> <tr><td><code>hessian</code></td>
<td>
<p>hessian evaluated at final parameter values</p>
</td></tr>
<tr><td><code>aux</code></td>
<td>
<p> a list with 20 elements </p>
 <ul>
<li><p> maxit: maximum number
of iterations allowed for optimization </p>
</li>
<li><p> lower: lower bound values for
parameters </p>
</li>
<li><p> upper: upper bound values for parameters </p>
</li>
<li><p> setlower:
TRUE if they are user set bounds </p>
</li>
<li><p> setupper: TRUE if they are user set
bounds </p>
</li>
<li><p> point: TRUE if point counts and FALSE if line transect </p>
</li>
<li>
<p>int.range: integration range values </p>
</li>
<li><p> showit: integer value that
determines information printed during iteration </p>
</li>
<li><p> integral.numeric
if TRUE compute logistic integrals numerically </p>
</li>
<li>
<p>breaks: breaks in distance for defined fixed bins for analysis </p>
</li>
<li>
<p>maxiter: maximum iterations used </p>
</li>
<li><p> refit: if TRUE, detection function
will be fitted more than once if parameters are at a boundary or when
convergence is not achieved </p>
</li>
<li><p> nrefits: number of refittings
</p>
</li>
<li><p> mono: if TRUE, monotonicity will be enforced </p>
</li>
<li>
<p>mono.strict: if TRUE, then strict monotonicity is enforced; otherwise weak
</p>
</li>
<li><p> width: radius of point count or half-width of strip </p>
</li>
<li>
<p>standardize: if TRUE, detection function is scaled so g(0)=1 </p>
</li>
<li><p> ddfobj:
distance detection function object; see <code><a href="#topic+create.ddfobj">create.ddfobj</a></code> </p>
</li>
<li>
<p>bounded: TRUE if estimated parameters are at the bounds </p>
</li>
<li><p> model:
list of formulas for detection function model (probably can remove this)
</p>
</li></ul>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Dave Miller; Jeff Laake; Lorenzo Milazzo
</p>

<hr>
<h2 id='dht'>Density and abundance estimates and variances</h2><span id='topic+dht'></span>

<h3>Description</h3>

<p>Compute density and abundance estimates and variances based on
Horvitz-Thompson-like estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dht(
  model,
  region.table,
  sample.table,
  obs.table = NULL,
  subset = NULL,
  se = TRUE,
  options = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dht_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
<tr><td><code id="dht_+3A_region.table">region.table</code></td>
<td>
<p><code>data.frame</code> of region records. Two columns:
<code>Region.Label</code> and <code>Area</code>. If only density is required, one can
set <code>Area=0</code> for all regions.</p>
</td></tr>
<tr><td><code id="dht_+3A_sample.table">sample.table</code></td>
<td>
<p><code>data.frame</code> of sample records. Three columns:
<code>Region.Label</code>, <code>Sample.Label</code>, <code>Effort</code>.</p>
</td></tr>
<tr><td><code id="dht_+3A_obs.table">obs.table</code></td>
<td>
<p><code>data.frame</code> of observation records with fields:
<code>object</code>, <code>Region.Label</code>, and <code>Sample.Label</code> which give links
to <code>sample.table</code>, <code>region.table</code> and the data records used in
<code>model</code>. Not necessary if the <code>data.frame</code> used to create the
model contains <code>Region.Label</code>, <code>Sample.Label</code> columns.</p>
</td></tr>
<tr><td><code id="dht_+3A_subset">subset</code></td>
<td>
<p>subset statement to create <code>obs.table</code></p>
</td></tr>
<tr><td><code id="dht_+3A_se">se</code></td>
<td>
<p>if <code>TRUE</code> computes standard errors, coefficient of variation
and confidence intervals (based on log-normal approximation). See
&quot;Uncertainty&quot; below.</p>
</td></tr>
<tr><td><code id="dht_+3A_options">options</code></td>
<td>
<p>a list of options that can be set, see &quot;<code>dht</code> options&quot;,
below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Density and abundance within the sampled region is computed based on a
Horvitz-Thompson-like estimator for groups and individuals (if a clustered
population) and this is extrapolated to the entire survey region based on
any defined regional stratification. The variance is based on replicate
samples within any regional stratification. For clustered populations,
<code class="reqn">E(s)</code> and its standard error are also output.
</p>
<p>Abundance is estimated with a Horvitz-Thompson-like estimator (Huggins 1989,
1991; Borchers et al 1998; Borchers and Burnham 2004). The abundance in the
sampled region is simply <code class="reqn">1/p_1 + 1/p_2 + ... + 1/p_n</code> where <code class="reqn">p_i</code>
is the estimated detection probability for the <code class="reqn">i</code>th detection of
<code class="reqn">n</code> total observations. It is not strictly a Horvitz-Thompson estimator
because the <code class="reqn">p_i</code> are estimated and not known. For animals observed in
tight clusters, that estimator gives the abundance of groups
(<code>group=TRUE</code> in <code>options</code>) and the abundance of individuals is
estimated as <code class="reqn">s_1/p_1 + s_2/p_2 + ... + s_n/p_n</code>, where <code class="reqn">s_i</code> is the
size (e.g., number of animals in the group) of each observation
(<code>group=FALSE</code> in <code>options</code>).
</p>
<p>Extrapolation and estimation of abundance to the entire survey region is
based on either a random sampling design or a stratified random sampling
design. Replicate samples (lines) are specified within regional strata
<code>region.table</code>, if any. If there is no stratification,
<code>region.table</code> should contain only a single record with the <code>Area</code>
for the entire survey region. The <code>sample.table</code> is linked to the
<code>region.table</code> with the <code>Region.Label</code>. The <code>obs.table</code> is
linked to the <code>sample.table</code> with the <code>Sample.Label</code> and
<code>Region.Label</code>. Abundance can be restricted to a subset (e.g., for a
particular species) of the population by limiting the list the observations
in <code>obs.table</code> to those in the desired subset. Alternatively, if
<code>Sample.Label</code> and <code>Region.Label</code> are in the <code>data.frame</code>
used to fit the model, then a <code>subset</code> argument can be given in place
of the <code>obs.table</code>. To use the <code>subset</code> argument but include all
of the observations, use <code>subset=1==1</code> to avoid creating an
<code>obs.table</code>.
</p>
<p>In extrapolating to the entire survey region it is important that the unit
measurements be consistent or converted for consistency. A conversion factor
can be specified with the <code>convert.units</code> variable in the
<code>options</code> list. The values of <code>Area</code> in <code>region.table</code>, must
be made consistent with the units for <code>Effort</code> in <code>sample.table</code>
and the units of <code>distance</code> in the <code>data.frame</code> that was analyzed.
It is easiest to do if the units of <code>Area</code> is the square of the units
of <code>Effort</code> and then it is only necessary to convert the units of
<code>distance</code> to the units of <code>Effort</code>. For example, if <code>Effort</code>
was entered in kilometres and <code>Area</code> in square kilometres and
<code>distance</code> in metres then using
<code>options=list(convert.units=0.001)</code> would convert metres to kilometres,
density would be expressed in square kilometres which would then be
consistent with units for <code>Area</code>. However, they can all be in different
units as long as the appropriate composite value for <code>convert.units</code> is
chosen. Abundance for a survey region can be expressed as: <code>A*N/a</code>
where <code>A</code> is <code>Area</code> for the survey region, <code>N</code> is the
abundance in the covered (sampled) region, and <code>a</code> is the area of the
sampled region and is in units of <code>Effort * distance</code>. The sampled
region <code>a</code> is multiplied by <code>convert.units</code>, so it should be
chosen such that the result is in the same units of <code>Area</code>. For
example, if <code>Effort</code> was entered in kilometres, <code>Area</code> in hectares
(100m x 100m) and <code>distance</code> in metres, then using
<code>options=list(convert.units=10)</code> will convert <code>a</code> to units of
hectares (100 to convert metres to 100 metres for distance and .1 to convert
km to 100m units).
</p>
<p>The argument <code>options</code> is a list of <code>variable=value</code> pairs that
set options for the analysis. All but two of these have been described above.
<code>pdelta</code> should not need to be changed but was included for
completeness. It controls the precision of the first derivative calculation
for the delta method variance. If the option <code>areas.supplied</code> is
<code>TRUE</code> then the covered area is assumed to be supplied in the
<code>CoveredArea</code> column of the sample <code>data.frame</code>.
</p>


<h3>Value</h3>

<p>list object of class <code>dht</code> with elements:
</p>
<table>
<tr><td><code>clusters</code></td>
<td>
<p>result list for object clusters</p>
</td></tr>
<tr><td><code>individuals</code></td>
<td>
<p>result list for individuals</p>
</td></tr>
<tr><td><code>Expected.S</code></td>
<td>
<p><code>data.frame</code> of estimates of expected cluster size
with fields <code>Region</code>, <code>Expected.S</code> and <code>se.Expected.S</code>
If each cluster <code>size=1</code>, then the result only includes individuals
and not clusters and <code>Expected.S</code>.</p>
</td></tr>
</table>
<p>The list structure of clusters and individuals are the same:
</p>
<table>
<tr><td><code>bysample</code></td>
<td>
<p><code>data.frame</code> giving results for each sample;
<code>Nchat</code> is the estimated abundance within the sample and <code>Nhat</code> is
scaled by surveyed area/covered area within that region</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>
<p><code>data.frame</code> of summary statistics for each region and
total</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p><code>data.frame</code> of estimates of abundance for each region and
total</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p><code>data.frame</code> of estimates of density for each region and total</p>
</td></tr>
<tr><td><code>average.p</code></td>
<td>
<p>average detection probability estimate</p>
</td></tr>
<tr><td><code>cormat</code></td>
<td>
<p>correlation matrix of regional abundance/density estimates and
total (if more than one region)</p>
</td></tr>
<tr><td><code>vc</code></td>
<td>
<p>list of 3: total variance-covariance matrix, detection function
component of variance and encounter rate component of variance. For
detection the v-c matrix and partial vector are returned</p>
</td></tr>
<tr><td><code>Nhat.by.sample</code></td>
<td>
<p>another summary of <code>Nhat</code> by sample used by
<code><a href="#topic+dht.se">dht.se</a></code></p>
</td></tr>
</table>


<h3>Uncertainty</h3>

<p>If the argument <code>se=TRUE</code>, standard errors for density and abundance is
computed. Coefficient of variation and log-normal confidence intervals are
constructed using a Satterthwaite approximation for degrees of freedom
(Buckland et al. 2001 p. 90). The function <code><a href="#topic+dht.se">dht.se</a></code> computes the
variance and interval estimates.
</p>
<p>The variance has two components:
</p>

<ul>
<li><p> variation due to uncertainty from estimation of the detection
function parameters;
</p>
</li>
<li><p> variation in abundance due to random sample selection;
</p>
</li></ul>

<p>The first component (model parameter uncertainty) is computed using a delta
method estimate of variance (Huggins 1989, 1991, Borchers et al. 1998) in
which the first derivatives of the abundance estimator with respect to the
parameters in the detection function are computed numerically (see
<code><a href="#topic+DeltaMethod">DeltaMethod</a></code>).
</p>
<p>The second component (encounter rate variance) can be computed in one of
several ways depending on the form taken for the encounter rate and the
estimator used. To begin with there three possible values for <code>varflag</code>
to calculate encounter rate:
</p>

<ul>
<li> <p><code>0</code> uses a binomial variance for the number of observations
(equation 13 of Borchers et al. 1998). This estimator is only useful if the
sampled region is the survey region and the objects are not clustered; this
situation will not occur very often;
</p>
</li>
<li> <p><code>1</code> uses the encounter rate <code class="reqn">n/L</code> (objects observed per unit
transect) from Buckland et al. (2001) pg 78-79 (equation 3.78) for line
transects (see also Fewster et al, 2009 estimator R2). This variance
estimator is not appropriate if <code>size</code> or a derivative of <code>size</code>
is used in the detection function;
</p>
</li>
<li> <p><code>2</code> is the default and uses the encounter rate estimator
<code class="reqn">\hat{N}/L</code> (estimated abundance per unit transect) suggested by Innes
et al (2002) and Marques &amp; Buckland (2004).
</p>
</li></ul>

<p>In general if any covariates are used in the models, the default
<code>varflag=2</code> is preferable as the estimated abundance will take into
account variability due to covariate effects. If the population is clustered
the mean group size and standard error is also reported.
</p>
<p>For options <code>1</code> and <code>2</code>, it is then possible to choose one of the
estimator forms given in Fewster et al (2009) for line transects:
<code>"R2"</code>, <code>"R3"</code>, <code>"R4"</code>, <code>"S1"</code>, <code>"S2"</code>,
<code>"O1"</code>, <code>"O2"</code> or <code>"O3"</code> by specifying the <code>ervar=</code>
option (default <code>"R2"</code>). For points, either the <code>"P2"</code> or 
<code>"P3"</code> estimator can be selected (&gt;=mrds 2.3.0 default <code>"P2"</code>,
&lt;= mrds 2.2.9 default <code>"P3"</code>). See <code><a href="#topic+varn">varn</a></code> and Fewster 
et al (2009) for further details on these estimators.
</p>


<h3><code>dht</code> options</h3>

<p>Several options are available to control calculations and output:
</p>

<dl>
<dt><code>ci.width</code></dt><dd><p>Confidence interval width, expressed as a decimal
between 0 and 1 (default <code>0.95</code>, giving a 95% CI)</p>
</dd>
<dt><code>pdelta</code></dt><dd><p>delta value for computing numerical first derivatives
(Default: 0.001)</p>
</dd>
<dt><code>varflag</code></dt><dd><p>0,1,2 (see &quot;Uncertainty&quot;) (Default: <code>2</code>)</p>
</dd>
<dt><code>convert.units</code></dt><dd><p> multiplier for width to convert to units of
length (Default: <code>1</code>)</p>
</dd>
<dt><code>ervar</code></dt><dd><p>encounter rate variance type (see &quot;Uncertainty&quot; and
<code>type</code> argument of <code><a href="#topic+varn">varn</a></code>). (Default: <code>"R2"</code> for
lines and <code>"P2"</code> for points)</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>


<h3>References</h3>

<p>Borchers, D.L., S.T. Buckland, P.W. Goedhart, E.D. Clarke, and S.L. Hedley.
1998. Horvitz-Thompson estimators for double-platform line transect
surveys. Biometrics 54: 1221-1237.
</p>
<p>Borchers, D.L. and K.P. Burnham. General formulation for distance sampling
pp 10-11 In: Advanced Distance Sampling, eds. S.T. Buckland, D.R.Anderson,
K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas. Oxford University
Press.
</p>
<p>Buckland, S.T., D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and
L. Thomas. 2001. Introduction to Distance Sampling: Estimating Abundance
of Biological Populations. Oxford University Press.
</p>
<p>Fewster, R.M., S.T. Buckland, K.P. Burnham, D.L. Borchers, P.E. Jupp, J.L.
Laake and L. Thomas. 2009. Estimating the encounter rate variance in
distance sampling. Biometrics 65: 225-236.
</p>
<p>Huggins, R.M. 1989. On the statistical analysis of capture experiments.
Biometrika 76:133-140.
</p>
<p>Huggins, R.M. 1991. Some practical aspects of a conditional likelihood
approach to capture experiments. Biometrics 47: 725-732.
</p>
<p>Innes, S., M.P. Heide-Jorgensen, J.L. Laake, K.L. Laidre, H.J. Cleator, P.
Richard, and R.E.A. Stewart. 2002. Surveys of belugas and narwhals in the
Canadian High Arctic in 1996. NAMMCO Scientific Publications 4: 169-190.
</p>
<p>Marques, F.F.C. and S.T. Buckland. 2004. Covariate models for the detection
function. In: Advanced Distance Sampling, eds. S.T. Buckland,
D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas.
Oxford University Press.
</p>


<h3>See Also</h3>

<p>print.dht dht.se
</p>

<hr>
<h2 id='dht.deriv'>Computes abundance estimates at specified parameter values using
Horvitz-Thompson-like estimator</h2><span id='topic+dht.deriv'></span>

<h3>Description</h3>

<p>Computes abundance at specified values of parameters for numerical
computation of first derivative with respect to parameters in detection
function.  An internal function called by DeltaMethod which is invoked by
dht.se
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dht.deriv(par, model, obs, samples, options = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dht.deriv_+3A_par">par</code></td>
<td>
<p>detection function parameter values</p>
</td></tr>
<tr><td><code id="dht.deriv_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
<tr><td><code id="dht.deriv_+3A_obs">obs</code></td>
<td>
<p>observations table</p>
</td></tr>
<tr><td><code id="dht.deriv_+3A_samples">samples</code></td>
<td>
<p>samples table</p>
</td></tr>
<tr><td><code id="dht.deriv_+3A_options">options</code></td>
<td>
<p>list of options as specified in <code><a href="#topic+dht">dht</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of abundance estimates at values of parameters specified in
par
</p>


<h3>Note</h3>

<p>Internal function; not intended to be called by user
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dht">dht</a></code>, <code><a href="#topic+dht.se">dht.se</a></code>, <code><a href="#topic+DeltaMethod">DeltaMethod</a></code>
</p>

<hr>
<h2 id='dht.se'>Variance and confidence intervals for density and abundance estimates</h2><span id='topic+dht.se'></span>

<h3>Description</h3>

<p>Computes standard error, cv, and log-normal confidence intervals for
abundance and density within each region (if any) and for the total of all
the regions. It also produces the correlation matrix for regional and total
estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dht.se(
  model,
  region.table,
  samples,
  obs,
  options,
  numRegions,
  estimate.table,
  Nhat.by.sample
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dht.se_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
<tr><td><code id="dht.se_+3A_region.table">region.table</code></td>
<td>
<p>table of region values</p>
</td></tr>
<tr><td><code id="dht.se_+3A_samples">samples</code></td>
<td>
<p>table of samples(replicates)</p>
</td></tr>
<tr><td><code id="dht.se_+3A_obs">obs</code></td>
<td>
<p>table of observations</p>
</td></tr>
<tr><td><code id="dht.se_+3A_options">options</code></td>
<td>
<p>list of options that can be set (see <code><a href="#topic+dht">dht</a></code>)</p>
</td></tr>
<tr><td><code id="dht.se_+3A_numregions">numRegions</code></td>
<td>
<p>number of regions</p>
</td></tr>
<tr><td><code id="dht.se_+3A_estimate.table">estimate.table</code></td>
<td>
<p>table of estimate values</p>
</td></tr>
<tr><td><code id="dht.se_+3A_nhat.by.sample">Nhat.by.sample</code></td>
<td>
<p>estimated abundances by sample</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance has two components:
</p>

<ul>
<li><p> variation due to uncertainty from estimation of the detection
function parameters;
</p>
</li>
<li><p> variation in abundance due to random sample selection;
</p>
</li></ul>

<p>The first component (model parameter uncertainty) is computed using a delta
method estimate of variance (Huggins 1989, 1991, Borchers et al. 1998) in
which the first derivatives of the abundance estimator with respect to the
parameters in the detection function are computed numerically (see
<code><a href="#topic+DeltaMethod">DeltaMethod</a></code>).
</p>
<p>The second component (encounter rate variance) can be computed in one of
several ways depending on the form taken for the encounter rate and the
estimator used. To begin with there three possible values for <code>varflag</code>
to calculate encounter rate:
</p>

<ul>
<li> <p><code>0</code> uses a binomial variance for the number of observations
(equation 13 of Borchers et al. 1998). This estimator is only useful if the
sampled region is the survey region and the objects are not clustered; this
situation will not occur very often;
</p>
</li>
<li> <p><code>1</code> uses the encounter rate <code class="reqn">n/L</code> (objects observed per unit
transect) from Buckland et al. (2001) pg 78-79 (equation 3.78) for line
transects (see also Fewster et al, 2009 estimator R2). This variance
estimator is not appropriate if <code>size</code> or a derivative of <code>size</code>
is used in the detection function;
</p>
</li>
<li> <p><code>2</code> is the default and uses the encounter rate estimator
<code class="reqn">\hat{N}/L</code> (estimated abundance per unit transect) suggested by Innes
et al (2002) and Marques &amp; Buckland (2004).
</p>
</li></ul>

<p>In general if any covariates are used in the models, the default
<code>varflag=2</code> is preferable as the estimated abundance will take into
account variability due to covariate effects. If the population is clustered
the mean group size and standard error is also reported.
</p>
<p>For options <code>1</code> and <code>2</code>, it is then possible to choose one of the
estimator forms given in Fewster et al (2009). For line transects:
<code>"R2"</code>, <code>"R3"</code>, <code>"R4"</code>, <code>"S1"</code>, <code>"S2"</code>,
<code>"O1"</code>, <code>"O2"</code> or <code>"O3"</code> can be used by specifying the
<code>ervar=</code> option (default <code>"R2"</code>). For points, either the 
<code>"P2"</code> or <code>"P3"</code> estimator can be selected (&gt;=mrds 2.3.0 
default <code>"P2"</code>, &lt;= mrds 2.2.9 default <code>"P3"</code>). See 
<code><a href="#topic+varn">varn</a></code> and Fewster et al (2009) for further details 
on these estimators.
</p>
<p>Exceptions to the above occur if there is only one sample in a stratum. In
that case it uses Poisson assumption (<code class="reqn">Var(x)=x</code>) and it assumes a known
variance so <code class="reqn">z=1.96</code> is used for critical value. In all other cases the
degrees of freedom for the <code class="reqn">t</code>-distribution assumed for the
log(abundance) or log(density) is based on the Satterthwaite approximation
(Buckland et al. 2001 pg 90) for the degrees of freedom (df). The df are
weighted by the squared cv in combining the two sources of variation because
of the assumed log-normal distribution because the components are
multiplicative. For combining df for the sampling variance across regions
they are weighted by the variance because it is a sum across regions.
</p>
<p>A non-zero correlation between regional estimates can occur from using a
common detection function across regions. This is reflected in the
correlation matrix of the regional and total estimates which is given in the
value list. It is only needed if subtotals of regional estimates are needed.
</p>


<h3>Value</h3>

<p>List with 2 elements: </p>
<table>
<tr><td><code>estimate.table</code></td>
<td>
<p>completed table with se,
cv and confidence limits</p>
</td></tr> <tr><td><code>vc</code></td>
<td>
<p>correlation matrix of estimates</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is called by <code>dht</code> and it is not expected that the
user will call this function directly but it is documented here for
completeness and for anyone expanding the code or using this function in
their own code.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>see <code><a href="#topic+dht">dht</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dht">dht</a></code>, <code><a href="#topic+print.dht">print.dht</a></code>
</p>

<hr>
<h2 id='distpdf'>Detection functions</h2><span id='topic+distpdf'></span><span id='topic+detfct'></span><span id='topic+adjfct.cos'></span><span id='topic+adjfct.herm'></span><span id='topic+hermite.poly'></span><span id='topic+adjfct.poly'></span><span id='topic+keyfct.hn'></span><span id='topic+keyfct.hz'></span><span id='topic+keyfct.gamma'></span><span id='topic+scalevalue'></span><span id='topic+fx'></span><span id='topic+fr'></span>

<h3>Description</h3>

<p>Various functions used to specify key and adjustment functions for
detection functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detfct(distance, ddfobj, select=NULL, index=NULL, width=NULL,
              standardize = TRUE, stdint=FALSE, left=0)

adjfct.cos(distance, scaling = 1, adj.order, adj.parm = NULL, adj.exp=FALSE)

adjfct.poly(distance, scaling = 1, adj.order, adj.parm = NULL, adj.exp=FALSE)

adjfct.herm(distance, scaling = 1, adj.order, adj.parm = NULL, adj.exp=FALSE)

scalevalue(key.scale, z)

keyfct.hn(distance, key.scale)

keyfct.hz(distance, key.scale, key.shape)

keyfct.gamma(distance, key.scale, key.shape)

fx(distance,ddfobj,select=NULL,index=NULL,width=NULL,
   standardize=TRUE,stdint=FALSE, left=0)

fr(distance,ddfobj,select=NULL,index=NULL,width=NULL,
   standardize=TRUE,stdint=FALSE)

distpdf(distance,ddfobj,select=NULL,index=NULL,width=NULL,standardize=TRUE,
           stdint=FALSE,point=FALSE, left=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distpdf_+3A_distance">distance</code></td>
<td>
<p>vector of distances</p>
</td></tr>
<tr><td><code id="distpdf_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance sampling object (see <code><a href="#topic+create.ddfobj">create.ddfobj</a></code>)</p>
</td></tr>
<tr><td><code id="distpdf_+3A_select">select</code></td>
<td>
<p>logical vector for selection of data values</p>
</td></tr>
<tr><td><code id="distpdf_+3A_index">index</code></td>
<td>
<p>specific data row index</p>
</td></tr>
<tr><td><code id="distpdf_+3A_width">width</code></td>
<td>
<p>(right) truncation width</p>
</td></tr>
<tr><td><code id="distpdf_+3A_standardize">standardize</code></td>
<td>
<p>logical used to decide whether to divide through by the
function evaluated at 0</p>
</td></tr>
<tr><td><code id="distpdf_+3A_stdint">stdint</code></td>
<td>
<p>logical used to decide whether integral is standardized</p>
</td></tr>
<tr><td><code id="distpdf_+3A_point">point</code></td>
<td>
<p>if TRUE, point counts; otherwise line transects</p>
</td></tr>
<tr><td><code id="distpdf_+3A_left">left</code></td>
<td>
<p>(left) truncation distance</p>
</td></tr>
<tr><td><code id="distpdf_+3A_z">z</code></td>
<td>
<p>design matrix for scale function</p>
</td></tr>
<tr><td><code id="distpdf_+3A_key.scale">key.scale</code></td>
<td>
<p>vector of scale values</p>
</td></tr>
<tr><td><code id="distpdf_+3A_key.shape">key.shape</code></td>
<td>
<p>vector of shape values</p>
</td></tr>
<tr><td><code id="distpdf_+3A_adj.order">adj.order</code></td>
<td>
<p>vector of adjustment orders</p>
</td></tr>
<tr><td><code id="distpdf_+3A_adj.parm">adj.parm</code></td>
<td>
<p>vector of adjustment parameters</p>
</td></tr>
<tr><td><code id="distpdf_+3A_scaling">scaling</code></td>
<td>
<p>the scaling for the adjustment terms</p>
</td></tr>
<tr><td><code id="distpdf_+3A_adj.exp">adj.exp</code></td>
<td>
<p>if TRUE uses exp(adj) for adjustment to keep f(x)&gt;0</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multi-covariate detection functions (MCDS) are represented by a function
<code class="reqn">g(x,w,\theta)</code> where x is distance, z is a set of covariates and
<code class="reqn">\theta</code> is the parameter vector.  The functions are defined such that
<code class="reqn">g(0,w,\theta)=1</code> and the covariates modify the scale <code class="reqn">(x/\sigma)</code>
where a log link is used to relate <code class="reqn">\sigma</code> to the covariates,
<code class="reqn">\sigma=exp(\theta*w)</code>. A CDS function is obtained with a constant
<code class="reqn">\sigma</code> which is equivalent to an intercept  design matrix, z.
</p>
<p><code>detfct</code> will call either a gamma, half-normal, hazard-rate or uniform
function only returning the probability of detection at that distance. In
addition to the simple model above, we may specify adjustment terms to fit
the data better. These adjustments are either Cosine, Hermite and simple
polynomials. These are specified as arguments to <code>detfct</code>, as detailed
below.
</p>
<p><code>detfct</code> function which calls the others and assembles the final result
using either key(x)[1+series(x)] or
(key(x)[1+series(x)])/(key(0)[1+series(0)]) (depending on the value of
<code>standardize</code>).
</p>
<p><code>keyfct.*</code> functions calculate key function values and <code>adjfct.*</code>
calculate adjustment term values.
</p>
<p><code>scalevalue</code> for either detection function it computes the scale with
the log link using the parameters and the covariate design matrix
</p>
<p><code>fx</code>, <code>fr</code> non-normalized probability density for line transects
and point counts respectively
</p>


<h3>Value</h3>

<p>For <code>detfct</code>, the value is a vector of detection probabilities
For <code>keyfct.*</code>, vector of key function evaluations
For <code>adjfct.*</code>, vector of adjustment series evaluations
For <code>scalevalue</code>, vector of the scale parameters.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>


<h3>References</h3>

<p>Marques, F. F. C., &amp; Buckland, S. T. (2003). Incorporating covariates into
standard line transect analyses. Biometrics, 59(4), 924-935.
</p>
<p>Buckland, S. T., Anderson, D. R., Burnham, K. P., Laake, J. L., Borchers, D.
L., &amp; Thomas, L. (2004). Advanced Distance Sampling. Oxford University
Press, Oxford, UK.
</p>
<p>Becker, E. F. and P. X. Quang. 2009. A gamma-shaped detection function for
line transect surveys with mark-recapture and covariate data. Journal of
Agricultural Biological and Environmental Statistics 14:207-223.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mcds">mcds</a></code>,  <code><a href="#topic+cds">cds</a></code>
</p>

<hr>
<h2 id='ds.function'>Distance Sampling Functions</h2><span id='topic+ds.function'></span>

<h3>Description</h3>

<p>Computes values of conditional and unconditional detection functions and
probability density functions for for line/point data for single observer or
dual observer in any of the 3 configurations (io,trial,rem).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ds.function(
  model,
  newdata = NULL,
  obs = "All",
  conditional = FALSE,
  pdf = TRUE,
  finebr
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds.function_+3A_model">model</code></td>
<td>
<p>model object</p>
</td></tr>
<tr><td><code id="ds.function_+3A_newdata">newdata</code></td>
<td>
<p>dataframe at which to compute values; if NULL uses fitting data</p>
</td></tr>
<tr><td><code id="ds.function_+3A_obs">obs</code></td>
<td>
<p>1 or 2 for observer 1 or 2, 3 for duplicates, &quot;.&quot; for combined
and &quot;All&quot; to return all of the values</p>
</td></tr>
<tr><td><code id="ds.function_+3A_conditional">conditional</code></td>
<td>
<p>if FALSE, computes p(x) based on distance detection
function and if TRUE based on mr detection function</p>
</td></tr>
<tr><td><code id="ds.function_+3A_pdf">pdf</code></td>
<td>
<p>if FALSE, returns p(x) and if TRUE, returns p(x)*pi(x)/integral
p(x)*pi(x)</p>
</td></tr>
<tr><td><code id="ds.function_+3A_finebr">finebr</code></td>
<td>
<p>fine break values over which line is averaged</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Placeholder &ndash; Not functional &mdash;-
</p>


<h3>Value</h3>

<p>List containing </p>
<table>
<tr><td><code>xgrid</code></td>
<td>
<p>grid of distance values</p>
</td></tr>
<tr><td><code>values</code></td>
<td>
<p>average detection fct values at the xgrid values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='flnl'>Log-likelihood computation for distance sampling data</h2><span id='topic+flnl'></span><span id='topic+flpt.lnl'></span>

<h3>Description</h3>

<p>For a specific set of parameter values, it computes and returns the negative
log-likelihood for the distance sampling likelihood for distances that are
unbinned, binned and a mixture of both.  The function <code>flnl</code> is the
function minimized using <code><a href="stats.html#topic+optim">optim</a></code> from within
<code><a href="#topic+ddf.ds">ddf.ds</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flnl(fpar, ddfobj, misc.options, fitting = "all")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flnl_+3A_fpar">fpar</code></td>
<td>
<p>parameter values for detection function at which negative
log-likelihood should be evaluated</p>
</td></tr>
<tr><td><code id="flnl_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance sampling object</p>
</td></tr>
<tr><td><code id="flnl_+3A_misc.options">misc.options</code></td>
<td>
<p>a <code>list</code> with the following elements: <code>width</code>
transect width; <code>int.range</code> the integration range for observations;
<code>showit</code> 0 to 3 controls level debug output; <code>integral.numeric</code> if
<code>TRUE</code> integral is computed numerically rather than analytically;
<code>point</code> is this a point transect?</p>
</td></tr>
<tr><td><code id="flnl_+3A_fitting">fitting</code></td>
<td>
<p>character <code>"key"</code> if only fitting key function
parameters, <code>"adjust"</code> if fitting adjustment parameters or <code>"all"</code>
to fit both</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most of the computation is in <code>flpt.lnl</code> in which the negative
log-likelihood is computed for each observation. <code>flnl</code> is a wrapper
that optionally outputs intermediate results and sums the individual
log-likelihood values.
</p>
<p><code>flnl</code> is the main routine that manipulates the parameters using
<code><a href="#topic+getpar">getpar</a></code> to handle fitting of key, adjustment or all of the
parameters.  It then calls <code>flpt.lnl</code> to do the actual computation of
the likelihood.  The probability density function for point counts is
<code>fr</code> and for line transects is <code>fx</code>.
<code>fx</code>=g(x)/mu (where g(x) is the detection function); whereas,
f(r)=r*g(r)/mu where mu in both cases is the normalizing constant.  Both
functions are in source code file for <code>link{detfct}</code> and are called from
<code>distpdf</code> and the integral calculations are made with
<code><a href="#topic+integratepdf">integratepdf</a></code>.
</p>


<h3>Value</h3>

<p>negative log-likelihood value at the parameter values specified in
<code>fpar</code>
</p>


<h3>Note</h3>

<p>These are internal functions used by <code><a href="#topic+ddf.ds">ddf.ds</a></code> to fit
distance sampling detection functions.  It is not intended for the user to
invoke these functions but they are documented here for completeness.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flt.var">flt.var</a></code>, <code><a href="#topic+detfct">detfct</a></code>
</p>

<hr>
<h2 id='flt.var'>Hessian computation for fitted distance detection function model parameters</h2><span id='topic+flt.var'></span>

<h3>Description</h3>

<p>Computes hessian to be used for variance-covariance matrix.  The hessian is
the outer product of the vector of first partials (see pg 62 of Buckland et
al 2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flt.var(ddfobj, misc.options)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flt.var_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance sampling object</p>
</td></tr>
<tr><td><code id="flt.var_+3A_misc.options">misc.options</code></td>
<td>
<p>width-transect width (W); int.range-integration range
for observations; showit-0 to 3 controls level of iteration printing;
integral.numeric-if TRUE integral is computed numerically rather
than analytically</p>
</td></tr>
</table>


<h3>Value</h3>

<p>variance-covariance matrix of parameters in the detection function
</p>


<h3>Note</h3>

<p>This is an internal function used by <code><a href="#topic+ddf.ds">ddf.ds</a></code> to fit
distance sampling detection functions.  It is not intended for the user to
invoke this function but it is documented here for completeness.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake and David L Miller
</p>


<h3>References</h3>

<p>Buckland et al. 2002
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flnl">flnl</a></code>,<code><a href="#topic+flpt.lnl">flpt.lnl</a></code>,<code><a href="#topic+ddf.ds">ddf.ds</a></code>
</p>

<hr>
<h2 id='g0'>Compute value of p(0) using a logit formulation</h2><span id='topic+g0'></span>

<h3>Description</h3>

<p>Compute value of p(0) using a logit formulation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g0(beta, z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="g0_+3A_beta">beta</code></td>
<td>
<p>logistic parameters</p>
</td></tr>
<tr><td><code id="g0_+3A_z">z</code></td>
<td>
<p>design matrix of covariate values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of p(0) values
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='getpar'>Extraction and assignment of parameters to vector</h2><span id='topic+getpar'></span>

<h3>Description</h3>

<p>Extracts parameters of a particular type (scale,
shape, adjustments or g0 (p(0))) from the vector of parameters in
<code>ddfobj</code>. All of the parameters are kept in a single vector for
optimization even though they have very different uses.  <code>assign.par</code>
parses them from the vector based on a known structure and assigns them into
<code>ddfobj</code>.  <code>getpar</code> extracts the requested types to be extracted
from <code>ddfobj</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getpar(ddfobj, fitting = "all", index = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getpar_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance sampling object (see <code><a href="#topic+create.ddfobj">create.ddfobj</a></code>)</p>
</td></tr>
<tr><td><code id="getpar_+3A_fitting">fitting</code></td>
<td>
<p>character string which is either &quot;all&quot;,&quot;key&quot;,&quot;adjust&quot; which
determines which parameters are retrieved</p>
</td></tr>
<tr><td><code id="getpar_+3A_index">index</code></td>
<td>
<p>logical that determines whether parameters are returned (FALSE)
or starting indices in parameter vector for scale, shape, adjustment
parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>index==FALSE, vector of parameters that were requested or
index==TRUE, vector of 3 indices for shape, scale, adjustment
</p>


<h3>Note</h3>

<p>Internal functions not intended to be called by user.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p>assign.par
</p>

<hr>
<h2 id='gof.ds'>Compute chi-square goodness-of-fit test for ds models</h2><span id='topic+gof.ds'></span>

<h3>Description</h3>

<p>Compute chi-square goodness-of-fit test for ds models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gof.ds(model, breaks = NULL, nc = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gof.ds_+3A_model">model</code></td>
<td>
<p><code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="gof.ds_+3A_breaks">breaks</code></td>
<td>
<p>distance cut points</p>
</td></tr>
<tr><td><code id="gof.ds_+3A_nc">nc</code></td>
<td>
<p>number of distance classes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with chi-square value, df and p-value
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p>ddf.gof
</p>

<hr>
<h2 id='gstdint'>Integral of pdf of distances</h2><span id='topic+gstdint'></span>

<h3>Description</h3>

<p>Computes the integral of <code>distpdf</code> with scale=1 (<code>stdint=TRUE</code>) or
specified scale (<code>stdint=FALSE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gstdint(
  x,
  ddfobj,
  index = NULL,
  select = NULL,
  width,
  standardize = TRUE,
  point = FALSE,
  stdint = TRUE,
  doeachint = FALSE,
  left = left
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gstdint_+3A_x">x</code></td>
<td>
<p>lower, upper value for integration</p>
</td></tr>
<tr><td><code id="gstdint_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance detection function specification</p>
</td></tr>
<tr><td><code id="gstdint_+3A_index">index</code></td>
<td>
<p>specific data row index</p>
</td></tr>
<tr><td><code id="gstdint_+3A_select">select</code></td>
<td>
<p>logical vector for selection of data values</p>
</td></tr>
<tr><td><code id="gstdint_+3A_width">width</code></td>
<td>
<p>truncation width</p>
</td></tr>
<tr><td><code id="gstdint_+3A_standardize">standardize</code></td>
<td>
<p>if <code>TRUE</code>, divide through by the function evaluated
at 0</p>
</td></tr>
<tr><td><code id="gstdint_+3A_point">point</code></td>
<td>
<p>logical to determine if point (<code>TRUE</code>) or line
transect(<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="gstdint_+3A_stdint">stdint</code></td>
<td>
<p>if <code>TRUE</code>, scale=1 otherwise specified scale used</p>
</td></tr>
<tr><td><code id="gstdint_+3A_doeachint">doeachint</code></td>
<td>
<p>if <code>TRUE</code> perform integration using
<code><a href="stats.html#topic+integrate">integrate</a></code></p>
</td></tr>
<tr><td><code id="gstdint_+3A_left">left</code></td>
<td>
<p>left truncation width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of integral values of detection function
</p>


<h3>Note</h3>

<p>This is an internal function that is not intended to be invoked
directly.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake and David L Miller
</p>

<hr>
<h2 id='histline'>Plot histogram line</h2><span id='topic+histline'></span>

<h3>Description</h3>

<p>Takes bar heights (height) and cutpoints (breaks), and constructs a
line-only histogram from them using the function plot() (if lineonly==FALSE)
or lines() (if lineonly==TRUE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>histline(
  height,
  breaks,
  lineonly = FALSE,
  outline = FALSE,
  ylim = range(height),
  xlab = "x",
  ylab = "y",
  det.plot = FALSE,
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="histline_+3A_height">height</code></td>
<td>
<p>heights of histogram bars</p>
</td></tr>
<tr><td><code id="histline_+3A_breaks">breaks</code></td>
<td>
<p>cutpoints for x</p>
</td></tr>
<tr><td><code id="histline_+3A_lineonly">lineonly</code></td>
<td>
<p>if TRUE, drawn with plot; otherwise with lines to allow
addition of current plot</p>
</td></tr>
<tr><td><code id="histline_+3A_outline">outline</code></td>
<td>
<p>if TRUE, only outline of histogram is plotted</p>
</td></tr>
<tr><td><code id="histline_+3A_ylim">ylim</code></td>
<td>
<p>limits for y axis</p>
</td></tr>
<tr><td><code id="histline_+3A_xlab">xlab</code></td>
<td>
<p>label for x axis</p>
</td></tr>
<tr><td><code id="histline_+3A_ylab">ylab</code></td>
<td>
<p>label for y axis</p>
</td></tr>
<tr><td><code id="histline_+3A_det.plot">det.plot</code></td>
<td>
<p>if TRUE, plot is of detection so yaxis limited to unit
interval</p>
</td></tr>
<tr><td><code id="histline_+3A_add">add</code></td>
<td>
<p>should this plot add to a previous window</p>
</td></tr>
<tr><td><code id="histline_+3A_...">...</code></td>
<td>
<p>Additional unspecified arguments for plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p>Jeff Laake and David L Miller
</p>

<hr>
<h2 id='integratedetfct.logistic'>Integrate a logistic detection function</h2><span id='topic+integratedetfct.logistic'></span>

<h3>Description</h3>

<p>Integrates a logistic detection function; a separate function is used because
in certain cases the integral can be solved analytically and also because
the scale trick used with the half-normal and hazard rate doesn't work
with the logistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integratedetfct.logistic(x, scalemodel, width, theta1, integral.numeric, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integratedetfct.logistic_+3A_x">x</code></td>
<td>
<p>logistic design matrix values</p>
</td></tr>
<tr><td><code id="integratedetfct.logistic_+3A_scalemodel">scalemodel</code></td>
<td>
<p>scale model for logistic</p>
</td></tr>
<tr><td><code id="integratedetfct.logistic_+3A_width">width</code></td>
<td>
<p>transect width</p>
</td></tr>
<tr><td><code id="integratedetfct.logistic_+3A_theta1">theta1</code></td>
<td>
<p>parameters for logistic</p>
</td></tr>
<tr><td><code id="integratedetfct.logistic_+3A_integral.numeric">integral.numeric</code></td>
<td>
<p>if <code>TRUE</code> computes numerical integral value</p>
</td></tr>
<tr><td><code id="integratedetfct.logistic_+3A_w">w</code></td>
<td>
<p>design covariates</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of integral values
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='integratelogistic.analytic'>Analytically integrate logistic detection function</h2><span id='topic+integratelogistic.analytic'></span>

<h3>Description</h3>

<p>Computes integral (analytically) over x from 0 to width of a logistic
detection function; For reference see integral #526 in CRC Std Math
Table 24th ed
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integratelogistic.analytic(x, models, beta, width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integratelogistic.analytic_+3A_x">x</code></td>
<td>
<p>matrix of data</p>
</td></tr>
<tr><td><code id="integratelogistic.analytic_+3A_models">models</code></td>
<td>
<p>list of model formulae</p>
</td></tr>
<tr><td><code id="integratelogistic.analytic_+3A_beta">beta</code></td>
<td>
<p>parameters of logistic detection function</p>
</td></tr>
<tr><td><code id="integratelogistic.analytic_+3A_width">width</code></td>
<td>
<p>transect half-width</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='integratepdf'>Numerically integrate pdf of observed distances over specified ranges</h2><span id='topic+integratepdf'></span>

<h3>Description</h3>

<p>Computes integral of pdf of observed distances over x for each observation.
The method of computation depends on argument switches set and the type of
detection function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integratepdf(
  ddfobj,
  select,
  width,
  int.range,
  standardize = TRUE,
  point = FALSE,
  left = 0,
  doeachint = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integratepdf_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance detection function specification</p>
</td></tr>
<tr><td><code id="integratepdf_+3A_select">select</code></td>
<td>
<p>logical vector for selection of data values</p>
</td></tr>
<tr><td><code id="integratepdf_+3A_width">width</code></td>
<td>
<p>truncation width</p>
</td></tr>
<tr><td><code id="integratepdf_+3A_int.range">int.range</code></td>
<td>
<p>integration range matrix; vector is converted to matrix</p>
</td></tr>
<tr><td><code id="integratepdf_+3A_standardize">standardize</code></td>
<td>
<p>logical used to decide whether to divide through by the
function evaluated at 0</p>
</td></tr>
<tr><td><code id="integratepdf_+3A_point">point</code></td>
<td>
<p>logical to determine if point count (<code>TRUE</code>) or line
transect (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="integratepdf_+3A_left">left</code></td>
<td>
<p>left truncation width</p>
</td></tr>
<tr><td><code id="integratepdf_+3A_doeachint">doeachint</code></td>
<td>
<p>calculate each integral numerically</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of integral values - one for each observation
</p>


<h3>Author(s)</h3>

<p>Jeff Laake &amp; Dave Miller
</p>

<hr>
<h2 id='io.glm'>Iterative offset GLM/GAM for fitting detection function</h2><span id='topic+io.glm'></span>

<h3>Description</h3>

<p>Provides an iterative algorithm for finding the MLEs of detection (capture)
probabilities for a two-occasion (double observer) mark-recapture experiment
using standard algorithms GLM/GAM and an offset to compensate for
conditioning on the set of observations.  While the likelihood can be
formulated and solved numerically, the use of GLM/GAM provides all of the
available tools for fitting, predictions, plotting etc without any further
development.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>io.glm(
  datavec,
  fitformula,
  eps = 1e-05,
  iterlimit = 500,
  GAM = FALSE,
  gamplot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="io.glm_+3A_datavec">datavec</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="io.glm_+3A_fitformula">fitformula</code></td>
<td>
<p>logit link formula</p>
</td></tr>
<tr><td><code id="io.glm_+3A_eps">eps</code></td>
<td>
<p>convergence criterion</p>
</td></tr>
<tr><td><code id="io.glm_+3A_iterlimit">iterlimit</code></td>
<td>
<p>maximum number of iterations allowed</p>
</td></tr>
<tr><td><code id="io.glm_+3A_gam">GAM</code></td>
<td>
<p>uses GAM instead of GLM for fitting</p>
</td></tr>
<tr><td><code id="io.glm_+3A_gamplot">gamplot</code></td>
<td>
<p>set to TRUE to get a gam plot object if <code>GAM=TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that currently the code in this function for GAMs has been commented
out until the remainder of the mrds package will work with GAMs.  This is an
internal function that is used as by <code>ddf.io.fi</code> to fit mark-recapture
models with 2 occasions.  The argument <code>mrmodel</code> is used for
<code>fitformula</code>.
</p>


<h3>Value</h3>

<p>list of class(&quot;ioglm&quot;,&quot;glm&quot;,&quot;lm&quot;) or class(&quot;ioglm&quot;,&quot;gam&quot;)
</p>
<table>
<tr><td><code>glmobj</code></td>
<td>
<p>GLM or GAM object</p>
</td></tr> <tr><td><code>offsetvalue</code></td>
<td>
<p>offsetvalues from
iterative fit</p>
</td></tr> <tr><td><code>plotobj</code></td>
<td>
<p>gam plot object (if GAM &amp; gamplot==TRUE,
else NULL)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake, David Borchers, Charles Paxton
</p>


<h3>References</h3>

<p>Buckland, S.T., J.M. breiwick, K.L. Cattanach, and J.L. Laake.
1993. Estimated population size of the California gray whale.  Marine
Mammal Science, 9:235-249.
</p>
<p>Burnham, K.P., S.T. Buckland, J.L. Laake, D.L. Borchers, T.A. Marques,
J.R.B. Bishop, and L. Thomas. 2004.  Further topics in distance sampling.
pp: 360-363. In: Advanced Distance Sampling, eds. S.T. Buckland,
D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas.
Oxford University Press.
</p>

<hr>
<h2 id='is.linear.logistic'>Collection of functions for logistic detection functions</h2><span id='topic+is.linear.logistic'></span>

<h3>Description</h3>

<p>These functions are used to test whether a logistic detection function is a
linear function of distance (<code>is.linear.logistic</code>) or is constant
(varies by distance but no other covariates) <code>is.logistic.constant</code>).
Based on these tests, the most appropriate manner for integrating the
detection function with respect to distance is chosen.  The integrals are
needed to estimate the average detection probability for a given set of
covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.linear.logistic(xmat, g0model, zdim, width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.linear.logistic_+3A_xmat">xmat</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="is.linear.logistic_+3A_g0model">g0model</code></td>
<td>
<p>logit model</p>
</td></tr>
<tr><td><code id="is.linear.logistic_+3A_zdim">zdim</code></td>
<td>
<p>number of columns in design matrix</p>
</td></tr>
<tr><td><code id="is.linear.logistic_+3A_width">width</code></td>
<td>
<p>transect width</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the logit is linear in distance then the integral can be computed
analytically. If the logit is constant or only varies by distance then only
one integral needs to be computed rather than an integral for each
observation.
</p>


<h3>Value</h3>

<p>Logical TRUE if condition holds and FALSE otherwise
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='is.logistic.constant'>Is a logit model constant for all observations?</h2><span id='topic+is.logistic.constant'></span>

<h3>Description</h3>

<p>Determines whether the specified logit model is constant for all
observations. If it is constant then only one integral needs to be computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.logistic.constant(xmat, g0model, width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.logistic.constant_+3A_xmat">xmat</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="is.logistic.constant_+3A_g0model">g0model</code></td>
<td>
<p>logit model</p>
</td></tr>
<tr><td><code id="is.logistic.constant_+3A_width">width</code></td>
<td>
<p>transect width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical value
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='keyfct.th1'>Threshold key function</h2><span id='topic+keyfct.th1'></span>

<h3>Description</h3>

<p>Threshold key function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keyfct.th1(distance, key.scale, key.shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keyfct.th1_+3A_distance">distance</code></td>
<td>
<p>perpendicular distance vector</p>
</td></tr>
<tr><td><code id="keyfct.th1_+3A_key.scale">key.scale</code></td>
<td>
<p>vector of scale values</p>
</td></tr>
<tr><td><code id="keyfct.th1_+3A_key.shape">key.shape</code></td>
<td>
<p>vector of shape values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of probabilities
</p>

<hr>
<h2 id='keyfct.th2'>Threshold key function</h2><span id='topic+keyfct.th2'></span>

<h3>Description</h3>

<p>Threshold key function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keyfct.th2(distance, key.scale, key.shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keyfct.th2_+3A_distance">distance</code></td>
<td>
<p>perpendicular distance vector</p>
</td></tr>
<tr><td><code id="keyfct.th2_+3A_key.scale">key.scale</code></td>
<td>
<p>vector of scale values</p>
</td></tr>
<tr><td><code id="keyfct.th2_+3A_key.shape">key.shape</code></td>
<td>
<p>vector of shape values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of probabilities
</p>

<hr>
<h2 id='keyfct.tpn'>Two-part normal key function</h2><span id='topic+keyfct.tpn'></span><span id='topic+two-part-normal'></span>

<h3>Description</h3>

<p>The two-part normal detection function of Becker and Christ (2015). Either
side of an estimated apex in the distance histogram has a half-normal
distribution, with differing scale parameters. Covariates may be included
but affect both sides of the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keyfct.tpn(distance, ddfobj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keyfct.tpn_+3A_distance">distance</code></td>
<td>
<p>perpendicular distance vector</p>
</td></tr>
<tr><td><code id="keyfct.tpn_+3A_ddfobj">ddfobj</code></td>
<td>
<p>meta object containing parameters, design matrices etc</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two-part normal models have 2 important parameters:
</p>

<ul>
<li><p> The apex, which estimates the peak in the detection function (where
g(x)=1). The log apex is reported in <code>summary</code> results, so taking the
exponential of this value should give the peak in the plotted function (see
examples).
</p>
</li>
<li><p> The parameter that controls the difference between the sides
<code>.dummy_apex_side</code>, which is automatically added to the formula for a
two-part normal model. One can add interactions with this variable as
normal, but don't need to add the main effect as it will be automatically
added.
</p>
</li></ul>



<h3>Value</h3>

<p>a vector of probabilities that the observation were detected given
they were at the specified distance and assuming that g(mu)=1
</p>


<h3>Author(s)</h3>

<p>Earl F Becker, David L Miller
</p>


<h3>References</h3>

<p>Becker, E. F., &amp; Christ, A. M. (2015). A Unimodal Model for Double Observer
Distance Sampling Surveys. PLOS ONE, 10(8), e0136403.
<a href="https://doi.org/10.1371/journal.pone.0136403">doi:10.1371/journal.pone.0136403</a>
</p>

<hr>
<h2 id='lfbcvi'>Black-capped vireo mark-recapture distance sampling analysis</h2><span id='topic+lfbcvi'></span>

<h3>Description</h3>

<p>These data represent avian point count surveys conducted at 453 point sample
survey locations on the 24,000 (approx) live-fire region of Fort Hood in
central Texas.  Surveys were conducted by independent double observers (2
per survey occasion) and as such we had a maximum of 3 paired survey
histories, giving a maximum of 6 sample occasions (see MacKenzie et al.
2006, MacKenzie and Royle 2005, and Laake et al. 2011 for various sample
survey design details).  At each point, we surveyed for 5 minutes
(technically broken into 3 time intervals of 2, 2, and 1 minutes; not used
here) and we noted detections by each observer and collected distance to
each observation within a set of distance bins (0-25, 25-50, 50-75, 75-100m)
of the target species (Black-capped vireo's in this case) for each surveyor.
Our primary focus was to use mark-recapture distance sampling methods to
estimate density of Black-capped vireo's, and to estimate detection rates
for the mark-recapture, distance, and composite model.
</p>


<h3>Format</h3>

<p>The format is a data frame with the following covariate metrics.
</p>
<dl>
<dt>PointID</dt><dd><p>Unique identifier for each sample location;
locations are the same for both species</p>
</dd>
<dt>VisitNumber</dt><dd><p>Visit number to the point</p>
</dd>
<dt>Species</dt><dd><p>Species designation, either Golden-cheeked warbler (GW) or
Black-capped Vireo (BV)</p>
</dd>
<dt>Distance</dt><dd><p>Distance measure, which is either NA (representing no
detection), or the median of the binned detection distances</p>
</dd>
<dt>PairNumber</dt><dd><p>ID value indicating which observers were paired for that
sampling occasion</p>
</dd>
<dt>Observer</dt><dd><p>Observer ID, either primary(1), or secondary (2)</p>
</dd>
<dt>Detected</dt><dd><p>Detection of a bird, either 1 = detected, or 0 = not
detected</p>
</dd>
<dt>Date</dt><dd><p>Date of survey since 15 march 2011</p>
</dd>
<dt>Pred</dt><dd><p>Predicted occupancy value for that survey hexagon based on
Farrell et al. (2013)</p>
</dd>
<dt>Category</dt><dd><p>Region.Label categorization, see <code>mrds</code> help file for
details on data structure</p>
</dd>
<dt>Effort</dt><dd><p>Amount of survey effort at the point</p>
</dd>
<dt>Day</dt><dd><p>Number of days since 15 March 2011</p>
</dd>
<dt>ObjectID</dt><dd><p>Unique ID for each paired observations</p>
</dd> </dl>



<h3>Details</h3>

<p>In addition to detailing the analysis used by Collier et al. (2013, In
Review), this example documents the use of <code>mrds</code> for avian point count
surveys and shows how density models can be incorporated with occupancy
models to develop spatially explicit density surface maps. For those that
are interested, for the distance sampling portion of our analysis, we used
both conventional distance sampling (<code>cds</code>) and multiple covariate
distance sampling (<code>mcds</code>) with uniform and half-normal key functions.
For the mark-recapture portion of our analysis, we tended to use covariates
for distance (median bin width), observer, and date of survey (days since 15
March 2011).
</p>
<p>We combined our <code>mrds</code> density estimates via a Horvitz-Thompson styled
estimator with the resource selection function gradient developed in Farrell
et al. (2013) and estimated density on an ~3.14ha hexagonal grid across our
study area, which provided a density gradient for the Fort Hood military
installation.  Because there was considerable data manipulation needed for
each analysis to structure the data appropriately for use in <code>mrds</code>,
rather than wrap each analysis in a single function, we have provided both
the Golden-cheeked warbler and Black-capped vireo analyses in their full
detail.  The primary differences you will see will be changes to model
structures and model outputs between the two species.
</p>


<h3>Author(s)</h3>

<p>Bret Collier and Jeff Laake
</p>


<h3>References</h3>

<p>Farrell, S.F., B.A. Collier, K.L. Skow, A.M. Long, A.J.
Campomizzi, M.L. Morrison, B. Hays, and R.N. Wilkins. 2013. Using
LiDAR-derived structural vegetation characteristics to develop
high-resolution, small-scale, species distribution models for conservation
planning. Ecosphere 43(3): 42. http://dx.doi.org/10.1890/ES12-000352.1
</p>
<p>Laake, J.L., B.A. Collier, M.L. Morrison, and R.N. Wilkins.
2011. Point-based mark recapture distance sampling. Journal of Agricultural,
Biological and Environmental Statistics 16: 389-408.
</p>
<p>Collier, B.A., S.L. Farrell, K.L. Skow, A. M. Long, A.J.
Campomizzi, K.B. Hays, J.L. Laake, M.L. Morrison, and R.N. Wilkins. 2013.
Spatially explicit density of
endangered avian species in a disturbed landscape.  Auk, In Review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(lfbcvi)
xy=cut(lfbcvi$Pred, c(-0.0001, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1),
  labels=c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))
x=data.frame(lfbcvi, New=xy)

# Note that I scaled the individual covariate of day-helps with
# convergence issues
bird.data &lt;- data.frame(object=x$ObjectID, observer=x$Observer,
                        detected=x$Detected, distance=x$Distance,
                        Region.Label=x$New, Sample.Label=x$PointID,
                        Day=(x$Day/max(x$Day)))

# make observer a factor variable
bird.data$observer=factor(bird.data$observer)

# Jeff Laake suggested this snippet to quickly create distance medians
# which adds bin information to the bird.data dataframe

bird.data$distbegin=0
bird.data$distend=100
bird.data$distend[bird.data$distance==12.5]=25
bird.data$distbegin[bird.data$distance==37.5]=25
bird.data$distend[bird.data$distance==37.5]=50
bird.data$distbegin[bird.data$distance==62.5]=50
bird.data$distend[bird.data$distance==62.5]=75
bird.data$distbegin[bird.data$distance==87.5]=75
bird.data$distend[bird.data$distance==87.5]=100

# Removed all survey points with distance=NA for a survey event;
# hence no observations for use in ddf() but needed later
bird.data=bird.data[complete.cases(bird.data),]

# Manipulations on full dataset for various data.frame creation for
# use in density estimation using dht()

#Samples dataframe
xx=x
x=data.frame(PointID=x$PointID, Species=x$Species,
             Category=x$New, Effort=x$Effort)
x=x[!duplicated(x$PointID),]
point.num=table(x$Category)
samples=data.frame(PointID=x$PointID, Region.Label=x$Category,
                   Effort=x$Effort)
final.samples=data.frame(Sample.Label=samples$PointID,
                         Region.Label=samples$Region.Label,
                         Effort=samples$Effort)

#obs dataframe
obs=data.frame(ObjectID=xx$ObjectID, PointID=xx$PointID)
#used to get Region and Sample assigned to ObjectID
obs=merge(obs, samples, by=c("PointID", "PointID"))
obs=obs[!duplicated(obs$ObjectID),]
obs=data.frame(object=obs$ObjectID, Region.Label=obs$Region.Label,
               Sample.Label=obs$PointID)

region.data=data.frame(Region.Label=c(1, 2, 3,4,5,6,7,8,9, 10),
Area=c(point.num[1]*3.14, point.num[2]*3.14,
       point.num[3]*3.14, point.num[4]*3.14,
       point.num[5]*3.14, point.num[6]*3.14,
       point.num[7]*3.14, point.num[8]*3.14,
       point.num[9]*3.14, point.num[10]*3.14))

# Candidate Models

BV1=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
BV1FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
BV2=ddf(
   dsmodel=~mcds(key="hr",formula=~1),
   mrmodel=~glm(~distance),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
BV3=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance+observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV3FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance+observer),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV4=ddf(
   dsmodel=~mcds(key="hr",formula=~1),
   mrmodel=~glm(~distance+observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV5=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV5FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV6=ddf(
   dsmodel=~mcds(key="hr",formula=~1),
   mrmodel=~glm(~distance*observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV7=ddf(
   dsmodel=~cds(key="hn",formula=~1),
   mrmodel=~glm(~distance*Day),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV7FI=ddf(
   dsmodel=~cds(key="hn",formula=~1),
   mrmodel=~glm(~distance*Day),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV8=ddf(
   dsmodel=~cds(key="hr",formula=~1),
   mrmodel=~glm(~distance*Day),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV9=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer*Day),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV9FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer*Day),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
BV10=ddf(
   dsmodel=~mcds(key="hr",formula=~1),
   mrmodel=~glm(~distance*observer*Day),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
#BV.DS=ddf(
#    dsmodel=~mcds(key="hn",formula=~1),
#    data=bird.data,
#    method="ds",
#    meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))

#AIC table building code.
AIC = c(BV1$criterion, BV1FI$criterion, BV2$criterion, BV3$criterion,
        BV3FI$criterion, BV4$criterion,  BV5$criterion, BV5FI$criterion,
        BV6$criterion, BV7$criterion, BV7FI$criterion, BV8$criterion,
        BV9$criterion, BV9FI$criterion, BV10$criterion)

#creates a set of row names for me to check my grep() call below
rn = c("BV1", "BV1FI", "BV2", "BV3",  "BV3FI", "BV4", "BV5", "BV5FI",
       "BV6", "BV7", "BV7FI", "BV8", "BV9", "BV9FI", "BV10")

#Number parameters
k = c(length(BV1$par), length(BV1FI$par), length(BV2$par),
      length(BV3$par), length(BV3FI$par), length(BV4$par),
      length(BV5$par),length(BV5FI$par), length(BV6$par),
      length(BV7$par), length(BV7FI$par), length(BV8$par),

#build AIC table
AIC.table=data.frame(AIC = AIC, rn=rn, k=k, dAIC = abs(min(AIC)-AIC) ,
                     likg=exp(-.5*(abs(min(AIC)-AIC))))
#row.names(AIC.table)=grep("BV", ls(), value=TRUE)
AIC.table=AIC.table[with(AIC.table, order(-likg, -dAIC, AIC, k)),]
AIC.table=data.frame(AIC.table, wi=AIC.table$likg/sum(AIC.table$likg))
AIC.table

# Model average N_hat_covered estimates
#  not very clean, but I wanted to show full process, need to use
#  collect.models and model.table here later on
estimate &lt;- c(BV1$Nhat, BV1FI$Nhat, BV2$Nhat, BV3$Nhat, BV3FI$Nhat,
              BV4$Nhat,  BV5$Nhat, BV5FI$Nhat, BV6$Nhat, BV7$Nhat,
              BV7FI$Nhat, BV8$Nhat, BV9$Nhat, BV9FI$Nhat, BV10$Nhat)

AIC.values=AIC

# had to use str() to extract here as Nhat.se is calculated in
# mrds:::summary.io, not in ddf(), so it takes a bit
std.err &lt;- c(summary(BV1)$Nhat.se, summary(BV1FI)$Nhat.se,
             summary(BV2)$Nhat.se, summary(BV3)$Nhat.se,
             summary(BV3FI)$Nhat.se, summary(BV4)$Nhat.se,
             summary(BV5)$Nhat.se, summary(BV5FI)$Nhat.se,
             summary(BV6)$Nhat.se, summary(BV7)$Nhat.se,
             summary(BV7FI)$Nhat.se,summary(BV8)$Nhat.se,
             summary(BV9)$Nhat.se, summary(BV9FI)$Nhat.se,
             summary(BV10)$Nhat.se)

## End(Not run)

## Not run: 
#Not Run
#requires RMark
library(RMark)
#uses model.average structure to model average real abundance estimates for
#covered area of the surveys
  mmi.list=list(estimate=estimate, AIC=AIC.values, se=std.err)
  model.average(mmi.list, revised=TRUE)

#Not Run
#Summary for the top 2 models
 #summary(BV5, se=TRUE)
 #summary(BV5FI, se=TRUE)

#Not Run
#Best Model
 #best.model=AIC.table[1,]

#Not Run
#GOF for models
#ddf.gof(BV5, breaks=c(0, 25, 50, 75, 100))

#Not Run
#Density estimation across occupancy categories
#out.BV=dht(BV5, region.data, final.samples, obs, se=TRUE,
#           options=list(convert.units=.01))

#Plot--Not Run

#Composite Detection Function
#plot(BV5, which=3, showpoints=FALSE, angle=0, density=0, col="black", lwd=3,
# main="Black-capped Vireo",xlab="Distance (m)", las=1, cex.axis=1.25,
# cex.lab=1.25)


## End(Not run)

</code></pre>

<hr>
<h2 id='lfgcwa'>Golden-cheeked warbler mark-recapture distance sampling analysis</h2><span id='topic+lfgcwa'></span>

<h3>Description</h3>

<p>These data represent avian point count surveys conducted at 453 point sample
survey locations on the 24,000 (approx) live-fire region of Fort Hood in
central Texas.  Surveys were conducted by independent double observers (2
per survey occasion) and as such we had a maximum of 3 paired survey
histories, giving a maximum of 6 sample occasions (see MacKenzie et al.
2006, MacKenzie and Royle 2005, and Laake et al. 2011 for various sample
survey design details).  At each point, we surveyed for 5 minutes
(technically broken into 3 time intervals of 2, 2, and 1 minutes; not used
here) and we noted detections by each observer and collected distance to
each observation within a set of distance bins (0-50, 50-100m; Laake et al.
2011) of the target species (Golden-cheeked warblers in this case) for each
surveyor.  Our primary focus was to use mark-recapture distance sampling
methods to estimate density of Golden-cheeked warblers, and to estimate
detection rates for the mark-recapture, distance, and composite model.
</p>


<h3>Format</h3>

<p>The format is a data frame with the following covariate metrics.
</p>
<dl>
<dt>PointID</dt><dd><p>Unique identifier for each sample location;
locations are the same for both species</p>
</dd>
<dt>VisitNumber</dt><dd><p>Visit number to the point</p>
</dd>
<dt>Species</dt><dd><p>Species designation, either Golden-cheeked warbler (GW) or
Black-capped Vireo (BV)</p>
</dd>
<dt>Distance</dt><dd><p>Distance measure, which is either NA (representing no
detection), or the median of the binned detection distances</p>
</dd>
<dt>PairNumber</dt><dd><p>ID value indicating which observers were paired for that
sampling occasion</p>
</dd>
<dt>Observer</dt><dd><p>Observer ID, either primary(1), or secondary (2)</p>
</dd>
<dt>Detected</dt><dd><p>Detection of a bird, either 1 = detected, or 0 = not
detected</p>
</dd>
<dt>Date</dt><dd><p>Date of survey since 15 March 2011, numeric value</p>
</dd>
<dt>Pred</dt><dd><p>Predicted occupancy value for that survey hexagon based on
Farrell et al. (2013)</p>
</dd>
<dt>Category</dt><dd><p>Region.Label categorization, see R package <code>mrds</code> help
file for details on data structure</p>
</dd>
<dt>Effort</dt><dd><p>Amount of survey effort at the point</p>
</dd>
<dt>Day</dt><dd><p>Number of days since 15 March 2011, numeric value</p>
</dd>
<dt>ObjectID</dt><dd><p>Unique ID for each paired observations</p>
</dd> </dl>



<h3>Details</h3>

<p>In addition to detailing the analysis used by Collier et al.
(2013, In Review), this example documents the use of <code>mrds</code> for avian
point count surveys and shows how density models can be incorporated with
occupancy models to develop spatially explicit density surface maps. For
those that are interested, for the distance sampling portion of our
analysis, we used both conventional distance sampling (<code>cds</code>) and
multiple covariate distance sampling (<code>mcds</code>) with uniform and
half-normal key functions.  For the mark-recapture portion of our analysis,
we tended to use covariates for distance (median bin width), observer, and
date of survey (days since 15 March 2011).
</p>
<p>We combined our <code>mrds</code> density estimates via a Horvitz-Thompson styled
estimator with the resource selection function gradient developed in Farrell
et al. (2013) and estimated density on an ~3.14ha hexagonal grid across our
study area, which provided a density gradient for Fort Hood.  Because there
was considerable data manipulation needed for each analysis to structure the
data appropriately for use in <code>mrds</code>, rather than wrap each analysis in
a single function, we have provided both the Golden-cheeked warbler and
Black-capped vireo analyses in their full detail.  The primary differences
you will see will be changes to model structures and model outputs between
the two species.
</p>


<h3>Author(s)</h3>

<p>Bret Collier and Jeff Laake
</p>


<h3>References</h3>

<p>Farrell, S.F., B.A. Collier, K.L. Skow, A.M. Long, A.J.
Campomizzi, M.L. Morrison, B. Hays, and R.N. Wilkins. 2013. Using
LiDAR-derived structural vegetation characteristics to develop
high-resolution, small-scale, species distribution models for conservation
planning. Ecosphere 43(3): 42. http://dx.doi.org/10.1890/ES12-000352.1
</p>
<p>Laake, J.L., B.A. Collier, M.L. Morrison, and R.N. Wilkins.
2011. Point-based mark recapture distance sampling. Journal of Agricultural,
Biological and Environmental Statistics 16: 389-408.
</p>
<p>Collier, B.A., S.L. Farrell, K.L. Skow, A.M. Long, A.J.
Campomizzi, K.B. Hays, J.L. Laake, M.L. Morrison, and R.N. Wilkins. 2013.
Spatially explicit density of endangered avian species in a disturbed
landscape.  Auk, In Review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(lfgcwa)
xy &lt;- cut(lfgcwa$Pred, c(-0.0001, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1),
 labels=c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))
x &lt;- data.frame(lfgcwa, New=xy)

# Note that I scaled the individual covariate of day-helps with
# convergence issues
bird.data &lt;- data.frame(object=x$ObjectID, observer=x$Observer,
                        detected=x$Detected, distance=x$Distance,
                        Region.Label=x$New, Sample.Label=x$PointID,
                        Day=(x$Day/max(x$Day)))

# make observer a factor variable
bird.data$observer=factor(bird.data$observer)

# Jeff Laake suggested this snippet to quickly create distance medians
# which adds bin information to the \code{bird.data} dataframe

bird.data$distbegin=0
bird.data$distend=100
bird.data$distend[bird.data$distance==12.5]=50
bird.data$distbegin[bird.data$distance==37.5]=0
bird.data$distend[bird.data$distance==37.5]=50
bird.data$distbegin[bird.data$distance==62.5]=50
bird.data$distend[bird.data$distance==62.5]=100
bird.data$distbegin[bird.data$distance==87.5]=50
bird.data$distend[bird.data$distance==87.5]=100

# Removed all survey points with distance=NA for a survey event;
# hence no observations for use in \code{ddf()} but needed later
bird.data=bird.data[complete.cases(bird.data),]

# Manipulations on full dataset for various data.frame creation
# for use in density estimation using \code{dht()}

# Samples dataframe
xx &lt;- x
x &lt;- data.frame(PointID=x$PointID, Species=x$Species,
                Category=x$New, Effort=x$Effort)
x &lt;- x[!duplicated(x$PointID),]
point.num &lt;- table(x$Category)
samples &lt;- data.frame(PointID=x$PointID, Region.Label=x$Category,
                      Effort=x$Effort)
final.samples=data.frame(Sample.Label=samples$PointID,
                         Region.Label=samples$Region.Label,
                         Effort=samples$Effort)

# obs dataframe
obs &lt;- data.frame(ObjectID=xx$ObjectID, PointID=xx$PointID)
# used to get Region and Sample assigned to ObjectID
obs &lt;- merge(obs, samples, by=c("PointID", "PointID"))
obs &lt;- obs[!duplicated(obs$ObjectID),]
obs &lt;- data.frame(object=obs$ObjectID, Region.Label=obs$Region.Label,
                  Sample.Label=obs$PointID)

#Region.Label dataframe
region.data &lt;- data.frame(Region.Label=c(1,2,3,4,5,6,7,8,9),
                          Area=c(point.num[1]*3.14,
                                 point.num[2]*3.14,
                                 point.num[3]*3.14,
                                 point.num[4]*3.14,
                                 point.num[5]*3.14,
                                 point.num[6]*3.14,
                                 point.num[7]*3.14,
                                 point.num[8]*3.14,
                                 point.num[9]*3.14))

# Candidate Models

GW1=ddf(
   dsmodel=~cds(key="unif", adj.series="cos", adj.order=1,adj.scale="width"),
   mrmodel=~glm(~distance),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
GW2=ddf(
   dsmodel=~cds(key="unif", adj.series="cos", adj.order=1,adj.scale="width"),
   mrmodel=~glm(~distance+observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
GW3=ddf(
   dsmodel=~cds(key="unif", adj.series="cos", adj.order=1,adj.scale="width"),
   mrmodel=~glm(~distance*observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
GW4=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
GW4FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE,point=TRUE,width=100,breaks=c(0,50,100)))
GW5=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance+observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
GW5FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance+observer),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
GW6=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
GW6FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
GW7=ddf(
   dsmodel=~cds(key="hn",formula=~1),
   mrmodel=~glm(~distance*Day),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
GW7FI=ddf(
   dsmodel=~cds(key="hn",formula=~1),
   mrmodel=~glm(~distance*Day),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
GW8=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer*Day),
   data=bird.data,
   method="io",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
GW8FI=ddf(
   dsmodel=~mcds(key="hn",formula=~1),
   mrmodel=~glm(~distance*observer*Day),
   data=bird.data,
   method="io.fi",
   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))
#GWDS=ddf(
#   dsmodel=~mcds(key="hn",formula=~1),
#   data=bird.data,
#   method="ds",
#   meta.data=list(binned=TRUE, point=TRUE, width=100,breaks=c(0,50,100)))



#### GCWA Summary Metrics

#AIC table building code, not exactly elegant, but I did not
want to add more package dependencies
AIC = c(GW1$criterion, GW2$criterion, GW3$criterion, GW4$criterion,
        GW4FI$criterion, GW5$criterion, GW5FI$criterion,
        GW6$criterion, GW6FI$criterion, GW7$criterion, GW7FI$criterion,
        GW8$criterion, GW8FI$criterion)

#creates a set of row names for me to check my grep() call below
rn &lt;- c("GW1", "GW2", "GW3", "GW4", "GW4FI", "GW5", "GW5FI", "GW6",
        "GW6FI", "GW7","GW7FI", "GW8", "GW8FI")

# number of parameters for each model
k &lt;- c(length(GW1$par), length(GW2$par), length(GW3$par), length(GW4$par),
       length(GW4FI$par), length(GW5$par), length(GW5FI$par),
       length(GW6$par), length(GW6FI$par), length(GW7$par),
       length(GW7FI$par), length(GW8$par), length(GW8FI$par))

# build AIC table and
AIC.table &lt;- data.frame(AIC = AIC, rn=rn, k=k, dAIC = abs(min(AIC)-AIC),
                        likg = exp(-.5*(abs(min(AIC)-AIC))))
# row.names(AIC.table)=grep("GW", ls(), value=TRUE)
AIC.table &lt;- AIC.table[with(AIC.table, order(-likg, -dAIC, AIC, k)),]
AIC.table &lt;- data.frame(AIC.table, wi=AIC.table$likg/sum(AIC.table$likg))
AIC.table

# Model average N_hat_covered estimates
# not very clean, but I wanted to show full process, need to use
# collect.models and model.table here

estimate &lt;- c(GW1$Nhat, GW2$Nhat, GW3$Nhat, GW4$Nhat, GW4FI$Nhat,
              GW5$Nhat, GW5FI$Nhat, GW6$Nhat, GW6FI$Nhat, GW7$Nhat,
              GW7FI$Nhat, GW8$Nhat, GW8FI$Nhat)
AIC.values &lt;- AIC

# Nhat.se is calculated in mrds:::summary.io, not in ddf(), so
# it takes a bit to pull out
std.err &lt;- c(summary(GW1)$Nhat.se, summary(GW2)$Nhat.se,
             summary(GW3)$Nhat.se,summary(GW4)$Nhat.se,
             summary(GW4FI)$Nhat.se, summary(GW5)$Nhat.se,
             summary(GW5FI)$Nhat.se, summary(GW6)$Nhat.se,
             summary(GW6FI)$Nhat.se, summary(GW7)$Nhat.se,
             summary(GW7FI)$Nhat.se,summary(GW8)$Nhat.se,
             summary(GW8FI)$Nhat.se)

## End(Not run)
## Not run: 
#Not Run
#requires RMark
library(RMark)
#uses model.average structure to model average real abundance estimates for
#covered area of the surveys
mmi.list=list(estimate=estimate, AIC=AIC.values, se=std.err)
model.average(mmi.list, revised=TRUE)

#Not Run
#Best Model FI
#best.modelFI=AIC.table[1,]
#best.model
#Best Model PI
#best.modelPI=AIC.table[2,]
#best.modelPI

#Not Run
#summary(GW7FI, se=TRUE)
#summary(GW7, se=TRUE)

#Not Run
#GOF for models
#ddf.gof(GW7, breaks=c(0,50,100))

#Not Run
#Density estimation across occupancy categories
#out.GW=dht(GW7, region.data, final.samples, obs, se=TRUE,
           options=list(convert.units=.01))

#Plots--Not Run
#Composite Detection Function examples
#plot(GW7, which=3, showpoints=FALSE, angle=0, density=0,
#     col="black", lwd=3, main="Golden-cheeked Warbler",
#     xlab="Distance (m)", las=1, cex.axis=1.25, cex.lab=1.25)

#Conditional Detection Function
#dd=expand.grid(distance=0:100,Day=(4:82)/82)
#dmat=model.matrix(~distance*Day,dd)
#dd$p=plogis(model.matrix(~distance*Day,dd)%*%coef(GW7$mr)$estimate)
#dd$Day=dd$Day*82
#with(dd[dd$Day==12,],plot(distance,p,ylim=c(0,1), las=1,
# ylab="Detection probability", xlab="Distance (m)",
#  type="l",lty=1, lwd=3, bty="l", cex.axis=1.5, cex.lab=1.5))
#with(dd[dd$Day==65,],lines(distance,p,lty=2, lwd=3))
#ch=paste(bird.data$detected[bird.data$observer==1],
#         bird.data$detected[bird.data$observer==2],
#         sep="")
#tab=table(ch,cut(82*bird.data$Day[bird.data$observer==1],c(0,45,83)),
# cut(bird.data$distance[bird.data$observer==1],c(0,50,100)))
#tabmat=cbind(colMeans(rbind(tab[3,,1]/colSums(tab[2:3,,1],
#                            tab[3,,1]/colSums(tab[c(1,3),,1])))),
#             colMeans(rbind(tab[3,,2]/colSums(tab[2:3,,2],
#                            tab[3,,2]/colSums(tab[c(1,3),,2])))))
#colnames(tabmat)=c("0-50","51-100")
#points(c(25,75),tabmat[1,],pch=1, cex=1.5)
#points(c(25,75),tabmat[2,],pch=2, cex=1.5)

# Another alternative plot using barplot instead of points
# (this is one in paper)

#ch=paste(bird.data$detected[bird.data$observer==1],
#         bird.data$detected[bird.data$observer==2],
#sep="")
#tab=table(ch,cut(82*bird.data$Day[bird.data$observer==1],c(0,45,83)),
# cut(bird.data$distance[bird.data$observer==1],c(0,50,100)))
#tabmat=cbind(colMeans(rbind(tab[3,,1]/colSums(tab[2:3,,1],
#                            tab[3,,1]/colSums(tab[c(1,3),,1])))),
#colMeans(rbind(tab[3,,2]/colSums(tab[2:3,,2],
#               tab[3,,2]/colSums(tab[c(1,3),,2])))))
#colnames(tabmat)=c("0-50","51-100")
#par(mfrow=c(2, 1), mai=c(1,1,1,1))
#with(dd[dd$Day==12,],
#     plot(distance,p,ylim=c(0,1), las=1,
#          ylab="Detection probability", xlab="",
#          type="l",lty=1, lwd=4, bty="l", cex.axis=1.5, cex.lab=1.5))
#segments(0, 0, .0, tabmat[1,1], lwd=3)
#segments(0, tabmat[1,1], 50, tabmat[1,1], lwd=4)
#segments(50, tabmat[1,1], 50, 0, lwd=4)
#segments(50, tabmat[1,2], 100, tabmat[1,2], lwd=4)
#segments(0, tabmat[1,1], 50, tabmat[1,1], lwd=4)
#segments(100, tabmat[1,2], 100, 0, lwd=4)
#mtext("a",line=-1, at=90)
#with(dd[dd$Day==65,],
#     plot(distance,p,ylim=c(0,1), las=1, ylab="Detection probability",
#          xlab="Distance", type="l",lty=1,
#          lwd=4, bty="l", cex.axis=1.5, cex.lab=1.5))
#segments(0, 0, .0, tabmat[2,1], lwd=4)
#segments(0, tabmat[2,1], 50, tabmat[2,1], lwd=4)
#segments(50, tabmat[2,1], 50, 0, lwd=4)
#segments(50, tabmat[2,2], 50, tabmat[2,1], lwd=4)
#segments(50, tabmat[2,2], 100, tabmat[2,2], lwd=4)
#segments(100, tabmat[2,2], 100, 0, lwd=4)
#mtext("b",line=-1, at=90)

## End(Not run)

</code></pre>

<hr>
<h2 id='logisticbyx'>Logistic as a function of covariates</h2><span id='topic+logisticbyx'></span>

<h3>Description</h3>

<p>treats logistic as a function of covariates; for a given covariate
combination it computes function at with those covariate values at a
range of distances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisticbyx(distance, x, models, beta, point)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logisticbyx_+3A_distance">distance</code></td>
<td>
<p>vector of distance values</p>
</td></tr>
<tr><td><code id="logisticbyx_+3A_x">x</code></td>
<td>
<p>covariate data</p>
</td></tr>
<tr><td><code id="logisticbyx_+3A_models">models</code></td>
<td>
<p>model list</p>
</td></tr>
<tr><td><code id="logisticbyx_+3A_beta">beta</code></td>
<td>
<p>logistic parameters</p>
</td></tr>
<tr><td><code id="logisticbyx_+3A_point">point</code></td>
<td>
<p><code>TRUE</code> if a point transect model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of probabilities
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='logisticbyz'>Logistic as a function of distance</h2><span id='topic+logisticbyz'></span>

<h3>Description</h3>

<p>Treats logistic as a function of distance; for a given distance it computes
function at all covariate values in data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisticbyz(x, distance, models, beta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logisticbyz_+3A_x">x</code></td>
<td>
<p>covariate data</p>
</td></tr>
<tr><td><code id="logisticbyz_+3A_distance">distance</code></td>
<td>
<p>single distance value</p>
</td></tr>
<tr><td><code id="logisticbyz_+3A_models">models</code></td>
<td>
<p>model list</p>
</td></tr>
<tr><td><code id="logisticbyz_+3A_beta">beta</code></td>
<td>
<p>logistic parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of probabilities
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='logisticdetfct'>Logistic detection function</h2><span id='topic+logisticdetfct'></span>

<h3>Description</h3>

<p>Logistic detection function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisticdetfct(distance, theta, w, std = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logisticdetfct_+3A_distance">distance</code></td>
<td>
<p>perpendicular distance vector</p>
</td></tr>
<tr><td><code id="logisticdetfct_+3A_theta">theta</code></td>
<td>
<p>scale parameters</p>
</td></tr>
<tr><td><code id="logisticdetfct_+3A_w">w</code></td>
<td>
<p>scale covariate matrix</p>
</td></tr>
<tr><td><code id="logisticdetfct_+3A_std">std</code></td>
<td>
<p>if TRUE uses scale=1
</p>
<p>The routine returns a vector of probabilities that the observation
were detected given they were at the specified distance and assuming that
g(0)=1 (ie a standard line transect detection function).</p>
</td></tr>
</table>

<hr>
<h2 id='logisticdupbyx'>Logistic for duplicates as a function of covariates</h2><span id='topic+logisticdupbyx'></span>

<h3>Description</h3>

<p>Treats logistic for duplicates as a function of covariate z; for a given z
it computes the function at with those covariate values at a range of
distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisticdupbyx(distance, x1, x2, models, beta, point)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logisticdupbyx_+3A_distance">distance</code></td>
<td>
<p>vector of distance values</p>
</td></tr>
<tr><td><code id="logisticdupbyx_+3A_x1">x1</code></td>
<td>
<p>covariate data for fct 1</p>
</td></tr>
<tr><td><code id="logisticdupbyx_+3A_x2">x2</code></td>
<td>
<p>covariate data for fct 2</p>
</td></tr>
<tr><td><code id="logisticdupbyx_+3A_models">models</code></td>
<td>
<p>model list</p>
</td></tr>
<tr><td><code id="logisticdupbyx_+3A_beta">beta</code></td>
<td>
<p>logistic parameters</p>
</td></tr>
<tr><td><code id="logisticdupbyx_+3A_point">point</code></td>
<td>
<p><code>TRUE</code> for point transect data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of probabilities
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='logisticdupbyx_fast'>Logistic for duplicates as a function of covariates (fast)</h2><span id='topic+logisticdupbyx_fast'></span>

<h3>Description</h3>

<p>As <code><a href="#topic+logisticdupbyx">logisticdupbyx</a></code>, but faster when distance is a covariate
(but no interactions with distance occur.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logisticdupbyx_fast(distance, x1, x2, models, beta, point, beta_distance)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logisticdupbyx_fast_+3A_distance">distance</code></td>
<td>
<p>vector of distance values</p>
</td></tr>
<tr><td><code id="logisticdupbyx_fast_+3A_x1">x1</code></td>
<td>
<p>linear predictor for 1, without distance</p>
</td></tr>
<tr><td><code id="logisticdupbyx_fast_+3A_x2">x2</code></td>
<td>
<p>linear predictor for 2, without distance</p>
</td></tr>
<tr><td><code id="logisticdupbyx_fast_+3A_models">models</code></td>
<td>
<p>model list</p>
</td></tr>
<tr><td><code id="logisticdupbyx_fast_+3A_beta">beta</code></td>
<td>
<p>logistic parameters</p>
</td></tr>
<tr><td><code id="logisticdupbyx_fast_+3A_point">point</code></td>
<td>
<p><code>TRUE</code> for point transect data</p>
</td></tr>
<tr><td><code id="logisticdupbyx_fast_+3A_beta_distance">beta_distance</code></td>
<td>
<p>parameter for distance</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='logit'>Logit function</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>Computes logit transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit_+3A_p">p</code></td>
<td>
<p>probability</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code> logit(p)</code> returns [log(p/(1-p)]
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='logLik.ddf'>log-likelihood value for a fitted detection function</h2><span id='topic+logLik.ddf'></span><span id='topic+logLik.ds'></span><span id='topic+logLik.io'></span><span id='topic+logLik.io.fi'></span><span id='topic+logLik.rem'></span><span id='topic+logLik.rem.fi'></span><span id='topic+logLik.trial'></span><span id='topic+logLik.trial.fi'></span>

<h3>Description</h3>

<p>Extract the log-likelihood from a fitted detection function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ddf'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.ddf_+3A_object">object</code></td>
<td>
<p>a fitted detection function model object</p>
</td></tr>
<tr><td><code id="logLik.ddf_+3A_...">...</code></td>
<td>
<p>included for S3 completeness, but ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value giving the log-likelihood with two attributes:
<code>"df"</code> the &quot;degrees of freedom&quot; for the model (number of parameters)
and <code>"nobs"</code> the number of observations used to fit the model
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='mcds'>MCDS function definition</h2><span id='topic+mcds'></span>

<h3>Description</h3>

<p>Creates model formula list for multiple covariate distance sampling using
values supplied in call to <code><a href="#topic+ddf">ddf</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcds(
  formula = NULL,
  key = NULL,
  adj.series = NULL,
  adj.order = c(NULL),
  adj.scale = "width",
  adj.exp = FALSE,
  shape.formula = ~1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcds_+3A_formula">formula</code></td>
<td>
<p>formula for scale function</p>
</td></tr>
<tr><td><code id="mcds_+3A_key">key</code></td>
<td>
<p>string identifying key function (currently either &quot;hn&quot;
(half-normal),&quot;hr&quot; (hazard-rate), &quot;unif&quot; (uniform) or &quot;gamma&quot; (gamma
distribution)</p>
</td></tr>
<tr><td><code id="mcds_+3A_adj.series">adj.series</code></td>
<td>
<p>string identifying adjustment functions cos (Cosine), herm
(Hermite polynomials), poly (simple polynomials) or NULL</p>
</td></tr>
<tr><td><code id="mcds_+3A_adj.order">adj.order</code></td>
<td>
<p>vector of order of adjustment terms to include</p>
</td></tr>
<tr><td><code id="mcds_+3A_adj.scale">adj.scale</code></td>
<td>
<p>whether to scale the adjustment terms by &quot;width&quot; or &quot;scale&quot;</p>
</td></tr>
<tr><td><code id="mcds_+3A_adj.exp">adj.exp</code></td>
<td>
<p>if TRUE uses exp(adj) for adjustment to keep f(x)&gt;0</p>
</td></tr>
<tr><td><code id="mcds_+3A_shape.formula">shape.formula</code></td>
<td>
<p>formula for shape function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A formula list used to define the detection function model
</p>
<table>
<tr><td><code>fct</code></td>
<td>
<p>string &quot;mcds&quot;</p>
</td></tr> <tr><td><code>key</code></td>
<td>
<p>key function string</p>
</td></tr>
<tr><td><code>adj.series</code></td>
<td>
<p>adjustment function string</p>
</td></tr> <tr><td><code>adj.order</code></td>
<td>
<p>adjustment
function orders</p>
</td></tr> <tr><td><code>adj.scale</code></td>
<td>
<p>adjustment function scale type</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula for scale function</p>
</td></tr> <tr><td><code>shape.formula</code></td>
<td>
<p>formula
for shape function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake; Dave Miller
</p>

<hr>
<h2 id='MCDS.exe'>Run MCDS.exe as a backend for mrds</h2><span id='topic+MCDS.exe'></span><span id='topic+MCDS'></span><span id='topic+mcds_dot_exe'></span>

<h3>Description</h3>

<p>Rather than use the R code provided in 'mrds', one can also use the binary
of 'MCDS.exe', to reproduce the results given by Distance for Windows. There
is no guarantee that one approach is &quot;better&quot; than the other, but 'mrds'
will select the model with the better likelihood and provide answers to
this. By default (once 'MCDS.exe' is available) both 'MCDS.exe' and R will
be used to obtain detection function parameter estimates. To select only
to use the 'MCDS.exe' optimizer set <code>control=list(optimizer='MCDS')</code> 
or only use the R optimizer set <code>control=list(optimizer='R')</code>.
</p>


<h3>Details</h3>

<p>Please see our examples pages for further information: https://examples.distancesampling.org/
</p>
<p>If you are running a non-Windows operating system, you can follow the
instructions below to have 'MCDS.exe' run using 'wine'.
</p>


<h3>Obtaining MCDS.exe</h3>

<p>The following code can be used to download 'MCDS.exe' from the distance 
sampling website:
<code>download.file("http://distancesampling.org/R/MCDS.exe", paste0(system.file(package="mrds"),"/MCDS.exe"), mode = "wb")</code>
The MCDS binary will be installed to the main directory of your your local R 
mrds library. Alternatively, you can copy the 'MCDS.exe' from your local 
Distance for Windows installation if you prefer. The location of your local 
mrds library main directory can be found by running the following in R:
<code>system.file("MCDS.exe", package="mrds")</code>.
</p>


<h3>Running MCDS.exe on non-Windows platforms</h3>

<p>This has been tentatively tested on a mac but should currently be 
considered largely experimental.
</p>
<p>One can still use MCDS.exe even if you are running a mac computer. To
do this one will need to install 'wine' a Windows emulator. It is important
to use a version of 'wine' which can run 32-bit programs.
</p>
<p>The package will attempt to work out which 'wine' binary to use (and detect
if it is installed), but this doesn't always work. In this case, the
location of the 'wine' binary can be specified in the 'control' 'list'
provided to 'ddf' using the 'winebin' element or supply the 'winebin' 
argument to the 'ds' function. For example, if 'wine' is installed at 
'/usr/bin/local/wine' you can set 'control$winebin' to that
location to use that binary.
</p>
<p>On macOS, this can be achieved using the 'homebrew' package management
system and installing the 'wine-crossover' package. You may need to change
the <code>control$winebin</code> to be 'wine', 'wine64' or 'wine32on64', 
depending on your system's setup. This package tries to work out what to 
do, but likely doesn't handle all corner cases. Currently this is untested 
on Mac M1 systems.
</p>


<h3>Stopping using MCDS.exe</h3>

<p>Once this feature is enabled (see below) using 'ddf' will always run both
its built-in R optimizer and 'MCDS.exe'. To disable this behaviour remove
the 'MCDS.exe' binary file. You can find it by running the following in R:
<code>system.file("MCDS.exe", package="mrds")</code>.
</p>


<h3>Author(s)</h3>

<p>David L Miller and Jonah McArthur
</p>

<hr>
<h2 id='mrds_opt'>Tips on optimisation issues in <code>mrds</code> models</h2><span id='topic+mrds_opt'></span>

<h3>Description</h3>

<p>Occasionally when fitting an 'mrds' model one can run into optimisation
issues. In general such problems can be quite complex so these &quot;quick fixes&quot;
may not work. If you come up against problems that are not fixed by these
tips, or you feel the results are dubious please go ahead and contact the
package authors.
</p>


<h3>Debug mode</h3>

<p>One can obtain debug output at each stage of the optimisation using the
<code>showit</code> option. This is set via <code>control</code>, so adding
<code>control=list(showit=3)</code> gives the highest level of debug output
(setting <code>showit</code> to 1 or 2 gives less output).
</p>


<h3>Re-scaling covariates</h3>

<p>Sometimes convergence issues in covariate (MCDS) models are caused by values
of the covariate being very large, so a rescaling of that covariate is then
necessary. Simply scaling by the standard deviation of the covariate can
help (e.g. <code>dat$size.scaled &lt;- dat$scale/sd(dat$scale)</code> for a covariate
<code>size</code>, then including <code>size.scaled</code> in the model instead of
<code>size</code>).
</p>
<p>It is important to note that one needs to use the original covariate (size)
when computing Horvitz-Thompson estimates of population size if the group
size is used in that estimate. i.e. use the unscaled size in the numerator
of the H-T estimator.
</p>


<h3>Factor levels</h3>

<p>By default R will set the base factor level to be the label which comes
first alphabetically. Sometimes this can be an issue when that factor level
corresponds to a subset of the data with very few observations. This can
lead to very large uncertainty estimates (CVs) for model parameters. One way
around this is to use <code><a href="stats.html#topic+relevel">relevel</a></code> to set the base level to a level
with more observations.
</p>


<h3>Initial values</h3>

<p>Initial (or starting) values for the dsmodel can be set via the <code>initial</code> 
element of the <code>control</code> list. <code>initial</code> is a list itself with 
elements <code>scale</code>, <code>shape</code> and <code>adjustment</code>, corresponding to 
the associated parameters. If a model has covariates then the <code>scale</code> or
<code>shape</code> elements will be vectors with parameter initial values in the
same order as they are specific in the model formula (using <code>showit</code> is
a good check they are in the correct order). Adjustment starting values are
in order of the order of that term (cosine order 2 is before cosine order 3
terms).
</p>
<p>One way of obtaining starting values is to fit a simpler model first (say
with fewer covariates or adjustments) and then use the starting values from
this simpler model for the corresponding parameters.
</p>
<p>Another alternative to obtain starting values is to fit the model (or some
submodel) using Distance for Windows. Note that Distance reports the scale
parameter (or intercept in a covariate model) on the exponential scale, so
one must <code>log</code> this before supplying it to <code>ddf</code>.
</p>


<h3>Bounds</h3>

<p>One can change the upper and lower bounds for the dsmodel parameters. These 
specify the largest and smallest values individual parameters can be. By 
placing these constraints on the parameters, it is possible to &quot;temper&quot; the
optimisation problem, making fitting possible.
</p>
<p>Again, one uses the <code>control</code> list, the elements <code>upperbounds</code> and
<code>lowerbounds</code>. In this case, each of <code>upperbounds</code> and
<code>lowerbounds</code> are vectors, which one can think of as each of the
vectors <code>shape</code>, <code>scale</code> and <code>adjustment</code> from the &quot;Initial
values&quot; section above, concatenated in that order. If one does not occur
(e.g. no shape parameter) then it is simple omitted from the vector.
</p>


<h3>Author(s)</h3>

<p>David L. Miller &lt;dave@ninepointeightone.net&gt;
</p>

<hr>
<h2 id='NCovered'>Compute estimated abundance in covered (sampled) region</h2><span id='topic+NCovered'></span><span id='topic+NCovered.ds'></span><span id='topic+NCovered.io'></span><span id='topic+NCovered.io.fi'></span><span id='topic+NCovered.trial'></span><span id='topic+NCovered.trial.fi'></span><span id='topic+NCovered.rem'></span><span id='topic+NCovered.rem.fi'></span>

<h3>Description</h3>

<p>Generic function that computes abundance within the covered region.  It
calls method (class) specific functions for the computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NCovered(par, model = NULL, group = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NCovered_+3A_par">par</code></td>
<td>
<p>parameter values (used when computing derivatives wrt parameter
uncertainty); if NULL parameter values in <code>model</code> are used</p>
</td></tr>
<tr><td><code id="NCovered_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
<tr><td><code id="NCovered_+3A_group">group</code></td>
<td>
<p>if TRUE computes group abundance and if FALSE individual
abundance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>abundance estimate
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='nlminb_wrapper'>Wrapper around <code>nlminb</code></h2><span id='topic+nlminb_wrapper'></span>

<h3>Description</h3>

<p>This is a wrapper around nlminb to use scaling, as this is not available in
<code><a href="optimx.html#topic+optimx">optimx</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlminb_wrapper(
  par,
  ll,
  ugr = NULL,
  lower = NULL,
  upper = NULL,
  mcontrol,
  hess = NULL,
  ddfobj,
  data,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlminb_wrapper_+3A_par">par</code></td>
<td>
<p>starting parameters</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_ll">ll</code></td>
<td>
<p>log likelihood function</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_ugr">ugr</code></td>
<td>
<p>gradient function</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_lower">lower</code></td>
<td>
<p>lower bounds on parameters</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_upper">upper</code></td>
<td>
<p>upper bounds on parameters</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_mcontrol">mcontrol</code></td>
<td>
<p>control options</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_hess">hess</code></td>
<td>
<p>hessian function</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_ddfobj">ddfobj</code></td>
<td>
<p>detection function specification object</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_data">data</code></td>
<td>
<p>the data</p>
</td></tr>
<tr><td><code id="nlminb_wrapper_+3A_...">...</code></td>
<td>
<p>anything else to pass to <code>ll</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>optimx</code> object
</p>


<h3>Author(s)</h3>

<p>David L Miller, modified from <code>optimx.run</code> by JC Nash, R
Varadhan, G Grothendieck.
</p>

<hr>
<h2 id='p.det'>Double-platform detection probability</h2><span id='topic+p.det'></span>

<h3>Description</h3>

<p>Computes detection probability for detection function computed from
mark-recapture data with possibly different link functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p.det(dpformula, dplink, dppars, dpdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p.det_+3A_dpformula">dpformula</code></td>
<td>
<p>formula for detection function</p>
</td></tr>
<tr><td><code id="p.det_+3A_dplink">dplink</code></td>
<td>
<p>link function (&quot;logit&quot;,&quot;loglog&quot;,&quot;cloglog&quot;)</p>
</td></tr>
<tr><td><code id="p.det_+3A_dppars">dppars</code></td>
<td>
<p>parameter vector</p>
</td></tr>
<tr><td><code id="p.det_+3A_dpdata">dpdata</code></td>
<td>
<p>double platform data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of predicted detection probabilities
</p>


<h3>Author(s)</h3>

<p>?????
</p>

<hr>
<h2 id='p.dist.table'>Distribution of probabilities of detection</h2><span id='topic+p.dist.table'></span><span id='topic+p_dist_table'></span>

<h3>Description</h3>

<p>Generate a table of frequencies of probability of detection from a detection
function model. This is particularly useful when employing covariates, as it
can indicate if there are detections with very small detection probabilities
that can be unduly influential when calculating abundance estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p.dist.table(object, bins = seq(0, 1, by = 0.1), proportion = FALSE)

p_dist_table(object, bins = seq(0, 1, by = 0.1), proportion = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p.dist.table_+3A_object">object</code></td>
<td>
<p>fitted detection function</p>
</td></tr>
<tr><td><code id="p.dist.table_+3A_bins">bins</code></td>
<td>
<p>how the results should be binned</p>
</td></tr>
<tr><td><code id="p.dist.table_+3A_proportion">proportion</code></td>
<td>
<p>should proportions be returned as well as counts?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because <code><a href="#topic+dht">dht</a></code> uses a Horvitz-Thompson-like estimator, abundance
estimates can be sensitive to errors in the estimated probabilities. The
estimator is based on <code class="reqn">\sum 1/ \hat{P}_a(z_i)</code>, which means that the
sensitivity is greater for smaller detection probabilities. As a rough
guide, we recommend that the method be not used if more than say 5% of the
<code class="reqn">\hat{P}_a(z_i)</code> are less than 0.2, or if any are less than 0.1. If
these conditions are violated, the truncation distance w can be reduced.
This causes some loss of precision relative to standard distance sampling
without covariates.
</p>


<h3>Value</h3>

<p>a <code>data.frame</code> with probability bins, counts and (optionally)
proportions. The object has an attribute <code>p_range</code> which contains the
range of estimated detection probabilities
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>References</h3>

<p>Marques, F.F.C. and S.T. Buckland. 2004. Covariate models for
the detection function.
In: Advanced Distance Sampling, eds. S.T. Buckland, D.R. Anderson, K.P.
Burnham, J.L. Laake, D.L. Borchers, and L. Thomas. Oxford University
Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# try out the tee data
data(book.tee.data)
egdata &lt;- book.tee.data$book.tee.dataframe
# fit model with covariates
result &lt;- ddf(dsmodel = ~mcds(key = "hn", formula = ~sex+size),
              data = egdata[egdata$observer==1, ], method = "ds",
              meta.data = list(width = 4))
# print table
p.dist.table(result)
# with proportions
p.dist.table(result, proportion=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='parse.optimx'>Parse optimx results and present a nice object</h2><span id='topic+parse.optimx'></span>

<h3>Description</h3>

<p>Take the resulting object from a call to optimx and make it into an object that mrds wants to talk to.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse.optimx(lt, lnl.last, par.last)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse.optimx_+3A_lt">lt</code></td>
<td>
<p>an optimx object</p>
</td></tr>
<tr><td><code id="parse.optimx_+3A_lnl.last">lnl.last</code></td>
<td>
<p>last value of the log likelihood</p>
</td></tr>
<tr><td><code id="parse.optimx_+3A_par.last">par.last</code></td>
<td>
<p>last value of the parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>lt</code> object that can be used later on
</p>

<hr>
<h2 id='pdot.dsr.integrate.logistic'>Compute probability that a object was detected by at least one observer</h2><span id='topic+pdot.dsr.integrate.logistic'></span>

<h3>Description</h3>

<p>Computes probability that a object was detected by at least one observer
(<code>pdot</code> or p_.) for a logistic detection function that contains
distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdot.dsr.integrate.logistic(
  right,
  width,
  beta,
  x,
  integral.numeric,
  BT,
  models,
  GAM = FALSE,
  rem = FALSE,
  point = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_right">right</code></td>
<td>
<p>either an integration range for binned data (vector of 2) or
the rightmost value for integration (from 0 to right)</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_width">width</code></td>
<td>
<p>transect width</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_beta">beta</code></td>
<td>
<p>parameters of logistic detection function</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_x">x</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_integral.numeric">integral.numeric</code></td>
<td>
<p>set to <code>TRUE</code> unless data are binned (done in
this fct) or the model is such that distance is not linear (eg distance^2),
If integral.numeric is <code>FALSE</code> it will compute the integral
analytically.  It should only be <code>FALSE</code> if is.linear.logistic function
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_bt">BT</code></td>
<td>
<p><code>FALSE</code> except for the trial configuration; BT stands for
Buckland-Turnock who initially proposed a trial configuration for dual
observers</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_models">models</code></td>
<td>
<p>list of models including <code>g0model</code></p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_gam">GAM</code></td>
<td>
<p>Not used at present. The idea was to be able to use a GAM for
g(0) portion of detection function; should always be F</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_rem">rem</code></td>
<td>
<p>only <code>TRUE</code> for the removal configuration but not used and
could be removed if pulled from the function calls. Originally thought the
pdot integral would differ but it is the same as the io formula. The only
thing that differs with removal is that p(2|1)=1. Observer 2 sees everything
seen by observer 1,</p>
</td></tr>
<tr><td><code id="pdot.dsr.integrate.logistic_+3A_point">point</code></td>
<td>
<p><code>TRUE</code> for point transects</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='plot_cond'>Plot conditional detection function from distance sampling model</h2><span id='topic+plot_cond'></span>

<h3>Description</h3>

<p>Plot proportion of observations detected within distance intervals (for
conditional detection functions) to compare visually the fitted model and
data. Internal function called by <code>plot</code> methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_cond(
  obs,
  xmat,
  gxvalues,
  model,
  nc,
  breaks,
  finebr,
  showpoints,
  showlines,
  maintitle,
  ylim,
  angle = -45,
  density = 20,
  col = "black",
  jitter = NULL,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_cond_+3A_obs">obs</code></td>
<td>
<p>observer code</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_xmat">xmat</code></td>
<td>
<p>processed data</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_gxvalues">gxvalues</code></td>
<td>
<p>detection function values for each observation</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_model">model</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot_cond_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_finebr">finebr</code></td>
<td>
<p>fine break values over which line is averaged</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if <code>TRUE</code> plots predicted value
for each observation</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if <code>TRUE</code> plots average predicted
value line</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_ylim">ylim</code></td>
<td>
<p>range of y axis (default <code>c(0,1)</code>)</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_angle">angle</code></td>
<td>
<p>shading angle for hatching</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_density">density</code></td>
<td>
<p>shading density for hatching</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_col">col</code></td>
<td>
<p>plotting colour</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points.  Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter.</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_subtitle">subtitle</code></td>
<td>
<p>if TRUE, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot_cond_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers
</p>

<hr>
<h2 id='plot_layout'>Layout for plot methods in mrds</h2><span id='topic+plot_layout'></span>

<h3>Description</h3>

<p>This function does the paging, using <code>devAskNewPage()</code>. This means we
can just call plots and R will make the prompt for us
Warning, this function has side effects! It modifies <code>devAskNewPage</code>!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_layout(which, pages)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_layout_+3A_which">which</code></td>
<td>
<p>which plots are to be created</p>
</td></tr>
<tr><td><code id="plot_layout_+3A_pages">pages</code></td>
<td>
<p>number of pages to span the plots across</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Code is stolen and modified from <code>plot.R</code> in <code>mgcv</code> by Simon Wood
</p>


<h3>Author(s)</h3>

<p>David L. Miller, based on code by Simon N. Wood
</p>

<hr>
<h2 id='plot_uncond'>Plot unconditional detection function from distance sampling model</h2><span id='topic+plot_uncond'></span>

<h3>Description</h3>

<p>Plots unconditional detection function for observer=obs observations
overlays histogram, average detection function and values for individual
observations data. Internal function called by <code>plot</code> methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_uncond(
  model,
  obs,
  xmat,
  gxvalues,
  nc,
  finebr,
  breaks,
  showpoints,
  showlines,
  maintitle,
  ylim,
  return.lines = FALSE,
  angle = -45,
  density = 20,
  col = "black",
  jitter = NULL,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_uncond_+3A_model">model</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_obs">obs</code></td>
<td>
<p>value of observer for plot</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_xmat">xmat</code></td>
<td>
<p>processed data</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_gxvalues">gxvalues</code></td>
<td>
<p>detection function values for each observation</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_finebr">finebr</code></td>
<td>
<p>fine break values over which line is averaged</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if TRUE plots predicted value for each
observation</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if TRUE plots average predicted value line</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_ylim">ylim</code></td>
<td>
<p>range of y axis; defaults to (0,1)</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_return.lines">return.lines</code></td>
<td>
<p>if TRUE, returns values for line</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_angle">angle</code></td>
<td>
<p>shading angle for hatching</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_density">density</code></td>
<td>
<p>shading density for hatching</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_col">col</code></td>
<td>
<p>plotting colour</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points.  Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter.</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_subtitle">subtitle</code></td>
<td>
<p>if TRUE, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot_uncond_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>return.lines==TRUE</code> returns dataframe <code>average.line</code>
otherwise just plots
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers
</p>

<hr>
<h2 id='plot.det.tables'>Observation detection tables</h2><span id='topic+plot.det.tables'></span>

<h3>Description</h3>

<p>Plot the tables created by <code><a href="#topic+det.tables">det.tables</a></code>. Produces a series of
tables for dual observer data that shows the number missed and detected for
each observer within defined distance classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'det.tables'
plot(
  x,
  which = 1:6,
  angle = NULL,
  density = NULL,
  col1 = "white",
  col2 = "lightgrey",
  new = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.det.tables_+3A_x">x</code></td>
<td>
<p>object returned by <code><a href="#topic+det.tables">det.tables</a></code></p>
</td></tr>
<tr><td><code id="plot.det.tables_+3A_which">which</code></td>
<td>
<p>items in x to plot (vector with values in 1:6)</p>
</td></tr>
<tr><td><code id="plot.det.tables_+3A_angle">angle</code></td>
<td>
<p>shading angle for hatching</p>
</td></tr>
<tr><td><code id="plot.det.tables_+3A_density">density</code></td>
<td>
<p>shading density for hatching</p>
</td></tr>
<tr><td><code id="plot.det.tables_+3A_col1">col1</code></td>
<td>
<p>plotting colour for total histogram bars.</p>
</td></tr>
<tr><td><code id="plot.det.tables_+3A_col2">col2</code></td>
<td>
<p>plotting colour for subset histogram bars.</p>
</td></tr>
<tr><td><code id="plot.det.tables_+3A_new">new</code></td>
<td>
<p>if <code>TRUE</code> new plotting window for each plot</p>
</td></tr>
<tr><td><code id="plot.det.tables_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to plotting functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots that are produced are as follows (controlled by the <code>which</code>
argument):
</p>

<dl>
<dt>1</dt><dd><p>Detected by either observer/Detected by observer 1</p>
</dd>
<dt>2</dt><dd><p>Detected by either observer/Detected by observer 2</p>
</dd>
<dt>3</dt><dd><p>Seen by both observers</p>
</dd>
<dt>4</dt><dd><p>Seen by either observer</p>
</dd>
<dt>5</dt><dd><p>Detected by observer 2/Detected by observer 1 | 2</p>
</dd>
<dt>6</dt><dd><p>Detected by observer 1/Detected by observer 2 | 1</p>
</dd>
</dl>



<h3>Value</h3>

<p>Just plots.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(book.tee.data)
region &lt;- book.tee.data$book.tee.region
egdata &lt;- book.tee.data$book.tee.dataframe
samples &lt;- book.tee.data$book.tee.samples
obs &lt;- book.tee.data$book.tee.obs
xx &lt;- ddf(mrmodel=~glm(formula=~distance*observer),
          dsmodel = ~mcds(key = "hn", formula = ~sex),
          data = egdata, method = "io", meta.data = list(width = 4))
tabs &lt;- det.tables(xx,breaks=c(0,.5,1,2,3,4))
par(mfrow=c(2,3))
plot(tabs,which=1:6,new=FALSE)

</code></pre>

<hr>
<h2 id='plot.ds'>Plot fit of detection functions and histograms of data from distance
sampling model</h2><span id='topic+plot.ds'></span>

<h3>Description</h3>

<p>Plots the fitted detection function(s) with a histogram of the observed
distances to compare visually the fitted model and data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds'
plot(
  x,
  which = 2,
  breaks = NULL,
  nc = NULL,
  jitter.v = rep(0, 3),
  showpoints = TRUE,
  subset = NULL,
  pl.col = "lightgrey",
  pl.den = NULL,
  pl.ang = NULL,
  main = NULL,
  pages = 0,
  pdf = FALSE,
  ylim = NULL,
  xlab = "Distance",
  ylab = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ds_+3A_x">x</code></td>
<td>
<p>fitted model from <code>ddf</code>.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_which">which</code></td>
<td>
<p>index to specify which plots should be produced:
</p>

<table>
<tr>
 <td style="text-align: left;">1 </td><td style="text-align: left;"> histogram of observed distances</td>
</tr>
<tr>
 <td style="text-align: left;">
             2 </td><td style="text-align: left;"> histogram of observed distances with fitted line and
             points (default)</td>
</tr>

</table>
</td></tr>
<tr><td><code id="plot.ds_+3A_breaks">breaks</code></td>
<td>
<p>user defined breakpoints</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_nc">nc</code></td>
<td>
<p>number of equal width bins for histogram</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_jitter.v">jitter.v</code></td>
<td>
<p>apply jitter to points by multiplying the fitted value by a
random draw from a normal distribution with mean 1 and sd <code>jitter.v</code>.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if <code>TRUE</code> plots predicted value for
each observation (conditional on its observed distance).</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_subset">subset</code></td>
<td>
<p>subset of data to plot.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_pl.col">pl.col</code></td>
<td>
<p>colour for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_pl.den">pl.den</code></td>
<td>
<p>shading density for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_pl.ang">pl.ang</code></td>
<td>
<p>shading angle for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_main">main</code></td>
<td>
<p>plot title.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the plots. For
example, if <code>pages=1</code> then all plots will be displayed on one page.
Default is 0, which prompts the user for the next plot to be displayed.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_pdf">pdf</code></td>
<td>
<p>plot the histogram of distances with the PDF of the probability
of detection overlaid. Ignored (with warning) for line transect models.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_ylim">ylim</code></td>
<td>
<p>vertical axis limits.</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_xlab">xlab</code></td>
<td>
<p>horizontal axis label (defaults to &quot;Distance&quot;).</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_ylab">ylab</code></td>
<td>
<p>vertical axis label (default automatically set depending on plot
type).</p>
</td></tr>
<tr><td><code id="plot.ds_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+hist">hist</a></code>, <code><a href="graphics.html#topic+lines">lines</a></code>,
<code><a href="graphics.html#topic+points">points</a></code>, etc).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the histogram can be controlled by the user-defined
arguments <code>nc</code> or <code>breaks</code>. The observation specific detection
probabilities along with the line representing the fitted average detection
probability.
</p>
<p>It is not intended for the user to call <code>plot.ds</code> but its arguments are
documented here. Instead the generic <code>plot</code> command should be used and
it will call the appropriate function based on the class of the <code>ddf</code>
object.
</p>


<h3>Value</h3>

<p>Just plots.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers, David L Miller
</p>


<h3>See Also</h3>

<p>add_df_covar_line
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# fit a model to the tee data
data(book.tee.data)
egdata &lt;- book.tee.data$book.tee.dataframe
xx &lt;- ddf(dsmodel=~mcds(key="hn", formula=~sex),
          data=egdata[egdata$observer==1, ],
          method="ds", meta.data=list(width=4))

# not showing predicted probabilities
plot(xx, breaks=c(0, 0.5, 1, 2, 3, 4), showpoints=FALSE)

# two subsets
plot(xx, breaks=c(0, 0.5, 1, 2, 3, 4), subset=sex==0)
plot(xx, breaks=c(0, 0.5, 1, 2, 3, 4), subset=sex==1)

# put both plots on one page
plot(xx, breaks=c(0, 0.5, 1, 2, 3, 4), pages=1, which=1:2)

</code></pre>

<hr>
<h2 id='plot.io'>Plot fit of detection functions and histograms of data from distance
sampling independent observer (<code>io</code>) model</h2><span id='topic+plot.io'></span>

<h3>Description</h3>

<p>Plots the fitted detection functions for a distance sampling model and
histograms of the distances (for unconditional detection functions) or
proportion of observations detected within distance intervals (for
conditional detection functions) to compare visually the fitted model and
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'io'
plot(
  x,
  which = 1:6,
  breaks = NULL,
  nc = NULL,
  maintitle = "",
  showlines = TRUE,
  showpoints = TRUE,
  ylim = c(0, 1),
  angle = NULL,
  density = NULL,
  col = "lightgrey",
  jitter = NULL,
  divisions = 25,
  pages = 0,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.io_+3A_x">x</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot.io_+3A_which">which</code></td>
<td>
<p>index to specify which plots should be produced.
</p>

<table>
<tr>
 <td style="text-align: left;">1 </td><td style="text-align: left;"> Plot primary unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             2 </td><td style="text-align: left;"> Plot secondary unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             3 </td><td style="text-align: left;"> Plot pooled unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             4 </td><td style="text-align: left;"> Plot duplicate unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             5 </td><td style="text-align: left;"> Plot primary conditional detection function</td>
</tr>
<tr>
 <td style="text-align: left;">
             6 </td><td style="text-align: left;"> Plot secondary conditional detection function </td>
</tr>

</table>

<p>Note that the order of which is ignored and plots are produced in the above
order.</p>
</td></tr>
<tr><td><code id="plot.io_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
<tr><td><code id="plot.io_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot.io_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot.io_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if TRUE a line representing the average
detection probability is plotted</p>
</td></tr>
<tr><td><code id="plot.io_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if TRUE plots predicted value for each
observation</p>
</td></tr>
<tr><td><code id="plot.io_+3A_ylim">ylim</code></td>
<td>
<p>range of vertical axis; defaults to (0,1)</p>
</td></tr>
<tr><td><code id="plot.io_+3A_angle">angle</code></td>
<td>
<p>shading angle for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.io_+3A_density">density</code></td>
<td>
<p>shading density for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.io_+3A_col">col</code></td>
<td>
<p>colour for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.io_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points. Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter.</p>
</td></tr>
<tr><td><code id="plot.io_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions for averaging line values; default = 25</p>
</td></tr>
<tr><td><code id="plot.io_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the plots. For
example, if <code>pages=1</code> then all plots will be displayed on one page.
Default is 0, which prompts the user for the next plot to be displayed.</p>
</td></tr>
<tr><td><code id="plot.io_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot.io_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot.io_+3A_subtitle">subtitle</code></td>
<td>
<p>if TRUE, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot.io_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the histogram can be controlled by the user-defined
arguments <code>nc</code> or <code>breaks</code>.  The observation specific detection
probabilities along with the line representing the fitted average detection
probability.
</p>
<p>It is not intended for the user to call <code>plot.io.fi</code> but its arguments
are documented here. Instead the generic <code>plot</code> command should be used
and it will call the appropriate function based on the class of the
<code>ddf</code> object.
</p>


<h3>Value</h3>

<p>Just plots
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers, David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mrds)
data(book.tee.data)
egdata &lt;- book.tee.data$book.tee.dataframe
result.io &lt;- ddf(dsmodel=~cds(key = "hn"), mrmodel=~glm(~distance),
                 data=egdata, method="io", meta.data=list(width=4))

# just plot everything
plot(result.io)

# Plot primary and secondary unconditional detection functions on one page
# and  primary and secondary conditional detection functions on another
plot(result.io,which=c(1,2,5,6),pages=2)

</code></pre>

<hr>
<h2 id='plot.io.fi'>Plot fit of detection functions and histograms of data from distance
sampling independent observer model with full independence (<code>io.fi</code>)</h2><span id='topic+plot.io.fi'></span>

<h3>Description</h3>

<p>Plots the fitted detection functions for a distance sampling model and
histograms of the distances (for unconditional detection functions) or
proportion of observations detected within distance intervals (for
conditional detection functions) to compare visually the fitted model and
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'io.fi'
plot(
  x,
  which = 1:6,
  breaks = NULL,
  nc = NULL,
  maintitle = "",
  showlines = TRUE,
  showpoints = TRUE,
  ylim = c(0, 1),
  angle = NULL,
  density = NULL,
  col = "lightgrey",
  jitter = NULL,
  divisions = 25,
  pages = 0,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.io.fi_+3A_x">x</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_which">which</code></td>
<td>
<p>index to specify which plots should be produced.
</p>

<table>
<tr>
 <td style="text-align: left;">1 </td><td style="text-align: left;"> Plot primary unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             2 </td><td style="text-align: left;"> Plot secondary unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             3 </td><td style="text-align: left;"> Plot pooled unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             4 </td><td style="text-align: left;"> Plot duplicate unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             5 </td><td style="text-align: left;"> Plot primary conditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             6 </td><td style="text-align: left;"> Plot secondary conditional detection function </td>
</tr>

</table>

<p>Note that the order of which is ignored and plots are produced in the above
order.</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if TRUE a line representing the average
detection probability is plotted</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if TRUE plots predicted value for each
observation</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_ylim">ylim</code></td>
<td>
<p>range of vertical axis; defaults to (0,1)</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_angle">angle</code></td>
<td>
<p>shading angle for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_density">density</code></td>
<td>
<p>shading density for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_col">col</code></td>
<td>
<p>colour for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points.  Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter.</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions for averaging line values; default = 25</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the plots. For
example, if <code>pages=1</code> then all plots will be displayed on one page.
Default is 0, which prompts the user for the next plot to be displayed.</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_subtitle">subtitle</code></td>
<td>
<p>if TRUE, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot.io.fi_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the histogram can be controlled by the user-defined
arguments <code>nc</code> or <code>breaks</code>.  The observation specific detection
probabilities along with the line representing the fitted average detection
probability.
</p>
<p>It is not intended for the user to call <code>plot.io.fi</code> but its arguments
are documented here. Instead the generic <code>plot</code> command should be used
and it will call the appropriate function based on the class of the
<code>ddf</code> object.
</p>


<h3>Value</h3>

<p>Just plots.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers, David L Miller
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(mrds)
data(book.tee.data)
egdata &lt;- book.tee.data$book.tee.dataframe
result.io.fi &lt;- ddf(mrmodel=~glm(~distance), data = egdata, method = "io.fi",
              meta.data = list(width = 4))

# just plot everything
plot(result.io.fi)

# Plot primary and secondary unconditional detection functions on one page
# and  primary and secondary conditional detection functions on another
plot(result.io.fi,which=c(1,2,5,6),pages=2)

</code></pre>

<hr>
<h2 id='plot.rem'>Plot fit of detection functions and histograms of data from removal distance
sampling model</h2><span id='topic+plot.rem'></span>

<h3>Description</h3>

<p>Plots the fitted detection functions for a distance sampling model and
histograms of the distances (for unconditional detection functions) or
proportion of observations detected within distance intervals (for
conditional detection functions) to compare visually the fitted model and
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rem'
plot(
  x,
  which = 1:3,
  breaks = NULL,
  nc = NULL,
  maintitle = "",
  showlines = TRUE,
  showpoints = TRUE,
  ylim = c(0, 1),
  angle = NULL,
  density = NULL,
  col = "lightgrey",
  jitter = NULL,
  divisions = 25,
  pages = 0,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rem_+3A_x">x</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot.rem_+3A_which">which</code></td>
<td>
<p>index to specify which plots should be produced.
</p>

<table>
<tr>
 <td style="text-align: left;">1 </td><td style="text-align: left;"> Plot primary unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             2 </td><td style="text-align: left;"> Plot pooled unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             3 </td><td style="text-align: left;"> Plot conditional (1|2) detection function </td>
</tr>

</table>
</td></tr>
<tr><td><code id="plot.rem_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if <code>TRUE</code> a line representing the
average detection probability is plotted</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if <code>TRUE</code> plots predicted value for
each observation</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_ylim">ylim</code></td>
<td>
<p>range of vertical axis; defaults to (0,1)</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_angle">angle</code></td>
<td>
<p>shading angle for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_density">density</code></td>
<td>
<p>shading density for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_col">col</code></td>
<td>
<p>colour for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points.  Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter.</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions for averaging line values; default = 25</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the plots. For
example, if <code>pages=1</code> then all plots will be displayed on one page.
Default is 0, which prompts the user for the next plot to be displayed.</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_subtitle">subtitle</code></td>
<td>
<p>if <code>TRUE</code>, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot.rem_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the histogram can be controlled by the user-defined
arguments <code>nc</code> or <code>breaks</code>.  The observation specific detection
probabilities along with the line representing the fitted average detection
probability.
</p>
<p>It is not intended for the user to call <code>plot.rem</code> but its arguments
are documented here. Instead the generic <code>plot</code> command should be used
and it will call the appropriate function based on the class of the
<code>ddf</code> object.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers, David L Miller
</p>

<hr>
<h2 id='plot.rem.fi'>Plot fit of detection functions and histograms of data from removal distance
sampling model</h2><span id='topic+plot.rem.fi'></span>

<h3>Description</h3>

<p>Plots the fitted detection functions for a distance sampling model and
histograms of the distances (for unconditional detection functions) or
proportion of observations detected within distance intervals (for
conditional detection functions) to compare visually the fitted model and
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rem.fi'
plot(
  x,
  which = 1:3,
  breaks = NULL,
  nc = NULL,
  maintitle = "",
  showlines = TRUE,
  showpoints = TRUE,
  ylim = c(0, 1),
  angle = NULL,
  density = NULL,
  col = "lightgrey",
  jitter = NULL,
  divisions = 25,
  pages = 0,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rem.fi_+3A_x">x</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_which">which</code></td>
<td>
<p>index to specify which plots should be produced.
</p>

<table>
<tr>
 <td style="text-align: left;">1 </td><td style="text-align: left;"> Plot primary unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             2 </td><td style="text-align: left;"> Plot pooled unconditional detection function </td>
</tr>
<tr>
 <td style="text-align: left;">
             3 </td><td style="text-align: left;"> Plot conditional (1|2) detection function </td>
</tr>

</table>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_breaks">breaks</code></td>
<td>
<p>user defined breakpoints</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if <code>TRUE</code> a line representing the
average detection probability is plotted</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if <code>TRUE</code> plots predicted value for
each observation</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_ylim">ylim</code></td>
<td>
<p>range of vertical axis; defaults to (0,1)</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_angle">angle</code></td>
<td>
<p>shading angle for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_density">density</code></td>
<td>
<p>shading density for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_col">col</code></td>
<td>
<p>colour for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points.  Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions for averaging line values; default = 25</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the plots. For
example, if <code>pages=1</code> then all plots will be displayed on one page.
Default is 0, which prompts the user for the next plot to be displayed.</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_subtitle">subtitle</code></td>
<td>
<p>if <code>TRUE</code>, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot.rem.fi_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the histogram can be controlled by the user-defined
arguments <code>nc</code> or <code>breaks</code>.  The observation specific detection
probabilities along with the line representing the fitted average detection
probability.
</p>
<p>It is not intended for the user to call <code>plot.rem.fi</code> but its arguments
are documented here. Instead the generic <code>plot</code> command should be used
and it will call the appropriate function based on the class of the
<code>ddf</code> object.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers, David L Miller
</p>

<hr>
<h2 id='plot.trial'>Plot fit of detection functions and histograms of data from distance
sampling trial observer model</h2><span id='topic+plot.trial'></span>

<h3>Description</h3>

<p>Plots the fitted detection functions for a distance sampling model and
histograms of the distances (for unconditional detection functions) or
proportion of observations detected within distance intervals (for
conditional detection functions) to compare visually the fitted model and
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trial'
plot(
  x,
  which = 1:2,
  breaks = NULL,
  nc = NULL,
  maintitle = "",
  showlines = TRUE,
  showpoints = TRUE,
  ylim = c(0, 1),
  angle = NULL,
  density = NULL,
  col = "lightgrey",
  jitter = NULL,
  divisions = 25,
  pages = 0,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.trial_+3A_x">x</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot.trial_+3A_which">which</code></td>
<td>
<p>index to specify which plots should be produced.
</p>

<table>
<tr>
 <td style="text-align: left;">1 </td><td style="text-align: left;"> Unconditional detection function for observer 1 </td>
</tr>
<tr>
 <td style="text-align: left;">
             2 </td><td style="text-align: left;"> Conditional detection function plot (1|2)</td>
</tr>

</table>
</td></tr>
<tr><td><code id="plot.trial_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if <code>TRUE</code> a line representing the average
detection probability is plotted</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if <code>TRUE</code> plots predicted value for each
observation</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_ylim">ylim</code></td>
<td>
<p>range of vertical axis; defaults to (0,1)</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_angle">angle</code></td>
<td>
<p>shading angle for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_density">density</code></td>
<td>
<p>shading density for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_col">col</code></td>
<td>
<p>colour for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points. Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter.</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions for averaging line values; default = 25</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the plots. For
example, if <code>pages=1</code> then all plots will be displayed on one page.
Default is 0, which prompts the user for the next plot to be displayed.</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_subtitle">subtitle</code></td>
<td>
<p>if <code>TRUE</code>, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot.trial_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the histogram can be controlled by the user-defined
arguments <code>nc</code> or <code>breaks</code>.  The observation specific detection
probabilities along with the line representing the fitted average detection
probability.
</p>
<p>It is not intended for the user to call <code>plot.io.fi</code> but its arguments
are documented here. Instead the generic <code>plot</code> command should be used
and it will call the appropriate function based on the class of the
<code>ddf</code> object.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers
</p>

<hr>
<h2 id='plot.trial.fi'>Plot fit of detection functions and histograms of data from distance
sampling trial observer model</h2><span id='topic+plot.trial.fi'></span>

<h3>Description</h3>

<p>Plots the fitted detection functions for a distance sampling model and
histograms of the distances (for unconditional detection functions) or
proportion of observations detected within distance intervals (for
conditional detection functions) to compare visually the fitted model and
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trial.fi'
plot(
  x,
  which = 1:2,
  breaks = NULL,
  nc = NULL,
  maintitle = "",
  showlines = TRUE,
  showpoints = TRUE,
  ylim = c(0, 1),
  angle = NULL,
  density = NULL,
  col = "lightgrey",
  jitter = NULL,
  divisions = 25,
  pages = 0,
  xlab = "Distance",
  ylab = "Detection probability",
  subtitle = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.trial.fi_+3A_x">x</code></td>
<td>
<p>fitted model from <code>ddf</code></p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_which">which</code></td>
<td>
<p>index to specify which plots should be produced.
</p>

<table>
<tr>
 <td style="text-align: left;">1 </td><td style="text-align: left;"> Unconditional detection function for observer 1 </td>
</tr>
<tr>
 <td style="text-align: left;">
             2 </td><td style="text-align: left;"> Conditional detection function plot (1|2)</td>
</tr>

</table>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_breaks">breaks</code></td>
<td>
<p>user define breakpoints</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_nc">nc</code></td>
<td>
<p>number of equal-width bins for histogram</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_maintitle">maintitle</code></td>
<td>
<p>main title line for each plot</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_showlines">showlines</code></td>
<td>
<p>logical variable; if <code>TRUE</code> a line representing the
average detection probability is plotted</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_showpoints">showpoints</code></td>
<td>
<p>logical variable; if <code>TRUE</code> plots predicted value for
each observation</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_ylim">ylim</code></td>
<td>
<p>range of vertical axis; defaults to (0,1)</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_angle">angle</code></td>
<td>
<p>shading angle for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_density">density</code></td>
<td>
<p>shading density for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_col">col</code></td>
<td>
<p>colour for histogram bars.</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_jitter">jitter</code></td>
<td>
<p>scaling option for plotting points. Jitter is applied to
points by multiplying the fitted value by a random draw from a normal
distribution with mean 1 and sd jitter.</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_divisions">divisions</code></td>
<td>
<p>number of divisions for averaging line values; default = 25</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the plots. For
example, if <code>pages=1</code> then all plots will be displayed on one page.
Default is 0, which prompts the user for the next plot to be displayed.</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_subtitle">subtitle</code></td>
<td>
<p>if TRUE, shows plot type as sub-title</p>
</td></tr>
<tr><td><code id="plot.trial.fi_+3A_...">...</code></td>
<td>
<p>other graphical parameters, passed to the plotting functions
(<code>plot</code>, <code>hist</code>, <code>lines</code>, <code>points</code>, etc)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The structure of the histogram can be controlled by the user-defined
arguments <code>nc</code> or <code>breaks</code>.  The observation specific detection
probabilities along with the line representing the fitted average detection
probability.
</p>
<p>It is not intended for the user to call <code>plot.io.fi</code> but its arguments
are documented here. Instead the generic <code>plot</code> command should be used
and it will call the appropriate function based on the class of the
<code>ddf</code> object.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, Jon Bishop, David Borchers
</p>

<hr>
<h2 id='predict.ds'>Predictions from <code>mrds</code> models</h2><span id='topic+predict.ds'></span><span id='topic+predict'></span><span id='topic+predict.ddf'></span><span id='topic+predict.io'></span><span id='topic+predict.io.fi'></span><span id='topic+predict.trial'></span><span id='topic+predict.trial.fi'></span><span id='topic+predict.rem'></span><span id='topic+predict.rem.fi'></span>

<h3>Description</h3>

<p>Predict detection probabilities (or effective strip widths/effective areas
of detection) from a fitted distance sampling model using either the
original data (i.e. &quot;fitted&quot; values) or using new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds'
predict(object, newdata=NULL, compute=FALSE,
int.range=NULL, esw=FALSE, se.fit=FALSE, ...)
       ## S3 method for class 'io.fi'
predict(object, newdata=NULL, compute=FALSE,
       int.range=NULL, integrate=FALSE, ...)
       ## S3 method for class 'io'
predict(object, newdata=NULL, compute=FALSE,
       int.range=NULL, ...)
       ## S3 method for class 'trial'
predict(object, newdata=NULL, compute=FALSE,
       int.range=NULL, ...)
       ## S3 method for class 'trial.fi'
predict(object, newdata=NULL, compute=FALSE,
       int.range=NULL, integrate=FALSE, ...)
       ## S3 method for class 'rem'
predict(object, newdata=NULL, compute=FALSE,
       int.range=NULL, ...)
       ## S3 method for class 'rem.fi'
predict(object, newdata=NULL, compute=FALSE,
       int.range=NULL, integrate=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ds_+3A_object">object</code></td>
<td>
<p><code>ddf</code> model object.</p>
</td></tr>
<tr><td><code id="predict.ds_+3A_newdata">newdata</code></td>
<td>
<p>new <code>data.frame</code> for prediction, this must include a
column called &quot;<code>distance</code>&quot;.</p>
</td></tr>
<tr><td><code id="predict.ds_+3A_compute">compute</code></td>
<td>
<p>if <code>TRUE</code> compute values and don't use the fitted values
stored in the model object.</p>
</td></tr>
<tr><td><code id="predict.ds_+3A_int.range">int.range</code></td>
<td>
<p>integration range for variable range analysis; either
vector or 2 column matrix.</p>
</td></tr>
<tr><td><code id="predict.ds_+3A_esw">esw</code></td>
<td>
<p>if <code>TRUE</code>, returns effective strip half-width (or effective
area of detection for point transect models) integral from 0 to the
truncation distance (<code>width</code>) of <code class="reqn">p(y)dy</code>; otherwise it returns the
integral from 0 to truncation width of <code class="reqn">p(y)\pi(y)</code> where
<code class="reqn">\pi(y)=1/w</code> for lines and <code class="reqn">\pi(y)=2r/w^2</code> for points.</p>
</td></tr>
<tr><td><code id="predict.ds_+3A_se.fit">se.fit</code></td>
<td>
<p>for <code>*.ds</code> models only, generate standard errors on the
predicted probabilities of detection (or ESW if <code>esw=TRUE</code>), stored in
the <code>se.fit</code> element</p>
</td></tr>
<tr><td><code id="predict.ds_+3A_...">...</code></td>
<td>
<p>for S3 consistency</p>
</td></tr>
<tr><td><code id="predict.ds_+3A_integrate">integrate</code></td>
<td>
<p>for <code>*.fi</code> methods, see Details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first 4 arguments are the same in each predict function.  The latter 2
are specific to certain functions. For line transects, the effective strip
half-width (<code>esw=TRUE</code>) is the integral of the fitted detection
function over either 0 to W or the specified <code>int.range</code>.  The
predicted detection probability is the average probability which is simply
the integral divided by the distance range. For point transect models,
<code>esw=TRUE</code> calculates the effective area of detection (commonly
referred to as &quot;nu&quot;, this is the integral of <code>2/width^2 * rg(r)</code>.
</p>
<p>Fitted detection probabilities are stored in the <code>model</code> object and
these are returned unless <code>compute=TRUE</code> or <code>newdata</code> is
specified. <code>compute=TRUE</code> is used to estimate numerical derivatives for
use in delta method approximations to the variance.
</p>
<p>For <code>method="io.fi"</code> or <code>method="trial.fi"</code> if
<code>integrate=FALSE</code>, <code>predict</code> returns the value of the conditional
detection probability and if <code>integrate=TRUE</code>, it returns the average
conditional detection probability by integrating over x (distance) with
respect to a uniform distribution.
</p>
<p>Note that the ordering of the returned results when no new data is supplied
(the &quot;fitted&quot; values) will not necessarily be the same as the data supplied
to <code><a href="#topic+ddf">ddf</a></code>, the data (and hence results from <code>predict</code>) will
be sorted by object ID (<code>object</code>) then observer ID (<code>observer</code>).
</p>


<h3>Value</h3>

<p>For all but the exceptions below, the value is a list with a single
element: <code>fitted</code>, a vector of average detection probabilities or esw
values for each observation in the original data or<code>newdata</code>
</p>
<p>For <code>predict.ds</code>, if <code>se.fit=TRUE</code> there is an additional element
<code>$se.fit</code>, which contains the standard errors of the probabilities of
detection or ESW.
</p>
<p>For <code>predict.io.fi</code>,<code>predict.trial.fi</code>,<code>predict.rem.fi</code> with
<code>integrate=TRUE</code>, the value is a list with one element: <code>fitted</code>,
which is a vector of integrated (average) detection probabilities for each
observation in the original data or <code>newdata</code>.
</p>
<p>For <code>predict.io.fi</code>, <code>predict.trial.fi</code>, or <code>predict.rem.fi</code>
with <code>integrate=FALSE</code>, the value is a list with the following
elements:
</p>

<dl>
<dt><code>fitted</code></dt><dd><p><code class="reqn">p(y)</code> values</p>
</dd>
<dt><code>p1</code></dt><dd><p><code class="reqn">p_{1|2}(y)</code>, conditional detection probability for
observer 1</p>
</dd>
<dt><code>p2</code></dt><dd><p><code class="reqn">p_{2|1}(y)</code>, conditional detection probability for
observer 2</p>
</dd>
<dt><code>fitted</code></dt><dd><p><code class="reqn">p_.(y) = p_{1|2}(y) + p_{2|1}(y) - p_{1|2}(y) *
   p_{2|1}(y)</code>, conditional detection probability of being seen by either
observer</p>
</dd></dl>



<h3>Note</h3>

<p>Each function is called by the generic function <code>predict</code> for the
appropriate <code>ddf</code> model object.  They can be called directly by the
user, but it is typically safest to use <code>predict</code> which calls the
appropriate function based on the type of model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf">ddf</a></code>, <code><a href="#topic+summary.ds">summary.ds</a></code>, <code><a href="#topic+plot.ds">plot.ds</a></code>
</p>

<hr>
<h2 id='print.ddf'>Simple pretty printer for distance sampling analyses</h2><span id='topic+print.ddf'></span>

<h3>Description</h3>

<p>Simply prints out summary of the model which was fitted. For more
detailed information see <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ddf'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ddf_+3A_x">x</code></td>
<td>
<p>a <code>ddf</code> object</p>
</td></tr>
<tr><td><code id="print.ddf_+3A_...">...</code></td>
<td>
<p>not passed through, just for S3 compatibility.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='print.ddf.gof'>Prints results of goodness of fit tests for detection functions</h2><span id='topic+print.ddf.gof'></span>

<h3>Description</h3>

<p>Provides formatted output for results of goodness of fit tests: chi-square,
Kolmogorv-Smirnov and Cramer-von Mises test as appropriate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ddf.gof'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ddf.gof_+3A_x">x</code></td>
<td>
<p>result of call to <code><a href="#topic+ddf.gof">ddf.gof</a></code></p>
</td></tr>
<tr><td><code id="print.ddf.gof_+3A_digits">digits</code></td>
<td>
<p>number of digits to round chi-squared table values to</p>
</td></tr>
<tr><td><code id="print.ddf.gof_+3A_...">...</code></td>
<td>
<p>unused unspecified arguments for generic print</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.gof">ddf.gof</a></code>
</p>

<hr>
<h2 id='print.det.tables'>Print results of observer detection tables</h2><span id='topic+print.det.tables'></span>

<h3>Description</h3>

<p>Provides formatted output for detection tables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'det.tables'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.det.tables_+3A_x">x</code></td>
<td>
<p>result of call to ddf</p>
</td></tr>
<tr><td><code id="print.det.tables_+3A_...">...</code></td>
<td>
<p>unused unspecified arguments for generic print</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.det.tables">plot.det.tables</a></code>
</p>

<hr>
<h2 id='print.dht'>Prints density and abundance estimates</h2><span id='topic+print.dht'></span>

<h3>Description</h3>

<p>Outputs summary statistics, abundance and density by region (if any) and
optionally a correlation matrix if more than one region.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dht'
print(x, cor = FALSE, bysample = FALSE, vcmatrices = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.dht_+3A_x">x</code></td>
<td>
<p>dht object that results from call to dht for a specific ddf object</p>
</td></tr>
<tr><td><code id="print.dht_+3A_cor">cor</code></td>
<td>
<p>if TRUE outputs correlation matrix of estimates</p>
</td></tr>
<tr><td><code id="print.dht_+3A_bysample">bysample</code></td>
<td>
<p>if TRUE, prints results for each sample</p>
</td></tr>
<tr><td><code id="print.dht_+3A_vcmatrices">vcmatrices</code></td>
<td>
<p>if TRUE, prints variance-covariance matrices</p>
</td></tr>
<tr><td><code id="print.dht_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dht">dht</a></code>
</p>

<hr>
<h2 id='print.p_dist_table'>Print distribution of probabilities of detection</h2><span id='topic+print.p_dist_table'></span>

<h3>Description</h3>

<p>Just a pretty printer for the table of probabilities of detection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'p_dist_table'
print(x, digits = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.p_dist_table_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+p_dist_table">p_dist_table</a></code></p>
</td></tr>
<tr><td><code id="print.p_dist_table_+3A_digits">digits</code></td>
<td>
<p>number of significant digits to print</p>
</td></tr>
<tr><td><code id="print.p_dist_table_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code><a href="base.html#topic+print.data.frame">print.data.frame</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>just prints the table and the range of ps
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='print.summary.ds'>Print summary of distance detection function model object</h2><span id='topic+print.summary.ds'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error. What is printed depends
on the corresponding call to summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.ds'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.ds_+3A_x">x</code></td>
<td>
<p>a summary of <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="print.summary.ds_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.ds">summary.ds</a></code>
</p>

<hr>
<h2 id='print.summary.io'>Print summary of distance detection function model object</h2><span id='topic+print.summary.io'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error. What is printed depends
on the corresponding call to summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.io'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.io_+3A_x">x</code></td>
<td>
<p>a summary of <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="print.summary.io_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.io">summary.io</a></code>
</p>

<hr>
<h2 id='print.summary.io.fi'>Print summary of distance detection function model object</h2><span id='topic+print.summary.io.fi'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error. What is printed depends
on the corresponding call to summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.io.fi'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.io.fi_+3A_x">x</code></td>
<td>
<p>a summary of <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="print.summary.io.fi_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.io.fi">summary.io.fi</a></code>
</p>

<hr>
<h2 id='print.summary.rem'>Print summary of distance detection function model object</h2><span id='topic+print.summary.rem'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error. What is printed depends
on the corresponding call to summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.rem'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.rem_+3A_x">x</code></td>
<td>
<p>a summary of <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="print.summary.rem_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.rem">summary.rem</a></code>
</p>

<hr>
<h2 id='print.summary.rem.fi'>Print summary of distance detection function model object</h2><span id='topic+print.summary.rem.fi'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error. What is printed depends
on the corresponding call to summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.rem.fi'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.rem.fi_+3A_x">x</code></td>
<td>
<p>a summary of <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="print.summary.rem.fi_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.rem.fi">summary.rem.fi</a></code>
</p>

<hr>
<h2 id='print.summary.trial'>Print summary of distance detection function model object</h2><span id='topic+print.summary.trial'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error. What is printed depends
on the corresponding call to summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.trial'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.trial_+3A_x">x</code></td>
<td>
<p>a summary of <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="print.summary.trial_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.trial">summary.trial</a></code>
</p>

<hr>
<h2 id='print.summary.trial.fi'>Print summary of distance detection function model object</h2><span id='topic+print.summary.trial.fi'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error. What is printed depends
on the corresponding call to summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.trial.fi'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.trial.fi_+3A_x">x</code></td>
<td>
<p>a summary of <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="print.summary.trial.fi_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.trial.fi">summary.trial.fi</a></code>
</p>

<hr>
<h2 id='prob.deriv'>Derivatives for variance of average p and average p(0) variance</h2><span id='topic+prob.deriv'></span>

<h3>Description</h3>

<p>Used in call to DeltaMethod from prob.se to get first derivatives
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prob.deriv(par, model, parfct, observer = NULL, fittedmodel = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prob.deriv_+3A_par">par</code></td>
<td>
<p>detection function parameter values</p>
</td></tr>
<tr><td><code id="prob.deriv_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
<tr><td><code id="prob.deriv_+3A_parfct">parfct</code></td>
<td>
<p>function of detection probabilities; currently only
average (over covariates) detection probability p integrated over distance
or average (over covariates) detection probability at distance 0; p(0)</p>
</td></tr>
<tr><td><code id="prob.deriv_+3A_observer">observer</code></td>
<td>
<p>1,2,3 for primary, secondary, or duplicates for average
p(0); passed to fct</p>
</td></tr>
<tr><td><code id="prob.deriv_+3A_fittedmodel">fittedmodel</code></td>
<td>
<p>full fitted ddf model when <code>trial.fi</code> or
<code>io.fi</code> is called from <code>trial</code> or <code>io</code> respectively</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Need to add equations here as I do not think they exist in any of the texts.
These should probably be checked with simulation.
</p>


<h3>Value</h3>

<p>Vector of values from fct at specified parameter values
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p>prob.se
</p>

<hr>
<h2 id='prob.se'>Average p and average p(0) variance</h2><span id='topic+prob.se'></span>

<h3>Description</h3>

<p>Computes components of variance for average p=n/N and average p(0) with
weights based on empirical covariate distribution, if it contains covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prob.se(model, fct, vcov, observer = NULL, fittedmodel = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prob.se_+3A_model">model</code></td>
<td>
<p>ddf model object</p>
</td></tr>
<tr><td><code id="prob.se_+3A_fct">fct</code></td>
<td>
<p>function of detection probabilities; currently only
average (over covariates) detection probability p integrated over distance
or average (over covariates) detection probability at distance 0; p(0)</p>
</td></tr>
<tr><td><code id="prob.se_+3A_vcov">vcov</code></td>
<td>
<p>variance-covariance matrix of parameter estimates</p>
</td></tr>
<tr><td><code id="prob.se_+3A_observer">observer</code></td>
<td>
<p>1,2,3 for primary, secondary, or duplicates for average
p(0); passed to fct</p>
</td></tr>
<tr><td><code id="prob.se_+3A_fittedmodel">fittedmodel</code></td>
<td>
<p>full fitted ddf model when <code>trial.fi</code> or
<code>io.fi</code> is called from <code>trial</code> or <code>io</code> respectively</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Need to add equations here as I do not think they exist in any of the texts.
These should probably be checked with simulation.
</p>


<h3>Value</h3>

<table>
<tr><td><code>var</code></td>
<td>
<p>variance</p>
</td></tr> <tr><td><code>partial</code></td>
<td>
<p>partial derivatives of
parameters with respect to fct</p>
</td></tr> <tr><td><code>covar</code></td>
<td>
<p>covariance of n and average p
or p(0)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>See Also</h3>

<p>prob.deriv
</p>

<hr>
<h2 id='process.data'>Process data for fitting distance sampling detection function</h2><span id='topic+process.data'></span>

<h3>Description</h3>

<p>Sets up dataframe and does some basic error checking. Adds needed fields to
dataframe and to <code>meta.data</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process.data(data, meta.data = list(), check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="process.data_+3A_data">data</code></td>
<td>
<p>dataframe object</p>
</td></tr>
<tr><td><code id="process.data_+3A_meta.data">meta.data</code></td>
<td>
<p>meta.data options; see <code><a href="#topic+ddf">ddf</a></code> for a description</p>
</td></tr>
<tr><td><code id="process.data_+3A_check">check</code></td>
<td>
<p>if <code>TRUE</code> check data for errors in the mrds structure; for
<code>method="ds" check=FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function does a number of error checking tasks, creating fields and
adding to <code>meta.data</code> including:
</p>
<p>1) If <code>check=TRUE</code>, check to make sure the record structure is okay for
mrds data. The number of primary records (observer=1) must equal the number
of secondary records (observer=2). Also, a field in the dataframe is created
<code>timesseen</code> which counts the number of times an object was detected
0,1,2; if <code>timesseen=0</code> then the record is tossed from the analysis.
Also if there are differences in the data (distance, size, covariates) for
observer 1 and 2 a warning is issued that the analysis may fail.  The code
assumes these values are the same for both observers.
</p>
<p>2) Based on the presence of fields <code>distbegin</code> and <code>distend</code>, a
determination is made of whether the data analysis should be based on binned
distances and a field <code>binned</code> is created, which is <code>TRUE</code> if the
distance for the observation is binned.  By assigning for each observation
this allows an analysis of a mixture of binned and unbinned distances.
</p>
<p>4) Data are restricted such that distances are not greater than <code>width</code>
and not less than <code>left</code> if those values are specified in
<code>meta.data</code>.  If they are not specified then <code>left</code> defaults to 0
and <code>width</code> defaults to the largest distance measurement.
</p>
<p>5) Determine if an integration range (<code>int.begin</code> and <code>int.end</code>
has been specified for the observations.  If it has, add the structure to
<code>meta.data</code>.  The integration range is typically used for aerial
surveys in which the altitude varies such that the strip width (left to
width) changes with a change in altitude.
</p>
<p>6) Fields defined as factors are cleaned up such that any unused levels are
eliminated.
</p>
<p>7) If the restrictions placed on the data, eliminated all of the data, the
function stops with an error message
</p>


<h3>Value</h3>

<table>
<tr><td><code>xmat</code></td>
<td>
<p>processed <code>data.frame</code> with added fields</p>
</td></tr>
<tr><td><code>meta.data</code></td>
<td>
<p>meta.data list</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='pronghorn'>Pronghorn aerial survey data from Wyoming</h2><span id='topic+pronghorn'></span>

<h3>Description</h3>

<p>Detections of pronghorn from fixed-wing aerial surveys in Southeastern
Wyoming using four angular bins defined by strut marks. Illustrates data
where altitude above ground level (AGL) varies during the survey.
</p>


<h3>Format</h3>

<p>A data frame with 660 observations on the following 5 variables.
</p>
 <dl>
<dt>STRATUM</dt><dd><p>a numeric vector</p>
</dd>
<dt>direction</dt><dd><p>a factor with levels <code>N</code> <code>S</code>
representing the survey direction</p>
</dd> <dt>AGL</dt><dd><p>height above ground
level</p>
</dd> <dt>Band</dt><dd><p>a factor with levels <code>A</code> <code>B</code> <code>C</code>
<code>D</code> which represent angular bands between breaks at
35.42,44.56,51.52,61.02,70.97 degrees.  These angles were set based on
selected distance bins based on the target AGL.</p>
</dd>
<dt>cluster</dt><dd><p>number of pronghorn in the observed cluster</p>
</dd> </dl>



<h3>Details</h3>

<p>Each record is an observed cluster of pronghorn.  The data provide the
stratum for the observation, the direction of travel, the AGL at the time of
the observation, the angular bin which contained the center of the pronghorn
cluster(group), and the number of pronghorn in the group. The angular bins
were defined by a combination of two window and five wing strut marks to
define bin cutpoints for perpendicular ground distances of 0-65, 65-90,
90-115, 115-165 and 165-265 meters when the plane is 300' (91.4 meters)
above ground level. The inner band is considered a blind region due to
obstruction of view beneath the plane; thus th the line is offset 65 meters
from underneath the plane.
</p>


<h3>Source</h3>

<p>Data provided courtesy of Rich Guenzel of Wyoming Game and Fish.
</p>


<h3>References</h3>

<p>Laake, J., R. J. Guenzel, J. L. Bengtson, P. Boveng, M. Cameron,
and M. B. Hanson. 2008.  Coping with variation in aerial survey protocol
for line-transect sampling. Wildlife Research 35:289-298.
</p>

<hr>
<h2 id='ptdata.distance'>Single observer point count data example from Distance</h2><span id='topic+ptdata.distance'></span>

<h3>Description</h3>

<p>Single observer point count data example from Distance
</p>


<h3>Format</h3>

<p>The format is 144 obs of 6 variables:
distance: numeric distance from center
observer: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 2 1 2 1 2 1 2 1 2 ...
detected: numeric 0/1
object: sequential object number
Sample.Label: point label
Region.Label: single region label
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ptdata.distance)
xx &lt;- ddf(dsmodel = ~cds(key="hn", formula = ~1), data = ptdata.distance,
          method = "ds", meta.data = list(point=TRUE))
summary(xx)
plot(xx,main="Distance point count data")
ddf.gof(xx)
Regions &lt;- data.frame(Region.Label=1,Area=1)
Samples &lt;- data.frame(Sample.Label=1:30,
                      Region.Label=rep(1,30),
                      Effort=rep(1,30))
print(dht(xx,sample.table=Samples,region.table=Regions))

</code></pre>

<hr>
<h2 id='ptdata.dual'>Simulated dual observer point count data</h2><span id='topic+ptdata.dual'></span>

<h3>Description</h3>

<p>Simulated dual observer point count data with detection p(0)=0.8;
hn sigma=30; w=100 for both observers with dependency y&gt;0, gamma=0.1
</p>


<h3>Format</h3>

<p>The format is 420 obs of 6 variables:
distance: numeric distance from center
observer: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 2 1 2 1 2 1 2 1 2 ...
detected: numeric 0/1
person: Factor with 2 levels A,B
pair: Factor with 2 levels &quot;AB&quot; BA&quot; $
object : sequential object number
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ptdata.dual)
xx &lt;- ddf(mrmodel=~glm(formula=~distance),
          dsmodel = ~cds(key="hn", formula = ~1),
          data = ptdata.dual, method = "io", meta.data = list(point=TRUE))
summary(xx)
plot(xx,main="Simulated point count data")

</code></pre>

<hr>
<h2 id='ptdata.removal'>Simulated removal observer point count data</h2><span id='topic+ptdata.removal'></span>

<h3>Description</h3>

<p>Simulated removal observer point count data with detection p(0)=0.8;
hn sigma=30; w=100 for both observers with dependency y&gt;0, gamma=0.1
</p>


<h3>Format</h3>

<p>The format is 408 obs of 6 variables:
distance: numeric distance from center
observer: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 2 1 2 1 2 1 2 1 2 ...
detected: numeric 0/1
person: Factor with 2 levels A,B
pair: Factor with 2 levels &quot;AB&quot; BA&quot;
object: sequential object number
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ptdata.removal)
xx &lt;- ddf(mrmodel=~glm(formula=~distance),
          dsmodel = ~cds(key="hn", formula = ~1),
          data = ptdata.removal, method = "rem",
          meta.data = list(point=TRUE))
summary(xx)
plot(xx,main="Simulated point count data")

</code></pre>

<hr>
<h2 id='ptdata.single'>Simulated single observer point count data</h2><span id='topic+ptdata.single'></span>

<h3>Description</h3>

<p>Simulated single observer point count data with detection p(0)=1;
hn sigma=30; w=100
</p>


<h3>Format</h3>

<p>The format is 341 obs of 4 variables: ..$
distance: numeric distance from center $
observer: Factor w/ 2 levels &quot;1&quot;,&quot;2&quot;: 1 2 1 2 1 2 1 2 1 2 ...  ..$
detected: numeric 0/1  $ object : sequential object number
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(ptdata.single)
xx=ddf(dsmodel = ~cds(key="hn", formula = ~1), data = ptdata.single,
         method = "ds", meta.data = list(point=TRUE))
summary(xx)
plot(xx,main="Simulated point count data")

</code></pre>

<hr>
<h2 id='qqplot.ddf'>Quantile-quantile plot and goodness of fit tests for detection functions</h2><span id='topic+qqplot.ddf'></span>

<h3>Description</h3>

<p>Constructs a quantile-quantile (Q-Q) plot for fitted model as a graphical
check of goodness of fit. Formal goodness of fit testing for detection
function models using Kolmogorov-Smirnov and Cramer-von Mises tests. Both
tests are based on looking at the quantile-quantile plot produced by
<code><a href="#topic+qqplot.ddf">qqplot.ddf</a></code> and deviations from the line x=y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qqplot.ddf(model, plot = TRUE, nboot = 100, ks = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qqplot.ddf_+3A_model">model</code></td>
<td>
<p>fitted distance detection function model object</p>
</td></tr>
<tr><td><code id="qqplot.ddf_+3A_plot">plot</code></td>
<td>
<p>the Q-Q plot be plotted or just report statistics?</p>
</td></tr>
<tr><td><code id="qqplot.ddf_+3A_nboot">nboot</code></td>
<td>
<p>number of replicates to use to calculate p-values for the
goodness of fit test statistics</p>
</td></tr>
<tr><td><code id="qqplot.ddf_+3A_ks">ks</code></td>
<td>
<p>perform the Kolmogorov-Smirnov test (this involves many bootstraps
so can take a while)</p>
</td></tr>
<tr><td><code id="qqplot.ddf_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Kolmogorov-Smirnov test asks the question &quot;what's the largest vertical
distance between a point and the y=x line?&quot; It uses this distance as a
statistic to test the null hypothesis that the samples (EDF and CDF in our
case) are from the same distribution (and hence our model fits well). If the
deviation between the y=x line and the points is too large we reject the
null hypothesis and say the model doesn't have a good fit.
</p>
<p>Rather than looking at the single biggest difference between the y=x line
and the points in the Q-Q plot, we might prefer to think about all the
differences between line and points, since there may be many smaller
differences that we want to take into account rather than looking for one
large deviation. Its null hypothesis is the same, but the statistic it uses
is the sum of the deviations from each of the point to the line.
</p>


<h3>Value</h3>

<p>A list of goodness of fit related values: </p>
<table>
<tr><td><code>edf</code></td>
<td>
<p>matrix of lower
and upper empirical distribution function values</p>
</td></tr> <tr><td><code>cdf</code></td>
<td>
<p>fitted
cumulative distribution function values</p>
</td></tr> <tr><td><code>ks</code></td>
<td>
<p>list with K-S statistic
(<code>Dn</code>) and p-value (<code>p</code>)</p>
</td></tr> <tr><td><code>CvM</code></td>
<td>
<p>list with CvM statistic
(<code>W</code>) and p-value (<code>p</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that a bootstrap procedure is required to ensure that the p-values from
the procedure are correct as the we are comparing the cumulative
distribution function (CDF) and empirical distribution function (EDF) and we
have estimated the parameters of the detection function.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>


<h3>References</h3>

<p>Burnham, K.P., S.T. Buckland, J.L. Laake, D.L. Borchers, T.A.
Marques, J.R.B. Bishop, and L. Thomas. 2004.  Further topics in distance
sampling. pp: 385-389. In: Advanced Distance Sampling, eds. S.T. Buckland,
D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas.
Oxford University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ddf.gof">ddf.gof</a></code>, <code><a href="#topic+cdf.ds">cdf.ds</a></code>
</p>

<hr>
<h2 id='rem.glm'>Iterative offset model fitting of mark-recapture with removal model</h2><span id='topic+rem.glm'></span>

<h3>Description</h3>

<p>Detection function fitting from mark-recapture data with a removal
configuration in which a secondary observer knows what the primary observer
detects and detects objects missed by the primary observer.  The iterative
offset glm/gam uses an offset to compensate for the conditioning on the set
of objects seen by either observer (eg 00 those missed by both observers are
not included in the analysis.  This function is similar to
<code><a href="#topic+io.glm">io.glm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rem.glm(
  datavec,
  fitformula,
  eps = 1e-05,
  iterlimit = 500,
  GAM = FALSE,
  gamplot = TRUE,
  datavec2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rem.glm_+3A_datavec">datavec</code></td>
<td>
<p>dataframe containing records seen by either observer 1 or 2</p>
</td></tr>
<tr><td><code id="rem.glm_+3A_fitformula">fitformula</code></td>
<td>
<p>logit link formula</p>
</td></tr>
<tr><td><code id="rem.glm_+3A_eps">eps</code></td>
<td>
<p>convergence criterion</p>
</td></tr>
<tr><td><code id="rem.glm_+3A_iterlimit">iterlimit</code></td>
<td>
<p>maximum number of iterations allowed</p>
</td></tr>
<tr><td><code id="rem.glm_+3A_gam">GAM</code></td>
<td>
<p>uses GAM instead of GLM for fitting</p>
</td></tr>
<tr><td><code id="rem.glm_+3A_gamplot">gamplot</code></td>
<td>
<p>set to TRUE to get a gam plot object if <code>GAM=TRUE</code></p>
</td></tr>
<tr><td><code id="rem.glm_+3A_datavec2">datavec2</code></td>
<td>
<p>dataframe containing all records for observer 1 and observer
2 as in io.glm form; this is used in case there is an observer(not
platform effect)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The only difference between this function and <code><a href="#topic+io.glm">io.glm</a></code> is the
offset and the data construction because there is only one detection
function being estimated for the primary observer. The two functions could
be merged.
</p>


<h3>Value</h3>

<p>list of class(&quot;remglm&quot;,&quot;glm&quot;,&quot;lm&quot;) or class(&quot;remglm&quot;,&quot;gam&quot;)
</p>
<table>
<tr><td><code>glmobj</code></td>
<td>
<p>GLM or GAM object</p>
</td></tr> <tr><td><code>offsetvalue</code></td>
<td>
<p>offsetvalues from
iterative fit</p>
</td></tr> <tr><td><code>plotobj</code></td>
<td>
<p>gam plot object (if GAM &amp; gamplot==TRUE,
else NULL)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>currently the code in this function for GAMs has been commented out
until the remainder of the mrds package will work with GAMs.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>


<h3>References</h3>

<p>Buckland, S.T., J.M. breiwick, K.L. Cattanach, and J.L. Laake.
1993. Estimated population size of the California gray whale.  Marine
Mammal Science, 9:235-249.
</p>
<p>Burnham, K.P., S.T. Buckland, J.L. Laake, D.L. Borchers, T.A. Marques,
J.R.B. Bishop, and L. Thomas. 2004.  Further topics in distance sampling.
pp: 360-363. In: Advanced Distance Sampling, eds. S.T. Buckland,
D.R.Anderson, K.P. Burnham, J.L. Laake, D.L. Borchers, and L. Thomas.
Oxford University Press.
</p>

<hr>
<h2 id='rescale_pars'>Calculate the parameter rescaling for parameters associated with covariates</h2><span id='topic+rescale_pars'></span>

<h3>Description</h3>

<p>This will calculate the rescaling needed when covariates to be included in
the scale of the detection function are &quot;too big&quot;. Based on code from
<code><a href="optimx.html#topic+optimx">optimx</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rescale_pars(initialvalues, ddfobj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rescale_pars_+3A_initialvalues">initialvalues</code></td>
<td>
<p>starting values for the optimisation</p>
</td></tr>
<tr><td><code id="rescale_pars_+3A_ddfobj">ddfobj</code></td>
<td>
<p>detection function object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Derivative-free methods like nlminb are sensitive to the parameters being
poorly scaled. This can also cause problems for quasi-Newton methods too (at
least, bad scaling won't _help_ the optimisation). So here we rescale the
parameters if necessary (unless we already got scaling from control)
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>

<hr>
<h2 id='sample_ddf'>Generate data from a fitted detection function and refit the model</h2><span id='topic+sample_ddf'></span>

<h3>Description</h3>

<p>Generate data from a fitted detection function and refit the model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_ddf(ds.object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_ddf_+3A_ds.object">ds.object</code></td>
<td>
<p>a fitted detection function object</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function changes the random number generator seed. To avoid any
potential side-effects, use something like: <code>seed &lt;-
get(".Random.seed",envir=.GlobalEnv)</code> before running code and
<code>assign(".Random.seed",seed,envir=.GlobalEnv)</code> after.
</p>


<h3>Author(s)</h3>

<p>David L. Miller
</p>

<hr>
<h2 id='setbounds'>Set parameter bounds</h2><span id='topic+setbounds'></span>

<h3>Description</h3>

<p>Set values of lower and upper bounds and check lengths of any user-specified
values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setbounds(lowerbounds, upperbounds, initialvalues, ddfobj, width, left)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setbounds_+3A_lowerbounds">lowerbounds</code></td>
<td>
<p>vector of lower bounds</p>
</td></tr>
<tr><td><code id="setbounds_+3A_upperbounds">upperbounds</code></td>
<td>
<p>vector of upper bounds</p>
</td></tr>
<tr><td><code id="setbounds_+3A_initialvalues">initialvalues</code></td>
<td>
<p>vector of initial parameter estimates</p>
</td></tr>
<tr><td><code id="setbounds_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance detection function object</p>
</td></tr>
<tr><td><code id="setbounds_+3A_width">width</code></td>
<td>
<p>truncation distance</p>
</td></tr>
<tr><td><code id="setbounds_+3A_left">left</code></td>
<td>
<p>left truncation distance</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>lower</code></td>
<td>
<p>vector of lower bounds</p>
</td></tr> <tr><td><code>upper</code></td>
<td>
<p>vector of upper
bounds</p>
</td></tr> <tr><td><code>setlower</code></td>
<td>
<p>logical indicating whether user set lower bounds</p>
</td></tr>
<tr><td><code>setupper</code></td>
<td>
<p>logical indicating whether user set upper bounds</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='setcov'>Creates design matrix for covariates in detection function</h2><span id='topic+setcov'></span>

<h3>Description</h3>

<p>This function creates a design matrix for the g(0) or scale covariates using
the input model formula. It returns a list which contains 2 elements: 1)
dim: the dimension (number of columns) of the design matrix, and 2) cov: the
constructed design matrix. This function is relatively simple because it
uses the built-in function <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> which does the
majority of the work.  This function handles 2 exceptions &quot;~.&quot;, the null
model with 0 columns and &quot;~1&quot; the intercept only model - a column of 1s.  If
a model other than the 2 exceptions is provided, it calls
<code><a href="stats.html#topic+model.matrix">model.matrix</a></code> to construct the columns. If any of the columns of
the design matrix are all 0's the column is removed.  This occurs when there
is no data for a particular factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setcov(dmat, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setcov_+3A_dmat">dmat</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="setcov_+3A_model">model</code></td>
<td>
<p>model formula</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a design matrix for the specified data and model
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='setinitial.ds'>Set initial values for detection function based on distance sampling</h2><span id='topic+setinitial.ds'></span><span id='topic+sethazard'></span>

<h3>Description</h3>

<p>For a given detection function, it computes the initial values for the
parameters including scale and shape parameters and adjustment function
parameters if any.  If there are user-defined initial values only the
parameters not specified by the user are computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setinitial.ds(ddfobj, width, initial, point, left)
       sethazard(ddfobj, dmat, width, left, point)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setinitial.ds_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance detection function object</p>
</td></tr>
<tr><td><code id="setinitial.ds_+3A_width">width</code></td>
<td>
<p>half-width of transect or radius of point count</p>
</td></tr>
<tr><td><code id="setinitial.ds_+3A_initial">initial</code></td>
<td>
<p>list of user-defined initial values with possible elements:
<code>scale</code>, <code>shape</code>, <code>adjustment</code></p>
</td></tr>
<tr><td><code id="setinitial.ds_+3A_point">point</code></td>
<td>
<p>if <code>TRUE</code>, point count data; otherwise, line transect data</p>
</td></tr>
<tr><td><code id="setinitial.ds_+3A_left">left</code></td>
<td>
<p>left truncation</p>
</td></tr>
<tr><td><code id="setinitial.ds_+3A_dmat">dmat</code></td>
<td>
<p><code>xmat</code> from <code>ddfobj</code></p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>scale</code></td>
<td>
<p>vector of initial scale parameter values</p>
</td></tr>
<tr><td><code>shape</code></td>
<td>
<p>vector of initial shape parameter values</p>
</td></tr>
<tr><td><code>adjustment</code></td>
<td>
<p>vector of initial adjustment function parameter values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>

<hr>
<h2 id='sim.mix'>Simulation of distance sampling data via mixture models
Allows one to simulate line transect distance sampling data using 
a mixture of half-normal detection functions.</h2><span id='topic+sim.mix'></span>

<h3>Description</h3>

<p>Simulation of distance sampling data via mixture models
Allows one to simulate line transect distance sampling data using 
a mixture of half-normal detection functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.mix(n, sigma, mix.prop, width, means = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.mix_+3A_n">n</code></td>
<td>
<p>number of samples to generate</p>
</td></tr>
<tr><td><code id="sim.mix_+3A_sigma">sigma</code></td>
<td>
<p>vector of scale parameters</p>
</td></tr>
<tr><td><code id="sim.mix_+3A_mix.prop">mix.prop</code></td>
<td>
<p>vector of mixture proportions (same length as sigma)</p>
</td></tr>
<tr><td><code id="sim.mix_+3A_width">width</code></td>
<td>
<p>truncation</p>
</td></tr>
<tr><td><code id="sim.mix_+3A_means">means</code></td>
<td>
<p>vector of means (used to generate wacky, non-monotonic data)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>distances a vector of distances
</p>


<h3>Note</h3>

<p>At the moment this is TOTALLY UNSUPPORTED!
Please don't use it for anything important!
</p>


<h3>Author(s)</h3>

<p>David Lawrence Miller
</p>

<hr>
<h2 id='solvecov'>Invert of covariance matrices</h2><span id='topic+solvecov'></span>

<h3>Description</h3>

<p>Tries to invert a matrix by <code>solve</code>. If this fails because of
singularity, an eigenvector decomposition is computed, and eigenvalues below
<code>1/cmax</code> are replaced by <code>1/cmax</code>, i.e., <code>cmax</code> will be the
corresponding eigenvalue of the inverted matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solvecov(m, cmax = 1e+10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="solvecov_+3A_m">m</code></td>
<td>
<p>a numeric symmetric matrix.</p>
</td></tr>
<tr><td><code id="solvecov_+3A_cmax">cmax</code></td>
<td>
<p>a positive value, see above.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components: <code>inv</code> the inverted
matrix, <code>coll</code> <code>TRUE</code> if <code>solve</code> failed because of
singularity.
</p>


<h3>Source</h3>

<p><code>solvecov</code> code was taken from package <code>fpc</code>: Christian Hennig
</p>


<h3>Author(s)</h3>

<p>Christian Hennig
</p>


<h3>See Also</h3>

<p>solve, eigen
</p>

<hr>
<h2 id='stake77'>Wooden stake data from 1977 survey</h2><span id='topic+stake77'></span>

<h3>Description</h3>

<p>Multiple surveys by different observers of a single 1km transect containing
150 wooden stakes placed randomly throughout a 40 m strip (20m on either
side).
</p>


<h3>Format</h3>

<p>A data frame with 150 observations on the following 10 variables.
</p>
 <dl>
<dt>StakeNo</dt><dd><p>unique number for each stake 1-150</p>
</dd>
<dt>PD</dt><dd><p>perpendicular distance at which the stake was placed
from the line</p>
</dd> <dt>Obs1</dt><dd><p>0/1 whether missed/seen by observer 1</p>
</dd>
<dt>Obs2</dt><dd><p>0/1 whether missed/seen by observer 2</p>
</dd>
<dt>Obs3</dt><dd><p>0/1 whether missed/seen by observer 3</p>
</dd>
<dt>Obs4</dt><dd><p>0/1 whether missed/seen by observer 4</p>
</dd>
<dt>Obs5</dt><dd><p>0/1 whether missed/seen by observer 5</p>
</dd>
<dt>Obs6</dt><dd><p>0/1 whether missed/seen by observer 6</p>
</dd>
<dt>Obs7</dt><dd><p>0/1 whether missed/seen by observer 7</p>
</dd>
<dt>Obs8</dt><dd><p>0/1 whether missed/seen by observer 8</p>
</dd> </dl>



<h3>Source</h3>

<p>Laake, J. 1978. Line transect estimators robust to animal movement.
M.S. Thesis. Utah State University, Logan, Utah. 55p.
</p>


<h3>References</h3>

<p>Burnham, K. P., D. R. Anderson, and J. L. Laake. 1980.
Estimation of Density from Line Transect Sampling of Biological
Populations. Wildlife Monographs:7-202.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(stake77)
# Extract functions for stake data and put in the mrds format
extract.stake &lt;- function(stake,obs){
  extract.obs &lt;- function(obs){
    example &lt;- subset(stake,eval(parse(text=paste("Obs",obs,"==1",sep=""))),
                      select="PD")
    example$distance &lt;- example$PD
    example$object &lt;- 1:nrow(example)
    example$PD &lt;- NULL
    return(example)
  }
  if(obs!="all"){
    return(extract.obs(obs=obs))
  }else{
    example &lt;- NULL
    for(i in 1:(ncol(stake)-2)){
      df &lt;- extract.obs(obs=i)
      df$person &lt;- i
      example &lt;- rbind(example,df)
    }
    example$person &lt;- factor(example$person)
    example$object &lt;- 1:nrow(example)
    return(example)
  }
}
extract.stake.pairs &lt;- function(stake,obs1,obs2,removal=FALSE){
  obs1 &lt;- paste("Obs",obs1,sep="")
  obs2 &lt;- paste("Obs",obs2,sep="")
  example &lt;- subset(stake,eval(parse(text=paste(obs1,"==1 |",obs2,"==1 ",
                                       sep=""))),select=c("PD",obs1,obs2))
  names(example) &lt;- c("distance","obs1","obs2")
  detected &lt;- c(example$obs1,example$obs2)
  example &lt;- data.frame(object   = rep(1:nrow(example),2),
                        distance = rep(example$distance,2),
                        detected = detected,
                        observer = c(rep(1,nrow(example)),
                                     rep(2,nrow(example))))
  if(removal) example$detected[example$observer==2] &lt;- 1
  return(example)
}
# extract data for observer 1 and fit a single observer model
stakes &lt;- extract.stake(stake77,1)
ds.model &lt;- ddf(dsmodel = ~mcds(key = "hn", formula = ~1), data = stakes,
                method = "ds", meta.data = list(width = 20))
plot(ds.model,breaks=seq(0,20,2),showpoints=TRUE)
ddf.gof(ds.model)

# extract data from observers 1 and 3 and fit an io model
stkpairs &lt;- extract.stake.pairs(stake77,1,3,removal=FALSE)
io.model &lt;- ddf(dsmodel = ~mcds(key = "hn", formula=~1),
                mrmodel=~glm(formula=~distance),
                data = stkpairs, method = "io")
summary(io.model)
par(mfrow=c(3,2))
plot(io.model,breaks=seq(0,20,2),showpoints=TRUE,new=FALSE)
dev.new()
ddf.gof(io.model)

</code></pre>

<hr>
<h2 id='stake78'>Wooden stake data from 1978 survey</h2><span id='topic+stake78'></span>

<h3>Description</h3>

<p>Multiple surveys by different observers of a single 1km transect containing
150 wooden stakes placed based on expected uniform distribution throughout a
40 m strip (20m on either side).
</p>


<h3>Format</h3>

<p>A data frame with 150 observations on the following 13 variables.
</p>
 <dl>
<dt>StakeNo</dt><dd><p>unique number for each stake 1-150</p>
</dd>
<dt>PD</dt><dd><p>perpendicular distance at which the stake was placed
from the line</p>
</dd> <dt>Obs1</dt><dd><p>0/1 whether missed/seen by observer 1</p>
</dd>
<dt>Obs2</dt><dd><p>0/1 whether missed/seen by observer 2</p>
</dd>
<dt>Obs3</dt><dd><p>0/1 whether missed/seen by observer 3</p>
</dd>
<dt>Obs4</dt><dd><p>0/1 whether missed/seen by observer 4</p>
</dd>
<dt>Obs5</dt><dd><p>0/1 whether missed/seen by observer 5</p>
</dd>
<dt>Obs6</dt><dd><p>0/1 whether missed/seen by observer 6</p>
</dd>
<dt>Obs7</dt><dd><p>0/1 whether missed/seen by observer 7</p>
</dd>
<dt>Obs8</dt><dd><p>0/1 whether missed/seen by observer 8</p>
</dd>
<dt>Obs9</dt><dd><p>0/1 whether missed/seen by observer 9</p>
</dd>
<dt>Obs10</dt><dd><p>0/1 whether missed/seen by observer 10</p>
</dd>
<dt>Obs11</dt><dd><p>0/1 whether missed/seen by observer 11</p>
</dd> </dl>



<h3>Details</h3>

<p>The 1997 survey was based on a single realization of a uniform distribution.
Because it was a single transect and there was no randomization of the
distances for each survey, we repeated the experiment and used distances
that provided a uniform distribution but randomly sorted the positions along
the line so there was no pattern obvious to the observer.
</p>


<h3>Source</h3>

<p>Laake, J. 1978. Line transect estimators robust to animal movement.
M.S. Thesis. Utah State University, Logan, Utah. 55p.
</p>


<h3>References</h3>

<p>Burnham, K. P., D. R. Anderson, and J. L. Laake. 1980.
Estimation of Density from Line Transect Sampling of Biological
Populations. Wildlife Monographs:7-202.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(stake78)
data(stake77)
# compare distribution of distances for all stakes
hist(stake77$PD)
hist(stake78$PD)
# Extract stake data and put in the mrds format for model fitting.
extract.stake &lt;- function(stake,obs){
  extract.obs &lt;- function(obs){
    example &lt;- subset(stake,eval(parse(text=paste("Obs",obs,"==1",sep=""))),
                      select="PD")
    example$distance &lt;- example$PD
    example$object &lt;- 1:nrow(example)
    example$PD &lt;- NULL
    return(example)
  }
  if(obs!="all"){
     return(extract.obs(obs=obs))
  }else{
    example &lt;- NULL
    for(i in 1:(ncol(stake)-2)){
      df &lt;- extract.obs(obs=i)
      df$person &lt;- i
      example &lt;- rbind(example,df)
    }
    example$person &lt;- factor(example$person)
    example$object &lt;- 1:nrow(example)
    return(example)
  }
}
extract.stake.pairs &lt;- function(stake,obs1,obs2,removal=FALSE){
  obs1 &lt;- paste("Obs",obs1,sep="")
  obs2 &lt;- paste("Obs",obs2,sep="")
  example &lt;- subset(stake,eval(parse(text=paste(obs1,"==1 |",obs2,"==1 ",
                                     sep=""))), select=c("PD",obs1,obs2))
  names(example) &lt;- c("distance","obs1","obs2")
  detected &lt;- c(example$obs1,example$obs2)
  example &lt;- data.frame(object=rep(1:nrow(example),2),
                        distance=rep(example$distance,2),
                        detected = detected,
                        observer=c(rep(1,nrow(example)),
                                   rep(2,nrow(example))))
  if(removal) example$detected[example$observer==2] &lt;- 1
  return(example)
}

# extract data for observer 10 and fit a single observer model
stakes &lt;- extract.stake(stake78,10)
ds.model &lt;- ddf(dsmodel = ~mcds(key = "hn", formula = ~1), data = stakes,
                method = "ds", meta.data = list(width = 20))
plot(ds.model,breaks=seq(0,20,2),showpoints=TRUE)
ddf.gof(ds.model)

# extract data from observers 5 and 7 and fit an io model
stkpairs &lt;- extract.stake.pairs(stake78,5,7,removal=FALSE)
io.model &lt;- ddf(dsmodel = ~mcds(key = "hn", formula=~1),
                mrmodel=~glm(formula=~distance),
                data = stkpairs, method = "io")
summary(io.model)
par(mfrow=c(3,2))
plot(io.model,breaks=seq(0,20,2),showpoints=TRUE,new=FALSE)
ddf.gof(io.model)


</code></pre>

<hr>
<h2 id='summary.ds'>Summary of distance detection function model object</h2><span id='topic+summary.ds'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ds'
summary(object, se = TRUE, N = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ds_+3A_object">object</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="summary.ds_+3A_se">se</code></td>
<td>
<p>if TRUE, computes standard errors</p>
</td></tr>
<tr><td><code id="summary.ds_+3A_n">N</code></td>
<td>
<p>if TRUE, computes abundance in covered (sampled) region</p>
</td></tr>
<tr><td><code id="summary.ds_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>N</code> is used to suppress computation of
abundance and average detection probability in calls to summarize the
<code>ds</code> and either <code>io.fi</code> or <code>trial.fi</code> for summaries of
<code>io</code> and <code>trial</code> objects respectively which are composed of a
<code>ds</code> model object and a mark-recapture model object. The corresponding
print function is called to print the summary results.
</p>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function is called by the generic function <code>summary</code> for any
<code>ddf</code> model object.  Each function can be called directly by the
user, but it is typically safest to use the generic function
<code>summary</code> which calls the appropriate function based on the type of
<code>ddf</code> model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='summary.io'>Summary of distance detection function model object</h2><span id='topic+summary.io'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'io'
summary(object, se = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.io_+3A_object">object</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="summary.io_+3A_se">se</code></td>
<td>
<p>if TRUE, computes standard errors</p>
</td></tr>
<tr><td><code id="summary.io_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>N</code> is used to suppress computation of
abundance and average detection probability in calls to summarize the
<code>ds</code> and either <code>io.fi</code> or <code>trial.fi</code> for summaries of
<code>io</code> and <code>trial</code> objects respectively which are composed of a
<code>ds</code> model object and a mark-recapture model object. The corresponding
print function is called to print the summary results.
</p>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function is called by the generic function <code>summary</code> for any
<code>ddf</code> model object.  Each function can be called directly by the
user, but it is typically safest to use the generic function
<code>summary</code> which calls the appropriate function based on the type of
<code>ddf</code> model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='summary.io.fi'>Summary of distance detection function model object</h2><span id='topic+summary.io.fi'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'io.fi'
summary(object, se = TRUE, N = TRUE, fittedmodel = NULL, ddfobj = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.io.fi_+3A_object">object</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="summary.io.fi_+3A_se">se</code></td>
<td>
<p>if TRUE, computes standard errors</p>
</td></tr>
<tr><td><code id="summary.io.fi_+3A_n">N</code></td>
<td>
<p>if TRUE, computes abundance in covered (sampled) region</p>
</td></tr>
<tr><td><code id="summary.io.fi_+3A_fittedmodel">fittedmodel</code></td>
<td>
<p>full fitted model when called from <code>trial</code> or
<code>io</code></p>
</td></tr>
<tr><td><code id="summary.io.fi_+3A_ddfobj">ddfobj</code></td>
<td>
<p>distance sampling object description</p>
</td></tr>
<tr><td><code id="summary.io.fi_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>N</code> is used to suppress computation of
abundance and average detection probability in calls to summarize the
<code>ds</code> and either <code>io.fi</code> or <code>trial.fi</code> for summaries of
<code>io</code> and <code>trial</code> objects respectively which are composed of a
<code>ds</code> model object and a mark-recapture model object. The corresponding
print function is called to print the summary results.
</p>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function is called by the generic function <code>summary</code> for any
<code>ddf</code> model object.  Each function can be called directly by the
user, but it is typically safest to use the generic function
<code>summary</code> which calls the appropriate function based on the type of
<code>ddf</code> model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='summary.rem'>Summary of distance detection function model object</h2><span id='topic+summary.rem'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rem'
summary(object, se = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rem_+3A_object">object</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="summary.rem_+3A_se">se</code></td>
<td>
<p>if TRUE, computes standard errors</p>
</td></tr>
<tr><td><code id="summary.rem_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>N</code> is used to suppress computation of
abundance and average detection probability in calls to summarize the
<code>ds</code> and either <code>io.fi</code> or <code>trial.fi</code> for summaries of
<code>io</code> and <code>trial</code> objects respectively which are composed of a
<code>ds</code> model object and a mark-recapture model object. The corresponding
print function is called to print the summary results.
</p>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function is called by the generic function <code>summary</code> for any
<code>ddf</code> model object.  Each function can be called directly by the
user, but it is typically safest to use the generic function
<code>summary</code> which calls the appropriate function based on the type of
<code>ddf</code> model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='summary.rem.fi'>Summary of distance detection function model object</h2><span id='topic+summary.rem.fi'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rem.fi'
summary(object, se = TRUE, N = TRUE, fittedmodel = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rem.fi_+3A_object">object</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="summary.rem.fi_+3A_se">se</code></td>
<td>
<p>if TRUE, computes standard errors</p>
</td></tr>
<tr><td><code id="summary.rem.fi_+3A_n">N</code></td>
<td>
<p>if TRUE, computes abundance in covered (sampled) region</p>
</td></tr>
<tr><td><code id="summary.rem.fi_+3A_fittedmodel">fittedmodel</code></td>
<td>
<p>full fitted model when called from <code>trial</code> or
<code>io</code></p>
</td></tr>
<tr><td><code id="summary.rem.fi_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>N</code> is used to suppress computation of
abundance and average detection probability in calls to summarize the
<code>ds</code> and either <code>io.fi</code> or <code>trial.fi</code> for summaries of
<code>io</code> and <code>trial</code> objects respectively which are composed of a
<code>ds</code> model object and a mark-recapture model object. The corresponding
print function is called to print the summary results.
</p>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function is called by the generic function <code>summary</code> for any
<code>ddf</code> model object.  Each function can be called directly by the
user, but it is typically safest to use the generic function
<code>summary</code> which calls the appropriate function based on the type of
<code>ddf</code> model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='summary.trial'>Summary of distance detection function model object</h2><span id='topic+summary.trial'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trial'
summary(object, se = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.trial_+3A_object">object</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="summary.trial_+3A_se">se</code></td>
<td>
<p>if TRUE, computes standard errors</p>
</td></tr>
<tr><td><code id="summary.trial_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>N</code> is used to suppress computation of
abundance and average detection probability in calls to summarize the
<code>ds</code> and either <code>io.fi</code> or <code>trial.fi</code> for summaries of
<code>io</code> and <code>trial</code> objects respectively which are composed of a
<code>ds</code> model object and a mark-recapture model object. The corresponding
print function is called to print the summary results.
</p>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function is called by the generic function <code>summary</code> for any
<code>ddf</code> model object.  Each function can be called directly by the
user, but it is typically safest to use the generic function
<code>summary</code> which calls the appropriate function based on the type of
<code>ddf</code> model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='summary.trial.fi'>Summary of distance detection function model object</h2><span id='topic+summary.trial.fi'></span>

<h3>Description</h3>

<p>Provides a brief summary of data and fitted detection probability model
parameters, model selection criterion, and optionally abundance in the
covered (sampled) region and its standard error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trial.fi'
summary(object, se = TRUE, N = TRUE, fittedmodel = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.trial.fi_+3A_object">object</code></td>
<td>
<p>a <code>ddf</code> model object</p>
</td></tr>
<tr><td><code id="summary.trial.fi_+3A_se">se</code></td>
<td>
<p>if TRUE, computes standard errors</p>
</td></tr>
<tr><td><code id="summary.trial.fi_+3A_n">N</code></td>
<td>
<p>if TRUE, computes abundance in covered (sampled) region</p>
</td></tr>
<tr><td><code id="summary.trial.fi_+3A_fittedmodel">fittedmodel</code></td>
<td>
<p>full fitted model when called from <code>trial</code> or
<code>io</code></p>
</td></tr>
<tr><td><code id="summary.trial.fi_+3A_...">...</code></td>
<td>
<p>unspecified and unused arguments for S3 consistency</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument <code>N</code> is used to suppress computation of
abundance and average detection probability in calls to summarize the
<code>ds</code> and either <code>io.fi</code> or <code>trial.fi</code> for summaries of
<code>io</code> and <code>trial</code> objects respectively which are composed of a
<code>ds</code> model object and a mark-recapture model object. The corresponding
print function is called to print the summary results.
</p>


<h3>Value</h3>

<p>list of extracted and summarized objects
</p>


<h3>Note</h3>

<p>This function is called by the generic function <code>summary</code> for any
<code>ddf</code> model object.  Each function can be called directly by the
user, but it is typically safest to use the generic function
<code>summary</code> which calls the appropriate function based on the type of
<code>ddf</code> model.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='survey.region.dht'>Extrapolate Horvitz-Thompson abundance estimates to entire surveyed region</h2><span id='topic+survey.region.dht'></span>

<h3>Description</h3>

<p>Extrapolate Horvitz-Thompson abundance estimates to entire surveyed region
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survey.region.dht(Nhat.by.sample, samples, width, left, point, areas.supplied)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="survey.region.dht_+3A_nhat.by.sample">Nhat.by.sample</code></td>
<td>
<p>dataframe of abundance by sample</p>
</td></tr>
<tr><td><code id="survey.region.dht_+3A_samples">samples</code></td>
<td>
<p>samples table</p>
</td></tr>
<tr><td><code id="survey.region.dht_+3A_width">width</code></td>
<td>
<p>truncation width</p>
</td></tr>
<tr><td><code id="survey.region.dht_+3A_left">left</code></td>
<td>
<p>left truncation if any</p>
</td></tr>
<tr><td><code id="survey.region.dht_+3A_point">point</code></td>
<td>
<p>if TRUE point count otherwise line transect</p>
</td></tr>
<tr><td><code id="survey.region.dht_+3A_areas.supplied">areas.supplied</code></td>
<td>
<p>if <code>TRUE</code>, covered area is extracted from the
<code>CoveredArea</code> column of <code>Nhat.by.sample</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Revised Nhat.by.sample dataframe containing estimates extrapolated
to survey region
</p>


<h3>Note</h3>

<p>Internal function called by <code><a href="#topic+dht">dht</a></code> and related functions.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake and David L Miller
</p>

<hr>
<h2 id='test.breaks'>Test validity for histogram breaks(cutpoints)</h2><span id='topic+test.breaks'></span>

<h3>Description</h3>

<p>Determines whether user specified breaks for histograms are properly ordered
and match the left and right truncation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.breaks(breaks, left, width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="test.breaks_+3A_breaks">breaks</code></td>
<td>
<p>vector of cutpoints (breaks) for distance histogram</p>
</td></tr>
<tr><td><code id="test.breaks_+3A_left">left</code></td>
<td>
<p>left truncation value</p>
</td></tr>
<tr><td><code id="test.breaks_+3A_width">width</code></td>
<td>
<p>right truncation value; either radius of point count or
half-width of transect</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of breaks modified to be valid if necessary
</p>


<h3>Author(s)</h3>

<p>Jeff Laake
</p>

<hr>
<h2 id='varn'>Compute empirical variance of encounter rate</h2><span id='topic+varn'></span><span id='topic+covn'></span>

<h3>Description</h3>

<p>Computes one of a series of possible variance estimates for the observed
encounter rate for a set of sample measurements (e.g., line lengths) and
number of observations per sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varn(lvec,nvec,type)

         covn(lvec, groups1, groups2, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varn_+3A_lvec">lvec</code></td>
<td>
<p>vector of sample measurements (e.g., line lengths)</p>
</td></tr>
<tr><td><code id="varn_+3A_nvec">nvec</code></td>
<td>
<p>vector of number observed</p>
</td></tr>
<tr><td><code id="varn_+3A_type">type</code></td>
<td>
<p>choice of variance estimator to use for encounter rate</p>
</td></tr>
<tr><td><code id="varn_+3A_groups1">groups1</code></td>
<td>
<p>vector of number of groups observed</p>
</td></tr>
<tr><td><code id="varn_+3A_groups2">groups2</code></td>
<td>
<p>vector of number of individuals observed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The choice of type follows the notation of Fewster et al. (2009) in that there are 8 choices of encounter rate variance that can be computed for lines and one for points:
</p>

<dl>
<dt><code>R2</code></dt><dd><p>random line placement with unequal line lengths
(design-assisted estimator)</p>
</dd>
<dt><code>R3</code></dt><dd><p>random line placement, model-assisted estimator, based on
true contagion process</p>
</dd>
<dt><code>R4</code></dt><dd><p>random line placement, model-assisted estimator, based on
apparent contagion process</p>
</dd>
<dt><code>S1</code></dt><dd><p>systematic line placement, post-stratification with no
strata overlap</p>
</dd>
<dt><code>S2</code></dt><dd><p>systematic line placement, post-stratification with no
strata overlap, variances weighted by line length per stratum</p>
</dd>
<dt><code>O1</code></dt><dd><p>systematic line placement, post-stratification with
overlapping strata (akin to S1)</p>
</dd>
<dt><code>O2</code></dt><dd><p>systematic line placement, post-stratification with
overlapping strata (weighted by line length per stratum, akin to S2)</p>
</dd>
<dt><code>O3</code></dt><dd><p>systematic line placement, post-stratification with
overlapping strata, model-assisted estimator with trend in encounter rate
with line length</p>
</dd>
<dt><code>P2</code></dt><dd><p>random point placement, potentially unequal number of
visits per point, design-based estimator</p>
</dd>
<dt><code>P3</code></dt><dd><p>random point placement, potentially unequal number of
visits per point, model-based estimator</p>
</dd>
</dl>

<p>Default value is <code>"R2"</code>, shown in Fewster et al. (2009) to have good
performance for completely random designs for lines. For systematic parallel
line transect designs, Fewster et al. recommend <code>"O2"</code>. For point
transects the default is <code>"P2"</code> (but <code>"P3"</code> is also available).
</p>
<p>For the systematic estimators, pairs are assigned in the order they are
given in the <code>lengths</code> and <code>groups</code> vectors.
</p>


<h3>Value</h3>

<p>Variance of encounter rate as defined by arguments
</p>


<h3>Note</h3>

<p>This function is also used with different calling arguments to compute
Innes et al variance of the estimated abundances/length rather than
observation encounter rate. The function covn is probably only valid for R3
and R2.  Currently, the R2 form is used for all types other than R3.
</p>


<h3>Author(s)</h3>

<p>Jeff Laake, David L Miller
</p>


<h3>References</h3>

<p>Fewster, R.M., S.T. Buckland, K.P. Burnham, D.L. Borchers, P.E.
Jupp, J.L. Laake and L. Thomas. 2009. Estimating the encounter rate
variance in distance sampling. Biometrics 65: 225-236.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
