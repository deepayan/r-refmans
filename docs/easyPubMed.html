<!DOCTYPE html><html lang="en"><head><title>Help for package easyPubMed</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {easyPubMed}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#easyPubMed-package'><p>Retrieve and Process Scientific Publication Records from Pubmed</p></a></li>
<li><a href='#article_to_df'><p>Extract Data from a PubMed Record</p></a></li>
<li><a href='#articles_to_list'><p>Cast PubMed Data into a List of Articles</p></a></li>
<li><a href='#batch_pubmed_download'><p>Download PubMed Records in XML or TXT Format</p></a></li>
<li><a href='#custom_grep'><p>Retrieve Text Between XML Tags</p></a></li>
<li><a href='#EPMsamples'><p>PubMed Records downloaded and analyzed via easyPubMed</p></a></li>
<li><a href='#fetch_all_pubmed_ids'><p>Retrieve All PubMed Record Identifiers Returned by a Query</p></a></li>
<li><a href='#fetch_pubmed_data'><p>Retrieve PubMed Data in XML or TXT Format</p></a></li>
<li><a href='#get_pubmed_ids'><p>Simple PubMed Record Search</p></a></li>
<li><a href='#get_pubmed_ids_by_fulltitle'><p>Simple PubMed Record Search by Full-length Title</p></a></li>
<li><a href='#PubMed_stopwords'><p>PubMed Records about Bladder Research from Northwestern University</p></a></li>
<li><a href='#table_articles_byAuth'><p>Extract Publication and Affiliation Data from PubMed Records</p></a></li>
<li><a href='#trim_address'><p>Trim and Format Address Information</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Search and Retrieve Scientific Publication Records from PubMed</td>
</tr>
<tr>
<td>Version:</td>
<td>2.13</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-03-25</td>
</tr>
<tr>
<td>Author:</td>
<td>Damiano Fantini</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Damiano Fantini &lt;damiano.fantini@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Query NCBI Entrez and retrieve PubMed records in XML or text format. Process PubMed records by extracting and aggregating data from selected fields. A large number of records can be easily downloaded via this simple-to-use interface to the NCBI PubMed API.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.1), utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-03-29 08:24:59 UTC; dami</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-03-29 09:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='easyPubMed-package'>Retrieve and Process Scientific Publication Records from Pubmed</h2><span id='topic+easyPubMed'></span><span id='topic+easyPubMed-package'></span>

<h3>Description</h3>

<p>Query NCBI Entrez and retrieve PubMed records in XML or TXT format. PubMed records 
can be downloaded and saved as XML or text files. Data integrity is enforced during data download, 
allowing to retrieve and save very large number of records effortlessly. PubMed records can be processed 
to extract publication- and author-specific information.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>try({
  ## Example 01: retrieve data in TXT format
  dami_query_string &lt;- "Damiano Fantini[AU]"
  dami_on_pubmed &lt;- get_pubmed_ids(dami_query_string)
  dami_papers &lt;- fetch_pubmed_data(dami_on_pubmed, format = "abstract")
  dami_papers[dami_papers == ""] &lt;- "\n"
  cat(paste(dami_papers[1:65], collapse = ""))
  #
}, silent = TRUE)

## Not run: 
## Example 02: retrieve data in XML format
library("easyPubMed")
dami_query_string &lt;- "Damiano Fantini[AU] AND 2018[PDAT]"
dami_on_pubmed &lt;- get_pubmed_ids(dami_query_string)
dami_papers &lt;- fetch_pubmed_data(dami_on_pubmed)
titles &lt;- sapply(dami_papers, custom_grep, tag = "ArticleTitle", format = "char", USE.NAMES = FALSE)
print(titles)
#
## Example 03: retrieve data from PubMed and save as XML file
ml_query &lt;- "Machine Learning[TI] AND 2016[PD]"
out1 &lt;- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180)
x &lt;- paste(readLines(out1[1], n = 10), collapse = "\n")
cat(x)
#
## Example 04: retrieve data from PubMed and save as TXT file
ml_query &lt;- "Machine Learning[TI] AND 2016[PD]"
out2 &lt;- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180, format = "medline")
x &lt;- paste(readLines(out1[1], n = 30), collapse = "\n")
cat(x)
#
## Example 05: extract information from a single PubMed record 
ml_query &lt;- "Machine Learning[TI] AND 2016[PD]"
out3 &lt;- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180)
PM_data &lt;- articles_to_list(out3[1])
PM_record_df &lt;- article_to_df(PM_data[[80]])
print(PM_record_df[1,])
print(PM_record_df[,"address"])
#
## Example 06: query PubMed and extract information from multiple records in one step 
ml_query &lt;- "Machine Learning[TI] AND 2016[PD]"
out4 &lt;- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180)
PM_tab &lt;- table_articles_byAuth(out4[1], autofill = TRUE, included_authors = "last")
PM_tab$address &lt;- substr(PM_tab$address, 1, 12)
PM_tab[50:70,c("pmid", "jabbrv", "year", "lastname", "address")]

## End(Not run)

</code></pre>

<hr>
<h2 id='article_to_df'>Extract Data from a PubMed Record</h2><span id='topic+article_to_df'></span>

<h3>Description</h3>

<p>Extract publication-specific information from a PubMed record driven by XML tags. 
The input record is a string (character-class vector of length 1) and includes 
PubMed-specific XML tags. Data are returned as a data frame where each row corresponds 
to one of the authors of the PubMed article.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>article_to_df(pubmedArticle, autofill = FALSE, 
                     max_chars = 500, getKeywords = FALSE, 
                     getAuthors = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="article_to_df_+3A_pubmedarticle">pubmedArticle</code></td>
<td>
<p>String including one PubMed record.</p>
</td></tr>
<tr><td><code id="article_to_df_+3A_autofill">autofill</code></td>
<td>
<p>Logical. If TRUE, missing affiliations are automatically imputed based on other non-NA 
addresses from the same record.</p>
</td></tr>
<tr><td><code id="article_to_df_+3A_max_chars">max_chars</code></td>
<td>
<p>Numeric (integer). Maximum number of characters to be extracted from the Article 
Abstract field. Set max_chars to -1 for extracting the full-length abstract. Set max_chars to 0 to 
extract no abstract.</p>
</td></tr>
<tr><td><code id="article_to_df_+3A_getkeywords">getKeywords</code></td>
<td>
<p>Logical. If TRUE, an attempt to extract article Keywords will be made.</p>
</td></tr>
<tr><td><code id="article_to_df_+3A_getauthors">getAuthors</code></td>
<td>
<p>Logical. If FALSE, author information won't be extracted. This will considerably 
speed up the operation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given one Pubmed Article record, this function will automatically extract a set of features. 
Extracted information include: PMID, DOI, article title, article abstract, publication date (year, month, day), 
journal name (title, abbreviation), keywords, and a set of author-specific info (names, affiliation, email address). 
Each row of the output data frame corresponds to one of the authors of the PubMed record. Author-independent info 
(publication ID, title, journal, date) are identical across all rows. If information about authors are not required, 
set 'getAuthors' = TRUE.
</p>


<h3>Value</h3>

<p>Data frame including the extracted features. Each row correspond a different author.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>try({
  ## Display some contents
  data("EPMsamples")
  #display Query String used for collecting the data
  print(EPMsamples$NUBL_1618$qry_st)
  #Get records
  BL_list &lt;- EPMsamples$NUBL_1618$rec_lst
  cat(BL_list[[1]])
  # cast PM recort to data.frame
  BL_df &lt;- article_to_df(BL_list[[1]], max_chars = 0)
  print(BL_df)
}, silent = TRUE)

## Not run: 
## Query PubMed, retrieve a selected citation and format it as a data frame
dami_query &lt;- "Damiano Fantini[AU] AND 2017[PDAT]"
dami_on_pubmed &lt;- get_pubmed_ids(dami_query)
dami_abstracts_xml &lt;- fetch_pubmed_data(dami_on_pubmed)
dami_abstracts_list &lt;- articles_to_list(dami_abstracts_xml)
article_to_df(pubmedArticle = dami_abstracts_list[[1]], autofill = FALSE)
article_to_df(pubmedArticle = dami_abstracts_list[[2]], autofill = TRUE, max_chars = 300)[1:2,]

## End(Not run)

</code></pre>

<hr>
<h2 id='articles_to_list'>Cast PubMed Data into a List of Articles</h2><span id='topic+articles_to_list'></span>

<h3>Description</h3>

<p>Convert an XML object of PubMed records into a list of strings 
(character vector of length 1) corresponding to individual PubMed articles. 
PubMed records are identified by a &quot;/PubmedArticle&quot; XML tag. This automatically casts 
all the content of each PubMed record to a character-class object without removing XML tags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>articles_to_list(pubmed_data, encoding = "UTF8", simplify = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="articles_to_list_+3A_pubmed_data">pubmed_data</code></td>
<td>
<p>String corresponding to the name of an XML file (typically, 
the result of a batch_pubmed_download() call). Alternatively, a string including 
PubMed records with XML tags, such as the object returned by a fetch_pubmed_data() call.</p>
</td></tr>
<tr><td><code id="articles_to_list_+3A_encoding">encoding</code></td>
<td>
<p>The encoding of an input/output connection can be specified by name 
(for example, &quot;ASCII&quot;, or &quot;UTF-8&quot;, in the same way as it would be given to the 
function base::iconv(). See iconv() help page for how to find out more about encodings 
that can be used on your platform. &quot;UTF-8&quot; is recommended.</p>
</td></tr>
<tr><td><code id="articles_to_list_+3A_simplify">simplify</code></td>
<td>
<p>Logical; should the result be simplified to a character vector. 
If FALSE, results are returned as a list.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input is an XML object or a string including PubMed records (with XML tags). These are the
output of easyPubMed functions: fetch_pubmed_data() or batch_pubmed_download(). 
The function returns a list or a character vector where each element is a different PubMed record.
</p>


<h3>Value</h3>

<p>List or character vector including all the records from the original XML object in text format. 
Elements in the list are not named and are only accessible via their numeric index.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>try({
  ## Retrieve PubMed data and return a list ot articles
  my_query &lt;- "Damiano Fantini[AU]"
  my_query &lt;- get_pubmed_ids(pubmed_query_string = my_query)
  my_data &lt;- fetch_pubmed_data(my_query, encoding = "ASCII")
  listed_articles &lt;- articles_to_list(my_data)
  custom_grep(listed_articles[[2]], "ArticleTitle", "char")
}, silent = TRUE)

## Not run: 
## Download PubMed data and return a list ot articles
dami_query &lt;- "Damiano Fantini[AU] AND 2018[PDAT]"
outfile &lt;- batch_pubmed_download(dami_query, dest_file_prefix = "easyPM_ex001_")
listed_articles &lt;- articles_to_list(pubmed_data = outfile)
custom_grep(listed_articles[[2]], "ArticleTitle", "char")

## End(Not run)

</code></pre>

<hr>
<h2 id='batch_pubmed_download'>Download PubMed Records in XML or TXT Format</h2><span id='topic+batch_pubmed_download'></span>

<h3>Description</h3>

<p>Performs a PubMed Query (via the get_pubmed_ids() function), downloads the 
resulting data (via multiple fetch_pubmed_data() calls) and then saves data in a series of 
xml or txt files on the local drive. The function is suitable for downloading 
a very large number of records.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batch_pubmed_download(pubmed_query_string, dest_dir = NULL, 
                             dest_file_prefix = "easyPubMed_data_", 
                             format = "xml", api_key = NULL, 
                             batch_size = 400, res_cn = 1, 
                             encoding = "UTF8")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="batch_pubmed_download_+3A_pubmed_query_string">pubmed_query_string</code></td>
<td>
<p>String (character-vector of length 1): this is the string 
used for querying PubMed (the standard PubMed Query synthax applies).</p>
</td></tr>
<tr><td><code id="batch_pubmed_download_+3A_dest_dir">dest_dir</code></td>
<td>
<p>String (character-vector of length 1): this string corresponds to the name 
of the existing folder where files will be saved. Existing files will be overwritten. 
If NULL, the current working directory will be used.</p>
</td></tr>
<tr><td><code id="batch_pubmed_download_+3A_dest_file_prefix">dest_file_prefix</code></td>
<td>
<p>String (character-vector of length 1): this string is used as 
prefix for the files that are written locally.</p>
</td></tr>
<tr><td><code id="batch_pubmed_download_+3A_format">format</code></td>
<td>
<p>String (character-vector of length 1): data will be requested from Entrez 
in this format. Acceptable values are: c(&quot;medline&quot;,&quot;uilist&quot;,&quot;abstract&quot;,&quot;asn.1&quot;, &quot;xml&quot;). 
When format != &quot;xml&quot;, data will be saved as text files (txt).</p>
</td></tr>
<tr><td><code id="batch_pubmed_download_+3A_api_key">api_key</code></td>
<td>
<p>String (character vector of length 1): user-specific API key to increase 
the limit of queries per second. You can obtain your key from NCBI.</p>
</td></tr>
<tr><td><code id="batch_pubmed_download_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer (1 &lt; batch_size &lt; 5000): maximum number of records 
to be saved in a single xml or txt file.</p>
</td></tr>
<tr><td><code id="batch_pubmed_download_+3A_res_cn">res_cn</code></td>
<td>
<p>Integer (&gt; 0): numeric index of the data batch to start downloading from. 
This parameter is useful to resume an incomplete download job after a system crash.</p>
</td></tr>
<tr><td><code id="batch_pubmed_download_+3A_encoding">encoding</code></td>
<td>
<p>The encoding of an input/output connection can be specified by name 
(for example, &quot;ASCII&quot;, or &quot;UTF-8&quot;, in the same way as it would be given to the 
function base::iconv(). See iconv() help page for how to find out more about encodings 
that can be used on your platform. Here, we recommend using &quot;UTF-8&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Download large number of PubMed records as a set of xml or txt files that are saved in the 
folder specified by the user. This function enforces data integrity. If a batch of downloaded 
data is corrupted, it is discarded and downloaded again. Each download cycle is monitored until 
the download job is successfully completed. This function should allow to download a whole copy 
of PubMed, if desired. The function informs the user about the current progress by constantly 
printing to console the number of batches still in queue for download. pubmed_query_string 
accepts standard PubMed synthax. The function will query PubMed multiple times using the same 
query string. Therefore, it is recommended to use a [EDAT] or a [PDAT] filter in the query 
if you want to ensure reproducible results.
</p>


<h3>Value</h3>

<p>Character vector including the names of files downloaded to the local system
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Example 01: retrieve data from PubMed and save as XML file
ml_query &lt;- "Machine Learning[TI] AND 2016[PD]"
out1 &lt;- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180)
readLines(out1[1])[1:30]
##
## Example 02: retrieve data from PubMed and save as TXT file
ml_query &lt;- "Machine Learning[TI] AND 2016[PD]"
out2 &lt;- batch_pubmed_download(pubmed_query_string = ml_query, batch_size = 180, format = "medline")
readLines(out2[1])[1:30]

## End(Not run)

</code></pre>

<hr>
<h2 id='custom_grep'>Retrieve Text Between XML Tags</h2><span id='topic+custom_grep'></span>

<h3>Description</h3>

<p>Extract text form a string containing XML or HTML tags. Text 
included between tags of interest will be returned. If multiple tagged substrings are found, 
they will be returned as different elements of a list or character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>custom_grep(xml_data, tag, format = "list")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="custom_grep_+3A_xml_data">xml_data</code></td>
<td>
<p>String (of class character and length 1): corresponds to the PubMed 
record or any string including XML/HTML tags.</p>
</td></tr>
<tr><td><code id="custom_grep_+3A_tag">tag</code></td>
<td>
<p>String (of class character and length 1): the tag of interest (does NOT include &lt; &gt; chars).</p>
</td></tr>
<tr><td><code id="custom_grep_+3A_format">format</code></td>
<td>
<p>c(&quot;list&quot;, &quot;char&quot;): specifies the format for the output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input string has to be a character string (length 1) containing tags (HTML or XML format). 
If an XML Document is provided as input, the function will rise an error.
</p>


<h3>Value</h3>

<p>List or vector where each element corresponds to an in-tag substring.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>try({
  ## extract substrings based on regular expressions
  string_01 &lt;- "I can't wait to watch the &lt;strong&gt;Late Night Show with" 
  string_01 &lt;- paste(string_01, "Seth Meyers&lt;/strong&gt; tonight at &lt;strong&gt;11:30&lt;/strong&gt;pm CT!")
  print(string_01)
  custom_grep(xml_data = string_01, tag = "strong", format = "char")
  custom_grep(xml_data = string_01, tag = "strong", format = "list")
}, silent = TRUE)

</code></pre>

<hr>
<h2 id='EPMsamples'>PubMed Records downloaded and analyzed via easyPubMed</h2><span id='topic+EPMsamples'></span>

<h3>Description</h3>

<p>This dataset includes a collection of 4 examples showing how to download and analyze records 
from PubMed by using easyPubMed. Each element in the EPMsamples list corresponds to a different query 
and/or analysis. Also, each element of EPMsamples is a list including intermediates and notes about the analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("EPMsamples")
</code></pre>


<h3>Format</h3>

<p>The dataset is formatted as a list including 4 elements: 
</p>
<p>* 'DF_papers_abs': List of 4
</p>
<p>* 'DF_papers_std': List of 4
</p>
<p>* 'NUBL_dw18': List of 3
</p>
<p>* 'NUBL_1618': List of 5</p>


<h3>Details</h3>

<p>The dataset was built as described in this vignette: <a href="https://www.data-pulse.com/projects/Rlibs/vignettes/building_the_easyPubMed_EPMsamples_dataset.html">https://www.data-pulse.com/projects/Rlibs/vignettes/building_the_easyPubMed_EPMsamples_dataset.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Display some contents
data("EPMsamples")
# The following examples are focused on example query #4 (i.e., NUBL_1618)
# Display Query String used for collecting the data
print(EPMsamples$NUBL_1618$qry_st)
# show one PubMed record element from the IL vector
NU_records &lt;- EPMsamples$NUBL_1618$rec_lst
cat(NU_records[[1]])
# cast PM recort to data.frame
BL_df &lt;- article_to_df(NU_records[[6]], max_chars = 0)
print(BL_df)
</code></pre>

<hr>
<h2 id='fetch_all_pubmed_ids'>Retrieve All PubMed Record Identifiers Returned by a Query</h2><span id='topic+fetch_all_pubmed_ids'></span>

<h3>Description</h3>

<p>Retrieve PubMed record identifiers from Entrez following a search performed 
via the get_pubmed_ids() function. Identifiers are returned as a character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fetch_all_pubmed_ids(pubmed_id_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fetch_all_pubmed_ids_+3A_pubmed_id_list">pubmed_id_list</code></td>
<td>
<p>List: the result of a get_pubmed_ids() call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Retrieve PubMed identifiers, without any other information (such as article title, 
authors, publication date, and so on). The PubMed IDs can be stored or used with other software.
</p>


<h3>Value</h3>

<p>Character vector including all PMID (PubMed Identifiers) returned by the current query.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Fetch only PubMed Record IDs (PMIDs)
dami_query_string &lt;- "Damiano Fantini[AU]"
dami_on_pubmed &lt;- get_pubmed_ids(dami_query_string)
dami_pmids &lt;- fetch_all_pubmed_ids(dami_on_pubmed)
print(dami_pmids)


## End(Not run)

</code></pre>

<hr>
<h2 id='fetch_pubmed_data'>Retrieve PubMed Data in XML or TXT Format</h2><span id='topic+fetch_pubmed_data'></span>

<h3>Description</h3>

<p>Retrieve PubMed records from Entrez following a search performed via the 
get_pubmed_ids() function. Data are downloaded in the XML or TXT format and are 
retrieved in batches of up to 5000 records.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fetch_pubmed_data(pubmed_id_list, 
                         retstart = 0, 
                         retmax = 500, 
                         format = "xml", 
                         encoding = "UTF8")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fetch_pubmed_data_+3A_pubmed_id_list">pubmed_id_list</code></td>
<td>
<p>List: the result of a get_pubmed_ids() call.</p>
</td></tr>
<tr><td><code id="fetch_pubmed_data_+3A_retstart">retstart</code></td>
<td>
<p>Integer (&gt;=0): index of the first UID in the retrieved PubMed Search Result set 
to be included in the output (default=0, corresponding to the first record of the entire set).</p>
</td></tr>
<tr><td><code id="fetch_pubmed_data_+3A_retmax">retmax</code></td>
<td>
<p>Integer (&gt;=1): size of the batch of PubMed records to be retrieved at one time.</p>
</td></tr>
<tr><td><code id="fetch_pubmed_data_+3A_format">format</code></td>
<td>
<p>Character: element specifying the output format. The following values are allowed: 
c(&quot;asn.1&quot;, &quot;xml&quot;, &quot;medline&quot;, &quot;uilist&quot;, &quot;abstract&quot;).</p>
</td></tr>
<tr><td><code id="fetch_pubmed_data_+3A_encoding">encoding</code></td>
<td>
<p>The encoding of an input/output connection can be specified by name 
(for example, &quot;ASCII&quot;, or &quot;UTF-8&quot;, in the same way as it would be given to the function base::iconv(). 
See iconv() help page for how to find out more about encodings that can be used on your platform. 
Here, we recommend using &quot;UTF-8&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Retrieve PubMed records based on the results of a get_pubmed_ids() query. 
Records are retrieved from Entrez via the PubMed API efetch function. The first entry to be retrieved 
may be adjusted via the retastart parameter (this allows the user to download large batches of PubMed 
data in multiple runs). The maximum number of entries to be retrieved can also be set adjusting the 
retmax parameter (1 &lt; retmax &lt; 5000). Data will be downloaded on the fly (no files are saved 
locally).
</p>


<h3>Value</h3>

<p>An object (vector) of class &quot;character&quot;. If format is set to &quot;xml&quot; (default), a single String including all 
PubMed records (with XML tags embedded) is returned. If a different format is selected, a vector of strings 
is returned, where each row corresponds to a line of the output document.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
<a href="https://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/">https://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>try({ 
  ## Example 01: retrieve data in TXT format
  library("easyPubMed")
  dami_query_string &lt;- "Damiano Fantini[AU] AND 2018[PDAT]"
  dami_on_pubmed &lt;- get_pubmed_ids(dami_query_string)
  Sys.sleep(1) # avoid server timeout
  dami_papers &lt;- fetch_pubmed_data(dami_on_pubmed, format = "abstract")
  dami_papers[dami_papers == ""] &lt;- "\n"
  cat(paste(dami_papers[1:65], collapse = ""))
}, silent = TRUE)

## Not run: 
## Example 02: retrieve data in XML format
library("easyPubMed")
dami_query_string &lt;- "Damiano Fantini[AU]"
dami_on_pubmed &lt;- get_pubmed_ids(dami_query_string)
dami_papers &lt;- fetch_pubmed_data(dami_on_pubmed)
titles &lt;- custom_grep(dami_papers, "ArticleTitle", "char")
print(titles)

## End(Not run)

</code></pre>

<hr>
<h2 id='get_pubmed_ids'>Simple PubMed Record Search</h2><span id='topic+get_pubmed_ids'></span>

<h3>Description</h3>

<p>Query PubMed (Entrez) in a simple way via the PubMed API eSearch function. 
Calling this function results in posting the query results on the PubMed History Server. 
This allows later access to the resulting data via the fetch_pubmed_data() function, 
or other easyPubMed functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pubmed_ids(pubmed_query_string, api_key = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pubmed_ids_+3A_pubmed_query_string">pubmed_query_string</code></td>
<td>
<p>is a string (character vector of length 1) that is used 
for querying PubMed (standard PubMed synthax, see reference for details).</p>
</td></tr>
<tr><td><code id="get_pubmed_ids_+3A_api_key">api_key</code></td>
<td>
<p>String (character vector of length 1): user-specific API key to 
increase the limit of queries per second. You can obtain your key from NCBI.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will use the String provided as argument for querying PubMed via the eSearch 
function of the PubMed API. The Query Term can include one or multiple words, as well as the standard 
PubMed operators (AND, OR, NOT) and tags (i.e., [AU], [PDAT], [Affiliation], and so on). ESearch will 
post the UIDs resulting from the search operation onto the History server so that they can be used directly 
in a subsequent fetchPubmedData() call.
</p>


<h3>Value</h3>

<p>The function returns a list. The list includes the number of records found on PubMed and 
the first 20 PubMed IDs (UID) retrieved by the query. The list also includes QueryKey and WebEnv 
that are required for a subsequent fetch_pubmed_data() call.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
<a href="https://www.ncbi.nlm.nih.gov/books/NBK3827/#_pubmedhelp_Search_Field_Descriptions_and_">https://www.ncbi.nlm.nih.gov/books/NBK3827/#_pubmedhelp_Search_Field_Descriptions_and_</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>try({
  ##  Search for scientific articles written by Damiano Fantini
  ##  and print the number of retrieved records to screen.
  ##  Also print the retrieved UIDs to screen.
  ##
  dami_on_pubmed &lt;- get_pubmed_ids("Damiano Fantini[AU]")
  print(dami_on_pubmed$Count)
  print(unlist(dami_on_pubmed$IdList))
}, silent = TRUE)

</code></pre>

<hr>
<h2 id='get_pubmed_ids_by_fulltitle'>Simple PubMed Record Search by Full-length Title</h2><span id='topic+get_pubmed_ids_by_fulltitle'></span>

<h3>Description</h3>

<p>Query PubMed (Entrez) in a simple way via the PubMed API eSearch function. 
This function is designed to query PubMed using a full-length publication title as query string. 
It performs stopword removal from the query string before querying the PubMed server. 
Calling this function results in posting the results on the PubMed History Server. 
This allows later access to the resulting data via the fetch_pubmed_data() function, 
or other easyPubMed functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pubmed_ids_by_fulltitle(fulltitle, field = "[Title]", api_key = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pubmed_ids_by_fulltitle_+3A_fulltitle">fulltitle</code></td>
<td>
<p>String (character vector of length 1) that corresponds to the full-length 
publication title used for querying PubMed (titles should be used as is, without 
adding extra filters/tags).</p>
</td></tr>
<tr><td><code id="get_pubmed_ids_by_fulltitle_+3A_field">field</code></td>
<td>
<p>String (character vector of length 1) with a tag indicating the PubMed 
record field where the full-length string (fulltitle) should be searched in. By default, 
this points to the 'Title' field. This field can be changed (use fields supported by PubMed) 
as required by the user (for example, to attempt an exact-match query using a specific sentence 
included in the abstract of a record).</p>
</td></tr>
<tr><td><code id="get_pubmed_ids_by_fulltitle_+3A_api_key">api_key</code></td>
<td>
<p>String (character vector of length 1): user-specific API key to increase 
the limit of queries per second. You can obtain your key from NCBI.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will use the String provided as argument for querying PubMed via the eSearch 
function of the PubMed API. The Query Term should include a full-length publication title, 
without other PubMed operators (AND, OR, NOT) nor tags (i.e., [AU], [PDAT], 
[Affiliation], and so on). ESearch will post the UIDs resulting from the search operation 
onto the History server so that they can be used directly in a subsequent fetchPubmedData() call.
</p>


<h3>Value</h3>

<p>The function returns a list. The list includes the number of records found on PubMed and the first 
20 PubMed IDs (UID) retrieved by the query. The list also includes QueryKey and WebEnv that are 
required for a subsequent fetch_pubmed_data() call.
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##  Search for a scientific article matching a full-length title
my_query &lt;- "Body mass index and cancer risk among Chinese patients with type 2 diabetes mellitus"
my_field &lt;- "[Title]"
# Full-length title query (designed to query titles)
res0 &lt;- get_pubmed_ids(my_query)
print(as.numeric(res0$Count))
# Weird count!
res &lt;- get_pubmed_ids_by_fulltitle(my_query, field = my_field)
# Num results = 1 as expected
print(as.numeric(res$Count))


## End(Not run)

</code></pre>

<hr>
<h2 id='PubMed_stopwords'>PubMed Records about Bladder Research from Northwestern University</h2><span id='topic+PubMed_stopwords'></span>

<h3>Description</h3>

<p>This dataset includes a collection of 87 PubMed Records of scientific publications about Bladder 
biology and pathology, published by clinical and research groups from Northwestern 
University (Chicago, IL), between 2016 and 2018.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PubMed_stopwords")
</code></pre>


<h3>Format</h3>

<p>A character vector including all PubMed stopwords tat are typically filtered out from queries.</p>


<h3>Details</h3>

<p>Number of stopwords included, n=133.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Display some contents
data("PubMed_stopwords")
head(PubMed_stopwords)
</code></pre>

<hr>
<h2 id='table_articles_byAuth'>Extract Publication and Affiliation Data from PubMed Records</h2><span id='topic+table_articles_byAuth'></span>

<h3>Description</h3>

<p>Extract Publication Info from PubMed records and cast data into a 
data.frame where each row corresponds to a different author. It is possible to limit
data extraction to first authors or last authors only, or get information about 
all authors of each PubMed record.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table_articles_byAuth(pubmed_data, 
                             included_authors = "all", 
                             max_chars = 500, 
                             autofill = TRUE, 
                             dest_file = NULL, 
                             getKeywords = TRUE, 
                             encoding = "UTF8")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="table_articles_byAuth_+3A_pubmed_data">pubmed_data</code></td>
<td>
<p>PubMed Data in XML format: typically, an XML file resulting from a 
batch_pubmed_download() call or an XML object, result of a fetch_pubmed_data() call.</p>
</td></tr>
<tr><td><code id="table_articles_byAuth_+3A_included_authors">included_authors</code></td>
<td>
<p>Character: c(&quot;first&quot;, &quot;last&quot;, &quot;all&quot;). Only includes information 
from the first, the last or all authors of a PubMed record.</p>
</td></tr>
<tr><td><code id="table_articles_byAuth_+3A_max_chars">max_chars</code></td>
<td>
<p>Numeric: maximum number of chars to extract from the AbstractText field.</p>
</td></tr>
<tr><td><code id="table_articles_byAuth_+3A_autofill">autofill</code></td>
<td>
<p>Logical. If TRUE, missing affiliations are imputed according to the available 
values (from the same article).</p>
</td></tr>
<tr><td><code id="table_articles_byAuth_+3A_dest_file">dest_file</code></td>
<td>
<p>String (character of length 1). Name of the file that will be written for 
storing the output. If NULL, no file will be saved.</p>
</td></tr>
<tr><td><code id="table_articles_byAuth_+3A_getkeywords">getKeywords</code></td>
<td>
<p>Logical. If TRUE, the operation will attempt to extract PubMed record 
keywords (MESH topics, keywords).</p>
</td></tr>
<tr><td><code id="table_articles_byAuth_+3A_encoding">encoding</code></td>
<td>
<p>The encoding of an input/output connection can be specified by name 
(for example, &quot;ASCII&quot;, or &quot;UTF-8&quot;, in the same way as it would be given to the function 
base::iconv(). See iconv() help page for how to find out more about encodings that can be 
used on your platform. Here, we recommend using &quot;UTF-8&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Retrieve publication and author information from PubMed data, and cast them as a data.frame.
</p>


<h3>Value</h3>

<p>Data frame including the following fields: c(&quot;article.title&quot;,&quot;article.abstract&quot;, &quot;date.year&quot;, 
&quot;date.month&quot;, &quot;date.day&quot;, &quot;journal.abbrv&quot;, &quot;journal.title&quot;, &quot;keywords&quot;, &quot;auth.last&quot;, 
&quot;auth.fore&quot;, &quot;auth.address&quot;, &quot;auth.email&quot;).
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Cast PubMed record info into a data.frame

dami_query &lt;- "Damiano Fantini[AU]"
dami_on_pubmed &lt;- get_pubmed_ids(dami_query)
dami_abstracts_xml &lt;- fetch_pubmed_data(dami_on_pubmed, encoding = "ASCII")
xx &lt;- table_articles_byAuth(pubmed_data = dami_abstracts_xml, 
                            included_authors = "first", 
                            max_chars = 100, 
                            autofill = TRUE)

print(xx[1:5, c("pmid", "lastname", "jabbrv")])
#
## Download records first
## Also, auto-fill disabled
dami_query &lt;- "Damiano Fantini[AU]"
curr.file &lt;- batch_pubmed_download(dami_query, dest_file_prefix = "test_bpd_", encoding = "ASCII")
xx &lt;- table_articles_byAuth(pubmed_data = curr.file[1], 
                            included_authors = "all", 
                            max_chars = 20, 
                            autofill = FALSE)
print(xx[1:5, c("pmid", "lastname", "jabbrv")])


## End(Not run)
</code></pre>

<hr>
<h2 id='trim_address'>Trim and Format Address Information</h2><span id='topic+trim_address'></span>

<h3>Description</h3>

<p>Set of rules for trimming and standardizing the format of address information 
retrieved from PubMed records. Affiliations including more than one address will be trimmend 
and only the first address will be returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim_address(addr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trim_address_+3A_addr">addr</code></td>
<td>
<p>Character string including an address as extracted from PubMed records.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character string including a formatted and trimmed address (if available).
</p>


<h3>Author(s)</h3>

<p>Damiano Fantini <a href="mailto:damiano.fantini@gmail.com">damiano.fantini@gmail.com</a>
</p>


<h3>References</h3>

<p><a href="https://www.data-pulse.com/dev_site/easypubmed/">https://www.data-pulse.com/dev_site/easypubmed/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>addr_string &lt;- " 2 Dept of Urology, Feinberg School of Medicine," 
addr_string &lt;- paste(addr_string, "Chicago, US; Dept of Mol Bio as well...")
print(addr_string)
print(trim_address(addr = addr_string))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
