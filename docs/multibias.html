<!DOCTYPE html><html lang="en"><head><title>Help for package multibias</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {multibias}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#multibias-package'><p>multibias: Simultaneous Multi-Bias Adjustment</p></a></li>
<li><a href='#adjust_em'><p>Adust for exposure misclassification.</p></a></li>
<li><a href='#adjust_em_om'><p>Adust for exposure misclassification and outcome misclassification.</p></a></li>
<li><a href='#adjust_em_sel'><p>Adust for exposure misclassification and selection bias.</p></a></li>
<li><a href='#adjust_emc'><p>Adust for exposure misclassification.</p></a></li>
<li><a href='#adjust_emc_omc'><p>Adust for exposure misclassification and outcome misclassification.</p></a></li>
<li><a href='#adjust_emc_sel'><p>Adust for exposure misclassification and selection bias.</p></a></li>
<li><a href='#adjust_om'><p>Adust for outcome misclassification.</p></a></li>
<li><a href='#adjust_om_sel'><p>Adust for outcome misclassification and selection bias.</p></a></li>
<li><a href='#adjust_omc'><p>Adust for outcome misclassification.</p></a></li>
<li><a href='#adjust_omc_sel'><p>Adust for outcome misclassification and selection bias.</p></a></li>
<li><a href='#adjust_sel'><p>Adust for selection bias.</p></a></li>
<li><a href='#adjust_uc'><p>Adust for uncontrolled confounding.</p></a></li>
<li><a href='#adjust_uc_em'><p>Adust for uncontrolled confounding and exposure misclassification.</p></a></li>
<li><a href='#adjust_uc_em_sel'><p>Adust for uncontrolled confounding, exposure misclassification, and selection</p>
bias.</a></li>
<li><a href='#adjust_uc_emc'><p>Adust for uncontrolled confounding and exposure misclassification.</p></a></li>
<li><a href='#adjust_uc_emc_sel'><p>Adust for uncontrolled confounding, exposure misclassification, and selection</p>
bias.</a></li>
<li><a href='#adjust_uc_om'><p>Adust for uncontrolled confounding and outcome misclassification.</p></a></li>
<li><a href='#adjust_uc_om_sel'><p>Adust for uncontrolled confounding, outcome misclassification, and selection</p>
bias.</a></li>
<li><a href='#adjust_uc_omc'><p>Adust for uncontrolled confounding and outcome misclassification.</p></a></li>
<li><a href='#adjust_uc_omc_sel'><p>Adust for uncontrolled confounding, outcome misclassification, and selection</p>
bias.</a></li>
<li><a href='#adjust_uc_sel'><p>Adust for uncontrolled confounding and selection bias.</p></a></li>
<li><a href='#data_observed'><p>Represent observed causal data</p></a></li>
<li><a href='#data_validation'><p>Represent validation causal data</p></a></li>
<li><a href='#df_em'><p>Simulated data with exposure misclassification</p></a></li>
<li><a href='#df_em_om'><p>Simulated data with exposure misclassification and outcome misclassification</p></a></li>
<li><a href='#df_em_om_source'><p>Data source for <code>df_em_om</code></p></a></li>
<li><a href='#df_em_sel'><p>Simulated data with exposure misclassification and selection bias</p></a></li>
<li><a href='#df_em_sel_source'><p>Data source for <code>df_em_sel</code></p></a></li>
<li><a href='#df_em_source'><p>Data source for <code>df_em</code></p></a></li>
<li><a href='#df_om'><p>Simulated data with outcome misclassification</p></a></li>
<li><a href='#df_om_sel'><p>Simulated data with outcome misclassification and selection bias</p></a></li>
<li><a href='#df_om_sel_source'><p>Data source for <code>df_om_sel</code></p></a></li>
<li><a href='#df_om_source'><p>Data source for <code>df_om</code></p></a></li>
<li><a href='#df_sel'><p>Simulated data with selection bias</p></a></li>
<li><a href='#df_sel_source'><p>Data source for <code>df_sel</code></p></a></li>
<li><a href='#df_uc'><p>Simulated data with uncontrolled confounding</p></a></li>
<li><a href='#df_uc_em'><p>Simulated data with uncontrolled confounding and exposure misclassification</p></a></li>
<li><a href='#df_uc_em_sel'><p>Simulated data with uncontrolled confounding, exposure misclassification,</p>
and selection bias</a></li>
<li><a href='#df_uc_em_sel_source'><p>Data source for <code>df_uc_em_sel</code></p></a></li>
<li><a href='#df_uc_em_source'><p>Data source for <code>df_uc_em</code></p></a></li>
<li><a href='#df_uc_om'><p>Simulated data with uncontrolled confounding and outcome misclassification</p></a></li>
<li><a href='#df_uc_om_sel'><p>Simulated data with uncontrolled confounding, outcome misclassification,</p>
and selection bias</a></li>
<li><a href='#df_uc_om_sel_source'><p>Data source for <code>df_uc_om_sel</code></p></a></li>
<li><a href='#df_uc_om_source'><p>Data source for <code>df_uc_om</code></p></a></li>
<li><a href='#df_uc_sel'><p>Simulated data with uncontrolled confounding and selection bias</p></a></li>
<li><a href='#df_uc_sel_source'><p>Data source for <code>df_uc_sel</code></p></a></li>
<li><a href='#df_uc_source'><p>Data source for <code>df_uc</code></p></a></li>
<li><a href='#evans'><p>Evans County dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Simultaneous Multi-Bias Adjustment</td>
</tr>
<tr>
<td>Version:</td>
<td>1.6.3</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul Brendel &lt;pcbrendel@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Quantify the causal effect of a binary exposure on a binary
    outcome with adjustment for multiple biases. The functions can
    simultaneously adjust for any combination of uncontrolled confounding,
    exposure/outcome misclassification, and selection bias.
    The underlying method generalizes the concept of combining inverse
    probability of selection weighting with predictive value weighting.
    Simultaneous multi-bias analysis can be used to enhance the validity
    and transparency of real-world evidence obtained from observational,
    longitudinal studies. Based on the work from Paul Brendel, Aracelis Torres,
    and Onyebuchi Arah (2023) &lt;<a href="https://doi.org/10.1093%2Fije%2Fdyad001">doi:10.1093/ije/dyad001</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr (&ge; 1.1.3), lifecycle (&ge; 1.0.3), magrittr (&ge; 2.0.3),
rlang (&ge; 1.1.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, MASS, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/pcbrendel/multibias">https://github.com/pcbrendel/multibias</a>,
<a href="http://www.paulbrendel.com/multibias/">http://www.paulbrendel.com/multibias/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/pcbrendel/multibias/issues">https://github.com/pcbrendel/multibias/issues</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-23 21:26:35 UTC; pbrendel</td>
</tr>
<tr>
<td>Author:</td>
<td>Paul Brendel [aut, cre, cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-23 21:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='multibias-package'>multibias: Simultaneous Multi-Bias Adjustment</h2><span id='topic+multibias'></span><span id='topic+multibias-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Quantify the causal effect of a binary exposure on a binary outcome with adjustment for multiple biases. The functions can simultaneously adjust for any combination of uncontrolled confounding, exposure/outcome misclassification, and selection bias. The underlying method generalizes the concept of combining inverse probability of selection weighting with predictive value weighting. Simultaneous multi-bias analysis can be used to enhance the validity and transparency of real-world evidence obtained from observational, longitudinal studies. Based on the work from Paul Brendel, Aracelis Torres, and Onyebuchi Arah (2023) <a href="https://doi.org/10.1093/ije/dyad001">doi:10.1093/ije/dyad001</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Paul Brendel <a href="mailto:pcbrendel@gmail.com">pcbrendel@gmail.com</a> [copyright holder]
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/pcbrendel/multibias">https://github.com/pcbrendel/multibias</a>
</p>
</li>
<li> <p><a href="http://www.paulbrendel.com/multibias/">http://www.paulbrendel.com/multibias/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/pcbrendel/multibias/issues">https://github.com/pcbrendel/multibias/issues</a>
</p>
</li></ul>


<hr>
<h2 id='adjust_em'>Adust for exposure misclassification.</h2><span id='topic+adjust_em'></span>

<h3>Description</h3>

<p><code>adjust_em</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for exposure misclassificaiton.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_em(
  data_observed,
  data_validation = NULL,
  x_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_em_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_em_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the true and misclassified exposure corresponding to the
observed exposure in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_em_+3A_x_model_coefs">x_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(X=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X* + &delta;<sub>2</sub>Y + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>X</em> represents the binary true exposure, <em>X</em>* is the binary
misclassified exposure, <em>Y</em> is the outcome, <em>C</em> represents
the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders. The number
of parameters is therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_em_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Values for the bias parameters
can be applied as fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_em,
  exposure = "Xstar",
  outcome = "Y",
  confounders = "C1"
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_em_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = "C1",
  misclassified_exposure = "Xstar"
)

adjust_em(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using x_model_coefs -------------------------------------------------------
adjust_em(
  data_observed = df_observed,
  x_model_coefs = c(-2.10, 1.62, 0.63, 0.35)
)

</code></pre>

<hr>
<h2 id='adjust_em_om'>Adust for exposure misclassification and outcome misclassification.</h2><span id='topic+adjust_em_om'></span>

<h3>Description</h3>

<p><code>adjust_em_om</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for exposure misclassification and outcome
misclassification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_em_om(
  data_observed,
  data_validation = NULL,
  x_model_coefs = NULL,
  y_model_coefs = NULL,
  x1y0_model_coefs = NULL,
  x0y1_model_coefs = NULL,
  x1y1_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_em_om_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_em_om_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the true and misclassified exposure and outcome
corresponding to the observed exposure and outcome in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_em_om_+3A_x_model_coefs">x_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(X=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X* + &delta;<sub>2</sub>Y* + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>X</em> represents the binary true exposure, <em>X</em>* is the
binary misclassified exposure, <em>Y</em>* is the binary misclassified
outcome, <em>C</em> represents the vector of
measured confounders (if any), and <em>j</em> corresponds to the number
of measured confounders. The number of parameters is therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_em_om_+3A_y_model_coefs">y_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(Y=1)) = &beta;<sub>0</sub> + &beta;<sub>1</sub>X + &beta;<sub>2</sub>Y* + &beta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>Y</em> represents the binary true outcome,
<em>X</em> is the binary exposure, <em>Y</em>* is the binary
misclassified outcome, <em>C</em> represents the vector of measured
confounders (if any), and <em>j</em> corresponds to the number of measured
confounders. The number of parameters is therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_em_om_+3A_x1y0_model_coefs">x1y0_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=1,Y=0) / P(X=0,Y=0)) = &gamma;<sub>1,0</sub> + &gamma;<sub>1,1</sub>X* + &gamma;<sub>1,2</sub>Y* + &gamma;<sub>1,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>Y</em> is the binary
true outcome, <em>X</em>* is the binary misclassified exposure, <em>Y</em>*
is the binary misclassified outcome, <em>C</em> represents the vector of
measured confounders (if any), and <em>j</em> corresponds to the
number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_em_om_+3A_x0y1_model_coefs">x0y1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=0,Y=1) / P(X=0,Y=0)) = &gamma;<sub>2,0</sub> + &gamma;<sub>2,1</sub>X* + &gamma;<sub>2,2</sub>Y* + &gamma;<sub>2,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>Y</em> is the binary
true outcome, <em>X</em>* is the binary misclassified exposure, <em>Y</em>*
is the binary misclassified outcome, <em>C</em> represents the vector of
measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_em_om_+3A_x1y1_model_coefs">x1y1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=1,Y=1) / P(X=0,Y=0)) = &gamma;<sub>3,0</sub> + &gamma;<sub>3,1</sub>X* + &gamma;<sub>3,2</sub>Y* + &gamma;<sub>3,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>Y</em> is the binary
true outcome, <em>X</em>* is the binary misclassified exposure, <em>Y</em>*
is the binary misclassified outcome, <em>C</em> represents the vector of
measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_em_om_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Two different options for the bias parameters
are available here: 1) parameters from separate models of <em>X</em> and <em>Y</em>
(<code>x_model_coefs</code> and <code>y_model_coefs</code>) or 2) parameters from
a joint model of <em>X</em> and <em>Y</em> (<code>x1y0_model_coefs</code>,
<code>x0y1_model_coefs</code>, and <code>x1y1_model_coefs</code>).
</p>
<p>Values for the regression coefficients can be applied as
fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_em_om,
  exposure = "Xstar",
  outcome = "Ystar",
  confounders = "C1"
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_em_om_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = "C1",
  misclassified_exposure = "Xstar",
  misclassified_outcome = "Ystar"
)

adjust_em_om(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using x_model_coefs and y_model_coefs -------------------------------------
adjust_em_om(
  data_observed = df_observed,
  x_model_coefs = c(-2.15, 1.64, 0.35, 0.38),
  y_model_coefs = c(-3.10, 0.63, 1.60, 0.39)
)

# Using x1y0_model_coefs, x0y1_model_coefs, and x1y1_model_coefs ------------
adjust_em_om(
  data_observed = df_observed,
  x1y0_model_coefs = c(-2.18, 1.63, 0.23, 0.36),
  x0y1_model_coefs = c(-3.17, 0.22, 1.60, 0.40),
  x1y1_model_coefs = c(-4.76, 1.82, 1.83, 0.72)
)

</code></pre>

<hr>
<h2 id='adjust_em_sel'>Adust for exposure misclassification and selection bias.</h2><span id='topic+adjust_em_sel'></span>

<h3>Description</h3>

<p><code>adjust_em_sel</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for exposure misclassification and selection bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_em_sel(
  data_observed,
  data_validation = NULL,
  x_model_coefs = NULL,
  s_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_em_sel_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_em_sel_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the true and misclassified exposure,
corresponding to the observed exposure in <code>data_observed</code>. There should also
be a selection indicator representing whether the observation in
<code>data_validation</code> was selected in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_em_sel_+3A_x_model_coefs">x_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(X=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X* + &delta;<sub>2</sub>Y + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>X</em> represents the binary true exposure, <em>X</em>* is the
binary misclassified exposure, <em>Y</em> is the outcome,
<em>C</em> represents the vector of
measured confounders (if any), and <em>j</em> corresponds to the number of
measured confounders. The number of parameters is therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_em_sel_+3A_s_model_coefs">s_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(S=1)) = &beta;<sub>0</sub> + &beta;<sub>1</sub>X* + &beta;<sub>2</sub>Y + &beta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>S</em> represents binary selection, <em>X</em>* is the
binary misclassified exposure,
<em>Y</em> is the outcome, <em>C</em> represents the vector of
measured confounders (if any), and <em>j</em> corresponds to the number of
measured confounders. The number of parameters is therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_em_sel_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Values for the bias parameters
can be applied as fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_em_sel,
  exposure = "Xstar",
  outcome = "Y",
  confounders = "C1"
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_em_sel_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = "C1",
  misclassified_exposure = "Xstar",
  selection = "S"
)

adjust_em_sel(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using x_model_coefs and s_model_coefs -------------------------------------
adjust_em_sel(
  data_observed = df_observed,
  x_model_coefs = c(-2.78, 1.62, 0.58, 0.34),
  s_model_coefs = c(0.04, 0.18, 0.92, 0.05)
)

</code></pre>

<hr>
<h2 id='adjust_emc'>Adust for exposure misclassification.</h2><span id='topic+adjust_emc'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_emc()</code> was renamed to <code>adjust_em()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_emc(data_observed, x_model_coefs, level = 0.95)
</code></pre>

<hr>
<h2 id='adjust_emc_omc'>Adust for exposure misclassification and outcome misclassification.</h2><span id='topic+adjust_emc_omc'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_emc_omc()</code> was renamed to <code>adjust_em_om()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_emc_omc(
  data_observed,
  x_model_coefs = NULL,
  y_model_coefs = NULL,
  x1y0_model_coefs = NULL,
  x0y1_model_coefs = NULL,
  x1y1_model_coefs = NULL,
  level = 0.95
)
</code></pre>

<hr>
<h2 id='adjust_emc_sel'>Adust for exposure misclassification and selection bias.</h2><span id='topic+adjust_emc_sel'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_emc_sel()</code> was renamed to <code>adjust_em_sel()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_emc_sel(data_observed, x_model_coefs, s_model_coefs, level = 0.95)
</code></pre>

<hr>
<h2 id='adjust_om'>Adust for outcome misclassification.</h2><span id='topic+adjust_om'></span>

<h3>Description</h3>

<p><code>adjust_om</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for outcome misclassificaiton.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_om(
  data_observed,
  data_validation = NULL,
  y_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_om_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_om_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the true and misclassified outcome corresponding to the
observed outcome in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_om_+3A_y_model_coefs">y_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(Y=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X + &delta;<sub>2</sub>Y* + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>Y</em> represents the binary true outcome, <em>X</em> is the exposure,
<em>Y</em>* is the binary misclassified outcome,
<em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders. The number
of parameters is therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_om_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Values for the bias parameters
can be applied as fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_om,
  exposure = "X",
  outcome = "Ystar",
  confounders = "C1"
)
# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_om_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = "C1",
  misclassified_outcome = "Ystar"
)

adjust_om(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using y_model_coefs -------------------------------------------------------
adjust_om(
  data_observed = df_observed,
  y_model_coefs = c(-3.1, 0.6, 1.6, 0.4)
)

</code></pre>

<hr>
<h2 id='adjust_om_sel'>Adust for outcome misclassification and selection bias.</h2><span id='topic+adjust_om_sel'></span>

<h3>Description</h3>

<p><code>adjust_om_sel</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for outcome misclassification and selection bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_om_sel(
  data_observed,
  data_validation = NULL,
  y_model_coefs = NULL,
  s_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_om_sel_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_om_sel_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the true and misclassified outcome,
corresponding to the observed outcome in <code>data_observed</code>. There should also
be a selection indicator representing whether the observation in
<code>data_validation</code> was selected in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_om_sel_+3A_y_model_coefs">y_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(Y=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X + &delta;<sub>2</sub>Y* + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>Y</em> represents the binary true outcome, <em>X</em> is the exposure,
<em>Y</em>* is the binary misclassified outcome, <em>C</em> represents
the vector of measured confounders (if any), and <em>j</em> corresponds
to the number of measured confounders. The number of parameters is
therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_om_sel_+3A_s_model_coefs">s_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(S=1)) = &beta;<sub>0</sub> + &beta;<sub>1</sub>X + &beta;<sub>2</sub>Y* + &beta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>S</em> represents binary selection,
<em>X</em> is the exposure, <em>Y</em>* is the binary misclassified outcome,
<em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.
The number of parameters is therefore 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_om_sel_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Values for the bias parameters
can be applied as fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_om_sel,
  exposure = "X",
  outcome = "Ystar",
  confounders = "C1"
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_om_sel_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = "C1",
  misclassified_outcome = "Ystar",
  selection = "S"
)

adjust_om_sel(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using y_model_coefs and s_model_coefs -------------------------------------
adjust_om_sel(
  data_observed = df_observed,
  y_model_coefs = c(-3.24, 0.58, 1.59, 0.45),
  s_model_coefs = c(0.03, 0.92, 0.12, 0.05)
)

</code></pre>

<hr>
<h2 id='adjust_omc'>Adust for outcome misclassification.</h2><span id='topic+adjust_omc'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_omc()</code> was renamed to <code>adjust_om()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_omc(data_observed, y_model_coefs, level = 0.95)
</code></pre>

<hr>
<h2 id='adjust_omc_sel'>Adust for outcome misclassification and selection bias.</h2><span id='topic+adjust_omc_sel'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_omc_sel()</code> was renamed to <code>adjust_om_sel()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_omc_sel(data_observed, y_model_coefs, s_model_coefs, level = 0.95)
</code></pre>

<hr>
<h2 id='adjust_sel'>Adust for selection bias.</h2><span id='topic+adjust_sel'></span>

<h3>Description</h3>

<p><code>adjust_sel</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for selection bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_sel(
  data_observed,
  data_validation = NULL,
  s_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_sel_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_sel_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the selection indicator representing whether the
observation was selected in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_sel_+3A_s_model_coefs">s_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(S=1)) = &beta;<sub>0</sub> + &beta;<sub>1</sub>X + &beta;<sub>2</sub>Y, 
where <em>S</em> represents binary selection, <em>X</em> is the exposure,
and <em>Y</em> is the outcome. The number of parameters is therefore 3.</p>
</td></tr>
<tr><td><code id="adjust_sel_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Values for the bias parameters
can be applied as fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_sel,
  exposure = "X",
  outcome = "Y",
  confounders = "C1"
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_sel_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = "C1",
  selection = "S"
)

adjust_sel(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using s_model_coefs -------------------------------------------------------
adjust_sel(
  data_observed = df_observed,
  s_model_coefs = c(0, 0.9, 0.9)
)

</code></pre>

<hr>
<h2 id='adjust_uc'>Adust for uncontrolled confounding.</h2><span id='topic+adjust_uc'></span>

<h3>Description</h3>

<p><code>adjust_uc</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for uncontrolled confounding from a binary confounder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc(
  data_observed,
  data_validation = NULL,
  u_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_uc_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_uc_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the confounder missing in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_uc_+3A_u_model_coefs">u_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(U=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>Y + &alpha;<sub>2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured confounder, <em>X</em> is the
exposure, <em>Y</em> is the outcome, <em>C</em> represents the vector of
measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Values for the bias parameters
can be applied as fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_uc,
  exposure = "X_bi",
  outcome = "Y_bi",
  confounders = c("C1", "C2", "C3")
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_uc_source,
  true_exposure = "X_bi",
  true_outcome = "Y_bi",
  confounders = c("C1", "C2", "C3", "U")
)

adjust_uc(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using u_model_coefs -------------------------------------------------------
adjust_uc(
  data_observed = df_observed,
  u_model_coefs = c(-0.19, 0.61, 0.70, -0.09, 0.10, -0.15)
)

</code></pre>

<hr>
<h2 id='adjust_uc_em'>Adust for uncontrolled confounding and exposure misclassification.</h2><span id='topic+adjust_uc_em'></span>

<h3>Description</h3>

<p><code>adjust_uc_em</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for uncontrolled confounding and exposure
misclassificaiton.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_em(
  data_observed,
  data_validation = NULL,
  u_model_coefs = NULL,
  x_model_coefs = NULL,
  x1u0_model_coefs = NULL,
  x0u1_model_coefs = NULL,
  x1u1_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_uc_em_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the true and misclassified exposure corresponding to the
observed exposure in <code>data_observed</code>.
There should also be data for the confounder missing in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_+3A_u_model_coefs">u_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(U=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>Y, 
where <em>U</em> is the binary unmeasured confounder, <em>X</em> is the
binary true exposure, and <em>Y</em> is the outcome.
The number of parameters therefore equals 3.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_+3A_x_model_coefs">x_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(X=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X* + &delta;<sub>2</sub>Y + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>X</em> represents the binary true exposure,
<em>X</em>* is the binary misclassified exposure, <em>Y</em> is the
outcome, and <em>C</em> represents the vector of measured confounders
(if any), and <em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_+3A_x1u0_model_coefs">x1u0_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=1,U=0)/P(X=0,U=0)) = &gamma;<sub>1,0</sub> + &gamma;<sub>1,1</sub>X* + &gamma;<sub>1,2</sub>Y + &gamma;<sub>1,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>U</em> is the binary unmeasured
confounder, <em>X</em>* is the binary misclassified exposure, <em>Y</em> is the
outcome, <em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_+3A_x0u1_model_coefs">x0u1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=0,U=1)/P(X=0,U=0)) = &gamma;<sub>2,0</sub> + &gamma;<sub>2,1</sub>X* + &gamma;<sub>2,2</sub>Y + &gamma;<sub>2,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>U</em> is the binary unmeasured
confounder, <em>X</em>* is the binary misclassified exposure, <em>Y</em> is the
outcome, <em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_+3A_x1u1_model_coefs">x1u1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=1,U=1)/P(X=0,U=0)) = &gamma;<sub>3,0</sub> + &gamma;<sub>3,1</sub>X* + &gamma;<sub>3,2</sub>Y + &gamma;<sub>3,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>U</em> is the binary unmeasured
confounder, <em>X</em>* is the binary misclassified exposure, <em>Y</em> is the
outcome, <em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Two different options for the bias parameters
are available here: 1) parameters from separate models of <em>U</em> and <em>X</em>
(<code>u_model_coefs</code> and <code>x_model_coefs</code>) or 2) parameters from a
joint model of <em>U</em> and <em>X</em> (<code>x1u0_model_coefs</code>,
<code>x0u1_model_coefs</code>, and <code>x1u1_model_coefs</code>).
</p>
<p>Values for the bias parameters can be applied as
fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_uc_em,
  exposure = "Xstar",
  outcome = "Y",
  confounders = "C1"
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_uc_em_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = c("C1", "U"),
  misclassified_exposure = "Xstar",
)

adjust_uc_em(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using u_model_coefs and x_model_coefs -------------------------------------
adjust_uc_em(
  data_observed = df_observed,
  u_model_coefs = c(-0.23, 0.63, 0.66),
  x_model_coefs = c(-2.47, 1.62, 0.73, 0.32)
)

# Using x1u0_model_coefs, x0u1_model_coefs, x1u1_model_coefs ----------------
adjust_uc_em(
  data_observed = df_observed,
  x1u0_model_coefs = c(-2.82, 1.62, 0.68, -0.06),
  x0u1_model_coefs = c(-0.20, 0.00, 0.68, -0.05),
  x1u1_model_coefs = c(-2.36, 1.62, 1.29, 0.27)
)

</code></pre>

<hr>
<h2 id='adjust_uc_em_sel'>Adust for uncontrolled confounding, exposure misclassification, and selection
bias.</h2><span id='topic+adjust_uc_em_sel'></span>

<h3>Description</h3>

<p><code>adjust_uc_em_sel</code> returns the exposure-outcome odds ratio and
confidence interval, adjusted for uncontrolled confounding, exposure
misclassificaiton, and selection bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_em_sel(
  data_observed,
  data_validation = NULL,
  u_model_coefs = NULL,
  x_model_coefs = NULL,
  x1u0_model_coefs = NULL,
  x0u1_model_coefs = NULL,
  x1u1_model_coefs = NULL,
  s_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_uc_em_sel_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for: 1) the true and misclassified exposure corresponding
to the observed exposure in <code>data_observed</code>, 2) the confounder missing in
<code>data_observed</code>, 3) a selection indicator representing whether the
observation in <code>data_validation</code> was selected in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_u_model_coefs">u_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(U=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>Y, 
where <em>U</em> is the binary unmeasured confounder, <em>X</em> is the
binary true exposure, and <em>Y</em> is the outcome.
The number of parameters therefore equals 3.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_x_model_coefs">x_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(X=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X* + &delta;<sub>2</sub>Y + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>X</em> represents binary true exposure, <em>X</em>* is the
binary misclassified exposure, <em>Y</em> is the outcome, <em>C</em>
represents the vector of measured confounders (if any), and
<em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_x1u0_model_coefs">x1u0_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=1,U=0)/P(X=0,U=0)) = &gamma;<sub>1,0</sub> + &gamma;<sub>1,1</sub>X* + &gamma;<sub>1,2</sub>Y + &gamma;<sub>1,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>U</em> is the binary
unmeasured confounder, <em>X</em>* is the binary misclassified exposure,
<em>Y</em> is the outcome, <em>C</em> represents the vector of measured confounders
(if any), and <em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_x0u1_model_coefs">x0u1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=0,U=1)/P(X=0,U=0)) = &gamma;<sub>2,0</sub> + &gamma;<sub>2,1</sub>X* + &gamma;<sub>2,2</sub>Y + &gamma;<sub>2,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>U</em> is the binary
unmeasured confounder, <em>X</em>* is the binary misclassified exposure,
<em>Y</em> is the outcome,
<em>C</em> represents the vector of measured confounders (if any), and
<em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_x1u1_model_coefs">x1u1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(X=1,U=1)/P(X=0,U=0)) = &gamma;<sub>3,0</sub> + &gamma;<sub>3,1</sub>X* + &gamma;<sub>3,2</sub>Y + &gamma;<sub>3,2+j</sub>C<sub>j</sub>, 
where <em>X</em> is the binary true exposure, <em>U</em> is the binary
unmeasured confounder, <em>X</em>* is the binary misclassified exposure,
<em>Y</em> is the outcome,
<em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_s_model_coefs">s_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(S=1)) = &beta;<sub>0</sub> + &beta;<sub>1</sub>X* + &beta;<sub>2</sub>Y + &beta;<sub>2+j</sub>C<sub>2+j</sub>, 
where <em>S</em> represents binary selection, <em>X</em>* is the
binary misclassified exposure, <em>Y</em> is the outcome,
<em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_em_sel_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Two different options for the bias
parameters are availale here: 1) parameters from separate models
of <em>U</em> and <em>X</em> (<code>u_model_coefs</code> and <code>x_model_coefs</code>)
or 2) parameters from a joint model of <em>U</em> and <em>X</em>
(<code>x1u0_model_coefs</code>, <code>x0u1_model_coefs</code>, and
<code>x1u1_model_coefs</code>). Both approaches require <code>s_model_coefs</code>.
</p>
<p>Values for the bias parameters can be applied as
fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_uc_em_sel,
  exposure = "Xstar",
  outcome = "Y",
  confounders = c("C1", "C2", "C3")
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_uc_em_sel_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = c("C1", "C2", "C3", "U"),
  misclassified_exposure = "Xstar",
  selection = "S"
)

adjust_uc_em_sel(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using u_model_coefs, x_model_coefs, s_model_coefs -------------------------
adjust_uc_em_sel(
  data_observed = df_observed,
  u_model_coefs = c(-0.32, 0.59, 0.69),
  x_model_coefs = c(-2.44, 1.62, 0.72, 0.32, -0.15, 0.85),
  s_model_coefs = c(0.00, 0.26, 0.78, 0.03, -0.02, 0.10)
)

# Using x1u0_model_coefs, x0u1_model_coefs, x1u1_model_coefs, s_model_coefs
adjust_uc_em_sel(
  data_observed = df_observed,
  x1u0_model_coefs = c(-2.78, 1.62, 0.61, 0.36, -0.27, 0.88),
  x0u1_model_coefs = c(-0.17, -0.01, 0.71, -0.08, 0.07, -0.15),
  x1u1_model_coefs = c(-2.36, 1.62, 1.29, 0.25, -0.06, 0.74),
  s_model_coefs = c(0.00, 0.26, 0.78, 0.03, -0.02, 0.10)
)

</code></pre>

<hr>
<h2 id='adjust_uc_emc'>Adust for uncontrolled confounding and exposure misclassification.</h2><span id='topic+adjust_uc_emc'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_uc_emc()</code> was renamed to <code>adjust_uc_em()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_emc(
  data_observed,
  u_model_coefs = NULL,
  x_model_coefs = NULL,
  x1u0_model_coefs = NULL,
  x0u1_model_coefs = NULL,
  x1u1_model_coefs = NULL,
  level = 0.95
)
</code></pre>

<hr>
<h2 id='adjust_uc_emc_sel'>Adust for uncontrolled confounding, exposure misclassification, and selection
bias.</h2><span id='topic+adjust_uc_emc_sel'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_uc_emc_sel()</code> was renamed to <code>adjust_uc_em_sel()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_emc_sel(
  data_observed,
  u_model_coefs = NULL,
  x_model_coefs = NULL,
  x1u0_model_coefs = NULL,
  x0u1_model_coefs = NULL,
  x1u1_model_coefs = NULL,
  s_model_coefs,
  level = 0.95
)
</code></pre>

<hr>
<h2 id='adjust_uc_om'>Adust for uncontrolled confounding and outcome misclassification.</h2><span id='topic+adjust_uc_om'></span>

<h3>Description</h3>

<p><code>adjust_uc_om</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for uncontrolled confounding and outcome
misclassificaiton.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_om(
  data_observed,
  data_validation = NULL,
  u_model_coefs = NULL,
  y_model_coefs = NULL,
  u1y0_model_coefs = NULL,
  u0y1_model_coefs = NULL,
  u1y1_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_uc_om_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the true and misclassified outcome corresponding to the
observed exposure in <code>data_observed</code>.
There should also be data for the confounder missing in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_+3A_u_model_coefs">u_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(U=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>Y, 
where <em>U</em> is the binary unmeasured confounder, <em>X</em> is the
exposure, <em>Y</em> is the binary true outcome. The number of parameters
therefore equals 3.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_+3A_y_model_coefs">y_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(Y=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X + &delta;<sub>2</sub>Y* + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>Y</em> represents binary true outcome, <em>X</em> is the exposure,
<em>Y</em>* is the binary misclassified outcome,
<em>C</em> represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_+3A_u1y0_model_coefs">u1y0_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(U=1,Y=0)/P(U=0,Y=0)) = &gamma;<sub>1,0</sub> + &gamma;<sub>1,1</sub>X + &gamma;<sub>1,2</sub>Y* + &gamma;<sub>1,2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured confounder, <em>Y</em> is the
binary true outcome, <em>X</em> is the exposure, <em>Y</em>* is the binary
misclassified outcome, <em>C</em> represents the vector of measured
confounders (if any), and <em>j</em> corresponds to the number of
measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_+3A_u0y1_model_coefs">u0y1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(U=0,Y=1)/P(U=0,Y=0)) = &gamma;<sub>2,0</sub> + &gamma;<sub>2,1</sub>X + &gamma;<sub>2,2</sub>Y* + &gamma;<sub>2,2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured confounder, <em>Y</em> is the
binary true outcome, <em>X</em> is the exposure, <em>Y</em>* is the binary
misclassified outcome, <em>C</em> represents the vector of measured
confounders (if any), and <em>j</em> corresponds to the number of
measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_+3A_u1y1_model_coefs">u1y1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(U=1,Y=1)/P(U=0,Y=0)) = &gamma;<sub>3,0</sub> + &gamma;<sub>3,1</sub>X + &gamma;<sub>3,2</sub>Y* + &gamma;<sub>3,2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured confounder, <em>Y</em> is the
binary true outcome, <em>X</em> is the exposure, <em>Y</em>* is the binary
misclassified outcome, <em>C</em> represents the vector of measured
confounders (if any), and <em>j</em> corresponds to the number of
measured confounders.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Two different options for the bias parameters
are available here: 1) parameters from separate models of <em>U</em> and <em>Y</em>
(<code>u_model_coefs</code> and <code>y_model_coefs</code>) or 2) parameters from
a joint model of <em>U</em> and <em>Y</em> (<code>u1y0_model_coefs</code>,
<code>u0y1_model_coefs</code>, and <code>u1y1_model_coefs</code>).
</p>
<p>Values for the bias parameters can be applied as
fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_uc_om,
  exposure = "X",
  outcome = "Ystar",
  confounders = "C1"
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_uc_om_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = c("C1", "U"),
  misclassified_outcome = "Ystar"
)

adjust_uc_om(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using u_model_coefs and y_model_coefs -------------------------------------
adjust_uc_om(
  data_observed = df_observed,
  u_model_coefs = c(-0.22, 0.61, 0.70),
  y_model_coefs = c(-2.85, 0.73, 1.60, 0.38)
)

# Using u1y0_model_coefs, u0y1_model_coefs, u1y1_model_coefs ----------------
adjust_uc_om(
  data_observed = df_observed,
  u1y0_model_coefs = c(-0.19, 0.61, 0.00, -0.07),
  u0y1_model_coefs = c(-3.21, 0.60, 1.60, 0.36),
  u1y1_model_coefs = c(-2.72, 1.24, 1.59, 0.34)
)

</code></pre>

<hr>
<h2 id='adjust_uc_om_sel'>Adust for uncontrolled confounding, outcome misclassification, and selection
bias.</h2><span id='topic+adjust_uc_om_sel'></span>

<h3>Description</h3>

<p><code>adjust_uc_om_sel</code> returns the exposure-outcome odds ratio and
confidence interval, adjusted for uncontrolled confounding, outcome
misclassificaiton, and selection bias.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_om_sel(
  data_observed,
  data_validation = NULL,
  u_model_coefs = NULL,
  y_model_coefs = NULL,
  u0y1_model_coefs = NULL,
  u1y0_model_coefs = NULL,
  u1y1_model_coefs = NULL,
  s_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_uc_om_sel_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for: 1) the true and misclassified outcome corresponding
to the observed outcome in <code>data_observed</code>, 2) the confounder missing in
<code>data_observed</code>, 3) a selection indicator representing whether the
observation in <code>data_validation</code> was selected in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_u_model_coefs">u_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(U=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>Y, 
where <em>U</em> is the binary unmeasured confounder, <em>X</em> is the
exposure, and <em>Y</em> is the binary true outcome.
The number of parameters therefore equals 3.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_y_model_coefs">y_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(Y=1)) = &delta;<sub>0</sub> + &delta;<sub>1</sub>X + &delta;<sub>2</sub>Y* + &delta;<sub>2+j</sub>C<sub>j</sub>, 
where <em>Y</em> represents binary true outcome, <em>X</em> is the
exposure, <em>Y</em>* is the binary misclassified outcome, <em>C</em>
represents the vector of measured confounders (if any),
and <em>j</em> corresponds to the number of measured
confounders. The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_u0y1_model_coefs">u0y1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(U=0,Y=1)/P(U=0,Y=0)) = &gamma;<sub>2,0</sub> + &gamma;<sub>2,1</sub>X + &gamma;<sub>2,2</sub>Y* + &gamma;<sub>2,2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured confounder,
<em>Y</em> is the binary true outcome,
<em>X</em> is the exposure, <em>Y</em>* is the binary misclassified outcome,
<em>C</em> represents the vector of measured confounders (if any), and
<em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_u1y0_model_coefs">u1y0_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(U=1,Y=0)/P(U=0,Y=0)) = &gamma;<sub>1,0</sub> + &gamma;<sub>1,1</sub>X + &gamma;<sub>1,2</sub>Y* + &gamma;<sub>1,2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured confounder,
<em>Y</em> is the binary true outcome,
<em>X</em> is the exposure, <em>Y</em>* is the binary misclassified outcome,
<em>C</em> represents the vector of measured confounders (if any), and
<em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_u1y1_model_coefs">u1y1_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the
model:
log(P(U=1,Y=1)/P(U=0,Y=0)) = &gamma;<sub>3,0</sub> + &gamma;<sub>3,1</sub>X + &gamma;<sub>3,2</sub>Y* + &gamma;<sub>3,2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured confounder,
<em>Y</em> is the binary true outcome,
<em>X</em> is the exposure, <em>Y</em>* is the binary misclassified outcome,
<em>C</em> represents the vector of measured confounders (if any), and
<em>j</em> corresponds to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_s_model_coefs">s_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(S=1)) = &beta;<sub>0</sub> + &beta;<sub>1</sub>X + &beta;<sub>2</sub>Y* + &beta;<sub>2+j</sub>C<sub>2+j</sub>, 
where <em>S</em> represents binary selection, <em>X</em> is the exposure,
<em>Y</em>* is the binary misclassified outcome, <em>C</em> represents
the vector of measured confounders (if any), and <em>j</em> corresponds
to the number of measured confounders.
The number of parameters therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_om_sel_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Two different options for the bias
parameters are availale here: 1) parameters from separate models
of <em>U</em> and <em>Y</em> (<code>u_model_coefs</code> and <code>y_model_coefs</code>)
or 2) parameters from a joint model of <em>U</em> and <em>Y</em>
(<code>u1y0_model_coefs</code>, <code>u0y1_model_coefs</code>, and
<code>u1y1_model_coefs</code>). Both approaches require <code>s_model_coefs</code>.
</p>
<p>Values for the regression coefficients can be applied as
fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_uc_om_sel,
  exposure = "X",
  outcome = "Ystar",
  confounders = c("C1", "C2", "C3")
)

# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_uc_om_sel_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = c("C1", "C2", "C3", "U"),
  misclassified_outcome = "Ystar",
  selection = "S"
)

adjust_uc_om_sel(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using u_model_coefs, y_model_coefs, s_model_coefs -------------------------
adjust_uc_om_sel(
  data_observed = df_observed,
  u_model_coefs = c(-0.32, 0.59, 0.69),
  y_model_coefs = c(-2.85, 0.71, 1.63, 0.40, -0.85, 0.22),
  s_model_coefs = c(0.00, 0.74, 0.19, 0.02, -0.06, 0.02)
)

# Using u1y0_model_coefs, u0y1_model_coefs, u1y1_model_coefs, s_model_coefs
adjust_uc_om_sel(
  data_observed = df_observed,
  u1y0_model_coefs = c(-0.20, 0.62, 0.01, -0.08, 0.10, -0.15),
  u0y1_model_coefs = c(-3.28, 0.63, 1.65, 0.42, -0.85, 0.26),
  u1y1_model_coefs = c(-2.70, 1.22, 1.64, 0.32, -0.77, 0.09),
  s_model_coefs = c(0.00, 0.74, 0.19, 0.02, -0.06, 0.02)
)

</code></pre>

<hr>
<h2 id='adjust_uc_omc'>Adust for uncontrolled confounding and outcome misclassification.</h2><span id='topic+adjust_uc_omc'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_uc_omc_sel()</code> was renamed to <code>adjust_uc_om_sel()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_omc(
  data_observed,
  u_model_coefs = NULL,
  y_model_coefs = NULL,
  u0y1_model_coefs = NULL,
  u1y0_model_coefs = NULL,
  u1y1_model_coefs = NULL,
  level = 0.95
)
</code></pre>

<hr>
<h2 id='adjust_uc_omc_sel'>Adust for uncontrolled confounding, outcome misclassification, and selection
bias.</h2><span id='topic+adjust_uc_omc_sel'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p><code>adjust_uc_omc_sel()</code> was renamed to <code>adjust_uc_om_sel()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_omc_sel(
  data_observed,
  u_model_coefs = NULL,
  y_model_coefs = NULL,
  u0y1_model_coefs = NULL,
  u1y0_model_coefs = NULL,
  u1y1_model_coefs = NULL,
  s_model_coefs,
  level = 0.95
)
</code></pre>

<hr>
<h2 id='adjust_uc_sel'>Adust for uncontrolled confounding and selection bias.</h2><span id='topic+adjust_uc_sel'></span>

<h3>Description</h3>

<p><code>adjust_uc_sel</code> returns the exposure-outcome odds ratio and confidence
interval, adjusted for uncontrolled confounding and exposure
misclassificaiton.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_uc_sel(
  data_observed,
  data_validation = NULL,
  u_model_coefs = NULL,
  s_model_coefs = NULL,
  level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adjust_uc_sel_+3A_data_observed">data_observed</code></td>
<td>
<p>Object of class <code>data_observed</code> corresponding to the
data to perform bias analysis on.</p>
</td></tr>
<tr><td><code id="adjust_uc_sel_+3A_data_validation">data_validation</code></td>
<td>
<p>Object of class <code>data_validation</code> corresponding to
the validation data used to adjust for bias in the observed data. Here, the
validation data should have data for the same variables as in the observed
data, plus data for the confounder missing in <code>data_observed</code>. There
should also be a selection indicator representing whether the observation in
<code>data_validation</code> was selected in <code>data_observed</code>.</p>
</td></tr>
<tr><td><code id="adjust_uc_sel_+3A_u_model_coefs">u_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(U=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>Y + &alpha;<sub>2+j</sub>C<sub>j</sub>, 
where <em>U</em> is the binary unmeasured
confounder, <em>X</em> is the exposure, <em>Y</em> is the outcome, <em>C</em>
represents the vector of measured confounders (if any), and <em>j</em>
corresponds to the number of measured confounders. The number of parameters
therefore equals 3 + <em>j</em>.</p>
</td></tr>
<tr><td><code id="adjust_uc_sel_+3A_s_model_coefs">s_model_coefs</code></td>
<td>
<p>The regression coefficients corresponding to the model:
logit(P(S=1)) = &beta;<sub>0</sub> + &beta;<sub>1</sub>X + &beta;<sub>2</sub>Y, 
where <em>S</em> represents binary selection, <em>X</em> is the exposure,
and <em>Y</em> is the outcome. The number of parameters therefore equals 3.</p>
</td></tr>
<tr><td><code id="adjust_uc_sel_+3A_level">level</code></td>
<td>
<p>Value from 0-1 representing the full range of the confidence
interval. Default is 0.95.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bias adjustment can be performed by inputting either a validation dataset or
the necessary bias parameters. Values for the bias parameters
can be applied as fixed values or as single draws from a probability
distribution (ex: <code>rnorm(1, mean = 2, sd = 1)</code>). The latter has
the advantage of allowing the researcher to capture the uncertainty
in the bias parameter estimates. To incorporate this uncertainty in the
estimate and confidence interval, this function should be run in loop across
bootstrap samples of the dataframe for analysis. The estimate and
confidence interval would then be obtained from the median and quantiles
of the distribution of odds ratio estimates.
</p>


<h3>Value</h3>

<p>A list where the first item is the odds ratio estimate of the
effect of the exposure on the outcome and the second item is the
confidence interval as the vector: (lower bound, upper bound).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_observed &lt;- data_observed(
  data = df_uc_sel,
  exposure = "X",
  outcome = "Y",
  confounders = c("C1", "C2", "C3")
)
# Using validation data -----------------------------------------------------
df_validation &lt;- data_validation(
  data = df_uc_sel_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = c("C1", "C2", "C3", "U"),
  selection = "S"
)

adjust_uc_sel(
  data_observed = df_observed,
  data_validation = df_validation
)

# Using u_model_coefs and s_model_coefs -------------------------------------
adjust_uc_sel(
  data_observed = df_observed,
  u_model_coefs = c(-0.19, 0.61, 0.72, -0.09, 0.10, -0.15),
  s_model_coefs = c(-0.01, 0.92, 0.94)
)

</code></pre>

<hr>
<h2 id='data_observed'>Represent observed causal data</h2><span id='topic+data_observed'></span>

<h3>Description</h3>

<p><code>data_observed</code> combines the observed dataframe with specific identification
of the columns corresponding to the exposure, outcome, and confounders. It is
an essential input of all <code>adjust</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_observed(data, exposure, outcome, confounders = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data_observed_+3A_data">data</code></td>
<td>
<p>Dataframe for bias analysis.</p>
</td></tr>
<tr><td><code id="data_observed_+3A_exposure">exposure</code></td>
<td>
<p>String name of the column in <code>data</code> corresponding to the
exposure variable.</p>
</td></tr>
<tr><td><code id="data_observed_+3A_outcome">outcome</code></td>
<td>
<p>String name of the column in <code>data</code> corresponding to the
outcome variable.</p>
</td></tr>
<tr><td><code id="data_observed_+3A_confounders">confounders</code></td>
<td>
<p>String name(s) of the column(s) in <code>data</code> corresponding
to the confounding variable(s).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data_observed(
  data = df_sel,
  exposure = "X",
  outcome = "Y",
  confounders = c("C1", "C2", "C3")
)

</code></pre>

<hr>
<h2 id='data_validation'>Represent validation causal data</h2><span id='topic+data_validation'></span>

<h3>Description</h3>

<p><code>data_validation</code> combines the validation dataframe with specific
identification of the appropriate columns for bias adjustment, including:
true exposure, true outcome, confounders, misclassified exposure,
misclassified outcome, and selection. The purpose of validation data is to
use an external data source to transport the necessary causal relationships
that are missing in the observed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_validation(
  data,
  true_exposure,
  true_outcome,
  confounders = NULL,
  misclassified_exposure = NULL,
  misclassified_outcome = NULL,
  selection = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data_validation_+3A_data">data</code></td>
<td>
<p>Dataframe of validation data</p>
</td></tr>
<tr><td><code id="data_validation_+3A_true_exposure">true_exposure</code></td>
<td>
<p>String name of the column in <code>data</code> corresponding to
the true exposure.</p>
</td></tr>
<tr><td><code id="data_validation_+3A_true_outcome">true_outcome</code></td>
<td>
<p>String name of the column in <code>data</code> corresponding to
the true outcome.</p>
</td></tr>
<tr><td><code id="data_validation_+3A_confounders">confounders</code></td>
<td>
<p>String name(s) of the column(s) in <code>data</code> corresponding
to the confounding variable(s).</p>
</td></tr>
<tr><td><code id="data_validation_+3A_misclassified_exposure">misclassified_exposure</code></td>
<td>
<p>String name of the column in <code>data</code>
corresponding to the misclassified exposure.</p>
</td></tr>
<tr><td><code id="data_validation_+3A_misclassified_outcome">misclassified_outcome</code></td>
<td>
<p>String name of the column in <code>data</code>
corresponding to the misclassified outcome.</p>
</td></tr>
<tr><td><code id="data_validation_+3A_selection">selection</code></td>
<td>
<p>String name of the column in <code>data</code> corresponding to the
selection indicator.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data_validation(
  data = df_sel_source,
  true_exposure = "X",
  true_outcome = "Y",
  confounders = c("C1", "C2", "C3"),
  selection = "S"
)

</code></pre>

<hr>
<h2 id='df_em'>Simulated data with exposure misclassification</h2><span id='topic+df_em'></span>

<h3>Description</h3>

<p>Data containing one source of bias, three known confounders, and
100,000 observations. This data is obtained from <code>df_emc_source</code>
by removing the column <em>X</em>. The resulting data corresponds to
what a researcher would see in the real-world: a misclassified exposure,
<em>Xstar</em>, and no data on the true exposure. As seen in
<code>df_emc_source</code>, the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_em
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_em_om'>Simulated data with exposure misclassification and outcome misclassification</h2><span id='topic+df_em_om'></span>

<h3>Description</h3>

<p>Data containing two sources of bias, three known confounders, and
100,000 observations. This data is obtained from <code>df_emc_omc_source</code>
by removing the columns <em>X</em> and <em>Y</em>. The resulting data corresponds
to what a researcher would see in the real-world: a misclassified exposure,
<em>Xstar</em>, and a misclassified outcome, <em>Ystar</em>. As seen in
<code>df_em_om_source</code>, the true, unbiased exposure-outcome
odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_em_om
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_em_om_source'>Data source for <code>df_em_om</code></h2><span id='topic+df_em_om_source'></span>

<h3>Description</h3>

<p>Data with complete information on the two sources of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_em_om</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_em_om</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_em_om_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 7 columns:
</p>

<dl>
<dt>X</dt><dd><p>true exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_em_sel'>Simulated data with exposure misclassification and selection bias</h2><span id='topic+df_em_sel'></span>

<h3>Description</h3>

<p>Data containing two sources of bias, three known confounders, and
100,000 observations. This data is obtained by sampling with replacement
with probability = <em>S</em> from <code>df_em_sel_source</code> then removing the
columns <em>X</em> and <em>S</em>. The resulting data corresponds to what a
researcher would see in the real-world: a misclassified exposure,
<em>Xstar</em>, and missing data for those not selected into the study
(<em>S</em>=0). As seen in <code>df_em_sel_source</code>, the true, unbiased
exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_em_sel
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_em_sel_source'>Data source for <code>df_em_sel</code></h2><span id='topic+df_em_sel_source'></span>

<h3>Description</h3>

<p>Data with complete information on the two sources of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_em_sel</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_em_sel</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_em_sel_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 7 columns:
</p>

<dl>
<dt>X</dt><dd><p>true exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>S</dt><dd><p>selection, 1 = selected into the study and 0 = not selected into the study</p>
</dd>
</dl>


<hr>
<h2 id='df_em_source'>Data source for <code>df_em</code></h2><span id='topic+df_em_source'></span>

<h3>Description</h3>

<p>Data with complete information on one sources of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_em</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_em</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 +  &alpha;<sub>4</sub>C3
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_em_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 6 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>true outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_om'>Simulated data with outcome misclassification</h2><span id='topic+df_om'></span>

<h3>Description</h3>

<p>Data containing one source of bias, three known confounders, and
100,000 observations. This data is obtained from <code>df_om_source</code>
by removing the column <em>Y</em>. The resulting data corresponds to
what a researcher would see in the real-world: a misclassified outcome,
<em>Ystar</em>, and no data on the true outcome. As seen in
<code>df_om_source</code>, the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_om
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_om_sel'>Simulated data with outcome misclassification and selection bias</h2><span id='topic+df_om_sel'></span>

<h3>Description</h3>

<p>Data containing two sources of bias, a known confounder, and
100,000 observations. This data is obtained by sampling with replacement
with probability = <em>S</em> from <code>df_om_sel_source</code> then removing the
columns <em>Y</em> and <em>S</em>. The resulting data corresponds to what a
researcher would see in the real-world: a misclassified outcome,
<em>Ystar</em>, and missing data for those not selected into the study
(<em>S</em>=0). As seen in <code>df_om_sel_source</code>, the true, unbiased
exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_om_sel
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_om_sel_source'>Data source for <code>df_om_sel</code></h2><span id='topic+df_om_sel_source'></span>

<h3>Description</h3>

<p>Data with complete information on the two sources of bias, a known
confounder, and 100,000 observations. This data is used to derive
<code>df_om_sel</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_om_sel</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_om_sel_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 7 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>true outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
<dt>S</dt><dd><p>selection, 1 = selected into the study and 0 = not selected into the study</p>
</dd>
</dl>


<hr>
<h2 id='df_om_source'>Data source for <code>df_om</code></h2><span id='topic+df_om_source'></span>

<h3>Description</h3>

<p>Data with complete information on one sources of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_om</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_om</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_om_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 6 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>true outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_sel'>Simulated data with selection bias</h2><span id='topic+df_sel'></span>

<h3>Description</h3>

<p>Data containing one source of bias, three known confounders, and 100,000
observations. This data is obtained by sampling with replacement with
probability = <em>S</em> from <code>df_sel_source</code> then removing the <em>S</em>
column. The resulting data corresponds to what a researcher would see
in the real-world: missing data for those not selected into the study
(<em>S</em>=0). As seen in <code>df_sel_source</code>, the true, unbiased
exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_sel
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_sel_source'>Data source for <code>df_sel</code></h2><span id='topic+df_sel_source'></span>

<h3>Description</h3>

<p>Data with complete information on study selection, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_sel</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_sel</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_sel_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 6 columns:
</p>

<dl>
<dt>X</dt><dd><p>true exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>S</dt><dd><p>selection, 1 = selected into the study and 0 = not selected into the study</p>
</dd>
</dl>


<hr>
<h2 id='df_uc'>Simulated data with uncontrolled confounding</h2><span id='topic+df_uc'></span>

<h3>Description</h3>

<p>Data containing one source of bias, three known confounders, and
100,000 observations. This data is obtained from <code>df_uc_source</code>
by removing the column <em>U</em>. The resulting data corresponds to
what a researcher would see in the real-world: information on known
confounders (<em>C1</em>, <em>C2</em>, and <em>C3</em>), but not for
confounder <em>U</em>.
As seen in <code>df_uc_source</code>, the true, unbiased exposure-outcome
effect estimate = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 7 columns:
</p>

<dl>
<dt>X_bi</dt><dd><p>binary exposure, 1 = present and 0 = absent</p>
</dd>
<dt>X_cont</dt><dd><p>continuous exposure</p>
</dd>
<dt>Y_bi</dt><dd><p>binary outcome corresponding to exposure <em>X_bi</em>, 1 = present and 0 = absent</p>
</dd>
<dt>Y_cont</dt><dd><p>continuous outcome corresponding to exposure <em>X_cont</em></p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_em'>Simulated data with uncontrolled confounding and exposure misclassification</h2><span id='topic+df_uc_em'></span>

<h3>Description</h3>

<p>Data containing two sources of bias, three known confounders, and
100,000 observations. This data is obtained from <code>df_uc_em_source</code>
by removing the columns <em>X</em> and <em>U</em>. The resulting data
corresponds to what a researcher would see in the real-world: a
misclassified exposure, <em>Xstar</em>, and missing data on a confounder
<em>U</em>. As seen in <code>df_uc_em_source</code>, the true, unbiased
exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_em
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_em_sel'>Simulated data with uncontrolled confounding, exposure misclassification,
and selection bias</h2><span id='topic+df_uc_em_sel'></span>

<h3>Description</h3>

<p>Data containing three sources of bias, three known confounders, and
100,000 observations. This data is obtained by sampling with replacement
with probability = <em>S</em> from <code>df_uc_em_sel_source</code> then removing
the columns <em>X</em>, <em>U</em>, and <em>S</em>. The resulting data corresponds
to what a researcher would see in the real-world: a misclassified exposure,
<em>Xstar</em>; missing data on a confounder <em>U</em>; and missing data for
those not selected into the study (<em>S</em>=0). As seen in
<code>df_uc_em_sel_source</code>, the true, unbiased exposure-outcome
odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_em_sel
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_em_sel_source'>Data source for <code>df_uc_em_sel</code></h2><span id='topic+df_uc_em_sel_source'></span>

<h3>Description</h3>

<p>Data with complete information on the three sources of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_uc_em_sel</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_uc_em_sel</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3 + &alpha;<sub>5</sub>U
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_em_sel_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 8 columns:
</p>

<dl>
<dt>X</dt><dd><p>true exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>U</dt><dd><p>unmeasured confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
<dt>S</dt><dd><p>selection, 1 = selected into the study and 0 = not selected into the study</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_em_source'>Data source for <code>df_uc_em</code></h2><span id='topic+df_uc_em_source'></span>

<h3>Description</h3>

<p>Data with complete information on the two sources of bias, a known
confounder, and 100,000 observations. This data is used to derive
<code>df_uc_em</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_uc_em</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>U
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_em_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 7 columns:
</p>

<dl>
<dt>X</dt><dd><p>true exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>U</dt><dd><p>unmeasured confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Xstar</dt><dd><p>misclassified exposure, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_om'>Simulated data with uncontrolled confounding and outcome misclassification</h2><span id='topic+df_uc_om'></span>

<h3>Description</h3>

<p>Data containing two sources of bias, three known confounders, and
100,000 observations. This data is obtained from <code>df_uc_om_source</code>
by removing the columns <em>Y</em> and <em>U</em>. The resulting data
corresponds to what a researcher would see in the real-world: a
misclassified outcome, <em>Ystar</em>, and missing data on the binary
confounder <em>U</em>. As seen in <code>df_uc_omc_source</code>, the true, unbiased
exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_om
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_om_sel'>Simulated data with uncontrolled confounding, outcome misclassification,
and selection bias</h2><span id='topic+df_uc_om_sel'></span>

<h3>Description</h3>

<p>Data containing three sources of bias, three known confounders, and
100,000 observations. This data is obtained by sampling with replacement
with probability = <em>S</em> from <code>df_uc_om_sel_source</code> then removing
the columns <em>Y</em>, <em>U</em>, and <em>S</em>. The resulting data
corresponds to what a researcher would see in the real-world:
a misclassified outcome, <em>Ystar</em>; missing data
on a confounder <em>U</em>; and missing data for those not selected
into the study (<em>S</em>=0). As seen in <code>df_uc_om_sel_source</code>,
the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_om_sel
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_om_sel_source'>Data source for <code>df_uc_om_sel</code></h2><span id='topic+df_uc_om_sel_source'></span>

<h3>Description</h3>

<p>Data with complete information on the three sources of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_uc_om_sel</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_uc_om_sel</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3 + &alpha;<sub>5</sub>U
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_om_sel_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 8 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>true outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>U</dt><dd><p>unmeasured confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
<dt>S</dt><dd><p>selection, 1 = selected into the study and 0 = not selected into the study</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_om_source'>Data source for <code>df_uc_om</code></h2><span id='topic+df_uc_om_source'></span>

<h3>Description</h3>

<p>Data with complete information on the two sources of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_uc_om</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_uc_om</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>U
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_om_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 7 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>U</dt><dd><p>unmeasured confounder, 1 = present and 0 = absent</p>
</dd>
<dt>Ystar</dt><dd><p>misclassified outcome, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_sel'>Simulated data with uncontrolled confounding and selection bias</h2><span id='topic+df_uc_sel'></span>

<h3>Description</h3>

<p>Data containing two sources of bias, three known confounders, and 100,000
observations. This data is obtained by sampling with replacement with
probability = <em>S</em> from <code>df_uc_sel_source</code> then removing
the columns <em>U</em> and <em>S</em>. The resulting data corresponds to
what a researcher would see
in the real-world: missing data on confounder <em>U</em>; and missing data for
those not selected into the study (<em>S</em>=0). As seen in
<code>df_uc_sel_source</code>, the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_sel
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 5 columns:
</p>

<dl>
<dt>X</dt><dd><p>exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_sel_source'>Data source for <code>df_uc_sel</code></h2><span id='topic+df_uc_sel_source'></span>

<h3>Description</h3>

<p>Data with complete information on the two sources of bias, a known
confounder, and 100,000 observations. This data is used to derive
<code>df_uc_sel</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_uc_sel</code>. With this source data, the fitted regression
logit(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3 + &alpha;<sub>5</sub>U
shows that the true, unbiased exposure-outcome odds ratio = 2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_uc_sel_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 7 columns:
</p>

<dl>
<dt>X</dt><dd><p>true exposure, 1 = present and 0 = absent</p>
</dd>
<dt>Y</dt><dd><p>outcome, 1 = present and 0 = absent</p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>U</dt><dd><p>unmeasured confounder, 1 = present and 0 = absent</p>
</dd>
<dt>S</dt><dd><p>selection, 1 = selected into the study and 0 = not selected into the study</p>
</dd>
</dl>


<hr>
<h2 id='df_uc_source'>Data source for <code>df_uc</code></h2><span id='topic+df_uc_source'></span>

<h3>Description</h3>

<p>Data with complete information on one source of bias, three known
confounders, and 100,000 observations. This data is used to derive
<code>df_uc</code> and can be used to obtain bias parameters for purposes
of validating the simultaneous multi-bias adjustment method with
<code>df_uc</code>. With this source data, the fitted regression
g(P(Y=1)) = &alpha;<sub>0</sub> + &alpha;<sub>1</sub>X + &alpha;<sub>2</sub>C1 + &alpha;<sub>3</sub>C2 + &alpha;<sub>4</sub>C3 + &alpha;<sub>5</sub>U
shows that the true, unbiased exposure-outcome effect estimate = 2 when:
</p>

<ol>
<li><p> g = logit, Y = <em>Y_bi</em>, and X = <em>X_bi</em> or
</p>
</li>
<li><p> g = identity, Y = <em>Y_cont</em>, X = <em>X_cont</em>.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>df_uc_source
</code></pre>


<h3>Format</h3>

<p>A dataframe with 100,000 rows and 8 columns:
</p>

<dl>
<dt>X_bi</dt><dd><p>binary exposure, 1 = present and 0 = absent</p>
</dd>
<dt>X_cont</dt><dd><p>continuous exposure</p>
</dd>
<dt>Y_bi</dt><dd><p>binary outcome corresponding to exposure <em>X_bi</em>, 1 = present and 0 = absent</p>
</dd>
<dt>Y_cont</dt><dd><p>continuous outcome corresponding to exposure <em>X_cont</em></p>
</dd>
<dt>C1</dt><dd><p>1st confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C2</dt><dd><p>2nd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>C3</dt><dd><p>3rd confounder, 1 = present and 0 = absent</p>
</dd>
<dt>U</dt><dd><p>uncontrolled confounder, 1 = present and 0 = absent</p>
</dd>
</dl>


<hr>
<h2 id='evans'>Evans County dataset</h2><span id='topic+evans'></span>

<h3>Description</h3>

<p>Data from a cohort study in which white males in Evans County were followed
for 7 years, with coronary heart disease as the outcome of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evans
</code></pre>


<h3>Format</h3>

<p>A dataframe with 609 rows and 9 columns:
</p>

<dl>
<dt>ID</dt><dd><p>subject identifiction</p>
</dd>
<dt>CHD</dt><dd><p>outcome variable; 1 = coronary heart disease</p>
</dd>
<dt>AGE</dt><dd><p>age (in years)</p>
</dd>
<dt>CHL</dt><dd><p>cholesterol, mg/dl</p>
</dd>
<dt>SMK</dt><dd><p>1 = subject has ever smoked</p>
</dd>
<dt>ECG</dt><dd><p>1 = presence of electrocardiogram abnormality</p>
</dd>
<dt>DBP</dt><dd><p>diastolic blood pressure, mmHg</p>
</dd>
<dt>SBP</dt><dd><p>systolic blood pressure, mmHg</p>
</dd>
<dt>HPT</dt><dd><p>1 = SBP greater than or equal to 160 or DBP greater than or equal to 95</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://web1.sph.emory.edu/dkleinb/logreg3.htm#data">http://web1.sph.emory.edu/dkleinb/logreg3.htm#data</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
