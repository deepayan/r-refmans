<!DOCTYPE html><html><head><title>Help for package bootf2</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bootf2}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bootf2'><p>Estimate 90% Confidence Intervals of <code class="reqn">f_2</code> with Bootstrap Methodology</p></a></li>
<li><a href='#calcf2'><p>Calculate Similarity Factor <code class="reqn">f_2</code></p></a></li>
<li><a href='#helper'><p>Helper Functions</p></a></li>
<li><a href='#shah1998'><p>Dissolution data from the article of Shah et al 1998</p></a></li>
<li><a href='#sim.dp'><p>Simulate Dissolution Profiles</p></a></li>
<li><a href='#sim.dp.byf2'><p>Simulate Dissolution Profiles by <code class="reqn">f_2</code> Values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Simulation and Comparison of Dissolution Profiles</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-08-19</td>
</tr>
<tr>
<td>Description:</td>
<td>Compare dissolution profiles with confidence interval of similarity
  factor f2 using bootstrap methodology as described in the literature, such as 
  Efron and Tibshirani (1993, ISBN:9780412042317), Davison and Hinkley (1997,
  ISBN:9780521573917), and Shah et al. (1998) &lt;<a href="https://doi.org/10.1023%2FA%3A1011976615750">doi:10.1023/A:1011976615750</a>&gt;. 
  The package can also be used to simulate dissolution profiles based on 
  mathematical modelling and multivariate normal distribution.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/zhengguoxu/bootf2">https://github.com/zhengguoxu/bootf2</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/zhengguoxu/bootf2/issues">https://github.com/zhengguoxu/bootf2/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, minpack.lm, MASS, readxl, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-08-19 15:04:06 UTC; zhengguo</td>
</tr>
<tr>
<td>Author:</td>
<td>Zhengguo Xu [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zhengguo Xu &lt;zhengguoxu@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-08-25 12:50:22 UTC</td>
</tr>
</table>
<hr>
<h2 id='bootf2'>Estimate 90% Confidence Intervals of <code class="reqn">f_2</code> with Bootstrap Methodology</h2><span id='topic+bootf2'></span>

<h3>Description</h3>

<p>Main function to estimate 90% confidence intervals of <code class="reqn">f_2</code> using
bootstrap methodology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootf2(test, ref, path.in, file.in, path.out, file.out,
       n.boots = 10000L, seed = 306L, digits = 2L, alpha = 0.05,
       regulation = c("EMA", "FDA", "WHO","Canada", "ANVISA"),
       min.points = 1L, both.TR.85 = FALSE, print.report = TRUE,
       report.style = c("concise", "intermediate", "detailed"),
       f2.type = c("all", "est.f2", "exp.f2", "bc.f2",
                   "vc.exp.f2", "vc.bc.f2"),
       ci.type = c("all", "normal", "basic", "percentile",
                   "bca.jackknife", "bca.boot"),
       quantile.type = c("all", as.character(1:9), "boot"),
       jackknife.type = c("all", "nt+nr", "nt*nr", "nt=nr"),
       time.unit = c("min", "h"), output.to.screen = FALSE,
       sim.data.out = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootf2_+3A_test">test</code>, <code id="bootf2_+3A_ref">ref</code></td>
<td>
<p><em>Data frames</em> of dissolution profiles of test and reference
product if <code>path.in</code> and <code>file.in</code> are not specified; otherwise, they
should be <em>character</em> strings indicating the worksheet names of the Excel
file where the dissolution data is saved. See Input/Output in Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_path.in">path.in</code>, <code id="bootf2_+3A_file.in">file.in</code>, <code id="bootf2_+3A_path.out">path.out</code>, <code id="bootf2_+3A_file.out">file.out</code></td>
<td>
<p><em>Character</em> strings of input and
output directories and file names. See Input/Output in Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_n.boots">n.boots</code></td>
<td>
<p>An <em>integer</em> indicating the number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_seed">seed</code></td>
<td>
<p><em>Integer</em> seed value for reproducibility. If missing, a random
seed will be generated for reproducibility purpose.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_digits">digits</code></td>
<td>
<p>An <em>integer</em> indicating the decimal points for the output.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_alpha">alpha</code></td>
<td>
<p>A <em>numeric</em> value between 0 and 1 to estimate
<code class="reqn">(1-2\times \alpha)\times 100</code> confidence interval.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_regulation">regulation</code></td>
<td>
<p><em>Character</em> strings indicating regulatory guidelines.
@seealso <code><a href="#topic+calcf2">calcf2()</a></code> for details on regulation rules.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_min.points">min.points</code></td>
<td>
<p>An <em>integer</em> indicating the minimum time points to be used
to calculate <code class="reqn">f_2</code>. For conventional <code class="reqn">f_2</code> calculation, the
default is 3, however, for bootstrap <code class="reqn">f_2</code>, the value should be
lower as there might be less time points available in certain bootstrap
samples. The default is 1. @seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_both.tr.85">both.TR.85</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, and if <code>regulation = "FDA"</code>, all
measurements up to the time points at which both test and reference
products dissolve more than 85% will be used to calculate <code class="reqn">f_2</code>.
This is the conventional, but incorrect, interpretation of the US FDA rule.
Therefore, the argument should only be set to <code>TRUE</code> for validation purpose
such as comparing the results from old literature that use the wrong
interpretation to calculate <code class="reqn">f_2</code>. @seealso <code><a href="#topic+calcf2">calcf2()</a></code> for details
on regulation rules.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_print.report">print.report</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, a plain text report will be
produced. See Input/Output in Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_report.style">report.style</code></td>
<td>
<p><code>"concise"</code> style produces the estimators and their
confidence intervals; <code>"intermediate"</code> style adds a list of individual
<code class="reqn">f_2</code>s for all bootstrap samples in the end of <code>"concise"</code> report;
<code>"detailed"</code> style further adds individual bootstrap samples along with
their <code class="reqn">f_2</code>s in the end of <code>"intermediate"</code> report. See
Input/Output in Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_f2.type">f2.type</code></td>
<td>
<p><em>Character</em> strings indicating which type of <code class="reqn">f_2</code>
estimator should be calculated. See Types of estimators in Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_ci.type">ci.type</code></td>
<td>
<p><em>Character</em> strings indicating which type of confidence
interval should be estimated. See Types of confidence intervals in
Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_quantile.type">quantile.type</code></td>
<td>
<p><em>Character</em> strings indicating the type of percentile.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_jackknife.type">jackknife.type</code></td>
<td>
<p><em>Character</em> strings indicating the type of jackknife
method. See Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_time.unit">time.unit</code></td>
<td>
<p><em>Character</em> strings indicating the unit of time. It should
be either <code>"min"</code> for minute or <code>"h"</code> for hour. It is mainly used for
checking CV rules and making plot. @seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_output.to.screen">output.to.screen</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, a <code>"concise"</code> style summary
report will be printed on screen. See Input/Output in Details.</p>
</td></tr>
<tr><td><code id="bootf2_+3A_sim.data.out">sim.data.out</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, all individual bootstrap data
sets will be included in the output.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Minimum required arguments that must be provided by the user</h4>

<p>Arguments <code>test</code> and <code>ref</code> must be provided by the user. They should be <code>R</code>
<code style="white-space: pre;">&#8288;data frames&#8288;</code>, with <em>time as the first column</em>, and all individual profiles
profiles as the rest columns. The actual names of the columns do not matter
since they will be renamed internally.
</p>



<h4>Input/Output</h4>

<p>The dissolution data of test and reference product can either be provided as
<em>data frames</em> for <code>test</code> and <code>ref</code>, as explained above, or be read from an
<em>Excel file</em> with data of test and reference stored in <em>separate worksheets</em>.
In the latter case, the argument <code>path.in</code>, the directory where the Excel
file is, and <code>file.in</code>, the name of the Excel file <em>including the file
extension <code>.xls</code> or <code>.xlsx</code></em>, must be provided. In such case, the argument
<code>test</code> and <code>ref</code> must be <em>the names of the worksheets in quotation marks</em>.
The first column of each Excel worksheet must be time, and the rest columns
are individual dissolution profiles. The first row should be column names,
such as time, unit01, unit02, ... The actual names of the columns do not
matter as they will be renamed internally.
</p>
<p>Arguments <code>path.out</code> and <code>file.out</code> are the names of the output directory
and file. If they are not provided, but argument <code>print.report</code> is <code>TRUE</code>,
then a plain text report will be generated automatically in the current
working directory with file name <code>test_vs_ref_TZ_YYYY-MM-DD_HHMMSS.txt</code>,
where <code>test</code> and <code>ref</code> are data set names of test and reference, <code>TZ</code> is the
time zone such as <code>CEST</code>, <code>YYYY-MM-DD</code> is the numeric date format and
<code>HHMMSS</code> is the numeric time format for hour, minute, and second.
</p>
<p>For a quick check, set argument <code>output.to.screen = TRUE</code>, a summary report
very similar to <code>concise</code> style report will be printed on screen.
</p>



<h4>Types of Estimators</h4>

<p>According to Shah et al, the population <code class="reqn">f_2</code> for the inference is
</p>
<p style="text-align: center;"><code class="reqn">f_2 = 100-25\log\left(1 + \frac{1}{P}\sum_{i=1}^P%
  \left(\mu_{\mathrm{T},i} - \mu_{\mathrm{R},i}\right)^2 \right)\,,</code>
</p>

<p>where <code class="reqn">P</code> is the number of time points; <code class="reqn">\mu_{\mathrm{T},i}</code>
and <code class="reqn">\mu_{\mathrm{R},i}</code> are <em>population mean</em> of test and
reference product at time point <code class="reqn">i</code>, respectively; <code class="reqn">\sum_{i=1}^P</code> is the summation from <code class="reqn">i = 1</code> to <code class="reqn">P</code>.
</p>
<p>Five estimators for <code class="reqn">f_2</code> are included in the function:
</p>

<ol>
<li><p> The estimated <code class="reqn">f_2</code>, denoted by <code class="reqn">\hat{f}_2</code>, is the
one written in various regulatory guidelines. It is expressed differently,
but mathematically equivalently, as
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_2 = 100-25\log\left(1 + \frac{1}{P}\sum_{i=1}^P\left(%
     \bar{X}_{\mathrm{T},i} - \bar{X}_{\mathrm{R},i}\right)^2 \right)\:,</code>
</p>

<p>where <code class="reqn">P</code> is the number of time points;
<code class="reqn">\bar{X}_{\mathrm{T},i}</code> and
<code class="reqn">\bar{X}_{\mathrm{R},i}</code> are mean dissolution data at the
<code class="reqn">i</code>th time point of <em>random samples</em> chosen from the test and the
reference population, respectively. Compared to the equation of population
<code class="reqn">f_2</code> above, the only difference is that in the equation of
<code class="reqn">\hat{f}_2</code> the <em>sample means</em> of dissolution profiles replace
the <em>population means</em> for the approximation. <em>In other words, a point
estimate is used for the statistical inference in practice</em>.
</p>
</li>
<li><p> The Bias-corrected <code class="reqn">f_2</code>, denoted by
<code class="reqn">\hat{f}_{2,\mathrm{bc}}</code>, was described in the article of
Shah et al, as
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2,\mathrm{bc}} = 100-25\log\left(1 + \frac{1}{P}%
     \left(\sum_{i=1}^P\left(\bar{X}_{\mathrm{T},i} - %
     \bar{X}_{\mathrm{R},i}\right)^2 - \frac{1}{n}\sum_{i=1}^P%
     \left(S_{\mathrm{T},i}^2 + S_{\mathrm{R},i}^2\right)\right)\right)\,,</code>
</p>

<p>where <code class="reqn">S_{\mathrm{T},i}^2</code> and
<code class="reqn">S_{\mathrm{R},i}^2</code> are unbiased estimates of variance at
the <code class="reqn">i</code>th time points of random samples chosen from test and reference
population, respectively; and <code class="reqn">n</code> is the sample size.
</p>
</li>
<li><p> The variance- and bias-corrected <code class="reqn">f_2</code>, denoted by
<code class="reqn">\hat{f}_{2,\mathrm{vcbc}}</code>, does not assume equal weight of
variance as <code class="reqn">\hat{f}_{2,\mathrm{bc}}</code> does.
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{vcbc}} = 100-25\log\left(1 +%
     \frac{1}{P}\left(\sum_{i=1}^P \left(\bar{X}_{\mathrm{T},i} -%
       \bar{X}_{\mathrm{R},i}\right)^2 - \frac{1}{n}\sum_{i=1}^P%
       \left(w_{\mathrm{T},i}\cdot S_{\mathrm{T},i}^2 +%
       w_{\mathrm{R},i}\cdot S_{\mathrm{R},i}^2\right)\right)\right)\,,</code>
</p>

<p>where <code class="reqn">w_{\mathrm{T},i}</code> and <code class="reqn">w_{\mathrm{R},i}</code> are
weighting factors for variance of test and reference products,
respectively, which can be calculated as follows:
</p>
<p style="text-align: center;"><code class="reqn">w_{\mathrm{T},i} = 0.5 + \frac{S_{\mathrm{T},i}^2}%
     {S_{\mathrm{T},i}^2 + S_{\mathrm{R},i}^2}\,,</code>
</p>
<p> and
</p>
<p style="text-align: center;"><code class="reqn">w_{\mathrm{R},i} = 0.5 + \frac{S_{\mathrm{R},i}^2}%
     {S_{\mathrm{T},i}^2 + S_{\mathrm{R},i}^2}\,.</code>
</p>

</li>
<li><p> The expected <code class="reqn">f_2</code>, denoted by <code class="reqn">\hat{f}_{2, \mathrm{exp}}</code>, is calculated based on the mathematical expectation of estimated
<code class="reqn">f_2</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{exp}} = 100-25\log\left(1 + \frac{1}{P}%
     \left(\sum_{i=1}^P\left(\bar{X}_{\mathrm{T},i} - %
     \bar{X}_{\mathrm{R},i}\right)^2 + \frac{1}{n}\sum_{i=1}^P%
     \left(S_{\mathrm{T},i}^2 + S_{\mathrm{R},i}^2\right)\right)\right)\,,</code>
</p>

<p>using mean dissolution profiles and variance from samples for the
approximation of population values.
</p>
</li>
<li><p> The variance-corrected expected <code class="reqn">f_2</code>, denoted by
<code class="reqn">\hat{f}_{2, \mathrm{vcexp}}</code>, is calculated as
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{vcexp}} = 100-25\log\left(1 +%
     \frac{1}{P}\left(\sum_{i=1}^P \left(\bar{X}_{\mathrm{T},i} -%
       \bar{X}_{\mathrm{R},i}\right)^2 + \frac{1}{n}\sum_{i=1}^P%
       \left(w_{\mathrm{T},i}\cdot S_{\mathrm{T},i}^2 +%
       w_{\mathrm{R},i}\cdot S_{\mathrm{R},i}^2\right)\right)\right)\,.</code>
</p>

</li></ol>




<h4>Types of Confidence Interval</h4>

<p>The following confidence intervals are included:
</p>

<ol>
<li><p> The Normal interval with bias correction, denoted by <code>normal</code> in the
function, is estimated according to Davison and Hinkley,
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{L,U}} = \hat{f}_{2, \mathrm{S}} - E_B \mp %
     \sqrt{V_B}\cdot Z_{1-\alpha}\,,</code>
</p>

<p>where <code class="reqn">\hat{f}_{2, \mathrm{L,U}}</code> are the lower and upper
limit of the confidence interval estimated from bootstrap samples;
<code class="reqn">\hat{f}_{2, \mathrm{S}}</code> denotes the estimators described
above; <code class="reqn">Z_{1-\alpha}</code> represents the inverse of standard
normal cumulative distribution function with type I error <code class="reqn">\alpha</code>;
<code class="reqn">E_B</code> and <code class="reqn">V_B</code> are the <em>resampling estimates</em> of bias
and variance calculated as
</p>
<p style="text-align: center;"><code class="reqn">E_B = \frac{1}{B}\sum_{b=1}^{B}\hat{f}_{2,b}^\star - %
     \hat{f}_{2, \mathrm{S}} = \bar{f}_2^\star - \hat{f}_{2,\mathrm{S}}\,,</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">V_B = \frac{1}{B-1}\sum_{b=1}^{B} \left(\hat{f}_{2,b}^\star
     -\bar{f}_2^\star\right)^2\,,</code>
</p>

<p>where <code class="reqn">B</code> is the number of bootstrap samples;
<code class="reqn">\hat{f}_{2,b}^\star</code> is the <code class="reqn">f_2</code> estimate with
<code class="reqn">b</code>th bootstrap sample, and <code class="reqn">\bar{f}_2^\star</code> is the
mean value.
</p>
</li>
<li><p> The basic interval, denoted by <code>basic</code> in the function, is estimated
according to Davison and Hinkley,
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{L}} = 2\hat{f}_{2, \mathrm{S}} -%
     \hat{f}_{2,(B+1)(1-\alpha)}^\star\,,</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{U}} = 2\hat{f}_{2, \mathrm{S}} -%
     \hat{f}_{2,(B+1)\alpha}^\star\,,</code>
</p>

<p>where <code class="reqn">\hat{f}_{2,(B+1)\alpha}^\star</code> and
<code class="reqn">\hat{f}_{2,(B+1)(1-\alpha)}^\star</code> are the
<code class="reqn">(B+1)\alpha</code>th and <code class="reqn">(B+1)(1-\alpha)</code>th <em>ordered resampling
estimates</em> of <code class="reqn">f_2</code>, respectively. When <code class="reqn">(B+1)\alpha</code> is not
an integer, the following equation is used for interpolation,
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2,(B+1)\alpha}^\star = \hat{f}_{2,k}^\star + %
     \frac{\Phi^{-1}\left(\alpha\right)-\Phi^{-1}\left(\frac{k}{B+1}\right)}%
     {\Phi^{-1}\left(\frac{k+1}{B+1}\right)-\Phi^{-1}%
     \left(\frac{k}{B+1}\right)}\left(\hat{f}_{2,k+1}^\star-%
     \hat{f}_{2,k}^\star\right),</code>
</p>

<p>where <code class="reqn">k</code> is the <em>integer part</em> of <code class="reqn">(B+1)\alpha</code>,
<code class="reqn">\hat{f}_{2,k+1}^\star</code> and <code class="reqn">\hat{f}_{2,k}^\star</code> are the <code class="reqn">(k+1)</code>th and the <code class="reqn">k</code>th ordered resampling
estimates of <code class="reqn">f_2</code>, respectively.
</p>
</li>
<li><p> The percentile intervals, denoted by <code>percentile</code> in the function, are
estimated using nine different types of quantiles, Type 1 to Type 9, as
summarized in Hyndman and Fan's article and implemented in <code>R</code>'s
<code>quantile</code> function. Using <code>R</code>'s <code>boot</code> package, program <code>bootf2BCA</code>
outputs a percentile interval using the equation above for interpolation.
To be able to compare the results among different programs, the same
interval, denoted by <code>Percentile (boot)</code> in the function, is also
included in the function.
</p>
</li>
<li><p> The bias-corrected and accelerated (BCa) intervals are estimated according
to Efron and Tibshirani,
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{L}} = \hat{f}_{2, \alpha_1}^\star\,,</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{f}_{2, \mathrm{U}} = \hat{f}_{2, \alpha_2}^\star\,,</code>
</p>

<p>where <code class="reqn">\hat{f}_{2, \alpha_1}^\star</code> and
<code class="reqn">\hat{f}_{2, \alpha_2}^\star</code> are the <code class="reqn">100\alpha_1</code>th and the <code class="reqn">100\alpha_2</code>th percentile of the
resampling estimates of <code class="reqn">f_2</code>, respectively. Type I errors
<code class="reqn">\alpha_1</code> and <code class="reqn">\alpha_2</code> are obtained as
</p>
<p style="text-align: center;"><code class="reqn">\alpha_1 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0 + \hat{z}_\alpha}%
     {1-\hat{a}\left(\hat{z}_0 + \hat{z}_\alpha\right)}\right),</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\alpha_2 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0 + %
     \hat{z}_{1-\alpha}}{1-\hat{a}\left(\hat{z}_0 + %
     \hat{z}_{1-\alpha}\right)}\right),</code>
</p>

<p>where <code class="reqn">\hat{z}_0</code> and <code class="reqn">\hat{a}</code> are called
<em>bias-correction</em> and <em>acceleration</em>, respectively.
</p>
<p>There are different methods to estimate <code class="reqn">\hat{z}_0</code> and
<code class="reqn">\hat{a}</code>. Shah et al. used jackknife technique, denoted by
<code>bca.jackknife</code> in the function,
</p>
<p style="text-align: center;"><code class="reqn">\hat{z}_0 = \Phi^{-1}\left(\frac{N\left\{\hat{f}_{2,b}^\star &lt;%
     \hat{f}_{2,\mathrm{S}} \right\}}{B}\right),</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\hat{a} = \frac{\sum_{i=1}^{n}\left(\hat{f}_{2,\mathrm{m}} -%
     \hat{f}_{2, i}\right)^3}{6\left(\sum_{i=1}^{n}\left(%
     \hat{f}_{2,\mathrm{m}} - \hat{f}_{2, i}\right)^2\right)^{3/2}}\,,</code>
</p>

<p>where <code class="reqn">N\left\{\cdot\right\}</code> denotes the number of
element in the set, <code class="reqn">\hat{f}_{2, i}</code> is the <code class="reqn">i</code>th
jackknife statistic, <code class="reqn">\hat{f}_{2,\mathrm{m}}</code> is the mean of
the jackknife statistics, and <code class="reqn">\sum</code> is the summation from 1 to
sample size <code class="reqn">n</code>.
</p>
<p>Program <code>bootf2BCA</code> gives a slightly different BCa interval with <code>R</code>'s
<code>boot</code> package. This approach, denoted by <code>bca.boot</code> in the function, is
also implemented in the function for estimating the interval.
</p>
</li></ol>




<h4>Notes on the argument <code>jackknife.type</code></h4>

<p>For any sample with size <code class="reqn">n</code>, the jackknife estimator is obtained by
estimating the parameter for each subsample omitting the <code class="reqn">i</code>th
observation. However, when two samples (e.g., test and reference) are
involved, there are several possible ways to do it. Assuming sample size
of test and reference are <code class="reqn">n_\mathrm{T}</code> and <code class="reqn">n_\mathrm{R}</code>,
the following three possibility are considered:
</p>

<ul>
<li><p> Estimated by removing one observation from both test and reference samples.
In this case, the prerequisite is <code class="reqn">n_\mathrm{T} = n_\mathrm{R}</code>,
denoted by <code>nt=nr</code> in the function. So if there are 12 units in test and
reference data sets, there will be 12 jackknife estimators.
</p>
</li>
<li><p> Estimate the jackknife for test sample while keeping the reference data
unchanged; and then estimate jackknife for reference sample while keeping
the test sample unchanged. This is denoted by <code>nt+nr</code> in the function.
This is the default method. So if there are 12 units in test and reference
data sets, there will be <code class="reqn">12 + 12 = 24</code> jackknife estimators.
</p>
</li>
<li><p> For each observation deleted from test sample, estimate jackknife for
reference sample. This is denoted by <code>nt*nr</code> in the function. So if there
are 12 units in test and reference data sets, there will be <code class="reqn">12 \times
  12 = 144</code> jackknife estimators.
</p>
</li></ul>




<h3>Value</h3>

<p>A list of 3 or 5 components.
</p>

<ul>
<li> <p><code>boot.ci</code>: A <em>data frame</em> of bootstrap <code class="reqn">f_2</code> confidence intervals.
</p>
</li>
<li> <p><code>boot.f2</code>: A <em>data frame</em> of all individual <code class="reqn">f_2</code> values for all
bootstrap data set.
</p>
</li>
<li> <p><code>boot.info</code>: A <em>data frame</em> with detailed information of bootstrap for
reproducibility purpose, such as all arguments used in the function, time
points used for calculation of <code class="reqn">f_2</code>, and the number of <code>NA</code>s.
</p>
</li>
<li> <p><code>boot.summary</code>: A <em>data frame</em> with descriptive statistics of the
bootstrap <code class="reqn">f_2</code>.
</p>
</li>
<li> <p><code>boot.t</code> and <code>boot.r</code>: <em>Lists</em> of individual bootstrap samples for test
and reference product if <code>sim.data.out = TRUE</code>.
</p>
</li></ul>



<h3>References</h3>

<p>Shah, V. P.; Tsong, Y.; Sathe, P.; Liu, J.-P. In Vitro
Dissolution Profile Comparison&mdash;Statistics and Analysis of the
Similarity Factor, <code class="reqn">f_2</code>. <em>Pharmaceutical Research</em> 1998,
<strong>15</strong> (6), 889&ndash;896. DOI: 10.1023/A:1011976615750.
</p>
<p>Davison, A. C.; Hinkley, D. V. Bootstrap Methods and Their
Application. Cambridge University Press, 1997.
</p>
<p>Hyndman, R. J.; Fan, Y. Sample Quantiles in Statistical Packages.
<em>The American Statistician</em> 1996, <strong>50</strong> (4), 361&ndash;365. DOI:
/10.1080/00031305.1996.10473566.
</p>
<p>Efron, B.; Tibshirani, R. An Introduction to the Bootstrap.
Chapman &amp; Hall, 1993.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># time points
tp &lt;- c(5, 10, 15, 20, 30, 45, 60)
# model.par for reference with low variability
par.r &lt;- list(fmax = 100, fmax.cv = 3, mdt = 15, mdt.cv = 14,
              tlag = 0, tlag.cv = 0, beta = 1.5, beta.cv = 8)
# simulate reference data
dr &lt;- sim.dp(tp, model.par = par.r, seed = 100, plot = FALSE)
# model.par for test
par.t &lt;- list(fmax = 100, fmax.cv = 3, mdt = 12.29, mdt.cv = 12,
              tlag = 0, tlag.cv = 0, beta = 1.727, beta.cv = 9)
# simulate test data with low variability
dt &lt;- sim.dp(tp, model.par = par.t, seed = 100, plot = FALSE)

# bootstrap. to reduce test run time, n.boots of 100 was used in the example.
# In practice, it is recommended to use n.boots of 5000--10000.
# Set `output.to.screen = TRUE` to view the result on screen
d &lt;- bootf2(dt$sim.disso, dr$sim.disso, n.boots = 100, print.report = FALSE)


</code></pre>

<hr>
<h2 id='calcf2'>Calculate Similarity Factor <code class="reqn">f_2</code></h2><span id='topic+calcf2'></span>

<h3>Description</h3>

<p>Main function to calculate <code class="reqn">f_2</code> according to different regulatory
guidelines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcf2(test, ref, path.in, file.in, path.out, file.out,
       regulation = c("EMA", "FDA", "WHO", "Canada", "ANVISA"),
       cv.rule = TRUE, message = FALSE, min.points = 3L,
       f2.type = c("est.f2", "exp.f2", "bc.f2", "vc.exp.f2",
                   "vc.bc.f2", "all"), both.TR.85 = FALSE,
       digits = 2L, time.unit = c("min", "h"),  plot = TRUE,
       plot.start.time = 0, plot.max.unit = 24L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcf2_+3A_test">test</code>, <code id="calcf2_+3A_ref">ref</code></td>
<td>
<p><em>Data frames</em> of dissolution profiles of test and reference
product if <code>path.in</code> and <code>file.in</code> are not specified; otherwise, they
should be <em>character</em> strings indicating the worksheet names of the Excel
file where the dissolution data is saved. See Input/Output in Details.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_path.in">path.in</code>, <code id="calcf2_+3A_file.in">file.in</code>, <code id="calcf2_+3A_path.out">path.out</code>, <code id="calcf2_+3A_file.out">file.out</code></td>
<td>
<p><em>Character</em> strings of input and
output directories and file names. See Input/Output in Details.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_regulation">regulation</code></td>
<td>
<p><em>Character</em> strings indicating regulatory guidelines. See
Regulation in Details.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_cv.rule">cv.rule</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, CV rule will be checked according
to regulatory guidelines. See Regulation in Details.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_message">message</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, the results and messages will be
printed on screen. Users are recommended to set it to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_min.points">min.points</code></td>
<td>
<p>An <em>integer</em> indicating the minimum time points to be used
to calculate <code class="reqn">f_2</code>. The default value 3 should be used for
conventional <code class="reqn">f_2</code> calculation. This parameter is mainly used for
bootstrap <code class="reqn">f_2</code> method. See Regulation in Details.
@seealso <code><a href="#topic+bootf2">bootf2()</a></code>.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_f2.type">f2.type</code></td>
<td>
<p><em>Character</em> strings indicating which <code class="reqn">f_2</code> estimators
should be calculated. For conventional <code class="reqn">f_2</code> calculation, the
default <code>"est.f2"</code> should be used. Other estimators are mainly for the
bootstrap method. @seealso <code><a href="#topic+bootf2">bootf2()</a></code>.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_both.tr.85">both.TR.85</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, and if <code>regulation = "FDA"</code>, all
measurements up to the time points at which both test and reference
products dissolve more than 85% will be used to calculate <code class="reqn">f_2</code>.
This is the conventional, but incorrect, interpretation of the US FDA rule.
Therefore, the argument should only be set to <code>TRUE</code> for validation purpose
such as comparing the results from old literature that use the wrong
interpretation to calculate <code class="reqn">f_2</code>. See Regulation in Details.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_digits">digits</code></td>
<td>
<p>An <em>integer</em> indicating the decimal points for the output.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_time.unit">time.unit</code></td>
<td>
<p><em>Character</em> strings indicating the unit of time. It should
be either <code>"min"</code> for minute or <code>"h"</code> for hour. It is mainly used for
checking CV rules and making plot. See Regulation in Details.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_plot">plot</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, a dissolution versus time plot will be
printed.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_plot.start.time">plot.start.time</code></td>
<td>
<p><em>Numeric</em> value indicating the starting time for the
plot.</p>
</td></tr>
<tr><td><code id="calcf2_+3A_plot.max.unit">plot.max.unit</code></td>
<td>
<p><em>Integer</em>. If the number of individual units is no more
than this value, the mean and all individual profiles will be plotted;
otherwise, individual profiles will be represented by boxplots at each
time point. Therefore, to avoid overplotting, this value should not be
too large. @seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Minimum required arguments that must be provided by the user</h4>

<p>Arguments <code>test</code> and <code>ref</code> must be provided by the user. They should be <code>R</code>
<code style="white-space: pre;">&#8288;data frames&#8288;</code>, with <em>time as the first column</em>, and all individual profiles
profiles as the rest columns, or mean profile as the second column if only
mean profile is available. The actual names of the columns do not matter
since they will be renamed internally.
</p>



<h4>Input/Output</h4>

<p>The dissolution data of test and reference product can either be provided as
<em>data frames</em> for <code>test</code> and <code>ref</code>, as explained above, or be read from an
<em>Excel file</em> with data of test and reference stored in <em>separate worksheets</em>.
In the latter case, the argument <code>path.in</code>, the directory where the Excel
file is, and <code>file.in</code>, the name of the Excel file <em>including the file
extension <code>.xls</code> or <code>.xlsx</code></em>, must be provided. In such case, the argument
<code>test</code> and <code>ref</code> must be <em>the names of the worksheets in quotation marks</em>.
The first column of each Excel worksheet must be time, and the rest columns
are individual dissolution profiles, or the second column must be mean
profile if only mean data is available. The first row should be column names,
such as time, unit01, unit02, ... The actual names of the columns do not
matter as they will be renamed internally.
</p>
<p>Arguments <code>path.out</code> and <code>file.out</code> are the names of the output directory
and file. It is an overkill to output such simple calculations; therefore,
unless these two arguments are specified by the user, results are printed
on screen by default.
</p>



<h4>Regulation</h4>

<p>To apply <code class="reqn">f_2</code> method, different regulatory guidelines have slightly
different requirements. Some requirements are almost universal, such as same
time points for the test and reference product, minimum 3 time points
(excluding time zero), and twelve individual profiles for each formulation.
Other requirements are slightly different among different regulatory
guidelines, or at least interpreted differently. Two main issues are the
rules for the variability (CV Rule) and time points where dissolution is more
than 85% (85% Rule).
</p>


<h5>CV rule</h5>


<ul>
<li> <p><code>EMA</code>, <code>Canada</code>, and <code>ANVISA</code>: The CV of the <em>first time point</em> should not
be greater than 20%, and the CV of the rest time points should not be
greater than 10%.
</p>
</li>
<li> <p><code>WHO</code>: The CV should not be greater than 20% for <em>time points up to
10 min</em>, and not greater than 10% for the rest time points.
</p>
</li>
<li> <p><code>FDA</code>: US FDA is more flexible. The CV for the <em>early time points</em> should
not be greater than 20%, and for the rest time points, not greater than
10%.
</p>
</li></ul>

<p>The phrase <em>the first time point</em> in <code>EMA</code> rule was later interpreted as all
time points up to 10 min, according to an unofficial communication with an
European regulator. This makes the <em><code>EMA</code> rule the same as <code>WHO</code> rule</em>. For
example, if there are 5 min and 10 min time points in the dissolution
profiles, the CV for both 5 min and 10 min should not be greater than 20%.
</p>
<p>The <em>first time point</em> in <code>ANVISA</code> rule corresponds to <em>40% of the total
collected points</em>. For example, for a dissolution profile with five
collection times, the first two collection times are considered first points.
</p>
<p>The phrase <em>early time points</em> in <code>FDA</code> rule is typically interpreted as
those points up to 15 min, sometimes even up to 20 min according to
an unofficial communication with FDA staff. In the function <code>calcf2()</code>, the
cutting point for FDA rule is 15 min.
</p>



<h5>85% Rule</h5>

<p>This rule is implemented as follows:
</p>

<ul>
<li> <p><code>EMA</code>, <code>FDA</code>, <code>Canada</code>, and <code>ANVISA</code>: Only one measurement is considered
after 85% of dissolution for any product.
</p>
</li>
<li> <p><code>WHO</code>: Dissolution profiles should be 'cut' at the time point where
the reference release more than 85%. Therefore, <code>WHO</code> rule only differs
from rule of <code>EMA</code>, <code>FDA</code>, <code>Canada</code>, and <code>ANVISA</code> when test product
dissolve faster than reference. If reference product dissolve faster, then
rules of all five regulatory bodies are same in this regard.
</p>
</li></ul>




<h5>Notes on conventional FDA rule</h5>

<p>The exact phrase in the guidance of US FDA regarding this rule is that
&quot;<em>Only one measurement should be considered after 85% dissolution of both
the products</em>.&quot; Due to the ambiguous word &quot;both&quot; used in the sentence, the
conventional interpretation was that all measurements up to the time point
at which both test and reference dissolved more than 85% should be included
in the calculation of <code class="reqn">f_2</code>. However, this is only true when both
test and reference dissolve more than 85% at the same time points.
</p>
<p>Consider the following example:</p>

<table>
<tr>
 <td style="text-align: right;">
   time </td><td style="text-align: right;"> test </td><td style="text-align: right;"> reference </td>
</tr>
<tr>
 <td style="text-align: right;">
   5 </td><td style="text-align: right;"> 7 </td><td style="text-align: right;"> 10 </td>
</tr>
<tr>
 <td style="text-align: right;">
   10 </td><td style="text-align: right;"> 15 </td><td style="text-align: right;"> 20 </td>
</tr>
<tr>
 <td style="text-align: right;">
   15 </td><td style="text-align: right;"> 50 </td><td style="text-align: right;"> 55 </td>
</tr>
<tr>
 <td style="text-align: right;">
   20 </td><td style="text-align: right;"> 69 </td><td style="text-align: right;"> 86 </td>
</tr>
<tr>
 <td style="text-align: right;">
   30 </td><td style="text-align: right;"> 82 </td><td style="text-align: right;"> 90 </td>
</tr>
<tr>
 <td style="text-align: right;">
   45 </td><td style="text-align: right;"> 84 </td><td style="text-align: right;"> 95 </td>
</tr>
<tr>
 <td style="text-align: right;">
   60 </td><td style="text-align: right;"> 86 </td><td style="text-align: right;"> 97 </td>
</tr>
<tr>
 <td style="text-align: right;">
</td>
</tr>

</table>

<p>According to conventional interpretation, all measurements up to 60 min
should be included to calculate <code class="reqn">f_2</code> because both test and reference
dissolved more than 85% only at 60 min, not at any earlier time point.
However, in such case, there would be 4 measurement of reference (20, 30, 45,
and 60 min) included in the calculation, which would be a direct
contradictory to the phrase &quot;Only <em>one measurement</em> should be considered
after 85% ...&quot; in the same statement in the guidance!
</p>
<p>In an unofficial communication using this example, an FDA staff confirmed
that only the first 4 time points (up to 20 min) would be used. In other
words, <em>FDA rule in this regard is the same as EMA rule</em>.
</p>
<p>The statement in <code>ANVISA</code> guideline also uses the word &quot;ambos&quot; (means both),
which could also lead to the similar confusion. Follow the same logic as
demonstrated above, it should also be interpreted as the same rule in EMA
guideline.
</p>
<p>Read vignette <em>Introduction to bootf2</em> for more details.
</p>




<h3>Value</h3>

<p>A <em>data frame</em> of <code class="reqn">f_2</code> type and <code class="reqn">f_2</code> value, the
number of time points used for the calculation (<code>f2.tp</code>), indication if
both test and reference dissolve more than 85% at 15 min (<code>d85at15</code>), and
other information used for the calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tp &lt;- c(5, 10, 15, 20, 30, 45, 60)

mod.par.t &lt;- list(fmax = 100, fmax.cv = 2, tlag = 0, tlag.cv = 0,
                  mdt = 20, mdt.cv = 5, beta = 2.2, beta.cv = 5)

d.t &lt;- sim.dp(tp, model.par = mod.par.t, seed = 100, n.units = 120L,
              plot = FALSE)$sim.disso

mod.par.r &lt;- list(fmax = 100, fmax.cv = 2, tlag = 0, tlag.cv = 0,
                  mdt = 25, mdt.cv = 4, beta = 2.1, beta.cv = 3)

d.r &lt;- sim.dp(tp, model.par = mod.par.r, seed = 100, n.units = 120L,
              plot = FALSE)$sim.disso

# set `message = TRUE` to view the compliance of the regulatory guidelines.
calcf2(d.t, d.r, plot = FALSE)

</code></pre>

<hr>
<h2 id='helper'>Helper Functions</h2><span id='topic+helper'></span><span id='topic+bpwhisker.l'></span><span id='topic+bpwhisker.u'></span><span id='topic+ci.header'></span><span id='topic+mod.ref'></span><span id='topic+rpt.ci'></span><span id='topic+rpt.f2'></span><span id='topic+rpt.concise'></span><span id='topic+rpt.detailed'></span><span id='topic+rpt.info'></span><span id='topic+rpt.intermediate'></span><span id='topic+rpt.screen'></span>

<h3>Description</h3>

<p>Helper Functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpwhisker.l(x)

bpwhisker.u(x)

ci.header(boot.info)

mod.ref(tp, ref.dp, digits = 4, model, max.disso, time.unit)

rpt.ci(f2type, btsum, boot.info)

rpt.f2(f2type, f2o, boot.info, a.jack, btsum)

rpt.concise(boot.f2.ci, boot.info, f2o, a.jack, btsum)

rpt.detailed(data.t, data.r, boot.t, boot.r, boot.f2, boot.info, f2o)

rpt.info(boot.info)

rpt.intermediate(boot.info, boot.f2)

rpt.screen(boot.f2.ci, boot.info, f2o, a.jack, btsum)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="helper_+3A_x">x</code></td>
<td>
<p>Numeric vector</p>
</td></tr>
<tr><td><code id="helper_+3A_boot.info">boot.info</code></td>
<td>
<p>A data frame of bootstrap information from <code>bootf2</code>
function.</p>
</td></tr>
<tr><td><code id="helper_+3A_tp">tp</code>, <code id="helper_+3A_ref.dp">ref.dp</code></td>
<td>
<p>Numeric vector of time points <code>tp</code> and their
corresponding mean dissolution profiles <code>ref.dp</code>.</p>
</td></tr>
<tr><td><code id="helper_+3A_digits">digits</code></td>
<td>
<p>An integer indicating the decimal points for the output.</p>
</td></tr>
<tr><td><code id="helper_+3A_model">model</code></td>
<td>
<p>Strings of model names. Currently only 'Weibull' and
'first-order' models are supported.</p>
</td></tr>
<tr><td><code id="helper_+3A_max.disso">max.disso</code></td>
<td>
<p>Numeric value indicating the maximum dissolution.</p>
</td></tr>
<tr><td><code id="helper_+3A_time.unit">time.unit</code></td>
<td>
<p>Character strings indicating the unit of time. It should
be either <code>"min"</code> for minute or <code>"h"</code> for hour. It is mainly
used for checking CV rules and making plot. @seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
<tr><td><code id="helper_+3A_f2type">f2type</code></td>
<td>
<p>Character strings indicating the f2 type.</p>
</td></tr>
<tr><td><code id="helper_+3A_btsum">btsum</code></td>
<td>
<p>A data frame of descriptive statistics of the bootstrap data
set.</p>
</td></tr>
<tr><td><code id="helper_+3A_f2o">f2o</code></td>
<td>
<p>Vector of f2 values calculated with the original data set</p>
</td></tr>
<tr><td><code id="helper_+3A_a.jack">a.jack</code></td>
<td>
<p>Data frame of acceleration from <code>jackf2</code> function</p>
</td></tr>
<tr><td><code id="helper_+3A_boot.f2.ci">boot.f2.ci</code></td>
<td>
<p>Matrix of f2 values from bootstrap data sets</p>
</td></tr>
<tr><td><code id="helper_+3A_data.t">data.t</code>, <code id="helper_+3A_data.r">data.r</code></td>
<td>
<p>Input data sets for test and reference.</p>
</td></tr>
<tr><td><code id="helper_+3A_boot.t">boot.t</code>, <code id="helper_+3A_boot.r">boot.r</code></td>
<td>
<p>List of bootstrap data sets for test and reference.</p>
</td></tr>
<tr><td><code id="helper_+3A_boot.f2">boot.f2</code></td>
<td>
<p>Matrix of f2 calculated from bootstrap data sets.</p>
</td></tr>
</table>

<hr>
<h2 id='shah1998'>Dissolution data from the article of Shah et al 1998</h2><span id='topic+shah1998'></span>

<h3>Description</h3>

<p>Dissolution data of reference and 5 batches of test products published
in the article of Shah et al, Pharm. Res.1998, 15(6), 889&ndash;896.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shah1998
</code></pre>


<h3>Format</h3>

<p>A list of 6 data frames. Each data frame is a set of dissolution
profiles with the format: the first column is time, the rest columns
are individual profiles.
</p>

<dl>
<dt>ref</dt><dd><p>dissolution of reference batch</p>
</dd>
<dt>test1</dt><dd><p>dissolution of test batch 1</p>
</dd>
<dt>test2</dt><dd><p>dissolution of test batch 2</p>
</dd>
<dt>test3</dt><dd><p>dissolution of test batch 3</p>
</dd>
<dt>test4</dt><dd><p>dissolution of test batch 4</p>
</dd>
<dt>test5</dt><dd><p>dissolution of test batch 5</p>
</dd>
</dl>



<h3>Source</h3>

<p>Shah VP, Tsong Y, Sathe P, Liu JP. In vitro dissolution profile
comparison&ndash;statistics and analysis of the similarity factor, f2.
Pharm Res. 1998 Jun;15(6):889-96. doi: 10.1023/a:1011976615750.
</p>

<hr>
<h2 id='sim.dp'>Simulate Dissolution Profiles</h2><span id='topic+sim.dp'></span>

<h3>Description</h3>

<p>Function to simulate dissolution profiles based on mathematical models or
multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.dp(tp, dp, dp.cv, model = c("Weibull", "first-order"),
       model.par = NULL, seed = NULL, n.units = 12L, product,
       max.disso = 100, ascending = FALSE, message = FALSE,
       time.unit = c("min", "h"), plot = TRUE,
       plot.max.unit = 36L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.dp_+3A_tp">tp</code></td>
<td>
<p><em>Numeric</em> vector of time points for the dissolution profiles.
See Details.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_dp">dp</code>, <code id="sim.dp_+3A_dp.cv">dp.cv</code></td>
<td>
<p><em>Numeric</em> vectors of the <em>target mean dissolution profile</em>
(<code>dp</code>) and its respective CV at time points <code>tp</code> (<code>dp.cv</code>). See Details.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_model">model</code></td>
<td>
<p><em>Character</em> strings of model names. Currently only <code>"Weibull"</code>
and <code>"first-order"</code> models are supported.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_model.par">model.par</code></td>
<td>
<p>A <em>list</em> with model parameters. If missing, a list of
random <code>model.par</code> will be generated. See Details.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_seed">seed</code></td>
<td>
<p><em>Integer</em> seed value for reproducibility. If missing, a random
seed will be generated for reproducibility purpose.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_n.units">n.units</code></td>
<td>
<p>An <em>integer</em> indicating the number of individual profiles
to be simulated.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_product">product</code></td>
<td>
<p><em>Character</em> strings indicating the product name of the
simulated profiles. If missing, a random name with 3 letters and 4 digits
will be generated.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_max.disso">max.disso</code></td>
<td>
<p><em>Numeric</em> value for the maximum possible dissolution.
In theory, the maximum dissolution is 100%, but in practice, it is not
uncommon to see higher values, such as 105%, or much lower values,
especially for products with low solubility.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_ascending">ascending</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, simulated profiles will always
increase with time. Only applicable when the approach based on
multivariate normal distribution is used. See Details.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_message">message</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, basic information of the simulation
will be printed on screen.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_time.unit">time.unit</code></td>
<td>
<p><em>Character</em> strings indicating the unit of time. It should
be either <code>"min"</code> for minute or <code>"h"</code> for hour. It is mainly used for
and making plot and generating <code>model.par</code> and <code>dp.cv</code> when they are not
provided by the user. @seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_plot">plot</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, a a dissolution versus time plot will be
included in the output.</p>
</td></tr>
<tr><td><code id="sim.dp_+3A_plot.max.unit">plot.max.unit</code></td>
<td>
<p><em>Integer</em>. If the number of individual units is no more
than this value, the mean and all individual profiles will be plotted;
otherwise, individual profiles will be represented by boxplots at each
time point. Therefore, to avoid overplotting, this value should not be
too large. @seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Simulation approaches</h4>

<p>The approach used to simulate individual dissolution profiles depends on if
the <em>target mean dissolution profile</em> <code>dp</code> is provided by the user or not.
</p>

<ul>
<li><p> If <code>dp</code> is not provided, then it will be calculated using <code>tp</code>, <code>model</code>,
and <code>model.par</code>. The parameters defined by <code>model.par</code> are considered as
the <em>population parameter</em>; consequently, the calculated <code>dp</code> is
considered as the <em>targeted population profile</em>. In addition, <code>n.units</code>
sets of <em>individual model parameters</em> will be simulated based on
exponential error model, and <em>individual dissolution profiles</em> will be
generated using those individual parameters. The mean of all simulated
individual profiles, <code>sim.mean</code>, included in one of the outputs data
frames, <code>sim.summary</code>, will be <em>similar, but not identical, to <code>dp</code></em>.
The difference between <code>sim.mean</code> and <code>dp</code> is determined by the number of
units and the variability of the model parameters. In general, the larger
the number of units and the lower of the variability, the smaller the
difference. Additional details on the mathematical models are given below.
</p>
</li>
<li><p> If <code>dp</code> is provided, then <code>n.units</code> of individual dissolution profiles
will be simulated using multivariate normal distribution. The mean of all
simulated individual profiles, <code>sim.mean</code>, will be <em>identical to <code>dp</code></em>.
In such case, it is recommended that <code>dp.cv</code>, the CV at time points <code>tp</code>,
should also be provided by the user. If <code>dp.cv</code> is not provided, it will
be generated automatically such that the CV is between 10% and 20% for time
points up to 10 min, between 1% and 3% for time points where the
dissolution is more than 95%, between 3% and 5% for time points where the
dissolution is between 90% and 95%, and between 5% and 10% for the rest of
time points. Whether the <code>dp.cv</code> is provided or generated automatically,
the CV calculated using all individual profiles will be equal to <code>dp.cv</code>.
Additional details on this approach are given below.
</p>
</li></ul>




<h4>Minimum required arguments that must be provided by the user</h4>

<p>If <code>dp</code> is provided by the user, logically, <code>tp</code> must also be provided, and
the approach based on multivariate normal distribution is used, as explained
above. If <code>dp</code> is not provided, <code>tp</code> could be missing, i.e., a simple
function call such as <code>sim.dp()</code> will simulate dissolution profiles. In such
case, a default <code>tp</code> will be generated depending on the <code>time.unit</code>: if the
<code>time.unit</code> is <code>"min"</code>, then <code>tp</code> would be <code>c(5, 10, 15, 20, 30, 45, 60)</code>;
otherwise the <code>tp</code> would be <code>c(1, 2, 3, 4, 6, 8, 10, 12)</code>. The rest
arguments are either optional, or required by the function but default
values will be used.
</p>



<h4>Notes on mathematical models</h4>

<p>The first-order model is expressed as
</p>
<p style="text-align: center;"><code class="reqn">f_t = f_\mathrm{max} \left(1 - %
  e^{-k\left(t - t_\mathrm{lag}\right)}\right),</code>
</p>

<p>and the Weibull model was expressed either as
</p>
<p style="text-align: center;"><code class="reqn">f_t = f_\mathrm{max} \left(1 - %
  e^{-\left(\frac{t - t_\mathrm{lag}}{\mathrm{MDT}}%
  \right)^\beta}\right)</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">f_t = f_\mathrm{max} \left(1 - %
  e^{-\frac{(t - t_\mathrm{lag})^\beta}{\alpha}}\right)</code>
</p>

<p>where <code class="reqn">f_\mathrm{max}</code> is the maximum dissolution,
<code class="reqn">\mathrm{MDT}</code> is the mean dissolution time,
<code class="reqn">t_\mathrm{lag}</code> is the lag time, <code class="reqn">\alpha</code> and
<code class="reqn">\beta</code> are the scale and shape factor in Weibull function,
and <code class="reqn">k</code> is the rate constant in the first-order model. Obviously,
The two Weibull models are mathematically equivalent by letting
<code class="reqn">\alpha = \mathrm{MDT}^\beta</code>.
</p>
<p>Individual model parameter were simulated according to the exponential
error model
</p>
<p style="text-align: center;"><code class="reqn">P_i = P_\mu e^{N\left(0, \sigma^2\right)}</code>
</p>

<p>where <code class="reqn">P_i</code> and <code class="reqn">P_\mu</code> denote the individual and
population model parameters; <code class="reqn">N\left(0, \sigma^2\right)</code>
represents the normal distribution with mean zero and variance <code class="reqn">\sigma^2</code>
(<code class="reqn">\sigma = \mathrm{CV}/100</code>).
</p>



<h4>How to supply <code>model.par</code></h4>

<p>The argument <code>model.par</code> should be supplied as a <em>named list</em> of model
parameters as explained above, and their respective CV for simulation of
individual parameters. Therefore, for the first-order model, three pairs of
parameters should be specified: <code>fmax/fmax.cv</code>, <code>k/k.cv</code>, and <code>tlag/tlag.cv</code>;
and for Weibull model, four pairs: <code>fmax/fmax.cv</code>, <code>tlag/tlag.cv</code>,
<code>beta/beta.cv</code>, and either <code>alpha/alpha.cv</code> or <code>mdt/mdt.cv</code>, depending on
the mathematical formula used. CV should be given in percentage, e.g., if
CV for <code>beta</code> is 30%, it should be specified as <code>beta.cv = 30</code>, <em>not</em>
<code>beta.cv = 0.3</code>. The order of the parameters does not matter, but the name
of the parameters must be given <em>exactly same</em> as described above.
For example:
</p>

<ul>
<li> <p><code>model.par = list(fmax = 100, fmax.cv = 5, k = 0.6, k.cv = 25, tlag = 0, tlag.cv = 0)</code> for the first-order model.
</p>
</li>
<li> <p><code>model.par = list(fmax = 100, fmax.cv = 5, tlag = 5, tlag.cv = 10, mdt = 15, mdt.cv = 20, beta = 1.5, beta.cv = 5)</code>, or
</p>
</li>
<li> <p><code>model.par = list(fmax = 100, fmax.cv = 5, tlag = 5, tlag.cv = 10, alpha = 60, alpha.cv = 20, beta = 1.5, beta.cv = 5)</code> for Weibull models.
</p>
</li></ul>




<h4>Notes on multivariate normal distribution approach</h4>

<p>When this approach is used, depending on <code>dp/dp.cv</code>, there is no guarantee
that all individual profiles increase with time; near the end of the time
points, some individual profiles may decrease, especially when the
dissolution is close to the plateau and the variability is high. This can
happen to real life data, especially for those products with drug substances
that are unstable in dissolution medium. To force increase for all profiles,
set <code>ascending = TRUE</code>. Depending on the data, the program may take long
time to run, or may even fail.
</p>



<h3>Value</h3>

<p>A list of 3 to 5 components:
</p>

<ul>
<li> <p><code>sim.summary</code>: A <em>data frame</em> with summary statistics of all
individual dissolution profiles.
</p>
</li>
<li> <p><code>sim.disso</code>: A <em>data frame</em> with all individual dissolution profiles.
</p>
</li>
<li> <p><code>sim.info</code>: A <em>data frame</em> with information of the simulation such as
the seed number and number of individual profiles. If modelling approach
is used, the data frame will contain model parameters as well.
</p>
</li>
<li> <p><code>model.par.ind</code>: A <em>data frame</em> of all individual model parameters
that were used for the simulation of individual dissolution profiles.
Available only if the modelling approach is used, i.e., when <code>dp</code>
is missing.
</p>
</li>
<li> <p><code>sim.dp</code>: A plot. Available only if the argument <code>plot</code> is <code>TRUE</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># time points
tp &lt;- c(5, 10, 15, 20, 30, 45, 60)

# using all default values to simulate profiles
d1 &lt;- sim.dp(tp, plot = FALSE)

# summary statistics
d1$sim.summary

# individual profiles
d1$sim.disso

# simulation information
d1$sim.info

#individual model parameters
d1$mod.par.ind

# using Weibull model to simulate 100 profiles without lag time
mod.par &lt;- list(fmax = 100, fmax.cv = 2, tlag = 0, tlag.cv = 0,
                mdt = 20, mdt.cv = 5, beta = 2.2, beta.cv = 5)
d2 &lt;- sim.dp(tp, model.par = mod.par, seed = 100, n.units = 100L,
             plot = FALSE)

# using multivariate normal distribution approach
# target mean profile with same length as tp
dp &lt;- c(39, 56, 67, 74, 83, 90, 94)

# CV% at each time point
dp.cv &lt;- c(19, 15, 10, 8, 8, 5, 3)

# simulation
d3 &lt;- sim.dp(tp, dp = dp, dp.cv = dp.cv, seed = 1234, plot = FALSE)

</code></pre>

<hr>
<h2 id='sim.dp.byf2'>Simulate Dissolution Profiles by <code class="reqn">f_2</code> Values</h2><span id='topic+sim.dp.byf2'></span>

<h3>Description</h3>

<p>Given any mean dissolution profile <code>dp</code>, this function will simulate a mean
dissolution profile such that when the newly simulated profile is compared
to <code>dp</code>, the calculated <code class="reqn">f_2</code> will be equal to the predefined target
<code class="reqn">f_2</code> value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim.dp.byf2(tp, dp, target.f2, seed = NULL, min.points = 3L,
            regulation = c("EMA", "FDA", "WHO", "Canada", "ANVISA"),
            model = c("Weibull", "first-order"), digits = 2L,
            max.disso = 100, message = FALSE, both.TR.85 = FALSE,
            time.unit = c("min", "h"), plot = TRUE, sim.dp.out,
            sim.target = c("ref.pop", "ref.median", "ref.mean"),
            model.par.cv = 50, fix.fmax.cv = 0, random.factor = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim.dp.byf2_+3A_tp">tp</code>, <code id="sim.dp.byf2_+3A_dp">dp</code></td>
<td>
<p><em>Numeric</em> vector of time points <code>tp</code> and the mean dissolution
profiles <code>dp</code>.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_target.f2">target.f2</code></td>
<td>
<p><em>Numeric</em> value of target <code class="reqn">f_2</code>. It can be a
<em>single value</em>, or a <em>vector of two values</em> that represent the lower and
upper limit of target <code class="reqn">f_2</code> value. See Details.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_seed">seed</code></td>
<td>
<p><em>Integer</em> seed value for reproducibility. If missing, a random
seed will be generated for reproducibility purpose.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_min.points">min.points</code></td>
<td>
<p>An <em>integer</em> indicating the minimum time points to be used
to calculate <code class="reqn">f_2</code>. The default value 3 should be used for
conventional <code class="reqn">f_2</code> calculation. See Details. @seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_regulation">regulation</code></td>
<td>
<p><em>Character</em> strings indicating regulatory guidelines.
@seealso <code><a href="#topic+calcf2">calcf2()</a></code> for the discussion of those guidelines.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_model">model</code></td>
<td>
<p><em>Character</em> strings of model names. Currently only <code>"Weibull"</code>
and <code>"first-order"</code> models are supported. @seealso <code><a href="#topic+sim.dp">sim.dp()</a></code> for the
description of models.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_digits">digits</code></td>
<td>
<p>An <em>integer</em> indicating the decimal points for the output.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_max.disso">max.disso</code></td>
<td>
<p><em>Numeric</em> value for the maximum possible dissolution.
In theory, the maximum dissolution is 100%, but in practice, it is not
uncommon to see higher values, such as 105%, or much lower values,
especially for products with low solubility.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_message">message</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, basic information of the simulation
will be printed on screen.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_both.tr.85">both.TR.85</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, and if <code>regulation = "FDA"</code>, all
measurements up to the time points at which both test and reference
products dissolve more than 85% will be used to calculate <code class="reqn">f_2</code>.
This is the conventional, but incorrect, interpretation of the US FDA rule.
Therefore, the argument should only be set to <code>TRUE</code> for validation purpose
such as comparing the results from old literature that use the wrong
interpretation to calculate <code class="reqn">f_2</code>. @seealso <code><a href="#topic+calcf2">calcf2()</a></code> for detailed
discussion.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_time.unit">time.unit</code></td>
<td>
<p><em>Character</em> strings indicating the unit of time. It should
be either <code>"min"</code> for minute or <code>"h"</code> for hour. It is mainly used for
checking CV rules and making plot. See Regulation in Details.
@seealso <code><a href="#topic+calcf2">calcf2()</a></code>.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_plot">plot</code></td>
<td>
<p><em>Logical</em>. If <code>TRUE</code>, a a dissolution versus time plot will be
included in the output.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_sim.dp.out">sim.dp.out</code></td>
<td>
<p>Output of function <code>sim.dp()</code>. If this argument is
supplied by the user, then <code>tp/dp</code>, <code>regulation</code>, <code>model</code>, <code>max.disso</code>,
and <code>time.unit</code> will be ignored, if they are provided by the user, since
all those arguments are included in <code>sim.dp.out</code>.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_sim.target">sim.target</code></td>
<td>
<p><em>Character</em> strings indicating to which target profile
should the newly simulated profile be compared for the calculation of
<code class="reqn">f_2</code>. This argument is only applicable when <code>sim.dp.out</code> is
provided. See Details.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_model.par.cv">model.par.cv</code>, <code id="sim.dp.byf2_+3A_fix.fmax.cv">fix.fmax.cv</code></td>
<td>
<p><em>Numeric</em> values expressed as percentages
used for random generation of model parameters and fmax when optimization
algorithm is not used, i.e., when <code>target.f2</code> is a vector of two numbers.
See Details.</p>
</td></tr>
<tr><td><code id="sim.dp.byf2_+3A_random.factor">random.factor</code></td>
<td>
<p><em>Numeric</em> value used for random generation of model
parameters when optimization algorithm is used, i.e., when <code>target.f2</code>
is a single number. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main principle of the function is as follows:
</p>

<ol>
<li><p> For any given mean dissolution profile <code>dp</code>, fit a suitable mathematical
model and obtain model parameters.
</p>

<ul>
<li><p> No precise fitting is required since those parameters will be served as
<em>initial value</em> for further model fitting.
</p>
</li>
<li><p> If <code>sim.dp.out</code>, the output of the function <code>sim.dp()</code>, is available,
no initial fitting is necessary as model parameters can be read directly
from the output, unless multivariate normal distribution approach was
used in <code>sim.dp()</code>. In such case, initial model fitting will be done.
</p>
</li></ul>

</li>
<li><p> Find a suitable model parameters and simulate a new dissolution profile,
comparing the new profile to the provided reference profile <code>dp</code> by
calculating <code class="reqn">f_2</code>. If the the obtained <code class="reqn">f_2</code> is
<em>equal to</em>, or <em>within the lower and upper limit of</em>, the <code>target.f2</code>,
then the function will output the obtained model parameters and the new
profile.
</p>
</li></ol>

<p>There are two approaches used to find the suitable model parameters:
</p>

<ul>
<li><p> If <code>target.f2</code> is a single value, optimization algorithm will be used and
the newly simulated dissolution profile will have <code class="reqn">f_2</code> equal to
<code>target.f2</code> when compared to <code>dp</code> (within numeric precision defined by the
tolerance).
</p>
</li>
<li><p> If <code>target.f2</code> is a vector of two numbers representing the lower and upper
limit of target <code class="reqn">f_2</code> value, such as <code>target.f2 = c(lower, upper)</code>,
then dissolution will be obtained by random searching and the calculated
<code class="reqn">f_2</code> will be within the range of lower and upper.
</p>
</li></ul>

<p>For example, you can set <code>target.f2 = c(54.95, 55.04)</code> to have target
<code class="reqn">f_2</code> of 55. Since <code class="reqn">f_2</code> should be normally reported without
decimal, in practice, this precision is enough. You might be able to do with
<code>c(54.99, 55.01)</code> if you really need more precision. However, the narrower
the range, the longer it takes the function to run. With narrow range such as
<code>c(54.999, 55.001)</code>, it is likely the program will fail. In such case,
provide single value to use optimization algorithm.
</p>
<p>Arguments <code>model.par.cv</code>, <code>fix.fmax.cv</code>, and <code>random.factor</code> are certain
numeric values used to better control the random generation of model
parameters. The default values should work in most scenarios. Those values
should be changed only when the function failed to return any value. Read
vignette of the function (<code>vignette("sim.dp.byf2", package = "bootf2")</code>)
for more details.
</p>
<p>The data frame <code>sim.summary</code> in <code>sim.dp.out</code>, the output of function
<code>sim.dp()</code>, contains <code>dp</code>, the population profile, and <code>sim.mean</code> and
<code>sim.median</code>, the mean and median profiles calculated with <code>n.units</code> of
simulated individual profiles. All these three profiles could be used as the
target profile that the newly simulated profile will be compare to. Argument
<code>sim.target</code> defines which of the three will be used: <code>ref.pop</code>, <code>ref.mean</code>,
and <code>ref.median</code> correspond to <code>dp</code>, <code>sim.mean</code> and <code>sim.median</code>,
respectively.
</p>


<h3>Value</h3>

<p>A <em>list</em> of 2 components: a <em>data frame of model parameters</em> and a
<em>data frame of mean dissolution profile</em> generated using the said model
parameters. The output can be passed to function <code>sim.dp()</code> to further
simulate multiple individual profiles.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tp &lt;- c(5, 10, 15, 20, 30, 45, 60)

mod.par.r &lt;- list(fmax = 100, fmax.cv = 2, tlag = 0, tlag.cv = 0,
                  mdt = 25, mdt.cv = 4, beta = 2.1, beta.cv = 3)

d.r &lt;- sim.dp(tp, model.par = mod.par.r, seed = 100, n.units = 120L,
              plot = FALSE)

model.par1 &lt;- sim.dp.byf2(sim.dp.out = d.r, target.f2 = 60, seed = 123)
model.par2 &lt;- sim.dp.byf2(sim.dp.out = d.r, target.f2 = c(59.95, 60.04),
                          seed = 123)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
