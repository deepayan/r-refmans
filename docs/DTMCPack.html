<!DOCTYPE html><html><head><title>Help for package DTMCPack</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DTMCPack}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DTMC'>
<p>Simulation of Discrete-Time/State Markov Chain</p></a></li>
<li><a href='#DTMCPack-package'>
<p>Suite of functions related to discrete-time discrete-state Markov Chains</p></a></li>
<li><a href='#FPTime'>
<p>First Passage Time</p></a></li>
<li><a href='#gr'>
<p>Example Data Set: Gambler's ruin on 4 states</p></a></li>
<li><a href='#hh'>
<p>Harry the SemiPro</p></a></li>
<li><a href='#id'>
<p>Initial distribution</p></a></li>
<li><a href='#MultDTMC'>
<p>Multiple Discrete time Markov Chains</p></a></li>
<li><a href='#statdistr'>
<p>Computing Stationary Distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Suite of Functions Related to Discrete-Time Discrete-State
Markov Chains</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-04-10</td>
</tr>
<tr>
<td>Author:</td>
<td>William Nicholson</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>William Nicholson&lt;wbnicholson@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A series of functions which aid in both simulating and determining the properties of finite, discrete-time, discrete state markov chains.  Two functions (DTMC, MultDTMC) produce n iterations of a Markov Chain(s)  based on transition probabilities and an initial distribution.  The function FPTime determines the first passage time into each state.  The function statdistr determines the stationary distribution of a Markov Chain.</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-10 16:53:49 UTC; will</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-11 02:12:30 UTC</td>
</tr>
</table>
<hr>
<h2 id='DTMC'>
Simulation of Discrete-Time/State Markov Chain
</h2><span id='topic+DTMC'></span>

<h3>Description</h3>

<p>This function simulates iterations through a discrete time Markov Chain.  A Markov Chain is a discrete Markov Process with a state space that usually consists of positive integers.  The advantage of a Markov process in a stochastic modeling context is that conditional dependencies over time are manageable because the probabilistic future of the process depends only on the present state, not the past.  Therefore, if we specify an initial distribution as well as a transition matrix, we can simulate many periods into the future without any further information.  Future transition probabilities can be computed by raising the transition matrix to higher-and higher powers, but this method is not numerically tractable for large matrices.  My method uses a uniform random variable to iterate a user-specified number of iterations of a Markov Chain based on the transition probabilities and the initital distribution.  A graphical output is also available in the form of a trace plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DTMC(tmat, io, N, trace)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DTMC_+3A_tmat">tmat</code></td>
<td>

<p>Transition matrix-rows must sum to 1 and the number of rows and columns must be equal.
</p>
</td></tr>
<tr><td><code id="DTMC_+3A_io">io</code></td>
<td>

<p>Initial observation, 1 column, must sum to 1, must be the same length as transition matrix.
</p>
</td></tr>
<tr><td><code id="DTMC_+3A_n">N</code></td>
<td>

<p>Number of simulations.
</p>
</td></tr>
<tr><td><code id="DTMC_+3A_trace">trace</code></td>
<td>

<p>Optional trace plot, specify as TRUE or FALSE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Trace</code></td>
<td>
<p>Trace-plot of the iterations through states (if selected)</p>
</td></tr>
<tr><td><code>State</code></td>
<td>
<p>An n x nrow(tmat) matrix detailing the iterations through each state of the Markov Chain</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Will Nicholson
</p>


<h3>References</h3>

<p>&quot;Adventures in Stochastic Processes&quot; by Sidney Resnick</p>


<h3>See Also</h3>

<p><code><a href="#topic+MultDTMC">MultDTMC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gr)
data(id)
DTMC(gr,id,10,trace=TRUE) 
# 10 iterations through "Gambler's ruin"</code></pre>

<hr>
<h2 id='DTMCPack-package'>
Suite of functions related to discrete-time discrete-state Markov Chains
</h2><span id='topic+DTMCPack-package'></span><span id='topic+DTMCPack'></span>

<h3>Description</h3>

<p>A series of functions which aid in both simulating and determining the properties of finite, discrete-time, discrete state markov chains.  This package may be of use to practioners who need to simulate Markov Chains, but its primary intended audience is students of an introductory stochastic processes studying class properties and long run behavior patterns of Markov Chains.   Two functions (DTMC, MultDTMC) produce n iterations of a Markov Chain(s)  based on transition probabilities and an initial distribution.  The function FPTime determines the first passage time into each state.  The function statdistr determines the stationary distribution of a Markov Chain.  Updated 4/10/22 to maintain compatibility with R.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> DTMCPack</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.1-2 </td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2013-05-22</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL(&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Will Nicholson
</p>
<p>Maintainer: &lt;wbn8@cornell.edu&gt;
</p>


<h3>References</h3>

<p>Sidney Resnick, &quot;Adventures in Stochastic Processes&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gr)
data(id)
DTMC(gr,id,10,trace=FALSE) 
</code></pre>

<hr>
<h2 id='FPTime'>
First Passage Time
</h2><span id='topic+FPTime'></span>

<h3>Description</h3>

<p>This function uses the companion function multDTMC to simulate several Markov chains to determine the first passage time into each state, i.e. the first time (after the initial iteration) that a specified state is reached in the Markov Process.  First Passage Time can be useful for both determining class properties as well as the stationary/invariant distribution for large Markov Chains in which explicit matrix inversion is not computationally tractable.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FPTime(state, nchains, tmat, io, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FPTime_+3A_state">state</code></td>
<td>

<p>State in which you want to find the first passage time.
</p>
</td></tr>
<tr><td><code id="FPTime_+3A_nchains">nchains</code></td>
<td>

<p>Number of chains you wish to simulate.
</p>
</td></tr>
<tr><td><code id="FPTime_+3A_tmat">tmat</code></td>
<td>

<p>Transition Matrix, must be a square matrix, rows must sum to 1.
</p>
</td></tr>
<tr><td><code id="FPTime_+3A_io">io</code></td>
<td>

<p>Initial Distribution
</p>
</td></tr>
<tr><td><code id="FPTime_+3A_n">n</code></td>
<td>

<p>Number of iterations to run for each Markov Chain.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>fp1</code></td>
<td>
<p>Vector of length(nchains) which gives first passage time into the specified state for each Markov Chain.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Will Nicholson
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DTMC">DTMC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gr)
data(id)
FPTime(1,10,gr,id,10) # First passage time into first state on Gambler's ruin
</code></pre>

<hr>
<h2 id='gr'>
Example Data Set: Gambler's ruin on 4 states</h2><span id='topic+gr'></span>

<h3>Description</h3>

<p>Motivating example, random walk with absorbing boundaries on 4 states.  Analogous to a gambler at a casino.  The 4 states represent a range of wealth.  States 1 and 4 are absorbing with state 1=&quot;Broke&quot;, state 4=&quot;wealthy enough to walk away&quot; and the intermediate states 2 and 3 are transitory.  It is assumed that he bets of all his winnings in the intermediate states and has equal probability of winning and losing
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gr)
data(id)
DTMC(gr,id,10,trace=FALSE)
</code></pre>

<hr>
<h2 id='hh'>
Harry the SemiPro
</h2><span id='topic+hh'></span>

<h3>Description</h3>

<p>Example Markov Chain from page 139 of Resnick.  The protagonist, basketball player &quot;Happy Harry's&quot; productivity fluctuates between three states (0-1 points), (2-5 points), (5 or more points) and the transition between states can be modeled using a Markov Chain.  Used as a motivating example to calculate the long run proportion of time spent in each state using the statdist function.
</p>


<h3>Source</h3>

<p>Sidney Resnick &quot;Adventures in Stochastic Processes&quot;</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hh)
statdistr(hh)
</code></pre>

<hr>
<h2 id='id'>
Initial distribution
</h2><span id='topic+id'></span>

<h3>Description</h3>

<p>A starting distribution for the gambler's ruin example, which assigns equal probability of starting in each state.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(id)
data(gr)
DTMC(gr,id,10,trace=FALSE)
</code></pre>

<hr>
<h2 id='MultDTMC'>
Multiple Discrete time Markov Chains
</h2><span id='topic+MultDTMC'></span>

<h3>Description</h3>

<p>An extension of the DTMC package which enables multiple cocurrent Markov Chain simulations.  At this time, plotting is not enabled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultDTMC(nchains, tmat, io, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultDTMC_+3A_nchains">nchains</code></td>
<td>

<p>Number of chains to simulate (integer).
</p>
</td></tr>
<tr><td><code id="MultDTMC_+3A_tmat">tmat</code></td>
<td>

<p>Transition Matrix
</p>
</td></tr>
<tr><td><code id="MultDTMC_+3A_io">io</code></td>
<td>

<p>Initial distribution
</p>
</td></tr>
<tr><td><code id="MultDTMC_+3A_n">n</code></td>
<td>

<p>Number of iterations to run each chain.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>chains</code></td>
<td>
<p>Returns nchains matrices of length nrow(tmat) by n which depict the transition of the Markov Chain.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Will Nicholson
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DTMC">DTMC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gr)
data(id)
MultDTMC(20,gr,id,10) # 20 chains with 10 iterations using the Gambler's ruin example.
</code></pre>

<hr>
<h2 id='statdistr'>
Computing Stationary Distribution</h2><span id='topic+statdistr'></span>

<h3>Description</h3>

<p>This function computes the stationary distribution of a markov chain (assuming one exists) using the formula from proposition 2.14.1 of Resnick: pi=(1,...1)(I-P+ONE)^(-1), where I is an mxm identity matrix, P is an mxm transition matrix, and ONE is an mxm matrix whose entries are all 1.  This formula works well if the number of states is small, but since it directly computes the inverse of the matrix, it is not tractable for larger matrices.  For larger matrices 1/E(FPTime(n)) is a rough approximation for the long run proportion of time spent in a state n.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>statdistr(tmat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="statdistr_+3A_tmat">tmat</code></td>
<td>

<p>Markov chain transition matrix, must be a square matrix and rows must sum to 1.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a stationary distribution: mxm matrix which represents the long run percentage of time spent in each state.
</p>


<h3>Author(s)</h3>

<p>Will Nicholson
</p>


<h3>References</h3>

<p>Resnick, &quot;Adventures in Stochastic Processes&quot;</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hh)
statdistr(hh)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
