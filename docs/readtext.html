<!DOCTYPE html><html><head><title>Help for package readtext</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {readtext}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add_docid'><p>Set the docid for multi-document objects</p></a></li>
<li><a href='#as.character.readtext'><p>return only the texts from a readtext object</p></a></li>
<li><a href='#basename_unique'><p>Return basenames that are unique</p></a></li>
<li><a href='#cache_remote'><p>Internal function to cache remote file</p></a></li>
<li><a href='#data_char_encodedtexts'><p>encoded texts for testing</p></a></li>
<li><a href='#data_files_encodedtexts'><p>a .zip file of texts containing a variety of differently encoded texts</p></a></li>
<li><a href='#encoding'><p>detect the encoding of texts</p></a></li>
<li><a href='#get_nexis_html'><p>extract texts and meta data from Nexis HTML files</p></a></li>
<li><a href='#get_temp'><p>Get path to temporary file or directory</p></a></li>
<li><a href='#impute_types'><p>Detect and set variable types automatically</p></a></li>
<li><a href='#print.readtext'><p>print method for a readtext object</p></a></li>
<li><a href='#readtext'><p>read a text file(s)</p></a></li>
<li><a href='#readtext_options'><p>Get or set package options for readtext</p></a></li>
<li><a href='#readtext-package'><p>Import and handling for plain and formatted text files</p></a></li>
<li><a href='#sort_fields'><p>Move text to the first column and set types to document variables</p></a></li>
<li><a href='#texts'><p>Get corpus texts [deprecated]</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.91</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Import and Handling for Plain and Formatted Text Files</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for importing and handling text files and formatted text
    files with additional meta-data, such including '.csv', '.tab', '.json', '.xml',
    '.html', '.pdf', '.doc', '.docx', '.rtf', '.xls', '.xlsx', and others.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>antiword, data.table, digest, httr, jsonlite (&ge; 0.9.10),
pillar, pdftools, readODS (&ge; 1.7.0), readxl, streamR, stringi,
striprtf, xml2, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, pkgload, rmarkdown, quanteda (&ge; 3.0), testthat, covr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/quanteda/readtext">https://github.com/quanteda/readtext</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/quanteda/readtext/issues">https://github.com/quanteda/readtext/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-23 05:01:29 UTC; kbenoit</td>
</tr>
<tr>
<td>Author:</td>
<td>Kenneth Benoit [aut, cre, cph],
  Adam Obeng [aut],
  Kohei Watanabe [ctb],
  Akitaka Matsuo [ctb],
  Paul Nulty [ctb],
  Stefan MÃ¼ller [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kenneth Benoit &lt;kbenoit@lse.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-23 05:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='add_docid'>Set the docid for multi-document objects</h2><span id='topic+add_docid'></span>

<h3>Description</h3>

<p>Set the docid for multi-document objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_docid(x, path, docid_field)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_docid_+3A_x">x</code></td>
<td>
<p>data.frame; contains texts and document variables</p>
</td></tr>
<tr><td><code id="add_docid_+3A_path">path</code></td>
<td>
<p>character; file path from which <code>x</code> is created; only use in error message</p>
</td></tr>
<tr><td><code id="add_docid_+3A_docid_field">docid_field</code></td>
<td>
<p>numeric or character; indicate position of a text column in x</p>
</td></tr>
</table>

<hr>
<h2 id='as.character.readtext'>return only the texts from a readtext object</h2><span id='topic+as.character.readtext'></span>

<h3>Description</h3>

<p>An accessor function to return the texts from a <a href="#topic+readtext">readtext</a> object as a
character vector, with names matching the document names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'readtext'
as.character(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.character.readtext_+3A_x">x</code></td>
<td>
<p>the readtext object whose texts will be extracted</p>
</td></tr>
<tr><td><code id="as.character.readtext_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>

<hr>
<h2 id='basename_unique'>Return basenames that are unique</h2><span id='topic+basename_unique'></span>

<h3>Description</h3>

<p>Return basenames that are unique
</p>


<h3>Usage</h3>

<pre><code class='language-R'>basename_unique(x, path_only = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="basename_unique_+3A_x">x</code></td>
<td>
<p>character vector; file paths</p>
</td></tr>
<tr><td><code id="basename_unique_+3A_path_only">path_only</code></td>
<td>
<p>logical; if <code>TRUE</code>, only return the unique part of the path</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>files &lt;- c("../data/glob/subdir1/test.txt", "../data/glob/subdir2/test.txt")
readtext:::basename_unique(files)
# [1] "subdir1/test.txt" "subdir2/test.txt"
readtext:::basename_unique(files, path_only = TRUE)
# [1] "subdir1" "subdir2"
readtext:::basename_unique(c("../data/test1.txt", "../data/test2.txt"))
# [1] "test1.txt" "test2.txt"
</code></pre>

<hr>
<h2 id='cache_remote'>Internal function to cache remote file</h2><span id='topic+cache_remote'></span>

<h3>Description</h3>

<p>Internal function to cache remote file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cache_remote(url, ignore_missing, cache, basename = NULL, verbosity = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cache_remote_+3A_url">url</code></td>
<td>
<p>location of a remote file</p>
</td></tr>
<tr><td><code id="cache_remote_+3A_ignore_missing">ignore_missing</code></td>
<td>
<p>if <code>TRUE</code>, warns for download status</p>
</td></tr>
<tr><td><code id="cache_remote_+3A_cache">cache</code></td>
<td>
<p><code>TRUE</code>, save file in system's temporary folder and load it
from the next time</p>
</td></tr>
<tr><td><code id="cache_remote_+3A_basename">basename</code></td>
<td>
<p>name of temporary file to preserve file extensions. If
<code>NULL</code>, random string will be used.</p>
</td></tr>
<tr><td><code id="cache_remote_+3A_verbosity">verbosity</code></td>
<td>

<ul>
<li><p> 0: output errors only
</p>
</li>
<li><p> 1: output errors and warnings (default)
</p>
</li>
<li><p> 2: output a brief summary message
</p>
</li>
<li><p> 3: output detailed file-related messages
</p>
</li></ul>
</td></tr>
</table>

<hr>
<h2 id='data_char_encodedtexts'>encoded texts for testing</h2><span id='topic+data_char_encodedtexts'></span>

<h3>Description</h3>

<p><code>data_char_encodedtexts</code> is a 10-element character vector with 10
different encodings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_char_encodedtexts
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 10.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Encoding(data_char_encodedtexts)
data.frame(labelled = names(data_char_encodedtexts), 
           detected = encoding(data_char_encodedtexts)$all)

## End(Not run)
</code></pre>

<hr>
<h2 id='data_files_encodedtexts'>a .zip file of texts containing a variety of differently encoded texts</h2><span id='topic+data_files_encodedtexts'></span>

<h3>Description</h3>

<p>A set of translations of the Universal Declaration of Human
Rights, plus one or two other miscellaneous texts, for testing the text
input functions that need to translate different input encodings.
</p>


<h3>Source</h3>

<p>The Universal Declaration of Human Rights resources,
<a href="https://www.un.org/en/about-us/universal-declaration-of-human-rights">https://www.un.org/en/about-us/universal-declaration-of-human-rights</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: # unzip the files to a temporary directory
FILEDIR &lt;- tempdir()
unzip(system.file("extdata", "data_files_encodedtexts.zip", package = "readtext"), 
      exdir = FILEDIR)

# get encoding from filename
filenames &lt;- list.files(FILEDIR, "\\.txt$")
# strip the extension
filenames &lt;- gsub(".txt$", "", filenames)
parts &lt;- strsplit(filenames, "_")
fileencodings &lt;- sapply(parts, "[", 3)
fileencodings

# find out which conversions are unavailable (through iconv())
cat("Encoding conversions not available for this platform:")
notAvailableIndex &lt;- which(!(fileencodings %in% iconvlist()))
fileencodings[notAvailableIndex]

# try readtext
require(quanteda)
txts &lt;- readtext(paste0(FILEDIR, "/", "*.txt"))
substring(texts(txts)[1], 1, 80) # gibberish
substring(texts(txts)[4], 1, 80) # hex
substring(texts(txts)[40], 1, 80) # hex

# read them in again
txts &lt;- readtext(paste0(FILEDIR,  "/", "*.txt"), encoding = fileencodings)
substring(texts(txts)[1], 1, 80)  # English
substring(texts(txts)[4], 1, 80)  # Arabic, looking good 
substring(texts(txts)[40], 1, 80) # Cyrillic, looking good
substring(texts(txts)[7], 1, 80)  # Chinese, looking good
substring(texts(txts)[26], 1, 80) # Hindi, looking good

txts &lt;- readtext(paste0(FILEDIR, "/", "*.txt"), encoding = fileencodings,
                  docvarsfrom = "filenames", 
                  docvarnames = c("document", "language", "inputEncoding"))
encodingCorpus &lt;- corpus(txts, source = "Created by encoding-tests.R") 
summary(encodingCorpus)

## End(Not run)
</code></pre>

<hr>
<h2 id='encoding'>detect the encoding of texts</h2><span id='topic+encoding'></span>

<h3>Description</h3>

<p>Detect the encoding of texts in a character <a href="#topic+readtext">readtext</a> object and report
on the most likely encoding for each document.  Useful in detecting the
encoding of input texts, so that a source encoding can be (re)specified when
inputting a set of texts using <code><a href="#topic+readtext">readtext()</a></code>, prior to constructing
a corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encoding(x, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encoding_+3A_x">x</code></td>
<td>
<p>character vector, corpus, or readtext object whose texts' encodings
will be detected.</p>
</td></tr>
<tr><td><code id="encoding_+3A_verbose">verbose</code></td>
<td>
<p>if <code>FALSE</code>, do not print diagnostic report</p>
</td></tr>
<tr><td><code id="encoding_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <a href="stringi.html#topic+stri_enc_detect">stri_enc_detect</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on <a href="stringi.html#topic+stri_enc_detect">stri_enc_detect</a>, which is in turn based on the ICU
libraries.  See the ICU User Guide,
<a href="https://unicode-org.github.io/icu/userguide/">https://unicode-org.github.io/icu/userguide/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: encoding(data_char_encodedtexts)
# show detected value for each text, versus known encoding
data.frame(labelled = names(data_char_encodedtexts), 
           detected = encoding(data_char_encodedtexts)$all)

# Russian text, Windows-1251
myreadtext &lt;- readtext("https://kenbenoit.net/files/01_er_5.txt")
encoding(myreadtext)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_nexis_html'>extract texts and meta data from Nexis HTML files</h2><span id='topic+get_nexis_html'></span>

<h3>Description</h3>

<p>This extract headings, body texts and meta data (date, byline, length,
section, edition) from items in HTML files downloaded by the scraper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nexis_html(path, paragraph_separator = "\n\n", verbosity, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_nexis_html_+3A_path">path</code></td>
<td>
<p>either path to a HTML file or a directory that contains HTML
files</p>
</td></tr>
<tr><td><code id="get_nexis_html_+3A_paragraph_separator">paragraph_separator</code></td>
<td>
<p>a character to separate paragraphs in body texts</p>
</td></tr>
<tr><td><code id="get_nexis_html_+3A_verbosity">verbosity</code></td>
<td>

<ul>
<li><p> 0: output errors only
</p>
</li>
<li><p> 1: output errors and warnings (default)
</p>
</li>
<li><p> 2: output a brief summary message
</p>
</li>
<li><p> 3: output detailed file-related messages
</p>
</li></ul>
</td></tr>
<tr><td><code id="get_nexis_html_+3A_...">...</code></td>
<td>
<p>only to trap extra arguments</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
irt &lt;- readtext:::get_nexis_html('tests/data/nexis/irish-times_1995-06-12_0001.html')
afp &lt;- readtext:::get_nexis_html('tests/data/nexis/afp_2013-03-12_0501.html')
gur &lt;- readtext:::get_nexis_html('tests/data/nexis/guardian_1986-01-01_0001.html')
sun &lt;- readtext:::get_nexis_html('tests/data/nexis/sun_2000-11-01_0001.html')
spg &lt;- readtext:::get_nexis_html('tests/data/nexis/spiegel_2012-02-01_0001.html', 
                                  language_date = 'german')

all &lt;- readtext('tests/data/nexis', source = 'nexis')
all &lt;- readtext('tests/data/nexis', source = 'nexis')

## End(Not run)
</code></pre>

<hr>
<h2 id='get_temp'>Get path to temporary file or directory</h2><span id='topic+get_temp'></span>

<h3>Description</h3>

<p>Get path to temporary file or directory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_temp(prefix = "readtext-", temp_dir = NULL, directory = FALSE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_temp_+3A_prefix">prefix</code></td>
<td>
<p>a string appended to random file or directory names.</p>
</td></tr>
<tr><td><code id="get_temp_+3A_temp_dir">temp_dir</code></td>
<td>
<p>a path to temporary directory. If <code>NULL</code>, value from
<code>tempdir()</code> will be used.</p>
</td></tr>
<tr><td><code id="get_temp_+3A_directory">directory</code></td>
<td>
<p>logical; if <code>TRUE</code>, temporary directory will be
created.</p>
</td></tr>
<tr><td><code id="get_temp_+3A_seed">seed</code></td>
<td>
<p>a seed value for <code>digest::digest</code>. If <code>NULL</code>, a random
value will be used.</p>
</td></tr>
</table>

<hr>
<h2 id='impute_types'>Detect and set variable types automatically</h2><span id='topic+impute_types'></span>

<h3>Description</h3>

<p>Detect and set variable types in a similar way as <code>read.csv()</code> does.
Should be used when imported data.frame is all characters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute_types(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_types_+3A_x">x</code></td>
<td>
<p>data.frame; columns are all characters vectors</p>
</td></tr>
</table>

<hr>
<h2 id='print.readtext'>print method for a readtext object</h2><span id='topic+print.readtext'></span>

<h3>Description</h3>

<p>Print a readtext object in a nicely formatted way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'readtext'
print(x, n = 6L, text_width = 10L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.readtext_+3A_x">x</code></td>
<td>
<p>the readtext object to be printed</p>
</td></tr>
<tr><td><code id="print.readtext_+3A_n">n</code></td>
<td>
<p>a single integer, the number of rows of a readtext object to print.</p>
</td></tr>
<tr><td><code id="print.readtext_+3A_text_width">text_width</code></td>
<td>
<p>number of characters to display of the text field</p>
</td></tr>
<tr><td><code id="print.readtext_+3A_...">...</code></td>
<td>
<p>not used here</p>
</td></tr>
</table>

<hr>
<h2 id='readtext'>read a text file(s)</h2><span id='topic+readtext'></span>

<h3>Description</h3>

<p>Read texts and (if any) associated document-level meta-data from one or more source files.
The text source files
come from the textual component of the files, and the document-level
metadata (&quot;docvars&quot;) come from either the file contents or filenames.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readtext(
  file,
  ignore_missing_files = FALSE,
  text_field = NULL,
  docid_field = NULL,
  docvarsfrom = c("metadata", "filenames", "filepaths"),
  dvsep = "_",
  docvarnames = NULL,
  encoding = NULL,
  source = NULL,
  cache = TRUE,
  verbosity = readtext_options("verbosity"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readtext_+3A_file">file</code></td>
<td>
<p>the complete filename(s) to be read. This is designed to
automagically handle a number of common scenarios, so the value can be a
&quot;glob&quot;-type wildcard value.  Currently available filetypes are:
</p>
<p><strong>Single file formats:</strong>
</p>

<dl>
<dt><code>txt</code></dt><dd><p>plain text files:
So-called structured text files, which describe both texts and metadata:
For all structured text filetypes, the column, field, or node
which contains the the text must be specified with the <code>text_field</code>
parameter, and all other fields are treated as docvars.</p>
</dd>
<dt><code>json</code></dt><dd><p>data in some form of JavaScript
Object Notation, consisting of the texts and optionally additional docvars.
The supported formats are:
</p>

<ul>
<li><p> a single JSON object per file
</p>
</li>
<li><p> line-delimited JSON, with one object per line
</p>
</li>
<li><p> line-delimited JSON, of the format produced from a Twitter stream.
This type of file has special handling which simplifies the Twitter format
into docvars.  The correct format for each JSON file is automatically detected.</p>
</li></ul>
</dd>
<dt><code style="white-space: pre;">&#8288;csv,tab,tsv&#8288;</code></dt><dd><p>comma- or tab-separated values</p>
</dd>
<dt><code>html</code></dt><dd><p>HTML documents, including specialized formats from known
sources, such as Nexis-formatted HTML.  See the <code>source</code> parameter
below.</p>
</dd>
<dt><code>xml</code></dt><dd><p>XML documents are supported &ndash; those of the
kind that can be read by <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code> and navigated through
<code><a href="xml2.html#topic+xml_find_all">xml2::xml_find_all()</a></code>. For xml files, an additional
argument <code>collapse</code> may be passed through <code>...</code> that names the character(s) to use in
appending different text elements together.</p>
</dd>
<dt><code>pdf</code></dt><dd><p>pdf formatted files, converted through <span class="pkg">pdftools</span>.</p>
</dd>
<dt><code>odt</code></dt><dd><p>Open Document Text formatted files.</p>
</dd>
<dt><code style="white-space: pre;">&#8288;doc, docx&#8288;</code></dt><dd><p>Microsoft Word formatted files.</p>
</dd>
<dt><code>rtf</code></dt><dd><p>Rich Text Files.</p>
</dd>
</dl>
<p><strong>Reading multiple files and file types:</strong>
</p>
<p>In addition, <code>file</code> can also not be a path
to a single local file, but also combinations of any of the above types, such as:
</p>
<dl>
<dt>a wildcard value</dt><dd><p>any valid
pathname with a wildcard (&quot;glob&quot;) expression that can be expanded by the
operating system.  This may consist of multiple file types.</p>
</dd>
<dt>a URL to a remote</dt><dd><p>which is downloaded then loaded</p>
</dd>
<dt><code style="white-space: pre;">&#8288;zip,tar,tar.gz,tar.bz&#8288;</code></dt><dd><p>archive file, which is unzipped. The
contained files must be either at the top level or in a single directory.
Archives, remote URLs and glob patterns can resolve to any of the other
filetypes, so you could have, for example, a remote URL to a zip file which
contained Twitter JSON files.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="readtext_+3A_ignore_missing_files">ignore_missing_files</code></td>
<td>
<p>if <code>FALSE</code>, then if the file
argument doesn't resolve to an existing file, then an error will be thrown.
Note that this can happen in a number of ways, including passing a path
to a file that does not exist, to an empty archive file, or to a glob
pattern that matches no files.</p>
</td></tr>
<tr><td><code id="readtext_+3A_text_field">text_field</code>, <code id="readtext_+3A_docid_field">docid_field</code></td>
<td>
<p>a variable (column) name or column number
indicating where to find the texts that form the documents for the corpus
and their identifiers.  This must be specified for file types <code>.csv</code>,
<code>.json</code>, and <code>.xls</code>/<code>.xlsx</code> files.  For XML files, an XPath
expression can be specified.</p>
</td></tr>
<tr><td><code id="readtext_+3A_docvarsfrom">docvarsfrom</code></td>
<td>
<p>used to specify that docvars should be taken from the
filenames, when the <code>readtext</code> inputs are filenames and the elements
of the filenames are document variables, separated by a delimiter
(<code>dvsep</code>).  This allows easy assignment of docvars from filenames such
as <code>1789-Washington.txt</code>, <code>1793-Washington</code>, etc. by <code>dvsep</code>
or from meta-data embedded in the text file header (<code>headers</code>).
If <code>docvarsfrom</code> is set to <code>"filepaths"</code>, consider the full path to the
file, not just the filename.</p>
</td></tr>
<tr><td><code id="readtext_+3A_dvsep">dvsep</code></td>
<td>
<p>separator (a regular expression character string) used in
filenames to delimit docvar elements if  <code>docvarsfrom="filenames"</code>
or <code>docvarsfrom="filepaths"</code> is used</p>
</td></tr>
<tr><td><code id="readtext_+3A_docvarnames">docvarnames</code></td>
<td>
<p>character vector of variable names for <code>docvars</code>, if
<code>docvarsfrom</code> is specified.  If this argument is not used, default
docvar names will be used (<code>docvar1</code>, <code>docvar2</code>, ...).</p>
</td></tr>
<tr><td><code id="readtext_+3A_encoding">encoding</code></td>
<td>
<p>vector: either the encoding of all files, or one encoding
for each files</p>
</td></tr>
<tr><td><code id="readtext_+3A_source">source</code></td>
<td>
<p>used to specify specific formats of some input file types, such
as JSON or HTML. Currently supported types are <code>"twitter"</code> for JSON and
<code>"nexis"</code> for HTML.</p>
</td></tr>
<tr><td><code id="readtext_+3A_cache">cache</code></td>
<td>
<p>if <code>TRUE</code>, save remote file to a temporary folder. Only used
when <code>file</code> is a URL.</p>
</td></tr>
<tr><td><code id="readtext_+3A_verbosity">verbosity</code></td>
<td>

<ul>
<li><p> 0: output errors only
</p>
</li>
<li><p> 1: output errors and warnings (default)
</p>
</li>
<li><p> 2: output a brief summary message
</p>
</li>
<li><p> 3: output detailed file-related messages
</p>
</li></ul>
</td></tr>
<tr><td><code id="readtext_+3A_...">...</code></td>
<td>
<p>additional arguments passed through to low-level file reading
function, such as <code><a href="base.html#topic+file">file()</a></code>, <code><a href="data.table.html#topic+fread">fread()</a></code>, etc.  Useful
for specifying an input encoding option, which is specified in the same was
as it would be give to <code><a href="base.html#topic+iconv">iconv()</a></code>.  See the Encoding section of
<a href="base.html#topic+file">file</a> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame consisting of a columns <code>doc_id</code> and <code>text</code>
that contain a document identifier and the texts respectively, with any
additional columns consisting of document-level variables either found
in the file containing the texts, or created through the
<code>readtext</code> call.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## get the data directory
if (!interactive()) pkgload::load_all()
DATA_DIR &lt;- system.file("extdata/", package = "readtext")

## read in some text data
# all UDHR files
(rt1 &lt;- readtext(paste0(DATA_DIR, "/txt/UDHR/*")))

# manifestos with docvars from filenames
(rt2 &lt;- readtext(paste0(DATA_DIR, "/txt/EU_manifestos/*.txt"),
                 docvarsfrom = "filenames", 
                 docvarnames = c("unit", "context", "year", "language", "party"),
                 encoding = "LATIN1"))
                 
# recurse through subdirectories
(rt3 &lt;- readtext(paste0(DATA_DIR, "/txt/movie_reviews/*"), 
                 docvarsfrom = "filepaths", docvarnames = "sentiment"))

## read in csv data
(rt4 &lt;- readtext(paste0(DATA_DIR, "/csv/inaugCorpus.csv")))

## read in tab-separated data
(rt5 &lt;- readtext(paste0(DATA_DIR, "/tsv/dailsample.tsv"), text_field = "speech"))

## read in JSON data
(rt6 &lt;- readtext(paste0(DATA_DIR, "/json/inaugural_sample.json"), text_field = "texts"))

## read in pdf data
# UNHDR
(rt7 &lt;- readtext(paste0(DATA_DIR, "/pdf/UDHR/*.pdf"), 
                 docvarsfrom = "filenames", 
                 docvarnames = c("document", "language")))
Encoding(rt7$text)

## read in Word data (.doc)
(rt8 &lt;- readtext(paste0(DATA_DIR, "/word/*.doc")))
Encoding(rt8$text)

## read in Word data (.docx)
(rt9 &lt;- readtext(paste0(DATA_DIR, "/word/*.docx")))
Encoding(rt9$text)

## use elements of path and filename as docvars
(rt10 &lt;- readtext(paste0(DATA_DIR, "/pdf/UDHR/*.pdf"), 
                  docvarsfrom = "filepaths", dvsep = "[/_.]"))

## End(Not run)
</code></pre>

<hr>
<h2 id='readtext_options'>Get or set package options for readtext</h2><span id='topic+readtext_options'></span>

<h3>Description</h3>

<p>Get or set global options affecting functions across <span class="pkg">readtext</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readtext_options(..., reset = FALSE, initialize = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readtext_options_+3A_...">...</code></td>
<td>
<p>options to be set, as key-value pair, same as
<code><a href="base.html#topic+options">options()</a></code>. This may be a list of valid key-value pairs, useful
for setting a group of options at once (see examples).</p>
</td></tr>
<tr><td><code id="readtext_options_+3A_reset">reset</code></td>
<td>
<p>logical; if <code>TRUE</code>, reset all <span class="pkg">readtext</span> options to
their default values</p>
</td></tr>
<tr><td><code id="readtext_options_+3A_initialize">initialize</code></td>
<td>
<p>logical; if <code>TRUE</code>, reset only the <span class="pkg">readtext</span>
options that are not already defined.  Used for setting initial values when
some have been defined previously, such as in <code>.Rprofile</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently available options are: </p>

<dl>
<dt><code>verbosity</code></dt><dd><p>Default
verbosity for messages produced when reading files.  See
<code><a href="#topic+readtext">readtext()</a></code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>When called using a <code>key = value</code> pair (where <code>key</code> can be
a label or quoted character name)), the option is set and <code>TRUE</code> is
returned invisibly.
</p>
<p>When called with no arguments, a named list of the package options is
returned.
</p>
<p>When called with <code>reset = TRUE</code> as an argument, all arguments are
options are reset to their default values, and <code>TRUE</code> is returned
invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# save the current options
(opt &lt;- readtext_options())

# set higher verbosity
readtext_options(verbosity = 3)

# read something in here
if (!interactive()) pkgload::load_all()
DATA_DIR &lt;- system.file("extdata/", package = "readtext")
readtext(paste0(DATA_DIR, "/txt/UDHR/*"))

# reset to saved options
readtext_options(opt)

## End(Not run)
</code></pre>

<hr>
<h2 id='readtext-package'>Import and handling for plain and formatted text files</h2><span id='topic+readtext-package'></span>

<h3>Description</h3>

<p>A set of functions for  importing and handling text files and formatted text
files with additional meta-data, such including .csv, .tab, .json, .xml, .xls,
.xlsx, and others.
</p>


<h3>Details</h3>

<p><span class="pkg">readtext</span> makes it easy to import text files in various formats,
including using operating system filemasks to load in groups of files based
on glob pattern matches, including files in multiple directories or
sub-directories. <span class="pkg">readtext</span> can also read multiple files into R from
compressed archive files such as .gz, .zip, .tar.gz, etc.  Finally
<span class="pkg">readtext</span> reads in the document-level meta-data associated with texts,
if those texts are in a format (e.g. .csv, .json) that includes additional,
non-textual data.
</p>


<h3>Package options</h3>

 <dl>
<dt><code>readtext_verbosity</code></dt><dd><p>Default
verbosity for messages produced when reading files.  See
<code><a href="#topic+readtext">readtext()</a></code>.</p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Ken Benoit, Adam Obeng, and Paul Nulty
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/quanteda/readtext">https://github.com/quanteda/readtext</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/quanteda/readtext/issues">https://github.com/quanteda/readtext/issues</a>
</p>
</li></ul>


<hr>
<h2 id='sort_fields'>Move text to the first column and set types to document variables</h2><span id='topic+sort_fields'></span>

<h3>Description</h3>

<p>Move text to the first column and set types to document variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort_fields(x, path, text_field, impute_types = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort_fields_+3A_x">x</code></td>
<td>
<p>data.frame; contains texts and document variables</p>
</td></tr>
<tr><td><code id="sort_fields_+3A_path">path</code></td>
<td>
<p>character; file path from which <code>x</code> is created; only use in error message</p>
</td></tr>
<tr><td><code id="sort_fields_+3A_text_field">text_field</code></td>
<td>
<p>numeric or character; indicate position of a text column in x</p>
</td></tr>
<tr><td><code id="sort_fields_+3A_impute_types">impute_types</code></td>
<td>
<p>logical; if <code>TRUE</code>, set types of variables automatically</p>
</td></tr>
</table>

<hr>
<h2 id='texts'>Get corpus texts [deprecated]</h2><span id='topic+texts'></span><span id='topic+texts.readtext'></span>

<h3>Description</h3>

<p>Get the texts from a <a href="#topic+readtext">readtext</a> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>texts(x, ...)

## S3 method for class 'readtext'
texts(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="texts_+3A_x">x</code></td>
<td>
<p>a <a href="#topic+readtext">readtext</a> object</p>
</td></tr>
<tr><td><code id="texts_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is <strong>deprecated</strong>.
</p>
<p>Use <code><a href="#topic+as.character.readtext">as.character.readtext()</a></code> to turn a readtext object into a simple named
character vector of documents.
</p>


<h3>Value</h3>

<p>a character vector of the texts in the corpus
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
