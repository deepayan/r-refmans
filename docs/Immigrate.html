<!DOCTYPE html><html lang="en"><head><title>Help for package Immigrate</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Immigrate}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BIM'><p>BIM</p></a></li>
<li><a href='#IM4E'><p>IM4E</p></a></li>
<li><a href='#Immigrate'><p>Immigrate</p></a></li>
<li><a href='#LFE'><p>LFE</p></a></li>
<li><a href='#one.IM4E'><p>one.IM4E</p></a></li>
<li><a href='#one.Immigrate'><p>one.Immigrate</p></a></li>
<li><a href='#park'><p>Parkinsons Dataset</p></a></li>
<li><a href='#pred.values'><p>pred.values</p></a></li>
<li><a href='#predict.BIM'><p>predict.BIM</p></a></li>
<li><a href='#predict.IM4E'><p>predict.IM4E</p></a></li>
<li><a href='#predict.Immigrate'><p>predict.Immigrate</p></a></li>
<li><a href='#predict.LFE'><p>predict.LFE</p></a></li>
<li><a href='#Simba'><p>Simba</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Iterative Max-Min Entropy Margin-Maximization with Interaction
Terms for Feature Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Ruzhang Zhao, Pengyu Hong, Jun S. Liu</td>
</tr>
<tr>
<td>Description:</td>
<td>Based on large margin principle, this package performs feature selection methods: "IM4E"(Iterative Margin-Maximization under Max-Min Entropy Algorithm); "Immigrate"(Iterative Max-Min Entropy Margin-Maximization with Interaction Terms Algorithm); "BIM"(Boosted version of IMMIGRATE algorithm); "Simba"(Iterative Search Margin Based Algorithm); "LFE"(Local Feature Extraction Algorithm). This package also performs prediction for the above feature selection methods.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ruzhang Zhao&lt;ruzhangzhao@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://cran.r-project.org/package=Immigrate">https://cran.r-project.org/package=Immigrate</a>,
<a href="https://arxiv.org/abs/1810.02658">https://arxiv.org/abs/1810.02658</a>,
<a href="https://github.com/RuzhangZhao/Immigrate/">https://github.com/RuzhangZhao/Immigrate/</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0.9000</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, pROC, stats</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-05-22 18:06:48 UTC; zhaoruzhang</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-05-22 22:42:22 UTC</td>
</tr>
</table>
<hr>
<h2 id='BIM'>BIM</h2><span id='topic+BIM'></span>

<h3>Description</h3>

<p>This function performs BIM algorithm (Boosted version of IMMIGRATE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BIM(
  xx,
  yy,
  nBoost = 3,
  max_iter = 5,
  removesmall = FALSE,
  sigstart = 0.02,
  sigend = 4
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BIM_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="BIM_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="BIM_+3A_nboost">nBoost</code></td>
<td>
<p>number of classifiers in BIM, default to be 3</p>
</td></tr>
<tr><td><code id="BIM_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iteration for IMMIRGATE classifier, default to be 5</p>
</td></tr>
<tr><td><code id="BIM_+3A_removesmall">removesmall</code></td>
<td>
<p>whether remove features with small weights, default to be FALSE</p>
</td></tr>
<tr><td><code id="BIM_+3A_sigstart">sigstart</code></td>
<td>
<p>start of sigma used in algorithm, default to be 0.02</p>
</td></tr>
<tr><td><code id="BIM_+3A_sigend">sigend</code></td>
<td>
<p>end of sigma used in algorithm, default to be 4</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>matrix</code></td>
<td>
<p>list of weight matrices</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>coefficient vectors for classifiers</p>
</td></tr>
<tr><td><code>sample_wt</code></td>
<td>
<p>sample weights, refer to cost function in link below for more details</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhao, Ruzhang, Pengyu Hong, and Jun S. Liu. &quot;IMMIGRATE: A Margin-based Feature Selection Method with Interaction Terms.&quot; Entropy 22.3 (2020): 291.
</p>


<h3>See Also</h3>

<p>Please refer to <a href="https://www.mdpi.com/1099-4300/22/3/291/htm">https://www.mdpi.com/1099-4300/22/3/291/htm</a> for more details.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
re&lt;-BIM(xx,yy)
</code></pre>

<hr>
<h2 id='IM4E'>IM4E</h2><span id='topic+IM4E'></span>

<h3>Description</h3>

<p>This function performs IM4E(Iterative Margin-Maximization under Max-Min Entropy) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IM4E(
  xx,
  yy,
  epsilon = 0.01,
  sig = 1,
  lambda = 1,
  max_iter = 10,
  removesmall = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IM4E_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="IM4E_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="IM4E_+3A_epsilon">epsilon</code></td>
<td>
<p>criterion for stopping iteration, default to be 0.01</p>
</td></tr>
<tr><td><code id="IM4E_+3A_sig">sig</code></td>
<td>
<p>sigma used in algorithm, default to be 1</p>
</td></tr>
<tr><td><code id="IM4E_+3A_lambda">lambda</code></td>
<td>
<p>lambda used in algorithm, default to be 1</p>
</td></tr>
<tr><td><code id="IM4E_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iteration</p>
</td></tr>
<tr><td><code id="IM4E_+3A_removesmall">removesmall</code></td>
<td>
<p>whether remove features with small weights, default to be FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>w</code></td>
<td>
<p>weight vector obtained by IM4E algorithm</p>
</td></tr>
<tr><td><code>iter_num</code></td>
<td>
<p>number of iteration for convergence</p>
</td></tr>
<tr><td><code>final_c</code></td>
<td>
<p>final cost value. Refer to the cost function in reference below for more details</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bei Y, Hong P. Maximizing margin quality and quantity[C]//Machine Learning for Signal Processing (MLSP), 2015 IEEE 25th International Workshop on. IEEE, 2015: 1-6.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
re&lt;-IM4E(xx,yy)
print(re)
</code></pre>

<hr>
<h2 id='Immigrate'>Immigrate</h2><span id='topic+Immigrate'></span>

<h3>Description</h3>

<p>This function performs IMMIGRATE(Iterative Max-Min Entropy Margin-Maximization with Interaction Terms ) algorithm.
IMMIGRATE is a hypothesis-margin based feature selection method with interaction terms.
Its weight matrix reflects the relative importance of features and their iteractions, which can be used for feature selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Immigrate(
  xx,
  yy,
  w0,
  epsilon = 0.01,
  sig = 1,
  max_iter = 10,
  removesmall = FALSE,
  randomw0 = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Immigrate_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="Immigrate_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="Immigrate_+3A_w0">w0</code></td>
<td>
<p>initial weight matrix, default to be diagonal matrix when missing</p>
</td></tr>
<tr><td><code id="Immigrate_+3A_epsilon">epsilon</code></td>
<td>
<p>criterion for stopping iteration</p>
</td></tr>
<tr><td><code id="Immigrate_+3A_sig">sig</code></td>
<td>
<p>sigma used in algorithm, default to be 1. Refer to the cost function in the link below for more details</p>
</td></tr>
<tr><td><code id="Immigrate_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iteration</p>
</td></tr>
<tr><td><code id="Immigrate_+3A_removesmall">removesmall</code></td>
<td>
<p>whether to remove features with small weights, default to be FALSE</p>
</td></tr>
<tr><td><code id="Immigrate_+3A_randomw0">randomw0</code></td>
<td>
<p>whether to use randomly initial weights, default to be FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>w</code></td>
<td>
<p>weight matrix obtained by IMMIGRATE algorithm</p>
</td></tr>
<tr><td><code>iter_num</code></td>
<td>
<p>number of iteration for convergence</p>
</td></tr>
<tr><td><code>final_c</code></td>
<td>
<p>final cost value. Refer to the cost function in link below for more details</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhao, Ruzhang, Pengyu Hong, and Jun S. Liu. &quot;IMMIGRATE: A Margin-based Feature Selection Method with Interaction Terms.&quot; Entropy 22.3 (2020): 291.
</p>


<h3>See Also</h3>

<p>Please refer to <a href="https://www.mdpi.com/1099-4300/22/3/291/htm">https://www.mdpi.com/1099-4300/22/3/291/htm</a> for more details.
</p>
<p>Please refer to <a href="https://github.com/RuzhangZhao/Immigrate/">https://github.com/RuzhangZhao/Immigrate/</a> for implementation demo.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
re&lt;-Immigrate(xx,yy)
print(re)
</code></pre>

<hr>
<h2 id='LFE'>LFE</h2><span id='topic+LFE'></span>

<h3>Description</h3>

<p>This function performs LFE(Local Feature Extraction) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LFE(xx, yy, T = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LFE_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="LFE_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="LFE_+3A_t">T</code></td>
<td>
<p>number of instance used to update weights, default to be 5</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>w</code></td>
<td>
<p>new weight matrix after LFE algorithm</p>
</td></tr>
</table>


<h3>References</h3>

<p>Sun Y, Wu D. A relief based feature extraction algorithm[C]//Proceedings of the 2008 SIAM International Conference on Data Mining. Society for Industrial and Applied Mathematics, 2008: 188-195.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
re&lt;-LFE(xx,yy)
print(re)
</code></pre>

<hr>
<h2 id='one.IM4E'>one.IM4E</h2><span id='topic+one.IM4E'></span>

<h3>Description</h3>

<p>This function performs (IM4E)Iterative Margin-Maximization under Max-Min Entropy algorithm for one loop.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>one.IM4E(train_xx, train_yy, w, sig = 1, lambda = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="one.IM4E_+3A_train_xx">train_xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="one.IM4E_+3A_train_yy">train_yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="one.IM4E_+3A_w">w</code></td>
<td>
<p>initial weight</p>
</td></tr>
<tr><td><code id="one.IM4E_+3A_sig">sig</code></td>
<td>
<p>sigma used in algorithm, default to be 1</p>
</td></tr>
<tr><td><code id="one.IM4E_+3A_lambda">lambda</code></td>
<td>
<p>lambda used in algorithm, default to be 1</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>w</code></td>
<td>
<p>new weight vector after one loop</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>cost after one loop</p>
</td></tr>
</table>

<hr>
<h2 id='one.Immigrate'>one.Immigrate</h2><span id='topic+one.Immigrate'></span>

<h3>Description</h3>

<p>This function performs Immigrate(Iterative Max-Min Entropy Margin-Maximization with Interaction Terms) algorithm for one loop.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>one.Immigrate(train_xx, train_yy, W, sig = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="one.Immigrate_+3A_train_xx">train_xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="one.Immigrate_+3A_train_yy">train_yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="one.Immigrate_+3A_w">W</code></td>
<td>
<p>initial weight matrix</p>
</td></tr>
<tr><td><code id="one.Immigrate_+3A_sig">sig</code></td>
<td>
<p>sigma used in algorithm, default to be 1</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>W</code></td>
<td>
<p>new weight matrix after one loop</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>cost after one loop</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Please refer to <a href="https://github.com/RuzhangZhao/Immigrate/">https://github.com/RuzhangZhao/Immigrate/</a> for implementation demo.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
W0 &lt;- diag(rep(1,ncol(xx)),ncol(xx))/sqrt(ncol(xx))
re&lt;-one.Immigrate(xx,yy,W0)
print(re$w)
</code></pre>

<hr>
<h2 id='park'>Parkinsons Dataset</h2><span id='topic+park'></span>

<h3>Description</h3>

<p>Parkinsons Dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(park)
</code></pre>


<h3>Format</h3>

<p>An object of class
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/parkinsons">parkinsons</a>
</p>


<h3>References</h3>

<p>Frank, A. and A. Asuncion. UCI Machine Learning Repository. 2010.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx &lt;- park$xx
yy &lt;- park$yy

</code></pre>

<hr>
<h2 id='pred.values'>pred.values</h2><span id='topic+pred.values'></span>

<h3>Description</h3>

<p>This function performs some statistical value prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pred.values(y_train, y_test, pred_train, pred_test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pred.values_+3A_y_train">y_train</code></td>
<td>
<p>label vector for training data</p>
</td></tr>
<tr><td><code id="pred.values_+3A_y_test">y_test</code></td>
<td>
<p>label vector for test data</p>
</td></tr>
<tr><td><code id="pred.values_+3A_pred_train">pred_train</code></td>
<td>
<p>predicted probabilities for training data</p>
</td></tr>
<tr><td><code id="pred.values_+3A_pred_test">pred_test</code></td>
<td>
<p>predicted probabilities for test data</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>AUC_train</code></td>
<td>
<p>AUC for training data</p>
</td></tr>
<tr><td><code>AUC_test</code></td>
<td>
<p> AUC for test data</p>
</td></tr>
<tr><td><code>accuracy_test</code></td>
<td>
<p> accuracy for test data</p>
</td></tr>
<tr><td><code>precision_test</code></td>
<td>
<p> precision for test data</p>
</td></tr>
<tr><td><code>recall_test</code></td>
<td>
<p> recall for test data</p>
</td></tr>
<tr><td><code>F1_test</code></td>
<td>
<p> F1 score for test data</p>
</td></tr>
<tr><td><code>thre</code></td>
<td>
<p> threshold to separate two labels, obtained from training data</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>y_train&lt;-c(0,1,0,1,0,1)
y_test&lt;-c(0,1,0,1)
pred_train&lt;-c(0.77,0.89,0.32,0.96,0.10,0.67)
pred_test&lt;-c(0.68,0.75,0.50,0.81)
re&lt;-pred.values(y_train,y_test,pred_train,pred_test)
print(re)

</code></pre>

<hr>
<h2 id='predict.BIM'>predict.BIM</h2><span id='topic+predict.BIM'></span>

<h3>Description</h3>

<p>This function performs the predition for BIM algorithm (Boosted version of IMMIGRATE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BIM'
predict(object, xx, yy, newx, type = "both", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.BIM_+3A_object">object</code></td>
<td>
<p>result of BIM algorithm</p>
</td></tr>
<tr><td><code id="predict.BIM_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="predict.BIM_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="predict.BIM_+3A_newx">newx</code></td>
<td>
<p>new model matrix to be predicted</p>
</td></tr>
<tr><td><code id="predict.BIM_+3A_type">type</code></td>
<td>
<p>the form of final output</p>
</td></tr>
<tr><td><code id="predict.BIM_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>response</code></td>
<td>
<p>predicted probabilities for for new data (newx)</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>predicted class for for new data (newx)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhao, Ruzhang, Pengyu Hong, and Jun S. Liu. &quot;IMMIGRATE: A Margin-based Feature Selection Method with Interaction Terms.&quot; Entropy 22.3 (2020): 291.
</p>


<h3>See Also</h3>

<p>Please refer to <a href="https://www.mdpi.com/1099-4300/22/3/291/htm">https://www.mdpi.com/1099-4300/22/3/291/htm</a> for more details.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
index&lt;-c(1:floor(nrow(xx)*0.3))
train_xx&lt;-xx[-index,]
test_xx&lt;-xx[index,]
train_yy&lt;-yy[-index]
test_yy&lt;-yy[index]
re&lt;-BIM(train_xx,train_yy)
res&lt;-predict(re,train_xx,train_yy,test_xx,type="class")
print(res)
</code></pre>

<hr>
<h2 id='predict.IM4E'>predict.IM4E</h2><span id='topic+predict.IM4E'></span>

<h3>Description</h3>

<p>This function performs the predition for IM4E(Iterative Margin-Maximization under Max-Min Entropy) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'IM4E'
predict(object, xx, yy, newx, sig = 1, type = "both", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.IM4E_+3A_object">object</code></td>
<td>
<p>weight or result of IM4E algorithm</p>
</td></tr>
<tr><td><code id="predict.IM4E_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="predict.IM4E_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="predict.IM4E_+3A_newx">newx</code></td>
<td>
<p>new model matrix to be predicted</p>
</td></tr>
<tr><td><code id="predict.IM4E_+3A_sig">sig</code></td>
<td>
<p>sigma used in algorithm, default to be 1</p>
</td></tr>
<tr><td><code id="predict.IM4E_+3A_type">type</code></td>
<td>
<p>the form of final output, default to be &quot;both&quot;. One can also choose &quot;response&quot;(predicted probabilities) or &quot;class&quot;(predicted labels).</p>
</td></tr>
<tr><td><code id="predict.IM4E_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>response</code></td>
<td>
<p>predicted probabilities for new data (newx)</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>predicted class labels for new data (newx)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bei Y, Hong P. Maximizing margin quality and quantity[C]//Machine Learning for Signal Processing (MLSP), 2015 IEEE 25th International Workshop on. IEEE, 2015: 1-6.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
index&lt;-c(1:floor(nrow(xx)*0.3))
train_xx&lt;-xx[-index,]
test_xx&lt;-xx[index,]
train_yy&lt;-yy[-index]
test_yy&lt;-yy[index]
re&lt;-IM4E(train_xx,train_yy)
res&lt;-predict(re,train_xx,train_yy,test_xx,type="class")
print(res)
</code></pre>

<hr>
<h2 id='predict.Immigrate'>predict.Immigrate</h2><span id='topic+predict.Immigrate'></span>

<h3>Description</h3>

<p>This function performs the predition for Immigrate(Iterative Max-Min Entropy Margin-Maximization with Interaction Terms) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Immigrate'
predict(object, xx, yy, newx, sig = 1, type = "both", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.Immigrate_+3A_object">object</code></td>
<td>
<p>result of Immigrate algorithm</p>
</td></tr>
<tr><td><code id="predict.Immigrate_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="predict.Immigrate_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="predict.Immigrate_+3A_newx">newx</code></td>
<td>
<p>new model matrix to be predicted</p>
</td></tr>
<tr><td><code id="predict.Immigrate_+3A_sig">sig</code></td>
<td>
<p>sigma used in prediction function, default to be 1. Refer to the prediction function in the link below for more details</p>
</td></tr>
<tr><td><code id="predict.Immigrate_+3A_type">type</code></td>
<td>
<p>the form of final output, default to be &quot;both&quot;. One can also choose &quot;response&quot;(predicted probabilities) or &quot;class&quot;(predicted labels).</p>
</td></tr>
<tr><td><code id="predict.Immigrate_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>response</code></td>
<td>
<p>predicted probabilities for new data (newx)</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>predicted class labels for new data (newx)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zhao, Ruzhang, Pengyu Hong, and Jun S. Liu. &quot;IMMIGRATE: A Margin-based Feature Selection Method with Interaction Terms.&quot; Entropy 22.3 (2020): 291.
</p>


<h3>See Also</h3>

<p>Please refer to <a href="https://www.mdpi.com/1099-4300/22/3/291/htm">https://www.mdpi.com/1099-4300/22/3/291/htm</a> for more details.
</p>
<p>Please refer to <a href="https://github.com/RuzhangZhao/Immigrate/">https://github.com/RuzhangZhao/Immigrate/</a> for implementation demo.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
index&lt;-c(1:floor(nrow(xx)*0.3))
train_xx&lt;-xx[-index,]
test_xx&lt;-xx[index,]
train_yy&lt;-yy[-index]
test_yy&lt;-yy[index]
re&lt;-Immigrate(train_xx,train_yy)
res&lt;-predict(re,train_xx,train_yy,test_xx,type="class")
print(res)
</code></pre>

<hr>
<h2 id='predict.LFE'>predict.LFE</h2><span id='topic+predict.LFE'></span>

<h3>Description</h3>

<p>This function performs predition for LFE(Local Feature Extraction) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LFE'
predict(object, xx, yy, newx, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.LFE_+3A_object">object</code></td>
<td>
<p>weights obtained from LFE</p>
</td></tr>
<tr><td><code id="predict.LFE_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="predict.LFE_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="predict.LFE_+3A_newx">newx</code></td>
<td>
<p>new model matrix to be predicted</p>
</td></tr>
<tr><td><code id="predict.LFE_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted labels for new data (newx)
</p>


<h3>References</h3>

<p>Sun Y, Wu D. A relief based feature extraction algorithm[C]//Proceedings of the 2008 SIAM International Conference on Data Mining. Society for Industrial and Applied Mathematics, 2008: 188-195.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
w&lt;-LFE(xx,yy)
pred&lt;-predict(w,xx,yy,xx)
print(pred)
</code></pre>

<hr>
<h2 id='Simba'>Simba</h2><span id='topic+Simba'></span>

<h3>Description</h3>

<p>This function performs Simba(Iterative Search Margin Based Algorithm).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Simba(xx, yy, T = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Simba_+3A_xx">xx</code></td>
<td>
<p>model matrix of explanatory variables</p>
</td></tr>
<tr><td><code id="Simba_+3A_yy">yy</code></td>
<td>
<p>label vector</p>
</td></tr>
<tr><td><code id="Simba_+3A_t">T</code></td>
<td>
<p>number of instance used to update weights, default to be 5</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>w</code></td>
<td>
<p>new weight after Simba algorithm</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gilad-Bachrach R, Navot A, Tishby N. Margin based feature selection-theory and algorithms[C]//Proceedings of the twenty-first international conference on Machine learning. ACM, 2004: 43.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(park)
xx&lt;-park$xx
yy&lt;-park$yy
re&lt;-Simba(xx,yy)
print(re)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
