<!DOCTYPE html><html lang="en"><head><title>Help for package survPen</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {survPen}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#+25cross+25'><p>Matrix cross-multiplication between two matrices</p></a></li>
<li><a href='#+25mult+25'><p>Matrix multiplication between two matrices</p></a></li>
<li><a href='#+25vec+25'><p>Matrix multiplication between a matrix and a vector</p></a></li>
<li><a href='#colSums2'><p>colSums of a matrix</p></a></li>
<li><a href='#constraint'><p>Sum-to-zero constraint</p></a></li>
<li><a href='#cor.var'><p>Implementation of the corrected variance Vc</p></a></li>
<li><a href='#crs'><p>Bases for cubic regression splines (equivalent to &quot;cr&quot; in <code>mgcv</code>)</p></a></li>
<li><a href='#crs.FP'><p>Penalty matrix constructor for cubic regression splines</p></a></li>
<li><a href='#CumulHazard'><p>Cumulative hazard (integral of hazard) only</p></a></li>
<li><a href='#datCancer'><p>Patients diagnosed with cervical cancer</p></a></li>
<li><a href='#deriv_R'><p>Derivative of a Choleski factor</p></a></li>
<li><a href='#DerivCumulHazard'><p>Cumulative hazard (integral of hazard) and its first and second derivatives wrt regression parameters beta</p></a></li>
<li><a href='#design.matrix'><p>Design matrix for the model needed in Gauss-Legendre quadrature</p></a></li>
<li><a href='#expected.table'><p>French women mortality table</p></a></li>
<li><a href='#grad_rho'><p>Gradient vector of LCV and LAML wrt rho (log smoothing parameters)</p></a></li>
<li><a href='#grad_rho_mult'><p>Gradient vector of LCV and LAML wrt rho (log smoothing parameters). Version for multiplicative decomposition : relative mortality ratio model</p></a></li>
<li><a href='#HazGL'><p>Gauss-Legendre evaluations</p></a></li>
<li><a href='#HeartFailure'><p>Patients with heart failure at risk of recurrent hospitalization events</p></a></li>
<li><a href='#Hess_rho'><p>Hessian matrix of LCV and LAML wrt rho (log smoothing parameters)</p></a></li>
<li><a href='#Hess_rho_mult'><p>Hessian matrix of LCV and LAML wrt rho (log smoothing parameters). Version for multiplicative decomposition : relative mortality ratio model</p></a></li>
<li><a href='#instr'><p>Position of the nth occurrence of a string in another one</p></a></li>
<li><a href='#inv.repam'><p>Reverses the initial reparameterization for stable evaluation of the log determinant of the penalty matrix</p></a></li>
<li><a href='#list.wicss'><p>List of ICSS standards for age-standardization of cancer (net) survival</p></a></li>
<li><a href='#model.cons'><p>Design and penalty matrices for the model</p></a></li>
<li><a href='#NR.beta'><p>Inner Newton-Raphson algorithm for regression parameters estimation</p></a></li>
<li><a href='#NR.rho'><p>Outer Newton-Raphson algorithm for smoothing parameters estimation via LCV or LAML optimization</p></a></li>
<li><a href='#predict.survPen'><p>Hazard and Survival prediction from fitted <code>survPen</code> model</p></a></li>
<li><a href='#predSNS'><p>Prediction of grouped indicators : population (net) survival (PNS) and age-standardized (net) survival (SNS)</p></a></li>
<li><a href='#print.summary.survPen'><p>print summary for a <code>survPen</code> fit</p></a></li>
<li><a href='#pwcst'><p>Defining piecewise constant (excess) hazard in survPen formulae</p></a></li>
<li><a href='#rd'><p>Defining random effects in survPen formulae</p></a></li>
<li><a href='#repam'><p>Applies initial reparameterization for stable evaluation of the log determinant of the penalty matrix</p></a></li>
<li><a href='#robust.var'><p>Implementation of the robust variance Vr</p></a></li>
<li><a href='#smf'><p>Defining smooths in survPen formulae</p></a></li>
<li><a href='#smooth.cons'><p>Design and penalty matrices of penalized splines in a smooth.spec object</p></a></li>
<li><a href='#smooth.cons.integral'><p>Design matrix of penalized splines in a smooth.spec object for Gauss-Legendre quadrature</p></a></li>
<li><a href='#smooth.spec'><p>Covariates specified as penalized splines</p></a></li>
<li><a href='#splitmult'><p>Split original dataset at specified times to fit a multiplicative model</p></a></li>
<li><a href='#summary.survPen'><p>Summary for a <code>survPen</code> fit</p></a></li>
<li><a href='#survPen'><p>(Excess) hazard model with (multidimensional) penalized splines and integrated smoothness estimation</p></a></li>
<li><a href='#survPen.fit'><p>(Excess) hazard model with multidimensional penalized splines for given smoothing parameters</p></a></li>
<li><a href='#survPenObject'><p>Fitted survPen object</p></a></li>
<li><a href='#tensor.in'><p>tensor model matrix for two marginal bases</p></a></li>
<li><a href='#tensor.prod.S'><p>Tensor product for penalty matrices</p></a></li>
<li><a href='#tensor.prod.X'><p>tensor model matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Multidimensional Penalized Splines for (Excess) Hazard Models,
Relative Mortality Ratio Models and Marginal Intensity Models</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits (excess) hazard, relative mortality ratio or marginal intensity models with multidimensional penalized splines allowing for 
        time-dependent effects, non-linear effects and interactions between several continuous covariates. In survival and net survival analysis, in addition to modelling the effect of time (via the baseline hazard), one has often to deal with several continuous covariates and model their functional forms, their time-dependent effects, and their interactions. Model specification becomes therefore a complex problem and penalized regression splines represent an appealing solution to that problem as splines offer the required flexibility while penalization limits overfitting issues. Current implementations of penalized survival models can be slow or unstable and sometimes lack some key features like taking into account expected mortality to provide net survival and excess hazard estimates. In contrast, survPen provides an automated, fast, and stable implementation (thanks to explicit calculation of the derivatives of the likelihood) and offers a unified framework for 
        multidimensional penalized hazard and excess hazard models. Later versions (&gt;2.0.0) include penalized models for relative mortality ratio, and marginal intensity in recurrent event setting.
	survPen may be of interest to those who 1) analyse any kind of time-to-event data: mortality, disease relapse, machinery breakdown, unemployment, etc 2) wish to describe the associated hazard and to understand which predictors impact its dynamics, 
	3) wish to model the relative mortality ratio between a cohort and a reference population, 4) wish to describe the marginal intensity for recurrent event data. 
	See Fauvernier et al. (2019a) &lt;<a href="https://doi.org/10.21105%2Fjoss.01434">doi:10.21105/joss.01434</a>&gt; for an overview of the package and Fauvernier et al. (2019b) &lt;<a href="https://doi.org/10.1111%2Frssc.12368">doi:10.1111/rssc.12368</a>&gt; for the method.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> | file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>statmod, stats, Rcpp (&ge; 1.0.2)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/fauvernierma/survPen">https://github.com/fauvernierma/survPen</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/fauvernierma/survPen/issues">https://github.com/fauvernierma/survPen/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-08 16:39:54 UTC; FAUVERNIERMA</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-08 17:20:02 UTC</td>
</tr>
<tr>
<td>Author:</td>
<td>Mathieu Fauvernier [aut, cre],
  Laurent Roche [aut],
  Laurent Remontet [aut],
  Zoe Uhry [ctb],
  Nadine Bossard [ctb],
  Elsa Coz [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mathieu Fauvernier &lt;mathieu.fauvernier@gmail.com&gt;</td>
</tr>
</table>
<hr>
<h2 id='+25cross+25'>Matrix cross-multiplication between two matrices</h2><span id='topic++25cross+25'></span>

<h3>Description</h3>

<p>Matrix cross-multiplication between two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mat1 %cross% Mat2
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25cross+2B25_+3A_mat1">Mat1</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="+2B25cross+2B25_+3A_mat2">Mat2</code></td>
<td>
<p>another matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prod the product t(Mat1)
</p>

<hr>
<h2 id='+25mult+25'>Matrix multiplication between two matrices</h2><span id='topic++25mult+25'></span>

<h3>Description</h3>

<p>Matrix multiplication between two matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mat1 %mult% Mat2
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25mult+2B25_+3A_mat1">Mat1</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="+2B25mult+2B25_+3A_mat2">Mat2</code></td>
<td>
<p>another matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prod the product Mat1
</p>

<hr>
<h2 id='+25vec+25'>Matrix multiplication between a matrix and a vector</h2><span id='topic++25vec+25'></span>

<h3>Description</h3>

<p>Matrix multiplication between a matrix and a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mat %vec% vec
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25vec+2B25_+3A_mat">Mat</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="+2B25vec+2B25_+3A_vec">vec</code></td>
<td>
<p>a vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prod the product Mat
</p>

<hr>
<h2 id='colSums2'>colSums of a matrix</h2><span id='topic+colSums2'></span>

<h3>Description</h3>

<p>colSums of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colSums2(Mat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="colSums2_+3A_mat">Mat</code></td>
<td>
<p>a matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>colSums(Mat)
</p>

<hr>
<h2 id='constraint'>Sum-to-zero constraint</h2><span id='topic+constraint'></span>

<h3>Description</h3>

<p>Applies the sum-to-zero constraints to design and penalty matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constraint(X, S, Z = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="constraint_+3A_x">X</code></td>
<td>
<p>A design matrix</p>
</td></tr>
<tr><td><code id="constraint_+3A_s">S</code></td>
<td>
<p>A penalty matrix or a list of penalty matrices</p>
</td></tr>
<tr><td><code id="constraint_+3A_z">Z</code></td>
<td>
<p>A list of sum-to-zero constraint matrices; default is NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of objects with the following items:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>Design matrix</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>Penalty matrix or list of penalty matrices</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>List of sum-to-zero constraint matrices</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

set.seed(15)

X &lt;- matrix(rnorm(10*3),nrow=10,ncol=3)
S &lt;- matrix(rnorm(3*3),nrow=3,ncol=3) ; S &lt;- 0.5*( S + t(S))

# applying sum-to-zero constraint to a desgin matrix and a penalty matrix
constr &lt;- constraint(X,S) 

</code></pre>

<hr>
<h2 id='cor.var'>Implementation of the corrected variance Vc</h2><span id='topic+cor.var'></span>

<h3>Description</h3>

<p>Takes the model at convergence and calculates the variance matrix corrected for smoothing parameter uncertainty
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor.var(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cor.var_+3A_model">model</code></td>
<td>
<p>survPen object, see <code><a href="#topic+survPen.fit">survPen.fit</a></code> for details</p>
</td></tr>
</table>


<h3>Value</h3>

<p>survPen object with corrected variance Vc
</p>

<hr>
<h2 id='crs'>Bases for cubic regression splines (equivalent to &quot;cr&quot; in <code>mgcv</code>)</h2><span id='topic+crs'></span>

<h3>Description</h3>

<p>Builds the design matrix and the penalty matrix for cubic regression splines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crs(x, knots = NULL, df = 10, intercept = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crs_+3A_x">x</code></td>
<td>
<p>Numeric vector</p>
</td></tr>
<tr><td><code id="crs_+3A_knots">knots</code></td>
<td>
<p>Numeric vectors that specifies the knots of the splines (including boundaries); default is NULL</p>
</td></tr>
<tr><td><code id="crs_+3A_df">df</code></td>
<td>
<p>numeric value that indicates the number of knots desired (or degrees of freedom) if knots=NULL; default is 10</p>
</td></tr>
<tr><td><code id="crs_+3A_intercept">intercept</code></td>
<td>
<p>if FALSE, the intercept is excluded from the basis; default is TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See package <code>mgcv</code> and section 4.1.2 of Wood (2006) for more details about this basis
</p>


<h3>Value</h3>

<p>List of three elements
</p>
<table role = "presentation">
<tr><td><code>bs</code></td>
<td>
<p>design matrix</p>
</td></tr>
<tr><td><code>pen</code></td>
<td>
<p>penalty matrix</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>vector of knots (specified or calculated from <code>df</code>)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wood, S. N. (2006), Generalized additive models: an introduction with R. London: Chapman &amp; Hall/CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(1,10,length=100)
# natural cubic spline with 3 knots
crs(x,knots=c(1,5,10))

</code></pre>

<hr>
<h2 id='crs.FP'>Penalty matrix constructor for cubic regression splines</h2><span id='topic+crs.FP'></span>

<h3>Description</h3>

<p>constructs the penalty matrix associated with cubic regression splines basis. This function is called inside
<code><a href="#topic+crs">crs</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crs.FP(knots, h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="crs.FP_+3A_knots">knots</code></td>
<td>
<p>Numeric vectors that specifies the knots of the splines (including boundaries)</p>
</td></tr>
<tr><td><code id="crs.FP_+3A_h">h</code></td>
<td>
<p>vector of knots differences (corresponds to <code>diff(sort(knots))</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of two elements:
</p>
<table role = "presentation">
<tr><td><code>F.mat</code></td>
<td>
<p>matrix used in function <code><a href="#topic+crs">crs</a></code> for basis construction</p>
</td></tr>
<tr><td><code>P.mat</code></td>
<td>
<p>penalty matrix</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# construction of the penalty matrix using a sequence of knots
knots &lt;- c(0,0.25,0.5,0.75,1)
diff.knots &lt;- diff(knots)

crs.FP(knots,diff.knots)

</code></pre>

<hr>
<h2 id='CumulHazard'>Cumulative hazard (integral of hazard) only</h2><span id='topic+CumulHazard'></span>

<h3>Description</h3>

<p>Cumulative hazard (integral of hazard) only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CumulHazard(X_GL, weights, tm, n_legendre, n, beta, is_pwcst, pwcst_weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CumulHazard_+3A_x_gl">X_GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="CumulHazard_+3A_weights">weights</code></td>
<td>
<p>vector of weights for Gauss-Legendre integration on [-1;1]</p>
</td></tr>
<tr><td><code id="CumulHazard_+3A_tm">tm</code></td>
<td>
<p>vector of midpoints times for Gauss-Legendre integration; tm = 0.5*(t1 - t0)</p>
</td></tr>
<tr><td><code id="CumulHazard_+3A_n_legendre">n_legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="CumulHazard_+3A_n">n</code></td>
<td>
<p>number of individuals in the dataset</p>
</td></tr>
<tr><td><code id="CumulHazard_+3A_beta">beta</code></td>
<td>
<p>vector of estimated regression parameters</p>
</td></tr>
<tr><td><code id="CumulHazard_+3A_is_pwcst">is_pwcst</code></td>
<td>
<p>True if there is a piecewise constant baseline specified. False otherwise</p>
</td></tr>
<tr><td><code id="CumulHazard_+3A_pwcst_weights">pwcst_weights</code></td>
<td>
<p>if is_pwcst is TRUE, matrix of weights giving the time contribution of each individual on each sub-interval. Otherwise NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cumulative hazard (integral of hazard)
</p>

<hr>
<h2 id='datCancer'>Patients diagnosed with cervical cancer</h2><span id='topic+datCancer'></span>

<h3>Description</h3>

<p>A simulated dataset containing the follow-up times of 2000 patients diagnosed with cervical cancer between 
1990 and 2010. End of follow-up is June 30th 2013. The variables are as follows:
</p>

<ul>
<li><p> begin. beginning of follow-up. For illustration purposes about left truncation only (0&ndash;1)
</p>
</li>
<li><p> fu. follow-up time in years (0&ndash;5)
</p>
</li>
<li><p> age. age at diagnosis in years, from 21.39 to 99.33
</p>
</li>
<li><p> yod. decimal year of diagnosis, from 1990.023 to 2010.999
</p>
</li>
<li><p> dead. censoring indicator (1 for dead, 0 for censored)
</p>
</li>
<li><p> rate. expected mortality rate (from overall mortality of the general population) (0&ndash;0.38)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(datCancer)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2000 rows and 6 variables
</p>

<hr>
<h2 id='deriv_R'>Derivative of a Choleski factor</h2><span id='topic+deriv_R'></span>

<h3>Description</h3>

<p>Derivative of a Choleski factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deriv_R(deriv_Vp, p, R1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deriv_R_+3A_deriv_vp">deriv_Vp</code></td>
<td>
<p>derivatives of the Bayesian covariance matrix wrt rho (log smoothing parameters).</p>
</td></tr>
<tr><td><code id="deriv_R_+3A_p">p</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code id="deriv_R_+3A_r1">R1</code></td>
<td>
<p>Choleski factor of Vp</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the derivatives of R1 wrt rho (log smoothing parameters)
</p>

<hr>
<h2 id='DerivCumulHazard'>Cumulative hazard (integral of hazard) and its first and second derivatives wrt regression parameters beta</h2><span id='topic+DerivCumulHazard'></span>

<h3>Description</h3>

<p>Cumulative hazard (integral of hazard) and its first and second derivatives wrt regression parameters beta
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DerivCumulHazard(
  X_GL,
  weights,
  tm,
  n_legendre,
  n,
  p,
  beta,
  expected,
  type,
  is_pwcst,
  pwcst_weights
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DerivCumulHazard_+3A_x_gl">X_GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_weights">weights</code></td>
<td>
<p>vector of weights for Gauss-Legendre integration on [-1;1]</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_tm">tm</code></td>
<td>
<p>vector of midpoints times for Gauss-Legendre integration; tm = 0.5*(t1 - t0)</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_n_legendre">n_legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_n">n</code></td>
<td>
<p>number of individuals in the dataset</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_p">p</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_beta">beta</code></td>
<td>
<p>vector of estimated regression parameters</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_expected">expected</code></td>
<td>
<p>vector of expected hazard rates</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_type">type</code></td>
<td>
<p>&quot;net&quot;, &quot;overall&quot; or &quot;mult&quot;</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_is_pwcst">is_pwcst</code></td>
<td>
<p>True if there is a piecewise constant baseline specified. False otherwise</p>
</td></tr>
<tr><td><code id="DerivCumulHazard_+3A_pwcst_weights">pwcst_weights</code></td>
<td>
<p>if is.pwcst is TRUE, matrix of weights giving the time contribution of each individual on each sub-interval. Otherwise NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of objects with the following items:
</p>
<table role = "presentation">
<tr><td><code>integral</code></td>
<td>
<p>cumulative hazard (integral of hazard)</p>
</td></tr>
<tr><td><code>f.first</code></td>
<td>
<p>first derivative of cumulative hazard wrt beta</p>
</td></tr>
<tr><td><code>f.second</code></td>
<td>
<p>second derivative of cumulative hazard wrt beta</p>
</td></tr>
</table>

<hr>
<h2 id='design.matrix'>Design matrix for the model needed in Gauss-Legendre quadrature</h2><span id='topic+design.matrix'></span>

<h3>Description</h3>

<p>Builds the design matrix for the whole model when the sum-to-zero constraints are specified. The function is called inside <code><a href="#topic+model.cons">model.cons</a></code>
for Gauss-Legendre quadrature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>design.matrix(
  formula,
  data.spec,
  t1.name,
  Z.smf,
  Z.tensor,
  Z.tint,
  list.smf,
  list.tensor,
  list.tint,
  list.rd
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="design.matrix_+3A_formula">formula</code></td>
<td>
<p>formula object identifying the model</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_data.spec">data.spec</code></td>
<td>
<p>data frame that represents the environment from which the covariate values and knots are to be calculated</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_t1.name">t1.name</code></td>
<td>
<p>name of the vector of follow-up times</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_z.smf">Z.smf</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+smf">smf</a></code> splines</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_z.tensor">Z.tensor</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+tensor">tensor</a></code> splines</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_z.tint">Z.tint</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+tint">tint</a></code> splines</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_list.smf">list.smf</code></td>
<td>
<p>List of all smf.smooth.spec objects contained in the model</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_list.tensor">list.tensor</code></td>
<td>
<p>List of all tensor.smooth.spec objects contained in the model</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_list.tint">list.tint</code></td>
<td>
<p>List of all tint.smooth.spec objects contained in the model</p>
</td></tr>
<tr><td><code id="design.matrix_+3A_list.rd">list.rd</code></td>
<td>
<p>List of all rd.smooth.spec objects contained in the model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>design matrix for the model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots

data &lt;- data.frame(time=seq(0,5,length=100),event=1,t0=0)

form &lt;- ~ smf(time,knots=c(0,1,3,5))

t1 &lt;- eval(substitute(time), data)
t0 &lt;- eval(substitute(t0), data)
event &lt;- eval(substitute(event), data)
	
# Setting up the model
model.c &lt;- model.cons(form,lambda=0,data.spec=data,t1=t1,t1.name="time",
t0=rep(0,100),t0.name="t0",event=event,event.name="event",
expected=rep(0,100),expected.name=NULL,type="overall",n.legendre=20,
cl="survPen(form,data,t1=time,event=event)",beta.ini=NULL)
 
# Retrieving the sum-to-zero constraint matrices and the list of knots
Z.smf &lt;- model.c$Z.smf ; list.smf &lt;- model.c$list.smf

# Calculating the design matrix
design.M &lt;- design.matrix(form,data.spec=data,t1.name="time",Z.smf=Z.smf,list.smf=list.smf,
Z.tensor=NULL,Z.tint=NULL,list.tensor=NULL,list.tint=NULL,list.rd=NULL)

</code></pre>

<hr>
<h2 id='expected.table'>French women mortality table</h2><span id='topic+expected.table'></span>

<h3>Description</h3>

<p>French women mortality table to serve as example of reference/expected mortality in excess hazard and relative mortality ratio models
The data come from the human mortality databse website: https://www.mortality.org/Country/Country?cntr=FRATNP
</p>

<ul>
<li><p> Age. Age group for 1-year interval from exact age x to just before exact age x+1 (0-110+)
</p>
</li>
<li><p> Year. Calendar Year (1816-2021)
</p>
</li>
<li><p> mx. Central death rate between ages x and x+1
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(expected.table)
</code></pre>


<h3>Format</h3>

<p>A data frame with 22866 rows and 3 variables
</p>

<hr>
<h2 id='grad_rho'>Gradient vector of LCV and LAML wrt rho (log smoothing parameters)</h2><span id='topic+grad_rho'></span>

<h3>Description</h3>

<p>Gradient vector of LCV and LAML wrt rho (log smoothing parameters)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad_rho(
  X_GL,
  GL_temp,
  haz_GL,
  deriv_rho_beta,
  weights,
  tm,
  nb_smooth,
  p,
  n_legendre,
  S_list,
  temp_LAML,
  Vp,
  S_beta,
  beta,
  inverse_new_S,
  X,
  temp_deriv3,
  event,
  expected,
  type,
  Ve,
  mat_temp,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grad_rho_+3A_x_gl">X_GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_gl_temp">GL_temp</code></td>
<td>
<p>list of vectors used to make intermediate calculations and save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_haz_gl">haz_GL</code></td>
<td>
<p>list of all the matrix-vector multiplications X.GL[[i]]%*%beta for Gauss Legendre integration in order to save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_deriv_rho_beta">deriv_rho_beta</code></td>
<td>
<p>firt derivative of beta wrt rho (implicit differentiation)</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_weights">weights</code></td>
<td>
<p>vector of weights for Gauss-Legendre integration on [-1;1]</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_tm">tm</code></td>
<td>
<p>vector of midpoints times for Gauss-Legendre integration; tm = 0.5*(t1 - t0)</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_nb_smooth">nb_smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_p">p</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_n_legendre">n_legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_s_list">S_list</code></td>
<td>
<p>List of all the rescaled penalty matrices multiplied by their associated smoothing parameters</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_temp_laml">temp_LAML</code></td>
<td>
<p>temporary matrix used when method=&quot;LAML&quot; to save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_vp">Vp</code></td>
<td>
<p>Bayesian covariance matrix</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_s_beta">S_beta</code></td>
<td>
<p>List such that S_beta[[i]]=S_list[[i]]%*%beta</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_beta">beta</code></td>
<td>
<p>vector of estimated regression parameters</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_inverse_new_s">inverse_new_S</code></td>
<td>
<p>inverse of the penalty matrix</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_x">X</code></td>
<td>
<p>design matrix for the model</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_temp_deriv3">temp_deriv3</code></td>
<td>
<p>temporary matrix for third derivatives calculation when type=&quot;net&quot; to save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_event">event</code></td>
<td>
<p>vector of right-censoring indicators</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_expected">expected</code></td>
<td>
<p>vector of expected hazard rates</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_type">type</code></td>
<td>
<p>&quot;net&quot; or &quot;overall&quot;</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_ve">Ve</code></td>
<td>
<p>frequentist covariance matrix</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_mat_temp">mat_temp</code></td>
<td>
<p>temporary matrix used when method=&quot;LCV&quot; to save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_+3A_method">method</code></td>
<td>
<p>criterion used to select the smoothing parameters. Should be &quot;LAML&quot; or &quot;LCV&quot;; default is &quot;LAML&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of objects with the following items:
</p>
<table role = "presentation">
<tr><td><code>grad_rho</code></td>
<td>
<p>gradient vector of LCV or LAML</p>
</td></tr>
<tr><td><code>deriv_rho_inv_Hess_beta</code></td>
<td>
<p>List of first derivatives of Vp wrt rho</p>
</td></tr>
<tr><td><code>deriv_rho_Hess_unpen_beta</code></td>
<td>
<p>List of first derivatives of the Hessian of the unpenalized log-likelihood wrt rho</p>
</td></tr>
</table>

<hr>
<h2 id='grad_rho_mult'>Gradient vector of LCV and LAML wrt rho (log smoothing parameters). Version for multiplicative decomposition : relative mortality ratio model</h2><span id='topic+grad_rho_mult'></span>

<h3>Description</h3>

<p>Gradient vector of LCV and LAML wrt rho (log smoothing parameters). Version for multiplicative decomposition : relative mortality ratio model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad_rho_mult(
  X_GL,
  GL_temp,
  haz_GL,
  deriv_rho_beta,
  weights,
  tm,
  nb_smooth,
  p,
  n_legendre,
  S_list,
  temp_LAML,
  Vp,
  S_beta,
  beta,
  inverse_new_S,
  X,
  event,
  expected,
  Ve,
  mat_temp,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grad_rho_mult_+3A_x_gl">X_GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_gl_temp">GL_temp</code></td>
<td>
<p>list of vectors used to make intermediate calculations and save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_haz_gl">haz_GL</code></td>
<td>
<p>list of all the matrix-vector multiplications X.GL[[i]]%*%beta for Gauss Legendre integration in order to save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_deriv_rho_beta">deriv_rho_beta</code></td>
<td>
<p>firt derivative of beta wrt rho (implicit differentiation)</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_weights">weights</code></td>
<td>
<p>vector of weights for Gauss-Legendre integration on [-1;1]</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_tm">tm</code></td>
<td>
<p>vector of midpoints times for Gauss-Legendre integration; tm = 0.5*(t1 - t0)</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_nb_smooth">nb_smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_p">p</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_n_legendre">n_legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_s_list">S_list</code></td>
<td>
<p>List of all the rescaled penalty matrices multiplied by their associated smoothing parameters</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_temp_laml">temp_LAML</code></td>
<td>
<p>temporary matrix used when method=&quot;LAML&quot; to save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_vp">Vp</code></td>
<td>
<p>Bayesian covariance matrix</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_s_beta">S_beta</code></td>
<td>
<p>List such that S_beta[[i]]=S_list[[i]]%*%beta</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_beta">beta</code></td>
<td>
<p>vector of estimated regression parameters</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_inverse_new_s">inverse_new_S</code></td>
<td>
<p>inverse of the penalty matrix</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_x">X</code></td>
<td>
<p>design matrix for the model</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_event">event</code></td>
<td>
<p>vector of right-censoring indicators</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_expected">expected</code></td>
<td>
<p>vector of expected hazard rates</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_ve">Ve</code></td>
<td>
<p>frequentist covariance matrix</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_mat_temp">mat_temp</code></td>
<td>
<p>temporary matrix used when method=&quot;LCV&quot; to save computation time</p>
</td></tr>
<tr><td><code id="grad_rho_mult_+3A_method">method</code></td>
<td>
<p>criterion used to select the smoothing parameters. Should be &quot;LAML&quot; or &quot;LCV&quot;; default is &quot;LAML&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of objects with the following items:
</p>
<table role = "presentation">
<tr><td><code>grad_rho</code></td>
<td>
<p>gradient vector of LCV or LAML</p>
</td></tr>
<tr><td><code>deriv_rho_inv_Hess_beta</code></td>
<td>
<p>List of first derivatives of Vp wrt rho</p>
</td></tr>
<tr><td><code>deriv_rho_Hess_unpen_beta</code></td>
<td>
<p>List of first derivatives of the Hessian of the unpenalized log-likelihood wrt rho</p>
</td></tr>
</table>

<hr>
<h2 id='HazGL'>Gauss-Legendre evaluations</h2><span id='topic+HazGL'></span>

<h3>Description</h3>

<p>Gauss-Legendre evaluations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HazGL(X_GL, n_legendre, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HazGL_+3A_x_gl">X_GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="HazGL_+3A_n_legendre">n_legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="HazGL_+3A_beta">beta</code></td>
<td>
<p>vector of estimated regression parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of all the matrix-vector multiplications X.GL[[i]]%*%beta for Gauss Legendre integration in order to save computation time
</p>

<hr>
<h2 id='HeartFailure'>Patients with heart failure at risk of recurrent hospitalization events</h2><span id='topic+HeartFailure'></span>

<h3>Description</h3>

<p>A simulated dataset containing 3 068 observations (2 268 events) in 800 patients with heart failure. 
The dataset is based on hfaction_cpx12 dataset from package WA. The variables are as follows:
</p>

<ul>
<li><p> id. patient identifcation number
</p>
</li>
<li><p> treatment. treatment=0 for control and treatment=1 for exercise training
</p>
</li>
<li><p> t0. beginning of follow-up for a given event
</p>
</li>
<li><p> t1. end of follow-up for a given event (up to 3.27 years)
</p>
</li>
<li><p> enum. event identification number for a given patient (between 1 and 6 events per patient)
</p>
</li>
<li><p> event. event indicator (1 for hospitalization, 0 for censored)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(HeartFailure)
</code></pre>


<h3>Format</h3>

<p>A data frame with 3 068 rows and 6 variables
</p>

<hr>
<h2 id='Hess_rho'>Hessian matrix of LCV and LAML wrt rho (log smoothing parameters)</h2><span id='topic+Hess_rho'></span>

<h3>Description</h3>

<p>Hessian matrix of LCV and LAML wrt rho (log smoothing parameters)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hess_rho(
  X_GL,
  X_GL_Q,
  GL_temp,
  haz_GL,
  deriv2_rho_beta,
  deriv_rho_beta,
  weights,
  tm,
  nb_smooth,
  p,
  n_legendre,
  deriv_rho_inv_Hess_beta,
  deriv_rho_Hess_unpen_beta,
  S_list,
  minus_eigen_inv_Hess_beta,
  temp_LAML,
  temp_LAML2,
  Vp,
  S_beta,
  beta,
  inverse_new_S,
  X,
  X_Q,
  temp_deriv3,
  temp_deriv4,
  event,
  expected,
  type,
  Ve,
  deriv_rho_Ve,
  mat_temp,
  deriv_mat_temp,
  eigen_mat_temp,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hess_rho_+3A_x_gl">X_GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_x_gl_q">X_GL_Q</code></td>
<td>
<p>list of transformed matrices from X_GL in order to calculate only the diagonal of the fourth derivative of the likelihood</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_gl_temp">GL_temp</code></td>
<td>
<p>list of vectors used to make intermediate calculations and save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_haz_gl">haz_GL</code></td>
<td>
<p>list of all the matrix-vector multiplications X.GL[[i]]%*%beta for Gauss Legendre integration in order to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_deriv2_rho_beta">deriv2_rho_beta</code></td>
<td>
<p>second derivatives of beta wrt rho (implicit differentiation)</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_deriv_rho_beta">deriv_rho_beta</code></td>
<td>
<p>firt derivatives of beta wrt rho (implicit differentiation)</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_weights">weights</code></td>
<td>
<p>vector of weights for Gauss-Legendre integration on [-1;1]</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_tm">tm</code></td>
<td>
<p>vector of midpoints times for Gauss-Legendre integration; tm = 0.5*(t1 - t0)</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_nb_smooth">nb_smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_p">p</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_n_legendre">n_legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_deriv_rho_inv_hess_beta">deriv_rho_inv_Hess_beta</code></td>
<td>
<p>list of first derivatives of Vp wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_deriv_rho_hess_unpen_beta">deriv_rho_Hess_unpen_beta</code></td>
<td>
<p>list of first derivatives of Hessian of unpenalized log likelihood wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_s_list">S_list</code></td>
<td>
<p>List of all the rescaled penalty matrices multiplied by their associated smoothing parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_minus_eigen_inv_hess_beta">minus_eigen_inv_Hess_beta</code></td>
<td>
<p>vector of eigenvalues of Vp</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_temp_laml">temp_LAML</code></td>
<td>
<p>temporary matrix used when method=&quot;LAML&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_temp_laml2">temp_LAML2</code></td>
<td>
<p>temporary matrix used when method=&quot;LAML&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_vp">Vp</code></td>
<td>
<p>Bayesian covariance matrix</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_s_beta">S_beta</code></td>
<td>
<p>List such that S_beta[[i]]=S_list[[i]]%*%beta</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_beta">beta</code></td>
<td>
<p>vector of estimated regression parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_inverse_new_s">inverse_new_S</code></td>
<td>
<p>inverse of the penalty matrix</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_x">X</code></td>
<td>
<p>design matrix for the model</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_x_q">X_Q</code></td>
<td>
<p>transformed design matrix in order to calculate only the diagonal of the fourth derivative of the likelihood</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_temp_deriv3">temp_deriv3</code></td>
<td>
<p>temporary matrix for third derivatives calculation when type=&quot;net&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_temp_deriv4">temp_deriv4</code></td>
<td>
<p>temporary matrix for fourth derivatives calculation when type=&quot;net&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_event">event</code></td>
<td>
<p>vector of right-censoring indicators</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_expected">expected</code></td>
<td>
<p>vector of expected hazard rates</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_type">type</code></td>
<td>
<p>&quot;net&quot; or &quot;overall&quot;</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_ve">Ve</code></td>
<td>
<p>frequentist covariance matrix</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_deriv_rho_ve">deriv_rho_Ve</code></td>
<td>
<p>list of derivatives of Ve wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_mat_temp">mat_temp</code></td>
<td>
<p>temporary matrix used when method=&quot;LCV&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_deriv_mat_temp">deriv_mat_temp</code></td>
<td>
<p>list of derivatives of mat_temp wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_eigen_mat_temp">eigen_mat_temp</code></td>
<td>
<p>vector of eigenvalues of mat_temp</p>
</td></tr>
<tr><td><code id="Hess_rho_+3A_method">method</code></td>
<td>
<p>criterion used to select the smoothing parameters. Should be &quot;LAML&quot; or &quot;LCV&quot;; default is &quot;LAML&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Hessian matrix of LCV or LAML wrt rho
</p>

<hr>
<h2 id='Hess_rho_mult'>Hessian matrix of LCV and LAML wrt rho (log smoothing parameters). Version for multiplicative decomposition : relative mortality ratio model</h2><span id='topic+Hess_rho_mult'></span>

<h3>Description</h3>

<p>Hessian matrix of LCV and LAML wrt rho (log smoothing parameters). Version for multiplicative decomposition : relative mortality ratio model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hess_rho_mult(
  X_GL,
  X_GL_Q,
  GL_temp,
  haz_GL,
  deriv2_rho_beta,
  deriv_rho_beta,
  weights,
  tm,
  nb_smooth,
  p,
  n_legendre,
  deriv_rho_inv_Hess_beta,
  deriv_rho_Hess_unpen_beta,
  S_list,
  minus_eigen_inv_Hess_beta,
  temp_LAML,
  temp_LAML2,
  Vp,
  S_beta,
  beta,
  inverse_new_S,
  X,
  X_Q,
  event,
  expected,
  Ve,
  deriv_rho_Ve,
  mat_temp,
  deriv_mat_temp,
  eigen_mat_temp,
  method
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hess_rho_mult_+3A_x_gl">X_GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_x_gl_q">X_GL_Q</code></td>
<td>
<p>list of transformed matrices from X_GL in order to calculate only the diagonal of the fourth derivative of the likelihood</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_gl_temp">GL_temp</code></td>
<td>
<p>list of vectors used to make intermediate calculations and save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_haz_gl">haz_GL</code></td>
<td>
<p>list of all the matrix-vector multiplications X.GL[[i]]%*%beta for Gauss Legendre integration in order to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_deriv2_rho_beta">deriv2_rho_beta</code></td>
<td>
<p>second derivatives of beta wrt rho (implicit differentiation)</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_deriv_rho_beta">deriv_rho_beta</code></td>
<td>
<p>firt derivatives of beta wrt rho (implicit differentiation)</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_weights">weights</code></td>
<td>
<p>vector of weights for Gauss-Legendre integration on [-1;1]</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_tm">tm</code></td>
<td>
<p>vector of midpoints times for Gauss-Legendre integration; tm = 0.5*(t1 - t0)</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_nb_smooth">nb_smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_p">p</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_n_legendre">n_legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_deriv_rho_inv_hess_beta">deriv_rho_inv_Hess_beta</code></td>
<td>
<p>list of first derivatives of Vp wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_deriv_rho_hess_unpen_beta">deriv_rho_Hess_unpen_beta</code></td>
<td>
<p>list of first derivatives of Hessian of unpenalized log likelihood wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_s_list">S_list</code></td>
<td>
<p>List of all the rescaled penalty matrices multiplied by their associated smoothing parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_minus_eigen_inv_hess_beta">minus_eigen_inv_Hess_beta</code></td>
<td>
<p>vector of eigenvalues of Vp</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_temp_laml">temp_LAML</code></td>
<td>
<p>temporary matrix used when method=&quot;LAML&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_temp_laml2">temp_LAML2</code></td>
<td>
<p>temporary matrix used when method=&quot;LAML&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_vp">Vp</code></td>
<td>
<p>Bayesian covariance matrix</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_s_beta">S_beta</code></td>
<td>
<p>List such that S_beta[[i]]=S_list[[i]]%*%beta</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_beta">beta</code></td>
<td>
<p>vector of estimated regression parameters</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_inverse_new_s">inverse_new_S</code></td>
<td>
<p>inverse of the penalty matrix</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_x">X</code></td>
<td>
<p>design matrix for the model</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_x_q">X_Q</code></td>
<td>
<p>transformed design matrix in order to calculate only the diagonal of the fourth derivative of the likelihood</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_event">event</code></td>
<td>
<p>vector of right-censoring indicators</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_expected">expected</code></td>
<td>
<p>vector of expected hazard rates</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_ve">Ve</code></td>
<td>
<p>frequentist covariance matrix</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_deriv_rho_ve">deriv_rho_Ve</code></td>
<td>
<p>list of derivatives of Ve wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_mat_temp">mat_temp</code></td>
<td>
<p>temporary matrix used when method=&quot;LCV&quot; to save computation time</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_deriv_mat_temp">deriv_mat_temp</code></td>
<td>
<p>list of derivatives of mat_temp wrt rho</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_eigen_mat_temp">eigen_mat_temp</code></td>
<td>
<p>vector of eigenvalues of mat_temp</p>
</td></tr>
<tr><td><code id="Hess_rho_mult_+3A_method">method</code></td>
<td>
<p>criterion used to select the smoothing parameters. Should be &quot;LAML&quot; or &quot;LCV&quot;; default is &quot;LAML&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Hessian matrix of LCV or LAML wrt rho
</p>

<hr>
<h2 id='instr'>Position of the nth occurrence of a string in another one</h2><span id='topic+instr'></span>

<h3>Description</h3>

<p>Returns the position of the nth occurrence of str2 in str1. Returns 0 if str2 is not found.
This code was first suggested by Abdelmonem Mahmoud Amer in https://stackoverflow.com/a/33005653/5421090
</p>


<h3>Usage</h3>

<pre><code class='language-R'>instr(str1, str2, startpos = 1, n = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="instr_+3A_str1">str1</code></td>
<td>
<p>main string in which str2 is to be found</p>
</td></tr>
<tr><td><code id="instr_+3A_str2">str2</code></td>
<td>
<p>substring contained in str1</p>
</td></tr>
<tr><td><code id="instr_+3A_startpos">startpos</code></td>
<td>
<p>starting position in str1; default is 1</p>
</td></tr>
<tr><td><code id="instr_+3A_n">n</code></td>
<td>
<p>which occurrence is to be found; default is 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>number representing the nth position of str2 in str1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

instr("character test to find the position of the third letter r","r",n=3)

</code></pre>

<hr>
<h2 id='inv.repam'>Reverses the initial reparameterization for stable evaluation of the log determinant of the penalty matrix</h2><span id='topic+inv.repam'></span>

<h3>Description</h3>

<p>Transforms the final model by reversing the initial reparameterization performed by <code><a href="#topic+repam">repam</a></code>. Derives the corrected version of the Bayesian covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inv.repam(model, X.ini, S.pen.ini)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inv.repam_+3A_model">model</code></td>
<td>
<p>survPen object, see <code><a href="#topic+survPen.fit">survPen.fit</a></code> for details</p>
</td></tr>
<tr><td><code id="inv.repam_+3A_x.ini">X.ini</code></td>
<td>
<p>initial design matrix (before reparameterization)</p>
</td></tr>
<tr><td><code id="inv.repam_+3A_s.pen.ini">S.pen.ini</code></td>
<td>
<p>initial penalty matrices</p>
</td></tr>
</table>


<h3>Value</h3>

<p>survPen object with standard parameterization
</p>

<hr>
<h2 id='list.wicss'>List of ICSS standards for age-standardization of cancer (net) survival</h2><span id='topic+list.wicss'></span>

<h3>Description</h3>

<p>Four data frames are available in the list : 1, 2, 3 and &quot;prostate&quot;. Each one corresponds to certain types of cancer.
Details can be found in Corazzieri et al. (2004) (10.1016/j.ejca.2004.07.002)  or at (in French) : https://www.santepubliquefrance.fr/docs/survie-des-personnes-atteintes-de-cancer-en-france-metropolitaine-1989-2018-materiel-et-methodes
For each data frame, the variables are as follows:
</p>

<ul>
<li><p> AgeClass. Age classes considered. Closed on the left and open on the right.
</p>
</li>
<li><p> AgeWeights. Weights associated with each age class
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>data(list.wicss)
</code></pre>


<h3>Format</h3>

<p>A list containing four data frames of 5 rows and 2 variables each
</p>

<hr>
<h2 id='model.cons'>Design and penalty matrices for the model</h2><span id='topic+model.cons'></span>

<h3>Description</h3>

<p>Sets up the model before optimization. Builds the design matrix, the penalty matrix and all the design matrices needed for Gauss-Legendre quadrature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model.cons(
  formula,
  lambda,
  data.spec,
  t1,
  t1.name,
  t0,
  t0.name,
  event,
  event.name,
  expected,
  expected.name,
  type,
  n.legendre,
  cl,
  beta.ini
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="model.cons_+3A_formula">formula</code></td>
<td>
<p>formula object identifying the model</p>
</td></tr>
<tr><td><code id="model.cons_+3A_lambda">lambda</code></td>
<td>
<p>vector of smoothing parameters</p>
</td></tr>
<tr><td><code id="model.cons_+3A_data.spec">data.spec</code></td>
<td>
<p>data frame that represents the environment from which the covariate values and knots are to be calculated</p>
</td></tr>
<tr><td><code id="model.cons_+3A_t1">t1</code></td>
<td>
<p>vector of follow-up times</p>
</td></tr>
<tr><td><code id="model.cons_+3A_t1.name">t1.name</code></td>
<td>
<p>name of <code>t1</code> in <code>data.spec</code></p>
</td></tr>
<tr><td><code id="model.cons_+3A_t0">t0</code></td>
<td>
<p>vector of origin times (usually filled with zeros)</p>
</td></tr>
<tr><td><code id="model.cons_+3A_t0.name">t0.name</code></td>
<td>
<p>name of <code>t0</code> in <code>data.spec</code></p>
</td></tr>
<tr><td><code id="model.cons_+3A_event">event</code></td>
<td>
<p>vector of censoring indicators</p>
</td></tr>
<tr><td><code id="model.cons_+3A_event.name">event.name</code></td>
<td>
<p>name of event in <code>data.spec</code></p>
</td></tr>
<tr><td><code id="model.cons_+3A_expected">expected</code></td>
<td>
<p>vector of expected hazard</p>
</td></tr>
<tr><td><code id="model.cons_+3A_expected.name">expected.name</code></td>
<td>
<p>name of expected in <code>data.spec</code></p>
</td></tr>
<tr><td><code id="model.cons_+3A_type">type</code></td>
<td>
<p>&quot;net&quot; or &quot;overall&quot;</p>
</td></tr>
<tr><td><code id="model.cons_+3A_n.legendre">n.legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code id="model.cons_+3A_cl">cl</code></td>
<td>
<p>original <code>survPen</code> call</p>
</td></tr>
<tr><td><code id="model.cons_+3A_beta.ini">beta.ini</code></td>
<td>
<p>initial set of regression parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of objects with the following items:
</p>
<table role = "presentation">
<tr><td><code>cl</code></td>
<td>
<p>original <code>survPen</code> call</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>&quot;net&quot;, &quot;overall&quot;, or &quot;mult&quot;</p>
</td></tr>
<tr><td><code>n.legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature. If is.pwcst is TRUE, for simplicity of implementation, n.legendre actually corresponds to the number of sub-intervals</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of individuals</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>number of parameters</p>
</td></tr>
<tr><td><code>X.para</code></td>
<td>
<p>design matrix associated with fully parametric parameters (unpenalized)</p>
</td></tr>
<tr><td><code>X.smooth</code></td>
<td>
<p>design matrix associated with the penalized parameters</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>design matrix for the model</p>
</td></tr>
<tr><td><code>is.pwcst</code></td>
<td>
<p>TRUE if there is a piecewise constant (excess) hazard specification. In that case the cumulative hazard can be derived without Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code>pwcst.breaks</code></td>
<td>
<p>if is.pwcst is TRUE, vector of breaks defining the sub-intervals on which the hazard is constant. Otherwise NULL.</p>
</td></tr>
<tr><td><code>pwcst.weights</code></td>
<td>
<p>if is.pwcst is TRUE, matrix of weights giving the time contribution of each individual on each sub-interval. Otherwise NULL.</p>
</td></tr>
<tr><td><code>leg</code></td>
<td>
<p>list of nodes and weights for Gauss-Legendre integration on [-1;1] as returned by <code><a href="statmod.html#topic+gauss.quad">gauss.quad</a></code></p>
</td></tr>
<tr><td><code>X.GL</code></td>
<td>
<p>list of matrices (<code>length(X.GL)=n.legendre</code>) for Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>penalty matrix for the model. Sum of the elements of <code>S.list</code></p>
</td></tr>
<tr><td><code>S.scale</code></td>
<td>
<p>vector of rescaling factors for the penalty matrices</p>
</td></tr>
<tr><td><code>rank.S</code></td>
<td>
<p>rank of the penalty matrix</p>
</td></tr>
<tr><td><code>S.F</code></td>
<td>
<p>balanced penalty matrix as described in section 3.1.2 of (Wood,2016). Sum of the elements of <code>S.F.list</code></p>
</td></tr>
<tr><td><code>U.F</code></td>
<td>
<p>Eigen vectors of S.F, useful for the initial reparameterization to separate penalized ad unpenalized subvectors. Allows stable evaluation of the log determinant of S and its derivatives</p>
</td></tr>
<tr><td><code>S.smf</code></td>
<td>
<p>List of penalty matrices associated with all &quot;smf&quot; calls</p>
</td></tr>
<tr><td><code>S.tensor</code></td>
<td>
<p>List of penalty matrices associated with all &quot;tensor&quot; calls</p>
</td></tr>
<tr><td><code>S.tint</code></td>
<td>
<p>List of penalty matrices associated with all &quot;tint&quot; calls</p>
</td></tr>
<tr><td><code>S.rd</code></td>
<td>
<p>List of penalty matrices associated with all &quot;rd&quot; calls</p>
</td></tr>
<tr><td><code>smooth.name.smf</code></td>
<td>
<p>List of names for the &quot;smf&quot; calls associated with S.smf</p>
</td></tr>
<tr><td><code>smooth.name.tensor</code></td>
<td>
<p>List of names for the &quot;tensor&quot; calls associated with S.tensor</p>
</td></tr>
<tr><td><code>smooth.name.tint</code></td>
<td>
<p>List of names for the &quot;tint&quot; calls associated with S.tint</p>
</td></tr>
<tr><td><code>smooth.name.rd</code></td>
<td>
<p>List of names for the &quot;rd&quot; calls associated with S.rd</p>
</td></tr>
<tr><td><code>S.pen</code></td>
<td>
<p>List of all the rescaled penalty matrices redimensioned to df.tot size. Every element of <code>pen</code> noted <code>pen[[i]]</code> is made from a penalty matrix returned by
<code><a href="#topic+smooth.cons">smooth.cons</a></code> and is multiplied by the factor 
S.scale=norm(X,type=&quot;I&quot;)^2/norm(pen[[i]],type=&quot;I&quot;)</p>
</td></tr>
<tr><td><code>S.list</code></td>
<td>
<p>Equivalent to S.pen but with every element multiplied by its associated smoothing parameter</p>
</td></tr>
<tr><td><code>S.F.list</code></td>
<td>
<p>Equivalent to S.pen but with every element divided by its Frobenius norm</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>vector of smoothing parameters</p>
</td></tr>
<tr><td><code>df.para</code></td>
<td>
<p>degrees of freedom associated with fully parametric terms (unpenalized)</p>
</td></tr>
<tr><td><code>df.smooth</code></td>
<td>
<p>degrees of freedom associated with penalized terms</p>
</td></tr>
<tr><td><code>df.tot</code></td>
<td>
<p><code>df.para + df.smooth</code></p>
</td></tr>
<tr><td><code>list.smf</code></td>
<td>
<p>List of all <code>smf.smooth.spec</code> objects contained in the model</p>
</td></tr>
<tr><td><code>list.tensor</code></td>
<td>
<p>List of all <code>tensor.smooth.spec</code> objects contained in the model</p>
</td></tr>
<tr><td><code>list.tint</code></td>
<td>
<p>List of all <code>tint.smooth.spec</code> objects contained in the model</p>
</td></tr>
<tr><td><code>nb.smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code>Z.smf</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraints to apply for <code><a href="#topic+smf">smf</a></code> splines</p>
</td></tr>
<tr><td><code>Z.tensor</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraints to apply for <code><a href="#topic+tensor">tensor</a></code> splines</p>
</td></tr>
<tr><td><code>Z.tint</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraints to apply for <code><a href="#topic+tint">tint</a></code> splines</p>
</td></tr>
<tr><td><code>beta.ini</code></td>
<td>
<p>initial set of regression parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots

data &lt;- data.frame(time=seq(0,5,length=100),event=1,t0=0)

form &lt;- ~ smf(time,knots=c(0,1,3,5))

t1 &lt;- eval(substitute(time), data)
t0 &lt;- eval(substitute(t0), data)
event &lt;- eval(substitute(event), data)

# The following code sets up everything we need in order to fit the model
model.c &lt;- model.cons(form,lambda=0,data.spec=data,t1=t1,t1.name="time",
t0=rep(0,100),t0.name="t0",event=event,event.name="event",
expected=rep(0,100),expected.name=NULL,type="overall",n.legendre=20,
cl="survPen(form,data,t1=time,event=event)",beta.ini=NULL)

</code></pre>

<hr>
<h2 id='NR.beta'>Inner Newton-Raphson algorithm for regression parameters estimation</h2><span id='topic+NR.beta'></span>

<h3>Description</h3>

<p>Applies Newton-Raphson algorithm for beta estimation. Two specific modifications aims at guaranteeing
convergence : first the hessian is perturbed whenever it is not positive definite and second, at each step, if the penalized
log-likelihood is not maximized, the step is halved until it is.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NR.beta(build, beta.ini, detail.beta, max.it.beta = 200, tol.beta = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NR.beta_+3A_build">build</code></td>
<td>
<p>list of objects returned by <code><a href="#topic+model.cons">model.cons</a></code></p>
</td></tr>
<tr><td><code id="NR.beta_+3A_beta.ini">beta.ini</code></td>
<td>
<p>vector of initial regression parameters; default is NULL, in which case the first beta will be <code>log(sum(event)/sum(t1))</code> and the others will be zero (except if there are &quot;by&quot; variables or if there is a piecewise constant hazard specification in which cases all betas are set to zero)</p>
</td></tr>
<tr><td><code id="NR.beta_+3A_detail.beta">detail.beta</code></td>
<td>
<p>if TRUE, details concerning the optimization process in the regression parameters are displayed; default is FALSE</p>
</td></tr>
<tr><td><code id="NR.beta_+3A_max.it.beta">max.it.beta</code></td>
<td>
<p>maximum number of iterations to reach convergence in the regression parameters; default is 200</p>
</td></tr>
<tr><td><code id="NR.beta_+3A_tol.beta">tol.beta</code></td>
<td>
<p>convergence tolerance for regression parameters; default is <code>1e-04</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If we note <code>ll.pen</code> and <code>beta</code> respectively the current penalized log-likelihood and estimated parameters and
<code>ll.pen.old</code> and <code>betaold</code> the previous ones, the algorithm goes on while
(abs(ll.pen-ll.pen.old)&gt;tol.beta) or any(abs((beta-betaold)/betaold)&gt;tol.beta)
</p>


<h3>Value</h3>

<p>List of objects:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>estimated regression parameters</p>
</td></tr>
<tr><td><code>ll.unpen</code></td>
<td>
<p>log-likelihood at convergence</p>
</td></tr>
<tr><td><code>ll.pen</code></td>
<td>
<p>penalized log-likelihood at convergence</p>
</td></tr>
<tr><td><code>iter.beta</code></td>
<td>
<p>number of iterations needed to converge</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots

data &lt;- data.frame(time=seq(0,5,length=100),event=1,t0=0)

form &lt;- ~ smf(time,knots=c(0,1,3,5))

t1 &lt;- eval(substitute(time), data)
t0 &lt;- eval(substitute(t0), data)
event &lt;- eval(substitute(event), data)
	
# Setting up the model before fitting
model.c &lt;- model.cons(form,lambda=0,data.spec=data,t1=t1,t1.name="time",
t0=rep(0,100),t0.name="t0",event=event,event.name="event",
expected=rep(0,100),expected.name=NULL,type="overall",n.legendre=20,
cl="survPen(form,data,t1=time,event=event)",beta.ini=NULL)
 
# Estimating the regression parameters at given smoothing parameter (here lambda=0)
Newton1 &lt;- NR.beta(model.c,beta.ini=rep(0,4),detail.beta=TRUE)

</code></pre>

<hr>
<h2 id='NR.rho'>Outer Newton-Raphson algorithm for smoothing parameters estimation via LCV or LAML optimization</h2><span id='topic+NR.rho'></span>

<h3>Description</h3>

<p>Applies Newton-Raphson algorithm for smoothing parameters estimation. Two specific modifications aims at guaranteeing
convergence : first the hessian is perturbed whenever it is not positive definite and second, at each step, if LCV or -LAML
is not minimized, the step is halved until it is.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NR.rho(
  build,
  rho.ini,
  data,
  formula,
  max.it.beta = 200,
  max.it.rho = 30,
  beta.ini = NULL,
  detail.rho = FALSE,
  detail.beta = FALSE,
  nb.smooth,
  tol.beta = 1e-04,
  tol.rho = 1e-04,
  step.max = 5,
  method = "LAML"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NR.rho_+3A_build">build</code></td>
<td>
<p>list of objects returned by <code><a href="#topic+model.cons">model.cons</a></code></p>
</td></tr>
<tr><td><code id="NR.rho_+3A_rho.ini">rho.ini</code></td>
<td>
<p>vector of initial log smoothing parameters; if it is NULL, all log lambda are set to -1</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_formula">formula</code></td>
<td>
<p>formula object specifying the model</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_max.it.beta">max.it.beta</code></td>
<td>
<p>maximum number of iterations to reach convergence in the regression parameters; default is 200</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_max.it.rho">max.it.rho</code></td>
<td>
<p>maximum number of iterations to reach convergence in the smoothing parameters; default is 30</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_beta.ini">beta.ini</code></td>
<td>
<p>vector of initial regression parameters; default is NULL, in which case the first beta will be <code>log(sum(event)/sum(t1))</code> and the others will be zero (except if there are &quot;by&quot; variables or if there is a piecewise constant hazard specification in which cases all betas are set to zero)</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_detail.rho">detail.rho</code></td>
<td>
<p>if TRUE, details concerning the optimization process in the smoothing parameters are displayed; default is FALSE</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_detail.beta">detail.beta</code></td>
<td>
<p>if TRUE, details concerning the optimization process in the regression parameters are displayed; default is FALSE</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_nb.smooth">nb.smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_tol.beta">tol.beta</code></td>
<td>
<p>convergence tolerance for regression parameters; default is <code>1e-04</code></p>
</td></tr>
<tr><td><code id="NR.rho_+3A_tol.rho">tol.rho</code></td>
<td>
<p>convergence tolerance for smoothing parameters; default is <code>1e-04</code></p>
</td></tr>
<tr><td><code id="NR.rho_+3A_step.max">step.max</code></td>
<td>
<p>maximum absolute value possible for any component of the step vector (on the log smoothing parameter scale); default is 5</p>
</td></tr>
<tr><td><code id="NR.rho_+3A_method">method</code></td>
<td>
<p>LCV or LAML; default is LAML</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If we note <code>val</code> the current LCV or LAML value,
<code>val.old</code> the previous one and <code>grad</code> the gradient vector of LCV or LAML with respect to the log smoothing parameters, the algorithm goes on
<code>while(abs(val-val.old)&gt;tol.rho|any(abs(grad)&gt;tol.rho))</code>
</p>


<h3>Value</h3>

<p>object of class survPen (see <code><a href="#topic+survPen.fit">survPen.fit</a></code> for details)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots

data &lt;- data.frame(time=seq(0,5,length=100),event=1,t0=0)

form &lt;- ~ smf(time,knots=c(0,1,3,5))

t1 &lt;- eval(substitute(time), data)
t0 &lt;- eval(substitute(t0), data)
event &lt;- eval(substitute(event), data)
	
# Setting up the model before fitting
model.c &lt;- model.cons(form,lambda=0,data.spec=data,t1=t1,t1.name="time",
t0=rep(0,100),t0.name="t0",event=event,event.name="event",
expected=0,expected.name=NULL,type="overall",n.legendre=20,
cl="survPen(form,data,t1=time,event=event)",beta.ini=NULL)
 
# Estimating the smoothing parameter and the regression parameters
# we need to apply a reparameterization to model.c before fitting
constructor &lt;- repam(model.c)$build # model constructor
constructor$optim.rho &lt;- 1 # we tell it we want to estimate the log smoothing parameters (rho)
Newton2 &lt;- NR.rho(constructor,rho.ini=-1,data,form,nb.smooth=1,detail.rho=TRUE)

</code></pre>

<hr>
<h2 id='predict.survPen'>Hazard and Survival prediction from fitted <code>survPen</code> model</h2><span id='topic+predict.survPen'></span>

<h3>Description</h3>

<p>Takes a fitted <code>survPen</code> object and produces hazard and survival predictions given a new set of values for the model covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'survPen'
predict(
  object,
  newdata,
  newdata.ref = NULL,
  n.legendre = 50,
  conf.int = 0.95,
  do.surv = TRUE,
  type = "standard",
  exclude.random = FALSE,
  get.deriv.H = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.survPen_+3A_object">object</code></td>
<td>
<p>a fitted <code>survPen</code> object as produced by <code><a href="#topic+survPen.fit">survPen.fit</a></code></p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_newdata">newdata</code></td>
<td>
<p>data frame giving the new covariates value</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_newdata.ref">newdata.ref</code></td>
<td>
<p>data frame giving the new covariates value for the reference population (used only when type=&quot;HR&quot;)</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_n.legendre">n.legendre</code></td>
<td>
<p>number of nodes to approximate the cumulative hazard by Gauss-Legendre quadrature; default is 50</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_conf.int">conf.int</code></td>
<td>
<p>numeric value giving the precision of the confidence intervals; default is 0.95</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_do.surv">do.surv</code></td>
<td>
<p>If TRUE (the default), the survival (or cumulative ratio for type='mult') and its lower and upper confidence values are computed. Survival computation requires numerical integration and can be time-consuming so if you only want the hazard use do.surv=FALSE; default is TRUE</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_type">type</code></td>
<td>
<p>if type=&quot;lpmatrix&quot; returns the design matrix (or linear predictor matrix) corresponding to the new values of the covariates; if equals &quot;HR&quot;, returns the predicted HR and survival difference (with CIs) between newdata and newdata.ref; default is &quot;standard&quot; for classical hazard and survival estimation</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_exclude.random">exclude.random</code></td>
<td>
<p>if TRUE all random effects are set to zero; default is FALSE</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_get.deriv.h">get.deriv.H</code></td>
<td>
<p>if TRUE, the derivatives wrt to the regression parameters of the cumulative hazard are returned; default is FALSE</p>
</td></tr>
<tr><td><code id="predict.survPen_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence intervals noted CI.U are built on the log cumulative hazard scale U=log(H) (efficient scale in terms of respect towards the normality assumption)
using Delta method. The confidence intervals on the survival scale are then <code>CI.surv = exp(-exp(CI.U))</code>
</p>


<h3>Value</h3>

<p>List of objects:
</p>
<table role = "presentation">
<tr><td><code>haz</code></td>
<td>
<p>hazard predicted by the model</p>
</td></tr>
<tr><td><code>haz.inf</code></td>
<td>
<p>lower value for the confidence interval of the hazard based on the Bayesian covariance matrix Vp (Wood et al. 2016)</p>
</td></tr>
<tr><td><code>haz.sup</code></td>
<td>
<p>Upper value for the confidence interval of the hazard based on the Bayesian covariance matrix Vp</p>
</td></tr>
<tr><td><code>surv</code></td>
<td>
<p>survival predicted by the model</p>
</td></tr>
<tr><td><code>surv.inf</code></td>
<td>
<p>lower value for the confidence interval of the survival based on the Bayesian covariance matrix Vp</p>
</td></tr>
<tr><td><code>surv.sup</code></td>
<td>
<p>Upper value for the confidence interval of the survival based on the Bayesian covariance matrix Vp</p>
</td></tr>
<tr><td><code>deriv.H</code></td>
<td>
<p>derivatives wrt to the regression parameters of the cumulative hazard. Useful to calculate standardized survival</p>
</td></tr>
<tr><td><code>HR</code></td>
<td>
<p>predicted hazard ratio ; only when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>HR.inf</code></td>
<td>
<p>lower value for the confidence interval of the hazard ratio based on the Bayesian covariance matrix Vp  ; only when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>HR.sup</code></td>
<td>
<p>Upper value for the confidence interval of the hazard ratio based on the Bayesian covariance matrix Vp  ; only when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>surv.diff</code></td>
<td>
<p>predicted relative difference ; only when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>surv.diff.inf</code></td>
<td>
<p>lower value for the confidence interval of the survival difference based on the Bayesian covariance matrix Vp  ; only when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>surv.diff.sup</code></td>
<td>
<p>Upper value for the confidence interval of the survival difference based on the Bayesian covariance matrix Vp  ; only when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>ratio</code></td>
<td>
<p>relative mortality ratio predicted by the model ; only for relative mortality ratio model (type=&quot;mult&quot;)</p>
</td></tr>
<tr><td><code>ratio.inf</code></td>
<td>
<p>lower value for the confidence interval of the relative mortality ratio based on the Bayesian covariance matrix Vp (Wood et al. 2016); only for relative mortality ratio model (type=&quot;mult&quot;)</p>
</td></tr>
<tr><td><code>ratio.sup</code></td>
<td>
<p>Upper value for the confidence interval of the relative mortality ratio on the Bayesian covariance matrix Vp; only for relative mortality ratio model (type=&quot;mult&quot;)</p>
</td></tr>
<tr><td><code>cumul.ratio</code></td>
<td>
<p>cumulative relative mortality ratio predicted by the model ; only for relative mortality ratio model (type=&quot;mult&quot;)</p>
</td></tr>
<tr><td><code>cumul.ratio.inf</code></td>
<td>
<p>lower value for the confidence interval of the cumulative relative mortality ratio based on the Bayesian covariance matrix Vp (Wood et al. 2016); only for relative mortality ratio model (type=&quot;mult&quot;)</p>
</td></tr>
<tr><td><code>cumul.ratio.sup</code></td>
<td>
<p>Upper value for the confidence interval of the cumulative relative mortality ratio on the Bayesian covariance matrix Vp; only for relative mortality ratio model (type=&quot;mult&quot;)</p>
</td></tr>
<tr><td><code>RR</code></td>
<td>
<p>predicted ratio of relative mortality ratios ; only for relative mortality ratio model when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>RR.inf</code></td>
<td>
<p>lower value for the confidence interval of the ratio of relative mortality ratios based on the Bayesian covariance matrix Vp  ; only for relative mortality ratio model when type = &quot;HR&quot;</p>
</td></tr>
<tr><td><code>RR.sup</code></td>
<td>
<p>Upper value for the confidence interval of the ratio of relative mortality ratios based on the Bayesian covariance matrix Vp  ; only for relative mortality ratio model when type = &quot;HR&quot;</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wood, S.N., Pya, N. and Saefken, B. (2016), Smoothing parameter and model selection for general smooth models (with discussion). Journal of the American Statistical Association 111, 1548-1575
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)
data(datCancer) # simulated dataset with 2000 individuals diagnosed with cervical cancer

f1 &lt;- ~tensor(fu,age,df=c(5,5))

# hazard model
mod1 &lt;- survPen(f1,data=datCancer,t1=fu,event=dead,expected=NULL,method="LAML")

# predicting hazard and survival curves for age 60
nt &lt;- seq(0,5,le=50)
pred &lt;- predict(mod1,data.frame(fu=nt,age=60))
pred$haz
pred$surv

# predicting hazard ratio at 1 year according to age (with reference age of 50)
newdata1 &lt;- data.frame(fu=1,age=seq(30,90,by=1))
newdata.ref1 &lt;- data.frame(fu=1,age=rep(50,times=61))
predHR_1 &lt;- predict(mod1,newdata=newdata1,newdata.ref=newdata.ref1,type="HR")
predHR_1$HR
predHR_1$HR.inf
predHR_1$HR.sup

# predicting hazard ratio at 3 years according to age (with reference age of 50)
# and difference of survival at 3 years
newdata3 &lt;- data.frame(fu=3,age=seq(30,90,by=1))
newdata.ref3 &lt;- data.frame(fu=3,age=rep(50,times=61))
predHR_3 &lt;- predict(mod1,newdata=newdata3,newdata.ref=newdata.ref3,type="HR")

# Hazard ratio
predHR_3$HR
predHR_3$HR.inf
predHR_3$HR.sup


# Difference of survival
predHR_3$diff.surv
predHR_3$diff.surv.inf
predHR_3$diff.surv.sup

</code></pre>

<hr>
<h2 id='predSNS'>Prediction of grouped indicators : population (net) survival (PNS) and age-standardized (net) survival (SNS)</h2><span id='topic+predSNS'></span>

<h3>Description</h3>

<p>Allows the prediction of population and age-standardized (net) survival as well as associated confidence intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predSNS(
  model,
  time.points,
  newdata,
  weight.table,
  var.name,
  var.model,
  conf.int = 0.95,
  method = "exact",
  n.legendre = 50
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predSNS_+3A_model">model</code></td>
<td>
<p>a fitted <code>survPen</code> model</p>
</td></tr>
<tr><td><code id="predSNS_+3A_time.points">time.points</code></td>
<td>
<p>vector of follow-up values</p>
</td></tr>
<tr><td><code id="predSNS_+3A_newdata">newdata</code></td>
<td>
<p>dataset containing the original age values used for fitting</p>
</td></tr>
<tr><td><code id="predSNS_+3A_weight.table">weight.table</code></td>
<td>
<p>dataset containing the age classes used for standardization, must be in the same format as the elements of the following list <code><a href="#topic+list.wicss">list.wicss</a></code></p>
</td></tr>
<tr><td><code id="predSNS_+3A_var.name">var.name</code></td>
<td>
<p>list containing one element : the column name in newdata that reports age values. This element should be named after the age variable present in the model formula. Typically, if newdata contains an 'age' column while the model uses a centered age 'agec', the list should be: list(agec=&quot;age&quot;)</p>
</td></tr>
<tr><td><code id="predSNS_+3A_var.model">var.model</code></td>
<td>
<p>list containing one element : the function that allows retrieving the age variable used in model formula from original age. Typically for age centered on 50, list(agec=function(age) age - 50)</p>
</td></tr>
<tr><td><code id="predSNS_+3A_conf.int">conf.int</code></td>
<td>
<p>numeric value giving the precision of the confidence intervals; default is 0.95</p>
</td></tr>
<tr><td><code id="predSNS_+3A_method">method</code></td>
<td>
<p>should be either 'exact' or 'approx'. The 'exact' method uses all age values in newdata for predictions. The 'approx' method uses either newdata$age (if age values are whole numbers) or floor(newdata$age) + 0.5 (if age values are not whole numbers) and then removes duplicates to reduce computational cost.</p>
</td></tr>
<tr><td><code id="predSNS_+3A_n.legendre">n.legendre</code></td>
<td>
<p>number of nodes to approximate the cumulative hazard by Gauss-Legendre quadrature; default is 50</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weight table used should always be in the same format as elements of <code><a href="#topic+list.wicss">list.wicss</a></code>.
Only age-standardization is possible for now. All other variables necessary for model predictions should be fixed to a single value.
For simplicity, in what follows we will consider that survival only depends on time and age.
</p>


<h3>Value</h3>

<p>List of nine elements
</p>
<table role = "presentation">
<tr><td><code>class.table</code></td>
<td>
<p>Number of individuals in each age class</p>
</td></tr>
<tr><td><code>SNS</code></td>
<td>
<p>Vector of predicted age-standardized (net) survival</p>
</td></tr>
<tr><td><code>SNS.inf</code></td>
<td>
<p>Lower bound of confidence intervals associated with predicted age-standardized (net) survival</p>
</td></tr>
<tr><td><code>SNS.sup</code></td>
<td>
<p>Upper bound of confidence intervals associated with predicted age-standardized (net) survival</p>
</td></tr>
<tr><td><code>PNS</code></td>
<td>
<p>Vector of predicted population (net) survival</p>
</td></tr>
<tr><td><code>PNS.inf</code></td>
<td>
<p>Lower bound of confidence intervals associated with predicted population (net) survival</p>
</td></tr>
<tr><td><code>PNS.sup</code></td>
<td>
<p>Upper bound of confidence intervals associated with predicted population (net) survival</p>
</td></tr>
<tr><td><code>PNS_per_class</code></td>
<td>
<p>matrix of predicted population (net) survival in each age class</p>
</td></tr>
<tr><td><code>PNS_per_class.inf</code></td>
<td>
<p>Lower bound of confidence intervals associated with predicted population (net) survival in each age class</p>
</td></tr>
<tr><td><code>PNS_per_class.sup</code></td>
<td>
<p>Upper bound of confidence intervals associated with predicted population (net) survival in each age class</p>
</td></tr>
</table>


<h3>Population Net Survival (PNS)</h3>

<p>For a given group of individuals, PNS at time t is defined as
</p>
<p style="text-align: center;"><code class="reqn">PNS(t)=\sum_i 1/n*S_i(t,a_i)</code>
</p>

<p>where <code class="reqn">a_i</code> is the age of individual <code class="reqn">i</code>
</p>


<h3>Standardized Net Survival (SNS)</h3>

<p>SNS at time t is defined as
</p>
<p style="text-align: center;"><code class="reqn">SNS(t)=\sum_i w_i*S_i(t,a_i)</code>
</p>

<p>where <code class="reqn">a_i</code> is the age of individual <code class="reqn">i</code> and <code class="reqn">w_i=w_{ref j(i)}/n_{j(i)}</code>.
<code class="reqn">w_{ref j(i)}</code> is the weigth of age class <code class="reqn">j</code> in the reference population (it corresponds to weight.table$AgeWeights).
Where <code class="reqn">n_{j(i)}</code> is the total number of individuals present in age class <code class="reqn">j(i)</code>: the age class of individual <code class="reqn">i</code>.
</p>


<h3>Standardized Net Survival (SNS) with method=&quot;approx&quot;</h3>

<p>For large datasets, SNS calculation is quite heavy. To reduce computational cost, the idea is to regroup individuals who have similar age values. By using floor(age) + 0.5 instead of age, the gain will be substantial while the prediction error will be minimal (method=&quot;approx&quot; will give slightly different predictions compared to method=&quot;exact&quot;).
Of course, if the provided age values are whole numbers then said provided age values will be used directly for grouping and there will be no prediction error (method=&quot;approx&quot; and method=&quot;exact&quot; will give the exact same predictions). 
</p>
<p style="text-align: center;"><code class="reqn">SNS(t)=\sum_a \tilde{w}_a*S(t,a)</code>
</p>

<p>The sum is here calculated over all possible values of age instead of all individuals.
We have <code class="reqn">\tilde{w}_a=n_a*w_{ref j(a)}/n_{j(a)}</code>.
Where <code class="reqn">j(a)</code> is the age class of age <code class="reqn">a</code> while <code class="reqn">n_a</code> is the number of individuals with age <code class="reqn">a</code>.
</p>


<h3>Variance and Confidence Intervals</h3>

<p>Confidence intervals for SNS are derived assuming normality of log(log(-SNS)) 
Lower and upper bound are given by
</p>
<p style="text-align: center;"><code class="reqn">IC_{95\%}(SNS)=[SNS^{1.96*\sqrt(Var(Log(Delta_{SNS})))};SNS^{-1.96*\sqrt(Var(Log(Delta_{SNS})))}]</code>
</p>

<p>with 
</p>
<p style="text-align: center;"><code class="reqn">Delta_{SNS}=-log(SNS)</code>
</p>

<p><code class="reqn">Var(Log(Delta_{SNS}))</code> is derived by Delta method.
</p>
<p>Confidence intervals for PNS are derived in the exact same way.
</p>


<h3>References</h3>

<p>Corazziari, I., Quinn, M., &amp; Capocaccia, R. (2004). Standard cancer patient population for age standardising survival ratios. European journal of cancer (Oxford, England : 1990), 40(15), 23072316. https://doi.org/10.1016/j.ejca.2004.07.002. <br /> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(datCancer)
data(list.wicss)

don &lt;- datCancer
don$agec &lt;- don$age - 50 # using centered age for modelling

#-------------------- model with time and age

knots.t&lt;-quantile(don$fu[don$dead==1],probs=seq(0,1,length=6)) # knots for time
knots.agec&lt;-quantile(don$agec[don$dead==1],probs=seq(0,1,length=5))   # knots for age

formula &lt;- as.formula(~tensor(fu,agec,df=c(length(knots.t),length(knots.agec)),
knots=list(fu=knots.t,age=knots.agec)))

mod &lt;- survPen(formula,data=don,t1=fu,event=dead,n.legendre=20, expected=rate)


#-------------------- Age classes and associated weights for age-standardized 
# net survival prediction
		
# weights of type 1					
wicss &lt;- list.wicss[["1"]]					
				
# to estimate population net survival, prediction dataframe
# is needed. It should contain original data for age 

pred.pop &lt;- data.frame(age=don$age)

#-------------------- prediction : age-standardized net survival and population net survival

pred &lt;- predSNS(mod,time.points=seq(0,5,by=0.1),newdata=pred.pop,
weight.table=wicss,var.name=list(agec="age"),
var.model=list(agec=function(age) age - 50),method="approx")



</code></pre>

<hr>
<h2 id='print.summary.survPen'>print summary for a <code>survPen</code> fit</h2><span id='topic+print.summary.survPen'></span>

<h3>Description</h3>

<p>print summary for a <code>survPen</code> fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.survPen'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  signif.stars = getOption("show.signif.stars"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summary.survPen_+3A_x">x</code></td>
<td>
<p>an object of class <code>summary.survPen</code></p>
</td></tr>
<tr><td><code id="print.summary.survPen_+3A_digits">digits</code></td>
<td>
<p>controls number of digits printed in output.</p>
</td></tr>
<tr><td><code id="print.summary.survPen_+3A_signif.stars">signif.stars</code></td>
<td>
<p>Should significance stars be printed alongside output.</p>
</td></tr>
<tr><td><code id="print.summary.survPen_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>print of summary
</p>

<hr>
<h2 id='pwcst'>Defining piecewise constant (excess) hazard in survPen formulae</h2><span id='topic+pwcst'></span>

<h3>Description</h3>

<p>Used inside a formula object to define a piecewise constant (excess) hazard. This is useful since it triggers an 
explicit calculation of cumulative hazard calculation (much more efficient and more precise than Gauss-Legendre
quadrature when hazard is constant).
The breaks given are used to defined sub-intervals that are left-open (except the first interval which is always 
left-closed) and right-closed. Internally, this constructor uses the cut function on the follow-up time with options 
include.lowest=TRUE and right=TRUE
Important : this function must not be used with other time-dependent effect functions because the Gauss-Legendre quadrature
will not operate correctly. If you really want to fit such a model, please use the cut function with the time variable as
an argument to fit a piecewise constant hazard (and do not forget to use a huge number of Gauss-Legendre quadrature nodes,
typically n.legendre=500)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwcst(breaks)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pwcst_+3A_breaks">breaks</code></td>
<td>
<p>numeric vector that specifies the boundaries of each sub-interval on which the hazard is constant</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>pwcst.spec</code>
</p>
<table role = "presentation">
<tr><td><code>pwcst.breaks</code></td>
<td>
<p>numeric vector that specifies the boundaries of each sub-interval on which the hazard is constant</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(survPen)

data(datCancer)

# piece constant hazard on 6 sub-intervals : [0;0.5]; ]0.5;1]; ]1;2]; ]2;3]; ]3;4]; ]4;5]
formula &lt;- ~pwcst(breaks=c(0,0.5,1,2,3,4,5))
mod &lt;- survPen(formula,t1=fu,event=dead,data=datCancer)

# The same but in an inefficient way
formula2 &lt;- ~cut(fu,breaks=c(0,0.5,1,2,3,4,5),include.lowest=TRUE,right=TRUE)
mod.inefficient &lt;- survPen(formula2,t1=fu,event=dead,data=datCancer,n.legendre=500)

</code></pre>

<hr>
<h2 id='rd'>Defining random effects in survPen formulae</h2><span id='topic+rd'></span>

<h3>Description</h3>

<p>Used inside a formula object to define a random effect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rd(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rd_+3A_...">...</code></td>
<td>
<p>Any number of covariates separated by &quot;,&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>rd.smooth.spec</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># cubic regression spline of time with 10 unspecified knots + random effect at the cluster level
formula.test &lt;- ~smf(time,df=10) + rd(cluster)


</code></pre>

<hr>
<h2 id='repam'>Applies initial reparameterization for stable evaluation of the log determinant of the penalty matrix</h2><span id='topic+repam'></span>

<h3>Description</h3>

<p>Transforms the object from <code><a href="#topic+model.cons">model.cons</a></code> by applying the matrix reparameterization (matrix U.F). The reparameterization
is reversed at convergence by <code><a href="#topic+inv.repam">inv.repam</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repam(build)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="repam_+3A_build">build</code></td>
<td>
<p>object as returned by <code><a href="#topic+model.cons">model.cons</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>build</code></td>
<td>
<p>an object as returned by <code><a href="#topic+model.cons">model.cons</a></code></p>
</td></tr>
<tr><td><code>X.ini</code></td>
<td>
<p>initial design matrix (before reparameterization)</p>
</td></tr>
<tr><td><code>S.pen.ini</code></td>
<td>
<p>initial penalty matrices</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots

data &lt;- data.frame(time=seq(0,5,length=100),event=1,t0=0)

form &lt;- ~ smf(time,knots=c(0,1,3,5))

t1 &lt;- eval(substitute(time), data)
t0 &lt;- eval(substitute(t0), data)
event &lt;- eval(substitute(event), data)
	
# Setting up the model before fitting
model.c &lt;- model.cons(form,lambda=0,data.spec=data,t1=t1,t1.name="time",
t0=rep(0,100),t0.name="t0",event=event,event.name="event",
expected=rep(0,100),expected.name=NULL,type="overall",n.legendre=20,
cl="survPen(form,data,t1=time,event=event)",beta.ini=NULL)
 
# Reparameterization allows separating the parameters into unpenalized and 
# penalized ones for maximum numerical stability
re.model.c &lt;- repam(model.c)

</code></pre>

<hr>
<h2 id='robust.var'>Implementation of the robust variance Vr</h2><span id='topic+robust.var'></span>

<h3>Description</h3>

<p>Takes the model at convergence and calculates the robust variance matrix accounting for correlated survival times
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robust.var(model, data, cluster.name, n.legendre = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="robust.var_+3A_model">model</code></td>
<td>
<p>survPen object, see <code><a href="#topic+survPen.fit">survPen.fit</a></code> for details</p>
</td></tr>
<tr><td><code id="robust.var_+3A_data">data</code></td>
<td>
<p>original dataset</p>
</td></tr>
<tr><td><code id="robust.var_+3A_cluster.name">cluster.name</code></td>
<td>
<p>name of cluster variable in data</p>
</td></tr>
<tr><td><code id="robust.var_+3A_n.legendre">n.legendre</code></td>
<td>
<p>number of nodes for Gauss-Legendre quadrature; default is 50</p>
</td></tr>
</table>


<h3>Value</h3>

<p>survPen object with robust variance Vr
</p>

<hr>
<h2 id='smf'>Defining smooths in survPen formulae</h2><span id='topic+smf'></span><span id='topic+tensor'></span><span id='topic+tint'></span>

<h3>Description</h3>

<p>Used inside a formula object to define a smooth, a tensor product smooth or a tensor product interaction. 
Natural cubic regression splines (linear beyond the knots, equivalent to <code>ns</code> from package <code>splines</code>) are used as marginal bases. While <code>tensor</code> builds a tensor product of marginal bases including 
the intercepts, <code>tint</code> applies a tensor product of the marginal bases without their intercepts.
Unlike <code>tensor</code>, the marginal effects of the covariates should also be present in the formula when using <code>tint</code>.
For a conceptual difference between tensor products and tensor product interactions see Section 5.6.3 from Wood (2017)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smf(..., knots = NULL, df = NULL, by = NULL, same.rho = FALSE)

tensor(..., knots = NULL, df = NULL, by = NULL, same.rho = FALSE)

tint(..., knots = NULL, df = NULL, by = NULL, same.rho = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smf_+3A_...">...</code></td>
<td>
<p>Any number of covariates separated by &quot;,&quot;</p>
</td></tr>
<tr><td><code id="smf_+3A_knots">knots</code></td>
<td>
<p>numeric vector that specifies the knots of the splines (including boundaries); default is NULL, in which case the knots are spread through the covariate values using quantiles. Precisely, for the term &quot;smf(x,df=df1)&quot;, the vector of knots will be: quantile(unique(x),seq(0,1,length=df1))</p>
</td></tr>
<tr><td><code id="smf_+3A_df">df</code></td>
<td>
<p>numeric value that indicates the number of knots (or degrees of freedom) desired; default is NULL. If knots and df are NULL, df will be set to 10</p>
</td></tr>
<tr><td><code id="smf_+3A_by">by</code></td>
<td>
<p>numeric or factor variable in order to define a varying coefficient smooth</p>
</td></tr>
<tr><td><code id="smf_+3A_same.rho">same.rho</code></td>
<td>
<p>if the specified by variable is a factor, specifies whether the smoothing parameters should be the same for all levels; default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>smf.smooth.spec</code>, <code>tensor.smooth.spec</code> or <code>tint.smooth.spec</code>  (see <code><a href="#topic+smooth.spec">smooth.spec</a></code> for details)
</p>


<h3>References</h3>

<p>Wood, S. N. (2017), Generalized additive models: an introduction with R. Second Edition. London: Chapman &amp; Hall/CRC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># penalized cubic regression spline of time with 5 unspecified knots
formula.test &lt;- ~smf(time,df=5)

# suppose that we want to fit a model from formula.test
library(survPen)
data(datCancer)

mod.test &lt;- survPen(~smf(fu,df=5) ,data=datCancer,t1=fu,event=dead)

# then the knots can be retrieved like this:
mod.test$list.smf[[1]]$knots
# or calculated like this
quantile(unique(datCancer$fu),seq(0,1,length=5))


# penalized cubic regression splines of time and age with respectively 5 and 7 unspecified knots
formula.test2 &lt;- ~smf(time,df=5)+smf(age,df=7)

# penalized cubic regression splines of time and age with respectively 3 and 4 specified knots
formula.test3 &lt;- ~smf(time,knots=c(0,3,5))+smf(age,knots=c(30,50,70,90))

# penalized tensor product for time and age with respectively 5 and 4 unspecified knots leading
# to 5*4 = 20 regression parameters
formula.test &lt;- ~tensor(time,age,df=c(5,4))

# penalized tensor product for time and age with respectively 3 and 4 specified knots
formula.test3 &lt;- ~tensor(time,agec,knots=list(c(0,3,5),c(30,50,70,90)))

# penalized tensor product for time, age and year with respectively 6, 5 and 4 unspecified knots
formula.test &lt;- ~tensor(time,age,year,df=c(6,5,4))

# penalized tensor product interaction for time and age with respectively 5 and 4 unspecified knots
# main effects are specified as penalized cubic regression splines
formula.test &lt;- ~smf(time,df=5)+smf(age,df=4)+tint(time,age,df=c(5,4))

</code></pre>

<hr>
<h2 id='smooth.cons'>Design and penalty matrices of penalized splines in a smooth.spec object</h2><span id='topic+smooth.cons'></span>

<h3>Description</h3>

<p>Builds the design and penalty matrices from the result of <code><a href="#topic+smooth.spec">smooth.spec</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth.cons(
  term,
  knots,
  df,
  by = NULL,
  option,
  data.spec,
  same.rho = FALSE,
  name
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smooth.cons_+3A_term">term</code></td>
<td>
<p>Vector of strings that generally comes from the value &quot;term&quot; of a <code>smooth.spec</code> object.</p>
</td></tr>
<tr><td><code id="smooth.cons_+3A_knots">knots</code></td>
<td>
<p>List of numeric vectors that specifies the knots of the splines (including boundaries).</p>
</td></tr>
<tr><td><code id="smooth.cons_+3A_df">df</code></td>
<td>
<p>Degrees of freedom: numeric vector that indicates the number of knots desired for each covariate.</p>
</td></tr>
<tr><td><code id="smooth.cons_+3A_by">by</code></td>
<td>
<p>numeric or factor variable in order to define a varying coefficient smooth; default is NULL.</p>
</td></tr>
<tr><td><code id="smooth.cons_+3A_option">option</code></td>
<td>
<p>&quot;smf&quot;, &quot;tensor&quot; or &quot;tint&quot;.</p>
</td></tr>
<tr><td><code id="smooth.cons_+3A_data.spec">data.spec</code></td>
<td>
<p>data frame that represents the environment from which the covariate values and knots are to be calculated; default is NULL.</p>
</td></tr>
<tr><td><code id="smooth.cons_+3A_same.rho">same.rho</code></td>
<td>
<p>if there is a factor by variable, should the smoothing parameters be the same for all levels; default is FALSE.</p>
</td></tr>
<tr><td><code id="smooth.cons_+3A_name">name</code></td>
<td>
<p>simplified name of the smooth.spec call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of objects with the following items:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>Design matrix</p>
</td></tr>
<tr><td><code>pen</code></td>
<td>
<p>List of penalty matrices</p>
</td></tr>
<tr><td><code>term</code></td>
<td>
<p>Vector of strings giving the names of each covariate</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>list of numeric vectors that specifies the knots for each covariate</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Number of covariates</p>
</td></tr>
<tr><td><code>all.df</code></td>
<td>
<p>Numeric vector giving the number of knots associated with each covariate</p>
</td></tr>
<tr><td><code>sum.df</code></td>
<td>
<p>Sum of all.df</p>
</td></tr>
<tr><td><code>Z.smf</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for &quot;smf&quot; splines</p>
</td></tr>
<tr><td><code>Z.tensor</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for &quot;tensor&quot; splines</p>
</td></tr>
<tr><td><code>Z.tint</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for &quot;tint&quot; splines</p>
</td></tr>
<tr><td><code>lambda.name</code></td>
<td>
<p>name of the smoothing parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots (so we get a design matrix with 3 columns 
# because of centering constraint)

data &lt;- data.frame(time=seq(0,5,length=100))
smooth.c &lt;- smooth.cons("time",knots=list(c(0,1,3,5)),df=4,option="smf",
data.spec=data,name="smf(time)")

</code></pre>

<hr>
<h2 id='smooth.cons.integral'>Design matrix of penalized splines in a smooth.spec object for Gauss-Legendre quadrature</h2><span id='topic+smooth.cons.integral'></span>

<h3>Description</h3>

<p>Almost identical to <code><a href="#topic+smooth.cons">smooth.cons</a></code>. This version is dedicated to Gauss-Legendre
quadrature. Here, the sum-to-zero constraints must be specified so that they correspond to the ones that
were calculated with the initial dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth.cons.integral(
  term,
  knots,
  df,
  by = NULL,
  option,
  data.spec,
  Z.smf,
  Z.tensor,
  Z.tint,
  name
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smooth.cons.integral_+3A_term">term</code></td>
<td>
<p>Vector of strings that generally comes from the value &quot;term&quot; of a smooth.spec object</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_knots">knots</code></td>
<td>
<p>List of numeric vectors that specifies the knots of the splines (including boundaries).</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_df">df</code></td>
<td>
<p>Degrees of freedom : numeric vector that indicates the number of knots desired for each covariate.</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_by">by</code></td>
<td>
<p>numeric or factor variable in order to define a varying coefficient smooth; default is NULL.</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_option">option</code></td>
<td>
<p>&quot;smf&quot;, &quot;tensor&quot; or &quot;tint&quot;.</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_data.spec">data.spec</code></td>
<td>
<p>data frame that represents the environment from which the covariate values and knots are to be calculated; default is NULL.</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_z.smf">Z.smf</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+smf">smf</a></code> splines.</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_z.tensor">Z.tensor</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+tensor">tensor</a></code> splines.</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_z.tint">Z.tint</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+tint">tint</a></code> splines.</p>
</td></tr>
<tr><td><code id="smooth.cons.integral_+3A_name">name</code></td>
<td>
<p>simplified name of the smooth.spec call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>design matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots (so we get a design matrix with 3 columns 
# because of centering constraint)

data &lt;- data.frame(time=seq(0,5,length=100))

# retrieving sum-to-zero constraint matrices
Z.smf &lt;- smooth.cons("time",knots=list(c(0,1,3,5)),df=4,option="smf",
data.spec=data,name="smf(time)")$Z.smf

# constructing the design matrices for Gauss-Legendre quadrature
smooth.c.int &lt;- smooth.cons.integral("time",knots=list(c(0,1,3,5)),df=4,option="smf",data.spec=data,
name="smf(time)",Z.smf=Z.smf,Z.tensor=NULL,Z.tint=NULL)

</code></pre>

<hr>
<h2 id='smooth.spec'>Covariates specified as penalized splines</h2><span id='topic+smooth.spec'></span>

<h3>Description</h3>

<p>Specifies the covariates to be considered as penalized splines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smooth.spec(
  ...,
  knots = NULL,
  df = NULL,
  by = NULL,
  option = NULL,
  same.rho = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smooth.spec_+3A_...">...</code></td>
<td>
<p>Numeric vectors specified in <code><a href="#topic+smf">smf</a></code>, <code><a href="#topic+tensor">tensor</a></code> or <code><a href="#topic+tint">tint</a></code></p>
</td></tr>
<tr><td><code id="smooth.spec_+3A_knots">knots</code></td>
<td>
<p>List of numeric vectors that specifies the knots of the splines (including boundaries); default is NULL</p>
</td></tr>
<tr><td><code id="smooth.spec_+3A_df">df</code></td>
<td>
<p>Degrees of freedom: numeric vector that indicates the number of knots desired for each covariate; default is NULL</p>
</td></tr>
<tr><td><code id="smooth.spec_+3A_by">by</code></td>
<td>
<p>numeric or factor variable in order to define a varying coefficient smooth; default is NULL</p>
</td></tr>
<tr><td><code id="smooth.spec_+3A_option">option</code></td>
<td>
<p>&quot;smf&quot;, &quot;tensor&quot; or &quot;tint&quot;. Depends on the wrapper function; default is &quot;smf&quot;</p>
</td></tr>
<tr><td><code id="smooth.spec_+3A_same.rho">same.rho</code></td>
<td>
<p>if there is a factor by variable, should the smoothing parameters be the same for all levels; default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class smooth.spec
</p>
<table role = "presentation">
<tr><td><code>term</code></td>
<td>
<p>Vector of strings giving the names of each covariate specified in ...</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>Numeric value giving the number of covariates associated with this spline</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>list of numeric vectors that specifies the knots for each covariate</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Numeric vector giving the number of knots associated with each covariate</p>
</td></tr>
<tr><td><code>by</code></td>
<td>
<p>numeric or factor variable in order to define a varying coefficient smooth</p>
</td></tr>
<tr><td><code>same.rho</code></td>
<td>
<p>if there is a factor by variable, should the smoothing parameters be the same for all levels; default is FALSE</p>
</td></tr>
<tr><td><code>name</code></td>
<td>
<p>simplified name of the call to function smooth.spec</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 10 unspecified knots
smooth.spec(time)

# tensor of time and age with 5*5 specified knots
smooth.s &lt;- smooth.spec(time,age,knots=list(time=seq(0,5,length=5),age=seq(20,80,length=5)),
option="tensor")

</code></pre>

<hr>
<h2 id='splitmult'>Split original dataset at specified times to fit a multiplicative model</h2><span id='topic+splitmult'></span>

<h3>Description</h3>

<p>This function allows splitting the original dataset in order to retrieve all the expected mortality rates available 
according to each individual's follow-up time. Typically, the expected mortality rates come from national mortality tables
and values are available for every combination of age and year (often with 1-year increment).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitmult(data, cut, start = NULL, end, event)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="splitmult_+3A_data">data</code></td>
<td>
<p>orginal datset</p>
</td></tr>
<tr><td><code id="splitmult_+3A_cut">cut</code></td>
<td>
<p>vector of timepoints to cut at (usually every year of follow-up)</p>
</td></tr>
<tr><td><code id="splitmult_+3A_start">start</code></td>
<td>
<p>character string with name of start variable (will be created and set to zero if it does not exist)</p>
</td></tr>
<tr><td><code id="splitmult_+3A_end">end</code></td>
<td>
<p>character string with name of event time variable</p>
</td></tr>
<tr><td><code id="splitmult_+3A_event">event</code></td>
<td>
<p>character string with name of censoring indicator</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is close to the survsplit function proposed in relsurv package, but it is simpler since fewer features are needed.
</p>


<h3>Value</h3>

<p>split dataset with follow-up time split at specified times. An 'id_row' column is added to identify original row numbers
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survPen)
data(datCancer)
data(expected.table)

#-------------------- creating split dataset for multiplicative model

splitdat &lt;- splitmult(datCancer, cut = (1:5), end = "fu", 
event = "dead")
		
#-------------------- merging with expected mortality table

# deriving current age and year (closest whole number)
splitdat$age_current &lt;- floor(splitdat$age + splitdat$fu + 0.5)

splitdat$year_current &lt;- floor(splitdat$yod + splitdat$fu + 0.5)


splitdat &lt;- merge(splitdat, expected.table, 
                by.x=c("age_current","year_current"), by.y=c("Age","Year"),all.x=TRUE)


</code></pre>

<hr>
<h2 id='summary.survPen'>Summary for a <code>survPen</code> fit</h2><span id='topic+summary.survPen'></span>

<h3>Description</h3>

<p>Takes a fitted <code>survPen</code> object and produces various useful summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'survPen'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.survPen_+3A_object">object</code></td>
<td>
<p>a fitted <code>survPen</code> object as produced by <code><a href="#topic+survPen.fit">survPen.fit</a></code></p>
</td></tr>
<tr><td><code id="summary.survPen_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of objects:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>the original survPen call</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the original survPen formula</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>reports the regression parameters estimates for unpenalized terms with the associated standard errors</p>
</td></tr>
<tr><td><code>HR_TAB</code></td>
<td>
<p>reports the exponential of the regression parameters estimates for unpenalized terms with the associated CI</p>
</td></tr>
<tr><td><code>edf.per.smooth</code></td>
<td>
<p>reports the edf associated with each smooth term</p>
</td></tr>
<tr><td><code>random</code></td>
<td>
<p>TRUE if there are random effects in the model</p>
</td></tr>
<tr><td><code>random.effects</code></td>
<td>
<p>reports the estimates of the log standard deviation (log(sd)) of every random effects plus the estimated standard error (also on the log(sd) scale)</p>
</td></tr>
<tr><td><code>likelihood</code></td>
<td>
<p>unpenalized likelihood of the model</p>
</td></tr>
<tr><td><code>penalized.likelihood</code></td>
<td>
<p>penalized likelihood of the model</p>
</td></tr>
<tr><td><code>nb.smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code>smoothing.parameter</code></td>
<td>
<p>smoothing parameters estimates</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>effective degrees of freedom</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>smoothing selection criterion used (LAML or LCV)</p>
</td></tr>
<tr><td><code>val.criterion</code></td>
<td>
<p>minimized value of criterion. For LAML, what is reported is the negative log marginal likelihood</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>convergence indicator, TRUE or FALSE. TRUE if Hess.beta.modif=FALSE and Hess.rho.modif=FALSE (or NULL)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

data(datCancer) # simulated dataset with 2000 individuals diagnosed with cervical cancer

# model : unidimensional penalized spline for time since diagnosis with 5 knots
f1 &lt;- ~smf(fu,df=5)

# fitting hazard model
mod1 &lt;- survPen(f1,data=datCancer,t1=fu,event=dead,expected=NULL,method="LAML")

# summary
summary(mod1)

</code></pre>

<hr>
<h2 id='survPen'>(Excess) hazard model with (multidimensional) penalized splines and integrated smoothness estimation</h2><span id='topic+survPen'></span>

<h3>Description</h3>

<p>Please have a look to <a href="../doc/survival_analysis_with_survPen.html">survival_analysis_with_survPen vignette</a> for a thorough description. <br /> <br />
Fits an (excess) hazard model with (multidimensional) penalized splines allowing for
time-dependent effects, non-linear effects and interactions between several continuous covariates. The linear predictor is specified on the logarithm of the (excess) hazard. Smooth terms are represented using
cubic regression splines with associated quadratic penalties. For multidimensional smooths, tensor product splines or tensor product interactions
are available. Smoothness is estimated automatically by optimizing one of two criteria: Laplace approximate marginal likelihood (LAML) or likelihood cross-validation (LCV).
When specifying the model's formula, no distinction is made between the part relative to the form of the baseline hazard and the one relative
to the effects of the covariates. Thus, time-dependent effects are naturally specified as interactions with some function of time via &quot;*&quot; or &quot;:&quot;. See the examples below for more details.
The main functions of the survPen package are <code><a href="#topic+survPen">survPen</a></code>, <code><a href="#topic+smf">smf</a></code>, <code><a href="#topic+tensor">tensor</a></code>, <code><a href="#topic+tint">tint</a></code> and <code><a href="#topic+rd">rd</a></code>. The first one fits the model while the other four are constructors for penalized splines. <br /> <br />
The user must be aware that the <code>survPen</code> package does not depend on <code>mgcv</code>. Thus, all the functionalities available in <code>mgcv</code> in terms of types of splines (such as thin plate regression splines or P-splines) are not available in <code>survPen</code> (yet).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survPen(
  formula,
  data,
  t1,
  t0 = NULL,
  event,
  expected = NULL,
  lambda = NULL,
  rho.ini = NULL,
  max.it.beta = 200,
  max.it.rho = 30,
  beta.ini = NULL,
  detail.rho = FALSE,
  detail.beta = FALSE,
  n.legendre = NULL,
  method = "LAML",
  tol.beta = 1e-04,
  tol.rho = 1e-04,
  step.max = 5,
  type = "overall",
  cluster = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="survPen_+3A_formula">formula</code></td>
<td>
<p>formula object specifying the model. Penalized terms are specified using <code><a href="#topic+smf">smf</a></code> (comparable to <code>s(...,bs="cr")</code> in <code>mgcv</code>),
<code><a href="#topic+tensor">tensor</a></code> (comparable to <code>te(...,bs="cr")</code> in <code>mgcv</code>), <code><a href="#topic+tint">tint</a></code> (comparable to <code>ti(...,bs="cr")</code> in <code>mgcv</code>),
or <code><a href="#topic+rd">rd</a></code> (comparable to <code>s(...,bs="re")</code> in <code>mgcv</code>).</p>
</td></tr>
<tr><td><code id="survPen_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="survPen_+3A_t1">t1</code></td>
<td>
<p>vector of follow-up times or name of the column in <code>data</code> containing follow-up times</p>
</td></tr>
<tr><td><code id="survPen_+3A_t0">t0</code></td>
<td>
<p>vector of origin times or name of the column in <code>data</code> containing origin times; allows to take into account left truncation; default is NULL, in which case it will be a vector of zeroes</p>
</td></tr>
<tr><td><code id="survPen_+3A_event">event</code></td>
<td>
<p>vector of right-censoring indicators or name of the column in <code>data</code> containing right-censoring indicators; 1 if the event occurred and 0 otherwise</p>
</td></tr>
<tr><td><code id="survPen_+3A_expected">expected</code></td>
<td>
<p>(for net survival only) vector of expected hazard or name of the column in <code>data</code> containing expected hazard; default is NULL, in which case overall survival will be estimated</p>
</td></tr>
<tr><td><code id="survPen_+3A_lambda">lambda</code></td>
<td>
<p>vector of smoothing parameters; default is NULL when it is to be estimated by LAML or LCV</p>
</td></tr>
<tr><td><code id="survPen_+3A_rho.ini">rho.ini</code></td>
<td>
<p>vector of initial log smoothing parameters; default is NULL, in which case every initial log lambda will be -1</p>
</td></tr>
<tr><td><code id="survPen_+3A_max.it.beta">max.it.beta</code></td>
<td>
<p>maximum number of iterations to reach convergence in the regression parameters; default is 200</p>
</td></tr>
<tr><td><code id="survPen_+3A_max.it.rho">max.it.rho</code></td>
<td>
<p>maximum number of iterations to reach convergence in the smoothing parameters; default is 30</p>
</td></tr>
<tr><td><code id="survPen_+3A_beta.ini">beta.ini</code></td>
<td>
<p>vector of initial regression parameters; default is NULL, in which case the first beta will be <code>log(sum(event)/sum(t1))</code> and the others will be zero (except if there are &quot;by&quot; variables or if there is a piecewise constant hazard specification in which cases all betas are set to zero)</p>
</td></tr>
<tr><td><code id="survPen_+3A_detail.rho">detail.rho</code></td>
<td>
<p>if TRUE, details concerning the optimization process in the smoothing parameters are displayed; default is FALSE</p>
</td></tr>
<tr><td><code id="survPen_+3A_detail.beta">detail.beta</code></td>
<td>
<p>if TRUE, details concerning the optimization process in the regression parameters are displayed; default is FALSE</p>
</td></tr>
<tr><td><code id="survPen_+3A_n.legendre">n.legendre</code></td>
<td>
<p>number of Gauss-Legendre quadrature nodes to be used to compute the cumulative hazard; default is NULL. If not supplied the value is set to 20 for (excess) hazard models and 10 for relative mortality ratio models</p>
</td></tr>
<tr><td><code id="survPen_+3A_method">method</code></td>
<td>
<p>criterion used to select the smoothing parameters. Should be &quot;LAML&quot; or &quot;LCV&quot;; default is &quot;LAML&quot;</p>
</td></tr>
<tr><td><code id="survPen_+3A_tol.beta">tol.beta</code></td>
<td>
<p>convergence tolerance for regression parameters; default is <code>1e-04</code>. See <code><a href="#topic+NR.beta">NR.beta</a></code> for details</p>
</td></tr>
<tr><td><code id="survPen_+3A_tol.rho">tol.rho</code></td>
<td>
<p>convergence tolerance for smoothing parameters; default is <code>1e-04</code>. See <code><a href="#topic+NR.rho">NR.rho</a></code> for details</p>
</td></tr>
<tr><td><code id="survPen_+3A_step.max">step.max</code></td>
<td>
<p>maximum absolute value possible for any component of the step vector (on the log smoothing parameter scale) in LCV or LAML optimization; default is 5. If necessary, consider lowering this value to achieve convergence</p>
</td></tr>
<tr><td><code id="survPen_+3A_type">type</code></td>
<td>
<p>should be either 'overall' for hazard regression, 'net' for excess hazard regression, or 'mult' for relative mortality ratio regression</p>
</td></tr>
<tr><td><code id="survPen_+3A_cluster">cluster</code></td>
<td>
<p>cluster variable for marginal hazard (intensity) models</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In time-to-event analysis, we may deal with one or several continuous covariates whose functional forms, time-dependent effects and interaction structure are challenging. 
One possible way to deal with these effects and interactions is to use the classical approximation of the survival likelihood by a Poisson likelihood. Thus, by artificially splitting 
the data, the package <code>mgcv</code> can then be used to fit penalized hazard models (Remontet et al. 2018). The problem with this option is that the setup is rather complex and the method can fail with huge datasets (before splitting).  
Wood et al. (2016) provided a general penalized framework that made available smooth function estimation to a wide variety of models. 
They proposed to estimate smoothing parameters by maximizing a Laplace approximate marginal likelihood (LAML) criterion and demonstrate how statistical consistency is maintained by doing so.
The <code><a href="#topic+survPen">survPen</a></code> function implements the framework described by Wood et al. (2016) for modelling time-to-event data without requiring data splitting and Poisson likelihood approximation.
The effects of continuous covariates are represented using low rank spline bases with associated quadratic penalties. The <code><a href="#topic+survPen">survPen</a></code> function allows to account simultaneously for time-dependent effects, non-linear effects and
interactions between several continuous covariates without the need to build a possibly demanding model-selection procedure.
Besides LAML, a likelihood cross-validation (LCV) criterion (O Sullivan 1988) can be used for smoothing parameter estimation.
First and second derivatives of LCV with respect to the smoothing parameters are implemented so that LCV optimization is computationally equivalent to the LAML optimization proposed by Wood et al. (2016).
In practice, LAML optimization is generally both a bit faster and a bit more stable so it is used as default. 
For <code class="reqn">m</code> covariates <code class="reqn">(x_1,\ldots,x_m)</code>, if we note <code class="reqn">h(t,x_1,\ldots,x_m)</code> the hazard at time <code class="reqn">t</code>, the hazard model is the following :
</p>
<p style="text-align: center;"><code class="reqn">log[h(t,x_1,\ldots,x_m)]=\sum_j g_j(t,x_1,\ldots,x_m)</code>
</p>

<p>where each <code class="reqn">g_j</code> is either the marginal basis of a specific covariate or a tensor product smooth of any number of covariates. The marginal bases of the covariates are represented
as natural (or restricted) cubic splines (as in function <code>ns</code> from library <code>splines</code>) with associated quadratic penalties. Full parametric (unpenalized) terms for the effects of covariates are also possible (see the examples below).
Each <code class="reqn">g_j</code> is then associated with zero, one or several smoothing parameters. 
The estimation procedure is based on outer Newton-Raphson iterations for the smoothing parameters and on inner Newton-Raphson iterations for the regression parameters (see Wood et al. 2016).
Estimation of the regression parameters in the inner algorithm is by direct maximization of the penalized likelihood of the survival model, therefore avoiding data augmentation and Poisson likelihood approximation. 
The cumulative hazard included in the log-likelihood is approximated by Gauss-Legendre quadrature for numerical stability.
</p>


<h3>Value</h3>

<p>Object of class &quot;survPen&quot; (see <code><a href="#topic+survPenObject">survPenObject</a></code> for details)
</p>


<h3>by variables</h3>

<p>The <code><a href="#topic+smf">smf</a></code>, <code><a href="#topic+tensor">tensor</a></code> and <code><a href="#topic+tint">tint</a></code> terms used to specify smooths accept an argument <code>by</code>. This <code>by</code> argument allows for building varying-coefficient models i.e. for letting
smooths interact with factors or parametric terms. If a <code>by</code> variable is numeric, then its ith element multiples the ith row of the model matrix corresponding to the smooth term concerned.
If a <code>by</code> variable is a factor then it generates an indicator vector for each level of the factor, unless it is an ordered factor. In the non-ordered case, the model matrix for the smooth term is then replicated 
for each factor level, and each copy has its rows multiplied by the corresponding rows of its indicator variable. The smoothness penalties are also duplicated for each factor level. In short a different smooth is generated 
for each factor level. The main interest of by variables over separated models is the <code>same.rho</code> argument (for <code><a href="#topic+smf">smf</a></code>, <code><a href="#topic+tensor">tensor</a></code> and <code><a href="#topic+tint">tint</a></code>) which allows forcing all smooths to have the same smoothing parameter(s). 
Ordered <code>by</code> variables are handled in the same way, except that no smooth is generated for the first level of the ordered factor. This is useful if you are interested in differences from a reference level.
</p>
<p>See the <a href="../doc/survival_analysis_with_survPen.html">survival_analysis_with_survPen vignette</a> for more details.
</p>


<h3>Random effects</h3>

<p>i.i.d random effects can be specified using penalization. Indeed, the ridge penalty is equivalent to an assumption that the regression parameters are i.i.d. normal random effects.
Thus, it is easy to fit a frailty hazard model. For example, consider the model term <code>rd(clust)</code> which will result in a model matrix component corresponding to <code>model.matrix(~clust-1)</code> being added to the model matrix for the whole model. 
The associated regression parameters are assumed i.i.d. normal, with unknown variance (to be estimated). This assumption is equivalent to an identity penalty matrix (i.e. a ridge penalty) on the regression parameters.
The unknown smoothing parameter <code class="reqn">\lambda</code> associated with the term <code>rd(clust)</code> is directly linked to the unknown variance <code class="reqn">\sigma^2</code>: <code class="reqn">\sigma^2 = \frac{1}{\lambda * S.scale}</code>.
Then, the estimated log standard deviation is: <code class="reqn">log(\hat{\sigma})=-0.5*log(\hat{\lambda})-0.5*log(S.scale)</code>. And the estimated variance of the log standard deviation is: <code class="reqn">Var[log(\hat{\sigma})]=0.25*Var[log(\hat{\lambda})]=0.25*inv.Hess.rho</code>.
See the <a href="../doc/survival_analysis_with_survPen.html">survival_analysis_with_survPen vignette</a> for more details.
</p>
<p>This approach allows implementing commonly used random effect structures. For example if <code>g</code> is a factor then <code>rd(g)</code> produces a random parameter for each level of <code>g</code>, the random parameters being i.i.d. normal. 
If <code>g</code> is a factor and <code>x</code> is numeric, then <code>rd(g,x)</code> produces an i.i.d. normal random slope relating the response to <code>x</code> for each level of <code>g</code>.
Thus, random effects treated as penalized splines allow specifying frailty (excess) hazard models (Charvat et al. 2016). For each individual i from cluster (usually geographical unit)  j, a possible model would be:
</p>
<p style="text-align: center;"><code class="reqn">log[h(t_{ij},x_{ij1},\ldots,x_{ijm})]=\sum_k g_k(t_{ij},x_{ij1},\ldots,x_{ijm}) + w_j</code>
</p>

<p>where <code>w_j</code> follows a normal distribution with mean 0. The random effect associated with the cluster variable is specified with the model term <code>rd(cluster)</code>. We could also specify a random effect depending on age for example with the model term <code>rd(cluster,age)</code>.
<code>u_j = exp(w_j)</code> is known as the shared frailty.
</p>
<p>See the <a href="../doc/survival_analysis_with_survPen.html">survival_analysis_with_survPen vignette</a> for more details.
</p>


<h3>Excess hazard model</h3>

<p>When studying the survival of patients who suffer from a common pathology we may be interested in the concept of excess mortality that represents the mortality due to that pathology. 
For example, in cancer epidemiology, individuals may die from cancer or from another cause. The problem is that the cause of death is often either unavailable or unreliable. 
Supposing that the mortality due to other causes may be obtained from the total mortality of the general population (called expected mortality for cancer patients), we can define the concept of excess mortality. 
The excess mortality is directly linked to the concept of net survival, which would be the observed survival if patients could not die from other causes. Therefore, when such competing events are present, 
one may choose to fit an excess hazard model instead of a classical hazard model. Flexible excess hazard models have already been proposed (for examples see Remontet et al. 2007, Charvat et al. 2016) but none of them deals with a penalized framework (in a non-fully Bayesian setting).
Excess mortality can be estimated supposing that, in patients suffering from a common pathology, mortality due to others causes than the pathology can be obtained from the (all cause) mortality of the general population; the latter is referred to as the expected mortality <code class="reqn">h_P</code>. 
The mortality observed in the patients (<code class="reqn">h_O</code>) is actually decomposed as the sum of <code class="reqn">h_P</code> and the excess mortality due to the pathology (<code class="reqn">h_E</code>). This may be written as:
</p>
<p style="text-align: center;"><code class="reqn">h_O(t,x)=h_E(t,x)+h_P(a+t,z)</code>
</p>

<p>In that equation, <code class="reqn">t</code> is the time since cancer diagnosis, <code class="reqn">a</code> is the age at diagnosis, <code class="reqn">h_P</code> is the mortality of the general population at age <code class="reqn">a+t</code> given demographical characteristics <code class="reqn">z</code> (<code class="reqn">h_P</code> is considered known and available from national statistics), 
and <code class="reqn">x</code> a vector of variables that may have an effect on <code class="reqn">h_E</code>. Including the age in the model is necessary in order to deal with the informative censoring due to other causes of death. 
Thus, for <code class="reqn">m</code> covariates <code class="reqn">(x_1,\ldots,x_m)</code>, if we note <code class="reqn">h_E(t,x_1,\ldots,x_m)</code> the excess hazard at time <code class="reqn">t</code>, the excess hazard model is the following:
</p>
<p style="text-align: center;"><code class="reqn">log[h_E(t,x_1,\ldots,x_m)]=\sum_j g_j(t,x_1,\ldots,x_m)</code>
</p>



<h3>Relative mortality ratio model</h3>

<p>Another important feature of the <code>survPen</code> package is that it allows fitting penalized relative mortality 
ratio models.
</p>
<p>As we discussed above, the excess mortality setting considers that the mortality (all causes) observed in 
the patients (<code class="reqn">h_O</code>) is actually decomposed as the sum of the expected 
mortality <code class="reqn">h_P</code> and the excess mortality due to the pathology (<code class="reqn">h_E</code>). 
</p>
<p>This may be written as:
</p>
<p style="text-align: center;"><code class="reqn">h_O(t,x)=h_E(t,x)+h_P(a+t,z)</code>
</p>

<p>One limitation of such a decomposition is that <code class="reqn">h_E</code> is considered positive. Indeed, sometimes this assumption
is not met. For example, in prostate cancer patients with low stages at diagnosis, we observe an 'undermortality'
due to selection effects and better overall medical care. In that case, the excess mortality is actually neagtive
and the net survival setting fails to describe the reality of those patients.
Besides, the excess mortality setting considers the studied disease as an independent cause of death
(conditionally on the covariates) compared to the other causes. This point of view is not usely considered
in multiple sclerosis epidemiology for example, where the disease is seen as a comorbidity impacting all pre-
existing causes of death. In that case, the observed hazard is decomposed as product of population hazard and
a relative mortality ratio <code class="reqn">r</code>
</p>
<p>This may be written as:
</p>
<p style="text-align: center;"><code class="reqn">h_O(t,x)=r(t,x)*h_P(a+t,z)</code>
</p>

<p>This decomposition was first proposed in a modelling framework by Andersen et al. (1985). However Andersen's model
was a non-flexible semi-parametric model.
</p>
<p>The <code>survPen</code> package allows modelling the relative mortality ratio <code class="reqn">r</code> as a multidimensional function of time and
covariates. For <code class="reqn">m</code> covariates <code class="reqn">(x_1,\ldots,x_m)</code>, if we note <code class="reqn">r(t,x_1,\ldots,x_m)</code> the relative mortality ratio 
at time <code class="reqn">t</code>, the model is as follows:
</p>
<p style="text-align: center;"><code class="reqn">log[r(t,x_1,\ldots,x_m)]=\sum_j g_j(t,x_1,\ldots,x_m) </code>
</p>

<p>Where the <code class="reqn">g_j</code> functions may be penalized unidimensional or penalized tensor product splines. All features
described for the (excess) hazard setting still apply when fitting a relative mortality ratio model.
One difference lies in the predictions. With a fitted relative mortality ratio model, you can only
retrieve the relative mortality ratio and cumulative relative mortality ratio predictions (with CIs), as well as 
the ratios of realtive mortality ratio (with type='HR'). 
No survival prediction (let alone survival difference) will be directly available because its calculation depends on 
expected mortality rates.
</p>
<p>Finally, one important difference between an excess hazard model and relative mortality ratio model is data preparation.
For an excess hazard model we only need individual data with expected mortality rate at the time of death. Whereas in a
relative mortality ratio model, the contribution to an individual to the likelihood requires all possible expected mortality rate
values during the entire follow-up.
Therefore, since the expected mortality rates come from national mortality tables usually available in 1-year intervals, we need to split the
original dataset as many times as there are 1-year intervals during each individual's follow-up. The function <code><a href="#topic+splitmult">splitmult</a></code> will help you
getting the splitdataset from the original one.
</p>
<p>See the <a href="../doc/survival_analysis_with_survPen.html">survival_analysis_with_survPen vignette</a> for more details and an example of analysis.
</p>


<h3>Marginal hazard (intensity) models with robust standard errors</h3>

<p>In presence of correlated time-to-event data (for example recurrent event data), robust standard errors accounting for said correlation need to be derived.
The 'survPen' package allows deriving such robust standard errors based on sandwich estimators (often called Huber sandwich estimator, see also Coz et al. submitted to Biostatistics, 
for an example in the recurrent event setting).
</p>
<p>The user only needs to specify the 'cluster' variable defining the statistical units for which repeated observations are available.
This specification is performed via the 'cluster' argument.
</p>
<p>See the <a href="../doc/survival_analysis_with_survPen.html">survival_analysis_with_survPen vignette</a> for more details and an example of analysis.
</p>


<h3>Convergence</h3>

<p>No convergence indicator is given. If the function returns an object of class <code>survPen</code>, it means that the algorithm has converged. If convergence issues occur, an error message is displayed.
If convergence issues occur, do not refrain to use detail.rho and/or detail.beta to see exactly what is going on in the optimization process. To achieve convergence, consider lowering step.max and/or changing rho.ini and beta.ini.
If your excess hazard model fails to converge, consider fitting a hazard model and use its estimated parameters as initial values for the excess hazard model. Finally, do not refrain to change the &quot;method&quot; argument (LCV or LAML) if convergence issues occur.
</p>


<h3>Other</h3>

<p>Be aware that all character variables are transformed to factors before fitting.
</p>


<h3>References</h3>

<p>Andersen, P. K., Borch-Johnsen, K., Deckert, T., Green, A., Hougaard, P., Keiding, N., and Kreiner, S. (1985). A Cox regression model for the relative mortality and its application to diabetes mellitus survival data. Biometrics, 921-932. <br /> <br />
Charvat, H., Remontet, L., Bossard, N., Roche, L., Dejardin, O., Rachet, B., ... and Belot, A. (2016), A multilevel excess hazard model to estimate net survival on hierarchical data allowing for non linear and non proportional effects of covariates. Statistics in medicine, 35(18), 3066-3084. <br /> <br />
Coz, E., Charvat, H., Maucort-Boulch, D., and Fauvernier, M. (submitted to Biostatistics). Flexible penalized marginal intensity models for recurrent event data. 
Fauvernier, M., Roche, L., Uhry, Z., Tron, L., Bossard, N., Remontet, L. and the CENSUR Working Survival Group. Multidimensional penalized hazard model with continuous covariates: applications for studying trends and social inequalities in cancer survival, in revision in the Journal of the Royal Statistical Society, series C. <br /> <br />
O Sullivan, F. (1988), Fast computation of fully automated log-density and log-hazard estimators. SIAM Journal on scientific and statistical computing, 9(2), 363-379. <br /> <br />
Remontet, L., Bossard, N., Belot, A., &amp; Esteve, J. (2007), An overall strategy based on regression models to estimate relative survival and model the effects of prognostic factors in cancer survival studies. Statistics in medicine, 26(10), 2214-2228. <br /> <br />
Remontet, L., Uhry, Z., Bossard, N., Iwaz, J., Belot, A., Danieli, C., Charvat, H., Roche, L. and CENSUR Working Survival Group (2018) Flexible and structured survival model for a simultaneous estimation of non-linear and non-proportional effects and complex interactions between continuous variables: Performance of this multidimensional penalized spline approach in net survival trend analysis. Stat Methods Med Res. 2018 Jan 1:962280218779408. doi: 10.1177/0962280218779408. [Epub ahead of print]. <br /> <br />
Wood, S.N., Pya, N. and Saefken, B. (2016), Smoothing parameter and model selection for general smooth models (with discussion). Journal of the American Statistical Association 111, 1548-1575
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


library(survPen)
data(datCancer) # simulated dataset with 2000 individuals diagnosed with cervical cancer

#-------------------------------------------------------- example 0
# Comparison between restricted cubic splines and penalized restricted cubic splines

library(splines)

# unpenalized
f &lt;- ~ns(fu,knots=c(0.25, 0.5, 1, 2, 4),Boundary.knots=c(0,5))

mod &lt;- survPen(f,data=datCancer,t1=fu,event=dead)

# penalized
f.pen &lt;- ~ smf(fu,knots=c(0,0.25, 0.5, 1, 2, 4,5)) # careful here: the boundary knots are included

mod.pen &lt;- survPen(f.pen,data=datCancer,t1=fu,event=dead)

# predictions

new.time &lt;- seq(0,5,length=100)
pred &lt;- predict(mod,data.frame(fu=new.time))
pred.pen &lt;- predict(mod.pen,data.frame(fu=new.time))

par(mfrow=c(1,1))
plot(new.time,pred$haz,type="l",ylim=c(0,0.2),main="hazard vs time",
xlab="time since diagnosis (years)",ylab="hazard",col="red")
lines(new.time,pred.pen$haz,col="blue3")
legend("topright",legend=c("unpenalized","penalized"),
col=c("red","blue3"),lty=rep(1,2))



#-------------------------------------------------------- example 1
# hazard models with unpenalized formulas compared to a penalized tensor product smooth

library(survPen)
data(datCancer) # simulated dataset with 2000 individuals diagnosed with cervical cancer

# constant hazard model
f.cst &lt;- ~1
mod.cst &lt;- survPen(f.cst,data=datCancer,t1=fu,event=dead)

# piecewise constant hazard model
f.pwcst &lt;- ~pwcst(breaks=seq(0,5,by=0.5))
mod.pwcst &lt;- survPen(f.pwcst,data=datCancer,t1=fu,event=dead)

# linear effect of time
f.lin &lt;- ~fu
mod.lin &lt;- survPen(f.lin,data=datCancer,t1=fu,event=dead)

# linear effect of time and age with proportional effect of age
f.lin.age &lt;- ~fu+age
mod.lin.age &lt;- survPen(f.lin.age,data=datCancer,t1=fu,event=dead)

# linear effect of time and age with time-dependent effect of age (linear)
f.lin.inter.age &lt;- ~fu*age
mod.lin.inter.age &lt;- survPen(f.lin.inter.age,data=datCancer,t1=fu,event=dead)

# cubic B-spline of time with a knot at 1 year, linear effect of age and time-dependent effect
# of age with a quadratic B-spline of time with a knot at 1 year
library(splines)
f.spline.inter.age &lt;- ~bs(fu,knots=c(1),Boundary.knots=c(0,5))+age+
age:bs(fu,knots=c(1),Boundary.knots=c(0,5),degree=2)
# here, bs indicates an unpenalized cubic spline

mod.spline.inter.age &lt;- survPen(f.spline.inter.age,data=datCancer,t1=fu,event=dead)


# tensor of time and age
f.tensor &lt;- ~tensor(fu,age)
mod.tensor &lt;- survPen(f.tensor,data=datCancer,t1=fu,event=dead)


# predictions of the models at age 60

new.time &lt;- seq(0,5,length=100)
pred.cst &lt;- predict(mod.cst,data.frame(fu=new.time))
pred.pwcst &lt;- predict(mod.pwcst,data.frame(fu=new.time))
pred.lin &lt;- predict(mod.lin,data.frame(fu=new.time))
pred.lin.age &lt;- predict(mod.lin.age,data.frame(fu=new.time,age=60))
pred.lin.inter.age &lt;- predict(mod.lin.inter.age,data.frame(fu=new.time,age=60))
pred.spline.inter.age &lt;- predict(mod.spline.inter.age,data.frame(fu=new.time,age=60))
pred.tensor &lt;- predict(mod.tensor,data.frame(fu=new.time,age=60))

lwd1 &lt;- 2

par(mfrow=c(1,1))
plot(new.time,pred.cst$haz,type="l",ylim=c(0,0.2),main="hazard vs time",
xlab="time since diagnosis (years)",ylab="hazard",col="blue3",lwd=lwd1)
segments(x0=new.time[1:99],x1=new.time[2:100],y0=pred.pwcst$haz[1:99],col="lightblue2",lwd=lwd1)
lines(new.time,pred.lin$haz,col="green3",lwd=lwd1)
lines(new.time,pred.lin.age$haz,col="yellow",lwd=lwd1)
lines(new.time,pred.lin.inter.age$haz,col="orange",lwd=lwd1)
lines(new.time,pred.spline.inter.age$haz,col="red",lwd=lwd1)
lines(new.time,pred.tensor$haz,col="black",lwd=lwd1)
legend("topright",
legend=c("cst","pwcst","lin","lin.age","lin.inter.age","spline.inter.age","tensor"),
col=c("blue3","lightblue2","green3","yellow","orange","red","black"),
lty=rep(1,7),lwd=rep(lwd1,7))


# you can also calculate the hazard yourself with the lpmatrix option.
# For example, compare the following predictions:
haz.tensor &lt;- pred.tensor$haz

X.tensor &lt;- predict(mod.tensor,data.frame(fu=new.time,age=60),type="lpmatrix")
haz.tensor.lpmatrix &lt;- exp(X.tensor%mult%mod.tensor$coefficients)

summary(haz.tensor.lpmatrix - haz.tensor)

#---------------- The 95% confidence intervals can be calculated like this:

# standard errors from the Bayesian covariance matrix Vp
std &lt;- sqrt(rowSums((X.tensor%mult%mod.tensor$Vp)*X.tensor))

qt.norm &lt;- stats::qnorm(1-(1-0.95)/2)
haz.inf &lt;- as.vector(exp(X.tensor%mult%mod.tensor$coefficients-qt.norm*std))
haz.sup &lt;- as.vector(exp(X.tensor%mult%mod.tensor$coefficients+qt.norm*std))

# checking that they are similar to the ones given by the predict function
summary(haz.inf - pred.tensor$haz.inf)
summary(haz.sup - pred.tensor$haz.sup)


#-------------------------------------------------------- example 2

library(survPen)
data(datCancer) # simulated dataset with 2000 individuals diagnosed with cervical cancer

# model : unidimensional penalized spline for time since diagnosis with 5 knots
f1 &lt;- ~smf(fu,df=5)
# when knots are not specified, quantiles are used. For example, for the term "smf(x,df=df1)",
# the vector of knots will be: quantile(unique(x),seq(0,1,length=df1)) 

# you can specify your own knots if you want
# f1 &lt;- ~smf(fu,knots=c(0,1,3,6,8))

# hazard model
mod1 &lt;- survPen(f1,data=datCancer,t1=fu,event=dead,expected=NULL,method="LAML")
summary(mod1)

# to see where the knots were placed
mod1$list.smf

# with LCV instead of LAML
mod1bis &lt;- survPen(f1,data=datCancer,t1=fu,event=dead,expected=NULL,method="LCV")
summary(mod1bis)

# hazard model taking into account left truncation (not representative of cancer data, 
# the begin variable was simulated for illustration purposes only)
mod2 &lt;- survPen(f1,data=datCancer,t0=begin,t1=fu,event=dead,expected=NULL,method="LAML")
summary(mod2)

# excess hazard model
mod3 &lt;- survPen(f1,data=datCancer,t1=fu,event=dead,expected=rate,method="LAML")
summary(mod3)

# compare the predictions of the models
new.time &lt;- seq(0,5,length=50)
pred1 &lt;- predict(mod1,data.frame(fu=new.time))
pred1bis &lt;- predict(mod1bis,data.frame(fu=new.time))
pred2 &lt;- predict(mod2,data.frame(fu=new.time))
pred3 &lt;- predict(mod3,data.frame(fu=new.time))

# LAML vs LCV
par(mfrow=c(1,2))
plot(new.time,pred1$haz,type="l",ylim=c(0,0.2),main="LCV vs LAML",
xlab="time since diagnosis (years)",ylab="hazard")
lines(new.time,pred1bis$haz,col="blue3")
legend("topright",legend=c("LAML","LCV"),col=c("black","blue3"),lty=c(1,1))

plot(new.time,pred1$surv,type="l",ylim=c(0,1),main="LCV vs LAML",
xlab="time since diagnosis (years)",ylab="survival")
lines(new.time,pred1bis$surv,col="blue3")



# hazard vs excess hazard
par(mfrow=c(1,2))
plot(new.time,pred1$haz,type="l",ylim=c(0,0.2),main="hazard vs excess hazard",
xlab="time since diagnosis (years)",ylab="hazard")
lines(new.time,pred3$haz,col="green3")
legend("topright",legend=c("overall","excess"),col=c("black","green3"),lty=c(1,1))

plot(new.time,pred1$surv,type="l",ylim=c(0,1),main="survival vs net survival",
xlab="time",ylab="survival")
lines(new.time,pred3$surv,col="green3")
legend("topright",legend=c("overall survival","net survival"), col=c("black","green3"), lty=c(1,1)) 

# hazard vs excess hazard with 95% Bayesian confidence intervals (based on Vp matrix, 
# see predict.survPen)
par(mfrow=c(1,1))
plot(new.time,pred1$haz,type="l",ylim=c(0,0.2),main="hazard vs excess hazard",
xlab="time since diagnosis (years)",ylab="hazard")
lines(new.time,pred3$haz,col="green3")
legend("topright",legend=c("overall","excess"),col=c("black","green3"),lty=c(1,1))

lines(new.time,pred1$haz.inf,lty=2)
lines(new.time,pred1$haz.sup,lty=2)

lines(new.time,pred3$haz.inf,lty=2,col="green3")
lines(new.time,pred3$haz.sup,lty=2,col="green3")



#-------------------------------------------------------- example 3

library(survPen)
data(datCancer) # simulated dataset with 2000 individuals diagnosed with cervical cancer

# models: tensor product smooth vs tensor product interaction of time since diagnosis and 
# age at diagnosis. Smoothing parameters are estimated via LAML maximization
f2 &lt;- ~tensor(fu,age,df=c(5,5))

f3 &lt;- ~tint(fu,df=5)+tint(age,df=5)+tint(fu,age,df=c(5,5))

# hazard model
mod4 &lt;- survPen(f2,data=datCancer,t1=fu,event=dead)
summary(mod4)

mod5 &lt;- survPen(f3,data=datCancer,t1=fu,event=dead)
summary(mod5)

# predictions
new.age &lt;- seq(50,90,length=50)
new.time &lt;- seq(0,7,length=50)

Z4 &lt;- outer(new.time,new.age,function(t,a) predict(mod4,data.frame(fu=t,age=a))$haz)
Z5 &lt;- outer(new.time,new.age,function(t,a) predict(mod5,data.frame(fu=t,age=a))$haz)

# color settings
col.pal &lt;- colorRampPalette(c("white", "red"))
colors &lt;- col.pal(100)

facet &lt;- function(z){

	facet.center &lt;- (z[-1, -1] + z[-1, -ncol(z)] + z[-nrow(z), -1] + z[-nrow(z), -ncol(z)])/4
	cut(facet.center, 100)
	
}

# plot the hazard surfaces for both models
par(mfrow=c(1,2))
persp(new.time,new.age,Z4,col=colors[facet(Z4)],main="tensor",theta=30,
xlab="time since diagnosis",ylab="age at diagnosis",zlab="excess hazard",ticktype="detailed")
persp(new.time,new.age,Z5,col=colors[facet(Z5)],main="tint",theta=30,
xlab="time since diagnosis",ylab="age at diagnosis",zlab="excess hazard",ticktype="detailed")

#-------------------------------------------------------- example 4

library(survPen)
data(datCancer) # simulated dataset with 2000 individuals diagnosed with cervical cancer

# model : tensor product spline for time, age and yod (year of diagnosis)
# yod is not centered here since it does not create unstability but be careful in practice
# and consider centering your covariates if you encounter convergence issues
f4 &lt;- ~tensor(fu,age,yod,df=c(5,5,5))

# excess hazard model
mod6 &lt;- survPen(f4,data=datCancer,t1=fu,event=dead,expected=rate)
summary(mod6)


# predictions of the surfaces for ages 50, 60, 70 and 80
new.year &lt;- seq(1990,2010,length=30)
new.time &lt;- seq(0,5,length=50)

Z_50 &lt;- outer(new.time,new.year,function(t,y) predict(mod6,data.frame(fu=t,yod=y,age=50))$haz)
Z_60 &lt;- outer(new.time,new.year,function(t,y) predict(mod6,data.frame(fu=t,yod=y,age=60))$haz)
Z_70 &lt;- outer(new.time,new.year,function(t,y) predict(mod6,data.frame(fu=t,yod=y,age=70))$haz)
Z_80 &lt;- outer(new.time,new.year,function(t,y) predict(mod6,data.frame(fu=t,yod=y,age=80))$haz)


# plot the hazard surfaces for a given age
par(mfrow=c(2,2))
persp(new.time,new.year,Z_50,col=colors[facet(Z_50)],main="age 50",theta=20,
xlab="time since diagnosis",ylab="yod",zlab="excess hazard",ticktype="detailed")
persp(new.time,new.year,Z_60,col=colors[facet(Z_60)],main="age 60",theta=20,
xlab="time since diagnosis",ylab="yod",zlab="excess hazard",ticktype="detailed")
persp(new.time,new.year,Z_70,col=colors[facet(Z_70)],main="age 70",theta=20,
xlab="time since diagnosis",ylab="yod",zlab="excess hazard",ticktype="detailed")
persp(new.time,new.year,Z_80,col=colors[facet(Z_80)],main="age 80",theta=20,
xlab="time since diagnosis",ylab="yod",zlab="excess hazard",ticktype="detailed")

########################################



</code></pre>

<hr>
<h2 id='survPen.fit'>(Excess) hazard model with multidimensional penalized splines for given smoothing parameters</h2><span id='topic+survPen.fit'></span>

<h3>Description</h3>

<p>Fits an (excess) hazard model. If penalized splines are present, the smoothing parameters are specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survPen.fit(
  build,
  data,
  formula,
  max.it.beta = 200,
  beta.ini = NULL,
  detail.beta = FALSE,
  method = "LAML",
  tol.beta = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="survPen.fit_+3A_build">build</code></td>
<td>
<p>list of objects returned by <code><a href="#topic+model.cons">model.cons</a></code></p>
</td></tr>
<tr><td><code id="survPen.fit_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="survPen.fit_+3A_formula">formula</code></td>
<td>
<p>formula object specifying the model</p>
</td></tr>
<tr><td><code id="survPen.fit_+3A_max.it.beta">max.it.beta</code></td>
<td>
<p>maximum number of iterations to reach convergence in the regression parameters; default is 200</p>
</td></tr>
<tr><td><code id="survPen.fit_+3A_beta.ini">beta.ini</code></td>
<td>
<p>vector of initial regression parameters; default is NULL, in which case the first beta will be <code>log(sum(event)/sum(t1))</code> and the others will be zero (except if there are &quot;by&quot; variables or if there is a piecewise constant hazard specification in which cases all betas are set to zero)</p>
</td></tr>
<tr><td><code id="survPen.fit_+3A_detail.beta">detail.beta</code></td>
<td>
<p>if TRUE, details concerning the optimization process in the regression parameters are displayed; default is FALSE</p>
</td></tr>
<tr><td><code id="survPen.fit_+3A_method">method</code></td>
<td>
<p>criterion used to select the smoothing parameters. Should be &quot;LAML&quot; or &quot;LCV&quot;; default is &quot;LAML&quot;</p>
</td></tr>
<tr><td><code id="survPen.fit_+3A_tol.beta">tol.beta</code></td>
<td>
<p>convergence tolerance for regression parameters; default is <code>1e-04</code>. See <code><a href="#topic+NR.beta">NR.beta</a></code> for details</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class &quot;survPen&quot; (see <code><a href="#topic+survPenObject">survPenObject</a></code> for details)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# standard spline of time with 4 knots

data &lt;- data.frame(time=seq(0,5,length=100),event=1,t0=0)

form &lt;- ~ smf(time,knots=c(0,1,3,5))

t1 &lt;- eval(substitute(time), data)
t0 &lt;- eval(substitute(t0), data)
event &lt;- eval(substitute(event), data)
	
# Setting up the model before fitting
model.c &lt;- model.cons(form,lambda=0,data.spec=data,t1=t1,t1.name="time",
t0=rep(0,100),t0.name="t0",event=event,event.name="event",
expected=rep(0,100),expected.name=NULL,type="overall",n.legendre=20,
cl="survPen(form,data,t1=time,event=event)",beta.ini=NULL)
 
# fitting
mod &lt;- survPen.fit(model.c,data,form)

</code></pre>

<hr>
<h2 id='survPenObject'>Fitted survPen object</h2><span id='topic+survPenObject'></span>

<h3>Description</h3>

<p>A fitted survPen object returned by function <code><a href="#topic+survPen">survPen</a></code> and of class &quot;survPen&quot;. 
Method functions predict and summary are available for this class.
</p>


<h3>Value</h3>

<p>A <code>survPen</code> object has the following elements:
</p>
<table role = "presentation">
<tr><td><code>call</code></td>
<td>
<p>original <code>survPen</code> call</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula object specifying the model</p>
</td></tr>
<tr><td><code>t0.name</code></td>
<td>
<p>name of the vector of origin times</p>
</td></tr>
<tr><td><code>t1.name</code></td>
<td>
<p>name of the vector of follow-up times</p>
</td></tr>
<tr><td><code>event.name</code></td>
<td>
<p>name of the vector of right-censoring indicators</p>
</td></tr>
<tr><td><code>expected.name</code></td>
<td>
<p>name of the vector of expected hazard</p>
</td></tr>
<tr><td><code>haz</code></td>
<td>
<p>fitted hazard</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated regression parameters. Unpenalized parameters are first, followed by the penalized ones</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>&quot;net&quot; for net survival estimation with penalized excess hazard model, &quot;overall&quot; for overall survival with penalized hazard model, or &quot;mult&quot; for penalized relative mortality ratio model</p>
</td></tr>
<tr><td><code>df.para</code></td>
<td>
<p>degrees of freedom associated with fully parametric terms (unpenalized)</p>
</td></tr>
<tr><td><code>df.smooth</code></td>
<td>
<p>degrees of freedom associated with penalized terms</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>number of regression parameters</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>effective degrees of freedom</p>
</td></tr>
<tr><td><code>edf1</code></td>
<td>
<p>alternative effective degrees of freedom ; used as an upper bound for edf2</p>
</td></tr>
<tr><td><code>edf2</code></td>
<td>
<p>effective degrees of freedom corrected for smoothing parameter uncertainty</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Akaike information criterion with number of parameters replaced by edf when there are penalized terms. Corresponds to 2*edf - 2*ll.unpen</p>
</td></tr>
<tr><td><code>aic2</code></td>
<td>
<p>Akaike information criterion corrected for smoothing parameter uncertainty. Be careful though, this is still a work in progress, especially when one of the smoothing parameters tends to infinity.</p>
</td></tr>
<tr><td><code>iter.beta</code></td>
<td>
<p>vector of numbers of iterations needed to estimate the regression parameters for each smoothing parameters trial. It thus contains <code>iter.rho+1</code> elements.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>design matrix of the model</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>penalty matrix of the model</p>
</td></tr>
<tr><td><code>S.scale</code></td>
<td>
<p>vector of rescaling factors for the penalty matrices</p>
</td></tr>
<tr><td><code>S.list</code></td>
<td>
<p>Equivalent to pen but with every element multiplied by its associated smoothing parameter</p>
</td></tr>
<tr><td><code>S.smf</code></td>
<td>
<p>List of penalty matrices associated with all &quot;smf&quot; calls</p>
</td></tr>
<tr><td><code>S.tensor</code></td>
<td>
<p>List of penalty matrices associated with all &quot;tensor&quot; calls</p>
</td></tr>
<tr><td><code>S.tint</code></td>
<td>
<p>List of penalty matrices associated with all &quot;tint&quot; calls</p>
</td></tr>
<tr><td><code>S.rd</code></td>
<td>
<p>List of penalty matrices associated with all &quot;rd&quot; calls</p>
</td></tr>
<tr><td><code>smooth.name.smf</code></td>
<td>
<p>List of names for the &quot;smf&quot; calls associated with S.smf</p>
</td></tr>
<tr><td><code>smooth.name.tensor</code></td>
<td>
<p>List of names for the &quot;tensor&quot; calls associated with S.tensor</p>
</td></tr>
<tr><td><code>smooth.name.tint</code></td>
<td>
<p>List of names for the &quot;tint&quot; calls associated with S.tint</p>
</td></tr>
<tr><td><code>smooth.name.rd</code></td>
<td>
<p>List of names for the &quot;rd&quot; calls associated with S.rd</p>
</td></tr>
<tr><td><code>S.pen</code></td>
<td>
<p>List of all the rescaled penalty matrices redimensioned to df.tot size. Every element of <code>S.pen</code> noted <code>S.pen[[i]]</code> is made from a penalty matrix <code>pen[[i]]</code> returned by
<code><a href="#topic+smooth.cons">smooth.cons</a></code> and is multiplied by S.scale</p>
</td></tr>
<tr><td><code>grad.unpen.beta</code></td>
<td>
<p>gradient vector of the log-likelihood with respect to the regression parameters</p>
</td></tr>
<tr><td><code>grad.beta</code></td>
<td>
<p>gradient vector of the penalized log-likelihood with respect to the regression parameters</p>
</td></tr>
<tr><td><code>Hess.unpen.beta</code></td>
<td>
<p>hessian of the log-likelihood with respect to the regression parameters</p>
</td></tr>
<tr><td><code>Hess.beta</code></td>
<td>
<p>hessian of the penalized log-likelihood with respect to the regression parameters</p>
</td></tr>
<tr><td><code>Hess.beta.modif</code></td>
<td>
<p>if TRUE, the hessian of the penalized log-likelihood has been perturbed at convergence</p>
</td></tr>
<tr><td><code>ll.unpen</code></td>
<td>
<p>log-likelihood at convergence</p>
</td></tr>
<tr><td><code>ll.pen</code></td>
<td>
<p>penalized log-likelihood at convergence</p>
</td></tr>
<tr><td><code>deriv.rho.beta</code></td>
<td>
<p>transpose of the Jacobian of beta with respect to the log smoothing parameters</p>
</td></tr>
<tr><td><code>deriv.rho.inv.Hess.beta</code></td>
<td>
<p>list containing the derivatives of the inverse of <code>Hess</code> with respect to the log smoothing parameters</p>
</td></tr>
<tr><td><code>deriv.rho.Hess.unpen.beta</code></td>
<td>
<p>list containing the derivatives of <code>Hess.unpen</code> with respect to the log smoothing parameters</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>estimated or given smoothing parameters</p>
</td></tr>
<tr><td><code>nb.smooth</code></td>
<td>
<p>number of smoothing parameters</p>
</td></tr>
<tr><td><code>iter.rho</code></td>
<td>
<p>number of iterations needed to estimate the smoothing parameters</p>
</td></tr>
<tr><td><code>optim.rho</code></td>
<td>
<p>identify whether the smoothing parameters were estimated or not; 1 when exiting the function <code><a href="#topic+NR.rho">NR.rho</a></code>; default is NULL</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>criterion used for smoothing parameter estimation</p>
</td></tr>
<tr><td><code>criterion.val</code></td>
<td>
<p>value of the criterion used for smoothing parameter estimation at convergence</p>
</td></tr>
<tr><td><code>LCV</code></td>
<td>
<p>Likelihood cross-validation criterion at convergence</p>
</td></tr>
<tr><td><code>LAML</code></td>
<td>
<p>negative Laplace approximate marginal likelihood at convergence</p>
</td></tr>
<tr><td><code>grad.rho</code></td>
<td>
<p>gradient vector of criterion with respect to the log smoothing parameters</p>
</td></tr>
<tr><td><code>Hess.rho</code></td>
<td>
<p>hessian matrix of criterion with respect to the log smoothing parameters</p>
</td></tr>
<tr><td><code>inv.Hess.rho</code></td>
<td>
<p>inverse of <code>Hess.rho</code></p>
</td></tr>
<tr><td><code>Hess.rho.modif</code></td>
<td>
<p>if TRUE, the hessian of LCV or LAML has been perturbed at convergence</p>
</td></tr>
<tr><td><code>Ve</code></td>
<td>
<p>Frequentist covariance matrix</p>
</td></tr>
<tr><td><code>Vr</code></td>
<td>
<p>Robust frequentist covariance matrix accounting for correlated survival times</p>
</td></tr>
<tr><td><code>Vp</code></td>
<td>
<p>Bayesian covariance matrix</p>
</td></tr>
<tr><td><code>Vc</code></td>
<td>
<p>Bayesian covariance matrix corrected for smoothing parameter uncertainty (see Wood et al. 2016)</p>
</td></tr>
<tr><td><code>Vc.approx</code></td>
<td>
<p>Kass and Steffey approximation of <code>Vc</code> (see Wood et al. 2016)</p>
</td></tr>
<tr><td><code>Z.smf</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+smf">smf</a></code> splines</p>
</td></tr>
<tr><td><code>Z.tensor</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+tensor">tensor</a></code> splines</p>
</td></tr>
<tr><td><code>Z.tint</code></td>
<td>
<p>List of matrices that represents the sum-to-zero constraint to apply for <code><a href="#topic+tint">tint</a></code> splines</p>
</td></tr>
<tr><td><code>list.smf</code></td>
<td>
<p>List of all <code>smf.smooth.spec</code> objects contained in the model</p>
</td></tr>
<tr><td><code>list.tensor</code></td>
<td>
<p>List of all <code>tensor.smooth.spec</code> objects contained in the model</p>
</td></tr>
<tr><td><code>list.tint</code></td>
<td>
<p>List of all <code>tint.smooth.spec</code> objects contained in the model</p>
</td></tr>
<tr><td><code>list.rd</code></td>
<td>
<p>List of all <code>rd.smooth.spec</code> objects contained in the model</p>
</td></tr>
<tr><td><code>U.F</code></td>
<td>
<p>Eigen vectors of S.F, useful for the initial reparameterization to separate penalized ad unpenalized subvectors. Allows stable evaluation of the log determinant of S and its derivatives</p>
</td></tr>
<tr><td><code>is.pwcst</code></td>
<td>
<p>TRUE if there is a piecewise constant (excess) hazard specification. In that case the cumulative hazard can be derived without Gauss-Legendre quadrature</p>
</td></tr>
<tr><td><code>pwcst.breaks</code></td>
<td>
<p>if is.pwcst is TRUE, vector of breaks defining the sub-intervals on which the hazard is constant. Otherwise NULL.</p>
</td></tr>
<tr><td><code>factor.structure</code></td>
<td>
<p>List containing the levels and classes of all factor variables present in the data frame used for fitting</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>convergence indicator, TRUE or FALSE. TRUE if Hess.beta.modif=FALSE and Hess.rho.modif=FALSE (or NULL)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wood, S.N., Pya, N. and Saefken, B. (2016), Smoothing parameter and model selection for general smooth models (with discussion). Journal of the American Statistical Association 111, 1548-1575
</p>

<hr>
<h2 id='tensor.in'>tensor model matrix for two marginal bases</h2><span id='topic+tensor.in'></span>

<h3>Description</h3>

<p>Function called recursively inside <code><a href="#topic+tensor.prod.X">tensor.prod.X</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensor.in(X1, X2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tensor.in_+3A_x1">X1</code></td>
<td>
<p>first marginal design matrix with n rows and p1 columns</p>
</td></tr>
<tr><td><code id="tensor.in_+3A_x2">X2</code></td>
<td>
<p>first marginal design matrix with n rows and p2 columns</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of dimensions n*(p1*p2) representing the row tensor product of the matrices X1 and X2
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# row-wise tensor product between two design matrices
set.seed(15)

X1 &lt;- matrix(rnorm(10*3),nrow=10,ncol=3)
X2 &lt;- matrix(rnorm(10*2),nrow=10,ncol=2)
tensor.in(X1,X2)

</code></pre>

<hr>
<h2 id='tensor.prod.S'>Tensor product for penalty matrices</h2><span id='topic+tensor.prod.S'></span>

<h3>Description</h3>

<p>Computes the penalty matrices of a tensor product smooth from the marginal penalty matrices. The code is from
function <code>tensor.prod.penalties</code> in <code>mgcv</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensor.prod.S(S)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tensor.prod.S_+3A_s">S</code></td>
<td>
<p>list of m marginal penalty matrices</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>TS</code></td>
<td>
<p>List of the penalty matrices associated with the tensor product smooth</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# tensor product between three penalty matrices
set.seed(15)

S1 &lt;- matrix(rnorm(3*3),nrow=3,ncol=3)
S2 &lt;- matrix(rnorm(2*2),nrow=2,ncol=2)

S1 &lt;- 0.5*(S1 + t(S1) ) ; S2 &lt;- 0.5*(S2 + t(S2) )

tensor.prod.S(list(S1,S2))

</code></pre>

<hr>
<h2 id='tensor.prod.X'>tensor model matrix</h2><span id='topic+tensor.prod.X'></span>

<h3>Description</h3>

<p>Computes the model matrix of tensor product smooth from the marginal bases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensor.prod.X(X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tensor.prod.X_+3A_x">X</code></td>
<td>
<p>list of m design matrices with n rows and p1, p2, ... pm columns respectively</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>T</code></td>
<td>
<p>Matrix of dimensions n*(p1*p2*...*pm) representing the row tensor product of the matrices in X</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(survPen)

# row-wise tensor product between three design matrices
set.seed(15)

X1 &lt;- matrix(rnorm(10*3),nrow=10,ncol=3)
X2 &lt;- matrix(rnorm(10*2),nrow=10,ncol=2)
X3 &lt;- matrix(rnorm(10*2),nrow=10,ncol=2)
tensor.prod.X(list(X1,X2,X3))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
