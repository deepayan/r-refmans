<!DOCTYPE html><html><head><title>Help for package deepMOU</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {deepMOU}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Abstracts'><p>Abstracts dataset</p></a></li>
<li><a href='#bubble_clust'><p>Bubble plot</p></a></li>
<li><a href='#cl_CNAE'><p>Classification labels of the CNAE2 data set</p></a></li>
<li><a href='#CNAE2'><p>CNAE dataset on classes 4 and 9</p></a></li>
<li><a href='#deep_mou_gibbs'><p>Deep Mixture of Unigrams</p></a></li>
<li><a href='#dir_mult_GD'><p>Dirichlet-Multinomial mixture model by Gradient Descend algorithm</p></a></li>
<li><a href='#heatmap_words'><p>Heatmap of word frequencies by cluster</p></a></li>
<li><a href='#mou_EM'><p>Mixture of Unigrams by Expectation-Maximization algorithm</p></a></li>
<li><a href='#plot.deepMOU'><p>Plotting method for &quot;shallow&quot; and deep mixtures of Unigrams and mixtures of Dirichlet-Multinomials</p></a></li>
<li><a href='#words_freq_plot'><p>Graph of most frequent words of each cluster</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Clustering of Short Texts by Mixture of Unigrams and Its Deep
Extensions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions providing an easy and intuitive way for fitting and clusters data using the Mixture of Unigrams models by means the Expectation-Maximization algorithm (Nigam, K. et al. (2000). &lt;<a href="https://doi.org/10.1023%2FA%3A1007692713085">doi:10.1023/A:1007692713085</a>&gt;), Mixture of Dirichlet-Multinomials estimated by Gradient Descent (Anderlucci, Viroli (2020) &lt;<a href="https://doi.org/10.1007%2Fs11634-020-00399-3">doi:10.1007/s11634-020-00399-3</a>&gt;) and Deep Mixture of Multinomials whose estimates are obtained with Gibbs sampling scheme (Viroli, Anderlucci (2020) &lt;<a href="https://doi.org/10.1007%2Fs11222-020-09989-9">doi:10.1007/s11222-020-09989-9</a>&gt;). There are also functions for graphical representation of clusters obtained.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>skmeans, extraDistr, dplyr, Rfast, entropy, ggplot2, graphics,
MASS</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-03-03 20:17:09 UTC; dippolitom</td>
</tr>
<tr>
<td>Author:</td>
<td>Martin D'Ippolito [aut, cre],
  Anderlucci Laura [aut],
  Cinzia Viroli [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Martin D'Ippolito &lt;martinmy69@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-03-04 02:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Abstracts'>Abstracts dataset</h2><span id='topic+Abstracts'></span>

<h3>Description</h3>

<p>Dataset composed by titles and abstracts of articles published in 2015 in five statistical journals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Abstracts)
</code></pre>


<h3>Format</h3>

<p>A matrix for the bag-of-words representation of the Abstracts dataset; terms are sorted in alphabetical order.
</p>


<h3>Details</h3>

<p>These are the titles and abstracts of all the articles published in 2015 by the following journals:
- Journal of American Statistical Association (JASA)
- Journal of the Royal Statistical Society - Series B
- Annals of Statistics
- Biometrika
- Statistical Science
</p>
<p>The dataset comprises 379 articles with a vocabulary of 606 words already
pre-processed (stemmed, lemmatized, stopwords removal etc.); terms with entropy
less than 0.3 were discarded (rule-of-thumb threshold).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = data(Abstracts)
print(head(x))
</code></pre>

<hr>
<h2 id='bubble_clust'>Bubble plot</h2><span id='topic+bubble_clust'></span>

<h3>Description</h3>

<p>Bi-dimensional representation (via Multi-Dimensional Scaling) of the clusters, where each bubble corresponds to a cluster,
its size is proportional to the relative frequency of documents and color saturation reflects cluster cohesion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bubble_clust(
  x,
  clusters,
  bubble_size = 1,
  bubble_col = c("red", "white"),
  cex_text = 1,
  main = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bubble_clust_+3A_x">x</code></td>
<td>
<p>Document-term matrix describing the frequency of terms that occur in a collection of documents. Rows correspond to documents in the collection and columns correspond to terms.</p>
</td></tr>
<tr><td><code id="bubble_clust_+3A_clusters">clusters</code></td>
<td>
<p>Integer vector of length of the number of cases, which indicates a clustering. The clusters have to be numbered from 1 to the number of clusters.</p>
</td></tr>
<tr><td><code id="bubble_clust_+3A_bubble_size">bubble_size</code></td>
<td>
<p>Graphical parameter for bubbles size.</p>
</td></tr>
<tr><td><code id="bubble_clust_+3A_bubble_col">bubble_col</code></td>
<td>
<p>Choose palette with two colors (default <code>"red"</code> and <code>"white"</code>).  The first (darker) color will denote homogeneous clusters, while the latter (lighter) more heterogeneous ones.</p>
</td></tr>
<tr><td><code id="bubble_clust_+3A_cex_text">cex_text</code></td>
<td>
<p>Size of texts inside bubbles.</p>
</td></tr>
<tr><td><code id="bubble_clust_+3A_main">main</code></td>
<td>
<p>A title for the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A graphical aid to visualize and to describe the obtained clusters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the CNAE2 dataset
data("CNAE2")

# Perform parameter estimation and clustering
mou_CNAE2 = mou_EM(x = CNAE2, k = 2)

# Usage of the function
bubble_clust(mou_CNAE2$x,mou_CNAE2$clusters, bubble_size = 5 )

</code></pre>

<hr>
<h2 id='cl_CNAE'>Classification labels of the CNAE2 data set</h2><span id='topic+cl_CNAE'></span>

<h3>Description</h3>

<p>True classification labels of documents from the <code>CNAE2</code> data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(CNAE2)
</code></pre>


<h3>Format</h3>

<p>A vector containing the true classification labels of documents of <code>CNAE2</code> data set.
</p>


<h3>Source</h3>

<p>See <code>CNAE2</code> for further details.
</p>

<hr>
<h2 id='CNAE2'>CNAE dataset on classes 4 and 9</h2><span id='topic+CNAE2'></span>

<h3>Description</h3>

<p>The data set <code>CNAE2</code> is a subset of the original CNAE-9 data, that 
comprises 1080 documents categorized into 9 topics of free text business 
descriptions of Brazilian companies. 
</p>
<p>Specifically, <code>CNAE2</code> contains only the documents belonging to topics &quot;4&quot; and &quot;9&quot;.
The data set is already pre-processed and provides the bag-of-words representation of
the documents; the columns with null counts are removed leading to a matrix with 240 documents
on a vocabulary with cardinality 357. This data set is highly sparse
(98
</p>
<p>Class labels are stored in <a href="#topic+cl_CNAE">cl_CNAE</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(CNAE2)
</code></pre>


<h3>Format</h3>

<p>A matrix for the bag-of-words representation of the CNAE2 dataset.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/CNAE-9">Original CNAE9 dataset</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = data(CNAE2)
print(head(x))
</code></pre>

<hr>
<h2 id='deep_mou_gibbs'>Deep Mixture of Unigrams</h2><span id='topic+deep_mou_gibbs'></span>

<h3>Description</h3>

<p>Performs parameter estimation by means of Gibbs sampling and cluster allocation
for the Deep Mixture of Unigrams.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deep_mou_gibbs(x, k, g, n_it = 500, seed_choice = 1, burn_in = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deep_mou_gibbs_+3A_x">x</code></td>
<td>
<p>Document-term matrix describing the frequency of terms that occur in a collection of documents. Rows correspond to documents in the collection and columns correspond to terms.</p>
</td></tr>
<tr><td><code id="deep_mou_gibbs_+3A_k">k</code></td>
<td>
<p>Number of clusters/groups at the top layer.</p>
</td></tr>
<tr><td><code id="deep_mou_gibbs_+3A_g">g</code></td>
<td>
<p>Number of clusters at the bottom layer.</p>
</td></tr>
<tr><td><code id="deep_mou_gibbs_+3A_n_it">n_it</code></td>
<td>
<p>Number of Gibbs steps.</p>
</td></tr>
<tr><td><code id="deep_mou_gibbs_+3A_seed_choice">seed_choice</code></td>
<td>
<p>Set seed for reproducible results.</p>
</td></tr>
<tr><td><code id="deep_mou_gibbs_+3A_burn_in">burn_in</code></td>
<td>
<p>Number of initial Gibbs samples to be discarded and not included in the computation of final estimates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Starting from the data matrix <code>x</code>, the Deep Mixture of Unigrams is fitted
and <code>k</code> clusters are obtained.
The algorithm for the estimation of the parameters is the Gibbs sampling.
In particular, the function assigns initial values to all the parameters to be estimated. Then <code>n_it</code> samples for the parameters are obtained using
conditional distributions on all the other parameters. The final estimates are obtained by averaging the samples given that initial <code>burn_in</code> samples are
discarded. Clustering is eventually performed by maximizing the posterior distribution of the latent variables.
For further details see the references.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The data matrix.</p>
</td></tr>
<tr><td><code>clusters</code></td>
<td>
<p>the clustering labels.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the number of clusters at the top layer.</p>
</td></tr>
<tr><td><code>g</code></td>
<td>
<p>the number of clusters at the bottom layer.</p>
</td></tr>
<tr><td><code>numobs</code></td>
<td>
<p>the sample size.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the vocabulary size.</p>
</td></tr>
<tr><td><code>z1</code></td>
<td>
<p>the allocation variables at the top layer.</p>
</td></tr>
<tr><td><code>z2</code></td>
<td>
<p>the allocation variables at the bottom layer.</p>
</td></tr>
<tr><td><code>Alpha</code></td>
<td>
<p>the estimates of Alpha parameters.</p>
</td></tr>
<tr><td><code>Beta</code></td>
<td>
<p>the estimates of the Beta parameters.</p>
</td></tr>
<tr><td><code>pi_hat</code></td>
<td>
<p>estimated probabilities of belonging to the <code>k</code> clusters at the top layer conditional to the <code>g</code> clusters at the bottom layer.</p>
</td></tr>
<tr><td><code>pi_hat_2</code></td>
<td>
<p>estimated probabilities of belonging to the <code>g</code> clusters at the bottom layer.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Viroli C, Anderlucci L (2020). &quot;Deep mixtures of Unigrams for uncovering topics in textual data.&quot; <em>Statistics and Computing</em>, pp. 1-18. doi: <a href="https://doi.org/10.1007/s11222-020-09989-9">10.1007/s11222-020-09989-9</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the CNAE2 dataset
data("CNAE2")

# Perform parameter estimation and clustering, very few iterations used for this example
deep_CNAE2 = deep_mou_gibbs(x = CNAE2, k = 2, g = 2, n_it = 5, burn_in = 2)

# Shows cluster labels to documents
deep_CNAE2$clusters
</code></pre>

<hr>
<h2 id='dir_mult_GD'>Dirichlet-Multinomial mixture model by Gradient Descend algorithm</h2><span id='topic+dir_mult_GD'></span>

<h3>Description</h3>

<p>Performs parameter estimation by means of a Gradient Descend algorithm and cluster allocation
for the Dirichlet-Multinomial mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dir_mult_GD(
  x,
  k,
  n_it = 100,
  eps = 1e-05,
  seed_choice = 1,
  KK = 20,
  min_iter = 2,
  init = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dir_mult_GD_+3A_x">x</code></td>
<td>
<p>Document-term matrix describing the frequency of terms that occur in a collection of documents. Rows correspond to documents in the collection and columns correspond to terms.</p>
</td></tr>
<tr><td><code id="dir_mult_GD_+3A_k">k</code></td>
<td>
<p>Number of clusters/groups.</p>
</td></tr>
<tr><td><code id="dir_mult_GD_+3A_n_it">n_it</code></td>
<td>
<p>Number of Gradient Descend steps.</p>
</td></tr>
<tr><td><code id="dir_mult_GD_+3A_eps">eps</code></td>
<td>
<p>Tolerance level for the convergence of the algorithm. Default is <code>1e-05</code>.</p>
</td></tr>
<tr><td><code id="dir_mult_GD_+3A_seed_choice">seed_choice</code></td>
<td>
<p>Set seed for reproducible results.</p>
</td></tr>
<tr><td><code id="dir_mult_GD_+3A_kk">KK</code></td>
<td>
<p>Maximum number of iterations allowed for the <a href="stats.html#topic+nlminb">nlminb</a> function (see below).</p>
</td></tr>
<tr><td><code id="dir_mult_GD_+3A_min_iter">min_iter</code></td>
<td>
<p>Minimum number of Gradient Descend steps.</p>
</td></tr>
<tr><td><code id="dir_mult_GD_+3A_init">init</code></td>
<td>
<p>Vector containing the initial document allocations for the initialization of the algorithm. If NULL (default) initialization is carried out via spherical k-means (<a href="skmeans.html#topic+skmeans">skmeans</a>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Starting from the data given by <code>x</code> the Dirichlet-Multinomial mixture model is fitted
and <code>k</code> clusters are obtained.
The algorithm for the parameter estimation is the Gradiend Descend.
In particular, the function assigns initial values to weights of the Dirichlet-Multinomial distribution for each cluster
and inital weights for the elements of the mixture. The estimates are obtained with maximum <code>n_it</code> steps of the
Descent Algorithm algorithm or until a tolerance level <code>eps</code> is reached; by using the posterior distribution
of the latent variable z, the documents are allocated to the cluster which maximizes the
posterior distribution.
For further details see the references.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The data matrix.</p>
</td></tr>
<tr><td><code>clusters</code></td>
<td>
<p>the clustering labels.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the number of clusters.</p>
</td></tr>
<tr><td><code>numobs</code></td>
<td>
<p>the sample size.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the vocabulary size.</p>
</td></tr>
<tr><td><code>likelihood</code></td>
<td>
<p>vector containing the likelihood values at each iteration.</p>
</td></tr>
<tr><td><code>pi_hat</code></td>
<td>
<p>estimated probabilities of belonging to the <code>k</code> clusters.</p>
</td></tr>
<tr><td><code>Theta</code></td>
<td>
<p>matrix containing the estimates of the Theta parameters for each cluster.</p>
</td></tr>
<tr><td><code>f_z_x</code></td>
<td>
<p>matrix containing the posterior probabilities of belonging to each cluster.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion (AIC) value of the fitted model.</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>Bayesian Information Criterion (BIC) value of the fitted model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Anderlucci L, Viroli C (2020). &quot;Mixtures of Dirichlet-Multinomial distributions for supervised and unsupervised classification of short text data.&quot; <em>Advances in Data Analysis and Classification</em>, <b>14</b>, 759-770. doi: <a href="https://doi.org/10.1007/s11634-020-00399-3">10.1007/s11634-020-00399-3</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the CNAE2 dataset
data("CNAE2")

# Perform parameter estimation and clustering, very
# few iterations are used for this example
dir_CNAE2 = dir_mult_GD(x = CNAE2, k = 2, n_it = 2)

# Shows cluster labels to documents
dir_CNAE2$clusters

</code></pre>

<hr>
<h2 id='heatmap_words'>Heatmap of word frequencies by cluster</h2><span id='topic+heatmap_words'></span>

<h3>Description</h3>

<p>Displays the heatmap of the cluster frequency distributions of the most frequent terms sorted by the most informative ones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heatmap_words(
  x,
  clusters,
  n_words = 50,
  legend_position = "bottom",
  font_size = 12,
  low_color = "grey92",
  top_color = "red",
  main = "Row frequencies of terms distribution",
  xlabel = NULL,
  ylabel = NULL,
  legend_title = "Entropy"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heatmap_words_+3A_x">x</code></td>
<td>
<p>Document-term matrix describing the frequency of terms that occur in a collection of documents. Rows correspond to documents in the collection and columns correspond to terms.</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_clusters">clusters</code></td>
<td>
<p>Integer vector of length of the number of cases, which indicates a clustering. The clusters have to be numbered from 1 to the number of clusters.</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_n_words">n_words</code></td>
<td>
<p>Number of words to include in the heatmap (default is 50).</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_legend_position">legend_position</code></td>
<td>
<p>Position of the legend (<code>"none"</code>, <code>"left"</code>, <code>"right"</code>, <code>"bottom"</code>, <code>"top"</code>, or two-element numeric vector as in <a href="ggplot2.html#topic+theme">theme</a>). Default is <code>"bottom"</code>.</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_font_size">font_size</code></td>
<td>
<p>Text size in pts (default is 12).</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_low_color">low_color</code></td>
<td>
<p>Base color for terms with no occurrence in a cluster (default is <code>"grey92"</code>)</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_top_color">top_color</code></td>
<td>
<p>Base color for terms concentrated in a single cluster (default is <code>"red"</code>)</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_main">main</code></td>
<td>
<p>A title for the plot. Default is <code>"Row frequencies of terms distribution"</code>.</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_xlabel">xlabel</code></td>
<td>
<p>A title for the x-axis. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_ylabel">ylabel</code></td>
<td>
<p>A title for the y-axis. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="heatmap_words_+3A_legend_title">legend_title</code></td>
<td>
<p>A title for the legend. Default is <code>"Entropy"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Takes as input the bag-of-words matrix and returns a heatmap displaying the row
frequency distribution of terms according to the clusters. Words are sorted by entropy.
</p>


<h3>Value</h3>

<p>A graphical aid to describe the clusters according to the most informative words.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the CNAE2 dataset
data("CNAE2")

# Get document labels by clustering using mou_EM
mou_CNAE2 = mou_EM(x = CNAE2, k = 2)

# Usage of the function
heatmap_words(x = mou_CNAE2$x, clusters = mou_CNAE2$clusters)

</code></pre>

<hr>
<h2 id='mou_EM'>Mixture of Unigrams by Expectation-Maximization algorithm</h2><span id='topic+mou_EM'></span>

<h3>Description</h3>

<p>Performs parameter estimation by means of the Expectation-Maximization (EM) algorithm and cluster allocation
for the Mixture of Unigrams.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mou_EM(x, k, n_it = 100, eps = 1e-07, seed_choice = 1, init = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mou_EM_+3A_x">x</code></td>
<td>
<p>Document-term matrix describing the frequency of terms that occur in a collection of documents. Rows correspond to documents in the collection and columns correspond to terms.</p>
</td></tr>
<tr><td><code id="mou_EM_+3A_k">k</code></td>
<td>
<p>Number of clusters/groups.</p>
</td></tr>
<tr><td><code id="mou_EM_+3A_n_it">n_it</code></td>
<td>
<p>Number of iterations for the Expectation-Maximization algorithm.</p>
</td></tr>
<tr><td><code id="mou_EM_+3A_eps">eps</code></td>
<td>
<p>Tolerance level for the convergence of the algorithm. Default is <code>1e-07</code>.</p>
</td></tr>
<tr><td><code id="mou_EM_+3A_seed_choice">seed_choice</code></td>
<td>
<p>Set seed for reproducible results</p>
</td></tr>
<tr><td><code id="mou_EM_+3A_init">init</code></td>
<td>
<p>Vector containing the initial document allocations for the initialization of the algorithm. If NULL (default) initialization is carried out via spherical k-means (<a href="skmeans.html#topic+skmeans">skmeans</a>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Starting from the data given by <code>x</code> the Mixture of Unigrams is fitted
and <code>k</code> clusters are obtained.
The algorithm for the parameter estimation is the Expectation-Maximization (EM).
In particular, the function assigns initial values to weights of the Multinomial distribution for each cluster
and inital weights for the components of the mixture. The estimates are obtained with maximum <code>n_it</code> steps of the
EM algorithm or until the tolerance level <code>eps</code> is reached; by using the posterior distribution
of the latent variable z, the documents are allocated to the cluster which maximizes the
posterior distribution.
For further details see the references.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The data matrix.</p>
</td></tr>
<tr><td><code>clusters</code></td>
<td>
<p>the clustering labels.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the number of clusters.</p>
</td></tr>
<tr><td><code>numobs</code></td>
<td>
<p>the sample size.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the vocabulary size.</p>
</td></tr>
<tr><td><code>likelihood</code></td>
<td>
<p>vector containing the likelihood values at each iteration.</p>
</td></tr>
<tr><td><code>pi_hat</code></td>
<td>
<p>estimated probabilities of belonging to the <code>k</code> clusters.</p>
</td></tr>
<tr><td><code>omega</code></td>
<td>
<p>matrix containing the estimates of the omega parameters for each cluster.</p>
</td></tr>
<tr><td><code>f_z_x</code></td>
<td>
<p>matrix containing the posterior probabilities of belonging to each cluster.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike Information Criterion (AIC) value of the fitted model.</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>Bayesian Information Criterion (BIC) value of the fitted model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Nigam, K., McCallum, A., Thrun, S., Mitchell, T.: Text classification from labeled and unlabeled documents using EM. Machine learning 39, 103-134 (2000).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the CNAE2 dataset
data("CNAE2")

# Perform parameter estimation and clustering
mou_CNAE2 = mou_EM(x = CNAE2, k = 2)

# Shows cluster labels to documents
mou_CNAE2$clusters

</code></pre>

<hr>
<h2 id='plot.deepMOU'>Plotting method for &quot;shallow&quot; and deep mixtures of Unigrams and mixtures of Dirichlet-Multinomials</h2><span id='topic+plot.deepMOU'></span>

<h3>Description</h3>

<p>Bi-dimensional representation (via Multi-Dimensional Scaling) of the clusters, where each bubble corresponds to a cluster,
its size is proportional to the relative frequency of documents and color saturation reflects cluster cohesion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'deepMOU'
plot(
  x,
  y,
  bubble_size = 1,
  bubble_col = c("red", "white"),
  cex_text = 1,
  main = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.deepMOU_+3A_x">x</code></td>
<td>
<p>Output from <code>mou_EM</code>, <code>dir_mult_GD</code> or <code>deep_mou_gibbs</code>.</p>
</td></tr>
<tr><td><code id="plot.deepMOU_+3A_y">y</code></td>
<td>
<p>Parameter not used</p>
</td></tr>
<tr><td><code id="plot.deepMOU_+3A_bubble_size">bubble_size</code></td>
<td>
<p>Graphical parameter for bubbles size.</p>
</td></tr>
<tr><td><code id="plot.deepMOU_+3A_bubble_col">bubble_col</code></td>
<td>
<p>Choose palette with two colors (default <code>"red"</code> and <code>"white"</code>).  The first (darker) color will denote homogeneous clusters, while the latter (lighter) more heterogeneous ones.</p>
</td></tr>
<tr><td><code id="plot.deepMOU_+3A_cex_text">cex_text</code></td>
<td>
<p>Size of texts inside bubbles.</p>
</td></tr>
<tr><td><code id="plot.deepMOU_+3A_main">main</code></td>
<td>
<p>A main title for the plot.</p>
</td></tr>
<tr><td><code id="plot.deepMOU_+3A_...">...</code></td>
<td>
<p>Parameter not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default graphical representation of <code>mou_EM</code>, <code>dir_mult_GD</code> and <code>deep_mou_gibbs</code> is the bubble plot. 
Namely, a bi-dimensional representation (via Multi-Dimensional Scaling) of the clusters, each bubble corresponds to a cluster,
its size is proportional to the relative frequency of documents and color saturation reflects cluster cohesion.
</p>


<h3>Value</h3>

<p>A graphical aid to visualize and to describe the obtained clusters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the CNAE2 dataset
data("CNAE2")

# Perform parameter estimation and clustering
mou_CNAE2 = mou_EM(x = CNAE2, k = 2)

# Usage of the function
plot(mou_CNAE2, bubble_size = 5 )

</code></pre>

<hr>
<h2 id='words_freq_plot'>Graph of most frequent words of each cluster</h2><span id='topic+words_freq_plot'></span>

<h3>Description</h3>

<p>Graphical plot of the most frequent words of each cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>words_freq_plot(
  x,
  clusters,
  clust_label = NULL,
  n_words = 5,
  words_size = 2,
  axis_size = 1,
  set_colors = NA,
  main = "Most frequent words for each cluster",
  xlabel = "",
  ylabel = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="words_freq_plot_+3A_x">x</code></td>
<td>
<p>Document-term matrix describing the frequency of terms that occur in a collection of documents. Rows correspond to documents in the collection and columns correspond to terms.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_clusters">clusters</code></td>
<td>
<p>Integer vector of length of the number of cases, which indicates a clustering. The clusters have to be numbered from 1 to the number of clusters.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_clust_label">clust_label</code></td>
<td>
<p>Vector of length of the number of cluster containing the cluster names to be displayed (by default <code>"Cluster_1"</code>, <code>"Cluster_2"</code>, ...).</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_n_words">n_words</code></td>
<td>
<p>Number of words to display.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_words_size">words_size</code></td>
<td>
<p>A numerical value giving the amount by which plotting words should be magnified with respect to the default setting.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_axis_size">axis_size</code></td>
<td>
<p>Magnification to be used for axis annotation with respect to the default setting.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_set_colors">set_colors</code></td>
<td>
<p>Choose palette for word colors.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_main">main</code></td>
<td>
<p>A title for the plot. Default is <code>"Most frequent words for each cluster"</code>.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_xlabel">xlabel</code></td>
<td>
<p>A title for the x-axis. Default is empty.</p>
</td></tr>
<tr><td><code id="words_freq_plot_+3A_ylabel">ylabel</code></td>
<td>
<p>A title for the y-axis. Default is empty.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of most frequent words to be shown can be set by
<code>n_words</code> and also clusters names can be passed beforehand as a character
vector to <code>clust_label</code>
</p>


<h3>Value</h3>

<p>A graphical aid for visualizing the most frequent terms for each cluster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the CNAE2 dataset
data("CNAE2")

# Perform parameter estimation and clustering
mou_CNAE2 = mou_EM(x = CNAE2, k = 2)

# Usage of the function
words_freq_plot(mou_CNAE2$x, mou_CNAE2$clusters,n_words = 4, words_size = 2, main = "Example" )

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
