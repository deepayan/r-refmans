<!DOCTYPE html><html><head><title>Help for package drpop</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {drpop}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#informat'><p>A function to check whether a given data table/matrix/data frame is in the appropriate for drpop.</p></a></li>
<li><a href='#plotci'><p>Plot estimated confidence interval of total population size from object of class <code>popsize</code> or <code>popsize_cond</code>.</p></a></li>
<li><a href='#popsize'><p>Estimate total population size and capture probability using user provided set of models or user provided nuisance estimates.</p></a></li>
<li><a href='#popsize_cond'><p>Estimate total population size and capture probability using user provided set of models conditioned on an attribute.</p></a></li>
<li><a href='#popsize_simul'><p>Estimate the total population size and capture probabilities using perturbed true nuisance functions.</p></a></li>
<li><a href='#qhat_gam'><p>Estimate marginal and joint distribution of lists j and k using generalized additive models.</p></a></li>
<li><a href='#qhat_logit'><p>Estimate marginal and joint distribution of lists j and k using logistic regression.</p></a></li>
<li><a href='#qhat_mlogit'><p>Estimate marginal and joint distribution of lists j and k using multinomial logistic model.</p></a></li>
<li><a href='#qhat_ranger'><p>Estimate marginal and joint distribution of lists j and k using ranger.</p></a></li>
<li><a href='#qhat_rangerlogit'><p>Estimate marginal and joint distribution of lists j and k using ensemble of ranger and logit.</p></a></li>
<li><a href='#qhat_sl'><p>Estimate marginal and joint distribution of lists j and k using super learner.</p></a></li>
<li><a href='#reformat'><p>A function to reorder the columns of a data table/matrix/data frame and to change factor variables to numeric.</p></a></li>
<li><a href='#simuldata'><p>A function to reorder the columns of a data table/matrix/data frame and to change factor variables to numeric.</p></a></li>
<li><a href='#tmle'><p>Returns the targeted maximum likelihood estimates for the nuisance functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Efficient and Doubly Robust Population Size Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimation of the total population size from capture-recapture data efficiently and with low bias implementing the methods from Das M, Kennedy EH, and Jewell NP (2021) &lt;<a href="https://arxiv.org/abs/2104.14091">arXiv:2104.14091</a>&gt;. The estimator is doubly robust against errors in the estimation of the intermediate nuisance parameters. Users can choose from the flexible estimation models provided in the package, or use any other preferred model.</td>
</tr>
<tr>
<td>Depends:</td>
<td>stats</td>
</tr>
<tr>
<td>Imports:</td>
<td>gam, janitor, reshape2, stringr, tidyr, dplyr, SuperLearner,
ggplot2, nnet, nnls, parallel, ranger</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 2.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-11-05 20:41:47 UTC; manja</td>
</tr>
<tr>
<td>Author:</td>
<td>Manjari Das <a href="https://orcid.org/0000-0002-6781-6368"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Edward H. Kennedy <a href="https://orcid.org/0000-0002-1510-8175"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Manjari Das &lt;manjari8d@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-11-05 21:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='informat'>A function to check whether a given data table/matrix/data frame is in the appropriate for drpop.</h2><span id='topic+informat'></span>

<h3>Description</h3>

<p>A function to check whether a given data table/matrix/data frame is in the appropriate for drpop.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>informat(data, K = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="informat_+3A_data">data</code></td>
<td>
<p>The data table/matrix/data frame which is to be checked.</p>
</td></tr>
<tr><td><code id="informat_+3A_k">K</code></td>
<td>
<p>The number of lists (optional).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean for whether <code>data</code> is in the appropriate format.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = matrix(sample(c(0,1), 2000, replace = TRUE), ncol = 2)
x = matrix(rnorm(nrow(data)*3, 2,1), nrow = nrow(data))

informat(data = data)
#this returns TRUE

data = cbind(data, x)
informat(data = data)
#this returns TRUE

informat(data = data, K = 3)
#this returns FALSE
</code></pre>

<hr>
<h2 id='plotci'>Plot estimated confidence interval of total population size from object of class <code>popsize</code> or <code>popsize_cond</code>.</h2><span id='topic+plotci'></span>

<h3>Description</h3>

<p>Plot estimated confidence interval of total population size from object of class <code>popsize</code> or <code>popsize_cond</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotci(object, tsize = 12, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotci_+3A_object">object</code></td>
<td>
<p>An object of class <code>popsize</code> or <code>popsize_cond</code>.</p>
</td></tr>
<tr><td><code id="plotci_+3A_tsize">tsize</code></td>
<td>
<p>The text size for the plots.</p>
</td></tr>
<tr><td><code id="plotci_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object <code>fig</code> with population size estimates and the 95% confidence intervals.
</p>


<h3>References</h3>

<p>H. Wickham. ggplot2: Elegant Graphics for Data Analysis. <em>Springer-Verlag</em> New York, 2016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data = simuldata(n = 10000, l = 1)$data_xstar

p = popsize(data = data, funcname = c("logit", "gam"))
plotci(p)

data = simuldata(n = 10000, l = 1, categorical = TRUE)$data_xstar
p = popsize_cond(data = data, condvar = 'catcov')
plotci(p)

</code></pre>

<hr>
<h2 id='popsize'>Estimate total population size and capture probability using user provided set of models or user provided nuisance estimates.</h2><span id='topic+popsize'></span>

<h3>Description</h3>

<p>Estimate total population size and capture probability using user provided set of models or user provided nuisance estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>popsize(
  data,
  K = 2,
  j,
  k,
  margin = 0.005,
  filterrows = FALSE,
  nfolds = 5,
  funcname = c("rangerlogit"),
  sl.lib = c("SL.gam", "SL.glm", "SL.glm.interaction", "SL.ranger", "SL.glmnet"),
  getnuis,
  q1mat,
  q2mat,
  q12mat,
  idfold,
  TMLE = TRUE,
  PLUGIN = TRUE,
  Nmin = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="popsize_+3A_data">data</code></td>
<td>
<p>The data frame in capture-recapture format with <code>K</code> lists for which total population is to be estimated.
The first K columns are the capture history indicators for the <code>K</code> lists. The remaining columns are covariates in numeric format.</p>
</td></tr>
<tr><td><code id="popsize_+3A_k">K</code></td>
<td>
<p>The number of lists that are present in the data.</p>
</td></tr>
<tr><td><code id="popsize_+3A_j">j</code></td>
<td>
<p>The first list to be used for estimation.</p>
</td></tr>
<tr><td><code id="popsize_+3A_k">k</code></td>
<td>
<p>The secod list to be used in the estimation.</p>
</td></tr>
<tr><td><code id="popsize_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="popsize_+3A_filterrows">filterrows</code></td>
<td>
<p>A logical value denoting whether to remove all rows with only zeroes.</p>
</td></tr>
<tr><td><code id="popsize_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to be used for cross fitting.</p>
</td></tr>
<tr><td><code id="popsize_+3A_funcname">funcname</code></td>
<td>
<p>The vector of estimation function names to obtain the population size.</p>
</td></tr>
<tr><td><code id="popsize_+3A_sl.lib">sl.lib</code></td>
<td>
<p>Algorithm library for <code><a href="#topic+qhat_sl">qhat_sl()</a></code>. See <code><a href="SuperLearner.html#topic+listWrappers">SuperLearner::listWrappers()</a></code>. Default library includes &quot;gam&quot;, &quot;glm&quot;, &quot;glmnet&quot;, &quot;glm.interaction&quot;, &quot;ranger&quot;.</p>
</td></tr>
<tr><td><code id="popsize_+3A_getnuis">getnuis</code></td>
<td>
<p>A list object with the nuisance function estimates and the fold assignment of the rows for cross-fitting or a data.frame with the nuisance estimates.</p>
</td></tr>
<tr><td><code id="popsize_+3A_q1mat">q1mat</code></td>
<td>
<p>A dataframe with capture probabilities for the first list.</p>
</td></tr>
<tr><td><code id="popsize_+3A_q2mat">q2mat</code></td>
<td>
<p>A dataframe with capture probabilities for the second list.</p>
</td></tr>
<tr><td><code id="popsize_+3A_q12mat">q12mat</code></td>
<td>
<p>A dataframe with capture probabilities for both the lists simultaneously.</p>
</td></tr>
<tr><td><code id="popsize_+3A_idfold">idfold</code></td>
<td>
<p>The fold assignment of each row during estimation.</p>
</td></tr>
<tr><td><code id="popsize_+3A_tmle">TMLE</code></td>
<td>
<p>The logical value to indicate whether TMLE has to be computed.</p>
</td></tr>
<tr><td><code id="popsize_+3A_plugin">PLUGIN</code></td>
<td>
<p>The logical value to indicate whether the plug-in estimates are returned.</p>
</td></tr>
<tr><td><code id="popsize_+3A_nmin">Nmin</code></td>
<td>
<p>The cutoff for minimum sample size to perform doubly robust estimation. Otherwise, Petersen estimator is returned.</p>
</td></tr>
<tr><td><code id="popsize_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function. See <code><a href="#topic+qhat_rangerlogit">qhat_rangerlogit()</a></code>, <code><a href="#topic+qhat_sl">qhat_sl()</a></code>, <code><a href="#topic+tmle">tmle()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of estimates containing the following components for each list-pair, model and method (PI = plug-in, DR = doubly-robust, TMLE = targeted maximum likelihood estimate):
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>  A dataframe of the below estimated quantities.
</p>

<ul>
<li><p>psi  The estimated capture probability.
</p>
</li>
<li><p>sigma  The efficiency bound.
</p>
</li>
<li><p>n  The estimated population size n.
</p>
</li>
<li><p>sigman  The estimated standard deviation of the population size.
</p>
</li>
<li><p>cin.l  The estimated lower bound of a 95% confidence interval of <code>n</code>.
</p>
</li>
<li><p>cin.u  The estimated upper bound of a 95% confidence interval of <code>n</code>.</p>
</li></ul>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>  The number of data points used in the estimation after removing rows with missing data.</p>
</td></tr>
<tr><td><code>ifvals</code></td>
<td>
<p>  The estimated influence function values for the observed data.</p>
</td></tr>
<tr><td><code>nuis</code></td>
<td>
<p>  The estimated nuisance functions (q12, q1, q2) for each element in funcname.</p>
</td></tr>
<tr><td><code>nuistmle</code></td>
<td>
<p>  The estimated nuisance functions (q12, q1, q2) from tmle for each element in funcname.</p>
</td></tr>
<tr><td><code>idfold</code></td>
<td>
<p>  The division of the rows into sets (folds) for cross-fitting.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bickel, P. J., Klaassen, C. A., Bickel, P. J., Ritov, Y., Klaassen, J., Wellner, J. A., and Ritov, Y. (1993). Efficient and adaptive estimation for semiparametric models, volume 4. <em>Johns Hopkins University Press Baltimore</em>
</p>
<p>van der Vaart, A. (2002a). Part iii: Semiparameric statistics. Lectures on Probability Theory and Statistics, pages 331-457
</p>
<p>van der Laan, M. J. and Robins, J. M. (2003). Unified methods for censored longitudinal data and causality. <em>Springer Science &amp; Business Media</em>
</p>
<p>Tsiatis, A. (2006). Semiparametric theory and missing data <em>springer. New York</em>
</p>
<p>Kennedy, E. H. (2016). Semiparametric theory and empirical processes in causal inference. <em>Statistical causal inferences and their applications in public health research</em>, pages 141-167. <em>Springer</em>
</p>
<p>Das, M., Kennedy, E. H., &amp; Jewell, N.P. (2021). Doubly robust capture-recapture methods for estimating population size. <em>arXiv preprint</em> <em>arXiv:2104.14091</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data = simuldata(1000, l = 3)$data
qhat = popsize(data = data, funcname = c("logit", "gam"), nfolds = 2, margin = 0.005)
psin_estimate = popsize(data = data, getnuis = qhat$nuis, idfold = qhat$idfold)

data = simuldata(n = 6000, l = 3)$data
psin_estimate = popsize(data = data[,1:2])
#this returns the basic plug-in estimate since covariates are absent.

psin_estimate = popsize(data = data, funcname = c("gam", "rangerlogit"))

</code></pre>

<hr>
<h2 id='popsize_cond'>Estimate total population size and capture probability using user provided set of models conditioned on an attribute.</h2><span id='topic+popsize_cond'></span>

<h3>Description</h3>

<p>Estimate total population size and capture probability using user provided set of models conditioned on an attribute.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>popsize_cond(
  data,
  K = 2,
  filterrows = FALSE,
  funcname = c("rangerlogit"),
  condvar,
  nfolds = 2,
  margin = 0.005,
  sl.lib = c("SL.gam", "SL.glm", "SL.glm.interaction", "SL.ranger", "SL.glmnet"),
  TMLE = TRUE,
  PLUGIN = TRUE,
  Nmin = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="popsize_cond_+3A_data">data</code></td>
<td>
<p>The data frame in capture-recapture format for which total population is to be estimated.
The first K columns are the capture history indicators for the K lists. The remaining columns are covariates in numeric format.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_k">K</code></td>
<td>
<p>The number of lists in the data. typically the first <code>K</code> rows of data.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_filterrows">filterrows</code></td>
<td>
<p>A logical value denoting whether to remove all rows with only zeroes.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_funcname">funcname</code></td>
<td>
<p>The vector of estimation function names to obtain the population size.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_condvar">condvar</code></td>
<td>
<p>The covariate for which conditional estimates are required.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to be used for cross fitting.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_sl.lib">sl.lib</code></td>
<td>
<p>Algorithm library for <code><a href="#topic+qhat_sl">qhat_sl()</a></code>. See <code><a href="SuperLearner.html#topic+listWrappers">SuperLearner::listWrappers()</a></code>. Default library includes &quot;gam&quot;, &quot;glm&quot;, &quot;glmnet&quot;, &quot;glm.interaction&quot;, &quot;ranger&quot;.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_tmle">TMLE</code></td>
<td>
<p>The logical value to indicate whether TMLE has to be computed.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_plugin">PLUGIN</code></td>
<td>
<p>The logical value to indicate whether the plug-in estimates are returned.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_nmin">Nmin</code></td>
<td>
<p>The cutoff for minimum sample size to perform doubly robust estimation. Otherwise, Petersen estimator is returned.</p>
</td></tr>
<tr><td><code id="popsize_cond_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function. See <code><a href="#topic+qhat_rangerlogit">qhat_rangerlogit()</a></code>, <code><a href="#topic+qhat_sl">qhat_sl()</a></code>, <code><a href="#topic+tmle">tmle()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of estimates containing the following components for each list-pair, model and method (PI = plug-in, DR = doubly-robust, TMLE = targeted maximum likelihood estimate):
</p>
<table>
<tr><td><code>result</code></td>
<td>
<p>  A dataframe of the below estimated quantities.
</p>

<ul>
<li><p>psi  The estimated capture probability.
</p>
</li>
<li><p>sigma  The efficiency bound.
</p>
</li>
<li><p>n  The estimated population size n.
</p>
</li>
<li><p>sigman  The estimated standard deviation of the population size.
</p>
</li>
<li><p>cin.l  The estimated lower bound of a 95% confidence interval of <code>n</code>.
</p>
</li>
<li><p>cin.u  The estimated upper bound of a 95% confidence interval of <code>n</code>.</p>
</li></ul>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>  The number of data points used in the estimation after removing rows with missing data.</p>
</td></tr>
<tr><td><code>ifvals</code></td>
<td>
<p>  The estimated influence function values for the observed data.</p>
</td></tr>
<tr><td><code>nuis</code></td>
<td>
<p>  The estimated nuisance functions (q12, q1, q2) for each element in funcname.</p>
</td></tr>
<tr><td><code>nuistmle</code></td>
<td>
<p>  The estimated nuisance functions (q12, q1, q2) from tmle for each element in funcname.</p>
</td></tr>
<tr><td><code>idfold</code></td>
<td>
<p>  The division of the rows into sets (folds) for cross-fitting.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Das, M., Kennedy, E. H., &amp; Jewell, N.P. (2021). Doubly robust capture-recapture methods for estimating population size. <em>arXiv preprint</em> <em>arXiv:2104.14091</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+popsize">popsize</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data = simuldata(n = 10000, l = 2, categorical = TRUE)$data

psin_estimate = popsize_cond(data = data, funcname = c("logit", "gam"),
     condvar = 'catcov', PLUGIN = TRUE, TMLE = TRUE)
#this returns the plug-in, the bias-corrected and the tmle estimate for the
#two models conditioned on column catcov

</code></pre>

<hr>
<h2 id='popsize_simul'>Estimate the total population size and capture probabilities using perturbed true nuisance functions.</h2><span id='topic+popsize_simul'></span>

<h3>Description</h3>

<p>Estimate the total population size and capture probabilities using perturbed true nuisance functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>popsize_simul(
  data,
  n,
  K = 2,
  nfolds = 5,
  pi1,
  pi2,
  omega,
  alpha,
  margin = 0.005,
  iter = 100,
  twolist = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="popsize_simul_+3A_data">data</code></td>
<td>
<p>The data frame in capture-recapture format for which total population is to be estimated.
The first K columns are the capture history indicators for the K lists. The remaining columns are covariates in numeric format.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_n">n</code></td>
<td>
<p>The true population size. Required to calculate the added error.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_k">K</code></td>
<td>
<p>The number of lists in the data. typically the first <code>K</code> rows of data.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds to be used for cross fitting.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_pi1">pi1</code></td>
<td>
<p>The function to calculate the conditional capture probabilities of list 1 using covariates.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_pi2">pi2</code></td>
<td>
<p>The function to calculate the conditional capture probabilities of list 2 using covariates.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_omega">omega</code></td>
<td>
<p>The standard deviation from zero of the added error.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_alpha">alpha</code></td>
<td>
<p>The rate of convergence. Takes values in (0, 1].</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_iter">iter</code></td>
<td>
<p>An integer denoting the maximum number of iterations allowed for targeted maximum likelihood method.</p>
</td></tr>
<tr><td><code id="popsize_simul_+3A_twolist">twolist</code></td>
<td>
<p>The logical value of whether targeted maximum likelihood algorithm fits only two modes when K = 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of estimates containing the following components:
</p>
<table>
<tr><td><code>psi</code></td>
<td>
<p>  A matrix of the estimated capture probability for each list pair, model and method combination. In the absence of covariates, the column represents the standard plug-in estimate.
The rows represent the list pair which is assumed to be independent conditioned on the covariates.
The columns represent the model and method combinations (PI = plug-in, DR = bias-corrected, TMLE = targeted maximum likelihood estimate)indicated in the columns.</p>
</td></tr>
<tr><td><code>sigma2</code></td>
<td>
<p>  A matrix of the efficiency bound <code>sigma^2</code> in the same format as <code>psi</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>  A matrix of the estimated population size n in the same format as <code>psi</code>.</p>
</td></tr>
<tr><td><code>varn</code></td>
<td>
<p>  A matrix of the variance for population size estimate in the same format as <code>psi</code>.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>  The number of data points used in the estimation after removing rows with missing data.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Das, M., Kennedy, E. H., &amp; Jewell, N.P. (2021). Doubly robust capture-recapture methods for estimating population size. <em>arXiv preprint</em> <em>arXiv:2104.14091</em>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simulresult = simuldata(n = 2000, l = 2)
data = simulresult$data

psin_estimate = popsize_simul(data = data,
      pi1 = simulresult$pi1, pi2 = simulresult$pi2,
      alpha = 0.25, omega = 1)

</code></pre>

<hr>
<h2 id='qhat_gam'>Estimate marginal and joint distribution of lists j and k using generalized additive models.</h2><span id='topic+qhat_gam'></span>

<h3>Description</h3>

<p>Estimate marginal and joint distribution of lists j and k using generalized additive models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qhat_gam(List.train, List.test, K = 2, j = 1, k = 2, margin = 0.005, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qhat_gam_+3A_list.train">List.train</code></td>
<td>
<p>The training data matrix used to estimate the distibution functions.</p>
</td></tr>
<tr><td><code id="qhat_gam_+3A_list.test">List.test</code></td>
<td>
<p>The data matrix on which the estimator function is applied.</p>
</td></tr>
<tr><td><code id="qhat_gam_+3A_k">K</code></td>
<td>
<p>The number of lists in the data.</p>
</td></tr>
<tr><td><code id="qhat_gam_+3A_j">j</code></td>
<td>
<p>The first list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_gam_+3A_k">k</code></td>
<td>
<p>The second list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_gam_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="qhat_gam_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the marginal and joint distribution probabilities <code>q1</code>, <code>q2</code> and <code>q12</code>.
</p>


<h3>References</h3>

<p>Trevor Hastie (2020). gam: Generalized Additive Models. <em>R package version 1.20</em>. https://CRAN.R-project.org/package=gam
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
qhat = qhat_gam(List.train = List.train, List.test = List.test, margin = 0.005)
q1 = qhat$q1
q2 = qhat$q2
q12 = qhat$q12

## End(Not run)
</code></pre>

<hr>
<h2 id='qhat_logit'>Estimate marginal and joint distribution of lists j and k using logistic regression.</h2><span id='topic+qhat_logit'></span>

<h3>Description</h3>

<p>Estimate marginal and joint distribution of lists j and k using logistic regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qhat_logit(List.train, List.test, K = 2, j = 1, k = 2, margin = 0.005, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qhat_logit_+3A_list.train">List.train</code></td>
<td>
<p>The training data matrix used to estimate the distibution functions.</p>
</td></tr>
<tr><td><code id="qhat_logit_+3A_list.test">List.test</code></td>
<td>
<p>The data matrix on which the estimator function is applied.</p>
</td></tr>
<tr><td><code id="qhat_logit_+3A_k">K</code></td>
<td>
<p>The number of lists in the data.</p>
</td></tr>
<tr><td><code id="qhat_logit_+3A_j">j</code></td>
<td>
<p>The first list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_logit_+3A_k">k</code></td>
<td>
<p>The second list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_logit_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="qhat_logit_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the marginal and joint distribution probabilities <code>q1</code>, <code>q2</code> and <code>q12</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
qhat = qhat_logit(List.train = List.train, List.test = List.test, margin = 0.005)
q1 = qhat$q1
q2 = qhat$q2
q12 = qhat$q12

## End(Not run)
</code></pre>

<hr>
<h2 id='qhat_mlogit'>Estimate marginal and joint distribution of lists j and k using multinomial logistic model.</h2><span id='topic+qhat_mlogit'></span>

<h3>Description</h3>

<p>Estimate marginal and joint distribution of lists j and k using multinomial logistic model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qhat_mlogit(List.train, List.test, K = 2, j = 1, k = 2, margin = 0.005, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qhat_mlogit_+3A_list.train">List.train</code></td>
<td>
<p>The training data matrix used to estimate the distibution functions.</p>
</td></tr>
<tr><td><code id="qhat_mlogit_+3A_list.test">List.test</code></td>
<td>
<p>The data matrix on which the estimator function is applied.</p>
</td></tr>
<tr><td><code id="qhat_mlogit_+3A_k">K</code></td>
<td>
<p>The number of lists in the data.</p>
</td></tr>
<tr><td><code id="qhat_mlogit_+3A_j">j</code></td>
<td>
<p>The first list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_mlogit_+3A_k">k</code></td>
<td>
<p>The second list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_mlogit_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="qhat_mlogit_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the marginal and joint distribution probabilities <code>q1</code>, <code>q2</code> and <code>q12</code>.
</p>


<h3>References</h3>

<p>Croissant Y (2020). Estimation of Random Utility Models in R: The mlogit Package. <em>Journal of Statistical Software</em>, <em>95</em>(11), 1-41. doi: 10.18637/jss.v095.i11 (URL: https://doi.org/10.18637/jss.v095.i11).
</p>
<p>Venables, W. N. &amp; Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth Edition. <em>Springer</em>, New York. ISBN 0-387-95457-0
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
qhat = qhat_mlogit(List.train = List.train, List.test = List.test, margin = 0.005)
q1 = qhat$q1
q2 = qhat$q2
q12 = qhat$q12

## End(Not run)
</code></pre>

<hr>
<h2 id='qhat_ranger'>Estimate marginal and joint distribution of lists j and k using ranger.</h2><span id='topic+qhat_ranger'></span>

<h3>Description</h3>

<p>Estimate marginal and joint distribution of lists j and k using ranger.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qhat_ranger(List.train, List.test, K = 2, j = 1, k = 2, margin = 0.005, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qhat_ranger_+3A_list.train">List.train</code></td>
<td>
<p>The training data matrix used to estimate the distibution functions.</p>
</td></tr>
<tr><td><code id="qhat_ranger_+3A_list.test">List.test</code></td>
<td>
<p>The data matrix on which the estimator function is applied.</p>
</td></tr>
<tr><td><code id="qhat_ranger_+3A_k">K</code></td>
<td>
<p>The number of lists in the data.</p>
</td></tr>
<tr><td><code id="qhat_ranger_+3A_j">j</code></td>
<td>
<p>The first list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_ranger_+3A_k">k</code></td>
<td>
<p>The second list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_ranger_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="qhat_ranger_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the marginal and joint distribution probabilities <code>q1</code>, <code>q2</code> and <code>q12</code>.
</p>


<h3>References</h3>

<p>Marvin N. Wright, Andreas Ziegler (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. <em>Journal of Statistical Software</em>, <em>77</em>(1), 1-17. doi:10.18637/jss.v077.i01
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
qhat = qhat_ranger(List.train = List.train, List.test = List.test, margin = 0.005)
q1 = qhat$q1
q2 = qhat$q2
q12 = qhat$q12

## End(Not run)
</code></pre>

<hr>
<h2 id='qhat_rangerlogit'>Estimate marginal and joint distribution of lists j and k using ensemble of ranger and logit.</h2><span id='topic+qhat_rangerlogit'></span>

<h3>Description</h3>

<p>Estimate marginal and joint distribution of lists j and k using ensemble of ranger and logit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qhat_rangerlogit(
  List.train,
  List.test,
  K = 2,
  j = 1,
  k = 2,
  margin = 0.005,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qhat_rangerlogit_+3A_list.train">List.train</code></td>
<td>
<p>The training data matrix used to estimate the distibution functions.</p>
</td></tr>
<tr><td><code id="qhat_rangerlogit_+3A_list.test">List.test</code></td>
<td>
<p>The data matrix on which the estimator function is applied.</p>
</td></tr>
<tr><td><code id="qhat_rangerlogit_+3A_k">K</code></td>
<td>
<p>The number of lists in the data.</p>
</td></tr>
<tr><td><code id="qhat_rangerlogit_+3A_j">j</code></td>
<td>
<p>The first list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_rangerlogit_+3A_k">k</code></td>
<td>
<p>The second list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_rangerlogit_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="qhat_rangerlogit_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the marginal and joint distribution probabilities <code>q1</code>, <code>q2</code> and <code>q12</code>.
</p>


<h3>References</h3>

<p>Marvin N. Wright, Andreas Ziegler (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. <em>Journal of Statistical Software</em>, <em>77</em>(1), 1-17. doi:10.18637/jss.v077.i01
</p>
<p>Polley, Eric C. and van der Laan, Mark J., (May 2010) Super Learner In Prediction. <em>U.C. Berkeley Division of Biostatistics Working Paper Series</em>. Working Paper 266. https://biostats.bepress.com/ucbbiostat/paper266
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
qhat = qhat_ranger(List.train = List.train, List.test = List.test, margin = 0.005)
q1 = qhat$q1
q2 = qhat$q2
q12 = qhat$q12

## End(Not run)
</code></pre>

<hr>
<h2 id='qhat_sl'>Estimate marginal and joint distribution of lists j and k using super learner.</h2><span id='topic+qhat_sl'></span>

<h3>Description</h3>

<p>Estimate marginal and joint distribution of lists j and k using super learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qhat_sl(
  List.train,
  List.test,
  K = 2,
  j = 1,
  k = 2,
  margin = 0.005,
  sl.lib = c("SL.glm", "SL.gam", "SL.glm.interaction", "SL.ranger", "SL.glmnet"),
  num_cores = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qhat_sl_+3A_list.train">List.train</code></td>
<td>
<p>The training data matrix used to estimate the distibution functions.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_list.test">List.test</code></td>
<td>
<p>The data matrix on which the estimator function is applied.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_k">K</code></td>
<td>
<p>The number of lists in the data.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_j">j</code></td>
<td>
<p>The first list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_k">k</code></td>
<td>
<p>The second list that is conditionally independent.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_sl.lib">sl.lib</code></td>
<td>
<p>The functions from the SuperLearner library to be used for model fitting. See <code><a href="SuperLearner.html#topic+listWrappers">SuperLearner::listWrappers()</a></code>.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of cores to be used for paralellization in Super Learner.</p>
</td></tr>
<tr><td><code id="qhat_sl_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the marginal and joint distribution probabilities <code>q1</code>, <code>q2</code> and <code>q12</code>.
</p>


<h3>References</h3>

<p>Eric Polley, Erin LeDell, Chris Kennedy and Mark van der Laan (2021). SuperLearner: Super Learner Prediction. <em>R package version 2.0-28</em>. https://CRAN.R-project.org/package=SuperLearner
</p>
<p>van der Laan, M. J., Polley, E. C. and Hubbard, A. E. (2008) Super Learner, <em>Statistical Applications of Genetics and Molecular Biology</em>, 6, article 25.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
qhat = qhat_sl(List.train = List.train, List.test = List.test, margin = 0.005, num_cores = 1)
q1 = qhat$q1
q2 = qhat$q2
q12 = qhat$q12

## End(Not run)
</code></pre>

<hr>
<h2 id='reformat'>A function to reorder the columns of a data table/matrix/data frame and to change factor variables to numeric.</h2><span id='topic+reformat'></span>

<h3>Description</h3>

<p>A function to reorder the columns of a data table/matrix/data frame and to change factor variables to numeric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reformat(data, capturelists)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reformat_+3A_data">data</code></td>
<td>
<p>The data table/matrix/data frame which is to be checked.</p>
</td></tr>
<tr><td><code id="reformat_+3A_capturelists">capturelists</code></td>
<td>
<p>The vector of column names or locations for the capture history list columns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data</code> With reordered columns so that the capture history columns are followed by the rest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = matrix(sample(c(0,1), 2000, replace = TRUE), ncol = 2)
x = matrix(rnorm(nrow(data)*3, 2, 1), nrow = nrow(data))

data = cbind(x, data)
result&lt;- reformat(data = data, capturelists = c(4,5))
</code></pre>

<hr>
<h2 id='simuldata'>A function to reorder the columns of a data table/matrix/data frame and to change factor variables to numeric.</h2><span id='topic+simuldata'></span>

<h3>Description</h3>

<p>A function to reorder the columns of a data table/matrix/data frame and to change factor variables to numeric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simuldata(n, l, categorical = FALSE, ep = 0, K = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simuldata_+3A_n">n</code></td>
<td>
<p>The size of the population.</p>
</td></tr>
<tr><td><code id="simuldata_+3A_l">l</code></td>
<td>
<p>The number of continuous covariates.</p>
</td></tr>
<tr><td><code id="simuldata_+3A_categorical">categorical</code></td>
<td>
<p>A logical value of whether to include a categorical column.</p>
</td></tr>
<tr><td><code id="simuldata_+3A_ep">ep</code></td>
<td>
<p>A numeric value to change the list probabilities.</p>
</td></tr>
<tr><td><code id="simuldata_+3A_k">K</code></td>
<td>
<p>The number of lists. Default value is 2. Maximum value is 3.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of estimates containing the following components:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>  A dataframe in with <code>K</code> list capture histories and covariates from a population if true size <code>n</code> with only observed rows.</p>
</td></tr>
<tr><td><code>data_xstar</code></td>
<td>
<p>  A dataframe in with two list capture histories and transformed covariates from a population if true size <code>n</code> with only observed rows.</p>
</td></tr>
<tr><td><code>psi0</code></td>
<td>
<p>  The empirical capture probability for the set-up used.</p>
</td></tr>
<tr><td><code>pi1</code></td>
<td>
<p>  The conditional capture probabilities for list 1.</p>
</td></tr>
<tr><td><code>pi2</code></td>
<td>
<p>  The conditional capture probabilities for list 2.</p>
</td></tr>
<tr><td><code>pi3</code></td>
<td>
<p>  The conditional capture probabilities for list 3 when <code>K = 3</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Tilling, K., &amp; Sterne, J. A. (1999). Capture-recapture models including covariate effects. <em>American journal of epidemiology</em>, <em>149</em>(4), 392-400.
</p>
<p>Kennedy, E. H. (2019). Nonparametric causal effects based on incremental propensity score interventions. <em>Journal of the American Statistical Association</em>, <em>114</em>(526), 645-656.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = simuldata(n = 1000, l = 2)$data
psi0 = simuldata(n = 10000, l = 2)$psi0
</code></pre>

<hr>
<h2 id='tmle'>Returns the targeted maximum likelihood estimates for the nuisance functions</h2><span id='topic+tmle'></span>

<h3>Description</h3>

<p>Returns the targeted maximum likelihood estimates for the nuisance functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tmle(
  datmat,
  iter = 250,
  margin = 0.005,
  stop_margin = 0.005,
  twolist = FALSE,
  K = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tmle_+3A_datmat">datmat</code></td>
<td>
<p>The data frame containing columns <code>yj</code>, <code>yk</code>, <code>yjk</code>, <code>q10</code>, <code>q02</code> and <code>q12</code>.</p>
</td></tr>
<tr><td><code id="tmle_+3A_iter">iter</code></td>
<td>
<p>An integer denoting the maximum number of iterations allowed for targeted maximum likelihood method. Default value is 100.</p>
</td></tr>
<tr><td><code id="tmle_+3A_margin">margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="tmle_+3A_stop_margin">stop_margin</code></td>
<td>
<p>The minimum value the estimates can attain to bound them away from zero.</p>
</td></tr>
<tr><td><code id="tmle_+3A_twolist">twolist</code></td>
<td>
<p>The logical value of whether targeted maximum likelihood algorithm fits only two modes when K = 2.</p>
</td></tr>
<tr><td><code id="tmle_+3A_k">K</code></td>
<td>
<p>The number of lists in the original data.</p>
</td></tr>
<tr><td><code id="tmle_+3A_...">...</code></td>
<td>
<p>Any extra arguments passed into the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of estimates containing the following components:
</p>
<table>
<tr><td><code>error</code></td>
<td>
<p>  An indicator of whether the algorithm ran and converged. Returns FALSE, if it ran correctly and FALSE otherwise.</p>
</td></tr>
<tr><td><code>datmat</code></td>
<td>
<p>  A data frame returning <code>datmat</code> with the updated estimates for the nuisance functions <code>q10</code>, <code>q02</code> and <code>q12</code>. This is returned only if <code>error</code> is FALSE.</p>
</td></tr>
</table>


<h3>References</h3>

<p>van der Laan, M. J. and Rubin, D. (2006). Targeted maximum likelihood learning. <em>The International Journal of Biostatistics</em>, <em>2</em>(1)
</p>
<p>Das, M., Kennedy, E. H., &amp; Jewell, N.P. (2021). Doubly robust capture-recapture methods for estimating population size. <em>arXiv preprint</em> arXiv:2104.14091.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = matrix(sample(c(0,1), 2000, replace = TRUE), ncol = 2)
xmat = matrix(runif(nrow(data)*3, 0, 1), nrow = nrow(data))
datmat = cbind(data, data[,1]*data[,2], xmat)
colnames(datmat) = c("yj", "yk", "yjk", "q10", "q02", "q12")
datmat = as.data.frame(datmat)
result = tmle(datmat, margin = 0.005, stop_margin = 0.00001, twolist = TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
