<!DOCTYPE html><html lang="en"><head><title>Help for package RMLPCA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RMLPCA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cov_d'><p>Covariance matrix for mlpca_d model</p></a></li>
<li><a href='#cov_e'><p>Covariance matrices for mlpca_e model</p></a></li>
<li><a href='#data_clean'><p>Error free data for all examples.</p></a></li>
<li><a href='#data_clean_e'><p>Error free data for all examples.</p></a></li>
<li><a href='#data_cleaned_mlpca_b'><p>Cleaned dataset after applied MLPCA B used for tests only</p></a></li>
<li><a href='#data_cleaned_mlpca_c'><p>Cleaned dataset after applied MLPCA C used for tests only</p></a></li>
<li><a href='#data_cleaned_mlpca_d'><p>Cleaned dataset after applied MLPCA D used for tests only</p></a></li>
<li><a href='#data_cleaned_mlpca_e'><p>Cleaned dataset after applied MLPCA E used for tests only</p></a></li>
<li><a href='#data_error_b'><p>Errors generated for mlpca_b model</p></a></li>
<li><a href='#data_error_c'><p>Errors generated for mlpca_c model</p></a></li>
<li><a href='#data_error_d'><p>Errors generated for mlpca_d model</p></a></li>
<li><a href='#data_error_e'><p>Errors generated for mlpca_e model</p></a></li>
<li><a href='#mlpca_b'><p>Maximum likelihood principal component analysis for mode B error conditions</p></a></li>
<li><a href='#mlpca_c'><p>Maximum likelihood principal component analysis for mode C error conditions</p></a></li>
<li><a href='#mlpca_d'><p>Maximum likelihood principal component analysis for mode D error conditions</p></a></li>
<li><a href='#mlpca_e'><p>Maximum likelihood principal component analysis for mode E error conditions</p></a></li>
<li><a href='#RMLPCA'><p>RMLPCA: A package for computating MLPCA algorithms b,c,d and e</p></a></li>
<li><a href='#sds_b'><p>Standard deviations for mlpca_b model</p></a></li>
<li><a href='#sds_c'><p>Standard deviations for mlpca_c model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Maximum Likelihood Principal Component Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>R implementation of Maximum Likelihood Principal Component Analysis
    The main idea of this package is to have an alternative way of PCA for 
    subspace modeling that considers measurement errors.
    More details can be found in Peter D. Wentzell (2009) 
    &lt;<a href="https://doi.org/10.1016%2FB978-0-444-64165-6.03029-9">doi:10.1016/B978-0-444-64165-6.03029-9</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/renanestatcamp/RMLPCA">https://github.com/renanestatcamp/RMLPCA</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/renanestatcamp/RMLPCA/issues">https://github.com/renanestatcamp/RMLPCA/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>Imports:</td>
<td>base, Matrix, pracma, RSpectra</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-29 00:36:56 UTC; renan</td>
</tr>
<tr>
<td>Author:</td>
<td>Renan Santos Barbosa [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Renan Santos Barbosa &lt;renansantosbarbosa@usp.br&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-11-05 08:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cov_d'>Covariance matrix for mlpca_d model</h2><span id='topic+cov_d'></span>

<h3>Description</h3>

<p>A random covariance matrix to simulate data errors
The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_d
</code></pre>


<h3>Format</h3>

<p>A matrix with 20 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='cov_e'>Covariance matrices for mlpca_e model</h2><span id='topic+cov_e'></span>

<h3>Description</h3>

<p>A random array of covariance matrices to simulate data errors
The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_e
</code></pre>


<h3>Format</h3>

<p>An array of dimension 20,20,30
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_clean'>Error free data for all examples.</h2><span id='topic+data_clean'></span>

<h3>Description</h3>

<p>A dataset generated by the rotation of a bivariate normal density, the method
applied to get this dataset is described on Wentzell, P. D., and S. Hou.
&quot;Exploratory data analysis with noisy measurements.&quot;
Journal of Chemometrics 26.6 (2012): 264-281.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_clean
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D., and S. Hou.
&quot;Exploratory data analysis with noisy measurements.&quot;
Journal of Chemometrics 26.6 (2012): 264-281.
</p>

<hr>
<h2 id='data_clean_e'>Error free data for all examples.</h2><span id='topic+data_clean_e'></span>

<h3>Description</h3>

<p>A dataset generated by the rotation of a bivariate normal density, the method
applied to get this dataset is described on Wentzell, P. D., and S. Hou.
&quot;Exploratory data analysis with noisy measurements.&quot;
Journal of Chemometrics 26.6 (2012): 264-281.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_clean_e
</code></pre>


<h3>Format</h3>

<p>A matrix with 30 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D., and S. Hou.
&quot;Exploratory data analysis with noisy measurements.&quot;
Journal of Chemometrics 26.6 (2012): 264-281.
</p>

<hr>
<h2 id='data_cleaned_mlpca_b'>Cleaned dataset after applied MLPCA B used for tests only</h2><span id='topic+data_cleaned_mlpca_b'></span>

<h3>Description</h3>

<p>A dataset where the values are estimated after mlpca_b is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_cleaned_mlpca_b
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_cleaned_mlpca_c'>Cleaned dataset after applied MLPCA C used for tests only</h2><span id='topic+data_cleaned_mlpca_c'></span>

<h3>Description</h3>

<p>A dataset where the values are estimated after mlpca_c is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_cleaned_mlpca_c
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_cleaned_mlpca_d'>Cleaned dataset after applied MLPCA D used for tests only</h2><span id='topic+data_cleaned_mlpca_d'></span>

<h3>Description</h3>

<p>A dataset where the values are estimated after mlpca_d is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_cleaned_mlpca_d
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_cleaned_mlpca_e'>Cleaned dataset after applied MLPCA E used for tests only</h2><span id='topic+data_cleaned_mlpca_e'></span>

<h3>Description</h3>

<p>A dataset where the values are estimated after mlpca_e is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_cleaned_mlpca_e
</code></pre>


<h3>Format</h3>

<p>A matrix with 30 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_error_b'>Errors generated for mlpca_b model</h2><span id='topic+data_error_b'></span>

<h3>Description</h3>

<p>A dataset where each column contain values from a normal density with mean
= 0 and standard deviation from 0.2 to 1, the standard deviations differs in
the column. The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_error_b
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_error_c'>Errors generated for mlpca_c model</h2><span id='topic+data_error_c'></span>

<h3>Description</h3>

<p>A dataset where each column contain values from a normal density with mean
= 0 and standard deviations simulated by a lognormal density with
meanlog = -4.75 and sdlog = 2.5, all the standard deviations are different.
The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_error_c
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_error_d'>Errors generated for mlpca_d model</h2><span id='topic+data_error_d'></span>

<h3>Description</h3>

<p>A dataset where the values come from a 20 -multivariate normal density where
all the means are 0 and the covariance matrix from cov_d.
The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_error_d
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='data_error_e'>Errors generated for mlpca_e model</h2><span id='topic+data_error_e'></span>

<h3>Description</h3>

<p>A dataset where the values come from a 20 -multivariate normal density where
all the means are 0 and the covariance matrix from cov_e.
The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_error_e
</code></pre>


<h3>Format</h3>

<p>A matrix with 30 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='mlpca_b'>Maximum likelihood principal component analysis for mode B error conditions</h2><span id='topic+mlpca_b'></span>

<h3>Description</h3>

<p>Performs maximum likelihood principal components analysis for
mode B error conditions (independent errors, homoscedastic within a column).
Equivalent to perfoming PCA on data scaled by the error SD, but results are
rescaled to the original space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlpca_b(X, Xsd, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlpca_b_+3A_x">X</code></td>
<td>
<p>MxN matrix of measurements.</p>
</td></tr>
<tr><td><code id="mlpca_b_+3A_xsd">Xsd</code></td>
<td>
<p>MxN matrix of measurements error standard deviations.</p>
</td></tr>
<tr><td><code id="mlpca_b_+3A_p">p</code></td>
<td>
<p>Rank of the model's subspace, p must be than the minimum of M and N.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned parameters, U, S and V, are analogs to the
truncated SVD solution, but have somewhat different properties since they
represent the MLPCA solution. In particular, the solutions for different
values of p are not necessarily nested (the rank 1 solution may not be in
the space of the rank 2 solution) and the eigenvectors do not necessarily
account for decreasing amounts of variance, since MLPCA is a subspace
modeling technique and not a variance modeling technique.
</p>


<h3>Value</h3>

<p>The parameters returned are the results of SVD on the estimated
subspace. The quantity Ssq represents the sum of squares of weighted
residuals. All the results are nested in a list format.
</p>


<h3>References</h3>

<p>Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(RMLPCA)
data(data_clean)
data(data_error_b)
data(sds_b)

# data that you will usually have on hands
data_noisy &lt;- data_clean + data_error_b

# run mlpca_b with rank p = 2
results &lt;- RMLPCA::mlpca_b(
  X = data_noisy,
  Xsd = sds_b,
  p = 2
)

# estimated clean dataset
data_cleaned_mlpca &lt;- results$U %*% results$S %*% t(results$V)
</code></pre>

<hr>
<h2 id='mlpca_c'>Maximum likelihood principal component analysis for mode C error conditions</h2><span id='topic+mlpca_c'></span>

<h3>Description</h3>

<p>Performs maximum likelihood principal components analysis for
mode C error conditions (independent errors, general heteroscedastic
case).
Employs ALS algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlpca_c(X, Xsd, p, MaxIter = 20000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlpca_c_+3A_x">X</code></td>
<td>
<p>MxN matrix of measurements</p>
</td></tr>
<tr><td><code id="mlpca_c_+3A_xsd">Xsd</code></td>
<td>
<p>MxN matrix of measurements error standard deviations</p>
</td></tr>
<tr><td><code id="mlpca_c_+3A_p">p</code></td>
<td>
<p>Rank of the model's subspace, p must be than the minimum of M and N</p>
</td></tr>
<tr><td><code id="mlpca_c_+3A_maxiter">MaxIter</code></td>
<td>
<p>Maximum no. of iterations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned parameters, U, S and V, are analogs to the
truncated SVD solution, but have somewhat different properties since they
represent the MLPCA solution. In particular, the solutions for different
values of p are not necessarily nested (the rank 1 solution may not be in
the space of the rank 2 solution) and the eigenvectors do not necessarily
account for decreasing amounts of variance, since MLPCA is a subspace
modeling technique and not a variance modeling technique.
</p>


<h3>Value</h3>

<p>The parameters returned are the results of SVD on the estimated
subspace. The quantity Ssq represents the sum of squares of weighted
residuals. ErrFlag indicates the convergence condition,
with 0 indicating normal termination and 1 indicating the maximum number of
iterations have been exceeded.
</p>


<h3>References</h3>

<p>Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(RMLPCA)
data(data_clean)
data(data_error_c)
data(sds_c)

# data that you will usually have on hands
data_noisy &lt;- data_clean + data_error_c

# run mlpca_c with rank p = 5
results &lt;- RMLPCA::mlpca_c(
  X = data_noisy,
  Xsd = sds_c,
  p = 2
)

# estimated clean dataset
data_cleaned_mlpca &lt;- results$U %*% results$S %*% t(results$V)
</code></pre>

<hr>
<h2 id='mlpca_d'>Maximum likelihood principal component analysis for mode D error conditions</h2><span id='topic+mlpca_d'></span>

<h3>Description</h3>

<p>Performs maximum likelihood principal components analysis for
mode D error conditions (commom row covariance matrices).
Employs rotation and scaling of the original data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlpca_d(X, Cov, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlpca_d_+3A_x">X</code></td>
<td>
<p>IxJ matrix of measurements</p>
</td></tr>
<tr><td><code id="mlpca_d_+3A_cov">Cov</code></td>
<td>
<p>JxJ matrix of measurement error covariance, which is commom to all
rows</p>
</td></tr>
<tr><td><code id="mlpca_d_+3A_p">p</code></td>
<td>
<p>Rank of the model's subspace</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned parameters, U, S and V, are analogs to the
truncated SVD solution, but have somewhat different properties since they
represent the MLPCA solution. In particular, the solutions for different
values of p are not necessarily nested (the rank 1 solution may not be in
the space of the rank 2 solution) and the eigenvectors do not necessarily
account for decreasing amounts of variance, since MLPCA is a subspace
modeling technique and not a variance modeling technique.
</p>


<h3>Value</h3>

<p>The parameters returned are the results of SVD on the estimated
subspace. The quantity Ssq represents the sum of squares of weighted
residuals.
</p>


<h3>References</h3>

<p>Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(RMLPCA)
  data(data_clean)
  data(data_error_d)
  # covariance matrix
  data(cov_d)
  data(data_cleaned_mlpca_d)
  # data that you will usually have on hands
  data_noisy &lt;- data_clean + data_error_d

  # run mlpca_c with rank p = 5
  results &lt;- RMLPCA::mlpca_d(
    X = data_noisy,
    Cov = cov_d,
    p = 2
  )

  # estimated clean dataset
  data_cleaned_mlpca &lt;- results$U %*% results$S %*% t(results$V)
</code></pre>

<hr>
<h2 id='mlpca_e'>Maximum likelihood principal component analysis for mode E error conditions</h2><span id='topic+mlpca_e'></span>

<h3>Description</h3>

<p>Performs maximum likelihood principal components analysis for
mode E error conditions (correlated errors, with a different covariance
matrix for each row, but no error correlation between the rows). Employs an
ALS algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlpca_e(X, Cov, p, MaxIter = 20000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlpca_e_+3A_x">X</code></td>
<td>
<p>IxJ matrix of measurements</p>
</td></tr>
<tr><td><code id="mlpca_e_+3A_cov">Cov</code></td>
<td>
<p>JXJXI matrices of measurement error covariance</p>
</td></tr>
<tr><td><code id="mlpca_e_+3A_p">p</code></td>
<td>
<p>Rank of the model's subspace, p must be than the minimum of I and J</p>
</td></tr>
<tr><td><code id="mlpca_e_+3A_maxiter">MaxIter</code></td>
<td>
<p>Maximum no. of iterations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The returned parameters, U, S and V, are analogs to the
truncated SVD solution, but have somewhat different properties since they
represent the MLPCA solution. In particular, the solutions for different
values of p are not necessarily nested (the rank 1 solution may not be in
the space of the rank 2 solution) and the eigenvectors do not necessarily
account for decreasing amounts of variance, since MLPCA is a subspace
modeling technique and not a variance modeling technique.
</p>


<h3>Value</h3>

<p>The parameters returned are the results of SVD on the estimated
subspace. The quantity Ssq represents the sum of squares of weighted
residuals. ErrFlag indicates the convergence condition,
with 0 indicating normal termination and 1 indicating the maximum number of
iterations have been exceeded.
</p>


<h3>Author(s)</h3>

<p>Renan Santos Barbosa
</p>


<h3>References</h3>

<p>Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(RMLPCA)
data(data_clean_e)
data(data_error_e)
# covariance matrix
data(cov_e)
data(data_cleaned_mlpca_e)
# data that you will usually have on hands
data_noisy &lt;- data_clean_e + data_error_e

# run mlpca_e with rank p = 1
results &lt;- RMLPCA::mlpca_e(
  X = data_noisy,
  Cov = cov_e,
  p = 1
)

# estimated clean dataset
data_cleaned_mlpca &lt;- results$U %*% results$S %*% t(results$V)

</code></pre>

<hr>
<h2 id='RMLPCA'>RMLPCA: A package for computating MLPCA algorithms b,c,d and e</h2><span id='topic+RMLPCA'></span>

<h3>Description</h3>

<p>The RMLPCA package provides four algorithms that to deals with measurement
errors
</p>

<hr>
<h2 id='sds_b'>Standard deviations for mlpca_b model</h2><span id='topic+sds_b'></span>

<h3>Description</h3>

<p>A dataset where each column contain the standard deviations from 0.2 to 1
that is necessary to run mlpca_b.
The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sds_b
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

<hr>
<h2 id='sds_c'>Standard deviations for mlpca_c model</h2><span id='topic+sds_c'></span>

<h3>Description</h3>

<p>A dataset where each value come from a lognormal density with meanlog = -4.75
and sdlog = 2.5.
The main ideia is described in figure 3 on Wentzell, P. D.
&quot;Other topics in soft-modeling: maximum likelihood-based soft-modeling
methods.&quot; (2009): 507-558.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sds_c
</code></pre>


<h3>Format</h3>

<p>A matrix with 300 rows and 20 columns
</p>


<h3>References</h3>

<p>Wentzell, P. D. &quot;Other topics in soft-modeling:
maximum likelihood-based soft-modeling methods.&quot; (2009): 507-558.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
