<!DOCTYPE html><html lang="en"><head><title>Help for package SFPL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SFPL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#data_sim'><p>Rank data simulation</p></a></li>
<li><a href='#ghana'>
<p>Ranking data</p></a></li>
<li><a href='#sfpl'><p>Sparse Fused Plackett-Luce</p></a></li>
<li><a href='#sfpl_approx'><p>Approximate Sparse Fused Plackett-Luce</p></a></li>
<li><a href='#sfpl_select'><p>Model selection for SFPL</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sparse Fused Plackett-Luce</td>
</tr>
<tr>
<td>Imports:</td>
<td>pracma, gtools</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sjoerd Hermes &lt;sjoerd.hermes@wur.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the methodological developments found in Hermes, van Heerwaarden, and Behrouzi (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2308.04325">doi:10.48550/arXiv.2308.04325</a>&gt;, and allows for the statistical modeling of multi-group rank data in combination with object variables. The package also allows for the simulation of synthetic multi-group rank data.  </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-22 08:58:57 UTC; sjoer</td>
</tr>
<tr>
<td>Author:</td>
<td>Sjoerd Hermes [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-26 19:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='data_sim'>Rank data simulation</h2><span id='topic+data_sim'></span>

<h3>Description</h3>

<p>Simulates (partial) rank data for multiple groups together with object variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_sim(m, M, n, p, K, delta, eta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="data_sim_+3A_m">m</code></td>
<td>
<p>Length of the partial ranking for each observation.</p>
</td></tr>
<tr><td><code id="data_sim_+3A_m">M</code></td>
<td>
<p>Total number of objects.</p>
</td></tr>
<tr><td><code id="data_sim_+3A_n">n</code></td>
<td>
<p>Number of observations (rankers) per group.</p>
</td></tr>
<tr><td><code id="data_sim_+3A_p">p</code></td>
<td>
<p>Number of object variables.</p>
</td></tr>
<tr><td><code id="data_sim_+3A_k">K</code></td>
<td>
<p>Number of groups.</p>
</td></tr>
<tr><td><code id="data_sim_+3A_delta">delta</code></td>
<td>
<p>Approximate fraction of different coefficients across the <code class="reqn">\beta^{(k)}</code>.</p>
</td></tr>
<tr><td><code id="data_sim_+3A_eta">eta</code></td>
<td>
<p>Approximate fraction of sparse coefficients in <code class="reqn">\beta^{(k)}</code> for all <code class="reqn">k</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>y</code></td>
<td>
<p>A list consisting of <code class="reqn">K</code> matrices with each matrix containing (partial) rankings across <code class="reqn">n</code> observations for group <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>A <code class="reqn">M \times p</code> matrix containing the values for the <code class="reqn">p</code> objects variables across the <code class="reqn">M</code> objects.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>A <code class="reqn">p \times K</code> matrix containing the true value of <code class="reqn">\beta</code>, which was used to generate <code class="reqn">y</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sjoerd Hermes<br />
Maintainer: Sjoerd Hermes <a href="mailto:sjoerd.hermes@wur.nl">sjoerd.hermes@wur.nl</a>
</p>


<h3>References</h3>

<p>1. Hermes, S., van Heerwaarden, J., and Behrouzi, P. (2024). Joint Learning from Heterogeneous Rank Data. arXiv preprint, arXiv:2407.10846 <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_sim(3, 10, 50, 5, 2, 0.25, 0.25)
</code></pre>

<hr>
<h2 id='ghana'>
Ranking data
</h2><span id='topic+ghana'></span>

<h3>Description</h3>

<p>This is a real dataset containing information on 5 object variables describing the properties of 13 different sweet potato varieties. In addition, the dataset contains partial
rankings made by men and women from Ghana.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("ghana")</code></pre>


<h3>Format</h3>

<p>A list with three dataframes. The first consists of the rankings made by men, the second consists of the rankings made by women and the third contain the object variables.
</p>


<h3>Details</h3>

<p>Contains a subset of the data used in the Hermes et al. (2024) paper.
</p>


<h3>Source</h3>

<p>Data from the Hermes et al. (2024) paper is based on Moyo et al. (2021).
</p>


<h3>References</h3>

<p>1. Hermes, S., van Heerwaarden, J., and Behrouzi, P. (2024). Joint Learning from Heterogeneous Rank Data. arXiv preprint, arXiv:2407.10846 <br />
2. Moyo, M., R. Ssali, S. Namanda, M. Nakitto, E. K. Dery, D. Akansake, J. Adjebeng-Danquah, J. van Etten,
K. de Sousa, H. Lindqvist-Kreuze, et al. (2021). Consumer preference testing of boiled sweetpotato using
crowdsourced citizen science in Ghana and Uganda. Frontiers in Sustainable Food Systems 5, 620363. <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ghana)
</code></pre>

<hr>
<h2 id='sfpl'>Sparse Fused Plackett-Luce</h2><span id='topic+sfpl'></span>

<h3>Description</h3>

<p>Contains the main function of this package that is used to estimate the parameter of interest <code class="reqn">\beta</code>. The inner workings of the function are described in Hermes et al., (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfpl(x, y, ls_vec, lf_vec, epsilon, verbose)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sfpl_+3A_x">x</code></td>
<td>
<p>A <code class="reqn">M \times p</code> matrix containing the values for the <code class="reqn">p</code> objects variables across the <code class="reqn">M</code> objects.</p>
</td></tr>
<tr><td><code id="sfpl_+3A_y">y</code></td>
<td>
<p>A list consisting of <code class="reqn">K</code> matrices with each matrix containing (partial) rankings across <code class="reqn">n</code> observations for group <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="sfpl_+3A_ls_vec">ls_vec</code></td>
<td>
<p>Vector containing shrinkage parameters.</p>
</td></tr>
<tr><td><code id="sfpl_+3A_lf_vec">lf_vec</code></td>
<td>
<p>Vector containing fusion penalty parameters.</p>
</td></tr>
<tr><td><code id="sfpl_+3A_epsilon">epsilon</code></td>
<td>
<p>Small positive value used to ensure that the penalty function is differentiable. Typically set at <code class="reqn">10^{-5}</code>.</p>
</td></tr>
<tr><td><code id="sfpl_+3A_verbose">verbose</code></td>
<td>
<p>Boolean that returns the process of the parameter estimation.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>beta_est</code></td>
<td>
<p>A list of length ls_vec<code class="reqn">\times</code>lf_vec that contains the parameter estimates <code class="reqn">\hat{beta}</code> for each combination of ls_vec and lf_vec.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sjoerd Hermes<br />
Maintainer: Sjoerd Hermes <a href="mailto:sjoerd.hermes@wur.nl">sjoerd.hermes@wur.nl</a>
</p>


<h3>References</h3>

<p>1. Hermes, S., van Heerwaarden, J., and Behrouzi, P. (2024). Joint Learning from Heterogeneous Rank Data. arXiv preprint, arXiv:2407.10846 <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# we first obtain the rankings and object variables
data(ghana)
y &lt;- list(ghana[[1]], ghana[[2]])
x &lt;- ghana[[3]]

# our next step consists of creating two vectors for the penalty parameters
ls_vec &lt;- lf_vec &lt;- c(0, 0.25)

# we choose epsilon to be small: 10^(-5), as we did in Hermes et al., (2024)
# now we can fit our model
epsilon &lt;- 10^(-5)
verbose &lt;- FALSE

result &lt;- sfpl(x, y, ls_vec, lf_vec, epsilon, verbose)

</code></pre>

<hr>
<h2 id='sfpl_approx'>Approximate Sparse Fused Plackett-Luce</h2><span id='topic+sfpl_approx'></span>

<h3>Description</h3>

<p>Contains an approximate (typically faster) version of the main function of this package that is used to estimate the parameter of interest <code class="reqn">\beta</code>. We recommend this version
due to its (relatively) fast convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfpl_approx(x, y, ls_vec, lf_vec, epsilon, verbose)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sfpl_approx_+3A_x">x</code></td>
<td>
<p>A <code class="reqn">M \times p</code> matrix containing the values for the <code class="reqn">p</code> objects variables across the <code class="reqn">M</code> objects.</p>
</td></tr>
<tr><td><code id="sfpl_approx_+3A_y">y</code></td>
<td>
<p>A list consisting of <code class="reqn">K</code> matrices with each matrix containing (partial) rankings across <code class="reqn">n</code> observations for group <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="sfpl_approx_+3A_ls_vec">ls_vec</code></td>
<td>
<p>Vector containing shrinkage parameters.</p>
</td></tr>
<tr><td><code id="sfpl_approx_+3A_lf_vec">lf_vec</code></td>
<td>
<p>Vector containing fusion penalty parameters.</p>
</td></tr>
<tr><td><code id="sfpl_approx_+3A_epsilon">epsilon</code></td>
<td>
<p>Small positive value used to ensure that the penalty function is differentiable. Typically set at <code class="reqn">10^{-5}</code>.</p>
</td></tr>
<tr><td><code id="sfpl_approx_+3A_verbose">verbose</code></td>
<td>
<p>Boolean that returns the process of the parameter estimation.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>beta_est</code></td>
<td>
<p>A list of length ls_vec<code class="reqn">\times</code>lf_vec that contains the parameter estimates <code class="reqn">\hat{beta}</code> for each combination of ls_vec and lf_vec.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sjoerd Hermes<br />
Maintainer: Sjoerd Hermes <a href="mailto:sjoerd.hermes@wur.nl">sjoerd.hermes@wur.nl</a>
</p>


<h3>References</h3>

<p>1. Hermes, S., van Heerwaarden, J., and Behrouzi, P. (2024). Joint Learning from Heterogeneous Rank Data. arXiv preprint, arXiv:2407.10846 <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# we first obtain the rankings and object variables
data(ghana)
y &lt;- list(ghana[[1]], ghana[[2]])
x &lt;- ghana[[3]]

# our next step consists of creating two vectors for the penalty parameters
ls_vec &lt;- lf_vec &lt;- c(0, 0.25)

# we choose epsilon to be small: 10^(-5), as we did in Hermes et al., (2024)
# now we can fit our model
epsilon &lt;- 10^(-5)
verbose &lt;- FALSE

result &lt;- sfpl_approx(x, y, ls_vec, lf_vec, epsilon, verbose)

</code></pre>

<hr>
<h2 id='sfpl_select'>Model selection for SFPL</h2><span id='topic+sfpl_select'></span>

<h3>Description</h3>

<p>This function selects the &quot;best&quot; fitted SFPL model using either the AIC or the BIC, see Hermes et al., (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfpl_select(beta_est, x, y, ls_vec, lf_vec)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sfpl_select_+3A_beta_est">beta_est</code></td>
<td>
<p>A list of length ls_vec<code class="reqn">\times</code>lf_vec that contains the parameter estimates <code class="reqn">\hat{beta}</code>, using either sfpl or sfpl_approx,
for each combination of ls_vec and lf_vec.</p>
</td></tr>
<tr><td><code id="sfpl_select_+3A_x">x</code></td>
<td>
<p>A <code class="reqn">M \times p</code> matrix containing the values for the <code class="reqn">p</code> objects variables across the <code class="reqn">M</code> objects.</p>
</td></tr>
<tr><td><code id="sfpl_select_+3A_y">y</code></td>
<td>
<p>A list consisting of <code class="reqn">K</code> matrices with each matrix containing (partial) rankings across <code class="reqn">n</code> observations for group <code class="reqn">k</code>.</p>
</td></tr>
<tr><td><code id="sfpl_select_+3A_ls_vec">ls_vec</code></td>
<td>
<p>Vector containing shrinkage parameters.</p>
</td></tr>
<tr><td><code id="sfpl_select_+3A_lf_vec">lf_vec</code></td>
<td>
<p>Vector containing fusion penalty parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>model_aic</code></td>
<td>
<p>A <code class="reqn">p \times K</code> matrix containing the parameter estimates using the penalty parameters <code class="reqn">\lambda_s, \lambda_f</code> as chosen by the AIC.</p>
</td></tr>
<tr><td><code>model_bic</code></td>
<td>
<p>A <code class="reqn">p \times K</code> matrix containing the parameter estimates using the penalty parameters <code class="reqn">\lambda_s, \lambda_f</code> as chosen by the BIC.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sjoerd Hermes<br />
Maintainer: Sjoerd Hermes <a href="mailto:sjoerd.hermes@wur.nl">sjoerd.hermes@wur.nl</a>
</p>


<h3>References</h3>

<p>1. Hermes, S., van Heerwaarden, J., and Behrouzi, P. (2024). Joint Learning from Heterogeneous Rank Data. arXiv preprint, arXiv:2407.10846 <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# we first obtain the rankings and object variables
data(ghana)
y &lt;- list(ghana[[1]], ghana[[2]])
x &lt;- ghana[[3]]

# our next step consists of creating two vectors for the penalty parameters
ls_vec &lt;- lf_vec &lt;- c(0, 0.25)

# we choose epsilon to be small: 10^(-5), as we did in Hermes et al., (2024)
# now we can fit our model
epsilon &lt;- 10^(-5)
verbose &lt;- FALSE

result &lt;- sfpl_approx(x, y, ls_vec, lf_vec, epsilon, verbose)

# now we select the best models using our model selection function
sfpl_select(result, x, y, ls_vec, lf_vec)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
