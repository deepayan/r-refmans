<!DOCTYPE html><html lang="en"><head><title>Help for package topicdoc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {topicdoc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coherence'><p>Helper function for calculating coherence for a single topic's worth of terms</p></a></li>
<li><a href='#contain_equal_docs'><p>Helper function to check that a topic model and a dtm contain the same number of documents</p></a></li>
<li><a href='#dist_from_corpus'><p>Calculate the distance of each topic from the overall corpus token distribution</p></a></li>
<li><a href='#doc_prominence'><p>Calculate the document prominence of each topic in a topic model</p></a></li>
<li><a href='#mean_token_length'><p>Calculate the average token length for each topic in a topic model</p></a></li>
<li><a href='#n_topics'><p>Helper function to determine the number of topics in a topic model</p></a></li>
<li><a href='#tf_df_dist'><p>Calculate the distance between token and document frequencies</p></a></li>
<li><a href='#tf_df_dist_diff'><p>Helper function to calculate the Hellinger distance</p>
between the token frequencies and document frequencies
for a specific topic's top N tokens</a></li>
<li><a href='#topic_coherence'><p>Calculate the topic coherence for each topic in a topic model</p></a></li>
<li><a href='#topic_diagnostics'><p>Calculate diagnostics for each topic in a topic model</p></a></li>
<li><a href='#topic_exclusivity'><p>Calculate the exclusivity of each topic in a topic model</p></a></li>
<li><a href='#topic_size'><p>Calculate the size of each topic in a topic model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Topic-Specific Diagnostics for LDA and CTM Topic Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculates topic-specific diagnostics (e.g. mean token length, exclusivity) for 
    Latent Dirichlet Allocation and Correlated Topic Models fit using the 'topicmodels' package.
    For more details, see Chapter 12 in Airoldi et al. (2014, ISBN:9781466504080), 
    pp 262-272 Mimno et al. (2011, ISBN:9781937284114), and Bischof et al. (2014) &lt;<a href="https://doi.org/10.48550/arXiv.1206.4631">doi:10.48550/arXiv.1206.4631</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/doug-friedman/topicdoc">https://github.com/doug-friedman/topicdoc</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/doug-friedman/topicdoc/issues">https://github.com/doug-friedman/topicdoc/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>slam, topicmodels</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, stm, testthat (&ge; 2.1.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-07-16 23:54:07 UTC; silly</td>
</tr>
<tr>
<td>Author:</td>
<td>Doug Friedman [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Doug Friedman &lt;doug.nhp@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-07-17 00:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='coherence'>Helper function for calculating coherence for a single topic's worth of terms</h2><span id='topic+coherence'></span>

<h3>Description</h3>

<p>Helper function for calculating coherence for a single topic's worth of terms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coherence(dtm_data, top_terms, smoothing_beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coherence_+3A_dtm_data">dtm_data</code></td>
<td>
<p>a document-term matrix of token counts coercible to <code>simple_triplet_matrix</code></p>
</td></tr>
<tr><td><code id="coherence_+3A_top_terms">top_terms</code></td>
<td>
<p>a character vector of the top terms for a given topic</p>
</td></tr>
<tr><td><code id="coherence_+3A_smoothing_beta">smoothing_beta</code></td>
<td>
<p>a numeric indicating the value to use to smooth the document frequencies
in order avoid log zero issues, the default is 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric indicating coherence for the topic
</p>

<hr>
<h2 id='contain_equal_docs'>Helper function to check that a topic model and a dtm contain the same number of documents</h2><span id='topic+contain_equal_docs'></span>

<h3>Description</h3>

<p>Helper function to check that a topic model and a dtm contain the same number of documents
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contain_equal_docs(topic_model, dtm_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="contain_equal_docs_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="contain_equal_docs_+3A_dtm_data">dtm_data</code></td>
<td>
<p>a document-term matrix of token counts coercible to <code>simple_triplet_matrix</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a logical indicating whether or not the two object contain the same number of documents
</p>

<hr>
<h2 id='dist_from_corpus'>Calculate the distance of each topic from the overall corpus token distribution</h2><span id='topic+dist_from_corpus'></span>

<h3>Description</h3>

<p>The Hellinger distance between the token probabilities or betas for each topic and
the overall probability for the word in the corpus is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist_from_corpus(topic_model, dtm_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dist_from_corpus_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="dist_from_corpus_+3A_dtm_data">dtm_data</code></td>
<td>
<p>a document-term matrix of token counts coercible to <code>simple_triplet_matrix</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of distances with length equal to the number of topics in the fitted model
</p>


<h3>References</h3>


<p>Jordan Boyd-Graber, David Mimno, and David Newman, 2014.
<em>Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements.</em>
CRC Handbooks ofModern Statistical Methods. CRC Press, Boca Raton, Florida.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
dist_from_corpus(lda, AssociatedPress[1:20,])
</code></pre>

<hr>
<h2 id='doc_prominence'>Calculate the document prominence of each topic in a topic model</h2><span id='topic+doc_prominence'></span>

<h3>Description</h3>

<p>Calculate the document prominence of each topic in a topic model based on either
the number of documents with an estimated gamma probability above a threshold or
the number of documents where a topic has the highest estimated gamma probability
</p>


<h3>Usage</h3>

<pre><code class='language-R'>doc_prominence(
  topic_model,
  method = c("gamma_threshold", "largest_gamma"),
  gamma_threshold = 0.2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="doc_prominence_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="doc_prominence_+3A_method">method</code></td>
<td>
<p>a string indicating which method to use -
&quot;gamma_threshold&quot; or &quot;largest_gamma&quot;, the default is &quot;gamma_threshold&quot;</p>
</td></tr>
<tr><td><code id="doc_prominence_+3A_gamma_threshold">gamma_threshold</code></td>
<td>
<p>a number between 0 and 1 indicating the gamma threshold to be used
when using the gamma threshold method, the default is 0.2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of document prominences with length equal to the number of topics in the fitted model
</p>


<h3>References</h3>


<p>Jordan Boyd-Graber, David Mimno, and David Newman, 2014.
<em>Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements.</em>
CRC Handbooks ofModern Statistical Methods. CRC Press, Boca Raton, Florida.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
doc_prominence(lda)
</code></pre>

<hr>
<h2 id='mean_token_length'>Calculate the average token length for each topic in a topic model</h2><span id='topic+mean_token_length'></span>

<h3>Description</h3>

<p>Using the the N highest probability tokens for each topic, calculate
the average token length for each topic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_token_length(topic_model, top_n_tokens = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean_token_length_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="mean_token_length_+3A_top_n_tokens">top_n_tokens</code></td>
<td>
<p>an integer indicating the number of top words to consider,
the default is 10</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of average token lengths with length equal to the number of topics in the fitted model
</p>


<h3>References</h3>


<p>Jordan Boyd-Graber, David Mimno, and David Newman, 2014.
<em>Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements.</em>
CRC Handbooks ofModern Statistical Methods. CRC Press, Boca Raton, Florida.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
mean_token_length(lda)
</code></pre>

<hr>
<h2 id='n_topics'>Helper function to determine the number of topics in a topic model</h2><span id='topic+n_topics'></span>

<h3>Description</h3>

<p>Helper function to determine the number of topics in a topic model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_topics(topic_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="n_topics_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an integer indicating the number of topics in the topic model
</p>

<hr>
<h2 id='tf_df_dist'>Calculate the distance between token and document frequencies</h2><span id='topic+tf_df_dist'></span>

<h3>Description</h3>

<p>Using the the N highest probability tokens for each topic,
calculate the Hellinger distance between the token frequencies and
the document frequencies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf_df_dist(topic_model, dtm_data, top_n_tokens = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tf_df_dist_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="tf_df_dist_+3A_dtm_data">dtm_data</code></td>
<td>
<p>a document-term matrix of token counts coercible to <code>simple_triplet_matrix</code></p>
</td></tr>
<tr><td><code id="tf_df_dist_+3A_top_n_tokens">top_n_tokens</code></td>
<td>
<p>an integer indicating the number of top words to consider,
the default is 10</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of distances with length equal to the number of topics in the fitted model
</p>


<h3>References</h3>


<p>Jordan Boyd-Graber, David Mimno, and David Newman, 2014.
<em>Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements.</em>
CRC Handbooks ofModern Statistical Methods. CRC Press, Boca Raton, Florida.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
tf_df_dist(lda, AssociatedPress[1:20,])
</code></pre>

<hr>
<h2 id='tf_df_dist_diff'>Helper function to calculate the Hellinger distance
between the token frequencies and document frequencies
for a specific topic's top N tokens</h2><span id='topic+tf_df_dist_diff'></span>

<h3>Description</h3>

<p>Helper function to calculate the Hellinger distance
between the token frequencies and document frequencies
for a specific topic's top N tokens
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tf_df_dist_diff(dtm_data, top_terms)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tf_df_dist_diff_+3A_dtm_data">dtm_data</code></td>
<td>
<p>a document-term matrix of token counts coercible to <code>simple_triplet_matrix</code></p>
</td></tr>
<tr><td><code id="tf_df_dist_diff_+3A_top_terms">top_terms</code></td>
<td>
<p>- a character vector of the top N tokens</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a single value representing the Hellinger distance
</p>

<hr>
<h2 id='topic_coherence'>Calculate the topic coherence for each topic in a topic model</h2><span id='topic+topic_coherence'></span>

<h3>Description</h3>

<p>Using the the N highest probability tokens for each topic, calculate
the topic coherence for each topic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topic_coherence(topic_model, dtm_data, top_n_tokens = 10, smoothing_beta = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="topic_coherence_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="topic_coherence_+3A_dtm_data">dtm_data</code></td>
<td>
<p>a document-term matrix of token counts coercible to <code>simple_triplet_matrix</code></p>
</td></tr>
<tr><td><code id="topic_coherence_+3A_top_n_tokens">top_n_tokens</code></td>
<td>
<p>an integer indicating the number of top words to consider,
the default is 10</p>
</td></tr>
<tr><td><code id="topic_coherence_+3A_smoothing_beta">smoothing_beta</code></td>
<td>
<p>a numeric indicating the value to use to smooth the document frequencies
in order avoid log zero issues, the default is 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of topic coherence scores with length equal to the number of topics in the fitted model
</p>


<h3>References</h3>


<p>Mimno, D., Wallach, H. M., Talley, E., Leenders, M., &amp; McCallum, A. (2011, July).
&quot;Optimizing semantic coherence in topic models.&quot; In Proceedings of the Conference on
Empirical Methods in Natural Language Processing (pp. 262-272). Association for
Computational Linguistics. Chicago
</p>
<p>McCallum, Andrew Kachites.  &quot;MALLET: A Machine Learning for Language Toolkit.&quot;
<a href="https://mallet.cs.umass.edu">https://mallet.cs.umass.edu</a> 2002.

</p>


<h3>See Also</h3>

<p><code><a href="stm.html#topic+semanticCoherence">semanticCoherence</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
topic_coherence(lda, AssociatedPress[1:20,])
</code></pre>

<hr>
<h2 id='topic_diagnostics'>Calculate diagnostics for each topic in a topic model</h2><span id='topic+topic_diagnostics'></span>

<h3>Description</h3>

<p>Generate a dataframe containing the diagnostics for each topic in a topic model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topic_diagnostics(
  topic_model,
  dtm_data,
  top_n_tokens = 10,
  method = c("gamma_threshold", "largest_gamma"),
  gamma_threshold = 0.2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="topic_diagnostics_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="topic_diagnostics_+3A_dtm_data">dtm_data</code></td>
<td>
<p>a document-term matrix of token counts coercible to <code>slam_triplet_matrix</code>
where each row is a document, each column is a token,
and each entry is the frequency of the token in a given document</p>
</td></tr>
<tr><td><code id="topic_diagnostics_+3A_top_n_tokens">top_n_tokens</code></td>
<td>
<p>an integer indicating the number of top words to consider for mean token length</p>
</td></tr>
<tr><td><code id="topic_diagnostics_+3A_method">method</code></td>
<td>
<p>a string indicating which method to use -
&quot;gamma_threshold&quot; or &quot;largest_gamma&quot;</p>
</td></tr>
<tr><td><code id="topic_diagnostics_+3A_gamma_threshold">gamma_threshold</code></td>
<td>
<p>a number between 0 and 1 indicating the gamma threshold to be used
when using the gamma threshold method, the default is 0.2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe where each row is a topic and each column contains
the associated diagnostic values
</p>


<h3>References</h3>


<p>Jordan Boyd-Graber, David Mimno, and David Newman, 2014.
<em>Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements.</em>
CRC Handbooks ofModern Statistical Methods. CRC Press, Boca Raton, Florida.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
topic_diagnostics(lda, AssociatedPress[1:20,])
</code></pre>

<hr>
<h2 id='topic_exclusivity'>Calculate the exclusivity of each topic in a topic model</h2><span id='topic+topic_exclusivity'></span>

<h3>Description</h3>

<p>Using the the N highest probability tokens for each topic, calculate
the exclusivity for each topic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topic_exclusivity(topic_model, top_n_tokens = 10, excl_weight = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="topic_exclusivity_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
<tr><td><code id="topic_exclusivity_+3A_top_n_tokens">top_n_tokens</code></td>
<td>
<p>an integer indicating the number of top words to consider,
the default is 10</p>
</td></tr>
<tr><td><code id="topic_exclusivity_+3A_excl_weight">excl_weight</code></td>
<td>
<p>a numeric between 0 and 1 indicating the weight to place on exclusivity
versus frequency in the calculation, 0.5 is the default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of exclusivity values with length equal to the number of topics in the fitted model
</p>


<h3>References</h3>


<p>Bischof, Jonathan, and Edoardo Airoldi. 2012.
&quot;Summarizing topical content with word frequency and exclusivity.&quot;
In Proceedings of the 29th International Conference on Machine Learning (ICML-12),
eds John Langford and Joelle Pineau.New York, NY: Omnipress, 201–208.

</p>


<h3>See Also</h3>

<p><code><a href="stm.html#topic+exclusivity">exclusivity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
topic_exclusivity(lda)
</code></pre>

<hr>
<h2 id='topic_size'>Calculate the size of each topic in a topic model</h2><span id='topic+topic_size'></span>

<h3>Description</h3>

<p>Calculate the size of each topic in a topic model based on the
number of fractional tokens found in each topic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topic_size(topic_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="topic_size_+3A_topic_model">topic_model</code></td>
<td>
<p>a fitted topic model object from one of the following:
<code><a href="topicmodels.html#topic+tm-class">tm-class</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of topic sizes with length equal to the number of topics in the fitted model
</p>


<h3>References</h3>


<p>Jordan Boyd-Graber, David Mimno, and David Newman, 2014.
<em>Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements.</em>
CRC Handbooks ofModern Statistical Methods. CRC Press, Boca Raton, Florida.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Using the example from the LDA function
library(topicmodels)
data("AssociatedPress", package = "topicmodels")
lda &lt;- LDA(AssociatedPress[1:20,], control = list(alpha = 0.1), k = 2)
topic_size(lda)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
