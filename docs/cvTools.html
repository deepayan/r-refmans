<!DOCTYPE html><html><head><title>Help for package cvTools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cvTools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cvTools-package'><p>Cross-Validation Tools for Regression Models</p></a></li>
<li><a href='#accessors'><p>Access or set information on cross-validation results</p></a></li>
<li><a href='#aggregate.cv'><p>Aggregate cross-validation results</p></a></li>
<li><a href='#bwplot.cv'><p>Box-and-whisker plots of cross-validation results</p></a></li>
<li><a href='#cost'><p>Prediction loss</p></a></li>
<li><a href='#cvFit'><p>Cross-validation for model evaluation</p></a></li>
<li><a href='#cvFolds'><p>Cross-validation folds</p></a></li>
<li><a href='#cvReshape'><p>Reshape cross-validation results</p></a></li>
<li><a href='#cvSelect'><p>Model selection based on cross-validation</p></a></li>
<li><a href='#cvTool'><p>Low-level function for cross-validation</p></a></li>
<li><a href='#cvTuning'><p>Cross-validation for tuning parameter selection</p></a></li>
<li><a href='#densityplot.cv'><p>Kernel density plots of cross-validation results</p></a></li>
<li><a href='#dotplot.cv'><p>Dot plots of cross-validation results</p></a></li>
<li><a href='#plot.cv'><p>Plot cross-validation results</p></a></li>
<li><a href='#repCV'><p>Cross-validation for linear models</p></a></li>
<li><a href='#subset.cv'><p>Subsetting cross-validation results</p></a></li>
<li><a href='#summary.cv'><p>Summarize cross-validation results</p></a></li>
<li><a href='#xyplot.cv'><p>X-Y plots of cross-validation results</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Cross-Validation Tools for Regression Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-13</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.11.0), lattice, robustbase</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools that allow developers to write functions for
    cross-validation with minimal programming effort and assist
    users with model selection.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Author:</td>
<td>Andreas Alfons <a href="https://orcid.org/0000-0002-2513-3788"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andreas Alfons &lt;alfons@ese.eur.nl&gt;</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-13 11:49:07 UTC; andreas</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-13 12:40:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='cvTools-package'>Cross-Validation Tools for Regression Models</h2><span id='topic+cvTools-package'></span><span id='topic+cvTools'></span>

<h3>Description</h3>

<p>Tools that allow developers to write functions for
    cross-validation with minimal programming effort and assist
    users with model selection.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> cvTools</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Cross-Validation Tools for Regression Models</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.3.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-03-13</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 2.11.0),
lattice,
robustbase</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> stats</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Tools that allow developers to write functions for
    cross-validation with minimal programming effort and assist
    users with model selection.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> 
    person("Andreas", "Alfons",
           email = "alfons@ese.eur.nl",
           role = c("aut", "cre"),
           comment = c(ORCID = "0000-0002-2513-3788"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Andreas Alfons [aut, cre] (&lt;https://orcid.org/0000-0002-2513-3788&gt;)</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Andreas Alfons &lt;alfons@ese.eur.nl&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Encoding: </td><td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
 <td style="text-align: left;">
RoxygenNote: </td><td style="text-align: left;"> 7.2.3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
accessors               Access or set information on cross-validation
                        results
aggregate.cv            Aggregate cross-validation results
bwplot.cv               Box-and-whisker plots of cross-validation
                        results
cost                    Prediction loss
cvFit                   Cross-validation for model evaluation
cvFolds                 Cross-validation folds
cvReshape               Reshape cross-validation results
cvSelect                Model selection based on cross-validation
cvTool                  Low-level function for cross-validation
cvTools-package         Cross-Validation Tools for Regression Models
cvTuning                Cross-validation for tuning parameter selection
densityplot.cv          Kernel density plots of cross-validation
                        results
dotplot.cv              Dot plots of cross-validation results
plot.cv                 Plot cross-validation results
repCV                   Cross-validation for linear models
subset.cv               Subsetting cross-validation results
summary.cv              Summarize cross-validation results
xyplot.cv               X-Y plots of cross-validation results
</pre>


<h3>Author(s)</h3>

<p>Andreas Alfons [aut, cre] (&lt;https://orcid.org/0000-0002-2513-3788&gt;)
</p>
<p>Maintainer: Andreas Alfons &lt;alfons@ese.eur.nl&gt;
</p>

<hr>
<h2 id='accessors'>Access or set information on cross-validation results</h2><span id='topic+accessors'></span><span id='topic+cvNames'></span><span id='topic+cvNames+3C-'></span><span id='topic+fits'></span><span id='topic+fits+3C-'></span><span id='topic+ncv'></span><span id='topic+nfits'></span>

<h3>Description</h3>

<p>Retrieve or set the names of cross-validation results, retrieve or set the
identifiers of the models, or retrieve the number of cross-validation
results or included models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvNames(x)

cvNames(x) &lt;- value

fits(x)

fits(x) &lt;- value

ncv(x)

nfits(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accessors_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or <code>"cvSelect"</code>
that contains cross-validation results.</p>
</td></tr>
<tr><td><code id="accessors_+3A_value">value</code></td>
<td>
<p>a vector of replacement values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>cvNames</code> returns the names of the cross-validation results.  The
replacement function thereby returns them invisibly.
</p>
<p><code>fits</code> returns the identifiers of the models for objects inheriting
from class <code>"cvSelect"</code> and <code>NULL</code> for objects inheriting from
class <code>"cv"</code>.  The replacement function thereby returns those values
invisibly.
</p>
<p><code>ncv</code> returns the number of cross-validation results.
</p>
<p><code>nfits</code> returns the number of models included in objects inheriting
from class <code>"cvSelect"</code> and <code>NULL</code> for objects inheriting from
class <code>"cv"</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, <code><a href="#topic+cvTuning">cvTuning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare raw and reweighted LTS estimators for 
## 50% and 75% subsets

# 50% subsets
fitLts50 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.5)
cvFitLts50 &lt;- cvLts(fitLts50, cost = rtmspe, folds = folds, 
    fit = "both", trim = 0.1)

# 75% subsets
fitLts75 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.75)
cvFitLts75 &lt;- cvLts(fitLts75, cost = rtmspe, folds = folds, 
    fit = "both", trim = 0.1)

# combine results into one object
cvFitsLts &lt;- cvSelect("0.5" = cvFitLts50, "0.75" = cvFitLts75)
cvFitsLts

# "cv" object
ncv(cvFitLts50)
nfits(cvFitLts50)
cvNames(cvFitLts50)
cvNames(cvFitLts50) &lt;- c("improved", "initial")
fits(cvFitLts50)
cvFitLts50

# "cvSelect" object
ncv(cvFitsLts)
nfits(cvFitsLts)
cvNames(cvFitsLts)
cvNames(cvFitsLts) &lt;- c("improved", "initial")
fits(cvFitsLts)
fits(cvFitsLts) &lt;- 1:2
cvFitsLts
</code></pre>

<hr>
<h2 id='aggregate.cv'>Aggregate cross-validation results</h2><span id='topic+aggregate.cv'></span><span id='topic+aggregate.cvSelect'></span><span id='topic+aggregate.cvTuning'></span>

<h3>Description</h3>

<p>Compute summary statistics of results from repeated <code class="reqn">K</code>-fold 
cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
aggregate(x, FUN = mean, select = NULL, ...)

## S3 method for class 'cvSelect'
aggregate(x, FUN = mean, select = NULL, ...)

## S3 method for class 'cvTuning'
aggregate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aggregate.cv_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or <code>"cvSelect"</code> 
that contains cross-validation results (note that the latter includes 
objects of class <code>"cvTuning"</code>).</p>
</td></tr>
<tr><td><code id="aggregate.cv_+3A_fun">FUN</code></td>
<td>
<p>a function to compute the summary statistics.</p>
</td></tr>
<tr><td><code id="aggregate.cv_+3A_select">select</code></td>
<td>
<p>a character, integer or logical vector indicating the columns 
of cross-validation results for which to compute the summary statistics.</p>
</td></tr>
<tr><td><code id="aggregate.cv_+3A_...">...</code></td>
<td>
<p>for the <code>"cvTuning"</code> method, additional arguments to be 
passed to the <code>"cvSelect"</code> method.  Otherwise additional arguments to 
be passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>"cv"</code> method returns a vector or matrix of aggregated 
cross-validation results, depending on whether <code>FUN</code> returns a single 
value or a vector.
</p>
<p>For the other methods, a data frame containing the aggregated 
cross-validation results for each model is returned.  In the case of the 
<code>"cvTuning"</code> method, the data frame contains the combinations of tuning 
parameters rather than a column describing the models.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="stats.html#topic+aggregate">aggregate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare raw and reweighted LTS estimators for
## 50% and 75% subsets

# 50% subsets
fitLts50 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.5)
cvFitLts50 &lt;- cvLts(fitLts50, cost = rtmspe, folds = folds,
    fit = "both", trim = 0.1)

# 75% subsets
fitLts75 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.75)
cvFitLts75 &lt;- cvLts(fitLts75, cost = rtmspe, folds = folds,
    fit = "both", trim = 0.1)

# combine results into one object
cvFitsLts &lt;- cvSelect("0.5" = cvFitLts50, "0.75" = cvFitLts75)
cvFitsLts

# summary of the results with the 50% subsets
aggregate(cvFitLts50, summary)
# summary of the combined results
aggregate(cvFitsLts, summary)

</code></pre>

<hr>
<h2 id='bwplot.cv'>Box-and-whisker plots of cross-validation results</h2><span id='topic+bwplot.cv'></span><span id='topic+bwplot.cvSelect'></span>

<h3>Description</h3>

<p>Produce box-and-whisker plots of results from repeated <code class="reqn">K</code>-fold 
cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
bwplot(x, data, select = NULL, ...)

## S3 method for class 'cvSelect'
bwplot(x, data, subset = NULL, select = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bwplot.cv_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or <code>"cvSelect"</code> 
that contains cross-validation results.</p>
</td></tr>
<tr><td><code id="bwplot.cv_+3A_data">data</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
<tr><td><code id="bwplot.cv_+3A_select">select</code></td>
<td>
<p>a character, integer or logical vector indicating the columns 
of cross-validation results to be plotted.</p>
</td></tr>
<tr><td><code id="bwplot.cv_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code>"formula"</code> 
method of <code><a href="lattice.html#topic+xyplot">bwplot</a></code>.</p>
</td></tr>
<tr><td><code id="bwplot.cv_+3A_subset">subset</code></td>
<td>
<p>a character, integer or logical vector indicating the subset 
of models for which to plot the cross-validation results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects with multiple columns of repeated cross-validation results, 
conditional box-and-whisker plots are produced.
</p>


<h3>Value</h3>

<p>An object of class <code>"trellis"</code> is returned invisibly.  The 
<code><a href="lattice.html#topic+update.trellis">update</a></code> method can be used to update 
components of the object and the <code><a href="lattice.html#topic+print.trellis">print</a></code> 
method (usually called by default) will plot it on an appropriate plotting 
device.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="#topic+plot.cv">plot</a></code>, 
<code><a href="#topic+densityplot.cv">densityplot</a></code>, 
<code><a href="#topic+xyplot.cvSelect">xyplot</a></code>, 
<code><a href="#topic+dotplot.cvSelect">dotplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare LS, MM and LTS regression

# perform cross-validation for an LS regression model
fitLm &lt;- lm(Y ~ ., data = coleman)
cvFitLm &lt;- cvLm(fitLm, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an MM regression model
fitLmrob &lt;- lmrob(Y ~ ., data = coleman, k.max = 500)
cvFitLmrob &lt;- cvLmrob(fitLmrob, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
cvFitLts &lt;- cvLts(fitLts, cost = rtmspe,
    folds = folds, trim = 0.1)

# combine results into one object
cvFits &lt;- cvSelect(LS = cvFitLm, MM = cvFitLmrob, LTS = cvFitLts)
cvFits

# plot results for the MM regression model
bwplot(cvFitLmrob)
# plot combined results
bwplot(cvFits)

</code></pre>

<hr>
<h2 id='cost'>Prediction loss</h2><span id='topic+cost'></span><span id='topic+mspe'></span><span id='topic+rmspe'></span><span id='topic+mape'></span><span id='topic+tmspe'></span><span id='topic+rtmspe'></span>

<h3>Description</h3>

<p>Compute the prediction loss of a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mspe(y, yHat, includeSE = FALSE)

rmspe(y, yHat, includeSE = FALSE)

mape(y, yHat, includeSE = FALSE)

tmspe(y, yHat, trim = 0.25, includeSE = FALSE)

rtmspe(y, yHat, trim = 0.25, includeSE = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cost_+3A_y">y</code></td>
<td>
<p>a numeric vector or matrix giving the observed values.</p>
</td></tr>
<tr><td><code id="cost_+3A_yhat">yHat</code></td>
<td>
<p>a numeric vector or matrix of the same dimensions as <code>y</code> 
giving the fitted values.</p>
</td></tr>
<tr><td><code id="cost_+3A_includese">includeSE</code></td>
<td>
<p>a logical indicating whether standard errors should be computed 
as well.</p>
</td></tr>
<tr><td><code id="cost_+3A_trim">trim</code></td>
<td>
<p>a numeric value giving the trimming proportion (the default is 
0.25).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mspe</code> and <code>rmspe</code> compute the mean squared prediction error and 
the root mean squared prediction error, respectively.  In addition, 
<code>mape</code> returns the mean absolute prediction error, which is somewhat 
more robust.
</p>
<p>Robust prediction loss based on trimming is implemented in <code>tmspe</code> and 
<code>rtmspe</code>.  To be more precise, <code>tmspe</code> computes the trimmed mean 
squared prediction error and <code>rtmspe</code> computes the root trimmed mean 
squared prediction error.  A proportion of the largest squared differences 
of the observed and fitted values are thereby trimmed.
</p>
<p>Standard errors can be requested via the <code>includeSE</code> argument.  Note that 
standard errors for <code>tmspe</code> are based on a winsorized standard 
deviation.  Furthermore, standard errors for <code>rmspe</code> and <code>rtmspe</code> 
are computed from the respective standard errors of <code>mspe</code> and 
<code>tmspe</code> via the delta method.
</p>


<h3>Value</h3>

<p>If standard errors are not requested, a numeric value giving the 
prediction loss is returned.
</p>
<p>Otherwise a list is returned, with the first component containing the 
prediction loss and the second component the corresponding standard error.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Tukey, J.W. and McLaughlin, D.H. (1963) Less vulnerable confidence and 
significance procedures for location based on a single sample: 
Trimming/winsorization.  <em>Sankhya: The Indian Journal of Statistics, 
Series A</em>, <b>25</b>(3), 331&ndash;352
</p>
<p>Oehlert, G.W. (1992) A note on the delta method.  <em>The American 
Statistician</em>, <b>46</b>(1), 27&ndash;29.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvTuning">cvTuning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># fit an MM-regression model
data("coleman")
fit &lt;- lmrob(Y~., data=coleman)

# compute the prediction loss from the fitted values
# (hence the prediction loss is underestimated in this simple 
# example since all observations are used to fit the model)
mspe(coleman$Y, predict(fit))
rmspe(coleman$Y, predict(fit))
mape(coleman$Y, predict(fit))
tmspe(coleman$Y, predict(fit), trim = 0.1)
rtmspe(coleman$Y, predict(fit), trim = 0.1)

# include standard error
mspe(coleman$Y, predict(fit), includeSE = TRUE)
rmspe(coleman$Y, predict(fit), includeSE = TRUE)
mape(coleman$Y, predict(fit), includeSE = TRUE)
tmspe(coleman$Y, predict(fit), trim = 0.1, includeSE = TRUE)
rtmspe(coleman$Y, predict(fit), trim = 0.1, includeSE = TRUE)

</code></pre>

<hr>
<h2 id='cvFit'>Cross-validation for model evaluation</h2><span id='topic+cvFit'></span><span id='topic+print.cv'></span><span id='topic+cvFit.default'></span><span id='topic+cvFit.function'></span><span id='topic+cvFit.call'></span>

<h3>Description</h3>

<p>Estimate the prediction error of a model via (repeated) <code class="reqn">K</code>-fold
cross-validation.  It is thereby possible to supply an object returned by a
model fitting function, a model fitting function itself, or an unevaluated
function call to a model fitting function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvFit(object, ...)

## Default S3 method:
cvFit(
  object,
  data = NULL,
  x = NULL,
  y,
  cost = rmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  names = NULL,
  predictArgs = list(),
  costArgs = list(),
  envir = parent.frame(),
  seed = NULL,
  ...
)

## S3 method for class ''function''
cvFit(
  object,
  formula,
  data = NULL,
  x = NULL,
  y,
  args = list(),
  cost = rmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  names = NULL,
  predictArgs = list(),
  costArgs = list(),
  envir = parent.frame(),
  seed = NULL,
  ...
)

## S3 method for class 'call'
cvFit(
  object,
  data = NULL,
  x = NULL,
  y,
  cost = rmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  names = NULL,
  predictArgs = list(),
  costArgs = list(),
  envir = parent.frame(),
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvFit_+3A_object">object</code></td>
<td>
<p>the fitted model for which to estimate the prediction error,
a function for fitting a model, or an unevaluated function call for fitting
a model (see <code><a href="base.html#topic+call">call</a></code> for the latter).  In the case of a fitted
model, the object is required to contain a component <code>call</code> that stores
the function call used to fit the model, which is typically the case for
objects returned by model fitting functions.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed down.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables required for fitting the
models.  This is typically used if the model in the function call is
described by a <code><a href="stats.html#topic+formula">formula</a></code>.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_x">x</code></td>
<td>
<p>a numeric matrix containing the predictor variables.  This is
typically used if the function call for fitting the models requires the
predictor matrix and the response to be supplied as separate arguments.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_y">y</code></td>
<td>
<p>a numeric vector or matrix containing the response.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_cost">cost</code></td>
<td>
<p>a cost function measuring prediction loss.  It should expect
the observed values of the response to be passed as the first argument and
the predicted values as the second argument, and must return either a
non-negative scalar value, or a list with the first component containing
the prediction error and the second component containing the standard
error.  The default is to use the root mean squared prediction error
(see <code><a href="#topic+cost">cost</a></code>).</p>
</td></tr>
<tr><td><code id="cvFit_+3A_k">K</code></td>
<td>
<p>an integer giving the number of folds into which the data should
be split (the default is five).  Keep in mind that this should be chosen
such that all folds are of approximately equal size.  Setting <code>K</code>
equal to the number of observations or groups yields leave-one-out
cross-validation.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_r">R</code></td>
<td>
<p>an integer giving the number of replications for repeated
<code class="reqn">K</code>-fold cross-validation.  This is ignored for for leave-one-out
cross-validation and other non-random splits of the data.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_foldtype">foldType</code></td>
<td>
<p>a character string specifying the type of folds to be
generated.  Possible values are <code>"random"</code> (the default),
<code>"consecutive"</code> or <code>"interleaved"</code>.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_grouping">grouping</code></td>
<td>
<p>a factor specifying groups of observations.  If supplied,
the data are split according to the groups rather than individual
observations such that all observations within a group belong to the same
fold.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_folds">folds</code></td>
<td>
<p>an object of class <code>"cvFolds"</code> giving the folds of the
data for cross-validation (as returned by <code><a href="#topic+cvFolds">cvFolds</a></code>).  If
supplied, this is preferred over the arguments for generating
cross-validation folds.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_names">names</code></td>
<td>
<p>an optional character vector giving names for the arguments
containing the data to be used in the function call (see &ldquo;Details&rdquo;).</p>
</td></tr>
<tr><td><code id="cvFit_+3A_predictargs">predictArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the
<code><a href="stats.html#topic+predict">predict</a></code> method of the fitted models.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_costargs">costArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the
prediction loss function <code>cost</code>.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_envir">envir</code></td>
<td>
<p>the <code><a href="base.html#topic+environment">environment</a></code> in which to evaluate the
function call for fitting the models (see <code><a href="base.html#topic+eval">eval</a></code>).</p>
</td></tr>
<tr><td><code id="cvFit_+3A_seed">seed</code></td>
<td>
<p>optional initial seed for the random number generator (see
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>).</p>
</td></tr>
<tr><td><code id="cvFit_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> describing the model.</p>
</td></tr>
<tr><td><code id="cvFit_+3A_args">args</code></td>
<td>
<p>a list of additional arguments to be passed to the model
fitting function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(Repeated) <code class="reqn">K</code>-fold cross-validation is performed in the following
way.  The data are first split into <code class="reqn">K</code> previously obtained blocks of
approximately equal size.  Each of the <code class="reqn">K</code> data blocks is left out once
to fit the model, and predictions are computed for the observations in the
left-out block with the <code><a href="stats.html#topic+predict">predict</a></code> method of the fitted
model.  Thus a prediction is obtained for each observation.
</p>
<p>The response variable and the obtained predictions for all observations are
then passed to the prediction loss function <code>cost</code> to estimate the
prediction error.  For repeated cross-validation, this process is replicated
and the estimated prediction errors from all replications as well as their
average are included in the returned object.
</p>
<p>Furthermore, if the response is a vector but the
<code><a href="stats.html#topic+predict">predict</a></code> method of the fitted models returns a matrix,
the prediction error is computed for each column.  A typical use case for
this behavior would be if the <code><a href="stats.html#topic+predict">predict</a></code> method returns
predictions from an initial model fit and stepwise improvements thereof.
</p>
<p>If <code>formula</code> or <code>data</code> are supplied, all variables required for
fitting the models are added as one argument to the function call, which is
the typical behavior of model fitting functions with a
<code><a href="stats.html#topic+formula">formula</a></code> interface.  In this case, the accepted values
for <code>names</code> depend on the method.  For the <code>function</code> method, a
character vector of length two should supplied, with the first element
specifying the argument name for the formula and the second element
specifying the argument name for the data (the default is to use
<code>c("formula", "data")</code>).  Note that names for both arguments should be
supplied even if only one is actually used.  For the other methods, which do
not have a <code>formula</code> argument, a character string specifying the
argument name for the data should be supplied (the default is to use
<code>"data"</code>).
</p>
<p>If <code>x</code> is supplied, on the other hand, the predictor matrix and the
response are added as separate arguments to the function call.  In this
case, <code>names</code> should be a character vector of length two, with the
first element specifying the argument name for the predictor matrix and the
second element specifying the argument name for the response (the default is
to use <code>c("x", "y")</code>).  It should be noted that the <code>formula</code> or
<code>data</code> arguments take precedence over <code>x</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"cv"</code> with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>an integer giving the number of observations or groups.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>an integer giving the number of folds.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>an integer giving the number of replications.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>a numeric vector containing the respective estimated
prediction errors.  For repeated cross-validation, those are average values
over all replications.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>a numeric vector containing the respective estimated
standard errors of the prediction loss.</p>
</td></tr>
<tr><td><code>reps</code></td>
<td>
<p>a numeric matrix in which each column contains the
respective estimated prediction errors from all replications.  This is
only returned for repeated cross-validation.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>the seed of the random number generator before
cross-validation was performed.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched function call.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvTool">cvTool</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>,
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="#topic+cvFolds">cvFolds</a></code>, <code><a href="#topic+cost">cost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")

## via model fit
# fit an MM regression model
fit &lt;- lmrob(Y ~ ., data=coleman)
# perform cross-validation
cvFit(fit, data = coleman, y = coleman$Y, cost = rtmspe, 
    K = 5, R = 10, costArgs = list(trim = 0.1), seed = 1234)

## via model fitting function
# perform cross-validation
# note that the response is extracted from 'data' in 
# this example and does not have to be supplied
cvFit(lmrob, formula = Y ~ ., data = coleman, cost = rtmspe, 
    K = 5, R = 10, costArgs = list(trim = 0.1), seed = 1234)

## via function call
# set up function call
call &lt;- call("lmrob", formula = Y ~ .)
# perform cross-validation
cvFit(call, data = coleman, y = coleman$Y, cost = rtmspe, 
    K = 5, R = 10, costArgs = list(trim = 0.1), seed = 1234)
</code></pre>

<hr>
<h2 id='cvFolds'>Cross-validation folds</h2><span id='topic+cvFolds'></span><span id='topic+print.cvFolds'></span>

<h3>Description</h3>

<p>Split observations or groups of observations into <code class="reqn">K</code> folds to be used
for (repeated) <code class="reqn">K</code>-fold cross-validation.  <code class="reqn">K</code> should thereby be
chosen such that all folds are of approximately equal size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvFolds(
  n,
  K = 5,
  R = 1,
  type = c("random", "consecutive", "interleaved"),
  grouping = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvFolds_+3A_n">n</code></td>
<td>
<p>an integer giving the number of observations to be split into
folds.  This is ignored if <code>grouping</code> is supplied in order to split
groups of observations into folds.</p>
</td></tr>
<tr><td><code id="cvFolds_+3A_k">K</code></td>
<td>
<p>an integer giving the number of folds into which the observations
should be split (the default is five).  Setting <code>K</code> equal to the number
of observations or groups yields leave-one-out cross-validation.</p>
</td></tr>
<tr><td><code id="cvFolds_+3A_r">R</code></td>
<td>
<p>an integer giving the number of replications for repeated
<code class="reqn">K</code>-fold cross-validation.  This is ignored for for leave-one-out
cross-validation and other non-random splits of the data.</p>
</td></tr>
<tr><td><code id="cvFolds_+3A_type">type</code></td>
<td>
<p>a character string specifying the type of folds to be
generated.  Possible values are <code>"random"</code> (the default),
<code>"consecutive"</code> or <code>"interleaved"</code>.</p>
</td></tr>
<tr><td><code id="cvFolds_+3A_grouping">grouping</code></td>
<td>
<p>a factor specifying groups of observations.  If supplied,
the data are split according to the groups rather than individual
observations such that all observations within a group belong to the same
fold.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"cvFolds"</code> with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>an integer giving the number of observations or groups.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>an integer giving the number of folds.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>an integer giving the number of replications.</p>
</td></tr>
<tr><td><code>subsets</code></td>
<td>
<p>an integer matrix in which each column contains a
permutation of the indices of the observations or groups.</p>
</td></tr>
<tr><td><code>which</code></td>
<td>
<p>an integer vector giving the fold for each permuted
observation or group.</p>
</td></tr>
<tr><td><code>grouping</code></td>
<td>
<p>a list giving the indices of the observations
belonging to each group.  This is only returned if a grouping factor
has been supplied.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, <code><a href="#topic+cvTuning">cvTuning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)  # set seed for reproducibility
cvFolds(20, K = 5, type = "random")
cvFolds(20, K = 5, type = "consecutive")
cvFolds(20, K = 5, type = "interleaved")
cvFolds(20, K = 5, R = 10)

</code></pre>

<hr>
<h2 id='cvReshape'>Reshape cross-validation results</h2><span id='topic+cvReshape'></span><span id='topic+cvReshape.cv'></span><span id='topic+cvReshape.cvSelect'></span>

<h3>Description</h3>

<p>Reshape cross-validation results into an object of class <code>"cvSelect"</code>
with only one column of results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvReshape(x, ...)

## S3 method for class 'cv'
cvReshape(x, selectBest = c("min", "hastie"), seFactor = 1, ...)

## S3 method for class 'cvSelect'
cvReshape(x, selectBest = c("min", "hastie"), seFactor = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvReshape_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or <code>"cvSelect"</code>
that contains cross-validation results.</p>
</td></tr>
<tr><td><code id="cvReshape_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed down.</p>
</td></tr>
<tr><td><code id="cvReshape_+3A_selectbest">selectBest</code></td>
<td>
<p>a character string specifying a criterion for selecting
the best model.  Possible values are <code>"min"</code> (the default) or
<code>"hastie"</code>.  The former selects the model with the smallest prediction
error.  The latter is useful for nested models or for models with a tuning
parameter controlling the complexity of the model (e.g., penalized
regression).  It selects the most parsimonious model whose prediction error
is no larger than <code>seFactor</code> standard errors above the prediction error
of the best overall model.  Note that the models are thereby assumed to be
ordered from the most parsimonious one to the most complex one.  In
particular a one-standard-error rule is frequently applied.</p>
</td></tr>
<tr><td><code id="cvReshape_+3A_sefactor">seFactor</code></td>
<td>
<p>a numeric value giving a multiplication factor of the
standard error for the selection of the best model.  This is ignored if
<code>selectBest</code> is <code>"min"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"cvSelect"</code> with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>an integer giving the number of observations.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>an integer giving the number of folds used in
cross-validation.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>an integer giving the number of replications used in
cross-validation.</p>
</td></tr>
<tr><td><code>best</code></td>
<td>
<p>an integer giving the index of the model with the best
prediction performance.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>a data frame containing the estimated prediction errors for
the models.  For repeated cross-validation, those are average values over
all replications.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>a data frame containing the estimated standard errors of the
prediction loss for the models.</p>
</td></tr>
<tr><td><code>selectBest</code></td>
<td>
<p>a character string specifying the criterion used for
selecting the best model.</p>
</td></tr>
<tr><td><code>seFactor</code></td>
<td>
<p>a numeric value giving the multiplication factor of
the standard error used for the selection of the best model.</p>
</td></tr>
<tr><td><code>reps</code></td>
<td>
<p>a data frame containing the estimated prediction errors
for the models from all replications.  This is only returned if repeated
cross-validation was performed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R. and Friedman, J. (2009) <em>The Elements of
Statistical Learning: Data Mining, Inference, and Prediction</em>.  Springer,
2nd edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, <code><a href="#topic+cvTuning">cvTuning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
cvFitLts &lt;- cvLts(fitLts, cost = rtmspe, K = 5, R = 10, 
    fit = "both", trim = 0.1, seed = 1234)
# compare original and reshaped object
cvFitLts
cvReshape(cvFitLts)
</code></pre>

<hr>
<h2 id='cvSelect'>Model selection based on cross-validation</h2><span id='topic+cvSelect'></span><span id='topic+print.cvSelect'></span>

<h3>Description</h3>

<p>Combine cross-validation results for various models into one object and
select the model with the best prediction performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvSelect(
  ...,
  .reshape = FALSE,
  .selectBest = c("min", "hastie"),
  .seFactor = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvSelect_+3A_...">...</code></td>
<td>
<p>objects inheriting from class <code>"cv"</code> or <code>"cvSelect"</code>
that contain cross-validation results.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_.reshape">.reshape</code></td>
<td>
<p>a logical indicating whether objects with more than one
column of cross-validation results should be reshaped to have only one
column (see &ldquo;Details&rdquo;).</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_.selectbest">.selectBest</code></td>
<td>
<p>a character string specifying a criterion for selecting
the best model.  Possible values are <code>"min"</code> (the default) or
<code>"hastie"</code>.  The former selects the model with the smallest prediction
error.  The latter is useful for nested models or for models with a tuning
parameter controlling the complexity of the model (e.g., penalized
regression).  It selects the most parsimonious model whose prediction error
is no larger than <code>.seFactor</code> standard errors above the prediction error
of the best overall model.  Note that the models are thereby assumed to be
ordered from the most parsimonious one to the most complex one.  In
particular a one-standard-error rule is frequently applied.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_.sefactor">.seFactor</code></td>
<td>
<p>a numeric value giving a multiplication factor of the
standard error for the selection of the best model.  This is ignored if
<code>.selectBest</code> is <code>"min"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Keep in mind that objects inheriting from class <code>"cv"</code> or
<code>"cvSelect"</code> may contain multiple columns of cross-validation
results.  This is the case if the response is univariate but the
<code><a href="stats.html#topic+predict">predict</a></code> method of the fitted model returns a
matrix.
</p>
<p>The <code>.reshape</code> argument determines how to handle such objects.  If
<code>.reshape</code> is <code>FALSE</code>, all objects are required to have the same
number of columns and the best model for each column is selected.  A typical
use case for this behavior would be if the investigated models contain
cross-validation results for a raw and a reweighted fit.  It might then be
of interest to researchers to compare the best model for the raw estimators
with the best model for the reweighted estimators.
</p>
<p>If <code>.reshape</code> is <code>TRUE</code>, objects with more than one column of
results are first transformed with <code><a href="#topic+cvReshape">cvReshape</a></code> to have only one
column.  Then the best overall model is selected.
</p>
<p>It should also be noted that the argument names of <code>.reshape</code>,
<code>.selectBest</code> and <code>.seFacor</code> start with a dot to avoid conflicts
with the argument names used for the objects containing cross-validation
results.
</p>


<h3>Value</h3>

<p>An object of class <code>"cvSelect"</code> with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>an integer giving the number of observations.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>an integer vector giving the number of folds used in
cross-validation for the respective model.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>an integer vector giving the number of replications used in
cross-validation for the respective model.</p>
</td></tr>
<tr><td><code>best</code></td>
<td>
<p>an integer vector giving the indices of the models with
the best prediction performance.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>a data frame containing the estimated prediction errors for
the models.  For models for which repeated cross-validation was performed,
those are average values over all replications.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>a data frame containing the estimated standard errors of the
prediction loss for the models.</p>
</td></tr>
<tr><td><code>selectBest</code></td>
<td>
<p>a character string specifying the criterion used for
selecting the best model.</p>
</td></tr>
<tr><td><code>seFactor</code></td>
<td>
<p>a numeric value giving the multiplication factor of
the standard error used for the selection of the best model.</p>
</td></tr>
<tr><td><code>reps</code></td>
<td>
<p>a data frame containing the estimated prediction errors
from all replications for those models for which repeated cross-validation
was performed.  This is only returned if repeated cross-validation was
performed for at least one of the models.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Even though the function allows to compare cross-validation results
obtained with a different number of folds or a different number of
replications, such comparisons should be made with care.  Hence warnings
are issued in those cases.  For maximum comparability, the same data folds
should be used in cross-validation for all models to be compared.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R. and Friedman, J. (2009) <em>The Elements of
Statistical Learning: Data Mining, Inference, and Prediction</em>.  Springer,
2nd edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvTuning">cvTuning</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

# set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare LS, MM and LTS regression

# perform cross-validation for an LS regression model
fitLm &lt;- lm(Y ~ ., data = coleman)
cvFitLm &lt;- cvLm(fitLm, cost = rtmspe, 
    folds = folds, trim = 0.1)

# perform cross-validation for an MM regression model
fitLmrob &lt;- lmrob(Y ~ ., data = coleman)
cvFitLmrob &lt;- cvLmrob(fitLmrob, cost = rtmspe, 
    folds = folds, trim = 0.1)

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
cvFitLts &lt;- cvLts(fitLts, cost = rtmspe, 
    folds = folds, trim = 0.1)

# compare cross-validation results
cvSelect(LS = cvFitLm, MM = cvFitLmrob, LTS = cvFitLts)
</code></pre>

<hr>
<h2 id='cvTool'>Low-level function for cross-validation</h2><span id='topic+cvTool'></span>

<h3>Description</h3>

<p>Basic function to estimate the prediction error of a model via (repeated) 
<code class="reqn">K</code>-fold cross-validation.  The model is thereby specified by an 
unevaluated function call to a model fitting function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvTool(
  call,
  data = NULL,
  x = NULL,
  y,
  cost = rmspe,
  folds,
  names = NULL,
  predictArgs = list(),
  costArgs = list(),
  envir = parent.frame()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvTool_+3A_call">call</code></td>
<td>
<p>an unevaluated function call for fitting a model (see 
<code><a href="base.html#topic+call">call</a></code>).</p>
</td></tr>
<tr><td><code id="cvTool_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables required for fitting the 
models.  This is typically used if the model in the function call is 
described by a <code><a href="stats.html#topic+formula">formula</a></code>.</p>
</td></tr>
<tr><td><code id="cvTool_+3A_x">x</code></td>
<td>
<p>a numeric matrix containing the predictor variables.  This is 
typically used if the function call for fitting the models requires the 
predictor matrix and the response to be supplied as separate arguments.</p>
</td></tr>
<tr><td><code id="cvTool_+3A_y">y</code></td>
<td>
<p>a numeric vector or matrix containing the response.</p>
</td></tr>
<tr><td><code id="cvTool_+3A_cost">cost</code></td>
<td>
<p>a cost function measuring prediction loss.  It should expect 
the observed values of the response to be passed as the first argument and 
the predicted values as the second argument, and must return either a 
non-negative scalar value, or a list with the first component containing 
the prediction error and the second component containing the standard 
error.  The default is to use the root mean squared prediction error 
(see <code><a href="#topic+cost">cost</a></code>).</p>
</td></tr>
<tr><td><code id="cvTool_+3A_folds">folds</code></td>
<td>
<p>an object of class <code>"cvFolds"</code> giving the folds of the 
data for cross-validation (as returned by <code><a href="#topic+cvFolds">cvFolds</a></code>).</p>
</td></tr>
<tr><td><code id="cvTool_+3A_names">names</code></td>
<td>
<p>an optional character vector giving names for the arguments 
containing the data to be used in the function call (see &ldquo;Details&rdquo;).</p>
</td></tr>
<tr><td><code id="cvTool_+3A_predictargs">predictArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the 
<code><a href="stats.html#topic+predict">predict</a></code> method of the fitted models.</p>
</td></tr>
<tr><td><code id="cvTool_+3A_costargs">costArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the 
prediction loss function <code>cost</code>.</p>
</td></tr>
<tr><td><code id="cvTool_+3A_envir">envir</code></td>
<td>
<p>the <code><a href="base.html#topic+environment">environment</a></code> in which to evaluate the 
function call for fitting the models (see <code><a href="base.html#topic+eval">eval</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(Repeated) <code class="reqn">K</code>-fold cross-validation is performed in the following 
way.  The data are first split into <code class="reqn">K</code> previously obtained blocks of 
approximately equal size (given by <code>folds</code>).  Each of the <code class="reqn">K</code> data 
blocks is left out once to fit the model, and predictions are computed for 
the observations in the left-out block with the <code><a href="stats.html#topic+predict">predict</a></code> 
method of the fitted model.  Thus a prediction is obtained for each 
observation.
</p>
<p>The response variable and the obtained predictions for all observations are 
then passed to the prediction loss function <code>cost</code> to estimate the 
prediction error.  For repeated cross-validation (as indicated by 
<code>folds</code>), this process is replicated and the estimated prediction 
errors from all replications are returned.
</p>
<p>Furthermore, if the response is a vector but the 
<code><a href="stats.html#topic+predict">predict</a></code> method of the fitted models returns a matrix, 
the prediction error is computed for each column.  A typical use case for 
this behavior would be if the <code><a href="stats.html#topic+predict">predict</a></code> method returns 
predictions from an initial model fit and stepwise improvements thereof.
</p>
<p>If <code>data</code> is supplied, all variables required for fitting the models 
are added as one argument to the function call, which is the typical 
behavior of model fitting functions with a <code><a href="stats.html#topic+formula">formula</a></code> 
interface.  In this case, a character string specifying the argument name 
can be passed via <code>names</code> (the default is to use <code>"data"</code>).  
</p>
<p>If <code>x</code> is supplied, on the other hand, the predictor matrix and the 
response are added as separate arguments to the function call.  In this 
case, <code>names</code> should be a character vector of length two, with the 
first element specifying the argument name for the predictor matrix and the 
second element specifying the argument name for the response (the default is 
to use <code>c("x", "y")</code>).  It should be noted that <code>data</code> takes 
precedence over <code>x</code> if both are supplied.
</p>


<h3>Value</h3>

<p>If only one replication is requested and the prediction loss 
function <code>cost</code> also returns the standard error, a list is returned, 
with the first component containing the estimated prediction errors and the 
second component the corresponding estimated standard errors.
</p>
<p>Otherwise the return value is a numeric matrix in which each column contains 
the respective estimated prediction errors from all replications.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="#topic+cvFolds">cvFolds</a></code>, 
<code><a href="#topic+cost">cost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

# set up function call for an MM regression model
call &lt;- call("lmrob", formula = Y ~ .)
# set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)

# perform cross-validation
cvTool(call, data = coleman, y = coleman$Y, cost = rtmspe, 
    folds = folds, costArgs = list(trim = 0.1))
</code></pre>

<hr>
<h2 id='cvTuning'>Cross-validation for tuning parameter selection</h2><span id='topic+cvTuning'></span><span id='topic+print.cvTuning'></span><span id='topic+cvTuning.function'></span><span id='topic+cvTuning.call'></span>

<h3>Description</h3>

<p>Select tuning parameters of a model by estimating the respective prediction
errors via (repeated) <code class="reqn">K</code>-fold cross-validation.  It is thereby possible
to supply a model fitting function or an unevaluated function call to a
model fitting function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvTuning(object, ...)

## S3 method for class ''function''
cvTuning(
  object,
  formula,
  data = NULL,
  x = NULL,
  y,
  tuning = list(),
  args = list(),
  cost = rmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  names = NULL,
  predictArgs = list(),
  costArgs = list(),
  selectBest = c("min", "hastie"),
  seFactor = 1,
  envir = parent.frame(),
  seed = NULL,
  ...
)

## S3 method for class 'call'
cvTuning(
  object,
  data = NULL,
  x = NULL,
  y,
  tuning = list(),
  cost = rmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  names = NULL,
  predictArgs = list(),
  costArgs = list(),
  selectBest = c("min", "hastie"),
  seFactor = 1,
  envir = parent.frame(),
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvTuning_+3A_object">object</code></td>
<td>
<p>a function or an unevaluated function call for fitting
a model (see <code><a href="base.html#topic+call">call</a></code> for the latter).</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed down.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> describing the model.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_data">data</code></td>
<td>
<p>a data frame containing the variables required for fitting the
models.  This is typically used if the model in the function call is
described by a <code><a href="stats.html#topic+formula">formula</a></code>.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_x">x</code></td>
<td>
<p>a numeric matrix containing the predictor variables.  This is
typically used if the function call for fitting the models requires the
predictor matrix and the response to be supplied as separate arguments.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_y">y</code></td>
<td>
<p>a numeric vector or matrix containing the response.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_tuning">tuning</code></td>
<td>
<p>a list of arguments giving the tuning parameter values to be
evaluated.  The names of the list components should thereby correspond to
the argument names of the tuning parameters.  For each tuning parameter, a
vector of values can be supplied.  Cross-validation is then applied over the
grid of all possible combinations of tuning parameter values.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_args">args</code></td>
<td>
<p>a list of additional arguments to be passed to the model
fitting function.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_cost">cost</code></td>
<td>
<p>a cost function measuring prediction loss.  It should expect
the observed values of the response to be passed as the first argument and
the predicted values as the second argument, and must return either a
non-negative scalar value, or a list with the first component containing
the prediction error and the second component containing the standard
error.  The default is to use the root mean squared prediction error
(see <code><a href="#topic+cost">cost</a></code>).</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_k">K</code></td>
<td>
<p>an integer giving the number of folds into which the data should
be split (the default is five).  Keep in mind that this should be chosen
such that all folds are of approximately equal size.  Setting <code>K</code>
equal to the number of observations or groups yields leave-one-out
cross-validation.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_r">R</code></td>
<td>
<p>an integer giving the number of replications for repeated
<code class="reqn">K</code>-fold cross-validation.  This is ignored for for leave-one-out
cross-validation and other non-random splits of the data.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_foldtype">foldType</code></td>
<td>
<p>a character string specifying the type of folds to be
generated.  Possible values are <code>"random"</code> (the default),
<code>"consecutive"</code> or <code>"interleaved"</code>.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_grouping">grouping</code></td>
<td>
<p>a factor specifying groups of observations.  If supplied,
the data are split according to the groups rather than individual
observations such that all observations within a group belong to the same
fold.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_folds">folds</code></td>
<td>
<p>an object of class <code>"cvFolds"</code> giving the folds of the
data for cross-validation (as returned by <code><a href="#topic+cvFolds">cvFolds</a></code>).  If
supplied, this is preferred over the arguments for generating
cross-validation folds.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_names">names</code></td>
<td>
<p>an optional character vector giving names for the arguments
containing the data to be used in the function call (see &ldquo;Details&rdquo;).</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_predictargs">predictArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the
<code><a href="stats.html#topic+predict">predict</a></code> method of the fitted models.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_costargs">costArgs</code></td>
<td>
<p>a list of additional arguments to be passed to the
prediction loss function <code>cost</code>.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_selectbest">selectBest</code></td>
<td>
<p>a character string specifying a criterion for selecting
the best model.  Possible values are <code>"min"</code> (the default) or
<code>"hastie"</code>.  The former selects the model with the smallest prediction
error.  The latter is useful for models with a tuning parameter controlling
the complexity of the model (e.g., penalized regression).  It selects the
most parsimonious model whose prediction error is no larger than
<code>seFactor</code> standard errors above the prediction error of the best
overall model.  Note that the models are thereby assumed to be ordered
from the most parsimonious one to the most complex one.  In particular
a one-standard-error rule is frequently applied.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_sefactor">seFactor</code></td>
<td>
<p>a numeric value giving a multiplication factor of the
standard error for the selection of the best model.  This is ignored if
<code>selectBest</code> is <code>"min"</code>.</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_envir">envir</code></td>
<td>
<p>the <code><a href="base.html#topic+environment">environment</a></code> in which to evaluate the
function call for fitting the models (see <code><a href="base.html#topic+eval">eval</a></code>).</p>
</td></tr>
<tr><td><code id="cvTuning_+3A_seed">seed</code></td>
<td>
<p>optional initial seed for the random number generator (see
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(Repeated) <code class="reqn">K</code>-fold cross-validation is performed in the following
way.  The data are first split into <code class="reqn">K</code> previously obtained blocks of
approximately equal size.  Each of the <code class="reqn">K</code> data blocks is left out once
to fit the model, and predictions are computed for the observations in the
left-out block with the <code><a href="stats.html#topic+predict">predict</a></code> method of the fitted
model.  Thus a prediction is obtained for each observation.
</p>
<p>The response variable and the obtained predictions for all observations are
then passed to the prediction loss function <code>cost</code> to estimate the
prediction error.  For repeated cross-validation, this process is replicated
and the estimated prediction errors from all replications as well as their
average are included in the returned object.
</p>
<p>Furthermore, if the response is a vector but the
<code><a href="stats.html#topic+predict">predict</a></code> method of the fitted models returns a matrix,
the prediction error is computed for each column.  A typical use case for
this behavior would be if the <code><a href="stats.html#topic+predict">predict</a></code> method returns
predictions from an initial model fit and stepwise improvements thereof.
</p>
<p>If <code>formula</code> or <code>data</code> are supplied, all variables required for
fitting the models are added as one argument to the function call, which is
the typical behavior of model fitting functions with a
<code><a href="stats.html#topic+formula">formula</a></code> interface.  In this case, the accepted values
for <code>names</code> depend on the method.  For the <code>function</code> method, a
character vector of length two should supplied, with the first element
specifying the argument name for the formula and the second element
specifying the argument name for the data (the default is to use
<code>c("formula", "data")</code>).  Note that names for both arguments should be
supplied even if only one is actually used.  For the <code>call</code> method,
which does not have a <code>formula</code> argument, a character string specifying
the argument name for the data should be supplied (the default is to use
<code>"data"</code>).
</p>
<p>If <code>x</code> is supplied, on the other hand, the predictor matrix and the
response are added as separate arguments to the function call.  In this
case, <code>names</code> should be a character vector of length two, with the
first element specifying the argument name for the predictor matrix and the
second element specifying the argument name for the response (the default is
to use <code>c("x", "y")</code>).  It should be noted that the <code>formula</code> or
<code>data</code> arguments take precedence over <code>x</code>.
</p>


<h3>Value</h3>

<p>If <code>tuning</code> is an empty list, <code><a href="#topic+cvFit">cvFit</a></code> is called to return
an object of class <code>"cv"</code>.
</p>
<p>Otherwise an object of class <code>"cvTuning"</code> (which inherits from class
<code>"cvSelect"</code>) with the following components is returned:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>an integer giving the number of observations or groups.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>an integer giving the number of folds.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>an integer giving the number of replications.</p>
</td></tr>
<tr><td><code>tuning</code></td>
<td>
<p>a data frame containing the grid of tuning parameter
values for which the prediction error was estimated.</p>
</td></tr>
<tr><td><code>best</code></td>
<td>
<p>an integer vector giving the indices of the optimal
combinations of tuning parameters.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>a data frame containing the estimated prediction errors for
all combinations of tuning parameter values.  For repeated cross-validation,
those are average values over all replications.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>a data frame containing the estimated standard errors of the
prediction loss for all combinations of tuning parameter values.</p>
</td></tr>
<tr><td><code>selectBest</code></td>
<td>
<p>a character string specifying the criterion used for
selecting the best model.</p>
</td></tr>
<tr><td><code>seFactor</code></td>
<td>
<p>a numeric value giving the multiplication factor of
the standard error used for the selection of the best model.</p>
</td></tr>
<tr><td><code>reps</code></td>
<td>
<p>a data frame containing the estimated prediction errors
from all replications for all combinations of tuning parameter values.  This
is only returned for repeated cross-validation.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>the seed of the random number generator before
cross-validation was performed.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The same cross-validation folds are used for all combinations of
tuning parameter values for maximum comparability.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R. and Friedman, J. (2009) <em>The Elements of
Statistical Learning: Data Mining, Inference, and Prediction</em>.  Springer,
2nd edition.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvTool">cvTool</a></code>, <code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>,
<code><a href="#topic+cvFolds">cvFolds</a></code>, <code><a href="#topic+cost">cost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")

## evaluate MM regression models tuned for 85% and 95% efficiency
tuning &lt;- list(tuning.psi = c(3.443689, 4.685061))

## via model fitting function
# perform cross-validation
# note that the response is extracted from 'data' in 
# this example and does not have to be supplied
cvTuning(lmrob, formula = Y ~ ., data = coleman, tuning = tuning, 
    cost = rtmspe, K = 5, R = 10, costArgs = list(trim = 0.1), 
    seed = 1234)

## via function call
# set up function call
call &lt;- call("lmrob", formula = Y ~ .)
# perform cross-validation
cvTuning(call, data = coleman, y = coleman$Y, tuning = tuning, 
    cost = rtmspe, K = 5, R = 10, costArgs = list(trim = 0.1), 
    seed = 1234)
</code></pre>

<hr>
<h2 id='densityplot.cv'>Kernel density plots of cross-validation results</h2><span id='topic+densityplot.cv'></span><span id='topic+densityplot.cvSelect'></span>

<h3>Description</h3>

<p>Produce kernel density plots of results from repeated <code class="reqn">K</code>-fold 
cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
densityplot(x, data, select = NULL, ...)

## S3 method for class 'cvSelect'
densityplot(x, data, subset = NULL, select = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="densityplot.cv_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or <code>"cvSelect"</code> 
that contains cross-validation results.</p>
</td></tr>
<tr><td><code id="densityplot.cv_+3A_data">data</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
<tr><td><code id="densityplot.cv_+3A_select">select</code></td>
<td>
<p>a character, integer or logical vector indicating the columns 
of cross-validation results to be plotted.</p>
</td></tr>
<tr><td><code id="densityplot.cv_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code>"formula"</code> 
method of <code><a href="lattice.html#topic+histogram">densityplot</a></code>.</p>
</td></tr>
<tr><td><code id="densityplot.cv_+3A_subset">subset</code></td>
<td>
<p>a character, integer or logical vector indicating the subset 
of models for which to plot the cross-validation results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects with multiple columns of repeated cross-validation results, 
conditional kernel density plots are produced.
</p>


<h3>Value</h3>

<p>An object of class <code>"trellis"</code> is returned invisibly.  The 
<code><a href="lattice.html#topic+update.trellis">update</a></code> method can be used to update 
components of the object and the <code><a href="lattice.html#topic+print.trellis">print</a></code> 
method (usually called by default) will plot it on an appropriate plotting 
device.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="#topic+plot.cv">plot</a></code>, 
<code><a href="#topic+bwplot.cv">bwplot</a></code>, <code><a href="#topic+xyplot.cvSelect">xyplot</a></code>, 
<code><a href="#topic+dotplot.cvSelect">dotplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare LS, MM and LTS regression

# perform cross-validation for an LS regression model
fitLm &lt;- lm(Y ~ ., data = coleman)
cvFitLm &lt;- cvLm(fitLm, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an MM regression model
fitLmrob &lt;- lmrob(Y ~ ., data = coleman, k.max = 500)
cvFitLmrob &lt;- cvLmrob(fitLmrob, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
cvFitLts &lt;- cvLts(fitLts, cost = rtmspe,
    folds = folds, trim = 0.1)

# combine results into one object
cvFits &lt;- cvSelect(LS = cvFitLm, MM = cvFitLmrob, LTS = cvFitLts)
cvFits

# plot results for the MM regression model
densityplot(cvFitLmrob)
# plot combined results
densityplot(cvFits)

</code></pre>

<hr>
<h2 id='dotplot.cv'>Dot plots of cross-validation results</h2><span id='topic+dotplot.cv'></span><span id='topic+dotplot.cvSelect'></span>

<h3>Description</h3>

<p>Produce dot plots of (average) results from (repeated) <code class="reqn">K</code>-fold 
cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
dotplot(x, data, select = NULL, seFactor = NA, ...)

## S3 method for class 'cvSelect'
dotplot(x, data, subset = NULL, select = NULL, seFactor = x$seFactor, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dotplot.cv_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cvSelect"</code> that contains 
cross-validation results.</p>
</td></tr>
<tr><td><code id="dotplot.cv_+3A_data">data</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
<tr><td><code id="dotplot.cv_+3A_select">select</code></td>
<td>
<p>a character, integer or logical vector indicating the columns 
of cross-validation results to be plotted.</p>
</td></tr>
<tr><td><code id="dotplot.cv_+3A_sefactor">seFactor</code></td>
<td>
<p>a numeric value giving the multiplication factor of the 
standard error for displaying error bars.  Error bars can be suppressed by 
setting this to <code>NA</code>.</p>
</td></tr>
<tr><td><code id="dotplot.cv_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code>"formula"</code> 
method of <code><a href="lattice.html#topic+xyplot">dotplot</a></code>.</p>
</td></tr>
<tr><td><code id="dotplot.cv_+3A_subset">subset</code></td>
<td>
<p>a character, integer or logical vector indicating the subset 
of models for which to plot the cross-validation results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects with multiple columns of repeated cross-validation results, 
conditional dot plots are produced.
</p>


<h3>Value</h3>

<p>An object of class <code>"trellis"</code> is returned invisibly.  The 
<code><a href="lattice.html#topic+update.trellis">update</a></code> method can be used to update 
components of the object and the <code><a href="lattice.html#topic+print.trellis">print</a></code> 
method (usually called by default) will plot it on an appropriate plotting 
device.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="#topic+plot.cv">plot</a></code>, 
<code><a href="#topic+xyplot.cvSelect">xyplot</a></code>, <code><a href="#topic+bwplot.cv">bwplot</a></code>, 
<code><a href="#topic+densityplot.cv">densityplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare LS, MM and LTS regression

# perform cross-validation for an LS regression model
fitLm &lt;- lm(Y ~ ., data = coleman)
cvFitLm &lt;- cvLm(fitLm, cost = rtmspe, 
    folds = folds, trim = 0.1)

# perform cross-validation for an MM regression model
fitLmrob &lt;- lmrob(Y ~ ., data = coleman, k.max = 500)
cvFitLmrob &lt;- cvLmrob(fitLmrob, cost = rtmspe, 
    folds = folds, trim = 0.1)

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
cvFitLts &lt;- cvLts(fitLts, cost = rtmspe, 
    folds = folds, trim = 0.1)

# combine and plot results
cvFits &lt;- cvSelect(LS = cvFitLm, MM = cvFitLmrob, LTS = cvFitLts)
cvFits
dotplot(cvFits)
</code></pre>

<hr>
<h2 id='plot.cv'>Plot cross-validation results</h2><span id='topic+plot.cv'></span><span id='topic+plot.cvSelect'></span>

<h3>Description</h3>

<p>Plot results from (repeated) <code class="reqn">K</code>-fold cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
plot(x, method = c("bwplot", "densityplot", "xyplot", "dotplot"), ...)

## S3 method for class 'cvSelect'
plot(x, method = c("bwplot", "densityplot", "xyplot", "dotplot"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or <code>"cvSelect"</code> 
that contains cross-validation results.</p>
</td></tr>
<tr><td><code id="plot.cv_+3A_method">method</code></td>
<td>
<p>a character string specifying the type of plot.  For the 
<code>"cv"</code> method, possible values are <code>"bwplot"</code> to create a 
box-and-whisker plot via <code><a href="#topic+bwplot.cv">bwplot</a></code> (the default), or 
<code>"densityplot"</code> to create a kernel density plot via 
<code><a href="#topic+densityplot.cv">densityplot</a></code>.  Note that those plots are only 
meaningful for results from repeated cross-validation.  For the 
<code>"cvSelect"</code> method, there are two additional possibilities: 
<code>"xyplot"</code> to plot the (average) results for each model via 
<code><a href="#topic+xyplot.cvSelect">xyplot</a></code>, or <code>"dotplot"</code> to create a 
similar dot plot via <code><a href="#topic+dotplot.cvSelect">dotplot</a></code>.  The default 
is to use <code>"bwplot"</code> for results from repeated cross-validation and 
<code>"xyplot"</code> otherwise.  In any case, partial string matching allows 
supply abbreviations of the accepted values.</p>
</td></tr>
<tr><td><code id="plot.cv_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed down.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects with multiple columns of cross-validation results, conditional 
plots are produced.
</p>


<h3>Value</h3>

<p>An object of class <code>"trellis"</code> is returned invisibly.  The 
<code><a href="lattice.html#topic+update.trellis">update</a></code> method can be used to update 
components of the object and the <code><a href="lattice.html#topic+print.trellis">print</a></code> 
method (usually called by default) will plot it on an appropriate plotting 
device.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="#topic+bwplot.cv">bwplot</a></code>, 
<code><a href="#topic+densityplot.cv">densityplot</a></code>, 
<code><a href="#topic+xyplot.cvSelect">xyplot</a></code>, 
<code><a href="#topic+dotplot.cvSelect">dotplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

# set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare LS, MM and LTS regression

# perform cross-validation for an LS regression model
fitLm &lt;- lm(Y ~ ., data = coleman)
cvFitLm &lt;- cvLm(fitLm, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an MM regression model
fitLmrob &lt;- lmrob(Y ~ ., data = coleman, k.max = 500)
cvFitLmrob &lt;- cvLmrob(fitLmrob, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
cvFitLts &lt;- cvLts(fitLts, cost = rtmspe,
    folds = folds,  trim = 0.1)

# combine results into one object
cvFits &lt;- cvSelect(LS = cvFitLm, MM = cvFitLmrob, LTS = cvFitLts)
cvFits

# plot results for the MM regression model
plot(cvFitLmrob, method = "bw")
plot(cvFitLmrob, method = "density")

# plot combined results
plot(cvFits, method = "bw")
plot(cvFits, method = "density")
plot(cvFits, method = "xy")
plot(cvFits, method = "dot")

</code></pre>

<hr>
<h2 id='repCV'>Cross-validation for linear models</h2><span id='topic+repCV'></span><span id='topic+cvExamples'></span><span id='topic+repCV.lm'></span><span id='topic+repCV.lmrob'></span><span id='topic+repCV.lts'></span><span id='topic+cvLm'></span><span id='topic+cvLmrob'></span><span id='topic+cvLts'></span>

<h3>Description</h3>

<p>Estimate the prediction error of a linear model via (repeated) <code class="reqn">K</code>-fold
cross-validation.  Cross-validation functions are available for least
squares fits computed with <code><a href="stats.html#topic+lm">lm</a></code> as well as for the
following robust alternatives: MM-type models computed with
<code><a href="robustbase.html#topic+lmrob">lmrob</a></code> and least trimmed squares fits computed with
<code><a href="robustbase.html#topic+ltsReg">ltsReg</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repCV(object, ...)

## S3 method for class 'lm'
repCV(
  object,
  cost = rmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  seed = NULL,
  ...
)

## S3 method for class 'lmrob'
repCV(
  object,
  cost = rtmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  seed = NULL,
  ...
)

## S3 method for class 'lts'
repCV(
  object,
  cost = rtmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  fit = c("reweighted", "raw", "both"),
  seed = NULL,
  ...
)

cvLm(
  object,
  cost = rmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  seed = NULL,
  ...
)

cvLmrob(
  object,
  cost = rtmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  seed = NULL,
  ...
)

cvLts(
  object,
  cost = rtmspe,
  K = 5,
  R = 1,
  foldType = c("random", "consecutive", "interleaved"),
  grouping = NULL,
  folds = NULL,
  fit = c("reweighted", "raw", "both"),
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repCV_+3A_object">object</code></td>
<td>
<p>an object returned from a model fitting function.  Methods
are implemented for objects of class <code>"lm"</code> computed with
<code><a href="stats.html#topic+lm">lm</a></code>, objects of class <code>"lmrob"</code> computed with
<code><a href="robustbase.html#topic+lmrob">lmrob</a></code>, and object of class <code>"lts"</code> computed
with <code><a href="robustbase.html#topic+ltsReg">ltsReg</a></code>.</p>
</td></tr>
<tr><td><code id="repCV_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the prediction loss
function <code>cost</code>.</p>
</td></tr>
<tr><td><code id="repCV_+3A_cost">cost</code></td>
<td>
<p>a cost function measuring prediction loss.  It should expect
the observed values of the response to be passed as the first argument and
the predicted values as the second argument, and must return either a
non-negative scalar value, or a list with the first component containing
the prediction error and the second component containing the standard
error.  The default is to use the root mean squared prediction error
for the <code>"lm"</code> method and the root trimmed mean squared prediction
error for the <code>"lmrob"</code> and <code>"lts"</code> methods (see
<code><a href="#topic+cost">cost</a></code>).</p>
</td></tr>
<tr><td><code id="repCV_+3A_k">K</code></td>
<td>
<p>an integer giving the number of folds into which the data should
be split (the default is five).  Keep in mind that this should be chosen
such that all folds are of approximately equal size.  Setting <code>K</code>
equal to the number of observations or groups yields leave-one-out
cross-validation.</p>
</td></tr>
<tr><td><code id="repCV_+3A_r">R</code></td>
<td>
<p>an integer giving the number of replications for repeated
<code class="reqn">K</code>-fold cross-validation.  This is ignored for for leave-one-out
cross-validation and other non-random splits of the data.</p>
</td></tr>
<tr><td><code id="repCV_+3A_foldtype">foldType</code></td>
<td>
<p>a character string specifying the type of folds to be
generated.  Possible values are <code>"random"</code> (the default),
<code>"consecutive"</code> or <code>"interleaved"</code>.</p>
</td></tr>
<tr><td><code id="repCV_+3A_grouping">grouping</code></td>
<td>
<p>a factor specifying groups of observations.  If supplied,
the data are split according to the groups rather than individual
observations such that all observations within a group belong to the same
fold.</p>
</td></tr>
<tr><td><code id="repCV_+3A_folds">folds</code></td>
<td>
<p>an object of class <code>"cvFolds"</code> giving the folds of the
data for cross-validation (as returned by <code><a href="#topic+cvFolds">cvFolds</a></code>).  If
supplied, this is preferred over the arguments for generating
cross-validation folds.</p>
</td></tr>
<tr><td><code id="repCV_+3A_seed">seed</code></td>
<td>
<p>optional initial seed for the random number generator (see
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>).</p>
</td></tr>
<tr><td><code id="repCV_+3A_fit">fit</code></td>
<td>
<p>a character string specifying for which fit to estimate the
prediction error.  Possible values are <code>"reweighted"</code> (the default) for
the prediction error of the reweighted fit, <code>"raw"</code> for the prediction
error of the raw fit, or <code>"both"</code> for the prediction error of both
fits.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(Repeated) <code class="reqn">K</code>-fold cross-validation is performed in the following
way.  The data are first split into <code class="reqn">K</code> previously obtained blocks of
approximately equal size.  Each of the <code class="reqn">K</code> data blocks is left out once
to fit the model, and predictions are computed for the observations in the
left-out block with the <code><a href="stats.html#topic+predict">predict</a></code> method of the fitted
model.  Thus a prediction is obtained for each observation.
</p>
<p>The response variable and the obtained predictions for all observations are
then passed to the prediction loss function <code>cost</code> to estimate the
prediction error.  For repeated cross-validation, this process is replicated
and the estimated prediction errors from all replications as well as their
average are included in the returned object.
</p>


<h3>Value</h3>

<p>An object of class <code>"cv"</code> with the following components:
</p>
<table>
<tr><td><code>n</code></td>
<td>
<p>an integer giving the number of observations or groups.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>an integer giving the number of folds.</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>an integer giving the number of replications.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>a numeric vector containing the estimated prediction
errors.  For the <code>"lm"</code> and <code>"lmrob"</code> methods, this is a single
numeric value.  For the <code>"lts"</code> method, this contains one value for
each of the requested fits.  In the case of repeated cross-validation, those
are average values over all replications.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>a numeric vector containing the estimated standard
errors of the prediction loss.  For the <code>"lm"</code> and <code>"lmrob"</code>
methods, this is a single numeric value.  For the <code>"lts"</code> method, this
contains one value for each of the requested fits.</p>
</td></tr>
<tr><td><code>reps</code></td>
<td>
<p>a numeric matrix containing the estimated prediction
errors from all replications.  For the <code>"lm"</code> and <code>"lmrob"</code>
methods, this is a matrix with one column.  For the <code>"lts"</code> method,
this contains one column for each of the requested fits.  However, this is
only returned for repeated cross-validation.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>the seed of the random number generator before
cross-validation was performed.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>repCV</code> methods are simple wrapper functions that extract the
data from the fitted model and call <code><a href="#topic+cvFit">cvFit</a></code> to perform
cross-validation.  In addition, <code>cvLm</code>, <code>cvLmrob</code> and <code>cvLts</code>
are aliases for the respective methods.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvFolds">cvFolds</a></code>, <code><a href="#topic+cost">cost</a></code>,
<code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="robustbase.html#topic+lmrob">lmrob</a></code>,
<code><a href="robustbase.html#topic+ltsReg">ltsReg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

# set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)

# perform cross-validation for an LS regression model
fitLm &lt;- lm(Y ~ ., data = coleman)
repCV(fitLm, cost = rtmspe, folds = folds, trim = 0.1)

# perform cross-validation for an MM regression model
fitLmrob &lt;- lmrob(Y ~ ., data = coleman)
repCV(fitLmrob, cost = rtmspe, folds = folds, trim = 0.1)

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
repCV(fitLts, cost = rtmspe, folds = folds, trim = 0.1)
repCV(fitLts, cost = rtmspe, folds = folds, 
    fit = "both", trim = 0.1)
</code></pre>

<hr>
<h2 id='subset.cv'>Subsetting cross-validation results</h2><span id='topic+subset.cv'></span><span id='topic+subset.cvSelect'></span>

<h3>Description</h3>

<p>Extract subsets of results from (repeated) <code class="reqn">K</code>-fold cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
subset(x, select = NULL, ...)

## S3 method for class 'cvSelect'
subset(x, subset = NULL, select = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset.cv_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or <code>"cvSelect"</code> 
that contains cross-validation results.</p>
</td></tr>
<tr><td><code id="subset.cv_+3A_select">select</code></td>
<td>
<p>a character, integer or logical vector indicating the columns 
of cross-validation results to be extracted.</p>
</td></tr>
<tr><td><code id="subset.cv_+3A_...">...</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
<tr><td><code id="subset.cv_+3A_subset">subset</code></td>
<td>
<p>a character, integer or logical vector indicating the subset 
of models for which to keep the cross-validation results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object similar to <code>x</code> containing just the selected results.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="base.html#topic+subset">subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare raw and reweighted LTS estimators for 
## 50% and 75% subsets

# 50% subsets
fitLts50 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.5)
cvFitLts50 &lt;- cvLts(fitLts50, cost = rtmspe, folds = folds, 
    fit = "both", trim = 0.1)

# 75% subsets
fitLts75 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.75)
cvFitLts75 &lt;- cvLts(fitLts75, cost = rtmspe, folds = folds, 
    fit = "both", trim = 0.1)

# combine results into one object
cvFitsLts &lt;- cvSelect("0.5" = cvFitLts50, "0.75" = cvFitLts75)
cvFitsLts

# extract reweighted LTS results with 50% subsets
subset(cvFitLts50, select = "reweighted")
subset(cvFitsLts, subset = c(TRUE, FALSE), select = "reweighted")
</code></pre>

<hr>
<h2 id='summary.cv'>Summarize cross-validation results</h2><span id='topic+summary.cv'></span><span id='topic+summary.cvSelect'></span><span id='topic+summary.cvTuning'></span>

<h3>Description</h3>

<p>Produce a summary of results from (repeated) <code class="reqn">K</code>-fold cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
summary(object, ...)

## S3 method for class 'cvSelect'
summary(object, ...)

## S3 method for class 'cvTuning'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.cv_+3A_object">object</code></td>
<td>
<p>an object inheriting from class <code>"cv"</code> or 
<code>"cvSelect"</code> that contains cross-validation results (note that the 
latter includes objects of class <code>"cvTuning"</code>).</p>
</td></tr>
<tr><td><code id="summary.cv_+3A_...">...</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"summary.cv"</code>, <code>"summary.cvSelect"</code> or 
<code>"summary.cvTuning"</code>, depending on the class of <code>object</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="base.html#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare raw and reweighted LTS estimators for
## 50% and 75% subsets

# 50% subsets
fitLts50 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.5)
cvFitLts50 &lt;- cvLts(fitLts50, cost = rtmspe, folds = folds,
    fit = "both", trim = 0.1)

# 75% subsets
fitLts75 &lt;- ltsReg(Y ~ ., data = coleman, alpha = 0.75)
cvFitLts75 &lt;- cvLts(fitLts75, cost = rtmspe, folds = folds,
    fit = "both", trim = 0.1)

# combine results into one object
cvFitsLts &lt;- cvSelect("0.5" = cvFitLts50, "0.75" = cvFitLts75)
cvFitsLts

# summary of the results with the 50% subsets
summary(cvFitLts50)
# summary of the combined results
summary(cvFitsLts)

</code></pre>

<hr>
<h2 id='xyplot.cv'>X-Y plots of cross-validation results</h2><span id='topic+xyplot.cv'></span><span id='topic+xyplot.cvSelect'></span><span id='topic+xyplot.cvTuning'></span>

<h3>Description</h3>

<p>Plot the (average) results from (repeated) <code class="reqn">K</code>-fold 
cross-validation on the <code class="reqn">y</code>-axis against the respective models on the 
<code class="reqn">x</code>-axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv'
xyplot(x, data, select = NULL, seFactor = NA, ...)

## S3 method for class 'cvSelect'
xyplot(x, data, subset = NULL, select = NULL, seFactor = x$seFactor, ...)

## S3 method for class 'cvTuning'
xyplot(x, data, subset = NULL, select = NULL, seFactor = x$seFactor, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xyplot.cv_+3A_x">x</code></td>
<td>
<p>an object inheriting from class <code>"cvSelect"</code> that contains 
cross-validation results (note that this includes objects of class 
<code>"cvTuning"</code>).</p>
</td></tr>
<tr><td><code id="xyplot.cv_+3A_data">data</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
<tr><td><code id="xyplot.cv_+3A_select">select</code></td>
<td>
<p>a character, integer or logical vector indicating the columns 
of cross-validation results to be plotted.</p>
</td></tr>
<tr><td><code id="xyplot.cv_+3A_sefactor">seFactor</code></td>
<td>
<p>a numeric value giving the multiplication factor of the 
standard error for displaying error bars.  Error bars can be suppressed by 
setting this to <code>NA</code>.</p>
</td></tr>
<tr><td><code id="xyplot.cv_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the <code>"formula"</code> 
method of <code><a href="lattice.html#topic+xyplot">xyplot</a></code>.</p>
</td></tr>
<tr><td><code id="xyplot.cv_+3A_subset">subset</code></td>
<td>
<p>a character, integer or logical vector indicating the subset 
of models for which to plot the cross-validation results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects with multiple columns of repeated cross-validation results, 
conditional plots are produced.
</p>
<p>In most situations, the default behavior is to represent the 
cross-validation results for each model by a vertical line segment (i.e., to 
call the default method of <code><a href="lattice.html#topic+xyplot">xyplot</a></code> with 
<code>type = "h"</code>).  However, the behavior is different for objects of class 
<code>"cvTuning"</code> with only one numeric tuning parameter.  In that 
situation, the cross-validation results are plotted against the values of 
the tuning parameter as a connected line (i.e., by using <code>type = "b"</code>).
</p>
<p>The default behavior can of course be overridden by supplying the 
<code>type</code> argument (a full list of accepted values can be found in the 
help file of <code><a href="lattice.html#topic+panel.xyplot">panel.xyplot</a></code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"trellis"</code> is returned invisibly.  The 
<code><a href="lattice.html#topic+update.trellis">update</a></code> method can be used to update 
components of the object and the <code><a href="lattice.html#topic+print.trellis">print</a></code> 
method (usually called by default) will plot it on an appropriate plotting 
device.
</p>


<h3>Author(s)</h3>

<p>Andreas Alfons
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cvFit">cvFit</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>, 
<code><a href="#topic+cvTuning">cvTuning</a></code>, <code><a href="#topic+plot.cv">plot</a></code>, 
<code><a href="#topic+dotplot.cvSelect">dotplot</a></code>, <code><a href="#topic+bwplot.cv">bwplot</a></code>, 
<code><a href="#topic+densityplot.cv">densityplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library("robustbase")
data("coleman")
set.seed(1234)  # set seed for reproducibility

## set up folds for cross-validation
folds &lt;- cvFolds(nrow(coleman), K = 5, R = 10)


## compare LS, MM and LTS regression

# perform cross-validation for an LS regression model
fitLm &lt;- lm(Y ~ ., data = coleman)
cvFitLm &lt;- cvLm(fitLm, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an MM regression model
fitLmrob &lt;- lmrob(Y ~ ., data = coleman, k.max = 500)
cvFitLmrob &lt;- cvLmrob(fitLmrob, cost = rtmspe,
    folds = folds, trim = 0.1)

# perform cross-validation for an LTS regression model
fitLts &lt;- ltsReg(Y ~ ., data = coleman)
cvFitLts &lt;- cvLts(fitLts, cost = rtmspe,
    folds = folds, trim = 0.1)

# combine and plot results
cvFits &lt;- cvSelect(LS = cvFitLm, MM = cvFitLmrob, LTS = cvFitLts)
cvFits
xyplot(cvFits)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
