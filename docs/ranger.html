<!DOCTYPE html><html lang="en"><head><title>Help for package ranger</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ranger}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#csrf'><p>Case-specific random forests.</p></a></li>
<li><a href='#deforest'><p>Deforesting a random forest</p></a></li>
<li><a href='#getTerminalNodeIDs'><p>Get terminal node IDs (deprecated)</p></a></li>
<li><a href='#holdoutRF'><p>Hold-out random forests</p></a></li>
<li><a href='#hshrink'><p>Hierarchical shrinkage</p></a></li>
<li><a href='#importance_pvalues'><p>ranger variable importance p-values</p></a></li>
<li><a href='#importance.ranger'><p>ranger variable importance</p></a></li>
<li><a href='#parse.formula'><p>Parse formula</p></a></li>
<li><a href='#predict.ranger'><p>Ranger prediction</p></a></li>
<li><a href='#predict.ranger.forest'><p>Ranger prediction</p></a></li>
<li><a href='#predictions.ranger'><p>Ranger predictions</p></a></li>
<li><a href='#predictions.ranger.prediction'><p>Ranger predictions</p></a></li>
<li><a href='#print.deforest.ranger'><p>Print deforested ranger summary</p></a></li>
<li><a href='#print.ranger'><p>Print Ranger</p></a></li>
<li><a href='#print.ranger.forest'><p>Print Ranger forest</p></a></li>
<li><a href='#print.ranger.prediction'><p>Print Ranger prediction</p></a></li>
<li><a href='#ranger'><p>Ranger</p></a></li>
<li><a href='#timepoints.ranger'><p>Ranger timepoints</p></a></li>
<li><a href='#timepoints.ranger.prediction'><p>Ranger timepoints</p></a></li>
<li><a href='#treeInfo'><p>Tree information in human readable format</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Fast Implementation of Random Forests</td>
</tr>
<tr>
<td>Version:</td>
<td>0.17.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-11-08</td>
</tr>
<tr>
<td>Description:</td>
<td>A fast implementation of Random Forests, particularly suited for high
          dimensional data. Ensembles of classification, regression, survival and
          probability prediction trees are supported. Data from genome-wide association
          studies can be analyzed efficiently. In addition to data frames, datasets of
          class 'gwaa.data' (R package 'GenABEL') and 'dgCMatrix' (R package 'Matrix') 
          can be directly analyzed.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.2), Matrix</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>survival, testthat</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://imbs-hl.github.io/ranger/">https://imbs-hl.github.io/ranger/</a>,
<a href="https://github.com/imbs-hl/ranger">https://github.com/imbs-hl/ranger</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/imbs-hl/ranger/issues">https://github.com/imbs-hl/ranger/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-08 05:11:24 UTC; wright</td>
</tr>
<tr>
<td>Author:</td>
<td>Marvin N. Wright [aut, cre],
  Stefan Wager [ctb],
  Philipp Probst [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marvin N. Wright &lt;cran@wrig.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-08 07:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='csrf'>Case-specific random forests.</h2><span id='topic+csrf'></span>

<h3>Description</h3>

<p>In case-specific random forests (CSRF), random forests are built specific to the cases of interest. 
Instead of using equal probabilities, the cases are weighted according to their difference to the case of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>csrf(
  formula,
  training_data,
  test_data,
  params1 = list(),
  params2 = list(),
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="csrf_+3A_formula">formula</code></td>
<td>
<p>Object of class <code>formula</code> or <code>character</code> describing the model to fit.</p>
</td></tr>
<tr><td><code id="csrf_+3A_training_data">training_data</code></td>
<td>
<p>Training data of class <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="csrf_+3A_test_data">test_data</code></td>
<td>
<p>Test data of class <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="csrf_+3A_params1">params1</code></td>
<td>
<p>Parameters for the proximity random forest grown in the first step.</p>
</td></tr>
<tr><td><code id="csrf_+3A_params2">params2</code></td>
<td>
<p>Parameters for the prediction random forests grown in the second step.</p>
</td></tr>
<tr><td><code id="csrf_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether or not to print computation progress.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm consists of 3 steps: 
</p>

<ol>
<li><p> Grow a random forest on the training data
</p>
</li>
<li><p> For each observation of interest (test data), the weights of all training observations are computed by counting the number of trees in which both observations are in the same terminal node.
</p>
</li>
<li><p> For each test observation, grow a weighted random forest on the training data, using the weights obtained in step 2. Predict the outcome of the test observation as usual.
</p>
</li></ol>

<p>In total, n+1 random forests are grown, where n is the number observations in the test dataset.
For details, see Xu et al. (2014).
</p>


<h3>Value</h3>

<p>Predictions for the test dataset.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>

<p>Xu, R., Nettleton, D. &amp; Nordman, D.J. (2014). Case-specific random forests. J Comp Graph Stat 25:49-65. <a href="https://doi.org/10.1080/10618600.2014.983641">doi:10.1080/10618600.2014.983641</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Split in training and test data
train.idx &lt;- sample(nrow(iris), 2/3 * nrow(iris))
iris.train &lt;- iris[train.idx, ]
iris.test &lt;- iris[-train.idx, ]

## Run case-specific RF
csrf(Species ~ ., training_data = iris.train, test_data = iris.test, 
     params1 = list(num.trees = 50, mtry = 4), 
     params2 = list(num.trees = 5))

</code></pre>

<hr>
<h2 id='deforest'>Deforesting a random forest</h2><span id='topic+deforest'></span><span id='topic+deforest.ranger'></span>

<h3>Description</h3>

<p>The main purpose of this function is to allow for post-processing of 
ensembles via L2 regularized regression (i.e., the LASSO), as described in 
Friedman and Popescu (2003). The basic idea is to use the LASSO to 
post-process the predictions from the individual base learners in an ensemble 
(i.e., decision trees) in the hopes of producing a much smaller model without 
sacrificing much in the way of accuracy, and in some cases, improving it. 
Friedman and Popescu (2003) describe conditions under which tree-based 
ensembles, like random forest, can potentially benefit from such 
post-processing (e.g., using shallower trees trained on much smaller samples 
of the training data without replacement). However, the computational 
benefits of such post-processing can only be realized if the base learners 
&quot;zeroed out&quot; by the LASSO can actually be removed from the original ensemble, 
hence the purpose of this function. A complete example using 
<code><a href="#topic+ranger">ranger</a></code> can be found at 
<a href="https://github.com/imbs-hl/ranger/issues/568">https://github.com/imbs-hl/ranger/issues/568</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deforest(object, which.trees = NULL, ...)

## S3 method for class 'ranger'
deforest(object, which.trees = NULL, warn = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deforest_+3A_object">object</code></td>
<td>
<p>A fitted random forest (e.g., a <code><a href="#topic+ranger">ranger</a></code>
object).</p>
</td></tr>
<tr><td><code id="deforest_+3A_which.trees">which.trees</code></td>
<td>
<p>Vector giving the indices of the trees to remove.</p>
</td></tr>
<tr><td><code id="deforest_+3A_...">...</code></td>
<td>
<p>Additional (optional) arguments. (Currently ignored.)</p>
</td></tr>
<tr><td><code id="deforest_+3A_warn">warn</code></td>
<td>
<p>Logical indicating whether or not to warn users that some of the 
standard output of a typical <code><a href="#topic+ranger">ranger</a></code> object or no longer 
available after deforestation. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"deforest.ranger"</code>; essentially, a 
<code><a href="#topic+ranger">ranger</a></code> object with certain components replaced with 
<code>NA</code>s (e.g., out-of-bag (OOB) predictions, variable importance scores 
(if requested), and OOB-based error metrics).
</p>


<h3>Note</h3>

<p>This function is a generic and can be extended by other packages.
</p>


<h3>Author(s)</h3>

<p>Brandon M. Greenwell
</p>


<h3>References</h3>

<p>Friedman, J. and Popescu, B. (2003). Importance sampled learning ensembles, 
Technical report, Stanford University, Department of Statistics.
<a href="https://jerryfriedman.su.domains/ftp/isle.pdf">https://jerryfriedman.su.domains/ftp/isle.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example of deforesting a random forest
rfo &lt;- ranger(Species ~ ., data = iris, probability = TRUE, num.trees = 100)
dfo &lt;- deforest(rfo, which.trees = c(1, 3, 5))
dfo  # same as `rfo` but with trees 1, 3, and 5 removed

## Sanity check
preds.rfo &lt;- predict(rfo, data = iris, predict.all = TRUE)$predictions
preds.dfo &lt;- predict(dfo, data = iris, predict.all = TRUE)$predictions
identical(preds.rfo[, , -c(1, 3, 5)], y = preds.dfo)
</code></pre>

<hr>
<h2 id='getTerminalNodeIDs'>Get terminal node IDs (deprecated)</h2><span id='topic+getTerminalNodeIDs'></span>

<h3>Description</h3>

<p>This function is deprecated. 
Please use predict() with <code>type = "terminalNodes"</code> instead.
This function calls predict() now.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTerminalNodeIDs(rf, dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTerminalNodeIDs_+3A_rf">rf</code></td>
<td>
<p><code>ranger</code> object.</p>
</td></tr>
<tr><td><code id="getTerminalNodeIDs_+3A_dat">dat</code></td>
<td>
<p>New dataset. Terminal node IDs for this dataset are obtained.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix with terminal nodeIDs for all observations in dataset and trees.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rf &lt;- ranger(Species ~ ., data = iris, num.trees = 5, write.forest = TRUE)
getTerminalNodeIDs(rf, iris)
</code></pre>

<hr>
<h2 id='holdoutRF'>Hold-out random forests</h2><span id='topic+holdoutRF'></span>

<h3>Description</h3>

<p>Grow two random forests on two cross-validation folds. 
Instead of out-of-bag data, the other fold is used to compute permutation importance.
Related to the novel permutation variable importance by Janitza et al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>holdoutRF(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="holdoutRF_+3A_...">...</code></td>
<td>
<p>All arguments are passed to <code><a href="#topic+ranger">ranger</a>()</code> (except <code>importance</code>, <code>case.weights</code>, <code>replace</code> and <code>holdout</code>.).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Hold-out random forests with variable importance.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>

<p>Janitza, S., Celik, E. &amp; Boulesteix, A.-L., (2015). A computationally fast variable importance test for random forests for high-dimensional data. Adv Data Anal Classif <a href="https://doi.org/10.1007/s11634-016-0276-4">doi:10.1007/s11634-016-0276-4</a>. <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='hshrink'>Hierarchical shrinkage</h2><span id='topic+hshrink'></span>

<h3>Description</h3>

<p>Apply hierarchical shrinkage to a ranger object. 
Hierarchical shrinkage is a regularization technique that recursively shrinks node predictions towards parent node predictions. 
For details see Agarwal et al. (2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hshrink(rf, lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hshrink_+3A_rf">rf</code></td>
<td>
<p>ranger object, created with <code>node.stats = TRUE</code>.</p>
</td></tr>
<tr><td><code id="hshrink_+3A_lambda">lambda</code></td>
<td>
<p>Non-negative shrinkage parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ranger object is modified in-place.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li><p> Agarwal, A., Tan, Y.S., Ronen, O., Singh, C. &amp; Yu, B. (2022). Hierarchical Shrinkage: Improving the accuracy and interpretability of tree-based models. Proceedings of the 39th International Conference on Machine Learning, PMLR 162:111-135.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Hierarchical shrinkage for a probablity forest
rf &lt;- ranger(Species ~ ., iris, node.stats = TRUE, probability = TRUE)
hshrink(rf, lambda = 5)
</code></pre>

<hr>
<h2 id='importance_pvalues'>ranger variable importance p-values</h2><span id='topic+importance_pvalues'></span>

<h3>Description</h3>

<p>Compute variable importance with p-values. 
For high dimensional data, the fast method of Janitza et al. (2016) can be used. 
The permutation approach of Altmann et al. (2010) is computationally intensive but can be used with all kinds of data. 
See below for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importance_pvalues(
  x,
  method = c("janitza", "altmann"),
  num.permutations = 100,
  formula = NULL,
  data = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="importance_pvalues_+3A_x">x</code></td>
<td>
<p><code>ranger</code> or <code>holdoutRF</code> object.</p>
</td></tr>
<tr><td><code id="importance_pvalues_+3A_method">method</code></td>
<td>
<p>Method to compute p-values. Use &quot;janitza&quot; for the method by Janitza et al. (2016) or &quot;altmann&quot; for the non-parametric method by Altmann et al. (2010).</p>
</td></tr>
<tr><td><code id="importance_pvalues_+3A_num.permutations">num.permutations</code></td>
<td>
<p>Number of permutations. Used in the &quot;altmann&quot; method only.</p>
</td></tr>
<tr><td><code id="importance_pvalues_+3A_formula">formula</code></td>
<td>
<p>Object of class formula or character describing the model to fit. Used in the &quot;altmann&quot; method only.</p>
</td></tr>
<tr><td><code id="importance_pvalues_+3A_data">data</code></td>
<td>
<p>Training data of class data.frame or matrix. Used in the &quot;altmann&quot; method only.</p>
</td></tr>
<tr><td><code id="importance_pvalues_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>ranger()</code>. Used in the &quot;altmann&quot; method only.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method of Janitza et al. (2016) uses a clever trick:
With an unbiased variable importance measure, the importance values of non-associated variables vary randomly around zero. 
Thus, all non-positive importance values are assumed to correspond to these non-associated variables and they are used to construct a distribution of the importance under the null hypothesis of no association to the response.
Since only the non-positive values of this distribution can be observed, the positive values are created by mirroring the negative distribution. 
See Janitza et al. (2016) for details.
</p>
<p>The method of Altmann et al. (2010) uses a simple permutation test: 
The distribution of the importance under the null hypothesis of no association to the response is created by several replications of permuting the response, growing an RF and computing the variable importance.
The authors recommend 50-100 permutations. 
However, much larger numbers have to be used to estimate more precise p-values.
We add 1 to the numerator and denominator to avoid zero p-values.
</p>


<h3>Value</h3>

<p>Variable importance and p-value for each variable.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>

<p>Janitza, S., Celik, E. &amp; Boulesteix, A.-L., (2016). A computationally fast variable importance test for random forests for high-dimensional data. Adv Data Anal Classif <a href="https://doi.org/10.1007/s11634-016-0276-4">doi:10.1007/s11634-016-0276-4</a>. <br />
Altmann, A., Tolosi, L., Sander, O. &amp; Lengauer, T. (2010). Permutation importance: a corrected feature importance measure, Bioinformatics 26:1340-1347.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Janitza's p-values with corrected Gini importance
n &lt;- 50
p &lt;- 400
dat &lt;- data.frame(y = factor(rbinom(n, 1, .5)), replicate(p, runif(n)))
rf.sim &lt;- ranger(y ~ ., dat, importance = "impurity_corrected")
importance_pvalues(rf.sim, method = "janitza")

## Permutation p-values 
## Not run: 
rf.iris &lt;- ranger(Species ~ ., data = iris, importance = 'permutation')
importance_pvalues(rf.iris, method = "altmann", formula = Species ~ ., data = iris)

## End(Not run)
</code></pre>

<hr>
<h2 id='importance.ranger'>ranger variable importance</h2><span id='topic+importance.ranger'></span><span id='topic+importance'></span>

<h3>Description</h3>

<p>Extract variable importance of ranger object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger'
importance(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="importance.ranger_+3A_x">x</code></td>
<td>
<p>ranger object.</p>
</td></tr>
<tr><td><code id="importance.ranger_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Variable importance measures.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='parse.formula'>Parse formula</h2><span id='topic+parse.formula'></span>

<h3>Description</h3>

<p>Parse formula and return dataset containing selected columns. 
Interactions are supported for numerical columns only. 
An interaction column is the product of all interacting columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse.formula(formula, data, env = parent.frame())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parse.formula_+3A_formula">formula</code></td>
<td>
<p>Object of class <code>formula</code> or <code>character</code> describing the model to fit.</p>
</td></tr>
<tr><td><code id="parse.formula_+3A_data">data</code></td>
<td>
<p>Training data of class <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="parse.formula_+3A_env">env</code></td>
<td>
<p>The environment in which the left hand side of <code>formula</code> is evaluated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dataset including selected columns and interactions.
</p>

<hr>
<h2 id='predict.ranger'>Ranger prediction</h2><span id='topic+predict.ranger'></span>

<h3>Description</h3>

<p>Prediction with new data and a saved forest from Ranger.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger'
predict(
  object,
  data = NULL,
  predict.all = FALSE,
  num.trees = object$num.trees,
  type = "response",
  se.method = "infjack",
  quantiles = c(0.1, 0.5, 0.9),
  what = NULL,
  seed = NULL,
  num.threads = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.ranger_+3A_object">object</code></td>
<td>
<p>Ranger <code>ranger</code> object.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_data">data</code></td>
<td>
<p>New test data of class <code>data.frame</code> or <code>gwaa.data</code> (GenABEL).</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_predict.all">predict.all</code></td>
<td>
<p>Return individual predictions for each tree instead of aggregated predictions for all trees. Return a matrix (sample x tree) for classification and regression, a 3d array for probability estimation (sample x class x tree) and survival (sample x time x tree).</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_num.trees">num.trees</code></td>
<td>
<p>Number of trees used for prediction. The first <code>num.trees</code> in the forest are used.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_type">type</code></td>
<td>
<p>Type of prediction. One of 'response', 'se', 'terminalNodes', 'quantiles' with default 'response'. See below for details.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_se.method">se.method</code></td>
<td>
<p>Method to compute standard errors. One of 'jack', 'infjack' with default 'infjack'. Only applicable if type = 'se'. See below for details.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_quantiles">quantiles</code></td>
<td>
<p>Vector of quantiles for quantile prediction. Set <code>type = 'quantiles'</code> to use.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_what">what</code></td>
<td>
<p>User specified function for quantile prediction used instead of <code>quantile</code>. Must return numeric vector, see examples.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_seed">seed</code></td>
<td>
<p>Random seed. Default is <code>NULL</code>, which generates the seed from <code>R</code>. Set to <code>0</code> to ignore the <code>R</code> seed. The seed is used in case of ties in classification mode.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_num.threads">num.threads</code></td>
<td>
<p>Number of threads. Use 0 for all available cores. Default is 2 if not set by options/environment variables (see below).</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_verbose">verbose</code></td>
<td>
<p>Verbose output on or off.</p>
</td></tr>
<tr><td><code id="predict.ranger_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>type = 'response'</code> (the default), the predicted classes (classification), predicted numeric values (regression), predicted probabilities (probability estimation) or survival probabilities (survival) are returned. 
For <code>type = 'se'</code>, the standard error of the predictions are returned (regression only). The jackknife-after-bootstrap or infinitesimal jackknife for bagging is used to estimate the standard errors based on out-of-bag predictions. See Wager et al. (2014) for details.
For <code>type = 'terminalNodes'</code>, the IDs of the terminal node in each tree for each observation in the given dataset are returned.
For <code>type = 'quantiles'</code>, the selected quantiles for each observation are estimated. See Meinshausen (2006) for details.
</p>
<p>If <code>type = 'se'</code> is selected, the method to estimate the variances can be chosen with <code>se.method</code>. Set <code>se.method = 'jack'</code> for jackknife-after-bootstrap and <code>se.method = 'infjack'</code> for the infinitesimal jackknife for bagging.
</p>
<p>For classification and <code>predict.all = TRUE</code>, a factor levels are returned as numerics.
To retrieve the corresponding factor levels, use <code>rf$forest$levels</code>, if <code>rf</code> is the ranger object.
</p>
<p>By default, ranger uses 2 threads. The default can be changed with: (1) <code>num.threads</code> in ranger/predict call, (2) environment variable
R_RANGER_NUM_THREADS, (3) <code>options(ranger.num.threads = N)</code>, (4) <code>options(Ncpus = N)</code>, with precedence in that order.
</p>


<h3>Value</h3>

<p>Object of class <code>ranger.prediction</code> with elements
</p>

<table>
<tr>
 <td style="text-align: left;">
      <code>predictions</code>    </td><td style="text-align: left;"> Predicted classes/values (only for classification and regression)  </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>unique.death.times</code> </td><td style="text-align: left;"> Unique death times (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>chf</code> </td><td style="text-align: left;"> Estimated cumulative hazard function for each sample (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>survival</code> </td><td style="text-align: left;"> Estimated survival function for each sample (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.trees</code>   </td><td style="text-align: left;"> Number of trees. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.independent.variables</code> </td><td style="text-align: left;"> Number of independent variables. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>treetype</code>    </td><td style="text-align: left;"> Type of forest/tree. Classification, regression or survival. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.samples</code>     </td><td style="text-align: left;"> Number of samples.
  </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li><p> Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17. <a href="https://doi.org/10.18637/jss.v077.i01">doi:10.18637/jss.v077.i01</a>.
</p>
</li>
<li><p> Wager, S., Hastie T., &amp; Efron, B. (2014). Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife. J Mach Learn Res 15:1625-1651. <a href="https://jmlr.org/papers/v15/wager14a.html">https://jmlr.org/papers/v15/wager14a.html</a>.
</p>
</li>
<li><p> Meinshausen (2006). Quantile Regression Forests. J Mach Learn Res 7:983-999. <a href="https://www.jmlr.org/papers/v7/meinshausen06a.html">https://www.jmlr.org/papers/v7/meinshausen06a.html</a>.  
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Classification forest
ranger(Species ~ ., data = iris)
train.idx &lt;- sample(nrow(iris), 2/3 * nrow(iris))
iris.train &lt;- iris[train.idx, ]
iris.test &lt;- iris[-train.idx, ]
rg.iris &lt;- ranger(Species ~ ., data = iris.train)
pred.iris &lt;- predict(rg.iris, data = iris.test)
table(iris.test$Species, pred.iris$predictions)

## Quantile regression forest
rf &lt;- ranger(mpg ~ ., mtcars[1:26, ], quantreg = TRUE)
pred &lt;- predict(rf, mtcars[27:32, ], type = "quantiles", quantiles = c(0.1, 0.5, 0.9))
pred$predictions

## Quantile regression forest with user-specified function
rf &lt;- ranger(mpg ~ ., mtcars[1:26, ], quantreg = TRUE)
pred &lt;- predict(rf, mtcars[27:32, ], type = "quantiles", 
                what = function(x) sample(x, 10, replace = TRUE))
pred$predictions

</code></pre>

<hr>
<h2 id='predict.ranger.forest'>Ranger prediction</h2><span id='topic+predict.ranger.forest'></span>

<h3>Description</h3>

<p>Prediction with new data and a saved forest from Ranger.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger.forest'
predict(
  object,
  data,
  predict.all = FALSE,
  num.trees = object$num.trees,
  type = "response",
  se.method = "infjack",
  seed = NULL,
  num.threads = NULL,
  verbose = TRUE,
  inbag.counts = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.ranger.forest_+3A_object">object</code></td>
<td>
<p>Ranger <code>ranger.forest</code> object.</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_data">data</code></td>
<td>
<p>New test data of class <code>data.frame</code> or <code>gwaa.data</code> (GenABEL).</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_predict.all">predict.all</code></td>
<td>
<p>Return individual predictions for each tree instead of aggregated predictions for all trees. Return a matrix (sample x tree) for classification and regression, a 3d array for probability estimation (sample x class x tree) and survival (sample x time x tree).</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_num.trees">num.trees</code></td>
<td>
<p>Number of trees used for prediction. The first <code>num.trees</code> in the forest are used.</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_type">type</code></td>
<td>
<p>Type of prediction. One of 'response', 'se', 'terminalNodes', 'quantiles' with default 'response'. See below for details.</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_se.method">se.method</code></td>
<td>
<p>Method to compute standard errors. One of 'jack', 'infjack' with default 'infjack'. Only applicable if type = 'se'. See below for details.</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_seed">seed</code></td>
<td>
<p>Random seed. Default is <code>NULL</code>, which generates the seed from <code>R</code>. Set to <code>0</code> to ignore the <code>R</code> seed. The seed is used in case of ties in classification mode.</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_num.threads">num.threads</code></td>
<td>
<p>Number of threads. Use 0 for all available cores. Default is 2 if not set by options/environment variables (see below).</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_verbose">verbose</code></td>
<td>
<p>Verbose output on or off.</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_inbag.counts">inbag.counts</code></td>
<td>
<p>Number of times the observations are in-bag in the trees.</p>
</td></tr>
<tr><td><code id="predict.ranger.forest_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>type = 'response'</code> (the default), the predicted classes (classification), predicted numeric values (regression), predicted probabilities (probability estimation) or survival probabilities (survival) are returned. 
For <code>type = 'se'</code>, the standard error of the predictions are returned (regression only). The jackknife-after-bootstrap or infinitesimal jackknife for bagging is used to estimate the standard errors based on out-of-bag predictions. See Wager et al. (2014) for details.
For <code>type = 'terminalNodes'</code>, the IDs of the terminal node in each tree for each observation in the given dataset are returned.
</p>
<p>If <code>type = 'se'</code> is selected, the method to estimate the variances can be chosen with <code>se.method</code>. Set <code>se.method = 'jack'</code> for jackknife after bootstrap and <code>se.method = 'infjack'</code> for the infinitesimal jackknife for bagging.
</p>
<p>For classification and <code>predict.all = TRUE</code>, a factor levels are returned as numerics.
To retrieve the corresponding factor levels, use <code>rf$forest$levels</code>, if <code>rf</code> is the ranger object.
</p>
<p>By default, ranger uses 2 threads. The default can be changed with: (1) <code>num.threads</code> in ranger/predict call, (2) environment variable
R_RANGER_NUM_THREADS, (3) <code>options(ranger.num.threads = N)</code>, (4) <code>options(Ncpus = N)</code>, with precedence in that order.
</p>


<h3>Value</h3>

<p>Object of class <code>ranger.prediction</code> with elements
</p>

<table>
<tr>
 <td style="text-align: left;">
      <code>predictions</code>    </td><td style="text-align: left;"> Predicted classes/values (only for classification and regression)  </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>unique.death.times</code> </td><td style="text-align: left;"> Unique death times (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>chf</code> </td><td style="text-align: left;"> Estimated cumulative hazard function for each sample (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>survival</code> </td><td style="text-align: left;"> Estimated survival function for each sample (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.trees</code>   </td><td style="text-align: left;"> Number of trees. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.independent.variables</code> </td><td style="text-align: left;"> Number of independent variables. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>treetype</code>    </td><td style="text-align: left;"> Type of forest/tree. Classification, regression or survival. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.samples</code>     </td><td style="text-align: left;"> Number of samples.
  </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li><p> Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17. <a href="https://doi.org/10.18637/jss.v077.i01">doi:10.18637/jss.v077.i01</a>.
</p>
</li>
<li><p> Wager, S., Hastie T., &amp; Efron, B. (2014). Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife. J Mach Learn Res 15:1625-1651. <a href="https://jmlr.org/papers/v15/wager14a.html">https://jmlr.org/papers/v15/wager14a.html</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='predictions.ranger'>Ranger predictions</h2><span id='topic+predictions.ranger'></span>

<h3>Description</h3>

<p>Extract training data predictions of Ranger object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger'
predictions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictions.ranger_+3A_x">x</code></td>
<td>
<p>Ranger object.</p>
</td></tr>
<tr><td><code id="predictions.ranger_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions: Classes for Classification forests, Numerical values for Regressions forests and the estimated survival functions for all individuals for Survival forests.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='predictions.ranger.prediction'>Ranger predictions</h2><span id='topic+predictions.ranger.prediction'></span><span id='topic+predictions'></span>

<h3>Description</h3>

<p>Extract predictions of Ranger prediction object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger.prediction'
predictions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictions.ranger.prediction_+3A_x">x</code></td>
<td>
<p>Ranger prediction object.</p>
</td></tr>
<tr><td><code id="predictions.ranger.prediction_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions: Classes for Classification forests, Numerical values for Regressions forests and the estimated survival functions for all individuals for Survival forests.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='print.deforest.ranger'>Print deforested ranger summary</h2><span id='topic+print.deforest.ranger'></span>

<h3>Description</h3>

<p>Print basic information about a deforested <code><a href="#topic+ranger">ranger</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'deforest.ranger'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.deforest.ranger_+3A_x">x</code></td>
<td>
<p>A <code><a href="#topic+deforest">deforest</a></code> object (i.e., an object that inherits from
class <code>"deforest.ranger"</code>).</p>
</td></tr>
<tr><td><code id="print.deforest.ranger_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Many of the components of a typical <code><a href="#topic+ranger">ranger</a></code> object are not 
available after deforestation and are instead replaced with <code>NA</code> (e.g., 
out-of-bag (OOB) predictions, variable importance scores (if requested), and 
OOB-based error metrics).
</p>


<h3>Author(s)</h3>

<p>Brandon M. Greenwell
</p>


<h3>See Also</h3>

<p><code><a href="#topic+deforest">deforest</a></code>.
</p>

<hr>
<h2 id='print.ranger'>Print Ranger</h2><span id='topic+print.ranger'></span>

<h3>Description</h3>

<p>Print contents of Ranger object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.ranger_+3A_x">x</code></td>
<td>
<p>Object of class 'ranger'.</p>
</td></tr>
<tr><td><code id="print.ranger_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='print.ranger.forest'>Print Ranger forest</h2><span id='topic+print.ranger.forest'></span>

<h3>Description</h3>

<p>Print contents of Ranger forest object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger.forest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.ranger.forest_+3A_x">x</code></td>
<td>
<p>Object of class 'ranger.forest'.</p>
</td></tr>
<tr><td><code id="print.ranger.forest_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>

<hr>
<h2 id='print.ranger.prediction'>Print Ranger prediction</h2><span id='topic+print.ranger.prediction'></span>

<h3>Description</h3>

<p>Print contents of Ranger prediction object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger.prediction'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.ranger.prediction_+3A_x">x</code></td>
<td>
<p>Object of class 'ranger.prediction'.</p>
</td></tr>
<tr><td><code id="print.ranger.prediction_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>

<hr>
<h2 id='ranger'>Ranger</h2><span id='topic+ranger'></span>

<h3>Description</h3>

<p>Ranger is a fast implementation of random forests (Breiman 2001) or recursive partitioning, particularly suited for high dimensional data.
Classification, regression, and survival forests are supported.
Classification and regression forests are implemented as in the original Random Forest (Breiman 2001), survival forests as in Random Survival Forests (Ishwaran et al. 2008).
Includes implementations of extremely randomized trees (Geurts et al. 2006) and quantile regression forests (Meinshausen 2006).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ranger(
  formula = NULL,
  data = NULL,
  num.trees = 500,
  mtry = NULL,
  importance = "none",
  write.forest = TRUE,
  probability = FALSE,
  min.node.size = NULL,
  min.bucket = NULL,
  max.depth = NULL,
  replace = TRUE,
  sample.fraction = ifelse(replace, 1, 0.632),
  case.weights = NULL,
  class.weights = NULL,
  splitrule = NULL,
  num.random.splits = 1,
  alpha = 0.5,
  minprop = 0.1,
  poisson.tau = 1,
  split.select.weights = NULL,
  always.split.variables = NULL,
  respect.unordered.factors = NULL,
  scale.permutation.importance = FALSE,
  local.importance = FALSE,
  regularization.factor = 1,
  regularization.usedepth = FALSE,
  keep.inbag = FALSE,
  inbag = NULL,
  holdout = FALSE,
  quantreg = FALSE,
  time.interest = NULL,
  oob.error = TRUE,
  num.threads = NULL,
  save.memory = FALSE,
  verbose = TRUE,
  node.stats = FALSE,
  seed = NULL,
  na.action = "na.learn",
  dependent.variable.name = NULL,
  status.variable.name = NULL,
  classification = NULL,
  x = NULL,
  y = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ranger_+3A_formula">formula</code></td>
<td>
<p>Object of class <code>formula</code> or <code>character</code> describing the model to fit. Interaction terms supported only for numerical variables.</p>
</td></tr>
<tr><td><code id="ranger_+3A_data">data</code></td>
<td>
<p>Training data of class <code>data.frame</code>, <code>matrix</code>, <code>dgCMatrix</code> (Matrix) or <code>gwaa.data</code> (GenABEL).</p>
</td></tr>
<tr><td><code id="ranger_+3A_num.trees">num.trees</code></td>
<td>
<p>Number of trees.</p>
</td></tr>
<tr><td><code id="ranger_+3A_mtry">mtry</code></td>
<td>
<p>Number of variables to possibly split at in each node. Default is the (rounded down) square root of the number variables. Alternatively, a single argument function returning an integer, given the number of independent variables.</p>
</td></tr>
<tr><td><code id="ranger_+3A_importance">importance</code></td>
<td>
<p>Variable importance mode, one of 'none', 'impurity', 'impurity_corrected', 'permutation'. The 'impurity' measure is the Gini index for classification, the variance of the responses for regression and the sum of test statistics (see <code>splitrule</code>) for survival.</p>
</td></tr>
<tr><td><code id="ranger_+3A_write.forest">write.forest</code></td>
<td>
<p>Save <code>ranger.forest</code> object, required for prediction. Set to <code>FALSE</code> to reduce memory usage if no prediction intended.</p>
</td></tr>
<tr><td><code id="ranger_+3A_probability">probability</code></td>
<td>
<p>Grow a probability forest as in Malley et al. (2012).</p>
</td></tr>
<tr><td><code id="ranger_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Minimal node size to split at. Default 1 for classification, 5 for regression, 3 for survival, and 10 for probability. For classification, this can be a vector of class-specific values.</p>
</td></tr>
<tr><td><code id="ranger_+3A_min.bucket">min.bucket</code></td>
<td>
<p>Minimal terminal node size. No nodes smaller than this value can occur. Default 3 for survival and 1 for all other tree types. For classification, this can be a vector of class-specific values.</p>
</td></tr>
<tr><td><code id="ranger_+3A_max.depth">max.depth</code></td>
<td>
<p>Maximal tree depth. A value of NULL or 0 (the default) corresponds to unlimited depth, 1 to tree stumps (1 split per tree).</p>
</td></tr>
<tr><td><code id="ranger_+3A_replace">replace</code></td>
<td>
<p>Sample with replacement.</p>
</td></tr>
<tr><td><code id="ranger_+3A_sample.fraction">sample.fraction</code></td>
<td>
<p>Fraction of observations to sample. Default is 1 for sampling with replacement and 0.632 for sampling without replacement. For classification, this can be a vector of class-specific values.</p>
</td></tr>
<tr><td><code id="ranger_+3A_case.weights">case.weights</code></td>
<td>
<p>Weights for sampling of training observations. Observations with larger weights will be selected with higher probability in the bootstrap (or subsampled) samples for the trees.</p>
</td></tr>
<tr><td><code id="ranger_+3A_class.weights">class.weights</code></td>
<td>
<p>Weights for the outcome classes (in order of the factor levels) in the splitting rule (cost sensitive learning). Classification and probability prediction only. For classification the weights are also applied in the majority vote in terminal nodes.</p>
</td></tr>
<tr><td><code id="ranger_+3A_splitrule">splitrule</code></td>
<td>
<p>Splitting rule. For classification and probability estimation &quot;gini&quot;, &quot;extratrees&quot; or &quot;hellinger&quot; with default &quot;gini&quot;.
For regression &quot;variance&quot;, &quot;extratrees&quot;, &quot;maxstat&quot;, &quot;beta&quot; or &quot;poisson&quot; with default &quot;variance&quot;.
For survival &quot;logrank&quot;, &quot;extratrees&quot;, &quot;C&quot; or &quot;maxstat&quot; with default &quot;logrank&quot;.</p>
</td></tr>
<tr><td><code id="ranger_+3A_num.random.splits">num.random.splits</code></td>
<td>
<p>For &quot;extratrees&quot; splitrule.: Number of random splits to consider for each candidate splitting variable.</p>
</td></tr>
<tr><td><code id="ranger_+3A_alpha">alpha</code></td>
<td>
<p>For &quot;maxstat&quot; splitrule: Significance threshold to allow splitting.</p>
</td></tr>
<tr><td><code id="ranger_+3A_minprop">minprop</code></td>
<td>
<p>For &quot;maxstat&quot; splitrule: Lower quantile of covariate distribution to be considered for splitting.</p>
</td></tr>
<tr><td><code id="ranger_+3A_poisson.tau">poisson.tau</code></td>
<td>
<p>For &quot;poisson&quot; splitrule: The coefficient of variation of the (expected) frequency is <code class="reqn">1/\tau</code>.
If a terminal node has only 0 responses, the estimate is set to <code class="reqn">\alpha 0 + (1-\alpha) mean(parent)</code> with <code class="reqn">\alpha = samples(child) mean(parent) / (\tau + samples(child) mean(parent))</code>.</p>
</td></tr>
<tr><td><code id="ranger_+3A_split.select.weights">split.select.weights</code></td>
<td>
<p>Numeric vector with weights between 0 and 1, used to calculate the probability to select variables for splitting. Alternatively, a list of size num.trees, containing split select weight vectors for each tree can be used.</p>
</td></tr>
<tr><td><code id="ranger_+3A_always.split.variables">always.split.variables</code></td>
<td>
<p>Character vector with variable names to be always selected in addition to the <code>mtry</code> variables tried for splitting.</p>
</td></tr>
<tr><td><code id="ranger_+3A_respect.unordered.factors">respect.unordered.factors</code></td>
<td>
<p>Handling of unordered factor covariates. One of 'ignore', 'order' and 'partition'. For the &quot;extratrees&quot; splitrule the default is &quot;partition&quot; for all other splitrules 'ignore'. Alternatively TRUE (='order') or FALSE (='ignore') can be used. See below for details.</p>
</td></tr>
<tr><td><code id="ranger_+3A_scale.permutation.importance">scale.permutation.importance</code></td>
<td>
<p>Scale permutation importance by standard error as in (Breiman 2001). Only applicable if permutation variable importance mode selected.</p>
</td></tr>
<tr><td><code id="ranger_+3A_local.importance">local.importance</code></td>
<td>
<p>Calculate and return local importance values as in (Breiman 2001). Only applicable if <code>importance</code> is set to 'permutation'.</p>
</td></tr>
<tr><td><code id="ranger_+3A_regularization.factor">regularization.factor</code></td>
<td>
<p>Regularization factor (gain penalization), either a vector of length p or one value for all variables.</p>
</td></tr>
<tr><td><code id="ranger_+3A_regularization.usedepth">regularization.usedepth</code></td>
<td>
<p>Consider the depth in regularization.</p>
</td></tr>
<tr><td><code id="ranger_+3A_keep.inbag">keep.inbag</code></td>
<td>
<p>Save how often observations are in-bag in each tree.</p>
</td></tr>
<tr><td><code id="ranger_+3A_inbag">inbag</code></td>
<td>
<p>Manually set observations per tree. List of size num.trees, containing inbag counts for each observation. Can be used for stratified sampling.</p>
</td></tr>
<tr><td><code id="ranger_+3A_holdout">holdout</code></td>
<td>
<p>Hold-out mode. Hold-out all samples with case weight 0 and use these for variable importance and prediction error.</p>
</td></tr>
<tr><td><code id="ranger_+3A_quantreg">quantreg</code></td>
<td>
<p>Prepare quantile prediction as in quantile regression forests (Meinshausen 2006). Regression only. Set <code>keep.inbag = TRUE</code> to prepare out-of-bag quantile prediction.</p>
</td></tr>
<tr><td><code id="ranger_+3A_time.interest">time.interest</code></td>
<td>
<p>Time points of interest (survival only). Can be <code>NULL</code> (default, use all observed time points), a vector of time points or a single number to use as many time points (grid over observed time points).</p>
</td></tr>
<tr><td><code id="ranger_+3A_oob.error">oob.error</code></td>
<td>
<p>Compute OOB prediction error. Set to <code>FALSE</code> to save computation time, e.g. for large survival forests.</p>
</td></tr>
<tr><td><code id="ranger_+3A_num.threads">num.threads</code></td>
<td>
<p>Number of threads. Use 0 for all available cores. Default is 2 if not set by options/environment variables (see below).</p>
</td></tr>
<tr><td><code id="ranger_+3A_save.memory">save.memory</code></td>
<td>
<p>Use memory saving (but slower) splitting mode. No effect for survival and GWAS data. Warning: This option slows down the tree growing, use only if you encounter memory problems.</p>
</td></tr>
<tr><td><code id="ranger_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.</p>
</td></tr>
<tr><td><code id="ranger_+3A_node.stats">node.stats</code></td>
<td>
<p>Save node statistics. Set to <code>TRUE</code> to save prediction, number of observations and split statistics for each node.</p>
</td></tr>
<tr><td><code id="ranger_+3A_seed">seed</code></td>
<td>
<p>Random seed. Default is <code>NULL</code>, which generates the seed from <code>R</code>. Set to <code>0</code> to ignore the <code>R</code> seed.</p>
</td></tr>
<tr><td><code id="ranger_+3A_na.action">na.action</code></td>
<td>
<p>Handling of missing values. Set to &quot;na.learn&quot; to internally handle missing values (default, see below), to &quot;na.omit&quot; to omit observations with missing values and to &quot;na.fail&quot; to stop if missing values are found.</p>
</td></tr>
<tr><td><code id="ranger_+3A_dependent.variable.name">dependent.variable.name</code></td>
<td>
<p>Name of dependent variable, needed if no formula given. For survival forests this is the time variable.</p>
</td></tr>
<tr><td><code id="ranger_+3A_status.variable.name">status.variable.name</code></td>
<td>
<p>Name of status variable, only applicable to survival data and needed if no formula given. Use 1 for event and 0 for censoring.</p>
</td></tr>
<tr><td><code id="ranger_+3A_classification">classification</code></td>
<td>
<p>Set to <code>TRUE</code> to grow a classification forest. Only needed if the data is a matrix or the response numeric.</p>
</td></tr>
<tr><td><code id="ranger_+3A_x">x</code></td>
<td>
<p>Predictor data (independent variables), alternative interface to data with formula or dependent.variable.name.</p>
</td></tr>
<tr><td><code id="ranger_+3A_y">y</code></td>
<td>
<p>Response vector (dependent variable), alternative interface to data with formula or dependent.variable.name. For survival use a <code>Surv()</code> object or a matrix with time and status.</p>
</td></tr>
<tr><td><code id="ranger_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods (currently ignored).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tree type is determined by the type of the dependent variable.
For factors classification trees are grown, for numeric values regression trees and for survival objects survival trees.
The Gini index is used as default splitting rule for classification.
For regression, the estimated response variances or maximally selected rank statistics (Wright et al. 2016) can be used.
For Survival the log-rank test, a C-index based splitting rule (Schmid et al. 2015) and maximally selected rank statistics (Wright et al. 2016) are available.
For all tree types, forests of extremely randomized trees (Geurts et al. 2006) can be grown.
</p>
<p>With the <code>probability</code> option and factor dependent variable a probability forest is grown.
Here, the node impurity is used for splitting, as in classification forests.
Predictions are class probabilities for each sample.
In contrast to other implementations, each tree returns a probability estimate and these estimates are averaged for the forest probability estimate.
For details see Malley et al. (2012).
</p>
<p>Note that nodes with size smaller than <code>min.node.size</code> can occur because <code>min.node.size</code> is the minimal node size <em>to split at</em>, as in original Random Forests.
To restrict the size of terminal nodes, set <code>min.bucket</code>. 
Variables selected with <code>always.split.variables</code> are tried additionally to the mtry variables randomly selected.
In <code>split.select.weights</code>, weights do not need to sum up to 1, they will be normalized later. 
The weights are assigned to the variables in the order they appear in the formula or in the data if no formula is used.
Names of the <code>split.select.weights</code> vector are ignored.
Weights assigned by <code>split.select.weights</code> to variables in <code>always.split.variables</code> are ignored. 
The usage of <code>split.select.weights</code> can increase the computation times for large forests.
</p>
<p>Unordered factor covariates can be handled in 3 different ways by using <code>respect.unordered.factors</code>: 
For 'ignore' all factors are regarded ordered, for 'partition' all possible 2-partitions are considered for splitting. 
For 'order' and 2-class classification the factor levels are ordered by their proportion falling in the second class, for regression by their mean response, as described in Hastie et al. (2009), chapter 9.2.4.
For multiclass classification the factor levels are ordered by the first principal component of the weighted covariance matrix of the contingency table (Coppersmith et al. 1999), for survival by the median survival (or the largest available quantile if the median is not available).
The use of 'order' is recommended, as it computationally fast and can handle an unlimited number of factor levels. 
Note that the factors are only reordered once and not again in each split. 
</p>
<p>The 'impurity_corrected' importance measure is unbiased in terms of the number of categories and category frequencies and is almost as fast as the standard impurity importance.
It is a modified version of the method by Sandri &amp; Zuccolotto (2008), which is faster and more memory efficient. See Nembrini et al. (2018) for details.
This importance measure can be combined with the methods to estimate p-values in <code><a href="#topic+importance_pvalues">importance_pvalues</a></code>. 
We recommend not to use the 'impurity_corrected' importance when making predictions since the feature permutation step might reduce predictive performance (a warning is raised when predicting on new data). 
</p>
<p>Note that ranger has different default values than other packages.
For example, our default for <code>mtry</code> is the square root of the number of variables for all tree types, whereas other packages use different values for regression.
Also, changing one hyperparameter does not change other hyperparameters (where possible). 
For example, <code>splitrule="extratrees"</code> uses randomized splitting but does not disable bagging as in Geurts et al. (2006).
To disable bagging, use <code>replace = FALSE, sample.fraction = 1</code>. 
This can also be used to grow a single decision tree without bagging and feature subsetting: <code>ranger(..., num.trees = 1, mtry = p, replace = FALSE, sample.fraction = 1)</code>, where p is the number of independent variables.
</p>
<p>While random forests are known for their robustness, default hyperparameters not always work well. 
For example, for high dimensional data, increasing the <code>mtry</code> value and the number of trees <code>num.trees</code> is recommended. 
For more details and recommendations, see Probst et al. (2019). 
To find the best hyperparameters, consider hyperparameter tuning with the <code>tuneRanger</code> or <code>mlr3</code> packages.
</p>
<p>Out-of-bag prediction error is calculated as accuracy (proportion of misclassified observations) for classification, as Brier score for probability estimation, as mean squared error (MSE) for regression and as one minus Harrell's C-index for survival.
Harrell's C-index is calculated based on the sum of the cumulative hazard function (CHF) over all timepoints, i.e., <code>rowSums(chf)</code>, where <code>chf</code> is the the out-of-bag CHF; for details, see Ishwaran et al. (2008).
Calculation of the out-of-bag prediction error can be turned off with <code>oob.error = FALSE</code>.
</p>
<p>Regularization works by penalizing new variables by multiplying the splitting criterion by a factor, see Deng &amp; Runger (2012) for details.  
If <code>regularization.usedepth=TRUE</code>, <code class="reqn">f^d</code> is used, where <em>f</em> is the regularization factor and <em>d</em> the depth of the node.
If regularization is used, multithreading is deactivated because all trees need access to the list of variables that are already included in the model.
</p>
<p>Missing values can be internally handled by setting <code>na.action = "na.learn"</code> (default), by omitting observations with missing values with <code>na.action = "na.omit"</code> or by stopping if missing values are found with <code>na.action = "na.fail"</code>.
With <code>na.action = "na.learn"</code>, missing values are ignored for calculating an initial split criterion value (i.e., decrease of impurity). Then for the best split, all missings are tried in both child nodes and the choice is made based again on the split criterion value. 
For prediction, this direction is saved as the &quot;default&quot; direction. If a missing occurs in prediction at a node where there is no default direction, it goes left.
</p>
<p>For a large number of variables and data frames as input data the formula interface can be slow or impossible to use.
Alternatively <code>dependent.variable.name</code> (and <code>status.variable.name</code> for survival) or <code>x</code> and <code>y</code> can be used.
Use <code>x</code> and <code>y</code> with a matrix for <code>x</code> to avoid conversions and save memory.
Consider setting <code>save.memory = TRUE</code> if you encounter memory problems for very large datasets, but be aware that this option slows down the tree growing. 
</p>
<p>For GWAS data consider combining <code>ranger</code> with the <code>GenABEL</code> package. 
See the Examples section below for a demonstration using <code>Plink</code> data.
All SNPs in the <code>GenABEL</code> object will be used for splitting. 
To use only the SNPs without sex or other covariates from the phenotype file, use <code>0</code> on the right hand side of the formula. 
Note that missing values are treated as an extra category while splitting.
</p>
<p>By default, ranger uses 2 threads. The default can be changed with: (1) <code>num.threads</code> in ranger/predict call, (2) environment variable
R_RANGER_NUM_THREADS, (3) <code>options(ranger.num.threads = N)</code>, (4) <code>options(Ncpus = N)</code>, with precedence in that order.
</p>
<p>See <a href="https://github.com/imbs-hl/ranger">https://github.com/imbs-hl/ranger</a> for the development version.
</p>


<h3>Value</h3>

<p>Object of class <code>ranger</code> with elements
</p>
<table role = "presentation">
<tr><td><code>forest</code></td>
<td>
<p>Saved forest (If write.forest set to TRUE). Note that the variable IDs in the <code>split.varIDs</code> object do not necessarily represent the column number in R.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>Predicted classes/values, based on out-of-bag samples (classification and regression only).</p>
</td></tr>
<tr><td><code>variable.importance</code></td>
<td>
<p>Variable importance for each independent variable.</p>
</td></tr>
<tr><td><code>variable.importance.local</code></td>
<td>
<p>Variable importance for each independent variable and each sample, if <code>local.importance</code> is set to TRUE and <code>importance</code> is set to 'permutation'.</p>
</td></tr>
<tr><td><code>prediction.error</code></td>
<td>
<p>Overall out-of-bag prediction error. For classification this is accuracy (proportion of misclassified observations), for probability estimation the Brier score, for regression the mean squared error and for survival one minus Harrell's C-index.</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>R squared. Also called explained variance or coefficient of determination (regression only). Computed on out-of-bag data.</p>
</td></tr>
<tr><td><code>confusion.matrix</code></td>
<td>
<p>Contingency table for classes and predictions based on out-of-bag samples (classification only).</p>
</td></tr>
<tr><td><code>unique.death.times</code></td>
<td>
<p>Unique death times (survival only).</p>
</td></tr>
<tr><td><code>chf</code></td>
<td>
<p>Estimated cumulative hazard function for each sample (survival only).</p>
</td></tr>
<tr><td><code>survival</code></td>
<td>
<p>Estimated survival function for each sample (survival only).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>Function call.</p>
</td></tr>
<tr><td><code>num.trees</code></td>
<td>
<p>Number of trees.</p>
</td></tr>
<tr><td><code>num.independent.variables</code></td>
<td>
<p>Number of independent variables.</p>
</td></tr>
<tr><td><code>mtry</code></td>
<td>
<p>Value of mtry used.</p>
</td></tr>
<tr><td><code>min.node.size</code></td>
<td>
<p>Value of minimal node size used.</p>
</td></tr>
<tr><td><code>treetype</code></td>
<td>
<p>Type of forest/tree. classification, regression or survival.</p>
</td></tr>
<tr><td><code>importance.mode</code></td>
<td>
<p>Importance mode used.</p>
</td></tr>
<tr><td><code>num.samples</code></td>
<td>
<p>Number of samples.</p>
</td></tr>
<tr><td><code>inbag.counts</code></td>
<td>
<p>Number of times the observations are in-bag in the trees.</p>
</td></tr>
<tr><td><code>dependent.variable.name</code></td>
<td>
<p>Name of the dependent variable. This is NULL when x/y interface is used.</p>
</td></tr>
<tr><td><code>status.variable.name</code></td>
<td>
<p>Name of the status variable (survival only). This is NULL when x/y interface is used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li><p> Wright, M. N. &amp; Ziegler, A. (2017). ranger: A fast implementation of random forests for high dimensional data in C++ and R. J Stat Softw 77:1-17. <a href="https://doi.org/10.18637/jss.v077.i01">doi:10.18637/jss.v077.i01</a>.
</p>
</li>
<li><p> Schmid, M., Wright, M. N. &amp; Ziegler, A. (2016). On the use of Harrell's C for clinical risk prediction via random survival forests. Expert Syst Appl 63:450-459. <a href="https://doi.org/10.1016/j.eswa.2016.07.018">doi:10.1016/j.eswa.2016.07.018</a>. 
</p>
</li>
<li><p> Wright, M. N., Dankowski, T. &amp; Ziegler, A. (2017). Unbiased split variable selection for random survival forests using maximally selected rank statistics. Stat Med 36:1272-1284. <a href="https://doi.org/10.1002/sim.7212">doi:10.1002/sim.7212</a>.
</p>
</li>
<li><p> Nembrini, S., Koenig, I. R. &amp; Wright, M. N. (2018). The revival of the Gini Importance? Bioinformatics. <a href="https://doi.org/10.1093/bioinformatics/bty373">doi:10.1093/bioinformatics/bty373</a>.
</p>
</li>
<li><p> Breiman, L. (2001). Random forests. Mach Learn, 45:5-32. <a href="https://doi.org/10.1023/A%3A1010933404324">doi:10.1023/A:1010933404324</a>. 
</p>
</li>
<li><p> Ishwaran, H., Kogalur, U. B., Blackstone, E. H., &amp; Lauer, M. S. (2008). Random survival forests. Ann Appl Stat 2:841-860. <a href="https://doi.org/10.1097/JTO.0b013e318233d835">doi:10.1097/JTO.0b013e318233d835</a>. 
</p>
</li>
<li><p> Malley, J. D., Kruppa, J., Dasgupta, A., Malley, K. G., &amp; Ziegler, A. (2012). Probability machines: consistent probability estimation using nonparametric learning machines. Methods Inf Med 51:74-81. <a href="https://doi.org/10.3414/ME00-01-0052">doi:10.3414/ME00-01-0052</a>.
</p>
</li>
<li><p> Hastie, T., Tibshirani, R., Friedman, J. (2009). The Elements of Statistical Learning. Springer, New York. 2nd edition.
</p>
</li>
<li><p> Geurts, P., Ernst, D., Wehenkel, L. (2006). Extremely randomized trees. Mach Learn 63:3-42. <a href="https://doi.org/10.1007/s10994-006-6226-1">doi:10.1007/s10994-006-6226-1</a>.
</p>
</li>
<li><p> Meinshausen (2006). Quantile Regression Forests. J Mach Learn Res 7:983-999. <a href="https://www.jmlr.org/papers/v7/meinshausen06a.html">https://www.jmlr.org/papers/v7/meinshausen06a.html</a>.  
</p>
</li>
<li><p> Sandri, M. &amp; Zuccolotto, P. (2008). A bias correction algorithm for the Gini variable importance measure in classification trees. J Comput Graph Stat, 17:611-628. <a href="https://doi.org/10.1198/106186008X344522">doi:10.1198/106186008X344522</a>.
</p>
</li>
<li><p> Coppersmith D., Hong S. J., Hosking J. R. (1999). Partitioning nominal attributes in decision trees. Data Min Knowl Discov 3:197-217. <a href="https://doi.org/10.1023/A%3A1009869804967">doi:10.1023/A:1009869804967</a>.
</p>
</li>
<li><p> Deng &amp; Runger (2012). Feature selection via regularized trees. The 2012 International Joint Conference on Neural Networks (IJCNN), Brisbane, Australia. <a href="https://doi.org/10.1109/IJCNN.2012.6252640">doi:10.1109/IJCNN.2012.6252640</a>.
</p>
</li>
<li><p> Probst, P., Wright, M. N. &amp; Boulesteix, A-L. (2019). Hyperparameters and tuning strategies for random forest. WIREs Data Mining Knowl Discov 9:e1301.<a href="https://doi.org/10.1002/widm.1301">doi:10.1002/widm.1301</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+predict.ranger">predict.ranger</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Classification forest with default settings
ranger(Species ~ ., data = iris)

## Prediction
train.idx &lt;- sample(nrow(iris), 2/3 * nrow(iris))
iris.train &lt;- iris[train.idx, ]
iris.test &lt;- iris[-train.idx, ]
rg.iris &lt;- ranger(Species ~ ., data = iris.train)
pred.iris &lt;- predict(rg.iris, data = iris.test)
table(iris.test$Species, pred.iris$predictions)

## Quantile regression forest
rf &lt;- ranger(mpg ~ ., mtcars[1:26, ], quantreg = TRUE)
pred &lt;- predict(rf, mtcars[27:32, ], type = "quantiles")
pred$predictions

## Variable importance
rg.iris &lt;- ranger(Species ~ ., data = iris, importance = "impurity")
rg.iris$variable.importance

## Survival forest
require(survival)
rg.veteran &lt;- ranger(Surv(time, status) ~ ., data = veteran)
plot(rg.veteran$unique.death.times, rg.veteran$survival[1,])

## Alternative interfaces (same results)
ranger(dependent.variable.name = "Species", data = iris)
ranger(y = iris[, 5], x = iris[, -5])

## Not run: 
## Use GenABEL interface to read Plink data into R and grow a classification forest
## The ped and map files are not included
library(GenABEL)
convert.snp.ped("data.ped", "data.map", "data.raw")
dat.gwaa &lt;- load.gwaa.data("data.pheno", "data.raw")
phdata(dat.gwaa)$trait &lt;- factor(phdata(dat.gwaa)$trait)
ranger(trait ~ ., data = dat.gwaa)

## End(Not run)

</code></pre>

<hr>
<h2 id='timepoints.ranger'>Ranger timepoints</h2><span id='topic+timepoints.ranger'></span><span id='topic+timepoints'></span>

<h3>Description</h3>

<p>Extract unique death times of Ranger Survival forest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger'
timepoints(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timepoints.ranger_+3A_x">x</code></td>
<td>
<p>Ranger Survival forest object.</p>
</td></tr>
<tr><td><code id="timepoints.ranger_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Unique death times
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='timepoints.ranger.prediction'>Ranger timepoints</h2><span id='topic+timepoints.ranger.prediction'></span>

<h3>Description</h3>

<p>Extract unique death times of Ranger Survival prediction object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ranger.prediction'
timepoints(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timepoints.ranger.prediction_+3A_x">x</code></td>
<td>
<p>Ranger Survival prediction object.</p>
</td></tr>
<tr><td><code id="timepoints.ranger.prediction_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Unique death times
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>

<hr>
<h2 id='treeInfo'>Tree information in human readable format</h2><span id='topic+treeInfo'></span>

<h3>Description</h3>

<p>Extract tree information of a <code>ranger</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>treeInfo(object, tree = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="treeInfo_+3A_object">object</code></td>
<td>
<p><code>ranger</code> object.</p>
</td></tr>
<tr><td><code id="treeInfo_+3A_tree">tree</code></td>
<td>
<p>Number of the tree of interest.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Node and variable ID's are 0-indexed, i.e., node 0 is the root node. 
If the formula interface is used in the <code>ranger</code> call, the variable ID's are usually different to the original data used to grow the tree. 
Refer to the variable name instead to be sure.
</p>
<p>Splitting at unordered factors (nominal variables) depends on the option <code>respect.unordered.factors</code> in the <code>ranger</code> call. 
For the &quot;ignore&quot; and &quot;order&quot; approaches, all values smaller or equal the <code>splitval</code> value go to the left and all values larger go to the right, as usual. 
However, with &quot;order&quot; the values correspond to the order in <code>object$forest$covariate.levels</code> instead of the original order (usually alphabetical).
In the &quot;partition&quot; mode, the <code>splitval</code> values for unordered factor are comma separated lists of values, representing the factor levels (in the original order) going to the right.
</p>


<h3>Value</h3>

<p>A data.frame with the columns
</p>

<table>
<tr>
 <td style="text-align: left;">
      <code>nodeID</code> </td><td style="text-align: left;"> The nodeID, 0-indexed. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>leftChild</code> </td><td style="text-align: left;"> ID of the left child node, 0-indexed. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>rightChild</code> </td><td style="text-align: left;"> ID of the right child node, 0-indexed. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>splitvarID</code> </td><td style="text-align: left;"> ID of the splitting variable, 0-indexed. Caution, the variable order changes if the formula interface is used. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>splitvarName</code> </td><td style="text-align: left;"> Name of the splitting variable. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>splitval</code> </td><td style="text-align: left;"> The splitting value. For numeric or ordinal variables, all values smaller or equal go to the left, larger values to the right. For unordered factor variables see above. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>terminal</code> </td><td style="text-align: left;"> Logical, TRUE for terminal nodes. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>prediction</code> </td><td style="text-align: left;"> One column with the predicted class (factor) for classification and the predicted numerical value for regression. One probability per class for probability estimation in several columns. Nothing for survival, refer to <code>object$forest$chf</code> for the CHF node predictions. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>numSamples</code> </td><td style="text-align: left;"> Number of samples in the node (only if ranger called with <code>node.stats = TRUE</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>splitStat</code> </td><td style="text-align: left;"> Split statistics, i.e., value of the splitting criterion (only if ranger called with <code>node.stats = TRUE</code>). </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ranger">ranger</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rf &lt;- ranger(Species ~ ., data = iris)
treeInfo(rf, 1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
