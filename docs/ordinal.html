<!DOCTYPE html><html><head><title>Help for package ordinal</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ordinal}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#addterm.clm2'>
<p>Try all one-term additions to and deletions from a model</p></a></li>
<li><a href='#anova.clm'><p>ANODE Tables and Likelihood ratio test of cumulative link models</p></a></li>
<li><a href='#anova.clm2'><p>Likelihood ratio test of cumulative link models</p></a></li>
<li><a href='#clm'>
<p>Cumulative Link Models</p>
</a></li>
<li><a href='#clm.control'><p>Set control parameters for cumulative link models</p></a></li>
<li><a href='#clm.fit'>
<p>Fit Cumulative Link Models</p>
</a></li>
<li><a href='#clm2'><p>Cumulative link models</p></a></li>
<li><a href='#clm2.control'><p>Set control parameters for cumulative link models</p></a></li>
<li><a href='#clmm'>
<p>Cumulative Link Mixed Models</p></a></li>
<li><a href='#clmm.control'>
<p>Set control parameters for cumulative link mixed models</p></a></li>
<li><a href='#clmm2'><p>Cumulative link mixed models</p></a></li>
<li><a href='#clmm2.control'><p>Set control parameters for cumulative link mixed models</p></a></li>
<li><a href='#condVar'>
<p>Extract conditional modes and conditional variances from clmm objects</p></a></li>
<li><a href='#confint'>
<p>Confidence intervals and profile likelihoods for parameters in</p>
cumulative link models</a></li>
<li><a href='#confint.clm2'>
<p>Confidence intervals and profile likelihoods for parameters in</p>
cumulative link models</a></li>
<li><a href='#convergence'><p>Check convergence of cumulative link models</p></a></li>
<li><a href='#drop.coef'>
<p>Ensure Full Rank Design Matrix</p></a></li>
<li><a href='#gfun'>
<p>Gradients of common densities</p>
</a></li>
<li><a href='#gumbel'>
<p>The Gumbel Distribution</p>
</a></li>
<li><a href='#income'>
<p>Income distribution (percentages) in the Northeast US</p></a></li>
<li><a href='#lgamma'>
<p>The log-gamma distribution</p>
</a></li>
<li><a href='#nominal_test'>
<p>Likelihood ratio tests of model terms in scale and nominal formulae</p></a></li>
<li><a href='#ordinal-package'>
<p>Regression Models for Ordinal Data via Cumulative Link (Mixed) Models</p></a></li>
<li><a href='#predict.clm'><p>Predict Method for CLM fits</p></a></li>
<li><a href='#predict.clm2'><p>Predict Method for CLM fits</p></a></li>
<li><a href='#profile.clmm2'>
<p>Confidence intervals and profile likelihoods for the standard</p>
deviation for the random term in cumulative link mixed models</a></li>
<li><a href='#slice'>
<p>Slice the likelihood of a clm</p></a></li>
<li><a href='#soup'>
<p>Discrimination study of packet soup</p></a></li>
<li><a href='#update.clm2'><p>Update method for cumulative link models</p></a></li>
<li><a href='#VarCorr'>
<p>Extract variance and correlation parameters</p></a></li>
<li><a href='#wine'>
<p>Bitterness of wine</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Regression Models for Ordinal Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2023.12-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-04</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.13.0), stats, methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>ucminf, MASS, Matrix, numDeriv, nlme</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lme4, nnet, xtable, testthat (&ge; 0.8), tools</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of cumulative link (mixed) models also known
    as ordered regression models, proportional odds models, proportional
    hazards models for grouped survival times and ordered logit/probit/...
    models. Estimation is via maximum likelihood and mixed models are fitted
    with the Laplace approximation and adaptive Gauss-Hermite quadrature.
    Multiple random effect terms are allowed and they may be nested, crossed or
    partially nested/crossed. Restrictions of symmetry and equidistance can be
    imposed on the thresholds (cut-points/intercepts). Standard model
    methods are available (summary, anova, drop-methods, step,
    confint, predict etc.) in addition to profile methods and slice
    methods for visualizing the likelihood function and checking
    convergence.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/runehaubo/ordinal">https://github.com/runehaubo/ordinal</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/runehaubo/ordinal/issues">https://github.com/runehaubo/ordinal/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-04 10:10:06 UTC; rhbc</td>
</tr>
<tr>
<td>Author:</td>
<td>Rune Haubo Bojesen Christensen [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Rune Haubo Bojesen Christensen &lt;rune.haubo@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-04 11:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='addterm.clm2'>
Try all one-term additions to and deletions from a model
</h2><span id='topic+addterm.clm2'></span><span id='topic+dropterm.clm2'></span>

<h3>Description</h3>

<p>Try fitting all models that differ from the current model by adding or
deleting a single term from those supplied while maintaining
marginality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clm2'
addterm(object, scope, scale = 0, test = c("none", "Chisq"),
        k = 2, sorted = FALSE, trace = FALSE,
        which = c("location", "scale"), ...)
## S3 method for class 'clm2'
dropterm(object, scope, scale = 0, test = c("none", "Chisq"),
        k = 2, sorted = FALSE, trace = FALSE,
        which = c("location", "scale"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addterm.clm2_+3A_object">object</code></td>
<td>

<p>A <code><a href="#topic+clm2">clm2</a></code> object.
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_scope">scope</code></td>
<td>

<p>for <code>addterm</code>:
a formula specifying a maximal model which should include the current
one. All additional terms in the maximal model with all marginal terms
in the original model are tried.
For <code>dropterm</code>:
a formula giving terms which might be dropped. By default, the model
formula. Only terms that can be dropped and maintain marginality are
actually tried.
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_scale">scale</code></td>
<td>

<p>used in the definition of the AIC statistic for selecting the
models. Specifying <code>scale</code> asserts that the dispersion is known.
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_test">test</code></td>
<td>

<p>should the results include a test statistic relative to the original
model?  The Chisq test is a likelihood-ratio test.
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_k">k</code></td>
<td>

<p>the multiple of the number of degrees of freedom used for the penalty.
Only <code>k=2</code> gives the genuine AIC: <code>k = log(n)</code> is sometimes referred
to as BIC or SBC.
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_sorted">sorted</code></td>
<td>

<p>should the results be sorted on the value of AIC?
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_trace">trace</code></td>
<td>

<p>if <code>TRUE</code> additional information may be given on the fits as they are tried.
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_which">which</code></td>
<td>
<p>should additions or deletions occur in location or scale
models?
</p>
</td></tr>
<tr><td><code id="addterm.clm2_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The definition of AIC is only up to an additive constant because the
likelihood function is only defined up to an additive constant.
</p>


<h3>Value</h3>

<p>A table of class <code>"anova"</code> containing columns for the change
in degrees of freedom, AIC and the likelihood ratio statistic. If
<code>test = "Chisq"</code> a column also contains the
p-value from the Chisq test.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm2">clm2</a></code>, <code><a href="#topic+anova.clm2">anova</a></code>,
<code><a href="MASS.html#topic+addterm.default">addterm.default</a></code> and <code><a href="MASS.html#topic+dropterm.default">dropterm.default</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
options(contrasts = c("contr.treatment", "contr.poly"))

if(require(MASS)) { ## dropterm, addterm, housing
    mB1 &lt;- clm2(SURENESS ~ PROD + GENDER + SOUPTYPE,
                scale = ~ COLD, data = soup, link = "probit",
                Hess = FALSE)
    dropterm(mB1, test = "Chi")       # or
    dropterm(mB1, which = "location", test = "Chi")
    dropterm(mB1, which = "scale", test = "Chi")
    addterm(mB1, scope = ~.^2, test = "Chi", which = "location")
    addterm(mB1, scope = ~ . + GENDER + SOUPTYPE,
            test = "Chi", which = "scale")
    addterm(mB1, scope = ~ . + AGEGROUP + SOUPFREQ,
            test = "Chi", which = "location")

    ## Fit model from polr example:
    fm1 &lt;- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
    addterm(fm1, ~ Infl + Type + Cont, test= "Chisq", which = "scale")
    dropterm(fm1, test = "Chisq")
}

</code></pre>

<hr>
<h2 id='anova.clm'>ANODE Tables and Likelihood ratio test of cumulative link models</h2><span id='topic+anova.clm'></span>

<h3>Description</h3>

<p>Type I, II, and III analysis of deviance (ANODE) tables for 
cumulative link models and
comparison of cumulative link models with likelihood ratio tests.
Models may differ by terms in location, scale and nominal
formulae, in link, threshold function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clm'
anova(object, ..., type = c("I", "II", "III", "1", "2", "3"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.clm_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+clm">clm</a></code> object.
</p>
</td></tr>
<tr><td><code id="anova.clm_+3A_...">...</code></td>
<td>
<p>optionally one or more additional <code><a href="#topic+clm">clm</a></code> objects.
</p>
</td></tr>
<tr><td><code id="anova.clm_+3A_type">type</code></td>
<td>
<p>the type of hypothesis test if <code>anova</code> is called with a 
single model; ignored if more than one model is passed to the method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ANODE table returned when <code>anova</code> is called with a single model apply only to 
terms in <code>formula</code>, that is, terms in <code>nominal</code> and <code>scale</code> are
ignored. 
</p>


<h3>Value</h3>

<p>An analysis of deviance table based on Wald chi-square test if called with a
single model and a comparison of
models with likelihood ratio tests if called with more than one model.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm">clm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Analysis of deviance tables with Wald chi-square tests:
fm &lt;- clm(rating ~ temp * contact, scale=~contact, data=wine)
anova(fm, type="I")
anova(fm, type="II")
anova(fm, type="III")

options(contrasts = c("contr.treatment", "contr.poly"))
m1 &lt;- clm2(SURENESS ~ PROD, scale = ~PROD, data = soup,
          link = "logistic")

## anova
anova(m1, update(m1, scale = ~.-PROD))
mN1 &lt;- clm2(SURENESS ~ 1, nominal = ~PROD, data = soup,
           link = "logistic")
anova(m1, mN1)
anova(m1, update(m1, scale = ~.-PROD), mN1)

## Fit model from polr example:
if(require(MASS)) {
    fm1 &lt;- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
    anova(fm1, update(fm1, scale =~ Cont))
}

</code></pre>

<hr>
<h2 id='anova.clm2'>Likelihood ratio test of cumulative link models</h2><span id='topic+anova.clm2'></span><span id='topic+anova.clmm2'></span>

<h3>Description</h3>

<p>Comparison of cumulative link models in likelihood ratio tests.
The models may differ by terms in location, scale and nominal
formulae, in link, threshold function and random effect structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clm2'
anova(object, ..., test = c("Chisq", "none"))
## S3 method for class 'clmm2'
anova(object, ..., test = c("Chisq", "none"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.clm2_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+clm2">clm2</a></code> object.
</p>
</td></tr>
<tr><td><code id="anova.clm2_+3A_...">...</code></td>
<td>
<p>one or more additional <code><a href="#topic+clm2">clm2</a></code> objects.
</p>
</td></tr>
<tr><td><code id="anova.clm2_+3A_test">test</code></td>
<td>
<p>if <code>test = "none"</code> the p-value for the likelihood
ratio test is suppressed.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The method returns an object of class <code>Anova</code> (for printing) and
<code>data.frame</code> with the following elements
</p>
<table>
<tr><td><code>Model</code></td>
<td>
<p>character description of the cumulative link models being
compared. Location, scale and nominal formulae are separated by
&quot;|&quot;s in this order.
</p>
</td></tr>
<tr><td><code>Resid.df</code></td>
<td>
<p>the residual degrees of freedom
</p>
</td></tr>
<tr><td><code>-2logLik</code></td>
<td>
<p>twice the negative log likelihood (proportional to the
deviance)</p>
</td></tr>
<tr><td><code>Test</code></td>
<td>
<p>indication of which models are being compared.
</p>
</td></tr>
<tr><td><code>DF</code></td>
<td>
<p>the difference in the degrees of freedom in the models being
compared, i.e. the degrees of freedom for the chi-squared test.
</p>
</td></tr>
<tr><td><code>LR stat.</code></td>
<td>
<p>the likelihood ratio statistic.
</p>
</td></tr>
<tr><td><code>Pr(Chi)</code></td>
<td>
<p>the p-value from the likelihood ratio test. Absent if
<code>test = "none"</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm2">clm2</a></code>, <code><a href="#topic+addterm.clm2">addterm</a></code>,
<code><a href="#topic+addtermOld">dropterm</a></code> and
<code><a href="stats.html#topic+anova">anova.default</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))
m1 &lt;- clm2(SURENESS ~ PROD, scale = ~PROD, data = soup,
          link = "logistic")

## anova
anova(m1, update(m1, scale = ~.-PROD))
mN1 &lt;- clm2(SURENESS ~ 1, nominal = ~PROD, data = soup,
           link = "logistic")
anova(m1, mN1)
anova(m1, update(m1, scale = ~.-PROD), mN1)

## Fit model from polr example:
if(require(MASS)) {
    fm1 &lt;- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
    anova(fm1, update(fm1, scale =~ Cont))
}

</code></pre>

<hr>
<h2 id='clm'>
Cumulative Link Models

</h2><span id='topic+clm'></span>

<h3>Description</h3>

<p>Fits cumulative link models (CLMs) such as the propotional odds
model. The model allows for various link functions and structured
thresholds that restricts the thresholds or cut-points to be e.g.,
equidistant or symmetrically arranged around the central
threshold(s). Nominal effects (partial proportional odds with the
logit link) are also allowed.
A modified Newton algorithm is used to optimize the likelihood function.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>clm(formula, scale, nominal, data, weights, start, subset, doFit = TRUE,
  na.action, contrasts, model = TRUE, control=list(),
  link = c("logit", "probit", "cloglog", "loglog", "cauchit", 
           "Aranda-Ordaz", "log-gamma"),
  threshold = c("flexible", "symmetric", "symmetric2", "equidistant"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clm_+3A_formula">formula</code></td>
<td>

<p>a formula expression as for regression models, of the form
<code>response ~ predictors</code>. The response should be a factor
(preferably an ordered factor), which will be interpreted as an
ordinal response with levels ordered as in the factor.
The model must have an intercept: attempts to remove one will
lead to a warning and will be ignored. An offset may be used. See the
documentation of <code><a href="stats.html#topic+formula">formula</a></code> for other details.
</p>
</td></tr>
<tr><td><code id="clm_+3A_scale">scale</code></td>
<td>

<p>an optional formula expression, of the form
<code> ~ predictors</code>, i.e. with an empty left hand side.
An offset may be used. Variables included here will have
multiplicative effects and can be interpreted as effects on the
scale (or dispersion) of a latent distribution.
</p>
</td></tr>
<tr><td><code id="clm_+3A_nominal">nominal</code></td>
<td>

<p>an optional formula of the form <code> ~ predictors</code>, i.e. with an
empty left hand side. The effects of the predictors in this formula
are assumed to be nominal rather than ordinal -
this corresponds to the so-called partial
proportional odds (with the logit link).
</p>
</td></tr>
<tr><td><code id="clm_+3A_data">data</code></td>
<td>

<p>an optional data frame in which to interpret the variables occurring
in the formulas.
</p>
</td></tr>
<tr><td><code id="clm_+3A_weights">weights</code></td>
<td>

<p>optional case weights in fitting. Defaults to 1. Negative weights
are not allowed.
</p>
</td></tr>
<tr><td><code id="clm_+3A_start">start</code></td>
<td>

<p>initial values for the parameters in the format
<code>c(alpha, beta, zeta)</code>, where <code>alpha</code> are the threshold
parameters (adjusted for potential nominal effects), <code>beta</code> are the
regression parameters and <code>zeta</code> are the scale parameters.
</p>
</td></tr>
<tr><td><code id="clm_+3A_subset">subset</code></td>
<td>

<p>expression saying which subset of the rows of the data should  be used
in the fit. All observations are included by default.
</p>
</td></tr>
<tr><td><code id="clm_+3A_dofit">doFit</code></td>
<td>

<p>logical for whether the model should be fitted or the model
environment should be returned.
</p>
</td></tr>
<tr><td><code id="clm_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data. Applies to terms in all three
formulae.
</p>
</td></tr>
<tr><td><code id="clm_+3A_contrasts">contrasts</code></td>
<td>

<p>a list of contrasts to be used for some or all of
the factors appearing as variables in the model formula.
</p>
</td></tr>
<tr><td><code id="clm_+3A_model">model</code></td>
<td>

<p>logical for whether the model frame should be part of the returned
object.
</p>
</td></tr>
<tr><td><code id="clm_+3A_control">control</code></td>
<td>

<p>a list of control parameters passed on to
<code><a href="#topic+clm.control">clm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="clm_+3A_link">link</code></td>
<td>

<p>link function, i.e., the type of location-scale distribution
assumed for the latent distribution. The default <code>"logit"</code> link
gives the proportional odds model.
</p>
</td></tr>
<tr><td><code id="clm_+3A_threshold">threshold</code></td>
<td>

<p>specifies a potential structure for the thresholds
(cut-points). <code>"flexible"</code> provides the standard unstructured
thresholds, <code>"symmetric"</code> restricts the distance between the
thresholds to be symmetric around the central one or two thresholds
for odd or equal numbers or thresholds respectively,
<code>"symmetric2"</code> restricts the latent
mean in the reference group to zero; this means that the central
threshold (even no. response levels) is zero or that the two central
thresholds are equal apart from their sign (uneven no. response
levels), and
<code>"equidistant"</code> restricts the distance between consecutive
thresholds to be of the same size.
</p>
</td></tr>
<tr><td><code id="clm_+3A_...">...</code></td>
<td>

<p>additional arguments are passed on to <code><a href="#topic+clm.control">clm.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a new (as of August 2011) improved implementation of CLMs. The
old implementation is available in <code><a href="#topic+clm2">clm2</a></code>, but will
probably be removed at some point.
</p>
<p>There are methods for the standard model-fitting functions, including
<code><a href="base.html#topic+summary">summary</a></code>,
<code><a href="stats.html#topic+anova">anova</a></code>,
<code><a href="stats.html#topic+model.frame">model.frame</a></code>,
<code><a href="stats.html#topic+model.matrix">model.matrix</a></code>,
<code><a href="stats.html#topic+drop1">drop1</a></code>,
<code><a href="MASS.html#topic+dropterm">dropterm</a></code>,
<code><a href="stats.html#topic+step">step</a></code>,
<code><a href="MASS.html#topic+stepAIC">stepAIC</a></code>,
<code><a href="stats.html#topic+extractAIC">extractAIC</a></code>,
<code><a href="stats.html#topic+AIC">AIC</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>,
<code><a href="stats.html#topic+nobs">nobs</a></code>,
<code><a href="stats.html#topic+profile">profile</a></code>,
<code><a href="stats.html#topic+confint">confint</a></code>,
<code><a href="stats.html#topic+vcov">vcov</a></code> and
<code><a href="#topic+slice.clm">slice</a></code>.

</p>


<h3>Value</h3>

<p>If <code>doFit = FALSE</code> the result is an environment
representing the model ready to be optimized.
If <code>doFit = TRUE</code> the result is an
object of class <code>"clm"</code> with the components listed below.
</p>
<p>Note that some components are only present if <code>scale</code> and
<code>nominal</code> are used.
</p>
<table>
<tr><td><code>aliased</code></td>
<td>
<p>list of length 3 or less with components <code>alpha</code>,
<code>beta</code> and <code>zeta</code> each being logical vectors containing
alias information for the parameters of the same names.
</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>a vector of threshold parameters.
</p>
</td></tr>
<tr><td><code>alpha.mat</code></td>
<td>
<p>(where relevant) a table (<code>data.frame</code>) of
threshold parameters where each row corresponds to an effect in the
<code>nominal</code> formula.
</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>(where relevant) a vector of regression parameters.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the mathed call.
</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a vector of coefficients of the form
<code>c(alpha, beta, zeta)</code>
</p>
</td></tr>
<tr><td><code>cond.H</code></td>
<td>
<p>condition number of the Hessian matrix at the optimum
(i.e. the ratio of the largest to the smallest eigenvalue).
</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>(where relevant) the contrasts used for the
<code>formula</code> part of the model.
</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>list of control parameters as generated by <code><a href="#topic+clm.control">clm.control</a></code>.
</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>convergence code where 0 indicates successful
convergence and negative values indicate convergence failure; 1 indicates 
successful convergence to a non-unique optimum.
</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>the estimated degrees of freedom, i.e., the number of
parameters in the model fit.
</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted probabilities.
</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>a vector of gradients for the coefficients at the
estimated optimum.
</p>
</td></tr>
<tr><td><code>Hessian</code></td>
<td>
<p>the Hessian matrix for the parameters at the estimated
optimum.
</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>a table of basic model information for printing.
</p>
</td></tr>
<tr><td><code>link</code></td>
<td>
<p>character, the link function used.
</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the value of the log-likelihood at the estimated
optimum.
</p>
</td></tr>
<tr><td><code>maxGradient</code></td>
<td>
<p>the maximum absolute gradient, i.e.,
<code>max(abs(gradient))</code>.
</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>if requested (the default), the
<code><a href="stats.html#topic+model.frame">model.frame</a></code> containing variables from <code>formula</code>,
<code>scale</code> and <code>nominal</code> parts.
</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the number of observations counted as <code>nrow(X)</code>, where
<code>X</code> is the design matrix.
</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>(where relevant) information returned by
<code><a href="stats.html#topic+model.frame">model.frame</a></code> on the special handling of <code>NA</code>s.
</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>the number of observations counted as <code>sum(weights)</code>.
</p>
</td></tr>
<tr><td><code>nom.contrasts</code></td>
<td>
<p>(where relevant) the contrasts used for the
<code>nominal</code> part of the model.
</p>
</td></tr>
<tr><td><code>nom.terms</code></td>
<td>
<p>(where relevant) the terms object for the
<code>nominal</code> part.
</p>
</td></tr>
<tr><td><code>nom.xlevels</code></td>
<td>
<p>(where relevant) a record of the levels of the
factors used in fitting for the <code>nominal</code> part.
</p>
</td></tr>
<tr><td><code>start</code></td>
<td>
<p>the parameter values at which the optimization has
started. An attribute <code>start.iter</code> gives the number of
iterations to obtain starting values for models where <code>scale</code>
is specified or where the <code>cauchit</code> link is chosen.
</p>
</td></tr>
<tr><td><code>S.contrasts</code></td>
<td>
<p>(where relevant) the contrasts used for the
<code>scale</code> part of the model.
</p>
</td></tr>
<tr><td><code>S.terms</code></td>
<td>
<p>(where relevant) the terms object for the <code>scale</code>
part.
</p>
</td></tr>
<tr><td><code>S.xlevels</code></td>
<td>
<p>(where relevant) a record of the levels of the
factors used in fitting for the <code>scale</code> part.
</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the terms object for the <code>formula</code> part.
</p>
</td></tr>
<tr><td><code>Theta</code></td>
<td>
<p>(where relevant) a table (<code>data.frame</code>) of
thresholds for all combinations of levels of factors in the
<code>nominal</code> formula.
</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>character, the threshold structure used.
</p>
</td></tr>
<tr><td><code>tJac</code></td>
<td>
<p>the transpose of the Jacobian for the threshold structure.
</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>(where relevant) a record of the levels of the factors
used in fitting for the <code>formula</code> part.
</p>
</td></tr>
<tr><td><code>y.levels</code></td>
<td>
<p>the levels of the response variable after removing
levels for which all weights are zero.
</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>(where relevant) a vector of scale regression parameters.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fm1 &lt;- clm(rating ~ temp * contact, data = wine)
fm1 ## print method
summary(fm1)
fm2 &lt;- update(fm1, ~.-temp:contact)
anova(fm1, fm2)

drop1(fm1, test = "Chi")
add1(fm1, ~.+judge, test = "Chi")

fm2 &lt;- step(fm1)
summary(fm2)

coef(fm1)
vcov(fm1)
AIC(fm1)
extractAIC(fm1)
logLik(fm1)
fitted(fm1)

confint(fm1) ## type = "profile"
confint(fm1, type = "Wald")
pr1 &lt;- profile(fm1)
confint(pr1)

## plotting the profiles:
par(mfrow = c(2, 2))
plot(pr1, root = TRUE) ## check for linearity
par(mfrow = c(2, 2))
plot(pr1)
par(mfrow = c(2, 2))
plot(pr1, approx = TRUE)
par(mfrow = c(2, 2))
plot(pr1, Log = TRUE)
par(mfrow = c(2, 2))
plot(pr1, Log = TRUE, relative = FALSE)

## other link functions:
fm4.lgt &lt;- update(fm1, link = "logit") ## default
fm4.prt &lt;- update(fm1, link = "probit")
fm4.ll &lt;- update(fm1, link = "loglog")
fm4.cll &lt;- update(fm1, link = "cloglog")
fm4.cct &lt;- update(fm1, link = "cauchit")
anova(fm4.lgt, fm4.prt, fm4.ll, fm4.cll, fm4.cct)

## structured thresholds:
fm5 &lt;- update(fm1, threshold = "symmetric")
fm6 &lt;- update(fm1, threshold = "equidistant")
anova(fm1, fm5, fm6)

## the slice methods:
slice.fm1 &lt;- slice(fm1)
par(mfrow = c(3, 3))
plot(slice.fm1)
## see more at '?slice.clm'

## Another example:
fm.soup &lt;- clm(SURENESS ~ PRODID, data = soup)
summary(fm.soup)

if(require(MASS)) { ## dropterm, addterm, stepAIC, housing
    fm1 &lt;- clm(rating ~ temp * contact, data = wine)
    dropterm(fm1, test = "Chi")
    addterm(fm1, ~.+judge, test = "Chi")
    fm3 &lt;- stepAIC(fm1)
    summary(fm3)

    ## Example from MASS::polr:
    fm1 &lt;- clm(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
    summary(fm1)
}

</code></pre>

<hr>
<h2 id='clm.control'>Set control parameters for cumulative link models</h2><span id='topic+clm.control'></span>

<h3>Description</h3>

<p>Set control parameters for cumulative link models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clm.control(method = c("Newton", "model.frame", "design", "ucminf", "nlminb",
   "optim"), 
   sign.location = c("negative", "positive"), 
   sign.nominal = c("positive", "negative"), 
   ..., trace = 0L,
   maxIter = 100L, gradTol = 1e-06, maxLineIter = 15L, relTol = 1e-6,
   tol = sqrt(.Machine$double.eps), maxModIter = 5L,
   convergence = c("warn", "silent", "stop", "message"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clm.control_+3A_method">method</code></td>
<td>
<p><code>"Newton"</code> fits the model by maximum likelihood and
<code>"model.frame"</code> cause <code><a href="#topic+clm">clm</a></code> to return the
<code>model.frame</code>, <code>"design"</code> causes <code><a href="#topic+clm">clm</a></code> to
return a list of design matrices etc. that can be used with
<code><a href="#topic+clm.fit">clm.fit</a></code>. <code>ucminf</code>, <code>nlminb</code> and <code>optim</code> refer 
to general purpose optimizers.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_sign.location">sign.location</code></td>
<td>
<p>change sign of the location part of the model.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_sign.nominal">sign.nominal</code></td>
<td>
<p>change sign of the nominal part of the model.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_trace">trace</code></td>
<td>
<p>numerical, if <code>&gt; 0</code> information is printed about and during
the optimization process. Defaults to <code>0</code>.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_maxiter">maxIter</code></td>
<td>
<p>the maximum number of Newton-Raphson iterations.
Defaults to <code>100</code>.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_gradtol">gradTol</code></td>
<td>
<p>the maximum absolute gradient; defaults to <code>1e-6</code>.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_maxlineiter">maxLineIter</code></td>
<td>
<p>the maximum number of step halfings allowed if
a Newton(-Raphson) step over shoots. Defaults to <code>15</code>.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_reltol">relTol</code></td>
<td>
<p>relative convergence tolerence: relative change in the
parameter estimates between Newton iterations. Defaults to <code>1e-6</code>.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_tol">tol</code></td>
<td>
<p>numerical tolerence on eigenvalues to determine
negative-definiteness of Hessian. If the Hessian of a model fit is
negative definite, the fitting algorithm did not converge. If the
Hessian is singular, the fitting algorithm did converge albeit not
to a <em>unique</em> optimum, so one or more parameters are not
uniquely determined even though the log-likelihood value is.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_maxmoditer">maxModIter</code></td>
<td>
<p>the maximum allowable number of consecutive
iterations where the Newton step needs to be modified to be a decent
direction. Defaults to <code>5</code>.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_convergence">convergence</code></td>
<td>
<p>action to take if the fitting algorithm did not
converge.
</p>
</td></tr>
<tr><td><code id="clm.control_+3A_...">...</code></td>
<td>
<p>control arguments parsed on to <code><a href="ucminf.html#topic+ucminf">ucminf</a></code>,
<code><a href="stats.html#topic+nlminb">nlminb</a></code> or <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of control parameters.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm">clm</a></code>
</p>

<hr>
<h2 id='clm.fit'>
Fit Cumulative Link Models

</h2><span id='topic+clm.fit'></span><span id='topic+clm.fit.default'></span><span id='topic+clm.fit.factor'></span>

<h3>Description</h3>

<p>A direct fitter of cumulative link models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
clm.fit(y, ...)

## Default S3 method:
clm.fit(y, ...)

## S3 method for class 'factor'
clm.fit(y, X, S, N, weights = rep(1, nrow(X)),
     offset = rep(0, nrow(X)), S.offset = rep(0, nrow(X)),
     control = list(), start, doFit=TRUE,
     link = c("logit", "probit", "cloglog", "loglog", "cauchit", 
              "Aranda-Ordaz", "log-gamma"),
     threshold = c("flexible", "symmetric", "symmetric2", "equidistant"),
     ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clm.fit_+3A_y">y</code></td>
<td>
<p>for the default method a list of model components. For the
factor method the response variable; a factor, preferably and ordered
factor.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_x">X</code>, <code id="clm.fit_+3A_s">S</code>, <code id="clm.fit_+3A_n">N</code></td>
<td>
<p>optional design matrices for the regression parameters,
scale parameters and nominal parameters respectively.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_weights">weights</code></td>
<td>
<p>optional case weights.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_offset">offset</code></td>
<td>
<p>an optional offset.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_s.offset">S.offset</code></td>
<td>
<p>an optional offset for the scale part of the model.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_control">control</code></td>
<td>
<p>a list of control parameters, optionally a call to
<code><a href="#topic+clm.control">clm.control</a></code>.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_start">start</code></td>
<td>
<p>an optional list of starting values of the form
<code>c(alpha, beta, zeta)</code> for the thresholds and nominal effects
(<code>alpha</code>), regression parameters (<code>beta</code>) and scale
parameters (<code>zeta</code>).
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_dofit">doFit</code></td>
<td>
<p>logical for whether the model should be fit or the model
environment should be returned.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_link">link</code></td>
<td>
<p>the link function.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_threshold">threshold</code></td>
<td>
<p>the threshold structure, see further at
<code><a href="#topic+clm">clm</a></code>.
</p>
</td></tr>
<tr><td><code id="clm.fit_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function does almost the same thing that <code><a href="#topic+clm">clm</a></code> does:
it fits a cumulative link model. The main differences are that
<code>clm.fit</code> does not setup design matrices from formulae and only
does minimal post processing after parameter estimation.
</p>
<p>Compared to <code><a href="#topic+clm">clm</a></code>, <code>clm.fit</code> does little to warn the
user of any problems with data or model. However, <code>clm.fit</code> will
attempt to identify column rank defecient designs. Any unidentified
parameters are indicated in the <code>aliased</code> component of the fit.
</p>
<p><code>clm.fit.factor</code> is not able to check if all thresholds are
increasing when nominal effects are specified since it needs access to
the terms object for the nominal model. If the terms object for the
nominal model (<code>nom.terms</code>) is included in <code>y</code>, the default
method is able to chech if all thresholds are increasing.
</p>




<h3>Value</h3>

<p>A list with the following components:
<code>aliased, alpha, coefficients, cond.H, convergence, df.residual,
    edf, fitted.values, gradient, Hessian, logLik, maxGradient, message,
    n, niter, nobs, tJac, vcov</code>
and optionally
<code>beta, zeta</code>
These components are documented in <code><a href="#topic+clm">clm</a></code>.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm">clm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## A simple example:
fm1 &lt;- clm(rating ~ contact + temp, data=wine)
summary(fm1)
## get the model frame containing y and X:
mf1 &lt;- update(fm1, method="design")
names(mf1)
res &lt;- clm.fit(mf1$y, mf1$X) ## invoking the factor method
stopifnot(all.equal(coef(res), coef(fm1)))
names(res)

## Fitting with the default method:
mf1$control$method &lt;- "Newton"
res2 &lt;- clm.fit(mf1)
stopifnot(all.equal(coef(res2), coef(fm1)))

</code></pre>

<hr>
<h2 id='clm2'>Cumulative link models</h2><span id='topic+clm2'></span>

<h3>Description</h3>

<p>A new improved implementation of CLMs is available in <code><a href="#topic+clm">clm</a></code>.
</p>
<p>Fits cumulative link models with an additive model for the location
and a multiplicative model for the scale. The function allows for
structured thresholds. A popular special case of a CLM is the
proportional odds model. In addition to the standard link functions,
two flexible link functions, &quot;Arandar-Ordaz&quot; and &quot;log-gamma&quot; are
available, where an extra link function parameter provides additional
flexibility. A subset of the predictors can be allowed to have nominal
rather than ordinal effects. This has been termed &quot;partial
proportional odds&quot; when the link is the logistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clm2(location, scale, nominal, data, weights, start, subset,
    na.action, contrasts, Hess = TRUE, model,
    link = c("logistic", "probit", "cloglog", "loglog",
    "cauchit", "Aranda-Ordaz", "log-gamma"), lambda,
    doFit = TRUE, control,
    threshold = c("flexible", "symmetric", "equidistant"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clm2_+3A_location">location</code></td>
<td>

<p>a formula expression as for regression models, of the form
<code>response ~ predictors</code>. The response should be a factor
(preferably an ordered factor), which will be interpreted as an
ordinal response with levels ordered as in the factor.
The model must have an intercept: attempts to remove one will
lead to a warning and will be ignored. An offset may be used.  See the
documentation of <code><a href="stats.html#topic+formula">formula</a></code> for other details.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_scale">scale</code></td>
<td>

<p>a optional formula expression as for the location part, of the form
<code> ~ predictors</code>, i.e. with an empty left hand side.
An offset may be used. See the
documentation of <code><a href="stats.html#topic+formula">formula</a></code> for other details.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_nominal">nominal</code></td>
<td>

<p>an optional formula of the form <code> ~ predictors</code>, i.e. with an
empty left hand side. The effects of the predictors in this formula are
assumed to nominal.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_data">data</code></td>
<td>

<p>an optional data frame in which to interpret the variables occurring
in the formulas.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_weights">weights</code></td>
<td>

<p>optional case weights in fitting. Defaults to 1.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_start">start</code></td>
<td>

<p>initial values for the parameters in the format
<code>c(alpha, beta, log(zeta), lambda)</code>.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_subset">subset</code></td>
<td>

<p>expression saying which subset of the rows of the data should  be used
in the fit. All observations are included by default.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data. Applies to terms in all three formulae.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_contrasts">contrasts</code></td>
<td>

<p>a list of contrasts to be used for some or all of
the factors appearing as variables in the model formula.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_hess">Hess</code></td>
<td>

<p>logical for whether the Hessian (the inverse of the observed
information matrix)
should be computed.
Use <code>Hess = TRUE</code> if you intend to call <code>summary</code> or
<code>vcov</code> on the fit and <code>Hess = FALSE</code> in all other instances
to save computing time. The argument is ignored if
<code>method = "Newton"</code> where the Hessian is always computed and
returned. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_model">model</code></td>
<td>

<p>logical for whether the model frames should be part of the returned
object.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_link">link</code></td>
<td>
<p>link function, i.e. the type of location-scale distribution
assumed for the latent distribution. The <code>Aranda-Ordaz</code> and
<code>log-gamma</code> links add additional flexibility with a link function
parameter, <code>lambda</code>. The <code>Aranda-Ordaz</code> link
(Aranda-Ordaz, 1983) equals the logistic
link, when <code>lambda = 1</code> and approaches the <code>loglog</code> link when
<code>lambda</code> approaches zero. The <code>log-gamma</code> link (Genter and
Farewell, 1985) equals the
<code>loglog</code> link when <code>lambda = 1</code>, the <code>probit</code> link when
<code>lambda = 0</code> and the <code>cloglog</code> link when <code>lambda =
    -1</code>.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_lambda">lambda</code></td>
<td>
<p>numerical scalar: the link function parameter. Used in
combination with link <code>Aranda-Ordaz</code> or <code>log-gamma</code> and
otherwise ignored. If lambda is specified, the model is estimated with
lambda fixed at this value and otherwise lambda is estimated by
ML. For <code>Aranda-Ordaz</code> lambda has to be positive; <code>&gt; 1e-5</code>
for numerical reasons.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_dofit">doFit</code></td>
<td>
<p>logical for whether the model should be fit or the model
environment should be returned.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_control">control</code></td>
<td>
<p>a call to <code><a href="#topic+clm2.control">clm2.control</a></code>.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_threshold">threshold</code></td>
<td>
<p>specifies a potential structure for the thresholds
(cut-points). <code>"flexible"</code> provides the standard unstructured
thresholds, <code>"symmetric"</code> restricts the distance between the
thresholds to be symmetric around the central one or two thresholds
for odd or equal numbers or thresholds respectively, and
<code>"equidistant"</code> restricts the distance between consecutive
thresholds to the same value.
</p>
</td></tr>
<tr><td><code id="clm2_+3A_...">...</code></td>
<td>

<p>additional arguments are passed on to <code><a href="#topic+clm2.control">clm2.control</a></code> and
possibly further on to the optimizer, which can lead to surprising
error or warning messages when mistyping arguments etc.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are methods for the standard model-fitting functions, including
<code><a href="base.html#topic+summary">summary</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>,
<code><a href="#topic+predict">predict</a></code>,
<code><a href="#topic+anova.clm2">anova</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>,
<code><a href="#topic+profile.clm2">profile</a></code>,
<code><a href="#topic+profile.clm2">plot.profile</a></code>,
<code><a href="#topic+confint.clm2">confint</a></code>,
<code><a href="#topic+update.clm2">update</a></code>,
<code><a href="#topic+addterm.clm2">dropterm</a></code>,
<code><a href="#topic+addterm.clm2">addterm</a></code>, and an <code>extractAIC</code> method.
</p>
<p>The design of the implementation is inspired by an idea proposed by
Douglas Bates in the talk &quot;Exploiting sparsity in model matrices&quot;
presented at the DSC conference in Copenhagen, July 14 2009.
Basically an environment is set up with all the information needed to
optimize the likelihood function. Extractor functions are then used to
get the value of likelihood at current or given parameter values and
to extract current values of the parameters. All computations are
performed inside the environment and relevant variables are updated
during the fitting process. After optimizer termination relevant
variables are extracted from the environment and the remaining are
discarded.
</p>
<p>Some aspects of <code>clm2</code>, for instance, how starting values are
obtained, and of the associated methods are
inspired by <code><a href="MASS.html#topic+polr">polr</a></code> from package <code>MASS</code>.
</p>


<h3>Value</h3>

<p>If <code>doFit = FALSE</code> the result is an environment
representing the model ready to be optimized.
If <code>doFit = TRUE</code> the result is an
object of class <code>"clm2"</code> with the following components:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>the parameter estimates of the location part.
</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>the parameter estimates of the scale part on the log
scale; the scale parameter estimates on the original scale are given
by <code>exp(zeta)</code>.
</p>
</td></tr>
<tr><td><code>Alpha</code></td>
<td>
<p>vector or matrix of the threshold parameters.
</p>
</td></tr>
<tr><td><code>Theta</code></td>
<td>
<p>vector or matrix of the thresholds.
</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>
<p>vector of threshold parameters, which, given a
threshold function (e.g. <code>"equidistant"</code>), and possible nominal
effects define the class boundaries, <code>Theta</code>.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the value of lambda if lambda is supplied or estimated,
otherwise missing.
</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the coefficients of the intercepts
(<code>theta</code>), the location  (<code>beta</code>), the scale
(<code>zeta</code>), and the link function parameter (<code>lambda</code>).
</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the number of residual degrees of freedoms,
calculated using the weights.
</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>vector of fitted values for each
observation. An observation here is each of the scalar elements of
the multinomial table and not a multinomial vector.
</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p><code>TRUE</code> if the gradient
based convergence criterion is met and <code>FALSE</code> otherwise.
</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>vector of gradients for all the parameters
at termination of the optimizer.
</p>
</td></tr>
<tr><td><code>optRes</code></td>
<td>
<p>list with results from the optimizer. The contents of the
list depends on the choice of optimizer.
</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the log likelihood of the model at
optimizer termination.
</p>
</td></tr>
<tr><td><code>Hessian</code></td>
<td>
<p>if the model was fitted with <code>Hess = TRUE</code>, this
is the Hessian matrix of the parameters at the optimum.
</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p><code>model.frame</code> for the scale model.
</p>
</td></tr>
<tr><td><code>location</code></td>
<td>
<p><code>model.frame</code> for the location model.
</p>
</td></tr>
<tr><td><code>nominal</code></td>
<td>
<p><code>model.frame</code> for the nominal model.
</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>the (effective) number of degrees of freedom used by the
model.
</p>
</td></tr>
<tr><td><code>start</code></td>
<td>
<p>the starting values.
</p>
</td></tr>
<tr><td><code>convTol</code></td>
<td>
<p>convergence tolerance for the maximum absolute
gradient of the parameters at termination of the optimizer.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character, the optimizer.
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response variable.
</p>
</td></tr>
<tr><td><code>lev</code></td>
<td>
<p>the names of the levels of the response variable.
</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>the (effective) number of observations, calculated as the
sum of the weights.
</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>character, the threshold function used in the model.
</p>
</td></tr>
<tr><td><code>estimLambda</code></td>
<td>
<p><code>1</code> if lambda is estimated in one of the
flexible link functions and <code>0</code> otherwise.
</p>
</td></tr>
<tr><td><code>link</code></td>
<td>
<p>character, the link function used in the model.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.
</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>contrasts applied to terms in location and scale
models.
</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>the function used to filter missing data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis.</em> Second edition.  Wiley.
</p>
<p>Aranda-Ordaz, F. J. (1983) An Extension of the Proportional-Hazards
Model for Grouped Data. <em>Biometrics</em>, 39, 109-117.
</p>
<p>Genter, F. C. and Farewell, V. T. (1985) Goodness-of-link testing in
ordinal regression models. <em>The Canadian Journal of Statistics</em>,
13(1), 37-44.
</p>
<p>Christensen, R. H. B., Cleaver, G. and Brockhoff, P. B. (2011)
Statistical and Thurstonian models for the A-not A protocol with and
without sureness. <em>Food Quality and Preference, 22</em>,
pp. 542-549.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))

## A tabular data set:
(tab26 &lt;- with(soup, table("Product" = PROD, "Response" = SURENESS)))
dimnames(tab26)[[2]] &lt;- c("Sure", "Not Sure", "Guess", "Guess", "Not Sure", "Sure")
dat26 &lt;- expand.grid(sureness = as.factor(1:6), prod = c("Ref", "Test"))
dat26$wghts &lt;- c(t(tab26))

m1 &lt;- clm2(sureness ~ prod, scale = ~prod, data = dat26,
          weights = wghts, link = "logistic")

## print, summary, vcov, logLik, AIC:
m1
summary(m1)
vcov(m1)
logLik(m1)
AIC(m1)
coef(m1)
coef(summary(m1))

## link functions:
m2 &lt;- update(m1, link = "probit")
m3 &lt;- update(m1, link = "cloglog")
m4 &lt;- update(m1, link = "loglog")
m5 &lt;- update(m1, link = "cauchit", start = coef(m1))
m6 &lt;- update(m1, link = "Aranda-Ordaz", lambda = 1)
m7 &lt;- update(m1, link = "Aranda-Ordaz")
m8 &lt;- update(m1, link = "log-gamma", lambda = 1)
m9 &lt;- update(m1, link = "log-gamma")

## nominal effects:
mN1 &lt;-  clm2(sureness ~ 1, nominal = ~ prod, data = dat26,
            weights = wghts, link = "logistic")
anova(m1, mN1)

## optimizer / method:
update(m1, scale = ~ 1, method = "Newton")
update(m1, scale = ~ 1, method = "nlminb")
update(m1, scale = ~ 1, method = "optim")


## threshold functions
mT1 &lt;- update(m1, threshold = "symmetric")
mT2 &lt;- update(m1, threshold = "equidistant")
anova(m1, mT1, mT2)

## Extend example from polr in package MASS:
## Fit model from polr example:
if(require(MASS)) {
    fm1 &lt;- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
    fm1
    summary(fm1)
    ## With probit link:
    summary(update(fm1, link = "probit"))
    ## Allow scale to depend on Cont-variable
    summary(fm2 &lt;- update(fm1, scale =~ Cont))
    anova(fm1, fm2)
    ## which seems to improve the fit
}

#################################
## It is possible to fit multinomial models (i.e. with nominal
## effects) as the following example shows:
if(require(nnet)) {
    (hous1.mu &lt;- multinom(Sat ~ 1, weights = Freq, data = housing))
    (hous1.clm &lt;- clm2(Sat ~ 1, weights = Freq, data = housing))

    ## It is the same likelihood:
    all.equal(logLik(hous1.mu), logLik(hous1.clm))

    ## and the same fitted values:
    fitHous.mu &lt;-
        t(fitted(hous1.mu))[t(col(fitted(hous1.mu)) == unclass(housing$Sat))]
    all.equal(fitted(hous1.clm), fitHous.mu)

    ## The coefficients of multinom can be retrieved from the clm2-object
    ## by:
    Pi &lt;- diff(c(0, plogis(hous1.clm$xi), 1))
    log(Pi[2:3]/Pi[1])

    ## A larger model with explanatory variables:
    (hous.mu &lt;- multinom(Sat ~ Infl + Type + Cont, weights = Freq, data = housing))
    (hous.clm &lt;- clm2(Sat ~ 1, nominal = ~ Infl + Type + Cont, weights = Freq,
                      data = housing))

    ## Almost the same likelihood:
    all.equal(logLik(hous.mu), logLik(hous.clm))

    ## And almost the same fitted values:
    fitHous.mu &lt;-
        t(fitted(hous.mu))[t(col(fitted(hous.mu)) == unclass(housing$Sat))]
    all.equal(fitted(hous.clm), fitHous.mu)
    all.equal(round(fitted(hous.clm), 5), round(fitHous.mu), 5)
}

</code></pre>

<hr>
<h2 id='clm2.control'>Set control parameters for cumulative link models</h2><span id='topic+clm2.control'></span>

<h3>Description</h3>

<p>Set control parameters for cumulative link models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clm2.control(method = c("ucminf", "Newton", "nlminb", "optim",
            "model.frame"), ..., convTol = 1e-4,
            trace = 0, maxIter = 100, gradTol = 1e-5,
            maxLineIter = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clm2.control_+3A_method">method</code></td>
<td>

<p>the optimizer used to maximize the likelihood
function. <code>"Newton"</code> only works for models without <code>scale</code>,
structured thresholds and flexible link functions,
but is considerably faster than the other
optimizers when applicable. <code>model.frame</code> simply returns a list
of model frames with the location, scale and nominal model
frames. <code>"optim"</code> uses the <code>"BFGS"</code> method.
</p>
</td></tr>
<tr><td><code id="clm2.control_+3A_...">...</code></td>
<td>
<p>control arguments passed on to the chosen optimizer; see
<code><a href="ucminf.html#topic+ucminf">ucminf</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>, and
<code><a href="stats.html#topic+nlminb">nlminb</a></code> for details.
</p>
</td></tr>
<tr><td><code id="clm2.control_+3A_convtol">convTol</code></td>
<td>
<p>convergence criterion on the size of the maximum
absolute gradient.
</p>
</td></tr>
<tr><td><code id="clm2.control_+3A_trace">trace</code></td>
<td>
<p>numerical, if &gt; 0 information is printed about and during
the optimization process. Defaults to <code>0</code>.
</p>
</td></tr>
<tr><td><code id="clm2.control_+3A_maxiter">maxIter</code></td>
<td>
<p>the maximum number of Newton-Raphson iterations.
Defaults to <code>100</code>.
</p>
</td></tr>
<tr><td><code id="clm2.control_+3A_gradtol">gradTol</code></td>
<td>
<p>the maximum absolute gradient. This is the termination
criterion and defaults to <code>1e-5</code>.
</p>
</td></tr>
<tr><td><code id="clm2.control_+3A_maxlineiter">maxLineIter</code></td>
<td>
<p>the maximum number of step halfings allowed if
a Newton(-Raphson) step over shoots. Defaults to <code>10</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of control parameters.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm2">clm2</a></code>
</p>

<hr>
<h2 id='clmm'>
Cumulative Link Mixed Models
</h2><span id='topic+clmm'></span>

<h3>Description</h3>

<p>Fits Cumulative Link Mixed Models with one or more random effects via
the Laplace approximation or quadrature methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clmm(formula, data, weights, start, subset, na.action, contrasts, Hess =
TRUE, model = TRUE, link = c("logit", "probit", "cloglog", "loglog",
"cauchit"), doFit = TRUE, control = list(), nAGQ = 1L,
threshold = c("flexible", "symmetric", "symmetric2", "equidistant"), ...)


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clmm_+3A_formula">formula</code></td>
<td>

<p>a two-sided linear formula object describing the fixed-effects part
of the model, with the response on the left of a ~ operator and the
terms, separated by + operators, on the right. The vertical bar
character &quot;|&quot; separates an expression for a model matrix and a
grouping factor.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_data">data</code></td>
<td>

<p>an optional data frame in which to interpret the variables occurring
in the formula.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_weights">weights</code></td>
<td>

<p>optional case weights in fitting. Defaults to 1.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_start">start</code></td>
<td>

<p>optional initial values for the parameters in the format
<code>c(alpha, beta, tau)</code>, where <code>alpha</code> are the threshold
parameters, <code>beta</code> are the fixed regression parameters and
<code>tau</code> are variance parameters for the random effects on the log
scale.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_subset">subset</code></td>
<td>

<p>expression saying which subset of the rows of the data should  be
used in the fit. All observations are included by default.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_contrasts">contrasts</code></td>
<td>

<p>a list of contrasts to be used for some or all of
the factors appearing as variables in the model formula.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_hess">Hess</code></td>
<td>

<p>logical for whether the Hessian (the inverse of the observed
information matrix)
should be computed.
Use <code>Hess = TRUE</code> if you intend to call <code>summary</code> or
<code>vcov</code> on the fit and <code>Hess = FALSE</code> in all other instances
to save computing time.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_model">model</code></td>
<td>

<p>logical for whether the model frames should be part of the returned
object.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_link">link</code></td>
<td>

<p>link function, i.e. the type of location-scale distribution
assumed for the latent distribution. The default <code>"logit"</code> link
gives the proportional odds mixed model.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_dofit">doFit</code></td>
<td>

<p>logical for whether the model should be fit or the model
environment should be returned.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_control">control</code></td>
<td>

<p>a call to <code><a href="#topic+clmm.control">clmm.control</a></code>
</p>
</td></tr>
<tr><td><code id="clmm_+3A_nagq">nAGQ</code></td>
<td>

<p>integer; the number of quadrature points to use in the adaptive
Gauss-Hermite quadrature approximation to the likelihood
function. The default (<code>1</code>) gives the Laplace
approximation. Higher values generally provide higher precision at
the expense of longer computation times, and
values between 5 and 10 generally provide accurate maximum
likelihood estimates. Negative values give the non-adaptive
Gauss-Hermite quadrature approximation, which is generally faster
but less
accurate than the adaptive version. See the references for further
details. Quadrature methods are only available with a single random
effects term; the Laplace approximation is always available.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_threshold">threshold</code></td>
<td>

<p>specifies a potential structure for the thresholds
(cut-points). <code>"flexible"</code> provides the standard unstructured
thresholds, <code>"symmetric"</code> restricts the distance between the
thresholds to be symmetric around the central one or two thresholds
for odd or equal numbers or thresholds respectively,
<code>"symmetric2"</code> restricts the latent
mean in the reference group to zero; this means that the central
threshold (even no. response levels) is zero or that the two central
thresholds are equal apart from their sign (uneven no. response
levels), and
<code>"equidistant"</code> restricts the distance between consecutive
thresholds to be of the same size.
</p>
</td></tr>
<tr><td><code id="clmm_+3A_...">...</code></td>
<td>

<p>additional arguments are passed on to <code><a href="#topic+clm.control">clm.control</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a new (as of August 2011) improved implementation of CLMMs. The
old implementation is available in <code><a href="#topic+clmm2">clmm2</a></code>. Some features
are not yet available in <code>clmm</code>; for instance
scale effects, nominal effects and flexible link functions are
currently only  available in <code>clmm2</code>. <code>clmm</code> is expected to
take over <code>clmm2</code> at some point.
</p>
<p>There are standard print, summary and anova methods implemented for
<code>"clmm"</code> objects.
</p>


<h3>Value</h3>

<p> a list containing
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>threshold parameters.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>fixed effect regression parameters.</p>
</td></tr>
<tr><td><code>stDev</code></td>
<td>
<p>standard deviation of the random effect terms.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p><code>log(stDev)</code> - the scale at which the log-likelihood
function is optimized.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the estimated model parameters = <code>c(alpha,
      beta, tau)</code>.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>List of control parameters as generated by <code><a href="#topic+clm.control">clm.control</a></code>.
</p>
</td></tr>
<tr><td><code>Hessian</code></td>
<td>
<p>Hessian of the model coefficients.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>the estimated degrees of freedom used by the model =
<code>length(coefficients)</code>.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p><code>sum(weights)</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>length(y).</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>fitted values evaluated with the random effects
at their conditional modes.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>residual degrees of freedom; <code>length(y) -
      sum(weights)</code></p>
</td></tr>
<tr><td><code>tJac</code></td>
<td>
<p>Jacobian of the threshold function corresponding to the
mapping from standard flexible thresholds to those used in the
model.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the terms object for the fixed effects.</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>contrasts applied to the fixed model terms.</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>the function used to filter missing data.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>value of the log-likelihood function for the model at
the optimum.</p>
</td></tr>
<tr><td><code>Niter</code></td>
<td>
<p>number of Newton iterations in the inner loop update of
the conditional modes of the random effects.</p>
</td></tr>
<tr><td><code>optRes</code></td>
<td>
<p>list of results from the optimizer.</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>
<p>list of the conditional modes of the random effects.</p>
</td></tr>
<tr><td><code>condVar</code></td>
<td>
<p>list of the conditional variance of the random effects
at their conditional modes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Cumulative link model with one random term:	
fmm1 &lt;- clmm(rating ~ temp + contact + (1|judge), data = wine)	
summary(fmm1)	
	
## Not run:  	
## May take a couple of seconds to run this.	

## Cumulative link mixed model with two random terms:
mm1 &lt;- clmm(SURENESS ~ PROD + (1|RESP) + (1|RESP:PROD), data = soup,
            link = "probit", threshold = "equidistant")
mm1
summary(mm1)

## test random effect:
mm2 &lt;- clmm(SURENESS ~ PROD + (1|RESP), data = soup,
            link = "probit", threshold = "equidistant")
anova(mm1, mm2)

## End(Not run)

</code></pre>

<hr>
<h2 id='clmm.control'>
Set control parameters for cumulative link mixed models
</h2><span id='topic+clmm.control'></span>

<h3>Description</h3>

<p>Set control parameters for cumulative link mixed models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clmm.control(method = c("nlminb", "ucminf", "model.frame"), ..., trace = 0,
maxIter = 50, gradTol = 1e-4, maxLineIter = 50,  useMatrix = FALSE,
innerCtrl = c("warnOnly", "noWarn", "giveError"),
checkRanef = c("warn", "error", "message"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clmm.control_+3A_method">method</code></td>
<td>

<p>the optimizer used to maximize the marginal likelihood function.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_...">...</code></td>
<td>
<p>control arguments passed on to the optimizer; see
<code><a href="ucminf.html#topic+ucminf">ucminf</a></code> for details.
<code>ucminf</code> for details.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_trace">trace</code></td>
<td>
<p>numerical, if &gt; 0 information is printed about and during
the outer optimization process, if &lt; 0 information is also printed
about the inner optimization process. Defaults to <code>0</code>.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_maxiter">maxIter</code></td>
<td>
<p>the maximum number of Newton updates of the inner
optimization. <code>50</code>.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_gradtol">gradTol</code></td>
<td>
<p>the maximum absolute gradient of the inner
optimization.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_maxlineiter">maxLineIter</code></td>
<td>
<p>the maximum number of step halfings allowed if
a Newton(-Raphson) step over shoots during the inner optimization.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_usematrix">useMatrix</code></td>
<td>
<p>if <code>TRUE</code>, a general implementation of the
Laplace approximation using the Matrix package is used, while if
<code>FALSE</code> (default), a C implementation of the Laplace
approximation valid only for models with a single random effects
term is used when possible.
<code>TRUE</code> is not valid for models fitted with quadrature methods.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_innerctrl">innerCtrl</code></td>
<td>
<p>the use of warnings/errors if the inner optimization
fails to converge.
</p>
</td></tr>
<tr><td><code id="clmm.control_+3A_checkranef">checkRanef</code></td>
<td>
<p>the use of message/warning/error if there are more random 
effects than observations.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of control parameters
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clmm">clmm</a></code>
</p>

<hr>
<h2 id='clmm2'>Cumulative link mixed models</h2><span id='topic+clmm2'></span>

<h3>Description</h3>

<p>Fits cumulative link mixed models, i.e. cumulative link models with
random effects via the Laplace approximation or the standard and the
adaptive Gauss-Hermite quadrature approximation. The functionality in
<code><a href="#topic+clm2">clm2</a></code> is also implemented here. Currently only a single
random term is allowed in the location-part of the model.
</p>
<p>A new implementation is available in <code><a href="#topic+clmm">clmm</a></code> that allows
for more than one random effect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clmm2(location, scale, nominal, random, data, weights, start, subset,
     na.action, contrasts, Hess = FALSE, model = TRUE, sdFixed,
     link = c("logistic", "probit", "cloglog", "loglog",
     "cauchit", "Aranda-Ordaz", "log-gamma"), lambda,
     doFit = TRUE, control, nAGQ = 1,
     threshold = c("flexible", "symmetric", "equidistant"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clmm2_+3A_location">location</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_scale">scale</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_nominal">nominal</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_random">random</code></td>
<td>

<p>a factor for the random effects in the location-part of the model.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_data">data</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_weights">weights</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_start">start</code></td>
<td>

<p>initial values for the parameters in the format
<code>c(alpha, beta, log(zeta), lambda, log(stDev))</code> where
<code>stDev</code> is the standard deviation of the random effects.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_subset">subset</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_na.action">na.action</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_contrasts">contrasts</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_hess">Hess</code></td>
<td>

<p>logical for whether the Hessian (the inverse of the observed
information matrix) should be computed.
Use <code>Hess = TRUE</code> if you intend to call <code>summary</code> or
<code>vcov</code> on the fit and <code>Hess = FALSE</code> in all other instances
to save computing time.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_model">model</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_sdfixed">sdFixed</code></td>
<td>

<p>If <code>sdFixed</code> is specified (a positive scalar), a model is fitted
where the standard deviation for the random term is fixed at the value
of <code>sdFixed</code>. If <code>sdFixed</code> is left unspecified, the standard
deviation of the random term is estimated from data.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_link">link</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_lambda">lambda</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_dofit">doFit</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code> although it can also be one of <code>c("no",
    "R" "C")</code>, where <code>"R"</code> use the R-implementation for fitting,
<code>"C"</code> (default) use C-implementation for fitting and <code>"no"</code>
behaves as <code>FALSE</code> and returns the environment.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_control">control</code></td>
<td>

<p>a call to <code><a href="#topic+clmm2.control">clmm2.control</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_threshold">threshold</code></td>
<td>

<p>as in <code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_nagq">nAGQ</code></td>
<td>

<p>the number of quadrature points to be used in the adaptive
Gauss-Hermite quadrature approximation to the marginal
likelihood. Defaults to <code>1</code> which leads to the Laplace
approximation. An odd number of quadrature points is encouraged and
3, 5 or 7 are usually enough to achive high precision. Negative
values give the standard, i.e. non-adaptive Gauss-Hermite
quadrature.
</p>
</td></tr>
<tr><td><code id="clmm2_+3A_...">...</code></td>
<td>

<p>additional arguments are passed on to <code><a href="#topic+clm2.control">clm2.control</a></code> and
possibly further on to the optimizer, which can lead to surprising
error or warning messages when mistyping arguments etc.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are methods for the standard model-fitting functions, including
<code><a href="base.html#topic+summary">summary</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>,
<code><a href="#topic+profile.clmm2">profile</a></code>,
<code><a href="#topic+profile.clmm2">plot.profile</a></code>,
<code><a href="#topic+confint.profile.clmm2">confint</a></code>,
<code><a href="#topic+anova.clm2">anova</a></code>, <code><a href="stats.html#topic+logLik">logLik</a></code>,
<code><a href="#topic+predict.clmm2">predict</a></code>
and an <code>extractAIC</code> method.
</p>
<p>A Newton scheme is used to obtain the conditional modes of the random
effects for Laplace and AGQ approximations, and a non-linear
optimization is performed over the fixed parameter set to get the
maximum likelihood estimates.
The Newton
scheme uses the observed Hessian rather than the expected as is done
in e.g. <code><a href="lme4.html#topic+glmer">glmer</a></code>, so results from the Laplace
approximation for binomial fits should in general be more precise -
particularly for other links than the <code>"logistic"</code>.
</p>
<p>Core parts of the function are implemented in C-code for speed.
</p>
<p>The function calls <code><a href="#topic+clm2">clm2</a></code> to up an
environment and to get starting values.
</p>


<h3>Value</h3>

<p>If <code>doFit = FALSE</code> the result is an environment
representing the model ready to be optimized.
If <code>doFit = TRUE</code> the result is an
object of class <code>"clmm2"</code> with the following components:
</p>
<table>
<tr><td><code>stDev</code></td>
<td>

<p>the standard deviation of the random effects.
</p>
</td></tr>
<tr><td><code>Niter</code></td>
<td>

<p>the total number of iterations in the Newton updates of the
conditional modes of the random effects.
</p>
</td></tr>
<tr><td><code>grFac</code></td>
<td>

<p>the grouping factor defining the random effects.
</p>
</td></tr>
<tr><td><code>nAGQ</code></td>
<td>

<p>the number of quadrature points used in the adaptive Gauss-Hermite
Quadrature approximation to the marginal likelihood.
</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>

<p>the conditional modes of the random effects, sometimes referred to
as &quot;random effect estimates&quot;.
</p>
</td></tr>
<tr><td><code>condVar</code></td>
<td>

<p>the conditional variances of the random effects at their conditional
modes.
</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the parameter estimates of the location part.
</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>the parameter estimates of the scale part on the log
scale; the scale parameter estimates on the original scale are given
by <code>exp(zeta)</code>.
</p>
</td></tr>
<tr><td><code>Alpha</code></td>
<td>
<p>vector or matrix of the threshold parameters.
</p>
</td></tr>
<tr><td><code>Theta</code></td>
<td>
<p>vector or matrix of the thresholds.
</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>
<p>vector of threshold parameters, which, given a
threshold function (e.g. <code>"equidistant"</code>), and possible nominal
effects define the class boundaries, <code>Theta</code>.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the value of lambda if lambda is supplied or estimated,
otherwise missing.
</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the coefficients of the intercepts
(<code>theta</code>), the location  (<code>beta</code>), the scale
(<code>zeta</code>), and the link function parameter (<code>lambda</code>).
</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the number of residual degrees of freedoms,
calculated using the weights.
</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>vector of fitted values conditional on the values
of the random effects. Use <code><a href="#topic+predict.clm2">predict</a></code> to
get the fitted
values for a random effect of zero. An observation here is taken to
be each of the scalar elements of the multinomial table and not a
multinomial vector.
</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p><code>TRUE</code> if the optimizer terminates wihtout
error and <code>FALSE</code> otherwise.
</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>vector of gradients for the unit-variance random
effects at their conditional modes.
</p>
</td></tr>
<tr><td><code>optRes</code></td>
<td>
<p>list with results from the optimizer. The contents of the
list depends on the choice of optimizer.
</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the log likelihood of the model at
optimizer termination.
</p>
</td></tr>
<tr><td><code>Hessian</code></td>
<td>
<p>if the model was fitted with <code>Hess = TRUE</code>, this
is the Hessian matrix of the parameters at the optimum.
</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p><code>model.frame</code> for the scale model.
</p>
</td></tr>
<tr><td><code>location</code></td>
<td>
<p><code>model.frame</code> for the location model.
</p>
</td></tr>
<tr><td><code>nominal</code></td>
<td>
<p><code>model.frame</code> for the nominal model.
</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>the (effective) number of degrees of freedom used by the
model.
</p>
</td></tr>
<tr><td><code>start</code></td>
<td>
<p>the starting values.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character, the optimizer.
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response variable.
</p>
</td></tr>
<tr><td><code>lev</code></td>
<td>
<p>the names of the levels of the response variable.
</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>the (effective) number of observations, calculated
as the sum of the weights.
</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>character, the threshold function used in the model.
</p>
</td></tr>
<tr><td><code>estimLambda</code></td>
<td>
<p><code>1</code> if lambda is estimated in one of the
flexible link functions and <code>0</code> otherwise.
</p>
</td></tr>
<tr><td><code>link</code></td>
<td>
<p>character, the link function used in the model.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.
</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>contrasts applied to terms in location and scale
models.
</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>the function used to filter missing data.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data Analysis.</em> Second edition.  Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))

## More manageable data set:
dat &lt;- subset(soup, as.numeric(as.character(RESP)) &lt;=  24)
dat$RESP &lt;- dat$RESP[drop=TRUE]

m1 &lt;- clmm2(SURENESS ~ PROD, random = RESP, data = dat, link="probit",
           Hess = TRUE, method="ucminf", threshold = "symmetric")

m1
summary(m1)
logLik(m1)
vcov(m1)
extractAIC(m1)
anova(m1, update(m1, location = SURENESS ~ 1, Hess = FALSE))
anova(m1, update(m1, random = NULL))

## Use adaptive Gauss-Hermite quadrature rather than the Laplace
## approximation:
update(m1, Hess = FALSE, nAGQ = 3)

## Use standard Gauss-Hermite quadrature:
update(m1, Hess = FALSE, nAGQ = -7)

##################################################################
## Binomial example with the cbpp data from the lme4-package:
if(require(lme4)) {
    cbpp2 &lt;- rbind(cbpp[,-(2:3)], cbpp[,-(2:3)])
    cbpp2 &lt;- within(cbpp2, {
        incidence &lt;- as.factor(rep(0:1, each=nrow(cbpp)))
        freq &lt;- with(cbpp, c(incidence, size - incidence))
    })

    ## Fit with Laplace approximation:
    fm1 &lt;- clmm2(incidence ~ period, random = herd, weights = freq,
                 data = cbpp2, Hess = 1)
    summary(fm1)

    ## Fit with the adaptive Gauss-Hermite quadrature approximation:
    fm2 &lt;- clmm2(incidence ~ period, random = herd, weights = freq,
                 data = cbpp2, Hess = 1, nAGQ = 7)
    summary(fm2)
}

</code></pre>

<hr>
<h2 id='clmm2.control'>Set control parameters for cumulative link mixed models</h2><span id='topic+clmm2.control'></span>

<h3>Description</h3>

<p>Set control parameters for cumulative link mixed models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clmm2.control(method = c("ucminf", "nlminb", "model.frame"), ...,
             trace = 0, maxIter = 50, gradTol = 1e-4,
             maxLineIter = 50,
             innerCtrl = c("warnOnly", "noWarn", "giveError"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clmm2.control_+3A_method">method</code></td>
<td>

<p>the optimizer used to maximize the marginal likelihood function.
</p>
</td></tr>
<tr><td><code id="clmm2.control_+3A_...">...</code></td>
<td>
<p>control arguments passed on to the chosen optimizer; see
<code><a href="ucminf.html#topic+ucminf">ucminf</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>, and
<code><a href="stats.html#topic+nlminb">nlminb</a></code> for details.
</p>
</td></tr>
<tr><td><code id="clmm2.control_+3A_trace">trace</code></td>
<td>
<p>numerical, if &gt; 0 information is printed about and during
the outer optimization process, if &lt; 0 information is also printed
about the inner optimization process. Defaults to <code>0</code>.
</p>
</td></tr>
<tr><td><code id="clmm2.control_+3A_maxiter">maxIter</code></td>
<td>
<p>the maximum number of Newton updates of the inner
optimization. <code>50</code>.
</p>
</td></tr>
<tr><td><code id="clmm2.control_+3A_gradtol">gradTol</code></td>
<td>
<p>the maximum absolute gradient of the inner
optimization.
</p>
</td></tr>
<tr><td><code id="clmm2.control_+3A_maxlineiter">maxLineIter</code></td>
<td>
<p>the maximum number of step halfings allowed if
a Newton(-Raphson) step over shoots during the inner optimization.
</p>
</td></tr>
<tr><td><code id="clmm2.control_+3A_innerctrl">innerCtrl</code></td>
<td>
<p>the use of warnings/errors if the inner optimization
fails to converge.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the default optimizer, <code>ucminf</code> is used, the default values
of that optimizers control options are changed to <code>grtol = 1e-5</code>
and <code>grad = "central"</code>. 
</p>


<h3>Value</h3>

<p>a list of control parameters.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clmm2">clmm2</a></code>
</p>

<hr>
<h2 id='condVar'>
Extract conditional modes and conditional variances from clmm objects
</h2><span id='topic+ranef'></span><span id='topic+condVar'></span><span id='topic+ranef.clmm'></span><span id='topic+condVar.clmm'></span>

<h3>Description</h3>

<p>The ranef function extracts the conditional modes of the random
effects from a clmm object. That is, the modes of the distributions
for the random effects given the observed data and estimated model
parameters. In a Bayesian language they are posterior modes.
</p>
<p>The conditional variances are computed from the second order
derivatives of the conditional distribution of the random
effects. Note that these variances are computed at a fixed value of
the model parameters and thus do not take the uncertainty of the
latter into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
condVar(object, ...)

## S3 method for class 'clmm'
ranef(object, condVar=FALSE, ...)

## S3 method for class 'clmm'
condVar(object, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="condVar_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+clmm">clmm</a></code> object.
</p>
</td></tr>
<tr><td><code id="condVar_+3A_condvar">condVar</code></td>
<td>

<p>an optional logical argument indicating of conditional variances
should be added as attributes to the conditional modes.
</p>
</td></tr>
<tr><td><code id="condVar_+3A_...">...</code></td>
<td>

<p>currently not used by the <code>clmm</code> methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>ranef</code> method returns a list of <code>data.frame</code>s; one for
each distinct grouping factor. Each <code>data.frame</code> has as many rows
as there are levels for that grouping factor and as many columns as
there are random effects for each level. For example a model can
contain a random intercept (one column) or a random
intercept and a random slope (two columns) for the same grouping
factor.
</p>
<p>If conditional variances are requested, they are returned in the same
structure as the conditional modes (random effect
estimates/predictions).
</p>


<h3>Value</h3>

<p>The <code>ranef</code> method returns a list of <code>data.frame</code>s with the
random effects predictions/estimates computed as conditional
modes. If <code>condVar = TRUE</code> a <code>data.frame</code> with the
conditional variances is stored as an attribute on each
<code>data.frame</code> with conditional modes.
</p>
<p>The <code>condVar</code> method returns a list of <code>data.frame</code>s with
the conditional variances. It is a convenience function that simply
computes the conditional modes and variances, then extracts and
returns only the latter.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fm1 &lt;- clmm(rating ~ contact + temp + (1|judge), data=wine)

## Extract random effect estimates/conditional modes:
re &lt;- ranef(fm1, condVar=TRUE)

## Get conditional variances:
attr(re$judge, "condVar")
## Alternatively:
condVar(fm1)

</code></pre>

<hr>
<h2 id='confint'>
Confidence intervals and profile likelihoods for parameters in
cumulative link models
</h2><span id='topic+confint.clm'></span><span id='topic+confint.profile.clm'></span><span id='topic+profile.clm'></span><span id='topic+plot.profile.clm'></span>

<h3>Description</h3>

<p>Computes confidence intervals from the profiled likelihood for one or
more parameters in a cumulative link model, or plots the
profile likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'clm'
confint(object, parm, level = 0.95,
        type = c("profile", "Wald"), trace = FALSE, ...)

## S3 method for class 'profile.clm'
confint(object, parm = seq_len(nprofiles),
        level = 0.95, ...)

## S3 method for class 'clm'
profile(fitted, which.beta = seq_len(nbeta),
        which.zeta = seq_len(nzeta), alpha = 0.001,
        max.steps = 50, nsteps = 8, trace = FALSE, step.warn = 5,
        control = list(), ...)

## S3 method for class 'profile.clm'
plot(x, which.par = seq_len(nprofiles),
        level = c(0.95, 0.99), Log = FALSE, relative = TRUE, root =
        FALSE, fig = TRUE, approx = root, n = 1e3,
        ask = prod(par("mfcol")) &lt; length(which.par) &amp;&amp; dev.interactive(),
        ..., ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint_+3A_object">object</code>, <code id="confint_+3A_fitted">fitted</code>, <code id="confint_+3A_x">x</code></td>
<td>

<p>a fitted <code><a href="#topic+clm">clm</a></code> object or a <code>profile.clm</code> object.
</p>
</td></tr>
<tr><td><code id="confint_+3A_parm">parm</code>, <code id="confint_+3A_which.par">which.par</code>, <code id="confint_+3A_which.beta">which.beta</code>, <code id="confint_+3A_which.zeta">which.zeta</code></td>
<td>

<p>a numeric or character vector indicating which regression
coefficients should be profiled. By default all coefficients are
profiled. Ignored for <code>confint.clm</code> where all parameters are
considered.
</p>
</td></tr>
<tr><td><code id="confint_+3A_level">level</code></td>
<td>

<p>the confidence level. For the <code>plot</code> method a vector of levels
for which horizontal lines should be drawn.
</p>
</td></tr>
<tr><td><code id="confint_+3A_type">type</code></td>
<td>

<p>the type of confidence interval.
</p>
</td></tr>
<tr><td><code id="confint_+3A_trace">trace</code></td>
<td>

<p>if <code>trace</code> is <code>TRUE</code> or positive, information about
progress is printed.
</p>
</td></tr>
<tr><td><code id="confint_+3A_log">Log</code></td>
<td>

<p>should the profile likelihood be plotted on the log-scale?
</p>
</td></tr>
<tr><td><code id="confint_+3A_relative">relative</code></td>
<td>

<p>should the relative or the absolute likelihood be plotted?
</p>
</td></tr>
<tr><td><code id="confint_+3A_root">root</code></td>
<td>

<p>should the (approximately linear) likelihood root statistic be
plotted?
</p>
</td></tr>
<tr><td><code id="confint_+3A_approx">approx</code></td>
<td>

<p>should the Gaussian or quadratic approximation to the (log)
likelihood be included?
</p>
</td></tr>
<tr><td><code id="confint_+3A_fig">fig</code></td>
<td>

<p>should the profile likelihood be plotted?
</p>
</td></tr>
<tr><td><code id="confint_+3A_ask">ask</code></td>
<td>

<p>logical; if <code>TRUE</code>, the user is asked before each plot, see
<code><a href="graphics.html#topic+par">par</a></code><code>(ask=.)</code>.
</p>
</td></tr>
<tr><td><code id="confint_+3A_n">n</code></td>
<td>

<p>the no. points used in the spline interpolation of the profile
likelihood.
</p>
</td></tr>
<tr><td><code id="confint_+3A_ylim">ylim</code></td>
<td>
<p>overrules default y-limits on the plot of the profile
likelihood.
</p>
</td></tr>
<tr><td><code id="confint_+3A_alpha">alpha</code></td>
<td>

<p>the likelihood is profiled in the 100*(1-alpha)% confidence region
as determined by the profile likelihood.
</p>
</td></tr>
<tr><td><code id="confint_+3A_control">control</code></td>
<td>

<p>a list of control parameters for <code><a href="#topic+clm">clm</a></code>. Possibly use
<code><a href="#topic+clm.control">clm.control</a></code> to set these.
</p>
</td></tr>






<tr><td><code id="confint_+3A_max.steps">max.steps</code></td>
<td>

<p>the maximum number of profiling steps in each direction for each
parameter.
</p>
</td></tr>
<tr><td><code id="confint_+3A_nsteps">nsteps</code></td>
<td>

<p>the (approximate) number of steps to take in each direction of the
profile for each parameter.
The step length is determined accordingly assuming a quadratic
approximation to the log-likelihood function.
The actual number of steps will often be close to <code>nsteps</code>, but
will deviate when the log-likelihood functions is irregular.
</p>
</td></tr>
<tr><td><code id="confint_+3A_step.warn">step.warn</code></td>
<td>

<p>a warning is issued if the number of steps in each
direction (up or down) for a parameter is less than
<code>step.warn</code>. If few steps are taken, the profile will be
unreliable and derived confidence intervals will be inaccurate.
</p>
</td></tr>
<tr><td><code id="confint_+3A_...">...</code></td>
<td>

<p>additional arguments to be parsed on to methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These <code>confint</code> methods call
the appropriate profile method, then finds the
confidence intervals by interpolation of the profile traces.
If the profile object is already available, this should be used as the
main argument rather than the fitted model object itself.
</p>


<h3>Value</h3>

<p><code>confint</code>:
A matrix with columns giving lower and upper confidence
limits for each parameter. These will be labelled as (1-level)/2 and
1 - (1-level)/2 in % (by default 2.5% and 97.5%).
</p>
<p><code>plot.profile.clm</code> invisibly returns the profile object, i.e., a
list of <code><a href="base.html#topic+data.frame">data.frame</a></code>s with an <code>lroot</code> component for
the likelihood root statistic and a  matrix <code>par.vals</code> with
values of the parameters.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+profile">profile</a></code> and <code><a href="stats.html#topic+confint">confint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Accurate profile likelihood confidence intervals compared to the
## conventional Wald intervals:
fm1 &lt;- clm(rating ~ temp * contact, data = wine)
confint(fm1) ## type = "profile"
confint(fm1, type = "Wald")
pr1 &lt;- profile(fm1)
confint(pr1)

## plotting the profiles:
par(mfrow = c(2, 2))
plot(pr1, root = TRUE) ## check for linearity
par(mfrow = c(2, 2))
plot(pr1)
par(mfrow = c(2, 2))
plot(pr1, approx = TRUE)
par(mfrow = c(2, 2))
plot(pr1, Log = TRUE)
par(mfrow = c(2, 2))
plot(pr1, Log = TRUE, relative = FALSE)
## Not likely to be useful but allowed for completeness:
par(mfrow = c(2, 2))
plot(pr1, Log = FALSE, relative = FALSE)

## Example from polr in package MASS:
## Fit model from polr example:
if(require(MASS)) {
    fm1 &lt;- clm(Sat ~ Infl + Type + Cont, weights = Freq,
               data = housing)
    pr1 &lt;- profile(fm1)
    confint(pr1)
    par(mfrow=c(2,2))
    plot(pr1)
}

</code></pre>

<hr>
<h2 id='confint.clm2'>
Confidence intervals and profile likelihoods for parameters in
cumulative link models
</h2><span id='topic+confint.clm2'></span><span id='topic+confint.profile.clm2'></span><span id='topic+profile.clm2'></span><span id='topic+plot.profile.clm2'></span>

<h3>Description</h3>

<p>Computes confidence intervals from the profiled likelihood for one or
more parameters in a fitted cumulative link model, or plots the
profile likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clm2'
confint(object, parm, level = 0.95, whichL = seq_len(p),
        whichS = seq_len(k), lambda = TRUE, trace = 0, ...)

## S3 method for class 'profile.clm2'
confint(object, parm = seq_along(Pnames), level = 0.95, ...)

## S3 method for class 'clm2'
profile(fitted, whichL = seq_len(p), whichS = seq_len(k),
        lambda = TRUE, alpha = 0.01, maxSteps = 50, delta = LrootMax/10,
        trace = 0, stepWarn = 8, ...)

## S3 method for class 'profile.clm2'
plot(x, parm = seq_along(Pnames), level = c(0.95, 0.99),
        Log = FALSE, relative = TRUE, fig = TRUE, n = 1e3, ..., ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.clm2_+3A_object">object</code></td>
<td>

<p>a fitted <code><a href="#topic+clm2">clm2</a></code> object or a <code>profile.clm2</code> object.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_fitted">fitted</code></td>
<td>

<p>a fitted <code><a href="#topic+clm2">clm2</a></code> object.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_x">x</code></td>
<td>
<p>a <code>profile.clm2</code> object.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_parm">parm</code></td>
<td>
<p>not used in <code>confint.clm2</code>.
</p>
<p>For <code>confint.profile.clm2</code>:
a specification of which parameters are to be given confidence
intervals, either a vector of numbers or a vector of names. If
missing, all parameters are considered.
</p>
<p>For <code>plot.profile.clm2</code>:
a specification of which parameters the profile likelihood are to be
plotted for, either a vector of numbers or a vector of names. If
missing, all parameters are considered.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_level">level</code></td>
<td>

<p>the confidence level required.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_whichl">whichL</code></td>
<td>

<p>a specification of which <em>location</em> parameters are to be given confidence
intervals, either a vector of numbers or a vector of names. If
missing, all location parameters are considered.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_whichs">whichS</code></td>
<td>

<p>a specification of which <em>scale</em> parameters are to be given confidence
intervals, either a vector of numbers or a vector of names. If
missing, all scale parameters are considered.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_lambda">lambda</code></td>
<td>

<p>logical. Should profile or confidence intervals be computed for the
link function parameter? Only used when one of the flexible link
functions are used; see the <code>link</code>-argument in
<code><a href="#topic+clm2">clm2</a></code>.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_trace">trace</code></td>
<td>

<p>logical.  Should profiling be traced?
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_alpha">alpha</code></td>
<td>
<p>Determines the range of profiling. By default the
likelihood is profiled in the 99% confidence interval region as
determined by the profile likelihood.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_maxsteps">maxSteps</code></td>
<td>
<p>the maximum number of profiling steps in each
direction (up and down) for each parameter.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_delta">delta</code></td>
<td>
<p>the length of profiling steps. To some extent this
parameter determines the degree of accuracy of the profile
likelihood in that smaller values, i.e. smaller steps gives a higher
accuracy. Note however that a spline interpolation is used when
constructing confidence intervals so fairly long steps can provide
high accuracy.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_stepwarn">stepWarn</code></td>
<td>
<p>a warning is issued if the no. steps in each direction
(up or down) for a parameter is less than <code>stepWarn</code> (defaults
to 8 steps) because this indicates an unreliable profile.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_log">Log</code></td>
<td>
<p>should the profile likelihood be plotted on the log-scale?
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_relative">relative</code></td>
<td>
<p>should the relative or the absolute likelihood be
plotted?
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_fig">fig</code></td>
<td>
<p>should the profile likelihood be plotted?
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_n">n</code></td>
<td>
<p>the no. points used in the spline interpolation of the
profile likelihood.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_ylim">ylim</code></td>
<td>
<p>overrules default y-limits on the plot of the profile
likelihood.
</p>
</td></tr>
<tr><td><code id="confint.clm2_+3A_...">...</code></td>
<td>

<p>additional argument(s) for methods including <code>range</code> (for the
hidden function <code>profileLambda</code>) that sets
the range of values of <code>lambda</code> at which the likelihood should
be profiled for this parameter.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These <code>confint</code> methods call
the appropriate profile method, then finds the
confidence intervals by interpolation of the profile traces.
If the profile object is already available, this should be used as the
main argument rather than the fitted model object itself.
</p>
<p>In <code>plot.profile.clm2</code>: at least one of <code>Log</code> and
<code>relative</code> arguments have to be <code>TRUE</code>.
</p>


<h3>Value</h3>

<p><code>confint</code>:
A matrix (or vector) with columns giving lower and upper confidence
limits for each parameter. These will be labelled as (1-level)/2 and
1 - (1-level)/2 in % (by default 2.5% and 97.5%).
The parameter names are preceded with <code>"loc."</code> or <code>"sca."</code>
to indicate whether the confidence interval applies to a location or a
scale parameter.
</p>
<p><code>plot.profile.clm2</code> invisibly returns the profile object.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+profile">profile</a></code> and <code><a href="stats.html#topic+confint">confint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))

## More manageable data set:
(tab26 &lt;- with(soup, table("Product" = PROD, "Response" = SURENESS)))
dimnames(tab26)[[2]] &lt;- c("Sure", "Not Sure", "Guess", "Guess", "Not Sure", "Sure")
dat26 &lt;- expand.grid(sureness = as.factor(1:6), prod = c("Ref", "Test"))
dat26$wghts &lt;- c(t(tab26))

m1 &lt;- clm2(sureness ~ prod, scale = ~prod, data = dat26,
          weights = wghts, link = "logistic")

## profile
pr1 &lt;- profile(m1)
par(mfrow = c(2, 2))
plot(pr1)

m9 &lt;- update(m1, link = "log-gamma")
pr9 &lt;- profile(m9, whichL = numeric(0), whichS = numeric(0))
par(mfrow = c(1, 1))
plot(pr9)

plot(pr9, Log=TRUE, relative = TRUE)
plot(pr9, Log=TRUE, relative = TRUE, ylim = c(-4, 0))
plot(pr9, Log=TRUE, relative = FALSE)

## confint
confint(pr9)
confint(pr1)

## Extend example from polr in package MASS:
## Fit model from polr example:
if(require(MASS)) {
    fm1 &lt;- clm2(Sat ~ Infl + Type + Cont, scale = ~ Cont, weights = Freq,
                data = housing)
    pr1 &lt;- profile(fm1)
    confint(pr1)
    par(mfrow=c(2,2))
    plot(pr1)
}

</code></pre>

<hr>
<h2 id='convergence'>Check convergence of cumulative link models</h2><span id='topic+convergence'></span><span id='topic+convergence.clm'></span><span id='topic+print.convergence.clm'></span>

<h3>Description</h3>

<p>Check the accuracy of the parameter estimates of cumulative link
models. The number of correct decimals and number of significant
digits is given for the maximum likelihood estimates of the parameters
in a cumulative link model fitted with <code><a href="#topic+clm">clm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
convergence(object, ...)

## S3 method for class 'clm'
convergence(object, digits = max(3, getOption("digits") - 3),
   tol = sqrt(.Machine$double.eps), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convergence_+3A_object">object</code></td>
<td>
<p>for the <code>clm</code> method an object of class
<code>"clm"</code>, i.e., the result of a call to <code>clm</code>.
</p>
</td></tr>
<tr><td><code id="convergence_+3A_digits">digits</code></td>
<td>
<p>the number of digits in the printed table.
</p>
</td></tr>
<tr><td><code id="convergence_+3A_tol">tol</code></td>
<td>
<p>numerical tolerence to judge if the Hessian is positive
definite from its smallest eigenvalue.
</p>
</td></tr>
<tr><td><code id="convergence_+3A_...">...</code></td>
<td>
<p>arguments to a from methods. Not used by the <code>clm</code> method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of correct decimals is defined as...
</p>
<p>The number of significant digits is defined as ...
</p>
<p>The number of correct decimals and the number of significant digits
are determined from the numerical errors in the parameter
estimates. The numerical errors are determined from the Method
Independent Error Theorem (Elden et al, 2004) and is based on the
Newton step evaluated at convergence.
</p>


<h3>Value</h3>

<p>Convergence information. In particular a table where the <code>Error</code>
column gives the numerical error in the parameter estimates. These
numbers express how far the parameter estimates in the fitted model
are from the true maximum likelihood estimates for this
model. The <code>Cor.Dec</code> gives the number of correct decimals with
which the the parameters are determined and the <code>Sig.Dig</code> gives
the number of significant digits with which the parameters are
determined.
</p>
<p>The number denoted <code>logLik.error</code> is the error in the value of
log-likelihood in the fitted model at the parameter values of that
fit. An accurate determination of the log-likelihood is essential for
accurate likelihood ratio tests in model comparison.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Elden, L., Wittmeyer-Koch, L. and Nielsen, H. B. (2004) <em>Introduction
to Numerical Computation &mdash; analysis and Matlab illustrations.</em>
Studentliteratur.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simple model:
fm1 &lt;- clm(rating ~ contact + temp, data=wine)
summary(fm1)
convergence(fm1)

</code></pre>

<hr>
<h2 id='drop.coef'>
Ensure Full Rank Design Matrix
</h2><span id='topic+drop.coef'></span>

<h3>Description</h3>

<p>Coefficients (columns) are dropped from a design matrix to ensure that
it has full rank.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop.coef(X, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drop.coef_+3A_x">X</code></td>
<td>

<p>a design matrix, e.g., the result of <code><a href="stats.html#topic+model.matrix">model.matrix</a></code>
possibly of less than full column rank, i.e., with redundant
parameters. Works for <code>ncol(X) &gt;= 0</code> and <code>nrow(X) &gt;= 0</code>.
</p>
</td></tr>
<tr><td><code id="drop.coef_+3A_silent">silent</code></td>
<td>

<p>should a message not be issued if X is column rank deficient?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Redundant columns of the design matrix are identified with the
LINPACK implementation of the <code><a href="Matrix.html#topic+qr">qr</a></code> decomposition and
removed. The returned design matrix will have <code>qr(X)$rank</code>
columns.
</p>


<h3>Value</h3>

<p>The design matrix <code>X</code> without redundant columns.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+qr">qr</a></code> and <code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- model.matrix( ~ PRODID * DAY, data = soup)
ncol(X)
newX &lt;- drop.coef(X)
ncol(newX)

## Essentially this is being computed:
qr.X &lt;- qr(X, tol = 1e-7, LAPACK = FALSE)
newX &lt;- X[, qr.X$pivot[1:qr.X$rank], drop = FALSE]
## is newX of full column rank?
ncol(newX) == qr(newX)$rank
## the number of columns being dropped:
ncol(X) - ncol(newX)

</code></pre>

<hr>
<h2 id='gfun'>
Gradients of common densities

</h2><span id='topic+gnorm'></span><span id='topic+glogis'></span><span id='topic+gcauchy'></span>

<h3>Description</h3>

<p>Gradients of common density functions in their standard forms, i.e.,
with zero location (mean) and unit scale. These are implemented in C
for speed and care is taken that the correct results are provided for
the argument being <code>NA</code>, <code>NaN</code>, <code>Inf</code>, <code>-Inf</code> or
just extremely small or large.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>
gnorm(x)

glogis(x)

gcauchy(x)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gfun_+3A_x">x</code></td>
<td>

<p>numeric vector of quantiles.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The gradients are given by:
</p>

<ul>
<li><p>gnorm: If <code class="reqn">f(x)</code> is the normal density with mean 0 and
spread 1, then the gradient is </p>
<p style="text-align: center;"><code class="reqn">f'(x) = -x f(x)</code>
</p>


</li>
<li><p>glogis: If <code class="reqn">f(x)</code> is the logistic density with mean 0 and
scale 1, then the gradient is
</p>
<p style="text-align: center;"><code class="reqn">f'(x) = 2 \exp(-x)^2 (1 + \exp(-x))^{-3} -
	\exp(-x)(1+\exp(-x))^{-2}</code>
</p>


</li>
<li><p>pcauchy: If
<code class="reqn">f(x) = [\pi(1 + x^2)^2]^{-1}</code>
is the cauchy density with mean 0 and scale 1, then the gradient
is
</p>
<p style="text-align: center;"><code class="reqn">f'(x) = -2x [\pi(1 + x^2)^2]^{-1}</code>
</p>


</li></ul>

<p>These gradients are used in the Newton-Raphson algorithms in fitting
cumulative link models with <code><a href="#topic+clm">clm</a></code> and cumulative link
mixed models with <code><a href="#topic+clmm">clmm</a></code>.
</p>


<h3>Value</h3>

<p>a numeric vector of gradients.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p>Gradients of densities are also implemented for the extreme value
distribtion (<code><a href="#topic+dgumbel">gumbel</a></code>) and the the log-gamma distribution
(<code><a href="base.html#topic+lgamma">log-gamma</a></code>). 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- -5:5
gnorm(x)
glogis(x)
gcauchy(x)

</code></pre>

<hr>
<h2 id='gumbel'>
The Gumbel Distribution

</h2><span id='topic+dgumbel'></span><span id='topic+pgumbel'></span><span id='topic+qgumbel'></span><span id='topic+rgumbel'></span><span id='topic+ggumbel'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function, random generation,
and gradient of density of the extreme 
value (maximum and minimum) distributions. The Gumbel distribution is
also known as the extreme value maximum distribution, the
double-exponential distribution and the log-Weibull distribution. 

</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dgumbel(x, location = 0, scale = 1, log = FALSE, max = TRUE)

pgumbel(q, location = 0, scale = 1, lower.tail = TRUE, max = TRUE)

qgumbel(p, location = 0, scale = 1, lower.tail = TRUE, max = TRUE)

rgumbel(n, location = 0, scale = 1, max = TRUE)

ggumbel(x, max = TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gumbel_+3A_x">x</code>, <code id="gumbel_+3A_q">q</code></td>
<td>

<p>numeric vector of quantiles.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_p">p</code></td>
<td>

<p>vector of probabilities.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_n">n</code></td>
<td>

<p>number of observations.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_location">location</code></td>
<td>

<p>numeric scalar.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_scale">scale</code></td>
<td>

<p>numeric scalar.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_lower.tail">lower.tail</code></td>
<td>

<p>logical; if <code>TRUE</code> (default), probabilities are
<code class="reqn">P[X \leq x]</code> otherwise, <code class="reqn">P[X &gt; x]</code>.
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_log">log</code></td>
<td>

<p>logical; if <code>TRUE</code>, probabilities p are given as log(p).
</p>
</td></tr>
<tr><td><code id="gumbel_+3A_max">max</code></td>
<td>

<p>distribution for extreme maxima (default) or minima? The default
corresponds to the standard right-skew Gumbel distribution.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dgumbel</code>, <code>pgumbel</code> and <code>ggumbel</code> are implemented in C
for speed and care is taken that 'correct' results are provided for
values of <code>NA</code>, <code>NaN</code>, <code>Inf</code>, <code>-Inf</code> or just
extremely small or large. 
</p>
<p>The distribution functions, densities and gradients are used in the
Newton-Raphson algorithms in fitting cumulative link models with
<code><a href="#topic+clm">clm</a></code> and cumulative link mixed models with
<code><a href="#topic+clmm">clmm</a></code>. 
</p>


<h3>Value</h3>

<p><code>pgumbel</code> gives the distribution function, <code>dgumbel</code>
gives the density, <code>ggumbel</code> gives the gradient of the
density, <code>qgumbel</code> is the quantile function, and
<code>rgumbel</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/Gumbel_distribution">https://en.wikipedia.org/wiki/Gumbel_distribution</a>
</p>


<h3>See Also</h3>

<p>Gradients of densities are also implemented for the normal, logistic, 
cauchy, cf. <code><a href="#topic+gnorm">gfun</a></code> and the log-gamma distribution,
cf. <code><a href="base.html#topic+lgamma">lgamma</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Illustrating the symmetry of the distribution functions:
pgumbel(5) == 1 - pgumbel(-5, max=FALSE) ## TRUE
dgumbel(5) == dgumbel(-5, max=FALSE) ## TRUE
ggumbel(5) == -ggumbel(-5, max=FALSE) ## TRUE

## More examples:
x &lt;- -5:5

(pp &lt;- pgumbel(x))
qgumbel(pp)
dgumbel(x)
ggumbel(x)

(ppp &lt;- pgumbel(x, max=FALSE))
## Observe that probabilities close to 0 are more accurately determined than 
## probabilities close to 1:
qgumbel(ppp, max=FALSE)
dgumbel(x, max=FALSE)
ggumbel(x, max=FALSE)

## random deviates:
set.seed(1)
(r1 &lt;- rgumbel(10))
set.seed(1)
r2 &lt;- -rgumbel(10, max = FALSE)
all(r1 == r2) ## TRUE

</code></pre>

<hr>
<h2 id='income'>
Income distribution (percentages) in the Northeast US
</h2><span id='topic+income'></span>

<h3>Description</h3>

<p>Income distribution (percentages) in the Northeast US in 1960 and 1970
adopted from McCullagh (1980).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>income
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>year</code></dt><dd>
<p>year.
</p>
</dd>
<dt><code>pct</code></dt><dd>
<p>percentage of population in income class per year.
</p>
</dd>
<dt><code>income</code></dt><dd>
<p>income groups. The unit is thousands of constant (1973) US dollars.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data are adopted from McCullagh (1980).
</p>


<h3>References</h3>

<p>McCullagh, P. (1980) Regression Models for Ordinal Data. <em>Journal
of the Royal Statistical Society. Series B (Methodological)</em>,
Vol. 42, No. 2., pp. 109-142.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
print(income)

## Convenient table:
(tab &lt;- xtabs(pct ~ year + income, income))

## small rounding error in 1970:
rowSums(tab)

## compare link functions via the log-likelihood:
links &lt;- c("logit", "probit", "cloglog", "loglog", "cauchit")
sapply(links, function(link) {
  clm(income ~ year, data=income, weights=pct, link=link)$logLik })
## a heavy tailed (cauchy) or left skew (cloglog) latent distribution
## is fitting best.

## The data are defined as:
income.levels &lt;- c(0, 3, 5, 7, 10, 12, 15)
income &lt;- paste(income.levels, c(rep("-", 6), "+"),
                c(income.levels[-1], ""), sep = "")
income &lt;-
  data.frame(year=factor(rep(c("1960", "1970"), each = 7)),
             pct = c(6.5, 8.2, 11.3, 23.5, 15.6, 12.7, 22.2,
               4.3, 6, 7.7, 13.2, 10.5, 16.3, 42.1),
             income=factor(rep(income, 2), ordered=TRUE,
               levels=income))

</code></pre>

<hr>
<h2 id='lgamma'>
The log-gamma distribution

</h2><span id='topic+plgamma'></span><span id='topic+dlgamma'></span><span id='topic+glgamma'></span>

<h3>Description</h3>

<p>Density, distribution function and gradient of density for the
log-gamma distribution. 
These are implemented in C
for speed and care is taken that the correct results are provided for
values of <code>NA</code>, <code>NaN</code>, <code>Inf</code>, <code>-Inf</code> or just
extremely small or large values.
</p>
<p>The log-gamma is a flexible location-scale distribution on the real
line with an extra parameter, <code class="reqn">\lambda</code>. For <code class="reqn">\lambda = 0</code> the
distribution equals the normal or Gaussian distribution, and for
<code class="reqn">\lambda</code> equal to 1 and -1, the Gumbel minimum and maximum
distributions are obtained.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>
plgamma(q, lambda, lower.tail = TRUE)

dlgamma(x, lambda, log = FALSE)

glgamma(x, lambda)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lgamma_+3A_x">x</code>, <code id="lgamma_+3A_q">q</code></td>
<td>

<p>numeric vector of quantiles.
</p>
</td></tr>
<tr><td><code id="lgamma_+3A_lambda">lambda</code></td>
<td>

<p>numerical scalar
</p>
</td></tr>






<tr><td><code id="lgamma_+3A_lower.tail">lower.tail</code></td>
<td>

<p>logical; if <code>TRUE</code> (default), probabilities are
<code class="reqn">P[X \leq x]</code> otherwise, <code class="reqn">P[X &gt; x]</code>.
</p>
</td></tr>
<tr><td><code id="lgamma_+3A_log">log</code></td>
<td>

<p>logical; if <code>TRUE</code>, probabilities p are given as log(p).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code class="reqn">\lambda &lt; 0</code> the distribution is right skew, if
<code class="reqn">\lambda = 0</code> the distribution is symmetric (and equals the normal
distribution), and if <code class="reqn">\lambda &gt; 0</code> the distribution is left
skew.




</p>
<p>These distribution functions, densities and gradients are used in the
Newton-Raphson algorithms in fitting cumulative link models with
<code><a href="#topic+clm2">clm2</a></code> and cumulative link mixed models with
<code><a href="#topic+clmm2">clmm2</a></code> using the log-gamma link. 
</p>


<h3>Value</h3>

<p><code>plgamma</code> gives the distribution function, <code>dlgamma</code>
gives the density and <code>glgamma</code> gives the gradient of the
density. 
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>References</h3>

<p>Genter, F. C. and Farewell, V. T. (1985) Goodness-of-link testing in
ordinal regression models. <em>The Canadian Journal of Statistics</em>,
13(1), 37-44.
</p>


<h3>See Also</h3>

<p>Gradients of densities are also implemented for the normal, logistic, 
cauchy, cf. <code><a href="#topic+gnorm">gfun</a></code> and the Gumbel distribution,
cf. <code><a href="#topic+dgumbel">gumbel</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Illustrating the link to other distribution functions: 
x &lt;- -5:5
plgamma(x, lambda = 0) == pnorm(x)
all.equal(plgamma(x, lambda = -1), pgumbel(x)) ## TRUE, but:
plgamma(x, lambda = -1) == pgumbel(x)
plgamma(x, lambda = 1) == pgumbel(x, max = FALSE)

dlgamma(x, lambda = 0) == dnorm(x)
dlgamma(x, lambda = -1) == dgumbel(x)
dlgamma(x, lambda = 1) == dgumbel(x, max = FALSE)

glgamma(x, lambda = 0) == gnorm(x)
all.equal(glgamma(x, lambda = -1), ggumbel(x)) ## TRUE, but:
glgamma(x, lambda = -1) == ggumbel(x)
all.equal(glgamma(x, lambda = 1), ggumbel(x, max = FALSE)) ## TRUE, but:
glgamma(x, lambda = 1) == ggumbel(x, max = FALSE)
## There is a loss of accuracy, but the difference is very small: 
glgamma(x, lambda = 1) - ggumbel(x, max = FALSE)

## More examples:
x &lt;- -5:5
plgamma(x, lambda = .5)
dlgamma(x, lambda = .5)
glgamma(x, lambda = .5)

</code></pre>

<hr>
<h2 id='nominal_test'>
Likelihood ratio tests of model terms in scale and nominal formulae
</h2><span id='topic+nominal_test'></span><span id='topic+scale_test'></span><span id='topic+nominal_test.clm'></span><span id='topic+scale_test.clm'></span>

<h3>Description</h3>

<p>Add all model terms to scale and nominal formulae and perform
likelihood ratio tests. These tests can be viewed as goodness-of-fit
tests. With the logit link, <code>nominal_test</code> provides likelihood
ratio tests of the proportional odds assumption. The <code>scale_test</code>
tests can be given a similar interpretation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nominal_test(object, ...)

## S3 method for class 'clm'
nominal_test(object, scope, trace=FALSE, ...)

scale_test(object, ...)

## S3 method for class 'clm'
scale_test(object, scope, trace=FALSE, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nominal_test_+3A_object">object</code></td>
<td>
<p>for the <code>clm</code> method an object of class
<code>"clm"</code>, i.e., the result of a call to <code>clm</code>.
</p>
</td></tr>
<tr><td><code id="nominal_test_+3A_scope">scope</code></td>
<td>

<p>a formula or character vector specifying the terms to add to scale
or nominal. In <code>nominal_test</code> terms in scope already in
<code>nominal</code> are ignored. In <code>scale_test</code> terms in scope
already in <code>scale</code> are ignored.
</p>
<p>In <code>nominal_test</code> the default is to add all terms
from <code>formula</code> (location part) and <code>scale</code> that are not
also in <code>nominal</code>.
</p>
<p>In <code>scale_test</code> the default is to add
all terms from <code>formula</code> (location part) that are not also in
<code>scale</code>.
</p>
</td></tr>
<tr><td><code id="nominal_test_+3A_trace">trace</code></td>
<td>

<p>if <code>TRUE</code> additional information may be given on the fits as
they are tried.
</p>
</td></tr>
<tr><td><code id="nominal_test_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The definition of AIC is only up to an additive constant because the
likelihood function is only defined up to an additive constant.
</p>


<h3>Value</h3>

<p>A table of class <code>"anova"</code> containing columns for the change
in degrees of freedom, AIC, the likelihood ratio statistic and a
p-value based on the asymptotic chi-square distribtion of the
likelihood ratio statistic under the null hypothesis.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Fit cumulative link model:
fm &lt;- clm(rating ~ temp + contact, data=wine)
summary(fm)
## test partial proportional odds assumption for temp and contact:
nominal_test(fm)
## no evidence of non-proportional odds.
## test if there are signs of scale effects:
scale_test(fm)
## no evidence of scale effects.

## tests of scale and nominal effects for the housing data from MASS:
if(require(MASS)) {
    fm1 &lt;- clm(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
    scale_test(fm1)
    nominal_test(fm1)
    ## Evidence of multiplicative/scale effect of 'Cont'. This is a breach
    ## of the proportional odds assumption.
}

</code></pre>

<hr>
<h2 id='ordinal-package'>
Regression Models for Ordinal Data via Cumulative Link (Mixed) Models
</h2><span id='topic+ordinal-package'></span><span id='topic+ordinal'></span>

<h3>Description</h3>

<p>This package facilitates analysis of ordinal (ordered categorical
data) via cumulative link models (CLMs) and cumulative link mixed
models (CLMMs). Robust and efficient computational methods gives
speedy and accurate estimation. A wide range of methods for model fits
aids the data analysis.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> ordinal</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>This package implements cumualtive link models and cumulative link
models with normally distributed random effects, denoted cumulative link
mixed (effects) models. Cumulative link models are also known as ordered
regression models, proportional odds models, proportional hazards models
for grouped survival times and ordered logit/probit/... models.
</p>
<p>Cumulative link models are fitted with <code><a href="#topic+clm">clm</a></code> and the main
features are:
</p>

<ul>
<li><p>A range of standard link functions are available.
</p>
</li>
<li><p>In addition to the standard location (additive) effects, scale
(multiplicative) effects are also allowed.
</p>
</li>
<li><p>nominal effects are allowed for any subset of the predictors &mdash;
these effects are also known as partial proportional odds effects
when using the logit link.
</p>
</li>
<li><p>Restrictions can be imposed on the thresholds/cut-points, e.g.,
symmetry or equidistance.
</p>
</li>
<li><p>A (modified) Newton-Raphson algorithm provides the maximum
likelihood estimates of the parameters. The estimation scheme is robust,
fast and accurate.
</p>
</li>
<li><p>Rank-deficient designs are identified and unidentified
coefficients exposed in <code>print</code> and <code>summary</code> methods as
with <code><a href="stats.html#topic+glm">glm</a></code>.
</p>
</li>
<li><p>A suite of standard methods are available including <code>anova</code>,
<code>add</code>/<code>drop</code>-methods, <code>step</code>, <code>profile</code>,
<code>confint</code>.
</p>
</li>
<li><p>A <code>slice</code> method facilitates illustration of
the likelihood function and a <code>convergence</code> method summarizes
the accuracy of the model estimation.
</p>
</li>
<li><p>The <code>predict</code> method can predict probabilities, response
class-predictions and cumulative probabilities, and it provides
standard errors and confidence intervals for the predictions.
</p>
</li></ul>

<p>Cumulative link mixed models are fitted with <code><a href="#topic+clmm">clmm</a></code> and the
main features are:
</p>

<ul>
<li><p>Any number of random effect terms can be included.
</p>
</li>
<li><p>The syntax for the model formula resembles that of <code><a href="lme4.html#topic+lmer">lmer</a></code> from the <code>lme4</code> package.
</p>
</li>
<li><p>Nested random effects, crossed random effects and partially
nested/crossed random effects are allowed.
</p>
</li>
<li><p>Estimation is via maximum likelihood using the Laplace
approximation or adaptive Gauss-Hermite quadrature (one random
effect).
</p>
</li>
<li><p>Vector-valued and correlated random effects such as random
slopes (random coefficient models) are fitted with the Laplace
approximation.
</p>
</li>
<li><p>Estimation employs sparse matrix methods from the
<code><a href="Matrix.html#topic+Matrix">Matrix</a></code> package. 
</p>
</li>
<li><p>During model fitting a Newton-Raphson algorithm updates the
conditional modes of the random effects a large number of times. The
likelihood function is optimized with a general purpose optimizer.
</p>
</li></ul>

<p>A major update of the package in August 2011 introduced new and improved
implementations of <code><a href="#topic+clm">clm</a></code> and <code><a href="#topic+clmm">clmm</a></code>. The old
implementations are available with <code><a href="#topic+clm2">clm2</a></code> and
<code><a href="#topic+clmm2">clmm2</a></code>. At the time of writing there is functionality in
<code>clm2</code> and <code>clmm2</code> not yet available in <code>clm</code> and
<code>clmm</code>. This includes flexible link functions (log-gamma and
Aranda-Ordaz links) and a profile method for random effect variance
parameters in CLMMs. The new implementations are expected to take over
the old implementations at some point, hence the latter will eventually
be <code><a href="base.html#topic+.Deprecated">deprecated</a></code> and
<code><a href="base.html#topic+.Defunct">defunct</a></code>.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>
<p>Maintainer: Rune Haubo B Christensen &lt;rune.haubo@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## A simple cumulative link model:
fm1 &lt;- clm(rating ~ contact + temp, data=wine)
summary(fm1)

## A simple cumulative link mixed model:
fmm1 &lt;- clmm(rating ~ contact + temp + (1|judge), data=wine)
summary(fmm1)

</code></pre>

<hr>
<h2 id='predict.clm'>Predict Method for CLM fits</h2><span id='topic+predict.clm'></span>

<h3>Description</h3>

<p>Obtains predictions from a cumulative link model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'clm'
predict(object, newdata, se.fit = FALSE, interval = FALSE,
           level = 0.95,
           type = c("prob", "class", "cum.prob", "linear.predictor"),
           na.action = na.pass, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.clm_+3A_object">object</code></td>
<td>
<p>a fitted object of class inheriting from
<code>clm</code>.</p>
</td></tr>
<tr><td><code id="predict.clm_+3A_newdata">newdata</code></td>
<td>
<p>optionally, a data frame in which to look for variables
with which to predict. Note that all predictor variables should be
present having the same names as the variables used to fit the
model. If the response variable is present in <code>newdata</code>
predictions are obtained for the levels of the response as given by
<code>newdata</code>. If the response variable is omitted from
<code>newdata</code> predictions are obtained for all levels of the
response variable for each of the rows of <code>newdata</code>.
</p>
</td></tr>
<tr><td><code id="predict.clm_+3A_se.fit">se.fit</code></td>
<td>
<p>should standard errors of the predictions be provided?
Not applicable and ignored when <code>type = "class"</code>.
</p>
</td></tr>
<tr><td><code id="predict.clm_+3A_interval">interval</code></td>
<td>
<p>should confidence intervals for the predictions be
provided?  Not applicable and ignored when <code>type = "class"</code>.
</p>
</td></tr>
<tr><td><code id="predict.clm_+3A_level">level</code></td>
<td>
<p>the confidence level.
</p>
</td></tr>
<tr><td><code id="predict.clm_+3A_type">type</code></td>
<td>
<p>the type of predictions. <code>"prob"</code> gives
probabilities, <code>"class"</code> gives predicted response class
membership defined as highest probability prediction,
<code>"cum.prob"</code> gives cumulative probabilities (see details)
and <code>"linear.predictor"</code> gives predictions on the scale of the
linear predictor including the boundary categories.
</p>
</td></tr>
<tr><td><code id="predict.clm_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values in <code>newdata</code>. The default is to predict <code>NA</code>.
</p>
</td></tr>
<tr><td><code id="predict.clm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>newdata</code> is omitted and <code>type = "prob"</code> a vector of
fitted probabilities are returned identical to the result from
<code>fitted</code>.
</p>
<p>If <code>newdata</code> is supplied and the response
variable is omitted, then predictions, standard errors and intervals
are matrices rather than vectors with the same number of rows as
<code>newdata</code> and with one column for each response class. If
<code>type = "class"</code> predictions are always a vector.
</p>
<p>If <code>newdata</code> is omitted, the way missing values in the original fit are handled
is determined by the <code>na.action</code> argument of that fit. If
<code>na.action = na.omit</code> omitted cases will not appear in the
residuals, whereas if <code>na.action = na.exclude</code>
they will appear (in predictions, standard
errors or interval limits), with residual value <code>NA</code>. See also
<code><a href="stats.html#topic+napredict">napredict</a></code>.
</p>
<p>If <code>type = "cum.prob"</code> or <code>type = "linear.predictor"</code> there
will be two sets of predictions, standard errors and intervals; one
for j and one for j-1 (in the usual notation) where j = 1, ..., J index
the response classes.
</p>
<p>If newdata is supplied and the response variable is omitted, then
<code>predict.clm</code> returns much the same thing as <code>predict.polr</code>
(matrices of predictions). Similarly, if <code>type = "class"</code>.
</p>
<p>If the fit is rank-deficient, some of the columns of the design matrix
will have been dropped. Prediction from such a fit only makes sense if
newdata is contained in the same subspace as the original data. That
cannot be checked accurately, so a warning is issued
(cf. <code><a href="stats.html#topic+predict.lm">predict.lm</a></code>).
</p>
<p>If a flexible link function is used (<code>Aranda-Ordaz</code> or <code>log-gamma</code>)
standard errors and confidence intervals of predictions do not take the
uncertainty in the link-parameter into account. 
</p>


<h3>Value</h3>

<p>A list containing the following components
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>predictions or fitted values if <code>newdata</code> is not
supplied.
</p>
</td></tr>
<tr><td><code>se.fit</code></td>
<td>
<p>if <code>se.fit=TRUE</code> standard errors of the predictions
otherwise <code>NULL</code>.
</p>
</td></tr>
<tr><td><code>upr</code>, <code>lwr</code></td>
<td>
<p>if <code>interval=TRUE</code> lower and upper confidence
limits.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm">clm</a></code>, <code><a href="#topic+clmm">clmm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## simple model:
fm1 &lt;- clm(rating ~ contact + temp, data=wine)
summary(fm1)

## Fitted values with standard errors and confidence intervals:
predict(fm1, se.fit=TRUE, interval=TRUE) # type="prob"
## class predictions for the observations:
predict(fm1, type="class")

newData &lt;- expand.grid(temp = c("cold", "warm"),
                       contact = c("no", "yes"))

## Predicted probabilities in all five response categories for each of
## the four cases in newData:
predict(fm1, newdata=newData, type="prob")
## now include standard errors and intervals:
predict(fm1, newdata=newData, se.fit=TRUE, interval=TRUE, type="prob")


</code></pre>

<hr>
<h2 id='predict.clm2'>Predict Method for CLM fits</h2><span id='topic+predict.clm2'></span><span id='topic+predict.clmm2'></span>

<h3>Description</h3>

<p>Obtains predictions from a cumulative link (mixed) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clm2'
predict(object, newdata, ...)


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.clm2_+3A_object">object</code></td>
<td>
<p>a fitted object of class inheriting from
<code>clm2</code> including <code>clmm2</code> objects.</p>
</td></tr>
<tr><td><code id="predict.clm2_+3A_newdata">newdata</code></td>
<td>
<p>optionally, a data frame in which to look for variables
with which to predict. Observe that the response variable should
also be present.</p>
</td></tr>
<tr><td><code id="predict.clm2_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method does not duplicate the behavior of
<code>predict.polr</code> in package <code>MASS</code> which produces a
matrix instead of a vector of predictions. The behavior of
<code>predict.polr</code> can be mimiced as shown in the examples.
</p>
<p>If <code>newdata</code> is not supplied, the fitted values are obtained. For
<code>clmm2</code> fits this means predictions that are controlled for the
observed value of the random effects. If the predictions for a
random effect of zero, i.e. an average 'subject', are wanted, the same
data used to fit the model should be supplied in the <code>newdata</code>
argument. For <code>clm2</code> fits those two sets of predictions are
identical.
</p>


<h3>Value</h3>

<p>A vector of predicted probabilities.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm2">clm2</a></code>, <code><a href="#topic+clmm2">clmm2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))

## More manageable data set for less voluminous printing:
(tab26 &lt;- with(soup, table("Product" = PROD, "Response" = SURENESS)))
dimnames(tab26)[[2]] &lt;- c("Sure", "Not Sure", "Guess", "Guess", "Not Sure", "Sure")
dat26 &lt;- expand.grid(sureness = as.factor(1:6), prod = c("Ref", "Test"))
dat26$wghts &lt;- c(t(tab26))
dat26

m1 &lt;- clm2(sureness ~ prod, scale = ~prod, data = dat26,
          weights = wghts, link = "logistic")
predict(m1)

mN1 &lt;-  clm2(sureness ~ 1, nominal = ~prod, data = dat26,
            weights = wghts)
predict(mN1)

predict(update(m1, scale = ~.-prod))


#################################
## Mimicing the behavior of predict.polr:
if(require(MASS)) {
    ## Fit model from polr example:
    fm1 &lt;- clm2(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
    predict(fm1)

    set.seed(123)
    nlev &lt;- 3
    y &lt;- gl(nlev, 5)
    x &lt;- as.numeric(y) + rnorm(15)
    fm.clm &lt;- clm2(y ~ x)
    fm.polr &lt;- polr(y ~ x)

    ## The equivalent of predict.polr(object, type = "probs"):
    (pmat.polr &lt;- predict(fm.polr, type = "probs"))
    ndat &lt;- expand.grid(y = gl(nlev,1), x = x)
    (pmat.clm &lt;- matrix(predict(fm.clm, newdata = ndat), ncol=nlev,
                        byrow = TRUE))
    all.equal(c(pmat.clm), c(pmat.polr), tol = 1e-5) # TRUE

    ## The equivalent of predict.polr(object, type = "class"):
    (class.polr &lt;- predict(fm.polr))
    (class.clm &lt;- factor(apply(pmat.clm, 1, which.max)))
    all.equal(class.clm, class.polr) ## TRUE
}

</code></pre>

<hr>
<h2 id='profile.clmm2'>
Confidence intervals and profile likelihoods for the standard
deviation for the random term in cumulative link mixed models
</h2><span id='topic+profile.clmm2'></span><span id='topic+confint.clmm2'></span><span id='topic+confint.profile.clmm2'></span><span id='topic+profile.clmm2'></span><span id='topic+plot.profile.clmm2'></span>

<h3>Description</h3>

<p>Computes confidence intervals from the profiled likelihood for
the standard devation for the random term in a fitted cumulative link
mixed model, or plots the associated profile likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'profile.clmm2'
confint(object, parm = seq_along(Pnames), level = 0.95, ...)

## S3 method for class 'clmm2'
profile(fitted, alpha = 0.01, range, nSteps = 20, trace = 1, ...)

## S3 method for class 'profile.clmm2'
plot(x, parm = seq_along(Pnames), level = c(0.95, 0.99),
        Log = FALSE, relative = TRUE, fig = TRUE, n = 1e3, ..., ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="profile.clmm2_+3A_object">object</code></td>
<td>

<p>a fitted <code>profile.clmm2</code> object.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_fitted">fitted</code></td>
<td>

<p>a fitted <code><a href="#topic+clmm2">clmm2</a></code> object.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_x">x</code></td>
<td>
<p>a <code>profile.clmm2</code> object.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_parm">parm</code></td>
<td>

<p>For <code>confint.profile.clmm2</code>:
a specification of which parameters are to be given confidence
intervals, either a vector of numbers or a vector of names. If
missing, all parameters are considered.
Currently only <code>"stDev"</code> or <code>1</code> are supported.
</p>
<p>For <code>plot.profile.clmm2</code>:
a specification of which parameters the profile likelihood are to be
plotted for, either a vector of numbers or a vector of names. If
missing, all parameters are considered.
Currently only <code>"stDev"</code> or <code>1</code> are supported.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_level">level</code></td>
<td>

<p>the confidence level required. Observe that the model has to be
profiled in the appropriate region; otherwise the limits are
<code>NA</code>.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_trace">trace</code></td>
<td>

<p>logical. Should profiling be traced? Defaults to <code>TRUE</code> due to
the time consuming nature of the computation.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_alpha">alpha</code></td>
<td>
<p>Determines the range of profiling. By default the
likelihood is profiled approximately in the 99% confidence interval
region as determined by the Wald approximation. This is usually
sufficient for 95% profile likelihood confidence limits.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_range">range</code></td>
<td>
<p>if range is specified, this overrules the range
computation based on <code>alpha</code>. <code>range</code> should be all
positive and <code>stDev</code> is profiled in <code>range(range)</code>.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_nsteps">nSteps</code></td>
<td>
<p>the number of points at which to profile the likelihood
function. This determines the resolution and accuracy of the profile
likelihood function; higher values gives a higher resolution, but
also longer computation times.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_log">Log</code></td>
<td>
<p>should the profile likelihood be plotted on the log-scale?
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_relative">relative</code></td>
<td>
<p>should the relative or the absolute likelihood be
plotted?
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_fig">fig</code></td>
<td>
<p>should the profile likelihood be plotted?
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_n">n</code></td>
<td>
<p>the no. points used in the spline interpolation of the
profile likelihood for plotting.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_ylim">ylim</code></td>
<td>
<p>overrules default y-limits on the plot of the profile
likelihood.
</p>
</td></tr>
<tr><td><code id="profile.clmm2_+3A_...">...</code></td>
<td>

<p>additional argument(s), e.g. graphical parameters for the
<code>plot</code> method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>confint.clmm2</code> method deliberately does not exist due to the
time consuming nature of the computations. The user is required to
compute the profile object first and then call <code>confint</code> on the
profile object to obtain profile likelihood confidence intervals.
</p>
<p>In <code>plot.profile.clm2</code>: at least one of <code>Log</code> and
<code>relative</code> arguments have to be <code>TRUE</code>.
</p>


<h3>Value</h3>

<p><code>confint</code>:
A matrix with columns giving lower and upper confidence
limits. These will be labelled as (1-level)/2 and
1 - (1-level)/2 in % (by default 2.5% and 97.5%).
</p>
<p><code>plot.profile.clm2</code> invisibly returns the profile object.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+profile">profile</a></code> and <code><a href="stats.html#topic+confint">confint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))

if(require(lme4)) { ## access cbpp data
    cbpp2 &lt;- rbind(cbpp[,-(2:3)], cbpp[,-(2:3)])
    cbpp2 &lt;- within(cbpp2, {
        incidence &lt;- as.factor(rep(0:1, each=nrow(cbpp)))
        freq &lt;- with(cbpp, c(incidence, size - incidence))
    })

    ## Fit with Laplace approximation:
    fm1 &lt;- clmm2(incidence ~ period, random = herd, weights = freq,
                 data = cbpp2, Hess = 1)

    pr.fm1 &lt;- profile(fm1)
    confint(pr.fm1)

    par(mfrow = c(2,2))
    plot(pr.fm1)
    plot(pr.fm1, Log=TRUE, relative = TRUE)
    plot(pr.fm1, Log=TRUE, relative = FALSE)
}

</code></pre>

<hr>
<h2 id='slice'>
Slice the likelihood of a clm
</h2><span id='topic+slice'></span><span id='topic+slice.clm'></span><span id='topic+plot.slice.clm'></span>

<h3>Description</h3>

<p>Slice likelihood and plot the slice. This is usefull for illustrating
the likelihood surface around the MLE (maximum likelihood estimate)
and provides graphics to substantiate (non-)convergence of a model
fit. Also, the closeness of a quadratic approximation to the
log-likelihood function can be inspected for relevant parameters. A
slice is considerably less computationally demanding than a profile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slice(object, ...)

## S3 method for class 'clm'
slice(object, parm = seq_along(par), lambda = 3,
     grid = 100, quad.approx = TRUE, ...)

## S3 method for class 'slice.clm'
plot(x, parm = seq_along(x),
    type = c("quadratic", "linear"), plot.mle = TRUE,
    ask = prod(par("mfcol")) &lt; length(parm) &amp;&amp; dev.interactive(), ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="slice_+3A_object">object</code></td>
<td>
<p>for the <code>clm</code> method an object of class
<code>"clm"</code>, i.e., the result of a call to <code>clm</code>.
</p>
</td></tr>
<tr><td><code id="slice_+3A_x">x</code></td>
<td>

<p>a <code>slice.clm</code> object, i.e., the result of
<code>slice(clm.object)</code>.
</p>
</td></tr>
<tr><td><code id="slice_+3A_parm">parm</code></td>
<td>

<p>for <code>slice.clm</code> a numeric or character vector indexing
parameters, for <code>plot.slice.clm</code> only a numeric vector is
accepted. By default all parameters are selected.
</p>
</td></tr>
<tr><td><code id="slice_+3A_lambda">lambda</code></td>
<td>

<p>the number of curvature units on each side of the MLE the slice
should cover.
</p>
</td></tr>
<tr><td><code id="slice_+3A_grid">grid</code></td>
<td>

<p>the number of values at which to compute the log-likelihood for each
parameter.
</p>
</td></tr>
<tr><td><code id="slice_+3A_quad.approx">quad.approx</code></td>
<td>

<p>compute and include the quadratic approximation to the
log-likelihood function?
</p>
</td></tr>
<tr><td><code id="slice_+3A_type">type</code></td>
<td>

<p><code>"quadratic"</code> plots the log-likelihood function which is
approximately quadratic, and <code>"linear"</code> plots the
signed square root of the log-likelihood function which is
approximately linear.
</p>
</td></tr>
<tr><td><code id="slice_+3A_plot.mle">plot.mle</code></td>
<td>

<p>include a vertical line at the MLE (maximum likelihood estimate)
when <code>type = "quadratic"</code>? Ignored for <code>type = "linear"</code>.
</p>
</td></tr>
<tr><td><code id="slice_+3A_ask">ask</code></td>
<td>

<p>logical; if <code>TRUE</code>, the user is asked before each plot, see
<code><a href="graphics.html#topic+par">par</a></code><code>(ask=.)</code>.
</p>
</td></tr>
<tr><td><code id="slice_+3A_...">...</code></td>
<td>

<p>further arguments to <code>plot.default</code> for the plot method. Not
used in the slice method.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>slice</code> method returns a list of <code>data.frame</code>s with one
<code>data.frame</code> for each parameter slice. Each <code>data.frame</code>
contains in the first column the values of the parameter and in the
second column the values of the (positive) log-likelihood
<code>"logLik"</code>. A third column is present if <code>quad.approx = TRUE</code>
and contains the corresponding quadratic approximation to the
log-likelihood. The original model fit is included as the attribute
<code>"original.fit"</code>.
</p>
<p>The <code>plot</code> method produces a plot of the likelihood slice for
each parameter.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## fit model:
fm1 &lt;- clm(rating ~ contact + temp, data = wine)
## slice the likelihood:
sl1 &lt;- slice(fm1)

## three different ways to plot the slices:
par(mfrow = c(2,3))
plot(sl1)
plot(sl1, type = "quadratic", plot.mle = FALSE)
plot(sl1, type = "linear")

## Verify convergence to the optimum:
sl2 &lt;- slice(fm1, lambda = 1e-5, quad.approx = FALSE)
plot(sl2)

</code></pre>

<hr>
<h2 id='soup'>
Discrimination study of packet soup
</h2><span id='topic+soup'></span>

<h3>Description</h3>

<p>The <code>soup</code> data frame has 1847 rows and 13 variables. 185
respondents participated in an A-not A discrimination test with
sureness. Before experimentation the respondents were familiarized
with the reference product and during experimentation, the respondents
were asked to rate samples on an ordered scale with six categories
given by combinations of (reference, not reference) and (sure, not
sure, guess) from 'referene, sure' = 1 to 'not reference, sure' = 6.

</p>


<h3>Usage</h3>

<pre><code class='language-R'>soup
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>RESP</code></dt><dd>
<p>factor with 185 levels: the respondents in the study.
</p>
</dd>
<dt><code>PROD</code></dt><dd>
<p>factor with 2 levels: index reference and test products.
</p>
</dd>
<dt><code>PRODID</code></dt><dd>
<p>factor with 6 levels: index reference and the five test product
variants.
</p>
</dd>
<dt><code>SURENESS</code></dt><dd>
<p>ordered factor with 6 levels: the respondents ratings of soup
samples.
</p>
</dd>
<dt><code>DAY</code></dt><dd>
<p>factor with two levels: experimentation was split over two days.
</p>
</dd>
<dt><code>SOUPTYPE</code></dt><dd>
<p>factor with three levels: the type of soup regularly consumed by the
respondent.
</p>
</dd>
<dt><code>SOUPFREQ</code></dt><dd>
<p>factor with 3 levels: the frequency with which the respondent
consumes soup.
</p>
</dd>
<dt><code>COLD</code></dt><dd>
<p>factor with two levels: does the respondent have a cold?
</p>
</dd>
<dt><code>EASY</code></dt><dd>
<p>factor with ten levels: How easy did the respondent find the
discrimation test? 1 = difficult, 10 = easy.
</p>
</dd>
<dt><code>GENDER</code></dt><dd>
<p>factor with two levels: gender of the respondent.
</p>
</dd>
<dt><code>AGEGROUP</code></dt><dd>
<p>factor with four levels: the age of the respondent.
</p>
</dd>
<dt><code>LOCATION</code></dt><dd>
<p>factor with three levels: three different locations where
experimentation took place. 
</p>
</dd>




</dl>


<h3>Source</h3>

<p>Data are produced by Unilever Research. Permission to publish
the data is granted. 
</p>


<h3>References</h3>

<p>Christensen, R. H. B., Cleaver, G. and Brockhoff, P. B.(2011)
Statistical and Thurstonian models for the A-not A protocol with and
without sureness. <em>Food Quality and Preference, 22</em>,
pp. 542-549. 
</p>

<hr>
<h2 id='update.clm2'>Update method for cumulative link models</h2><span id='topic+update.clm2'></span><span id='topic+update.clmm2'></span>

<h3>Description</h3>

<p>Update method for cumulative link models fitted with <code>clm2</code>.
This makes it possible to use e.g.
<code>update(obj, location = ~ . - var1, scale = ~ . + var2)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clm2'
update(object, formula., location, scale, nominal,...,
        evaluate = TRUE)
## S3 method for class 'clmm2'
update(object, formula., location, scale, nominal,...,
        evaluate = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update.clm2_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+clm2">clm2</a></code> object.
</p>
</td></tr>
<tr><td><code id="update.clm2_+3A_formula.">formula.</code></td>
<td>
<p>not used&mdash;unfortunately this argument is part of the
default method.
</p>
</td></tr>
<tr><td><code id="update.clm2_+3A_location">location</code></td>
<td>
<p>an optional new formula for the location; see
<code><a href="stats.html#topic+update.formula">update.formula</a></code> for details.
</p>
</td></tr>
<tr><td><code id="update.clm2_+3A_scale">scale</code></td>
<td>
<p>an optional new formula for the scale; see
<code><a href="stats.html#topic+update.formula">update.formula</a></code> for details.
</p>
</td></tr>
<tr><td><code id="update.clm2_+3A_nominal">nominal</code></td>
<td>
<p>an optional new formula for nominal effects; see
<code><a href="stats.html#topic+update.formula">update.formula</a></code> for details.
</p>
</td></tr>
<tr><td><code id="update.clm2_+3A_...">...</code></td>
<td>
<p>additional arguments to the call, or arguments with
changed values.
</p>
</td></tr>
<tr><td><code id="update.clm2_+3A_evaluate">evaluate</code></td>
<td>
<p>if true evaluate the new call else return the call.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>evaluate = TRUE</code> the fitted object is returned,
otherwise the updated call.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))

m1 &lt;-  clm2(SURENESS ~ PROD, scale = ~PROD, data = soup,
           link = "logistic")

m2 &lt;- update(m1, link = "probit")
m3 &lt;- update(m1, link = "cloglog")
m4 &lt;- update(m1, link = "loglog")
anova(m1, update(m1, scale = ~.-PROD))
mT1 &lt;- update(m1, threshold = "symmetric")

</code></pre>

<hr>
<h2 id='VarCorr'>
Extract variance and correlation parameters
</h2><span id='topic+VarCorr'></span><span id='topic+VarCorr.clmm'></span>

<h3>Description</h3>

<p>The VarCorr function extracts the variance and (if present)
correlation parameters for random effect terms in a
cumulative link mixed model (CLMM) fitted with <code>clmm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'clmm'
VarCorr(x, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VarCorr_+3A_x">x</code></td>
<td>
<p>a <code><a href="#topic+clmm">clmm</a></code> object.
</p>
</td></tr>
<tr><td><code id="VarCorr_+3A_...">...</code></td>
<td>

<p>currently not used by the <code>clmm</code> method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>VarCorr</code> method returns a list of <code>data.frame</code>s; one for
each distinct grouping factor. Each <code>data.frame</code> has as many rows
as there are levels for that grouping factor and as many columns as
there are random effects for each level. For example a model can
contain a random intercept (one column) or a random
intercept and a random slope (two columns) for the same grouping
factor.
</p>
<p>If conditional variances are requested, they are returned in the same
structure as the conditional modes (random effect
estimates/predictions).
</p>


<h3>Value</h3>

<p>A list of matrices with variances in the diagonal and correlation
parameters in the off-diagonal &mdash; one matrix for each random effects term
in the model. Standard deviations are provided as attributes to the
matrices.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
fm1 &lt;- clmm(rating ~ contact + temp + (1|judge), data=wine)
VarCorr(fm1)

</code></pre>

<hr>
<h2 id='wine'>
Bitterness of wine
</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>The <code>wine</code> data set is adopted from Randall(1989) and from a
factorial experiment on factors determining the bitterness of
wine. Two treatment factors (temperature and contact) each have two
levels. Temperature and contact between juice and skins can be
controlled when cruching grapes during wine production. Nine judges
each assessed wine from two bottles from each of the four treatment
conditions, hence there are 72 observations in all.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wine
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>response</code></dt><dd>
<p>scorings of wine bitterness on a 0&mdash;100 continuous scale.
</p>
</dd>
<dt><code>rating</code></dt><dd>
<p>ordered factor with 5 levels; a grouped version of <code>response</code>.
</p>
</dd>
<dt><code>temp</code></dt><dd>
<p>temperature: factor with two levels.
</p>
</dd>
<dt><code>contact</code></dt><dd>
<p>factor with two levels (<code>"no"</code> and <code>"yes"</code>).
</p>
</dd>
<dt><code>bottle</code></dt><dd>
<p>factor with eight levels.
</p>
</dd>
<dt><code>judge</code></dt><dd>
<p>factor with nine levels.
</p>
</dd>
</dl>


<h3>Source</h3>

<p>Data are adopted from Randall (1989).
</p>


<h3>References</h3>

<p>Randall, J (1989). The analysis of sensory data by generalised linear
model. <em>Biometrical journal 7</em>, pp. 781&ndash;793.
</p>
<p>Tutz, G. and W. Hennevogl (1996). Random effects in ordinal regression
models. <em>Computational Statistics &amp; Data Analysis 22</em>,
pp. 537&ndash;557.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
head(wine)
str(wine)

## Variables 'rating' and 'response' are related in the following way:
(intervals &lt;- seq(0,100, by = 20))
all(wine$rating == findInterval(wine$response, intervals)) ## ok

## A few illustrative tabulations:
## Table matching Table 5 in Randall (1989):
temp.contact.bottle &lt;- with(wine, temp:contact:bottle)[drop=TRUE]
xtabs(response ~ temp.contact.bottle + judge, data = wine)

## Table matching Table 6 in Randall (1989):
with(wine, {
  tcb &lt;- temp:contact:bottle
  tcb &lt;- tcb[drop=TRUE]
  table(tcb, rating)
})
## or simply: with(wine, table(bottle, rating))

## Table matching Table 1 in Tutz &amp; Hennevogl (1996):
tab &lt;- xtabs(as.numeric(rating) ~ judge + temp.contact.bottle,
             data = wine)
colnames(tab) &lt;-
  paste(rep(c("c","w"), each = 4), rep(c("n", "n", "y", "y"), 2),
        1:8, sep=".")
tab


## A simple model:
m1 &lt;- clm(rating ~ temp * contact, data = wine)
summary(m1)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
