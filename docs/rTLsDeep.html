<!DOCTYPE html><html lang="en"><head><title>Help for package rTLsDeep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rTLsDeep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#confmatrix_treedamage'><p>Confusion matrix</p></a></li>
<li><a href='#fit_dl_model'><p>Fitting deep learning models for post-hurricane individual tree level damage classification</p></a></li>
<li><a href='#gcmplot'><p>Plot confusion matrix</p></a></li>
<li><a href='#get_best_angle'><p>Get best angle for plotting the tree</p></a></li>
<li><a href='#get_dl_model'><p>Selecting deep learning modeling approaches</p></a></li>
<li><a href='#get_validation_classes'><p>Tree-level damage classes for validation datasets</p></a></li>
<li><a href='#getMinBBox'><p>Rotating calipers algorithm</p></a></li>
<li><a href='#getTLS2D'><p>Grid snapshot</p></a></li>
<li><a href='#predict_treedamage'><p>Predict post-hurricane individual tree level damage</p></a></li>
<li><a href='#rTLsDeep'><p>rTLsDeep: Set of tools for post-hurricane individual tree-level damage classification from terrestrial laser scanning and deep learning.</p></a></li>
<li><a href='#tlsrotate3d'><p>Rotate TLS-derived 3D Point Clouds</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Post-Hurricane Damage Severity Classification from TLS and AI</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Terrestrial laser scanning (TLS) data processing and post-hurricane damage severity classification at the individual tree level using deep Learning. Further details were published in Klauberg et al. (2023) &lt;<a href="https://doi.org/10.3390%2Frs15041165">doi:10.3390/rs15041165</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, ggplot2, grDevices, lidR, keras, matrixStats,
reticulate, rgl, sf, tensorflow</td>
</tr>
<tr>
<td>Suggests:</td>
<td>terra, viridis</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/carlos-alberto-silva/rTLsDeep">https://github.com/carlos-alberto-silva/rTLsDeep</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/carlos-alberto-silva/rTLsDeep/issues">https://github.com/carlos-alberto-silva/rTLsDeep/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-30 00:28:32 UTC; caioh</td>
</tr>
<tr>
<td>Author:</td>
<td>Carine Klauberg [aut],
  Ricardo Dalagnol [aut, cph],
  Matheus Ferreira [aut, ctb],
  Jason Vogel [aut, ctb],
  Caio Hamamura [aut, ctb, cre],
  Carlos Alberto Silva [aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Caio Hamamura &lt;caiohamamura@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-31 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='confmatrix_treedamage'>Confusion matrix</h2><span id='topic+confmatrix_treedamage'></span>

<h3>Description</h3>

<p>This function calculates a cross-tabulation of reference and predicted classes with associated statistics based on the deep learning models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confmatrix_treedamage(predict_class, test_classes, class_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confmatrix_treedamage_+3A_predict_class">predict_class</code></td>
<td>
<p>A vector with the predicted classes. This is the output from the predict_treedamage function.</p>
</td></tr>
<tr><td><code id="confmatrix_treedamage_+3A_test_classes">test_classes</code></td>
<td>
<p>A vector with the predicted classes. This is the output from the get_validation_classes function.</p>
</td></tr>
<tr><td><code id="confmatrix_treedamage_+3A_class_list">class_list</code></td>
<td>
<p>A character string or numeric value describing the post-hurricane individual tree level damage classes, e.g.: c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the confusion matrix comparing predictions with the reference from validation dataset.
</p>


<h3>See Also</h3>

<p><a href="https://www.rdocumentation.org/packages/caret/versions/3.45/topics/confusionMatrix">https://www.rdocumentation.org/packages/caret/versions/3.45/topics/confusionMatrix</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Set directory to tensorflow (python environment)
# This is required if running deep learning local computer with GPU
# Guide to install here: https://doi.org/10.5281/zenodo.3929709
tensorflow_dir = NA

# define model type
model_type = "simple"
#model_type = "vgg"
#model_type = "inception"
#model_type = "resnet"
#model_type = "densenet"
#model_type = "efficientnet"

# Image and model properties
# path to image folders - black
train_image_files_path &lt;- system.file('extdata', 'train', package='rTLsDeep')
test_image_files_path &lt;- system.file('extdata', 'validation', package='rTLsDeep')
img_width &lt;- 256
img_height &lt;- 256
class_list_train = unique(list.files(train_image_files_path))
class_list_test = unique(list.files(test_image_files_path))
lr_rate = 0.00003
target_size = c(img_width, img_height)
channels = 4
batch_size = 8L
epochs = 4L

# get model
model = get_dl_model(model_type=model_type,
                    img_width=img_width,
                    img_height=img_height,
                    channels=channels,
                    lr_rate = lr_rate,
                    tensorflow_dir = tensorflow_dir,
                    class_list = class_list_train)


# train model and return best weights
weights = fit_dl_model(model = model,
                                train_input_path = train_image_files_path,
                                test_input_path = test_image_files_path,
                                target_size = target_size,
                                batch_size = batch_size,
                                class_list = class_list_train,
                                epochs = epochs,
                                lr_rate = lr_rate)


# Predicting post-hurricane damage at the tree-level
tree_damage&lt;-predict_treedamage(model=model,
                           input_file_path=test_image_files_path,
                           weights=weights,
                           target_size = c(256,256),
                           class_list=class_list_test,
                           batch_size = batch_size)

# Get damage classes for test datasets
classes&lt;-get_validation_classes(file_path=test_image_files_path)

# Calculate, print and return confusion matrix
cm = confmatrix_treedamage(predict_class = tree_damage,
                          test_classes=classes,
                          class_list = class_list_test)

</code></pre>

<hr>
<h2 id='fit_dl_model'>Fitting deep learning models for post-hurricane individual tree level damage classification</h2><span id='topic+fit_dl_model'></span>

<h3>Description</h3>

<p>This function fits deep learning models for post-hurricane individual tree level damage classification using TLS-derived 2D images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_dl_model(
  model,
  train_input_path,
  test_input_path,
  output_path = tempdir(),
  target_size = c(256, 256),
  batch_size = 8,
  class_list,
  epochs = 20L,
  lr_rate = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_dl_model_+3A_model">model</code></td>
<td>
<p>A model object output of the get_dl_model function. See [rTLsDeep::get_dl_model()].</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_train_input_path">train_input_path</code></td>
<td>
<p>A character string describing the path to the training dataset, e.g.: &quot;C:/train_data/&quot;.</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_test_input_path">test_input_path</code></td>
<td>
<p>A character string describing the path to the testing dataset, e.g.: &quot;C:/test_data/&quot;.</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_output_path">output_path</code></td>
<td>
<p>A character string describing the path where to save the weights for the neural network.</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_target_size">target_size</code></td>
<td>
<p>A vector of two values describing the image dimensions (Width and height) to be used in the model. Default: c(256,256)</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_batch_size">batch_size</code></td>
<td>
<p>A numerical value indicating the number of images to be processed at the same time. Reduce the batch_size if the GPU is giving memory errors.</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_class_list">class_list</code></td>
<td>
<p>A character string or numeric value describing the post-hurricane individual tree level damage classes, e.g.: c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;).</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_epochs">epochs</code></td>
<td>
<p>A numeric value indicating the number of iterations to train the model. Use at least 20 for pre-trained models, and at least 200 for a model without pre-trained weights.</p>
</td></tr>
<tr><td><code id="fit_dl_model_+3A_lr_rate">lr_rate</code></td>
<td>
<p>A numeric value indicating the learning rate. Default: 0.0001.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character string indicating the filename of the best weights trained for the chosen model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Set directory to tensorflow (python environment)
# This is required if running deep learning local computer with GPU
# Guide to install here: https://doi.org/10.5281/zenodo.3929709
tensorflow_dir = NA

# define model type
model_type = "simple"
#model_type = "vgg"
#model_type = "inception"
#model_type = "resnet"
#model_type = "densenet"
#model_type = "efficientnet"

train_image_files_path = system.file('extdata', 'train', package='rTLsDeep')
test_image_files_path = system.file('extdata', 'validation', package='rTLsDeep')
img_width &lt;- 256
img_height &lt;- 256
class_list_train = unique(list.files(train_image_files_path))
class_list_test = unique(list.files(test_image_files_path))
lr_rate = 0.0001
target_size &lt;- c(img_width, img_height)
channels &lt;- 4
batch_size = 8L
epochs = 2L

# get model
if (reticulate::py_module_available('tensorflow') == FALSE)
{
 tensorflow::install_tensorflow()
}

model = get_dl_model(model_type=model_type,
                    img_width=img_width,
                    img_height=img_height,
                    channels=channels,
                    lr_rate = lr_rate,
                    tensorflow_dir = tensorflow_dir,
                    class_list = class_list_train)


# train model and return best weights
weights = fit_dl_model(model = model,
                                train_input_path = train_image_files_path,
                                test_input_path = test_image_files_path,
                                target_size = target_size,
                                batch_size = batch_size,
                                class_list = class_list_train,
                                epochs = epochs,
                                lr_rate = lr_rate)

unlink('epoch_history', recursive = TRUE)
unlink('weights', recursive = TRUE)
unlink('weights_r_save', recursive = TRUE)


</code></pre>

<hr>
<h2 id='gcmplot'>Plot confusion matrix</h2><span id='topic+gcmplot'></span>

<h3>Description</h3>

<p>This function plots the confusion matrix for classification assessment
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcmplot(
  cm,
  colors = c(low = "white", high = "#009194"),
  title = "cm",
  prop = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gcmplot_+3A_cm">cm</code></td>
<td>
<p>An confusion matrix object of class &quot;confusionMatrix&quot;. Output of the [rTLsDeep::confmatrix_damage()] function.</p>
</td></tr>
<tr><td><code id="gcmplot_+3A_colors">colors</code></td>
<td>
<p>A vector defining the low and high colors. Default is c(low=&quot;white&quot;, high=&quot;#009194&quot;).</p>
</td></tr>
<tr><td><code id="gcmplot_+3A_title">title</code></td>
<td>
<p>A character defining the title of the figure.</p>
</td></tr>
<tr><td><code id="gcmplot_+3A_prop">prop</code></td>
<td>
<p>If TRUE percentage values will be plotted to the figure otherwise Freq.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class gg and ggplot and plot of the confusion matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Path to rds file
rdsfile &lt;- system.file("extdata", "cm_vgg.rds", package="rTLsDeep")

# Read RDS fo;e
cm_vgg&lt;-readRDS(rdsfile)

# Plot confusion matrix
gcmplot_vgg&lt;-gcmplot(cm_vgg,
                    colors=c(low="white", high="#009194"),
                    title="densenet")

</code></pre>

<hr>
<h2 id='get_best_angle'>Get best angle for plotting the tree</h2><span id='topic+get_best_angle'></span>

<h3>Description</h3>

<p>Calculates the minimum oriented bounding box using the
rotating calipers algorithm and extracts the angle
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_best_angle(las)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_best_angle_+3A_las">las</code></td>
<td>
<p>An object of class LAS [lidR::readLAS()].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the model object with the required parameters and model_type used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lasfile &lt;- system.file("extdata", "tree_c2.laz", package = "rTLsDeep")
las &lt;- lidR::readLAS(lasfile)

(get_best_angle(las))

</code></pre>

<hr>
<h2 id='get_dl_model'>Selecting deep learning modeling approaches</h2><span id='topic+get_dl_model'></span>

<h3>Description</h3>

<p>This function selects and returns the deep learning approach to be used with the fit_dl_model function for
post-hurricane individual tree-level damage classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_dl_model(
  model_type = "vgg",
  img_width = 256,
  img_height = 256,
  lr_rate = 1e-04,
  tensorflow_dir = NA,
  channels,
  class_list
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_dl_model_+3A_model_type">model_type</code></td>
<td>
<p>A character string describing the deep learning model to be used. Available models: &quot;vgg&quot;, &quot;resnet&quot;, &quot;inception&quot;, &quot;densenet&quot;, &quot;efficientnet&quot;, &quot;simple&quot;.</p>
</td></tr>
<tr><td><code id="get_dl_model_+3A_img_width">img_width</code></td>
<td>
<p>A numeric value describing the width of the image used for training. Default: 256.</p>
</td></tr>
<tr><td><code id="get_dl_model_+3A_img_height">img_height</code></td>
<td>
<p>A numeric value describing the height of the image used for training. Default: 256.</p>
</td></tr>
<tr><td><code id="get_dl_model_+3A_lr_rate">lr_rate</code></td>
<td>
<p>A numeric value indicating the learning rate. Default: 0.0001.</p>
</td></tr>
<tr><td><code id="get_dl_model_+3A_tensorflow_dir">tensorflow_dir</code></td>
<td>
<p>A character string indicating the directory for the tensorflow python environment. Guide to install the environment here: https://doi.org/10.5281/zenodo.3929709. Default = NA.</p>
</td></tr>
<tr><td><code id="get_dl_model_+3A_channels">channels</code></td>
<td>
<p>A numeric value for the number of channels/bands of the input images.</p>
</td></tr>
<tr><td><code id="get_dl_model_+3A_class_list">class_list</code></td>
<td>
<p>A character string or numeric value describing the post-hurricane individual tree level damage classes, e.g.: c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the model object with the required parameters and model_type used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Set directory to tensorflow (python environment)
# This is required if running deep learning local computer with GPU
# Guide to install here: https://doi.org/10.5281/zenodo.3929709
tensorflow_dir = NA

# define model type
model_type = "simple"
#model_type = "vgg"
#model_type = "inception"
#model_type = "resnet"
#model_type = "densenet"
#model_type = "efficientnet"

train_image_files_path = system.file('extdata', 'train', package='rTLsDeep')
test_image_files_path = system.file('extdata', 'validation', package='rTLsDeep')
img_width &lt;- 256
img_height &lt;- 256
class_list_train = unique(list.files(train_image_files_path))
class_list_test = unique(list.files(test_image_files_path))
lr_rate = 0.0001
target_size &lt;- c(img_width, img_height)
channels = 4

# get model
if (reticulate::py_module_available('tensorflow') == FALSE)
{
 tensorflow::install_tensorflow()
}
model = get_dl_model(model_type=model_type,
                    img_width=img_width,
                    img_height=img_height,
                    channels=channels,
                    lr_rate = lr_rate,
                    tensorflow_dir = tensorflow_dir,
                    class_list = class_list_train)


</code></pre>

<hr>
<h2 id='get_validation_classes'>Tree-level damage classes for validation datasets</h2><span id='topic+get_validation_classes'></span>

<h3>Description</h3>

<p>This function return the post-hurricane individual tree-level damage classes based on file names in a given directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_validation_classes(file_path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_validation_classes_+3A_file_path">file_path</code></td>
<td>
<p>A character string indicating the path to the validation folders, one for each class.
This folder must have sub folders with samples for each class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the classes based on file names in a given folder.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Image and model properties
val_image_files_path = system.file('extdata', 'validation', package='rTLsDeep')

# Get damage classes for validation datasets
classes = get_validation_classes(file_path=val_image_files_path)

</code></pre>

<hr>
<h2 id='getMinBBox'>Rotating calipers algorithm</h2><span id='topic+getMinBBox'></span>

<h3>Description</h3>

<p>Calculates the minimum oriented bounding box using the
rotating calipers algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMinBBox(hull)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getMinBBox_+3A_hull">hull</code></td>
<td>
<p>A matrix of xy values from a convex hull from which
will calculate the minimum oriented bounding box.</p>
</td></tr>
</table>

<hr>
<h2 id='getTLS2D'>Grid snapshot</h2><span id='topic+getTLS2D'></span>

<h3>Description</h3>

<p>This function captures a 2D grid snapshot of the TLS-derived 3D Point Cloud
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTLS2D(las, res = 0.05, by = "xz", func = ~list(Z = max(Z)), scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTLS2D_+3A_las">las</code></td>
<td>
<p>An object of class LAS [lidR::readLAS()].</p>
</td></tr>
<tr><td><code id="getTLS2D_+3A_res">res</code></td>
<td>
<p>Numeric defining the resolution or grid cell size of the 2D image.</p>
</td></tr>
<tr><td><code id="getTLS2D_+3A_by">by</code></td>
<td>
<p>Character defining the grid snapshot view: 'xz', 'yx' or 'xy'. Default: 'xz'.</p>
</td></tr>
<tr><td><code id="getTLS2D_+3A_func">func</code></td>
<td>
<p>formula defining the equation to be passed in each grid. Default: ~list(Z = max(Z)).</p>
</td></tr>
<tr><td><code id="getTLS2D_+3A_scale">scale</code></td>
<td>
<p>if TRUE, the xyz coordinates will be scaled to local coordinates by subtracting their values to their
corresponding minimum values (e.g. x - min(x). Default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class SpatRaste containing the 2D grid snapshot of the TLS 3D point cloud.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Loading lidR and viridis libraries
library(lidR)
library(viridis)

# Path to las file
lasfile &lt;- system.file("extdata", "tree_c1.laz", package="rTLsDeep")

# Reading las file
las&lt;-readLAS(lasfile)

# Visualizing las file
suppressWarnings(plot(las))

# Creating a 2D grid snapshot
func = ~list(Z = max(Z))
by="xz"
res=0.05
scale=TRUE

g&lt;-getTLS2D(las, res=res, by=by, func = func, scale=scale)

# Visualizing 2D grid snapshot
plot(g, asp=TRUE, col=viridis::viridis(100),axes=FALSE, xlab="",ylab="")

# Exporting 2D grid snapshot as png file
output_png = paste0(tempfile(), '.png')
png(output_png, units="px", width=1500, height=1500)
terra::image(g, col=viridis::viridis(100))

dev.off()
</code></pre>

<hr>
<h2 id='predict_treedamage'>Predict post-hurricane individual tree level damage</h2><span id='topic+predict_treedamage'></span>

<h3>Description</h3>

<p>This function predicts post-hurricane individual tree-level damage from TLS derived 2D images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_treedamage(
  model,
  input_file_path,
  weights,
  target_size = c(256, 256),
  class_list,
  batch_size = 8
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_treedamage_+3A_model">model</code></td>
<td>
<p>A model object output of the get_dl_model function. See [rTLsDeep::get_dl_model()].</p>
</td></tr>
<tr><td><code id="predict_treedamage_+3A_input_file_path">input_file_path</code></td>
<td>
<p>A character string describing the path to the images to predict, e.g.: &quot;C:/test_data/&quot;.</p>
</td></tr>
<tr><td><code id="predict_treedamage_+3A_weights">weights</code></td>
<td>
<p>A character string indicating the filename of the weights to use for prediction.</p>
</td></tr>
<tr><td><code id="predict_treedamage_+3A_target_size">target_size</code></td>
<td>
<p>A vector of two values describing the image dimensions (Width and height) to be used in the model. Default: c(256,256)</p>
</td></tr>
<tr><td><code id="predict_treedamage_+3A_class_list">class_list</code></td>
<td>
<p>A character string or numeric value describing the post-hurricane individual tree level damage classes, e.g.: c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;).</p>
</td></tr>
<tr><td><code id="predict_treedamage_+3A_batch_size">batch_size</code></td>
<td>
<p>A numerical value indicating the number of images to be processed at the same time. Reduce the batch_size if the GPU is giving memory errors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character string with the prediction classes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Set directory to tensorflow (python environment)
# This is required if running deep learning local computer with GPU
# Guide to install here: https://doi.org/10.5281/zenodo.3929709
tensorflow_dir = NA

# define model type
model_type = "simple"
#model_type = "vgg"
#model_type = "inception"
#model_type = "resnet"
#model_type = "densenet"
#model_type = "efficientnet"

train_image_files_path = system.file('extdata', 'train', package='rTLsDeep')
test_image_files_path = system.file('extdata', 'validation', package='rTLsDeep')
img_width &lt;- 256
img_height &lt;- 256
class_list_train = unique(list.files(train_image_files_path))
class_list_test = unique(list.files(test_image_files_path))
lr_rate = 0.0001
target_size &lt;- c(img_width, img_height)
channels = 4
batch_size = 8L
epochs = 20L

# get model
model = get_dl_model(model_type=model_type,
                    img_width=img_width,
                    img_height=img_height,
                    lr_rate = lr_rate,
                    tensorflow_dir = tensorflow_dir,
                    channels = channels,
                    class_list = class_list_train)


# train model and return best weights
weights = fit_dl_model(model = model,
                                train_input_path = train_image_files_path,
                                test_input_path = test_image_files_path,
                                target_size = target_size,
                                batch_size = batch_size,
                                class_list = class_list_train,
                                epochs = epochs,
                                lr_rate = lr_rate)


# Predicting post-hurricane damage at the tree-level
tree_damage&lt;-predict_treedamage(model=model,
                           input_file_path=test_image_files_path,
                           weights=weights,
                           target_size = c(256,256),
                           class_list=class_list_test,
                           batch_size = batch_size)

unlink('epoch_history', recursive = TRUE)
unlink('weights', recursive = TRUE)
unlink('weights_r_save', recursive = TRUE)

</code></pre>

<hr>
<h2 id='rTLsDeep'>rTLsDeep: Set of tools for post-hurricane individual tree-level damage classification from terrestrial laser scanning and deep learning.</h2><span id='topic+rTLsDeep'></span>

<h3>Description</h3>

<p>The rTLSDeep package provides options for:
i) rotating and deriving 2D images from TLS 3D point clouds
ii) calibrating and validating convolutional neural network (CNN) architectures and 
iii) predicting post-hurricane damage severity at the individual tree level
</p>

<hr>
<h2 id='tlsrotate3d'>Rotate TLS-derived 3D Point Clouds</h2><span id='topic+tlsrotate3d'></span>

<h3>Description</h3>

<p>This function rotates TLS-derived 3D Point Clouds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlsrotate3d(las, theta, by = "z", scale = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tlsrotate3d_+3A_las">las</code></td>
<td>
<p>An object of class LAS [lidR::readLAS()].</p>
</td></tr>
<tr><td><code id="tlsrotate3d_+3A_theta">theta</code></td>
<td>
<p>Numeric defining the angle in degrees (from 0 to 360) for rotating the 3d point cloud.</p>
</td></tr>
<tr><td><code id="tlsrotate3d_+3A_by">by</code></td>
<td>
<p>Character defining the rotation around x ('x'), y ('y') or z ('z') axis. Default: around z-axis.</p>
</td></tr>
<tr><td><code id="tlsrotate3d_+3A_scale">scale</code></td>
<td>
<p>if TRUE, the xyz coordinates will be scaled to local coordinates by subtracting their values to their
corresponding minimum values (e.g. x - min(x). Default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class LAS containing the rotated 3d point cloud.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Path to las file
lasfile &lt;- system.file("extdata", "tree_c1.laz", package="rTLsDeep")

# Reading las file
las&lt;-lidR::readLAS(lasfile)

# Visualizing las file
suppressWarnings(lidR::plot(las))

# Rotating 3d point cloud around Z-axis
lasr&lt;-tlsrotate3d(las,theta=180, by="x", scale=TRUE)

# Visualizing rotated las file
suppressWarnings(lidR::plot(lasr))

if (!rgl::rgl.useNULL())
 rgl::play3d(rgl::spin3d(axis = c(0, 0, 1), rpm = 5), duration = 10)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
