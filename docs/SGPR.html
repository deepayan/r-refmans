<!DOCTYPE html><html lang="en"><head><title>Help for package SGPR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SGPR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SGPR-package'><p>SGPR: Sparse Group Penalized Regression for Bi-Level Variable Selection</p></a></li>
<li><a href='#coef.sgp'><p>Coefficients from an SGP model</p></a></li>
<li><a href='#coef.sgp.cv'><p>Coefficients from SGP models</p></a></li>
<li><a href='#get.loss'><p>A function that calculates the loss/cost</p></a></li>
<li><a href='#plot.sgp'><p>Plots the coefficient path of an SGP object</p></a></li>
<li><a href='#plot.sgp.cv'><p>Plots the cross-validation curve from a SGP object</p></a></li>
<li><a href='#predict.sgp'><p>Predictions based on a SGP model</p></a></li>
<li><a href='#predict.sgp.cv'><p>Predictions based on a SGP models</p></a></li>
<li><a href='#process.group'><p>Process groupings for a sparse group penalty</p></a></li>
<li><a href='#process.lambda'><p>Set up a lambda sequence</p></a></li>
<li><a href='#process.penalty'><p>Process the arguments about the sparse group penalty</p></a></li>
<li><a href='#process.X'><p>Process X for a sparse group penalty</p></a></li>
<li><a href='#process.y'><p>Process y for a sparse group penalty</p></a></li>
<li><a href='#process.Z'><p>Process Z for a sparse group penalty</p></a></li>
<li><a href='#sgp'><p>Fit a sparse group regularized regression path</p></a></li>
<li><a href='#sgp.cv'><p>Cross-validation for sparse group penalties</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sparse Group Penalized Regression for Bi-Level Variable
Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits the regularization path of regression models
    (linear and logistic) with additively combined penalty terms. All
    possible combinations with Least Absolute Shrinkage and Selection Operator (LASSO), 
    Smoothly Clipped Absolute Deviation (SCAD), Minimax Concave Penalty (MCP) and 
    Exponential Penalty (EP) are supported. This includes Sparse Group LASSO (SGL), 
    Sparse Group SCAD (SGS), Sparse Group MCP (SGM) and Sparse Group EP (SGE).
    For more information, see Buch, G., Schulz, A., Schmidtmann, I., Strauch, K., &amp; Wild, P. S. (2024) &lt;<a href="https://doi.org/10.1002%2Fbimj.202200334">doi:10.1002/bimj.202200334</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-15 18:52:21 UTC; Mufasa</td>
</tr>
<tr>
<td>Author:</td>
<td>Gregor Buch [aut, cre, cph],
  Andreas Schulz [ths],
  Irene Schmidtmann [ths],
  Konstantin Strauch [ths],
  Philipp Wild [ths]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gregor Buch &lt;buchgregor@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-16 14:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='SGPR-package'>SGPR: Sparse Group Penalized Regression for Bi-Level Variable Selection</h2><span id='topic+SGPR'></span><span id='topic+SGPR-package'></span>

<h3>Description</h3>

<p>Fits the regularization path of regression models (linear and logistic) with additively combined penalty terms. All possible combinations with Least Absolute Shrinkage and Selection Operator (LASSO), Smoothly Clipped Absolute Deviation (SCAD), Minimax Concave Penalty (MCP) and Exponential Penalty (EP) are supported. This includes Sparse Group LASSO (SGL), Sparse Group SCAD (SGS), Sparse Group MCP (SGM) and Sparse Group EP (SGE). For more information, see Buch, G., Schulz, A., Schmidtmann, I., Strauch, K., &amp; Wild, P. S. (2024) <a href="https://doi.org/10.1002/bimj.202200334">doi:10.1002/bimj.202200334</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Gregor Buch <a href="mailto:buchgregor@gmail.com">buchgregor@gmail.com</a> [copyright holder]
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Andreas Schulz [thesis advisor]
</p>
</li>
<li><p> Irene Schmidtmann [thesis advisor]
</p>
</li>
<li><p> Konstantin Strauch [thesis advisor]
</p>
</li>
<li><p> Philipp Wild [thesis advisor]
</p>
</li></ul>


<hr>
<h2 id='coef.sgp'>Coefficients from an SGP model</h2><span id='topic+coef.sgp'></span>

<h3>Description</h3>

<p>A function that extracts the estimated coefficients from an SGP object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgp'
coef(object, lambda, index = 1:length(object$lambda), drop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.sgp_+3A_object">object</code></td>
<td>
<p>A object that was generated with sgp.</p>
</td></tr>
<tr><td><code id="coef.sgp_+3A_lambda">lambda</code></td>
<td>
<p>The value of lambda at which the coefficients are to be extracted.</p>
</td></tr>
<tr><td><code id="coef.sgp_+3A_index">index</code></td>
<td>
<p>The index that indicates the lambda at which the coefficients are to be extracted (alternative to specifying 'lambda').</p>
</td></tr>
<tr><td><code id="coef.sgp_+3A_drop">drop</code></td>
<td>
<p>A Boolean value that specifies whether empty dimensions should be removed.</p>
</td></tr>
<tr><td><code id="coef.sgp_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector or matrix with the estimated coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 12
nr &lt;- 4
g &lt;- paste0("Group ",ceiling(1:p / nr))
X &lt;- matrix(rnorm(n * p), n, p)
b &lt;- c(-3:3)
y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

lin_fit &lt;- sgp(X, y_lin, g, type = "linear")
coef(lin_fit, index = 5:7)

log_fit &lt;- sgp(X, y_log, g, type = "logit")
coef(log_fit, index = 5:7)

</code></pre>

<hr>
<h2 id='coef.sgp.cv'>Coefficients from SGP models</h2><span id='topic+coef.sgp.cv'></span>

<h3>Description</h3>

<p>A function that extracts the estimated coefficients from an cross-validated SGP object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgp.cv'
coef(object, lambda = object$lambda.min, index = object$min, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.sgp.cv_+3A_object">object</code></td>
<td>
<p>A object that was generated with sgp.cv.</p>
</td></tr>
<tr><td><code id="coef.sgp.cv_+3A_lambda">lambda</code></td>
<td>
<p>The value of lambda at which the coefficients are to be extracted.</p>
</td></tr>
<tr><td><code id="coef.sgp.cv_+3A_index">index</code></td>
<td>
<p>The index that indicates the lambda at which the coefficients are to be extracted (alternative to specifying 'lambda').</p>
</td></tr>
<tr><td><code id="coef.sgp.cv_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector or matrix with the estimated coefficients.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 12
nr &lt;- 4
g &lt;- paste0("Group ",ceiling(1:p / nr))
X &lt;- matrix(rnorm(n * p), n, p)
b &lt;- c(-3:3)
y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

lin_fit &lt;- sgp.cv(X, y_lin, g, type = "linear")
coef(lin_fit)

log_fit &lt;- sgp.cv(X, y_log, g, type = "logit")
coef(log_fit)

</code></pre>

<hr>
<h2 id='get.loss'>A function that calculates the loss/cost</h2><span id='topic+get.loss'></span>

<h3>Description</h3>

<p>A function that calculates the loss/cost
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.loss(y, pred, type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.loss_+3A_y">y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code id="get.loss_+3A_pred">pred</code></td>
<td>
<p>The predicted values for the response.</p>
</td></tr>
<tr><td><code id="get.loss_+3A_type">type</code></td>
<td>
<p>A string indicating the type of regression model (linear or binomial).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The loss of the input vectors.
</p>

<hr>
<h2 id='plot.sgp'>Plots the coefficient path of an SGP object</h2><span id='topic+plot.sgp'></span>

<h3>Description</h3>

<p>Produces a coefficient profile plot of the coefficient paths for a fitted SGP object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgp'
plot(x, alpha = 1, legend.pos, label = FALSE, log.l = FALSE, norm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.sgp_+3A_x">x</code></td>
<td>
<p>A object that was generated with sgp.</p>
</td></tr>
<tr><td><code id="plot.sgp_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter for the alpha-blending.</p>
</td></tr>
<tr><td><code id="plot.sgp_+3A_legend.pos">legend.pos</code></td>
<td>
<p>Coordinates or keyword for positioning the legend.</p>
</td></tr>
<tr><td><code id="plot.sgp_+3A_label">label</code></td>
<td>
<p>A Boolean value that specifies whether the plot should be annotated.</p>
</td></tr>
<tr><td><code id="plot.sgp_+3A_log.l">log.l</code></td>
<td>
<p>A Boolean value that specifies whether the horizontal axis should be on the log scale.</p>
</td></tr>
<tr><td><code id="plot.sgp_+3A_norm">norm</code></td>
<td>
<p>A Boolean value that specifies whether the norm of each group should be plotted.</p>
</td></tr>
<tr><td><code id="plot.sgp_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object with the coefficient path of an SGP.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 12
nr &lt;- 4
g &lt;- paste0("Group ",ceiling(1:p / nr))
X &lt;- matrix(rnorm(n * p), n, p)
b &lt;- c(-3:3)
y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

lin_fit &lt;- sgp(X, y_lin, g, type = "linear")
plot(lin_fit, legend.pos = "topright", label = TRUE)
plot(lin_fit,  label = TRUE, norm = TRUE)

log_fit &lt;- sgp(X, y_log, g, type = "logit")
plot(log_fit, legend.pos = "topright", label = TRUE)
plot(log_fit, label = TRUE, norm = TRUE)

</code></pre>

<hr>
<h2 id='plot.sgp.cv'>Plots the cross-validation curve from a SGP object</h2><span id='topic+plot.sgp.cv'></span>

<h3>Description</h3>

<p>Plots the cross-validation curve as a function of the lambda values used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgp.cv'
plot(x, log.l = TRUE, highlight = TRUE, col = "firebrick3", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.sgp.cv_+3A_x">x</code></td>
<td>
<p>A object that was generated with sgp.cv.</p>
</td></tr>
<tr><td><code id="plot.sgp.cv_+3A_log.l">log.l</code></td>
<td>
<p>A Boolean value that specifies whether the horizontal axis should be on the log scale.</p>
</td></tr>
<tr><td><code id="plot.sgp.cv_+3A_highlight">highlight</code></td>
<td>
<p>A Boolean value that specifies whether a vertical line should be added at the value where the cross-validation error is minimized.</p>
</td></tr>
<tr><td><code id="plot.sgp.cv_+3A_col">col</code></td>
<td>
<p>Controls the color of the dots.</p>
</td></tr>
<tr><td><code id="plot.sgp.cv_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object with the cross-validation curve of an SGP.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 12
nr &lt;- 4
g &lt;- paste0("Group ",ceiling(1:p / nr))
X &lt;- matrix(rnorm(n * p), n, p)
b &lt;- c(-3:3)
y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

lin_fit &lt;- sgp.cv(X, y_lin, g, type = "linear")
plot(lin_fit, col = "blue")

log_fit &lt;- sgp.cv(X, y_log, g, type = "logit")
plot(log_fit, col = "blue")

</code></pre>

<hr>
<h2 id='predict.sgp'>Predictions based on a SGP model</h2><span id='topic+predict.sgp'></span>

<h3>Description</h3>

<p>A function that extracts information from a SGP object and performs predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgp'
predict(
  object,
  X = NULL,
  extract = c("link", "response", "class", "coef", "vars", "groups", "nvars", "ngroups",
    "norm"),
  lambda,
  index = 1:length(object$lambda),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.sgp_+3A_object">object</code></td>
<td>
<p>A object that was generated with sgp.</p>
</td></tr>
<tr><td><code id="predict.sgp_+3A_x">X</code></td>
<td>
<p>The design matrix for making predictions.</p>
</td></tr>
<tr><td><code id="predict.sgp_+3A_extract">extract</code></td>
<td>
<p>A string indicating the type of information to return.</p>
</td></tr>
<tr><td><code id="predict.sgp_+3A_lambda">lambda</code></td>
<td>
<p>The value of lambda at which predictions should be made.</p>
</td></tr>
<tr><td><code id="predict.sgp_+3A_index">index</code></td>
<td>
<p>The index that indicates the lambda at which predictions should be made (alternative to specifying 'lambda').</p>
</td></tr>
<tr><td><code id="predict.sgp_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Different objects depending on the sting indicated by 'extract'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 12
nr &lt;- 4
g &lt;- paste0("Group ",ceiling(1:p / nr))
X &lt;- matrix(rnorm(n * p), n, p)
b &lt;- c(-3:3)
y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

lin_fit &lt;- sgp(X, y_lin, g, type = "linear")
predict(lin_fit, X = X, extract = "nvars")

log_fit &lt;- sgp(X, y_log, g, type = "logit")
predict(log_fit, X = X, extract = "nvars")

</code></pre>

<hr>
<h2 id='predict.sgp.cv'>Predictions based on a SGP models</h2><span id='topic+predict.sgp.cv'></span>

<h3>Description</h3>

<p>A function that extracts information from a cross-validated SGP object and performs predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sgp.cv'
predict(
  object,
  X,
  lambda = object$lambda.min,
  index = object$min,
  extract = c("link", "response", "class", "coefficients", "vars", "groups", "nvars",
    "ngroups", "norm"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.sgp.cv_+3A_object">object</code></td>
<td>
<p>A object that was generated with sgp.cv.</p>
</td></tr>
<tr><td><code id="predict.sgp.cv_+3A_x">X</code></td>
<td>
<p>The design matrix for making predictions.</p>
</td></tr>
<tr><td><code id="predict.sgp.cv_+3A_lambda">lambda</code></td>
<td>
<p>The value of lambda at which predictions should be made.</p>
</td></tr>
<tr><td><code id="predict.sgp.cv_+3A_index">index</code></td>
<td>
<p>The index that indicates the lambda at which predictions should be made (alternative to specifying 'lambda').</p>
</td></tr>
<tr><td><code id="predict.sgp.cv_+3A_extract">extract</code></td>
<td>
<p>A string indicating the type of information to return.</p>
</td></tr>
<tr><td><code id="predict.sgp.cv_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Different objects depending on the sting indicated by 'extract'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 12
nr &lt;- 4
g &lt;- paste0("Group ",ceiling(1:p / nr))
X &lt;- matrix(rnorm(n * p), n, p)
b &lt;- c(-3:3)
y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

lin_fit &lt;- sgp.cv(X, y_lin, g, type = "linear")
predict(lin_fit, X = X, extract = "link")

log_fit &lt;- sgp.cv(X, y_log, g, type = "logit")
predict(log_fit, X = X, extract = "class")

</code></pre>

<hr>
<h2 id='process.group'>Process groupings for a sparse group penalty</h2><span id='topic+process.group'></span>

<h3>Description</h3>

<p>A function that checks the group information for possible errors and processes it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process.group(group, group.weight)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process.group_+3A_group">group</code></td>
<td>
<p>A vector that specifies the group membership of each variable in X.</p>
</td></tr>
<tr><td><code id="process.group_+3A_group.weight">group.weight</code></td>
<td>
<p>A vector specifying weights that are multiplied by the group penalty to account for different group sizes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A structure containing the prepared group structure and, as an attribute, its labels and group weights.
</p>

<hr>
<h2 id='process.lambda'>Set up a lambda sequence</h2><span id='topic+process.lambda'></span>

<h3>Description</h3>

<p>A function that sets up a lambda sequence for a sparse group penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process.lambda(
  X,
  y,
  group,
  Z,
  type,
  alpha,
  lambda.min,
  log.lambda,
  nlambda,
  group.weight,
  ada_mult
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process.lambda_+3A_x">X</code></td>
<td>
<p>The design matrix without intercept with the variables to be selected.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_y">y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_group">group</code></td>
<td>
<p>A vector indicating the group membership of each variable in X.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_z">Z</code></td>
<td>
<p>The design matrix of the variables to be included in the model without penalization.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_type">type</code></td>
<td>
<p>A string indicating the type of regression model (linear or binomial).</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter for the mixture of penalties at group and variable level.
A value of 0 results in a selection at group level, a value of 1
results in a selection at variable level and everything in between
is bi-level selection.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_lambda.min">lambda.min</code></td>
<td>
<p>An integer multiplied by the maximum lambda to define the end of the lambda sequence.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_log.lambda">log.lambda</code></td>
<td>
<p>A Boolean value that specifies whether the values of the lambda
sequence should be on the log scale.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_nlambda">nlambda</code></td>
<td>
<p>An integer that specifies the length of the lambda sequence.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_group.weight">group.weight</code></td>
<td>
<p>A vector specifying weights that are multiplied by the group
penalty to account for different group sizes.</p>
</td></tr>
<tr><td><code id="process.lambda_+3A_ada_mult">ada_mult</code></td>
<td>
<p>An integer that defines the multiplier for adjusting the convergence threshold.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with values for lambda.
</p>

<hr>
<h2 id='process.penalty'>Process the arguments about the sparse group penalty</h2><span id='topic+process.penalty'></span>

<h3>Description</h3>

<p>A function that checks arguments about the penalty and translates them to integer (for the C++ code).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process.penalty(penalty, pvar, pgr, vargamma, grgamma, vartau, grtau, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process.penalty_+3A_penalty">penalty</code></td>
<td>
<p>A string that specifies the sparse group penalty to be used.</p>
</td></tr>
<tr><td><code id="process.penalty_+3A_pvar">pvar</code></td>
<td>
<p>A string that specifies the penalty used at the variable level.</p>
</td></tr>
<tr><td><code id="process.penalty_+3A_pgr">pgr</code></td>
<td>
<p>A string that specifies the penalty used at the group level.</p>
</td></tr>
<tr><td><code id="process.penalty_+3A_vargamma">vargamma</code></td>
<td>
<p>An integer that defines the value of gamma for the penalty at the variable level.</p>
</td></tr>
<tr><td><code id="process.penalty_+3A_grgamma">grgamma</code></td>
<td>
<p>An integer that specifies the value of gamma for the penalty at the group level.</p>
</td></tr>
<tr><td><code id="process.penalty_+3A_vartau">vartau</code></td>
<td>
<p>An integer that defines the value of tau for the penalty at the variable level.</p>
</td></tr>
<tr><td><code id="process.penalty_+3A_grtau">grtau</code></td>
<td>
<p>An integer that specifies the value of tau for the penalty at the group level.</p>
</td></tr>
<tr><td><code id="process.penalty_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter for the mixture of penalties at group and variable level.
A value of 0 results in a selection at group level, a value of 1
results in a selection at variable level and everything in between
is bi-level selection.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two integers indicating the penalty for the C++ code.
</p>

<hr>
<h2 id='process.X'>Process X for a sparse group penalty</h2><span id='topic+process.X'></span>

<h3>Description</h3>

<p>A function that checks the design matrix X for possible errors and scales it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process.X(X, group)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process.X_+3A_x">X</code></td>
<td>
<p>The design matrix without intercept with the variables to be selected.</p>
</td></tr>
<tr><td><code id="process.X_+3A_group">group</code></td>
<td>
<p>A vector that specifies the group membership of each variable in X.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<dl>
<dt>X</dt><dd><p>The standardized design matrix X.</p>
</dd>
<dt>vars</dt><dd><p>The variable names of the matrix.</p>
</dd>
<dt>center</dt><dd><p>The center of the variables before the transformation.</p>
</dd>
<dt>scale</dt><dd><p>The scale of the variables before the transformation.</p>
</dd>
</dl>


<hr>
<h2 id='process.y'>Process y for a sparse group penalty</h2><span id='topic+process.y'></span>

<h3>Description</h3>

<p>A function that checks the response vector y for possible errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process.y(y, type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process.y_+3A_y">y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code id="process.y_+3A_type">type</code></td>
<td>
<p>A string indicating the type of regression model (linear or binomial).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The verified response vector y.
</p>

<hr>
<h2 id='process.Z'>Process Z for a sparse group penalty</h2><span id='topic+process.Z'></span>

<h3>Description</h3>

<p>A function that checks the design matrix Z for possible errors and scales it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process.Z(Z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process.Z_+3A_z">Z</code></td>
<td>
<p>The design matrix of the variables to be included in the model without penalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<dl>
<dt>Z</dt><dd><p>The standardized design matrix Z.</p>
</dd>
<dt>vars</dt><dd><p>The variable names of the matrix.</p>
</dd>
<dt>center</dt><dd><p>The center of the variables before the transformation.</p>
</dd>
<dt>scale</dt><dd><p>The scale of the variables before the transformation.</p>
</dd>
</dl>


<hr>
<h2 id='sgp'>Fit a sparse group regularized regression path</h2><span id='topic+sgp'></span>

<h3>Description</h3>

<p>A function that determines the regularization paths for models with
sparse group penalties at a grid of values for the regularization parameter lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sgp(
  X,
  y,
  group = 1:ncol(X),
  penalty = c("sgl", "sgs", "sgm", "sge"),
  alpha = 1/3,
  type = c("linear", "logit"),
  Z = NULL,
  nlambda = 100,
  lambda.min = {
     if (nrow(X) &gt; ncol(X)) 
         1e-04
     else 0.05
 },
  log.lambda = TRUE,
  lambdas,
  prec = 1e-04,
  ada_mult = 2,
  max.iter = 10000,
  standardize = TRUE,
  vargamma = ifelse(pvar == "scad" | penalty == "sgs", 4, 3),
  grgamma = ifelse(pgr == "scad" | penalty == "sgs", 4, 3),
  vartau = 1,
  grtau = 1,
  pvar = c("lasso", "scad", "mcp", "exp"),
  pgr = c("lasso", "scad", "mcp", "exp"),
  group.weight = rep(1, length(unique(group))),
  returnX = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sgp_+3A_x">X</code></td>
<td>
<p>The design matrix without intercept with the variables to be selected.</p>
</td></tr>
<tr><td><code id="sgp_+3A_y">y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code id="sgp_+3A_group">group</code></td>
<td>
<p>A vector indicating the group membership of each variable in X.</p>
</td></tr>
<tr><td><code id="sgp_+3A_penalty">penalty</code></td>
<td>
<p>A string that specifies the sparse group penalty to be used.</p>
</td></tr>
<tr><td><code id="sgp_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter for the mixture of penalties at group and variable level.
A value of 0 results in a selection at group level, a value of 1
results in a selection at variable level and everything in between
is bi-level selection.</p>
</td></tr>
<tr><td><code id="sgp_+3A_type">type</code></td>
<td>
<p>A string indicating the type of regression model (linear or binomial).</p>
</td></tr>
<tr><td><code id="sgp_+3A_z">Z</code></td>
<td>
<p>The design matrix of the variables to be included in the model without penalization.</p>
</td></tr>
<tr><td><code id="sgp_+3A_nlambda">nlambda</code></td>
<td>
<p>An integer that specifies the length of the lambda sequence.</p>
</td></tr>
<tr><td><code id="sgp_+3A_lambda.min">lambda.min</code></td>
<td>
<p>An integer multiplied by the maximum lambda to define the end of the lambda sequence.</p>
</td></tr>
<tr><td><code id="sgp_+3A_log.lambda">log.lambda</code></td>
<td>
<p>A Boolean value that specifies whether the values of the lambda
sequence should be on the log scale.</p>
</td></tr>
<tr><td><code id="sgp_+3A_lambdas">lambdas</code></td>
<td>
<p>A user supplied vector with values for lambda.</p>
</td></tr>
<tr><td><code id="sgp_+3A_prec">prec</code></td>
<td>
<p>The convergence threshold for the algorithm.</p>
</td></tr>
<tr><td><code id="sgp_+3A_ada_mult">ada_mult</code></td>
<td>
<p>An integer that defines the multiplier for adjusting the convergence threshold.</p>
</td></tr>
<tr><td><code id="sgp_+3A_max.iter">max.iter</code></td>
<td>
<p>The convergence threshold for the algorithm.</p>
</td></tr>
<tr><td><code id="sgp_+3A_standardize">standardize</code></td>
<td>
<p>An integer that defines the multiplier for adjusting the convergence threshold.</p>
</td></tr>
<tr><td><code id="sgp_+3A_vargamma">vargamma</code></td>
<td>
<p>An integer that defines the value of gamma for the penalty at the variable level.</p>
</td></tr>
<tr><td><code id="sgp_+3A_grgamma">grgamma</code></td>
<td>
<p>An integer that specifies the value of gamma for the penalty at the group level.</p>
</td></tr>
<tr><td><code id="sgp_+3A_vartau">vartau</code></td>
<td>
<p>An integer that defines the value of tau for the penalty at the variable level.</p>
</td></tr>
<tr><td><code id="sgp_+3A_grtau">grtau</code></td>
<td>
<p>An integer that specifies the value of tau for the penalty at the group level.</p>
</td></tr>
<tr><td><code id="sgp_+3A_pvar">pvar</code></td>
<td>
<p>A string that specifies the penalty used at the variable level.</p>
</td></tr>
<tr><td><code id="sgp_+3A_pgr">pgr</code></td>
<td>
<p>A string that specifies the penalty used at the group level.</p>
</td></tr>
<tr><td><code id="sgp_+3A_group.weight">group.weight</code></td>
<td>
<p>A vector specifying weights that are multiplied by the group
penalty to account for different group sizes.</p>
</td></tr>
<tr><td><code id="sgp_+3A_returnx">returnX</code></td>
<td>
<p>A Boolean value that specifies whether standardized design matrix should be returned.</p>
</td></tr>
<tr><td><code id="sgp_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two options are available for choosing a penalty. With the argument <code>penalty</code>,
the methods Sparse Group LASSO, Sparse Group SCAD, Sparse Group MCP and Sparse Group EP
can be selected with the abbreviations <code>sgl</code>, <code>sgs</code>, <code>sgm</code> and <code>sge</code>.
Alternatively, penalties can be combined additively with the arguments <code>pvar</code>
and <code>pgr</code>, where <code>pvar</code> is the penalty applied at the variable level and
<code>pgr</code> is the penalty applied at the group level. The options are <code>lasso</code>,
<code>scad</code>, <code>mcp</code> and <code>exp</code> for Least Absolute Shrinkage and Selection Operator,
Smoothly Clipped Absolute Deviation, Minimax Concave Penalty and Exponential Penalty.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<dl>
<dt>beta</dt><dd><p>A vector with estimated coefficients.</p>
</dd>
<dt>type</dt><dd><p>A string indicating the type of regression model (linear or binomial).</p>
</dd>
<dt>group</dt><dd><p>A vector indicating the group membership of the individual variables in X.</p>
</dd>
<dt>lambdas</dt><dd><p>The sequence of lambda values.</p>
</dd>
<dt>alpha</dt><dd><p>Tuning parameter for the mixture of penalties at group and variable level.</p>
</dd>
<dt>loss</dt><dd><p>A vector containing either the residual sum of squares (linear) or the negative log-likelihood (binomial).</p>
</dd>
<dt>prec</dt><dd><p>The convergence threshold used for each lambda.</p>
</dd>
<dt>n</dt><dd><p>Number of observations.</p>
</dd>
<dt>penalty</dt><dd><p>A string indicating the sparse group penalty used.</p>
</dd>
<dt>df</dt><dd><p>A vector of pseudo degrees of freedom for each lambda.</p>
</dd>
<dt>iter</dt><dd><p>A vector of the number of iterations for each lambda.</p>
</dd>
<dt>group.weight</dt><dd><p>A vector of weights multiplied by the group penalty.</p>
</dd>
<dt>y</dt><dd><p>The response vector.</p>
</dd>
<dt>X</dt><dd><p>The design matrix without intercept.</p>
</dd>
</dl>



<h3>References</h3>


<ul>
<li><p> Buch, G., Schulz, A., Schmidtmann, I., Strauch, K., and Wild, P. S. (2024)
Sparse Group Penalties for bi-level variable selection. Biometrical Journal, 66, 2200334.
<a href="https://doi.org/10.1002/bimj.202200334">doi:10.1002/bimj.202200334</a>
</p>
</li>
<li><p> Simon, N., Friedman, J., Hastie, T., and Tibshirani, R. (2011)
A Sparse-Group Lasso. Journal of computational and graphical statistics, 22(2), 231-245.
<a href="https://doi.org/10.1080/10618600.2012.681250">doi:10.1080/10618600.2012.681250</a>
</p>
</li>
<li><p>  Breheny, P., and Huang J. (2009)
Penalized methods for bi-level variable selection. Statistics and its interface, 2: 369-380.
<a href="https://doi.org/10.4310/sii.2009.v2.n3.a10">doi:10.4310/sii.2009.v2.n3.a10</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Generate data
 n &lt;- 100
 p &lt;- 200
 nr &lt;- 10
 g &lt;- ceiling(1:p / nr)
 X &lt;- matrix(rnorm(n * p), n, p)
 b &lt;- c(-3:3)
 y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
 y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

# Linear regression
 lin_fit &lt;- sgp(X, y_lin, g, type = "linear", penalty = "sgl")
 plot(lin_fit)
 lin_fit &lt;- sgp(X, y_lin, g, type = "linear", penalty = "sgs")
 plot(lin_fit)
 lin_fit &lt;- sgp(X, y_lin, g, type = "linear", penalty = "sgm")
 plot(lin_fit)
 lin_fit &lt;- sgp(X, y_lin, g, type = "linear", penalty = "sge")
 plot(lin_fit)

# Logistic regression
 log_fit &lt;- sgp(X, y_log, g, type = "logit", penalty = "sgl")
 plot(log_fit)
 log_fit &lt;- sgp(X, y_log, g, type = "logit", penalty = "sgs")
 plot(log_fit)
 log_fit &lt;- sgp(X, y_log, g, type = "logit", penalty = "sgm")
 plot(log_fit)
 log_fit &lt;- sgp(X, y_log, g, type = "logit", penalty = "sge")
 plot(log_fit)

</code></pre>

<hr>
<h2 id='sgp.cv'>Cross-validation for sparse group penalties</h2><span id='topic+sgp.cv'></span>

<h3>Description</h3>

<p>A function that performs k-fold cross-validation for sparse group penalties for a lambda sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sgp.cv(
  X,
  y,
  group = 1:ncol(X),
  Z = NULL,
  ...,
  nfolds = 10,
  seed,
  fold,
  type,
  returnY = FALSE,
  print.trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sgp.cv_+3A_x">X</code></td>
<td>
<p>The design matrix without intercept with the variables to be selected.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_y">y</code></td>
<td>
<p>The response vector.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_group">group</code></td>
<td>
<p>A vector indicating the group membership of each variable in X.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_z">Z</code></td>
<td>
<p>The design matrix of the variables to be included in the model without penalization.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_...">...</code></td>
<td>
<p>Other parameters of underlying basic functions.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds for cross-validation.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_seed">seed</code></td>
<td>
<p>A seed provided by the user for the random number generator.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_fold">fold</code></td>
<td>
<p>A vector of folds specified by the user (default is a random assignment).</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_type">type</code></td>
<td>
<p>A string indicating the type of regression model (linear or binomial).</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_returny">returnY</code></td>
<td>
<p>A Boolean value indicating whether the fitted values should be returned.</p>
</td></tr>
<tr><td><code id="sgp.cv_+3A_print.trace">print.trace</code></td>
<td>
<p>A Boolean value that specifies whether the beginning of a fold should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<dl>
<dt>cve</dt><dd><p>The average cross-validation error for each value of lambda.</p>
</dd>
<dt>cvse</dt><dd><p>The estimated standard error for each value of cve.</p>
</dd>
<dt>lambdas</dt><dd><p>The sequence of lambda values.</p>
</dd>
<dt>fit</dt><dd><p>The sparse group penalty model fitted to the entire data.</p>
</dd>
<dt>fold</dt><dd><p>The fold assignments for each observation for the cross-validation procedure.</p>
</dd>
<dt>min</dt><dd><p>The index of lambda corresponding to the minimum cross-validation error.</p>
</dd>
<dt>lambda.min</dt><dd><p>The value of lambda with the minimum cross-validation error.</p>
</dd>
<dt>null.dev</dt><dd><p>The deviance for the empty model.</p>
</dd>
<dt>pe</dt><dd><p>The cross-validation prediction error for each value of lambda (for binomial only).</p>
</dd>
<dt>pred</dt><dd><p>The fitted values from the cross-validation folds.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# Generate data
 n &lt;- 100
 p &lt;- 200
 nr &lt;- 10
 g &lt;- ceiling(1:p / nr)
 X &lt;- matrix(rnorm(n * p), n, p)
 b &lt;- c(-3:3)
 y_lin &lt;- X[, 1:length(b)] %*% b + 5 * rnorm(n)
 y_log &lt;- rbinom(n, 1, exp(y_lin) / (1 + exp(y_lin)))

# Linear regression
 lin_fit &lt;- sgp.cv(X, y_lin, g, type = "linear", penalty = "sgl")
 plot(lin_fit)
 predict(lin_fit, extract = "vars")
 lin_fit &lt;- sgp.cv(X, y_lin, g, type = "linear", penalty = "sgs")
 plot(lin_fit)
 predict(lin_fit, extract = "vars")
 lin_fit &lt;- sgp.cv(X, y_lin, g, type = "linear", penalty = "sgm")
 plot(lin_fit)
 predict(lin_fit, extract = "vars")
 lin_fit &lt;- sgp.cv(X, y_lin, g, type = "linear", penalty = "sge")
 plot(lin_fit)
 predict(lin_fit, extract = "vars")

# Logistic regression
 log_fit &lt;- sgp.cv(X, y_log, g, type = "logit", penalty = "sgl")
 plot(log_fit)
 predict(log_fit, extract = "vars")
 log_fit &lt;- sgp.cv(X, y_log, g, type = "logit", penalty = "sgs")
 plot(log_fit)
 predict(log_fit, extract = "vars")
 log_fit &lt;- sgp.cv(X, y_log, g, type = "logit", penalty = "sgm")
 plot(log_fit)
 predict(log_fit, extract = "vars")
 log_fit &lt;- sgp.cv(X, y_log, g, type = "logit", penalty = "sge")
 plot(log_fit)
 predict(log_fit, extract = "vars")


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
