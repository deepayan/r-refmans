<!DOCTYPE html><html lang="en"><head><title>Help for package clustMixType</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {clustMixType}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#clprofiles'><p>Profiling k-Prototypes Clustering</p></a></li>
<li><a href='#kproto'><p>k-Prototypes Clustering</p></a></li>
<li><a href='#lambdaest'><p>Compares Variability of Variables</p></a></li>
<li><a href='#plot.kproto'><p>Assign k-Prototypes Clusters</p></a></li>
<li><a href='#predict.kproto'><p>Assign k-Prototypes Clusters</p></a></li>
<li><a href='#stability_kproto'><p>Determination the stability of k Prototypes Clustering</p></a></li>
<li><a href='#summary.kproto'><p>Summary Method for kproto Cluster Result</p></a></li>
<li><a href='#validation_kproto'><p>Validating k Prototypes Clustering</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.4-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-06-27</td>
</tr>
<tr>
<td>Title:</td>
<td>k-Prototypes Clustering for Mixed Variable-Type Data</td>
</tr>
<tr>
<td>Author:</td>
<td>Gero Szepannek [aut, cre], Rabea Aschenbruck [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gero Szepannek &lt;gero.szepannek@web.de&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>RColorBrewer, tibble, combinat, dplyr, rlang</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to perform k-prototypes partitioning clustering for
    mixed variable-type data according to Z.Huang (1998): Extensions to the k-Means
    Algorithm for Clustering Large Data Sets with Categorical Variables, Data Mining
    and Knowledge Discovery 2, 283-304.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-27 06:21:12 UTC; aschenbruck</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-01 13:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='clprofiles'>Profiling k-Prototypes Clustering</h2><span id='topic+clprofiles'></span>

<h3>Description</h3>

<p>Visualization of a k-prototypes clustering result for cluster interpretation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clprofiles(object, x, vars = NULL, col = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clprofiles_+3A_object">object</code></td>
<td>
<p>Object resulting from a call of resulting <code>kproto</code>. Also other <code>kmeans</code> like objects with <code>object$cluster</code> and <code>object$size</code> are possible.</p>
</td></tr>
<tr><td><code id="clprofiles_+3A_x">x</code></td>
<td>
<p>Original data.</p>
</td></tr>
<tr><td><code id="clprofiles_+3A_vars">vars</code></td>
<td>
<p>Optional vector of either column indices or variable names.</p>
</td></tr>
<tr><td><code id="clprofiles_+3A_col">col</code></td>
<td>
<p>Palette of cluster colours to be used for the plots. As a default RColorBrewer's 
<code>brewer.pal(max(unique(object$cluster)), "Set3")</code> is used for k &gt; 2 clusters and lightblue and orange else.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For numerical variables boxplots and for factor variables barplots of each cluster are generated.
</p>


<h3>Author(s)</h3>

<p><a href="mailto:gero.szepannek@web.de">gero.szepannek@web.de</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate toy data with factors and numerics

n   &lt;- 100
prb &lt;- 0.9
muk &lt;- 1.5 
clusid &lt;- rep(1:4, each = n)

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)

x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)

x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))

x &lt;- data.frame(x1,x2,x3,x4)

# apply k-prototyps
kpres &lt;- kproto(x, 4)
clprofiles(kpres, x)

# in real world clusters are often not as clear cut
# by variation of lambda the emphasize is shifted towards factor / numeric variables    
kpres &lt;- kproto(x, 2)
clprofiles(kpres, x)

kpres &lt;- kproto(x, 2, lambda = 0.1)
clprofiles(kpres, x)

kpres &lt;- kproto(x, 2, lambda = 25)
clprofiles(kpres, x)

</code></pre>

<hr>
<h2 id='kproto'>k-Prototypes Clustering</h2><span id='topic+kproto'></span><span id='topic+kproto.default'></span>

<h3>Description</h3>

<p>Computes k-prototypes clustering for mixed-type data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kproto(x, ...)

## Default S3 method:
kproto(
  x,
  k,
  lambda = NULL,
  type = "huang",
  iter.max = 100,
  nstart = 1,
  na.rm = "yes",
  keep.data = TRUE,
  verbose = TRUE,
  init = NULL,
  p_nstart.m = 0.9,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kproto_+3A_x">x</code></td>
<td>
<p>Data frame with both numerics and factors (also ordered factors are possible).</p>
</td></tr>
<tr><td><code id="kproto_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="kproto_+3A_k">k</code></td>
<td>
<p>Either the number of clusters, a vector specifying indices of initial prototypes, or a data frame of 
prototypes of the same columns as <code>x</code>.</p>
</td></tr>
<tr><td><code id="kproto_+3A_lambda">lambda</code></td>
<td>
<p>Parameter &gt; 0 to trade off between Euclidean distance of numeric variables and simple matching 
coefficient between categorical variables (if <code>type = "huang"</code>). Also a vector of variable specific factors 
is possible where the order must correspond to the order of the variables in the data. In this case all variables' 
distances will be multiplied by their corresponding lambda value.</p>
</td></tr>
<tr><td><code id="kproto_+3A_type">type</code></td>
<td>
<p>Character, to specify the distance for clustering. Either <code>"huang"</code> or <code>"gower"</code> (cf. details 
below).</p>
</td></tr>
<tr><td><code id="kproto_+3A_iter.max">iter.max</code></td>
<td>
<p>Numeric; maximum number of iterations if no convergence before.</p>
</td></tr>
<tr><td><code id="kproto_+3A_nstart">nstart</code></td>
<td>
<p>Numeric; If &gt; 1 repetitive computations with random initializations are computed and the result with 
minimum <code>tot.dist</code> is returned.</p>
</td></tr>
<tr><td><code id="kproto_+3A_na.rm">na.rm</code></td>
<td>
<p>Character, either <code>"yes"</code> to strip <code>NA</code> values for complete case analysis, <code>"no"</code> to 
keep and ignore <code>NA</code> values, <code>"imp.internal"</code> to impute the <code>NAs</code> within the algorithm or 
<code>"imp.onestep"</code> to apply the algorithm ignoring the <code>NAs</code> and impute them after the partition is determined.</p>
</td></tr>
<tr><td><code id="kproto_+3A_keep.data">keep.data</code></td>
<td>
<p>Logical, whether original should be included in the returned object.</p>
</td></tr>
<tr><td><code id="kproto_+3A_verbose">verbose</code></td>
<td>
<p>Logical, whether additional information about process should be printed. 
Caution: For <code>verbose=FALSE</code>, if the number of clusters is reduced during the iterations it will not mentioned.</p>
</td></tr>
<tr><td><code id="kproto_+3A_init">init</code></td>
<td>
<p>Character, to specify the initialization strategy. Either <code>"nbh.dens"</code>, <code>"sel.cen"</code> or 
<code>"nstart.m"</code>. Default is <code>"NULL"</code>, which results in nstart repetitive algorithm computations with random 
starting prototypes. Otherwise, <code>nstart</code> is not used. Argument <code>k</code> must be a number if a specific 
initialization strategy is choosen!</p>
</td></tr>
<tr><td><code id="kproto_+3A_p_nstart.m">p_nstart.m</code></td>
<td>
<p>Numeric, probability(=0.9 is default) for <code>init="nstart.m"</code>, where the strategy assures 
that with a probability of <code>p_nstart.m</code> at least one of the m sets of initial prototypes contains objects 
of every cluster group (cf. Aschenbruck et al. (2023): Random-based Initialization for clustering mixed-type data 
with the k-Prototypes algorithm. In: <em>Cladag 2023 Book of abstracts and short spapers</em>, isbn: 9788891935632.).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Like k-means, the k-prototypes algorithm iteratively recomputes cluster prototypes and reassigns 
clusters, whereby with <code>type = "huang"</code> clusters are assigned using the distance
<code class="reqn">d(x,y) =  d_{euclid}(x,y) + \lambda d_{simple\,matching}(x,y)</code>. Cluster prototypes are computed as 
cluster means for numeric variables and modes for factors (cf. Huang, 1998). Ordered factors variables 
are treated as categorical variables.<br />
For <code>type = "gower"</code> range-normalized absolute distances from the cluster median are computed for 
the numeric variables (and for the ranks of the ordered factors respectively). For factors simple matching 
distance is used as in the original k prototypes algorithm. The prototypes are given by the median for 
numeric variables, the mode for factors and the level with the closest rank to the median rank of the 
corresponding cluster (cf. Szepannek et al., 2024).<br />
In case of <code>na.rm = FALSE</code>: for each observation variables with missings are ignored (i.e. only the 
remaining variables are considered for distance computation). In consequence for observations with missings 
this might result in a change of variable's weighting compared to the one specified by <code>lambda</code>. For 
these observations distances to the prototypes will typically be smaller as they are based on fewer variables.<br />
The <code>type</code> argument also accepts input <code>"standard"</code>, but this naming convention is deprecated and 
has been renamed to <code>"huang"</code>. Please use <code>"huang"</code> instead.
</p>


<h3>Value</h3>

<p><code><a href="stats.html#topic+kmeans">kmeans</a></code> like object of class <code>kproto</code>:
</p>
<table role = "presentation">
<tr><td><code>cluster</code></td>
<td>
<p>Vector of cluster memberships.</p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p>Data frame of cluster prototypes.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Distance parameter lambda.</p>
</td></tr>
<tr><td><code>size</code></td>
<td>
<p>Vector of cluster sizes.</p>
</td></tr>
<tr><td><code>withinss</code></td>
<td>
<p>Vector of within cluster distances for each cluster, i.e. summed distances of all observations belonging to a cluster to their respective prototype.</p>
</td></tr>
<tr><td><code>tot.withinss</code></td>
<td>
<p>Target function: sum of all observations' distances to their corresponding cluster prototype.</p>
</td></tr>
<tr><td><code>dists</code></td>
<td>
<p>Matrix with distances of observations to all cluster prototypes.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Prespecified maximum number of iterations.</p>
</td></tr>
<tr><td><code>trace</code></td>
<td>
<p>List with two elements (vectors) tracing the iteration process: 
<code>tot.dists</code> and <code>moved</code> number of observations over all iterations.</p>
</td></tr>
<tr><td><code>inits</code></td>
<td>
<p>Initial prototypes determined by specified initialization strategy, if init is either 'nbh.dens' or 'sel.cen'.</p>
</td></tr>
<tr><td><code>nstart.m</code></td>
<td>
<p>only for 'init = nstart_m': determined number of randomly choosen sets.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>if 'keep.data = TRUE' than the original data will be added to the output list.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Type argument of the function call.</p>
</td></tr>
<tr><td><code>stdization</code></td>
<td>
<p>Only returned for <code>type = "gower"</code>: List of standardized ranks for ordinal variables 
and an additional element <code>num_ranges</code> with ranges of all numeric variables. Used by <code><a href="#topic+predict.kproto">predict.kproto</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p><a href="mailto:gero.szepannek@web.de">gero.szepannek@web.de</a>
</p>


<h3>References</h3>


<ul>
<li><p> Szepannek, G. (2018): clustMixType: User-Friendly Clustering of Mixed-Type Data in R, 
<em>The R Journal 10/2</em>, 200-208, <a href="https://doi.org/10.32614/RJ-2018-048">doi:10.32614/RJ-2018-048</a>.
</p>
</li>
<li><p> Aschenbruck, R., Szepannek, G., Wilhelm, A. (2022): Imputation Strategies for Clustering Mixed‑Type Data with Missing Values, 
<em>Journal of Classification</em>, <a href="https://doi.org/10.1007/s00357-022-09422-y">doi:10.1007/s00357-022-09422-y</a>. 
</p>
</li>
<li><p> Szepannek, G., Aschenbruck, R., Wilhelm, A. (2024): Clustering Large Mixed-Type Data with Ordinal Variables,
<em>Advances in Data Analysis and Classification</em>, <a href="https://doi.org/10.1007/s11634-024-00595-5">doi:10.1007/s11634-024-00595-5</a>.
</p>
</li>
<li><p> Z.Huang (1998): Extensions to the k-Means Algorithm for Clustering Large Data Sets with Categorical Variables, 
<em>Data Mining and Knowledge Discovery 2</em>, 283-304.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># generate toy data with factors and numerics

n   &lt;- 100
prb &lt;- 0.9
muk &lt;- 1.5 
clusid &lt;- rep(1:4, each = n)

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)

x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)

x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))

x &lt;- data.frame(x1,x2,x3,x4)

# apply k-prototypes
kpres &lt;- kproto(x, 4)
clprofiles(kpres, x)

# in real world clusters are often not as clear cut
# by variation of lambda the emphasize is shifted towards factor / numeric variables    
kpres &lt;- kproto(x, 2)
clprofiles(kpres, x)

kpres &lt;- kproto(x, 2, lambda = 0.1)
clprofiles(kpres, x)

kpres &lt;- kproto(x, 2, lambda = 25)
clprofiles(kpres, x)

</code></pre>

<hr>
<h2 id='lambdaest'>Compares Variability of Variables</h2><span id='topic+lambdaest'></span>

<h3>Description</h3>

<p>Investigation of the variables' variances/concentrations to support specification of lambda for k-prototypes clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambdaest(
  x,
  num.method = 1,
  fac.method = 1,
  outtype = "numeric",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lambdaest_+3A_x">x</code></td>
<td>
<p>Data.frame with both numerics and factors.</p>
</td></tr>
<tr><td><code id="lambdaest_+3A_num.method">num.method</code></td>
<td>
<p>Integer 1 or 2. Specifies the heuristic used for numeric variables.</p>
</td></tr>
<tr><td><code id="lambdaest_+3A_fac.method">fac.method</code></td>
<td>
<p>Integer 1 or 2. Specifies the heuristic used for factor variables.</p>
</td></tr>
<tr><td><code id="lambdaest_+3A_outtype">outtype</code></td>
<td>
<p>Specifies the desired output: either 'numeric', 'vector' or 'variation'.</p>
</td></tr>
<tr><td><code id="lambdaest_+3A_verbose">verbose</code></td>
<td>
<p>Logical whether additional information about process should be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variance (<code>num.method = 1</code>) or standard deviation (<code>num.method = 2</code>) of numeric variables 
and <code class="reqn">1-\sum_i p_i^2</code> (<code>fac.method = 1</code>) or <code class="reqn">1-\max_i p_i</code> (<code>fac.method = 2</code>) for factors is computed.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>lambda</code></td>
<td>
<p>Ratio of averages over all numeric/factor variables is returned. 
In case of <code>outtype = "vector"</code> the separate lambda for all variables is returned as the inverse of the single variables' 
variation as specified by the <code>num.method</code> and <code>fac.method</code> argument. <code>outtype = "variation"</code> directly returns these quantities and is not meant to be 
passed directly to <code>kproto()</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p><a href="mailto:gero.szepannek@web.de">gero.szepannek@web.de</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate toy data with factors and numerics

n   &lt;- 100
prb &lt;- 0.9
muk &lt;- 1.5 
clusid &lt;- rep(1:4, each = n)

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)

x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)

x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))

x &lt;- data.frame(x1,x2,x3,x4)

lambdaest(x)
res &lt;- kproto(x, 4, lambda = lambdaest(x))

</code></pre>

<hr>
<h2 id='plot.kproto'>Assign k-Prototypes Clusters</h2><span id='topic+plot.kproto'></span>

<h3>Description</h3>

<p>Plot distributions of the clusters across the variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kproto'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kproto_+3A_x">x</code></td>
<td>
<p>Object resulting from a call of <code>kproto</code>.</p>
</td></tr>
<tr><td><code id="plot.kproto_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passet to <code><a href="#topic+clprofiles">clprofiles</a></code> such as e.g. <code>vars</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Wrapper around <code><a href="#topic+clprofiles">clprofiles</a></code>. Only works for <code>kproto</code> object created with <code>keep.data = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p><a href="mailto:gero.szepannek@web.de">gero.szepannek@web.de</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate toy data with factors and numerics

n   &lt;- 100
prb &lt;- 0.9
muk &lt;- 1.5 
clusid &lt;- rep(1:4, each = n)

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)

x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)

x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))

x &lt;- data.frame(x1,x2,x3,x4)

# apply k-prototyps
kpres &lt;- kproto(x, 4)
plot(kpres, vars = c("x1","x3")) 


</code></pre>

<hr>
<h2 id='predict.kproto'>Assign k-Prototypes Clusters</h2><span id='topic+predict.kproto'></span>

<h3>Description</h3>

<p>Predicts k-prototypes cluster memberships and distances for new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kproto'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.kproto_+3A_object">object</code></td>
<td>
<p>Object resulting from a call of <code>kproto</code>.</p>
</td></tr>
<tr><td><code id="predict.kproto_+3A_newdata">newdata</code></td>
<td>
<p>New data frame (of same structure) where cluster memberships are to be predicted.</p>
</td></tr>
<tr><td><code id="predict.kproto_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="stats.html#topic+kmeans">kmeans</a></code> like object of class <code>kproto</code>:
</p>
<table role = "presentation">
<tr><td><code>cluster</code></td>
<td>
<p>Vector of cluster memberships.</p>
</td></tr>
<tr><td><code>dists</code></td>
<td>
<p>Matrix with distances of observations to all cluster prototypes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p><a href="mailto:gero.szepannek@web.de">gero.szepannek@web.de</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate toy data with factors and numerics

n   &lt;- 100
prb &lt;- 0.9
muk &lt;- 1.5 
clusid &lt;- rep(1:4, each = n)

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)

x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)

x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))

x &lt;- data.frame(x1,x2,x3,x4)

# apply k-prototyps
kpres &lt;- kproto(x, 4)
predicted.clusters &lt;- predict(kpres, x) 


</code></pre>

<hr>
<h2 id='stability_kproto'>Determination the stability of k Prototypes Clustering</h2><span id='topic+stability_kproto'></span>

<h3>Description</h3>

<p>Calculating the stability for a k-Prototypes clustering with k clusters or computing the stability-based optimal number of clusters for k-Prototype clustering. Possible stability indices are: <code>Jaccard</code>, <code>Rand</code>, <code>Fowlkes \&amp; Mallows</code> and <code>Luxburg</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stability_kproto(
  object,
  method = c("rand", "jaccard", "luxburg", "fowlkesmallows"),
  B = 100,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stability_kproto_+3A_object">object</code></td>
<td>
<p>Object of class <code>kproto</code> resulting from a call with <code>kproto(..., keep.data=TRUE)</code></p>
</td></tr>
<tr><td><code id="stability_kproto_+3A_method">method</code></td>
<td>
<p>character specifying the stability, either one or more of <code>luxburg</code>, <code>fowlkesmallows</code>, <code>rand</code> or/and <code>jaccard</code>.</p>
</td></tr>
<tr><td><code id="stability_kproto_+3A_b">B</code></td>
<td>
<p>numeric, number of bootstrap samples</p>
</td></tr>
<tr><td><code id="stability_kproto_+3A_verbose">verbose</code></td>
<td>
<p>Logical whether information about the bootstrap procedure should be given.</p>
</td></tr>
<tr><td><code id="stability_kproto_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="#topic+kproto">kproto</a></code>, like:
</p>

<ul>
<li> <p><code>nstart</code>: If &gt; 1 repetitive computations of <code>kproto</code> with random initial prototypes are computed.
</p>
</li>
<li> <p><code>lambda</code>: Factor to trade off between Euclidean distance of numeric variables and simple matching coefficient between categorical variables.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>The output contains the stability for a given k-Prototype clustering in a list with two elements:
</p>
<table role = "presentation">
<tr><td><code>kp_stab</code></td>
<td>
<p>stability values for the given clustering</p>
</td></tr>
<tr><td><code>kp_bts_stab</code></td>
<td>
<p>stability values for each bootstrap samples</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rabea Aschenbruck
</p>


<h3>References</h3>


<ul>
<li><p> Aschenbruck, R., Szepannek, G., Wilhelm, A.F.X (2023): 
Stability of mixed-type cluster partitions for determination of the number of clusters. 
<em>Submitted</em>.
</p>
</li>
<li><p> von Luxburg, U. (2010): 
Clustering stability: an overview. 
<em>Foundations and Trends in Machine Learning, Vol 2, Issue 3</em>.
<a href="https://doi.org/10.1561/2200000008">doi:10.1561/2200000008</a>.
</p>
</li>
<li><p> Ben-Hur, A., Elisseeff, A., Guyon, I. (2002): 
A stability based method for discovering structure in clustered data. 
<em>Pacific Symposium on Biocomputing</em>.
<a href="https://doi.org/10/bhfxmf">doi:10/bhfxmf</a>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# generate toy data with factors and numerics
n   &lt;- 10
prb &lt;- 0.99
muk &lt;- 2.5 

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)
x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)
x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x &lt;- data.frame(x1,x2,x3,x4)

#' # apply k-prototypes
kpres &lt;- kproto(x, 4, keep.data = TRUE)

# calculate cluster stability
stab &lt;- stability_kproto(method = c("luxburg","fowlkesmallows"), object = kpres)


## End(Not run)

</code></pre>

<hr>
<h2 id='summary.kproto'>Summary Method for kproto Cluster Result</h2><span id='topic+summary.kproto'></span>

<h3>Description</h3>

<p>Investigation of variances to specify lambda for k-prototypes clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kproto'
summary(object, data = NULL, pct.dig = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.kproto_+3A_object">object</code></td>
<td>
<p>Object of class <code>kproto</code>.</p>
</td></tr>
<tr><td><code id="summary.kproto_+3A_data">data</code></td>
<td>
<p>Optional data set to be analyzed. If <code>!(is.null(data))</code> clusters for <code>data</code> are assigned by 
<code>predict(object, data)</code>. If not specified the clusters of the original data ara analyzed which is only possible if <code>kproto</code> 
has been called using <code>keep.data = TRUE</code>.</p>
</td></tr>
<tr><td><code id="summary.kproto_+3A_pct.dig">pct.dig</code></td>
<td>
<p>Number of digits for rounding percentages of factor variables.</p>
</td></tr>
<tr><td><code id="summary.kproto_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to internal call of <code>summary()</code> for numeric variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For numeric variables statistics are computed for each clusters using <code>summary()</code>. 
For categorical variables distribution percentages are computed.
</p>


<h3>Value</h3>

<p>List where each element corresponds to one variable. Each row of any element corresponds to one cluster.
</p>


<h3>Author(s)</h3>

<p><a href="mailto:gero.szepannek@web.de">gero.szepannek@web.de</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate toy data with factors and numerics

n   &lt;- 100
prb &lt;- 0.9
muk &lt;- 1.5 
clusid &lt;- rep(1:4, each = n)

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)

x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)

x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))

x &lt;- data.frame(x1,x2,x3,x4)

res &lt;- kproto(x, 4)
summary(res)

</code></pre>

<hr>
<h2 id='validation_kproto'>Validating k Prototypes Clustering</h2><span id='topic+validation_kproto'></span>

<h3>Description</h3>

<p>Calculating the preferred validation index for a k-Prototypes clustering with k clusters or computing the optimal number of clusters based on the choosen index for k-Prototype clustering. Possible validation indices are: <code>cindex</code>, <code>dunn</code>, <code>gamma</code>, <code>gplus</code>, <code>mcclain</code>, <code>ptbiserial</code>, <code>silhouette</code> and <code>tau</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validation_kproto(
  method = "silhouette",
  object = NULL,
  data = NULL,
  type = "huang",
  k = NULL,
  lambda = NULL,
  kp_obj = "optimal",
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validation_kproto_+3A_method">method</code></td>
<td>
<p>Character specifying the validation index: <code>cindex</code>, <code>dunn</code>, <code>gamma</code>, <code>gplus</code>, <code>mcclain</code>, <code>ptbiserial</code>, <code>silhouette</code> (default) or <code>tau</code>.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_object">object</code></td>
<td>
<p>Object of class <code>kproto</code> resulting from a call with <code>kproto(..., keep.data=TRUE)</code>.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_data">data</code></td>
<td>
<p>Original data; only required if <code>object == NULL</code> and neglected if <code>object != NULL</code>.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_type">type</code></td>
<td>
<p>Character, to specify the distance for clustering; either <code>"huang"</code> or <code>"gower"</code>.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_k">k</code></td>
<td>
<p>Vector specifying the search range for optimum number of clusters; if <code>NULL</code> the range will set as <code>2:sqrt(n)</code>. Only required if <code>object == NULL</code> and neglected if <code>object != NULL</code>.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_lambda">lambda</code></td>
<td>
<p>Factor to trade off between Euclidean distance of numeric variables and simple matching coefficient between categorical variables.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_kp_obj">kp_obj</code></td>
<td>
<p>character either &quot;optimal&quot; or &quot;all&quot;: Output of the index-optimal clustering (kp_obj == &quot;optimal&quot;) or all computed cluster partitions (kp_obj == &quot;all&quot;); only required if <code>object != NULL</code>.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_verbose">verbose</code></td>
<td>
<p>Logical, whether additional information about process should be printed.</p>
</td></tr>
<tr><td><code id="validation_kproto_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="#topic+kproto">kproto</a></code>, like:
</p>

<ul>
<li> <p><code>nstart</code>: If &gt; 1 repetitive computations of <code>kproto</code> with random initializations are computed.
</p>
</li>
<li> <p><code>na.rm</code>: Character, either <code>"yes"</code> to strip <code>NA</code> values for complete case analysis, <code>"no"</code> to keep and ignore <code>NA</code> values, <code>"imp.internal"</code> to impute the <code>NAs</code> within the algorithm or <code>"imp.onestep"</code> to apply the algorithm ignoring the <code>NAs</code> and impute them after the partition is determined.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>More information about the implemented validation indices:
</p>

<ul>
<li> <p><code>cindex</code> </p>
<p style="text-align: center;"><code class="reqn">Cindex = \frac{S_w-S_{min}}{S_{max}-S_{min}}</code>
</p>
 <p><br />
For <code class="reqn">S_{min}</code> and <code class="reqn">S_{max}</code> it is necessary to calculate the distances between all pairs of points in the entire data set (<code class="reqn">\frac{n(n-1)}{2}</code>). 
<code class="reqn">S_{min}</code> is the sum of the &quot;total number of pairs of objects belonging to the same cluster&quot; smallest distances and 
<code class="reqn">S_{max}</code> is the sum of the &quot;total number of pairs of objects belonging to the same cluster&quot; largest distances. <code class="reqn">S_w</code> is the sum of the within-cluster distances. <br />
The minimum value of the index is used to indicate the optimal number of clusters.
</p>
</li>
<li> <p><code>dunn</code> </p>
<p style="text-align: center;"><code class="reqn">Dunn = \frac{\min_{1 \leq i &lt; j \leq q} d(C_i, C_j)}{\max_{1 \leq k \leq q} diam(C_k)}</code>
</p>
 <p><br />
The following applies: The dissimilarity between the two clusters <code class="reqn">C_i</code> and <code class="reqn">C_j</code> is defined as <code class="reqn">d(C_i, C_j)=\min_{x \in C_i, y \in C_j} d(x,y)</code> and
the diameter of a cluster is defined as <code class="reqn">diam(C_k)=\max_{x,y \in C} d(x,y)</code>. <br />
The maximum value of the index is used to indicate the optimal number of clusters.
</p>
</li>
<li> <p><code>gamma</code> </p>
<p style="text-align: center;"><code class="reqn">Gamma = \frac{s(+)-s(-)}{s(+)+s(-)}</code>
</p>
 <p><br /> 
Comparisons are made between all within-cluster dissimilarities and all between-cluster dissimilarities. 
<code class="reqn">s(+)</code> is the number of concordant comparisons and <code class="reqn">s(-)</code> is the number of discordant comparisons.
A comparison is named concordant (resp. discordant) if a within-cluster dissimilarity is strictly less (resp. strictly greater) than a between-cluster dissimilarity.<br />
The maximum value of the index is used to indicate the optimal number of clusters.
</p>
</li>
<li> <p><code>gplus</code> </p>
<p style="text-align: center;"><code class="reqn">Gplus = \frac{2 \cdot s(-)}{\frac{n(n-1)}{2} \cdot (\frac{n(n-1)}{2}-1)}</code>
</p>
 <p><br /> 
Comparisons are made between all within-cluster dissimilarities and all between-cluster dissimilarities. 
<code class="reqn">s(-)</code> is the number of discordant comparisons and a comparison is named discordant if a within-cluster 
dissimilarity is strictly greater than a between-cluster dissimilarity. <br />
The minimum value of the index is used to indicate the optimal number of clusters.
</p>
</li>
<li> <p><code>mcclain</code> </p>
<p style="text-align: center;"><code class="reqn">McClain = \frac{\bar{S}_w}{\bar{S}_b}</code>
</p>
 <p><br /> 
<code class="reqn">\bar{S}_w</code> is the sum of within-cluster distances divided by the number of within-cluster distances and 
<code class="reqn">\bar{S}_b</code> is the sum of between-cluster distances divided by the number of between-cluster distances.<br />
The minimum value of the index is used to indicate the optimal number of clusters.
</p>
</li>
<li><p><code>ptbiserial</code> </p>
<p style="text-align: center;"><code class="reqn">Ptbiserial = \frac{(\bar{S}_b-\bar{S}_w) \cdot (\frac{N_w \cdot N_b}{N_t^2})^{0.5}}{s_d}</code>
</p>
 <p><br /> 
<code class="reqn">\bar{S}_w</code> is the sum of within-cluster distances divided by the number of within-cluster distances and 
<code class="reqn">\bar{S}_b</code> is the sum of between-cluster distances divided by the number of between-cluster distances.<br />
<code class="reqn">N_t</code> is the total number of pairs of objects in the data, <code class="reqn">N_w</code> is the total number of pairs of 
objects belonging to the same cluster and <code class="reqn">N_b</code> is the total number of pairs of objects belonging to different clusters.
<code class="reqn">s_d</code> is the standard deviation of all distances.<br />
The maximum value of the index is used to indicate the optimal number of clusters.
</p>
</li>
<li> <p><code>silhouette</code> </p>
<p style="text-align: center;"><code class="reqn">Silhouette = \frac{1}{n} \sum_{i=1}^n \frac{b(i)-a(i)}{max(a(i),b(i))}</code>
</p>
 <p><br /> 
<code class="reqn">a(i)</code> is the average dissimilarity of the i<em>th</em> object to all other objects of the same/own cluster.
<code class="reqn">b(i)=min(d(i,C))</code>, where <code class="reqn">d(i,C)</code> is the average dissimilarity of the i<em>th</em> object to all the other clusters except the own/same cluster.<br />
The maximum value of the index is used to indicate the optimal number of clusters.
</p>
</li>
<li> <p><code>tau</code> </p>
<p style="text-align: center;"><code class="reqn">Tau = \frac{s(+) - s(-)}{((\frac{N_t(N_t-1)}{2}-t)\frac{N_t(N_t-1)}{2})^{0.5}}</code>
</p>
 <p><br /> 
Comparisons are made between all within-cluster dissimilarities and all between-cluster dissimilarities. 
<code class="reqn">s(+)</code> is the number of concordant comparisons and <code class="reqn">s(-)</code> is the number of discordant comparisons.
A comparison is named concordant (resp. discordant) if a within-cluster dissimilarity is strictly less 
(resp. strictly greater) than a between-cluster dissimilarity.<br />
<code class="reqn">N_t</code> is the total number of distances <code class="reqn">\frac{n(n-1)}{2}</code> and <code class="reqn">t</code> is the number of comparisons 
of two pairs of objects where both pairs represent within-cluster comparisons or both pairs are between-cluster
comparisons. <br />
The maximum value of the index is used to indicate the optimal number of clusters.
</p>
</li></ul>



<h3>Value</h3>

<p>For computing the optimal number of clusters based on the choosen validation index for k-Prototype clustering the output contains:
</p>
<table role = "presentation">
<tr><td><code>k_opt</code></td>
<td>
<p>optimal number of clusters (sampled in case of ambiguity)</p>
</td></tr>
<tr><td><code>index_opt</code></td>
<td>
<p>index value of the index optimal clustering</p>
</td></tr>
<tr><td><code>indices</code></td>
<td>
<p>calculated indices for <code class="reqn">k=2,...,k_{max}</code></p>
</td></tr>
<tr><td><code>kp_obj</code></td>
<td>
<p>if(kp_obj == &quot;optimal&quot;) the kproto object of the index optimal clustering and if(kp_obj == &quot;all&quot;) all kproto which were calculated</p>
</td></tr>
</table>
<p>For computing the index-value for a given k-Prototype clustering the output contains:
</p>
<table role = "presentation">
<tr><td><code>index</code></td>
<td>
<p>calculated index-value</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rabea Aschenbruck
</p>


<h3>References</h3>


<ul>
<li><p> Aschenbruck, R., Szepannek, G. (2020): 
Cluster Validation for Mixed-Type Data. 
<em>Archives of Data Science, Series A, Vol 6, Issue 1</em>.
<a href="https://doi.org/10.5445/KSP/1000098011/02">doi:10.5445/KSP/1000098011/02</a>.
</p>
</li>
<li><p> Charrad, M., Ghazzali, N., Boiteau, V., Niknafs, A. (2014): 
NbClust: An R Package for Determining the Relevant Number of Clusters in a Data Set. 
<em>Journal of Statistical Software, Vol 61, Issue 6</em>.
<a href="https://doi.org/10.18637/jss.v061.i06">doi:10.18637/jss.v061.i06</a>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# generate toy data with factors and numerics
n   &lt;- 10
prb &lt;- 0.99
muk &lt;- 2.5 

x1 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x1 &lt;- c(x1, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x1 &lt;- as.factor(x1)
x2 &lt;- sample(c("A","B"), 2*n, replace = TRUE, prob = c(prb, 1-prb))
x2 &lt;- c(x2, sample(c("A","B"), 2*n, replace = TRUE, prob = c(1-prb, prb)))
x2 &lt;- as.factor(x2)
x3 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x4 &lt;- c(rnorm(n, mean = -muk), rnorm(n, mean = muk), rnorm(n, mean = -muk), rnorm(n, mean = muk))
x &lt;- data.frame(x1,x2,x3,x4)


# calculate optimal number of cluster, index values and clusterpartition with Silhouette-index
val &lt;- validation_kproto(method = "silhouette", data = x, k = 3:5, nstart = 5)


# apply k-prototypes
kpres &lt;- kproto(x, 4, keep.data = TRUE)

# calculate cindex-value for the given clusterpartition
cindex_value &lt;- validation_kproto(method = "cindex", object = kpres)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
