<!DOCTYPE html><html lang="en-US"><head><title>Help for package fdapace</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fdapace}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BwNN'><p>Minimum bandwidth based on kNN criterion.</p></a></li>
<li><a href='#CheckData'><p>Check data format</p></a></li>
<li><a href='#CheckOptions'><p>Check option format</p></a></li>
<li><a href='#ConvertSupport'><p>Convert support of a mu/phi/cov etc. to and from obsGrid and workGrid</p></a></li>
<li><a href='#CreateBasis'><p>Create an orthogonal basis of K functions in [0, 1], with nGrid points.</p></a></li>
<li><a href='#CreateBWPlot'><p>Functional Principal Component Analysis Bandwidth Diagnostics plot</p></a></li>
<li><a href='#CreateCovPlot'><p>Creates a correlation surface plot based on the results from FPCA() or FPCder().</p></a></li>
<li><a href='#CreateDesignPlot'><p>Create design plots for functional data. See Yao, F., Müller, H.G., Wang, J.L. (2005). Functional</p>
data analysis for sparse longitudinal data. J. American Statistical Association 100, 577-590
for interpretation and usage of these plots.
This function will open a new device as default.</a></li>
<li><a href='#CreateDiagnosticsPlot'><p>Functional Principal Component Analysis Diagnostics plot</p></a></li>
<li><a href='#CreateFuncBoxPlot'><p>Create functional boxplot using 'bagplot', 'KDE' or 'pointwise' methodology</p></a></li>
<li><a href='#CreateModeOfVarPlot'><p>Functional Principal Component Analysis: Mode of variation plot</p></a></li>
<li><a href='#CreateOutliersPlot'><p>Functional Principal Component or Functional Singular Value Decomposition Scores Plot using 'bagplot' or 'KDE' methodology</p></a></li>
<li><a href='#CreatePathPlot'><p>Create the fitted sample path plot based on the results from FPCA().</p></a></li>
<li><a href='#CreateScreePlot'><p>Create the scree plot for the fitted eigenvalues</p></a></li>
<li><a href='#CreateStringingPlot'><p>Create plots for observed and stringed high dimensional data</p></a></li>
<li><a href='#cumtrapzRcpp'><p>Cumulative Trapezoid Rule Numerical Integration</p></a></li>
<li><a href='#Dyn_test'><p>Bootstrap test of Dynamic Correlation</p></a></li>
<li><a href='#DynCorr'><p>Dynamical Correlation</p></a></li>
<li><a href='#FAM'><p>Functional Additive Models</p></a></li>
<li><a href='#FCCor'><p>Calculation of functional correlation between two simultaneously observed processes.</p></a></li>
<li><a href='#FClust'><p>Functional clustering and identifying substructures of longitudinal data</p></a></li>
<li><a href='#FCReg'><p>Functional Concurrent Regression using 2D smoothing</p></a></li>
<li><a href='#fdapace'><p>fdapace: Functional Data Analysis and Empirical Dynamics</p></a></li>
<li><a href='#fitted.FPCA'><p>Fitted functional data from FPCA object</p></a></li>
<li><a href='#fitted.FPCAder'><p>Fitted functional data for derivatives from the FPCAder object</p></a></li>
<li><a href='#FLM'><p>Functional Linear Models</p></a></li>
<li><a href='#FLMCI'><p>Confidence Intervals for Functional Linear Models.</p></a></li>
<li><a href='#FOptDes'><p>Optimal Designs for Functional and Longitudinal Data</p>
for Trajectory Recovery or Scalar Response Prediction</a></li>
<li><a href='#FPCA'><p>Functional Principal Component Analysis</p></a></li>
<li><a href='#FPCAder'><p>Obtain the derivatives of eigenfunctions/ eigenfunctions of derivatives</p>
(note: these two are not the same)</a></li>
<li><a href='#FPCquantile'><p>Conditional Quantile estimation with functional covariates</p></a></li>
<li><a href='#FSVD'><p>Functional Singular Value Decomposition</p></a></li>
<li><a href='#FVPA'><p>Functional Variance Process Analysis for dense functional data</p></a></li>
<li><a href='#GetCovSurface'><p>Covariance Surface</p></a></li>
<li><a href='#GetCrCorYX'><p>Create cross-correlation matrix from auto- and cross-covariance matrix</p></a></li>
<li><a href='#GetCrCorYZ'><p>Create cross-correlation matrix from auto- and cross-covariance matrix</p></a></li>
<li><a href='#GetCrCovYX'><p>Functional Cross Covariance between longitudinal variable Y and longitudinal variable X</p></a></li>
<li><a href='#GetCrCovYZ'><p>Functional Cross Covariance between longitudinal variable Y and scalar variable Z</p></a></li>
<li><a href='#GetMeanCI'><p>Bootstrap pointwise confidence intervals for the mean function for densely observed data.</p></a></li>
<li><a href='#GetMeanCurve'><p>Mean Curve</p></a></li>
<li><a href='#GetNormalisedSample'><p>Normalise sparse multivariate functional data</p></a></li>
<li><a href='#kCFC'><p>Functional clustering and identifying substructures of longitudinal data using kCFC.</p></a></li>
<li><a href='#Lwls1D'><p>One dimensional local linear kernel smoother</p></a></li>
<li><a href='#Lwls2D'><p>Two dimensional local linear kernel smoother.</p></a></li>
<li><a href='#Lwls2DDeriv'><p>Two dimensional local linear kernel smoother to target derivatives.</p></a></li>
<li><a href='#MakeBWtoZscore02y'><p>Z-score body-weight for age 0 to 24 months based on WHO standards</p></a></li>
<li><a href='#MakeFPCAInputs'><p>Format FPCA input</p></a></li>
<li><a href='#MakeGPFunctionalData'><p>Create a Dense Functional Data sample for a Gaussian process</p></a></li>
<li><a href='#MakeHCtoZscore02y'><p>Z-score head-circumference for age 0 to 24 months based on WHO standards</p></a></li>
<li><a href='#MakeLNtoZscore02y'><p>Z-score height for age 0 to 24 months based on WHO standards</p></a></li>
<li><a href='#MakeSparseGP'><p>Create a sparse Functional Data sample for a Gaussian Process</p></a></li>
<li><a href='#medfly25'><p>Number of eggs laid daily from medflies</p></a></li>
<li><a href='#MultiFAM'><p>Functional Additive Models with Multiple Predictor Processes</p></a></li>
<li><a href='#NormCurvToArea'><p>Normalize a curve to a particular area, by multiplication with a factor</p></a></li>
<li><a href='#predict.FPCA'><p>Predict FPC scores and curves for a new sample given an FPCA object</p></a></li>
<li><a href='#print.FPCA'><p>Print an FPCA object</p></a></li>
<li><a href='#print.FSVD'><p>Print an FSVD object</p></a></li>
<li><a href='#print.WFDA'><p>Print a WFDA object</p></a></li>
<li><a href='#SBFitting'><p>Iterative Smooth Backfitting Algorithm</p></a></li>
<li><a href='#SelectK'><p>Selects number of functional principal components for</p>
given FPCA output and selection criteria</a></li>
<li><a href='#SetOptions'><p>Set the PCA option list</p></a></li>
<li><a href='#Sparsify'><p>Sparsify densely observed functional data</p></a></li>
<li><a href='#str.FPCA'><p>Compactly display the structure of an FPCA object</p></a></li>
<li><a href='#Stringing'><p>Stringing for High-Dimensional data</p></a></li>
<li><a href='#trapzRcpp'><p>Trapezoid Rule Numerical Integration</p></a></li>
<li><a href='#TVAM'><p>Iterative Smooth Backfitting Algorithm</p></a></li>
<li><a href='#VCAM'><p>Sieve estimation:</p>
B-spline based estimation procedure for time-varying additive models. The VCAM function can be used to perform function-to-scalar regression.</a></li>
<li><a href='#WFDA'><p>Time-Warping in Functional Data Analysis:</p>
Pairwise curve synchronization for functional data</a></li>
<li><a href='#Wiener'><p>Simulate a standard Wiener processes (Brownian motions)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functional Data Analysis and Empirical Dynamics</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/functionaldata/tPACE">https://github.com/functionaldata/tPACE</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/functionaldata/tPACE/issues">https://github.com/functionaldata/tPACE/issues</a></td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.0</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-07-02</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yidong Zhou &lt;ydzhou@ucdavis.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A versatile package that provides implementation of various
    methods of Functional Data Analysis (FDA) and Empirical Dynamics. The core of this
    package is Functional Principal Component Analysis (FPCA), a key technique for
    functional data analysis, for sparsely or densely sampled random trajectories
    and time courses, via the Principal Analysis by Conditional Estimation
    (PACE) algorithm. This core algorithm yields covariance and mean functions,
    eigenfunctions and principal component (scores), for both functional data and
    derivatives, for both dense (functional) and sparse (longitudinal) sampling designs.
    For sparse designs, it provides fitted continuous trajectories with confidence bands,
    even for subjects with very few longitudinal observations. PACE is a viable and
    flexible alternative to random effects modeling of longitudinal data. There is also a
    Matlab version (PACE) that contains some methods not available on fdapace and vice
    versa. Updates to fdapace were supported by grants from NIH Echo and NSF DMS-1712864 and DMS-2014626. 
    Please cite our package if you use it (You may run the command citation("fdapace") to get the citation format and bibtex entry).
    References: Wang, J.L., Chiou, J., Müller, H.G. (2016) &lt;<a href="https://doi.org/10.1146%2Fannurev-statistics-041715-033624">doi:10.1146/annurev-statistics-041715-033624</a>&gt;; Chen, K., Zhang, X., Petersen, A., Müller, H.G. (2017) &lt;<a href="https://doi.org/10.1007%2Fs12561-015-9137-5">doi:10.1007/s12561-015-9137-5</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>false</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.5), Hmisc, MASS, Matrix, pracma, numDeriv</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Suggests:</td>
<td>plot3D, rgl, aplpack, mgcv, ks, gtools, knitr, rmarkdown,
EMCluster, minqa, testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-03 05:34:58 UTC; yidong</td>
</tr>
<tr>
<td>Author:</td>
<td>Yidong Zhou <a href="https://orcid.org/0000-0003-1423-1857"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre,
    aut],
  Han Chen [aut],
  Su I Iao [aut],
  Poorbita Kundu [aut],
  Hang Zhou [aut],
  Satarupa Bhattacharjee [aut],
  Cody Carroll <a href="https://orcid.org/0000-0003-3525-8653"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Yaqing Chen [aut],
  Xiongtao Dai [aut],
  Jianing Fan [aut],
  Alvaro Gajardo [aut],
  Pantelis Z. Hadjipantelis [aut],
  Kyunghee Han [aut],
  Hao Ji [aut],
  Changbo Zhu [aut],
  Paromita Dubey [ctb],
  Shu-Chin Lin [ctb],
  Hans-Georg Müller [cph, ths, aut],
  Jane-Ling Wang [cph, ths, aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-03 07:20:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='BwNN'>Minimum bandwidth based on kNN criterion.</h2><span id='topic+BwNN'></span>

<h3>Description</h3>

<p>Input a list of time points Lt, and the number of unique neighbors k. Obtain  the minimum bandwidth  guaranteeing k unique neighbours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BwNN(Lt, k = 3, onlyMean = FALSE, onlyCov = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BwNN_+3A_lt">Lt</code></td>
<td>
<p>n-by-1 list of vectors</p>
</td></tr>
<tr><td><code id="BwNN_+3A_k">k</code></td>
<td>
<p>number of unique neighbors for cov and mu (default = 3)</p>
</td></tr>
<tr><td><code id="BwNN_+3A_onlymean">onlyMean</code></td>
<td>
<p>Indicator to return only the minimum bandwidth for the mean</p>
</td></tr>
<tr><td><code id="BwNN_+3A_onlycov">onlyCov</code></td>
<td>
<p>Indicator to return only the minimum bandwidth for the covariance</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>tinyGrid = list(c(1,7), c(2,3),  6,  c(2,4), c(4,5))
BwNN(tinyGrid, k = 2) # c(3,2)
</code></pre>

<hr>
<h2 id='CheckData'>Check data format</h2><span id='topic+CheckData'></span>

<h3>Description</h3>

<p>Check if there are problems with the form and basic structure of the functional data 'y' and the recorded times 't'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckData(y, t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CheckData_+3A_y">y</code></td>
<td>
<p>is a n-by-1 list of vectors</p>
</td></tr>
<tr><td><code id="CheckData_+3A_t">t</code></td>
<td>
<p>is a n-by-1 list of vectors</p>
</td></tr>
</table>

<hr>
<h2 id='CheckOptions'>Check option format</h2><span id='topic+CheckOptions'></span>

<h3>Description</h3>

<p>Check if the options structure is valid and set the  NULL options
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckOptions(t, optns, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CheckOptions_+3A_t">t</code></td>
<td>
<p>is a n-by-1 list of vectors</p>
</td></tr>
<tr><td><code id="CheckOptions_+3A_optns">optns</code></td>
<td>
<p>is an initialized option list</p>
</td></tr>
<tr><td><code id="CheckOptions_+3A_n">n</code></td>
<td>
<p>is a total number of sample curves</p>
</td></tr>
</table>

<hr>
<h2 id='ConvertSupport'>Convert support of a mu/phi/cov etc. to and from obsGrid and workGrid</h2><span id='topic+ConvertSupport'></span>

<h3>Description</h3>

<p>Convert the support of a given function 1-D or 2-D function from <code>fromGrid</code> to <code>toGrid</code>.
Both grids need to be sorted. This is an interpolation/convenience function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConvertSupport(
  fromGrid,
  toGrid,
  mu = NULL,
  Cov = NULL,
  phi = NULL,
  isCrossCov = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ConvertSupport_+3A_fromgrid">fromGrid</code></td>
<td>
<p>vector of points with input grid to interpolate from</p>
</td></tr>
<tr><td><code id="ConvertSupport_+3A_togrid">toGrid</code></td>
<td>
<p>vector of points with the target grid to interpolate on</p>
</td></tr>
<tr><td><code id="ConvertSupport_+3A_mu">mu</code></td>
<td>
<p>any vector of function to be interpolated</p>
</td></tr>
<tr><td><code id="ConvertSupport_+3A_cov">Cov</code></td>
<td>
<p>a square matrix supported on fromGrid * fromGrid, to be interpolated to toGrid * toGrid.</p>
</td></tr>
<tr><td><code id="ConvertSupport_+3A_phi">phi</code></td>
<td>
<p>any matrix, each column containing a function to be interpolated</p>
</td></tr>
<tr><td><code id="ConvertSupport_+3A_iscrosscov">isCrossCov</code></td>
<td>
<p>logical, indicating whether the input covariance is a cross-covariance. If so then the output is not made symmetric.</p>
</td></tr>
</table>

<hr>
<h2 id='CreateBasis'>Create an orthogonal basis of K functions in [0, 1], with nGrid points.</h2><span id='topic+CreateBasis'></span>

<h3>Description</h3>

<p>Create an orthogonal basis of K functions in [0, 1], with nGrid points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateBasis(
  K,
  pts = seq(0, 1, length.out = 50),
  type = c("cos", "sin", "fourier", "legendre01", "poly")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateBasis_+3A_k">K</code></td>
<td>
<p>A positive integer specifying the number of eigenfunctions to generate.</p>
</td></tr>
<tr><td><code id="CreateBasis_+3A_pts">pts</code></td>
<td>
<p>A vector specifying the time points to evaluate the basis functions.</p>
</td></tr>
<tr><td><code id="CreateBasis_+3A_type">type</code></td>
<td>
<p>A string for the type of orthogonal basis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A K by nGrid matrix, each column containing an basis function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>basis &lt;- CreateBasis(3, type='fourier')
head(basis)

</code></pre>

<hr>
<h2 id='CreateBWPlot'>Functional Principal Component Analysis Bandwidth Diagnostics plot</h2><span id='topic+CreateBWPlot'></span>

<h3>Description</h3>

<p>This function by default creates the mean and first principal modes of variation plots for
50
If provided with a derivative options object (?FPCAder) it will return the 
differentiated mean and first two principal modes of variation for 50
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateBWPlot(fpcaObj, derOptns = NULL, bwMultipliers = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateBWPlot_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>An FPCA class object returned by FPCA().</p>
</td></tr>
<tr><td><code id="CreateBWPlot_+3A_deroptns">derOptns</code></td>
<td>
<p>A list of options to control the derivation parameters; see ?FPCAder. If NULL standard diagnostics are returned</p>
</td></tr>
<tr><td><code id="CreateBWPlot_+3A_bwmultipliers">bwMultipliers</code></td>
<td>
<p>A vector of multipliers that the original 'bwMu' and 'bwCov' will be multiplied by. (default: c(0.50, 0.75, 1.00, 1.25, 1.50))
- default: NULL</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 40
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res1 &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=FALSE))
CreateBWPlot(res1)
</code></pre>

<hr>
<h2 id='CreateCovPlot'>Creates a correlation surface plot based on the results from FPCA() or FPCder().</h2><span id='topic+CreateCovPlot'></span>

<h3>Description</h3>

<p>This function will open a new device if not instructed otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateCovPlot(
  fpcaObj,
  covPlotType = "Fitted",
  corr = FALSE,
  isInteractive = FALSE,
  colSpectrum = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateCovPlot_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>returned object from FPCA().</p>
</td></tr>
<tr><td><code id="CreateCovPlot_+3A_covplottype">covPlotType</code></td>
<td>
<p>a string specifying the type of covariance surface to be plotted:
'Smoothed': plot the smoothed cov surface 
'Fitted': plot the fitted cov surface</p>
</td></tr>
<tr><td><code id="CreateCovPlot_+3A_corr">corr</code></td>
<td>
<p>a boolean value indicating whether to plot the fitted covariance or correlation surface from the fpca object
TRUE: fitted correlation surface;
FALSE: fitted covariance surface;
default is FALSE; 
Only plotted for fitted fpca objects</p>
</td></tr>
<tr><td><code id="CreateCovPlot_+3A_isinteractive">isInteractive</code></td>
<td>
<p>an option for interactive plot:
TRUE: interactive plot; FALSE: printable plot</p>
</td></tr>
<tr><td><code id="CreateCovPlot_+3A_colspectrum">colSpectrum</code></td>
<td>
<p>character vector to be use as input in the 'colorRampPalette' function defining the colouring scheme (default: c('blue','red'))</p>
</td></tr>
<tr><td><code id="CreateCovPlot_+3A_...">...</code></td>
<td>
<p>other arguments passed into persp3d, persp3D, plot3d or points3D for plotting options</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=TRUE))
CreateCovPlot(res) ##plotting the covariance surface
CreateCovPlot(res, corr = TRUE) ##plotting the correlation surface
</code></pre>

<hr>
<h2 id='CreateDesignPlot'>Create design plots for functional data. See Yao, F., Müller, H.G., Wang, J.L. (2005). Functional
data analysis for sparse longitudinal data. J. American Statistical Association 100, 577-590
for interpretation and usage of these plots. 
This function will open a new device as default.</h2><span id='topic+CreateDesignPlot'></span>

<h3>Description</h3>

<p>Create design plots for functional data. See Yao, F., Müller, H.G., Wang, J.L. (2005). Functional
data analysis for sparse longitudinal data. J. American Statistical Association 100, 577-590
for interpretation and usage of these plots. 
This function will open a new device as default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateDesignPlot(
  Lt,
  obsGrid = NULL,
  isColorPlot = TRUE,
  noDiagonal = TRUE,
  addLegend = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateDesignPlot_+3A_lt">Lt</code></td>
<td>
<p>a list of observed time points for functional data</p>
</td></tr>
<tr><td><code id="CreateDesignPlot_+3A_obsgrid">obsGrid</code></td>
<td>
<p>a vector of sorted observed time points. Default are the 
unique time points in Lt.</p>
</td></tr>
<tr><td><code id="CreateDesignPlot_+3A_iscolorplot">isColorPlot</code></td>
<td>
<p>an option for colorful plot: 
TRUE: create color plot with color indicating counts
FALSE: create black and white plot with dots indicating observed time pairs</p>
</td></tr>
<tr><td><code id="CreateDesignPlot_+3A_nodiagonal">noDiagonal</code></td>
<td>
<p>an option specifying plotting the diagonal design points:
TRUE:  remove diagonal time pairs
FALSE:  do not remove diagonal time pairs</p>
</td></tr>
<tr><td><code id="CreateDesignPlot_+3A_addlegend">addLegend</code></td>
<td>
<p>Logical, default TRUE</p>
</td></tr>
<tr><td><code id="CreateDesignPlot_+3A_...">...</code></td>
<td>
<p>Other arguments passed into <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
CreateDesignPlot(sampWiener$Lt, sort(unique(unlist(sampWiener$Lt))))
</code></pre>

<hr>
<h2 id='CreateDiagnosticsPlot'>Functional Principal Component Analysis Diagnostics plot</h2><span id='topic+CreateDiagnosticsPlot'></span><span id='topic+plot.FPCA'></span>

<h3>Description</h3>

<p>Deprecated. Use <code>plot.FPCA</code> instead.
</p>
<p>Plotting the results of an FPCA, including printing the design plot, mean function, scree-plot
and the first three eigenfunctions for a functional sample. If provided with a derivative options object (?FPCAder), it will  return the 
differentiated mean function and first two principal modes of variation for 50%, 75%, 100%, 125% and 150% of the defined bandwidth choice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateDiagnosticsPlot(...)

## S3 method for class 'FPCA'
plot(x, openNewDev = FALSE, addLegend = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateDiagnosticsPlot_+3A_...">...</code></td>
<td>
<p>passed into <code>plot.FPCA</code>.</p>
</td></tr>
<tr><td><code id="CreateDiagnosticsPlot_+3A_x">x</code></td>
<td>
<p>An FPCA class object returned by FPCA().</p>
</td></tr>
<tr><td><code id="CreateDiagnosticsPlot_+3A_opennewdev">openNewDev</code></td>
<td>
<p>A logical specifying if a new device should be opened - default: FALSE</p>
</td></tr>
<tr><td><code id="CreateDiagnosticsPlot_+3A_addlegend">addLegend</code></td>
<td>
<p>A logical specifying whether to add legend.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The black, red, and green curves stand for the first, second, and third eigenfunctions, respectively. 
<code>plot.FPCA</code> is currently implemented only for the original function, but not a derivative FPCA object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res1 &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=FALSE))
plot(res1)
</code></pre>

<hr>
<h2 id='CreateFuncBoxPlot'>Create functional boxplot using 'bagplot', 'KDE' or 'pointwise' methodology</h2><span id='topic+CreateFuncBoxPlot'></span>

<h3>Description</h3>

<p>Using an FPCA object create a functional box-plot based on the function scores.
The green line corresponds to the functional median, the dark gray area to the area spanned
by the curves within the 25th and 75-th percentile and the light gray to the area spanned
by the curves within the 2.5th and 97.5-th percentile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateFuncBoxPlot(fpcaObj, optns = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateFuncBoxPlot_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>An object of class FPCA returned by the function FPCA().</p>
</td></tr>
<tr><td><code id="CreateFuncBoxPlot_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="CreateFuncBoxPlot_+3A_...">...</code></td>
<td>
<p>Additional arguments for the 'plot' function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available control options are 
</p>

<dl>
<dt>ifactor</dt><dd><p>inflation ifactor for the bag-plot defining the loop of bag-plot or multiplying ifactor 
the KDE pilot bandwidth matrix. (see ?aplpack::compute.bagplot; ?ks::Hpi respectively; default: 2.58; 2 respectively).</p>
</dd>
<dt>variant</dt><dd><p>string defining the method used ('KDE', 'pointwise' or 'bagplot') (default: 'bagplot')</p>
</dd>
<dt>unimodal</dt><dd><p>logical specifying if the KDE estimate should be unimodal (default: FALSE, relevant only for variant='KDE')</p>
</dd>
<dt>addIndx</dt><dd><p>vector of indices corresponding to which samples one should overlay (Default: NULL)</p>
</dd>
<dt>K</dt><dd><p>integer number of the first K components used for the representation. (default: length(fpcaObj$lambda ))</p>
</dd> 
</dl>



<h3>References</h3>

<p><cite>P. J. Rousseeuw, I. Ruts, J. W. Tukey (1999): The bagplot: a bivariate boxplot, The American Statistician, vol. 53, no. 4, 382-387</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=TRUE))
CreateFuncBoxPlot(res, list(addIndx=c(1:3)) )
</code></pre>

<hr>
<h2 id='CreateModeOfVarPlot'>Functional Principal Component Analysis: Mode of variation plot</h2><span id='topic+CreateModeOfVarPlot'></span>

<h3>Description</h3>

<p>Creates the k-th mode of variation plot around the mean. The red-line is
the functional mean, the grey shaded areas show the range of variation
around the mean: <code class="reqn"> \pm Q \sqrt{\lambda_k} \phi_k</code>
for the dark grey area Q = 1, and for the light grey are Q = 2. In the case of 'rainbowPlot'
the blue edge corresponds to Q = -3, the green edge to Q = +3 and the red-line to Q = 0 (the mean).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateModeOfVarPlot(
  fpcaObj,
  k = 1,
  rainbowPlot = FALSE,
  colSpectrum = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateModeOfVarPlot_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>An FPCA class object returned by FPCA().</p>
</td></tr>
<tr><td><code id="CreateModeOfVarPlot_+3A_k">k</code></td>
<td>
<p>The k-th mode of variation to plot (default k = 1)</p>
</td></tr>
<tr><td><code id="CreateModeOfVarPlot_+3A_rainbowplot">rainbowPlot</code></td>
<td>
<p>Indicator to create a rainbow-plot instead of a shaded plot (default: FALSE)</p>
</td></tr>
<tr><td><code id="CreateModeOfVarPlot_+3A_colspectrum">colSpectrum</code></td>
<td>
<p>Character vector to be use as input in the 'colorRampPalette' function defining the outliers colours (default: c(&quot;blue&quot;,&quot;red&quot;, &quot;green&quot;), relevant only for rainbowPlot=TRUE)</p>
</td></tr>
<tr><td><code id="CreateModeOfVarPlot_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code>plot</code> function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=TRUE))
CreateModeOfVarPlot(res)
</code></pre>

<hr>
<h2 id='CreateOutliersPlot'>Functional Principal Component or Functional Singular Value Decomposition Scores Plot using 'bagplot' or 'KDE' methodology</h2><span id='topic+CreateOutliersPlot'></span>

<h3>Description</h3>

<p>This function will create, using the first components scores, a set of convex hulls of the scores based on 'bagplot' or 'KDE' methodology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateOutliersPlot(fObj, optns = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateOutliersPlot_+3A_fobj">fObj</code></td>
<td>
<p>A class object returned by FPCA() or FSVD().</p>
</td></tr>
<tr><td><code id="CreateOutliersPlot_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="CreateOutliersPlot_+3A_...">...</code></td>
<td>
<p>Additional arguments for the 'plot' function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available control options are 
</p>

<dl>
<dt>ifactor</dt><dd><p>inflation ifactor for the bag-plot defining the loop of bag-plot or multiplying ifactor the KDE pilot bandwidth matrix. (see ?aplpack::compute.bagplot; ?ks::Hpi respectively; default: 2.58; 2 respectively).</p>
</dd>
<dt>variant</dt><dd><p>string defining the outlier method used ('KDE', 'NN' or 'bagplot') (default: 'KDE')</p>
</dd>
<dt>unimodal</dt><dd><p>logical specifying if the KDE estimate should be unimodal (default: FALSE, relevant only for variant='KDE')</p>
</dd>
<dt>maxVar</dt><dd><p>logical specifying if during slicing we should used the directions of maximum variance (default: FALSE for FPCA, TRUE for FSVD)</p>
</dd>
<dt>nSlices</dt><dd><p>integer between 3 and 16, denoting the number of slices to be used (default: 4, relevant only for groupingType='slice') </p>
</dd>
<dt>showSlices</dt><dd><p>logical specifying if during slicing we should show the outline of the slice (default: FALSE)</p>
</dd>
<dt>colSpectrum</dt><dd><p>character vector to be use as input in the 'colorRampPalette' function defining the outliers colours (default: c(&quot;red&quot;,  &quot;yellow&quot;, 'blue'), relevant only for groupingType='slice') </p>
</dd>
<dt>groupingType</dt><dd><p>string specifying if a slice grouping ('slice') or a standard percentile/bagplot grouping ('standard') should be returned (default: 'standard')</p>
</dd> 
<dt>fIndices</dt><dd><p>a two-component vector with the index of the mode of variation to consider (default: c(1,2) for FPCA and c(1,1) for FSVD)</p>
</dd>
</dl>



<h3>Value</h3>

<p>An (temporarily) invisible copy of a list containing the labels associated with each of sample curves.
</p>


<h3>References</h3>

<p><cite>P. J. Rousseeuw, I. Ruts, J. W. Tukey (1999): The bagplot: a bivariate boxplot, The American Statistician, vol. 53, no. 4, 382-387</cite>
<cite>R. J. Hyndman and H. L. Shang. (2010) Rainbow plots, bagplots, and boxplots for functional data, Journal of Computational and Graphical Statistics, 19(1), 29-45</cite>

</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
n &lt;- 420
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=TRUE))
CreateOutliersPlot(res)

</code></pre>

<hr>
<h2 id='CreatePathPlot'>Create the fitted sample path plot based on the results from FPCA().</h2><span id='topic+CreatePathPlot'></span>

<h3>Description</h3>

<p>Create the fitted sample path plot based on the results from FPCA().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreatePathPlot(
  fpcaObj,
  subset,
  K = NULL,
  inputData = fpcaObj[["inputData"]],
  showObs = !is.null(inputData),
  obsOnly = FALSE,
  showMean = FALSE,
  derOptns = list(p = 0),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreatePathPlot_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>Returned object from FPCA().</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_subset">subset</code></td>
<td>
<p>A vector of indices or a logical vector for subsetting the
observations.</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_k">K</code></td>
<td>
<p>The number of components to reconstruct the fitted sample paths.</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_inputdata">inputData</code></td>
<td>
<p>A list of length 2 containing the sparse/dense
(unsupported yet) observations. <code>inputData</code> needs to contain two
fields: <code>Lt</code> for a list of time points and <code>Ly</code> for a list of
observations. Default to the 'inputData' field within 'fpcaObj'.</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_showobs">showObs</code></td>
<td>
<p>Whether to plot the original observations for each subject.</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_obsonly">obsOnly</code></td>
<td>
<p>Whether to show only the original curves.</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_showmean">showMean</code></td>
<td>
<p>Whether to plot the mean function as a bold solid curve.</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_deroptns">derOptns</code></td>
<td>
<p>A list of options to control derivation parameters; see &lsquo;fitted.FPCA&rsquo;. (default = NULL)</p>
</td></tr>
<tr><td><code id="CreatePathPlot_+3A_...">...</code></td>
<td>
<p>other arguments passed into matplot for plotting options</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan',
            verbose=TRUE))
CreatePathPlot(res, subset=1:5)

# CreatePathPlot has a lot of usages:

CreatePathPlot(res)
CreatePathPlot(res, 1:20)
CreatePathPlot(res, 1:20, showObs=FALSE)
CreatePathPlot(res, 1:20, showMean=TRUE, showObs=FALSE)
CreatePathPlot(res, 1:20, obsOnly=TRUE)
CreatePathPlot(res, 1:20, obsOnly=TRUE, showObs=FALSE)
CreatePathPlot(inputData=sampWiener, subset=1:20, obsOnly=TRUE)

</code></pre>

<hr>
<h2 id='CreateScreePlot'>Create the scree plot for the fitted eigenvalues</h2><span id='topic+CreateScreePlot'></span>

<h3>Description</h3>

<p>This function will open a new device if not instructed otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateScreePlot(fpcaObj, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateScreePlot_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>A object of class FPCA returned by the function FPCA().</p>
</td></tr>
<tr><td><code id="CreateScreePlot_+3A_...">...</code></td>
<td>
<p>Additional arguments for the 'plot' function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=TRUE))
CreateScreePlot(res)
</code></pre>

<hr>
<h2 id='CreateStringingPlot'>Create plots for observed and stringed high dimensional data</h2><span id='topic+CreateStringingPlot'></span>

<h3>Description</h3>

<p>The function produces the following three plots:
1) A plot of predictors (standardized if specified so during stringing) in original order for a subset of observations;
2) A plot of predictors in stringed order for the same subset of observations;
3) A plot of the stringing function, which is the stringed order vs. the original order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateStringingPlot(stringingObj, subset, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateStringingPlot_+3A_stringingobj">stringingObj</code></td>
<td>
<p>A stringing object of class &quot;Stringing&quot;, returned by the function Stringing.</p>
</td></tr>
<tr><td><code id="CreateStringingPlot_+3A_subset">subset</code></td>
<td>
<p>A vector of indices or a logical vector for subsetting the observations. If missing,  first min(n,50) observations will be plotted where n is the sample size.</p>
</td></tr>
<tr><td><code id="CreateStringingPlot_+3A_...">...</code></td>
<td>
<p>Other arguments passed into matplot for plotting options</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This approach is based on 
Chen, K., Chen, K., Müller, H.G., Wang, J.L. (2011). Stringing high-dimensional data for functional analysis. J. American Statistical Association 106, 275&ndash;284.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 50
wiener = Wiener(n = n)[,-1]
p = ncol(wiener)
rdmorder = sample(size = p, x=1:p, replace = FALSE)
stringingfit = Stringing(X = wiener[,rdmorder], disOptns = "correlation")
diff_norev = sum(abs(rdmorder[stringingfit$StringingOrder] - 1:p))
diff_rev = sum(abs(rdmorder[stringingfit$StringingOrder] - p:1))
if(diff_rev &lt;= diff_norev){
  stringingfit$StringingOrder = rev(stringingfit$StringingOrder)
  stringingfit$Ly = lapply(stringingfit$Ly, rev)
}
CreateStringingPlot(stringingfit, 1:20)

</code></pre>

<hr>
<h2 id='cumtrapzRcpp'>Cumulative Trapezoid Rule Numerical Integration</h2><span id='topic+cumtrapzRcpp'></span>

<h3>Description</h3>

<p>Cumulative Trapezoid Rule Numerical Integration using Rcpp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cumtrapzRcpp(X, Y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cumtrapzRcpp_+3A_x">X</code></td>
<td>
<p>Sorted vector of X values</p>
</td></tr>
<tr><td><code id="cumtrapzRcpp_+3A_y">Y</code></td>
<td>
<p>Vector of Y values.</p>
</td></tr>
</table>

<hr>
<h2 id='Dyn_test'>Bootstrap test of Dynamic Correlation</h2><span id='topic+Dyn_test'></span>

<h3>Description</h3>

<p>Perform one sample (H0: Dynamic correlation = 0) or two sample (H0:Dynamic_correlation_1 = Dynamic_correlation_2) bootstrap test 
of H_0: Dynamical Correlation=0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dyn_test(x1, y1, t1, x2, y2, t2, B = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Dyn_test_+3A_x1">x1</code></td>
<td>
<p>a n by m matrix where rows representing subjects and columns representing measurements, missings are allowed.</p>
</td></tr>
<tr><td><code id="Dyn_test_+3A_y1">y1</code></td>
<td>
<p>a n by m matrix where rows representing subjects and columns representing measurements, missings are allowed.</p>
</td></tr>
<tr><td><code id="Dyn_test_+3A_t1">t1</code></td>
<td>
<p>a vector of time points where x1,y1 are observed.</p>
</td></tr>
<tr><td><code id="Dyn_test_+3A_x2">x2</code></td>
<td>
<p>(optional if missing will be one sample test) a n by m matrix where rows representing subjects and columns representing measurements, missings are allowed.</p>
</td></tr>
<tr><td><code id="Dyn_test_+3A_y2">y2</code></td>
<td>
<p>(optional if missing will be one sample test) a n by m matrix where rows representing subjects and columns representing measurements, missings are allowed.</p>
</td></tr>
<tr><td><code id="Dyn_test_+3A_t2">t2</code></td>
<td>
<p>(optional if missing will be one sample test) a vector of time points where x2,y2 are observed.</p>
</td></tr>
<tr><td><code id="Dyn_test_+3A_b">B</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of the following 
</p>
<table role = "presentation">
<tr><td><code>stats</code></td>
<td>
<p>Test statistics.</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>p-value of the test.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Dubin J A, Müller H G. (2005)  Dynamical correlation for multivariate longitudinal data.  
Journal of the American Statistical Association 100(471): 872-881.</cite>
</p>
<p><cite>Liu S, Zhou Y, Palumbo R, Wang, J.L. (2016).  Dynamical correlation: A new method for quantifying synchrony with multivariate intensive 
longitudinal data.  Psychological Methods 21(3): 291.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=20             # sample size
t=seq(0,1,length.out=100)       # length of data
mu_quad_x=8*t^2-4*t+5
mu_quad_y=8*t^2-12*t+6
fun=rbind(rep(1,length(t)),-t,t^2)
z1=matrix(0,n,3)
z1[,1]=rnorm(n,0,2)
z1[,2]=rnorm(n,0,16/3)
z1[,3]=rnorm(n,0,4)   # covariance matrix of random effects
x1_quad_error=y1_quad_error=matrix(0,nrow=n,ncol=length(t))
for (i in 1:n){
  x1_quad_error[i,]=mu_quad_x+z1[i,]%*%fun+rnorm(length(t),0,0.01)
  y1_quad_error[i,]=mu_quad_y+2*z1[i,]%*%fun +rnorm(length(t),0,0.01)
}
bt_DC=Dyn_test(x1_quad_error,y1_quad_error,t,B=500) # using B=500 for speed consideration

</code></pre>

<hr>
<h2 id='DynCorr'>Dynamical Correlation</h2><span id='topic+DynCorr'></span>

<h3>Description</h3>

<p>Calculates the Dynamical Correlation for 2 paired dense regular functional data observed on the same grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DynCorr(x, y, t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DynCorr_+3A_x">x</code></td>
<td>
<p>a n by m matrix where rows representing subjects and columns representing measurements, missings are allowed.</p>
</td></tr>
<tr><td><code id="DynCorr_+3A_y">y</code></td>
<td>
<p>a n by m matrix where rows representing subjects and columns representing measurements, missings are allowed.</p>
</td></tr>
<tr><td><code id="DynCorr_+3A_t">t</code></td>
<td>
<p>a length m vector of time points where x,y are observed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A length n vector of individual dynamic correlations. The dynamic correlation can be obtained by taking average of this vector.
</p>


<h3>References</h3>

<p><cite>Dubin J A, Müller H G. Dynamical correlation for multivariate longitudinal data (2005).  
Journal of the American Statistical Association 100(471): 872-881.</cite>
<cite>Liu S, Zhou Y, Palumbo R, Wang, J.L. (2016).  Dynamical correlation: A new method for quantifying synchrony with 
multivariate intensive longitudinal data. Psychological methods 21(3): 291.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(10)
n=200             # sample size
t=seq(0,1,length.out=100)       # length of data
mu_quad_x=8*t^2-4*t+5
mu_quad_y=8*t^2-12*t+6
fun=rbind(rep(1,length(t)),-t,t^2)
z1=matrix(0,n,3)
z1[,1]=rnorm(n,0,2)
z1[,2]=rnorm(n,0,16/3)
z1[,3]=rnorm(n,0,4)
x1_quad_error=y1_quad_error=matrix(0,nrow=n,ncol=length(t))
for (i in 1:n){
  x1_quad_error[i,]=mu_quad_x+z1[i,]%*%fun+rnorm(length(t),0,0.01)
  y1_quad_error[i,]=mu_quad_y+2*z1[i,]%*%fun +rnorm(length(t),0,0.01)
}
dyn1_quad=DynCorr(x1_quad_error,y1_quad_error,t) 
</code></pre>

<hr>
<h2 id='FAM'>Functional Additive Models</h2><span id='topic+FAM'></span>

<h3>Description</h3>

<p>Functional additive models with a single predictor process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FAM(
  Y,
  Lx,
  Lt,
  nEval = 51,
  newLx = NULL,
  newLt = NULL,
  bwMethod = 0,
  alpha = 0.7,
  supp = c(-2, 2),
  optns = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FAM_+3A_y">Y</code></td>
<td>
<p>An <em>n</em>-dimensional vector whose elements consist of scalar responses.</p>
</td></tr>
<tr><td><code id="FAM_+3A_lx">Lx</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. See <code>FPCA</code> for detail.</p>
</td></tr>
<tr><td><code id="FAM_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual. Each vector should be sorted in ascending order. See <code>FPCA</code> for detail.</p>
</td></tr>
<tr><td><code id="FAM_+3A_neval">nEval</code></td>
<td>
<p>The number of evaluation grid points for kernel smoothing (default is 51. If it is specified as 0, then estimated FPC scores in the training set are used for evaluation grid instead of equal grid).</p>
</td></tr>
<tr><td><code id="FAM_+3A_newlx">newLx</code></td>
<td>
<p>A list of the observed values for test set. See <code>predict.FPCA</code> for detail.</p>
</td></tr>
<tr><td><code id="FAM_+3A_newlt">newLt</code></td>
<td>
<p>A list of the observed time points for test set. See <code>predict.FPCA</code> for detail.</p>
</td></tr>
<tr><td><code id="FAM_+3A_bwmethod">bwMethod</code></td>
<td>
<p>The method of bandwidth selection for kernel smoothing, a positive value for designating K-fold cross-validtaion and zero for GCV (default is 50)</p>
</td></tr>
<tr><td><code id="FAM_+3A_alpha">alpha</code></td>
<td>
<p>The shrinkage factor (positive number) for bandwidth selection. See Han et al. (2016) (default is 0.7).</p>
</td></tr>
<tr><td><code id="FAM_+3A_supp">supp</code></td>
<td>
<p>The lower and upper limits of kernel smoothing domain for studentized FPC scores, which FPC scores are divided by the square roots of eigenvalues (default is [-2,2]).</p>
</td></tr>
<tr><td><code id="FAM_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by list(name=value). See <code>FPCA</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>FAM</code> fits functional additive models for a scalar response and single predictor process proposed by Müller and Yao (2007) that </p>
<p style="text-align: center;"><code class="reqn">E(Y | \mathbf{X}) = \sum_{k=1}^K g_{k}(\xi_{k}),</code>
</p>
<p> where <code class="reqn">\xi_{k}</code> stand for the k-th FPC score of the the predictor process.
</p>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p>Mean estimator of <code class="reqn">EY</code></p>
</td></tr>
<tr><td><code>fam</code></td>
<td>
<p>A <em>N</em> by <em>K</em> matrix whose column vectors consist of the component function estimators at the given estimation points.</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>
<p>An <em>N</em> by <em>K</em> matrix whose column vectors consist of <em>N</em> vectors of estimation points for each component function.</p>
</td></tr>
<tr><td><code>bw</code></td>
<td>
<p>A <em>K</em>-dimensional bandwidth vector.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>A <em>K</em>-dimensional vector containing eigenvalues.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>An <em>nWorkGrid</em> by <em>K</em> matrix containing eigenfunctions, supported by <code>WorkGrid</code>. See <code>FPCA</code>.</p>
</td></tr>
<tr><td><code>workGrid</code></td>
<td>
<p>An <em>nWorkGrid</em> by <em>K_j</em> working grid, the internal regular grid on which the eigen analysis is carried on. See <code>FPCA</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Müller, H.-G. and Yao, F. (2005), &quot;Functional additive models&quot;, JASA, Vol.103, No.484, p.1534-1544.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1000)

library(MASS)

f1 &lt;- function(t) 0.5*t
f2 &lt;- function(t) 2*cos(2*pi*t/4)
f3 &lt;- function(t) 1.5*sin(2*pi*t/4)
f4 &lt;- function(t) 2*atan(2*pi*t/4)

n &lt;- 100
N &lt;- 100

sig &lt;- diag(c(4.0,2.0,1.5,1.2))

scoreX &lt;- mvrnorm(n,mu=rep(0,4),Sigma=sig)
scoreXTest &lt;- mvrnorm(N,mu=rep(0,4),Sigma=sig)

Y &lt;- f1(scoreX[,1]) + f2(scoreX[,2]) + f3(scoreX[,3]) + f4(scoreX[,4]) + rnorm(n,0,0.1)
YTest &lt;- f1(scoreXTest[,1]) + f2(scoreXTest[,2]) + 
  f3(scoreXTest[,3]) + f4(scoreXTest[,4]) + rnorm(N,0,0.1)

phi1 &lt;- function(t) sqrt(2)*sin(2*pi*t)
phi2 &lt;- function(t) sqrt(2)*sin(4*pi*t)
phi3 &lt;- function(t) sqrt(2)*cos(2*pi*t)
phi4 &lt;- function(t) sqrt(2)*cos(4*pi*t)

grid &lt;- seq(0,1,length.out=21)
Lt &lt;- Lx &lt;- list()
for (i in 1:n) {
  Lt[[i]] &lt;- grid
  Lx[[i]] &lt;- scoreX[i,1]*phi1(grid) + scoreX[i,2]*phi2(grid) + 
    scoreX[i,3]*phi3(grid) + scoreX[i,4]*phi4(grid) + rnorm(1,0,0.01)
}

LtTest &lt;- LxTest &lt;- list()
for (i in 1:N) {
  LtTest[[i]] &lt;- grid
  LxTest[[i]] &lt;- scoreXTest[i,1]*phi1(grid) + scoreXTest[i,2]*phi2(grid) + 
    scoreXTest[i,3]*phi3(grid) + scoreXTest[i,4]*phi4(grid) + rnorm(1,0,0.01)
}


# estimation
fit &lt;- FAM(Y=Y,Lx=Lx,Lt=Lt)

xi &lt;- fit$xi

op &lt;- par(mfrow=c(2,2))
j &lt;- 1
g1 &lt;- f1(sort(xi[,j]))
tmpSgn &lt;- sign(sum(g1*fit$fam[,j]))
plot(sort(xi[,j]),g1,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi1')
points(sort(xi[,j]),tmpSgn*fit$fam[order(xi[,j]),j],type='l')

j &lt;- 2
g2 &lt;- f2(sort(xi[,j]))
tmpSgn &lt;- sign(sum(g2*fit$fam[,j]))
plot(sort(xi[,j]),g2,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi2')
points(sort(xi[,j]),tmpSgn*fit$fam[order(xi[,j]),j],type='l')

j &lt;- 3
g3 &lt;- f3(sort(xi[,j]))
tmpSgn &lt;- sign(sum(g3*fit$fam[,j]))
plot(sort(xi[,j]),g3,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi3')
points(sort(xi[,j]),tmpSgn*fit$fam[order(xi[,j]),j],type='l')

j &lt;- 4
g4 &lt;- f4(sort(xi[,j]))
tmpSgn &lt;- sign(sum(g4*fit$fam[,j]))
plot(sort(xi[,j]),g4,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi4')
points(sort(xi[,j]),tmpSgn*fit$fam[order(xi[,j]),j],type='l')
par(op)

# fitting
fit &lt;- FAM(Y=Y,Lx=Lx,Lt=Lt,nEval=0)
yHat &lt;- fit$mu+apply(fit$fam,1,'sum')
plot(yHat,Y)
abline(coef=c(0,1),col=2)


# R^2
R2 &lt;- 1-sum((Y-yHat)^2)/sum((Y-mean(Y))^2)
R2


# prediction
fit &lt;- FAM(Y=Y,Lx=Lx,Lt=Lt,newLx=LxTest,newLt=LtTest)
yHat &lt;- fit$mu+apply(fit$fam,1,'sum')
plot(yHat,YTest,xlim=c(-10,10))
abline(coef=c(0,1),col=2)
</code></pre>

<hr>
<h2 id='FCCor'>Calculation of functional correlation between two simultaneously observed processes.</h2><span id='topic+FCCor'></span>

<h3>Description</h3>

<p>Calculation of functional correlation between two simultaneously observed processes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FCCor(
  x,
  y,
  Lt,
  bw = stop("bw missing"),
  kern = "epan",
  Tout = sort(unique(unlist(Lt)))
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FCCor_+3A_x">x</code></td>
<td>
<p>A list of function values corresponding to the first process.</p>
</td></tr>
<tr><td><code id="FCCor_+3A_y">y</code></td>
<td>
<p>A list of function values corresponding to the second process.</p>
</td></tr>
<tr><td><code id="FCCor_+3A_lt">Lt</code></td>
<td>
<p>A list of time points for both <code>x</code> and <code>y</code>.</p>
</td></tr>
<tr><td><code id="FCCor_+3A_bw">bw</code></td>
<td>
<p>A numeric vector for bandwidth of length either 5 or 1, specifying the bandwidths for E(X), E(Y), var(X), var(Y), and cov(X, Y). If <code>bw</code> is a scalar then all five bandwidths are chosen to be the same.</p>
</td></tr>
<tr><td><code id="FCCor_+3A_kern">kern</code></td>
<td>
<p>Smoothing kernel for mu and covariance; &quot;rect&quot;, &quot;gauss&quot;, &quot;epan&quot;, &quot;gausvar&quot;, &quot;quar&quot; (default: &quot;gauss&quot;)</p>
</td></tr>
<tr><td><code id="FCCor_+3A_tout">Tout</code></td>
<td>
<p>Output time points. Default to the sorted unique time points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>FCCor</code> calculate only the concurrent correlation corr(X(t), Y(t)) (note that the time points t are the same). It assumes no measurement error in the observed values.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table role = "presentation">
<tr><td><code>corr</code></td>
<td>
<p>A vector of the correlation corr(X(t), Y(t)) evaluated at <code>Tout</code>.</p>
</td></tr>
<tr><td><code>Tout</code></td>
<td>
<p>Same as the input Tout.</p>
</td></tr>
<tr><td><code>bw</code></td>
<td>
<p>The bandwidths used for E(X), E(Y), var(X), var(Y), and cov(X, Y).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 200
nGridIn &lt;- 50
sparsity &lt;- 1:5 # must have length &gt; 1
bw &lt;- 0.2
kern &lt;- 'epan'
T &lt;- matrix(seq(0.5, 1, length.out=nGridIn))

## Corr(X(t), Y(t)) = 1/2
A &lt;- Wiener(n, T)
B &lt;- Wiener(n, T) 
C &lt;- Wiener(n, T) + matrix((1:nGridIn) , n, nGridIn, byrow=TRUE)
X &lt;- A + B
Y &lt;- A + C
indEach &lt;- lapply(1:n, function(x) sort(sample(nGridIn, sample(sparsity, 1))))
tAll &lt;- lapply(1:n, function(i) T[indEach[[i]]])
Xsp &lt;- lapply(1:n, function(i) X[i, indEach[[i]]])
Ysp &lt;- lapply(1:n, function(i) Y[i, indEach[[i]]])

plot(T, FCCor(Xsp, Ysp, tAll, bw)[['corr']], ylim=c(-1, 1))
abline(h=0.5)
</code></pre>

<hr>
<h2 id='FClust'>Functional clustering and identifying substructures of longitudinal data</h2><span id='topic+FClust'></span>

<h3>Description</h3>

<p>Default:  Cluster functional data using the functional principal component (FPC) scores obtained from the data
FPC analysis using EMCluster (Chen and Maitra, 2015) or directly clustering the functional data using kCFC (Chiou and Li, 2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FClust(Ly, Lt, k = 3, cmethod = "EMCluster", optnsFPCA = NULL, optnsCS = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FClust_+3A_ly">Ly</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='dense'</code>).</p>
</td></tr>
<tr><td><code id="FClust_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y.</p>
</td></tr>
<tr><td><code id="FClust_+3A_k">k</code></td>
<td>
<p>A scalar defining the number of clusters to define; default 3.</p>
</td></tr>
<tr><td><code id="FClust_+3A_cmethod">cmethod</code></td>
<td>
<p>A string specifying the clustering method to use ('EMCluster' or 'kCFC'); default: 'EMCluster'.</p>
</td></tr>
<tr><td><code id="FClust_+3A_optnsfpca">optnsFPCA</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> to be used for by FPCA on the sample y; by default: 
&quot;list( methodMuCovEst ='smooth', FVEthreshold= 0.90, methodBwCov = 'GCV', methodBwMu = 'GCV' )&quot;. See &lsquo;Details in ?FPCA&rsquo;.</p>
</td></tr>
<tr><td><code id="FClust_+3A_optnscs">optnsCS</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> to be used for cluster-specific FPCA from kCFC; by default:
&quot;list( methodMuCovEst ='smooth', FVEthreshold= 0.70, methodBwCov = 'GCV', methodBwMu = 'GCV' )&quot;. See &lsquo;Details in ?FPCA&rsquo; and '?kCFC'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Within EMCluster, uses the model initiated <code>EMCluster::em.EM</code> and returns the optimal model based on <code>EMCluster::emcluster</code>. 
See ?EMCluster::emcluster for details.
</p>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>cluster</code></td>
<td>
<p>A vector of levels 1:k, indicating the cluster to which each curve is allocated.</p>
</td></tr> 
<tr><td><code>fpca</code></td>
<td>
<p>An FPCA object derived from the sample used by Rmixmod, otherwise NULL.</p>
</td></tr> 
<tr><td><code>clusterObj</code></td>
<td>
<p>Either a EMCluster object or kCFC object.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Wei-Chen Chen and Ranjan Maitra, &quot;EMCluster: EM Algorithm for Model-Based Clustering of Finite Mixture Gaussian Distribution&quot;. (2015)</cite>
</p>
<p><cite>Julien Jacques and Cristian Preda, &quot;Funclust: A curves clustering method using functional random variables density approximation&quot;. Neurocomputing 112 (2013): 164-171</cite>
</p>
<p><cite>Jeng-Min Chiou and Pai-Ling Li, &quot;Functional clustering and identifying substructures of longitudinal data&quot;. Journal of the Royal Statistical Society B 69 (2007): 679-699</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(medfly25)
Flies &lt;- MakeFPCAInputs(medfly25$ID, medfly25$Days, medfly25$nEggs) 
newClust &lt;- FClust(Flies$Ly, Flies$Lt, k = 2, optnsFPCA = 
                    list(methodMuCovEst = 'smooth', userBwCov = 2, FVEthreshold = 0.90))
                    
# We denote as 'veryLowCount' the group of flies that lay less
# than twenty-five eggs during the 25-day period examined.

veryLowCount = ifelse( sapply( unique(medfly25$ID), function(u) 
                   sum( medfly25$nEggs[medfly25$ID == u] )) &lt; 25, 0, 1)
N &lt;- length(unique(medfly25$ID))
(correctRate &lt;- sum( (1 + veryLowCount) ==  newClust$cluster) / N) # 99.6%

</code></pre>

<hr>
<h2 id='FCReg'>Functional Concurrent Regression using 2D smoothing</h2><span id='topic+FCReg'></span>

<h3>Description</h3>

<p>Functional concurrent regression with dense or sparse functional data for scalar or functional dependent variables. Note: function-to-scalar regression can also be handled using the VCAM function in fdapace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FCReg(
  vars,
  userBwMu,
  userBwCov,
  outGrid,
  kern = "gauss",
  measurementError = TRUE,
  diag1D = "none",
  useGAM = FALSE,
  returnCov = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FCReg_+3A_vars">vars</code></td>
<td>
<p>A list of input functional/scalar covariates. Each field corresponds to a functional (a list) or scalar (a vector) covariate. The last entry is assumed to be the response if no entry is names 'Y'. If a field corresponds to a functional covariate, it should have two fields: 'Lt', a list of time points, and 'Ly', a list of function values.</p>
</td></tr>
<tr><td><code id="FCReg_+3A_userbwmu">userBwMu</code></td>
<td>
<p>A scalar with bandwidth used for smoothing the mean</p>
</td></tr>
<tr><td><code id="FCReg_+3A_userbwcov">userBwCov</code></td>
<td>
<p>A scalar with bandwidth used for smoothing the auto- and cross-covariances</p>
</td></tr>
<tr><td><code id="FCReg_+3A_outgrid">outGrid</code></td>
<td>
<p>A vector with the output time points</p>
</td></tr>
<tr><td><code id="FCReg_+3A_kern">kern</code></td>
<td>
<p>Smoothing kernel choice, common for mu and covariance; &quot;rect&quot;, &quot;gauss&quot;, &quot;epan&quot;, &quot;gausvar&quot;, &quot;quar&quot; (default: &quot;gauss&quot;)</p>
</td></tr>
<tr><td><code id="FCReg_+3A_measurementerror">measurementError</code></td>
<td>
<p>Indicator measurement errors on the functional observations should be assumed. If TRUE the diagonal raw covariance will be removed when smoothing. (default: TRUE)</p>
</td></tr>
<tr><td><code id="FCReg_+3A_diag1d">diag1D</code></td>
<td>
<p>A string specifying whether to use 1D smoothing for the diagonal line of the covariance. 
'none': don't use 1D smoothing; 'cross': use 1D only for cross-covariances; 'all': use 1D for both auto- and cross-covariances. (default : 'none')</p>
</td></tr>
<tr><td><code id="FCReg_+3A_usegam">useGAM</code></td>
<td>
<p>Indicator to use gam smoothing instead of local-linear smoothing (semi-parametric option) (default: FALSE)</p>
</td></tr>
<tr><td><code id="FCReg_+3A_returncov">returnCov</code></td>
<td>
<p>Indicator to return the covariance surfaces, which is a four dimensional array. The first two dimensions correspond to outGrid
and the last two correspond to the covariates and the response, i.e. (i, j, k, l) entry being Cov(X_k(t_i), X_l(t_j)) (default: FALSE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If measurement error is assumed, the diagonal elements of the raw covariance will be removed. This could result in highly unstable estimate if the design is very sparse, or strong seasonality presents. 
WARNING! For very sparse functional data, setting measurementError = TRUE is not recommended.
</p>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>A matrix for the concurrent regression effects, where rows correspond to different predictors and columns to different time points.</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>
<p>A vector containing the time-varying intercept.</p>
</td></tr>
<tr><td><code>outGrid</code></td>
<td>
<p>A vector of the output time points.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>A 4-dimensional array for the (cross-)covariance surfaces, with the (i, j, k, l) entry being Cov(X_k(t_i), X_l(t_j))</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>A vector of the time-varying R2.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Yao, F., Müller, H.G., Wang, J.L. &quot;Functional Linear Regression Analysis for Longitudinal Data.&quot; Annals of Statistics 33, (2005): 2873-2903.(Dense data)</cite> 
<cite>Sentürk, D., Müller, H.G. &quot;Functional varying coefficient models for longitudinal data.&quot; J. American Statistical Association, 10, (2010): 1256&ndash;1264.</cite>
<cite>Sentürk, D., Nguyen, D.V. &quot;Varying Coefficient Models for Sparse Noise-contaminated Longitudinal Data&quot;, Statistica Sinica 21(4), (2011): 1831-1856. (Sparse data)</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Y(t) = \beta_0(t) + \beta_1(t) X_1(t) + \beta_2(t) Z_2 + \epsilon

# Settings
set.seed(1)
n &lt;- 75
nGridIn &lt;- 150
sparsity &lt;- 5:10 # Sparse data sparsity
T &lt;- round(seq(0, 1, length.out=nGridIn), 4) # Functional data support
bw &lt;- 0.1
outGrid &lt;- round(seq(min(T), 1, by=0.05), 2)

# Simulate functional data 
mu &lt;- T * 2 # mean function for X_1
sigma &lt;- 1

beta_0 &lt;- 0
beta_1 &lt;- 1
beta_2 &lt;- 1

Z &lt;- MASS::mvrnorm(n, rep(0, 2), diag(2))
X_1 &lt;- Z[, 1, drop=FALSE] %*% matrix(1, 1, nGridIn) + matrix(mu, n, nGridIn, byrow=TRUE)
epsilon &lt;- rnorm(n, sd=sigma)
Y &lt;- matrix(NA, n, nGridIn)
for (i in seq_len(n)) {
  Y[i, ] &lt;- beta_0 + beta_1 * X_1[i, ] + beta_2 * Z[i, 2] + epsilon[i]
}

# Sparsify functional data
set.seed(1)
X_1sp &lt;- Sparsify(X_1, T, sparsity)
set.seed(1)
Ysp &lt;- Sparsify(Y, T, sparsity)
vars &lt;- list(X_1=X_1sp, Z_2=Z[, 2], Y=Ysp)
withError2D &lt;- FCReg(vars, bw, bw, outGrid)
</code></pre>

<hr>
<h2 id='fdapace'>fdapace: Functional Data Analysis and Empirical Dynamics</h2><span id='topic+fdapace'></span>

<h3>Description</h3>

<p>fdapace is a versatile package that provides implementation of various methods
of Functional Data Analysis (FDA) and Empirical Dynamics. The core of this
package is Functional Principal Component Analysis (FPCA), a key technique
for functional data analysis, for sparsely or densely sampled random
trajectories and time courses, via the Principal Analysis by Conditional
Estimation (PACE) algorithm. This core algorithm yields covariance and mean 
functions, eigenfunctions and principal component (scores), for both functional 
data and derivatives, for both dense (functional) and sparse (longitudinal) 
sampling designs. For sparse designs, it provides fitted continuous 
trajectories with confidence bands, even for subjects with very few longitudinal 
observations. PACE is a viable and flexible alternative to random effects modeling
of longitudinal data. There is also a Matlab version (PACE) that contains some 
methods not available on fdapace and vice versa.
</p>


<h3>Details</h3>

<p>Links for fdapace/PACE:
Matlab version of pace at http://anson.ucdavis.edu/~mueller/data/pace.html
Papers and background at http://anson.ucdavis.edu/~mueller/  and  http://www.stat.ucdavis.edu/~wang/
</p>
<p>PACE is based on the idea that observed functional data are generated by a 
sample of underlying (but usually not fully observed) random trajectories 
that are realizations of a stochastic process. It does not rely on pre-smoothing 
of trajectories, which is problematic if functional data are sparsely sampled.
</p>
<p>The functional principal components can be used for further statistical analysis 
depending on the demands of a user, for example if one has densely sampled 
functional predictors and a generalized response, such as in a GLM, the predictor 
functions can be replaced by their first couple of principal component scores that
will then be used as predictors; one can also easily fit polynomial functional 
models by using powers (usually squares) and interactions of functional principal 
components among the predictors for a scalar response. 
</p>
<p>fdapace is a comprehensive package that directly implements fitting of the following models:
</p>

<ul>
<li><p> functional linear regression 
</p>
</li>
<li><p> functional additive regression
</p>
</li>
<li><p> functional covariance and correlation (via dynamic correlation) 
</p>
</li>
<li><p> functional clustering 
</p>
</li>
<li><p> concurrent (varying coefficient) regression models for sparse and dense designs
</p>
</li>
<li><p> varying coefficient additive models
</p>
</li>
<li><p> multivariate functional data analysis (normalization and functional singular component analysis)
</p>
</li>
<li><p> variance processes and volatility processes (the latter of interest in finance)
</p>
</li>
<li><p> optimal designs for longitudinal data analysis (for trajectory prediction and for functional linear regression) 
</p>
</li>
<li><p> stringing, a method to convert high-dimensional data into functional data
</p>
</li>
<li><p> quantile regression, with functions as predictors
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Yidong Zhou <a href="mailto:ydzhou@ucdavis.edu">ydzhou@ucdavis.edu</a> (<a href="https://orcid.org/0000-0003-1423-1857">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Han Chen
</p>
</li>
<li><p> Su I Iao
</p>
</li>
<li><p> Poorbita Kundu
</p>
</li>
<li><p> Hang Zhou
</p>
</li>
<li><p> Satarupa Bhattacharjee
</p>
</li>
<li><p> Cody Carroll (<a href="https://orcid.org/0000-0003-3525-8653">ORCID</a>)
</p>
</li>
<li><p> Yaqing Chen
</p>
</li>
<li><p> Xiongtao Dai
</p>
</li>
<li><p> Jianing Fan
</p>
</li>
<li><p> Alvaro Gajardo
</p>
</li>
<li><p> Pantelis Z. Hadjipantelis
</p>
</li>
<li><p> Kyunghee Han
</p>
</li>
<li><p> Hao Ji
</p>
</li>
<li><p> Changbo Zhu
</p>
</li>
<li><p> Hans-Georg Müller <a href="mailto:hgmueller@ucdavis.edu">hgmueller@ucdavis.edu</a> [copyright holder, thesis advisor]
</p>
</li>
<li><p> Jane-Ling Wang <a href="mailto:janelwang@ucdavis.edu">janelwang@ucdavis.edu</a> [copyright holder, thesis advisor]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Paromita Dubey [contributor]
</p>
</li>
<li><p> Shu-Chin Lin [contributor]
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p> Wang, J.L., Chiou, J.,  Müller, H.G. (2016). Functional data analysis. Annual Review of Statistics and Its Application 3, 257&ndash;295;
</p>
</li>
<li><p> Chen, K., Zhang, X., Petersen, A., Müller, H.G.  (2017). Quantifying infinite-dimensional data: Functional Data Analysis in action. Statistics in Biosciences 9, 582–-604.
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/functionaldata/tPACE">https://github.com/functionaldata/tPACE</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/functionaldata/tPACE/issues">https://github.com/functionaldata/tPACE/issues</a>
</p>
</li></ul>

<p>_PACKAGE
</p>

<hr>
<h2 id='fitted.FPCA'>Fitted functional data from FPCA object</h2><span id='topic+fitted.FPCA'></span>

<h3>Description</h3>

<p>Combines the zero-meaned fitted values and the interpolated mean to get the fitted values for the trajectories 
or the derivatives of these trajectories.
Estimates are given on the work-grid, not on the observation grid. Use ConvertSupport 
to map the estimates to your desired domain. <code>100*(1-alpha)</code>-percentage coverage intervals, or 
bands, for trajectory estimates (not derivatives) are provided. For details consult the example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FPCA'
fitted(
  object,
  K = NULL,
  derOptns = list(p = 0),
  ciOptns = list(alpha = NULL, cvgMethod = NULL),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.FPCA_+3A_object">object</code></td>
<td>
<p>A object of class FPCA returned by the function FPCA().</p>
</td></tr>
<tr><td><code id="fitted.FPCA_+3A_k">K</code></td>
<td>
<p>The integer number of the first K components used for the representation. (default: length(fpcaObj$lambda ))</p>
</td></tr>
<tr><td><code id="fitted.FPCA_+3A_deroptns">derOptns</code></td>
<td>
<p>A list of options to control the derivation parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;. (default = NULL)</p>
</td></tr>
<tr><td><code id="fitted.FPCA_+3A_cioptns">ciOptns</code></td>
<td>
<p>A list of options to control the confidence interval/band specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;. (default = NULL)</p>
</td></tr>
<tr><td><code id="fitted.FPCA_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available derivation control options are 
</p>

<dl>
<dt>p</dt><dd><p>The order of the derivatives returned (default: 0, max: 2)</p>
</dd>
<dt>method</dt><dd><p>The method used to produce the sample of derivatives ('FPC' (default) or 'QUO'). See Liu and Müller (2009) for more details</p>
</dd>
<dt>bw</dt><dd><p>Bandwidth for smoothing the derivatives (default: p * 0.10 * S)</p>
</dd>
<dt>kernelType</dt><dd><p>Smoothing kernel choice; same available types are FPCA(). default('epan')</p>
</dd>
</dl>

<p>Available confidence interval/band control options are 
</p>

<dl>
<dt>alpha</dt><dd><p>Significant level for confidence interval/band for trajectory coverage. default=0.05 (currently only work when p=0)</p>
</dd>
<dt>cvgMethod</dt><dd><p>Option for trajectory coverage method between 'interval' (pointwise coverage) and 'band' (simultaneous coverage). default='band'</p>
</dd>
</dl>



<h3>Value</h3>

<p>If <code>alpha</code> is <code>NULL</code>, <code>p&gt;1</code> or functional observations are dense, an <code>n</code> by <code>length(workGrid)</code> matrix, each row of which contains a sample. Otherwise, it returns a list which consists of the following items:
</p>
<table role = "presentation">
<tr><td><code>workGrid</code></td>
<td>
<p>An evaluation grid for fitted values.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>An n by length(workGrid) matrix, each row of which contains a sample.</p>
</td></tr>
<tr><td><code>cvgUpper</code></td>
<td>
<p>An n by length(workGrid) matrix, each row of which contains the upper <code>alpha</code>-coverage limit</p>
</td></tr>
<tr><td><code>cvgLower</code></td>
<td>
<p>An n by length(workGrid) matrix, each row of which contains the lower <code>alpha</code>-coverage limit</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Yao, F., Müller, H.-G. and Wang, J.-L. &quot;Functional data analysis for sparse longitudinal data&quot;, Journal of the American Statistical Association, vol.100, No. 470 (2005): 577-590.</cite>
</p>
<p><cite>Liu, Bitao, and Hans-Georg Müller. &quot;Estimating derivatives for samples of sparsely observed functions, with application to online auction dynamics.&quot; Journal of the American Statistical Association 104, no. 486 (2009): 704-717. (Sparse data FPCA)</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 100
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 5:10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=TRUE))
fittedY &lt;- fitted(res, ciOptns = list(alpha=0.05))

workGrid &lt;- res$workGrid
cvgUpper &lt;- fittedY$cvgUpper
cvgLower &lt;- fittedY$cvgLower

op &lt;- par(mfrow=c(2,3))
ind &lt;- sample(1:n,6)
for (i in 1:6) {
 j &lt;- ind[i]
 plot(workGrid,cvgUpper[j,],type='l',ylim=c(min(cvgLower[j,]),max(cvgUpper[j,])),col=4,lty=2,
   xlab='t', ylab='X(t)', main=paste(j,'-th subject',sep=''))
 points(workGrid,cvgLower[j,],type='l',col=4,lty=2)
 points(res$inputData$Lt[[j]],res$inputData$Ly[[j]])
}
par(op)
    
</code></pre>

<hr>
<h2 id='fitted.FPCAder'>Fitted functional data for derivatives from the FPCAder object</h2><span id='topic+fitted.FPCAder'></span>

<h3>Description</h3>

<p>Combines the zero-meaned fitted values and the mean derivative to get the fitted values for the derivative trajectories.
Estimates are given on the work-grid, not on the observation grid. Use ConvertSupport to map the 
estimates to your desired domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FPCAder'
fitted(object, K = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.FPCAder_+3A_object">object</code></td>
<td>
<p>A object of class FPCA returned by the function FPCA().</p>
</td></tr>
<tr><td><code id="fitted.FPCAder_+3A_k">K</code></td>
<td>
<p>The integer number of the first K components used for the representation. (default: length(derObj$lambda ))</p>
</td></tr>
<tr><td><code id="fitted.FPCAder_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>n</code> by <code>length(workGrid)</code> matrix, each row of which contains a sample.
</p>


<h3>References</h3>

<p><cite>Liu, Bitao, and Hans-Georg Müller. &quot;Estimating derivatives for samples of sparsely observed functions, with application to online auction dynamics.&quot; Journal of the American Statistical Association 104, no. 486 (2009): 704-717. (Sparse data FPCA)</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
</code></pre>

<hr>
<h2 id='FLM'>Functional Linear Models</h2><span id='topic+FLM'></span>

<h3>Description</h3>

<p>Functional linear models for scalar or functional responses and scalar and/or functional predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FLM(Y, X, XTest = NULL, optnsListY = NULL, optnsListX = NULL, nPerm = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FLM_+3A_y">Y</code></td>
<td>
<p>Either an <em>n</em>-dimensional vector whose elements consist of scalar responses, or a list which contains functional responses in the form of a list LY and the time points LT at which they are observed (i.e., list(Ly = LY,Lt = LT)).</p>
</td></tr>
<tr><td><code id="FLM_+3A_x">X</code></td>
<td>
<p>A list of either (1) lists which contains the observed functional predictors list Lxj and the time points list Ltj at which they are observed. It needs to be of the form <code>list(list(Ly = Lx1,Lt = Lxt1),list(Ly = Lx2,Lt = Lxt2),...)</code>; (2) a matrix containing one or more scalar covariates; or (3) a mix of (1) and (2), in which case the scalar covariates must come after the functional ones.</p>
</td></tr>
<tr><td><code id="FLM_+3A_xtest">XTest</code></td>
<td>
<p>A list which contains the values of functional predictors for a held-out testing set.</p>
</td></tr>
<tr><td><code id="FLM_+3A_optnslisty">optnsListY</code></td>
<td>
<p>A list of options control parameters for the response specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo; in  <code>FPCA</code>.</p>
</td></tr>
<tr><td><code id="FLM_+3A_optnslistx">optnsListX</code></td>
<td>
<p>Either (1) A list of options control parameters for the predictors specified by <code>list(name=value)</code>; or (2) A list of list of options, e.g. <code>list(list(name1=value1), list(name2=value2))</code>. See &lsquo;Details&rsquo; in  <code>FPCA</code>.</p>
</td></tr>
<tr><td><code id="FLM_+3A_nperm">nPerm</code></td>
<td>
<p>If this argument is specified, perform a permutation test to obtain the (global) p-value for the test of regression relationship between X and Y. Recommend to set to 1000 or larger if specified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the following:
</p>
<table role = "presentation">
<tr><td><code>alpha</code></td>
<td>
<p>A length-one numeric if the response Y is scalar. Or a vector of <code>length(workGridY)</code> of the fitted constant alpha(t) in the linear model if Y is functional.</p>
</td></tr>
<tr><td><code>betaList</code></td>
<td>
<p>A list of fitted beta(s) vectors, one entry per functional predictor and one entry for all scalar predictors, if Y is scalar. Each of dimension <code>length(workGridX[[j]])</code>.
</p>
<p>Or a list of fitted beta(s,t) matrices, one per predictor, if Y is functional. Each of dimension <code>length(workGridX[[j]])</code> times <code>length(workGridY)</code>.
</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>The functional R2</p>
</td></tr>
<tr><td><code>pv</code></td>
<td>
<p>Permutation p-value based on the functional R2. NA if <code>nPerm</code> is <code>NULL</code></p>
</td></tr>
<tr><td><code>yHat</code></td>
<td>
<p>A length n vector if Y is scalar. 
</p>
<p>Or an n by <code>length(workGridY)</code> matrix of fitted Y's from the model if Y is functional.</p>
</td></tr>
<tr><td><code>yPred</code></td>
<td>
<p>Same as YHat if XTest is not provided. 
</p>
<p>Or a length <code>length(XTest[[1]]$Ly)</code> vector of predicted Y's if Y is scalar.
</p>
<p>Or a <code>length(XTest[[1]]$Ly)</code> by <code>length(workGridY)</code> matrix of predicted Y's if Y is functional.</p>
</td></tr>
<tr><td><code>estXi</code></td>
<td>
<p>A list of n by k_j matrices of estimated functional principal component scores of predictors, where k_j is the number of eigenfunctions selected for each predictor.</p>
</td></tr>
<tr><td><code>testXi</code></td>
<td>
<p>A list of n by k_j matrices of estimated functional principal component scores of predictors in XTest, with eigenfunctions fitted only with X.</p>
</td></tr>
<tr><td><code>lambdaX</code></td>
<td>
<p>A length sum_j k_j vector of estimated eigenvalues for predictors.</p>
</td></tr>
<tr><td><code>workGridX</code></td>
<td>
<p>A list of vectors, each is a working grid for a predictor.</p>
</td></tr>
<tr><td><code>optnsListX</code></td>
<td>
<p>A list of list of options actually used by the FPCA for the predictor functions</p>
</td></tr>
<tr><td><code>optnsListY</code></td>
<td>
<p>A list of options actually used by the FPCA for the response functions</p>
</td></tr>
<tr><td><code>phiY</code></td>
<td>
<p>A <code>length(workGridY)</code> by k_y the estimated eigenfunctions of Y's, where k_y is number of eigenfunctions selected for Y. NULL if Y is scalar.</p>
</td></tr>
<tr><td><code>workGridY</code></td>
<td>
<p>A vector of working grid of the response Y's. NULL if Y is scalar</p>
</td></tr>
<tr><td><code>muY</code></td>
<td>
<p>The mean or the mean function of the response</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Yao, F., Müller, H.G., Wang, J.L. (2005). Functional linear regression analysis for longitudinal data. Annals of Statistics 33, 2873&ndash;2903.</cite>
<cite>Hall, P., Horowitz, J.L. (2007). Methodology and convergence rates for functional linear regression. The Annals of Statistics, 35(1), 70&ndash;91.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1000)

library(MASS)

### functional covariate
phi1 &lt;- function(t,k) sqrt(2)*sin(2*pi*k*t)
phi2 &lt;- function(t,k) sqrt(2)*cos(2*pi*k*t)

lambdaX &lt;- c(1,0.7)

# training set
n &lt;- 50
Xi &lt;- matrix(rnorm(2*n),nrow=n,ncol=2)

denseLt &lt;- list(); denseLy &lt;- list()
sparseLt &lt;- list(); sparseLy &lt;- list()

t0 &lt;- seq(0,1,length.out=51)
for (i in 1:n) {
 denseLt[[i]] &lt;- t0
  denseLy[[i]] &lt;- lambdaX[1]*Xi[i,1]*phi1(t0,1) + lambdaX[2]*Xi[i,2]*phi1(t0,2)
  
  ind &lt;- sort(sample(1:length(t0),3))
  sparseLt[[i]] &lt;- t0[ind]
  sparseLy[[i]] &lt;- denseLy[[i]][ind]
}

denseX &lt;- list(Ly=denseLy,Lt=denseLt)
sparseX &lt;- list(Ly=sparseLy,Lt=sparseLt)

denseX &lt;- list(X=denseX)
sparseX &lt;- list(X=sparseX)

# test set
N &lt;- 30

XiTest &lt;- matrix(rnorm(2*N),nrow=N,ncol=2)

denseLtTest &lt;- list(); denseLyTest &lt;- list()

sparseLtTest &lt;- list(); sparseLyTest &lt;- list()

t0 &lt;- seq(0,1,length.out=51)
for (i in 1:N) {
  denseLtTest[[i]] &lt;- t0
  denseLyTest[[i]] &lt;- lambdaX[1]*XiTest[i,1]*phi1(t0,1) + lambdaX[2]*XiTest[i,2]*phi1(t0,2)
  
  ind &lt;- sort(sample(1:length(t0),5))
  sparseLtTest[[i]] &lt;- t0[ind]
  sparseLyTest[[i]] &lt;- denseLyTest[[i]][ind]
}

denseXTest &lt;- list(Ly=denseLyTest,Lt=denseLtTest)
sparseXTest &lt;- list(Ly=sparseLyTest,Lt=sparseLtTest)

denseXTest &lt;- list(X=denseXTest)
sparseXTest &lt;- list(X=sparseXTest)


### scalar response
beta &lt;- c(1, -1)
Y &lt;- c(Xi%*%diag(lambdaX)%*%beta) + rnorm(n,0,0.5)
YTest &lt;- c(XiTest%*%diag(lambdaX)%*%beta) + rnorm(N,0,0.5)

## dense
denseFLM &lt;- FLM(Y=Y,X=denseX,XTest=denseXTest,optnsListX=list(FVEthreshold=0.95))

trueBetaList &lt;- list()
trueBetaList[[1]] &lt;- cbind(phi1(denseFLM$workGridX[[1]],1),phi1(denseFLM$workGridX[[1]],2))%*%beta

# coefficient function estimation error (L2-norm)
plot(denseFLM$workGridX[[1]],denseFLM$betaList[[1]],type='l',xlab='t',ylab=paste('beta',1,sep=''))
points(denseFLM$workGridX[[1]],trueBetaList[[1]],type='l',col=2)

denseEstErr &lt;-
  sqrt(trapzRcpp(denseFLM$workGridX[[1]],(denseFLM$betaList[[1]] - trueBetaList[[1]])^2))
denseEstErr

op &lt;- par(mfrow=c(1,2))
plot(denseFLM$yHat,Y,xlab='fitted Y', ylab='observed Y')
abline(coef=c(0,1),col=8)
plot(denseFLM$yPred,YTest,xlab='predicted Y', ylab='observed Y')
abline(coef=c(0,1),col=8)
par(op)

# prediction error
densePredErr &lt;- sqrt(mean((YTest - denseFLM$yPred)^2))
densePredErr

</code></pre>

<hr>
<h2 id='FLMCI'>Confidence Intervals for Functional Linear Models.</h2><span id='topic+FLMCI'></span>

<h3>Description</h3>

<p>Bootstrap pointwise confidence intervals for the coefficient functions in functional linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FLMCI(Y, X, level = 0.95, R = 999, optnsListY = NULL, optnsListX = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FLMCI_+3A_y">Y</code></td>
<td>
<p>Either an n-dimensional vector whose elements consist of scalar responses, or a list which contains functional responses in the form of a list LY and the time points LT at which they are observed (i.e., <code>list(Ly = LY,Lt = LT)</code>).</p>
</td></tr>
<tr><td><code id="FLMCI_+3A_x">X</code></td>
<td>
<p>A list of lists which contains the observed functional predictors list Lxj and the time points list Ltj at which they are observed. It needs to be of the form <code>list(list(Ly = Lx1,Lt = Lxt1),list(Ly = Lx2,Lt = Lxt2),...)</code>.</p>
</td></tr>
<tr><td><code id="FLMCI_+3A_level">level</code></td>
<td>
<p>A number taking values in [0,1] determining the confidence level. Default: 0.95.</p>
</td></tr>
<tr><td><code id="FLMCI_+3A_r">R</code></td>
<td>
<p>An integer holding the number of bootstrap replicates. Default: 999.</p>
</td></tr>
<tr><td><code id="FLMCI_+3A_optnslisty">optnsListY</code></td>
<td>
<p>A list of options control parameters for the response specified by <code>list(name=value)</code>. See 'Details' in FPCA.</p>
</td></tr>
<tr><td><code id="FLMCI_+3A_optnslistx">optnsListX</code></td>
<td>
<p>A list of options control parameters for the predictors specified by <code>list(name=value)</code>. See 'Details' in FPCA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If measurement error is assumed, the diagonal elements of the raw covariance will be removed. This could result in highly unstable estimate 
if the design is very sparse, or strong seasonality presents. 
WARNING! For very sparse functional data, setting <code>measurementError=TRUE</code> is not recommended.
</p>


<h3>Value</h3>

<p>A list containing the following fields: 
</p>
<table role = "presentation">
<tr><td><code>CI_alpha</code></td>
<td>
<p>CI for the intercept function &mdash; A data frame holding three variables: 
<code>CI_grid</code> &mdash; the time grid where the CIs are evaluated,
<code>CI_lower</code> and <code>CI_upper</code> &mdash; the lower and upper bounds of the CIs 
for the intercept function on <code>CIgrid</code>.</p>
</td></tr>
<tr><td><code>CI_beta</code></td>
<td>
<p> A list containing CIs for the slope functions &mdash; the length of
the list is the same as the number of covariates. Each list contains the following fields:
A data frame holding three variables: <code>CI_grid</code> &mdash; the time grid where the CIs are evaluated,
<code>CI_lower</code> and <code>CI_upper</code> &mdash; the lower and upper bounds of the CIs 
for the coefficient function on <code>CIgrid</code> for <code class="reqn">j = 1,2,\dots</code>.</p>
</td></tr>
<tr><td><code>level</code></td>
<td>
<p>The confidence level of the CIs.</p>
</td></tr>
</table>

<hr>
<h2 id='FOptDes'>Optimal Designs for Functional and Longitudinal Data
for Trajectory Recovery or Scalar Response Prediction</h2><span id='topic+FOptDes'></span>

<h3>Description</h3>

<p>Optimal Designs for Functional and Longitudinal Data
for Trajectory Recovery or Scalar Response Prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FOptDes(
  Ly,
  Lt,
  Resp,
  p = 3,
  optns = list(),
  isRegression = !missing(Resp),
  isSequential = FALSE,
  RidgeCand = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FOptDes_+3A_ly">Ly</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='dense'</code>).</p>
</td></tr>
<tr><td><code id="FOptDes_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="FOptDes_+3A_resp">Resp</code></td>
<td>
<p>A vector of response values, keep void for trajectory recovery, only necessary for scalar response prediction task.</p>
</td></tr>
<tr><td><code id="FOptDes_+3A_p">p</code></td>
<td>
<p>A fixed positive integer indicating the number of optimal design points requested, with default: 3.</p>
</td></tr>
<tr><td><code id="FOptDes_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> for FPCA, with default: list().</p>
</td></tr>
<tr><td><code id="FOptDes_+3A_isregression">isRegression</code></td>
<td>
<p>A logical argument, indicating the purpose of the optimal designs: TRUE for scalar response prediction, FALSE for trajectory recovery, with default value !missing(Resp).</p>
</td></tr>
<tr><td><code id="FOptDes_+3A_issequential">isSequential</code></td>
<td>
<p>A logical argument, indicating whether to use the sequential optimization procedure for faster computation, recommended for relatively large p (default: FALSE).</p>
</td></tr>
<tr><td><code id="FOptDes_+3A_ridgecand">RidgeCand</code></td>
<td>
<p>A vector of positive numbers as ridge penalty candidates for regularization. The final value is selected via cross validation. If only 1 ridge parameter is specified, CV procedure is skipped.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To select a proper RidgeCand, check with the returned optimal ridge parameter. If the selected parameter is the maximum/minimum values in the candidates, it is possible that the selected one is too small/big.
</p>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>OptDes</code></td>
<td>
<p>The vector of optimal design points of the regular time grid of the observed data.</p>
</td></tr>
<tr><td><code>R2</code></td>
<td>
<p>Coefficient of determination. (Check the paper for details.)</p>
</td></tr>
<tr><td><code>R2adj</code></td>
<td>
<p>Adjusted coefficient of determination.</p>
</td></tr>
<tr><td><code>OptRidge</code></td>
<td>
<p>The selected ridge parameter.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Ji, H., Müller, H.G. (2017) &quot;Optimal Designs for Longitudinal and Functional Data&quot; 
Journal of the Royal Statistical Society: Series B 79, 859-876.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 50
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- MakeFPCAInputs(IDs = rep(1:n, each=length(pts)), 
                             tVec = rep(pts, times = n), 
                             yVec = t(sampWiener))
res &lt;- FOptDes(Ly=sampWiener$Ly, Lt=sampWiener$Lt, p=2,
               isSequential=FALSE, RidgeCand = seq(0.02,0.2,0.02))
</code></pre>

<hr>
<h2 id='FPCA'>Functional Principal Component Analysis</h2><span id='topic+FPCA'></span>

<h3>Description</h3>

<p>FPCA for dense or sparse functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FPCA(Ly, Lt, optns = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FPCA_+3A_ly">Ly</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='Dense'</code>).</p>
</td></tr>
<tr><td><code id="FPCA_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="FPCA_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the input is sparse data, make sure you check the design plot is dense and the 2D domain is well covered
by support points, using <code>plot</code> or <code>CreateDesignPlot</code>. Some study design such as snippet data (where each subject is 
observed only on a sub-interval of the period of study) will have an ill-covered design plot, in which case the nonparametric 
covariance estimate will be unreliable.
WARNING! Slow computation times may occur if the dataType argument is incorrect. If FPCA is taking a while, please double check that a dense design is not mistakenly coded as 'Sparse'. Applying FPCA to a mixture of very dense and sparse curves may result in computational issues.
</p>
<p>Available control options are 
</p>

<dl>
<dt>userBwCov</dt><dd><p>The bandwidth value for the smoothed covariance function; positive numeric - default: determine automatically based on 'methodBwCov'</p>
</dd>
<dt>methodBwCov</dt><dd><p>The bandwidth choice method for the smoothed covariance function; 'GMeanAndGCV' (the geometric mean of the GCV bandwidth and the minimum bandwidth),'CV','GCV' - default: 10% of the support</p>
</dd>
<dt>userBwMu</dt><dd><p>The bandwidth value for the smoothed mean function (using 'CV' or 'GCV'); positive numeric - default: determine automatically based on 'methodBwMu'</p>
</dd>
<dt>methodBwMu</dt><dd><p>The bandwidth choice method for the mean function; 'GMeanAndGCV' (the geometric mean of the GCV bandwidth and the minimum bandwidth),'CV','GCV' - default: 5% of the support</p>
</dd> 
<dt>dataType</dt><dd><p>The type of design we have (usually distinguishing between sparse or dense functional data); 'Sparse', 'Dense', 'DenseWithMV', 'p&gt;&gt;n' - default:  determine automatically based on 'IsRegular'</p>
</dd>
<dt>diagnosticsPlot</dt><dd><p>Deprecated. Same as the option 'plot'</p>
</dd>
<dt>plot</dt><dd><p>Plot FPCA results (design plot, mean, scree plot and first K (&lt;=3) eigenfunctions); logical - default: FALSE</p>
</dd>
<dt>error</dt><dd><p>Assume measurement error in the dataset; logical - default: TRUE</p>
</dd>
<dt>fitEigenValues</dt><dd><p>Whether also to obtain a regression fit of the eigenvalues - default: FALSE</p>
</dd>
<dt>FVEthreshold</dt><dd><p>Fraction-of-Variance-Explained threshold used during the SVD of the fitted covariance function; numeric (0,1] - default: 0.99</p>
</dd>
<dt>FVEfittedCov</dt><dd><p>Fraction-of-Variance explained by the components that are used to construct fittedCov; numeric (0,1] - default: NULL (all components available will be used)</p>
</dd>
<dt>kernel</dt><dd><p>Smoothing kernel choice, common for mu and covariance; &quot;rect&quot;, &quot;gauss&quot;, &quot;epan&quot;, &quot;gausvar&quot;, &quot;quar&quot; - default: &quot;gauss&quot;; dense data are assumed noise-less so no smoothing is performed. </p>
</dd>
<dt>kFoldMuCov</dt><dd><p>The number of folds to be used for mean and covariance smoothing. Default: 10</p>
</dd>
<dt>lean</dt><dd><p>If TRUE the 'inputData' field in the output list is empty. Default: FALSE</p>
</dd>
<dt>maxK</dt><dd><p>The maximum number of principal components to consider - default: min(20, N-2,nRegGrid-2), N:# of curves, nRegGrid:# of support points in each direction of covariance surface</p>
</dd>
<dt>methodXi</dt><dd><p>The method to estimate the PC scores; 'CE' (Conditional Expectation), 'IN' (Numerical Integration) - default: 'CE' for sparse data and dense data with missing values, 'IN' for dense data. If time points are irregular but spacing is small enough, 'IN' method is utilized by default.</p>
</dd>
<dt>methodMuCovEst</dt><dd><p>The method to estimate the mean and covariance in the case of dense functional data; 'cross-sectional', 'smooth' - default: 'cross-sectional'</p>
</dd>
<dt>nRegGrid</dt><dd><p>The number of support points in each direction of covariance surface; numeric - default: 51</p>
</dd>
<dt>numBins</dt><dd><p>The number of bins to bin the data into; positive integer &gt; 10, default: NULL</p>
</dd>
<dt>methodSelectK</dt><dd><p>The method of choosing the number of principal components K; 'FVE','AIC','BIC', or a positive integer as specified number of components: default 'FVE')</p>
</dd>
<dt>shrink</dt><dd><p>Whether to use shrinkage method to estimate the scores in the dense case (see Yao et al 2003) - default FALSE</p>
</dd>
<dt>outPercent</dt><dd><p>A 2-element vector in [0,1] indicating the percentages of the time range to be considered as left and right boundary regions of the time window of observation - default (0,1) which corresponds to no boundary</p>
</dd>
<dt>methodRho</dt><dd><p>The method of regularization (add to diagonal of covariance surface) in estimating principal component scores; 'trunc': rho is truncation of sigma2, 'ridge': rho is a ridge parameter, 'vanilla': vanilla approach - default &quot;vanilla&quot;.</p>
</dd>
<dt>rotationCut</dt><dd><p>The 2-element vector in [0,1] indicating the percent of data truncated during sigma^2 estimation; default  (0.25, 0.75))</p>
</dd>
<dt>useBinnedData</dt><dd><p>Should the data be binned? 'FORCE' (Enforce the # of bins), 'AUTO' (Select the # of  bins automatically), 'OFF' (Do not bin) - default: 'AUTO'</p>
</dd>
<dt>useBinnedCov</dt><dd><p>Whether to use the binned raw covariance for smoothing; logical - default:TRUE</p>
</dd>
<dt>usergrid</dt><dd><p>Whether to use observation grid for fitting, if false will use equidistant grid. logical - default:FALSE</p>
</dd>
<dt>userCov</dt><dd><p>The user-defined smoothed covariance function; list of two elements: numerical vector 't' and matrix 'cov', 't' must cover the support defined by 'Ly' - default: NULL</p>
</dd>
<dt>userMu</dt><dd><p>The user-defined smoothed mean function; list of two numerical vector 't' and 'mu' of equal size, 't' must cover the support defined 'Ly' - default: NULL</p>
</dd>
<dt>userSigma2</dt><dd><p>The user-defined measurement error variance. A positive scalar. If specified then the vanilla approach is used (methodRho is set to 'vanilla', unless specified otherwise). Default to 'NULL'</p>
</dd>
<dt>userRho</dt><dd><p>The user-defined measurement truncation threshold used for the calculation of functional principal components scores. A positive scalar. Default to 'NULL'</p>
</dd>
<dt>useBW1SE</dt><dd><p>Pick the largest bandwidth such that CV-error is within one Standard Error from the minimum CV-error, relevant only if methodBwMu ='CV' and/or methodBwCov ='CV'; logical - default: FALSE</p>
</dd>
<dt>imputeScores</dt><dd><p>Whether to impute the FPC scores or not; default: 'TRUE'</p>
</dd>
<dt>verbose</dt><dd><p>Display diagnostic messages; logical - default: FALSE</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>sigma2</code></td>
<td>
<p>Variance for measurement error.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>A vector of length <em>K</em> containing eigenvalues.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>An nWorkGrid by <em>K</em> matrix containing eigenfunctions, supported on workGrid.</p>
</td></tr>
<tr><td><code>xiEst</code></td>
<td>
<p>A <em>n</em> by <em>K</em> matrix containing the FPC estimates.</p>
</td></tr> 
<tr><td><code>xiVar</code></td>
<td>
<p>A list of length <em>n</em>, each entry containing the variance estimates for the FPC estimates.</p>
</td></tr>
<tr><td><code>obsGrid</code></td>
<td>
<p>The (sorted) grid points where all observation points are pooled.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>A vector of length nWorkGrid containing the mean function estimate.</p>
</td></tr>
<tr><td><code>workGrid</code></td>
<td>
<p>A vector of length nWorkGrid. The internal regular grid on which the eigen analysis is carried on.</p>
</td></tr>
<tr><td><code>smoothedCov</code></td>
<td>
<p>A nWorkGrid by nWorkGrid matrix of the smoothed covariance surface.</p>
</td></tr>
<tr><td><code>fittedCov</code></td>
<td>
<p>A nWorkGrid by nWorkGrid matrix of the fitted covariance surface, which is guaranteed to be non-negative definite.</p>
</td></tr>
<tr><td><code>fittedCorr</code></td>
<td>
<p>A nWorkGrid by nWorkGrid matrix of the fitted correlation surface computed from fittedCov.</p>
</td></tr>
<tr><td><code>optns</code></td>
<td>
<p>A list of actually used options.</p>
</td></tr>
<tr><td><code>timings</code></td>
<td>
<p>A vector with execution times for the basic parts of the FPCA call.</p>
</td></tr>
<tr><td><code>bwMu</code></td>
<td>
<p>The selected (or user specified) bandwidth for smoothing the mean function.</p>
</td></tr>
<tr><td><code>bwCov</code></td>
<td>
<p>The selected (or user specified) bandwidth for smoothing the covariance function.</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>A regularizing scalar for the measurement error variance estimate.</p>
</td></tr>
<tr><td><code>cumFVE</code></td>
<td>
<p>A vector with the fraction of the cumulative total variance explained with each additional FPC.</p>
</td></tr>
<tr><td><code>FVE</code></td>
<td>
<p>A fraction indicating the total variance explained by chosen FPCs with corresponding 'FVEthreshold'.</p>
</td></tr>
<tr><td><code>selectK</code></td>
<td>
<p>Number <em>K</em> of selected components.</p>
</td></tr>
<tr><td><code>criterionValue</code></td>
<td>
<p>A scalar specifying the criterion value obtained by the selected number of components with specific methodSelectK: FVE, AIC, BIC values or NULL for fixed K.</p>
</td></tr>
<tr><td><code>inputData</code></td>
<td>
<p>A list containing the original 'Ly' and 'Lt' lists used as inputs to FPCA. NULL if 'lean' was specified to be TRUE.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Yao, F., Müller, H.G., Clifford, A.J., Dueker, S.R., Follett, J., Lin, Y., Buchholz, B., Vogel, J.S. (2003). &quot;Shrinkage estimation 
for functional principal component scores, with application to the population kinetics of plasma folate.&quot; Biometrics 59, 676-685. (Shrinkage estimates for dense data)</cite>
</p>
<p><cite>Yao, Fang, Müller, Hans-Georg and Wang, Jane-Ling (2005). &quot;Functional data analysis for sparse longitudinal data.&quot; 
Journal of the American Statistical Association 100, no. 470  577-590. (Sparse data FPCA)</cite>
</p>
<p><cite>Liu, Bitao  and Müller, Hans-Georg (2009). &quot;Estimating derivatives for samples of sparsely observed functions, 
with application to online auction dynamics.&quot; Journal of the American Statistical Association 104, no. 486 704-717. (Sparse data FPCA)</cite>
</p>
<p><cite>Castro, P. E., Lawton, W.H. and Sylvestre, E.A. (1986). &quot;Principal modes of variation for processes with continuous 
sample curves.&quot; Technometrics 28, no. 4, 329-337. (modes of variation for dense data FPCA)</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt, 
            list(dataType='Sparse', error=FALSE, kernel='epan', verbose=TRUE))
plot(res) # The design plot covers [0, 1] * [0, 1] well.
CreateCovPlot(res, 'Fitted')
CreateCovPlot(res, corr = TRUE)
</code></pre>

<hr>
<h2 id='FPCAder'>Obtain the derivatives of eigenfunctions/ eigenfunctions of derivatives
(note: these two are not the same)</h2><span id='topic+FPCAder'></span>

<h3>Description</h3>

<p>Obtain the derivatives of eigenfunctions/ eigenfunctions of derivatives
(note: these two are not the same)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FPCAder(fpcaObj, derOptns = list(p = 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FPCAder_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>A object of class FPCA returned by the function FPCA().</p>
</td></tr>
<tr><td><code id="FPCAder_+3A_deroptns">derOptns</code></td>
<td>
<p>A list of options to control the derivation parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;. (default = NULL)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available derivative options are 
</p>

<dl>
<dt>method</dt><dd><p>The method used for obtaining the derivatives &ndash; default is  'FPC', which is the derivatives of eigenfunctions; 'DPC': eigenfunctions of derivatives, 
with G^(1,1) estimated by an initial kernel local smoothing step for  G^(1,0),  then applying a 1D smoother in the second direction; 
'FPC': functional principal component, based on smoothing the eigenfunctions; 'FPC1': functional principal component, based on smoothing G^(1,0). 
The latter may produce better estimates than 'FPC' but is slower.</p>
</dd>
<dt>p</dt><dd><p>The order of the derivatives returned (default: 1, max: 2). </p>
</dd>
<dt>bw</dt><dd><p>Bandwidth for the 1D and the 2D smoothers (default: p * 0.1 * S, where S is the length of the domain).</p>
</dd>
<dt>kernelType</dt><dd><p>Smoothing kernel choice; same available types are FPCA(). default('epan')</p>
</dd>
</dl>



<h3>References</h3>

<p><cite>Dai, X., Tao, W., Müller, H.G. (2018). Derivative principal components for representing the time dynamics of longitudinal and functional data.
Statistica Sinica 28, 1583&ndash;1609. (DPC)</cite>
<cite>Liu, Bitao, and Hans-Georg Müller. &quot;Estimating derivatives for samples of sparsely observed functions, 
with application to online auction dynamics.&quot; Journal of the American Statistical Association 104, no. 486 (2009): 704-717. (FPC)</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
bw &lt;- 0.2
kern &lt;- 'epan'
set.seed(1)
n &lt;- 50 
M &lt;- 30
pts &lt;- seq(0, 1, length.out=M)
lambdaTrue &lt;- c(1, 0.8, 0.1)^2
sigma2 &lt;- 0.1

samp2 &lt;- MakeGPFunctionalData(n, M, pts, K=length(lambdaTrue), 
                              lambda=lambdaTrue, sigma=sqrt(sigma2), basisType='legendre01')
samp2 &lt;- c(samp2, MakeFPCAInputs(tVec=pts, yVec=samp2$Yn))
fpcaObj &lt;- FPCA(samp2$Ly, samp2$Lt, list(methodMuCovEst='smooth',
                userBwCov=bw, userBwMu=bw, kernel=kern, error=TRUE)) 
CreatePathPlot(fpcaObj, showObs=FALSE)

FPCoptn &lt;- list(bw=bw, kernelType=kern, method='FPC')
DPCoptn &lt;- list(bw=bw, kernelType=kern, method='DPC')
FPC &lt;- FPCAder(fpcaObj, FPCoptn)
DPC &lt;- FPCAder(fpcaObj, DPCoptn)

CreatePathPlot(FPC, ylim=c(-5, 10))
CreatePathPlot(DPC, ylim=c(-5, 10))

# Get the true derivatives
phi &lt;-  CreateBasis(K=3, type='legendre01', pts=pts)
basisDerMat &lt;- apply(phi, 2, function(x) 
                       ConvertSupport(seq(0, 1, length.out=M - 1), pts, diff(x) * (M - 1)))
trueDer &lt;- matrix(1, n, M, byrow=TRUE) + tcrossprod(samp2$xi, basisDerMat)
matplot(t(trueDer), type='l', ylim=c(-5, 10))

# DPC is slightly better in terms of RMSE
mean((fitted(FPC) - trueDer)^2)
mean((fitted(DPC) - trueDer)^2)

</code></pre>

<hr>
<h2 id='FPCquantile'>Conditional Quantile estimation with functional covariates</h2><span id='topic+FPCquantile'></span>

<h3>Description</h3>

<p>Main function to implement conditional Quantile estimation with functional covariates and scalar response. The method includes 3 steps: 
1) FPCA using the PACE method for X(t_x)
2) Computation of the conditional distribution function through a functional generalized linear model.
3) Prediction of quantiles for given predictor values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FPCquantile(
  Lx,
  Lt_x,
  y,
  outQ = c(0.1, 0.25, 0.5, 0.75, 0.9),
  optns_x = NULL,
  isNewSub = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FPCquantile_+3A_lx">Lx</code></td>
<td>
<p>A length n list of predictor function where x[[i]] is the row vector of measurements for ith subject, i=1,...,n</p>
</td></tr>
<tr><td><code id="FPCquantile_+3A_lt_x">Lt_x</code></td>
<td>
<p>A length n list where the observations of x are taken, t_x[[i]] is a row vector of time points where x[[i]] are observed, i=1,...,n</p>
</td></tr>
<tr><td><code id="FPCquantile_+3A_y">y</code></td>
<td>
<p>A 1*n vector for scalar response y. y[i] is the response value for the ith subject, i = 1,...,n.</p>
</td></tr>
<tr><td><code id="FPCquantile_+3A_outq">outQ</code></td>
<td>
<p>A vector of desired quantile levels with default value outQ = c(0.1, 0.25, 0.5, 0.75, 0.9).</p>
</td></tr>
<tr><td><code id="FPCquantile_+3A_optns_x">optns_x</code></td>
<td>
<p>A list of options for predictor x with control parameters specified by list(name=value) with default NA. See function FPCA for details.</p>
</td></tr>
<tr><td><code id="FPCquantile_+3A_isnewsub">isNewSub</code></td>
<td>
<p>A 1*n vector of 0s or 1s, where n is the total count of subjects. 0 denotes the corresponding subject is only used for training and 1 denotes the corresponding subject is only used for prediction. (default: 0's)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the following
</p>
<table role = "presentation">
<tr><td><code>pred_quantile</code></td>
<td>
<p>A matrix of n*length(outQ) where the the first nn (number of 0s in <code>isNewSub</code>) rows containing fitted  conditional quantiles of Y corresponding to the training subjects, and the last n-nn rows containing predicted conditional quantiles of Y corresponding to the subjects isNewSub ==1.</p>
</td></tr>
<tr><td><code>pred_CDF</code></td>
<td>
<p>A matrix of n*100. The ith row contains the fitted or predicted conditional distribution function <code class="reqn">F(y|X_i)</code>, evaluated at an equally spaced grid of 100 points.</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>A matrix of 50*(K+1) contains the coefficient functions, defined as <code class="reqn">F(y|X) = g(\sum_(k=0)^K b_k(y)\xi_k)</code>, see equation (5) in the paper for details, where K is the number of components selected to expand the predictor functions X, and <code class="reqn">\xi_k</code> is the kth principal component score.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Chen, K., Müller, H.G. (2011). Conditional quantile analysis when covariates are functions, with application to growth data. 
J. Royal Statistical Society B 74, 67-89</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(10)

n = 200
npred = 50
m = 50
xi &lt;- Wiener(n, 0:m/m)

x=list()
t_x=list()
y=numeric(n)
for(i in 1:n){
 t_x = c(t_x,list(0:m/m))
 x = c(x,list(xi[i,]))
 y[i] = 5*rnorm(1)+2*sum(xi[i,])
}

outQ = c(0.1,0.25,0.5,0.75,0.9,0.95)
isNewSub = c(rep(0,150),rep(1,50))
qtreg = FPCquantile(x, t_x, y, outQ,optns_x = NULL,isNewSub)

</code></pre>

<hr>
<h2 id='FSVD'>Functional Singular Value Decomposition</h2><span id='topic+FSVD'></span>

<h3>Description</h3>

<p>FSVD for a pair of dense or sparse functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FSVD(
  Ly1,
  Lt1,
  Ly2,
  Lt2,
  FPCAoptns1 = NULL,
  FPCAoptns2 = NULL,
  SVDoptns = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FSVD_+3A_ly1">Ly1</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='dense'</code>).</p>
</td></tr>
<tr><td><code id="FSVD_+3A_lt1">Lt1</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="FSVD_+3A_ly2">Ly2</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='dense'</code>).</p>
</td></tr>
<tr><td><code id="FSVD_+3A_lt2">Lt2</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="FSVD_+3A_fpcaoptns1">FPCAoptns1</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> for the FPC analysis of sample 1. See &lsquo;?FPCA&rsquo;.</p>
</td></tr>
<tr><td><code id="FSVD_+3A_fpcaoptns2">FPCAoptns2</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> for the FPC analysis of sample 2. See &lsquo;?FPCA&rsquo;.</p>
</td></tr>
<tr><td><code id="FSVD_+3A_svdoptns">SVDoptns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> for the FSVD analysis of samples 1 &amp; 2. See 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available control options for SVDoptns are: 
</p>

<dl>
<dt>bw1</dt><dd><p>The bandwidth value for the smoothed cross-covariance function across the direction of sample 1; positive numeric - default: determine automatically based on 'methodBwCov'</p>
</dd>
<dt>bw2</dt><dd><p>The bandwidth value for the smoothed cross-covariance function across the direction of sample 2; positive numeric - default: determine automatically based on 'methodBwCov'</p>
</dd>
<dt>methodBwCov</dt><dd><p>The bandwidth choice method for the smoothed covariance function; 'GMeanAndGCV' (the geometric mean of the GCV bandwidth and the minimum bandwidth),'CV','GCV' - default: 10% of the support</p>
</dd>
<dt>userMu1</dt><dd><p>The user defined mean of sample 1 used to centre it prior to the cross-covariance estimation. - default: determine automatically based by the FPCA of sample 1</p>
</dd>
<dt>userMu2</dt><dd><p>The user defined mean of sample 2 used to centre it prior to the cross-covariance estimation. - default: determine automatically based by the FPCA of sample 2</p>
</dd>
<dt>maxK</dt><dd><p>The maximum number of singular components to consider; default: min(20, N-1), N:# of curves.</p>
</dd>
<dt>kernel</dt><dd><p>Smoothing kernel choice, common for mu and covariance; &quot;rect&quot;, &quot;gauss&quot;, &quot;epan&quot;, &quot;gausvar&quot;, &quot;quar&quot; - default: &quot;gauss&quot;; dense data are assumed noise-less so no smoothing is performed.</p>
</dd>
<dt>rmDiag</dt><dd><p>Logical describing if the routine should remove diagonal raw cov for cross cov estimation (default: FALSE) </p>
</dd>
<dt>noScores</dt><dd><p>Logical describing if the routine should return functional singular scores or not (default: TRUE) </p>
</dd>
<dt>regulRS</dt><dd><p>String describing if the regularisation of the composite cross-covariance matrix should be done using 'sigma1' or 'rho' (see ?FPCA for details) (default: 'sigma2') </p>
</dd>
<dt>bwRoutine</dt><dd><p>String specifying the routine used to find the optimal bandwidth 'grid-search', 'bobyqa', 'l-bfgs-b' (default: 'l-bfgs-b')</p>
</dd>
<dt>flip</dt><dd><p>Logical describing if the routine should flip the sign of the singular components functions or not after the SVD of the cross-covariance matrix. (default: FALSE)</p>
</dd>
<dt>useGAM</dt><dd><p>Indicator to use gam smoothing instead of local-linear smoothing (semi-parametric option) (default: FALSE)</p>
</dd>
<dt>dataType1</dt><dd><p>The type of design we have for sample 1 (usually distinguishing between sparse or dense functional data); 'Sparse', 'Dense', 'DenseWithMV' - default:  determine automatically based on 'IsRegular'</p>
</dd>
<dt>dataType2</dt><dd><p>The type of design we have for sample 2 (usually distinguishing between sparse or dense functional data); 'Sparse', 'Dense', 'DenseWithMV' - default:  determine automatically based on 'IsRegular'</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>bw1</code></td>
<td>
<p>The selected (or user specified) bandwidth for smoothing the cross-covariance function across the support of sample 1.</p>
</td></tr>
<tr><td><code>bw2</code></td>
<td>
<p>The selected (or user specified) bandwidth for smoothing the cross-covariance function across the support of sample 2.</p>
</td></tr>
<tr><td><code>CrCov</code></td>
<td>
<p>The smoothed cross-covariance between samples 1 &amp; 2.</p>
</td></tr>
<tr><td><code>sValues</code></td>
<td>
<p>A list of length <em>nsvd</em>, each entry containing the singular value estimates for the FSC estimates.</p>
</td></tr>
<tr><td><code>nsvd</code></td>
<td>
<p>The number of singular components used.</p>
</td></tr>
<tr><td><code>canCorr</code></td>
<td>
<p>The canonical correlations for each dimension.</p>
</td></tr>
<tr><td><code>FVE</code></td>
<td>
<p>A percentage indicating the total variance explained by chosen FSCs with corresponding 'FVEthreshold'.</p>
</td></tr>
<tr><td><code>sFun1</code></td>
<td>
<p>An nWorkGrid by <em>K</em> matrix containing the estimated singular functions for sample 1.</p>
</td></tr>
<tr><td><code>sFun2</code></td>
<td>
<p>An nWorkGrid by <em>K</em> matrix containing the estimated singular functions for sample 2.</p>
</td></tr>
<tr><td><code>grid1</code></td>
<td>
<p>A vector of length nWorkGrid1. The internal regular grid on which the singular analysis is carried on the support of sample 1.</p>
</td></tr>
<tr><td><code>grid2</code></td>
<td>
<p>A vector of length nWorkGrid2. The internal regular grid on which the singular analysis is carried on the support of sample 2.</p>
</td></tr>
<tr><td><code>sScores1</code></td>
<td>
<p>A <em>n</em> by <em>K</em> matrix containing the singular scores for sample 1.</p>
</td></tr>
<tr><td><code>sScores2</code></td>
<td>
<p>A <em>n</em> by <em>K</em> matrix containing the singular scores for sample 2.</p>
</td></tr>
<tr><td><code>optns</code></td>
<td>
<p>A list of options used by the SVD and the FPCA's procedures.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Yang, W., Müller, H.G., Stadtmüller, U. (2011). Functional singular component analysis. J. Royal Statistical Society B73, 303-324.</cite>
</p>

<hr>
<h2 id='FVPA'>Functional Variance Process Analysis for dense functional data</h2><span id='topic+FVPA'></span>

<h3>Description</h3>

<p>Functional Variance Process Analysis for dense functional data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FVPA(y, t, q = 0.1, optns = list(error = TRUE, FVEthreshold = 0.9))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FVPA_+3A_y">y</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='dense'</code>).</p>
</td></tr>
<tr><td><code id="FVPA_+3A_t">t</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y.</p>
</td></tr>
<tr><td><code id="FVPA_+3A_q">q</code></td>
<td>
<p>A scalar defining the percentile of the pooled sample residual sample used for adjustment before taking log (default: 0.1).</p>
</td></tr>
<tr><td><code id="FVPA_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>; by default: 'error' has to be TRUE, 'FVEthreshold' is set to 0.90. See &lsquo;Details in ?FPCA&rsquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>sigma2</code></td>
<td>
<p>Variance estimator of the functional variance process.</p>
</td></tr> 
<tr><td><code>fpcaObjY</code></td>
<td>
<p>FPCA object for the original data.</p>
</td></tr> 
<tr><td><code>fpcaObjR</code></td>
<td>
<p>FPCA object for the functional variance process associated with the original data.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Hans-Georg Müller, Ulrich Stadtmüller and Fang Yao, &quot;Functional variance processes.&quot; Journal of the American Statistical Association 101 (2006): 1007-1018</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 25
pts &lt;- seq(0, 1, by=0.01)
sampWiener &lt;- Wiener(n, pts)
# Data have to dense for FVPA to be relevant!
sampWiener &lt;- Sparsify(sampWiener, pts, 101) 
fvpaObj &lt;- FVPA(sampWiener$Ly, sampWiener$Lt)
</code></pre>

<hr>
<h2 id='GetCovSurface'>Covariance Surface</h2><span id='topic+GetCovSurface'></span>

<h3>Description</h3>

<p>Covariance surface estimation for dense or sparse functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetCovSurface(Ly, Lt, optns = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetCovSurface_+3A_ly">Ly</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='Dense'</code>).</p>
</td></tr>
<tr><td><code id="GetCovSurface_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="GetCovSurface_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;.
</p>
<p>Available control options are 
</p>

<dl>
<dt>userBwCov</dt><dd><p>The bandwidth value for the smoothed covariance function; positive numeric - default: determine automatically based on 'methodBwCov'</p>
</dd>
<dt>methodBwCov</dt><dd><p>The bandwidth choice method for the smoothed covariance function; 'GMeanAndGCV' (the geometric mean of the GCV bandwidth and the minimum bandwidth),'CV','GCV' - default: 10% of the support</p>
</dd>
<dt>userBwMu</dt><dd><p>The bandwidth value for the smoothed mean function (using 'CV' or 'GCV'); positive numeric - default: determine automatically based on 'methodBwMu'</p>
</dd>
<dt>methodBwMu</dt><dd><p>The bandwidth choice method for the mean function; 'GMeanAndGCV' (the geometric mean of the GCV bandwidth and the minimum bandwidth),'CV','GCV' - default: 5% of the support</p>
</dd> 
<dt>dataType</dt><dd><p>The type of design we have (usually distinguishing between sparse or dense functional data); 'Sparse', 'Dense', 'DenseWithMV', 'p&gt;&gt;n' - default:  determine automatically based on 'IsRegular'</p>
</dd>
<dt>error</dt><dd><p>Assume measurement error in the dataset; logical - default: TRUE</p>
</dd>
<dt>kernel</dt><dd><p>Smoothing kernel choice, common for mu and covariance; &quot;rect&quot;, &quot;gauss&quot;, &quot;epan&quot;, &quot;gausvar&quot;, &quot;quar&quot; - default: &quot;gauss&quot;; dense data are assumed noise-less so no smoothing is performed. </p>
</dd>
<dt>kFoldMuCov</dt><dd><p>The number of folds to be used for mean and covariance smoothing. Default: 10</p>
</dd>
<dt>lean</dt><dd><p>If TRUE the 'inputData' field in the output list is empty. Default: FALSE</p>
</dd>
<dt>methodMuCovEst</dt><dd><p>The method to estimate the mean and covariance in the case of dense functional data; 'cross-sectional', 'smooth' - default: 'cross-sectional'</p>
</dd>
<dt>nRegGrid</dt><dd><p>The number of support points in each direction of covariance surface; numeric - default: 51</p>
</dd>
<dt>numBins</dt><dd><p>The number of bins to bin the data into; positive integer &gt; 10, default: NULL</p>
</dd>
<dt>rotationCut</dt><dd><p>The 2-element vector in [0,1] indicating the percent of data truncated during sigma^2 estimation; default  (0.25, 0.75))</p>
</dd>
<dt>useBinnedData</dt><dd><p>Should the data be binned? 'FORCE' (Enforce the # of bins), 'AUTO' (Select the # of  bins automatically), 'OFF' (Do not bin) - default: 'AUTO'</p>
</dd>
<dt>useBinnedCov</dt><dd><p>Whether to use the binned raw covariance for smoothing; logical - default:TRUE</p>
</dd>
<dt>userMu</dt><dd><p>The user-defined smoothed mean function; list of two numerical vector 't' and 'mu' of equal size, 't' must cover the support defined 'Ly' - default: NULL</p>
</dd>
<dt>userSigma2</dt><dd><p>The user-defined measurement error variance. A positive scalar. If specified then no regularization is used (rho is set to 'no', unless specified otherwise). Default to 'NULL'</p>
</dd>
<dt>useBW1SE</dt><dd><p>Pick the largest bandwidth such that CV-error is within one Standard Error from the minimum CV-error, relevant only if methodBwMu ='CV' and/or methodBwCov ='CV'; logical - default: FALSE</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>cov</code></td>
<td>
<p>A square matrix of size nWorkGrid containing the covariance surface estimate.</p>
</td></tr>
<tr><td><code>sigma2</code></td>
<td>
<p>A numeric estimate of the variance of measurement error.</p>
</td></tr>
<tr><td><code>workGrid</code></td>
<td>
<p>A vector of length nWorkGrid. The internal regular grid on which the covariance surface estimation is carried out.</p>
</td></tr>
<tr><td><code>bwCov</code></td>
<td>
<p>The selected (or user specified) bandwidth for smoothing thecovariance surface.</p>
</td></tr>
<tr><td><code>optns</code></td>
<td>
<p>A list of actually-used options relevant to the covariance surface calculation.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.025)
sampWiener &lt;- Wiener(n, pts)
mu = sin(2*pi*pts)
sampWiener &lt;- Sparsify(t(t(sampWiener) + mu), pts, 10)
res = GetCovSurface(Ly = sampWiener$Ly, Lt = sampWiener$Lt)
</code></pre>

<hr>
<h2 id='GetCrCorYX'>Create cross-correlation matrix from auto- and cross-covariance matrix</h2><span id='topic+GetCrCorYX'></span>

<h3>Description</h3>

<p>Create cross-correlation matrix from auto- and cross-covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetCrCorYX(ccXY, ccXX, ccYY)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetCrCorYX_+3A_ccxy">ccXY</code></td>
<td>
<p>The cross-covariance matrix between variables X and Y.</p>
</td></tr>
<tr><td><code id="GetCrCorYX_+3A_ccxx">ccXX</code></td>
<td>
<p>The auto-covariance matrix of variable X or the diagonal of that matrix.</p>
</td></tr>
<tr><td><code id="GetCrCorYX_+3A_ccyy">ccYY</code></td>
<td>
<p>The auto-covariance matrix of variable Y or the diagonal of that matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cross-correlation matrix between variables X and Y.
</p>

<hr>
<h2 id='GetCrCorYZ'>Create cross-correlation matrix from auto- and cross-covariance matrix</h2><span id='topic+GetCrCorYZ'></span>

<h3>Description</h3>

<p>Create cross-correlation matrix from auto- and cross-covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetCrCorYZ(ccYZ, acYY, covZ)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetCrCorYZ_+3A_ccyz">ccYZ</code></td>
<td>
<p>The cross-covariance vector between variables Y and Z (n-by-1).</p>
</td></tr>
<tr><td><code id="GetCrCorYZ_+3A_acyy">acYY</code></td>
<td>
<p>The auto-covariance n-by-n matrix of variable Y or the (n-by-1) diagonal of that matrix.</p>
</td></tr>
<tr><td><code id="GetCrCorYZ_+3A_covz">covZ</code></td>
<td>
<p>The (scalar) covariance of variable Z.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A cross-correlation matrix between variables Y (functional) and Z (scalar).
</p>

<hr>
<h2 id='GetCrCovYX'>Functional Cross Covariance between longitudinal variable Y and longitudinal variable X</h2><span id='topic+GetCrCovYX'></span>

<h3>Description</h3>

<p>Calculate the raw and the smoothed cross-covariance between functional predictors using bandwidth bw or estimate that bw using GCV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetCrCovYX(
  bw1 = NULL,
  bw2 = NULL,
  Ly1,
  Lt1 = NULL,
  Ymu1 = NULL,
  Ly2,
  Lt2 = NULL,
  Ymu2 = NULL,
  useGAM = FALSE,
  rmDiag = FALSE,
  kern = "gauss",
  bwRoutine = "l-bfgs-b"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetCrCovYX_+3A_bw1">bw1</code></td>
<td>
<p>Scalar bandwidth for smoothing the cross-covariance function (if NULL it will be automatically estimated) (Y)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_bw2">bw2</code></td>
<td>
<p>Scalar bandwidth for smoothing the cross-covariance function (if NULL it will be automatically estimated) (X)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_ly1">Ly1</code></td>
<td>
<p>List of N vectors with amplitude information (Y)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_lt1">Lt1</code></td>
<td>
<p>List of N vectors with timing information (Y)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_ymu1">Ymu1</code></td>
<td>
<p>Vector Q-1 Vector of length nObsGrid containing the mean function estimate (Y)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_ly2">Ly2</code></td>
<td>
<p>List of N vectors with amplitude information (X)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_lt2">Lt2</code></td>
<td>
<p>List of N vectors with timing information (X)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_ymu2">Ymu2</code></td>
<td>
<p>Vector Q-1 Vector of length nObsGrid containing the mean function estimate (X)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_usegam">useGAM</code></td>
<td>
<p>Indicator to use gam smoothing instead of local-linear smoothing (semi-parametric option) (default: FALSE)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_rmdiag">rmDiag</code></td>
<td>
<p>Indicator to remove the diagonal element when smoothing (default: FALSE)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_kern">kern</code></td>
<td>
<p>String specifying the kernel type (default: FALSE;  see ?FPCA for details)</p>
</td></tr>
<tr><td><code id="GetCrCovYX_+3A_bwroutine">bwRoutine</code></td>
<td>
<p>String specifying the routine used to find the optimal bandwidth 'grid-search', 'bobyqa', 'l-bfgs-b' (default: 'l-bfgs-b')
If the variables Ly1 and Ly2 are in matrix form the data are assumed dense
and only the raw cross-covariance is returned. One can obtain Ymu1 and Ymu2
from <code>FPCA</code> and <code>ConvertSupport</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>smoothedCC</code></td>
<td>
<p>The smoothed cross-covariance as a matrix (currently only 51 by 51)</p>
</td></tr>
<tr><td><code>rawCC</code></td>
<td>
<p>The raw cross-covariance as a list</p>
</td></tr>
<tr><td><code>bw</code></td>
<td>
<p>The bandwidth used for smoothing as a vector of length 2</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>The GCV score associated with the scalar used</p>
</td></tr>
<tr><td><code>smoothGrid</code></td>
<td>
<p>The grid over which the smoothed cross-covariance is evaluated</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Yang, Wenjing, Hans-Georg Müller, and Ulrich Stadtmüller. &quot;Functional singular component analysis.&quot; Journal of the Royal Statistical Society: Series B (Statistical Methodology) 73.3 (2011): 303-324</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Ly1= list( rep(2.1,7), rep(2.1,3),2.1 );
Lt1 = list(1:7,1:3, 1);
Ly2 = list( rep(1.1,7), rep(1.1,3),1.1); 
Lt2 = list(1:7,1:3, 1);
Ymu1 = rep(55,7);
Ymu2 = rep(1.1,7);
AA&lt;-GetCrCovYX(Ly1 = Ly1, Ly2= Ly2, Lt1=Lt1, Lt2=Lt2, Ymu1=Ymu1, Ymu2=Ymu2)
  
</code></pre>

<hr>
<h2 id='GetCrCovYZ'>Functional Cross Covariance between longitudinal variable Y and scalar variable Z</h2><span id='topic+GetCrCovYZ'></span>

<h3>Description</h3>

<p>Calculate the raw and the smoothed cross-covariance between functional
and scalar predictors using bandwidth bw or estimate that bw using GCV
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetCrCovYZ(
  bw = NULL,
  Z,
  Zmu = NULL,
  Ly,
  Lt = NULL,
  Ymu = NULL,
  support = NULL,
  kern = "gauss"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetCrCovYZ_+3A_bw">bw</code></td>
<td>
<p>Scalar bandwidth for smoothing the cross-covariance function (if NULL it will be automatically estimated)</p>
</td></tr>
<tr><td><code id="GetCrCovYZ_+3A_z">Z</code></td>
<td>
<p>Vector N-1 Vector of length N with the scalar function values</p>
</td></tr>
<tr><td><code id="GetCrCovYZ_+3A_zmu">Zmu</code></td>
<td>
<p>Scalar with the mean of Z (if NULL it will be automatically estimated)</p>
</td></tr>
<tr><td><code id="GetCrCovYZ_+3A_ly">Ly</code></td>
<td>
<p>List of N vectors with amplitude information</p>
</td></tr>
<tr><td><code id="GetCrCovYZ_+3A_lt">Lt</code></td>
<td>
<p>List of N vectors with timing information</p>
</td></tr>
<tr><td><code id="GetCrCovYZ_+3A_ymu">Ymu</code></td>
<td>
<p>Vector Q-1 Vector of length nObsGrid containing the mean function estimate</p>
</td></tr>
<tr><td><code id="GetCrCovYZ_+3A_support">support</code></td>
<td>
<p>Vector of unique and sorted values for the support of the smoothed cross-covariance function (if NULL it will be automatically estimated)</p>
</td></tr>
<tr><td><code id="GetCrCovYZ_+3A_kern">kern</code></td>
<td>
<p>Kernel type to be used. See ?FPCA for more details. (default: 'gauss')
If the variables Ly1 is in matrix form the data are assumed dense and only
the raw cross-covariance is returned. One can obtain Ymu1 
from <code>FPCA</code> and <code>ConvertSupport</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>smoothedCC</code></td>
<td>
<p>The smoothed cross-covariance as a vector</p>
</td></tr>
<tr><td><code>rawCC</code></td>
<td>
<p>The raw cross-covariance as a vector </p>
</td></tr>
<tr><td><code>bw</code></td>
<td>
<p>The bandwidth used for smoothing as a scalar</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>The GCV score associated with the scalar used</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Yang, Wenjing, Hans-Georg Müller, and Ulrich Stadtmüller. &quot;Functional singular component analysis.&quot; Journal of the Royal Statistical Society: Series B (Statistical Methodology) 73.3 (2011): 303-324</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Ly &lt;- list( runif(5),  c(1:3), c(2:4), c(4))
Lt &lt;- list( c(1:5), c(1:3), c(1:3), 4)
Z = rep(4,4) # Constant vector so the covariance has to be zero.
sccObj = GetCrCovYZ(bw=1, Z= Z, Ly=Ly, Lt=Lt, Ymu=rep(4,5))
</code></pre>

<hr>
<h2 id='GetMeanCI'>Bootstrap pointwise confidence intervals for the mean function for densely observed data.</h2><span id='topic+GetMeanCI'></span>

<h3>Description</h3>

<p>Note that bootstrap pointwise confidence intervals do not work for sparsely observed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetMeanCI(Ly, Lt, level = 0.95, R = 999, optns = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetMeanCI_+3A_ly">Ly</code></td>
<td>
<p>A list of n vectors containing the observed values for each individual. 
Missing values specified by <code>NA</code>s are supported for dense case <code>(dataType='dense')</code>.</p>
</td></tr>
<tr><td><code id="GetMeanCI_+3A_lt">Lt</code></td>
<td>
<p>A list of n vectors containing the observation time points for each 
individual corresponding to each element in <code>Ly</code>. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="GetMeanCI_+3A_level">level</code></td>
<td>
<p>A number taking values in [0,1] determing the confidence level. Default: 0.95.</p>
</td></tr>
<tr><td><code id="GetMeanCI_+3A_r">R</code></td>
<td>
<p>An integer holding the number of bootstrap replicates. Default: 999.</p>
</td></tr>
<tr><td><code id="GetMeanCI_+3A_optns">optns</code></td>
<td>
<p>A list of options; see <code><a href="#topic+FPCA">FPCA</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two elements: 
</p>
<table role = "presentation">
<tr><td><code>CI</code></td>
<td>
<p>A data frame holding three variables: <code>CIgrid</code> &mdash; the time grid where the CIs are evaluated; <code>lower</code> and <code>upper</code> &mdash; the lower and upper bounds of the CIs on <code>CIgrid</code>.</p>
</td></tr>
<tr><td><code>level</code></td>
<td>
<p>The confidence level of the CIs</p>
</td></tr></table>
<p>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 30
tgrid &lt;- seq(0,1,length.out=21)
phi1 &lt;- function(t) sqrt(2)*sin(2*pi*t)
phi2 &lt;- function(t) sqrt(2)*sin(4*pi*t)
Lt &lt;- rep(list(tgrid), n)
Ly &lt;- lapply(1:n, function(i){
 tgrid + rnorm(1,0,2) * phi1(tgrid) + rnorm(1,0,0.5) * phi2(tgrid) + rnorm(1,0,0.01)
 })
res &lt;- GetMeanCI(Lt = Lt, Ly = Ly, level = 0.9)
</code></pre>

<hr>
<h2 id='GetMeanCurve'>Mean Curve</h2><span id='topic+GetMeanCurve'></span>

<h3>Description</h3>

<p>Mean curve calculation for dense or sparse functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetMeanCurve(Ly, Lt, optns = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetMeanCurve_+3A_ly">Ly</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='Dense'</code>).</p>
</td></tr>
<tr><td><code id="GetMeanCurve_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="GetMeanCurve_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;.
</p>
<p>Available control options are 
</p>

<dl>
<dt>userBwMu</dt><dd><p>The bandwidth value for the smoothed mean function (using 'CV' or 'GCV'); positive numeric - default: determine automatically based on 'methodBwMu'</p>
</dd>
<dt>methodBwMu</dt><dd><p>The bandwidth choice method for the mean function; 'GMeanAndGCV' (the geometric mean of the GCV bandwidth and the minimum bandwidth),'CV','GCV' - default: 5% of the support</p>
</dd> 
<dt>dataType</dt><dd><p>The type of design we have (usually distinguishing between sparse or dense functional data); 'Sparse', 'Dense', 'DenseWithMV', 'p&gt;&gt;n' - default:  determine automatically based on 'IsRegular'</p>
</dd>
<dt>plot</dt><dd><p>Plot mean curve; logical - default: FALSE</p>
</dd>
<dt>kernel</dt><dd><p>Smoothing kernel choice, common for mu and covariance; &quot;rect&quot;, &quot;gauss&quot;, &quot;epan&quot;, &quot;gausvar&quot;, &quot;quar&quot; - default: &quot;gauss&quot;; dense data are assumed noise-less so no smoothing is performed. </p>
</dd>
<dt>kFoldMuCov</dt><dd><p>The number of folds to be used for mean and covariance smoothing. Default: 10</p>
</dd>
<dt>methodMuCovEst</dt><dd><p>The method to estimate the mean and covariance in the case of dense functional data; 'cross-sectional', 'smooth' - default: 'cross-sectional'</p>
</dd>
<dt>numBins</dt><dd><p>The number of bins to bin the data into; positive integer &gt; 10, default: NULL</p>
</dd>
<dt>useBinnedData</dt><dd><p>Should the data be binned? 'FORCE' (Enforce the # of bins), 'AUTO' (Select the # of  bins automatically), 'OFF' (Do not bin) - default: 'AUTO'</p>
</dd>
<dt>userMu</dt><dd><p>The user-defined smoothed mean function; list of two numerical vector 't' and 'mu' of equal size, 't' must cover the support defined 'Ly' - default: NULL</p>
</dd>
<dt>useBW1SE</dt><dd><p>Pick the largest bandwidth such that CV-error is within one Standard Error from the minimum CV-error, relevant only if methodBwMu ='CV' and/or methodBwCov ='CV'; logical - default: FALSE</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p>A vector of length nWorkGrid containing the mean function estimate.</p>
</td></tr>
<tr><td><code>workGrid</code></td>
<td>
<p>A vector of length nWorkGrid. The internal regular grid on which the mean estimation is carried out.</p>
</td></tr>
<tr><td><code>bwMu</code></td>
<td>
<p>The selected (or user specified) bandwidth for smoothing the mean function.</p>
</td></tr>
<tr><td><code>optns</code></td>
<td>
<p>A list of actually-used options relevant to the mean function calculation.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.025)
sampWiener &lt;- Wiener(n, pts)
mu = sin(2*pi*pts)
sampWiener &lt;- Sparsify(t(t(sampWiener) + mu), pts, 10)
res = GetMeanCurve(Ly = sampWiener$Ly, Lt = sampWiener$Lt, optns = list(plot = TRUE))
</code></pre>

<hr>
<h2 id='GetNormalisedSample'>Normalise sparse multivariate functional data</h2><span id='topic+GetNormalisedSample'></span><span id='topic+GetNormalizedSample'></span>

<h3>Description</h3>

<p>Normalise sparse functional sample given in an FPCA object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetNormalisedSample(fpcaObj, errorSigma = FALSE)

GetNormalizedSample(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetNormalisedSample_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>An FPCA object.</p>
</td></tr>
<tr><td><code id="GetNormalisedSample_+3A_errorsigma">errorSigma</code></td>
<td>
<p>Indicator to use sigma^2 error variance when normalising the data (default: FALSE)</p>
</td></tr>
<tr><td><code id="GetNormalisedSample_+3A_...">...</code></td>
<td>
<p>Passed into GetNormalisedSample</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the normalised sample 'y' at times 't'
</p>


<h3>References</h3>

<p><cite>Chiou, Jeng-Min and Chen, Yu-Ting and Yang, Ya-Fang. &quot;Multivariate Functional Principal Component Analysis: A Normalization Approach&quot; Statistica Sinica 24 (2014): 1571-1596</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 100
M &lt;- 51
pts &lt;- seq(0, 1, length.out=M)
mu &lt;- rep(0, length(pts))
sampDense &lt;- MakeGPFunctionalData(n, M, mu, K=1, basisType='sin', sigma=0.01)
samp4 &lt;- MakeFPCAInputs(tVec=sampDense$pts, yVec=sampDense$Yn)
res4E &lt;- FPCA(samp4$Ly, samp4$Lt, list(error=TRUE))
sampN &lt;- GetNormalisedSample(res4E, errorSigma=TRUE)

CreatePathPlot(subset=1:20, inputData=samp4, obsOnly=TRUE, showObs=FALSE)
CreatePathPlot(subset=1:20, inputData=sampN, obsOnly=TRUE, showObs=FALSE)
</code></pre>

<hr>
<h2 id='kCFC'>Functional clustering and identifying substructures of longitudinal data using kCFC.</h2><span id='topic+kCFC'></span>

<h3>Description</h3>

<p>Functional clustering and identifying substructures of longitudinal data using kCFC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kCFC(
  y,
  t,
  k = 3,
  kSeed = 123,
  maxIter = 125,
  optnsSW = list(methodMuCovEst = "smooth", FVEthreshold = 0.9, methodBwCov = "GCV",
    methodBwMu = "GCV"),
  optnsCS = list(methodMuCovEst = "smooth", FVEthreshold = 0.7, methodBwCov = "GCV",
    methodBwMu = "GCV")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kCFC_+3A_y">y</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual. Missing values specified by <code>NA</code>s are supported for dense case (<code>dataType='dense'</code>).</p>
</td></tr>
<tr><td><code id="kCFC_+3A_t">t</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y.</p>
</td></tr>
<tr><td><code id="kCFC_+3A_k">k</code></td>
<td>
<p>A scalar defining the number of clusters to define; default 3. Values that define very small clusters (eg.cluster size &lt;=3) will potentially err.</p>
</td></tr>
<tr><td><code id="kCFC_+3A_kseed">kSeed</code></td>
<td>
<p>A scalar valid seed number to ensure replication; default: 123</p>
</td></tr>
<tr><td><code id="kCFC_+3A_maxiter">maxIter</code></td>
<td>
<p>A scalar defining the maximum number of iterations allowed; default 20, common for both the simple kmeans initially and the subsequent k-centres</p>
</td></tr>
<tr><td><code id="kCFC_+3A_optnssw">optnsSW</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> to be used for sample-wide FPCA; by default: &quot;list( methodMuCovEst ='smooth', FVEthreshold= 0.90, methodBwCov = 'GCV', methodBwMu = 'GCV' )&quot;. See &lsquo;Details in ?FPCA&rsquo;.</p>
</td></tr>
<tr><td><code id="kCFC_+3A_optnscs">optnsCS</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code> to be used for cluster-specific FPCA; by default:  &quot;list( methodMuCovEst ='smooth', FVEthreshold= 0.70, methodBwCov = 'GCV', methodBwMu = 'GCV' )&quot;. See &lsquo;Details in ?FPCA&rsquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>cluster</code></td>
<td>
<p>A vector of levels 1:k, indicating the cluster to which each curve is allocated.</p>
</td></tr> 
<tr><td><code>fpcaList</code></td>
<td>
<p>A list with the fpcaObj for each separate cluster.</p>
</td></tr> 
<tr><td><code>iterToConv</code></td>
<td>
<p>A number indicating how many iterations where required until convergence.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Jeng-Min Chiou, Pai-Ling Li, &quot;Functional clustering and identifying substructures of longitudinal data.&quot; Journal of the Royal Statistical Society 69 (2007): 679-699</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(medfly25) 
Flies &lt;- MakeFPCAInputs(medfly25$ID, medfly25$Days, medfly25$nEggs)
kcfcObj &lt;- kCFC(Flies$Ly[1:150], Flies$Lt[1:150], # using only 150 for speed consideration 
                 optnsSW = list(methodMuCovEst = 'smooth', userBwCov = 2, FVEthreshold = 0.90),
                 optnsCS = list(methodMuCovEst = 'smooth', userBwCov = 2, FVEthreshold = 0.70))

</code></pre>

<hr>
<h2 id='Lwls1D'>One dimensional local linear kernel smoother</h2><span id='topic+Lwls1D'></span>

<h3>Description</h3>

<p>One dimensional local linear kernel smoother for longitudinal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lwls1D(
  bw,
  kernel_type,
  win = rep(1L, length(xin)),
  xin,
  yin,
  xout,
  npoly = 1L,
  nder = 0L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lwls1D_+3A_bw">bw</code></td>
<td>
<p>Scalar holding the bandwidth</p>
</td></tr>
<tr><td><code id="Lwls1D_+3A_kernel_type">kernel_type</code></td>
<td>
<p>Character holding the kernel type (see ?FPCA for supported kernels)</p>
</td></tr>
<tr><td><code id="Lwls1D_+3A_win">win</code></td>
<td>
<p>Vector of length N with weights</p>
</td></tr>
<tr><td><code id="Lwls1D_+3A_xin">xin</code></td>
<td>
<p>Vector of length N with measurement points</p>
</td></tr>
<tr><td><code id="Lwls1D_+3A_yin">yin</code></td>
<td>
<p>Vector of length N with measurement values</p>
</td></tr>
<tr><td><code id="Lwls1D_+3A_xout">xout</code></td>
<td>
<p>Vector of length M with output measurement points</p>
</td></tr>
<tr><td><code id="Lwls1D_+3A_npoly">npoly</code></td>
<td>
<p>Scalar (integer) degree of polynomial fitted (default 1)</p>
</td></tr>
<tr><td><code id="Lwls1D_+3A_nder">nder</code></td>
<td>
<p>Scalar (integer) degree of derivative fitted (default 0)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of length M with measurement values at the the point specified by 'xout'
</p>

<hr>
<h2 id='Lwls2D'>Two dimensional local linear kernel smoother.</h2><span id='topic+Lwls2D'></span>

<h3>Description</h3>

<p>Two dimensional local weighted least squares smoother. Only local linear smoother for estimating the original curve is available (no higher order, no derivative).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lwls2D(
  bw,
  kern = "epan",
  xin,
  yin,
  win = NULL,
  xout1 = NULL,
  xout2 = NULL,
  xout = NULL,
  subset = NULL,
  crosscov = FALSE,
  method = ifelse(kern == "gauss", "plain", "sort2")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lwls2D_+3A_bw">bw</code></td>
<td>
<p>A scalar or a vector of length 2 specifying the bandwidth.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_kern">kern</code></td>
<td>
<p>Kernel used: 'gauss', 'rect', 'gausvar', 'epan' (default), 'quar'.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_xin">xin</code></td>
<td>
<p>An n by 2 data frame or matrix of x-coordinate.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_yin">yin</code></td>
<td>
<p>A vector of y-coordinate.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_win">win</code></td>
<td>
<p>A vector of weights on the observations.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_xout1">xout1</code></td>
<td>
<p>a p1-vector of first output coordinate grid. Defaults to the input gridpoints if left unspecified.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_xout2">xout2</code></td>
<td>
<p>a p2-vector of second output coordinate grid. Defaults to the input gridpoints if left unspecified.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_xout">xout</code></td>
<td>
<p>alternative to xout1 and xout2. A matrix of p by 2 specifying the output points (may be inefficient if the size of <code>xout</code> is small).</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_subset">subset</code></td>
<td>
<p>a vector with the indices of x-/y-/w-in to be used (Default: NULL)</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_crosscov">crosscov</code></td>
<td>
<p>using function for cross-covariance estimation (Default: FALSE). FALSE for auto-covariance estimation and 
TRUE for two-dimensional local linear kernel smoothing or cross-covariance estimation. 
For auto-covariance estimation (i.e., when <code>crosscov</code> is FALSE), <code>xout1</code> and <code>xout2</code> should be the same.</p>
</td></tr>
<tr><td><code id="Lwls2D_+3A_method">method</code></td>
<td>
<p>should one try to sort the values xin and yin before using the lwls smoother? if yes ('sort2' - default for non-Gaussian kernels), if no ('plain' - fully stable; de)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a p1 by p2 matrix of fitted values if xout is not specified. Otherwise a vector of length p corresponding to the rows of xout.
</p>

<hr>
<h2 id='Lwls2DDeriv'>Two dimensional local linear kernel smoother to target derivatives.</h2><span id='topic+Lwls2DDeriv'></span>

<h3>Description</h3>

<p>Two dimensional local weighted least squares smoother. Only a local linear smoother for estimating the original curve is available (no higher order)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lwls2DDeriv(
  bw,
  kern = "epan",
  xin,
  yin,
  win = NULL,
  xout1 = NULL,
  xout2 = NULL,
  xout = NULL,
  npoly = 1L,
  nder1 = 0L,
  nder2 = 0L,
  subset = NULL,
  crosscov = TRUE,
  method = "sort2"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lwls2DDeriv_+3A_bw">bw</code></td>
<td>
<p>A scalar or a vector of length 2 specifying the bandwidth.</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_kern">kern</code></td>
<td>
<p>Kernel used: 'gauss', 'rect', 'gausvar', 'epan' (default), 'quar'.</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_xin">xin</code></td>
<td>
<p>An n by 2 data frame or matrix of x-coordinate.</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_yin">yin</code></td>
<td>
<p>A vector of y-coordinate.</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_win">win</code></td>
<td>
<p>A vector of weights on the observations.</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_xout1">xout1</code></td>
<td>
<p>a p1-vector of first output coordinate grid. Defaults to the input gridpoints if left unspecified.</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_xout2">xout2</code></td>
<td>
<p>a p2-vector of second output coordinate grid. Defaults to the input gridpoints if left unspecified.</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_xout">xout</code></td>
<td>
<p>alternative to xout1 and xout2. A matrix of p by 2 specifying the output points (may be inefficient if the size of <code>xout</code> is small).</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_npoly">npoly</code></td>
<td>
<p>The degree of polynomials (include all <code class="reqn">x^a y^b</code> terms where <code class="reqn">a + b &lt;= npoly</code>)</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_nder1">nder1</code></td>
<td>
<p>Order of derivative in the first direction</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_nder2">nder2</code></td>
<td>
<p>Order of derivative in the second direction</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_subset">subset</code></td>
<td>
<p>a vector with the indices of x-/y-/w-in to be used (Default: NULL)</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_crosscov">crosscov</code></td>
<td>
<p>using function for cross-covariance estimation (Default: TRUE)</p>
</td></tr>
<tr><td><code id="Lwls2DDeriv_+3A_method">method</code></td>
<td>
<p>should one try to sort the values xin and yin before using the lwls smoother? if yes ('sort2' - default for non-Gaussian kernels), if no ('plain' - fully stable; de)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a p1 by p2 matrix of fitted values if xout is not specified. Otherwise a vector of length p corresponding to the rows of xout.
</p>

<hr>
<h2 id='MakeBWtoZscore02y'>Z-score body-weight for age 0 to 24 months based on WHO standards</h2><span id='topic+MakeBWtoZscore02y'></span>

<h3>Description</h3>

<p>Make vector of age and body-weight to z-scores based on WHO standards using LMS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MakeBWtoZscore02y(sex, age, bw)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MakeBWtoZscore02y_+3A_sex">sex</code></td>
<td>
<p>A character 'M' or 'F' indicating the sex of the child.</p>
</td></tr>
<tr><td><code id="MakeBWtoZscore02y_+3A_age">age</code></td>
<td>
<p>A vector of time points of size Q.</p>
</td></tr>
<tr><td><code id="MakeBWtoZscore02y_+3A_bw">bw</code></td>
<td>
<p>A vector of body-weight readings of size Q.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of Z-scores of size Q.
</p>

<hr>
<h2 id='MakeFPCAInputs'>Format FPCA input</h2><span id='topic+MakeFPCAInputs'></span>

<h3>Description</h3>

<p>Turn vector inputs to the list so they can be used in FPCA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MakeFPCAInputs(
  IDs = NULL,
  tVec,
  yVec,
  na.rm = FALSE,
  sort = FALSE,
  deduplicate = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MakeFPCAInputs_+3A_ids">IDs</code></td>
<td>
<p>np-by-1 vector of subject IDs (Default: NULL)</p>
</td></tr>
<tr><td><code id="MakeFPCAInputs_+3A_tvec">tVec</code></td>
<td>
<p>Either an np-by-1 vector of measurement times, or a p-by-1 vector corresponding to the common time support</p>
</td></tr>
<tr><td><code id="MakeFPCAInputs_+3A_yvec">yVec</code></td>
<td>
<p>n-by-1 vector of measurements from the variable of interest, or a n-by-p matrix with each row corresponding to the dense observations.</p>
</td></tr>
<tr><td><code id="MakeFPCAInputs_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating if NA should be omitted (Default: FALSE)</p>
</td></tr>
<tr><td><code id="MakeFPCAInputs_+3A_sort">sort</code></td>
<td>
<p>logical indicating if Lt (and the correspoding Ly values) should be ensured to be sorted (Default: FALSE)</p>
</td></tr>
<tr><td><code id="MakeFPCAInputs_+3A_deduplicate">deduplicate</code></td>
<td>
<p>logical indicating if the Lt should be ensured not to have within-subject duplicated values; the Ly values of repeated Lt values are averaged (Default: FALSE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>L list containing 3 lists each of length 'm', 'm' being the number of unique subject IDs
</p>

<hr>
<h2 id='MakeGPFunctionalData'>Create a Dense Functional Data sample for a Gaussian process</h2><span id='topic+MakeGPFunctionalData'></span>

<h3>Description</h3>

<p>For a Gaussian process, create a dense functional data sample of size n over a [0,1] support.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MakeGPFunctionalData(
  n,
  M = 100,
  mu = rep(0, M),
  K = 2,
  lambda = rep(1, K),
  sigma = 0,
  basisType = "cos"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MakeGPFunctionalData_+3A_n">n</code></td>
<td>
<p>number of samples to generate</p>
</td></tr>
<tr><td><code id="MakeGPFunctionalData_+3A_m">M</code></td>
<td>
<p>number of equidistant readings per sample (default: 100)</p>
</td></tr>
<tr><td><code id="MakeGPFunctionalData_+3A_mu">mu</code></td>
<td>
<p>vector of size M specifying the mean (default: rep(0,M))</p>
</td></tr>
<tr><td><code id="MakeGPFunctionalData_+3A_k">K</code></td>
<td>
<p>scalar specifying the number of basis to be used (default: 2)</p>
</td></tr>
<tr><td><code id="MakeGPFunctionalData_+3A_lambda">lambda</code></td>
<td>
<p>vector of size K specifying the variance of each components (default: rep(1,K))</p>
</td></tr>
<tr><td><code id="MakeGPFunctionalData_+3A_sigma">sigma</code></td>
<td>
<p>The standard deviation of the Gaussian noise added to each observation points.</p>
</td></tr>
<tr><td><code id="MakeGPFunctionalData_+3A_basistype">basisType</code></td>
<td>
<p>string specifying the basis type used; possible options are: 'sin', 'cos' and 'fourier' (default: 'cos') (See code of 'CreateBasis' for implementation details.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>Y</code></td>
<td>
<p>A vector of noiseless observations.</p>
</td></tr>
<tr><td><code>Yn</code></td>
<td>
<p>A vector of noisy observations if <code>sigma</code> &gt; 0.</p>
</td></tr>
</table>

<hr>
<h2 id='MakeHCtoZscore02y'>Z-score head-circumference for age 0 to 24 months based on WHO standards</h2><span id='topic+MakeHCtoZscore02y'></span>

<h3>Description</h3>

<p>Convert vector of age and height measurement to z-scores based on WHO standards using mu and sigma (not LMS)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MakeHCtoZscore02y(sex, age, hc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MakeHCtoZscore02y_+3A_sex">sex</code></td>
<td>
<p>A character 'M' or 'F' indicating the sex of the child.</p>
</td></tr>
<tr><td><code id="MakeHCtoZscore02y_+3A_age">age</code></td>
<td>
<p>A vector of time points of size Q.</p>
</td></tr>
<tr><td><code id="MakeHCtoZscore02y_+3A_hc">hc</code></td>
<td>
<p>A vector of head circumference readings of size Q (in cm).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of Z-scores of size Q.
</p>

<hr>
<h2 id='MakeLNtoZscore02y'>Z-score height for age 0 to 24 months based on WHO standards</h2><span id='topic+MakeLNtoZscore02y'></span>

<h3>Description</h3>

<p>Convert vector of age and height measurement to z-scores based on WHO standards using mu and sigma (not LMS)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MakeLNtoZscore02y(sex, age, ln)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MakeLNtoZscore02y_+3A_sex">sex</code></td>
<td>
<p>A character 'M' or 'F' indicating the sex of the child.</p>
</td></tr>
<tr><td><code id="MakeLNtoZscore02y_+3A_age">age</code></td>
<td>
<p>A vector of time points of size Q.</p>
</td></tr>
<tr><td><code id="MakeLNtoZscore02y_+3A_ln">ln</code></td>
<td>
<p>A vector of body-length readings of size Q (in cm).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of Z-scores of size Q.
</p>

<hr>
<h2 id='MakeSparseGP'>Create a sparse Functional Data sample for a Gaussian Process</h2><span id='topic+MakeSparseGP'></span>

<h3>Description</h3>

<p>Functional data sample of size n, sparsely sampled from a Gaussian process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MakeSparseGP(
  n,
  rdist = runif,
  sparsity = 2:9,
  muFun = function(x) rep(0, length(x)),
  K = 2,
  lambda = rep(1, K),
  sigma = 0,
  basisType = "cos",
  CovFun = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MakeSparseGP_+3A_n">n</code></td>
<td>
<p>number of samples to generate.</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_rdist">rdist</code></td>
<td>
<p>a sampler for generating the random design time points within [0, 1].</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_sparsity">sparsity</code></td>
<td>
<p>A vector of integers. The number of observation per sample is chosen to be one of the elements in sparsity with equal chance.</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_mufun">muFun</code></td>
<td>
<p>a function that takes a vector input and output a vector of the corresponding mean (default: zero function).</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_k">K</code></td>
<td>
<p>scalar specifying the number of basis to be used (default: 2).</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_lambda">lambda</code></td>
<td>
<p>vector of size K specifying the variance of each components (default: rep(1,K)).</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_sigma">sigma</code></td>
<td>
<p>The standard deviation of the Gaussian noise added to each observation points.</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_basistype">basisType</code></td>
<td>
<p>string specifying the basis type used; possible options are: 'sin', 'cos' and 'fourier' (default: 'cos') (See code of 'CreateBasis' for implementation details.)</p>
</td></tr>
<tr><td><code id="MakeSparseGP_+3A_covfun">CovFun</code></td>
<td>
<p>an alternative specification of the covariance structure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TODO
</p>

<hr>
<h2 id='medfly25'>Number of eggs laid daily from medflies</h2><span id='topic+medfly25'></span>

<h3>Description</h3>

<p>A dataset containing the eggs laid from 789 medflies (Mediterranean fruit flies,
Ceratitis capitata) during the first 25 days of their lives. This is a subset of 
the dataset used by Carey at al. (1998); only flies that lived at least 25 days 
are included, i.e, at the end of the recording period [0,25] all flies are still alive.
</p>


<h3>Format</h3>

<p>A data frame with 19725 rows and 3 variables:
</p>

<dl>
<dt>ID</dt><dd><p>: Medfly ID according to the original dataset</p>
</dd>
<dt>Days</dt><dd><p>: Day of measurement</p>
</dd>
<dt>nEggs</dt><dd><p>: Number of eggs laid at that particular day</p>
</dd> 
<dt>nEggsRemain</dt><dd><p>: Remaining total number of eggs laid</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://anson.ucdavis.edu/~mueller/data/medfly1000.html">https://anson.ucdavis.edu/~mueller/data/medfly1000.html</a>
</p>


<h3>References</h3>

<p>Carey, J.R., Liedo, P., Müller, H.G., Wang, J.L., Chiou, J.M. (1998). Relationship of age patterns of fecundity to mortality, longevity, and lifetime reproduction in a large cohort of Mediterranean fruit fly females. J. of Gerontology &ndash;Biological Sciences 53, 245-251. 
</p>

<hr>
<h2 id='MultiFAM'>Functional Additive Models with Multiple Predictor Processes</h2><span id='topic+MultiFAM'></span>

<h3>Description</h3>

<p>Smooth backfitting procedure for functional additive models with multiple predictor processes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultiFAM(
  Y,
  X,
  ker = "epan",
  nEval = 51,
  XTest = NULL,
  bwMethod = 0,
  alpha = 0.7,
  supp = c(-2, 2),
  optnsList = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MultiFAM_+3A_y">Y</code></td>
<td>
<p>An <em>n</em>-dimensional vector whose elements consist of scalar responses.</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_x">X</code></td>
<td>
<p>A <em>d</em>-dimensional list whose components consist of two lists of <em>Ly</em> and <em>Lt</em> containing observation times and functional covariate values for each predictor component, respectively. For details of <em>Ly</em> and <em>Lt</em>, see <code>FPCA</code> for detail.</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_ker">ker</code></td>
<td>
<p>A <code>function</code> object representing the base kernel to be used in the smooth backfitting algorithm (default is 'epan' which is the only option supported currently).</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_neval">nEval</code></td>
<td>
<p>The number of evaluation grid points for kernel smoothing (default is 51. If it is specified as 0, then estimated FPC scores in the training set are used for evaluation grid instead of equal grid).</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_xtest">XTest</code></td>
<td>
<p>A <em>d</em>-dimensional list for test set of functional predictors (default is NULL). If <code>XTest</code> is specified, then estimated FPC scores in the test set are used for evaluation grid.</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_bwmethod">bwMethod</code></td>
<td>
<p>The method of initial bandwidth selection for kernel smoothing, a positive value for designating K-fold cross-validtaion and zero for GCV (default is 0)</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_alpha">alpha</code></td>
<td>
<p>The shrinkage factor (positive number) for bandwidth selection. See Han et al. (2016) (default is 0.7).</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_supp">supp</code></td>
<td>
<p>The lower and upper limits of kernel smoothing domain for studentized FPC scores, which FPC scores are divided by the square roots of eigenvalues (default is [-2,2]).</p>
</td></tr>
<tr><td><code id="MultiFAM_+3A_optnslist">optnsList</code></td>
<td>
<p>A <em>d</em>-dimensional list whose components consist of <code>optns</code> for each predictor component, respectively. (default is NULL which assigns the same default <code>optns</code> for all components as in <code>FPCA</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MultiFAM</code> fits functional additive models for a scalar response and 
multiple predictor processes and implements  the smooth backfitting  algorithm provided in
Han, K., Müller, H.G., Park, B.U.  (2018). Smooth backfitting for additive modeling with small errors-in-variables, 
with an application to additive functional regression for multiple predictor functions. Bernoulli 24, 1233&ndash;1265.
</p>
<p>It is based on the model  </p>
<p style="text-align: center;"><code class="reqn">E(Y | \mathbf{X}) = \sum_{j=1}^d \sum_{k=1}^{K_j} g_{jk}(\xi_{jk}),</code>
</p>
<p> where <code class="reqn">\xi_{jk}</code> stand for the k-th FPC scores of the j-th predictor 
process. <code>MultiFAM</code> only is for the multiple predictor processes case.
For a univariate predictor use FAM, the functional additive model (Müller and Yao 2008). 
It is necessary to designate an estimation support for the additive component functions where the additive modeling is only allowed over 
restricted intervals  (see Han et al., 2018).
</p>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p>A scalar for the centered regression model.</p>
</td></tr>
<tr><td><code>SBFit</code></td>
<td>
<p>An <em>N</em> by <code class="reqn">(K_1 + ... + K_d)</code> matrix whose column vectors consist of the smooth backfitting component 
function estimators at the given <em>N</em> estimation points.</p>
</td></tr>
<tr><td><code>xi</code></td>
<td>
<p>An <em>N</em> by <code class="reqn">(K_1 + ... + K_d)</code> matrix whose column vectors consist of the FPC score grid vectors 
at which each additive component function is evaluated.</p>
</td></tr>
<tr><td><code>bw</code></td>
<td>
<p>A <code class="reqn">(K_1 + ... + K_d)</code>-dimensional bandwidth vector.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>A <code class="reqn">(K_1 + ... + K_d)</code>-dimensional vector containing eigenvalues.</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>A <em>d</em>-dimensional list whose components consist of an <em>nWorkGrid</em> by <em>K_j</em> matrix containing eigenfunctions, 
supported by <code>WorkGrid</code>. See <code>FPCA</code>.</p>
</td></tr>
<tr><td><code>workGrid</code></td>
<td>
<p>A <em>d</em>-dimensional list whose components consist of an <em>nWorkGrid</em> by <em>K_j</em> working grid, 
a regular grid on which the eigenanalysis is carried out See <code>FPCA</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Mammen, E., Linton, O. and Nielsen, J. (1999), &quot;The existence and asymptotic properties of a backfitting projection algorithm under weak conditions&quot;, Annals of Statistics, Vol.27, No.5, p.1443-1490.</cite>
</p>
<p><cite>Mammen, E. and Park, B. U. (2006), &quot;A simple smooth backfitting method for additive models&quot;, Annals of Statistics, Vol.34, No.5, p.2252-2271.</cite>
</p>
<p><cite>Müller, H.-G. and Yao, F. (2008), &quot;Functional additive models&quot;, Journal of the American Statistical Association, Vol.103, No.484, p.1534-1544.</cite>
</p>
<p><cite>Han, K., Müller, H.-G. and Park, B. U. (2016), &quot;Smooth backfitting for additive modeling with small errors-in-variables, with an application to additive functional regression for multiple predictor functions&quot;, Bernoulli (accepted).</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1000)

library(MASS)

f11 &lt;- function(t) t
f12 &lt;- function(t) 2*cos(2*pi*t/4)
f21 &lt;- function(t) 1.5*sin(2*pi*t/4)
f22 &lt;- function(t) 1.5*atan(2*pi*t/4)

n&lt;-100
N&lt;-200

sig &lt;- matrix(c(2.0, 0.0, 0.5, -.2,
                0.0, 1.2, -.2, 0.3,
                0.5, -.2, 1.7, 0.0,
                -.2, 0.3, 0.0, 1.0),
              nrow=4,ncol=4)

scoreX &lt;- mvrnorm(n,mu=rep(0,4),Sigma=sig)
scoreXTest &lt;- mvrnorm(N,mu=rep(0,4),Sigma=sig)

Y &lt;- f11(scoreX[,1]) + f12(scoreX[,2]) + f21(scoreX[,3]) + f22(scoreX[,4]) + rnorm(n,0,0.5)
YTest &lt;- f11(scoreXTest[,1]) + f12(scoreXTest[,2]) + 
f21(scoreXTest[,3]) + f22(scoreXTest[,4]) + rnorm(N,0,0.5)

phi11 &lt;- function(t) sqrt(2)*sin(2*pi*t)
phi12 &lt;- function(t) sqrt(2)*sin(4*pi*t)
phi21 &lt;- function(t) sqrt(2)*cos(2*pi*t)
phi22 &lt;- function(t) sqrt(2)*cos(4*pi*t)

grid &lt;- seq(0,1,length.out=21)
Lt &lt;- Lx1 &lt;- Lx2 &lt;- list()
for (i in 1:n) {
  Lt[[i]] &lt;- grid
  Lx1[[i]] &lt;- scoreX[i,1]*phi11(grid) + scoreX[i,2]*phi12(grid) + rnorm(1,0,0.01)
  Lx2[[i]] &lt;- scoreX[i,3]*phi21(grid) + scoreX[i,4]*phi22(grid) + rnorm(1,0,0.01)
}

LtTest &lt;- Lx1Test &lt;- Lx2Test &lt;- list()
for (i in 1:N) {
  LtTest[[i]] &lt;- grid
  Lx1Test[[i]] &lt;- scoreXTest[i,1]*phi11(grid) + scoreXTest[i,2]*phi12(grid) + rnorm(1,0,0.01)
  Lx2Test[[i]] &lt;- scoreXTest[i,3]*phi21(grid) + scoreXTest[i,4]*phi22(grid) + rnorm(1,0,0.01)
}

X1 &lt;- list(Ly=Lx1, Lt=Lt)
X2 &lt;- list(Ly=Lx2, Lt=Lt)

X1Test &lt;- list(Ly=Lx1Test, Lt=LtTest)
X2Test &lt;- list(Ly=Lx2Test, Lt=LtTest)

X &lt;- list(X1, X2)
XTest &lt;- list(X1Test, X2Test)

# estimation
sbf &lt;- MultiFAM(Y=Y,X=X)

xi &lt;- sbf$xi

par(mfrow=c(2,2))
j &lt;- 1
p0 &lt;- trapzRcpp(sort(xi[,j]),dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))
g11 &lt;- f11(sort(xi[,j])) - 
trapzRcpp(sort(xi[,j]),f11(sort(xi[,j]))*dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))/p0
tmpSgn &lt;- sign(sum(g11*sbf$SBFit[,j]))
plot(sort(xi[,j]),g11,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi11')
points(sort(xi[,j]),tmpSgn*sbf$SBFit[order(xi[,j]),j],type='l')
legend('top',c('true','SBF'),col=c(2,1),lwd=2,bty='n',horiz=TRUE)

j &lt;- 2
p0 &lt;- trapzRcpp(sort(xi[,j]),dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))
g12 &lt;- f12(sort(xi[,j])) - 
trapzRcpp(sort(xi[,j]),f12(sort(xi[,j]))*dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))/p0
tmpSgn &lt;- sign(sum(g12*sbf$SBFit[,j]))
plot(sort(xi[,j]),g12,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi12')
points(sort(xi[,j]),tmpSgn*sbf$SBFit[order(xi[,j]),j],type='l')
legend('top',c('true','SBF'),col=c(2,1),lwd=2,bty='n',horiz=TRUE)

j &lt;- 3
p0 &lt;- trapzRcpp(sort(xi[,j]),dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))
g21 &lt;- f21(sort(xi[,j])) - 
trapzRcpp(sort(xi[,j]),f21(sort(xi[,j]))*dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))/p0
tmpSgn &lt;- sign(sum(g21*sbf$SBFit[,j]))
plot(sort(xi[,j]),g21,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi21')
points(sort(xi[,j]),tmpSgn*sbf$SBFit[order(xi[,j]),j],type='l')
legend('top',c('true','SBF'),col=c(2,1),lwd=2,bty='n',horiz=TRUE)

j &lt;- 4
p0 &lt;- trapzRcpp(sort(xi[,j]),dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))
g22 &lt;- f22(sort(xi[,j])) - 
trapzRcpp(sort(xi[,j]),f22(sort(xi[,j]))*dnorm(sort(xi[,j]),0,sqrt(sig[j,j])))/p0
tmpSgn &lt;- sign(sum(g22*sbf$SBFit[,j]))
plot(sort(xi[,j]),g22,type='l',col=2,ylim=c(-2.5,2.5),xlab='xi22')
points(sort(xi[,j]),tmpSgn*sbf$SBFit[order(xi[,j]),j],type='l')
legend('top',c('true','SBF'),col=c(2,1),lwd=2,bty='n',horiz=TRUE)


# fitting
sbf &lt;- MultiFAM(Y=Y,X=X,nEval=0)
yHat &lt;- sbf$mu+apply(sbf$SBFit,1,'sum')
plot(yHat,Y)
abline(coef=c(0,1),col=2)


# R^2
R2 &lt;- 1-sum((Y-yHat)^2)/sum((Y-mean(Y))^2)
R2


# prediction
sbf &lt;- MultiFAM(Y=Y,X=X,XTest=XTest)
yHat &lt;- sbf$mu+apply(sbf$SBFit,1,'sum')
plot(yHat,YTest)
abline(coef=c(0,1),col=2)

</code></pre>

<hr>
<h2 id='NormCurvToArea'>Normalize a curve to a particular area, by multiplication with a factor</h2><span id='topic+NormCurvToArea'></span>

<h3>Description</h3>

<p>Normalize a curve such that its integration over the design time-points equals a particular value (according to trapezoid integration).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NormCurvToArea(y, x = seq(0, 1, length.out = length(y)), area = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NormCurvToArea_+3A_y">y</code></td>
<td>
<p>values of curve at time-points <code>x</code></p>
</td></tr>
<tr><td><code id="NormCurvToArea_+3A_x">x</code></td>
<td>
<p>design time-points (default: <code>seq(0,1, length.out=length(y))</code>)</p>
</td></tr>
<tr><td><code id="NormCurvToArea_+3A_area">area</code></td>
<td>
<p>value to normalize the curve onto (default: 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>values of curve at times <code>x</code> such that its integration over <code>x</code> equals <code>area</code>.
</p>

<hr>
<h2 id='predict.FPCA'>Predict FPC scores and curves for a new sample given an FPCA object</h2><span id='topic+predict.FPCA'></span>

<h3>Description</h3>

<p>Return a list containing the matrix with the first k FPC scores according to conditional expectation or numerical integration, the matrix of predicted trajectories and the prediction work grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FPCA'
predict(object, newLy, newLt, sigma2 = NULL, K = NULL, xiMethod = "CE", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.FPCA_+3A_object">object</code></td>
<td>
<p>An FPCA object.</p>
</td></tr>
<tr><td><code id="predict.FPCA_+3A_newly">newLy</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual.</p>
</td></tr>
<tr><td><code id="predict.FPCA_+3A_newlt">newLt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y.</p>
</td></tr>
<tr><td><code id="predict.FPCA_+3A_sigma2">sigma2</code></td>
<td>
<p>The user-defined measurement error variance. A positive scalar. (default: rho if applicable, otherwise sigma2 if applicable, otherwise 0 if no error. )</p>
</td></tr>
<tr><td><code id="predict.FPCA_+3A_k">K</code></td>
<td>
<p>The scalar defining the number of clusters to define; (default: from user-specified FPCA Object).</p>
</td></tr>
<tr><td><code id="predict.FPCA_+3A_ximethod">xiMethod</code></td>
<td>
<p>The integration method used to calculate the functional principal component scores 
(standard numerical integration 'IN' or conditional expectation 'CE'); default: 'CE'.</p>
</td></tr>
<tr><td><code id="predict.FPCA_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>scores</code></td>
<td>
<p>A matrix of size <em>n</em>-by-<em>k</em> which comprise of the predicted functional principal component scores.</p>
</td></tr>
<tr><td><code>predCurves</code></td>
<td>
<p>A matrix of size <em>n</em>-by-<em>l</em> where <em>l</em> is the length of the work grid in <em>object</em>.</p>
</td></tr>
<tr><td><code>predGrid</code></td>
<td>
<p>A vector of length <em>l</em> which is the output grid of the predicted curves. This is same is the workgrid of <em>object</em>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
n &lt;- 50
pts &lt;- seq(0, 1, by=0.05)
# The first n samples are for training and the rest testing
sampWiener &lt;- Wiener(2 * n, pts)
sparsity &lt;- 2:5
train &lt;- Sparsify(sampWiener[seq_len(n), , drop=FALSE], pts, sparsity)
test &lt;- Sparsify(sampWiener[seq(n + 1, 2 * n), , drop=FALSE], pts, sparsity)
res &lt;- FPCA(train$Ly, train$Lt)
pred &lt;- predict(res, test$Ly, test$Lt, K=3)
plot(pred$predGrid, pred$predCurves[1,])


</code></pre>

<hr>
<h2 id='print.FPCA'>Print an FPCA object</h2><span id='topic+print.FPCA'></span>

<h3>Description</h3>

<p>Print a simple description of an FPCA object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FPCA'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.FPCA_+3A_x">x</code></td>
<td>
<p>An FPCA object.</p>
</td></tr>
<tr><td><code id="print.FPCA_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
n &lt;- 20
pts &lt;- seq(0, 1, by=0.05)
sampWiener &lt;- Wiener(n, pts)
sampWiener &lt;- Sparsify(sampWiener, pts, 10)
res &lt;- FPCA(sampWiener$Ly, sampWiener$Lt)
res


</code></pre>

<hr>
<h2 id='print.FSVD'>Print an FSVD object</h2><span id='topic+print.FSVD'></span>

<h3>Description</h3>

<p>Print a simple description of an FSVD object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FSVD'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.FSVD_+3A_x">x</code></td>
<td>
<p>An FSVD object.</p>
</td></tr>
<tr><td><code id="print.FSVD_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='print.WFDA'>Print a WFDA object</h2><span id='topic+print.WFDA'></span>

<h3>Description</h3>

<p>Print a simple description of a WFDA object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'WFDA'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.WFDA_+3A_x">x</code></td>
<td>
<p>A WFDA object.</p>
</td></tr>
<tr><td><code id="print.WFDA_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='SBFitting'>Iterative Smooth Backfitting Algorithm</h2><span id='topic+SBFitting'></span>

<h3>Description</h3>

<p>Smooth backfitting procedure for nonparametric additive models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SBFitting(Y, x, X, h = NULL, K = "epan", supp = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SBFitting_+3A_y">Y</code></td>
<td>
<p>An <em>n</em>-dimensional vector whose elements consist of scalar responses.</p>
</td></tr>
<tr><td><code id="SBFitting_+3A_x">x</code></td>
<td>
<p>An <em>N</em> by <em>d</em> matrix whose column vectors consist of <em>N</em> vectors of estimation points for each component function.</p>
</td></tr>
<tr><td><code id="SBFitting_+3A_x">X</code></td>
<td>
<p>An <em>n</em> by <em>d</em> matrix whose row vectors consist of multivariate predictors.</p>
</td></tr>
<tr><td><code id="SBFitting_+3A_h">h</code></td>
<td>
<p>A <em>d</em> vector of bandwidths for kernel smoothing to estimate each component function.</p>
</td></tr>
<tr><td><code id="SBFitting_+3A_k">K</code></td>
<td>
<p>A <code>function</code> object representing the kernel to be used in the smooth backfitting (default is 'epan', the the Epanechnikov kernel.).</p>
</td></tr>
<tr><td><code id="SBFitting_+3A_supp">supp</code></td>
<td>
<p>A <em>d</em> by 2 matrix whose row vectors consist of the lower and upper limits of estimation intervals for each component function (default is the <em>d</em>-dimensional unit rectangle of <em>[0,1]</em>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SBFitting</code> fits component functions of additive models for a scalar response and a multivariate predictor based on the 
smooth backfitting algorithm proposed by Mammen et al. (1999), see also Mammen and Park (2006), Yu et al. (2008), Lee et al. (2010, 2012) and 
others. <code>SBFitting</code> only focuses on the locally constant smooth backfitting estimator for the multivariate predictor case. 
Note that the fitting in the special case of a univariate predictor is the same as that provided by a local constant kernel regression 
estimator (Nadaraya-Watson estimator). The local polynomial approach can be extended similarly (currently omitted). 
Support of the multivariate predictor is assumed to be a product of closed intervals. Users should designate an estimation support for the additive
component function where modeling is  restricted to subintervals of the domain  (see Han et al., 2016). If 
one puts <code>X</code> in the argument for the estimation points <code>x</code>, <code>SBFitting</code> returns the estimated values of 
the conditional mean responses given the observed predictors.
</p>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>SBFit</code></td>
<td>
<p>An <em>N</em> by <em>d</em> matrix whose column vectors consist of the smooth backfitting component function estimators at the given estimation points.</p>
</td></tr>
<tr><td><code>mY</code></td>
<td>
<p>A scalar of centered part of the regression model.</p>
</td></tr>
<tr><td><code>NW</code></td>
<td>
<p>An <em>N</em> by <em>d</em> matrix whose column vectors consist of the Nadaraya-Watson marginal regression function estimators for each predictor 
component at the given estimation points.</p>
</td></tr>
<tr><td><code>mgnDens</code></td>
<td>
<p>An <em>N</em> by <em>d</em> matrix whose column vectors consist of the marginal kernel density estimators for 
each predictor component at the given estimation points.</p>
</td></tr>
<tr><td><code>jntDens</code></td>
<td>
<p>An <em>N</em> by <em>N</em> by <em>d</em> by <em>d</em> array representing the 2-dimensional joint kernel 
density estimators for all pairs of predictor components at the given estimation grid. For example, <code>[,,j,k]</code> of 
the object provides the 2-dimensional joint kernel density estimator of the <code>(j,k)</code>-component of predictor components 
at the corresponding <em>N</em> by <em>N</em> matrix of estimation grid.</p>
</td></tr>
<tr><td><code>itemNum</code></td>
<td>
<p>The iteration number that the smooth backfitting algorithm has stopped.</p>
</td></tr>
<tr><td><code>itemErr</code></td>
<td>
<p>The iteration error of the smooth backfitting algorithm that represents the maximum L2 distance among component functions in the last successive updates.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Mammen, E., Linton, O. and Nielsen, J. (1999), &quot;The existence and asymptotic properties of a backfitting projection algorithm under weak conditions&quot;, Annals of Statistics, Vol.27, No.5, p.1443-1490.</cite>
</p>
<p><cite>Mammen, E. and Park, B. U. (2006), &quot;A simple smooth backfitting method for additive models&quot;, Annals of Statistics, Vol.34, No.5, p.2252-2271.</cite>
</p>
<p><cite>Yu, K., Park, B. U. and Mammen, E. (2008), &quot;Smooth backfitting in generalized additive models&quot;, Annals of Statistics, Vol.36, No.1, p.228-260.</cite>
</p>
<p><cite>Lee, Y. K., Mammen, E. and Park., B. U. (2010), &quot;backfitting and smooth backfitting for additive quantile models&quot;, Vol.38, No.5, p.2857-2883.</cite>
</p>
<p><cite>Lee, Y. K., Mammen, E. and Park., B. U. (2012), &quot;Flexible generalized varying coefficient regression models&quot;, Annals of Statistics, Vol.40, No.3, p.1906-1933.</cite>
</p>
<p><cite>Han, K., Müller, H.-G. and Park, B. U. (2016), &quot;Smooth backfitting for additive modeling with small errors-in-variables, with an application to additive functional regression for multiple predictor functions&quot;, Bernoulli (accepted).</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(100)

n &lt;- 100
d &lt;- 2
X &lt;- pnorm(matrix(rnorm(n*d),nrow=n,ncol=d)%*%matrix(c(1,0.6,0.6,1),nrow=2,ncol=2))

f1 &lt;- function(t) 2*(t-0.5)
f2 &lt;- function(t) sin(2*pi*t)

Y &lt;- f1(X[,1])+f2(X[,2])+rnorm(n,0,0.1)

# component function estimation
N &lt;- 101
x &lt;- matrix(rep(seq(0,1,length.out=N),d),nrow=N,ncol=d)
h &lt;- c(0.12,0.08)
  
sbfEst &lt;- SBFitting(Y,x,X,h)
fFit &lt;- sbfEst$SBFit

op &lt;- par(mfrow=c(1,2))
plot(x[,1],f1(x[,1]),type='l',lwd=2,col=2,lty=4,xlab='X1',ylab='Y')
points(x[,1],fFit[,1],type='l',lwd=2,col=1)
points(X[,1],Y,cex=0.3,col=8)
legend('topleft',legend=c('SBF','true'),col=c(1,2),lwd=2,lty=c(1,4),horiz=FALSE,bty='n')
abline(h=0,col=8)

plot(x[,2],f2(x[,2]),type='l',lwd=2,col=2,lty=4,xlab='X2',ylab='Y')
points(x[,2],fFit[,2],type='l',lwd=2,col=1)
points(X[,2],Y,cex=0.3,col=8)
legend('topright',legend=c('SBF','true'),col=c(1,2),lwd=2,lty=c(1,4),horiz=FALSE,bty='n')
abline(h=0,col=8)
par(op)

# prediction
x &lt;- X
h &lt;- c(0.12,0.08)
  
sbfPred &lt;- SBFitting(Y,X,X,h)
fPred &lt;- sbfPred$mY+apply(sbfPred$SBFit,1,'sum')

op &lt;- par(mfrow=c(1,1))
plot(fPred,Y,cex=0.5,xlab='SBFitted values',ylab='Y')
abline(coef=c(0,1),col=8)
par(op)
</code></pre>

<hr>
<h2 id='SelectK'>Selects number of functional principal components for
given FPCA output and selection criteria</h2><span id='topic+SelectK'></span>

<h3>Description</h3>

<p>Selects number of functional principal components for
given FPCA output and selection criteria
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectK(fpcaObj, criterion = "FVE", FVEthreshold = 0.95, Ly = NULL, Lt = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SelectK_+3A_fpcaobj">fpcaObj</code></td>
<td>
<p>A list containing FPCA related objects returned by MakeFPCAResults().</p>
</td></tr>
<tr><td><code id="SelectK_+3A_criterion">criterion</code></td>
<td>
<p>A string or positive integer specifying selection criterion for the number of functional principal components.
Available options: 'FVE', 'AIC', 'BIC', or the specified number of components - default: 'FVE'
For explanations of these criteria, see Yao et al (2005, JASA)</p>
</td></tr>
<tr><td><code id="SelectK_+3A_fvethreshold">FVEthreshold</code></td>
<td>
<p>A threshold fraction to be specified by the user when using &quot;FVE&quot; as selection criterion: (0,1] - default: NULL</p>
</td></tr>
<tr><td><code id="SelectK_+3A_ly">Ly</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual - default: NULL</p>
</td></tr>
<tr><td><code id="SelectK_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to Ly - default: NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following two fields:
</p>
<table role = "presentation">
<tr><td><code>K</code></td>
<td>
<p>An integer indicating the selected number of components based on given criterion.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>The calculated criterion value for the selected number of components, i.e. FVE, AIC or BIC value, NULL for fixedK criterion.</p>
</td></tr>
</table>

<hr>
<h2 id='SetOptions'>Set the PCA option list</h2><span id='topic+SetOptions'></span>

<h3>Description</h3>

<p>Set the PCA option list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SetOptions(y, t, optns)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SetOptions_+3A_y">y</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual.</p>
</td></tr>
<tr><td><code id="SetOptions_+3A_t">t</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y.</p>
</td></tr>
<tr><td><code id="SetOptions_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>. See &lsquo;Details&rsquo;.
</p>
<p>See '?FPCA for more details. Casual users are not advised to tamper with this function.</p>
</td></tr>
</table>

<hr>
<h2 id='Sparsify'>Sparsify densely observed functional data</h2><span id='topic+Sparsify'></span>

<h3>Description</h3>

<p>Given a matrix of densely observed functional data, create a sparsified sample for experimental purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sparsify(samp, pts, sparsity, aggressive = FALSE, fragment = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Sparsify_+3A_samp">samp</code></td>
<td>
<p>A matrix of densely observed functional data, with each row containing one sample.</p>
</td></tr>
<tr><td><code id="Sparsify_+3A_pts">pts</code></td>
<td>
<p>A vector of grid points corresponding to the columns of <code>samp</code>.</p>
</td></tr>
<tr><td><code id="Sparsify_+3A_sparsity">sparsity</code></td>
<td>
<p>A vector of integers. The number of observation per sample is chosen to be one of the elements in sparsity with equal chance.</p>
</td></tr>
<tr><td><code id="Sparsify_+3A_aggressive">aggressive</code></td>
<td>
<p>Sparsify in an &quot;aggressive&quot; manner making sure that near-by readings are excluded.</p>
</td></tr>
<tr><td><code id="Sparsify_+3A_fragment">fragment</code></td>
<td>
<p>Sparsify the observations into fragments, which are (almost) uniformly distributed in the time domain. Default to FALSE as not fragmenting. Otherwise a positive number specifying the approximate length of each fragment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of length 2, containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>Lt</code></td>
<td>
<p>A list of observation time points for each sample.</p>
</td></tr>
<tr><td><code>Ly</code></td>
<td>
<p>A list of values for each sample, corresponding to the time points.</p>
</td></tr>
</table>

<hr>
<h2 id='str.FPCA'>Compactly display the structure of an FPCA object</h2><span id='topic+str.FPCA'></span>

<h3>Description</h3>

<p>Compactly display the structure of an FPCA object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FPCA'
str(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="str.FPCA_+3A_object">object</code></td>
<td>
<p>An FPCA object</p>
</td></tr>
<tr><td><code id="str.FPCA_+3A_...">...</code></td>
<td>
<p>Not used</p>
</td></tr>
</table>

<hr>
<h2 id='Stringing'>Stringing for High-Dimensional data</h2><span id='topic+Stringing'></span>

<h3>Description</h3>

<p>Converting high-dimensional data to functional data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stringing(
  X,
  Y = NULL,
  standardize = FALSE,
  disOptns = "euclidean",
  disMat = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Stringing_+3A_x">X</code></td>
<td>
<p>A matrix (n by p) of data, where X[i,] is the row vector of measurements for the ith subject.</p>
</td></tr>
<tr><td><code id="Stringing_+3A_y">Y</code></td>
<td>
<p>A vector (n by 1), where Y[i] is the response associated with X[i,]</p>
</td></tr>
<tr><td><code id="Stringing_+3A_standardize">standardize</code></td>
<td>
<p>A logical variable indicating whether standardization of the input data matrix is required, with default: FALSE.</p>
</td></tr>
<tr><td><code id="Stringing_+3A_disoptns">disOptns</code></td>
<td>
<p>A distance metric to be used, one of the following: &quot;euclidean&quot; (default), &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot;, &quot;minkowski&quot;, &quot;correlation&quot;, &quot;spearman&quot;, &quot;hamming&quot;, &quot;xycor&quot;, or &quot;user&quot;. If specified as &quot;xycor&quot;, the absolute difference of correlation between predictor and response is used. If specified as &quot;user&quot;, a dissimilarity matrix for the argument <code>disMat</code> must be provided.</p>
</td></tr>
<tr><td><code id="Stringing_+3A_dismat">disMat</code></td>
<td>
<p>A user-specified dissimilarity matrix, only necessary when <code>disOptns</code> is &quot;user&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>Ly</code></td>
<td>
<p>A list of n vectors, which are the random trajectories for all subjects identified by the Stringing method.</p>
</td></tr>
<tr><td><code>Lt</code></td>
<td>
<p>A list of n time points vectors, at which corresponding measurements Ly are taken.</p>
</td></tr>
<tr><td><code>StringingOrder</code></td>
<td>
<p>A vector representing the order of the stringing, s.t. using as column index on <code>X</code> yields recovery of the underlying process.</p>
</td></tr>
<tr><td><code>Xin</code></td>
<td>
<p>A matrix, corresponding to the input data matrix.</p>
</td></tr>
<tr><td><code>Xstd</code></td>
<td>
<p>A matrix, corresponding to the standardized input data matrix. It is NULL if standardize is FALSE.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Chen, K., Chen, K., Müller, H. G., and Wang, J. L. (2011). &quot;Stringing high-dimensional data for functional analysis.&quot; Journal of the American Statistical Association, 106(493), 275-284.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 50
wiener = Wiener(n = n)[,-1]
p = ncol(wiener)
rdmorder = sample(size = p, x=1:p, replace = FALSE)
stringingfit = Stringing(X = wiener[,rdmorder], disOptns = "correlation")
diff_norev = sum(abs(rdmorder[stringingfit$StringingOrder] - 1:p))
diff_rev = sum(abs(rdmorder[stringingfit$StringedOrder] - p:1))
if(diff_rev &lt;= diff_norev){
  stringingfit$StringingOrder = rev(stringingfit$StringingOrder)
  stringingfit$Ly = lapply(stringingfit$Ly, rev)
}
plot(1:p, rdmorder[stringingfit$StringingOrder], pch=18); abline(a=0,b=1)

</code></pre>

<hr>
<h2 id='trapzRcpp'>Trapezoid Rule Numerical Integration</h2><span id='topic+trapzRcpp'></span>

<h3>Description</h3>

<p>Trapezoid Rule Numerical Integration using Rcpp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trapzRcpp(X, Y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trapzRcpp_+3A_x">X</code></td>
<td>
<p>Sorted vector of X values</p>
</td></tr>
<tr><td><code id="trapzRcpp_+3A_y">Y</code></td>
<td>
<p>Vector of Y values.</p>
</td></tr>
</table>

<hr>
<h2 id='TVAM'>Iterative Smooth Backfitting Algorithm</h2><span id='topic+TVAM'></span>

<h3>Description</h3>

<p>Smooth backfitting procedure for time-varying additive models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TVAM(
  Lt,
  Ly,
  LLx,
  gridT = NULL,
  x = NULL,
  ht = NULL,
  hx = NULL,
  K = "epan",
  suppT = NULL,
  suppX = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TVAM_+3A_lt">Lt</code></td>
<td>
<p>An <em>n</em>-dimensional list of <em>N_i</em>-dimensional vector whose elements consist of longitudinal time points for each <em>i</em>-th subject.</p>
</td></tr>
<tr><td><code id="TVAM_+3A_ly">Ly</code></td>
<td>
<p>An <em>n</em>-dimensional list of <em>N_i</em>-dimensional vector whose elements consist of longitudinal response observations of each <em>i</em>-subject corresponding to <em>Lt</em>.</p>
</td></tr>
<tr><td><code id="TVAM_+3A_llx">LLx</code></td>
<td>
<p>A tuple of <em>d</em>-lists, where each list represents longitudinal covariate observations of the <em>j</em>-th component corresponding to <em>Lt</em> and <em>Ly</em>.</p>
</td></tr>
<tr><td><code id="TVAM_+3A_gridt">gridT</code></td>
<td>
<p>An <em>M</em>-dimensional sequence of evaluation time points for additive surface estimators. (Must be sorted in increasing orders.)</p>
</td></tr>
<tr><td><code id="TVAM_+3A_x">x</code></td>
<td>
<p>An <em>N</em> by <em>d</em> matrix whose column vectors consist of <em>N</em> vectors of evaluation points for additive surface component estimators at each covariate value.</p>
</td></tr>
<tr><td><code id="TVAM_+3A_ht">ht</code></td>
<td>
<p>A bandwidth for kernel smoothing in time component.</p>
</td></tr>
<tr><td><code id="TVAM_+3A_hx">hx</code></td>
<td>
<p>A <em>d</em> vector of bandwidths for kernel smoothing covariate components, respectively.</p>
</td></tr>
<tr><td><code id="TVAM_+3A_k">K</code></td>
<td>
<p>A <code>function</code> object representing the kernel to be used in the smooth backfitting (default is 'epan', the the Epanechnikov kernel.).</p>
</td></tr>
<tr><td><code id="TVAM_+3A_suppt">suppT</code></td>
<td>
<p>A 2-dimensional vector consists of the lower and upper limits of estimation intervals for time component (default is <em>[0,1]</em>).</p>
</td></tr>
<tr><td><code id="TVAM_+3A_suppx">suppX</code></td>
<td>
<p>A <em>d</em> by 2 matrix whose row vectors consist of the lower and upper limits of estimation intervals for each component function (default is the <em>d</em>-dimensional unit rectangle of <em>[0,1]</em>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>TVAM</code> estimates component surfaces of time-varying additive models for longitudinal observations based on the smooth backfitting algorithm proposed by Zhang et al. (2013). <code>TVAM</code> only focuses on the local constant smooth backfitting in contrast to the original development as in Zhang et al. (2013). However, the local polynomial version can be extended similarly, so that those are omitted in the development. Especially in this development, one can designate an estimation support of additive surfaces when the additive modeling is only allowed over restricted intervals or one is interested in the modeling over the support (see Han et al., 2016).
</p>


<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>tvamComp</code></td>
<td>
<p>A tuple of <em>d</em>-lists, where each list is given by  <em>M</em> by <em>N</em> matrix whose elements represents the smooth backfitting surface estimator of the <em>j</em>-component evaluated at <code>gridT</code> and the <em>j</em>-th column of <code>x</code>.</p>
</td></tr>
<tr><td><code>tvamMean</code></td>
<td>
<p>An <em>M</em>-dimensional vector whose elements consist of the marginal time regression function estimated at <code>gridT</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Zhang, X., Park, B. U. and Wang, J.-L. (2013), &quot;Time-varying additive models for longitudinal data&quot;, Journal of the 
American Statistical Association, Vol.108, No.503, p.983-998.</cite>
</p>
<p><cite>Han, K., Müller, H.-G. and Park, B. U. (2018), &quot;Smooth backfitting for additive modeling with 
small errors-in-variables, with an application to additive functional regression for multiple predictor functions&quot;, Bernoulli, Vol.24, No.2, p.1233-1265.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1000)

n &lt;- 30
Lt &lt;- list()
Ly &lt;- list()
Lx1 &lt;- list()
Lx2 &lt;- list()

for (i in 1:n) {
  Ni &lt;- sample(10:15,1)
  
  Lt[[i]] &lt;- sort(runif(Ni,0,1))
  Lx1[[i]] &lt;- runif(Ni,0,1)
  Lx2[[i]] &lt;- runif(Ni,0,1)
  Ly[[i]] &lt;- Lt[[i]]*(cos(2*pi*Lx1[[i]]) + sin(2*pi*Lx2[[i]])) + rnorm(Ni,0,0.1)
  
}

LLx &lt;- list(Lx1,Lx2)

gridT &lt;- seq(0,1,length.out=31)
x0 &lt;- seq(0,1,length.out=31)
x &lt;- cbind(x0,x0)

ht &lt;- 0.1
hx &lt;- c(0.1,0.1)

tvam &lt;- TVAM(Lt,Ly,LLx,gridT=gridT,x=x,ht=ht,hx=hx,K='epan')

g0Sbf &lt;- tvam$tvamMean
gjSbf &lt;- tvam$tvamComp

op &lt;- par(mfrow=c(1,2), mar=c(1,1,1,1)+0.1)
persp(gridT,x0,gjSbf[[1]],theta=60,phi=30,
      xlab='time',ylab='x1',zlab='g1(t, x1)')
persp(gridT,x0,gjSbf[[2]],theta=60,phi=30,
      xlab='time',ylab='x2',zlab='g1(t, x2)')
par(op)

</code></pre>

<hr>
<h2 id='VCAM'>Sieve estimation:
B-spline based estimation procedure for time-varying additive models. The VCAM function can be used to perform function-to-scalar regression.</h2><span id='topic+VCAM'></span>

<h3>Description</h3>

<p>Sieve estimation:
B-spline based estimation procedure for time-varying additive models. The VCAM function can be used to perform function-to-scalar regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VCAM(Lt, Ly, X, optnAdd = list(), optnVc = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="VCAM_+3A_lt">Lt</code></td>
<td>
<p>An <em>n</em>-dimensional list of <em>N_i</em>-dimensional vectors whose elements consist of longitudinal time points for each <em>i</em>-th subject.</p>
</td></tr>
<tr><td><code id="VCAM_+3A_ly">Ly</code></td>
<td>
<p>An <em>n</em>-dimensional list of <em>N_i</em>-dimensional vectors whose elements consist of longitudinal response observations of each <em>i</em>-subject corresponding to <em>Lt</em>.</p>
</td></tr>
<tr><td><code id="VCAM_+3A_x">X</code></td>
<td>
<p>An <em>n</em> by <em>d</em> matrix whose row vectors consist of covariate vector of additive components for each subject.</p>
</td></tr>
<tr><td><code id="VCAM_+3A_optnadd">optnAdd</code></td>
<td>
<p>A list of options controls B-spline parameters for additive components, specified by list(name=value). See 'Details'.</p>
</td></tr>
<tr><td><code id="VCAM_+3A_optnvc">optnVc</code></td>
<td>
<p>A list of options controls B-spline parameters for varying-coefficient components, specified by list(name=value). See 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>VCAM</code> provides a simple algorithm based on B-spline basis to estimate its nonparametric additive and varying-coefficient components.
</p>
<p>Available control options for <em>optnAdd</em> are 
</p>

<dl>
<dt>nKnot</dt><dd><p>A <em>d</em>-dimensional vector which designates the number of knots for each additive component function estimation (default=10).</p>
</dd>
<dt>order</dt><dd><p>A <em>d</em>-dimensional vector which designates the order of B-spline basis for each additive component function estimation (default=3).</p>
</dd>
<dt>grid</dt><dd><p>A <em>N</em> by <em>d</em> matrix whose column vector consist of evaluation grid points for each component function estimation.</p>
</dd>
</dl>

<p>and control options for <em>optnVc</em> are 
</p>

<dl>
<dt>nKnot</dt><dd><p>A <em>(d+1)</em>-dimensional vector which designates the number of knots for overall mean function and each varying-coefficient component function estimation (default=10).</p>
</dd>
<dt>order</dt><dd><p>A <em>(d+1)</em>-dimensional vector which designates the order of B-spline basis for overall mean function and each varying-coefficient component function estimation (default=3).</p>
</dd>
<dt>grid</dt><dd><p>A <em>M</em> by <em>(d+1)</em> matrix whose column vectors consist of evaluation grid points for overall mean function and each varying-coefficient component function estimation.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>Lt</code></td>
<td>
<p>The same with input given by <em>Lt</em></p>
</td></tr>
<tr><td><code>LyHat</code></td>
<td>
<p>Fitted values corresponding to <em>Ly</em></p>
</td></tr>
<tr><td><code>phiEst</code></td>
<td>
<p>An <em>N</em> by <em>d</em> matrix whose column vectors consist of estimates for each additive component function evaluated at <em>gridX</em>.</p>
</td></tr>
<tr><td><code>beta0Est</code></td>
<td>
<p>An <em>M</em>-dimensional vector for overall mean function estimates evaluated at <em>gridT</em>.</p>
</td></tr>
<tr><td><code>betaEst</code></td>
<td>
<p>An <em>M</em> by <em>d</em> matrix whose column vectors consist of estimates for each varying-coefficient components evaluated at <em>gridT</em>.</p>
</td></tr>
<tr><td><code>gridX</code></td>
<td>
<p>The same with input given by <em>optnAdd$grid</em></p>
</td></tr>
<tr><td><code>gridT</code></td>
<td>
<p>The same with input  given by <em>optnVc$grid</em></p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Zhang, X. and Wang, J.-L. (2015), &quot;Varying-coefficient additive models for functional data&quot;, Biometrika, Vol.102, No.1, p.15-32.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MASS)

set.seed(100)

n &lt;- 100
d &lt;- 2

Lt &lt;- list()
Ly &lt;- list()

m &lt;- rep(0,2)
S &lt;- matrix(c(1,0.5,0.5,1),nrow=2,ncol=2)
X &lt;- pnorm(mvrnorm(n,m,S))

beta0 &lt;- function(t) 1.5*sin(3*pi*(t+0.5))
beta1 &lt;- function(t) 3*(1-t)^2
beta2 &lt;- function(t) 4*t^3

phi1 &lt;- function(x) sin(2*pi*x)
phi2 &lt;- function(x) 4*x^3-1

for (i in 1:n) {
  Ni &lt;- sample(10:20,1)
  
  Lt[[i]] &lt;- sort(runif(Ni,0,1))
  Ly[[i]] &lt;- beta0(Lt[[i]]) + 
     beta1(Lt[[i]])*phi1(X[i,1]) + beta2(Lt[[i]])*phi2(X[i,2]) + rnorm(Ni,0,0.1)
  
}


vcam &lt;- VCAM(Lt,Ly,X)

op &lt;- par(no.readonly = TRUE)

par(mfrow=c(1,1))
plot(unlist(vcam$LyHat),unlist(Ly),xlab='observed Y',ylab='fitted Y')
abline(coef=c(0,1),col=8)

par(mfrow=c(1,2))
plot(vcam$gridX[,1],vcam$phiEst[,1],type='l',ylim=c(-1,1),xlab='x1',ylab='phi1')
points(vcam$gridX[,1],phi1(vcam$gridX[,1]),col=2,type='l',lty=2,lwd=2)
legend('topright',c('true','est'),lwd=2,lty=c(1,2),col=c(1,2))

plot(vcam$gridX[,2],vcam$phiEst[,2],type='l',ylim=c(-1,3),xlab='x2',ylab='phi2')
points(vcam$gridX[,2],phi2(vcam$gridX[,2]),col=2,type='l',lty=2,lwd=2)
legend('topleft',c('true','est'),lwd=2,lty=c(1,2),col=c(1,2))

par(mfrow=c(1,3))
plot(vcam$gridT,vcam$beta0Est,type='l',xlab='t',ylab='beta0')
points(vcam$gridT,beta0(vcam$gridT),col=2,type='l',lty=2,lwd=2)
legend('topright',c('true','est'),lwd=2,lty=c(1,2),col=c(1,2))

plot(vcam$gridT,vcam$betaEst[,1],type='l',xlab='t',ylab='beta1')
points(vcam$gridT,beta1(vcam$gridT),col=2,type='l',lty=2,lwd=2)
legend('topright',c('true','est'),lwd=2,lty=c(1,2),col=c(1,2))

plot(vcam$gridT,vcam$betaEst[,2],type='l',xlab='t',ylab='beta2')
points(vcam$gridT,beta2(vcam$gridT),col=2,type='l',lty=2,lwd=2)
legend('topright',c('true','est'),lwd=2,lty=c(1,2),col=c(1,2))

par(op)

</code></pre>

<hr>
<h2 id='WFDA'>Time-Warping in Functional Data Analysis:
Pairwise curve synchronization for functional data</h2><span id='topic+WFDA'></span>

<h3>Description</h3>

<p>Time-Warping in Functional Data Analysis:
Pairwise curve synchronization for functional data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WFDA(Ly, Lt, optns = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WFDA_+3A_ly">Ly</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observed values for each individual.</p>
</td></tr>
<tr><td><code id="WFDA_+3A_lt">Lt</code></td>
<td>
<p>A list of <em>n</em> vectors containing the observation time points for each individual corresponding to y. Each vector should be sorted in ascending order.</p>
</td></tr>
<tr><td><code id="WFDA_+3A_optns">optns</code></td>
<td>
<p>A list of options control parameters specified by <code>list(name=value)</code>. See 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WFDA uses a pairwise warping method to obtain the desired alignment (registration) of the random trajectories. 
The data has to be regular. The routine returns the aligned curves and the associated warping function. 
</p>
<p>Available control options are 
</p>

<dl>
<dt>choice</dt><dd><p>Choice of estimating the warping functions ('weighted' or 'truncated'). If 'weighted' then weighted averages of pairwise warping functions are computed; the weighting is based on the inverse pairwise distances. If 'truncated' the pairs with the top 10% largest distances are truncated and the simple average of the remaining pairwise distances are used - default: 'truncated'</p>
</dd>
<dt>subsetProp</dt><dd><p>Pairwise warping functions are determined by using a subset of the whole sample; numeric (0,1] - default: 0.50</p>
</dd>
<dt>lambda</dt><dd><p>Penalty parameter used for estimating pairwise warping functions; numeric - default : V*10^-4, where V is the average L2 norm of y-mean(y).</p>
</dd>
<dt>nknots</dt><dd><p>Number of knots used for estimating the piece-wise linear pairwise warping functions; numeric - default: 2</p>
</dd> 
<dt>isPWL</dt><dd><p>Indicator if the resulting warping functions should piece-wise linear, if FALSE 'nknots' is ignored and the resulting warping functions are simply monotonic; logical - default: TRUE (significantly larger computation time.)</p>
</dd> 
<dt>seed</dt><dd><p>Random seed for the selection of the subset of warping functions; numeric - default: 666</p>
</dd>
<dt>verbose</dt><dd><p>Indicator if the progress of the pairwise warping procedure should be displayed; logical - default: FALSE</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list containing the following fields:
</p>
<table role = "presentation">
<tr><td><code>optns</code></td>
<td>
<p>Control options used.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Penalty parameter used.</p>
</td></tr>
<tr><td><code>aligned</code></td>
<td>
<p>Aligned curves evaluated at time 't'</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>Warping functions for 't'</p>
</td></tr> 
<tr><td><code>hInv</code></td>
<td>
<p>Inverse warping functions evaluated at 't'</p>
</td></tr> 
<tr><td><code>costs</code></td>
<td>
<p>The mean cost associated with each curve</p>
</td></tr> 
<tr><td><code>timing</code></td>
<td>
<p>The time required by time-warping.</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Tang, R. and Müller, H.G. (2008). &quot;Pairwise curve synchronization for functional data.&quot; Biometrika 95, 875-889</cite>
</p>
<p><cite>Tang, R. and Müller, H.G. (2009) &quot;Time-synchronized clustering of gene expression trajectories.&quot; Biostatistics 10, 32-45</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N = 44;
eps = 0.123;
M = 41;
set.seed(123) 
Tfinal = 3
me &lt;- function(t) exp(-Tfinal*(((t/Tfinal^2)-0.5))^2);
T = seq(0,Tfinal,length.out = M) 
recondingTimesMat = matrix(nrow = N, ncol = M)
yMat = matrix(nrow = N, ncol = M)

for (i in 1:N){
  peak = runif(min = 0.2,max =  0.8,1) * Tfinal 
  recondingTimesMat[i,] = sort( unique(c( seq(0.0 , peak, length.out = round((M+1)/2)),
                            seq( peak, Tfinal, length.out = round((M+1)/2))))) * Tfinal
  yMat[i,] = me(recondingTimesMat[i,]) * rnorm(1, mean=4.0, sd=  eps)
                                       + rnorm(M, mean=0.0, sd=  eps) 
}

Y = as.list(as.data.frame(t(yMat)))
X = rep(list(T),N)
 
sss =  WFDA(Ly = Y, Lt = X, list( choice = 'weighted' ))
op &lt;- par(mfrow=c(1,2))
matplot(x= T, t(yMat), t='l', main = 'Raw', ylab = 'Y'); grid()
matplot(x= T, t(sss$aligned), t='l', main = 'Aligned', ylab='Y'); grid() 
par(op)
</code></pre>

<hr>
<h2 id='Wiener'>Simulate a standard Wiener processes (Brownian motions)</h2><span id='topic+Wiener'></span>

<h3>Description</h3>

<p>Simulate <code>n</code> standard Wiener processes on [0, 1], possibly
sparsifying the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Wiener(n = 1, pts = seq(0, 1, length = 50), sparsify = NULL, K = 50)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Wiener_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="Wiener_+3A_pts">pts</code></td>
<td>
<p>A vector of points in [0, 1] specifying the support of the processes.</p>
</td></tr>
<tr><td><code id="Wiener_+3A_sparsify">sparsify</code></td>
<td>
<p>A vector of integers. The number of observations per curve will be uniform distribution on sparsify.</p>
</td></tr>
<tr><td><code id="Wiener_+3A_k">K</code></td>
<td>
<p>The number of components.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is based on the Karhunen-Loève expansion of the Wiener process
</p>


<h3>Value</h3>

<p>If <code>sparsify</code> is not specified, a matrix with <code>n</code> rows corresponding to the samples are returned. Otherwise the sparsified sample is returned.
</p>


<h3>See Also</h3>

<p>Sparsify
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
