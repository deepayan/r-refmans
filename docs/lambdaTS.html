<!DOCTYPE html><html><head><title>Help for package lambdaTS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lambdaTS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bitcoin_gold_oil'><p>bitcoin_gold_oil data set</p></a></li>
<li><a href='#lambdaTS'><p>lambdaTS: Variational Seq2Seq Lambda Transformer Model for Time Series Analysis</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variational Seq2Seq Model with Lambda Transformer for Time
Series Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Giancarlo Vercellino</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Giancarlo Vercellino &lt;giancarlo.vercellino@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Time series analysis based on lambda transformer and variational seq2seq, built on 'Torch'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>car, purrr, abind, ggplot2, readr, stringr, lubridate, narray,
fANCOVA, imputeTS, modeest, scales, tictoc, bizdays, torch</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-20 19:33:50 UTC; gvercellino</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-20 20:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bitcoin_gold_oil'>bitcoin_gold_oil data set</h2><span id='topic+bitcoin_gold_oil'></span>

<h3>Description</h3>

<p>A data frame with different time series (prices and volumes) for bitcoin, gold and oil.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bitcoin_gold_oil
</code></pre>


<h3>Format</h3>

<p>A data frame with 18 columns and 1827 rows.
</p>


<h3>Source</h3>

<p>Yahoo Finance
</p>

<hr>
<h2 id='lambdaTS'>lambdaTS: Variational Seq2Seq Lambda Transformer Model for Time Series Analysis</h2><span id='topic+lambdaTS'></span><span id='topic+lambdaTS-package'></span>

<h3>Description</h3>

<p>Time series analysis based on Lambda Transformer and Variational Seq2Seq, built on 'Torch'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambdaTS(
  data,
  target,
  future,
  past = future,
  ci = 0.8,
  deriv = 1,
  yjt = TRUE,
  shift = 0,
  smoother = FALSE,
  k_embed = 30,
  r_proj = ceiling(k_embed/3) + 1,
  n_heads = 1,
  n_bases = 1,
  activ = "linear",
  loss_metric = "elbo",
  optim = "adam",
  epochs = 30,
  lr = 0.01,
  patience = epochs,
  verbose = TRUE,
  sample_n = 100,
  seed = 42,
  dev = "cpu",
  starting_date = NULL,
  dbreak = NULL,
  days_off = NULL,
  min_set = future,
  holdout = 0.5,
  batch_size = 30
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambdaTS_+3A_data">data</code></td>
<td>
<p>A data frame with ts on columns and possibly a date column (not mandatory)</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_target">target</code></td>
<td>
<p>String. Time series names to be jointly analyzed within the seq2seq model</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_future">future</code></td>
<td>
<p>Positive integer. The future dimension with number of time-steps to be predicted</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_past">past</code></td>
<td>
<p>Positive integer. The past dimension with number of time-steps in the past used for the prediction. Default: future</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_ci">ci</code></td>
<td>
<p>Confidence interval. Default: 0.8</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_deriv">deriv</code></td>
<td>
<p>Positive integer. Number of differentiation operations to perform on the original series. 0 = no change; 1: one diff; 2: two diff, and so on.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_yjt">yjt</code></td>
<td>
<p>Logical. Performing Yeo-Johnson Transformation on data is always advisable, especially when dealing with different ts at different scales. Default: TRUE</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_shift">shift</code></td>
<td>
<p>Vector of positive integers. Allow for target variables to shift ahead of time. Zero means no shift. Length must be equal to the number of targets. Default: 0.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_smoother">smoother</code></td>
<td>
<p>Logical. Perform optimal smooting using standard loess. Default: FALSE</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_k_embed">k_embed</code></td>
<td>
<p>Positive integer. Number of Time2Vec embedding dimensions. Minimum value is 2. Default: 30</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_r_proj">r_proj</code></td>
<td>
<p>Positive integer. Number of dimensions for the reduction space (to reduce quadratic complexity). Must be largely less than k_embed size. Default: ceiling(k_embed/3) + 1</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_n_heads">n_heads</code></td>
<td>
<p>Positive integer. Number of heads for the attention mechanism. Computationally expensive, use with care. Default: 1</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_n_bases">n_bases</code></td>
<td>
<p>Positive integer. Number of normal curves to build on each parameter. Computationally expensive, use with care. Default: 1</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_activ">activ</code></td>
<td>
<p>String. The activation function for the linear transformation of the attention matrix into the future sequence. Implemented options are: &quot;linear&quot;, &quot;leaky_relu&quot;, &quot;celu&quot;, &quot;elu&quot;, &quot;gelu&quot;, &quot;selu&quot;, &quot;softplus&quot;, &quot;bent&quot;, &quot;snake&quot;, &quot;softmax&quot;, &quot;softmin&quot;, &quot;softsign&quot;, &quot;sigmoid&quot;, &quot;tanh&quot;, &quot;tanhshrink&quot;, &quot;swish&quot;, &quot;hardtanh&quot;, &quot;mish&quot;. Default: &quot;linear&quot;.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_loss_metric">loss_metric</code></td>
<td>
<p>String. Loss function for the variational model. Two options: &quot;elbo&quot; or &quot;crps&quot;. Default: &quot;crps&quot;.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_optim">optim</code></td>
<td>
<p>String. Optimization methods available are: &quot;adadelta&quot;, &quot;adagrad&quot;, &quot;rmsprop&quot;, &quot;rprop&quot;, &quot;sgd&quot;, &quot;asgd&quot;, &quot;adam&quot;. Default: &quot;adam&quot;.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_epochs">epochs</code></td>
<td>
<p>Positive integer. Default: 30.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_lr">lr</code></td>
<td>
<p>Positive numeric. Learning rate. Default: 0.01.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_patience">patience</code></td>
<td>
<p>Positive integer. Waiting time (in epochs) before evaluating the overfit performance. Default: epochs.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Default: TRUE</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_sample_n">sample_n</code></td>
<td>
<p>Positive integer. Number of samples from the variational model to evalute the mean forecast values. Computationally expensive, use with care. Default: 100.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_seed">seed</code></td>
<td>
<p>Random seed. Default: 42.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_dev">dev</code></td>
<td>
<p>String. Torch implementation of computational platform: &quot;cpu&quot; or &quot;cuda&quot; (gpu). Default: &quot;cpu&quot;.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_starting_date">starting_date</code></td>
<td>
<p>Date. Initial date to assign temporal values to the series. Default: NULL (progressive numbers).</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_dbreak">dbreak</code></td>
<td>
<p>String. Minimum time marker for x-axis, in liberal form: i.e., &quot;3 months&quot;, &quot;1 week&quot;, &quot;20 days&quot;. Default: NULL.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_days_off">days_off</code></td>
<td>
<p>String. Weekdays to exclude (i.e., c(&quot;saturday&quot;, &quot;sunday&quot;)). Default: NULL.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_min_set">min_set</code></td>
<td>
<p>Positive integer. Minimun number for validation set in case of automatic resize of past dimension. Default: future.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_holdout">holdout</code></td>
<td>
<p>Positive numeric. Percentage of time series for holdout validation. Default: 0.5.</p>
</td></tr>
<tr><td><code id="lambdaTS_+3A_batch_size">batch_size</code></td>
<td>
<p>Positive integer. Default: 30.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a list including:
</p>

<ul>
<li><p> prediction: a table with quantile predictions, mean and std for each ts
</p>
</li>
<li><p> history: plot of loss during the training process for the joint-transformed ts
</p>
</li>
<li><p> plot: graph with history and prediction for each ts
</p>
</li>
<li><p> learning_error: errors for the joint-ts in the transformed scale (rmse, mae, mdae, mpe, mape, smape, rrse, rae)
</p>
</li>
<li><p> feature_errors: errors for each ts in the original scale (rmse, mae, mdae, mpe, mape, smape, rrse, rae)
</p>
</li>
<li><p> pred_stats: for each predicted time feature, IQR to range, KL-divergence, risk ratio, upside probability, averaged across time-points and compared at the terminal points.
</p>
</li>
<li><p> time_log
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Giancarlo Vercellino <a href="mailto:giancarlo.vercellino@gmail.com">giancarlo.vercellino@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
lambdaTS(bitcoin_gold_oil, c("gold_close", "oil_Close"), 30, deriv = 1)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
