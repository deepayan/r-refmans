<!DOCTYPE html><html lang="en"><head><title>Help for package abn</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {abn}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abn-package'><p><code>abn</code> Package</p></a></li>
<li><a href='#.onAttach'><p>Prints start up message</p></a></li>
<li><a href='#abn.version'><p>abn Version Information</p></a></li>
<li><a href='#adg'><p>Dataset related to average daily growth performance and abattoir findings in pigs commercial production.</p></a></li>
<li><a href='#AIC.abnFit'><p>Print AIC of objects of class <code>abnFit</code></p></a></li>
<li><a href='#bern_bugs'><p>Bugs code for Bernoulli response</p></a></li>
<li><a href='#BIC.abnFit'><p>Print BIC of objects of class <code>abnFit</code></p></a></li>
<li><a href='#build.control'><p>Control the iterations in <code>buildScoreCache</code></p></a></li>
<li><a href='#buildScoreCache'><p>Build a cache of goodness of fit metrics for each node in a DAG, possibly subject to user-defined restrictions</p></a></li>
<li><a href='#calc.node.inla.glm'><p>Fit a given regression using INLA</p></a></li>
<li><a href='#calc.node.inla.glmm'><p>Fit a given regression using INLA</p></a></li>
<li><a href='#categorical_bugs'><p>Bugs code for Categorical response</p></a></li>
<li><a href='#Cfunctions'><p>Documentation of C Functions</p></a></li>
<li><a href='#check.valid.buildControls'><p>Simple check on the control parameters</p></a></li>
<li><a href='#check.valid.dag'><p>Set of simple commonsense validity checks on the directed acyclic graph definition matrix</p></a></li>
<li><a href='#check.valid.data'><p>Set of simple commonsense validity checks on the data.df and data.dists arguments</p></a></li>
<li><a href='#check.valid.fitControls'><p>Simple check on the control parameters</p></a></li>
<li><a href='#check.valid.groups'><p>Simple check on the grouping variable</p></a></li>
<li><a href='#check.valid.parents'><p>Set of simple checks on the given parent limits</p></a></li>
<li><a href='#check.which.valid.nodes'><p>Set of simple checks on the list given as parent limits</p></a></li>
<li><a href='#coef.abnFit'><p>Print coefficients of objects of class <code>abnFit</code></p></a></li>
<li><a href='#compareDag'><p>Compare two DAGs or EGs</p></a></li>
<li><a href='#compareEG'><p>Compare two DAGs or EGs</p></a></li>
<li><a href='#createAbnDag'><p>Make DAG of class &quot;abnDag&quot;</p></a></li>
<li><a href='#discretization'><p>Discretization of a Possibly Continuous Data Frame of Random Variables based on their distribution</p></a></li>
<li><a href='#entropyData'><p>Computes an Empirical Estimation of the Entropy from a Table of Counts</p></a></li>
<li><a href='#essentialGraph'><p>Construct the essential graph</p></a></li>
<li><a href='#eval.across.grid'><p>function to get marginal across an equal grid</p></a></li>
<li><a href='#ex0.dag.data'><p>Synthetic validation data set for use with abn library examples</p></a></li>
<li><a href='#ex1.dag.data'><p>Synthetic validation data set for use with abn library examples</p></a></li>
<li><a href='#ex2.dag.data'><p>Synthetic validation data set for use with abn library examples</p></a></li>
<li><a href='#ex3.dag.data'><p>Validation data set for use with abn library examples</p></a></li>
<li><a href='#ex4.dag.data'><p>Valdiation data set for use with abn library examples</p></a></li>
<li><a href='#ex5.dag.data'><p>Valdiation data set for use with abn library examples</p></a></li>
<li><a href='#ex6.dag.data'><p>Valdiation data set for use with abn library examples</p></a></li>
<li><a href='#ex7.dag.data'><p>Valdiation data set for use with abn library examples</p></a></li>
<li><a href='#expit'><p>expit of proportions</p></a></li>
<li><a href='#expit_cpp'><p>expit function</p></a></li>
<li><a href='#factorial'><p>Factorial</p></a></li>
<li><a href='#factorial_fast'><p>Fast Factorial</p></a></li>
<li><a href='#family.abnFit'><p>Print family of objects of class <code>abnFit</code></p></a></li>
<li><a href='#FCV'><p>Dataset related to Feline calicivirus infection among cats in Switzerland.</p></a></li>
<li><a href='#find.next.left.x'><p>Find next X evaluation Point</p></a></li>
<li><a href='#fit.control'><p>Control the iterations in <code>fitAbn</code></p></a></li>
<li><a href='#fitAbn'><p>Fit an additive Bayesian network model</p></a></li>
<li><a href='#forLoopContentFitBayes'><p>Regress each node on its parents.#'</p></a></li>
<li><a href='#formula_abn'><p>Formula to adjacency matrix</p></a></li>
<li><a href='#g2b2c_data'><p>Toy Data Set for Examples in README</p></a></li>
<li><a href='#g2pbcgrp'><p>Toy Data Set for Examples in README</p></a></li>
<li><a href='#gauss_bugs'><p>Bugs code for Gaussian response</p></a></li>
<li><a href='#get.quantiles'><p>function to extract quantiles from INLA output</p></a></li>
<li><a href='#get.var.types'><p>Create ordered vector with integers denoting the distribution</p></a></li>
<li><a href='#getmarginals'><p>Internal function called by <code>fitAbn.bayes</code>.</p></a></li>
<li><a href='#getMargsINLA'><p>function to extract marginals from INLA output</p></a></li>
<li><a href='#getModeVector'><p>function to extract the mode from INLA output</p></a></li>
<li><a href='#getMSEfromModes'><p>Extract Standard Deviations from all Gaussian Nodes</p></a></li>
<li><a href='#infoDag'><p>Compute standard information for a DAG.</p></a></li>
<li><a href='#irls_binomial_cpp'><p>Iterative Reweighed Least Square algorithm for Binomials</p></a></li>
<li><a href='#irls_binomial_cpp_br'><p>BR Iterative Reweighed Least Square algorithm for Binomials</p></a></li>
<li><a href='#irls_binomial_cpp_fast'><p>Fast Iterative Reweighed Least Square algorithm for Binomials</p></a></li>
<li><a href='#irls_binomial_cpp_fast_br'><p>Fast Br Iterative Reweighed Least Square algorithm for Binomials</p></a></li>
<li><a href='#irls_gaussian_cpp'><p>Iterative Reweighed Least Square algorithm for Gaussians</p></a></li>
<li><a href='#irls_gaussian_cpp_fast'><p>Fast Iterative Reweighed Least Square algorithm for Gaussians</p></a></li>
<li><a href='#irls_poisson_cpp'><p>Iterative Reweighed Least Square algorithm for Poissons</p></a></li>
<li><a href='#irls_poisson_cpp_fast'><p>Fast Iterative Reweighed Least Square algorithm for Poissons</p></a></li>
<li><a href='#linkStrength'><p>Returns the strengths of the edge connections in a Bayesian Network learned from observational data</p></a></li>
<li><a href='#logit'><p>Logit of proportions</p></a></li>
<li><a href='#logit_cpp'><p>logit functions</p></a></li>
<li><a href='#logLik.abnFit'><p>Print logLik of objects of class <code>abnFit</code></p></a></li>
<li><a href='#makebugs'><p>Make BUGS model from fitted DAG</p></a></li>
<li><a href='#makebugsGroup'><p>Make BUGS model from fitted DAG with grouping</p></a></li>
<li><a href='#mb'><p>Compute the Markov blanket</p></a></li>
<li><a href='#mi_cpp'><p>Mutual Information</p></a></li>
<li><a href='#miData'><p>Empirical Estimation of the Entropy from a Table of Counts</p></a></li>
<li><a href='#modes2coefs'><p>Convert modes to fitAbn.mle$coefs structure</p></a></li>
<li><a href='#mostProbable'><p>Find most probable DAG structure</p></a></li>
<li><a href='#nobs.abnFit'><p>Print number of observations of objects of class <code>abnFit</code></p></a></li>
<li><a href='#odds'><p>Probability to odds</p></a></li>
<li><a href='#or'><p>Odds Ratio from a matrix</p></a></li>
<li><a href='#pigs.vienna'><p>Dataset related to diseases present in &lsquo;finishing pigs&rsquo;, animals about to enter the human food chain at an abattoir.</p></a></li>
<li><a href='#plot.abnDag'><p>Plots DAG from an object of class <code>abnDag</code></p></a></li>
<li><a href='#plot.abnFit'><p>Plot objects of class <code>abnFit</code></p></a></li>
<li><a href='#plot.abnHeuristic'><p>Plot objects of class <code>abnHeuristic</code></p></a></li>
<li><a href='#plot.abnHillClimber'><p>Plot objects of class <code>abnHillClimber</code></p></a></li>
<li><a href='#plot.abnMostprobable'><p>Plot objects of class <code>abnMostprobable</code></p></a></li>
<li><a href='#plotAbn'><p>Plot an ABN graphic</p></a></li>
<li><a href='#pois_bugs'><p>Bugs code for Poisson response</p></a></li>
<li><a href='#print.abnCache'><p>Print objects of class <code>abnCache</code></p></a></li>
<li><a href='#print.abnDag'><p>Print objects of class <code>abnDag</code></p></a></li>
<li><a href='#print.abnFit'><p>Print objects of class <code>abnFit</code></p></a></li>
<li><a href='#print.abnHeuristic'><p>Print objects of class <code>abnHeuristic</code></p></a></li>
<li><a href='#print.abnHillClimber'><p>Print objects of class <code>abnHillClimber</code></p></a></li>
<li><a href='#print.abnMostprobable'><p>Print objects of class <code>abnMostprobable</code></p></a></li>
<li><a href='#rank_cpp'><p>Rank of a matrix</p></a></li>
<li><a href='#scoreContribution'><p>Compute the score's contribution in a network of each observation.</p></a></li>
<li><a href='#searchHeuristic'><p>A family of heuristic algorithms that aims at finding high scoring directed acyclic graphs</p></a></li>
<li><a href='#searchHillClimber'><p>Find high scoring directed acyclic graphs using heuristic search.</p></a></li>
<li><a href='#simulateAbn'><p>Simulate data from a fitted additive Bayesian network.</p></a></li>
<li><a href='#simulateDag'><p>Simulate a DAG with with arbitrary arcs density</p></a></li>
<li><a href='#skewness'><p>Computes skewness of a distribution</p></a></li>
<li><a href='#std.area.under.grid'><p>Standard Area Under the Marginal</p></a></li>
<li><a href='#strsplits'><p>Recursive string splitting</p></a></li>
<li><a href='#summary.abnDag'><p>Prints summary statistics from an object of class <code>abnDag</code></p></a></li>
<li><a href='#summary.abnFit'><p>Print summary of objects of class <code>abnFit</code></p></a></li>
<li><a href='#summary.abnMostprobable'><p>Print summary of objects of class <code>abnMostprobable</code></p></a></li>
<li><a href='#tidy.cache'><p>tidy up cache</p></a></li>
<li><a href='#toGraphviz'><p>Convert a DAG into graphviz format</p></a></li>
<li><a href='#validate_abnDag'><p>Check for valid DAG of class <code>abnDag</code></p></a></li>
<li><a href='#validate_dists'><p>Check for valid distribution</p></a></li>
<li><a href='#var33'><p>simulated dataset from a DAG comprising of 33 variables</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Modelling Multivariate Data with Additive Bayesian Networks</td>
</tr>
<tr>
<td>Version:</td>
<td>3.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-22</td>
</tr>
<tr>
<td>Description:</td>
<td>The 'abn' R package facilitates Bayesian network analysis, a
    probabilistic graphical model that derives from empirical data a
    directed acyclic graph (DAG). This DAG describes the dependency
    structure between random variables. The R package 'abn' provides
    routines to help determine optimal Bayesian network models for a given
    data set. These models are used to identify statistical dependencies
    in messy, complex data. Their additive formulation is equivalent to
    multivariate generalised linear modelling, including mixed models with
    independent and identically distributed (iid) random effects. The core
    functionality of the 'abn' package revolves around model selection,
    also known as structure discovery. It supports both exact and
    heuristic structure learning algorithms and does not restrict the data
    distribution of parent-child combinations, providing flexibility in
    model creation and analysis. The 'abn' package uses Laplace
    approximations for metric estimation and includes wrappers to the
    'INLA' package. It also employs 'JAGS' for data simulation purposes.
    For more resources and information, visit the 'abn' website.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://r-bayesian-networks.org/">https://r-bayesian-networks.org/</a>,
<a href="https://github.com/furrer-lab/abn">https://github.com/furrer-lab/abn</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/furrer-lab/abn/issues">https://github.com/furrer-lab/abn/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, foreach, graph, lme4, mclogit, methods, nnet,
Rcpp, Rgraphviz, rjags, stringi</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bookdown, boot, brglm, devtools (&ge; 2.4.5), entropy, ggplot2,
gridExtra, INLA, knitr, Matrix (&ge; 1.6.3), MatrixModels (&ge;
0.5.3), microbenchmark, moments, R.rsp, RhpcBLASctl, rmarkdown,
testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="https://inla.r-inla-download.org/R/stable/">https://inla.r-inla-download.org/R/stable/</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Gnu Scientific Library version &gt;= 1.12</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-22 13:26:41 UTC; root</td>
</tr>
<tr>
<td>Author:</td>
<td>Matteo Delucchi <a href="https://orcid.org/0000-0002-9327-1496"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Reinhard Furrer <a href="https://orcid.org/0000-0002-6319-2332"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Gilles Kratzer <a href="https://orcid.org/0000-0002-5929-8935"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Fraser Iain Lewis <a href="https://orcid.org/0000-0003-4580-2712"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Jonas I. Liechti <a href="https://orcid.org/0000-0003-3447-3060"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Marta Pittavino <a href="https://orcid.org/0000-0002-1232-1034"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Kalina Cherneva [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matteo Delucchi &lt;matteo.delucchi@math.uzh.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-30 20:10:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='abn-package'><code>abn</code> Package</h2><span id='topic+abn'></span><span id='topic+abn-package'></span>

<h3>Description</h3>

<p><code>abn</code> is a collection of functions for fitting, selecting/learning, analyzing, reporting Additive Bayesian Networks.
</p>


<h3>Value</h3>

<p>nothing.
</p>


<h3>General overview</h3>

<p>What is <span class="pkg">abn</span>:
Bayesian network modeling is a data analysis technique that is ideally suited to messy, highly correlated, and complex data sets.
This methodology is somewhat distinct from other forms of statistical modeling in that its focus is on structure discovery - determining an optimal graphical model that describes the inter-relationships in the underlying processes which generated the data.
It is a multivariate technique and can be used for one or many dependent variables.
This is a data-driven approach, as opposed to, rely only on subjective expert opinion to determine how variables of interest are inter-related (for example, structural equation modeling).
</p>
<p>The R package <span class="pkg">abn</span> is designed to fit additive Bayesian models to observational data sets.
It contains routines to score Bayesian Networks based on Bayesian or information-theoretic formulation of generalized linear models.
It is equipped with exact search and greedy search algorithms to select the best network.
The Bayesian implementation supports random effects to control for one layer clustering.
It supports a possible mixture of continuous, discrete, and count data and inputs of prior knowledge at a structural level.
</p>
<p>The R package <span class="pkg">abn</span> requires the R package <span class="pkg">Rgraphviz</span> to work well.
It is store outside of CRAN; see &lsquo;Examples&rsquo; for the code to install the last version.
</p>
<p>The web page <a href="https://r-bayesian-networks.org/">r-bayesian-networks.org</a> provides further case studies.
See also the files provided in the package directories <code>inst/bootstrapping_example</code> and <code>inst/old_vignette</code> for more details.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Matteo Delucchi <a href="mailto:matteo.delucchi@math.uzh.ch">matteo.delucchi@math.uzh.ch</a> (<a href="https://orcid.org/0000-0002-9327-1496">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Reinhard Furrer <a href="mailto:reinhard.furrer@math.uzh.ch">reinhard.furrer@math.uzh.ch</a> (<a href="https://orcid.org/0000-0002-6319-2332">ORCID</a>)
</p>
</li>
<li><p> Gilles Kratzer <a href="mailto:gilles.kratzer@gmail.com">gilles.kratzer@gmail.com</a> (<a href="https://orcid.org/0000-0002-5929-8935">ORCID</a>)
</p>
</li>
<li><p> Fraser Iain Lewis <a href="mailto:fraser.iain.lewis@gmail.com">fraser.iain.lewis@gmail.com</a> (<a href="https://orcid.org/0000-0003-4580-2712">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Jonas I. Liechti <a href="mailto:j-i-l@t4d.ch">j-i-l@t4d.ch</a> (<a href="https://orcid.org/0000-0003-3447-3060">ORCID</a>) [contributor]
</p>
</li>
<li><p> Marta Pittavino <a href="mailto:marta.pittavino@math.uzh.ch">marta.pittavino@math.uzh.ch</a> (<a href="https://orcid.org/0000-0002-1232-1034">ORCID</a>) [contributor]
</p>
</li>
<li><p> Kalina Cherneva <a href="mailto:kalinacherneva@gmail.com">kalinacherneva@gmail.com</a> [contributor]
</p>
</li></ul>



<h3>References</h3>

<p>Kratzer, Gilles, Fraser Lewis, Arianna Comin, Marta Pittavino, and Reinhard Furrer. “Additive Bayesian Network Modeling with the R Package Abn.” Journal of Statistical Software 105 (January 28, 2023): 1–41. https://doi.org/10.18637/jss.v105.i08.
</p>
<p>Kratzer, G., Lewis, F.I., Comin, A., Pittavino, M. and Furrer, R. (2019). &quot;Additive Bayesian Network Modelling with the R Package abn&quot;. arXiv preprint arXiv:1911.09006.
</p>
<p>Lewis, F. I., and Ward, M. P. (2013). &quot;Improving epidemiologic data analyses through multivariate regression modeling&quot;. Emerging themes in epidemiology, 10(1), 4.
</p>
<p>Kratzer, G., Pittavino, M, Lewis, F. I., and Furrer, R., (2017). &quot;abn: an R package for modelling multivariate data using additive Bayesian networks&quot;. R package version 2.2.  https://CRAN.R-project.org/package=abn
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://r-bayesian-networks.org/">https://r-bayesian-networks.org/</a>
</p>
</li>
<li> <p><a href="https://github.com/furrer-lab/abn">https://github.com/furrer-lab/abn</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/furrer-lab/abn/issues">https://github.com/furrer-lab/abn/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Citations:
print(citation('abn'), bibtex=TRUE)

## Installing the R package Rgraphviz:
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("Rgraphviz")

## README.md in the directory `bootstrapping_example/`:
# edit(file=paste0( path.package('abn'),'/bootstrapping_example/README.md'))
</code></pre>

<hr>
<h2 id='.onAttach'>Prints start up message</h2><span id='topic+.onAttach'></span>

<h3>Description</h3>

<p>Prints start up message
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.onAttach(lib, pkg)
</code></pre>


<h3>Value</h3>

<p>Prints startup message to the console
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(abn)
</code></pre>

<hr>
<h2 id='abn.version'>abn Version Information</h2><span id='topic+abn.version'></span>

<h3>Description</h3>

<p><code>abn.version()</code> provides detailed information about the running version of <span class="pkg">abn</span>
or the <span class="pkg">abn</span> components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abn.version(what = c("abn", "system"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="abn.version_+3A_what">what</code></td>
<td>
<p>detailed information about the version of <span class="pkg">abn</span> or the system (see returns).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>abn.version(what = "system")</code> is a list with character-string components
</p>

<dl>
<dt>R</dt><dd><p><code>R.version.string</code></p>
</dd>
<dt>abn</dt><dd><p>essentially <code>abn.version$version.string</code></p>
</dd>
<dt>GSL, JAGS, INLA</dt><dd><p>version numbers thereof</p>
</dd>
</dl>

<p><code>abn.version(what = "abn")</code> is a list with character-string components
</p>

<dl>
<dt>status</dt><dd><p>the status of the version (e.g., <code>"beta"</code>)</p>
</dd>
<dt>major</dt><dd><p>the major version number</p>
</dd>
<dt>minor</dt><dd><p>the minor version number</p>
</dd>
<dt>year</dt><dd><p>the year the version was released</p>
</dd>
<dt>month</dt><dd><p>the month the version was released</p>
</dd>
<dt>day</dt><dd><p>the day the version was released</p>
</dd>
<dt>version.string</dt><dd><p>a <code>character</code> string concatenating
the info above, useful for plotting, etc.</p>
</dd>
</dl>

<p><code>abn.version</code> is a list of class <code>"simple.list"</code> which has a <code>print</code> method.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+R.version">R.version</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>abn.version()$version.string
## Not run: 
  abn.version("system")

## End(Not run)
</code></pre>

<hr>
<h2 id='adg'>Dataset related to average daily growth performance and abattoir findings in pigs commercial production.</h2><span id='topic+adg'></span>

<h3>Description</h3>

<p>The case study dataset is about growth performance and abattoir findings in pigs commercial production in a selected set of 15 Canadian farms collected in March 1987.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adg
</code></pre>


<h3>Format</h3>

<p>An adapted data frame of the original dataset which  consists of 341 observations of 8 variables and a grouping variable (farm).
</p>

<dl>
<dt>AR</dt><dd><p>presence of atrophic rhinitis.</p>
</dd>
<dt>pneumS</dt><dd><p>presence of moderate to severe pneumonia.</p>
</dd>
<dt>female</dt><dd><p>sex of the pig (1=female, 0=castrated). </p>
</dd>
<dt>livdam</dt><dd><p>presence of liver damage (parasite-induced white spots).</p>
</dd>
<dt>eggs</dt><dd><p>presence of fecal/gastrointestinal nematode eggs at time of slaughter.</p>
</dd>
<dt>wormCount</dt><dd><p>count of nematodes in small intestine at time of slaughter.</p>
</dd>
<dt>age</dt><dd><p>days elapsed from birth to slaughter (days).</p>
</dd>
<dt>adg</dt><dd><p>average daily weight gain (grams).</p>
</dd>
<dt>farm</dt><dd><p>farm ID.</p>
</dd>
</dl>



<h3>Details</h3>

<p>When using the data to fit an additive Bayesian network,
the variables <code>AR</code>, <code>pneumS</code>, <code>female</code>, <code>livdam</code>,
<code>eggs</code> are considered binomial, <code>wormcount</code> Poisson,
<code>age</code> and <code>adg</code> Gaussian.
The variable <code>farm</code> can be used to adjust for grouping.
</p>


<h3>References</h3>

<p>Kratzer, G., Lewis, F.I., Comin, A., Pittavino, M. and Furrer, R. (2019). &quot;Additive Bayesian Network Modelling with the R Package abn&quot;. arXiv preprint arXiv:1911.09006.
Dohoo, Ian Robert, Wayne Martin, and Henrik Stryhn. Veterinary epidemiologic research. No. V413 DOHv. Charlottetown, Canada: AVC Incorporated, 2003.
</p>

<hr>
<h2 id='AIC.abnFit'>Print AIC of objects of class <code>abnFit</code></h2><span id='topic+AIC.abnFit'></span>

<h3>Description</h3>

<p>Print AIC of objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
AIC(object, digits = 3L, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AIC.abnFit_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="AIC.abnFit_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="AIC.abnFit_+3A_verbose">verbose</code></td>
<td>
<p>print additional output.</p>
</td></tr>
<tr><td><code id="AIC.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the AIC of the fitted model.
</p>

<hr>
<h2 id='bern_bugs'>Bugs code for Bernoulli response</h2><span id='topic+bern_bugs'></span><span id='topic+bern_bugsGroup'></span>

<h3>Description</h3>

<p>Bugs model for a Binomial response <code class="reqn">X</code> in a single trial:
<code class="reqn">X \sim \mathcal{B}(n=1, p) = \mathcal{Bernoulli}(p)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bern_bugs(nodename, nodesintercept, parentnames, parentcoefs)

bern_bugsGroup(nodename, nodesintercept, parentnames, parentcoefs, sigma_alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bern_bugs_+3A_nodename">nodename</code></td>
<td>
<p>character string of response variable name.</p>
</td></tr>
<tr><td><code id="bern_bugs_+3A_nodesintercept">nodesintercept</code></td>
<td>
<p>overall mean of response. Parameter from fixed-effects intercept.</p>
</td></tr>
<tr><td><code id="bern_bugs_+3A_parentnames">parentnames</code></td>
<td>
<p>single character string (for one parent) or vector of characters (for multiple parent nodes) with parent node (predictor variables) names.</p>
</td></tr>
<tr><td><code id="bern_bugs_+3A_parentcoefs">parentcoefs</code></td>
<td>
<p>overall slope for each predictor (parent node) variable (fixed-effects).</p>
</td></tr>
<tr><td><code id="bern_bugs_+3A_sigma_alpha">sigma_alpha</code></td>
<td>
<p>between-group variance. Parameter from random-effects intercept.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bugs model returned as stdout.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>bern_bugsGroup()</code>: Bugs code for Bernoulli response with varying intercept
</p>
</li></ul>


<h3>See Also</h3>

<p><a href="#topic+makebugs">makebugs</a> <a href="#topic+simulateAbn">simulateAbn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bern_bugs(nodename = "a",
          parentnames = c("b", "c"),
          nodesintercept = c(0.318077),
          parentcoefs = list("b"=c(b=0.3059395),
                             "c"=c(c=0.5555)))
</code></pre>

<hr>
<h2 id='BIC.abnFit'>Print BIC of objects of class <code>abnFit</code></h2><span id='topic+BIC.abnFit'></span>

<h3>Description</h3>

<p>Print BIC of objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
BIC(object, digits = 3L, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BIC.abnFit_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="BIC.abnFit_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="BIC.abnFit_+3A_verbose">verbose</code></td>
<td>
<p>print additional output.</p>
</td></tr>
<tr><td><code id="BIC.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the BIC of the fitted model.
</p>

<hr>
<h2 id='build.control'>Control the iterations in <code><a href="#topic+buildScoreCache">buildScoreCache</a></code></h2><span id='topic+build.control'></span>

<h3>Description</h3>

<p>Allow the user to set restrictions in the <code><a href="#topic+buildScoreCache">buildScoreCache</a></code> for both the Bayesian and the MLE approach.
Control function similar to <code><a href="#topic+fit.control">fit.control</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build.control(
  method = "bayes",
  max.mode.error = 10,
  mean = 0,
  prec = 0.001,
  loggam.shape = 1,
  loggam.inv.scale = 5e-05,
  max.iters = 100,
  epsabs = 1e-07,
  error.verbose = FALSE,
  trace = 0L,
  epsabs.inner = 1e-06,
  max.iters.inner = 100,
  finite.step.size = 1e-07,
  hessian.params = c(1e-04, 0.01),
  max.iters.hessian = 10,
  max.hessian.error = 0.5,
  factor.brent = 100,
  maxiters.hessian.brent = 100,
  num.intervals.brent = 100,
  n.grid = 250,
  ncores = 1,
  cluster.type = "FORK",
  max.irls = 100,
  tol = 1e-08,
  tolPwrss = 1e-07,
  check.rankX = "message+drop.cols",
  check.scaleX = "message+rescale",
  check.conv.grad = "message",
  check.conv.singular = "message",
  check.conv.hess = "message",
  xtol_abs = 1e-06,
  ftol_abs = 1e-06,
  trace.mblogit = FALSE,
  catcov.mblogit = "free",
  epsilon = 1e-06,
  seed = 9062019L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="build.control_+3A_method">method</code></td>
<td>
<p>a character that takes one of two values: &quot;bayes&quot; or &quot;mle&quot;. Overrides <code>method</code> argument from <code><a href="#topic+buildScoreCache">buildScoreCache</a></code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_max.mode.error">max.mode.error</code></td>
<td>
<p>if the estimated modes from INLA differ by a factor of <code>max.mode.error</code> or more from those computed internally, then results from INLA are replaced by those computed internally. To force INLA always to be used, then <code>max.mode.error=100</code>, to force INLA never to be used <code>max.mod.error=0</code>. See also <code><a href="#topic+fitAbn">fitAbn</a></code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_mean">mean</code></td>
<td>
<p>the prior mean for all the Gaussian additive terms for each node. INLA argument <code>control.fixed=list(mean.intercept=...)</code> and <code>control.fixed=list(mean=...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_prec">prec</code></td>
<td>
<p>the prior precision (<code class="reqn">\tau = \frac{1}{\sigma^2}</code>) for all the Gaussian additive term for each node. INLA argument <code>control.fixed=list(prec.intercept=...)</code> and <code>control.fixed=list(prec=...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_loggam.shape">loggam.shape</code></td>
<td>
<p>the shape parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_loggam.inv.scale">loggam.inv.scale</code></td>
<td>
<p>the inverse scale parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_max.iters">max.iters</code></td>
<td>
<p>total number of iterations allowed when estimating the modes in Laplace approximation. passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_epsabs">epsabs</code></td>
<td>
<p>absolute error when estimating the modes in Laplace approximation for models with no random effects. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_error.verbose">error.verbose</code></td>
<td>
<p>logical, additional output in the case of errors occurring in the optimization. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_trace">trace</code></td>
<td>
<p>Non-negative integer. If positive, tracing information on the progress of the &quot;L-BFGS-B&quot; optimization is produced. Higher values may produce more tracing information. (There are six levels of tracing.  To understand exactly what these do see the source code.). Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_epsabs.inner">epsabs.inner</code></td>
<td>
<p>absolute error in the maximization step in the (nested) Laplace approximation for each random effect term. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_max.iters.inner">max.iters.inner</code></td>
<td>
<p>total number of iterations in the maximization step in the nested Laplace approximation. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_finite.step.size">finite.step.size</code></td>
<td>
<p>suggested step length used in finite difference estimation of the derivatives for the (outer) Laplace approximation when estimating modes. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_hessian.params">hessian.params</code></td>
<td>
<p>a numeric vector giving parameters for the adaptive algorithm, which determines the optimal stepsize in the finite-difference estimation of the hessian. First entry is the initial guess, second entry absolute error. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_max.iters.hessian">max.iters.hessian</code></td>
<td>
<p>integer, maximum number of iterations to use when determining an optimal finite difference approximation (Nelder-Mead). Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_max.hessian.error">max.hessian.error</code></td>
<td>
<p>if the estimated log marginal likelihood when using an adaptive 5pt finite-difference rule for the Hessian differs by more than <code>max.hessian.error</code> from when using an adaptive 3pt rule then continue to minimize the local error by switching to the Brent-Dekker root bracketing method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_factor.brent">factor.brent</code></td>
<td>
<p>if using Brent-Dekker root bracketing method then define the outer most interval end points as the best estimate of <code class="reqn">h</code> (stepsize) from the Nelder-Mead as <code class="reqn">h/factor.brent,h*factor.brent)</code>. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_maxiters.hessian.brent">maxiters.hessian.brent</code></td>
<td>
<p>maximum number of iterations allowed in the Brent-Dekker method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_num.intervals.brent">num.intervals.brent</code></td>
<td>
<p>the number of initial different bracket segments to try in the Brent-Dekker method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_n.grid">n.grid</code></td>
<td>
<p>recompute density on an equally spaced grid with <code>n.grid</code> points.</p>
</td></tr>
<tr><td><code id="build.control_+3A_ncores">ncores</code></td>
<td>
<p>The number of cores to parallelize to, see &lsquo;Details&rsquo;. If &gt;0, the number of CPU cores to be used. -1 for all available -1 core. Only for <code>method="mle"</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_cluster.type">cluster.type</code></td>
<td>
<p>The type of cluster to be used, see <code>?parallel::makeCluster</code>. <code>abn</code> then defaults to <code>"PSOCK"</code> on Windows and <code>"FORK"</code> on Unix-like systems. With &quot;FORK&quot; the child process are started with <code>rscript_args = "--no-environ"</code> to avoid loading the whole workspace into each child.</p>
</td></tr>
<tr><td><code id="build.control_+3A_max.irls">max.irls</code></td>
<td>
<p>total number of iterations for estimating network scores using an Iterative Reweighed Least Square algorithm. Is this DEPRECATED?</p>
</td></tr>
<tr><td><code id="build.control_+3A_tol">tol</code></td>
<td>
<p>real number giving the minimal tolerance expected to terminate the Iterative Reweighed Least Square algorithm to estimate network score. Passed to <code>irls_binomial_cpp_fast_br</code> and <code>irls_poisson_cpp_fast</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_tolpwrss">tolPwrss</code></td>
<td>
<p>numeric scalar passed to <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - the tolerance for declaring convergence in the penalized iteratively weighted residual sum-of-squares step. Similar to <code>tol</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_check.rankx">check.rankX</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - specifying if <code>rankMatrix(X)</code> should be compared with <code>ncol(X)</code> and if columns from the design matrix should possibly be dropped to ensure that it has full rank. Defaults to <code>message+drop.cols</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_check.scalex">check.scaleX</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - check for problematic scaling of columns of fixed-effect model matrix, e.g. parameters measured on very different scales. Defaults to <code>message+rescale</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_check.conv.grad">check.conv.grad</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - checking the gradient of the deviance function for convergence. Defaults to <code>message</code> but can be one of &quot;ignore&quot; - skip the test; &quot;warning&quot; - warn if test fails; &quot;message&quot; - print a message if test fails; &quot;stop&quot; - throw an error if test fails.</p>
</td></tr>
<tr><td><code id="build.control_+3A_check.conv.singular">check.conv.singular</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - checking for a singular fit, i.e. one where some parameters are on the boundary of the feasible space (for example, random effects variances equal to 0 or correlations between random effects equal to +/- 1.0). Defaults to <code>message</code> but can be one of &quot;ignore&quot; - skip the test; &quot;warning&quot; - warn if test fails; &quot;message&quot; - print a message if test fails; &quot;stop&quot; - throw an error if test fails.</p>
</td></tr>
<tr><td><code id="build.control_+3A_check.conv.hess">check.conv.hess</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - checking the Hessian of the deviance function for convergence. Defaults to <code>message</code> but can be one of &quot;ignore&quot; - skip the test; &quot;warning&quot; - warn if test fails; &quot;message&quot; - print a message if test fails; &quot;stop&quot; - throw an error if test fails.</p>
</td></tr>
<tr><td><code id="build.control_+3A_xtol_abs">xtol_abs</code></td>
<td>
<p>Defaults to 1e-6 stop on small change of parameter value. Only for <code>method='mle', group.var=...</code>. Default convergence tolerance for fitted <code>(g)lmer</code> models is reduced to the value provided here if default values did not fit. This value here is passed to the <code>optCtrl</code> argument of <code>(g)lmer</code> (see help of <code><a href="lme4.html#topic+convergence">lme4::convergence()</a></code>).</p>
</td></tr>
<tr><td><code id="build.control_+3A_ftol_abs">ftol_abs</code></td>
<td>
<p>Defaults to 1e-6 stop on small change in deviance. Similar to <code>xtol_abs</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_trace.mblogit">trace.mblogit</code></td>
<td>
<p>logical indicating if output should be produced for each iteration. Directly passed to <code>trace</code> argument in <code><a href="mclogit.html#topic+mclogit.control">mclogit.control</a></code>. Is independent of <code>verbose</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_catcov.mblogit">catcov.mblogit</code></td>
<td>
<p>Defaults to &quot;free&quot; meaning that there are no restrictions on the covariances of random effects between the logit equations. Set to &quot;diagonal&quot; if random effects pertinent to different categories are uncorrelated or &quot;single&quot; if random effect variances pertinent to all categories are identical.</p>
</td></tr>
<tr><td><code id="build.control_+3A_epsilon">epsilon</code></td>
<td>
<p>Defaults to 1e-8. Positive convergence tolerance <code class="reqn">\epsilon</code> that is directly passed to the <code>control</code> argument of <code>mclogit::mblogit</code> as <code>mclogit.control</code>. Only for <code>method='mle', group.var=...</code>.</p>
</td></tr>
<tr><td><code id="build.control_+3A_seed">seed</code></td>
<td>
<p>a non-negative integer which sets the seed in <code>set.seed(seed)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parallelization over all children is possible via the function <code>foreach</code> of the package <span class="pkg">doParallel</span>.  <code>ncores=0</code> or <code>ncores=1</code> use single threaded <code>foreach</code>. <code>ncores=-1</code> uses all available cores but one.
</p>


<h3>Value</h3>

<p>Named list according the provided arguments.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.control">fit.control</a></code>.
</p>
<p>Other buildScoreCache: 
<code><a href="#topic+buildScoreCache">buildScoreCache</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ctrlmle &lt;- abn::build.control(method = "mle",
                        ncores = 0,
                        cluster.type = "PSOCK",
                        max.irls = 100,
                        tol = 10^-11,
                        tolPwrss = 1e-7,
                        check.rankX = "message+drop.cols",
                        check.scaleX = "message+rescale",
                        check.conv.grad = "message",
                        check.conv.singular = "message",
                        check.conv.hess = "message",
                        xtol_abs = 1e-6,
                        ftol_abs = 1e-6,
                        trace.mblogit = FALSE,
                        catcov.mblogit = "free",
                        epsilon = 1e-6,
                        seed = 9062019L)
ctrlbayes &lt;- abn::build.control(method = "bayes",
                           max.mode.error = 10,
                           mean = 0, prec = 0.001,
                           loggam.shape = 1,
                           loggam.inv.scale = 5e-05,
                           max.iters = 100,
                           epsabs = 1e-07,
                           error.verbose = FALSE,
                           epsabs.inner = 1e-06,
                           max.iters.inner = 100,
                           finite.step.size = 1e-07,
                           hessian.params = c(1e-04, 0.01),
                           max.iters.hessian = 10,
                           max.hessian.error = 0.5,
                           factor.brent = 100,
                           maxiters.hessian.brent = 100,
                           num.intervals.brent = 100,
                           tol = 10^-8,
                           seed = 9062019L)

</code></pre>

<hr>
<h2 id='buildScoreCache'>Build a cache of goodness of fit metrics for each node in a DAG, possibly subject to user-defined restrictions</h2><span id='topic+buildScoreCache'></span><span id='topic+buildScoreCache.bayes'></span><span id='topic+forLoopContentBayes'></span><span id='topic+forLoopContent'></span><span id='topic+buildScoreCache.mle'></span>

<h3>Description</h3>

<p>Iterates over all valid parent combinations - subject to ban, retain, and <code>max.parent</code> limits - for each node, or a subset of nodes, and computes a cache of scores (AIC, BIC, log marginal likelihood).
This cache can then be used in different DAG structural search algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>buildScoreCache(data.df = NULL,
data.dists = NULL,
method = "bayes",
group.var = NULL,
adj.vars = NULL,
cor.vars = NULL,
dag.banned = NULL,
dag.retained = NULL,
max.parents = NULL,
which.nodes = NULL,
defn.res = NULL,
centre = TRUE,
dry.run = FALSE,
control = NULL,
verbose = FALSE,
debugging = FALSE,
...)

buildScoreCache.bayes(
  data.df = NULL,
  data.dists = NULL,
  group.var = NULL,
  cor.vars = NULL,
  dag.banned = NULL,
  dag.retained = NULL,
  max.parents = NULL,
  which.nodes = NULL,
  defn.res = NULL,
  dry.run = FALSE,
  centre = TRUE,
  force.method = NULL,
  mylist = NULL,
  grouped.vars = NULL,
  group.ids = NULL,
  control = build.control(method = "bayes"),
  verbose = FALSE,
  debugging = FALSE
)

forLoopContentBayes(
  row.no = NULL,
  children = NULL,
  node.defn = NULL,
  dag.m = NULL,
  force.method = NULL,
  data.df = NULL,
  data.dists = NULL,
  var.types = NULL,
  control = NULL,
  grouped.vars = NULL,
  group.ids = NULL,
  verbose = FALSE
)

forLoopContent(
  row.num,
  mycache,
  data.dists,
  data.df.multi,
  adj.vars,
  data.df,
  data.df.lvl,
  group.var,
  group.ids,
  control,
  n,
  verbose
)

buildScoreCache.mle(
  data.df = NULL,
  data.dists = NULL,
  max.parents = NULL,
  adj.vars = NULL,
  cor.vars = NULL,
  dag.banned = NULL,
  dag.retained = NULL,
  which.nodes = NULL,
  centre = TRUE,
  defn.res = NULL,
  dry.run = FALSE,
  verbose = FALSE,
  debugging = FALSE,
  force.method = NULL,
  group.var = NULL,
  grouped.vars = NULL,
  group.ids = NULL,
  control = build.control(method = "mle")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="buildScoreCache_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data used for learning each node. Binary variables must be declared as factors.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_data.dists">data.dists</code></td>
<td>
<p>a named list giving the distribution for each node in the network, see &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_method">method</code></td>
<td>
<p>should a &quot;Bayes&quot; or &quot;mle&quot; approach be used, see &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_group.var">group.var</code></td>
<td>
<p>variable name for nodes to be fitted as variable intercept as in a mixed-effects model (&quot;Bayes&quot; and &quot;mle&quot;) and gives the column name in <code>data.df</code> of the grouping variable which must be a factor denoting group membership.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_adj.vars">adj.vars</code></td>
<td>
<p>a character vector giving the column names in <code>data.df</code> for which the network score has to be adjusted for, see &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_cor.vars">cor.vars</code></td>
<td>
<p>a character vector giving the column names in <code>data.df</code> for which a mixed model should be used to adjust for within group correlation or pure adjustment (&quot;bayes&quot; only).</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_dag.banned">dag.banned</code></td>
<td>
<p>a matrix or a formula statement (see &lsquo;Details&rsquo; for format) defining which arcs are not permitted - banned - see &lsquo;Details&rsquo; for format. Note that colnames and rownames must be set, otherwise same row/column names as data.df will be assumed. If set as NULL an empty matrix is assumed.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_dag.retained">dag.retained</code></td>
<td>
<p>a matrix or a formula statement (see &lsquo;Details&rsquo; for format) defining which arcs are must be retained in any model search, see &lsquo;Details&rsquo; for format. Note that colnames and rownames must be set, otherwise same row/column names as data.df will be assumed. If set as NULL an empty matrix is assumed.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_max.parents">max.parents</code></td>
<td>
<p>a constant or named list giving the maximum number of parents allowed, the list version allows this to vary per node (only for <code>method="bayes"</code>. A constant can be a single integer, a numeric vector of the length of variables with the same integer for all variable (e.g. <code>c(2,2)</code>) or a named list with all values being the same (e.g. <code>list("A"=2, "B"=2)</code>).</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_which.nodes">which.nodes</code></td>
<td>
<p>a vector giving the column indices of the variables to be included, if ignored all variables are included. This is used to subset <code>data.df</code>.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_defn.res">defn.res</code></td>
<td>
<p>an optional user-supplied list of child and parent combinations, see &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_centre">centre</code></td>
<td>
<p>should the observations in each Gaussian node first be standardized to mean zero and standard deviation one, defaults to TRUE.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_dry.run">dry.run</code></td>
<td>
<p>if TRUE then a list of the child nodes and parent combinations are returned but without estimation of node scores (log marginal likelihoods).</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_control">control</code></td>
<td>
<p>a list of control parameters. See <code><a href="#topic+build.control">build.control</a></code> for the names of the settable control values and their effect.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE then provides some additional output.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_debugging">debugging</code></td>
<td>
<p>if <code>TRUE</code> and <code>method = 'mle'</code> this enables to step into the for-loop.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_...">...</code></td>
<td>
<p>additional arguments passed for optimization.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_force.method">force.method</code></td>
<td>
<p>&quot;notset&quot;, &quot;INLA&quot; or &quot;C&quot;. This is specified in <code><a href="#topic+buildScoreCache">buildScoreCache</a>(control=list(max.mode.error=...))</code>.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_mylist">mylist</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.data">check.valid.data</a></code>.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_grouped.vars">grouped.vars</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.groups">check.valid.groups</a></code>.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_group.ids">group.ids</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.groups">check.valid.groups</a></code>.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_row.no">row.no</code></td>
<td>
<p>The row number of the child-parent combination to be processed.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_children">children</code></td>
<td>
<p>vector of child node integers.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_node.defn">node.defn</code></td>
<td>
<p>child-parent combination table.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_dag.m">dag.m</code></td>
<td>
<p>Empty adjacency matrix.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_var.types">var.types</code></td>
<td>
<p>vector of numeric encoding of distribution types. See <code>get.var.types(data.dists)</code></p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_row.num">row.num</code></td>
<td>
<p>number of child-node (mostly corresponds to child node index e.g. in dag).</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_mycache">mycache</code></td>
<td>
<p>prepared cache.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_data.df.multi">data.df.multi</code></td>
<td>
<p>extended data.df for one-hot-encoded multinomial variables.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_data.df.lvl">data.df.lvl</code></td>
<td>
<p>copy of original <code>data.df</code>.</p>
</td></tr>
<tr><td><code id="buildScoreCache_+3A_n">n</code></td>
<td>
<p>corresponds to <code>nvars</code>, number of variables in data.dists.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes a cache of scores based on possible restrictions (maximum complexity, retained and banned arcs).
This function is very similar to <code><a href="#topic+fitAbn">fitAbn</a></code> - see that help page for details of the type of models used and in particular <code>data.dists</code> specification - but rather than fit a single complete DAG <code>buildScoreCache</code> iterates over all different parent combinations for each node, creating a cache of scores.
This cache of score could be used to select the optimal network in other function such as <code><a href="#topic+searchHeuristic">searchHeuristic</a></code> or <code><a href="#topic+mostProbable">mostProbable</a></code>.
&lsquo;dag.banned&rsquo; and &lsquo;dag.retained&rsquo; specify which arcs are forced to be absent or present in the DAG, respectively.
If provided as matrix, rows represent child nodes and columns their parents for elements with a value $=1$.
</p>
<p>Two very different approaches are implemented: a Bayesian and frequentist approaches. They can be selected using the <code>method</code> argument.
</p>


<h4>If <code>method="bayes"</code>:</h4>

<p>This function is used to calculate all individual node scores (log marginal likelihoods).
Internal code is used by default for numerical estimation in nodes without random effects, and INLA is the default for nodes with random effects.
This default behavior can be overridden using <code>control=list(max.mode.error=...)</code>. The default is <code>max.mode.error=10</code>, which means that the modes estimated from INLA output must be within 10\
Otherwise, the internal code is used rather than INLA.
To force the use of INLA on all nodes, use max.mode.error=100, which then ignores this check, to force the use of internal code then use <code>max.mode.error=0</code>. For more detials, see <a href="#topic+fitAbn">fitAbn</a>.
The variable <code>which.nodes</code> is to allow the computation to be separated by node, for example, over different CPUs using say <code>R CMD BATCH</code>.
This may useful and indeed likely essential with larger problems or those with random effects.
Note that in this case, the results must then be combined back into a list of identical formats to that produced by an individual call to <code>buildScoreCache</code>,
comprising of all nodes (in the same order as the columns in <code>data.df</code>) before sending it to any search routines. Using <code>dry.run</code> can be useful here.
</p>



<h4>If <code>method="mle"</code>:</h4>

<p>This function is used to calculate all individual information-theoretic node scores. The possible information-theoretic based network scores computed in <code>buildScoreCache</code> are the maximum likelihood (mlik, called marginal likelihood in this context as it is computed node wise),
the Akaike Information Criteria (aic), the Bayesian Information Criteria (bic) and the Minimum distance Length (mdl). The classical definitions of those metrics are given in Kratzer and Furrer (2018). This function computes a cache that can be fed into a model search algorithm.
The numerical routines used here are identical to those in <code><a href="#topic+fitAbn">fitAbn</a></code> and see that help page for further details and also the quality assurance section on the <a href="https://r-bayesian-networks.org/">r-bayesian-networks.org</a> of the <span class="pkg">abn</span> website for more details.
</p>



<h3>Value</h3>

<p>A named list of class <code>abnCache</code>.
</p>

<dl>
<dt><code>children</code></dt><dd><p>a vector of the child node indexes (from 1) corresponding to the columns in data.df (ignoring any grouping variable)</p>
</dd>
<dt><code>node.defn</code></dt><dd><p>a matrix giving the parent combination</p>
</dd>
<dt><code>mlik</code></dt><dd><p>log marginal likelihood value for each node combination. If the model cannot be fitted then NA is returned. </p>
</dd>
<dt><code>error.code</code></dt><dd><p>if non-zero then either the root finding algorithm (glm nodes) or the maximisation algorithm (glmm nodes) terminated in an unusual way suggesting a possible unreliable result, or else the finite difference hessian estimation produced and error or warning (glmm nodes). NULL if <code>method="mle"</code>.</p>
</dd>
<dt><code>error.code.desc</code></dt><dd><p>a textual description of the <code>error.code</code>. NULL if <code>method="mle"</code></p>
</dd>
<dt><code>hessian.accuracy</code></dt><dd><p>An estimate of the error in the final mlik value for each parent combination - this is the absolute difference between two different adaptive finite difference rules where each computes the mlik value. NULL if <code>method="mle"</code></p>
</dd>
<dt><code>data.df</code></dt><dd><p>a version of the original data (for internal use only in other functions such as <code><a href="#topic+mostProbable">mostProbable</a></code>).</p>
</dd>
<dt><code>data.dists</code></dt><dd><p>the named list of nodes distributions (for internal use only in other functions such as <code><a href="#topic+mostProbable">mostProbable</a></code>).</p>
</dd>
<dt><code>max.parents</code></dt><dd><p>the maximum number of parents (for internal use only in other functions such as <code><a href="#topic+mostProbable">mostProbable</a></code>).</p>
</dd>
<dt><code>dag.retained</code></dt><dd><p>the matrix encoding the retained arcs (for internal use only in other functions such as <code><a href="#topic+searchHeuristic">searchHeuristic</a></code>).</p>
</dd>
<dt><code>dag.banned</code></dt><dd><p>the matrix encoding the banned arcs (for internal use only in other functions such as <code><a href="#topic+searchHeuristic">searchHeuristic</a></code>).</p>
</dd>
<dt><code>aic</code></dt><dd><p>aic value for each node combination. If the model cannot be fitted then NaN is returned. NULL if <code>method="bayes"</code>.</p>
</dd>
<dt><code>bic</code></dt><dd><p>bic value for each node combination. If the model cannot be fitted then NaN is returned. NULL if <code>method="bayes"</code>.</p>
</dd>
<dt><code>mdl</code></dt><dd><p>mdl value for each node combination. If the model cannot be fitted then NaN is returned. NULL if <code>method="bayes"</code>.</p>
</dd>
</dl>

<p>Named vector of results from one child-parent combination subject to the <code>row.no</code>.
The names are:
</p>

<dl>
<dt>childParentCombNo</dt><dd><p>The row number of the child-parent combination in the <code>node.defn</code> table.
This must be the same as the row number in <code>node.defn</code>:
careful if <code>buildScoreCache.bayes()</code> is run in parallel!</p>
</dd>
<dt>mlik</dt><dd><p>The marginal log-likelihood of the child-parent combination.</p>
</dd>
<dt>error.code</dt><dd><p>The error code returned by <code>inla()</code>.</p>
</dd>
<dt>hessian.accuracy</dt><dd><p>The accuracy of the Hessian matrix returned by <code>inla()</code>.</p>
</dd>
<dt>used.INLA</dt><dd><p>A logical value indicating whether <code>inla()</code> was used to fit the model.</p>
</dd>
</dl>

<p>A list that will be passed to <code><a href="#topic+buildScoreCache.mle">buildScoreCache.mle</a></code>.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>buildScoreCache.bayes()</code>: Fit a given DAG to data with method=&quot;bayes&quot;.
</p>
</li>
<li> <p><code>forLoopContentBayes()</code>: Internal function called by <code>buildScoreCache.bayes()</code>.
</p>
</li>
<li> <p><code>forLoopContent()</code>: Internal function called by <code>buildScoreCache.mle()</code>.
</p>
</li>
<li> <p><code>buildScoreCache.mle()</code>: Fit a given DAG to data with method=&quot;mle&quot;.
</p>
</li></ul>


<h3>References</h3>

<p>Kratzer, Gilles, Fraser Lewis, Arianna Comin, Marta Pittavino, and Reinhard Furrer. “Additive Bayesian Network Modeling with the R Package Abn.” Journal of Statistical Software 105 (January 28, 2023): 1–41. https://doi.org/10.18637/jss.v105.i08.
</p>
<p>Kratzer, G., Lewis, F.I., Comin, A., Pittavino, M., and Furrer, R. (2019). &quot;Additive Bayesian Network Modelling with the R Package abn&quot;. arXiv:1911.09006.
</p>
<p>Kratzer, G., and Furrer, R., (2018). &quot;Information-Theoretic Scoring Rules to Learn Additive Bayesian Network Applied to Epidemiology&quot;. arXiv:1808.01126.
</p>
<p>Lewis, F. I., and McCormick, B. J. J. (2012). &quot;Revealing the complexity of health determinants in resource poor settings&quot;. <em>American Journal Of Epidemiology</em>. doi:10.1093/aje/KWS183).
</p>
<p>Further information about <span class="pkg">abn</span> can be found at: <a href="https://r-bayesian-networks.org/">r-bayesian-networks.org</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fitAbn">fitAbn</a></code>
</p>
<p>Other buildScoreCache: 
<code><a href="#topic+build.control">build.control</a>()</code>
</p>
<p>Other Bayes: 
<code><a href="#topic+calc.node.inla.glm">calc.node.inla.glm</a>()</code>,
<code><a href="#topic+calc.node.inla.glmm">calc.node.inla.glmm</a>()</code>,
<code><a href="#topic+fitAbn">fitAbn</a>()</code>,
<code><a href="#topic+getmarginals">getmarginals</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simple example
# Generate data
N &lt;- 1e6
mydists &lt;- list(a="gaussian",
                b="gaussian",
                c="gaussian")
a &lt;- rnorm(n = N, mean = 0, sd = 1)
b &lt;- 1 + 2*rnorm(n = N, mean = 5, sd = 1)
c &lt;- 2 + 1*a + 2*b + rnorm(n = N, mean = 2, sd = 1)
mydf &lt;- data.frame("a" = scale(a),
                   "b" = scale(b),
                   "c" = scale(c))

# ABN with MLE
mycache.mle &lt;- buildScoreCache(data.df = mydf,
                               data.dists = mydists,
                               method = "mle",
                            max.parents = 2)
dag.mle &lt;- mostProbable(score.cache = mycache.mle,
                        max.parents = 2)
myfit.mle &lt;- fitAbn(object = dag.mle,
                    method = "mle",
                    max.parents = 2)
plot(myfit.mle)

## Not run: 
# ABN with Bayes
if(requireNamespace("INLA", quietly = TRUE)){
  # Run only if INLA is available
  mycache.bayes &lt;- buildScoreCache(data.df = mydf,
                                   data.dists = mydists,
                                   method = "bayes",
                                   max.parents = 2)
  dag.bayes &lt;- mostProbable(score.cache = mycache.bayes,
                            max.parents = 2)
  myfit.bayes &lt;- fitAbn(object = dag.bayes,
                        method = "bayes",
                        max.parents = 2)
  plot(myfit.bayes)
}
# Compare MLE and Bayes with lm
mymod.lm &lt;- lm(c ~ a + b, data = mydf)
summary(mymod.lm)

##################################################################################################
## Example 1 - "mle" vs. "bayes" and the later with using the internal C routine compared to INLA
##################################################################################################

# Subset of the build-in dataset, see  ?ex0.dag.data
mydat &lt;- ex0.dag.data[,c("b1","b2","g1","g2","b3","g3")] ## take a subset of cols

# setup distribution list for each node
mydists &lt;- list(b1="binomial", b2="binomial", g1="gaussian",
                g2="gaussian", b3="binomial", g3="gaussian")

# Structural constraints
## ban arc from b2 to b1
## always retain arc from g2 to g1
## parent limits - can be specified for each node separately
max.par &lt;- list("b1"=2, "b2"=2, "g1"=2, "g2"=2, "b3"=2, "g3"=2)

# now build the cache of pre-computed scores accordingly to the structural constraints
res.c &lt;- buildScoreCache(data.df=mydat,
                         data.dists=mydists,
                         dag.banned= ~b1|b2,
                         dag.retained= ~g1|g2,
                         max.parents=max.par,
                         method="bayes")


# repeat but using R-INLA. The mlik's should be virtually identical.
# Force using of INLA build.control(max.mode.error=100)
if(requireNamespace("INLA", quietly = TRUE)){
  res.inla &lt;- buildScoreCache(data.df=mydat,
                              data.dists=mydists,
                              dag.banned= ~b1|b2, # ban arc from b2 to b1
                              dag.retained= ~g1|g2, # always retain arc from g2 to g1
                              max.parents=max.par,
                              method="bayes",
                              control=build.control(max.mode.error=100))

  ## comparison - very similar
  difference &lt;- res.c$mlik - res.inla$mlik
  summary(difference)
}

# Comparison Bayes with MLE (unconstrained):
res.mle &lt;- buildScoreCache(data.df=mydat, data.dists=mydists,
                           max.parents=3, method="mle")
res.abn &lt;- buildScoreCache(data.df=mydat, data.dists=mydists,
                           max.parents=3, method="bayes")
# of course different, but same order:
plot(-res.mle$bic, res.abn$mlik)

#################################################################
## Example 2 - mle with several cores
#################################################################

## Many variables, few observations
mydat &lt;- ex0.dag.data
mydists &lt;- as.list(rep(c("binomial", "gaussian", "poisson"), each=10))
names(mydists) &lt;- names(mydat)

system.time({
  res.mle1 &lt;- buildScoreCache(data.df=mydat,
                              data.dists=mydists,
                              max.parents=2,
                              method="mle",
                              control = build.control(method = "mle",
                                                      ncores=1))})
system.time({
  res.mle2 &lt;- buildScoreCache(data.df=mydat,
                              data.dists=mydists,
                              max.parents=2,
                              method="mle",
                              control = build.control(method = "mle",
                                                      ncores=2))})

#################################################################
## Example 3 - grouped data - random effects example e.g. glmm
#################################################################

## this data comes with abn see ?ex3.dag.data
mydat &lt;- ex3.dag.data[,c("b1","b2","b3","b4","b5","b6","b7",
                         "b8","b9","b10","b11","b12","b13", "group")]

mydists &lt;- list(b1="binomial", b2="binomial", b3="binomial",
                b4="binomial", b5="binomial", b6="binomial", b7="binomial",
                b8="binomial", b9="binomial", b10="binomial",b11="binomial",
                b12="binomial", b13="binomial" )
max.par &lt;- 2

## in this example INLA is used as default since these are glmm nodes
## when running this at node-parent combination 71 the default accuracy check on the
## INLA modes is exceeded (default is a max. of 10 percent difference from
## modes estimated using internal code) and a message is given that internal code
## will be used in place of INLA's results.

mycache.bayes &lt;- buildScoreCache(data.df=mydat,
                                 data.dists=mydists,
                                 group.var="group",
                                 method = "bayes",
                                 max.parents=max.par)
dag.bayes &lt;- mostProbable(score.cache=mycache.bayes)
plot(dag.bayes)

mycache.mle &lt;- buildScoreCache(data.df=mydat,
                               data.dists=mydists,
                               group.var="group",
                               method = "mle",
                               max.parents=max.par)
dag.mle &lt;- mostProbable(score.cache=mycache.mle)
plot(dag.mle)

## End(Not run)

</code></pre>

<hr>
<h2 id='calc.node.inla.glm'>Fit a given regression using INLA</h2><span id='topic+calc.node.inla.glm'></span>

<h3>Description</h3>

<p>Internal wrapper to INLA and are called from <code>fitAbn.bayes</code> and <code>buildScoreCache.bayes</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.node.inla.glm(
  child.loc = NULL,
  dag.m.loc = NULL,
  data.df.loc = NULL,
  data.dists.loc = NULL,
  ntrials.loc = NULL,
  exposure.loc = NULL,
  compute.fixed.loc = NULL,
  mean.intercept.loc = NULL,
  prec.intercept.loc = NULL,
  mean.loc = NULL,
  prec.loc = NULL,
  loggam.shape.loc = NULL,
  loggam.inv.scale.loc = NULL,
  verbose.loc = FALSE,
  nthreads = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc.node.inla.glm_+3A_child.loc">child.loc</code></td>
<td>
<p>index of current child node.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_dag.m.loc">dag.m.loc</code></td>
<td>
<p>dag as matrix.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_data.df.loc">data.df.loc</code></td>
<td>
<p>data df,</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_data.dists.loc">data.dists.loc</code></td>
<td>
<p>list of distributions.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_ntrials.loc">ntrials.loc</code></td>
<td>
<p><code>rep(1,dim(data.df)[1])</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_exposure.loc">exposure.loc</code></td>
<td>
<p><code>rep(1,dim(data.df)[1])</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_compute.fixed.loc">compute.fixed.loc</code></td>
<td>
<p>TRUE.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_mean.intercept.loc">mean.intercept.loc</code></td>
<td>
<p>the prior mean for all the Gaussian additive terms for each node. INLA argument <code>control.fixed=list(mean.intercept=...)</code> and <code>control.fixed=list(mean=...)</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_prec.intercept.loc">prec.intercept.loc</code></td>
<td>
<p>the prior precision for all the Gaussian additive term for each node. INLA argument <code>control.fixed=list(prec.intercept=...)</code> and <code>control.fixed=list(prec=...)</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_mean.loc">mean.loc</code></td>
<td>
<p>the prior mean for all the Gaussian additive terms for each node. INLA argument <code>control.fixed=list(mean.intercept=...)</code> and <code>control.fixed=list(mean=...)</code>. Same as <code>mean.intercept.loc</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_prec.loc">prec.loc</code></td>
<td>
<p>the prior precision for all the Gaussian additive term for each node. INLA argument <code>control.fixed=list(prec.intercept=...)</code> and <code>control.fixed=list(prec=...)</code>. Same as <code>prec.intercept.loc</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_loggam.shape.loc">loggam.shape.loc</code></td>
<td>
<p>the shape parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_loggam.inv.scale.loc">loggam.inv.scale.loc</code></td>
<td>
<p>the inverse scale parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_verbose.loc">verbose.loc</code></td>
<td>
<p>FALSE to not print additional output.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glm_+3A_nthreads">nthreads</code></td>
<td>
<p>number of threads to use for INLA. Default is <code>fit.control[["ncores"]]</code> or <code>build.control[["ncores"]]</code> which is the number of cores specified in <code>control</code> and defaults to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If INLA failed, FALSE or an error is returned. Otherwise, the direct output from INLA is returned.
</p>


<h3>See Also</h3>

<p>Other Bayes: 
<code><a href="#topic+buildScoreCache">buildScoreCache</a>()</code>,
<code><a href="#topic+calc.node.inla.glmm">calc.node.inla.glmm</a>()</code>,
<code><a href="#topic+fitAbn">fitAbn</a>()</code>,
<code><a href="#topic+getmarginals">getmarginals</a>()</code>
</p>

<hr>
<h2 id='calc.node.inla.glmm'>Fit a given regression using INLA</h2><span id='topic+calc.node.inla.glmm'></span>

<h3>Description</h3>

<p>Internal wrapper to INLA and are called from <code>fitAbn.bayes</code> and <code>buildScoreCache.bayes</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.node.inla.glmm(
  child.loc = NULL,
  dag.m.loc = NULL,
  data.df.loc = NULL,
  data.dists.loc = NULL,
  ntrials.loc = NULL,
  exposure.loc = NULL,
  compute.fixed.loc = NULL,
  mean.intercept.loc = NULL,
  prec.intercept.loc = NULL,
  mean.loc = NULL,
  prec.loc = NULL,
  loggam.shape.loc = NULL,
  loggam.inv.scale.loc = NULL,
  verbose.loc = FALSE,
  nthreads = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc.node.inla.glmm_+3A_child.loc">child.loc</code></td>
<td>
<p>index of current child node.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_dag.m.loc">dag.m.loc</code></td>
<td>
<p>dag as matrix.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_data.df.loc">data.df.loc</code></td>
<td>
<p>data df,</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_data.dists.loc">data.dists.loc</code></td>
<td>
<p>list of distributions.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_ntrials.loc">ntrials.loc</code></td>
<td>
<p><code>rep(1,dim(data.df)[1])</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_exposure.loc">exposure.loc</code></td>
<td>
<p><code>rep(1,dim(data.df)[1])</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_compute.fixed.loc">compute.fixed.loc</code></td>
<td>
<p>TRUE.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_mean.intercept.loc">mean.intercept.loc</code></td>
<td>
<p>the prior mean for all the Gaussian additive terms for each node. INLA argument <code>control.fixed=list(mean.intercept=...)</code> and <code>control.fixed=list(mean=...)</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_prec.intercept.loc">prec.intercept.loc</code></td>
<td>
<p>the prior precision for all the Gaussian additive term for each node. INLA argument <code>control.fixed=list(prec.intercept=...)</code> and <code>control.fixed=list(prec=...)</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_mean.loc">mean.loc</code></td>
<td>
<p>the prior mean for all the Gaussian additive terms for each node. INLA argument <code>control.fixed=list(mean.intercept=...)</code> and <code>control.fixed=list(mean=...)</code>. Same as <code>mean.intercept.loc</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_prec.loc">prec.loc</code></td>
<td>
<p>the prior precision for all the Gaussian additive term for each node. INLA argument <code>control.fixed=list(prec.intercept=...)</code> and <code>control.fixed=list(prec=...)</code>. Same as <code>prec.intercept.loc</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_loggam.shape.loc">loggam.shape.loc</code></td>
<td>
<p>the shape parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_loggam.inv.scale.loc">loggam.inv.scale.loc</code></td>
<td>
<p>the inverse scale parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_verbose.loc">verbose.loc</code></td>
<td>
<p>FALSE to not print additional output.</p>
</td></tr>
<tr><td><code id="calc.node.inla.glmm_+3A_nthreads">nthreads</code></td>
<td>
<p>number of threads to use for INLA. Default is <code>fit.control[["ncores"]]</code> or <code>build.control[["ncores"]]</code> which is the number of cores specified in <code>control</code> and defaults to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If INLA failed, FALSE or an error is returned. Otherwise, the direct output from INLA is returned.
</p>


<h3>See Also</h3>

<p>Other Bayes: 
<code><a href="#topic+buildScoreCache">buildScoreCache</a>()</code>,
<code><a href="#topic+calc.node.inla.glm">calc.node.inla.glm</a>()</code>,
<code><a href="#topic+fitAbn">fitAbn</a>()</code>,
<code><a href="#topic+getmarginals">getmarginals</a>()</code>
</p>

<hr>
<h2 id='categorical_bugs'>Bugs code for Categorical response</h2><span id='topic+categorical_bugs'></span><span id='topic+categorical_bugsGroup'></span>

<h3>Description</h3>

<p>Bugs code for Categorical response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categorical_bugs(
  nodename,
  nodesCatIdx,
  parentnames,
  nodesintercepts,
  parentcoefs
)

categorical_bugsGroup(
  nodename,
  nodesCatIdx,
  nodesintercepts,
  parentnames,
  parentcoefs,
  sigma,
  sigma_alpha
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="categorical_bugs_+3A_nodename">nodename</code></td>
<td>
<p>character string of response variable name.</p>
</td></tr>
<tr><td><code id="categorical_bugs_+3A_nodescatidx">nodesCatIdx</code></td>
<td>
<p>integer vector of length <code class="reqn">|K-1|</code> and starting at <code class="reqn">k+1</code> (see Examples).</p>
</td></tr>
<tr><td><code id="categorical_bugs_+3A_parentnames">parentnames</code></td>
<td>
<p>single character string (for one parent) or vector of characters (for multiple parent nodes) with parent node (predictor variables) names.</p>
</td></tr>
<tr><td><code id="categorical_bugs_+3A_nodesintercepts">nodesintercepts</code></td>
<td>
<p>overall mean of response. Parameter from fixed-effects intercept.</p>
</td></tr>
<tr><td><code id="categorical_bugs_+3A_parentcoefs">parentcoefs</code></td>
<td>
<p>overall slope for each predictor (parent node) variable (fixed-effects).</p>
</td></tr>
<tr><td><code id="categorical_bugs_+3A_sigma">sigma</code></td>
<td>
<p>within-group variance. Parameter from random-effects residual.</p>
</td></tr>
<tr><td><code id="categorical_bugs_+3A_sigma_alpha">sigma_alpha</code></td>
<td>
<p>between-group variance-covariance matrix. Parameters from random-effects intercept.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output of <code><a href="#topic+fitAbn">fitAbn</a></code> with <code>method = "mle"</code> is based on
the output of logistic regression models fit with either <code><a href="stats.html#topic+lm">lm</a></code>,
<code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="lme4.html#topic+glmer">glmer</a></code>, <code><a href="nnet.html#topic+multinom">multinom</a></code>,
<code><a href="mclogit.html#topic+mblogit">mblogit</a></code> or internal <code>irls</code> methods.
They all use the first factor level as reference level.
Therefore, <code>nodesCatIdx</code> starts with index <code class="reqn">2</code> and not <code class="reqn">1</code>.
<code>nodesintercepts</code> and <code>parentcoefs</code> refer to the values of
<code>(Intercept)</code> and <code>Estimate</code> of the respective model output.
Predictor names build the keys in <code>parentcoef</code>.
</p>


<h3>Value</h3>

<p>Bugs model returned as stdout.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>categorical_bugsGroup()</code>: Bugs code for Categorical response with varying intercept
</p>
</li></ul>


<h3>See Also</h3>

<p><a href="#topic+makebugs">makebugs</a> <a href="#topic+simulateAbn">simulateAbn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A -&gt; B
# Where B is a categorical variable with 4 levels.
categorical_bugs(nodename = "b",
                 nodesCatIdx = c(2, 3, 4),
                 parentnames = "a",
                 nodesintercepts = c(2.188650, 3.133928, 3.138531),
                 parentcoefs = list("a"=c(a=1.686432, a=3.134161, a=5.052104)))
</code></pre>

<hr>
<h2 id='Cfunctions'>Documentation of C Functions</h2><span id='topic+Cfunctions'></span><span id='topic+buildcachematrix'></span><span id='topic+checkforcycles'></span><span id='topic+fit_single_node'></span><span id='topic+fitabn_marginals'></span><span id='topic+mostprobable_C'></span><span id='topic+searchhill'></span>

<h3>Description</h3>

<p>This is mainly to circumvent issues in R CMD check.
</p>


<h3>Value</h3>

<p>nothing.
</p>

<hr>
<h2 id='check.valid.buildControls'>Simple check on the control parameters</h2><span id='topic+check.valid.buildControls'></span>

<h3>Description</h3>

<p>Simple check on the control parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.valid.buildControls(control, method = "bayes", verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.valid.buildControls_+3A_control">control</code></td>
<td>
<p>list of control arguments with new parameters supplied to <code><a href="#topic+buildScoreCache">buildScoreCache</a></code> or <code><a href="#topic+fitAbn">fitAbn</a></code>.</p>
</td></tr>
<tr><td><code id="check.valid.buildControls_+3A_method">method</code></td>
<td>
<p>&quot;bayes&quot; or &quot;mle&quot; strategy from argument <code>method=...</code> in <code><a href="#topic+buildScoreCache">buildScoreCache</a></code> or <code><a href="#topic+fitAbn">fitAbn</a></code>. Defaults to &quot;bayes&quot;.</p>
</td></tr>
<tr><td><code id="check.valid.buildControls_+3A_verbose">verbose</code></td>
<td>
<p>when TRUE additional information is printed. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with all control arguments with respect to the method but with new values.
</p>

<hr>
<h2 id='check.valid.dag'>Set of simple commonsense validity checks on the directed acyclic graph definition matrix</h2><span id='topic+check.valid.dag'></span>

<h3>Description</h3>

<p>Set of simple commonsense validity checks on the directed acyclic graph definition matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.valid.dag(
  dag = NULL,
  data.df = NULL,
  is.ban.matrix = FALSE,
  group.var = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.valid.dag_+3A_dag">dag</code></td>
<td>
<p>Named square matrix or a formula statement specifying a directed acyclic graph.
If NULL an empty network is assumed.</p>
</td></tr>
<tr><td><code id="check.valid.dag_+3A_data.df">data.df</code></td>
<td>
<p>data frame with names corresponding to variable/node names.</p>
</td></tr>
<tr><td><code id="check.valid.dag_+3A_is.ban.matrix">is.ban.matrix</code></td>
<td>
<p>Diagonals and cycles are not checked for ban-matrices. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="check.valid.dag_+3A_group.var">group.var</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dag as named square matrix
</p>

<hr>
<h2 id='check.valid.data'>Set of simple commonsense validity checks on the data.df and data.dists arguments</h2><span id='topic+check.valid.data'></span>

<h3>Description</h3>

<p>Set of simple commonsense validity checks on the data.df and data.dists arguments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.valid.data(data.df = NULL, data.dists = NULL, group.var = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.valid.data_+3A_data.df">data.df</code></td>
<td>
<p>data frame with names corresponding to variable/node names.</p>
</td></tr>
<tr><td><code id="check.valid.data_+3A_data.dists">data.dists</code></td>
<td>
<p>list specifying each columns distribution type. Names correspond to column names and values must be one of &quot;gaussian&quot;, &quot;binomial&quot;, &quot;poisson&quot;, &quot;multinomial&quot;.</p>
</td></tr>
<tr><td><code id="check.valid.data_+3A_group.var">group.var</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of indexes for each distribution type
</p>
<p>a list of the indexes for each distribution type
</p>

<hr>
<h2 id='check.valid.fitControls'>Simple check on the control parameters</h2><span id='topic+check.valid.fitControls'></span>

<h3>Description</h3>

<p>Simple check on the control parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.valid.fitControls(control, method = "bayes", verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.valid.fitControls_+3A_control">control</code></td>
<td>
<p>list of control arguments with new parameters supplied to <code><a href="#topic+buildScoreCache">buildScoreCache</a></code> or <code><a href="#topic+fitAbn">fitAbn</a></code>.</p>
</td></tr>
<tr><td><code id="check.valid.fitControls_+3A_method">method</code></td>
<td>
<p>&quot;bayes&quot; or &quot;mle&quot; strategy from argument <code>method=...</code> in <code><a href="#topic+buildScoreCache">buildScoreCache</a></code> or <code><a href="#topic+fitAbn">fitAbn</a></code>. Defaults to &quot;bayes&quot;.</p>
</td></tr>
<tr><td><code id="check.valid.fitControls_+3A_verbose">verbose</code></td>
<td>
<p>when TRUE additional information is printed. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with all control arguments with respect to the method but with new values.
</p>

<hr>
<h2 id='check.valid.groups'>Simple check on the grouping variable</h2><span id='topic+check.valid.groups'></span>

<h3>Description</h3>

<p>Simple check on the grouping variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.valid.groups(
  group.var = NULL,
  data.df = NULL,
  cor.vars = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.valid.groups_+3A_group.var">group.var</code></td>
<td>
<p>Name of grouping variable.</p>
</td></tr>
<tr><td><code id="check.valid.groups_+3A_data.df">data.df</code></td>
<td>
<p>data frame of all variables including the variable specified in <code>group.var</code> as factor.</p>
</td></tr>
<tr><td><code id="check.valid.groups_+3A_cor.vars">cor.vars</code></td>
<td>
<p>Name(s) of variables to which the grouping should be applied to.</p>
</td></tr>
<tr><td><code id="check.valid.groups_+3A_verbose">verbose</code></td>
<td>
<p>when TRUE additional information is printed. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with data.df, indexes of variables to which the grouping should be applied to and the associated group for each observation as integer.
</p>

<hr>
<h2 id='check.valid.parents'>Set of simple checks on the given parent limits</h2><span id='topic+check.valid.parents'></span>

<h3>Description</h3>

<p>Set of simple checks on the given parent limits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.valid.parents(data.df = NULL, max.parents = NULL, group.var = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.valid.parents_+3A_data.df">data.df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="check.valid.parents_+3A_max.parents">max.parents</code></td>
<td>
<p>single integer for one overall max parent limit.
A list with names corresponding to variable/column names of <code>data.df</code> and individual parent limits.
NULL for no parent limit restriction(s).</p>
</td></tr>
<tr><td><code id="check.valid.parents_+3A_group.var">group.var</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of max number of parents per variable
</p>

<hr>
<h2 id='check.which.valid.nodes'>Set of simple checks on the list given as parent limits</h2><span id='topic+check.which.valid.nodes'></span>

<h3>Description</h3>

<p>Set of simple checks on the list given as parent limits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.which.valid.nodes(data.df = NULL, which.nodes = NULL, group.var = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.which.valid.nodes_+3A_data.df">data.df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="check.which.valid.nodes_+3A_which.nodes">which.nodes</code></td>
<td>
<p>a vector giving the column indices of the variables to be included, if ignored all variables are included.</p>
</td></tr>
<tr><td><code id="check.which.valid.nodes_+3A_group.var">group.var</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
</table>


<h3>Value</h3>

<p>integer vector of column indexes of valid nodes in data.df
</p>

<hr>
<h2 id='coef.abnFit'>Print coefficients of objects of class <code>abnFit</code></h2><span id='topic+coef.abnFit'></span>

<h3>Description</h3>

<p>Print coefficients of objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
coef(object, digits = 3L, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.abnFit_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="coef.abnFit_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="coef.abnFit_+3A_verbose">verbose</code></td>
<td>
<p>print additional output.</p>
</td></tr>
<tr><td><code id="coef.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the coefficients of the fitted model.
</p>

<hr>
<h2 id='compareDag'>Compare two DAGs or EGs</h2><span id='topic+compareDag'></span>

<h3>Description</h3>

<p>Function that returns multiple graph metrics to compare two DAGs
or essential graphs, known as confusion matrix or error matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareDag(ref, test, node.names = NULL, checkDAG = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareDag_+3A_ref">ref</code></td>
<td>
<p>a matrix or a formula statement (see details for format) defining
the reference network structure, a directed acyclic graph (DAG).
Note that row names must be set or given in <code>node.names</code>
if the DAG is given via a formula statement.</p>
</td></tr>
<tr><td><code id="compareDag_+3A_test">test</code></td>
<td>
<p>a matrix or a formula statement (see details for format) defining
the test network structure, a directed acyclic graph (DAG).
Note that row names must be set or given in <code>node.names</code>
if the DAG is given via a formula statement.</p>
</td></tr>
<tr><td><code id="compareDag_+3A_node.names">node.names</code></td>
<td>
<p>a vector of names if the DAGs are given via formula, see details.</p>
</td></tr>
<tr><td><code id="compareDag_+3A_checkdag">checkDAG</code></td>
<td>
<p>should the DAGs be tested for DAGs (default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This R function returns standard Directed Acyclic Graph comparison metrics.
In statistical classification, those metrics are known as a
confusion matrix or error matrix.
</p>
<p>Those metrics allows visualization of the difference between different DAGs.
In the case where comparing TRUTH to learned structure or two learned structures,
those metrics allow the user to estimate the performance of the learning algorithm.
In order to compute the metrics, a contingency table is computed of a
pondered difference of the adjacency matrices od the two graphs.
</p>
<p>The <code>ref</code> or <code>test</code> can be provided using a formula statement
(similar to GLM input).
A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>.
The formula statement have to start with <code>~</code>.
In this example, node1 has two parents (parent1 and parent2).
node2 and node3 have the same parent3.
The parents names have to exactly match those given in <code>node.names</code>.
<code>:</code> is the separtor between either children or parents,
<code>|</code> separates children (left side) and parents (right side),
<code>+</code> separates terms, <code>.</code> replaces all the variables in <code>node.names</code>.
</p>
<p>To test for essential graphs (or graphs) in general, the test for DAG
need to be switched off <code>checkDAG=FALSE</code>.
The function <code>compareEG()</code> is a wrapper to <code>compareDag(, checkDAG=FALSE)</code>.
</p>


<h3>Value</h3>


<dl>
<dt><code>TP</code></dt><dd><p>True Positive</p>
</dd>
<dt><code>TN</code></dt><dd><p>True Negative</p>
</dd>
<dt><code>FP</code></dt><dd><p>False Positive</p>
</dd>
<dt><code>FN</code></dt><dd><p>False Negative</p>
</dd>
<dt><code>CP</code></dt><dd><p>Condition Positive (ref)</p>
</dd>
<dt><code>CN</code></dt><dd><p>Condition Negative (ref)</p>
</dd>
<dt><code>PCP</code></dt><dd><p>Predicted Condition Positive (test)</p>
</dd>
<dt><code>PCN</code></dt><dd><p>Predicted Condition Negative (test)</p>
</dd>
<dt><code>True Positive Rate</code></dt><dd><p style="text-align: center;"><code class="reqn">=\frac{\sum TP}{\sum CP}</code>
</p>
</dd>
<dt><code>False Positive Rate</code></dt><dd><p style="text-align: center;"><code class="reqn">=\frac{\sum FP}{\sum CN}</code>
</p>
</dd>
<dt><code>Accuracy</code></dt><dd><p style="text-align: center;"><code class="reqn">=\frac{\sum TP + \sum TN}{Total population}</code>
</p>
</dd>
<dt><code>G-measure</code></dt><dd><p style="text-align: center;"><code class="reqn">\sqrt {{\frac {TP}{TP+FP}}\cdot {\frac {TP}{TP+FN}}}</code>
</p>
</dd>
<dt><code>F1-Score</code></dt><dd><p style="text-align: center;"><code class="reqn">\frac{2 \sum TP}{2 \sum TP + \sum FN + \sum FP}</code>
</p>
</dd>
<dt><code>Positive Predictive Value</code></dt><dd><p style="text-align: center;"><code class="reqn">\frac{\sum TP}{\sum PCP}</code>
</p>
</dd>
<dt><code>False Ommision Rate</code></dt><dd><p style="text-align: center;"><code class="reqn">\frac{\sum FN}{\sum PCN}</code>
</p>
</dd>
<dt><code>Hamming-Distance</code></dt><dd><p>Number of changes needed to match the matrices.</p>
</dd>
</dl>



<h3>References</h3>

<p>Sammut, Claude, and Geoffrey I. Webb. (2017). Encyclopedia of machine learning and data mining. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.m &lt;- matrix(data = c(0,1,0,
                          0,0,0,
                          1,0,0), nrow = 3, ncol = 3)
ref.m &lt;- matrix(data = c(0,0,0,
                         1,0,0,
                         1,0,0), nrow = 3, ncol = 3)

colnames(test.m) &lt;- rownames(test.m) &lt;- colnames(ref.m) &lt;- colnames(ref.m) &lt;- c("a", "b", "c")

unlist(compareDag(ref = ref.m, test = test.m))
</code></pre>

<hr>
<h2 id='compareEG'>Compare two DAGs or EGs</h2><span id='topic+compareEG'></span>

<h3>Description</h3>

<p>Function that returns multiple graph metrics to compare two DAGs
or essential graphs, known as confusion matrix or error matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareEG(ref, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareEG_+3A_ref">ref</code></td>
<td>
<p>a matrix or a formula statement (see details for format) defining
the reference network structure, a directed acyclic graph (DAG).
Note that row names must be set or given in <code>node.names</code>
if the DAG is given via a formula statement.</p>
</td></tr>
<tr><td><code id="compareEG_+3A_test">test</code></td>
<td>
<p>a matrix or a formula statement (see details for format) defining
the test network structure, a directed acyclic graph (DAG).
Note that row names must be set or given in <code>node.names</code>
if the DAG is given via a formula statement.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This R function returns standard Directed Acyclic Graph comparison metrics.
In statistical classification, those metrics are known as a
confusion matrix or error matrix.
</p>
<p>Those metrics allows visualization of the difference between different DAGs.
In the case where comparing TRUTH to learned structure or two learned structures,
those metrics allow the user to estimate the performance of the learning algorithm.
In order to compute the metrics, a contingency table is computed of a
pondered difference of the adjacency matrices od the two graphs.
</p>
<p>The <code>ref</code> or <code>test</code> can be provided using a formula statement
(similar to GLM input).
A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>.
The formula statement have to start with <code>~</code>.
In this example, node1 has two parents (parent1 and parent2).
node2 and node3 have the same parent3.
The parents names have to exactly match those given in <code>node.names</code>.
<code>:</code> is the separtor between either children or parents,
<code>|</code> separates children (left side) and parents (right side),
<code>+</code> separates terms, <code>.</code> replaces all the variables in <code>node.names</code>.
</p>
<p>To test for essential graphs (or graphs) in general, the test for DAG
need to be switched off <code>checkDAG=FALSE</code>.
The function <code>compareEG()</code> is a wrapper to <code>compareDag(, checkDAG=FALSE)</code>.
</p>


<h3>Value</h3>


<dl>
<dt><code>TP</code></dt><dd><p>True Positive</p>
</dd>
<dt><code>TN</code></dt><dd><p>True Negative</p>
</dd>
<dt><code>FP</code></dt><dd><p>False Positive</p>
</dd>
<dt><code>FN</code></dt><dd><p>False Negative</p>
</dd>
<dt><code>CP</code></dt><dd><p>Condition Positive (ref)</p>
</dd>
<dt><code>CN</code></dt><dd><p>Condition Negative (ref)</p>
</dd>
<dt><code>PCP</code></dt><dd><p>Predicted Condition Positive (test)</p>
</dd>
<dt><code>PCN</code></dt><dd><p>Predicted Condition Negative (test)</p>
</dd>
<dt><code>True Positive Rate</code></dt><dd><p style="text-align: center;"><code class="reqn">=\frac{\sum TP}{\sum CP}</code>
</p>
</dd>
<dt><code>False Positive Rate</code></dt><dd><p style="text-align: center;"><code class="reqn">=\frac{\sum FP}{\sum CN}</code>
</p>
</dd>
<dt><code>Accuracy</code></dt><dd><p style="text-align: center;"><code class="reqn">=\frac{\sum TP + \sum TN}{Total population}</code>
</p>
</dd>
<dt><code>G-measure</code></dt><dd><p style="text-align: center;"><code class="reqn">\sqrt {{\frac {TP}{TP+FP}}\cdot {\frac {TP}{TP+FN}}}</code>
</p>
</dd>
<dt><code>F1-Score</code></dt><dd><p style="text-align: center;"><code class="reqn">\frac{2 \sum TP}{2 \sum TP + \sum FN + \sum FP}</code>
</p>
</dd>
<dt><code>Positive Predictive Value</code></dt><dd><p style="text-align: center;"><code class="reqn">\frac{\sum TP}{\sum PCP}</code>
</p>
</dd>
<dt><code>False Ommision Rate</code></dt><dd><p style="text-align: center;"><code class="reqn">\frac{\sum FN}{\sum PCN}</code>
</p>
</dd>
<dt><code>Hamming-Distance</code></dt><dd><p>Number of changes needed to match the matrices.</p>
</dd>
</dl>



<h3>References</h3>

<p>Sammut, Claude, and Geoffrey I. Webb. (2017). Encyclopedia of machine learning and data mining. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test.m &lt;- matrix(data = c(0,1,0,
                          0,0,0,
                          1,0,0), nrow = 3, ncol = 3)
ref.m &lt;- matrix(data = c(0,0,0,
                         1,0,0,
                         1,0,0), nrow = 3, ncol = 3)

colnames(test.m) &lt;- rownames(test.m) &lt;- colnames(ref.m) &lt;- colnames(ref.m) &lt;- c("a", "b", "c")

unlist(compareDag(ref = ref.m, test = test.m))
</code></pre>

<hr>
<h2 id='createAbnDag'>Make DAG of class &quot;abnDag&quot;</h2><span id='topic+createAbnDag'></span>

<h3>Description</h3>

<p>Make DAG of class &quot;abnDag&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createAbnDag( dag, data.df = NULL, data.dists = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createAbnDag_+3A_dag">dag</code></td>
<td>
<p>a matrix or a formula specifying a DAG, see &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="createAbnDag_+3A_data.df">data.df</code></td>
<td>
<p>named dataframe.</p>
</td></tr>
<tr><td><code id="createAbnDag_+3A_data.dists">data.dists</code></td>
<td>
<p>named list giving the distribution for each node in the network. If not provided it will be sample and returned.</p>
</td></tr>
<tr><td><code id="createAbnDag_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An object of class <code>class(abnDag)</code> contains a named matrix describing the DAG and possibly additional objects such as the associated distributions of the nodes.
If the dag is specified with a formula, either <code>data.df</code> or <code>data.dists</code> is required with the <code>.</code> quantifier.
If the dag is specified with an unnamed matrix and both <code>data.df</code> and <code>data.dists</code> are missing,  lower-case letters of the Roman alphabet are used for the node names.
</p>


<h3>Value</h3>

<p>abnDag object as list of dag, data.df, data.dists.
</p>
<p>Create a legitimate DAGs
</p>
<p>Create a legitimate DAG in the abn format.
</p>
<p>An object of class <code>abnDag</code> containing a named matrix and a named list giving the distribution for each node.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dagFromFormula &lt;- createAbnDag(dag = ~a+b|a,
                              data.df = data.frame("a"=1, "b"=1),
                              data.dists = list(a="binomial", b="gaussian"))
dagFromMatrix &lt;- createAbnDag(dag = matrix(c(0,1,0,0), 2, 2),
                              data.df = data.frame("a"=1, "b"=1),
                              data.dists = list(a="binomial", b="gaussian"))
plot(dagFromMatrix)

</code></pre>

<hr>
<h2 id='discretization'>Discretization of a Possibly Continuous Data Frame of Random Variables based on their distribution</h2><span id='topic+discretization'></span>

<h3>Description</h3>

<p>This function discretizes a data frame of possibly continuous random variables
through rules for discretization. The discretization algorithms are unsupervised
and univariate. See details for the complete list of discretization rules (the number of state of each
random variable could also be provided).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discretization(data.df = NULL,
                      data.dists = NULL,
                      discretization.method = "sturges",
                      nb.states = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discretization_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data to discretize, binary and multinomial variables must be declared as factors, others as a numeric vector. The data frame must be named.</p>
</td></tr>
<tr><td><code id="discretization_+3A_data.dists">data.dists</code></td>
<td>
<p>a named list giving the distribution for each node in the network.</p>
</td></tr>
<tr><td><code id="discretization_+3A_discretization.method">discretization.method</code></td>
<td>
<p>a character vector giving the discretization method to use; see details. If a number is provided, the variable will be discretized by equal binning.</p>
</td></tr>
<tr><td><code id="discretization_+3A_nb.states">nb.states</code></td>
<td>
<p>logical variable to select the output. If set to <code>TRUE</code> a list with the discretized data frame and the number of state of each variable is returned. If set to FALSE only the discretized data frame is returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fd</code> Freedman Diaconis rule. <code>IQR()</code> stands for interquartile range.
The number of bins is given by </p>
<p style="text-align: center;"><code class="reqn">\frac{range(x) * n^{1/3}}{2 * IQR(x)}</code>
</p>

<p>The Freedman Diaconis rule is known to be less sensitive than the Scott's rule to outlier.
</p>
<p><code>doane</code> Doane's rule.
The number of bins is given by </p>
<p style="text-align: center;"><code class="reqn">1 + \log_{2}{n} + \log_{2}{1+\frac{|g|}{\sigma_{g}}}</code>
</p>

<p>This is a modification of Sturges' formula, which attempts to improve its performance with non-normal data.
</p>
<p><code>sqrt</code> The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">\sqrt(n)</code>
</p>

<p><code>cencov</code> Cencov's rule.
The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">n^{1/3}</code>
</p>

<p><code>rice</code> Rice' rule.
The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">2 n^{1/3}</code>
</p>

<p><code>terrell-scott</code> Terrell-Scott's rule.
The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">(2 n)^{1/3}</code>
</p>

<p>It is known that Cencov, Rice, and Terrell-Scott rules over-estimates k, compared to other rules due to its simplicity.
</p>
<p><code>sturges</code> Sturges's rule.
The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">1 + \log_2(n)</code>
</p>

<p><code>scott</code> Scott's rule.
The number of bins is given by: </p>
<p style="text-align: center;"><code class="reqn">range(x) / \sigma(x) n^{-1/3}</code>
</p>



<h3>Value</h3>

<p>The discretized data frame or a list containing the table of
counts for each bin the discretized data frame.
</p>
<p>table of counts for each bin of the discretized data frame.
</p>


<h3>References</h3>

<p>Garcia, S., et al.  (2013). A survey of discretization techniques: Taxonomy and empirical analysis in supervised learning. <em>IEEE Transactions on Knowledge and Data Engineering</em>, 25.4, 734-750.
</p>
<p>Cebeci, Z. and Yildiz, F. (2017). Unsupervised Discretization of Continuous Variables in a Chicken Egg Quality Traits Dataset. <em>Turkish Journal of Agriculture-Food Science and Technology</em>, 5.4, 315-320.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate random variable
rv &lt;- rnorm(n = 100, mean = 5, sd = 2)
dist &lt;- list("gaussian")
names(dist) &lt;- c("rv")

## Compute the entropy through discretization
entropyData(freqs.table = discretization(data.df = rv, data.dists = dist,
discretization.method = "sturges", nb.states = FALSE))
</code></pre>

<hr>
<h2 id='entropyData'>Computes an Empirical Estimation of the Entropy from a Table of Counts</h2><span id='topic+entropyData'></span>

<h3>Description</h3>

<p>This function empirically estimates the Shannon entropy from a table of counts using the observed frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entropyData(freqs.table)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="entropyData_+3A_freqs.table">freqs.table</code></td>
<td>
<p>a table of counts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The general concept of entropy is defined for probability distributions.
The <code>entropyData()</code> function estimates empirical entropy from data.
The probability is estimated from data using frequency tables.
Then the estimates are plug-in in the definition of the entropy to return
the so-called empirical entropy. A common known problem of empirical entropy
is that the estimations are biased due to the sampling noise.
It is also known that the bias will decrease as the sample size increases.
</p>


<h3>Value</h3>

<p>Shannon's entropy estimate on natural logarithm scale.
</p>
<p>integer
</p>


<h3>References</h3>

<p>Cover, Thomas M, and Joy A Thomas. (2012). &quot;Elements of Information Theory&quot;. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+discretization">discretization</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate random variable
rv &lt;- rnorm(n = 100, mean = 5, sd = 2)
dist &lt;- list("gaussian")
names(dist) &lt;- c("rv")

## Compute the entropy through discretization
entropyData(freqs.table = discretization(data.df = rv, data.dists = dist,
discretization.method = "sturges", nb.states = FALSE))
</code></pre>

<hr>
<h2 id='essentialGraph'>Construct the essential graph</h2><span id='topic+essentialGraph'></span>

<h3>Description</h3>

<p>Constructs different versions of the essential graph from a given DAG.
External function that computes essential graph of a dag Minimal PDAG:
The only directed edges are those who participate in v-structure Completed PDAG:
very directed edge corresponds to a compelled edge, and every undirected
edge corresponds to a reversible edge
</p>


<h3>Usage</h3>

<pre><code class='language-R'>essentialGraph(dag, node.names = NULL, PDAG = "minimal")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="essentialGraph_+3A_dag">dag</code></td>
<td>
<p>a matrix or a formula statement (see &lsquo;Details&rsquo; for format)
defining the network structure, a directed acyclic graph (DAG).</p>
</td></tr>
<tr><td><code id="essentialGraph_+3A_node.names">node.names</code></td>
<td>
<p>a vector of names if the DAG is given via formula, see &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="essentialGraph_+3A_pdag">PDAG</code></td>
<td>
<p>a character value that can be: minimal or complete, see &lsquo;Details&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns an essential graph from a DAG,
aka acyclic partially directed graph (PDAG).
This can be useful if the learning procedure is defined up to a Markov class
of equivalence.
A minimal PDAG is defined as only directed edges are those who participate
in v-structure. Whereas the completed PDAG: every directed edge corresponds
to a compelled edge, and every undirected edge corresponds to a reversible edge.
</p>
<p>The <code>dag</code> can be provided using a formula statement (similar to glm).
A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>.
The formula statement have to start with <code>~</code>.
In this example, node1 has two parents (parent1 and parent2).
node2 and node3 have the same parent3.
The parents names have to exactly match those given in <code>node.names</code>.
<code>:</code> is the separator between either children or parents,
<code>|</code> separates children (left side) and parents (right side),
<code>+</code> separates terms, <code>.</code> replaces all the variables in <code>node.names</code>.
</p>


<h3>Value</h3>

<p>A matrix giving the PDAG.
</p>


<h3>References</h3>

<p>West, D. B. (2001). Introduction to Graph Theory. Vol. 2. Upper Saddle River: Prentice Hall.
Chickering, D. M. (2013) A Transformational Characterization of Equivalent Bayesian Network Structures, arXiv:1302.4938.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dag &lt;- matrix(c(0,0,0, 1,0,0, 1,1,0), nrow = 3, ncol = 3)
dist &lt;- list(a="gaussian", b="gaussian", c="gaussian")
colnames(dag) &lt;- rownames(dag) &lt;- names(dist)

essentialGraph(dag)
</code></pre>

<hr>
<h2 id='eval.across.grid'>function to get marginal across an equal grid</h2><span id='topic+eval.across.grid'></span>

<h3>Description</h3>

<p>function to get marginal across an equal grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval.across.grid(mylist, n.grid, single)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eval.across.grid_+3A_mylist">mylist</code></td>
<td>
<p>list of matrices of two cols x, y</p>
</td></tr>
<tr><td><code id="eval.across.grid_+3A_n.grid">n.grid</code></td>
<td>
<p>grid size</p>
</td></tr>
<tr><td><code id="eval.across.grid_+3A_single">single</code></td>
<td>
<p>NULL or TRUE if only a single node and parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='ex0.dag.data'>Synthetic validation data set for use with abn library examples</h2><span id='topic+ex0.dag.data'></span>

<h3>Description</h3>

<p>300 observations simulated from a DAG with 10 binary variables, 10 Gaussian variables and 10 poisson variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex0.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame, binary variables are factors.
The relevant formulas are given below (note these do not give parameter
estimates just the form of the relationships, e.g. logit()=1 means a logit
link function and comprises of only an intercept term).
</p>

<dl>
<dt>b1</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b2</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b3</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b4</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b5</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b6</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b7</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b8</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b9</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>b10</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>g1</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g2</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g3</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g4</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g5</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g6</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g7</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g8</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g9</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>g10</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>p1</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p2</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p3</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p4</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p5</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p6</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p7</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p8</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p9</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>p10</dt><dd><p>poisson, log()=1 </p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## The dataset was (essentially) generated using the following code:
datasize &lt;- 300
tmp &lt;- c(rep("y", as.integer(datasize/2)), rep("n", as.integer(datasize/2)))
set.seed(1)

ex0.dag.data &lt;- data.frame(b1=sample(tmp, size=datasize, replace=TRUE),
                           b2=sample(tmp, size=datasize, replace=TRUE),
                           b3=sample(tmp, size=datasize, replace=TRUE),
                           b4=sample(tmp, size=datasize, replace=TRUE),
                           b5=sample(tmp, size=datasize, replace=TRUE),
                           b6=sample(tmp, size=datasize, replace=TRUE),
                           b7=sample(tmp, size=datasize, replace=TRUE),
                           b8=sample(tmp, size=datasize, replace=TRUE),
                           b9=sample(tmp, size=datasize, replace=TRUE),
                           b10=sample(tmp, size=datasize, replace=TRUE),
                           g1=rnorm(datasize, mean=0,sd=1),
                           g2=rnorm(datasize, mean=0,sd=1),
                           g3=rnorm(datasize, mean=0,sd=1),
                           g4=rnorm(datasize, mean=0,sd=1),
                           g5=rnorm(datasize, mean=0,sd=1),
                           g6=rnorm(datasize, mean=0,sd=1),
                           g7=rnorm(datasize, mean=0,sd=1),
                           g8=rnorm(datasize, mean=0,sd=1),
                           g9=rnorm(datasize, mean=0,sd=1),
                           g10=rnorm(datasize, mean=0,sd=1),
                           p1=rpois(datasize, lambda=10),
                           p2=rpois(datasize, lambda=10),
                           p3=rpois(datasize, lambda=10),
                           p4=rpois(datasize, lambda=10),
                           p5=rpois(datasize, lambda=10),
                           p6=rpois(datasize, lambda=10),
                           p7=rpois(datasize, lambda=10),
                           p8=rpois(datasize, lambda=10),
                           p9=rpois(datasize, lambda=10),
                           p10=rpois(datasize, lambda=10))

## End(Not run)
</code></pre>

<hr>
<h2 id='ex1.dag.data'>Synthetic validation data set for use with abn library examples</h2><span id='topic+ex1.dag.data'></span>

<h3>Description</h3>

<p>10000 observations simulated from a DAG with 10 variables from Poisson, Bernoulli and Gaussian distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex1.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame, binary variables are factors.
The relevant formulas are given below (note these do not give parameter
estimates just the form of the relationships, like in glm(),
e.g. logit()=1+p1 means a logit link function and comprises of an
intercept term and a term involving p1).
</p>

<dl>
<dt>b1</dt><dd><p>binary, logit()=1 </p>
</dd>
<dt>p1</dt><dd><p>poisson, log()=1 </p>
</dd>
<dt>g1</dt><dd><p>gaussian, identity()=1 </p>
</dd>
<dt>b2</dt><dd><p>binary, logit()=1</p>
</dd>
<dt>p2</dt><dd><p>poisson, log()=1+b1+p1 </p>
</dd>
<dt>b3</dt><dd><p>binary, logit()=1+b1+g1+b2 </p>
</dd>
<dt>g2</dt><dd><p>gaussian, identify()=1+p1+g1+b2 </p>
</dd>
<dt>b4</dt><dd><p>binary, logit()=1+g1+p2</p>
</dd>
<dt>b5</dt><dd><p>binary, logit()=1+g1+g2 </p>
</dd>
<dt>g3</dt><dd><p>gaussian, identity()=1+g1+b2 </p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## The data is one realisation from the the underlying DAG:
ex1.true.dag &lt;- matrix(data=c(
  0,0,0,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,
  1,1,0,0,0,0,0,0,0,0,
  1,0,1,1,0,0,0,0,0,0,
  0,1,1,1,0,0,0,0,0,0,
  0,0,1,0,1,0,0,0,0,0,
  0,0,1,0,0,0,1,0,0,0,
  0,0,1,1,0,0,0,0,0,0), ncol=10, byrow=TRUE)

colnames(ex1.true.dag) &lt;- rownames(ex1.true.dag) &lt;-
  c("b1","p1","g1","b2","p2","b3","g2","b4","b5","g3")
</code></pre>

<hr>
<h2 id='ex2.dag.data'>Synthetic validation data set for use with abn library examples</h2><span id='topic+ex2.dag.data'></span>

<h3>Description</h3>

<p>10000 observations simulated from a DAG with 18 variables three sets each from Poisson, Bernoulli and Gaussian distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex2.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame, binary variables are factors.
The relevant formulas are given below (note these do not give parameter
estimates just the form of the relationships, e.g. logit()=1
means a logit link function and comprises of only an intercept term).
</p>

<dl>
<dt>b1</dt><dd><p>binary,logit()=1+g1+b2+b3+p3+b4+g4+b5</p>
</dd>
<dt>g1</dt><dd><p>gaussian,identity()=1</p>
</dd>
<dt>p1</dt><dd><p>poisson,log()=1+g6</p>
</dd>
<dt>b2</dt><dd><p>binary,logit()=1+p3+b4+p6</p>
</dd>
<dt>g2</dt><dd><p>gaussian,identify()=1+b2</p>
</dd>
<dt>p2</dt><dd><p>poisson,log()=1+b2</p>
</dd>
<dt>b3</dt><dd><p>binary,logit()=1+g1+g2+p2+g3+p3+g4</p>
</dd>
<dt>g3</dt><dd><p>gaussian,identify()=1+g1+p3+b4</p>
</dd>
<dt>p3</dt><dd><p>poisson,log()=1</p>
</dd>
<dt>b4</dt><dd><p>binary,logit()=1+g1+p3+p5</p>
</dd>
<dt>g4</dt><dd><p>gaussian,identify()=1+b4;</p>
</dd>
<dt>p4</dt><dd><p>poisson,log()=1+g1+b2+g2+b5</p>
</dd>
<dt>b5</dt><dd><p>binary,logit()=1+b2+g2+b3+p3+g4</p>
</dd>
<dt>g5</dt><dd><p>gaussian,identify()=1</p>
</dd>
<dt>p5</dt><dd><p>poisson,log()=1+g1+g5+b6+g6</p>
</dd>
<dt>b6</dt><dd><p>binary,logit()=1</p>
</dd>
<dt>g6</dt><dd><p>gaussian,identify()=1</p>
</dd>
<dt>p6</dt><dd><p>poisson,log()=1+g5</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## The true underlying stochastic model has DAG - this data is a single realisation.
ex2.true.dag &lt;- matrix(data = c(
  0,1,0,1,0,0,1,0,1,1,1,0,1,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
  0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,
  0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
  0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
  0,1,0,0,1,1,0,1,1,0,1,0,0,0,0,0,0,0,
  0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
  0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,
  0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
  0,1,0,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,
  0,0,0,1,1,0,1,0,1,0,1,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
  0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,
  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
  0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
), ncol = 18, byrow = TRUE)

colnames(ex2.true.dag) &lt;- rownames(ex2.true.dag) &lt;- c("b1","g1","p1","b2",
                                                      "g2","p2","b3","g3",
                                                      "p3","b4","g4","p4",
                                                      "b5","g5","p5","b6",
                                                      "g6","p6")
</code></pre>

<hr>
<h2 id='ex3.dag.data'>Validation data set for use with abn library examples</h2><span id='topic+ex3.dag.data'></span>

<h3>Description</h3>

<p>1000 observations across with 13 binary variables and one grouping variable. Real (anonymised) data of unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex3.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame with 14 columns, where
<code>b1,b2,...,b13</code> are binary variables encoded as factors and
<code>group</code> is a factor with 100 factors  defining the sampling
groups (10 observations each).
</p>

<hr>
<h2 id='ex4.dag.data'>Valdiation data set for use with abn library examples</h2><span id='topic+ex4.dag.data'></span>

<h3>Description</h3>

<p>2000 observations across with 10 binary variables and one grouping variable. Real (anonymised) data of unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex4.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame with eleven columns:
<code>group</code> factor with 85 levels defining sampling groups;
<code>b1,...,b10</code> binary variables encoded as factors.
</p>

<hr>
<h2 id='ex5.dag.data'>Valdiation data set for use with abn library examples</h2><span id='topic+ex5.dag.data'></span>

<h3>Description</h3>

<p>434 observations across with 18 variables, 6 binary and 12 continuous, and one grouping variable. Real (anonymised) data of unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex5.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame with 19 columns: <code>b1,...,b6</code> binary
variables, encoded as factors;
<code>g1,...,g12</code> continuous variables. Finally, the column
<code>group</code> defines sampling groups (encoded as a factor as well).
</p>

<hr>
<h2 id='ex6.dag.data'>Valdiation data set for use with abn library examples</h2><span id='topic+ex6.dag.data'></span>

<h3>Description</h3>

<p>800 observations across with 8 variables, 1 count, 2 binary and 4 continuous, and 1 grouping variable. Real (anonymised) data of unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex6.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame with eight columns. Binary variables are factors
</p>

<dl>
<dt>p1</dt><dd><p>count</p>
</dd>
<dt>g1</dt><dd><p>continuous</p>
</dd>
<dt>g2</dt><dd><p>continuous</p>
</dd>
<dt>b1</dt><dd><p>binary</p>
</dd>
<dt>b2</dt><dd><p>binary</p>
</dd>
<dt>g3</dt><dd><p>continuous</p>
</dd>
<dt>g4</dt><dd><p>continuous</p>
</dd>
<dt>group</dt><dd><p>factor,defines sampling groups</p>
</dd>
</dl>


<hr>
<h2 id='ex7.dag.data'>Valdiation data set for use with abn library examples</h2><span id='topic+ex7.dag.data'></span>

<h3>Description</h3>

<p>10648 observations across with 3 variables, 2 binary and 1 grouping variable.
Real (anonymised) data of unknown structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ex7.dag.data
</code></pre>


<h3>Format</h3>

<p>A data frame, binary variables are factors
</p>

<dl>
<dt>b1</dt><dd><p>binary</p>
</dd>
<dt>b2</dt><dd><p>binary</p>
</dd>
<dt>group</dt><dd><p>factor, defines sampling groups</p>
</dd>
</dl>


<hr>
<h2 id='expit'>expit of proportions</h2><span id='topic+expit'></span>

<h3>Description</h3>

<p>See also the C implementation <code>?abn::expit_cpp()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expit(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expit_+3A_x">x</code></td>
<td>
<p>numeric with values between <code>[0,1]</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of same length as <code>x</code>.
</p>

<hr>
<h2 id='expit_cpp'>expit function</h2><span id='topic+expit_cpp'></span>

<h3>Description</h3>

<p>transform <code>x</code> either via the logit, or expit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expit_cpp(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expit_cpp_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector
</p>

<hr>
<h2 id='factorial'>Factorial</h2><span id='topic+factorial'></span>

<h3>Description</h3>

<p>Calculate the factorial in C##
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factorial(n)
</code></pre>


<h3>Value</h3>

<p>a double
</p>

<hr>
<h2 id='factorial_fast'>Fast Factorial</h2><span id='topic+factorial_fast'></span>

<h3>Description</h3>

<p>Calculate the factorial in C##
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factorial_fast(n)
</code></pre>


<h3>Value</h3>

<p>a double
</p>

<hr>
<h2 id='family.abnFit'>Print family of objects of class <code>abnFit</code></h2><span id='topic+family.abnFit'></span>

<h3>Description</h3>

<p>Print family of objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
family(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="family.abnFit_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="family.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the distributions for each variable of the fitted model.
</p>

<hr>
<h2 id='FCV'>Dataset related to Feline calicivirus infection among cats in Switzerland.</h2><span id='topic+FCV'></span>

<h3>Description</h3>

<p>The dataset is about the Feline calicivirus (FCV) infection among cats in Switzerland.
FCV is a virus that occurs worldwide in domestic cats but also in exotic felids.
FCV is a highly contagious virus that is the major cause of upper respiratory
disease or cat flue that affects felids. This is a complex disease caused by
different viral and bacterial pathogens, i.e., FCV, FHV-1, <em>Mycoplasma felis</em>,
<em>Chlamydia felis</em> and <em>Bordetella bronchiseptica</em>.
It can be aggravated by retrovirus infections such as FeLV and FIV.
This composite dynamic makes it very interesting for a BN modeling approach.
The data were collected between September 2012 and April 2013.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FCV
</code></pre>


<h3>Format</h3>

<p>An adapted data frame of the original dataset, which consists of 300 observations of 15 variables.
</p>

<dl>
<dt>FCV</dt><dd><p>Feline Calici Virus status (0/1).</p>
</dd>
<dt>FHV_1</dt><dd><p>Feline Herpes Virus 1 status (0/1). </p>
</dd>
<dt>C_felis</dt><dd><p>C-felis and Chlamydia felis status (0/1).</p>
</dd>
<dt>M_felis</dt><dd><p>Mycoplasma felis status (0/1).</p>
</dd>
<dt>B_bronchiseptica</dt><dd><p>B-bronchiseptica &amp; Bordetella bronchispetica status (0/1).</p>
</dd>
<dt>FeLV</dt><dd><p>feline leukosis virus status (0/1).</p>
</dd>
<dt>FIV</dt><dd><p>feline immunodeficiency virus status (0/1).</p>
</dd>
<dt>Gingivostomatitis</dt><dd><p>gingivostomatitis complex status (0/1).</p>
</dd>
<dt>URTD</dt><dd><p>URTD complex (upper respiratory complex) (0/1).</p>
</dd>
<dt>Vaccinated</dt><dd><p>vaccination status (0/1).</p>
</dd>
<dt>Pedigree</dt><dd><p>pedigree (0/1).</p>
</dd>
<dt>Outdoor</dt><dd><p>outdoor access (0/1).</p>
</dd>
<dt>Sex</dt><dd><p>sex and castrated status (M, MN, F, FS).</p>
</dd>
<dt>GroupSize</dt><dd><p>number of cats in the group (counts).</p>
</dd>
<dt>Age</dt><dd><p>age in year (continuous)\.</p>
</dd>
</dl>



<h3>References</h3>

<p>Berger, A., Willi, B., Meli, M. L., Boretti, F. S., Hartnack, S., Dreyfus, A., ... and Hofmann-Lehmann, R. (2015). Feline calicivirus and other respiratory pathogens in cats with Feline calicivirus-related symptoms and in clinically healthy cats in Switzerland. BMC Veterinary Research, 11(1), 282.
</p>

<hr>
<h2 id='find.next.left.x'>Find next X evaluation Point</h2><span id='topic+find.next.left.x'></span><span id='topic+find.next.right.x'></span>

<h3>Description</h3>

<p>Attempt to find the next x evaluation point using spline extrapolation traversing left from mode.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find.next.left.x(mat.xy, g.max, g.factor, x.delta, max.fact.delta)

find.next.right.x(mat.xy, g.max, g.factor, x.delta, max.fact.delta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find.next.left.x_+3A_mat.xy">mat.xy</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="find.next.left.x_+3A_g.max">g.max</code></td>
<td>
<p>integer. See Details.</p>
</td></tr>
<tr><td><code id="find.next.left.x_+3A_g.factor">g.factor</code></td>
<td>
<p>integer. See Details.</p>
</td></tr>
<tr><td><code id="find.next.left.x_+3A_x.delta">x.delta</code></td>
<td>
<p>integer. See Details.</p>
</td></tr>
<tr><td><code id="find.next.left.x_+3A_max.fact.delta">max.fact.delta</code></td>
<td>
<p>integer. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>if new x point is more than a factor max.fact.delta (e.g. 0.2) from last evaluated point then stop here
<code>cat("evaluating node ",nodeid,": parameter:",paramid," at betafixed=",betafixed," with gvalue=",gvalue,"\n",sep="");</code>
find the next x value left which differs from the max. gvalue by at least a factor of g.factor, searching in step sizes of
x.delta subject to the constraint that if we move more than max.fact.delta*last.x then we evaluate here. Avoids big steps.
</p>


<h3>Value</h3>

<p>integer
</p>
<p>integer
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>find.next.right.x()</code>: Attempt to find the next x evaluation point using spline extrapolation traversing right from mode.
</p>
</li></ul>

<hr>
<h2 id='fit.control'>Control the iterations in <code><a href="#topic+fitAbn">fitAbn</a></code></h2><span id='topic+fit.control'></span>

<h3>Description</h3>

<p>Allow the user to set restrictions in the <code><a href="#topic+fitAbn">fitAbn</a></code> for both the Bayesian and the MLE approach.
Control function similar to <code><a href="#topic+build.control">build.control</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.control(
  method = "bayes",
  max.mode.error = 10,
  mean = 0,
  prec = 0.001,
  loggam.shape = 1,
  loggam.inv.scale = 5e-05,
  max.iters = 100,
  epsabs = 1e-07,
  error.verbose = FALSE,
  trace = 0L,
  epsabs.inner = 1e-06,
  max.iters.inner = 100,
  finite.step.size = 1e-07,
  hessian.params = c(1e-04, 0.01),
  max.iters.hessian = 10,
  max.hessian.error = 1e-04,
  factor.brent = 100,
  maxiters.hessian.brent = 10,
  num.intervals.brent = 100,
  min.pdf = 0.001,
  n.grid = 250,
  std.area = TRUE,
  marginal.quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975),
  max.grid.iter = 1000,
  marginal.node = NULL,
  marginal.param = NULL,
  variate.vec = NULL,
  ncores = 1,
  cluster.type = "FORK",
  max.irls = 100,
  tol = 1e-11,
  tolPwrss = 1e-07,
  check.rankX = "message+drop.cols",
  check.scaleX = "message+rescale",
  check.conv.grad = "message",
  check.conv.singular = "message",
  check.conv.hess = "message",
  xtol_abs = 1e-06,
  ftol_abs = 1e-06,
  trace.mblogit = FALSE,
  catcov.mblogit = "free",
  epsilon = 1e-06,
  seed = 9062019L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.control_+3A_method">method</code></td>
<td>
<p>a character that takes one of two values: &quot;bayes&quot; or &quot;mle&quot;. Overrides <code>method</code> argument from <code><a href="#topic+buildScoreCache">buildScoreCache</a></code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_max.mode.error">max.mode.error</code></td>
<td>
<p>if the estimated modes from INLA differ by a factor of <code>max.mode.error</code> or more from those computed internally, then results from INLA are replaced by those computed internally. To force INLA always to be used, then <code>max.mode.error=100</code>, to force INLA never to be used <code>max.mod.error=0</code>. See also <code><a href="#topic+fitAbn">fitAbn</a></code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_mean">mean</code></td>
<td>
<p>the prior mean for all the Gaussian additive terms for each node. INLA argument <code>control.fixed=list(mean.intercept=...)</code> and <code>control.fixed=list(mean=...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_prec">prec</code></td>
<td>
<p>the prior precision (<code class="reqn">\tau = \frac{1}{\sigma^2}</code>) for all the Gaussian additive term for each node. INLA argument <code>control.fixed=list(prec.intercept=...)</code> and <code>control.fixed=list(prec=...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_loggam.shape">loggam.shape</code></td>
<td>
<p>the shape parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_loggam.inv.scale">loggam.inv.scale</code></td>
<td>
<p>the inverse scale parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_max.iters">max.iters</code></td>
<td>
<p>total number of iterations allowed when estimating the modes in Laplace approximation. passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_epsabs">epsabs</code></td>
<td>
<p>absolute error when estimating the modes in Laplace approximation for models with no random effects. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_error.verbose">error.verbose</code></td>
<td>
<p>logical, additional output in the case of errors occurring in the optimization. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_trace">trace</code></td>
<td>
<p>Non-negative integer. If positive, tracing information on the progress of the &quot;L-BFGS-B&quot; optimization is produced. Higher values may produce more tracing information. (There are six levels of tracing.  To understand exactly what these do see the source code.). Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_epsabs.inner">epsabs.inner</code></td>
<td>
<p>absolute error in the maximization step in the (nested) Laplace approximation for each random effect term. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_max.iters.inner">max.iters.inner</code></td>
<td>
<p>total number of iterations in the maximization step in the nested Laplace approximation. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_finite.step.size">finite.step.size</code></td>
<td>
<p>suggested step length used in finite difference estimation of the derivatives for the (outer) Laplace approximation when estimating modes. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_hessian.params">hessian.params</code></td>
<td>
<p>a numeric vector giving parameters for the adaptive algorithm, which determines the optimal stepsize in the finite-difference estimation of the hessian. First entry is the initial guess, second entry absolute error. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_max.iters.hessian">max.iters.hessian</code></td>
<td>
<p>integer, maximum number of iterations to use when determining an optimal finite difference approximation (Nelder-Mead). Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_max.hessian.error">max.hessian.error</code></td>
<td>
<p>if the estimated log marginal likelihood when using an adaptive 5pt finite-difference rule for the Hessian differs by more than <code>max.hessian.error</code> from when using an adaptive 3pt rule then continue to minimize the local error by switching to the Brent-Dekker root bracketing method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_factor.brent">factor.brent</code></td>
<td>
<p>if using Brent-Dekker root bracketing method then define the outer most interval end points as the best estimate of <code class="reqn">h</code> (stepsize) from the Nelder-Mead as <code class="reqn">h/factor.brent,h*factor.brent)</code>. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_maxiters.hessian.brent">maxiters.hessian.brent</code></td>
<td>
<p>maximum number of iterations allowed in the Brent-Dekker method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_num.intervals.brent">num.intervals.brent</code></td>
<td>
<p>the number of initial different bracket segments to try in the Brent-Dekker method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_min.pdf">min.pdf</code></td>
<td>
<p>the value of the posterior density function below which we stop the estimation only used when computing marginals, see details.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_n.grid">n.grid</code></td>
<td>
<p>recompute density on an equally spaced grid with <code>n.grid</code> points.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_std.area">std.area</code></td>
<td>
<p>logical, should the area under the estimated posterior density be standardized to exactly one, useful for error checking.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_marginal.quantiles">marginal.quantiles</code></td>
<td>
<p>vector giving quantiles at which to compute the posterior marginal distribution at.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_max.grid.iter">max.grid.iter</code></td>
<td>
<p>gives number of grid points to estimate posterior density at when not explicitly specifying a grid used to avoid excessively long computation.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_marginal.node">marginal.node</code></td>
<td>
<p>used in conjunction with <code>marginal.param</code> to allow bespoke estimate of a marginal density over a specific grid. value from 1 to the number of nodes.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_marginal.param">marginal.param</code></td>
<td>
<p>used in conjunction with <code>marginal.node</code>. value of 1 is for intercept, see modes entry in results for the appropriate number.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_variate.vec">variate.vec</code></td>
<td>
<p>a vector containing the places to evaluate the posterior marginal density, must be supplied if <code>marginal.node</code> is not null.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_ncores">ncores</code></td>
<td>
<p>The number of cores to parallelize to, see &lsquo;Details&rsquo;. If &gt;0, the number of CPU cores to be used. -1 for all available -1 core. Only for <code>method="mle"</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_cluster.type">cluster.type</code></td>
<td>
<p>The type of cluster to be used, see <code>?parallel::makeCluster</code>. <code>abn</code> then defaults to <code>"PSOCK"</code> on Windows and <code>"FORK"</code> on Unix-like systems. With &quot;FORK&quot; the child process are started with <code>rscript_args = "--no-environ"</code> to avoid loading the whole workspace into each child.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_max.irls">max.irls</code></td>
<td>
<p>total number of iterations for estimating network scores using an Iterative Reweighed Least Square algorithm. Is this DEPRECATED?</p>
</td></tr>
<tr><td><code id="fit.control_+3A_tol">tol</code></td>
<td>
<p>real number giving the minimal tolerance expected to terminate the Iterative Reweighed Least Square algorithm to estimate network score. Passed to <code>irls_binomial_cpp_fast_br</code> and <code>irls_poisson_cpp_fast</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_tolpwrss">tolPwrss</code></td>
<td>
<p>numeric scalar passed to <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - the tolerance for declaring convergence in the penalized iteratively weighted residual sum-of-squares step. Similar to <code>tol</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_check.rankx">check.rankX</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - specifying if <code>rankMatrix(X)</code> should be compared with <code>ncol(X)</code> and if columns from the design matrix should possibly be dropped to ensure that it has full rank. Defaults to <code>message+drop.cols</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_check.scalex">check.scaleX</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - check for problematic scaling of columns of fixed-effect model matrix, e.g. parameters measured on very different scales. Defaults to <code>message+rescale</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_check.conv.grad">check.conv.grad</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - checking the gradient of the deviance function for convergence. Defaults to <code>message</code> but can be one of &quot;ignore&quot; - skip the test; &quot;warning&quot; - warn if test fails; &quot;message&quot; - print a message if test fails; &quot;stop&quot; - throw an error if test fails.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_check.conv.singular">check.conv.singular</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - checking for a singular fit, i.e. one where some parameters are on the boundary of the feasible space (for example, random effects variances equal to 0 or correlations between random effects equal to +/- 1.0). Defaults to <code>message</code> but can be one of &quot;ignore&quot; - skip the test; &quot;warning&quot; - warn if test fails; &quot;message&quot; - print a message if test fails; &quot;stop&quot; - throw an error if test fails.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_check.conv.hess">check.conv.hess</code></td>
<td>
<p>character passed to <code><a href="lme4.html#topic+lmerControl">lmerControl</a></code> and <code><a href="lme4.html#topic+glmerControl">glmerControl</a></code> - checking the Hessian of the deviance function for convergence. Defaults to <code>message</code> but can be one of &quot;ignore&quot; - skip the test; &quot;warning&quot; - warn if test fails; &quot;message&quot; - print a message if test fails; &quot;stop&quot; - throw an error if test fails.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_xtol_abs">xtol_abs</code></td>
<td>
<p>Defaults to 1e-6 stop on small change of parameter value. Only for <code>method='mle', group.var=...</code>. Default convergence tolerance for fitted <code>(g)lmer</code> models is reduced to the value provided here if default values did not fit. This value here is passed to the <code>optCtrl</code> argument of <code>(g)lmer</code> (see help of <code><a href="lme4.html#topic+convergence">lme4::convergence()</a></code>).</p>
</td></tr>
<tr><td><code id="fit.control_+3A_ftol_abs">ftol_abs</code></td>
<td>
<p>Defaults to 1e-6 stop on small change in deviance. Similar to <code>xtol_abs</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_trace.mblogit">trace.mblogit</code></td>
<td>
<p>logical indicating if output should be produced for each iteration. Directly passed to <code>trace</code> argument in <code><a href="mclogit.html#topic+mclogit.control">mclogit.control</a></code>. Is independent of <code>verbose</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_catcov.mblogit">catcov.mblogit</code></td>
<td>
<p>Defaults to &quot;free&quot; meaning that there are no restrictions on the covariances of random effects between the logit equations. Set to &quot;diagonal&quot; if random effects pertinent to different categories are uncorrelated or &quot;single&quot; if random effect variances pertinent to all categories are identical.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_epsilon">epsilon</code></td>
<td>
<p>Defaults to 1e-8. Positive convergence tolerance <code class="reqn">\epsilon</code> that is directly passed to the <code>control</code> argument of <code>mclogit::mblogit</code> as <code>mclogit.control</code>. Only for <code>method='mle', group.var=...</code>.</p>
</td></tr>
<tr><td><code id="fit.control_+3A_seed">seed</code></td>
<td>
<p>a non-negative integer which sets the seed in <code>set.seed(seed)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parallelization over all children is possible via the function <code>foreach</code> of the package <span class="pkg">doParallel</span>.  <code>ncores=0</code> or <code>ncores=1</code> use single threaded <code>foreach</code>. <code>ncores=-1</code> uses all available cores but one.
</p>


<h3>Value</h3>

<p>a list of control parameters for the <code><a href="#topic+fitAbn">fitAbn</a></code> function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+build.control">build.control</a></code>.
</p>
<p>Other fitAbn: 
<code><a href="#topic+fitAbn">fitAbn</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ctrlmle &lt;- abn::fit.control(method = "mle",
                       max.irls = 100,
                       tol = 10^-11,
                       tolPwrss = 1e-7,
                       xtol_abs = 1e-6,
                       ftol_abs = 1e-6,
                       epsilon = 1e-6,
                       ncores = 2,
                       cluster.type = "PSOCK",
                       seed = 9062019L)
ctrlbayes &lt;- abn::fit.control(method = "bayes",
                         mean = 0,
                         prec = 0.001,
                         loggam.shape = 1,
                         loggam.inv.scale = 5e-05,
                         max.mode.error = 10,
                         max.iters = 100,
                         epsabs = 1e-07,
                         error.verbose = FALSE,
                         epsabs.inner = 1e-06,
                         max.iters.inner = 100,
                         finite.step.size = 1e-07,
                         hessian.params = c(1e-04, 0.01),
                         max.iters.hessian = 10,
                         max.hessian.error = 1e-04,
                         factor.brent = 100,
                         maxiters.hessian.brent = 10,
                         num.intervals.brent = 100,
                         min.pdf = 0.001,
                         n.grid = 100,
                         std.area = TRUE,
                         marginal.quantiles = c(0.025, 0.25, 0.5, 0.75, 0.975),
                         max.grid.iter = 1000,
                         marginal.node = NULL,
                         marginal.param = NULL,
                         variate.vec = NULL,
                         ncores = 1,
                         cluster.type = NULL,
                         seed = 9062019L)

</code></pre>

<hr>
<h2 id='fitAbn'>Fit an additive Bayesian network model</h2><span id='topic+fitAbn'></span><span id='topic+fitAbn.bayes'></span><span id='topic+fitAbn.mle'></span><span id='topic+regressionLoop'></span>

<h3>Description</h3>

<p>Fits an additive Bayesian network to observed data and is equivalent to Bayesian or information-theoretic multi-dimensional regression modeling.
Two numerical options are available in the Bayesian settings, standard Laplace approximation or else an integrated nested Laplace approximation provided via a call to the R INLA library (see <a href="https://www.r-inla.org/">r-inla.org</a> - this is not hosted on CRAN).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitAbn(object = NULL,
       dag = NULL,
       data.df = NULL,
       data.dists = NULL,
       method = NULL,
       group.var = NULL,
       adj.vars = NULL,
       cor.vars = NULL,
       centre = TRUE,
       compute.fixed = FALSE,
       control = NULL,
       verbose = FALSE,
       debugging = FALSE,
       ...)

fitAbn.bayes(
  dag = NULL,
  data.df = NULL,
  data.dists = NULL,
  group.var = NULL,
  cor.vars = NULL,
  centre = TRUE,
  compute.fixed = FALSE,
  control = fit.control(method = "bayes"),
  mylist = NULL,
  grouped.vars = NULL,
  group.ids = NULL,
  force.method = NULL,
  verbose = FALSE,
  debugging = FALSE
)

fitAbn.mle(
  dag = NULL,
  data.df = NULL,
  data.dists = NULL,
  group.var = NULL,
  grouped.vars = NULL,
  group.ids = NULL,
  adj.vars = NULL,
  cor.vars = NULL,
  centre = TRUE,
  control = fit.control(method = "mle"),
  verbose = FALSE,
  debugging = FALSE
)

regressionLoop(
  i = NULL,
  dag = NULL,
  data.df = NULL,
  data.df.multi = NULL,
  data.dists = NULL,
  group.var = NULL,
  grouped.vars = NULL,
  group.ids = NULL,
  control = NULL,
  nvars = NULL,
  nobs = NULL,
  dag.multi = NULL,
  verbose = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitAbn_+3A_object">object</code></td>
<td>
<p>an object of class <code>abnLearned</code> produced by <code><a href="#topic+mostProbable">mostProbable</a></code>, <code><a href="#topic+searchHeuristic">searchHeuristic</a></code> or <code><a href="#topic+searchHillClimber">searchHillClimber</a></code>.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_dag">dag</code></td>
<td>
<p>a matrix or a formula statement (see details) defining the network structure, a directed acyclic graph (DAG), see details for format. Note that column names and row names must be set up.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data used for learning the network, binary variables must be declared as factors, and no missing values all allowed in any variable.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_data.dists">data.dists</code></td>
<td>
<p>a named list giving the distribution for each node in the network, see details.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_method">method</code></td>
<td>
<p>if <code>NULL</code>, takes method of <code>object</code>, otherwise <code>"bayes"</code> or <code>"mle"</code> for the method to be used, see details.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_group.var">group.var</code></td>
<td>
<p>only applicable for mixed models and gives the column name in <code>data.df</code> of the grouping variable (which must be a factor denoting group membership).</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_adj.vars">adj.vars</code></td>
<td>
<p>a character vector giving the column names in <code>data.df</code> for which the network score has to be adjusted for, see details.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_cor.vars">cor.vars</code></td>
<td>
<p>a character vector giving the column names in data.df for which a mixed model should be used (<code>method = 'bayes'</code> only).</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_centre">centre</code></td>
<td>
<p>should the observations in each Gaussian node first be standardised to mean zero and standard deviation one.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_compute.fixed">compute.fixed</code></td>
<td>
<p>a logical flag, set to <code>TRUE</code> for computation of marginal posterior distributions, see details.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_control">control</code></td>
<td>
<p>a list of control parameters. See <code><a href="#topic+fit.control">fit.control</a></code> for the names of the settable control values and their effect.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code> then provides some additional output, in particular the code used to call INLA, if applicable.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_debugging">debugging</code></td>
<td>
<p>if <code>TRUE</code> and <code>method = 'mle'</code> this enables to step into the for-loop.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_...">...</code></td>
<td>
<p>additional arguments passed for optimization.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_mylist">mylist</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.data">check.valid.data</a></code>.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_grouped.vars">grouped.vars</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.groups">check.valid.groups</a></code>. Column indexes of all variables which are affected from grouping effect.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_group.ids">group.ids</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.groups">check.valid.groups</a></code>. Vector of group allocation for each observation (row) in 'data.df'.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_force.method">force.method</code></td>
<td>
<p>&quot;notset&quot;, &quot;INLA&quot; or &quot;C&quot;. This is specified in <code><a href="#topic+buildScoreCache">buildScoreCache</a>(control=list(max.mode.error=...))</code>.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_i">i</code></td>
<td>
<p>number of child-node (mostly corresponds to child node index e.g. in dag).</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_data.df.multi">data.df.multi</code></td>
<td>
<p>extended data.df for one-hot-encoded multinomial variables.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_nvars">nvars</code></td>
<td>
<p>number of variables in data.dists.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_nobs">nobs</code></td>
<td>
<p>number of observations in data.df.</p>
</td></tr>
<tr><td><code id="fitAbn_+3A_dag.multi">dag.multi</code></td>
<td>
<p>extended dag for one-hot-encoded multinomial variables.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>If <code>method="Bayes"</code>:</h4>

<p>The procedure <code>fitAbn</code> fits an additive Bayesian network model to data where each node (variable - a column in data.df) can be either: presence/absence (Bernoulli); continuous (Gaussian); or an unbounded count (Poisson). Multinomial distributions are only supported with <code>method = "mle"</code> (see below).
The model comprises of a set of conditionally independent generalized linear regressions with or without random effects.
Internal code is used by default for numerical estimation in nodes without random effects, and INLA is the default for nodes with random effects.
This default behavior can be overridden using <code>control=list(max.mode.error=...)</code>. The default is <code>max.mode.error=10</code>, which means that the modes estimated from INLA output must be within 10\
Otherwise, the internal code is used rather than INLA.
To force the use of INLA on all nodes, use <code>max.mode.error=100</code>, which then ignores this check, to force the use of internal code then use <code>max.mode.error=0</code>.
For the numerical reliability and perform of <span class="pkg">abn</span> see <a href="https://r-bayesian-networks.org/">https://r-bayesian-networks.org/</a>.
Generally speaking, INLA can be swift and accurate, but in several cases, it can perform very poorly and so some care is required (which is why there is an internal check on the modes).
Binary variables must be declared as factors with two levels, and the argument <code>data.dists</code> must be a list with named arguments, one for each of the variables in <code>data.df</code> (except a grouping variable - if present!), where each entry is either &quot;poisson&quot;,&quot;binomial&quot;, &quot;multinomial&quot; or &quot;gaussian&quot;, see examples below.
The &quot;poisson&quot; and &quot;binomial&quot; distributions use log and logit link functions, respectively.
Note that &quot;binomial&quot; here actually means only binary, one Bernoulli trial per row in <code>data.df</code>.
</p>
<p>If the data are grouped into correlated blocks - wherein a standard regression context a mixed model might be used - then a network comprising of one or more nodes where a generalized linear mixed model is used (but limited to only a single random effect).
This is achieved by specifying parameters <code>group.var</code> and <code>cor.vars</code>.
Where the former defines the group membership variable, which should be a factor indicating which observations belong to the same grouping.
The parameter <code>cor.vars</code> is a character vector that contains the names of the nodes for which a mixed model should be used. This is not yet implemented with <code>method = 'mle'</code>.
For example, in some problems, it may be appropriate for all variables (except <code>group.var</code>) in data.df to be parametrized as a mixed model while in others it may only be a single variable for which grouping adjustment is required (as the remainder of variables are covariates measured at group level).
</p>
<p>In the network structure definition, <code>dag</code>, each row represents a node in the network, and the columns in each row define the parents for that particular node, see the example below for the specific format.
The <code>dag</code> can be provided using a formula statement (similar to GLM).
A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>.
The formula statement have to start with <code>~</code>. In this example, node1 has two parents (parent1 and parent2). node2 and node3 have the same parent3.
The parents names must match those given in <code>data.df</code>. <code>:</code> is the separator between either children or parents, <code>|</code> separates children (left side) and parents (right side), <code>+</code> separates terms, <code>.</code> replaces all the variables in <code>data.df</code>.
</p>
<p>If <code>compute.fixed=TRUE</code> then the marginal posterior distributions for all parameters are computed.
Note the current algorithm used to determine the evaluation grid is rather crude and may need to be manually refined using <code>variate.vec</code> (one parameter at a time) for publication-quality density estimates.
Note that a manual grid can only be used with internal code and not INLA (which uses its own grid).
The end points are defined as where the value of the marginal density drops below a given threshold <code>pdf.min</code>.
When estimating the log marginal likelihood in models with random effects (using internal code rather than INLA), an attempt is made to minimize the error by comparing the estimates given between a 3pt and 5pt rule when estimating the Hessian in the Laplace approximation.
The modes used in each case are identical. The first derivatives are computed using gsl's adaptive finite difference function, and this is embedding inside the standard 3pt and 5pt rules for the second derivatives.
In all cases, a central difference approximation is tried first with a forward difference being a fall back (as the precision parameters are strictly positive).
The error is minimized through choosing an optimal step size using gsl's Nelder-Mead optimization, and if this fails, (e.g., is larger than <code>max.hessian.error</code>) then the Brent-Dekker root bracketing method is used as a fallback.
If the error cannot be reduced to below <code>max.hessian.error</code>, then the step size, which gave the lowest error during the searches (across potentially many different initial bracket choices), is used for the final Hessian evaluations in the Laplace approximation.
</p>



<h4>If <code>method="mle"</code>:</h4>

<p>The procedure <code>fitAbn</code> with the argument <code>method= "mle"</code> fits an additive Bayesian network model to data where each node (variable - a column in data.df) can be either: presence/absence (Bernoulli); continuous (Gaussian); an unbounded count (Poisson); or a discrete variable (Multinomial).
The model comprises of a set of conditionally independent generalized linear regressions with or without adjustment.
Binary and discrete variables must be declared as factors and the argument <code>data.dists</code> must be a list with named arguments, one for each of the variables in <code>data.df</code>, where each entry is either &quot;poisson&quot;,&quot;binomial&quot;, &quot;multinomial&quot; or &quot;gaussian&quot;, see examples below.
The &quot;poisson&quot; and &quot;binomial&quot; distributions use log and logit link functions, respectively.
Note that &quot;binomial&quot; here actually means only binary, one Bernoulli trial per row in data.df.
</p>
<p>If the data are grouped into correlated blocks - wherein a standard regression context a mixed-effect model might be used - then a network comprising of one or more nodes where a generalized linear mixed model is used (but limited to only a single random intercept).
This is achieved by specifying parameter <code>group.var</code> (<code>cor.vars</code> as with <code>method = "bayes"</code> is not yet implemented with <code>method = "mle"</code>).
The parameter <code>group.var</code> defines the group membership variable, which should be a factor indicating which observations belong to the same grouping.
This corresponds to <code>"1|group.var"</code> in the formula notation of e.g. <span class="pkg">lme4</span>.
</p>
<p>In the context of <code>fitAbn</code> adjustment means that irrespective to the adjacency matrix the adjustment variable set (<code>adj.vars</code>) will be add as covariate to every node defined by <code>cor.vars</code>.
</p>
<p>In the network structure definition, <code>dag</code>, each row represents a node in the network, and the columns in each row define the parents for that particular node, see the example below for the specific format.
The <code>dag</code> can be provided using a formula statement (similar to GLM). A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>.
The formula statement have to start with <code>~</code>. In this example, node1 has two parents (parent1 and parent2). node2 and node3 have the same parent3.
The parents names have to exactly match those given in <code>data.df</code>. <code>:</code> is the separator between either children or parents, <code>|</code> separates children (left side) and parents (right side), <code>+</code> separates terms, <code>.</code> replaces all the variables in <code>data.df</code>.
</p>
<p>The Information-theoretic based network scores used in <code>fitAbn</code> with argument <code>method="mle"</code> are the maximum likelihood (mlik, called marginal likelihood in this context as it is computed node wise), the Akaike Information Criteria (aic), the Bayesian Information Criteria (bic) and the Minimum distance Length (mdl). The classical definitions of those metrics are given in Kratzer and Furrer (2018).
</p>
<p>The numerical routine is based on an iterative scheme to estimate the regression coefficients. The Iterative Reweighed Least Square (IRLS) programmed using Rcpp/RcppArmadrillo. One hard coded feature of <code>fitAbn</code> with argument <code>method="mle"</code> is a conditional use of a bias reduced binomial regression when a classical Generalized Linear Model (GLM) fails to estimate the maximum likelihood of the given model accurately. Additionally, a QR decomposition is performed to check for rank deficiency. If the model is rank deficient and the BR GLM fails to estimate it, then predictors are sequentially removed. This feature aims at better estimating network scores when data sparsity is present.
</p>
<p>A special care should be taken when interpreting or even displaying p-values computed with <code>fitAbn</code>. Indeed, the full model is already selected using goodness of fit metrics based on the (same) full dataset.
</p>
<p>The <code>control</code> argument is a list with separate arguments for the Bayesian and MLE implementation. See  <code><a href="#topic+fit.control">fit.control</a></code> for details.
</p>



<h3>Value</h3>

<p>An object of class <code>abnFit</code>. A named list. One entry for each of the variables in <code>data.df</code> (excluding the grouping variable, if present) which contains an estimate of the log marginal likelihood for that individual node. An entry &quot;mlik&quot; which is the total log marginal likelihood for the full ABN model. A vector of <code>error.codes</code> - non-zero if a numerical error or warning occurred, and a vector error.code.desc giving a text description of the error. A list <code>modes</code>, which contains all the mode estimates for each parameter at each node. A vector called Hessian accuracy, which is the estimated local error in the log marginal likelihood for each node.  If <code>compute.fixed=TRUE</code> then a list entry called <code>marginals</code> which contains a named entry for every parameter in the ABN and each entry in this list is a two-column matrix where the first column is the value of the marginal parameter, say x, and the second column is the respective density value, pdf(x). Also, a list called <code>marginal.quantiles</code> is produced, giving the quantiles for each marginal posterior distribution.
</p>
<p>list
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>fitAbn.bayes()</code>: Internal function called by <code>fitAbn</code>.
</p>
</li>
<li> <p><code>fitAbn.mle()</code>: Internal function called by <code>fitAbn</code>.
</p>
</li>
<li> <p><code>regressionLoop()</code>: Internal function called by <code>fitAbn.mle()</code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Fraser Iain Lewis and Gilles Kratzer.
</p>


<h3>References</h3>

<p>Kratzer, G., Lewis, F.I., Comin, A., Pittavino, M. and Furrer, R. (2019). &quot;Additive Bayesian Network Modelling with the R Package abn&quot;. arXiv preprint arXiv:1911.09006.
</p>
<p>Kratzer, G., and Furrer, R., 2018. Information-Theoretic Scoring Rules to Learn Additive Bayesian Network Applied to Epidemiology. Preprint; Arxiv: stat.ML/1808.01126.
</p>
<p>Lewis, F. I., and McCormick, B. J. J. (2012). Revealing the complexity of health determinants in resource poor settings. <em>American Journal Of Epidemiology</em>. DOI:10.1093/aje/KWS183.
</p>
<p>Further information about <span class="pkg">abn</span> can be found at: <a href="https://r-bayesian-networks.org/">r-bayesian-networks.org</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+buildScoreCache">buildScoreCache</a></code>
</p>
<p>Other fitAbn: 
<code><a href="#topic+fit.control">fit.control</a>()</code>
</p>
<p>Other Bayes: 
<code><a href="#topic+buildScoreCache">buildScoreCache</a>()</code>,
<code><a href="#topic+calc.node.inla.glm">calc.node.inla.glm</a>()</code>,
<code><a href="#topic+calc.node.inla.glmm">calc.node.inla.glmm</a>()</code>,
<code><a href="#topic+getmarginals">getmarginals</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Built-in dataset with a subset of cols
mydat &lt;- ex0.dag.data[, c("b1", "b2", "b3", "g1", "b4", "p2", "p4")]

## setup distribution list for each node
mydists &lt;- list(b1 = "binomial",
                b2 = "binomial",
                b3 = "binomial",
                g1 = "gaussian",
                b4 = "binomial",
                p2 = "poisson",
                p4 = "poisson")

## Null model - all independent variables
mydag_empty &lt;- matrix(0, nrow = 7, ncol = 7)
colnames(mydag_empty) &lt;- rownames(mydag_empty) &lt;- names(mydat)

## Now fit the model to calculate its goodness-of-fit
myres &lt;- fitAbn(dag = mydag_empty,
                data.df = mydat,
                data.dists = mydists)

## Log-marginal likelihood goodness-of-fit for complete DAG
print(myres$mlik)

## fitAbn accepts also the formula statement
myres &lt;- fitAbn(dag = ~ b1 | b2 + b2 | p4:g1 + g1 | p2 + b3 | g1 + b4 | b1 + p4 | g1,
                data.df = mydat,
                data.dists = mydists)
print(myres$mlik) # a much weaker fit than full independence DAG

# Plot the DAG via Rgraphviz
plot(myres)

## Or equivalently using the formula statement, with plotting
## Now repeat but include some dependencies first
mydag &lt;- mydag_empty
mydag["b1", "b2"] &lt;- 1 # b1&lt;-b2 and so on
mydag["b2", "p4"] &lt;- mydag["b2", "g1"] &lt;- mydag["g1", "p2"] &lt;- 1
mydag["b3", "g1"] &lt;- mydag["b4", "b1"] &lt;- mydag["p4", "g1"] &lt;- 1
myres_alt &lt;- fitAbn(dag = mydag,
                    data.df = mydat,
                    data.dists = mydists)
plot(myres_alt)

## -----------------------------------------------------------------------------
## This function contains an MLE implementation accessible through a method
## parameter use built-in simulated data set
## -----------------------------------------------------------------------------
myres_mle &lt;- fitAbn(dag = ~ b1 | b2 + b2 | p4 + g1 + g1 | p2 + b3 | g1 + b4 | b1 + p4 | g1,
                    data.df = mydat,
                    data.dists = mydists,
                    method = "mle")

## Print the output for mle first then for Bayes:
print(myres_mle)
plot(myres_mle)

print(myres)
plot(myres)

## This is a basic plot of some posterior densities. The algorithm used for
## selecting density points is quite straightforward, but it might result
## in a sparse distribution. Therefore, we also recompute the density over
## an evenly spaced grid of 50 points between the two endpoints that had
## a minimum PDF at f = min.pdf.
## Setting max.mode.error = 0 forces the use of the internal C code.
myres_c &lt;- fitAbn(dag = mydag,
                  data.df = mydat,
                  data.dists = mydists,
                  compute.fixed = TRUE,
                  control = list(max.mode.error = 0))

print(names(myres_c$marginals)) # gives all the different parameter names

## Repeat but use INLA for the numerics using max.mode.error = 100
## as using internal code is the default here rather than INLA
myres_inla &lt;- fitAbn(dag = mydag,
                     data.df = mydat,
                     data.dists = mydists,
                     compute.fixed = TRUE,
                     control = list(max.mode.error = 100))

## Plot posterior densities
default_par &lt;- par(no.readonly = TRUE) # save default par settings
par(mfrow = c(2, 2), mai = c(.7, .7, .2, .1))
plot(myres_c$marginals$b1[["b1 | (Intercept)"]], type = "l", xlab = "b1 | (Intercept)")
lines(myres_inla$marginals$b1[["b1 | (Intercept)"]], col = "blue")
plot(myres_c$marginals$b2[["b2 | p4"]], type = "l", xlab = "b2 | p4")
lines(myres_inla$marginals$b2[["b2 | p4"]], col = "blue")
plot(myres_c$marginals$g1[["g1 | precision"]], type = "l", xlab = "g1 | precision")
lines(myres_inla$marginals$g1[["g1 | precision"]], col = "blue")
plot(myres_c$marginals$b4[["b4 | b1"]], type = "l", xlab = "b4 | b1")
lines(myres_inla$marginals$b4[["b4 | b1"]], col = "blue")
par(default_par) # reset par settings

## An elementary mixed model example using built-in data specify DAG,
## only two variables using a subset of variables from ex3.dag.data
## both variables are assumed to need (separate) adjustment for the
## group variable, i.e., a binomial GLMM at each node

mydists &lt;- list(b1 = "binomial",
                b2 = "binomial")

## Compute marginal likelihood - use internal code via max.mode.error=0
## as using INLA is the default here.
## Model where b1 &lt;- b2
myres_c &lt;- fitAbn(dag = ~b1 | b2,
                  data.df = ex3.dag.data[, c(1, 2, 14)],
                  data.dists = mydists,
                  group.var = "group",
                  cor.vars = c("b1", "b2"),
                  control = list(max.mode.error = 0))
print(myres_c) # show all the output

## compare mode for node b1 with glmer(), lme4::glmer is automatically attached.

## Now for marginals - INLA is strongly preferable for estimating marginals for
## nodes with random effects as it is far faster, but may not be reliable
## see https://r-bayesian-networks.org/

## INLA's estimates of the marginals, using high n.grid = 500
## as this makes the plots smoother - see below.
myres_inla &lt;- fitAbn(dag = ~b1 | b2,
                   data.df = ex3.dag.data[, c(1, 2, 14)],
                  data.dists = mydists,
                  group.var = "group",
                  cor.vars = c("b1", "b2"),
                  compute.fixed = TRUE,
                  n.grid = 500,
                  control = list(max.mode.error = 100,
                                 max.hessian.error = 10E-02))

## this is NOT recommended - marginal density estimation using fitAbn in
## mixed models is really just for diagnostic purposes, better to use
## fitAbn.inla() here; but here goes... be patient
myres_c &lt;- fitAbn(dag = ~b1 | b2,
                  data.df = ex3.dag.data[, c(1, 2, 14)],
                  data.dists = mydists,
                  group.var = "group",
                  cor.vars = c("b1", "b2"),
                  compute.fixed = TRUE,
                  control = list(max.mode.error = 0,
                                 max.hessian.error = 10E-02))

## compare marginals between internal and INLA.
default_par &lt;- par(no.readonly = TRUE) # save default par settings
par(mfrow = c(2, 3))
# 5 parameters - two intercepts, one slope, two group level precisions
plot(myres_inla$marginals$b1[[1]], type = "l", col = "blue")
lines(myres_c$marginals$b1[[1]], col = "brown", lwd = 2)
plot(myres_inla$marginals$b1[[2]], type = "l", col = "blue")
lines(myres_c$marginals$b1[[2]], col = "brown", lwd = 2)
# the precision of group-level random effects
plot(myres_inla$marginals$b1[[3]], type = "l", col = "blue", xlim = c(0, 2))
lines(myres_c$marginals$b1[[3]], col = "brown", lwd = 2)
plot(myres_inla$marginals$b2[[1]], type = "l", col = "blue")
lines(myres_c$marginals$b2[[1]], col = "brown", lwd = 2)
plot(myres_inla$marginals$b2[[1]], type = "l", col = "blue")
lines(myres_c$marginals$b2[[1]], col = "brown", lwd = 2)
# the precision of group-level random effects
plot(myres_inla$marginals$b2[[2]], type = "l", col = "blue", xlim = c(0, 2))
lines(myres_c$marginals$b2[[2]], col = "brown", lwd = 2)
par(default_par) # reset par settings

### these are very similar although not exactly identical

## use internal code but only to compute a single parameter over a specified
## grid.
## This can be necessary if the simple auto grid finding functions does
## a poor job.
myres_c &lt;- fitAbn(dag = ~b1 | b2,
                  data.df = ex3.dag.data[, c(1, 2, 14)],
                  data.dists = mydists,
                  group.var = "group",
                  cor.vars = c("b1", "b2"),
                  centre = FALSE,
                  compute.fixed = TRUE,
                  control = list(marginal.node = 1,
                                 marginal.param = 3, # precision term in node 1
                                 variate.vec = seq(0.05, 1.5, len = 25),
                                 max.hessian.error = 10E-02))

default_par &lt;- par(no.readonly = TRUE) # save default par settings
par(mfrow = c(1, 2))
plot(myres_c$marginals$b1[[1]], type = "l", col = "blue") # still fairly sparse
# An easy way is to use spline to fill in the density without recomputing other
# points provided the original grid is not too sparse.
plot(spline(myres_c$marginals$b1[[1]], n = 100), type = "b", col = "brown")
par(default_par) # reset par settings

## End(Not run)

</code></pre>

<hr>
<h2 id='forLoopContentFitBayes'>Regress each node on its parents.#'</h2><span id='topic+forLoopContentFitBayes'></span>

<h3>Description</h3>

<p>Regress each node on its parents.#'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forLoopContentFitBayes(
  child = NULL,
  dag = NULL,
  data.df = NULL,
  var.types = NULL,
  grouped.vars = NULL,
  group.ids = NULL,
  control = NULL,
  INLA.marginals = NULL,
  verbose = NULL,
  force.method = NULL,
  data.dists = NULL,
  mymodes = NULL,
  error.code = NULL,
  hessian.accuracy = NULL,
  mymargs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forLoopContentFitBayes_+3A_child">child</code></td>
<td>
<p>integer of node to be regressed</p>
</td></tr>
<tr><td><code id="forLoopContentFitBayes_+3A_var.types">var.types</code></td>
<td>
<p>vector of numeric encoding of distribution types. See <code>get.var.types(data.dists)</code></p>
</td></tr>
<tr><td><code id="forLoopContentFitBayes_+3A_inla.marginals">INLA.marginals</code></td>
<td>
<p>vector of logicals indicating which nodes are to be fitted using INLA</p>
</td></tr>
<tr><td><code id="forLoopContentFitBayes_+3A_mymodes">mymodes</code></td>
<td>
<p>Empty list of modes for each node</p>
</td></tr>
<tr><td><code id="forLoopContentFitBayes_+3A_error.code">error.code</code></td>
<td>
<p>Empty element of error codes for each node</p>
</td></tr>
<tr><td><code id="forLoopContentFitBayes_+3A_hessian.accuracy">hessian.accuracy</code></td>
<td>
<p>Empty element of hessian accuracies for each node</p>
</td></tr>
<tr><td><code id="forLoopContentFitBayes_+3A_mymargs">mymargs</code></td>
<td>
<p>Empty list of marginals for each node</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of mlik, modes, marginals, error codes, hessian accuracies and a logical if INLA was used for each node.
</p>

<hr>
<h2 id='formula_abn'>Formula to adjacency matrix</h2><span id='topic+formula_abn'></span>

<h3>Description</h3>

<p>Internal function that produce a square matrix length(name) with <code class="reqn">0,1</code> depending on f.
f have to start with ~ terms are entries of name terms are separated by + term1 | term2 indicates
col(term1) row(term2) puts a 1 term1 | term2:term3: ... : is used as a sep . = all terms in name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>formula_abn(f, name)
</code></pre>


<h3>Value</h3>

<p>A square matrix
</p>

<hr>
<h2 id='g2b2c_data'>Toy Data Set for Examples in README</h2><span id='topic+g2b2c_data'></span>

<h3>Description</h3>

<p>1000 observations with 5 variables: 2 continuous, 2 binary and 1 categorical.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g2b2c_data
</code></pre>


<h3>Format</h3>

<p>A data frame with five columns. Binary and categorical variables are factors.
</p>

<dl>
<dt>G1</dt><dd><p>gaussian</p>
</dd>
<dt>B1</dt><dd><p>binomial</p>
</dd>
<dt>B2</dt><dd><p>binomial</p>
</dd>
<dt>C</dt><dd><p>categorical</p>
</dd>
<dt>G2</dt><dd><p>gaussian</p>
</dd>
</dl>


<hr>
<h2 id='g2pbcgrp'>Toy Data Set for Examples in README</h2><span id='topic+g2pbcgrp'></span>

<h3>Description</h3>

<p>10000 observations with 6 variables: 2 continuous, 1 binary, 1 count, 1 categorical and 1 grouping factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>g2pbcgrp
</code></pre>


<h3>Format</h3>

<p>A data frame with six columns. Binary and categorical variables are factors.
</p>

<dl>
<dt>G1</dt><dd><p>gaussian</p>
</dd>
<dt>P</dt><dd><p>poisson</p>
</dd>
<dt>B</dt><dd><p>binomial</p>
</dd>
<dt>C</dt><dd><p>categorical</p>
</dd>
<dt>G2</dt><dd><p>gaussian</p>
</dd>
<dt>group</dt><dd><p>categorical</p>
</dd>
</dl>


<hr>
<h2 id='gauss_bugs'>Bugs code for Gaussian response</h2><span id='topic+gauss_bugs'></span><span id='topic+gauss_bugsGroup'></span>

<h3>Description</h3>

<p>Bugs model for a normal distributed response variable
<code class="reqn">X \sim \mathcal{N}(\mu,\,\sigma^{2})</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gauss_bugs(nodename, nodesintercept, parentnames, parentcoefs, std)

gauss_bugsGroup(
  nodename,
  nodesintercept,
  parentnames,
  parentcoefs,
  sigma,
  sigma_alpha
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gauss_bugs_+3A_nodename">nodename</code></td>
<td>
<p>character string of response variable name.</p>
</td></tr>
<tr><td><code id="gauss_bugs_+3A_nodesintercept">nodesintercept</code></td>
<td>
<p>overall mean of response. Parameter from fixed-effects intercept.</p>
</td></tr>
<tr><td><code id="gauss_bugs_+3A_parentnames">parentnames</code></td>
<td>
<p>single character string (for one parent) or vector of characters (for multiple parent nodes) with parent node (predictor variables) names.</p>
</td></tr>
<tr><td><code id="gauss_bugs_+3A_parentcoefs">parentcoefs</code></td>
<td>
<p>overall slope for each predictor (parent node) variable (fixed-effects).</p>
</td></tr>
<tr><td><code id="gauss_bugs_+3A_std">std</code></td>
<td>
<p>integer with standard deviation of response variable that will be
converted to precision (see Details).</p>
</td></tr>
<tr><td><code id="gauss_bugs_+3A_sigma">sigma</code></td>
<td>
<p>within-group variance. Parameter from random-effects residual.</p>
</td></tr>
<tr><td><code id="gauss_bugs_+3A_sigma_alpha">sigma_alpha</code></td>
<td>
<p>between-group variance. Parameter from random-effects intercept.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance of the normal distribution is <code class="reqn">\frac{1}{\tau}</code>.
</p>


<h3>Value</h3>

<p>Bugs model returned as stdout.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>gauss_bugsGroup()</code>: Bugs code for Gaussian response with varying intercept
</p>
</li></ul>


<h3>See Also</h3>

<p><a href="#topic+makebugs">makebugs</a> <a href="#topic+simulateAbn">simulateAbn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gauss_bugs(nodename = "a",
           parentnames = c("b", "c"),
           nodesintercept = c(0.318077),
           parentcoefs = list("b"=c(b=0.3059395),
                              "c"=c(c=0.5555)),
           std = c(0.05773503))
</code></pre>

<hr>
<h2 id='get.quantiles'>function to extract quantiles from INLA output</h2><span id='topic+get.quantiles'></span><span id='topic+get.ind.quantiles'></span>

<h3>Description</h3>

<p>function to get to extract quantiles
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.quantiles(mylist, quantiles, single)

get.ind.quantiles(outmat, inmat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.quantiles_+3A_mylist">mylist</code></td>
<td>
<p>list of matrices of two cols x, y</p>
</td></tr>
<tr><td><code id="get.quantiles_+3A_quantiles">quantiles</code></td>
<td>
<p>vector with the desired quantiles</p>
</td></tr>
<tr><td><code id="get.quantiles_+3A_single">single</code></td>
<td>
<p>NULL or TRUE if only a single node and parameter</p>
</td></tr>
<tr><td><code id="get.quantiles_+3A_outmat">outmat</code></td>
<td>
<p>matrix where the first col has the desired quantiles. We want to estimate this and out in into the second col</p>
</td></tr>
<tr><td><code id="get.quantiles_+3A_inmat">inmat</code></td>
<td>
<p>is the actual x,f(x) matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>
<p>matrix
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>get.ind.quantiles()</code>: helper function for get.quantiles
</p>
</li></ul>

<hr>
<h2 id='get.var.types'>Create ordered vector with integers denoting the distribution</h2><span id='topic+get.var.types'></span>

<h3>Description</h3>

<p>gaussian = 1, binomial = 2, poisson = 3, multinomial = 4
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.var.types(data.dists = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.var.types_+3A_data.dists">data.dists</code></td>
<td>
<p>list specifying each columns distribution type. Names correspond to column names and values must be one of &quot;gaussian&quot;, &quot;binomial&quot;, &quot;poisson&quot;, &quot;multinomial&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric encoding of distribution corresponding to its list element number in <code>data.dists</code>.
</p>

<hr>
<h2 id='getmarginals'>Internal function called by <code>fitAbn.bayes</code>.</h2><span id='topic+getmarginals'></span>

<h3>Description</h3>

<p>Function for computing marginal posterior densities using C and is called from fit.dag()
Only to be called internally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getmarginals(
  res.list,
  data.df,
  dag.m,
  var.types,
  max.parents,
  mean,
  prec,
  loggam.shape,
  loggam.inv.scale,
  max.iters,
  epsabs,
  verbose,
  error.verbose,
  trace,
  grouped.vars,
  group.ids,
  epsabs.inner,
  max.iters.inner,
  finite.step.size,
  hessian.params,
  max.iters.hessian,
  min.pdf,
  marginal.node,
  marginal.param,
  variate.vec,
  n.grid,
  INLA.marginals,
  iter.max,
  max.hessian.error,
  factor.brent,
  maxiters.hessian.brent,
  num.intervals.brent
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getmarginals_+3A_res.list">res.list</code></td>
<td>
<p>rest of arguments as for call to C fitabn</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data used for learning the network, binary variables must be declared as factors, and no missing values all allowed in any variable.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_dag.m">dag.m</code></td>
<td>
<p>adjacency matrix</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_var.types">var.types</code></td>
<td>
<p>distributions in terms of a numeric code</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_max.parents">max.parents</code></td>
<td>
<p>max number of parents over all nodes in dag (different from other <code>max.parents</code> definitions).</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_mean">mean</code></td>
<td>
<p>the prior mean for all the Gaussian additive terms for each node. INLA argument <code>control.fixed=list(mean.intercept=...)</code> and <code>control.fixed=list(mean=...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_prec">prec</code></td>
<td>
<p>the prior precision (<code class="reqn">\tau = \frac{1}{\sigma^2}</code>) for all the Gaussian additive term for each node. INLA argument <code>control.fixed=list(prec.intercept=...)</code> and <code>control.fixed=list(prec=...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_loggam.shape">loggam.shape</code></td>
<td>
<p>the shape parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_loggam.inv.scale">loggam.inv.scale</code></td>
<td>
<p>the inverse scale parameter in the Gamma distribution prior for the precision in a Gaussian node. INLA argument <code>control.family=list(hyper = list(prec = list(prior="loggamma",param=c(loggam.shape, loggam.inv.scale))))</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_max.iters">max.iters</code></td>
<td>
<p>total number of iterations allowed when estimating the modes in Laplace approximation. passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_epsabs">epsabs</code></td>
<td>
<p>absolute error when estimating the modes in Laplace approximation for models with no random effects. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code> then provides some additional output, in particular the code used to call INLA, if applicable.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_error.verbose">error.verbose</code></td>
<td>
<p>logical, additional output in the case of errors occurring in the optimization. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_trace">trace</code></td>
<td>
<p>Non-negative integer. If positive, tracing information on the progress of the &quot;L-BFGS-B&quot; optimization is produced. Higher values may produce more tracing information. (There are six levels of tracing.  To understand exactly what these do see the source code.). Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_grouped.vars">grouped.vars</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.groups">check.valid.groups</a></code>. Column indexes of all variables which are affected from grouping effect.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_group.ids">group.ids</code></td>
<td>
<p>result returned from <code><a href="#topic+check.valid.groups">check.valid.groups</a></code>. Vector of group allocation for each observation (row) in 'data.df'.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_epsabs.inner">epsabs.inner</code></td>
<td>
<p>absolute error in the maximization step in the (nested) Laplace approximation for each random effect term. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_max.iters.inner">max.iters.inner</code></td>
<td>
<p>total number of iterations in the maximization step in the nested Laplace approximation. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_finite.step.size">finite.step.size</code></td>
<td>
<p>suggested step length used in finite difference estimation of the derivatives for the (outer) Laplace approximation when estimating modes. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_hessian.params">hessian.params</code></td>
<td>
<p>a numeric vector giving parameters for the adaptive algorithm, which determines the optimal stepsize in the finite-difference estimation of the hessian. First entry is the initial guess, second entry absolute error. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_max.iters.hessian">max.iters.hessian</code></td>
<td>
<p>integer, maximum number of iterations to use when determining an optimal finite difference approximation (Nelder-Mead). Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_min.pdf">min.pdf</code></td>
<td>
<p>the value of the posterior density function below which we stop the estimation only used when computing marginals, see details.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_marginal.node">marginal.node</code></td>
<td>
<p>used in conjunction with <code>marginal.param</code> to allow bespoke estimate of a marginal density over a specific grid. value from 1 to the number of nodes.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_marginal.param">marginal.param</code></td>
<td>
<p>used in conjunction with <code>marginal.node</code>. value of 1 is for intercept, see modes entry in results for the appropriate number.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_variate.vec">variate.vec</code></td>
<td>
<p>a vector containing the places to evaluate the posterior marginal density, must be supplied if <code>marginal.node</code> is not null.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_n.grid">n.grid</code></td>
<td>
<p>recompute density on an equally spaced grid with <code>n.grid</code> points.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_inla.marginals">INLA.marginals</code></td>
<td>
<p>vector - TRUE if INLA used false otherwise</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_iter.max">iter.max</code></td>
<td>
<p>same as <code>max.iters</code> in <code><a href="#topic+fit.control">fit.control</a></code>. Total number of iterations allowed when estimating the modes in Laplace approximation. Passed to .Call(&quot;fit_single_node&quot;, ...).</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_max.hessian.error">max.hessian.error</code></td>
<td>
<p>if the estimated log marginal likelihood when using an adaptive 5pt finite-difference rule for the Hessian differs by more than <code>max.hessian.error</code> from when using an adaptive 3pt rule then continue to minimize the local error by switching to the Brent-Dekker root bracketing method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_factor.brent">factor.brent</code></td>
<td>
<p>if using Brent-Dekker root bracketing method then define the outer most interval end points as the best estimate of <code class="reqn">h</code> (stepsize) from the Nelder-Mead as <code class="reqn">h/factor.brent,h*factor.brent)</code>. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_maxiters.hessian.brent">maxiters.hessian.brent</code></td>
<td>
<p>maximum number of iterations allowed in the Brent-Dekker method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
<tr><td><code id="getmarginals_+3A_num.intervals.brent">num.intervals.brent</code></td>
<td>
<p>the number of initial different bracket segments to try in the Brent-Dekker method. Passed to <code>.Call("fit_single_node", ...)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list with &quot;modes&quot;, &quot;error.code&quot;, &quot;hessian.accuracy&quot;, &quot;error.code.desc&quot;, &quot;mliknode&quot;, &quot;mlik&quot;, &quot;mse&quot;, &quot;coef&quot;, &quot;used.INLA&quot;, &quot;marginals&quot;.
</p>


<h3>See Also</h3>

<p>Other Bayes: 
<code><a href="#topic+buildScoreCache">buildScoreCache</a>()</code>,
<code><a href="#topic+calc.node.inla.glm">calc.node.inla.glm</a>()</code>,
<code><a href="#topic+calc.node.inla.glmm">calc.node.inla.glmm</a>()</code>,
<code><a href="#topic+fitAbn">fitAbn</a>()</code>
</p>

<hr>
<h2 id='getMargsINLA'>function to extract marginals from INLA output</h2><span id='topic+getMargsINLA'></span>

<h3>Description</h3>

<p>function to extract marginals from INLA output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMargsINLA(list.fixed, list.hyper)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getMargsINLA_+3A_list.fixed">list.fixed</code></td>
<td>
<p>list of matrices of two cols x, y</p>
</td></tr>
<tr><td><code id="getMargsINLA_+3A_list.hyper">list.hyper</code></td>
<td>
<p>list of hyperparameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector
</p>

<hr>
<h2 id='getModeVector'>function to extract the mode from INLA output</h2><span id='topic+getModeVector'></span>

<h3>Description</h3>

<p>function to extract the mode from INLA output
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getModeVector(list.fixed, list.hyper)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getModeVector_+3A_list.fixed">list.fixed</code></td>
<td>
<p>list of matrices of two cols x, y</p>
</td></tr>
<tr><td><code id="getModeVector_+3A_list.hyper">list.hyper</code></td>
<td>
<p>list of hyperparameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector
</p>

<hr>
<h2 id='getMSEfromModes'>Extract Standard Deviations from all Gaussian Nodes</h2><span id='topic+getMSEfromModes'></span>

<h3>Description</h3>

<p>Extract Standard Deviations from all Gaussian Nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMSEfromModes(modes, dists)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getMSEfromModes_+3A_modes">modes</code></td>
<td>
<p>list of modes.</p>
</td></tr>
<tr><td><code id="getMSEfromModes_+3A_dists">dists</code></td>
<td>
<p>list of distributions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>named numeric vector. Names correspond to node name. Value to standard deviations.
</p>

<hr>
<h2 id='infoDag'>Compute standard information for a DAG.</h2><span id='topic+infoDag'></span>

<h3>Description</h3>

<p>This function returns standard metrics for DAG description. A list that
contains the number of nodes, the number of arcs,
the average Markov blanket size, the neighborhood average set size,
the parent average set size and children average set size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infoDag(object, node.names = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="infoDag_+3A_object">object</code></td>
<td>
<p>an object of class <code>abnLearned</code>, <code>abnFit</code>.
Alternatively, a matrix or a formula statement defining the network structure,
a directed acyclic graph (DAG).
Note that row names must be set up or given in <code>node.names</code>.</p>
</td></tr>
<tr><td><code id="infoDag_+3A_node.names">node.names</code></td>
<td>
<p>a vector of names if the DAG is given via formula, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns a named list with the following entries:
the number of nodes, the number of arcs, the average Markov blanket size,
the neighborhood average set size, the parent average set size, and the
children's average set size.
</p>
<p>The <code>dag</code> can be provided using a formula statement (similar to glm).
A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>.
The formula statement have to start with <code>~</code>.
In this example, node1 has two parents (parent1 and parent2).
node2 and node3 have the same parent3.
The parents names have to exactly match those given in <code>node.names</code>.
<code>:</code> is the separator between either children or parents,
<code>|</code> separates children (left side) and parents (right side),
<code>+</code> separates terms, <code>.</code> replaces all the variables in <code>node.names</code>.
</p>


<h3>Value</h3>

<p>A named list that contains following entries:
the number of nodes, the number of arcs,
the average Markov blanket size, the neighborhood average set size,
the parent average set size and children average set size.
</p>


<h3>References</h3>

<p>West, D. B. (2001). Introduction to graph theory. Vol. 2. Upper Saddle River: Prentice Hall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Creating a dag:
dag &lt;- matrix(c(0,0,0,0, 1,0,0,0, 1,1,0,1, 0,1,0,0), nrow = 4, ncol = 4)
dist &lt;- list(a="gaussian", b="gaussian", c="gaussian", d="gaussian")
colnames(dag) &lt;- rownames(dag) &lt;- names(dist)

infoDag(dag)
plot(createAbnDag(dag = dag, data.dists = dist))
</code></pre>

<hr>
<h2 id='irls_binomial_cpp'>Iterative Reweighed Least Square algorithm for Binomials</h2><span id='topic+irls_binomial_cpp'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Binomial nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_binomial_cpp(A, b, maxit, tol)
</code></pre>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='irls_binomial_cpp_br'>BR Iterative Reweighed Least Square algorithm for Binomials</h2><span id='topic+irls_binomial_cpp_br'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Binomial nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_binomial_cpp_br(A, b, maxit, tol)
</code></pre>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='irls_binomial_cpp_fast'>Fast Iterative Reweighed Least Square algorithm for Binomials</h2><span id='topic+irls_binomial_cpp_fast'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Binomial nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_binomial_cpp_fast(A, b, maxit, tol)
</code></pre>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='irls_binomial_cpp_fast_br'>Fast Br Iterative Reweighed Least Square algorithm for Binomials</h2><span id='topic+irls_binomial_cpp_fast_br'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Binomial nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_binomial_cpp_fast_br(A, b, maxit, tol)
</code></pre>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='irls_gaussian_cpp'>Iterative Reweighed Least Square algorithm for Gaussians</h2><span id='topic+irls_gaussian_cpp'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Gaussian nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_gaussian_cpp(A, b, maxit, tol)
</code></pre>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='irls_gaussian_cpp_fast'>Fast Iterative Reweighed Least Square algorithm for Gaussians</h2><span id='topic+irls_gaussian_cpp_fast'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Gaussian nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_gaussian_cpp_fast(A, b, maxit, tol)
</code></pre>

<hr>
<h2 id='irls_poisson_cpp'>Iterative Reweighed Least Square algorithm for Poissons</h2><span id='topic+irls_poisson_cpp'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Poisson nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_poisson_cpp(A, b, maxit, tol)
</code></pre>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='irls_poisson_cpp_fast'>Fast Iterative Reweighed Least Square algorithm for Poissons</h2><span id='topic+irls_poisson_cpp_fast'></span>

<h3>Description</h3>

<p>IRLS to estimate network score of Poisson nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irls_poisson_cpp_fast(A, b, maxit, tol)
</code></pre>


<h3>Value</h3>

<p>a list
</p>

<hr>
<h2 id='linkStrength'>Returns the strengths of the edge connections in a Bayesian Network learned from observational data</h2><span id='topic+linkStrength'></span>

<h3>Description</h3>

<p>A flexible implementation of multiple proxy for strength measures useful for
visualizing the edge connections in a Bayesian Network learned from observational data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linkStrength(dag,
                    data.df = NULL,
                    data.dists = NULL,
                    method = c("mi.raw",
                               "mi.raw.pc",
                               "mi.corr",
                               "ls",
                               "ls.pc",
                               "stat.dist"),
                    discretization.method = "doane")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="linkStrength_+3A_dag">dag</code></td>
<td>
<p>a matrix or a formula statement (see details for format) defining
the network structure, a directed acyclic graph (DAG).
Note that rownames must be set or given in <code>data.dist</code> if the DAG is
given via a formula statement.</p>
</td></tr>
<tr><td><code id="linkStrength_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data used for learning each node,
binary variables must be declared as factors.</p>
</td></tr>
<tr><td><code id="linkStrength_+3A_data.dists">data.dists</code></td>
<td>
<p>a named list giving the distribution for each node in the
network, see &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="linkStrength_+3A_method">method</code></td>
<td>
<p>the method to be used. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="linkStrength_+3A_discretization.method">discretization.method</code></td>
<td>
<p>a character vector giving the discretization
method to use. See <code><a href="#topic+discretization">discretization</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns multiple proxies for estimating the connection strength
of the edges of a possibly discretized Bayesian network's data set.
The returned connection strength measures are: the Raw Mutual Information
(<code>mi.raw</code>), the Percentage Mutual information (<code>mi.raw.pc</code>),
the Raw Mutual Information computed via correlation (<code>mi.corr</code>),
the link strength (<code>ls</code>), the percentage link strength (<code>ls.pc</code>)
and the statistical distance (<code>stat.dist</code>).
</p>
<p>The general concept of entropy is defined for probability distributions.
The probability is estimated from data using frequency tables.
Then the estimates are plug-in in the definition of the entropy to return
the so-called empirical entropy. A standard known problem of empirical entropy
is that the estimations are biased due to the sampling noise.
This is also known that the bias will decrease as the sample size increases.
The mutual information estimation is computed from the observed frequencies
through a plug-in estimator based on entropy.
For the case of an arc going from the node X to the node Y and the remaining
set of parent of Y is denoted as Z.
</p>
<p>The mutual information is defined as I(X, Y) = H(X) + H(Y) - H(X, Y),
where H() is the entropy.
</p>
<p>The Percentage Mutual information is defined as PI(X,Y) = I(X,Y)/H(Y|Z).
</p>
<p>The Mutual Information computed via correlation is defined as
MI(X,Y) = -0.5 log(1-cor(X,Y)^2).
</p>
<p>The link strength is defined as LS(X-&gt;Y) = H(Y|Z)-H(Y|X,Z).
</p>
<p>The percentage link strength is defined as PLS(X-&gt;Y) = LS(X-&gt;Y) / H(Y|Z).
</p>
<p>The statistical distance is defined as SD(X,Y) = 1- MI(X,Y) / max(H(X),H(Y)).
</p>


<h3>Value</h3>

<p>The function returns a named matrix with the requested metric.
</p>


<h3>References</h3>

<p>Boerlage, B. (1992).  Link strength in Bayesian networks. Diss. University of British Columbia.
Ebert-Uphoff, Imme. &quot;Tutorial on how to measure link strengths in discrete Bayesian networks.&quot; (2009).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Gaussian
N &lt;- 1000
mydists &lt;- list(a="gaussian",
                b="gaussian",
                c="gaussian")
a &lt;- rnorm(n = N, mean = 0, sd = 1)
b &lt;- 1 + 2*rnorm(n = N, mean = 5, sd = 1)
c &lt;- 2 + 1*a + 2*b + rnorm(n = N, mean = 2, sd = 1)
mydf &lt;- data.frame("a" = a,
                   "b" = b,
                   "c" = c)
mycache.mle &lt;- buildScoreCache(data.df = mydf,
                               data.dists = mydists,
                               method = "mle",
                               max.parents = 2)
mydag.mp &lt;- mostProbable(score.cache = mycache.mle, verbose = FALSE)
linkstr &lt;- linkStrength(dag = mydag.mp$dag,
                        data.df = mydf,
                        data.dists = mydists,
                        method = "ls",
                        discretization.method = "sturges")
</code></pre>

<hr>
<h2 id='logit'>Logit of proportions</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>See also the C implementation <code>?abn::logit_cpp()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logit_+3A_x">x</code></td>
<td>
<p>numeric with values between <code>[0,1]</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of same length as <code>x</code>.
</p>
<p>numeric vector of same length as <code>x</code>.
</p>

<hr>
<h2 id='logit_cpp'>logit functions</h2><span id='topic+logit_cpp'></span>

<h3>Description</h3>

<p>transform <code>x</code> either via the logit, or expit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit_cpp(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logit_cpp_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector
</p>

<hr>
<h2 id='logLik.abnFit'>Print logLik of objects of class <code>abnFit</code></h2><span id='topic+logLik.abnFit'></span>

<h3>Description</h3>

<p>Print logLik of objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
logLik(object, digits = 3L, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logLik.abnFit_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="logLik.abnFit_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="logLik.abnFit_+3A_verbose">verbose</code></td>
<td>
<p>print additional output.</p>
</td></tr>
<tr><td><code id="logLik.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the logLik of the fitted model.
</p>

<hr>
<h2 id='makebugs'>Make BUGS model from fitted DAG</h2><span id='topic+makebugs'></span>

<h3>Description</h3>

<p>Make BUGS model from fitted DAG
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makebugs(dag, data.dists, coefs, stderrors)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makebugs_+3A_dag">dag</code></td>
<td>
<p>named adjacency matrix representing the DAG. Names correspond to node names.</p>
</td></tr>
<tr><td><code id="makebugs_+3A_data.dists">data.dists</code></td>
<td>
<p>list of node distributions.</p>
</td></tr>
<tr><td><code id="makebugs_+3A_coefs">coefs</code></td>
<td>
<p>a list named by the node names containing for each element a matrix with the nodes' coefficients.</p>
</td></tr>
<tr><td><code id="makebugs_+3A_stderrors">stderrors</code></td>
<td>
<p>a list named by the node names containing for each element a matrix with the nodes' standard errors</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bugs model returned as stdout.
</p>


<h3>See Also</h3>

<p><a href="#topic+simulateAbn">simulateAbn</a> <a href="#topic+gauss_bugs">gauss_bugs</a> <a href="#topic+bern_bugs">bern_bugs</a> <a href="#topic+categorical_bugs">categorical_bugs</a> <a href="#topic+pois_bugs">pois_bugs</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Prepare data and arguments
mydists &lt;- list(a="gaussian",
                b="multinomial",
                c="binomial",
                d="poisson")
mydag &lt;- matrix(0, 4, 4, byrow = TRUE,
                dimnames = list(c("a", "b", "c", "d"),
                                c("a", "b", "c", "d")))
mydag[2,1] &lt;- mydag[3,2] &lt;- mydag[4,3] &lt;- 1
# plotAbn(mydag, data.dists = mydists)
mycoefs &lt;- list("a"=matrix(-6.883383e-17, byrow = TRUE,
                           dimnames = list(NULL,
                                           "a|intercept")),
                "b"=matrix(c(2.18865, 3.133928, 3.138531, 1.686432, 3.134161, 5.052104),
                           nrow= 1, byrow = TRUE,
                           dimnames = list(c(NULL),
                                      c("b|intercept.2", "b|intercept.3", "b|intercept.4",
                                      "a.2", "a.3", "a.4"))),
                "c"=matrix(c(1.11, 2.22, 3.33, 4.44, 5.55),
                           nrow= 1, byrow = TRUE,
                           dimnames = list(c(NULL),
                                      c("c|intercept", "b1", "b2", "b3", "b4"))),
                "d"=matrix(c(3.33, 4.44),
                           nrow= 1, byrow = TRUE,
                           dimnames = list(c(NULL),
                                      c("d|intercept", "c"))))
mymse &lt;- c("a"=0,"b"=1,"c"=2,"d"=3)
## Make BUGS model
makebugs(dag = mydag, data.dists = mydists, coefs = mycoefs, stderrors = mymse)

</code></pre>

<hr>
<h2 id='makebugsGroup'>Make BUGS model from fitted DAG with grouping</h2><span id='topic+makebugsGroup'></span>

<h3>Description</h3>

<p>Make BUGS model from fitted DAG with grouping
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makebugsGroup(
  dag,
  data.dists,
  stderrors,
  group.var,
  mu,
  betas,
  sigma,
  sigma_alpha
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makebugsGroup_+3A_dag">dag</code></td>
<td>
<p>named adjacency matrix representing the DAG. Names correspond to node names.</p>
</td></tr>
<tr><td><code id="makebugsGroup_+3A_data.dists">data.dists</code></td>
<td>
<p>list of node distributions.</p>
</td></tr>
<tr><td><code id="makebugsGroup_+3A_stderrors">stderrors</code></td>
<td>
<p>a list named by the node names containing for each element a matrix with the nodes' standard errors</p>
</td></tr>
<tr><td><code id="makebugsGroup_+3A_group.var">group.var</code></td>
<td>
<p>only applicable for mixed models and gives the column name in <code>data.df</code> of the grouping variable (which must be a factor denoting group membership).</p>
</td></tr>
<tr><td><code id="makebugsGroup_+3A_mu">mu</code></td>
<td>
<p>Standard deviation of fixed effects.</p>
</td></tr>
<tr><td><code id="makebugsGroup_+3A_betas">betas</code></td>
<td>
<p>Coefficients/slopes of fixed effects .</p>
</td></tr>
<tr><td><code id="makebugsGroup_+3A_sigma">sigma</code></td>
<td>
<p>variance of random effects.</p>
</td></tr>
<tr><td><code id="makebugsGroup_+3A_sigma_alpha">sigma_alpha</code></td>
<td>
<p>variance-covariance matrix corresponding to covariances output from <code><a href="mclogit.html#topic+mblogit">mblogit</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bugs model returned as stdout.
</p>


<h3>See Also</h3>

<p><a href="#topic+simulateAbn">simulateAbn</a> <a href="#topic+gauss_bugsGroup">gauss_bugsGroup</a> <a href="#topic+bern_bugsGroup">bern_bugsGroup</a> <a href="#topic+categorical_bugsGroup">categorical_bugsGroup</a> <a href="#topic+pois_bugsGroup">pois_bugsGroup</a>
</p>

<hr>
<h2 id='mb'>Compute the Markov blanket</h2><span id='topic+mb'></span>

<h3>Description</h3>

<p>This function computes the Markov blanket of a set of nodes given a DAG (Directed Acyclic Graph).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mb(dag, node, data.dists = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mb_+3A_dag">dag</code></td>
<td>
<p>a matrix or a formula statement (see details for format) defining the network structure, a directed acyclic graph (DAG).</p>
</td></tr>
<tr><td><code id="mb_+3A_node">node</code></td>
<td>
<p>a character vector of the nodes for which the Markov Blanket should be returned.</p>
</td></tr>
<tr><td><code id="mb_+3A_data.dists">data.dists</code></td>
<td>
<p>a named list giving the distribution for each node in the network, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns the Markov Blanket of a set of nodes given a DAG.
</p>
<p>The <code>dag</code> can be provided using a formula statement (similar to glm). A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>. The formula statement have to start with <code>~</code>. In this example, node1 has two parents (parent1 and parent2). node2 and node3 have the same parent3. The parents names have to exactly match those given in <code>name</code>. <code>:</code> is the separtor between either children or parents, <code>|</code> separates children (left side) and parents (right side), <code>+</code> separates terms, <code>.</code> replaces all the variables in <code>name</code>.
</p>


<h3>Value</h3>

<p>character vector of node names from the Markov blanket.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Defining distribution and dag
dist &lt;- list(a="gaussian", b="gaussian", c="gaussian", d="gaussian",
             e="binomial", f="binomial")
dag &lt;- matrix(c(0,1,1,0,1,0,
                0,0,1,1,0,1,
                0,0,0,0,0,0,
                0,0,0,0,0,0,
                0,0,0,0,0,1,
                0,0,0,0,0,0), nrow = 6L, ncol = 6L, byrow = TRUE)
colnames(dag) &lt;- rownames(dag) &lt;- names(dist)

mb(dag, node = "b")
mb(dag, node = c("b","e"))

mb(~a|b:c:e+b|c:d:f+e|f, node = "e", data.dists = dist)
</code></pre>

<hr>
<h2 id='mi_cpp'>Mutual Information</h2><span id='topic+mi_cpp'></span>

<h3>Description</h3>

<p>Calculates the mutual information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mi_cpp(joint_dist)
</code></pre>


<h3>Value</h3>

<p>a double
</p>

<hr>
<h2 id='miData'>Empirical Estimation of the Entropy from a Table of Counts</h2><span id='topic+miData'></span>

<h3>Description</h3>

<p>This function empirically estimates the Mutual Information from a table of counts using the observed frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>miData(freqs.table, method = c("mi.raw", "mi.raw.pc"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="miData_+3A_freqs.table">freqs.table</code></td>
<td>
<p>a table of counts.</p>
</td></tr>
<tr><td><code id="miData_+3A_method">method</code></td>
<td>
<p>a character determining if the Mutual Information should be normalized.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mutual information estimation is computed from the observed frequencies through a plugin estimator based on entropy.
</p>
<p>The plugin estimator is </p>
<p style="text-align: center;"><code class="reqn">I(X, Y) = H (X) + H(Y) - H(X, Y)</code>
</p>
<p>, where </p>
<p style="text-align: center;"><code class="reqn">H()</code>
</p>
<p> is the entropy computed with <code><a href="#topic+entropyData">entropyData</a></code>.
</p>


<h3>Value</h3>

<p>Mutual information estimate.
</p>
<p>integer
</p>


<h3>References</h3>

<p>Cover, Thomas M, and Joy A Thomas. (2012). &quot;Elements of Information Theory&quot;. John Wiley &amp; Sons.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+discretization">discretization</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate random variable
Y &lt;- rnorm(n = 100, mean = 0, sd = 2)
X &lt;- rnorm(n = 100, mean = 5, sd = 2)

dist &lt;- list(Y="gaussian", X="gaussian")

miData(discretization(data.df = cbind(X,Y), data.dists = dist,
                      discretization.method = "fd", nb.states = FALSE),
                      method = "mi.raw")
</code></pre>

<hr>
<h2 id='modes2coefs'>Convert modes to fitAbn.mle$coefs structure</h2><span id='topic+modes2coefs'></span>

<h3>Description</h3>

<p>Convert modes to fitAbn.mle$coefs structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modes2coefs(modes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modes2coefs_+3A_modes">modes</code></td>
<td>
<p>list of modes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of matrix arrays.
</p>

<hr>
<h2 id='mostProbable'>Find most probable DAG structure</h2><span id='topic+mostProbable'></span>

<h3>Description</h3>

<p>Find most probable DAG structure using exact order based approach due to Koivisto and Sood, 2004.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mostProbable(score.cache, score="bic", prior.choice=1, verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mostProbable_+3A_score.cache">score.cache</code></td>
<td>
<p>object of class <code>abnCache</code> typically outputted by from <code>buildScoreCache()</code>.</p>
</td></tr>
<tr><td><code id="mostProbable_+3A_score">score</code></td>
<td>
<p>which score should be used to score the network. Possible choices are <code>aic, bic, mdl, mlik</code>.</p>
</td></tr>
<tr><td><code id="mostProbable_+3A_prior.choice">prior.choice</code></td>
<td>
<p>an integer, 1 or 2, where 1 is a uniform structural prior and 2 uses a weighted prior, see details</p>
</td></tr>
<tr><td><code id="mostProbable_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE then provides some additional output.</p>
</td></tr>
<tr><td><code id="mostProbable_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure runs the exact order based structure discovery approach of Koivisto and Sood (2004) to find the most probable posterior network (DAG). The local.score is the node cache, as created using <code><a href="#topic+buildScoreCache">buildScoreCache</a></code> (or manually provided the same format is used). Note that the scope of this search is given by the options used in local.score, for example, by restricting the number of parents or the ban or retain constraints given there.
</p>
<p>This routine can take a long time to complete and is highly sensitive to the number of nodes in the network. It is recommended to use this on a reduced data set to get an idea as to the computational practicality of this approach.  In particular, memory usage can quickly increase to beyond what may be available. For additive models, problems comprising up to 20 nodes are feasible on most machines. Memory requirements can increase considerably after this, but then so does the run time making this less practical. It is recommended that some form of over-modeling adjustment is performed on this resulting DAG (unless dealing with vast numbers of observations), for example, using parametric bootstrapping, which is straightforward to implement in MCMC engines such as JAGS or WinBUGS. See the case studies at <a href="https://r-bayesian-networks.org/">https://r-bayesian-networks.org/</a>
or the files provided in the package directories <code>inst/bootstrapping_example</code> and <code>inst/old_vignette</code>
for details.
</p>
<p>The parameter <code>prior.choice</code> determines the prior used within each node for a given choice of parent combination. In Koivisto and Sood (2004) p.554, a form of prior is used, which assumes that the prior probability for parent combinations comprising of the same number of parents are all equal. Specifically, that the prior probability for parent set G with cardinality |G| is proportional to <code>1/[n-1 choose |G|]</code> where there are n total nodes. Note that this favors parent combinations with either very low or very high cardinality, which may not be appropriate. This prior is used when <code>prior.choice=2</code>. When <code>prior.choice=1</code> an uninformative prior is used where parent combinations of all cardinalities are equally likely. The latter is equivalent to the structural prior used in the heuristic searches e.g., <code>searchHillclimber</code> or <code>searchHeuristic</code>.
</p>
<p>Note that the network score (log marginal likelihood) of the most probable DAG is not returned as it can easily be computed using <code><a href="#topic+fitAbn">fitAbn</a></code>, see examples below.
</p>


<h3>Value</h3>

<p>An object of class <code>abnMostprobable</code>, which is a list containing: a matrix giving the DAG definition of the most probable posterior structure, the cache of pre-computed scores and the score used for selection.
</p>


<h3>References</h3>

<p>Koivisto, M. V. (2004). Exact Structure Discovery in Bayesian Networks, Journal of Machine Learning Research, vol 5, 549-573.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##############################
## Example 1
##############################
## This data comes with 'abn' see ?ex1.dag.data
mydat &lt;- ex1.dag.data[1:5000, c(1:7, 10)]

## Setup distribution list for each node:
mydists &lt;- list(b1 = "binomial",
                p1 = "poisson",
                g1 = "gaussian",
                b2 = "binomial",
                p2 = "poisson",
                b3 = "binomial",
                g2 = "gaussian",
                g3 = "gaussian")

## Parent limits, for speed purposes quite specific here:
max_par &lt;- list("b1" = 0,
                "p1" = 0,
                "g1" = 1,
                "b2" = 1,
                "p2" = 2,
                "b3" = 3,
                "g2" = 3,
                "g3" = 2)
## Now build cache (no constraints in ban nor retain)
mycache &lt;- buildScoreCache(data.df = mydat,
                           data.dists = mydists,
                           max.parents = max_par)

## Find the globally best DAG:
mp_dag &lt;- mostProbable(score.cache = mycache)
myres &lt;- fitAbn(object = mp_dag,
                create.graph = TRUE)
plot(myres) # plot the best model

## Fit the known true DAG (up to variables 'b4' and 'b5'):
true_dag &lt;- matrix(data = 0, ncol = 8, nrow = 8)
colnames(true_dag) &lt;- rownames(true_dag) &lt;- names(mydists)

true_dag["p2", c("b1", "p1")] &lt;- 1
true_dag["b3", c("b1", "g1", "b2")] &lt;- 1
true_dag["g2", c("p1", "g1", "b2")] &lt;- 1
true_dag["g3", c("g1", "b2")] &lt;- 1

fitAbn(dag = true_dag,
       data.df = mydat,
       data.dists = mydists)$mlik

#################################################################
## Example 2 - models with random effects
#################################################################
## This data comes with abn see ?ex3.dag.data
mydat &lt;- ex3.dag.data[, c(1:4, 14)]
mydists &lt;- list(b1 = "binomial",
                b2 = "binomial",
                b3 = "binomial",
                b4 = "binomial")

## This takes a few seconds and requires INLA:
mycache_mixed &lt;- buildScoreCache(data.df = mydat,
                                 data.dists = mydists,
                                 group.var = "group",
                                 max.parents = 2)

## Find the most probable DAG:
mp_dag &lt;- mostProbable(score.cache = mycache_mixed)
## and get goodness of fit:
fitAbn(object = mp_dag,
       group.var = "group")$mlik

## End(Not run)
</code></pre>

<hr>
<h2 id='nobs.abnFit'>Print number of observations of objects of class <code>abnFit</code></h2><span id='topic+nobs.abnFit'></span>

<h3>Description</h3>

<p>Print number of observations of objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nobs.abnFit_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="nobs.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the number of observations of the fitted model.
</p>

<hr>
<h2 id='odds'>Probability to odds</h2><span id='topic+odds'></span>

<h3>Description</h3>

<p>Probability to odds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>odds(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="odds_+3A_x">x</code></td>
<td>
<p>numeric vector of probabilities with values between <code>[0,1]</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of same length as <code>x</code>.
</p>

<hr>
<h2 id='or'>Odds Ratio from a matrix</h2><span id='topic+or'></span>

<h3>Description</h3>

<p>Compute the odds ratio from a contingency table or a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>or(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="or_+3A_x">x</code></td>
<td>
<p>a 2x2 table or matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A real value.
</p>

<hr>
<h2 id='pigs.vienna'>Dataset related to diseases present in &lsquo;finishing pigs&rsquo;, animals about to enter the human food chain at an abattoir.</h2><span id='topic+pigs.vienna'></span>

<h3>Description</h3>

<p>The data we consider here comprise of a randomly chosen batch of 50 pigs from
each of 500 randomly chosen pig producers in the UK.
The dataset consists of 25000 observations, 10 binary variables, and a grouping variable.
These are &lsquo;finishing pigs&rsquo;, animals about to enter the human food chain at an abattoir.
Further description of the data set is present on the vignette.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pigs.vienna
</code></pre>


<h3>Format</h3>

<p>A data frame with a mixture of 10 discrete variables, each of which is set as a factor, and a grouping variable.
</p>

<dl>
<dt>PC</dt><dd><p>Binary.</p>
</dd>
<dt>PT</dt><dd><p>Binary. </p>
</dd>
<dt>MS</dt><dd><p>Binary.</p>
</dd>
<dt>HS</dt><dd><p>Binary.</p>
</dd>
<dt>TAIL</dt><dd><p>Binary.</p>
</dd>
<dt>Abscess</dt><dd><p>Binary.</p>
</dd>
<dt>Pyaemia</dt><dd><p>Binary.</p>
</dd>
<dt>EPcat</dt><dd><p>Binary.</p>
</dd>
<dt>PDcat</dt><dd><p>Binary.</p>
</dd>
<dt>plbinary</dt><dd><p>Binary.</p>
</dd>
<dt>batch</dt><dd><p>Group variable, corresponding to the 500 different pig producers</p>
</dd>
</dl>



<h3>Details</h3>

<p>This dataset was used in an older version of the vignette.
See also the files provided in the package directories
<code>inst/bootstrapping_example</code> and <code>inst/old_vignette</code> give a
detailed analysis of the dataset and provide more details for a
bootstrapping example thereof.
</p>


<h3>References</h3>

<p>Hartnack, S., et al. (2016) &quot;Attitudes of Austrian veterinarians towards euthanasia in small animal practice: impacts of age and gender on views on euthanasia.&quot; BMC Veterinary Research 12.1: 26.
</p>

<hr>
<h2 id='plot.abnDag'>Plots DAG from an object of class <code>abnDag</code></h2><span id='topic+plot.abnDag'></span>

<h3>Description</h3>

<p>Plots DAG from an object of class <code>abnDag</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnDag'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abnDag_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnDag</code></p>
</td></tr>
<tr><td><code id="plot.abnDag_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Rgraphviz::plot</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mydag &lt;- createAbnDag(dag = ~a+b|a,
                      data.df = data.frame("a"=1, "b"=1),
                      data.dists = list(a="binomial", b="gaussian"))
plot(mydag)
</code></pre>

<hr>
<h2 id='plot.abnFit'>Plot objects of class <code>abnFit</code></h2><span id='topic+plot.abnFit'></span>

<h3>Description</h3>

<p>Plot objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abnFit_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="plot.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a plot of the fitted model.
</p>

<hr>
<h2 id='plot.abnHeuristic'>Plot objects of class <code>abnHeuristic</code></h2><span id='topic+plot.abnHeuristic'></span>

<h3>Description</h3>

<p>Plot objects of class <code>abnHeuristic</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnHeuristic'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abnHeuristic_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnHeuristic</code></p>
</td></tr>
<tr><td><code id="plot.abnHeuristic_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot of the scores of the heuristic search.
</p>

<hr>
<h2 id='plot.abnHillClimber'>Plot objects of class <code>abnHillClimber</code></h2><span id='topic+plot.abnHillClimber'></span>

<h3>Description</h3>

<p>Plot objects of class <code>abnHillClimber</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnHillClimber'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abnHillClimber_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnHillClimber</code></p>
</td></tr>
<tr><td><code id="plot.abnHillClimber_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot of the consensus DAG.
</p>

<hr>
<h2 id='plot.abnMostprobable'>Plot objects of class <code>abnMostprobable</code></h2><span id='topic+plot.abnMostprobable'></span>

<h3>Description</h3>

<p>Plot objects of class <code>abnMostprobable</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnMostprobable'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.abnMostprobable_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnMostprobable</code></p>
</td></tr>
<tr><td><code id="plot.abnMostprobable_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot of the mostprobable consensus DAG.
</p>

<hr>
<h2 id='plotAbn'>Plot an ABN graphic</h2><span id='topic+plotAbn'></span>

<h3>Description</h3>

<p>Plot an ABN DAG using formula statement or a matrix in using Rgraphviz through the graphAM class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotAbn(dag, data.dists=NULL, markov.blanket.node=NULL, fitted.values=NULL,
               digits=2, edge.strength=NULL, edge.strength.lwd=5, edge.direction="pc",
               edge.color="black", edge.linetype="solid", edge.arrowsize=0.6,
               edge.fontsize=node.fontsize, node.fontsize=12,
               node.fillcolor=c("lightblue", "brown3", "chartreuse3"),
               node.fillcolor.list=NULL,
               node.shape=c("circle", "box", "ellipse", "diamond"),
               plot=TRUE , ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotAbn_+3A_dag">dag</code></td>
<td>
<p>a matrix or a formula statement (see details for format) defining
the network structure, a Directed Acyclic Graph (DAG).
Note that rownames must be set or given in <code>data.dists</code>.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_data.dists">data.dists</code></td>
<td>
<p>a named list giving the distribution for each node in the network, see details.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_markov.blanket.node">markov.blanket.node</code></td>
<td>
<p>name of variables to display its Markov blanket.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_fitted.values">fitted.values</code></td>
<td>
<p>modes or coefficents outputted from <code><a href="#topic+fitAbn">fitAbn</a></code>.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_digits">digits</code></td>
<td>
<p>number of digits to display the <code>fitted.values</code>.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_edge.strength">edge.strength</code></td>
<td>
<p>a named matrix containing evaluations of edge strength
which will change the arcs width (could be Mutual information, p-values,
number of bootstrap retrieve samples or the outcome of the <code><a href="#topic+linkStrength">linkStrength</a></code>).</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_edge.strength.lwd">edge.strength.lwd</code></td>
<td>
<p>maximum line width for <code>edge.strength</code>.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_edge.direction">edge.direction</code></td>
<td>
<p>character giving the direction in which arcs should
be plotted, <code>pc</code> (parent to child) or <code>cp</code> (child to parent) or <code>undirected</code>.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_edge.color">edge.color</code></td>
<td>
<p>the colour of the edge.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_edge.linetype">edge.linetype</code></td>
<td>
<p>the linetype of the edge. Defaults to <code>"solid"</code>.
Valid values are the same as for the R's base graphic parameter <code>lty</code>.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_edge.arrowsize">edge.arrowsize</code></td>
<td>
<p>the thickness of the arrows. Not relevant if <code>arc.strength</code> is provided.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_edge.fontsize">edge.fontsize</code></td>
<td>
<p>the font size of the arcs fitted values.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_node.fontsize">node.fontsize</code></td>
<td>
<p>the font size of the nodes names.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_node.fillcolor">node.fillcolor</code></td>
<td>
<p>the colour of the node. Second and third element is
used for the Markov blanket and node of the Markov blanket.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_node.fillcolor.list">node.fillcolor.list</code></td>
<td>
<p>the list of node that should be coloured.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_node.shape">node.shape</code></td>
<td>
<p>the shape of the nodes according the Gaussian, binomial, Poisson and multinomial distributions.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_plot">plot</code></td>
<td>
<p>logical variable, if set to <code>TRUE</code> then the graph is plotted.</p>
</td></tr>
<tr><td><code id="plotAbn_+3A_...">...</code></td>
<td>
<p>arguments passed to the plotting function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default binomial nodes are squares, multinomial nodes are empty, Gaussian nodes are circles and poison nodes are ellipses.
</p>
<p>The <code>dag</code> can be provided using a formula statement (similar to glm). A typical formula is <code> ~ node1|parent1:parent2 + node2:node3|parent3</code>.
</p>
<p>The construction is based on the <span class="pkg">graph</span> package. Properties of the graph can be changed after the construction, see &lsquo;Examples&rsquo;.
</p>


<h3>Value</h3>

<p>A rendered graph, if <code>plot=TRUE</code>. The <code>graphAM</code> object is returned invisibly.
</p>


<h3>See Also</h3>

<p><code><a href="graph.html#topic+graphAM-class">graphAM-class</a></code>, <code><a href="graph.html#topic+edgeRenderInfo">edgeRenderInfo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Define distribution list
dist &lt;- list(a = "gaussian",
             b = "gaussian",
             c = "gaussian",
             d = "gaussian",
             e = "binomial",
             f = "binomial")

# Define a matrix formulation
edge_strength &lt;- matrix(c(0, 0.5, 0.5, 0.7, 0.1, 0,
                          0, 0, 0.3, 0.1, 0, 0.8,
                          0, 0, 0, 0.35, 0.66, 0,
                          0, 0, 0, 0, 0.9, 0,
                          0, 0, 0, 0, 0, 0.8,
                          0, 0, 0, 0, 0, 0),
                        nrow = 6L,
                        ncol = 6L,
                        byrow = TRUE)

## Naming of the matrix
colnames(edge_strength) &lt;- rownames(edge_strength) &lt;- names(dist)

## Plot form a matrix
plotAbn(dag = edge_strength,
        data.dists = dist)

## Edge strength
plotAbn(dag = ~ a | b:c:d:e + b | c:d:f + c | d:e + d | e + e | f,
        data.dists = dist,
        edge.strength = edge_strength)

## Plot from a formula for a different DAG!
plotAbn(dag = ~ a | b:c:e + b | c:d:f + e | f,
        data.dists = dist)

## Markov blanket
plotAbn(dag = ~ a | b:c:e + b | c:d:f + e | f,
        data.dists = dist,
        markov.blanket.node = "e")

## Change col for all edges
tmp &lt;- plotAbn(dag = ~ a | b:c:e + b | c:d:f + e | f,
               data.dists = dist,
               plot = FALSE)
graph::edgeRenderInfo(tmp) &lt;- list(col = "blue")
Rgraphviz::renderGraph(tmp)

## Change lty for individual ones. Named vector is necessary
tmp &lt;- plotAbn(dag = ~ a | b:c:e + b | c:d:f + e | f,
               data.dists = dist,
               plot = FALSE)
edgelty &lt;- rep(c("solid", "dotted"), c(6, 1))
names(edgelty) &lt;- names(graph::edgeRenderInfo(tmp, "col"))
graph::edgeRenderInfo(tmp) &lt;- list(lty = edgelty)
Rgraphviz::renderGraph(tmp)
</code></pre>

<hr>
<h2 id='pois_bugs'>Bugs code for Poisson response</h2><span id='topic+pois_bugs'></span><span id='topic+pois_bugsGroup'></span>

<h3>Description</h3>

<p>Bugs model for count response variable
<code class="reqn">X \sim \mathcal{Pois}(\lambda)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pois_bugs(nodename, nodesintercept, parentnames, parentcoefs)

pois_bugsGroup(nodename, nodesintercept, parentnames, parentcoefs, sigma_alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pois_bugs_+3A_nodename">nodename</code></td>
<td>
<p>character string of response variable name.</p>
</td></tr>
<tr><td><code id="pois_bugs_+3A_nodesintercept">nodesintercept</code></td>
<td>
<p>overall mean of response. Parameter from fixed-effects intercept.</p>
</td></tr>
<tr><td><code id="pois_bugs_+3A_parentnames">parentnames</code></td>
<td>
<p>single character string (for one parent) or vector of characters (for multiple parent nodes) with parent node (predictor variables) names.</p>
</td></tr>
<tr><td><code id="pois_bugs_+3A_parentcoefs">parentcoefs</code></td>
<td>
<p>overall slope for each predictor (parent node) variable (fixed-effects).</p>
</td></tr>
<tr><td><code id="pois_bugs_+3A_sigma_alpha">sigma_alpha</code></td>
<td>
<p>between-group variance. Parameter from random-effects intercept.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bugs model returned as stdout.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>pois_bugsGroup()</code>: Bugs code for Poisson response with varying intercept
</p>
</li></ul>


<h3>See Also</h3>

<p><a href="#topic+makebugs">makebugs</a> <a href="#topic+simulateAbn">simulateAbn</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pois_bugs(nodename = "a",
          parentnames = c("b", "c"),
          nodesintercept = c(0.318077),
          parentcoefs = list("b"=c(b=0.3059395),
                             "c"=c(c=0.5555)))
</code></pre>

<hr>
<h2 id='print.abnCache'>Print objects of class <code>abnCache</code></h2><span id='topic+print.abnCache'></span>

<h3>Description</h3>

<p>Print objects of class <code>abnCache</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnCache'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abnCache_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnCache</code></p>
</td></tr>
<tr><td><code id="print.abnCache_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="print.abnCache_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>summary statement of the class of <code>abnCache</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Subset of the build-in dataset, see  ?ex0.dag.data
mydat &lt;- ex0.dag.data[,c("b1","b2","g1","g2","b3","g3")] ## take a subset of cols

## setup distribution list for each node
mydists &lt;- list(b1="binomial", b2="binomial", g1="gaussian",
                g2="gaussian", b3="binomial", g3="gaussian")

# Structural constraints
# ban arc from b2 to b1
# always retain arc from g2 to g1

## parent limits
max.par &lt;- list("b1"=2, "b2"=2, "g1"=2, "g2"=2, "b3"=2, "g3"=2)

## now build the cache of pre-computed scores accordingly to the structural constraints
if(requireNamespace("INLA", quietly = TRUE)){
  # Run only if INLA is available
res.c &lt;- buildScoreCache(data.df=mydat, data.dists=mydists,
                         dag.banned= ~b1|b2, dag.retained= ~g1|g2, max.parents=max.par)
print(res.c)
}
</code></pre>

<hr>
<h2 id='print.abnDag'>Print objects of class <code>abnDag</code></h2><span id='topic+print.abnDag'></span>

<h3>Description</h3>

<p>Print objects of class <code>abnDag</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnDag'
print(x, digits = 3L, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abnDag_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnDag</code></p>
</td></tr>
<tr><td><code id="print.abnDag_+3A_digits">digits</code></td>
<td>
<p>number of digits of the adjacency matrix.</p>
</td></tr>
<tr><td><code id="print.abnDag_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>outputs adjacency matrix and statement of the class of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mydag &lt;- createAbnDag(dag = ~a+b|a, data.df = data.frame("a"=1, "b"=1))
print(mydag)
</code></pre>

<hr>
<h2 id='print.abnFit'>Print objects of class <code>abnFit</code></h2><span id='topic+print.abnFit'></span>

<h3>Description</h3>

<p>Print objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
print(x, digits = 3L, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abnFit_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="print.abnFit_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="print.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the parameters of the fitted model.
</p>

<hr>
<h2 id='print.abnHeuristic'>Print objects of class <code>abnHeuristic</code></h2><span id='topic+print.abnHeuristic'></span>

<h3>Description</h3>

<p>Print objects of class <code>abnHeuristic</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnHeuristic'
print(x, digits = 2L, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abnHeuristic_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnHeuristic</code></p>
</td></tr>
<tr><td><code id="print.abnHeuristic_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="print.abnHeuristic_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the best score found and the distribution of the scores.
</p>

<hr>
<h2 id='print.abnHillClimber'>Print objects of class <code>abnHillClimber</code></h2><span id='topic+print.abnHillClimber'></span>

<h3>Description</h3>

<p>Print objects of class <code>abnHillClimber</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnHillClimber'
print(x, digits = 3L, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abnHillClimber_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnHillClimber</code></p>
</td></tr>
<tr><td><code id="print.abnHillClimber_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="print.abnHillClimber_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the consensus DAG and the class of the object.
</p>

<hr>
<h2 id='print.abnMostprobable'>Print objects of class <code>abnMostprobable</code></h2><span id='topic+print.abnMostprobable'></span>

<h3>Description</h3>

<p>Print objects of class <code>abnMostprobable</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnMostprobable'
print(x, digits = 3L, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.abnMostprobable_+3A_x">x</code></td>
<td>
<p>Object of class <code>abnMostprobable</code></p>
</td></tr>
<tr><td><code id="print.abnMostprobable_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="print.abnMostprobable_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the mostprobable consensus DAG.
</p>

<hr>
<h2 id='rank_cpp'>Rank of a matrix</h2><span id='topic+rank_cpp'></span>

<h3>Description</h3>

<p>similar to <code>base::rank</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rank_cpp(A)
</code></pre>


<h3>Value</h3>

<p>an integer
</p>

<hr>
<h2 id='scoreContribution'>Compute the score's contribution in a network of each observation.</h2><span id='topic+scoreContribution'></span>

<h3>Description</h3>

<p>This function computes the score's contribution of each observation to the total network score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreContribution(object = NULL,
                         dag = NULL, data.df = NULL, data.dists = NULL,
                         verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scoreContribution_+3A_object">object</code></td>
<td>
<p>an object of class '<code>abnLearned</code>'
produced by <code><a href="#topic+mostProbable">mostProbable</a></code>,
<code><a href="#topic+searchHeuristic">searchHeuristic</a></code> or <code><a href="#topic+searchHillClimber">searchHillClimber</a></code>.</p>
</td></tr>
<tr><td><code id="scoreContribution_+3A_dag">dag</code></td>
<td>
<p>a matrix or a formula statement (see details) defining the network structure,
a directed acyclic graph (DAG), see details for format.
Note that colnames and rownames must be set.</p>
</td></tr>
<tr><td><code id="scoreContribution_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data used for learning the network,
binary variables must be declared as factors and
no missing values all allowed in any variable.</p>
</td></tr>
<tr><td><code id="scoreContribution_+3A_data.dists">data.dists</code></td>
<td>
<p>a named list giving the distribution for each node
in the network, see details.</p>
</td></tr>
<tr><td><code id="scoreContribution_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code> then provides some additional output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the score contribution of each observation
to the total network score.
This function is available only in the <code>mle</code> settings.
To do so one uses the <code><a href="stats.html#topic+glm">glm</a></code> and <code><a href="stats.html#topic+predict">predict</a></code> functions.
This function is an attempt to perform diagnostic for an ABN analysis.
</p>


<h3>Value</h3>

<p>A named list that contains the scores contributions:
maximum likelihood, aic, bic, mdl and diagonal values of the hat matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Use a subset of a built-in simulated data set
mydat &lt;- ex1.dag.data[,c("b1","g1","p1")]

## setup distribution list for each node
mydists &lt;- list(b1="binomial", g1="gaussian", p1="poisson")

## now build cache
mycache &lt;- buildScoreCache(data.df = mydat, data.dists = mydists, max.parents = 2, method = "mle")

## Find the globally best DAG
mp.dag &lt;- mostProbable(score.cache=mycache, score="bic", verbose = FALSE)

out &lt;- scoreContribution(object = mp.dag)

## Observations contribution per network node
boxplot(out$bic)

## End(Not run)
</code></pre>

<hr>
<h2 id='searchHeuristic'>A family of heuristic algorithms that aims at finding high scoring directed acyclic graphs</h2><span id='topic+searchHeuristic'></span>

<h3>Description</h3>

<p>A flexible implementation of multiple greedy search algorithms to find high scoring network (DAG)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>searchHeuristic(score.cache, score = "mlik",
                       num.searches = 1, seed = 42L, start.dag = NULL,
                       max.steps = 100,
                       algo = "hc", tabu.memory = 10, temperature = 0.9,
                       verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="searchHeuristic_+3A_score.cache">score.cache</code></td>
<td>
<p>output from <code>buildScoreCache()</code>.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_score">score</code></td>
<td>
<p>which score should be used to score the network. Possible choices are <code>aic, bic, mdl, mlik</code>.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_num.searches">num.searches</code></td>
<td>
<p>a positive integer giving the number of different search to run, see details.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_seed">seed</code></td>
<td>
<p>a non-negative integer which sets the seed.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_start.dag">start.dag</code></td>
<td>
<p>a DAG given as a matrix, see details for format, which can be used to explicity provide a starting point for the structural search.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_max.steps">max.steps</code></td>
<td>
<p>a constant giving the number of search steps per search, see details.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_algo">algo</code></td>
<td>
<p>which heuristic algorithm should be used. Possible choices are: <code>hc, tabu, sa</code>.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_tabu.memory">tabu.memory</code></td>
<td>
<p>a non-negative integer number to set the memory of the <code>tabu</code> search.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_temperature">temperature</code></td>
<td>
<p>a real number giving the update in temperature for the <code>sa</code> (simulated annealing) search algorithm.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE then provides some additional output.</p>
</td></tr>
<tr><td><code id="searchHeuristic_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a flexible implementation of multiple greedy heuristic algorithms,
particularly well adapted to the <code>abn</code> framework.
It targets multi-random restarts heuristic algorithms.
The user can select the <code>num.searches</code> and the maximum number of steps
within by <code>max.steps</code>. The optimization algorithm within each search is
relatively rudimentary.
</p>
<p>The function <code>searchHeuristic</code> is different from the
<code><a href="#topic+searchHillClimber">searchHillClimber</a></code> in the sense that this function is fully
written in R, whereas the <code><a href="#topic+searchHillClimber">searchHillClimber</a></code> is written in C
and thus expected to be faster. The function <code><a href="#topic+searchHillClimber">searchHillClimber</a></code>
at each hill-climbing step consider every information from the pre-computed
scores cache while the function <code><a href="#topic+searchHeuristic">searchHeuristic</a></code> performs a local
stepwise optimization. This function chooses a structural move (or edge move)
and compute the score's change. On this point, it is closer to the MCMCMC
algorithm from Madigan and York (1995) and Giudici and Castelo (2003)
with a single edge move.
</p>
<p>If the user select <code>random</code>, then a random valid DAG is selected.
The routine used favourise low density structure.
The function implements three algorithm selected with the
parameter <code>algo</code>: <code>hc</code>, <code>tabu</code> or <code>sa</code>.
</p>
<p>If <code>algo=hc</code>:
The Hill-climber algorithm (<code>hc</code>) is a single move algorithm.
At each Hill-climbing step within a search an arc is attempted to be added.
The new score is computed and compared to the previous network's score.
</p>
<p>If <code>algo=tabu</code>:
The same algorithm is as with <code>hc</code> is used, but a list of banned moves
is computed. The parameter <code>tabu.memory</code> controls the length of the tabu
list. The idea is that the classical Hill-climber algorithm is inefficient
when it should cross low probability regions to unblock from a local maximum
and reaching a higher score peak. By forcing the algorithm to choose some not
already used moves, this will force the algorithm to escape the local maximum.
</p>
<p>If <code>algo=sa</code>:
This variant of the heuristic search algorithm is based on simulated annealing
described by Metropolis et al. (1953).
Some accepted moves could result in a decrease of the network score.
The acceptance rate can be monitored with the parameter <code>temperature</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>abnHeuristic</code> (which extends the class <code>abnLearnd</code>) and contains list with entires:
</p>

<dl>
<dt>dags</dt><dd><p>a list of DAGs</p>
</dd>
<dt>scores</dt><dd><p>a vector giving the network score for the locally optimal network for each search</p>
</dd>
<dt>detailed.score</dt><dd><p>a vector giving the evolution of the network score for the all the random restarts</p>
</dd>
<dt>score</dt><dd><p>a number giving the network score for the locally optimal network</p>
</dd>
<dt>score.cache</dt><dd><p>the pre-computed cache of scores</p>
</dd>
<dt>num.searches</dt><dd><p>a numeric giving the number of random restart</p>
</dd>
<dt>max.steps</dt><dd><p>a numeric giving the maximal number of optimization steps within each search</p>
</dd>
<dt>algorithm</dt><dd><p>a character for indicating the algorithm used</p>
</dd>
</dl>



<h3>References</h3>

<p>Heckerman, D., Geiger, D. and Chickering, D. M. (1995). Learning Bayesian networks: The combination of knowledge and statistical data. <em>Machine Learning</em>, 20, 197-243.
Madigan, D. and York, J. (1995) &quot;Bayesian graphical models for discrete data&quot;. International Statistical Review, 63:215232.
Giudici, P. and Castelo, R. (2003). &quot;Improving Markov chain Monte Carlo model search for data mining&quot;. Machine Learning, 50:127158.
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., &amp; Teller, E. (1953). &quot;Equation of state calculations by fast computing machines&quot;. The journal of chemical physics, 21(6), 1087-1092.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##############################################
## example: use built-in simulated data set
##############################################

mydat &lt;- ex1.dag.data ## this data comes with abn see ?ex1.dag.data

## setup distribution list for each node
mydists&lt;-list(b1="binomial", p1="poisson", g1="gaussian", b2="binomial",
              p2="poisson", b3="binomial", g2="gaussian", b4="binomial",
              b5="binomial", g3="gaussian")

mycache &lt;- buildScoreCache(data.df = mydat, data.dists = mydists, max.parents = 2)

## Now peform 10 greedy searches
heur.res &lt;- searchHeuristic(score.cache = mycache, data.dists = mydists,
                            start.dag = "random", num.searches = 10,
                            max.steps = 50)

## Plot (one) dag
plotAbn(heur.res$dags[[1]], data.dists = mydists)

## End(Not run)
</code></pre>

<hr>
<h2 id='searchHillClimber'>Find high scoring directed acyclic graphs using heuristic search.</h2><span id='topic+searchHillClimber'></span>

<h3>Description</h3>

<p>Find high scoring network (DAG) structures using a random re-starts greedy hill-climber heuristic search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>searchHillClimber(score.cache, score = "mlik", num.searches = 1, seed = 42,
                         start.dag = NULL, support.threshold = 0.5, timing.on = TRUE,
                         dag.retained = NULL, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="searchHillClimber_+3A_score.cache">score.cache</code></td>
<td>
<p>output from <code>buildScoreCache()</code>.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_score">score</code></td>
<td>
<p>character giving which network score should be used to
select the structure. Currently <code>'mlik'</code> only.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_num.searches">num.searches</code></td>
<td>
<p>number of times to run the search.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_seed">seed</code></td>
<td>
<p>non-negative integer which sets the seed in the GSL random number generator.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_start.dag">start.dag</code></td>
<td>
<p>a DAG given as a matrix, see details for format, which can be used to provide a starting point for the structural search explicitly.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_support.threshold">support.threshold</code></td>
<td>
<p>the proportion of search results - each locally optimal DAG - in which each arc must appear to be a part of the consensus network.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_timing.on">timing.on</code></td>
<td>
<p>extra output in terms of duration computation.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_dag.retained">dag.retained</code></td>
<td>
<p>a DAG given as a matrix, see details for format. This is necessary if the score.cache was created using an explicit retain matrix, and the same retain matrix should be used here. dag.retained is used by the algorithm which generates the initial random DAG to ensure that the necessary arcs are retained.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_verbose">verbose</code></td>
<td>
<p>extra output.</p>
</td></tr>
<tr><td><code id="searchHillClimber_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure runs a greedy hill-climbing search similar, but not identical,
to the method presented initially in Heckerman et al. 1995.
(Machine Learning, 20, 197-243).
Each search begins with a randomly chosen DAG structure where this is
constructed in such a way as to attempt to choose a DAG uniformly from
the vast landscape of possible structures. The algorithm used is as follows:
given a node cache (from <code><a href="#topic+buildScoreCache">buildScoreCache</a></code>,
then within this set of all allowed local parent combinations,
a random combination is chosen for each node.
This is then combined into a full DAG, which is then checked for cycles,
where this check iterates over the nodes in a random order.
If all nodes have at least one child (i.e., at least one cycle is present),
then the first node examined has all its children removed, and the check for
cycles is then repeated. If this has removed the only cycle present,
then this DAG is used at the starting point for the search,
if not, a second node is chosen (randomly) and the process is then
repeated until a DAG is obtained.
</p>
<p>The actual hill-climbing algorithm itself differs slightly from that presented
in Heckerman et al. as a full cache of all possible local combinations are available.
At each hill-climbing step, everything in the node cache is considered.
In other words, all possible single swaps between members of cache currently present
in the DAG and those in the full cache. The single swap, which provides the greatest
increase in goodness of fit is chosen. A single swap here is the removal
or addition of any one node-parent combination present in the cache while
avoiding a cycle. This means that as well as all single arc changes
(addition or removal), multiple arc changes are also considered at each same step,
note however that arc reversal in this scheme takes two steps (as this requires
first removal of a parent arc from one node and then addition of a parent arc
to a different node). The original algorithm perturbed the current DAG by only
a single arc at each step but also included arc reversal.
The current implementation may not be any more efficient than the original
but is arguably more natural given a pre-computed cache of local scores.
</p>
<p>A start DAG may be provided in which case num.searches must
equal 1 - this option is really just to provide a local search
around a previously identified optimal DAG.
</p>
<p>This function is designed for two different purposes:
i) interactive visualization; and
ii) longer batch processing. The former provides easy visual &quot;eyeballing&quot; of
data in terms of its majority consensus network (or similar threshold),
which is a graphical structure which comprises of all arcs which feature in
a given proportion (<code>support.threshold</code>) of locally optimal DAGs already
identified during the run. The general hope is that this structure will
stabilize - become fixed - relatively quickly, at least for problems with
smaller numbers of nodes.
</p>


<h3>Value</h3>

<p>A list with entries:
</p>

<dl>
<dt>init.score</dt><dd><p>a vector giving network score for initial network from which the search commenced</p>
</dd>
<dt>final.score</dt><dd><p>a vector giving the network score for the locally optimal network</p>
</dd>
<dt>init.dag</dt><dd><p>list of matrices, initial DAGs</p>
</dd>
<dt>final.dag</dt><dd><p>list of matrices, locally optimal DAGs</p>
</dd>
<dt>consensus</dt><dd><p>a matrix holding a binary graph, not necessary a DAG!</p>
</dd>
<dt>support.threshold</dt><dd><p>percentage supported used to create consensus matrix</p>
</dd>
</dl>



<h3>References</h3>

<p>Lewis, F. I., and McCormick, B. J. J. (2012). Revealing the complexity of health determinants in resource poor settings. <em>American Journal Of Epidemiology</em>. DOI:10.1093/aje/KWS183).
</p>

<hr>
<h2 id='simulateAbn'>Simulate data from a fitted additive Bayesian network.</h2><span id='topic+simulateAbn'></span>

<h3>Description</h3>

<p>Simulate data from a fitted additive Bayesian network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateAbn(
  object = NULL,
  run.simulation = TRUE,
  bugsfile = NULL,
  n.chains = 10L,
  n.adapt = 1000L,
  n.thin = 100L,
  n.iter = 10000L,
  seed = 42L,
  verbose = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateAbn_+3A_object">object</code></td>
<td>
<p>of type <code>abnFit</code>.</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_run.simulation">run.simulation</code></td>
<td>
<p>call JAGS to simulate data (default is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_bugsfile">bugsfile</code></td>
<td>
<p>A path to a valid file or <code>NULL</code> (default)  to delete the bugs file after simulation.</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_n.chains">n.chains</code></td>
<td>
<p>number of parallel chains for the model.</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_n.adapt">n.adapt</code></td>
<td>
<p>number of iteration for adaptation. If <code>n.adapt</code> is set to zero, then no adaptation takes place.</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_n.thin">n.thin</code></td>
<td>
<p>thinning interval for monitors.</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_n.iter">n.iter</code></td>
<td>
<p>number of iteration to monitor.</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_seed">seed</code></td>
<td>
<p>by default set to 42.</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE prints additional output</p>
</td></tr>
<tr><td><code id="simulateAbn_+3A_debug">debug</code></td>
<td>
<p>if TRUE prints bug file content to stdout and does not run simulations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame
</p>


<h3>See Also</h3>

<p><a href="#topic+makebugs">makebugs</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- FCV[, c(12:15)]
mydists &lt;- list(Outdoor="binomial",
                Sex="multinomial",
                GroupSize="poisson",
                Age="gaussian")

## buildScoreCache -&gt; mostProbable() -&gt; fitAbn()
suppressWarnings({
  mycache.mle &lt;- buildScoreCache(data.df = df, data.dists = mydists, method = "mle",
                                 adj.vars = NULL, cor.vars = NULL,
                                 dag.banned = NULL, dag.retained = NULL,
                                 max.parents = 1,
                                 which.nodes = NULL, defn.res = NULL)
}) # ignore non-convergence warnings
mp.dag.mle &lt;- mostProbable(score.cache = mycache.mle, verbose = FALSE)
myres.mle &lt;- fitAbn(object = mp.dag.mle, method = "mle")

myres.sim &lt;- simulateAbn(object = myres.mle,
                             run.simulation = TRUE,
                             bugsfile = NULL,
                             verbose = FALSE)
str(myres.sim)
prop.table(table(myres.sim$Outdoor))
prop.table(table(df$Outdoor))

</code></pre>

<hr>
<h2 id='simulateDag'>Simulate a DAG with with arbitrary arcs density</h2><span id='topic+simulateDag'></span>

<h3>Description</h3>

<p>Provided with node names, returns an <code>abnDAG</code>.
Arc density refers to the chance of a node being connected to the node before it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateDag(node.name, data.dists = NULL, edge.density = 0.5, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulateDag_+3A_node.name">node.name</code></td>
<td>
<p>a vector of character giving the names of the nodes. It gives the size of the simulated DAG.</p>
</td></tr>
<tr><td><code id="simulateDag_+3A_data.dists">data.dists</code></td>
<td>
<p>named list corresponding to the <code>node.name</code> specifying the distribution for each node. If not provided arbitrary distributions are assigned to the nodes.</p>
</td></tr>
<tr><td><code id="simulateDag_+3A_edge.density">edge.density</code></td>
<td>
<p>number in <code>[0,1]</code> specifying the edge probability in the dag.</p>
</td></tr>
<tr><td><code id="simulateDag_+3A_verbose">verbose</code></td>
<td>
<p>print more information on the run.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates DAGs by sampling triangular matrices and reorder columns and rows randomly.
The network density (<code>edge.density</code>) is used column-wise as binomial sampling probability.
Then the matrix is named using the user-provided names.
</p>


<h3>Value</h3>

<p>object of class <code>abnDag</code> consisting of a named matrix, a named list giving the distribution for each node and an empty element for the data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdag &lt;- simulateDag(node.name = c("a", "b", "c", "d"),
                      edge.density = 0.5,
                      data.dists = list(a = "gaussian",
                                        b = "binomial",
                                        c = "poisson",
                                        d = "multinomial"))

## Example using Ozon entries:
dist &lt;- list(Ozone="gaussian",   Solar.R="gaussian",  Wind="gaussian",
             Temp="gaussian",    Month="gaussian",    Day="gaussian")
out &lt;- simulateDag(node.name = names(dist), data.dists = dist, edge.density = 0.8)
plot(out)
</code></pre>

<hr>
<h2 id='skewness'>Computes skewness of a distribution</h2><span id='topic+skewness'></span>

<h3>Description</h3>

<p>Computes skewness of a distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewness(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="skewness_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>integer
</p>

<hr>
<h2 id='std.area.under.grid'>Standard Area Under the Marginal</h2><span id='topic+std.area.under.grid'></span>

<h3>Description</h3>

<p>function to get std. are under marginal to exactly unity.
It should be very close to unity but in some cases due to numerical accuracy
differences (since each point is a separate estimate) this might be a little adrift
turn this option off to see how reliable the original estimation is
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std.area.under.grid(mylist, single)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="std.area.under.grid_+3A_mylist">mylist</code></td>
<td>
<p>list of matrices of two cols x, y</p>
</td></tr>
<tr><td><code id="std.area.under.grid_+3A_single">single</code></td>
<td>
<p>NULL or TRUE if only a single node and parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>

<hr>
<h2 id='strsplits'>Recursive string splitting</h2><span id='topic+strsplits'></span>

<h3>Description</h3>

<p>Internal function that call multiple times strsplit() and remove space
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strsplits(x, splits, ...)
</code></pre>


<h3>Value</h3>

<p>A vector of strings
</p>

<hr>
<h2 id='summary.abnDag'>Prints summary statistics from an object of class <code>abnDag</code></h2><span id='topic+summary.abnDag'></span>

<h3>Description</h3>

<p>Prints summary statistics from an object of class <code>abnDag</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnDag'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.abnDag_+3A_object">object</code></td>
<td>
<p>an object of class <code>abnLearned</code>, <code>abnFit</code>.
Alternatively, a matrix or a formula statement defining the network structure,
a directed acyclic graph (DAG).
Note that row names must be set up or given in <code>node.names</code>.</p>
</td></tr>
<tr><td><code id="summary.abnDag_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with summary statistics of the DAG.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mydag &lt;- createAbnDag(dag = ~a+b|a, data.df = data.frame("a"=1, "b"=1))
summary(mydag)
</code></pre>

<hr>
<h2 id='summary.abnFit'>Print summary of objects of class <code>abnFit</code></h2><span id='topic+summary.abnFit'></span>

<h3>Description</h3>

<p>Print summary of objects of class <code>abnFit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnFit'
summary(object, digits = 3L, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.abnFit_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnFit</code></p>
</td></tr>
<tr><td><code id="summary.abnFit_+3A_digits">digits</code></td>
<td>
<p>number of digits of the results.</p>
</td></tr>
<tr><td><code id="summary.abnFit_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints summary statistics of the fitted model.
</p>

<hr>
<h2 id='summary.abnMostprobable'>Print summary of objects of class <code>abnMostprobable</code></h2><span id='topic+summary.abnMostprobable'></span>

<h3>Description</h3>

<p>Print summary of objects of class <code>abnMostprobable</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'abnMostprobable'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.abnMostprobable_+3A_object">object</code></td>
<td>
<p>Object of class <code>abnMostprobable</code></p>
</td></tr>
<tr><td><code id="summary.abnMostprobable_+3A_...">...</code></td>
<td>
<p>additional parameters. Not used at the moment.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints the mostprobable consensus DAG and the number of observations used to calculate it.
</p>

<hr>
<h2 id='tidy.cache'>tidy up cache</h2><span id='topic+tidy.cache'></span>

<h3>Description</h3>

<p>tidy up cache
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tidy.cache(thecache)
</code></pre>


<h3>Value</h3>

<p>list of chache with error indexes removed
</p>

<hr>
<h2 id='toGraphviz'>Convert a DAG into graphviz format</h2><span id='topic+toGraphviz'></span>

<h3>Description</h3>

<p>Given a matrix defining a DAG create a text file suitable for plotting with graphviz.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toGraphviz(dag,
                  data.df=NULL,
                  data.dists=NULL,
                  group.var=NULL,
                  outfile=NULL,
                  directed=TRUE,
                  verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="toGraphviz_+3A_dag">dag</code></td>
<td>
<p>a matrix defining a DAG.</p>
</td></tr>
<tr><td><code id="toGraphviz_+3A_data.df">data.df</code></td>
<td>
<p>a data frame containing the data used for learning the network.</p>
</td></tr>
<tr><td><code id="toGraphviz_+3A_data.dists">data.dists</code></td>
<td>
<p>a list with named arguments matching the names of the data frame which gives the distribution family for each variable. See <code><a href="#topic+fitAbn">fitAbn</a></code> for details.</p>
</td></tr>
<tr><td><code id="toGraphviz_+3A_group.var">group.var</code></td>
<td>
<p>only applicable for mixed models and gives the column name in <code>data.df</code> of the grouping variable (which must be a factor denoting group membership). See <code>fitAbn</code> for details.</p>
</td></tr>
<tr><td><code id="toGraphviz_+3A_outfile">outfile</code></td>
<td>
<p>a character string giving the filename which will contain the graphviz graph.</p>
</td></tr>
<tr><td><code id="toGraphviz_+3A_directed">directed</code></td>
<td>
<p>logical; if TRUE, a directed acyclic graph is produced, otherwise an undirected graph.</p>
</td></tr>
<tr><td><code id="toGraphviz_+3A_verbose">verbose</code></td>
<td>
<p>if TRUE more output is printed. If TRUE and 'outfile=NULL' the '.dot' file is printed to console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Graphviz (<a href="https://www.graphviz.org">https://www.graphviz.org</a>) is a visualisation software developed by AT&amp;T and freely available.
This function creates a text representation of the DAG, or the undirected graph, so this can be plotted using graphviz.
The R package, <code>Rgraphviz</code> (available through the Bioconductor project <a href="https://www.bioconductor.org/">https://www.bioconductor.org/</a>) interfaces R and the working installation of graphviz.
</p>
<p>Binary nodes will appear as squares, Gaussian as ovals and Poisson nodes as diamonds in the resulting graphviz network diagram.
There are many other shapes possible for nodes and numerous other visual enhancements - see online graphviz documentation.
</p>
<p>Bespoke refinements can be added by editing the raw outfile produced.
For full manual editing, particularly of the layout, or adding annotations,
one easy solution is to convert a postscript format graph (produced in graphviz using the -Tps switch)
into a vector format using a tool such as pstoedit (<a href="http://www.pstoedit.net/">http://www.pstoedit.net/</a>),
and then edit using a vector drawing tool like xfig.
This can then be resaved as postscript or pdf thus retaining full vector quality.
</p>


<h3>Value</h3>

<p>Nothing is returned, but a file <code>outfile</code> written.
</p>


<h3>Author(s)</h3>

<p>Fraser Iain Lewis
</p>
<p>Marta Pittavino
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## On a typical linux system the following code constructs a nice
## looking pdf file 'graph.pdf'.
## Not run: 
## Subset of a build-in dataset
mydat &lt;- ex0.dag.data[,c("b1","b2","b3","g1","b4","p2","p4")]

## setup distribution list for each node
mydists &lt;- list(b1="binomial", b2="binomial", b3="binomial",
                g1="gaussian", b4="binomial", p2="poisson",
                                p4="poisson")
## specify DAG model
mydag &lt;- matrix(c(   0,1,0,0,1,0,0, #
                     0,0,0,0,0,0,0, #
                     0,1,0,0,1,0,0, #
                     1,0,0,0,0,0,1, #
                     0,0,0,0,0,0,0, #
                     0,0,0,1,0,0,0, #
                     0,0,0,0,1,0,0  #
), byrow=TRUE, ncol=7)

colnames(mydag) &lt;- rownames(mydag) &lt;- names(mydat)

## create file for processing with graphviz
outfile &lt;- paste(tempdir(), "graph.dot", sep="/")
toGraphviz(dag=mydag, data.df=mydat, data.dists=mydists, outfile=outfile)
## and then process using graphviz tools e.g. on linux
if(Sys.info()[["sysname"]] == "Linux" &amp;&amp; interactive()) {
  system(paste( "dot -Tpdf -o graph.pdf", outfile))
  system("evince graph.pdf")
}
## Example using data with a group variable  where b1&lt;-b2
mydag &lt;- matrix(c(0,1, 0,0), byrow=TRUE, ncol=2)

colnames(mydag) &lt;- rownames(mydag) &lt;- names(ex3.dag.data[,c(1,2)])
## specific distributions
mydists &lt;- list(b1="binomial", b2="binomial")

## create file for processing with graphviz
outfile &lt;- paste0(tempdir(), "/graph.dot")
toGraphviz(dag=mydag, data.df=ex3.dag.data[,c(1,2,14)], data.dists=mydists,
           group.var="group",
           outfile=outfile, directed=FALSE)
## and then process using graphviz tools e.g. on linux:
if(Sys.info()[["sysname"]] == "Linux" &amp;&amp; interactive()) {
  pdffile &lt;- paste0(tempdir(), "/graph.pdf")
  system(paste("dot -Tpdf -o ", pdffile, outfile))
  system(paste("evince ", pdffile, " &amp;"))   ## or some other viewer
}

## End(Not run)
</code></pre>

<hr>
<h2 id='validate_abnDag'>Check for valid DAG of class <code>abnDag</code></h2><span id='topic+validate_abnDag'></span>

<h3>Description</h3>

<p>Beside some basic checks, this function also checks for square matrix with no undirected cycles (trivial cycles) and
for no undirected cycles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_abnDag(dag, data.df = NULL, returnDag = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_abnDag_+3A_dag">dag</code></td>
<td>
<p>dag is either a formula, a matrix  or an object of class 'abnDag'</p>
</td></tr>
<tr><td><code id="validate_abnDag_+3A_data.df">data.df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="validate_abnDag_+3A_returndag">returnDag</code></td>
<td>
<p>if TRUE (default) returns DAG as matrix.</p>
</td></tr>
<tr><td><code id="validate_abnDag_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to <code>check.valid.dag()</code>.
</p>


<h3>Value</h3>

<p>Either TRUE/FALSE or DAG as matrix.
</p>

<hr>
<h2 id='validate_dists'>Check for valid distribution</h2><span id='topic+validate_dists'></span>

<h3>Description</h3>

<p>The distribution names must match <code style="white-space: pre;">&#8288;inla() family=''&#8288;</code>.
Similar to <code>get.var.types()</code>, mainly different in output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_dists(data.dists, returnDists = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_dists_+3A_data.dists">data.dists</code></td>
<td>
<p>list of variable distributions.</p>
</td></tr>
<tr><td><code id="validate_dists_+3A_returndists">returnDists</code></td>
<td>
<p>if TRUE (default) returns the same list as provided.</p>
</td></tr>
<tr><td><code id="validate_dists_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>either TRUE/FALSE or list of variable distributions as provided as input.
</p>

<hr>
<h2 id='var33'>simulated dataset from a DAG comprising of 33 variables</h2><span id='topic+var33'></span>

<h3>Description</h3>

<p>250 observations simulated from a DAG with 17 binary variables and 16 continuous.
A DAG of this data features in the vignette.
Note that the conditional dependence relations given are those in the population
and may differ in the realization of 250 observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var33
</code></pre>


<h3>Format</h3>

<p>A data frame with a mixture of discrete variables each of which is
set as a factor and continuous variables.
Joint distribution structure used to generate the data.
</p>

<dl>
<dt>v1</dt><dd><p>Binary, independent. </p>
</dd>
<dt>v2</dt><dd><p>Gaussian, conditionally dependent upon v1. </p>
</dd>
<dt>v3</dt><dd><p>Binary, independent. </p>
</dd>
<dt>v4</dt><dd><p>Binary, conditionally dependent upon v3. </p>
</dd>
<dt>v5</dt><dd><p>Gaussian, conditionally dependent upon v6. </p>
</dd>
<dt>v6</dt><dd><p>Binary, conditionally dependent upon v4 and v7. </p>
</dd>
<dt>v7</dt><dd><p>Gaussian,  conditionally dependent upon v8. </p>
</dd>
<dt>v8</dt><dd><p>Gaussian,  conditionally dependent upon v9. </p>
</dd>
<dt>v9</dt><dd><p>Binary, conditionally dependent upon v10. </p>
</dd>
<dt>v10</dt><dd><p>Binary, independent. </p>
</dd>
<dt>v11</dt><dd><p>Binary,  conditionally dependent upon v10, v12 and v19. </p>
</dd>
<dt>v12</dt><dd><p>Binary, independent.</p>
</dd>
<dt>v13</dt><dd><p>Gaussian, independent.</p>
</dd>
<dt>v14</dt><dd><p>Gaussian,  conditionally dependent upon v13. </p>
</dd>
<dt>v15</dt><dd><p>Binary, conditionally dependent upon v14 and v21. </p>
</dd>
<dt>v16</dt><dd><p>Gaussian, independent. </p>
</dd>
<dt>v17</dt><dd><p>Gaussian, conditionally dependent upon v16 and v20. </p>
</dd>
<dt>v18</dt><dd><p>Binary,  conditionally dependent upon v20. </p>
</dd>
<dt>v19</dt><dd><p>Binary,  conditionally dependent upon v20. </p>
</dd>
<dt>v20</dt><dd><p>Binary, independent. </p>
</dd>
<dt>v21</dt><dd><p>Binary, conditionally dependent upon v20. </p>
</dd>
<dt>v22</dt><dd><p>Gaussian, conditionally dependent upon v21. </p>
</dd>
<dt>v23</dt><dd><p>Gaussian, conditionally dependent upon v21. </p>
</dd>
<dt>v24</dt><dd><p>Gaussian, conditionally dependent upon v23. </p>
</dd>
<dt>v25</dt><dd><p>Gaussian, conditionally dependent upon v23 and v26. </p>
</dd>
<dt>v26</dt><dd><p>Binary, conditionally dependent upon v20. </p>
</dd>
<dt>v27</dt><dd><p>Binary, independent. </p>
</dd>
<dt>v28</dt><dd><p>Binary, conditionally dependent upon v27, v29 and v31. </p>
</dd>
<dt>v29</dt><dd><p>Gaussian, independent. </p>
</dd>
<dt>v30</dt><dd><p>Gaussian,  conditionally dependent upon v29. </p>
</dd>
<dt>v31</dt><dd><p>Gaussian, independent. </p>
</dd>
<dt>v32</dt><dd><p>Binary,  conditionally dependent upon v21, v29 and v31. </p>
</dd>
<dt>v33</dt><dd><p>Gaussian,  conditionally dependent upon v31. </p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## Constructing the DAG of the dataset:
dag33 &lt;- matrix(0, 33, 33)
dag33[2,1] &lt;- 1
dag33[4,3] &lt;- 1
dag33[6,4] &lt;- 1; dag33[6,7] &lt;- 1
dag33[5,6] &lt;- 1
dag33[7,8] &lt;- 1
dag33[8,9] &lt;- 1
dag33[9,10] &lt;- 1
dag33[11,10] &lt;- 1; dag33[11,12] &lt;- 1; dag33[11,19] &lt;- 1;
dag33[14,13] &lt;- 1
dag33[17,16] &lt;- 1; dag33[17,20] &lt;- 1
dag33[15,14] &lt;- 1; dag33[15,21] &lt;- 1
dag33[18,20] &lt;- 1
dag33[19,20] &lt;- 1
dag33[21,20] &lt;- 1
dag33[22,21] &lt;- 1
dag33[23,21] &lt;- 1
dag33[24,23] &lt;- 1
dag33[25,23] &lt;- 1; dag33[25,26] &lt;- 1
dag33[26,20] &lt;- 1
dag33[33,31] &lt;- 1
dag33[33,31] &lt;- 1
dag33[32,21] &lt;- 1; dag33[32,31] &lt;- 1; dag33[32,29] &lt;- 1
dag33[30,29] &lt;- 1
dag33[28,27] &lt;- 1; dag33[28,29] &lt;- 1; dag33[28,31] &lt;- 1

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
