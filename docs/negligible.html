<!DOCTYPE html><html><head><title>Help for package negligible</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {negligible}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#neg.cat'><p>Equivalence Testing for Categorical Variables</p></a></li>
<li><a href='#neg.cfi'><p>Equivalence Tests for CFI</p></a></li>
<li><a href='#neg.cor'><p>Test for Lack of Association between Two Continuous Normally Distributed Variables: Equivalence-based correlation tests</p></a></li>
<li><a href='#neg.esm'><p>Test for Evaluating Substantial Mediation</p></a></li>
<li><a href='#neg.indvars'><p>Negligible Effect Test for Variances of Independent Populations</p></a></li>
<li><a href='#neg.intcont'><p>Negligible Interaction Test for Continuous Predictors</p></a></li>
<li><a href='#neg.normal'><p>Negligible Effect Test for Normality of a Univariate Distribution</p></a></li>
<li><a href='#neg.paired'><p>Negligible Effect Test on the Difference between the Means of Dependent Populations</p></a></li>
<li><a href='#neg.pd'><p>Proportional Distance Function (post hoc function - not to be used independently)</p></a></li>
<li><a href='#neg.reg'><p>Test for Evaluating Negligible Effect Between a Predictor and Outcome in a Multiple Regression Model</p></a></li>
<li><a href='#neg.rmsea'><p>Equivalence Tests for RMSEA</p></a></li>
<li><a href='#neg.semfit'><p>Equivalence Tests for Fit Indices</p></a></li>
<li><a href='#neg.srmr'><p>Equivalence Tests for SRMR</p></a></li>
<li><a href='#neg.twocors'><p>Test for Evaluating Negligible Effects of Two Independent or Dependent Correlation Coefficients: Based on Counsell &amp; Cribbie (2015)</p></a></li>
<li><a href='#neg.twoindmeans'><p>Negligible Effect Test on the Difference between the Means of Independent Populations</p></a></li>
<li><a href='#perfectionism'><p>Perfectionism Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Collection of Functions for Negligible Effect/Equivalence
Testing</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.6</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Robert Cribbie &lt;cribbie@yorku.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Researchers often want to evaluate whether there is a negligible
    relationship among variables. The 'negligible' package provides functions that 
    are useful for conducting negligible effect testing (also called
    equivalence testing). For example, there are functions for evaluating the 
    equivalence of means or the presence of a negligible association 
    (correlation or  regression). Beribisky, N., Mara, C., &amp; Cribbie, R. A. (2020) &lt;<a href="https://doi.org/10.20982%2Ftqmp.16.4.p424">doi:10.20982/tqmp.16.4.p424</a>&gt;.
    Beribisky, N., Davidson, H., Cribbie, R. A. (2019) &lt;<a href="https://doi.org/10.7717%2Fpeerj.6853">doi:10.7717/peerj.6853</a>&gt;.
    Shiskina, T., Farmus, L., &amp; Cribbie, R. A. (2018) &lt;<a href="https://doi.org/10.20982%2Ftqmp.14.3.p167">doi:10.20982/tqmp.14.3.p167</a>&gt;.
    Mara, C. &amp; Cribbie, R. A. (2017) &lt;<a href="https://doi.org/10.1080%2F00220973.2017.1301356">doi:10.1080/00220973.2017.1301356</a>&gt;.
    Counsell, A. &amp; Cribbie, R. A. (2015) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12045">doi:10.1111/bmsp.12045</a>&gt;.
    van Wieringen, K. &amp; Cribbie, R. A. (2014) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12015">doi:10.1111/bmsp.12015</a>&gt;.
    Goertzen, J. R. &amp; Cribbie, R. A. (2010) &lt;<a href="https://doi.org/10.1348%2F000711009x475853">doi:10.1348/000711009x475853</a>&gt;.
    Cribbie, R. A., Gruman, J. &amp; Arpin-Cribbie, C. (2004) &lt;<a href="https://doi.org/10.1002%2Fjclp.10217">doi:10.1002/jclp.10217</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>DescTools, lavaan, WRS2, ggplot2, nptest, dplyr, fungible,
rockchalk, MBESS, tidyr, stats, e1071</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-02 17:48:47 UTC; cribbie</td>
</tr>
<tr>
<td>Author:</td>
<td>Robert Cribbie [aut, cre],
  Udi Alter [aut],
  Nataly Beribisky [aut],
  Phil Chalmers [aut],
  Alyssa Counsell [aut],
  Linda Farmus [aut],
  Naomi Martinez Gutierrez [aut],
  Victoria Ng [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-03 01:50:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='neg.cat'>Equivalence Testing for Categorical Variables</h2><span id='topic+neg.cat'></span><span id='topic+print.neg.cat'></span>

<h3>Description</h3>

<p>Testing for the presence of a negligible association between two categorical variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.cat(
  v1 = NULL,
  v2 = NULL,
  tab = NULL,
  eiU = 0.2,
  data = NULL,
  plot = TRUE,
  save = FALSE,
  nbootpd = 1000,
  alpha = 0.05
)

## S3 method for class 'neg.cat'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.cat_+3A_v1">v1</code></td>
<td>
<p>first categorical variable</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_v2">v2</code></td>
<td>
<p>second categorical variable</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_tab">tab</code></td>
<td>
<p>contingency table for the two predictor variables</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_eiu">eiU</code></td>
<td>
<p>upper limit of equivalence interval</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_data">data</code></td>
<td>
<p>optional data file containing the categorical variables</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_plot">plot</code></td>
<td>
<p>logical; should a plot be printed out with the effect and the proportional distance</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_save">save</code></td>
<td>
<p>should the plot be saved to 'jpg' or 'png'</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_nbootpd">nbootpd</code></td>
<td>
<p>number of bootstrap samples for calculating the CI for the proportional distance</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_alpha">alpha</code></td>
<td>
<p>nominal acceptable Type I error rate level</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_x">x</code></td>
<td>
<p>Data frame from neg.cat</p>
</td></tr>
<tr><td><code id="neg.cat_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether a negligible relationship exists among two categorical variables.
</p>
<p>The statistical test is based on the Cramer's V statistic; namely addressing the question of whether the upper limit of the confidence interval for Cramer's V falls below the upper bound of the negligible effect (equivalence) interval (eiU).
</p>
<p>If the upper bound of the CI for Cramer's V falls below eiU, we can reject Ho: The relationship is nonnegligible (V &gt;= eiU).
</p>
<p>eiU is set to .2 by default, but should be set based on the context of the research. Since Cramer's V statistic is in a correlation metric, setting eiU is a matter of determining what correlation is the minimally meaningful effect size (MMES) given the context of the research.
</p>
<p>Users can input either the names of the categorical variables (v1, v2) or a frequency (contingency) table (tab).
</p>
<p>The proportional distance (V/eiU) estimates the proportional distance of the effect from 0 to eiU, and acts as an alternative effect size measure.
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the following:
</p>

<ul>
<li> <p><code>cramv</code> Cramer's V statistic
</p>
</li>
<li> <p><code>propvar</code> Proportion of variance explained (V^2)
</p>
</li>
<li> <p><code>cil</code> Lower bound of the confidence interval for Cramer's V
</p>
</li>
<li> <p><code>ciu</code> Upper bound of the confidence interval for Cramer's V
</p>
</li>
<li> <p><code>eiU</code> Upper bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>decis</code> NHST decision
</p>
</li>
<li> <p><code>PD</code> Proportional distance
</p>
</li>
<li> <p><code>CI95L</code> Lower bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>CI95U</code> Upper bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a>
</p>
<p>The confidence interval for the proportional distance is computed via bootstrapping (percentile bootstrap).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sex&lt;-rep(c("m","f"),c(12,22))
haircol&lt;-rep(c("bld","brn","bld","brn"),c(9,7,11,7))
d &lt;- data.frame(sex,haircol)
tab&lt;-table(sex,haircol)
neg.cat(tab=tab, alpha=.05, nbootpd=5)
neg.cat(v1=sex, v2=haircol, data=d, nbootpd=5)
</code></pre>

<hr>
<h2 id='neg.cfi'>Equivalence Tests for CFI</h2><span id='topic+neg.cfi'></span><span id='topic+print.neg.cfi'></span>

<h3>Description</h3>

<p>Function performs one of six equivalence tests for CFI fit index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.cfi(
  mod,
  alpha = 0.05,
  eq.bound,
  modif.eq.bound = FALSE,
  ci.method = "equiv",
  nbootpd = 50,
  nboot = 250L,
  round = 3,
  plot = TRUE,
  saveplot = TRUE
)

## S3 method for class 'neg.cfi'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.cfi_+3A_mod">mod</code></td>
<td>
<p>lavaan model object</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_alpha">alpha</code></td>
<td>
<p>desired alpha level (default = .05)</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_eq.bound">eq.bound</code></td>
<td>
<p>lower end of equivalence interval for comparison; must be .99, .95, .92 or .90 if modif.eq.bound = TRUE</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_modif.eq.bound">modif.eq.bound</code></td>
<td>
<p>should the lower end of the equivalence interval be modified (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_ci.method">ci.method</code></td>
<td>
<p>method used to calculate confidence interval; options are &quot;yuan&quot;, &quot;equiv&quot; or &quot;yhy.boot&quot;; &quot;yuan&quot; corresponds to (1-alpha) percent CI, &quot;equiv&quot; corresponds to (1-2alpha) percent CI, &quot;yhy.boot&quot; corresponds to (1-2alpha) percent boot CI (default = &quot;equiv&quot;)</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_nbootpd">nbootpd</code></td>
<td>
<p>number of bootstrap samples by &quot;yhy.boot&quot; for pd function</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap samples if &quot;yhy.boot&quot; is selected as ci.method (default = 250L)</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_round">round</code></td>
<td>
<p>number of digits to round equivalence bound and confidence interval bounds (default = 3)</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_plot">plot</code></td>
<td>
<p>logical, plotting the results (default = TRUE)</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_saveplot">saveplot</code></td>
<td>
<p>saving plots (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.cfi</code></p>
</td></tr>
<tr><td><code id="neg.cfi_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>#'
The user specifies the lavaan fitted model object, the desired equivalence bound, and method of confidence interval computation. By default, the function does not modify the equivalence bounds according to Yuan et al. (2016). The user can also choose to instead run an equivalence test using a modified equivalence bound if the equivalence bound to be modified is .01, .05, .08, or .10. Alpha level can also be modified.
</p>
<p>For information on modified equivalence bounds see Yuan, K. H., Chan, W., Marcoulides, G. A., &amp; Bentler, P. M. (2016). Assessing structural equation models by equivalence testing with adjusted fit indexes. Structural Equation Modeling: A Multidisciplinary Journal, 23(3), 319-330. doi: https://doi.org/10.1080/10705511.2015.1065414.
</p>
<p>The proportional distance quantifies the proportional distance from 0 to the nearest negligible effect (equivalence) interval (here, eiU). As values get farther from 0 the relationship becomes more substantial, with values greater than 1 indicating that the effect falls outside of the negligible effect (equivalence) interval.
</p>


<h3>Value</h3>

<p>returns a <code>list</code> containing analysis and respective statistics
and decision.
</p>

<ul>
<li> <p><code>title1</code> The title of the CFI equivalence test. The appropriate title of the test will be displayed depending on the ci.method chosen and whether modif.eq.bound is TRUE or FALSE.
</p>
</li>
<li> <p><code>cfi_index</code> The CFI index.
</p>
</li>
<li> <p><code>ci.method</code> The method for confidence interval calculation.
</p>
</li>
<li> <p><code>cfi_eq</code> The lower end of the confidence interval for the CFI index.
</p>
</li>
<li> <p><code>eq.bound</code> The equivalence bound.
</p>
</li>
<li> <p><code>PD</code> Proportional distance (PD).
</p>
</li>
<li> <p><code>cilpd</code> Lower bound of the 1-alpha CI for the PD.
</p>
</li>
<li> <p><code>ciupd</code> Upper bound of the 1-alpha CI for the PD.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Nataly Beribisky <a href="mailto:natalyb1@yorku.ca">natalyb1@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- lavaan::HolzingerSwineford1939
hs.mod &lt;- 'visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9'
fit1 &lt;- lavaan::cfa(hs.mod, data = d)
neg.cfi(mod = fit1, alpha = .05, eq.bound = .95,  modif.eq.bound = FALSE, ci.method = "equiv",
round = 3, plot = TRUE)

</code></pre>

<hr>
<h2 id='neg.cor'>Test for Lack of Association between Two Continuous Normally Distributed Variables: Equivalence-based correlation tests</h2><span id='topic+neg.cor'></span><span id='topic+print.neg.cor'></span>

<h3>Description</h3>

<p>Function performs an equivalence based test of lack of association with resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.cor(
  v1,
  v2,
  eiU,
  eiL,
  alpha = 0.05,
  na.rm = TRUE,
  plot = TRUE,
  data = NULL,
  saveplot = FALSE,
  seed = NA,
  ...
)

## S3 method for class 'neg.cor'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.cor_+3A_v1">v1</code></td>
<td>
<p>the first variable of interest</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_v2">v2</code></td>
<td>
<p>the second variable of interest</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_eiu">eiU</code></td>
<td>
<p>the upper bound of the equivalence interval, in terms of the magnitude of a correlation</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_eil">eiL</code></td>
<td>
<p>the lower bound of the equivalence interval, in terms of the magnitude of a correlation</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_alpha">alpha</code></td>
<td>
<p>desired alpha level</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; remove missing values?</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_plot">plot</code></td>
<td>
<p>whether or not to print graphics of the results (default = TRUE)</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_data">data</code></td>
<td>
<p>data frame where two variables (v1 and y) are contained - optional</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_saveplot">saveplot</code></td>
<td>
<p>saving plots (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_seed">seed</code></td>
<td>
<p>optional argument to set seed</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed</p>
</td></tr>
<tr><td><code id="neg.cor_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.cor</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>From Goertzen, J. R., &amp; Cribbie, R. A. (2010). Detecting a lack of association. British Journal of Mathematical and Statistical Psychology, 63(3), 527â€“537
</p>
<p>This function evaluates whether a negligible relationship exists among two continuous variables.
</p>
<p>The statistical test is based on a bootstrap-generated 1-2*alpha CI for the correlation; in other words, does the 1-2*alpha CI for the falls completely within the negligible effect (equivalence) interval.
</p>
<p>The user needs to specify the lower and upper bounds of the negligible effect (equivalence) interval (eiL,eiU). Since we working in a correlation magnitude, setting these bounds requires estimating the minimally meaningful effect size (MMES); in this case, the minimally meaningful correlation (e.g., eiL = - .3, eiU = .3).
</p>
<p>The 'plot' argument, if TRUE, will generate a plot of the observed effect (correlation) with the associated 1-2*alpha CI, along with a plot of the PD and the associated 1-alpha CI.
</p>


<h3>Value</h3>

<p>A <code>list</code> including the following:
</p>

<ul>
<li> <p><code>corxy</code> Sample correlation value
</p>
</li>
<li> <p><code>eiL</code> Lower bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>eiU</code> Upper bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>nresamples</code> Number of resamples for the bootstrapping procedure
</p>
</li>
<li> <p><code>q1</code> Lower bound of the confidence interval for the correlation
</p>
</li>
<li> <p><code>q2</code> Upper bound of the confidence interval for the correlation
</p>
</li>
<li> <p><code>PD</code> Proportional distance
</p>
</li>
<li> <p><code>CIPDL</code> Lower bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>CIPDU</code> Upper bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a>
Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a> and
Nataly Beribisky <a href="mailto:natalyb1@yorku.ca">natalyb1@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Negligible correlation test between v1 and v2
#with an interval of ei=(-.2.2)
v1 &lt;- rnorm(50)
v2 &lt;- rnorm(50)
cor(v1, v2)
neg.cor(v1 = v1, v2 = v2, eiU = .2, eiL = -.2)
</code></pre>

<hr>
<h2 id='neg.esm'>Test for Evaluating Substantial Mediation</h2><span id='topic+neg.esm'></span><span id='topic+print.neg.esm'></span>

<h3>Description</h3>

<p>Function computes the equivalence testing method (total effect) for evaluating substantial mediation and Kenny method for full mediation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.esm(
  X,
  Y,
  M,
  alpha = 0.05,
  minc = 0.15,
  eil = -0.15,
  eiu = 0.15,
  nboot = 1000L,
  data = NULL,
  plot = TRUE,
  saveplot = FALSE,
  seed = NA
)

## S3 method for class 'neg.esm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.esm_+3A_x">X</code></td>
<td>
<p>predictor variable</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_y">Y</code></td>
<td>
<p>outcome variable</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_m">M</code></td>
<td>
<p>mediator variable</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_alpha">alpha</code></td>
<td>
<p>alpha level (default = .05)</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_minc">minc</code></td>
<td>
<p>minimum correlation between x and Y (default is .15)</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_eil">eil</code></td>
<td>
<p>lower bound of equivalence interval in standardized units(default is -.15)</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_eiu">eiu</code></td>
<td>
<p>upper bound of equivalence interval in standardized units (default is .15)</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstraps (default = 500L)</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_data">data</code></td>
<td>
<p>optional data argument</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_plot">plot</code></td>
<td>
<p>logical, plotting the results (default = TRUE)</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_saveplot">saveplot</code></td>
<td>
<p>saving plots (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_seed">seed</code></td>
<td>
<p>optional argument to set seed</p>
</td></tr>
<tr><td><code id="neg.esm_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.esm</code></p>
</td></tr>
<tr><td><code id="neg.esm_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether a negligible direct effect of X on Y exists after controlling for the mediator. Another way to word this is that the indirect effect accounts for a substantial proportion of the variability in X-Y relationship. See Beribisky, Mara, and Cribbie (https://doi.org/10.20982/tqmp.16.4.p424)
</p>
<p>The user specifies the IV (X), DV (Y) and mediator (M). The user can also specify the alpha level, the lower/upper bound of the negligible effect interval (eiL, eiU), the number of bootstrap samples (nboot), as well as the minimum correlation between X and Y that is permitted for a valid test of substantial mediation.
</p>
<p>The variables X, Y and M can be specified as stand-alone, or a data argument can be used if the data reside in an R dataset.
</p>
<p>For the Kenny method see: https://davidakenny.net/cm/mediate.htm
</p>
<p>The proportional distance quantifies the proportional distance from 0 to the nearest negligible effect (equivalence) interval (eiL, eiU). As values get farther from 0 the relationship becomes more substantial, with values greater than 1 indicating that the effect falls outside of the negligible effect (equivalence) interval.
</p>
<p>Note that the number of bootstrap samples (nboot) are low for the example since the example has a time limit of 5 seconds to pass CRAN testing; we recommend running a much higher number of bootstrap samples for analyses.
</p>


<h3>Value</h3>

<p>A <code>list</code> including the following:
</p>

<ul>
<li> <p><code>minc</code> Minimum correlation between X and Y for a valid negligible effect (equivalence) test
</p>
</li>
<li> <p><code>corxy</code> Sample correlation between the IV (X) and DV (Y)
</p>
</li>
<li> <p><code>dir_eff</code> Sample standardized direct effect between the IV (X) and DV (Y) after controlling for the mediator (M)
</p>
</li>
<li> <p><code>eiL</code> Lower bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>eiU</code> Upper bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>cil</code> Lower bound of the 1-2*alpha CI for the standardized direct effect of X on Y
</p>
</li>
<li> <p><code>ciu</code> Upper bound of the 1-2*alpha CI for the standardized direct effect of X on Y
</p>
</li>
<li> <p><code>PD</code> Proportional distance (PD)
</p>
</li>
<li> <p><code>cilpd</code> Lower bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>ciupd</code> Upper bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>ab_par</code> Standardized indirect effect
</p>
</li>
<li> <p><code>abdivc_k</code> Proportion mediated: Standardized indirect effect divided by the standardized total effect
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Nataly Beribisky <a href="mailto:natalyb1@yorku.ca">natalyb1@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#equivalence test for substantial mediation
#with an equivalence interval of -.15 to .15
X&lt;-rnorm(100,sd=2)
M&lt;-.5*X + rnorm(100)
Y&lt;-.5*M + rnorm(100)
neg.esm(X,Y,M, eil = -.15, eiu = .15, nboot = 5)
</code></pre>

<hr>
<h2 id='neg.indvars'>Negligible Effect Test for Variances of Independent Populations</h2><span id='topic+neg.indvars'></span><span id='topic+print.neg.indvars'></span>

<h3>Description</h3>

<p>This function allows researchers to test whether the difference
in the variances of independent populations is negligible, where
negligible represents the smallest meaningful effect size (MMES, where
in this case the effect is the difference in population variances)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.indvars(dv, iv, eps = 0.5, alpha = 0.05, na.rm = TRUE, data = NULL, ...)

## S3 method for class 'neg.indvars'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.indvars_+3A_dv">dv</code></td>
<td>
<p>Outcome Variable</p>
</td></tr>
<tr><td><code id="neg.indvars_+3A_iv">iv</code></td>
<td>
<p>Independent Variable</p>
</td></tr>
<tr><td><code id="neg.indvars_+3A_eps">eps</code></td>
<td>
<p>Used to Establish the Equivalence Bound (Conservative: .25; Liberal: .50, according to Wellek, 2010)</p>
</td></tr>
<tr><td><code id="neg.indvars_+3A_alpha">alpha</code></td>
<td>
<p>Nominal Type I Error Rate</p>
</td></tr>
<tr><td><code id="neg.indvars_+3A_na.rm">na.rm</code></td>
<td>
<p>Missing Data Treatment</p>
</td></tr>
<tr><td><code id="neg.indvars_+3A_data">data</code></td>
<td>
<p>Dataset containing dv and iv</p>
</td></tr>
<tr><td><code id="neg.indvars_+3A_...">...</code></td>
<td>
<p>Extra arguments</p>
</td></tr>
<tr><td><code id="neg.indvars_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.indvars</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether the difference in the population variances of J independent groups can be considered negligible (i.e., the population variances can be considered equivalent).
</p>
<p>The user provides the name of the outcome/dependent variable (should be continuous) and the name of Independent Variable (predictor, should be a factor), as well as the epsilon value (eps) which determines the smallest difference in variances that can be considered non-negligible.
</p>
<p>Wellek (2010) suggests liberal and conservative values of eps = .50 and eps = .25, respectively. See Wellek, 2010, pp. 16, 17, 22, for details.
</p>
<p>See Mara &amp; Cribbie (2018): https://doi.org/10.1080/00220973.2017.1301356
</p>


<h3>Value</h3>

<p>A <code>list</code> including the following:
</p>

<ul>
<li> <p><code>vars</code> Sample variances
</p>
</li>
<li> <p><code>sds</code> Sample standard deviations
</p>
</li>
<li> <p><code>mads</code> Sample median absolute deviations
</p>
</li>
<li> <p><code>ratio</code> Ratio of the largest to smallest variance
</p>
</li>
<li> <p><code>eps</code> Epsilon (e) can be described as the maximum difference in the variances that one would consider to be unimportant (see Details).
</p>
</li>
<li> <p><code>LWW_md</code> Levene-Wellek-Welch statistic based on the median.
</p>
</li>
<li> <p><code>crit_LWW_md</code> Critical value for the Levene-Wellek-Welch statistic based on the median.
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Constance Mara <a href="mailto:Constance.Mara@cchmc.org">Constance.Mara@cchmc.org</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Two Group Example
indvar&lt;-rep(c("a","b"),c(10,12))
depvar&lt;-rnorm(22)
d&lt;-data.frame(indvar,depvar)
neg.indvars(depvar,indvar)
neg.indvars(dv=depvar,iv=indvar,eps=.25,data=d)
neg.indvars(dv=depvar,iv=indvar,eps=.5)

#Four Group Example
indvar&lt;-rep(c("a","b","c","d"),c(10,12,15,13))
depvar&lt;-rnorm(50)
d&lt;-data.frame(indvar,depvar)
neg.indvars(dv=depvar,iv=indvar,eps=.25,data=d)
neg.indvars(dv=depvar,iv=indvar)
</code></pre>

<hr>
<h2 id='neg.intcont'>Negligible Interaction Test for Continuous Predictors</h2><span id='topic+neg.intcont'></span>

<h3>Description</h3>

<p>Testing for the presence of a negligible interaction between two continuous predictor variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.intcont(
  outcome = NULL,
  pred1 = NULL,
  pred2 = NULL,
  eiL,
  eiU,
  standardized = TRUE,
  nbootpd = 1000,
  data = NULL,
  alpha = 0.05,
  plot = TRUE,
  save = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.intcont_+3A_outcome">outcome</code></td>
<td>
<p>continuous outcome variable</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_pred1">pred1</code></td>
<td>
<p>first continuous predictor variable</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_pred2">pred2</code></td>
<td>
<p>second continuous predictor variable</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_eil">eiL</code></td>
<td>
<p>lower limit of the negligible effect (equivalence) interval</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_eiu">eiU</code></td>
<td>
<p>upper limit of the negligible effect (equivalence) interval</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_standardized">standardized</code></td>
<td>
<p>logical; should the solution be based on standardized variables (and eiL/eiU)</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_nbootpd">nbootpd</code></td>
<td>
<p>number of bootstrap samples for the calculation of the CI for the proportional distance</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_data">data</code></td>
<td>
<p>optional data file containing the categorical variables</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_alpha">alpha</code></td>
<td>
<p>nominal acceptable Type I error rate level</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_plot">plot</code></td>
<td>
<p>logical; should a plot be printed out with the effect and the proportional distance</p>
</td></tr>
<tr><td><code id="neg.intcont_+3A_save">save</code></td>
<td>
<p>logical; should the plot be saved</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether the interaction between two continuous predictor variables is negligible. This can be important for deciding whether to remove an interaction term from a model or to evaluate a hypothesis related to negligible interaction.
</p>
<p>eiL/eiU represent the bounds of the negligible effect (equivalence) interval (i.e., the minimally meaningful effect size, MMES) and should be set based on the context of the research. When standardized = TRUE, Acock (2014) suggests that the MMES for correlations can also be applied to standardized effects - Acock, A. C. (2014). A Gentle Introduction to Stata (4th ed.). Texas: Stata Press.
</p>
<p>User can input the outcome variable and two predictor variable names directly (i.e., without a data statement), or can use the data statement to indicate the dataset in which the variables can be found.
</p>
<p>The advantage of this approach when standardized = TRUE and there are only two predictors is that the Delta method is adopted. However, for general cases researchers can also use the neg.reg function.
</p>
<p>The proportional distance (interaction coefficient/negligible effect bound) estimates the proportional distance of the effect from 0 to negligible effect bound, and acts as an alternative effect size measure.
</p>
<p>The confidence interval for the proportional distance is computed via bootstrapping (percentile bootstrap).
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the following:
</p>

<ul>
<li> <p><code>intcoef</code> Interaction coefficient
</p>
</li>
<li> <p><code>intcil</code> Lower bound of the 1-alpha CI for the interaction coefficient
</p>
</li>
<li> <p><code>intciu</code> Upper bound of the 1-alpha CI for the interaction coefficient
</p>
</li>
<li> <p><code>eiL</code> Lower bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>eiU</code> Upper bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>sprs</code> Semi-partial correlation squared for the interaction term
</p>
</li>
<li> <p><code>PD</code> Proportional distance
</p>
</li>
<li> <p><code>CI95L</code> Lower bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>CI95U</code> Upper bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>y&lt;-rnorm(25)
x1&lt;-rnorm(25)
x2&lt;-rnorm(25)
d&lt;-data.frame(y,x1,x2)
neg.intcont(outcome = y, pred1 = x1, pred2 = x2, data = d,
eiL = -.25, eiU = .25, standardized = TRUE, nbootpd = 100)
</code></pre>

<hr>
<h2 id='neg.normal'>Negligible Effect Test for Normality of a Univariate Distribution</h2><span id='topic+neg.normal'></span><span id='topic+print.neg.normal'></span>

<h3>Description</h3>

<p>This function allows researchers to test whether the distribution
of scores in a distribution has a Shapiro-Wilk W statistic that is negligibly different from 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.normal(x, eiL = 0.95, nboot = 1000, plot = TRUE, alpha = 0.05, data = NULL)

## S3 method for class 'neg.normal'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.normal_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.normal</code></p>
</td></tr>
<tr><td><code id="neg.normal_+3A_eil">eiL</code></td>
<td>
<p>Lower Bound of the Negligible Effect Interval for W</p>
</td></tr>
<tr><td><code id="neg.normal_+3A_nboot">nboot</code></td>
<td>
<p>Number of Bootstrap Samples for computing the CIs</p>
</td></tr>
<tr><td><code id="neg.normal_+3A_plot">plot</code></td>
<td>
<p>If the user prefers plots to be generated</p>
</td></tr>
<tr><td><code id="neg.normal_+3A_alpha">alpha</code></td>
<td>
<p>Nominal Type I Error Rate</p>
</td></tr>
<tr><td><code id="neg.normal_+3A_data">data</code></td>
<td>
<p>Dataset containing x</p>
</td></tr>
<tr><td><code id="neg.normal_+3A_...">...</code></td>
<td>
<p>Extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>#' This function allows researchers to test whether the distribution
of scores in a distribution has a Shapiro-Wilk W statistic that is negligibly different from 1.
I.e., we are testing the null hypothesis that W is less than or equal to some
prespecified lower bound for W (i.e., the least extreme value of W that is
non-negligibly different from 1). We recommend .95 and .975 as liberal and conservative bounds,
respectively
</p>


<h3>Value</h3>

<p>A <code>list</code> including the following:
</p>

<ul>
<li> <p><code>sw</code> Sample Shapiro-Wilk W statistic
</p>
</li>
<li> <p><code>sskew</code> Sample skewness
</p>
</li>
<li> <p><code>skurt</code> Sample kurtosis
</p>
</li>
<li> <p><code>sddiff_mn_mdn</code> Standardized difference between the sample mean and median
</p>
</li>
<li> <p><code>sddiff_mn_trmn</code> Standardized difference between the sample mean and trimmed mean
</p>
</li>
<li> <p><code>lb</code> Lower bound of 1-alpha CI for W
</p>
</li>
<li> <p><code>eiL</code> Maximum W for which the degree of nonnormality is considered extreme
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Linda Farmus <a href="mailto:lifarm@yorku.ca">lifarm@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Normal Distribution
xx&lt;-stats::rnorm(200)
neg.normal(xx)
#Positive Skewed Distribution
xx&lt;-stats::rchisq(200, df=3)
neg.normal(xx)
</code></pre>

<hr>
<h2 id='neg.paired'>Negligible Effect Test on the Difference between the Means of Dependent Populations</h2><span id='topic+neg.paired'></span><span id='topic+print.neg.paired'></span>

<h3>Description</h3>

<p>This function allows researchers to test whether the difference
between the means of two dependent populations is negligible, where
negligible represents the smallest meaningful effect size (MMES)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.paired(
  var1 = NULL,
  var2 = NULL,
  outcome = NULL,
  group = NULL,
  ID = NULL,
  eil,
  eiu,
  normality = TRUE,
  nboot = 10000,
  alpha = 0.05,
  plot = TRUE,
  saveplot = FALSE,
  data = NULL,
  seed = NA,
  ...
)

## S3 method for class 'neg.paired'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.paired_+3A_var1">var1</code></td>
<td>
<p>Data for Group 1 (if outcome, group and ID are omitted)</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_var2">var2</code></td>
<td>
<p>Data for Group 2 (if outcome, group and ID are omitted)</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_outcome">outcome</code></td>
<td>
<p>Dependent Variable (if var1 and var2 are omitted)</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_group">group</code></td>
<td>
<p>Dichotomous Predictor/Independent Variable (if var1 and var2 are omitted)</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_id">ID</code></td>
<td>
<p>participant ID (if var1 and var2 are omitted)</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_eil">eil</code></td>
<td>
<p>Lower Bound of the Equivalence Interval</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_eiu">eiu</code></td>
<td>
<p>Upper Bound of the Equivalence Interval</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_normality">normality</code></td>
<td>
<p>Are the population variances (and hence the residuals) assumed to be normally distributed?</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_nboot">nboot</code></td>
<td>
<p>Number of bootstrap samples for calculating CIs</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_alpha">alpha</code></td>
<td>
<p>Nominal Type I Error rate</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_plot">plot</code></td>
<td>
<p>Should a plot of the results be produced?</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_saveplot">saveplot</code></td>
<td>
<p>Should the plot be saved?</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_data">data</code></td>
<td>
<p>Dataset containing var1/var2 or outcome/group/ID</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_seed">seed</code></td>
<td>
<p>Seed number</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_...">...</code></td>
<td>
<p>Extra arguments</p>
</td></tr>
<tr><td><code id="neg.paired_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.paired</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether the difference in the means of 2 dependent populations can be considered negligible (i.e., the population means can be considered equivalent).
</p>
<p>The user specifies either the data associated with the first and second groups/populations (var1, var2, both should be continuous) or specifies the Indepedent Variable/Predictor (group, should be a factor) and the Dependent Variable (outcome, should be continuous). A 'data' statement can be used if the variables are stored in an R dataset.
</p>
<p>The user must also specify the lower and upper bounds of the negligible effect (equivalence) interval. These are specified in the original units of the outcome variable.
</p>


<h3>Value</h3>

<p>A <code>list</code> including the following:
</p>

<ul>
<li> <p><code>meanx</code> Sample mean of the first population/group.
</p>
</li>
<li> <p><code>meany</code> Sample mean of the second population/group.
</p>
</li>
<li> <p><code>medx</code> Sample median of the first population/group.
</p>
</li>
<li> <p><code>medy</code> Sample median second population/group.
</p>
</li>
<li> <p><code>sdx</code> Sample standard deviation of the first population/group.
</p>
</li>
<li> <p><code>sdy</code> Sample standard deviation of the second population/group.
</p>
</li>
<li> <p><code>madx</code> Sample median absolute deviation of the first population/group.
</p>
</li>
<li> <p><code>mady</code> Sample median absolute deviation of the second population/group.
</p>
</li>
<li> <p><code>eil</code> Lower bound of the negligible effect (equivalence) interval.
</p>
</li>
<li> <p><code>eiu</code> Upper bound of the negligible effect (equivalence) interval.
</p>
</li>
<li> <p><code>effsizeraw</code> Simple difference in the means (or medians if normality = FALSE)
</p>
</li>
<li> <p><code>cilraw2</code> Lower bound of the 1-alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>ciuraw2</code> Upper bound of the 1-alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>cilraw</code> Lower bound of the 1-2*alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>ciuraw</code> Upper bound of the 1-2*alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>effsized</code> Standardized mean (or median if normality = FALSE) difference.
</p>
</li>
<li> <p><code>cild</code> Lower bound of the 1-alpha CI for the standardized mean (or median if normality = FALSE) difference.
</p>
</li>
<li> <p><code>ciud</code> Upper bound of the 1-alpha CI for the standardized mean (or median if normality = FALSE) difference.
</p>
</li>
<li> <p><code>effsizepd</code> Proportional distance statistic.
</p>
</li>
<li> <p><code>cilpd</code> Lower bound of the 1-alpha CI for the proportional distance statistic.
</p>
</li>
<li> <p><code>ciupd</code> Upper bound of the 1-alpha CI for the proportional distance statistic.
</p>
</li>
<li> <p><code>t1</code> First t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>t1</code> Second t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>df1</code> Degrees of freedom for the first t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>df2</code> Degrees of freedom for the second t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>pval1</code> p value associated with the first t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>pval2</code> p value associated with the second t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li>
<li> <p><code>seed</code> Seed number
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a>
Naomi Martinez Gutierrez <a href="mailto:naomimg@yorku.ca">naomimg@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#wide format
ID&lt;-rep(1:20)
control&lt;-rnorm(20)
intervention&lt;-rnorm(20)
d&lt;-data.frame(ID, control, intervention)
head(d)
neg.paired(var1=control,var2=intervention,eil=-1,eiu=1,plot=TRUE,
           data=d)
neg.paired(var1=d$control,var2=d$intervention,eil=-1,eiu=1,plot=TRUE)
neg.paired(var1=d$control,var2=d$intervention,eil=-1,eiu=1,normality=FALSE,
           nboot=10,plot=TRUE)

## Not run: 
#long format
sample1&lt;-sample(1:20, 20, replace=FALSE)
sample2&lt;-sample(1:20, 20, replace=FALSE)
ID&lt;-c(sample1, sample2)
group&lt;-rep(c("control","intervention"),c(20,20))
outcome&lt;-c(control,intervention)
d&lt;-data.frame(ID,group,outcome)
neg.paired(outcome=outcome,group=group,ID=ID,eil=-1,eiu=1,plot=TRUE,data=d)
neg.paired(outcome=d$outcome,group=d$group,ID=d$ID,eil=-1,eiu=1,plot=TRUE)
neg.paired(outcome=d$outcome,group=d$group,ID=d$ID,eil=-1,eiu=1,plot=TRUE, normality=FALSE)

#long format with multiple variables
sample1&lt;-sample(1:20, 20, replace=FALSE)
sample2&lt;-sample(1:20, 20, replace=FALSE)
ID&lt;-c(sample1, sample2)
attendance&lt;-sample(1:3, 20, replace=TRUE)
group&lt;-rep(c("control","intervention"),c(20,20))
outcome&lt;-c(control,intervention)
d&lt;-data.frame(ID,group,outcome,attendance)
neg.paired(outcome=outcome,group=group,ID=ID,eil=-1,eiu=1,plot=TRUE,data=d)
neg.paired(outcome=d$outcome,group=d$group,ID=d$ID,eil=-1,eiu=1,plot=TRUE)

#open a dataset
library(negligible)
d&lt;-perfectionism
names(d)
head(d)
neg.paired(var1=atqpre.total,var2=atqpost.total,
           eil=-10,eiu=10,data=d)

#Dataset with missing data
x&lt;-rnorm(10)
x[c(3,6)]&lt;-NA
y&lt;-rnorm(10)
y[c(7)]&lt;-NA
neg.paired(x,y,eil=-1,eiu=1, normality=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='neg.pd'>Proportional Distance Function (post hoc function - not to be used independently)</h2><span id='topic+neg.pd'></span>

<h3>Description</h3>

<p>Proportional Distance Function (post hoc function - not to be used independently)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.pd(effect, PD, eil, eiu, PDcil, PDciu, cil, ciu, Elevel, Plevel, save, oe)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.pd_+3A_effect">effect</code></td>
<td>
<p>observed effect</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_pd">PD</code></td>
<td>
<p>proportional distance for effect</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_eil">eil</code></td>
<td>
<p>lower bound of the equivalence interval</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_eiu">eiu</code></td>
<td>
<p>upper bound of the equivalence interval</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_pdcil">PDcil</code></td>
<td>
<p>lower bound of the CI for the proportional distance</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_pdciu">PDciu</code></td>
<td>
<p>upper bound of the CI for the proportional distance</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_cil">cil</code></td>
<td>
<p>lower bound of the CI for the effect</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_ciu">ciu</code></td>
<td>
<p>upper bound of the CI for the effect</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_elevel">Elevel</code></td>
<td>
<p>1-2alpha CI for the effect</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_plevel">Plevel</code></td>
<td>
<p>1-alpha CI for the PD</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_save">save</code></td>
<td>
<p>Whether to save the plot or not</p>
</td></tr>
<tr><td><code id="neg.pd_+3A_oe">oe</code></td>
<td>
<p>Name of the original units of the effect of interest</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing is returned
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
1+1

## End(Not run)
</code></pre>

<hr>
<h2 id='neg.reg'>Test for Evaluating Negligible Effect Between a Predictor and Outcome in a Multiple Regression Model</h2><span id='topic+neg.reg'></span><span id='topic+print.neg.reg'></span>

<h3>Description</h3>

<p>This function evaluates whether a certain predictor variable in a multiple regression model can be considered statistically and practically negligible according to a predefined interval. i.e., minimally meaningful effect size (MMES)/smallest effect size of interest (SESOI). Where the effect tested is the relationship between the predictor of interest and the outcome variable, holding all other predictors constant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.reg(
  data = NULL,
  formula = NULL,
  predictor = NULL,
  b = NULL,
  se = NULL,
  nop = NULL,
  n = NULL,
  eil,
  eiu,
  alpha = 0.05,
  test = "AH",
  std = FALSE,
  bootstrap = TRUE,
  nboot = 1000,
  plots = TRUE,
  saveplots = FALSE,
  seed = NA,
  ...
)

## S3 method for class 'neg.reg'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.reg_+3A_data">data</code></td>
<td>
<p>a data.frame or matrix which includes the variables considered in the regression model</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_formula">formula</code></td>
<td>
<p>an argument of the form y~x1+x2...xn which defines the regression model</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_predictor">predictor</code></td>
<td>
<p>name of the variable/predictor upon which the test will be applied</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_b">b</code></td>
<td>
<p>effect size of the regression coefficient of interest, can be in standardized or unstandardized units</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_se">se</code></td>
<td>
<p>standard error associated with the above regression coefficient effect size, pay close attention to standardized vs. unstandardized</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_nop">nop</code></td>
<td>
<p>number of predictors (excluding intercept) in the regression model</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_n">n</code></td>
<td>
<p>the sample size used in the regression analysis</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_eil">eil</code></td>
<td>
<p>lower bound of the equivalence interval measured in the same units as the regression coefficients (can be either standardized or unstandardized)</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_eiu">eiu</code></td>
<td>
<p>upper bound of the equivalence interval measured in the same units as the regression coefficients (can be either standardized or unstandardized)</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_alpha">alpha</code></td>
<td>
<p>desired alpha level, default is .05</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_test">test</code></td>
<td>
<p>AH is the default based on recommendation in Alter &amp; Counsell (2020), TOST is an additional option</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_std">std</code></td>
<td>
<p>indicate if eil and eiu along with b (when dataset is not entered) are in standardized units</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_bootstrap">bootstrap</code></td>
<td>
<p>logical, default is TRUE, incorporating bootstrapping when calculating regression coefficients, SE, and CIs</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_nboot">nboot</code></td>
<td>
<p>1000 is the default. indicate if other number of bootstrapping iterations is desired</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_plots">plots</code></td>
<td>
<p>logical, plotting the results. TRUE is set as default</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_saveplots">saveplots</code></td>
<td>
<p>FALSE for no, &quot;png&quot; and &quot;jpeg&quot; for different formats</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_seed">seed</code></td>
<td>
<p>to reproduce previous analyses using bootstrapping, the user can set their seed of choice</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
<tr><td><code id="neg.reg_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.reg</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether a certain predictor variable in a multiple regression model can be considered statistically and practically negligible according to a predefined interval. i.e., minimally meaningful effect size (MMES)/smallest effect size of interest (SESOI). Where the effect tested is the relationship between the predictor of interest and the outcome variable, holding all other predictors constant.
</p>
<p>Unlike the most common null hypothesis significance tests looking to detect a difference or the existence of an effect statistically different than zero, in negligible effect testing, the hypotheses are flipped: In essence, H0 states that the effect is non-negligible, whereas H1 states that the effect is in fact statistically and practically negligible.
</p>
<p>The statistical tests are based on Anderson-Hauck (1983) and Schuirmann's (1987) Two One-Sided Test (TOST) equivalence testing procedures; namely addressing the question of whether the estimated effect size (and its associated uncertainty) of a predictor variable in a multiple regression model is smaller than the what the user defines as negligible effect size. Defining what is considered negligible effect is done by specifying the negligible (equivalence) interval: its upper (eiu) and lower (eil) bounds.
</p>
<p>The negligible (equivalence) interval should be set based on the context of the research. Because the predictor's effect size can be in either standardized or unstandardized units, setting eil and eiu is a matter of determining what magnitude of the relationship between predictor and outcome in either standardized or unstandardized units is the minimally meaningful effect size (MMES) given the context of the research.
</p>
<p>It is necessary to be consistent with the units of measurement. For example, unstandardized negligible interval bounds (i.e., eil and eiu) must only be used when std = FALSE (default). If the effect size (b), standard error (se), and sample size (n) are entered manually as arguments (i.e., without the dataset), these should also be in the same units of measurements. Whereas if the user prefers to specify eiu and eil in standardized unites, std = TRUE should be specified. In which case, any units entered into the function must also be in standardized form. Mixing unstandardized and standardized units would yield inaccurate results and likely lead to invalid conclusions. Thus, users must be cognizant of the measurement units of the negligible interval.
</p>
<p>There are two main approaches to using neg.reg. The first (and more recommended) is by inserting a dataset ('data' argument) into the function. If the user/s have access to the dataset, they should use the following set of arguments: data, formula, predictor, bootstrap (optional), nboot (optional), and seed (optional). However, this function also accommodates cases where no dataset is available. In this case, users should use the following set of arguments instead: b, se, n, and nop. In either situation, users must specify the negligible interval bounds (eiu and eil). Other optional arguments and features include: alpha, std, test, plots, and saveplots.
</p>
<p>The proportional distance (PD; effect size/eiu) estimates the proportional distance of the estimated effect to eiu, and acts as an alternative effect size measure.
</p>
<p>The confidence interval for the PD is computed via bootstrapping (percentile bootstrap), unless the user does not insert a dataset. In which case, the PD confidence interval is calculated by dividing the upper and lower CI bounds for the effect size estimate by the absolute value of the negligible interval bounds.
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the following:
</p>

<ul>
<li> <p><code>formula</code> The regression model
</p>
</li>
<li> <p><code>effect</code> Specifying if effect size is in standardized or unstandardized units
</p>
</li>
<li> <p><code>test</code> Test type, i.e., Anderson-Hauck (AH) or Two One-Sided Tests (TOST)
</p>
</li>
<li> <p><code>t.value</code> t test statistic. If TOST was specified, only the smaller of the t values will be presented
</p>
</li>
<li> <p><code>df</code> Degrees of freedom associated with the test statistic
</p>
</li>
<li> <p><code>n</code> Sample size
</p>
</li>
<li> <p><code>p.value</code> p value associated with the test statistic. If TOST was specified, only the larger of the p values will be presented
</p>
</li>
<li> <p><code>eil</code> Lower bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>eiu</code> Upper bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>predictor</code> Variable name of the predictor in question
</p>
</li>
<li> <p><code>b</code> Effect size of the specified predictor
</p>
</li>
<li> <p><code>se</code> Standard error associated with the effect size point estimate (in the same units)
</p>
</li>
<li> <p><code>l.ci</code> Lower bound of the 1-alpha CI for the effect size
</p>
</li>
<li> <p><code>u.ci</code> Upper bound of the 1-alpha CI for the effect size
</p>
</li>
<li> <p><code>pd</code> Proportional distance
</p>
</li>
<li> <p><code>pd.l.ci</code> Lower bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>pd.u.ci</code> Upper bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>seed</code> Seed identity if bootstrapping is used
</p>
</li>
<li> <p><code>decision</code> NHST decision
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Udi Alter <a href="mailto:udialter@gmail.com">udialter@gmail.com</a> and
Alyssa Counsell <a href="mailto:a.counsell@torontomu.ca">a.counsell@torontomu.ca</a> and
Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Negligible Regression Coefficient (equivalence interval: -.1 to .1)
pr1 &lt;- stats::rnorm(20, mean = 0, sd= 1)
pr2 &lt;- stats::rnorm(20, mean = 0, sd= 1)
dp &lt;- stats::rnorm(20, mean = 0, sd= 1)
dat &lt;- data.frame(pr1,pr2,dp)

# dataset available (unstandardized coefficients, AH procedure, using bootstrap-generated CIs):
neg.reg(formula=dp~pr1+pr2,data=dat,predictor=pr1,eil=-.1,eiu=.1,nboot=5)
neg.reg(formula=dat$dp ~ dat$pr1 + dat$pr2, predictor= pr1, eil= -.25, eiu= .25, nboot=5)

# dataset unavailable (standardized coefficients, TOST procedure):
neg.reg(b= .017, se= .025, nop= 3, n= 500, eil=-.1,eiu=.1, std=TRUE, test="TOST")
# end.



</code></pre>

<hr>
<h2 id='neg.rmsea'>Equivalence Tests for RMSEA</h2><span id='topic+neg.rmsea'></span><span id='topic+print.neg.rmsea'></span>

<h3>Description</h3>

<p>Function performs one of four equivalence tests for RMSEA fit index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.rmsea(
  mod,
  alpha = 0.05,
  eq.bound,
  modif.eq.bound = FALSE,
  ci.method = "not.close",
  nbootpd = 50L,
  nboot = 250L,
  round = 3,
  plot = TRUE,
  saveplot = FALSE
)

## S3 method for class 'neg.rmsea'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.rmsea_+3A_mod">mod</code></td>
<td>
<p>lavaan model object</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_alpha">alpha</code></td>
<td>
<p>desired alpha level (default = .05)</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_eq.bound">eq.bound</code></td>
<td>
<p>upper end of equivalence interval for comparison; must be .01, .05, .08 or .10 if modif.eq.bound = TRUE</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_modif.eq.bound">modif.eq.bound</code></td>
<td>
<p>should the upper end of the equivalence interval be modified? (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_ci.method">ci.method</code></td>
<td>
<p>method used to calculate confidence interval; options are &quot;not.close&quot; or &quot;yhy.boot&quot;; &quot;not.close&quot; corresponds to (1-2alpha) percent CI, &quot;yhy.boot&quot; corresponds to (1-2alpha) percent boot CI (default = &quot;not.close&quot;)</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_nbootpd">nbootpd</code></td>
<td>
<p>number of bootstrap samples by &quot;yhy.boot&quot; for pd function</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap samples if &quot;yhy.boot&quot; is selected as ci.method (default = 250L)</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_round">round</code></td>
<td>
<p>number of digits to round equivalence bound and confidence interval bounds (default = 3)</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_plot">plot</code></td>
<td>
<p>logical, plotting the results (default = TRUE)</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_saveplot">saveplot</code></td>
<td>
<p>saving plots (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.rmsea</code></p>
</td></tr>
<tr><td><code id="neg.rmsea_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user specifies the lavaan fitted model object, the desired equivalence bound, and method of confidence interval computation. By default, the function does not modify the equivalence bounds according to Yuan et al. (2016). The user can also choose to instead run an equivalence test using a modified equivalence bound if the equivalence bound to be modified is .01, .05, .08, or .10. Alpha level can also be modified.
</p>
<p>For information on modified equivalence bounds see Yuan, K. H., Chan, W., Marcoulides, G. A., &amp; Bentler, P. M. (2016). Assessing structural equation models by equivalence testing with adjusted fit indexes. Structural Equation Modeling: A Multidisciplinary Journal, 23(3), 319-330. doi: https://doi.org/10.1080/10705511.2015.1065414.
</p>
<p>The proportional distance quantifies the proportional distance from 0 to the nearest negligible effect (equivalence) interval (here, eiU). As values get farther from 0 the relationship becomes more substantial, with values greater than 1 indicating that the effect falls outside of the negligible effect (equivalence) interval.
</p>


<h3>Value</h3>

<p>returns a <code>list</code> including the following:
</p>

<ul>
<li> <p><code>title1</code> The title of the RMSEA equivalence test. The appropriate title of the test will be displayed depending on the ci.method chosen and whether modif.eq.bound is TRUE or FALSE.
</p>
</li>
<li> <p><code>rmsea_index</code> The RMSEA index.
</p>
</li>
<li> <p><code>ci.method</code> The method for confidence interval calculation (direct computation or bootstrap).
</p>
</li>
<li> <p><code>rmsea_eq</code> The upper end of the 1-2*alpha confidence interval for the RMSEA index.
</p>
</li>
<li> <p><code>eq.bound</code> The equivalence bound.
</p>
</li>
<li> <p><code>PD</code> Proportional distance (PD).
</p>
</li>
<li> <p><code>cilpd</code> Lower bound of the 1-alpha CI for the PD.
</p>
</li>
<li> <p><code>ciupd</code> Upper bound of the 1-alpha CI for the PD.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Nataly Beribisky <a href="mailto:natalyb1@yorku.ca">natalyb1@yorku.ca</a>
</p>
<p>@export neg.rmsea
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- lavaan::HolzingerSwineford1939
hs.mod &lt;- 'visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9'
fit1 &lt;- lavaan::cfa(hs.mod, data = d)
neg.rmsea(alpha = .05, mod = fit1, eq.bound = .05, ci.method = "not.close", modif.eq.bound = FALSE,
round = 5, nboot = 50)
</code></pre>

<hr>
<h2 id='neg.semfit'>Equivalence Tests for Fit Indices</h2><span id='topic+neg.semfit'></span>

<h3>Description</h3>

<p>Function performs equivalence tests for RMSEA, CFI, and SRMR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.semfit(
  mod,
  alpha = 0.05,
  round = 3,
  rmsea.eq.bound = 0.05,
  rmsea.modif.eq.bound = FALSE,
  rmsea.ci.method = "not.close",
  rmsea.nboot = 250L,
  cfi.eq.bound = 0.95,
  cfi.modif.eq.bound = FALSE,
  cfi.ci.method = "yhy.boot",
  cfi.nboot = 250L,
  srmr.eq.bound = 0.08,
  srmr.modif.eq.bound = FALSE,
  srmr.ci.method = "MO",
  usrmr = TRUE,
  srmr.nboot = 250L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.semfit_+3A_mod">mod</code></td>
<td>
<p>lavaan model object</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_alpha">alpha</code></td>
<td>
<p>desired alpha level (default = .05)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_round">round</code></td>
<td>
<p>number of digits to round equivalence bound and confidence interval bounds (default = 3)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_rmsea.eq.bound">rmsea.eq.bound</code></td>
<td>
<p>upper bound of the equivalence interval for RMSEA for comparison; must be .01, .05, .08, or .10 if rmsea.modif.eq.bound = TRUE</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_rmsea.modif.eq.bound">rmsea.modif.eq.bound</code></td>
<td>
<p>should the upper bound of the equivalence interval for RMSEA be modified (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_rmsea.ci.method">rmsea.ci.method</code></td>
<td>
<p>method used to calculate confidence interval for RMSEA; options are &quot;not.close&quot; or &quot;yhy.boot&quot;; &quot;not.close&quot; corresponds to (1-2alpha) percent CI, &quot;yhy.boot&quot; corresponds to (1-2alpha) percent boot CI (default = &quot;not.close&quot;)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_rmsea.nboot">rmsea.nboot</code></td>
<td>
<p>number of bootstrap samples if &quot;yhy.boot&quot; is selected as rmsea.ci.method (default = 250L)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_cfi.eq.bound">cfi.eq.bound</code></td>
<td>
<p>lower bound of equivalence interval for CFI for comparison; must be .99, .95, .92 or .90 if cfi.modif.eq.bound = TRUE</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_cfi.modif.eq.bound">cfi.modif.eq.bound</code></td>
<td>
<p>should the lower bound of the equivalence interval for CFI be modified (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_cfi.ci.method">cfi.ci.method</code></td>
<td>
<p>method used to calculate confidence interval for CFI; options are &quot;yuan&quot;, &quot;equiv&quot; or &quot;yhy.boot&quot;; &quot;yuan&quot; corresponds to (1-alpha) percent CI, &quot;equiv&quot; corresponds to (1-2alpha) percent CI, &quot;yhy.boot&quot; corresponds to (1-2alpha) percent boot CI (default = &quot;equiv&quot;)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_cfi.nboot">cfi.nboot</code></td>
<td>
<p>number of bootstrap samples if &quot;yhy.boot&quot; is selected as cfi.ci.method (default = 250L)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_srmr.eq.bound">srmr.eq.bound</code></td>
<td>
<p>upper bound of equivalence interval for SRMR for comparison; must be .05 or .10 if modif.eq.bound = TRUE</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_srmr.modif.eq.bound">srmr.modif.eq.bound</code></td>
<td>
<p>should the upper bound of the equivalence interval for SRMR be modified? (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_srmr.ci.method">srmr.ci.method</code></td>
<td>
<p>method used to calculate confidence interval for SRMR; options are &quot;MO&quot; or &quot;yhy.boot&quot;; &quot;MO&quot; corresponds to (1-2alpha) percent CI, &quot;yhy.boot&quot; corresponds to (1-2alpha) percent boot CI (default = &quot;MO&quot;)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_usrmr">usrmr</code></td>
<td>
<p>fit index around which equivalence test should be structured (usrmr = TRUE which is the default states that usrmr from Maydeu-Olivares, 2017 will be used, otherwise srmr from fitmeasures() output in lavaan will be used)</p>
</td></tr>
<tr><td><code id="neg.semfit_+3A_srmr.nboot">srmr.nboot</code></td>
<td>
<p>number of bootstrap samples if &quot;yhy.boot&quot; is selected as srmr.ci.method (default = 250L)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>#'
The user specifies the lavaan fitted model object, the desired equivalence bound, and method of confidence interval computation for RMSEA, CFI, and SRMR. By default, the function does not modify the equivalence bounds according to Yuan et al. (2016) or according to Shi et al. (2018). The user can also choose to instead run an equivalence test using a modified equivalence bound if the equivalence bound to be modified is .01, .05, .08, or .10 for RMSEA,.99, .95, .92 or .90 for CFI, .05 or .10 for SRMR.
Alpha level can also be modified.
</p>
<p>For information on modified equivalence bounds for CFI and RMSEA see Yuan, K. H., Chan, W., Marcoulides, G. A., &amp; Bentler, P. M. (2016). Assessing structural equation models by equivalence testing with adjusted fit indexes. Structural Equation Modeling: A Multidisciplinary Journal, 23(3), 319-330. doi: https://doi.org/10.1080/10705511.2015.1065414.
For information on uSRMR and modified cut-offs for SRMR see:
Maydeu-Olivares, A. (2017). Maximum likelihood estimation of structural equation models for continuous data: Standard errors and goodness of fit. Structural Equation Modeling: A Multidisciplinary Journal, 24(3), 383-394.
Shi, D., Maydeu-Olivares, A., &amp; DiStefano, C. (2018). The relationship between the standardized root mean square residual and model misspecification in factor analysis models. Multivariate Behavioral Research, 53(5), 676-694.
</p>


<h3>Value</h3>

<p>returns a <code>list</code> containing analysis and respective statistics
and decision.
</p>

<ul>
<li> <p><code>title1</code> The appropriate title of the test will be displayed depending on the ci.method chosen and whether modif.eq.bound is TRUE or FALSE.
</p>
</li>
<li> <p><code>cfi_index</code> The CFI index.
</p>
</li>
<li> <p><code>ci.method</code> The method for confidence interval calculation.
</p>
</li>
<li> <p><code>cfi_eq</code> The lower end of the confidence interval for the CFI index.
</p>
</li>
<li> <p><code>eq.bound</code> The equivalence bound.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Nataly Beribisky <a href="mailto:natalyb1@yorku.ca">natalyb1@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- lavaan::HolzingerSwineford1939
hs.mod &lt;- 'visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9'
fit1 &lt;- lavaan::cfa(hs.mod, data = d)
neg.cfi(mod = fit1, alpha = .05, eq.bound = .95,  modif.eq.bound = FALSE, ci.method = "equiv",
round = 3, plot = TRUE)

</code></pre>

<hr>
<h2 id='neg.srmr'>Equivalence Tests for SRMR</h2><span id='topic+neg.srmr'></span><span id='topic+print.neg.srmr'></span>

<h3>Description</h3>

<p>Function performs one of four equivalence tests for SRMR fit index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.srmr(
  mod,
  alpha = 0.05,
  eq.bound,
  modif.eq.bound = FALSE,
  ci.method = "MO",
  usrmr = TRUE,
  nboot = 250L,
  round = 3
)

## S3 method for class 'neg.srmr'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.srmr_+3A_mod">mod</code></td>
<td>
<p>lavaan model object</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_alpha">alpha</code></td>
<td>
<p>desired alpha level (default = .05)</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_eq.bound">eq.bound</code></td>
<td>
<p>upper bound of equivalence interval for comparison; must be .05 or .10 if modif.eq.bound = TRUE</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_modif.eq.bound">modif.eq.bound</code></td>
<td>
<p>should the upper bound of the equivalence interval be modified? (default = FALSE)</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_ci.method">ci.method</code></td>
<td>
<p>method used to calculate confidence interval; options are &quot;MO&quot; or &quot;yhy.boot&quot;; &quot;MO&quot; corresponds to (1-2alpha) percent CI, &quot;yhy.boot&quot; corresponds to (1-2alpha) percent boot CI (default = &quot;MO&quot;)</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_usrmr">usrmr</code></td>
<td>
<p>fit index around which equivalence test should be structured (usrmr = TRUE which is the default states that usrmr from Maydeu-Olivares, 2017 will be used, otherwise srmr from fitmeasures() output in lavaan will be used)</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap samples if &quot;yhy.boot&quot; is selected as ci.method (default = 250L)</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_round">round</code></td>
<td>
<p>number of digits to round equivalence bound and confidence interval bounds (default = 3)</p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.srmr</code></p>
</td></tr>
<tr><td><code id="neg.srmr_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user specifies the lavaan fitted model object, the desired equivalence bound, the method of confidence interval computation, and whether unbiased SRMR or original SRMR should be used. By default, the function does not modify the equivalence bounds. The user can also choose to instead run an equivalence test using a modified equivalence bound of .05 or .10 multiplied by the average communality of the observed indicators. Alpha level can also be modified.
</p>
<p>For information on unbiased SRMR and its confidence interval computation see Maydeu-Olivares, A. (2017). Maximum likelihood estimation of structural equation models for continuous data: Standard errors and goodness of fit. Structural Equation Modeling: A Multidisciplinary Journal, 24(3), 383-394. https://doi.org/10.1080/10705511.2016.1269606
</p>


<h3>Value</h3>

<p>returns a <code>list</code> including the following:
</p>

<ul>
<li> <p><code>title1</code> The title of the SRMR equivalence test. The appropriate title of the test will be displayed depending on the ci.method chosen whether usrmr and modif.eq.bound are TRUE or FALSE.
</p>
</li>
<li> <p><code>srmr_index</code> The SRMR index.
</p>
</li>
<li> <p><code>ci.method</code> The method for confidence interval calculation (direct computation or bootstrap).
</p>
</li>
<li> <p><code>srmr_ci</code> The upper bound of the 1-2*alpha confidence interval for the RMSEA index.
</p>
</li>
<li> <p><code>eq.bound</code> The equivalence bound.
</p>
</li>
<li> <p><code>PD</code> Proportional distance (PD).
</p>
</li>
<li> <p><code>cilpd</code> Lower bound of the 1-alpha CI for the PD.
</p>
</li>
<li> <p><code>ciupd</code> Upper bound of the 1-alpha CI for the PD.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Nataly Beribisky <a href="mailto:natalyb1@yorku.ca">natalyb1@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- lavaan::HolzingerSwineford1939
hs.mod &lt;- 'visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9'
fit1 &lt;- lavaan::cfa(hs.mod, data = d)
neg.srmr(mod=fit1,alpha=.05,eq.bound=.08,usrmr = TRUE)
</code></pre>

<hr>
<h2 id='neg.twocors'>Test for Evaluating Negligible Effects of Two Independent or Dependent Correlation Coefficients: Based on Counsell &amp; Cribbie (2015)</h2><span id='topic+neg.twocors'></span><span id='topic+print.neg.twocors'></span>

<h3>Description</h3>

<p>This function evaluates whether the difference between two correlation coefficients can be considered statistically and practically negligible
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.twocors(
  data = NULL,
  r1v1 = NULL,
  r1v2 = NULL,
  r2v1 = NULL,
  r2v2 = NULL,
  r1 = NULL,
  n1 = NULL,
  r2 = NULL,
  n2 = NULL,
  dep = FALSE,
  r3 = NA,
  test = "AH",
  eiu,
  eil,
  alpha = 0.05,
  bootstrap = TRUE,
  nboot = 1000,
  seed = NA,
  plots = TRUE,
  saveplots = FALSE,
  ...
)

## S3 method for class 'neg.twocors'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.twocors_+3A_data">data</code></td>
<td>
<p>a data.frame or matrix which includes the variables in r1 and r2</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_r1v1">r1v1</code></td>
<td>
<p>the name of the 1st variable included in the 1st correlation coefficient (r1, variable 1)</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_r1v2">r1v2</code></td>
<td>
<p>the name of the 2nd variable included in the 1st correlation coefficient (r1, variable 2)</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_r2v1">r2v1</code></td>
<td>
<p>the name of the 1st variable included in the 2nd correlation coefficient (r2, variable 1)</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_r2v2">r2v2</code></td>
<td>
<p>the name of the 2nd variable included in the 2st correlation coefficient (r2, variable 2)</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_r1">r1</code></td>
<td>
<p>entered 1st correlation coefficient manually, without a dataset</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_n1">n1</code></td>
<td>
<p>entered sample size associated with r1 manually, without a dataset</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_r2">r2</code></td>
<td>
<p>entered 2nd correlation coefficient manually, without a dataset</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_n2">n2</code></td>
<td>
<p>entered sample size associated with r2 manually, without a dataset</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_dep">dep</code></td>
<td>
<p>are the correlation coefficients dependent (overlapping)?</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_r3">r3</code></td>
<td>
<p>if the correlation coefficients are dependent and no datasets were entered, specify the correlation between the two, non-intersecting variables (e.g. if r1 = r12 and r2 = r13, then r3 = r23)</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_test">test</code></td>
<td>
<p>'AH' is the default based on recommendation in Counsell &amp; Cribbie (2015), 'TOST' is an additional (albeit, more conservative) option.</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_eiu">eiu</code></td>
<td>
<p>upper bound of the equivalence interval measured as the largest difference between the two correlations for which the two coefficients would still be considered equivalent</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_eil">eil</code></td>
<td>
<p>lower bound of the equivalence interval measured as the largest difference between the two correlations for which the two coefficients would still be considered equivalent</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_alpha">alpha</code></td>
<td>
<p>desired alpha level, defualt is .05</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_bootstrap">bootstrap</code></td>
<td>
<p>logical, default is TRUE, incorporating bootstrapping when calculating regression coefficients, SE, and CIs</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_nboot">nboot</code></td>
<td>
<p>1000 is the default. indicate if other number of bootstrapping iterations is desired</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_seed">seed</code></td>
<td>
<p>to reproduce previous analyses using bootstrapping, the user can set their seed of choice</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_plots">plots</code></td>
<td>
<p>logical, plotting the results. TRUE is set as default</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_saveplots">saveplots</code></td>
<td>
<p>FALSE for no, &quot;png&quot; and &quot;jpeg&quot; for different formats</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
<tr><td><code id="neg.twocors_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.twocors</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether the difference between two correlation coefficients can be considered statistically and practically negligible according to a predefined interval. i.e., minimally meaningful effect size (MMES)/smallest effect size of interest (SESOI). The effect size tested is the difference between two correlation coefficients (i.e., r1 - r2).
</p>
<p>Unlike the most common null hypothesis significance tests looking to detect a difference or the existence of an effect statistically different than zero, in negligible effect testing, the hypotheses are flipped: In essence, H0 states that the effect is non-negligible, whereas H1 states that the effect is in fact statistically and practically negligible.
</p>
<p>The statistical tests are based on Anderson-Hauck (1983) and Schuirmann's (1987) Two One-Sided Test (TOST) equivalence testing procedures; namely addressing the question of whether the estimated effect size (and its associated uncertainty) of a difference between two correlation coefficients (i.e., r1 and r2) is smaller than the what the user defines as negligible effect size. Defining what is considered negligible effect is done by specifying the negligible (equivalence) interval: its upper (eiu) and lower (eil) bounds.
</p>
<p>The negligible (equivalence) interval should be set based on the context of the research. Because the two correlations (and, therefore their difference) are in standardized units, setting eil and eiu is a matter of determining what is the smallest difference between the two correlations that can be considered of practical significance. For example, if the user determines that the smallest effect of interest is 0.1 â€“ that is, any difference between the two correlation coefficient larger than 0.1 is meaningful in this context - then eil will be set to -0.1 and eiu to 0.1. Therefore, any observable difference that is larger than -0.1 AND smaller than 0.1, will be considered practically negligible.
</p>
<p>There are two main approaches to using neg.twocors. The first (and more recommended) is by inserting a dataset ('data' argument) into the function. If the user/s have access to the dataset, they should use the following set of arguments: data, formula, r1v1, r1v2, r2v1, r2v2, dep (if applicable), bootstrap (optional), nboot (optional), and seed (optional). However, this function also accommodates cases where no dataset is available. In this case, users should use the following set of arguments instead: r1, n1, r2, n2, and r3 (if applicable). In either situation, users must specify the negligible interval bounds (eiu and eil). Other optional arguments and features include: alpha, test, plots, and saveplots.
</p>
<p>This function accommodates both independent and dependent correlations. A user might want to compare two independent correlations. For example, the correlation between X and Y in one group (e.g., Control group; rXYc) with the correlation between X and Y in a different, independent group (e.g., Treatment group; rXYt). The â€˜independent correlationsâ€™ setting (i.e., dep=FALSE) is the default in this function. However, in other cases, a user might want to compare two dependent correlation coefficients. That is, the two correlations share a common variable (i.e., same variable values). For example, the correlation between X and Y in one group (e.g., Treatment group; rXYt) with the correlation between X and B in the same group (e.g., Treatment group; rXBt). Because values in variable X are shared among the two correlations, the two correlations (e.g., rXYt and rXBt) are not independent from one another, but, in fact, dependent. To compare two dependent correlation coefficients, users need only to specify dep=TRUE. If no dataset is entered into the function, users should also use the argument r3, which will hold the correlation between the two non-shared variables. In the example above (i.e., rXYt and rXBt), the two non-shared variables are Y and B. In this case, r3 = rYBt.  If dep=TRUE is entered into the function, test statistics and p values will be calculated differently to account for the shared variable. The negligible testing methods for comparing dependent correlations in this function are based on Williamsâ€™s (1959) modification to Hotellingâ€™s (1931) test for comparing overlapping dependent correlations. For more details see Counsell and Cribbie (2015).
</p>
<p>The proportional distance (PD; effect size/eiu) estimates the proportional distance of the estimated effect to eiu, and acts as an alternative effect size measure.
</p>
<p>The confidence interval for the PD is computed via bootstrapping (percentile bootstrap), unless the user does not insert a dataset. In which case, the PD confidence interval is calculated by dividing the upper and lower CI bounds for the effect size estimate by the absolute value of the negligible interval bounds.
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the following:
</p>

<ul>
<li> <p><code>r1v1</code> Name of the 1st variable included in the 1st correlation coefficient (r1, variable 1 ; if applicable)
</p>
</li>
<li> <p><code>r1v2</code> Name of the 2nd variable included in the 1st correlation coefficient (r1, variable 2; if applicable)
</p>
</li>
<li> <p><code>r2v1</code> Name of the 1st variable included in the 2nd correlation coefficient (r2, variable 1; if applicable)
</p>
</li>
<li> <p><code>r2v2</code> Name of the 2nd variable included in the 2nd correlation coefficient (r2, variable 2; if applicable)
</p>
</li>
<li> <p><code>r1</code> Effect size of the first bivariate relationship (1st correlation coefficient)
</p>
</li>
<li> <p><code>n1</code> Sample size in each variable included in the first correlation (r1)
</p>
</li>
<li> <p><code>r2</code> Effect size of the second bivariate relationship (2nd correlation coefficient)
</p>
</li>
<li> <p><code>n2</code> Sample size in each variable included in the second correlation (r2)
</p>
</li>
<li> <p><code>r3</code> If the correlation coefficients (r1 and r2) are dependent, r3 is then the correlation coefficient of the two, non-intersecting variables (e.g. if r1 = r12 and r2 = r13, then r3 = r23; if applicable)
</p>
</li>
<li> <p><code>rsdiff</code> The difference between the two correlation coefficients. Specifically, r1 - r2.
</p>
</li>
<li> <p><code>se</code> Standard error associated with the effect size point estimate (the difference between r1 and r2). The SE calculations are based on Kraatz (2007) and can be found in  Counsell &amp; Cribbie (2015)
</p>
</li>
<li> <p><code>dep</code> Logical. TRUE if r1 and r2 are dependent, otherwise FALSE
</p>
</li>
<li> <p><code>eil</code> Lower bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>eiu</code> Upper bound of the negligible effect (equivalence) interval
</p>
</li>
<li> <p><code>u.ci.a</code> Upper bound of the 1-alpha CI for the effect size
</p>
</li>
<li> <p><code>l.ci.a</code> Lower bound of the 1-alpha CI for the effect size
</p>
</li>
<li> <p><code>pd</code> Proportional distance
</p>
</li>
<li> <p><code>pd.l.ci</code> Lower bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>pd.u.ci</code> Upper bound of the 1-alpha CI for the PD
</p>
</li>
<li> <p><code>seed</code> Seed identity if bootstrapping is used (if applicable)
</p>
</li>
<li> <p><code>nboot</code> Number of bootstrapping iterations, if bootstrapping was used (if applicable)
</p>
</li>
<li> <p><code>which.test</code> Test type, e.g., AH-rho-D, KTOST-rho etc. See Counsell &amp; Cribbie (2015) for details
</p>
</li>
<li> <p><code>degfree</code> Degrees of freedom associated with the test statistic
</p>
</li>
<li> <p><code>pv</code> p value associated with the test statistic. If TOST was specified, only the larger of the p values will be presented
</p>
</li>
<li> <p><code>NHSTdecision</code> NHST decision
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a> and
Alyssa Counsell <a href="mailto:a.counsell@ryerson.ca">a.counsell@ryerson.ca</a> and
Udi Alter <a href="mailto:udialter@gmail.com">udialter@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Negligible difference between two correlation coefficients
# Equivalence interval: -.15 to .15
v1a&lt;-stats::rnorm(10)
v2a&lt;-stats::rnorm(10)
v1b &lt;- stats::rnorm(10)
v2b &lt;- stats::rnorm(10)
dat&lt;-data.frame(v1a, v2a, v1b, v2b)
# dataset available (independent correlation coefficients):
neg.twocors(r1v1=v1a,r1v2=v2a,r2v1=v1b,r2v2=v2b,data=dat,eiu=.15,eil=-.15,nboot=50, dep=FALSE)
neg.twocors(r1=0.5,n1=300,r2=0.6,n2=500,eiu=.15,eil=-0.15, dep=TRUE, r3=0.51)
# end.




</code></pre>

<hr>
<h2 id='neg.twoindmeans'>Negligible Effect Test on the Difference between the Means of Independent Populations</h2><span id='topic+neg.twoindmeans'></span><span id='topic+print.neg.twoindmeans'></span>

<h3>Description</h3>

<p>This function allows researchers to test whether the difference
between the means of two independent populations is negligible, where
negligible represents the smallest meaningful effect size (MMES, which
in this case the effect is the mean difference)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neg.twoindmeans(
  v1 = NULL,
  v2 = NULL,
  dv = NULL,
  iv = NULL,
  eiL,
  eiU,
  varequiv = FALSE,
  normality = FALSE,
  tr = 0.2,
  nboot = 500,
  alpha = 0.05,
  plot = TRUE,
  saveplot = FALSE,
  data = NULL
)

## S3 method for class 'neg.twoindmeans'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neg.twoindmeans_+3A_v1">v1</code></td>
<td>
<p>Data for Group 1 (if dv and iv are omitted)</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_v2">v2</code></td>
<td>
<p>Data for Group 2 (if dv and iv are omitted)</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_dv">dv</code></td>
<td>
<p>Dependent Variable (if v1 and v2 are omitted)</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_iv">iv</code></td>
<td>
<p>Dichotomous Predictor/Independent Variable (if v1 and v2 are omitted)</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_eil">eiL</code></td>
<td>
<p>Lower Bound of the Equivalence Interval</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_eiu">eiU</code></td>
<td>
<p>Upper Bound of the Equivalence Interval</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_varequiv">varequiv</code></td>
<td>
<p>Are the population variances assumed to be equal? Population variances are assumed to be unequal if normality=FALSE.</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_normality">normality</code></td>
<td>
<p>Are the population variances (and hence the residuals) assumed to be normally distributed?</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_tr">tr</code></td>
<td>
<p>Proportion of trimming from each tail (relevant if normality = FALSE)</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_nboot">nboot</code></td>
<td>
<p>Number of bootstrap samples for calculating CIs</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_alpha">alpha</code></td>
<td>
<p>Nominal Type I Error rate</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_plot">plot</code></td>
<td>
<p>Should a plot of the results be produced?</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_saveplot">saveplot</code></td>
<td>
<p>Should the plot be saved?</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_data">data</code></td>
<td>
<p>Dataset containing v1/v2 or iv/dv</p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_x">x</code></td>
<td>
<p>object of class <code>neg.twoindmeans</code></p>
</td></tr>
<tr><td><code id="neg.twoindmeans_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function evaluates whether the difference in the means of 2 independent populations can be considered negligible (i.e., the population means can be considered equivalent).
</p>
<p>The user specifies either the data associated with the first and second groups/populations (iv1, iv2, both should be continuous) or specifies the Indepedent Variable/Predictor (iv, should be a factor) and the Dependent Variable (outcome, should be continuous). A 'data' statement can be used if the variables are stored in an R dataset.
</p>
<p>The user must also specify the lower and upper bounds of the negligible effect (equivalence) interval. These are specified in the original units of the outcome variable.
</p>
<p>The arguments 'varequiv' and 'normality' control what test statistic is adopted. If varequiv = TRUE and normality = TRUE the ordinary Student t statistic is adopted. If varequiv = FALSE and normality = TRUE the Welch t statistic is adopted. If normality = FALSE  the ordinary Student t statistic is adopted.  d
</p>


<h3>Value</h3>

<p>A <code>list</code> including the following:
</p>

<ul>
<li> <p><code>meanx</code> Sample mean of the first population/group.
</p>
</li>
<li> <p><code>meany</code> Sample mean of the second population/group.
</p>
</li>
<li> <p><code>trmeanx</code> Sample trimmed mean of the first population/group.
</p>
</li>
<li> <p><code>trmeany</code> Sample trimmed mean of the second population/group.
</p>
</li>
<li> <p><code>sdx</code> Sample standard deviation of the first population/group.
</p>
</li>
<li> <p><code>sdy</code> Sample standard deviation of the second population/group.
</p>
</li>
<li> <p><code>madx</code> Sample median absolute deviation of the first population/group.
</p>
</li>
<li> <p><code>mady</code> Sample median absolute deviation of the second population/group.
</p>
</li>
<li> <p><code>eiL</code> Lower bound of the negligible effect (equivalence) interval.
</p>
</li>
<li> <p><code>eiU</code> Upper bound of the negligible effect (equivalence) interval.
</p>
</li>
<li> <p><code>effsizeraw</code> Simple difference in the means (or trimmed means if normality = FALSE)
</p>
</li>
<li> <p><code>cilraw2</code> Lower bound of the 1-alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>ciuraw2</code> Upper bound of the 1-alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>cilraw</code> Lower bound of the 1-2*alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>ciuraw</code> Upper bound of the 1-2*alpha CI for the raw mean difference.
</p>
</li>
<li> <p><code>effsized</code> Standardized mean (or trimmed mean if normality = FALSE) difference.
</p>
</li>
<li> <p><code>cild</code> Lower bound of the 1-alpha CI for the standardized mean (or trimmed mean if normality = FALSE) difference.
</p>
</li>
<li> <p><code>ciud</code> Upper bound of the 1-alpha CI for the standardized mean (or trimmed mean if normality = FALSE) difference.
</p>
</li>
<li> <p><code>effsizepd</code> Proportional distance statistic.
</p>
</li>
<li> <p><code>cilpd</code> Lower bound of the 1-alpha CI for the proportional distance statistic.
</p>
</li>
<li> <p><code>ciupd</code> Upper bound of the 1-alpha CI for the proportional distance statistic.
</p>
</li>
<li> <p><code>t1</code> First t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>t1</code> Second t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>df1</code> Degrees of freedom for the first t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>df2</code> Degrees of freedom for the second t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>p1</code> p value associated with the first t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>p2</code> p value associated with the second t-statistic from the TOST procedure.
</p>
</li>
<li> <p><code>alpha</code> Nominal Type I error rate
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rob Cribbie <a href="mailto:cribbie@yorku.ca">cribbie@yorku.ca</a>
R. Philip Chalmers <a href="mailto:chalmrp@yorku.ca">chalmrp@yorku.ca</a>
Naomi Martinez Gutierrez <a href="mailto:naomimg@yorku.ca">naomimg@yorku.ca</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>indvar&lt;-rep(c("a","b"),c(10,12))
depvar&lt;-rnorm(22)
d&lt;-data.frame(indvar,depvar)
neg.twoindmeans(dv=depvar,iv=indvar,eiL=-1,eiU=1,plot=TRUE,data=d)
neg.twoindmeans(dv=depvar,iv=indvar,eiL=-1,eiU=1)
neg.twoindmeans(v1=depvar[indvar=="a"],v2=depvar[indvar=="b"],eiL=-1,eiU=1)
xx&lt;-neg.twoindmeans(dv=depvar,iv=indvar,eiL=-1,eiU=1)
xx$decis
</code></pre>

<hr>
<h2 id='perfectionism'>Perfectionism Data</h2><span id='topic+perfectionism'></span>

<h3>Description</h3>

<p>This dataset comes from the dissertation of Chantal Arpin-Cribbie.
The study was an RCT looking at the effect of an online CBT therapy on
perfectionism (and related variables) in a sample of undergraduate
students with extreme perfectionism. This dataset has missing data
imputed with a single stochastic regression imputation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(perfectionism)
</code></pre>


<h3>Format</h3>

<p>A data frame with 83 rows and 17 variables:
</p>

<dl>
<dt>group</dt><dd><p>whether the participants received the CBT therapy, a general stress reduction protocol, or no treatment</p>
</dd>
<dt>mpshfpre.sop</dt><dd><p>Pretest Score, Self-oriented Perfectionism, Hewitt &amp; Flett Multidimensional Perfectionism Scale</p>
</dd>
<dt>mpshfpre.spp</dt><dd><p>Pretest Score, Socially-prescribed Perfectionism, Hewitt &amp; Flett Multidimensional Perfectionism Scale</p>
</dd>
<dt>pcipre.total</dt><dd><p>Pretest Score, Perfection Cognitions Inventory</p>
</dd>
<dt>baipre.total</dt><dd><p>Pretest Score, Beck Anxiety Inventory</p>
</dd>
<dt>cesdpre.total</dt><dd><p>Pretest Score, CESD Depression Scale</p>
</dd>
<dt>mpsfpre.cm</dt><dd><p>Pretest Score, Concern Over Mistakes subscale, Frost Multidimensional Perfectionism Scale</p>
</dd>
<dt>mpshfpost.sop</dt><dd><p>Posttest Score, Self-oriented Perfectionism, Hewitt &amp; Flett Multidimensional Perfectionism Scale</p>
</dd>
<dt>mpshfpost.spp</dt><dd><p>Posttest Score, Self-prescribed Perfectionism, Hewitt &amp; Flett Multidimensional Perfectionism Scale</p>
</dd>
<dt>pcipost.total</dt><dd><p>Posttest Score, Perfection Cognitions Inventory</p>
</dd>
<dt>baipost.total</dt><dd><p>Posttest Score, Beck Anxiety Inventory</p>
</dd>
<dt>cesdpost.total</dt><dd><p>Posttest Score, CESD Depression Scale</p>
</dd>
<dt>mpsfpost.cm</dt><dd><p>Posttest Score, Concern Over Mistakes subscale, Frost Multidimensional Perfectionism Scale</p>
</dd>
<dt>atqpre.total</dt><dd><p>Pretest Score, Automatic Thoughts Quesionnaire</p>
</dd>
<dt>atqpost.total</dt><dd><p>Posttest Score, Automatic Thoughts Questionnaire</p>
</dd>
<dt>mpshfpre.oop</dt><dd><p>Pretest score, Other Oriented Perfectionism, Hewitt &amp; Flett Multidimensional Perfectionism Scale</p>
</dd>
<dt>mpshfpost.oop</dt><dd><p>Posttest Score, Other Oriented Perfectionism, Hewitt &amp; Flett Multidimensional Perfectionism Scale</p>
</dd>
</dl>
<p>...

</p>


<h3>Source</h3>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/22122217/">https://pubmed.ncbi.nlm.nih.gov/22122217/</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
