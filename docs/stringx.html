<!DOCTYPE html><html lang="en"><head><title>Help for package stringx</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {stringx}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#about_stringx'><p>Drop-in Replacements for Base String Functions Powered by Stringi</p></a></li>
<li><a href='#digits_dec'><p>Character Constants</p></a></li>
<li><a href='#grepl2'><p>Detect Pattern Occurrences</p></a></li>
<li><a href='#ISOdatetime'><p>Construct Date-time Objects</p></a></li>
<li><a href='#nchar'><p>Get Length or Width of Strings</p></a></li>
<li><a href='#paste'><p>Concatenate Strings</p></a></li>
<li><a href='#regexpr2'><p>Locate Pattern Occurrences</p></a></li>
<li><a href='#regextr2'><p>Extract Pattern Occurrences</p></a></li>
<li><a href='#sprintf'><p>Format Strings</p></a></li>
<li><a href='#startsWith'><p>Detect Pattern Occurrences at Start or End of Strings</p></a></li>
<li><a href='#strcoll'><p>Compare Strings</p></a></li>
<li><a href='#strptime'><p>Parse and Format Date-time Objects</p></a></li>
<li><a href='#strrep'><p>Duplicate Strings</p></a></li>
<li><a href='#strsplit'><p>Split Strings into Tokens</p></a></li>
<li><a href='#strtrans'><p>Transliteration and Other Text Transforms</p></a></li>
<li><a href='#strtrim'><p>Shorten Strings to Specified Width</p></a></li>
<li><a href='#strwrap'><p>Word-Wrap Text</p></a></li>
<li><a href='#sub2'><p>Replace Pattern Occurrences</p></a></li>
<li><a href='#substr'><p>Extract or Replace Substrings</p></a></li>
<li><a href='#trimws'><p>Trim Leading or Trailing Whitespaces</p></a></li>
<li><a href='#xtfrm2'><p>Sort Strings</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Replacements for Base String Functions Powered by 'stringi'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.9</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-01-11</td>
</tr>
<tr>
<td>Description:</td>
<td>English is the native language for only 5% of the World population.
    Also, only 17% of us can understand this text. Moreover, the Latin alphabet
    is the main one for merely 36% of the total.
    The early computer era, now a very long time ago, was dominated by the US.
    Due to the proliferation of the internet, smartphones, social media, and
    other technologies and communication platforms, this is no longer the case.
    This package replaces base R string functions (such as grep(),
    tolower(), sprintf(), and strptime()) with ones that fully
    support the Unicode standards related to natural language and
    date-time processing. It also fixes some long-standing inconsistencies,
    and introduces some new, useful features.
    Thanks to 'ICU' (International Components for Unicode) and 'stringi',
    they are fast, reliable, and portable across different platforms.</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/gagolews/stringx/issues">https://github.com/gagolews/stringx/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>,
<a href="https://github.com/gagolews/stringx">https://github.com/gagolews/stringx</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stringi (&ge; 1.7.2)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>realtest (&ge; 0.2.1)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-11 16:25:27 UTC; gagolews</td>
</tr>
<tr>
<td>Author:</td>
<td>Marek Gagolewski <a href="https://orcid.org/0000-0003-0637-6028"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marek Gagolewski &lt;marek@gagolewski.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-11 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='about_stringx'>Drop-in Replacements for Base String Functions Powered by Stringi</h2><span id='topic+about_stringx'></span><span id='topic+stringx'></span>

<h3>Description</h3>

<p><span class="pkg">stringx</span> reimplements the built-in R string processing functions
based on <span class="pkg">stringi</span> &ndash; a mature R package for fast, correct, consistent,
and convenient text manipulation. Thanks to the <span class="pkg">ICU</span> library, we obtain
predictable results on every platform, in each locale, and under any
native character encoding.
</p>
<p><b>Keywords</b>: R, text processing, character strings,
internationalisation, localisation, ICU, ICU4C, i18n, l10n, Unicode
</p>
<p><b>License</b>: GNU General Public License version 2 or later
</p>


<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>References</h3>

<p><em><span class="pkg">stringi</span> Package homepage</em>,
<a href="https://stringi.gagolewski.com/">https://stringi.gagolewski.com/</a>
</p>
<p><em>ICU &ndash; International Components for Unicode</em>,
<a href="https://icu.unicode.org/">https://icu.unicode.org/</a>
</p>
<p><em>The Unicode Consortium</em>,
<a href="https://home.unicode.org/">https://home.unicode.org/</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>

<hr>
<h2 id='digits_dec'>Character Constants</h2><span id='topic+digits_dec'></span><span id='topic+digits_hex'></span><span id='topic+letters_greek'></span><span id='topic+LETTERS_GREEK'></span><span id='topic+letters_bb'></span><span id='topic+LETTERS_BB'></span><span id='topic+letters_cal'></span><span id='topic+LETTERS_CAL'></span><span id='topic+letters_frak'></span><span id='topic+LETTERS_FRAK'></span><span id='topic+letters_bf'></span><span id='topic+LETTERS_BF'></span>

<h3>Description</h3>

<p>Letters and digits sets complementing the built-in
<code>LETTERS</code> and <code>letters</code>, see <a href="base.html#topic+Constants">Constants</a>.
</p>
<p>Note: calling, e.g., <code><a href="#topic+tolower">tolower</a></code> on <code>LETTERS_FRAK</code>
in the current version of <span class="pkg">ICU</span> does not currently yield
<code>letters_frak</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>digits_dec

digits_hex

letters_greek

LETTERS_GREEK

letters_bb

LETTERS_BB

letters_cal

LETTERS_CAL

letters_frak

LETTERS_FRAK

letters_bf

LETTERS_BF
</code></pre>


<h3>Format</h3>

<p>Decimal digits
</p>
<p>Hexadecimal digits
</p>
<p>Greek letters (lower case)
</p>
<p>Greek letters (upper case)
</p>
<p>Blackboard bold English letters (lower case)
</p>
<p>Blackboard bold English letters (upper case)
</p>
<p>Calligraphy (script) English letters (lower case)
</p>
<p>Calligraphy (script) English letters (upper case)
</p>
<p>Fraktur English letters (lower case)
</p>
<p>Fraktur English letters (upper case)
</p>
<p>Bold English letters (lower case)
</p>
<p>Bold English letters (upper case)
</p>


<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>letters_bb
letters_bf
letters_cal
letters_frak
letters_greek
LETTERS_BB
LETTERS_BF
LETTERS_CAL
LETTERS_FRAK
LETTERS_GREEK
digits_dec
digits_hex

</code></pre>

<hr>
<h2 id='grepl2'>Detect Pattern Occurrences</h2><span id='topic+grepl2'></span><span id='topic+grepv2'></span><span id='topic+grepv2+3C-'></span><span id='topic+grepl'></span><span id='topic+grep'></span>

<h3>Description</h3>

<p><code>grepl2</code> indicates whether a string matches the corresponding pattern
or not.
</p>
<p><code>grepv2</code> returns a subset of <code>x</code> matching the corresponding
patterns. Its replacement version allows for substituting such a subset with
new content.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grepl2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE, invert = FALSE)

grepv2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE, invert = FALSE)

grepv2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE, invert = FALSE) &lt;- value

grepl(
  pattern,
  x,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  invert = FALSE,
  perl = FALSE,
  useBytes = FALSE
)

grep(
  pattern,
  x,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  value = FALSE,
  invert = FALSE,
  perl = FALSE,
  useBytes = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grepl2_+3A_x">x</code></td>
<td>
<p>character vector whose elements are to be examined</p>
</td></tr>
<tr><td><code id="grepl2_+3A_pattern">pattern</code></td>
<td>
<p>character vector of nonempty search patterns;
for <code>grepv2</code> and <code>grep</code>, must not be longer than <code>x</code></p>
</td></tr>
<tr><td><code id="grepl2_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stringi.html#topic+stri_detect">stri_detect</a></code>,
e.g., <code>max_count</code>, <code>locale</code>, <code>dotall</code></p>
</td></tr>
<tr><td><code id="grepl2_+3A_ignore_case">ignore_case</code>, <code id="grepl2_+3A_ignore.case">ignore.case</code></td>
<td>
<p>single logical value; indicates whether matching
should be case-insensitive</p>
</td></tr>
<tr><td><code id="grepl2_+3A_fixed">fixed</code></td>
<td>
<p>single logical value;
<code>FALSE</code> for matching with regular expressions
(see <a href="stringi.html#topic+about_search_regex">about_search_regex</a>);
<code>TRUE</code> for fixed pattern matching
(<a href="stringi.html#topic+about_search_fixed">about_search_fixed</a>);
<code>NA</code> for the Unicode collation algorithm
(<a href="stringi.html#topic+about_search_coll">about_search_coll</a>)</p>
</td></tr>
<tr><td><code id="grepl2_+3A_invert">invert</code></td>
<td>
<p>single logical value; indicates whether a no-match
is rather of interest</p>
</td></tr>
<tr><td><code id="grepl2_+3A_value">value</code></td>
<td>
<p>character vector of replacement strings
or a single logical value
indicating whether indexes of strings in <code>x</code> matching
patterns should be returned</p>
</td></tr>
<tr><td><code id="grepl2_+3A_perl">perl</code>, <code id="grepl2_+3A_usebytes">useBytes</code></td>
<td>
<p>not used (with a warning if
attempting to do so) [DEPRECATED]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are fully vectorised with respect to <code>x</code> and
<code>pattern</code>.
</p>
<p>The [DEPRECATED] <code>grepl</code> simply calls
<code>grepl2</code> which have a cleaned-up argument list.
</p>
<p>The [DEPRECATED] <code>grep</code> with <code>value=FALSE</code> is actually redundant &ndash;
it can be trivially reproduced with <code>grepl</code> and
<code><a href="base.html#topic+which">which</a></code>.
</p>
<p><code>grepv2</code> and <code>grep</code> with <code>value=FALSE</code> combine
pattern matching and subsetting and some users may find it convenient
in conjunction with the forward pipe operator, <code><a href="base.html#topic++7C+3E">|&gt;</a></code>.
</p>


<h3>Value</h3>

<p><code>grepl2</code> and [DEPRECATED] <code>grep</code> return a logical vector.
They preserve the attributes of the longest inputs (unless they are
dropped due to coercion). Missing values in the inputs are propagated
consistently.
</p>
<p><code>grepv2</code> and [DEPRECATED] <code>grep</code> with <code>value=TRUE</code> returns
a subset of <code>x</code> with elements matching the corresponding patterns.
[DEPRECATED] <code>grep</code> with <code>value=FALSE</code> returns the indexes
in <code>x</code> where a match occurred.
Missing values are not included in the outputs and only the <code>names</code>
attribute is preserved, because the length of the result may be different
than that of <code>x</code>.
</p>
<p>The replacement version of <code>grepv2</code> modifies <code>x</code> 'in-place'.
</p>


<h3>Differences from Base R</h3>

<p><code>grepl</code> and <code>grep</code> are [DEPRECATED] replacements for base
<code><a href="base.html#topic+grep">grep</a></code> and <code><a href="base.html#topic+grepl">grepl</a></code>
implemented with <code><a href="stringi.html#topic+stri_detect">stri_detect</a></code>.
</p>

<ul>
<li><p> there are inconsistencies between the argument order and naming
in <code><a href="base.html#topic+grepl">grepl</a></code>, <code><a href="base.html#topic+strsplit">strsplit</a></code>,
and <code><a href="base.html#topic+startsWith">startsWith</a></code> (amongst others); e.g.,
where the needle can precede the haystack, the use of the forward
pipe operator, <code><a href="base.html#topic++7C+3E">|&gt;</a></code>, is less convenient
<b>[fixed by introducing <code>grepl2</code>]</b>
</p>
</li>
<li><p> base R implementation is not portable as it is based on
the system PCRE or TRE library
(e.g., some Unicode classes may not be available or matching thereof
can depend on the current <code>LC_CTYPE</code> category
<b>[fixed here]</b>
</p>
</li>
<li><p> not suitable for natural language processing
<b>[fixed here &ndash; use <code>fixed=NA</code>]</b>
</p>
</li>
<li><p> two different regular expression libraries are used
(and historically, ERE was used in place of TRE)
<b>[here, <span class="pkg">ICU</span> Java-like regular expression engine
is only available, hence the <code>perl</code> argument has no meaning]</b>
</p>
</li>
<li><p> not vectorised w.r.t. <code>pattern</code>
<b>[fixed here, however, in <code>grep</code>, <code>pattern</code> cannot be
longer than <code>x</code>]</b>
</p>
</li>
<li><p> missing values in haystack will result in a no-match
<b>[fixed in <code>grepl</code>; see Value]</b>
</p>
</li>
<li> <p><code>ignore.case=TRUE</code> cannot be used with <code>fixed=TRUE</code>
<b>[fixed here]</b>
</p>
</li>
<li><p> no attributes are preserved
<b>[fixed here; see Value]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+paste">paste</a></code>, <code><a href="#topic+nchar">nchar</a></code>,
<code><a href="#topic+strsplit">strsplit</a></code>, <code><a href="#topic+gsub2">gsub2</a></code>,
<code><a href="#topic+gregexpr2">gregexpr2</a></code>, <code><a href="#topic+gregextr2">gregextr2</a></code>,
<code><a href="#topic+gsubstr">gsubstr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("abc", "1237", "\U0001f602", "\U0001f603", "stringx\U0001f970", NA)
grepl2(x, "\\p{L}")
which(grepl2(x, "\\p{L}"))  # like grep

# at least 1 letter or digit:
p &lt;- c("\\p{L}", "\\p{N}")
`dimnames&lt;-`(outer(x, p, grepl2), list(x, p))

x |&gt; grepv2("\\p{L}")
grepv2(x, "\\p{L}", invert=TRUE) &lt;- "\U0001F496"
print(x)

</code></pre>

<hr>
<h2 id='ISOdatetime'>Construct Date-time Objects</h2><span id='topic+ISOdatetime'></span><span id='topic+ISOdate'></span><span id='topic+Sys.time'></span>

<h3>Description</h3>

<p><code>ISOdate</code> and <code>ISOdatetime</code> construct date-time objects
from numeric representations.
<code>Sys.time</code> returns current time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ISOdatetime(
  year,
  month,
  day,
  hour,
  min,
  sec,
  tz = "",
  lenient = FALSE,
  locale = NULL
)

ISOdate(
  year,
  month,
  day,
  hour = 0L,
  min = 0L,
  sec = 0L,
  tz = "",
  lenient = FALSE,
  locale = NULL
)

Sys.time()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ISOdatetime_+3A_year">year</code>, <code id="ISOdatetime_+3A_month">month</code>, <code id="ISOdatetime_+3A_day">day</code>, <code id="ISOdatetime_+3A_hour">hour</code>, <code id="ISOdatetime_+3A_min">min</code>, <code id="ISOdatetime_+3A_sec">sec</code></td>
<td>
<p>numeric vectors</p>
</td></tr>
<tr><td><code id="ISOdatetime_+3A_tz">tz</code></td>
<td>
<p><code>NULL</code> or <code>''</code> for the default time zone
(see <code><a href="stringi.html#topic+stri_timezone_get">stri_timezone_get</a></code>)
or a single string with a timezone identifier,
see <code><a href="stringi.html#topic+stri_timezone_list">stri_timezone_list</a></code></p>
</td></tr>
<tr><td><code id="ISOdatetime_+3A_lenient">lenient</code></td>
<td>
<p>single logical value; should date/time parsing be lenient?</p>
</td></tr>
<tr><td><code id="ISOdatetime_+3A_locale">locale</code></td>
<td>
<p><code>NULL</code> or <code>''</code> for the default locale
(see <code><a href="stringi.html#topic+stri_locale_get">stri_locale_get</a></code>)
or a single string with a locale identifier,
see <code><a href="stringi.html#topic+stri_locale_list">stri_locale_list</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>These functions return an object of class <code>POSIXxt</code>, which
extends upon <code><a href="base.html#topic+POSIXct">POSIXct</a></code>, <code><a href="#topic+strptime">strptime</a></code>.
</p>
<p>You might wish to consider calling <code><a href="base.html#topic+as.Date">as.Date</a></code> on
the result yielded by <code>ISOdate</code>.
</p>
<p>No attributes are preserved (because they are too many).
</p>


<h3>Differences from Base R</h3>

<p>Replacements for base <code><a href="base.html#topic+ISOdatetime">ISOdatetime</a></code>
and <code><a href="base.html#topic+ISOdate">ISOdate</a></code> implemented with
<code><a href="stringi.html#topic+stri_datetime_create">stri_datetime_create</a></code>.
</p>

<ul>
<li> <p><code>ISOdate</code> does not treat dates as being at midnight
by default <b>[fixed here]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+strptime">strptime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ISOdate(1970, 1, 1)
ISOdatetime(1970, 1, 1, 12, 0, 0)

</code></pre>

<hr>
<h2 id='nchar'>Get Length or Width of Strings</h2><span id='topic+nchar'></span><span id='topic+nzchar'></span>

<h3>Description</h3>

<p><code>nchar</code> computes the number of code points, bytes used, or
estimated total width of strings in a character vector.
<code>nzchar</code> indicates which strings are empty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nchar(x, type = "chars", allowNA = FALSE, keepNA = TRUE)

nzchar(x, keepNA = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nchar_+3A_x">x</code></td>
<td>
<p>character vector or an object coercible to</p>
</td></tr>
<tr><td><code id="nchar_+3A_type">type</code></td>
<td>
<p><code>"chars"</code> gives the number of code points,
<code>"width"</code> estimates the string width,
<code>"bytes"</code> computes the number of bytes</p>
</td></tr>
<tr><td><code id="nchar_+3A_allowna">allowNA</code></td>
<td>
<p>not used (with a warning if attempting to do so) [DEPRECATED]</p>
</td></tr>
<tr><td><code id="nchar_+3A_keepna">keepNA</code></td>
<td>
<p>if <code>FALSE</code>, missing values will
be treated as <code>"NA"</code> strings; otherwise, the corresponding outputs
will be missing as well [DEPRECATED]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>String width might be useful when displaying text using a monospaced font.
</p>


<h3>Value</h3>

<p><code>nchar</code> returns an integer vector.
</p>
<p><code>nzchar</code> returns a logical vector, where <code>TRUE</code> indicates
that the corresponding string is of non-zero length (i.e., non-empty).
</p>


<h3>Differences from Base R</h3>

<p>Replacement for base <code><a href="base.html#topic+nchar">nchar</a></code> and <code><a href="base.html#topic+nzchar">nzchar</a></code>
implemented with <code><a href="stringi.html#topic+stri_length">stri_length</a></code>,
<code><a href="stringi.html#topic+stri_width">stri_width</a></code>,
<code><a href="stringi.html#topic+stri_numbytes">stri_numbytes</a></code>,
and <code><a href="stringi.html#topic+stri_isempty">stri_isempty</a></code>.
</p>

<ul>
<li> <p><code>keepNA</code> does not default to <code>TRUE</code>, and hence
missing values are treated as <code>"NA"</code> strings
<b>[fixed here]</b>
</p>
</li>
<li><p> some emojis, combining characters and modifiers (e.g., skin tones)
are not recognised properly
<b>[fixed here]</b>
</p>
</li>
<li><p> only the <code>names</code> attribute is propagated
<b>[fixed here]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+sprintf">sprintf</a></code>, <code><a href="#topic+substr">substr</a></code>,
<code><a href="#topic+strtrim">strtrim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
    "\U0001F4A9",
    "\U0001F64D\U0001F3FC\U0000200D\U00002642\U0000FE0F",
    "\U0001F64D\U0001F3FB\U0000200D\U00002642",
    "\U000026F9\U0001F3FF\U0000200D\U00002640\U0000FE0F",
    "\U0001F3F4\U000E0067\U000E0062\U000E0073\U000E0063\U000E0074\U000E007F"
)
print(x)
base::nchar(x, "width")
stringx::nchar(x, "width")


</code></pre>

<hr>
<h2 id='paste'>Concatenate Strings</h2><span id='topic+paste'></span><span id='topic+paste0'></span><span id='topic++25x+2B+25'></span><span id='topic+strcat'></span>

<h3>Description</h3>

<p>Concatenate (join) the corresponding and/or consecutive elements of
given vectors, after converting them to strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paste(..., sep = " ", collapse = NULL, recycle0 = FALSE)

paste0(..., sep = "", collapse = NULL, recycle0 = FALSE)

e1 %x+% e2

strcat(x, collapse = "", na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="paste_+3A_...">...</code></td>
<td>
<p>character vectors (or objects coercible to)
whose corresponding/consecutive elements are to be concatenated</p>
</td></tr>
<tr><td><code id="paste_+3A_sep">sep</code></td>
<td>
<p>single string; separates terms</p>
</td></tr>
<tr><td><code id="paste_+3A_collapse">collapse</code></td>
<td>
<p>single string or <code>NULL</code>; an optional
separator if tokens are to be merged into a single string</p>
</td></tr>
<tr><td><code id="paste_+3A_recycle0">recycle0</code></td>
<td>
<p>single logical value; if <code>FALSE</code>, then empty
vectors provided via <code>...</code> are silently ignored</p>
</td></tr>
<tr><td><code id="paste_+3A_e1">e1</code>, <code id="paste_+3A_e2">e2</code></td>
<td>
<p>character vectors (or objects coercible to)
whose corresponding elements are to be concatenated</p>
</td></tr>
<tr><td><code id="paste_+3A_x">x</code></td>
<td>
<p>character vector (or an object coercible to)
whose consecutive elements are to be concatenated</p>
</td></tr>
<tr><td><code id="paste_+3A_na.rm">na.rm</code></td>
<td>
<p>single logical value; if <code>TRUE</code>, missing values
are silently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>`%x+%`</code> is an operator that concatenates corresponding
strings from two character vectors (and which behaves just like
the arithmetic <code>`+`</code> operator).
</p>
<p><code>strcat</code> joins (aggregates based on string concatenation)
consecutive strings in a character vector, possibly with
a specified separator in place, into a single string.
</p>
<p><code>paste</code> and <code>paste0</code>, concatenate a number
of vectors using the same separator and then possibly join them into
a single string. We recommend using
<code>`%x+%`</code>, <code><a href="#topic+sprintf">sprintf</a></code>, and <code>strcat</code> instead
(see below for discussion).
</p>


<h3>Value</h3>

<p>A character vector (in UTF-8).
</p>
<p><code>`%x+%`</code> preserves object attributes in a similar way as
other <a href="base.html#topic+Arithmetic">Arithmetic</a> operators (however, they may be lost
during <code>as.character(...)</code> conversion, which is an S3 generic).
</p>
<p><code>strcat</code> is an aggregation function, therefore it
preserves no attributes whatsoever.
</p>
<p>Currently, <code>paste</code> and <code>paste0</code> preserve no attributes too.
</p>


<h3>Differences from Base R</h3>

<p>Replacement for base <code><a href="base.html#topic+paste">paste</a></code>
implemented with <code><a href="stringi.html#topic+stri_join">stri_join</a></code>.
</p>
<p>Note that <code>paste</code> can be thought of as a string counterpart
of both the <code>`+`</code> operator (actually, some languages do have a binary
operator for string concatenation, e.g., <code>`.`</code> in Perl and PHP,
<code>`+`</code> (<code>str.__add__</code>) in Python; R should have it too,
but does not) which is additionally vectorised ('Map') and the
<code><a href="base.html#topic+sum">sum</a></code> function ('Reduce').
Therefore, we would expect it to behave similarly with regards
to the propagation of missing values and the preservation of object
attributes, but it does not.
</p>

<ul>
<li><p> missing values treated as <code>"NA"</code> strings (it is a well-documented
feature though) <b>[fixed here]</b>
</p>
</li>
<li><p> partial recycling with no warning &quot;longer object length is not
a multiple of shorter object length&quot; <b>[fixed here]</b>
</p>
</li>
<li><p> empty vectors are treated as vectors of empty strings
<b>[fixed here]</b>
</p>
</li>
<li><p> input objects' attributes are not preserved
<b>[fixed only in <code>`%x+%`</code> operator]</b>
</p>
</li>
<li> <p><code>paste0</code> multiplies entities without necessity;
<code>sep=""</code> should be the default in <code>paste</code> <b>[not fixed]</b>
</p>
</li>
<li> <p><code>paste0</code> treats the named argument <code>sep="..."</code> as one
more vector to concatenate
<b>[fixed by introducing <code>sep</code> argument]</b>
</p>
</li>
<li><p> overloading <code>`+.character`</code> has no effect in R, because S3
method dispatch is done internally with hard-coded support for
character arguments. We could have replaced the generic <code>`+`</code>
with the one that calls <code><a href="base.html#topic+UseMethod">UseMethod</a></code>, but the
dispatch would be done on the type of the first argument anyway
(not to mention it feels like a too intrusive solution).
Actually having a separate operator for concatenation (similar to
PHP's or Perl's <code>`.`</code>) which always coerces to character
frees the user from manual coercion (is it such a burden on the other
hand?)
<b>[fixed by introducing <code>`%x+%`</code> operator]</b>
</p>
</li></ul>

<p>It should also be noted that <code>paste</code> with <code>collapse=NULL</code> is a
special case of <code>sprintf</code> (which is featured in many programming
languages; R's version is of course vectorised).
For instance, <code>paste(x, y, sep=",")</code>
is equivalent to <code>sprintf("%s,%s", x, y)</code>.
</p>
<p>Taking into account the above, <code>paste</code> and <code>paste0</code> seem
redundant and hence we mark them as [DEPRECATED].
Here are our recommendations:
</p>

<ul>
<li><p> the most frequent use case - concatenating corresponding
strings from two character vectors with no separator - is covered
by a new operator <code>`%x+%`</code> which propagates NAs correctly
and handles object attributes the same way as the built-in arithmetic
operators;
</p>
</li>
<li><p> for fancy elementwise (like 'Map') concatenation,
use our version of <code><a href="#topic+sprintf">sprintf</a></code>;
</p>
</li>
<li><p> for the 'flattening' of consecutive strings in a character vector
(like 'Reduce'), use the new function <code>strcat</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+strrep">strrep</a></code>, <code><a href="#topic+sprintf">sprintf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># behaviour of `+` vs. base::paste vs. stringx::paste
x &lt;- structure(c(x=1, y=NA, z=100, w=1000), F="*")
y1 &lt;- structure(c(a=1, b=2, c=3), G="#", F="@")
y2 &lt;- structure(c(a=1, b=2, c=3, d=4), G="#", F="@")
y3 &lt;- structure(1:4, G="#", F="@", dim=c(2, 2), dimnames=list(NULL, c("a", "b")))
x + y1
x + y2
x + y3
y2 + x
base::paste(x, y1)
base::paste(x, y2)
base::paste(x, y3)
stringx::paste(x, y1)
stringx::paste(x, y2)
stringx::paste(x, y3)
base::paste(x, character(0), y2, sep=",")
stringx::paste(x, character(0), y2, sep=",")
x %x+% y1
x %x+% y2
x %x+% y3
y2 %x+% x
x %x+% character(0)
strcat(x, collapse=",")
strcat(x, collapse=",", na.rm=TRUE)


</code></pre>

<hr>
<h2 id='regexpr2'>Locate Pattern Occurrences</h2><span id='topic+regexpr2'></span><span id='topic+gregexpr2'></span><span id='topic+regexec2'></span><span id='topic+gregexec2'></span><span id='topic+regexpr'></span><span id='topic+gregexpr'></span><span id='topic+regexec'></span><span id='topic+gregexec'></span>

<h3>Description</h3>

<p><code>regexpr2</code> and <code>gregexpr2</code> locate, respectively, first and all
(i.e., <b>g</b>lobally) occurrences of a pattern.
<code>regexec2</code> and <code>gregexec2</code> can additionally
pinpoint the matches to parenthesised subexpressions (regex capture groups).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regexpr2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE)

gregexpr2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE)

regexec2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE)

gregexec2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE)

regexpr(
  pattern,
  x = text,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  perl = FALSE,
  useBytes = FALSE,
  text
)

gregexpr(
  pattern,
  x = text,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  perl = FALSE,
  useBytes = FALSE,
  text
)

regexec(
  pattern,
  x = text,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  perl = FALSE,
  useBytes = FALSE,
  text
)

gregexec(
  pattern,
  x = text,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  perl = FALSE,
  useBytes = FALSE,
  text
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="regexpr2_+3A_x">x</code></td>
<td>
<p>character vector whose elements are to be examined</p>
</td></tr>
<tr><td><code id="regexpr2_+3A_pattern">pattern</code></td>
<td>
<p>character vector of nonempty search patterns</p>
</td></tr>
<tr><td><code id="regexpr2_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stringi.html#topic+stri_locate">stri_locate</a></code>,
e.g., <code>omit_empty</code>, <code>locale</code>, <code>dotall</code></p>
</td></tr>
<tr><td><code id="regexpr2_+3A_ignore_case">ignore_case</code>, <code id="regexpr2_+3A_ignore.case">ignore.case</code></td>
<td>
<p>single logical value; indicates whether matching
should be case-insensitive</p>
</td></tr>
<tr><td><code id="regexpr2_+3A_fixed">fixed</code></td>
<td>
<p>single logical value;
<code>FALSE</code> for matching with regular expressions
(see <a href="stringi.html#topic+about_search_regex">about_search_regex</a>);
<code>TRUE</code> for fixed pattern matching
(<a href="stringi.html#topic+about_search_fixed">about_search_fixed</a>);
<code>NA</code> for the Unicode collation algorithm
(<a href="stringi.html#topic+about_search_coll">about_search_coll</a>)</p>
</td></tr>
<tr><td><code id="regexpr2_+3A_perl">perl</code>, <code id="regexpr2_+3A_usebytes">useBytes</code></td>
<td>
<p>not used (with a warning if
attempting to do so) [DEPRECATED]</p>
</td></tr>
<tr><td><code id="regexpr2_+3A_text">text</code></td>
<td>
<p>alias to the <code>x</code> argument [DEPRECATED]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are fully vectorised with respect to both <code>x</code> and
<code>pattern</code>.
</p>
<p>Use <code><a href="#topic+substrl">substrl</a></code> and <code><a href="#topic+gsubstrl">gsubstrl</a></code>
to extract or replace the identified chunks.
Also, consider using <code><a href="#topic+regextr2">regextr2</a></code> and
<code><a href="#topic+gregextr2">gregextr2</a></code> directly instead.
</p>


<h3>Value</h3>

<p><code>regexpr2</code> and [DEPRECATED] <code>regexpr</code> return an integer vector
which gives the start positions of the first substrings matching a pattern.
The <code>match.length</code> attribute gives the corresponding
match lengths. If there is no match, the two values are set to -1.
</p>
<p><code>gregexpr2</code> and [DEPRECATED] <code>gregexpr</code> yield
a list whose elements are integer vectors with <code>match.length</code>
attributes, giving the positions of all the matches.
For consistency with <code>regexpr2</code>, a no-match is denoted with
a single -1, hence the output is guaranteed to consist of non-empty integer
vectors.
</p>
<p><code>regexec2</code> and [DEPRECATED] <code>regexec</code> return
a list of integer vectors giving the positions of the first matches
and the locations of matches to the consecutive parenthesised subexpressions
(which can only be recognised if <code>fixed=FALSE</code>).
Each vector is equipped with the <code>match.length</code> attribute.
</p>
<p><code>gregexec2</code> and [DEPRECATED] <code>gregexec</code> generate
a list of matrices, where each column corresponds to a separate match;
the first row is the start index of the match, the second row gives the
position of the first captured group, and so forth.
Their <code>match.length</code> attributes are matrices of corresponding sizes.
</p>
<p>These functions preserve the attributes of the longest inputs (unless they
are dropped due to coercion). Missing values in the inputs are propagated
consistently.
</p>


<h3>Differences from Base R</h3>

<p>Replacements for base <code><a href="base.html#topic+gregexpr">gregexpr</a></code> (and others)
implemented with <code><a href="stringi.html#topic+stri_locate">stri_locate</a></code>.
</p>

<ul>
<li><p> there are inconsistencies between the argument order and naming
in <code><a href="base.html#topic+grepl">grepl</a></code>, <code><a href="base.html#topic+strsplit">strsplit</a></code>,
and <code><a href="base.html#topic+startsWith">startsWith</a></code> (amongst others); e.g.,
where the needle can precede the haystack, the use of the forward
pipe operator, <code><a href="base.html#topic++7C+3E">|&gt;</a></code>, is less convenient
<b>[fixed here]</b>
</p>
</li>
<li><p> base R implementation is not portable as it is based on
the system PCRE or TRE library
(e.g., some Unicode classes may not be available or matching thereof
can depend on the current <code>LC_CTYPE</code> category
<b>[fixed here]</b>
</p>
</li>
<li><p> not suitable for natural language processing
<b>[fixed here &ndash; use <code>fixed=NA</code>]</b>
</p>
</li>
<li><p> two different regular expression libraries are used
(and historically, ERE was used in place of TRE)
<b>[here, <span class="pkg">ICU</span> Java-like regular expression engine
is only available, hence the <code>perl</code> argument has no meaning]</b>
</p>
</li>
<li><p> not vectorised w.r.t. <code>pattern</code>
<b>[fixed here]</b>
</p>
</li>
<li> <p><code>ignore.case=TRUE</code> cannot be used with <code>fixed=TRUE</code>
<b>[fixed here]</b>
</p>
</li>
<li><p> no attributes are preserved
<b>[fixed here; see Value]</b>
</p>
</li>
<li><p> in <code>regexec</code>, <code>match.length</code> attribute is unnamed
even if the capture groups are (but <code>gregexec</code> sets dimnames
of both start positions and lengths)
<b>[fixed here]</b>
</p>
</li>
<li> <p><code>regexec</code> and <code>gregexec</code> with <code>fixed</code> other than
<code>FALSE</code> make little sense.
<b>[this argument is [DEPRECATED] in <code>regexec2</code>
and <code>gregexec2</code>]</b>
</p>
</li>
<li> <p><code>gregexec</code> does not always yield a list of matrices
<b>[fixed here]</b>
</p>
</li>
<li><p> a no-match to a conditional capture group is assigned length 0
<b>[fixed here]</b>
</p>
</li>
<li><p> no-matches result in a single -1, even if capture groups are
defined in the pattern
<b>[fixed here]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+paste">paste</a></code>, <code><a href="#topic+nchar">nchar</a></code>,
<code><a href="#topic+strsplit">strsplit</a></code>, <code><a href="#topic+gsub2">gsub2</a></code>,
<code><a href="#topic+grepl2">grepl2</a></code>, <code><a href="#topic+gregextr2">gregextr2</a></code>, <code><a href="#topic+gsubstrl">gsubstrl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(aca1="acacaca", aca2="gaca", noaca="actgggca", na=NA)
regexpr2(x, "(A)[ACTG]\\1", ignore_case=TRUE)
regexpr2(x, "aca") &gt;= 0  # like grepl2
gregexpr2(x, "aca", fixed=TRUE, overlap=TRUE)

# two named capture groups:
regexec2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)")
gregexec2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)")

# extraction:
gsubstrl(x, gregexpr2(x, "(A)[ACTG]\\1", ignore_case=TRUE))
gregextr2(x, "(A)[ACTG]\\1", ignore_case=TRUE)  # equivalent

</code></pre>

<hr>
<h2 id='regextr2'>Extract Pattern Occurrences</h2><span id='topic+regextr2'></span><span id='topic+gregextr2'></span><span id='topic+regextr2+3C-'></span><span id='topic+gregextr2+3C-'></span>

<h3>Description</h3>

<p><code>regextr2</code> and <code>gregextr2</code> extract, respectively, first and all
(i.e., <b>g</b>lobally) occurrences of a pattern.
Their replacement versions substitute the matching substrings with
new content.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regextr2(
  x,
  pattern,
  ...,
  ignore_case = FALSE,
  fixed = FALSE,
  capture_groups = FALSE
)

gregextr2(
  x,
  pattern,
  ...,
  ignore_case = FALSE,
  fixed = FALSE,
  capture_groups = FALSE
)

regextr2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE) &lt;- value

gregextr2(x, pattern, ..., ignore_case = FALSE, fixed = FALSE) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="regextr2_+3A_x">x</code></td>
<td>
<p>character vector whose elements are to be examined</p>
</td></tr>
<tr><td><code id="regextr2_+3A_pattern">pattern</code></td>
<td>
<p>character vector of nonempty search patterns</p>
</td></tr>
<tr><td><code id="regextr2_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stringi.html#topic+stri_locate">stri_locate</a></code>,
e.g., <code>omit_empty</code>, <code>locale</code>, <code>dotall</code></p>
</td></tr>
<tr><td><code id="regextr2_+3A_ignore_case">ignore_case</code></td>
<td>
<p>single logical value; indicates whether matching
should be case-insensitive</p>
</td></tr>
<tr><td><code id="regextr2_+3A_fixed">fixed</code></td>
<td>
<p>single logical value;
<code>FALSE</code> for matching with regular expressions
(see <a href="stringi.html#topic+about_search_regex">about_search_regex</a>);
<code>TRUE</code> for fixed pattern matching
(<a href="stringi.html#topic+about_search_fixed">about_search_fixed</a>);
<code>NA</code> for the Unicode collation algorithm
(<a href="stringi.html#topic+about_search_coll">about_search_coll</a>)</p>
</td></tr>
<tr><td><code id="regextr2_+3A_capture_groups">capture_groups</code></td>
<td>
<p>single logical value; whether matches
individual capture groups should be extracted separately</p>
</td></tr>
<tr><td><code id="regextr2_+3A_value">value</code></td>
<td>
<p>character vector  (for <code>regextr</code>)
or list of character vectors  (for <code>gregextr</code>)
defining the replacement strings</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Convenience functions based on <code><a href="#topic+gregexpr2">gregexpr2</a></code>
and <code><a href="#topic+gsubstrl">gsubstrl</a></code> (amongst others).
Provided as pipe operator-friendly alternatives
to [DEPRECATED] <code><a href="base.html#topic+regmatches">regmatches</a></code> and
[DEPRECATED] <code><a href="utils.html#topic+strcapture">strcapture</a></code>.
</p>
<p>They are fully vectorised with respect to <code>x</code>,
<code>pattern</code>, and <code>value</code>.
</p>
<p>Note that, unlike in <code><a href="#topic+gsub2">gsub2</a></code>,
each substituted chunk can be replaced with different content.
However, references to matches to capture groups cannot be made.
</p>


<h3>Value</h3>

<p><code>capture_groups</code> is <code>FALSE</code>,
<code>regextr2</code> returns a character vector and
<code>gregextr2</code> gives a list of character vectors.
</p>
<p>Otherwise, <code>regextr2</code> returns a list of character vectors,
giving the whole match as well as matches to the individual capture groups.
In <code>gregextr2</code>, this will be a matrix with as many columns
as there are matches.
</p>
<p>Missing values in the inputs are propagated consistently.
In <code>regextr2</code>, a no-match is always denoted with <code>NA</code>
(or series thereof). In <code>gregextr2</code>, the corresponding result is
empty (unless we mean a no-match to an optional capture group within
a matching substring). Note that this function distinguishes
between a missing input and a no-match.
</p>
<p>Their replacement versions return a character vector.
</p>
<p>These functions preserve the attributes of the longest inputs (unless they
are dropped due to coercion).
</p>


<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+paste">paste</a></code>, <code><a href="#topic+nchar">nchar</a></code>,
<code><a href="#topic+strsplit">strsplit</a></code>, <code><a href="#topic+gsub2">gsub2</a></code>
<code><a href="#topic+grepl2">grepl2</a></code>, <code><a href="#topic+gregexpr2">gregexpr2</a></code>, <code><a href="#topic+gsubstrl">gsubstrl</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(aca1="acacaca", aca2="gaca", noaca="actgggca", na=NA)
regextr2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)")
gregextr2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)")
regextr2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)", capture_groups=TRUE)
gregextr2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)", capture_groups=TRUE)

# substitution - note the different replacement strings:
`gregextr2&lt;-`(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)", value=list(c("!", "?"), "#"))
# references to capture groups can only be used in gsub and sub:
gsub2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)", "{$1}{$2}")

regextr2(x, "(?&lt;x&gt;a)(?&lt;y&gt;cac?)") &lt;- "\U0001D554\U0001F4A9"
print(x)  # x was modified 'in-place'


</code></pre>

<hr>
<h2 id='sprintf'>Format Strings</h2><span id='topic+sprintf'></span><span id='topic+printf'></span>

<h3>Description</h3>

<p><code>sprintf</code> creates strings from a given template and the arguments
provided. A new function (present in C and many other languages),
<code>printf</code>, displays formatted strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sprintf(fmt, ..., na_string = NA_character_)

printf(fmt, ..., file = "", sep = "\n", append = FALSE, na_string = "NA")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sprintf_+3A_fmt">fmt</code></td>
<td>
<p>character vector of format strings</p>
</td></tr>
<tr><td><code id="sprintf_+3A_...">...</code></td>
<td>
<p>vectors with data to format
(coercible to integer, real, or character)</p>
</td></tr>
<tr><td><code id="sprintf_+3A_na_string">na_string</code></td>
<td>
<p>single string to represent missing values;
if <code>NA</code>, missing values in <code>...</code>
result in the corresponding outputs be missing too</p>
</td></tr>
<tr><td><code id="sprintf_+3A_file">file</code></td>
<td>
<p>see <code><a href="base.html#topic+cat">cat</a></code></p>
</td></tr>
<tr><td><code id="sprintf_+3A_sep">sep</code></td>
<td>
<p>see <code><a href="base.html#topic+cat">cat</a></code></p>
</td></tr>
<tr><td><code id="sprintf_+3A_append">append</code></td>
<td>
<p>see <code><a href="base.html#topic+cat">cat</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the purpose of <code>printf</code> is to display a string, not
to create a new one for use elsewhere, therefore this function,
as an exception, treats missing values as <code>"NA"</code> strings.
</p>


<h3>Value</h3>

<p><code>sprintf</code> returns a character vector (in UTF-8).
No attributes are preserved.
<code>printf</code> returns 'nothing'.
</p>


<h3>Differences from Base R</h3>

<p>Replacement for base <code><a href="base.html#topic+sprintf">sprintf</a></code>
implemented with <code><a href="stringi.html#topic+stri_sprintf">stri_sprintf</a></code>.
</p>

<ul>
<li><p> missing values in <code>...</code> are treated as <code>"NA"</code> strings
<b>[fixed in <code>sprintf</code>, left in <code>printf</code>, but see the
<code>na_string</code> argument]</b>
</p>
</li>
<li><p> partial recycling results in an error
<b>[fixed here &ndash; warning given]</b>
</p>
</li>
<li><p> input objects' attributes are not preserved
<b>[not fixed, somewhat tricky]</b>
</p>
</li>
<li><p> in to-string conversions, field widths and precisions are
interpreted as bytes which is of course problematic for text in UTF-8
<b>[fixed by interpreting these as Unicode code point widths]</b>
</p>
</li>
<li> <p><code>fmt</code> is limited to 8192 bytes and the number of arguments
passed via <code>...</code> to 99 (note that we can easily
exceed this limit by using <code><a href="base.html#topic+do.call">do.call</a></code>)
<b>[rewritten from scratch, there is no limit anymore]</b>
</p>
</li>
<li><p> unused values in <code>...</code> are evaluated anyway (should not
evaluation be lazy?)
<b>[not fixed here because this is somewhat questionable;
in both base R and our case, a warning is given if this is the case;
moreover, the length of the longest argument always
determines the length of the output]</b>
</p>
</li>
<li><p> coercion of each argument can only be done once
<b>[fixed here - can coerce to integer, real, and character]</b>
</p>
</li>
<li><p> either width or precision can be fetched from <code>...</code>,
but not both
<b>[fixed here - two asterisks are allowed in format specifiers]</b>
</p>
</li>
<li> <p><code>NA</code>/<code>NaNs</code> are not prefixed by a sign/space even if
we explicitly request this
<b>[fixed here - prefixed by a space]</b>
</p>
</li>
<li><p> the outputs are implementation-dependent; the format strings
are passed down to the system (<code>libc</code>) <code>sprintf</code> function
<b>[not fixed here (yet), but the format specifiers
are normalised more eagerly]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+paste">paste</a></code>, <code><a href="#topic+strrep">strrep</a></code>,
<code><a href="#topic+strtrim">strtrim</a></code>, <code><a href="#topic+substr">substr</a></code>, <code><a href="#topic+nchar">nchar</a></code>,
<code><a href="#topic+strwrap">strwrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># UTF-8 number of bytes vs Unicode code point width:
l &lt;- c("e", "e\u00b2", "\u03c0", "\u03c0\u00b2", "\U0001f602\U0001f603")
r &lt;- c(exp(1), exp(2), pi, pi^2, NaN)
cat(base::sprintf("%8s=%+.3f", l, r), sep="\n")
cat(stringx::sprintf("%8s=%+.3f", l, r), sep="\n")

</code></pre>

<hr>
<h2 id='startsWith'>Detect Pattern Occurrences at Start or End of Strings</h2><span id='topic+startsWith'></span><span id='topic+endsWith'></span>

<h3>Description</h3>

<p>Determines if a string starts or ends with a match to a specified
fixed pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>startsWith(
  x,
  pattern = prefix,
  ...,
  ignore_case = ignore.case,
  fixed = TRUE,
  ignore.case = FALSE,
  prefix
)

endsWith(
  x,
  pattern = suffix,
  ...,
  ignore_case = ignore.case,
  fixed = TRUE,
  ignore.case = FALSE,
  suffix
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="startsWith_+3A_x">x</code></td>
<td>
<p>character vector whose elements are to be examined</p>
</td></tr>
<tr><td><code id="startsWith_+3A_pattern">pattern</code></td>
<td>
<p>character vector with patterns to search for</p>
</td></tr>
<tr><td><code id="startsWith_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stringi.html#topic+stri_startswith">stri_startswith</a></code>
and <code><a href="stringi.html#topic+stri_endswith">stri_endswith</a></code>, e.g., <code>locale</code></p>
</td></tr>
<tr><td><code id="startsWith_+3A_ignore_case">ignore_case</code></td>
<td>
<p>single logical value; indicates whether matching
should be case-insensitive</p>
</td></tr>
<tr><td><code id="startsWith_+3A_fixed">fixed</code></td>
<td>
<p>single logical value;
<code>TRUE</code> for fixed pattern matching
(see <a href="stringi.html#topic+about_search_fixed">about_search_fixed</a>);
<code>NA</code> for the Unicode collation algorithm
(<a href="stringi.html#topic+about_search_coll">about_search_coll</a>);
<code>FALSE</code> is not supported &ndash; use <code><a href="#topic+grepl">grepl</a></code> instead</p>
</td></tr>
<tr><td><code id="startsWith_+3A_ignore.case">ignore.case</code></td>
<td>
<p>alias to the <code>ignore_case</code> argument [DEPRECATED]</p>
</td></tr>
<tr><td><code id="startsWith_+3A_prefix">prefix</code>, <code id="startsWith_+3A_suffix">suffix</code></td>
<td>
<p>aliases to the <code>pattern</code> argument [DEPRECATED]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are fully vectorised with respect to both arguments.
</p>
<p>For matching with regular expressions, see <code><a href="#topic+grepl">grepl</a></code>
with patterns like <code>"^prefix"</code> and <code>"suffix$"</code>.
</p>


<h3>Value</h3>

<p>Each function returns a logical vector, indicating whether a pattern
match has been detected or not.
They preserve the attributes of the longest inputs (unless they are
dropped due to coercion).
</p>


<h3>Differences from Base R</h3>

<p>Replacements for base <code><a href="base.html#topic+startsWith">startsWith</a></code>
and <code><a href="base.html#topic+endsWith">endsWith</a></code>
implemented with <code><a href="stringi.html#topic+stri_startswith">stri_startswith</a></code>
and <code><a href="stringi.html#topic+stri_endswith">stri_endswith</a></code>.
</p>

<ul>
<li><p> there are inconsistencies between the argument order and naming
in <code><a href="base.html#topic+grepl">grepl</a></code>, <code><a href="base.html#topic+strsplit">strsplit</a></code>,
and <code><a href="base.html#topic+startsWith">startsWith</a></code> (amongst others); e.g.,
where the needle can precede the haystack, the use of the forward
pipe operator, <code><a href="base.html#topic++7C+3E">|&gt;</a></code>, is less convenient
<b>[fixed here]</b>
</p>
</li>
<li> <p><code><a href="base.html#topic+grepl">grepl</a></code> also features the <code>ignore.case</code> argument
<b>[added here]</b>
</p>
</li>
<li><p> partial recycling without the usual warning
<b>[fixed here]</b>
</p>
</li>
<li><p> no attributes preserved whatsoever
<b>[fixed here]</b>
</p>
</li>
<li><p> not suitable for natural language processing
<b>[fixed here &ndash; use <code>fixed=NA</code>]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+grepl">grepl</a></code>, <code><a href="#topic+substr">substr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>startsWith("ababa", c("a", "ab", "aba", "baba", NA))
outer(
    c("aba", "abb", "abc", "baba", "bac"),
    c("A", "B", "C"),
    endsWith,
    ignore_case=TRUE
)
x &lt;- c("Mario", "mario", "M\u00E1rio", "M\u00C1RIO", "Mar\u00EDa", "Rosario")
x[startsWith(x, "mario", ignore_case=TRUE)]
x[startsWith(x, "mario", fixed=NA, strength=1L)]

</code></pre>

<hr>
<h2 id='strcoll'>Compare Strings</h2><span id='topic+strcoll'></span><span id='topic++25x+3C+25'></span><span id='topic++25x+3C+3D+25'></span><span id='topic++25x+3D+3D+25'></span><span id='topic++25x+21+3D+25'></span><span id='topic++25x+3E+25'></span><span id='topic++25x+3E+3D+25'></span>

<h3>Description</h3>

<p>These functions provide means to compare strings in any locale
using the Unicode collation algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strcoll(
  e1,
  e2,
  locale = NULL,
  strength = 3L,
  alternate_shifted = FALSE,
  french = FALSE,
  uppercase_first = NA,
  case_level = FALSE,
  normalisation = FALSE,
  numeric = FALSE
)

e1 %x&lt;% e2

e1 %x&lt;=% e2

e1 %x==% e2

e1 %x!=% e2

e1 %x&gt;% e2

e1 %x&gt;=% e2
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strcoll_+3A_e1">e1</code>, <code id="strcoll_+3A_e2">e2</code></td>
<td>
<p>character vector whose corresponding elements are to be
compared</p>
</td></tr>
<tr><td><code id="strcoll_+3A_locale">locale</code></td>
<td>
<p><code>NULL</code> or <code>""</code> for the default locale
(see <code><a href="stringi.html#topic+stri_locale_get">stri_locale_get</a></code>)
or a single string with a locale identifier,
see <code><a href="stringi.html#topic+stri_locale_list">stri_locale_list</a></code></p>
</td></tr>
<tr><td><code id="strcoll_+3A_strength">strength</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="strcoll_+3A_alternate_shifted">alternate_shifted</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="strcoll_+3A_french">french</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="strcoll_+3A_uppercase_first">uppercase_first</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="strcoll_+3A_case_level">case_level</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="strcoll_+3A_normalisation">normalisation</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="strcoll_+3A_numeric">numeric</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are fully vectorised with respect to both arguments.
</p>
<p>For a locale-insensitive behaviour like that of
<code>strcmp</code> from the standard C library, call
<code>strcoll(e1, e2, locale="C", strength=4L, normalisation=FALSE)</code>.
However, some normalisation will still be performed.
</p>


<h3>Value</h3>

<p><code>strcoll</code> returns an integer vector representing the comparison results:
if a string in <code>e1</code> is smaller than the corresponding string in
<code>e2</code>, the corresponding result will be equal to <code>-1</code>, and
<code>0</code> if they are canonically equivalent,
as well as <code>1</code> if the former is greater than the latter.
</p>
<p>The binary operators call <code>strcoll</code> with default arguments and
return logical vectors.
</p>


<h3>Differences from Base R</h3>

<p>Replacements for base <a href="base.html#topic+Comparison">Comparison</a> operators
implemented with <code><a href="stringi.html#topic+stri_cmp">stri_cmp</a></code>.
</p>

<ul>
<li><p> collation in different locales is difficult and non-portable across
platforms
<b>[fixed here &ndash; using services provided by ICU]</b>
</p>
</li>
<li><p> overloading <code>`&lt;.character`</code> has no effect in R, because S3
method dispatch is done internally with hard-coded support for
character arguments. We could have replaced the generic <code>`&lt;`</code>
with the one that calls <code><a href="base.html#topic+UseMethod">UseMethod</a></code>, but
it feels like a too intrusive solution
<b>[fixed by introducing the <code>`%x&lt;%`</code> operator]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+xtfrm">xtfrm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># lexicographic vs. numeric sort
strcoll("100", c("1", "10", "11", "99", "100", "101", "1000"))
strcoll("100", c("1", "10", "11", "99", "100", "101", "1000"), numeric=TRUE)
strcoll("hladn\u00FD", "chladn\u00FD", locale="sk_SK")

</code></pre>

<hr>
<h2 id='strptime'>Parse and Format Date-time Objects</h2><span id='topic+strptime'></span><span id='topic+POSIXxt'></span><span id='topic+strftime'></span><span id='topic+format.POSIXxt'></span><span id='topic+is.POSIXxt'></span><span id='topic+as.POSIXxt'></span><span id='topic+as.POSIXxt.POSIXt'></span><span id='topic+as.POSIXlt.POSIXxt'></span><span id='topic+as.POSIXxt.default'></span><span id='topic+as.Date.POSIXxt'></span><span id='topic+as.POSIXxt.Date'></span><span id='topic+as.POSIXxt.character'></span><span id='topic+Ops.POSIXxt'></span><span id='topic+seq.POSIXxt'></span><span id='topic+c.POSIXxt'></span><span id='topic+rep.POSIXxt'></span>

<h3>Description</h3>

<p>Note that the date-time processing functions in <span class="pkg">stringx</span> are a work
in progress. Feature requests/comments/remarks are welcome.
</p>
<p><code>strptime</code> parses strings representing date-time data
and converts it to a date-time object.
</p>
<p><code>strftime</code> formats a date-time object and outputs it as a
character vector.
</p>
<p>The functions are meant to be compatible with each other,
especially with regards to formatting/printing. This is why
they return/deal with objects of a new class, <code>POSIXxt</code>, which
expends upon the built-in <code>POSIXct</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strptime(x, format, tz = "", lenient = FALSE, locale = NULL)

strftime(
  x,
  format = "%Y-%m-%dT%H:%M:%S%z",
  tz = attr(x, "tzone")[1L],
  usetz = FALSE,
  ...,
  locale = NULL
)

## S3 method for class 'POSIXxt'
format(
  x,
  format = "%Y-%m-%dT%H:%M:%S%z",
  tz = attr(x, "tzone")[1L],
  usetz = FALSE,
  ...,
  locale = NULL
)

is.POSIXxt(x)

as.POSIXxt(x, tz = "", ...)

## S3 method for class 'POSIXt'
as.POSIXxt(x, tz = attr(x, "tzone")[1L], ...)

## S3 method for class 'POSIXxt'
as.POSIXlt(x, tz = attr(x, "tzone")[1L], ..., locale = NULL)

## Default S3 method:
as.POSIXxt(x, tz = "", ...)

## S3 method for class 'POSIXxt'
as.Date(x, ...)

## S3 method for class 'Date'
as.POSIXxt(x, ...)

## S3 method for class 'character'
as.POSIXxt(x, tz = "", format = NULL, ..., lenient = FALSE, locale = NULL)

## S3 method for class 'POSIXxt'
Ops(e1, e2)

## S3 method for class 'POSIXxt'
seq(from, to, by, length.out = NULL, along.with = NULL, ...)

## S3 method for class 'POSIXxt'
c(..., recursive = FALSE)

## S3 method for class 'POSIXxt'
rep(..., recursive = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strptime_+3A_x">x</code></td>
<td>
<p>object to be converted: a character vector for <code>strptime</code>
and <code>as.POSIXxt.character</code>,
an object of class <code>POSIXxt</code> for <code>strftime</code>
an object of class <code>Date</code> for <code>as.POSIXxt.Date</code>,
or objects coercible to</p>
</td></tr>
<tr><td><code id="strptime_+3A_format">format</code></td>
<td>
<p>character vector of date-time format specifiers,
see <code><a href="stringi.html#topic+stri_datetime_fstr">stri_datetime_fstr</a></code>;
e.g., <code>"%Y-%m-%d"</code> or <code>"datetime_full"</code>;
the default conforms to the ISO 8601 guideline</p>
</td></tr>
<tr><td><code id="strptime_+3A_tz">tz</code></td>
<td>
<p><code>NULL</code> or <code>''</code> for the default time zone
(see <code><a href="stringi.html#topic+stri_timezone_get">stri_timezone_get</a></code>)
or a single string with a timezone identifier,
see <code><a href="stringi.html#topic+stri_timezone_list">stri_timezone_list</a></code>;
note that when <code>x</code> is equipped with <code>tzone</code> attribute,
this datum is used;
<code>as.POSIXxt.character</code> treats dates as being at midnight local time</p>
</td></tr>
<tr><td><code id="strptime_+3A_lenient">lenient</code></td>
<td>
<p>single logical value; should date/time parsing be lenient?</p>
</td></tr>
<tr><td><code id="strptime_+3A_locale">locale</code></td>
<td>
<p><code>NULL</code> or <code>''</code> for the default locale
(see <code><a href="stringi.html#topic+stri_locale_get">stri_locale_get</a></code>)
or a single string with a locale identifier,
see <code><a href="stringi.html#topic+stri_locale_list">stri_locale_list</a></code></p>
</td></tr>
<tr><td><code id="strptime_+3A_usetz">usetz</code></td>
<td>
<p>not used (with a warning if attempting to do so) [DEPRECATED]</p>
</td></tr>
<tr><td><code id="strptime_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
<tr><td><code id="strptime_+3A_e1">e1</code>, <code id="strptime_+3A_e2">e2</code>, <code id="strptime_+3A_from">from</code>, <code id="strptime_+3A_to">to</code>, <code id="strptime_+3A_by">by</code>, <code id="strptime_+3A_length.out">length.out</code>, <code id="strptime_+3A_along.with">along.with</code>, <code id="strptime_+3A_recursive">recursive</code></td>
<td>
<p>arguments to <code><a href="base.html#topic+c">c</a></code>, <code><a href="base.html#topic+rep">rep</a></code>, <code><a href="base.html#topic+seq">seq</a></code>, etc.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the ISO 8601 guideline suggests a year-month-day
date format and a 24-hour time format always indicating the effective
time zone, e.g., <code>2015-12-31T23:59:59+0100</code>. This is so as to avoid
ambiguity.
</p>
<p>When parsing strings, missing fields are filled based on today's midnight
data.
</p>


<h3>Value</h3>

<p><code>strftime</code> and <code>format</code> return a character vector (in UTF-8).
</p>
<p><code>strptime</code>, <code>as.POSIXxt.Date</code>,
and <code>asPOSIXxt.character</code> return an object
of class <code>POSIXxt</code>, which
extends upon <code><a href="base.html#topic+POSIXct">POSIXct</a></code>,
see also <a href="base.html#topic+DateTimeClasses">DateTimeClasses</a>.
</p>
<p>Subtraction returns an object of the class <code>difftime</code>,
see <code><a href="base.html#topic+difftime">difftime</a></code>.
</p>
<p>If a string cannot be recognised as valid date/time specifier
(as per the given format string), the corresponding output will be <code>NA</code>.
</p>


<h3>Differences from Base R</h3>

<p>Replacements for base <code><a href="base.html#topic+strptime">strptime</a></code>
and <code><a href="base.html#topic+strftime">strftime</a></code> implemented with
<code><a href="stringi.html#topic+stri_datetime_parse">stri_datetime_parse</a></code> and
<code><a href="stringi.html#topic+stri_datetime_format">stri_datetime_format</a></code>.
</p>
<p><code>format.POSIXxt</code> is a thin wrapper around <code>strftime</code>.
</p>

<ul>
<li><p> formatting/parsing date-time in different locales and calendars
is difficult and non-portable across platforms
<b>[fixed here &ndash; using services provided by ICU]</b>
</p>
</li>
<li><p> default format not conforming to ISO 8601, in particular not
displaying the current time zone
<b>[fixed here]</b>
</p>
</li>
<li><p> only the names attribute in <code>x</code> is propagated
<b>[fixed here]</b>
</p>
</li>
<li><p> partial recycling with no warning
<b>[fixed here]</b>
</p>
</li>
<li> <p><code>strptime</code> returns an object of class <code>POSIXlt</code>,
which is not the most convenient to work with, e.g., when
including in data frames
<b>[fixed here]</b>
</p>
</li>
<li><p> Ideally, there should be only one class to represent dates
and one to represent date/time; <code>POSIXlt</code>
is no longer needed as we have
<code><a href="stringi.html#topic+stri_datetime_fields">stri_datetime_fields</a></code>;
our new <code>POSIXxt</code> class aims to solve the underlying problems
with <code>POSIXct</code>'s not being consistent with regards to
working in different time zones and dates
(see, e.g., <code>as.Date(as.POSIXct(strftime(Sys.Date())))</code>)
<b>[addressed here]</b>
</p>
</li>
<li><p> dates without times are not always treated as being at midnight
(despite that being stated in the help page for <code>as.POSIXct</code>)
<b>[fixed here]</b>
</p>
</li>
<li> <p><code>strftime</code> does not honour the <code>tzone</code> attribute,
which is used whilst displaying time (via <code><a href="base.html#topic+format">format</a></code>)
<b>[fixed here]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+sprintf">sprintf</a></code>, <code><a href="#topic+ISOdatetime">ISOdatetime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>strftime(Sys.time())  # default format - ISO 8601
f &lt;- c("date_full", "%Y-%m-%d", "date_relative_short", "datetime_full")
strftime(Sys.time(), f)  # current default locale
strftime(Sys.time(), f, locale="de_DE")
strftime(Sys.time(), "date_short", locale="en_IL@calendar=hebrew")
strptime("1970-01-01 00:00:00", "%Y-%m-%d %H:%M:%S", tz="GMT")
strptime("14 Nisan 5703", "date_short", locale="en_IL@calendar=hebrew")
as.POSIXxt("1970-01-01")
as.POSIXxt("1970/01/01 12:00")


</code></pre>

<hr>
<h2 id='strrep'>Duplicate Strings</h2><span id='topic+strrep'></span><span id='topic++25x+2A+25'></span>

<h3>Description</h3>

<p>Concatenate a number of copies of each string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strrep(x, times)

e1 %x*% e2
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strrep_+3A_e1">e1</code>, <code id="strrep_+3A_x">x</code></td>
<td>
<p>character vector (or an object coercible to)
whose elements are to be duplicated</p>
</td></tr>
<tr><td><code id="strrep_+3A_e2">e2</code>, <code id="strrep_+3A_times">times</code></td>
<td>
<p>numeric vector giving the number of times to repeat
the corresponding strings</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both arguments are recycled if necessary.
</p>
<p>The <code>`%x*%`</code> operator mimics a vectorised version of Python's
<code>`*`</code> for strings (<code>str.__mul__</code>).
</p>


<h3>Value</h3>

<p>A character vector (in UTF-8).
</p>
<p><code>`%x*%`</code> and <code>strrep</code> preserve object attributes
in a similar way as other <a href="base.html#topic+Arithmetic">Arithmetic</a> operators.
</p>


<h3>Differences from Base R</h3>

<p>Replacement for base <code><a href="base.html#topic+strrep">strrep</a></code>
implemented with <code><a href="stringi.html#topic+stri_dup">stri_dup</a></code>.
</p>

<ul>
<li><p> partial recycling with no warning &quot;longer object length is not
a multiple of shorter object length&quot; <b>[fixed here]</b>
</p>
</li>
<li><p> base <code>strrep</code> seems to preserve only the <code>names</code> attribute,
and only if the input is of type character
(whilst <code>paste</code> preserves nothing)
<b>[fixed]</b>
</p>
</li>
<li><p> overloading <code>`*.character`</code> has no effect in R, because S3
method dispatch is done internally with hard-coded support for
character arguments. We could have replaced the generic <code>`*`</code>
with the one that calls <code><a href="base.html#topic+UseMethod">UseMethod</a></code>, but
it feels like a too intrusive solution
<b>[fixed by introducing <code>`%x+%`</code> operator]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+paste">paste</a></code>, <code><a href="#topic+sprintf">sprintf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- structure(c(A="a", B=NA, C="c"), attrib1="value1")
x %x*% 3
x %x*% 1:3
"a" %x*% 1:3
stringx::strrep(x, 3)
base::strrep(x, 3)
y &lt;- matrix(1:6, nrow=2, dimnames=list(c("A", "B"), NULL))
y %x*% 1:2
stringx::strrep(y, 1:2)
base::strrep(y, 1:2)

</code></pre>

<hr>
<h2 id='strsplit'>Split Strings into Tokens</h2><span id='topic+strsplit'></span>

<h3>Description</h3>

<p>Splits each string into chunks delimited by occurrences of a given pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strsplit(
  x,
  pattern = split,
  ...,
  ignore_case = ignore.case,
  fixed = FALSE,
  perl = FALSE,
  useBytes = FALSE,
  ignore.case = FALSE,
  split
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strsplit_+3A_x">x</code></td>
<td>
<p>character vector whose elements are to be examined</p>
</td></tr>
<tr><td><code id="strsplit_+3A_pattern">pattern</code></td>
<td>
<p>character vector of nonempty search patterns</p>
</td></tr>
<tr><td><code id="strsplit_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stringi.html#topic+stri_split">stri_split</a></code>,
e.g., <code>omit_empty</code>, <code>locale</code>, <code>dotall</code></p>
</td></tr>
<tr><td><code id="strsplit_+3A_ignore_case">ignore_case</code></td>
<td>
<p>single logical value; indicates whether matching
should be case-insensitive</p>
</td></tr>
<tr><td><code id="strsplit_+3A_fixed">fixed</code></td>
<td>
<p>single logical value;
<code>FALSE</code> for matching with regular expressions
(see <a href="stringi.html#topic+about_search_regex">about_search_regex</a>);
<code>TRUE</code> for fixed pattern matching
(<a href="stringi.html#topic+about_search_fixed">about_search_fixed</a>);
<code>NA</code> for the Unicode collation algorithm
(<a href="stringi.html#topic+about_search_coll">about_search_coll</a>)</p>
</td></tr>
<tr><td><code id="strsplit_+3A_perl">perl</code>, <code id="strsplit_+3A_usebytes">useBytes</code></td>
<td>
<p>not used (with a warning if
attempting to do so) [DEPRECATED]</p>
</td></tr>
<tr><td><code id="strsplit_+3A_ignore.case">ignore.case</code></td>
<td>
<p>alias to the <code>ignore_case</code> argument [DEPRECATED]</p>
</td></tr>
<tr><td><code id="strsplit_+3A_split">split</code></td>
<td>
<p>alias to the <code>pattern</code> argument [DEPRECATED]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is fully vectorised with respect to both arguments.
</p>
<p>For splitting text into 'characters' (grapheme clusters), words,
or sentences, use <code><a href="stringi.html#topic+stri_split_boundaries">stri_split_boundaries</a></code> instead.
</p>


<h3>Value</h3>

<p>Returns a list of character vectors representing the identified tokens.
</p>


<h3>Differences from Base R</h3>

<p>Replacements for base <code><a href="base.html#topic+strsplit">strsplit</a></code>
implemented with <code><a href="stringi.html#topic+stri_split">stri_split</a></code>.
</p>

<ul>
<li><p> base R implementation is not portable as it is based on
the system PCRE or TRE library
(e.g., some Unicode classes may not be available or matching thereof
can depend on the current <code>LC_CTYPE</code> category
<b>[fixed here]</b>
</p>
</li>
<li><p> not suitable for natural language processing
<b>[fixed here &ndash; use <code>fixed=NA</code>]</b>
</p>
</li>
<li><p> two different regular expression libraries are used
(and historically, ERE was used in place of TRE)
<b>[here, <span class="pkg">ICU</span> Java-like regular expression engine
is only available, hence the <code>perl</code> argument has no meaning]</b>
</p>
</li>
<li><p> there are inconsistencies between the argument order and naming
in <code><a href="base.html#topic+grepl">grepl</a></code>, <code><a href="base.html#topic+strsplit">strsplit</a></code>,
and <code><a href="base.html#topic+startsWith">startsWith</a></code> (amongst others); e.g.,
where the needle can precede the haystack, the use of the forward
pipe operator, <code><a href="base.html#topic++7C+3E">|&gt;</a></code>, is less convenient
<b>[fixed here]</b>
</p>
</li>
<li> <p><code><a href="base.html#topic+grepl">grepl</a></code> also features the <code>ignore.case</code> argument
<b>[added here]</b>
</p>
</li>
<li><p> if <code>split</code> is a zero-length vector, it is treated as <code>""</code>,
which extracts individual code points (which is not the best idea
for natural language processing tasks)
<b>[empty search patterns are not supported here, zero-length vectors
are propagated correctly]</b>
</p>
</li>
<li><p> last empty token is removed from the output, but first is not
<b>[fixed here &ndash; see also the <code>omit_empty</code> argument]</b>
</p>
</li>
<li><p> missing values in <code>split</code> are not propagated correctly
<b>[fixed here]</b>
</p>
</li>
<li><p> partial recycling without the usual warning, not fully vectorised
w.r.t. the <code>split</code> argument
<b>[fixed here]</b>
</p>
</li>
<li><p> only the <code>names</code> attribute of <code>x</code> is preserved
<b>[fixed here]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+paste">paste</a></code>, <code><a href="#topic+nchar">nchar</a></code>,
<code><a href="#topic+grepl">grepl</a></code>, <code><a href="#topic+gsub">gsub</a></code>, <code><a href="#topic+substr">substr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stringx::strsplit(c(x="a, b", y="c,d,  e"), ",\\s*")
x &lt;- strcat(c(
    "abc", "123", ",!.", "\U0001F4A9",
    "\U0001F64D\U0001F3FC\U0000200D\U00002642\U0000FE0F",
    "\U000026F9\U0001F3FF\U0000200D\U00002640\U0000FE0F",
    "\U0001F3F4\U000E0067\U000E0062\U000E0073\U000E0063\U000E0074\U000E007F"
))
# be careful when splitting into individual code points:
base::strsplit(x, "")  # stringx does not support this
stringx::strsplit(x, "(?s)(?=.)", omit_empty=TRUE)  # look-ahead for any char with dot-all
stringi::stri_split_boundaries(x, type="character")  # grapheme clusters

</code></pre>

<hr>
<h2 id='strtrans'>Transliteration and Other Text Transforms</h2><span id='topic+strtrans'></span><span id='topic+chartr2'></span><span id='topic+chartr'></span><span id='topic+tolower'></span><span id='topic+toupper'></span><span id='topic+casefold'></span>

<h3>Description</h3>

<p>These functions can be used to translate characters, including case mapping
and folding, script to script conversion, and Unicode normalisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strtrans(x, transform)

chartr2(x, pattern, replacement)

chartr(old, new, x)

tolower(x, locale = NULL)

toupper(x, locale = NULL)

casefold(x, upper = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strtrans_+3A_x">x</code></td>
<td>
<p>character vector (or an object coercible to)</p>
</td></tr>
<tr><td><code id="strtrans_+3A_transform">transform</code></td>
<td>
<p>single string with ICU general transform
specifier, see <code><a href="stringi.html#topic+stri_trans_list">stri_trans_list</a></code></p>
</td></tr>
<tr><td><code id="strtrans_+3A_pattern">pattern</code>, <code id="strtrans_+3A_old">old</code></td>
<td>
<p>single string</p>
</td></tr>
<tr><td><code id="strtrans_+3A_replacement">replacement</code>, <code id="strtrans_+3A_new">new</code></td>
<td>
<p>single string,
preferably of the same length as <code>old</code></p>
</td></tr>
<tr><td><code id="strtrans_+3A_locale">locale</code></td>
<td>
<p><code>NULL</code> or <code>""</code> for the default locale
(see <code><a href="stringi.html#topic+stri_locale_get">stri_locale_get</a></code>)
or a single string with a locale identifier,
see <code><a href="stringi.html#topic+stri_locale_list">stri_locale_list</a></code></p>
</td></tr>
<tr><td><code id="strtrans_+3A_upper">upper</code></td>
<td>
<p>single logical value; switches between case folding
(the default, <code>NA</code>), lower-, and upper-case</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>tolower</code> and <code>toupper</code> perform case mapping.
<code>chartr2</code> (and [DEPRECATED] <code>chartr</code>) translate individual code points.
<code>casefold</code> commits case folding.
The new function <code>strtrans</code> applies general <span class="pkg">ICU</span> transforms,
see <code><a href="stringi.html#topic+stri_trans_general">stri_trans_general</a></code>.
</p>


<h3>Value</h3>

<p>These functions return a character vector (in UTF-8).
They preserve most attributes of <code>x</code>.
Note that their base R counterparts drop all the attributes
if not fed with character vectors.
</p>


<h3>Differences from Base R</h3>

<p>Unlike their base R counterparts, the new <code>tolower</code> and
<code>toupper</code> are locale-sensitive;
see <code><a href="stringi.html#topic+stri_trans_tolower">stri_trans_tolower</a></code>.
</p>
<p>The base <code><a href="base.html#topic+casefold">casefold</a></code> simply dispatches to
<code>tolower</code> or <code>toupper</code>
'for compatibility with S-PLUS' (which was only crucial long time ago).
The version implemented here, by default, performs the true case folding,
whose purpose is to make two pieces of text that differ only in case
identical, see <code><a href="stringi.html#topic+stri_trans_casefold">stri_trans_casefold</a></code>.
</p>
<p><code>chartr2</code> and [DEPRECATED] <code>chartr</code> are
wrappers for <code><a href="stringi.html#topic+stri_trans_char">stri_trans_char</a></code>.
Contrary to the base <code><a href="base.html#topic+chartr">chartr</a></code>, they always generate
a warning when <code>old</code> and <code>new</code> are of different lengths.
<code>chartr2</code> has argument order and naming consistent with
<code><a href="#topic+gsub">gsub</a></code>.
</p>


<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>strtrans(strcat(letters_bf), "Any-NFKD; Any-Upper")
strtrans(strcat(letters_bb[1:6]), "Any-Hex/C")
strtrans(strcat(letters_greek), "Greek-Latin")

toupper(letters_greek)
tolower(LETTERS_GREEK)

base::toupper("gro\u00DF")
stringx::toupper("gro\u00DF")

casefold("gro\u00DF")

x &lt;- as.matrix(c(a="\u00DFpam ba\U0001D554on spam", b=NA))
chartr("\u00DF\U0001D554aba", "SCXBA", x)

toupper('i', locale='en_US')
toupper('i', locale='tr_TR')

</code></pre>

<hr>
<h2 id='strtrim'>Shorten Strings to Specified Width</h2><span id='topic+strtrim'></span>

<h3>Description</h3>

<p>Right-trims strings so that they do not exceed a given width
(as determined by <code><a href="stringi.html#topic+stri_width">stri_width</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strtrim(x, width)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strtrim_+3A_x">x</code></td>
<td>
<p>character vector
whose elements are to be trimmed</p>
</td></tr>
<tr><td><code id="strtrim_+3A_width">width</code></td>
<td>
<p>numeric vector giving the widths to which the corresponding
strings are to be trimmed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both arguments are recycled if necessary.
</p>
<p>Not to be confused with <code><a href="#topic+trimws">trimws</a></code>.
</p>
<p>Might be useful when displaying strings using a monospaced font.
</p>


<h3>Value</h3>

<p>Returns a character vector (in UTF-8).
Preserves object attributes
in a similar way as <a href="base.html#topic+Arithmetic">Arithmetic</a> operators.
</p>


<h3>Differences from Base R</h3>

<p>Replacement for base <code><a href="base.html#topic+strtrim">strtrim</a></code>
implemented with (special case of) <code><a href="stringi.html#topic+stri_sprintf">stri_sprintf</a></code>.
</p>

<ul>
<li><p> both arguments are not recycled in an usual manner
<b>[fixed here]</b>
</p>
</li>
<li><p> missing values are not allowed in <code>width</code>
<b>[fixed here]</b>
</p>
</li>
<li><p> some emojis, combining characters and modifiers (e.g., skin tones)
are not recognised properly <b>[fixed here]</b>
</p>
</li>
<li><p> attributes are only propagated from the 1st argument
<b>[fixed]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+sprintf">sprintf</a></code>, <code><a href="#topic+substr">substr</a></code>,
<code><a href="#topic+nchar">nchar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>base::strtrim("aaaaa", 1:3)
stringx::strtrim("aaaaa", 1:3)
x &lt;- c(
    "\U0001F4A9",
    "\U0001F64D\U0001F3FC\U0000200D\U00002642\U0000FE0F",
    "\U0001F64D\U0001F3FB\U0000200D\U00002642",
    "\U000026F9\U0001F3FF\U0000200D\U00002640\U0000FE0F",
    "\U0001F3F4\U000E0067\U000E0062\U000E0073\U000E0063\U000E0074\U000E007F"
)
print(x)
base::strtrim(x, 2)
stringx::strtrim(x, 2)

</code></pre>

<hr>
<h2 id='strwrap'>Word-Wrap Text</h2><span id='topic+strwrap'></span>

<h3>Description</h3>

<p>Splits each string into words which are then arranged to form text lines
of mo more than a given width.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strwrap(
  x,
  width = 0.9 * getOption("width"),
  indent = 0,
  exdent = 0,
  prefix = "",
  simplify = TRUE,
  initial = prefix,
  locale = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strwrap_+3A_x">x</code></td>
<td>
<p>character vector whose elements are to be word-wrapped</p>
</td></tr>
<tr><td><code id="strwrap_+3A_width">width</code></td>
<td>
<p>single integer; maximal total width of the code points
per line (as determined by <code><a href="stringi.html#topic+stri_width">stri_width</a></code>)</p>
</td></tr>
<tr><td><code id="strwrap_+3A_indent">indent</code></td>
<td>
<p>single integer; first line indentation size</p>
</td></tr>
<tr><td><code id="strwrap_+3A_exdent">exdent</code></td>
<td>
<p>single integer; consequent lines indentation size</p>
</td></tr>
<tr><td><code id="strwrap_+3A_prefix">prefix</code></td>
<td>
<p>single string; prefix for each line except the first</p>
</td></tr>
<tr><td><code id="strwrap_+3A_simplify">simplify</code></td>
<td>
<p>see Value</p>
</td></tr>
<tr><td><code id="strwrap_+3A_initial">initial</code></td>
<td>
<p>single string; prefix for the first line</p>
</td></tr>
<tr><td><code id="strwrap_+3A_locale">locale</code></td>
<td>
<p><code>NULL</code> or <code>""</code> for the default locale
(see <code><a href="stringi.html#topic+stri_locale_get">stri_locale_get</a></code>)
or a single string with a locale identifier,
see <code><a href="stringi.html#topic+stri_locale_list">stri_locale_list</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Might be useful when displaying strings using a monospaced font.
</p>


<h3>Value</h3>

<p>If <code>simplify</code> is <code>FALSE</code>, a list of <code>length(x)</code> numeric
vectors is returned.
</p>
<p>Otherwise, the function yields a character vector (in UTF-8).
Note that the length of the output may be different
than that of the input.
</p>
<p>Due to this, no attributes are preserved.
</p>


<h3>Differences from Base R</h3>

<p>Replacement for base <code><a href="base.html#topic+strwrap">strwrap</a></code>
implemented with <code><a href="stringi.html#topic+stri_wrap">stri_wrap</a></code>.
</p>

<ul>
<li><p> missing values not propagated
<b>[fixed here]</b>
</p>
</li>
<li><p> some emojis, combining characters and modifiers (e.g., skin tones)
are not recognised properly
<b>[fixed here]</b>
</p>
</li>
<li><p> what is considered a word does not depend on locale
<b>[fixed here - using <span class="pkg">ICU</span>'s word break iterators]</b>
</p>
</li>
<li><p> multiple whitespaces between words are not preserved except after
a dot, question mark, or exclamation mark,
which leads to two spaces inserted
<b>[changed here &ndash; any sequence of whitespaces considered
word boundaries is converted to a single space]</b>
</p>
</li>
<li><p> a greedy word wrap algorithm is used, which may lead to high
raggedness
<b>[fixed here &ndash; using the Knuth-Plass method]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>References</h3>

<p>D.E. Knuth, M.F. Plass,
Breaking paragraphs into lines,
<em>Software: Practice and Experience</em> 11(11),
1981, pp. 1119&ndash;1184.
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+sprintf">sprintf</a></code>, <code><a href="#topic+trimws">trimws</a></code>,
<code><a href="#topic+nchar">nchar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>strwrap(paste0(
    strrep("az ", 20),
    strrep("\u0105\u20AC ", 20),
    strrep("\U0001F643 ", 20),
    strrep("\U0001F926\U0000200D\U00002642\U0000FE0F ", 20)
), width=60)


</code></pre>

<hr>
<h2 id='sub2'>Replace Pattern Occurrences</h2><span id='topic+sub2'></span><span id='topic+gsub2'></span><span id='topic+sub'></span><span id='topic+gsub'></span>

<h3>Description</h3>

<p><code>sub2</code> replaces the first pattern occurrence in each string
with a given replacement string.
<code>gsub2</code> replaces all (i.e., 'globally') pattern matches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sub2(x, pattern, replacement, ..., ignore_case = FALSE, fixed = FALSE)

gsub2(x, pattern, replacement, ..., ignore_case = FALSE, fixed = FALSE)

sub(
  pattern,
  replacement,
  x,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  perl = FALSE,
  useBytes = FALSE
)

gsub(
  pattern,
  replacement,
  x,
  ...,
  ignore.case = FALSE,
  fixed = FALSE,
  perl = FALSE,
  useBytes = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sub2_+3A_x">x</code></td>
<td>
<p>character vector with strings whose chunks are to be modified</p>
</td></tr>
<tr><td><code id="sub2_+3A_pattern">pattern</code></td>
<td>
<p>character vector of nonempty search patterns</p>
</td></tr>
<tr><td><code id="sub2_+3A_replacement">replacement</code></td>
<td>
<p>character vector with the corresponding replacement
strings; in <code>sub2</code> and <code>gsub2</code>, back-references
(whenever <code>fixed=FALSE</code>)
are indicated by <code>$0</code>..<code>$99</code> and <code>$&lt;name&gt;</code>,
whereas the base-R compatible <code>sub</code> and <code>gsub</code>,
only allow <code>\1</code>..<code>\9</code></p>
</td></tr>
<tr><td><code id="sub2_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="stringi.html#topic+stri_replace_first">stri_replace_first</a></code>
or <code><a href="stringi.html#topic+stri_replace_all">stri_replace_all</a></code>,
e.g., <code>locale</code>, <code>dotall</code></p>
</td></tr>
<tr><td><code id="sub2_+3A_ignore_case">ignore_case</code>, <code id="sub2_+3A_ignore.case">ignore.case</code></td>
<td>
<p>single logical value; indicates whether matching
should be case-insensitive</p>
</td></tr>
<tr><td><code id="sub2_+3A_fixed">fixed</code></td>
<td>
<p>single logical value;
<code>FALSE</code> for matching with regular expressions
(see <a href="stringi.html#topic+about_search_regex">about_search_regex</a>);
<code>TRUE</code> for fixed pattern matching
(<a href="stringi.html#topic+about_search_fixed">about_search_fixed</a>);
<code>NA</code> for the Unicode collation algorithm
(<a href="stringi.html#topic+about_search_coll">about_search_coll</a>)</p>
</td></tr>
<tr><td><code id="sub2_+3A_perl">perl</code>, <code id="sub2_+3A_usebytes">useBytes</code></td>
<td>
<p>not used (with a warning if
attempting to do so) [DEPRECATED]</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not to be confused with <code><a href="#topic+substr">substr</a></code>.
</p>
<p>These functions are fully vectorised with respect to <code>x</code>,
<code>pattern</code>, and <code>replacement</code>.
</p>
<p><code>gsub2</code> uses <code>vectorise_all=TRUE</code> because of the attribute
preservation rules, <code><a href="stringi.html#topic+stri_replace_all">stri_replace_all</a></code> should be
called directly if different behaviour is needed.
</p>
<p>The [DEPRECATED] <code>sub</code> and [DEPRECATED] <code>gsub</code> simply call
<code>sub2</code> and <code>gsub2</code>
which have a cleaned-up argument list. Additionally,
if <code>fixed=FALSE</code>, the back-references in <code>replacement</code> strings
are converted to these accepted by the <span class="pkg">ICU</span> regex engine.
</p>


<h3>Value</h3>

<p>Both functions return a character vector.
They preserve the attributes of the longest inputs (unless they are
dropped due to coercion).
</p>


<h3>Differences from Base R</h3>

<p>Replacements for base <code><a href="base.html#topic+sub">sub</a></code> and <code><a href="base.html#topic+gsub">gsub</a></code>
implemented with <code><a href="stringi.html#topic+stri_replace_first">stri_replace_first</a></code>
and <code><a href="stringi.html#topic+stri_replace_all">stri_replace_all</a></code>, respectively.
</p>

<ul>
<li><p> there are inconsistencies between the argument order and naming
in <code><a href="base.html#topic+grepl">grepl</a></code>, <code><a href="base.html#topic+strsplit">strsplit</a></code>,
and <code><a href="base.html#topic+startsWith">startsWith</a></code> (amongst others); e.g.,
where the needle can precede the haystack, the use of the forward
pipe operator, <code><a href="base.html#topic++7C+3E">|&gt;</a></code>, is less convenient
<b>[fixed here]</b>
</p>
</li>
<li><p> base R implementation is not portable as it is based on
the system PCRE or TRE library
(e.g., some Unicode classes may not be available or matching thereof
can depend on the current <code>LC_CTYPE</code> category
<b>[fixed here]</b>
</p>
</li>
<li><p> not suitable for natural language processing
<b>[fixed here &ndash; use <code>fixed=NA</code>]</b>
</p>
</li>
<li><p> two different regular expression libraries are used
(and historically, ERE was used in place of TRE)
<b>[here, <span class="pkg">ICU</span> Java-like regular expression engine
is only available, hence the <code>perl</code> argument has no meaning]</b>
</p>
</li>
<li><p> not vectorised w.r.t. <code>pattern</code> and <code>replacement</code>
<b>[fixed here]</b>
</p>
</li>
<li><p> only 9 (unnamed) back-references can be referred to in the
replacement strings
<b>[fixed in <code>sub2</code> and <code>gsub2</code>]</b>
</p>
</li>
<li> <p><code>perl=TRUE</code> supports <code>\U</code>, <code>\L</code>, and <code>\E</code>
in the replacement strings
<b>[not available here]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+paste">paste</a></code>, <code><a href="#topic+nchar">nchar</a></code>,
<code><a href="#topic+grepl2">grepl2</a></code>, <code><a href="#topic+gregexpr2">gregexpr2</a></code>, <code><a href="#topic+gregextr2">gregextr2</a></code>
<code><a href="#topic+strsplit">strsplit</a></code>, <code><a href="#topic+gsubstr">gsubstr</a></code>
</p>
<p><code><a href="#topic+trimws">trimws</a></code> for removing whitespaces (amongst others)
from the start or end of strings
</p>


<h3>Examples</h3>

<pre><code class='language-R'>"change \U0001f602 me \U0001f603" |&gt; gsub2("\\p{L}+", "O_O")

x &lt;- c("mario", "Mario", "M\u00E1rio", "M\u00C1RIO", "Mar\u00EDa", "Rosario", NA)
sub2(x, "mario", "M\u00E1rio", fixed=NA, strength=1L)
sub2(x, "mario", "Mario", fixed=NA, strength=2L)

x &lt;- "abcdefghijklmnopqrstuvwxyz"
p &lt;- "(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)(.)"
base::sub(p, "\\1\\9", x)
base::gsub(p, "\\1\\9", x)
base::gsub(p, "\\1\\9", x, perl=TRUE)
base::gsub(p, "\\1\\13", x)
sub2(x, p, "$1$13")
gsub2(x, p, "$1$13")


</code></pre>

<hr>
<h2 id='substr'>Extract or Replace Substrings</h2><span id='topic+substr'></span><span id='topic+substrl'></span><span id='topic+substr+3C-'></span><span id='topic+substrl+3C-'></span><span id='topic+gsubstr'></span><span id='topic+gsubstrl'></span><span id='topic+gsubstr+3C-'></span><span id='topic+gsubstrl+3C-'></span><span id='topic+substring'></span><span id='topic+substring+3C-'></span>

<h3>Description</h3>

<p><code>substr</code> and <code>substrl</code> extract
contiguous parts of given character strings.
The former operates based on start and end positions
while the latter is fed with substring lengths.
</p>
<p>Their replacement versions allow for substituting parts of strings
with new content.
</p>
<p><code>gsubstr</code> and <code>gsubstrl</code> allow for extracting or replacing
multiple chunks from each string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>substr(x, start = 1L, stop = -1L)

substrl(
  x,
  start = 1L,
  length = attr(start, "match.length"),
  ignore_negative_length = FALSE
)

substr(x, start = 1L, stop = -1L) &lt;- value

substrl(x, start = 1L, length = attr(start, "match.length")) &lt;- value

gsubstr(x, start = list(1L), stop = list(-1L))

gsubstrl(
  x,
  start = list(1L),
  length = lapply(start, attr, "match.length"),
  ignore_negative_length = TRUE
)

gsubstr(x, start = list(1L), stop = list(-1L)) &lt;- value

gsubstrl(x, start = list(1L), length = lapply(start, attr, "match.length")) &lt;- value

substring(text, first = 1L, last = -1L)

substring(text, first = 1L, last = -1L) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="substr_+3A_x">x</code>, <code id="substr_+3A_text">text</code></td>
<td>
<p>character vector
whose parts are to be extracted/replaced</p>
</td></tr>
<tr><td><code id="substr_+3A_start">start</code>, <code id="substr_+3A_first">first</code></td>
<td>
<p>numeric vector (for <code>substr</code>)
or list of numeric vectors (for <code>gsubstr</code>)
giving the start indexes;
e.g., 1 denotes the first code point;
negative indexes
count from the end of a string, i.e., -1 is the last character</p>
</td></tr>
<tr><td><code id="substr_+3A_stop">stop</code>, <code id="substr_+3A_last">last</code></td>
<td>
<p>numeric vector (for <code>substr</code>)
or list of numeric vectors (for <code>gsubstr</code>)
giving the end indexes (inclusive);
note that if the start position is farther than the
end position, this indicates an empty substring therein (see Examples)</p>
</td></tr>
<tr><td><code id="substr_+3A_length">length</code></td>
<td>
<p>numeric vector  (for <code>substr</code>)
or list of numeric vectors (for <code>gsubstr</code>)
giving the substring lengths;
negative lengths result in a missing value or empty vector
(see <code>ignore_negative_length</code>) or the corresponding
substring being unchanged</p>
</td></tr>
<tr><td><code id="substr_+3A_ignore_negative_length">ignore_negative_length</code></td>
<td>
<p>single logical value;
whether negative lengths should be ignored or yield missing values</p>
</td></tr>
<tr><td><code id="substr_+3A_value">value</code></td>
<td>
<p>character vector  (for <code>substr</code>)
or list of character vectors  (for <code>gsubstr</code>)
defining the replacements strings</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not to be confused with <code><a href="#topic+sub">sub</a></code>.
</p>
<p><code>substring</code> is a [DEPRECATED] synonym for <code>substr</code>.
</p>
<p>Note that these functions can break some meaningful Unicode code point
sequences, e.g., when inputs are not normalised. For extracting
initial parts of strings based on character width, see <code><a href="#topic+strtrim">strtrim</a></code>.
</p>
<p>Note that <code>gsubstr</code> (and related functions) expect
<code>start</code>, <code>stop</code>, <code>length</code>, and <code>value</code>
to be lists. Non-list arguments will be converted by calling
<code><a href="base.html#topic+as.list">as.list</a></code>. This is different from the default policy
applied by <code><a href="stringi.html#topic+stri_sub_all">stri_sub_all</a></code>, which calls
<code><a href="base.html#topic+list">list</a></code>.
</p>
<p>Note that <code>substrl</code> and <code>gsubstrl</code> are
interoperable with <code><a href="#topic+regexpr2">regexpr2</a></code> and <code><a href="#topic+gregexpr2">gregexpr2</a></code>,
respectively, and hence can be considered as substituted for the
[DEPRECATED] <code><a href="base.html#topic+regmatches">regmatches</a></code> (which is more specialised).
</p>


<h3>Value</h3>

<p><code>substr</code> and <code>substrl</code> return a character vector (in UTF-8).
<code>gsubstr</code> and <code>gsubstrl</code> return a list of character vectors.
</p>
<p>Their replacement versions modify <code>x</code> 'in-place' (see Examples).
</p>
<p>The attributes are copied from the longest arguments (similar to
binary operators).
</p>


<h3>Differences from Base R</h3>

<p>Replacements for and enhancements of base <code><a href="base.html#topic+substr">substr</a></code>
and <code><a href="base.html#topic+substring">substring</a></code>
implemented with <code><a href="stringi.html#topic+stri_sub">stri_sub</a></code> and
<code><a href="stringi.html#topic+stri_sub_all">stri_sub_all</a></code>,
</p>

<ul>
<li> <p><code>substring</code> is &quot;for compatibility with S&quot;, but this should
no longer matter
<b>[here, <code>substring</code> is equivalent to <code>substr</code>; in a
future version, using the former may result in a warning]</b>
</p>
</li>
<li> <p><code>substr</code> is not vectorised with respect to all the arguments
(and <code>substring</code> is not fully vectorised wrt <code>value</code>)
<b>[fixed here]</b>
</p>
</li>
<li><p> not all attributes are taken from the longest of the inputs
<b>[fixed here]</b>
</p>
</li>
<li><p> partial recycling with no warning
<b>[fixed here]</b>
</p>
</li>
<li><p> the replacement must be of the same length as the chunk
being substituted <b>[fixed here]</b>
</p>
</li>
<li><p> negative indexes are silently treated as 1
<b>[changed here: negative indexes count from the end of the string]</b>
</p>
</li>
<li><p> replacement of different length than the extracted substring
never changes the length of the string
<b>[changed here &ndash; output length is input length minus
length of extracted plus length of replacement]</b>
</p>
</li>
<li> <p><code><a href="#topic+regexpr">regexpr</a></code> (amongst others) return start positions
and lengths of matches, but base <code>substr</code> only uses
start and end
<b>[fixed by introducing <code>substrl</code>]</b>
</p>
</li>
<li><p> there is no function to extract or replace multiple
chunks in each string (other than <code><a href="base.html#topic+regmatches">regmatches</a></code>
that works on outputs generated by <code><a href="base.html#topic+gregexpr">gregexpr</a></code> et al.)
<b>[fixed by introducing <code>gsubstrl</code>]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+strtrim">strtrim</a></code>, <code><a href="#topic+nchar">nchar</a></code>,
<code><a href="#topic+startsWith">startsWith</a></code>, <code><a href="#topic+endsWith">endsWith</a></code>,
<code><a href="#topic+gregexpr">gregexpr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- "spam, spam, bacon, and spam"
base::substr(x, c(1, 13), c(4, 17))
base::substring(x, c(1, 13), c(4, 17))
substr(x, c(1, 13), c(4, 17))
substrl(x, c(1, 13), c(4, 5))

# replacement function used as an ordinary one - return a copy of x:
base::`substr&lt;-`(x, 1, 4, value="jam")
`substr&lt;-`(x, 1, 4, value="jam")
base::`substr&lt;-`(x, 1, 4, value="porridge")
`substr&lt;-`(x, 1, 4, value="porridge")

# interoperability with gregexpr2:
p &lt;- "[\\w&amp;&amp;[^a]][\\w&amp;&amp;[^n]][\\w&amp;&amp;[^d]]\\w+"  # regex: all words but 'and'
gsubstrl(x, gregexpr2(x, p))
`gsubstrl&lt;-`(x, gregexpr2(x, p), value=list(c("a", "b", "c", "d")))

# replacement function modifying x in-place:
substr(x, 1, 4) &lt;- "eggs"
substr(x, 1, 0) &lt;- "porridge, "        # prepend (start&lt;stop)
substr(x, nchar(x)+1) &lt;- " every day"  # append (start&lt;stop)
print(x)



</code></pre>

<hr>
<h2 id='trimws'>Trim Leading or Trailing Whitespaces</h2><span id='topic+trimws'></span>

<h3>Description</h3>

<p>Removes whitespaces (or other code points as specified by the
<code>whitespace</code> argument) from left, right, or both sides of each string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trimws(x, which = "both", whitespace = "\\p{Wspace}")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trimws_+3A_x">x</code></td>
<td>
<p>character vector
whose elements are to be trimmed</p>
</td></tr>
<tr><td><code id="trimws_+3A_which">which</code></td>
<td>
<p>single string; either <code>"both"</code>, <code>"left"</code>,
or <code>"right"</code>; side(s) from which the code points matching
the <code>whitespace</code> pattern are to be removed</p>
</td></tr>
<tr><td><code id="trimws_+3A_whitespace">whitespace</code></td>
<td>
<p>single string; specifies the set of Unicode code points
for removal, see 'Character Classes' in
<a href="stringi.html#topic+about_search_regex">about_search_regex</a> for more details</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not to be confused with <code><a href="#topic+strtrim">strtrim</a></code>.
</p>


<h3>Value</h3>

<p>Returns a character vector (in UTF-8).
</p>


<h3>Differences from Base R</h3>

<p>Replacement for base <code><a href="base.html#topic+trimws">trimws</a></code>
implemented with <code><a href="stringi.html#topic+stri_replace_all_regex">stri_replace_all_regex</a></code>
(and not <code><a href="stringi.html#topic+stri_trim">stri_trim</a></code>, which uses a slightly different
syntax for pattern specifiers).
</p>

<ul>
<li><p> the default <code>whitespace</code> argument does not reflect the
'contemporary' definition of whitespaces
(e.g., does not include zero-width spaces)
<b>[fixed here]</b>
</p>
</li>
<li><p> base R implementation is not portable as it is based on
the system PCRE library
(e.g., some Unicode classes may not be available or matching thereof
can depend on the current <code>LC_CTYPE</code> category)
<b>[fixed here]</b>
</p>
</li>
<li><p> no sanity checks are performed on <code>whitespace</code>
<b>[fixed here]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+sub">sub</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>base::trimws("NAAAAANA!!!NANAAAAA", whitespace=NA)  # stringx raises an error
x &lt;- "   :)\v\u00a0 \n\r\t"
base::trimws(x)
stringx::trimws(x)

</code></pre>

<hr>
<h2 id='xtfrm2'>Sort Strings</h2><span id='topic+xtfrm2'></span><span id='topic+xtfrm2.default'></span><span id='topic+xtfrm2.character'></span><span id='topic+xtfrm'></span><span id='topic+xtfrm.default'></span><span id='topic+xtfrm.character'></span><span id='topic+sort.character'></span>

<h3>Description</h3>

<p>The <code>sort</code> method for objects of class <code>character</code>
(<code>sort.character</code>) uses the locale-sensitive Unicode collation
algorithm to arrange strings in a vector with regards to a
chosen lexicographic order.
</p>
<p><code>xtfrm2</code> and [DEPRECATED] <code>xtfrm</code> generate an integer vector
that sort in the same way as its input, and hence can be used
in conjunction with <code><a href="base.html#topic+order">order</a></code> or <code><a href="base.html#topic+rank">rank</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xtfrm2(x, ...)

## Default S3 method:
xtfrm2(x, ...)

## S3 method for class 'character'
xtfrm2(
  x,
  ...,
  locale = NULL,
  strength = 3L,
  alternate_shifted = FALSE,
  french = FALSE,
  uppercase_first = NA,
  case_level = FALSE,
  normalisation = FALSE,
  numeric = FALSE
)

xtfrm(x)

## Default S3 method:
xtfrm(x)

## S3 method for class 'character'
xtfrm(x)

## S3 method for class 'character'
sort(
  x,
  ...,
  decreasing = FALSE,
  na.last = NA,
  locale = NULL,
  strength = 3L,
  alternate_shifted = FALSE,
  french = FALSE,
  uppercase_first = NA,
  case_level = FALSE,
  normalisation = FALSE,
  numeric = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="xtfrm2_+3A_x">x</code></td>
<td>
<p>character vector whose elements are to be sorted</p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_...">...</code></td>
<td>
<p>further arguments passed to other methods</p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_locale">locale</code></td>
<td>
<p><code>NULL</code> or <code>""</code> for the default locale
(see <code><a href="stringi.html#topic+stri_locale_get">stri_locale_get</a></code>)
or a single string with a locale identifier,
see <code><a href="stringi.html#topic+stri_locale_list">stri_locale_list</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_strength">strength</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_alternate_shifted">alternate_shifted</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_french">french</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_uppercase_first">uppercase_first</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_case_level">case_level</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_normalisation">normalisation</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_numeric">numeric</code></td>
<td>
<p>see <code><a href="stringi.html#topic+stri_opts_collator">stri_opts_collator</a></code></p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_decreasing">decreasing</code></td>
<td>
<p>single logical value; if <code>FALSE</code>, the ordering
is nondecreasing (weakly increasing)</p>
</td></tr>
<tr><td><code id="xtfrm2_+3A_na.last">na.last</code></td>
<td>
<p>single logical value; if <code>TRUE</code>, then missing values
are placed at the end; if <code>FALSE</code>, they are put at the beginning;
if <code>NA</code>, then they are removed from the output whatsoever.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>What 'xtfrm' stands for the current author does not know,
but would appreciate someone's enlightening him.
</p>


<h3>Value</h3>

<p><code>sort.character</code> returns a character vector, with only
the <code>names</code> attribute preserved. Note that the output vector
may be shorter than the input one.
</p>
<p><code>xtfrm2.character</code> and <code>xtfrm.character</code> return an integer vector;
most attributes are preserved.
</p>


<h3>Differences from Base R</h3>

<p>Replacements for the default S3 methods <code><a href="base.html#topic+sort">sort</a></code>
and <code><a href="base.html#topic+xtfrm">xtfrm</a></code> for character vectors
implemented with <code><a href="stringi.html#topic+stri_sort">stri_sort</a></code>
and <code><a href="stringi.html#topic+stri_rank">stri_rank</a></code>.
</p>

<ul>
<li><p> Collation in different locales is difficult and non-portable across
platforms
<b>[fixed here &ndash; using services provided by ICU]</b>
</p>
</li>
<li><p> Overloading <code>xtfrm.character</code> has no effect in R, because S3
method dispatch is done internally with hard-coded support for
character arguments. Thus, we needed to replace the generic
<code>xtfrm</code> with the one that calls <code><a href="base.html#topic+UseMethod">UseMethod</a></code>
<b>[fixed here]</b>
</p>
</li>
<li> <p><code>xtfrm</code> does not support customisation of the linear ordering
relation it is based upon
<b>[fixed by introducing <code>...</code> argument to the new
generic, <code>xtfrm2</code>]</b>
</p>
</li>
<li><p> Neither <code><a href="base.html#topic+order">order</a></code>, <code><a href="base.html#topic+rank">rank</a></code>, nor
<code><a href="base.html#topic+sort.list">sort.list</a></code> is a generic, therefore
they should have to be rewritten from scratch to allow the inclusion of
our patches; interestingly, <code>order</code> even calls <code>xtfrm</code>,
but only for classed objects
<b>[not fixed here &ndash; see Examples for a workaround]</b>
</p>
</li>
<li> <p><code>xtfrm</code> for objects of type <code>character</code>
does not preserve the names attribute (but does so for <code>numeric</code>)
<b>[fixed here]</b>
</p>
</li>
<li> <p><code>sort</code> seems to preserve only the names attribute
which makes sense if <code>na.last</code> is <code>NA</code>, because the resulting
vector might be shorter
<b>[not fixed here as it would break compatibility with other
sorting methods]</b>
</p>
</li>
<li><p> Note that <code>sort</code> by default removes missing values whatsoever,
whereas <code><a href="base.html#topic+order">order</a></code> has <code>na.last=TRUE</code>
<b>[not fixed here as it would break compatibility with other
sorting methods]</b>
</p>
</li></ul>



<h3>Author(s)</h3>

<p><a href="https://www.gagolewski.com/">Marek Gagolewski</a>
</p>


<h3>See Also</h3>

<p>The official online manual of <span class="pkg">stringx</span> at <a href="https://stringx.gagolewski.com/">https://stringx.gagolewski.com/</a>
</p>
<p>Related function(s): <code><a href="#topic+strcoll">strcoll</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("a1", "a100", "a101", "a1000", "a10", "a10", "a11", "a99", "a10", "a1")
base::sort.default(x)   # lexicographic sort
sort(x, numeric=TRUE)   # calls stringx:::sort.character
xtfrm2(x, numeric=TRUE)  # calls stringx:::xtfrm2.character

rank(xtfrm2(x, numeric=TRUE), ties.method="average")  # ranks with averaged ties
order(xtfrm2(x, numeric=TRUE))    # ordering permutation
x[order(xtfrm2(x, numeric=TRUE))] # equivalent to sort()

# order a data frame w.r.t. decreasing ids and increasing vals
d &lt;- data.frame(vals=round(runif(length(x)), 1), ids=x)
d[order(-xtfrm2(d[["ids"]], numeric=TRUE), d[["vals"]]), ]


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
