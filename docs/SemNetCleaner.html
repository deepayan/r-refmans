<!DOCTYPE html><html lang="en"><head><title>Help for package SemNetCleaner</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SemNetCleaner}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SemNetCleaner-package'><p>SemNetCleaner&ndash;package</p></a></li>
<li><a href='#bad.response'><p>Bad Responses to NA</p></a></li>
<li><a href='#best.guess'><p>Makes Best Guess for Spelling Correction</p></a></li>
<li><a href='#bin2resp'><p>Binary Responses to Character Responses</p></a></li>
<li><a href='#convert2snafu'><p>Pathfinder Network</p></a></li>
<li><a href='#correct.changes'><p>Correct Changes from <code>textcleaner</code></p></a></li>
<li><a href='#letter.freq'><p>Letter Frequencies Based on 40,000 Words</p></a></li>
<li><a href='#open.animals'><p>Openness and Verbal Fluency</p></a></li>
<li><a href='#open.clean'><p>Cleaned Response Matrices (Openness and Verbal Fluency)</p></a></li>
<li><a href='#open.preprocess'><p>Preprocessed <code>textcleaner</code> Object (Openness and Verbal Fluency)</p></a></li>
<li><a href='#pluralize'><p>Converts Words to their Plural Form</p></a></li>
<li><a href='#qwerty.dist'><p>QWERTY Distance for Same Length Words</p></a></li>
<li><a href='#read.data'><p>Read in Common Data File Extensions</p></a></li>
<li><a href='#resp2bin'><p>Responses to binary matrix</p></a></li>
<li><a href='#singularize'><p>Converts Words to their Singular Form</p></a></li>
<li><a href='#textcleaner'><p>Text Cleaner</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>An Automated Cleaning Tool for Semantic and Linguistic Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-09-14</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexander P. Christensen &lt;alexpaulchristensen@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements several functions that automates the cleaning and spell-checking of text data. Also converges, finalizes, removes plurals and continuous strings, and puts text data in binary format for semantic network analysis. Uses the 'SemNetDictionaries' package to make the cleaning process more accurate, efficient, and reproducible.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3.0)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/AlexChristensen/SemNetCleaner">https://github.com/AlexChristensen/SemNetCleaner</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/AlexChristensen/SemNetCleaner/issues">https://github.com/AlexChristensen/SemNetCleaner/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0), SemNetDictionaries (&ge; 0.1.8)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stringdist, searcher, tcltk, foreign, readxl, R.matlab,
stringi, rstudioapi, easycsv, shiny, editData, miniUI</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, htmlTable, markdown, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-16 13:46:18 UTC; apchr</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexander P. Christensen
    <a href="https://orcid.org/0000-0002-9798-7037"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-16 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='SemNetCleaner-package'>SemNetCleaner&ndash;package</h2><span id='topic+SemNetCleaner'></span><span id='topic+SemNetCleaner-package'></span>

<h3>Description</h3>

<p>Implements several functions that automates the cleaning and
spell-checking of text data. Also converges, finalizes, removes plurals and
continuous strings, and puts text data in binary format for semantic network analysis.
Uses the <code><a href="SemNetDictionaries.html#topic+SemNetDictionaries">SemNetDictionaries</a></code> package to make
the cleaning process more accurate, efficient, and reproducible.
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/AlexChristensen/SemNetCleaner">https://github.com/AlexChristensen/SemNetCleaner</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/AlexChristensen/SemNetCleaner/issues">https://github.com/AlexChristensen/SemNetCleaner/issues</a>
</p>
</li></ul>


<hr>
<h2 id='bad.response'>Bad Responses to NA</h2><span id='topic+bad.response'></span>

<h3>Description</h3>

<p>A wrapper function to determine whether responses are good or bad.
Bad responses are replaced with missing (<code>NA</code>). Good responses are returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bad.response(word, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bad.response_+3A_word">word</code></td>
<td>
<p>Character.
A word to be tested for whether it is bad</p>
</td></tr>
<tr><td><code id="bad.response_+3A_...">...</code></td>
<td>
<p>Vector.
Additional responses to be considered bad</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If response is bad, then returns <code>NA</code>.
If response is valid, then returns the response
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Bad response
bad.response(word = " ")

# Good response
bad.response(word = "hello")

# Make a good response bad
bad.response(word = "hello","hello")

# Add additional bad responses
bad.response(word = "hello", c("hello","world"))

</code></pre>

<hr>
<h2 id='best.guess'>Makes Best Guess for Spelling Correction</h2><span id='topic+best.guess'></span>

<h3>Description</h3>

<p>A wrapper function for the best guess of a spelling mistake
based on the letters, the ordering of those letters, and the potential
for letters to be interchanged. The
<a href="https://en.wikipedia.org/wiki/Damerau-Levenshtein_distance">Damerau-Levenshtein distance</a>
is used to guide inferences into what word the participant was trying to spell from a dictionary
(see <code><a href="SemNetDictionaries.html#topic+SemNetDictionaries">SemNetDictionaries</a></code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>best.guess(word, full.dictionary, dictionary = NULL, tolerance = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="best.guess_+3A_word">word</code></td>
<td>
<p>Character.
A word to get best guess spelling options from dictionary</p>
</td></tr>
<tr><td><code id="best.guess_+3A_full.dictionary">full.dictionary</code></td>
<td>
<p>Character vector.
The dictionary to search for best guesses in.
See <code><a href="SemNetDictionaries.html#topic+SemNetDictionaries">SemNetDictionaries</a></code></p>
</td></tr>
<tr><td><code id="best.guess_+3A_dictionary">dictionary</code></td>
<td>
<p>Character.
A dictionary from <code><a href="SemNetDictionaries.html#topic+SemNetDictionaries">SemNetDictionaries</a></code> for monikers (enhances guessing)</p>
</td></tr>
<tr><td><code id="best.guess_+3A_tolerance">tolerance</code></td>
<td>
<p>Numeric.
The distance tolerance set for automatic spell-correction purposes.
This function uses the function <code><a href="stringdist.html#topic+stringdist">stringdist</a></code>
to compute the Damerau-Levenshtein distance, which is used to determine potential best guesses
</p>
<p>Unique words (i.e., <em>n</em> = 1) that are within the (distance) tolerance are
automatically output as best guess responses. This default is based on Damerau's (1964)
proclamation that more than 80% of all human misspellings can be expressed by a single error
(e.g., insertion, deletion, substitution, and transposition). If there is more than one word
that is within or below the distance tolerance, then these will be provided as potential
options.
</p>
<p>The recommended and default distance tolerance is <code>tolerance = 1</code>,
which only spell corrects a word if there is only one word with a DL distance of 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The best guess(es) of the word
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>References</h3>

<p>Damerau, F. J. (1964).
A technique for computer detection and correction of spelling errors.
<em>Communications of the ACM</em>, <em>7</em>, 171-176.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Misspelled "bombay"
best.guess("bomba", full.dictionary = SemNetDictionaries::animals.dictionary)

</code></pre>

<hr>
<h2 id='bin2resp'>Binary Responses to Character Responses</h2><span id='topic+bin2resp'></span>

<h3>Description</h3>

<p>Converts the binary response matrix into characters for each participant
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bin2resp(rmat, to.data.frame = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bin2resp_+3A_rmat">rmat</code></td>
<td>
<p>Binary matrix.
A binarized response matrix of verbal fluency or linguistic data</p>
</td></tr>
<tr><td><code id="bin2resp_+3A_to.data.frame">to.data.frame</code></td>
<td>
<p>Boolean.
Should output be a data frame where participants are columns?
Defaults to <code>FALSE</code>.
Set to <code>TRUE</code> to convert output to data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing objects for each participant and their responses
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Toy example
raw &lt;- open.animals[c(1:10),-c(1:3)]

if(interactive())
{
  # Clean and prepocess data
  clean &lt;- textcleaner(open.animals[,-c(1:2)], partBY = "row", dictionary = "animals")

  # Change binary response matrix to word response matrix
  charmat &lt;- bin2resp(clean$responses$binary)
}

</code></pre>

<hr>
<h2 id='convert2snafu'>Pathfinder Network</h2><span id='topic+convert2snafu'></span>

<h3>Description</h3>

<p>Estimates a pathfinder network using the MST-Pathfinder
Network method from Quirin et al. (2008; see also Schvaneveldt, 1990)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert2snafu(..., category)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert2snafu_+3A_...">...</code></td>
<td>
<p>Matrix or data frame.
A clean response matrices</p>
</td></tr>
<tr><td><code id="convert2snafu_+3A_category">category</code></td>
<td>
<p>Character.
Category of verbal fluency data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The format of the file has 7 columns:
</p>

<ul>
<li><p>idDefaults to the row names of the inputted <code>data</code>
</p>
</li>
<li><p>listnumThe list number for the fluency category. Defaults to 0.
Future implementations will allow more lists
</p>
</li>
<li><p>categoryThe verbal fluency category that is input into the
<code>category</code> argument
</p>
</li>
<li><p>itemThe verbal fluency responses for every participant
</p>
</li>
<li><p>RTResponse time. Currently not implemented. Defaults to 0
</p>
</li>
<li><p>RTstartStart of response time. Currently not implemented. Defaults to 0
</p>
</li>
<li><p>groupNames of groups. Defaults to the names of the objects input into
the function (<code>...</code>)
</p>
</li></ul>



<h3>Value</h3>

<p>A .csv file formatted for SNAFU
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>References</h3>

<p># For SNAFU, see:
Zemla, J. C., Cao, K., Mueller, K. D., &amp; Austerweil, J. L. (2020).
SNAFU: The Semantic Network and Fluency Utility.
<em>Behavior Research Methods</em>, 1-19.
https://doi.org/10.3758/s13428-019-01343-w
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Convert data to SNAFU
if(interactive())
{convert2snafu(open.clean, category = "animals")}

</code></pre>

<hr>
<h2 id='correct.changes'>Correct Changes from <code><a href="#topic+textcleaner">textcleaner</a></code></h2><span id='topic+correct.changes'></span>

<h3>Description</h3>

<p>A function that corrects changes that were made
automatically by <code><a href="#topic+textcleaner">textcleaner</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correct.changes(textcleaner.obj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="correct.changes_+3A_textcleaner.obj">textcleaner.obj</code></td>
<td>
<p>Object from <code><a href="#topic+textcleaner">textcleaner</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the corrected lists from <code><a href="#topic+textcleaner">textcleaner</a></code>s:
</p>
<table role = "presentation">
<tr><td><code>binary</code></td>
<td>
<p>A matrix of responses where each row represents a participant
and each column represents a unique response. A response that a participant has provided is a '<code>1</code>'
and a response that a participant has not provided is a '<code>0</code>'</p>
</td></tr>
<tr><td><code>responses</code></td>
<td>
<p>A list containing two objects:
</p>

<ul>
<li><p>clean
A response matrix that has been spell-checked and de-pluralized with duplicates removed.
This can be used as a final dataset for analyses (e.g., fluency of responses)
</p>
</li>
<li><p>original
The original response matrix that has had white spaces before and
after words response. Also converts all upper-case letters to lower case
</p>
</li></ul>

</td></tr>
<tr><td><code>spellcheck</code></td>
<td>
<p>A list containing three objects:
</p>

<ul>
<li><p><code>full</code>
All responses regardless of spell-checking changes
</p>
</li>
<li><p><code>auto</code>
Only the incorrect responses that were changed during spell-check
</p>
</li>
<li><p><code>changes</code>
Only the changes made within the function <code><a href="#topic+correct.changes">correct.changes</a></code>
</p>
</li></ul>

</td></tr>
<tr><td><code>removed</code></td>
<td>
<p>A list containing two objects: 
</p>

<ul>
<li><p><code>rows</code>
Identifies removed participants by their row (or column) location in the original data file
</p>
</li>
<li><p><code>ids</code>
Identifies removed participants by their ID (see argument <code>data</code>)
</p>
</li></ul>

</td></tr>
<tr><td><code>partChanges</code></td>
<td>
<p>A list where each participant is a list index with each
response that was been changed. Participants are identified by their ID (see argument <code>data</code>).
This can be used to replicate the cleaning process and to keep track of changes more generally.
Participants with <code>NA</code> did not have any changes from their original data
and participants with missing data are removed (see <code>removed$ids</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Toy example
raw &lt;- open.animals[c(1:10),-c(1:3)]

if(interactive())
{
    #Full test
    clean &lt;- textcleaner(open.animals[,-c(1,2)], partBY = "row", dictionary = "animals")
}

</code></pre>

<hr>
<h2 id='letter.freq'>Letter Frequencies Based on 40,000 Words</h2><span id='topic+letter.freq'></span>

<h3>Description</h3>

<p>A vector corresponding the frequency of letters across 40,000 words.
Retrieved from: http://pi.math.cornell.edu/~mec/2003-2004/cryptography/subs/frequencies.html
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(letter.freq)
</code></pre>


<h3>Format</h3>

<p>letter.freq (26-element numeric vector)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("letter.freq")
</code></pre>

<hr>
<h2 id='open.animals'>Openness and Verbal Fluency</h2><span id='topic+open.animals'></span>

<h3>Description</h3>

<p>Raw Animals verbal fluency data (<em>n</em> = 516) from Christensen et al. (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(open.animals)
</code></pre>


<h3>Format</h3>

<p>open.animals (matrix 516 x 38)
</p>


<h3>Details</h3>

<p>First column is a grouping variable (<code>"Group"</code>) with <code>1</code> corresponding
to low openness to experience and <code>2</code> to high openness to experience
</p>
<p>Second column is the latent variable of openness to experience with Intellect items removed
(see Christensen et al., 2018 for more details).
</p>
<p>Third column is the ID variable for each participant.
</p>
<p>Columns 4-38 are raw fluency data.
</p>


<h3>References</h3>

<p>Christensen, A. P., Kenett, Y. N., Cotter, K. N., Beaty, R. E., &amp; Silvia, P. J. (2018).
Remotely close associations: Openness to experience and semantic memory structure.
<em>European Journal of Personality</em>, <em>32</em>, 480-492.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("open.animals")
</code></pre>

<hr>
<h2 id='open.clean'>Cleaned Response Matrices (Openness and Verbal Fluency)</h2><span id='topic+open.clean'></span>

<h3>Description</h3>

<p>Cleaned response matrices for the Animals verbal fluency data (<em>n</em> = 516)
from Christensen et al. (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(open.clean)
</code></pre>


<h3>Format</h3>

<p>open.clean (matrix, 516 x 35)
</p>


<h3>References</h3>

<p>Christensen, A. P., Kenett, Y. N., Cotter, K. N., Beaty, R. E., &amp; Silvia, P. J. (2018).
Remotely close associations: Openness to experience and semantic memory structure.
<em>European Journal of Personality</em>, <em>32</em>, 480-492.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("open.clean")
</code></pre>

<hr>
<h2 id='open.preprocess'>Preprocessed <code><a href="#topic+textcleaner">textcleaner</a></code> Object (Openness and Verbal Fluency)</h2><span id='topic+open.preprocess'></span>

<h3>Description</h3>

<p>Preprocessed <code><a href="#topic+textcleaner">textcleaner</a></code> object for the Animals verbal fluency data (<em>n</em> = 516)
from Christensen and Kenett (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(open.preprocess)
</code></pre>


<h3>Format</h3>

<p>open.preprocess (list, length = 4)
</p>


<h3>References</h3>

<p>Christensen, A. P., &amp; Kenett, Y. N. (2020).
Semantic network analysis (SemNA): A tutorial on preprocessing, estimating, and analyzing semantic networks.
<em>PsyArxiv</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("open.preprocess")
</code></pre>

<hr>
<h2 id='pluralize'>Converts Words to their Plural Form</h2><span id='topic+pluralize'></span>

<h3>Description</h3>

<p>A function to change words to their plural form.
The rules for converting words to their plural forms
are based on the grammar rules found here:
<a href="https://www.grammarly.com/blog/plural-nouns/">https://www.grammarly.com/blog/plural-nouns/</a>.
This function handles most special cases and some irregular cases (see examples)
but caution is necessary. If no plural form is identified, then the original
word is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pluralize(word)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pluralize_+3A_word">word</code></td>
<td>
<p>A word</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the word in singular form, unless a plural form
could not be found (then the original word is returned)
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Handles any prototypical cases
"dogs"
pluralize("dog")

"foxes"
pluralize("fox")

"wolves"
pluralize("wolf")

"octopi"
pluralize("octopus")

"taxa"
pluralize("taxon")

# And most special cases:
"wives"
pluralize("wife")

"roofs"
pluralize("roof")

"photos"
pluralize("photo")

# And some irregular cases:
"children"
pluralize("child")

"teeth"
pluralize("tooth")

"mice"
pluralize("mouse")

</code></pre>

<hr>
<h2 id='qwerty.dist'>QWERTY Distance for Same Length Words</h2><span id='topic+qwerty.dist'></span>

<h3>Description</h3>

<p>Computes QWERTY Distance for words that have
the same number of characters. Distance is computed based on
the number of keys a character is away from another character
on a QWERTY keyboard
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qwerty.dist(wordA, wordB)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qwerty.dist_+3A_worda">wordA</code></td>
<td>
<p>Character vector.
Word to be compared</p>
</td></tr>
<tr><td><code id="qwerty.dist_+3A_wordb">wordB</code></td>
<td>
<p>Character vector.
Word to be compared</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric value for distance between <code>wordA</code> and <code>wordB</code>
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Identical values for Damerau-Levenshtein 
stringdist::stringdist("big", "pig", method="dl")

stringdist::stringdist("big", "bug", method="dl")

#Different distances for QWERTY
qwerty.dist("big", "pig")

qwerty.dist("big", "bug") # Probably meant to type "bug" 

</code></pre>

<hr>
<h2 id='read.data'>Read in Common Data File Extensions</h2><span id='topic+read.data'></span>

<h3>Description</h3>

<p>A single function to read in common data file extensions.
Note that this function is specialized for reading in text data in the
format necessary for functions in SemNetCleaner
</p>
<p>File extensions supported:
</p>

<ul>
<li><p>.Rdata </p>
</li>
<li><p>.rds </p>
</li>
<li><p>.csv </p>
</li>
<li><p>.xlsx
</p>
</li>
<li><p>.xls </p>
</li>
<li><p>.sav </p>
</li>
<li><p>.txt </p>
</li>
<li><p>.mat </p>
</li>
<li><p>.dat
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>read.data(file = file.choose(), header = TRUE, sep = ",", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.data_+3A_file">file</code></td>
<td>
<p>Character.
A path to the file to load.
Defaults to interactive file selection using <code><a href="base.html#topic+file.choose">file.choose</a></code></p>
</td></tr>
<tr><td><code id="read.data_+3A_header">header</code></td>
<td>
<p>Boolean.
A logical value indicating whether the file contains the
names of the variables as its first line.
If missing, the value is determined from the file format:
header is set to <code>TRUE</code> if and only if the first row
contains one fewer field than the number of columns</p>
</td></tr>
<tr><td><code id="read.data_+3A_sep">sep</code></td>
<td>
<p>Character.
The field separator character.
Values on each line of the file are separated by this character.
If sep = &quot;&quot; (the default for <code><a href="utils.html#topic+read.table">read.table</a></code>) the separator
is a 'white space', that is one or more spaces, tabs, newlines or
carriage returns</p>
</td></tr>
<tr><td><code id="read.data_+3A_...">...</code></td>
<td>
<p>Additional arguments.
Allows for additional arguments to be passed onto
the respective read functions. See documentation in the list below:
</p>

<ul>
<li><p>.Rdata
<code><a href="base.html#topic+load">load</a></code>
</p>
</li>
<li><p>.rds
<code><a href="base.html#topic+readRDS">readRDS</a></code>
</p>
</li>
<li><p>.csv
<code><a href="utils.html#topic+read.table">read.table</a></code>
</p>
</li>
<li><p>.xlsx
<code><a href="readxl.html#topic+read_excel">read_excel</a></code>
</p>
</li>
<li><p>.xls
<code><a href="readxl.html#topic+read_excel">read_excel</a></code>
</p>
</li>
<li><p>.sav
<code><a href="foreign.html#topic+read.spss">read.spss</a></code>
</p>
</li>
<li><p>.txt
<code><a href="utils.html#topic+read.table">read.table</a></code>
</p>
</li>
<li><p>.mat
<code><a href="R.matlab.html#topic+readMat">readMat</a></code>
</p>
</li>
<li><p>.dat
<code><a href="utils.html#topic+read.table">read.table</a></code>
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing a representation of the data in the file.
If file extension is &quot;.Rdata&quot;, then data will be read to the global environment
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>References</h3>

<p># R Core Team
</p>
<p>R Core Team (2019). R: A language and environment for
statistical computing. R Foundation for Statistical Computing,
Vienna, Austria. URL https://www.R-project.org/.
</p>
<p># readxl
</p>
<p>Hadley Wickham and Jennifer Bryan (2019). readxl: Read Excel
Files. R package version 1.3.1.
https://CRAN.R-project.org/package=readxl
</p>
<p># R.matlab
</p>
<p>Henrik Bengtsson (2018). R.matlab: Read and Write MAT Files
and Call MATLAB from Within R. R package version 3.6.2.
https://CRAN.R-project.org/package=R.matlab
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use this example for your data
if(interactive())
{read.data()}

# Example for CRAN tests
## Create test data
test1 &lt;- c(1:5, "6,7", "8,9,10")

## Path to temporary file
tf &lt;- tempfile()

## Create test file
writeLines(test1, tf)

## Read in data
read.data(tf)

# See documentation of respective R functions for specific examples

</code></pre>

<hr>
<h2 id='resp2bin'>Responses to binary matrix</h2><span id='topic+resp2bin'></span>

<h3>Description</h3>

<p>Converts the response matrix to binary response matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resp2bin(resp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resp2bin_+3A_resp">resp</code></td>
<td>
<p>Response matrix.
A response matrix of verbal fluency or linguistic data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing objects for each participant and their responses
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Toy example
raw &lt;- open.animals[c(1:10),-c(1:3)]

if(interactive())
{
  # Clean and prepocess data
  clean &lt;- textcleaner(open.animals[,-c(1:2)], partBY = "row", dictionary = "animals")

  # Change response matrix to binary response matrix
  binmat &lt;- resp2bin(clean$responses$corrected)
}

</code></pre>

<hr>
<h2 id='singularize'>Converts Words to their Singular Form</h2><span id='topic+singularize'></span>

<h3>Description</h3>

<p>A function to change words to their singular form.
The rules for converting words to their singular forms
are based on the <strong><em>inverse</em></strong> of the grammar rules found here:
<a href="https://www.grammarly.com/blog/plural-nouns/">https://www.grammarly.com/blog/plural-nouns/</a>.
This function handles most special cases and some irregular cases (see examples)
but caution is necessary. If no singular form is identified, then the original
word is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singularize(word, dictionary = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="singularize_+3A_word">word</code></td>
<td>
<p>Character.
A word</p>
</td></tr>
<tr><td><code id="singularize_+3A_dictionary">dictionary</code></td>
<td>
<p>Boolean.
Should dictionary be used to verify word exists?
Default to <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the word in singular form, unless a singular form
could not be found (then the original word is returned)
</p>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Handles any prototypical cases
# "dog"
singularize("dogs")

# "fox"
singularize("foxes")

# "wolf"
singularize("wolves")

# "octopus"
singularize("octopi")

# "taxon"
singularize("taxa")

# And most special cases:
# "wife"
singularize("wives")

# "fez"
singularize("fezzes")

# "roof"
singularize("roofs")

# "photo"
singularize("photos")

# And some irregular cases:
# "child"
singularize("children")

# "tooth"
singularize("teeth")

# "mouse"
singularize("mice")

</code></pre>

<hr>
<h2 id='textcleaner'>Text Cleaner</h2><span id='topic+textcleaner'></span>

<h3>Description</h3>

<p>An automated cleaning function for spell-checking, de-pluralizing,
removing duplicates, and binarizing text data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textcleaner(
  data = NULL,
  miss = 99,
  partBY = c("row", "col"),
  dictionary = NULL,
  spelling = c("UK", "US"),
  add.path = NULL,
  keepStrings = FALSE,
  allowPunctuations = c("-", "all"),
  allowNumbers = FALSE,
  lowercase = TRUE,
  continue = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textcleaner_+3A_data">data</code></td>
<td>
<p>Matrix or data frame.
A dataset of text data.
Participant IDs will be automatically identified if they are included.
If no IDs are provided, then their order in the corresponding
row (or column is used). A message will notify the user how IDs were assigned</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_miss">miss</code></td>
<td>
<p>Numeric or character.
Value for missing data.
Defaults to <code>99</code></p>
</td></tr>
<tr><td><code id="textcleaner_+3A_partby">partBY</code></td>
<td>
<p>Character.
Are participants by row or column?
Set to <code>"row"</code> for by row.
Set to <code>"col"</code> for by column</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_dictionary">dictionary</code></td>
<td>
<p>Character vector.
Can be a vector of a corpus or any text for comparison.
Dictionary to be used for more efficient text cleaning.
Defaults to <code>NULL</code>, which will use <code><a href="SemNetDictionaries.html#topic+general.dictionary">general.dictionary</a></code>
</p>
<p>Use <code>dictionaries()</code> or <code>find.dictionaries()</code> for more options
(See <code><a href="SemNetDictionaries.html#topic+SemNetDictionaries">SemNetDictionaries</a></code> for more details)</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_spelling">spelling</code></td>
<td>
<p>Character vector.
English spelling to be used.
</p>

<ul>
<li><p><code>"UK"</code>
For British spelling (e.g., colour, grey, programme, theatre)
</p>
</li>
<li><p><code>"US"</code>
For American spelling (e.g., color, gray, program, theater)
</p>
</li></ul>
</td></tr>
<tr><td><code id="textcleaner_+3A_add.path">add.path</code></td>
<td>
<p>Character.
Path to additional dictionaries to be found.
DOES NOT search recursively (through all folders in path)
to avoid time intensive search.
Set to <code>"choose"</code> to open an interactive directory explorer</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_keepstrings">keepStrings</code></td>
<td>
<p>Boolean.
Should strings be retained or separated?
Defaults to <code>FALSE</code>.
Set to <code>TRUE</code> to retain strings as strings</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_allowpunctuations">allowPunctuations</code></td>
<td>
<p>Character vector.
Allows punctuation characters to be included in responses.
Defaults to <code>"-"</code>.
Set to <code>"all"</code> to keep all punctuation characters</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_allownumbers">allowNumbers</code></td>
<td>
<p>Boolean.
Defaults to <code>FALSE</code>.
Set to <code>TRUE</code> to keep numbers in text</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_lowercase">lowercase</code></td>
<td>
<p>Boolean.
Should words be converted to lowercase?
Defaults to <code>TRUE</code>.
Set to <code>FALSE</code> to keep words as they are</p>
</td></tr>
<tr><td><code id="textcleaner_+3A_continue">continue</code></td>
<td>
<p>List.
A result previously unfinished that still needs to be completed.
Allows you to continue to manually spell-check their data
after you've closed or errored out.
Defaults to <code>NULL</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a list containing the following objects:
</p>
<table role = "presentation">
<tr><td><code>binary</code></td>
<td>
<p>A matrix of responses where each row represents a participant
and each column represents a unique response. A response that a participant has provided is a '<code>1</code>'
and a response that a participant has not provided is a '<code>0</code>'</p>
</td></tr>
<tr><td><code>responses</code></td>
<td>
<p>A list containing two objects:
</p>

<ul>
<li><p><code>clean</code>
A response matrix that has been spell-checked and de-pluralized with duplicates removed.
This can be used as a final dataset for analyses (e.g., fluency of responses)
</p>
</li>
<li><p><code>original</code>
The original response matrix that has had white spaces before and
after words response. Also converts all upper-case letters to lower case
</p>
</li></ul>

</td></tr>
<tr><td><code>spellcheck</code></td>
<td>
<p>A list containing three objects:
</p>

<ul>
<li><p><code>full</code>
All responses regardless of spell-checking changes
</p>
</li>
<li><p><code>auto</code>
Only the incorrect responses that were changed during spell-check
</p>
</li></ul>

</td></tr>
<tr><td><code>removed</code></td>
<td>
<p>A list containing two objects: 
</p>

<ul>
<li><p><code>rows</code>
Identifies removed participants by their row (or column) location in the original data file
</p>
</li>
<li><p><code>ids</code>
Identifies removed participants by their ID (see argument <code>data</code>)
</p>
</li></ul>

</td></tr>
<tr><td><code>partChanges</code></td>
<td>
<p>A list where each participant is a list index with each
response that was been changed. Participants are identified by their ID (see argument <code>data</code>).
This can be used to replicate the cleaning process and to keep track of changes more generally.
Participants with <code>NA</code> did not have any changes from their original data
and participants with missing data are removed (see <code>removed$ids</code>)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alexander Christensen &lt;alexpaulchristensen@gmail.com&gt;
</p>


<h3>References</h3>

<p>Hornik, K., &amp; Murdoch, D. (2010).
Watch Your Spelling!.
<em>The R Journal</em>, <em>3</em>, 22-28.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Toy example
raw &lt;- open.animals[c(1:10),-c(1:3)]

if(interactive())
{
    #Full test
    clean &lt;- textcleaner(open.animals[,-c(1,2)], partBY = "row", dictionary = "animals")
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
