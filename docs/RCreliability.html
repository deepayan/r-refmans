<!DOCTYPE html><html><head><title>Help for package RCreliability</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RCreliability}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RCreliability.ex'><p>RCreliability.ex</p></a></li>
<li><a href='#RCreliability.in'><p>RCreliability.in</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Correct Bias in Estimated Regression Coefficients</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>This function corrects the bias in estimated regression coefficients due to classical additive measurement error (i.e., within-person variation) in logistic regressions under the main study/external reliability study design and the main study/internal reliability study design. The output includes the naive and corrected estimators for the regression coefficients; for the variance estimates of the corrected estimators, the extra variation due to estimating the parameters in the measurement error model is ignored or taken into account. Reference: Carroll RJ, Ruppert D, Stefanski L, Crainiceanu CM (2006) &lt;<a href="https://doi.org/10.1201%2F9781420010138">doi:10.1201/9781420010138</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>sandwich, mgcv</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Author:</td>
<td>Yu Lu [aut, cre, cph],
  Molin Wang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yu Lu &lt;yulu@hsph.harvard.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-12-09 14:00:45 UTC; luyu</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-12-10 09:00:30 UTC</td>
</tr>
</table>
<hr>
<h2 id='RCreliability.ex'>RCreliability.ex</h2><span id='topic+RCreliability.ex'></span>

<h3>Description</h3>

<p>This function corrects the bias in estimated regression coefficients due to classical additive measurement error (i.e., within-person variation) in logistic regressions under the main study/external reliability study design. The output includes naive and corrected estimators for the regression coefficients; for the variance estimates of the corrected estimators, the extra variation due to estimating the parameters in the measurement error model is ignored or taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RCreliability.ex(z.main, r, z.rep, W=NULL, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RCreliability.ex_+3A_z.main">z.main</code></td>
<td>

<p>covariates measured with error in the main study, a n*p matrix, where n is the number of subjects in the main study and p is the number of covariates.
</p>
</td></tr>
<tr><td><code id="RCreliability.ex_+3A_r">r</code></td>
<td>

<p>number of replicates in the reliability study, vector of length m, where m is the number of subjects in the reliability study. Note: For each subject, the covariates  with error in the reliability study should have the same number of replicates.
</p>
</td></tr>
<tr><td><code id="RCreliability.ex_+3A_z.rep">z.rep</code></td>
<td>

<p>covariates measured with error in the reliability study, a list with p elements, each element in a form of a m*max(r) matrix; subjects with less observations than max(r) should also have max(r) columns with the unobserved elements filled with NA.
</p>
</td></tr>
<tr><td><code id="RCreliability.ex_+3A_w">W</code></td>
<td>

<p>covariates without measurement errors, a n*q matrix, where q stands for the number of covariates without measurement errors. Default is NULL.
</p>
</td></tr>
<tr><td><code id="RCreliability.ex_+3A_y">Y</code></td>
<td>

<p>response variable in the main study, vector of length n. Values should be 0 or 1 in this logistic regression setting.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with 3 table of regression statistics.
</p>
<table>
<tr><td><code>Naive estimates</code></td>
<td>

<p>Estimates of regression coefficients ignoring the measurement errors.
</p>
</td></tr>
<tr><td><code>Corrected estimates</code></td>
<td>

<p>Regression calibration estimates without taking into account the extra variation due to estimating the parameters in the measurement error model.
</p>
</td></tr>
<tr><td><code>Corrected estimates</code>, <code>taking into account the extra variation due to estimating the parameters in the measurement error model</code></td>
<td>

<p>Regression calibration estimates taking into account the extra variation due to estimating the parameters in the measurement error model.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yu Lu, Molin Wang
</p>


<h3>References</h3>

<p>Carroll RJ, Ruppert D, Stefanski L, Crainiceanu CM. Measurement Error in Nonlinear Models: A Modern Perspective. 2nd ed. New York: Chapman &amp; Hall/CRC; 2006
</p>


<h3>See Also</h3>

<p>RCreliability.in function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(RCreliability)
library(mgcv)

# Regression on only one covariates measured with error
x&lt;-rnorm(3000,0,1)
#ICC=0.7 generate z
z.main &lt;- matrix(x[1:1500]+rnorm(1500,0,sqrt(0.4)))
r&lt;-c(rep(3,700),rep(4,800))
z.rep&lt;-list(rbind(cbind(x[1501:2200]+rnorm(700,0,sqrt(0.4)),
x[1501:2200]+rnorm(700,0,sqrt(0.4)),
x[1501:2200]+rnorm(700,0,sqrt(0.4)),NA),
                  cbind(x[2201:3000]+rnorm(800,0,sqrt(0.4)),
                  x[2201:3000]+rnorm(800,0,sqrt(0.4)),
                  x[2201:3000]+rnorm(800,0,sqrt(0.4)),
                  x[2201:3000]+rnorm(800,0,sqrt(0.4)))))
#prevalence about 0.105
p&lt;-exp(-2.2+log(1.5)*x[1:1500])/
(1+exp(-2.2+log(1.5)*x[1:1500]))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))
fit1 &lt;- RCreliability.ex(z.main,r,z.rep,W=NULL,Y)
fit1

# Regression on one covariates measured with error and one confounder
x&lt;-rnorm(3000,0,1)
#ICC=0.7 generate z
z.main &lt;- matrix(x[1:1500]+rnorm(1500,0,sqrt(0.4)))
r&lt;-c(rep(3,700),rep(4,800))
z.rep&lt;-list(rbind(cbind(x[1501:2200]+rnorm(700,0,sqrt(0.4)),
x[1501:2200]+rnorm(700,0,sqrt(0.4)),
x[1501:2200]+rnorm(700,0,sqrt(0.4)),NA),
                  cbind(x[2201:3000]+rnorm(800,0,sqrt(0.4)),
                  x[2201:3000]+rnorm(800,0,sqrt(0.4)),
                  x[2201:3000]+rnorm(800,0,sqrt(0.4)),
                  x[2201:3000]+rnorm(800,0,sqrt(0.4)))))
W&lt;-matrix(sapply(x[1:1500], function(t){if(t&gt;median(x)) {return(rbinom(1,1,0.5))}
  if(t&lt;=median(x)){return(rbinom(1,1,0.3))}}))
#prevalence about 0.103
p&lt;-exp(-2.4+log(1.5)*x[1:1500]+log(1.5)*W)/
(1+exp(-2.4+log(1.5)*x[1:1500]+log(1.5)*W))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))
fit2&lt;-RCreliability.ex(z.main,r,z.rep,W=W,Y)
fit2

# Regression on two covariates measured with error and no confounder
x&lt;-rmvn(3000,c(0,0),matrix(c(1,0.3,0.3,1),nrow=2))
#ICC=0.7 generate z
z.main = x[1:1500,1:2]+rnorm(1500,0,sqrt(0.4))
r&lt;-c(rep(2,500),rep(3,400),rep(4,600))
z.rep&lt;-list(rbind(cbind(x[1501:2000,1]+rnorm(500,0,sqrt(0.4)),
x[1501:2000,1]+rnorm(500,0,sqrt(0.4)),NA,NA),
                  cbind(x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),NA),
                  cbind(x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,1]+rnorm(600,0,sqrt(0.4)))),
            rbind(cbind(x[1501:2000,2]+rnorm(500,0,sqrt(0.4)),
            x[1501:2000,2]+rnorm(500,0,sqrt(0.4)),NA,NA),
                  cbind(x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),NA),
                  cbind(x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,2]+rnorm(600,0,sqrt(0.4)))))
#prevalence about 0.105
p&lt;-exp(-2.3+log(1.5)*rowSums(x[1:1500,]))/
(1+exp(-2.3+log(1.5)*rowSums(x[1:1500,])))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))
fit3&lt;-RCreliability.ex(z.main,r,z.rep,W=NULL,Y)
fit3

# Regression on two covariates measured with error and two confounders
x&lt;-rmvn(3000,c(0,0,0),matrix(c(1,0.3,0.2,0.3,1,0.5,0.2,0.5,1),nrow=3))
w2&lt;-sapply(x[,1], function(t){if(t&gt;median(x[,1])) {return(rbinom(1,1,0.5))}
  if(t&lt;=median(x[,1])){return(rbinom(1,1,0.3))}})
#ICC=0.7 generate z
r&lt;-c(rep(2,500),rep(3,400),rep(4,600))
W&lt;-cbind(x[1:1500,3],w2[1:1500])

z.main = x[1:1500,1:2]+rnorm(1500,0,sqrt(0.4))

z.rep&lt;-list(rbind(cbind(x[1501:2000,1]+rnorm(500,0,sqrt(0.4)),
x[1501:2000,1]+rnorm(500,0,sqrt(0.4)),NA,NA),
                  cbind(x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),NA),
                  cbind(x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,1]+rnorm(600,0,sqrt(0.4)))),
            rbind(cbind(x[1501:2000,2]+rnorm(500,0,sqrt(0.4)),
            x[1501:2000,2]+rnorm(500,0,sqrt(0.4)),NA,NA),
                  cbind(x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
                  x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),NA),
                  cbind(x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
                  x[2401:3000,2]+rnorm(600,0,sqrt(0.4)))))
#prevalence about 0.105
p&lt;-exp(-2.7+log(1.5)*rowSums(x[1:1500,1:3])+log(1.5)*w2[1:1500])/
(1+exp(-2.7+log(1.5)*rowSums(x[1:1500,1:3])+log(1.5)*w2[1:1500]))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))[1:1500]
fit4&lt;-RCreliability.ex(z.main,r,z.rep,W=W,Y)
fit4

</code></pre>

<hr>
<h2 id='RCreliability.in'>RCreliability.in</h2><span id='topic+RCreliability.in'></span>

<h3>Description</h3>

<p>This function corrects the bias in estimated regression coefficients due to classical additive measurement error (i.e., within-person variation) in logistic regressions under the partially or fully replicated design. The output includes naive and corrected estimators for the regression coefficients; for the variance estimates of the corrected estimators, the extra variation due to estimating the parameters in the measurement error model is ignored or taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RCreliability.in(r, z, W=NULL, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RCreliability.in_+3A_r">r</code></td>
<td>

<p>number of replicates in the reliability study, vector of length n, where n is the number of subjects in the reliability study. Note: For each subject, the covariates  with error in the reliability study should have the same number of replicates.
</p>
</td></tr>
<tr><td><code id="RCreliability.in_+3A_z">z</code></td>
<td>

<p>covariates measured with error in the reliability study, a list with p elements, each element in a form of a n*max(r) matrix; subjects with less observations than max(r) should also have max(r) columns with the unobserved elements filled with NA.
</p>
</td></tr>
<tr><td><code id="RCreliability.in_+3A_w">W</code></td>
<td>

<p>covariates without measurement errors, a n*q matrix, where q stands for the number of covariates without measurement errors. Default is NULL.
</p>
</td></tr>
<tr><td><code id="RCreliability.in_+3A_y">Y</code></td>
<td>

<p>response variable in the main study, vector of length n. Values should be 0 or 1 in this logistic regression setting.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with 3 table of regression statistics.
</p>
<table>
<tr><td><code>Naive estimates</code></td>
<td>

<p>Estimates of regression coefficients ignoring the measurement errors.
</p>
</td></tr>
<tr><td><code>Corrected estimates</code></td>
<td>

<p>Regression calibration estimates without taking into account the extra variation due to estimating the parameters in the measurement error model.
</p>
</td></tr>
<tr><td><code>Corrected estimates</code>, <code>taking into account the extra variation due to estimating the parameters in the measurement error model</code></td>
<td>

<p>Regression calibration estimates taking into account the extra variation due to estimating the parameters in the measurement error model.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yu Lu, Molin Wang
</p>


<h3>References</h3>

<p>Carroll RJ, Ruppert D, Stefanski L, Crainiceanu CM. Measurement Error in Nonlinear Models: A Modern Perspective. 2nd ed. New York: Chapman &amp; Hall/CRC; 2006
</p>


<h3>See Also</h3>

<p>RCreliability.ex function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(RCreliability)
library(mgcv)

# Regression on only one covariates measured with error
x&lt;-rnorm(3000,0,1)
#ICC=0.7 generate z
r&lt;-c(rep(1,1500),rep(3,700),rep(4,800))
z&lt;-list(rbind(cbind(x[1:1500]+rnorm(1500,0,sqrt(0.4)),NA,NA,NA),
              cbind(x[1501:2200]+rnorm(700,0,sqrt(0.4)),
              x[1501:2200]+rnorm(700,0,sqrt(0.4)),
              x[1501:2200]+rnorm(700,0,sqrt(0.4)),NA),
              cbind(x[2201:3000]+rnorm(800,0,sqrt(0.4)),
              x[2201:3000]+rnorm(800,0,sqrt(0.4)),
              x[2201:3000]+rnorm(800,0,sqrt(0.4)),
              x[2201:3000]+rnorm(800,0,sqrt(0.4)))))
#prevalence=0.105
p&lt;-exp(-2.2+log(1.5)*x)/(1+exp(-2.2+log(1.5)*x))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))
fit1 &lt;- RCreliability.in(r,z,W=NULL,Y)
fit1

# Regression on one covariates measured with error and one confounder
x&lt;-rnorm(3000,0,1)
#ICC=0.7 generate z
r&lt;-c(rep(1,1500),rep(3,700),rep(4,800))
z&lt;-list(rbind(cbind(x[1:1500]+rnorm(1500,0,sqrt(0.4)),NA,NA,NA),
              cbind(x[1501:2200]+rnorm(700,0,sqrt(0.4)),
              x[1501:2200]+rnorm(700,0,sqrt(0.4)),
              x[1501:2200]+rnorm(700,0,sqrt(0.4)),NA),
              cbind(x[2201:3000]+rnorm(800,0,sqrt(0.4)),
              x[2201:3000]+rnorm(800,0,sqrt(0.4)),
              x[2201:3000]+rnorm(800,0,sqrt(0.4)),
              x[2201:3000]+rnorm(800,0,sqrt(0.4)))))
W&lt;-sapply(x, function(t){if(t&gt;median(x)) {return(rbinom(1,1,0.5))}
  if(t&lt;=median(x)){return(rbinom(1,1,0.3))}})
#prevalence about 0.104
p&lt;-exp(-2.4+log(1.5)*x+log(1.5)*W)/(1+exp(-2.4+log(1.5)*x+log(1.5)*W))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))
fit2&lt;-RCreliability.in(r,z,W=W,Y)
fit2

# Regression on two covariates measured with error and no confounder
x&lt;-rmvn(3000,c(0,0),matrix(c(1,0.3,0.3,1),nrow=2))
#ICC=0.7 generate z
r&lt;-c(rep(1,1500),rep(2,500),rep(3,400),rep(4,600))
z&lt;-list(rbind(cbind(x[1:1500,1]+rnorm(1500,0,sqrt(0.4)),NA,NA,NA),
              cbind(x[1501:1500,1]+rnorm(500,0,sqrt(0.4)),
              x[1501:1500,1]+rnorm(500,0,sqrt(0.4)),NA,NA),
              cbind(x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),NA),
              cbind(x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,1]+rnorm(600,0,sqrt(0.4)))),
        rbind(cbind(x[1:1500,2]+rnorm(1500,0,sqrt(0.4)),NA,NA,NA),
              cbind(x[1501:1500,2]+rnorm(500,0,sqrt(0.4)),
              x[1501:1500,2]+rnorm(500,0,sqrt(0.4)),NA,NA),
              cbind(x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),NA),
              cbind(x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,2]+rnorm(600,0,sqrt(0.4)))))
#prevalence about 0.105
p&lt;-exp(-2.3+log(1.5)*rowSums(x))/(1+exp(-2.3+log(1.5)*rowSums(x)))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))
fit3&lt;-RCreliability.in(r,z, W=NULL,Y)
fit3


# Regression on two covariates measured with error and two confounders
x&lt;-rmvn(3000,c(0,0,0),matrix(c(1,0.3,0.2,0.3,1,0.5,0.2,0.5,1),nrow=3))
w2&lt;-sapply(x[,1], function(t){if(t&gt;median(x[,1])) {return(rbinom(1,1,0.5))}
  if(t&lt;=median(x[,1])){return(rbinom(1,1,0.3))}})
#ICC=0.7 generate z
r&lt;-c(rep(1,1500),rep(2,500),rep(3,400),rep(4,600))
W&lt;-cbind(x[,3],w2)
z&lt;-list(rbind(cbind(x[1:1500,1]+rnorm(1500,0,sqrt(0.4)),NA,NA,NA),
              cbind(x[1501:1500,1]+rnorm(500,0,sqrt(0.4)),
              x[1501:1500,1]+rnorm(500,0,sqrt(0.4)),NA,NA),
              cbind(x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,1]+rnorm(400,0,sqrt(0.4)),NA),
              cbind(x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,1]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,1]+rnorm(600,0,sqrt(0.4)))),
        rbind(cbind(x[1:1500,2]+rnorm(1500,0,sqrt(0.4)),NA,NA,NA),
              cbind(x[1501:1500,2]+rnorm(500,0,sqrt(0.4)),
              x[1501:1500,2]+rnorm(500,0,sqrt(0.4)),NA,NA),
              cbind(x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),
              x[2001:2400,2]+rnorm(400,0,sqrt(0.4)),NA),
              cbind(x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,2]+rnorm(600,0,sqrt(0.4)),
              x[2401:3000,2]+rnorm(600,0,sqrt(0.4)))))
#prevalence about 0.104
p&lt;-exp(-2.65+log(1.5)*rowSums(x[,1:3])+log(1.5)*w2)/
(1+exp(-2.65+log(1.5)*rowSums(x[,1:3])+log(1.5)*w2))
Y&lt;-sapply(p,function(x) rbinom(1,1,x))
fit4&lt;-RCreliability.in(r,z,W=W,Y)
fit4


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
