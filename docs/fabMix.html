<!DOCTYPE html><html lang="en"><head><title>Help for package fabMix</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fabMix}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fabMix-package'>
<p>Overfitting Bayesian Mixtures of Factor Analyzers with Parsimonious Covariance and Unknown Number of Components</p></a></li>
<li><a href='#complete.log.likelihood'>
<p>Complete log-likelihood function for xCx models.</p></a></li>
<li><a href='#complete.log.likelihood_q0'>
<p>Complete log-likelihood function for xUx models and <code class="reqn">q=0</code></p></a></li>
<li><a href='#complete.log.likelihood_q0_sameSigma'>
<p>Complete log-likelihood function for xCx models and <code class="reqn">q=0</code></p></a></li>
<li><a href='#complete.log.likelihood_Sj'>
<p>Complete log-likelihood function for xUx models.</p></a></li>
<li><a href='#compute_A_B_G_D_and_simulate_mu_Lambda'>
<p>Computation and simulations</p></a></li>
<li><a href='#compute_A_B_G_D_and_simulate_mu_Lambda_CCU'>
<p>Computation and simulations for CCU</p></a></li>
<li><a href='#compute_A_B_G_D_and_simulate_mu_Lambda_CUU'>
<p>Computation and simulations for CUU</p></a></li>
<li><a href='#compute_A_B_G_D_and_simulate_mu_Lambda_q0'>
<p>Computation and simulations for <code class="reqn">q = 0</code>.</p></a></li>
<li><a href='#compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma'>
<p>Computation and simulations for <code class="reqn">q = 0</code>.</p></a></li>
<li><a href='#compute_A_B_G_D_and_simulate_mu_Lambda_Sj'>
<p>Computation and simulations</p></a></li>
<li><a href='#compute_sufficient_statistics'>
<p>Compute sufficient statistics</p></a></li>
<li><a href='#compute_sufficient_statistics_given_mu'>
<p>Compute sufficient statistics given mu</p></a></li>
<li><a href='#compute_sufficient_statistics_q0'>
<p>Compute sufficient statistics for <code class="reqn">q = 0</code></p></a></li>
<li><a href='#CorMat_mcmc_summary'>
<p>Compute quantiles for the correlation matrix.</p></a></li>
<li><a href='#CovMat_mcmc_summary'>
<p>Compute quantiles for the covariance matrix.</p></a></li>
<li><a href='#dealWithLabelSwitching'>
<p>Apply label switching algorithms</p></a></li>
<li><a href='#fabMix'>
<p>Main function</p></a></li>
<li><a href='#fabMix_CxC'>
<p>Function to estimate the <code>CUC</code> and <code>CCC</code> models</p></a></li>
<li><a href='#fabMix_CxU'>
<p>Function to estimate the <code>CCU</code> and <code>CUU</code> models</p></a></li>
<li><a href='#fabMix_missing_values'>
<p>Function to estimate the UUU or UCU models in case of missing values</p></a></li>
<li><a href='#fabMix_parallelModels'>
<p>Function for model-level parallelization</p></a></li>
<li><a href='#fabMix_UxC'>
<p>Function to estimate the <code>UUC</code> and <code>UCC</code> models</p></a></li>
<li><a href='#fabMix_UxU'>
<p>Function to estimate the <code>UUU</code> and <code>UCU</code> model</p></a></li>
<li><a href='#getStuffForDIC'>
<p>Compute information criteria</p></a></li>
<li><a href='#log_dirichlet_pdf'>
<p>Log-density function of the Dirichlet distribution</p></a></li>
<li><a href='#myDirichlet'>
<p>Simulate from the Dirichlet distribution</p></a></li>
<li><a href='#observed.log.likelihood0'>
<p>Log-likelihood of the mixture model</p></a></li>
<li><a href='#observed.log.likelihood0_q0_sameSigma'>
<p>Log-likelihood of the mixture model for <code class="reqn">q=0</code> and same variance of errors</p></a></li>
<li><a href='#observed.log.likelihood0_Sj'>
<p>Log-likelihood of the mixture model</p></a></li>
<li><a href='#observed.log.likelihood0_Sj_q0'>
<p>Log-likelihood of the mixture model for <code class="reqn">q=0</code></p></a></li>
<li><a href='#overfitting_q0'>
<p>MCMC sampler for <code class="reqn">q=0</code></p></a></li>
<li><a href='#overfitting_q0_sameSigma'>
<p>MCMC sampler for <code class="reqn">q=0</code> and same error variance parameterization</p></a></li>
<li><a href='#overfittingMFA'>
<p>Basic MCMC sampler for the <code>UCU</code> model</p></a></li>
<li><a href='#overfittingMFA_CCC'>
<p>Basic MCMC sampler for the <code>CCC</code> model</p></a></li>
<li><a href='#overfittingMFA_CCU'>
<p>Basic MCMC sampler for the <code>CCU</code> model</p></a></li>
<li><a href='#overfittingMFA_CUC'>
<p>Basic MCMC sampler for the <code>CUC</code> model</p></a></li>
<li><a href='#overfittingMFA_CUU'>
<p>Basic MCMC sampler for the <code>CUU</code> model</p></a></li>
<li><a href='#overfittingMFA_missing_values'>
<p>Basic MCMC sampler for the case of missing data</p></a></li>
<li><a href='#overfittingMFA_Sj'>
<p>Basic MCMC sampler for the <code>UUU</code> model</p></a></li>
<li><a href='#overfittingMFA_Sj_missing_values'>
<p>Basic MCMC sampler for the case of missing data and different error variance</p></a></li>
<li><a href='#overfittingMFA_UCC'>
<p>Basic MCMC sampler for the <code>UCC</code> model</p></a></li>
<li><a href='#overfittingMFA_UUC'>
<p>Basic MCMC sampler for the <code>UUC</code> model</p></a></li>
<li><a href='#plot.fabMix.object'>
<p>Plot function</p></a></li>
<li><a href='#print.fabMix.object'>
<p>Print function</p></a></li>
<li><a href='#readLambdaValues'>
<p>Read Lambda values.</p></a></li>
<li><a href='#simData'>
<p>Synthetic data generator</p></a></li>
<li><a href='#simData2'>
<p>Synthetic data generator 2</p></a></li>
<li><a href='#summary.fabMix.object'>
<p>Summary method</p></a></li>
<li><a href='#update_all_y'>
<p>Gibbs sampling for <code class="reqn">y</code> in <code>xCx</code> model</p></a></li>
<li><a href='#update_all_y_Sj'>
<p>Gibbs sampling for <code class="reqn">y</code>  in <code>xUx</code> model</p></a></li>
<li><a href='#update_OmegaINV'>
<p>Gibbs sampling for <code class="reqn">\Omega^{-1}</code></p></a></li>
<li><a href='#update_OmegaINV_Cxx'>
<p>Gibbs sampling for <code class="reqn">\Omega^{-1}</code> for Cxx model</p></a></li>
<li><a href='#update_SigmaINV_faster'>
<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code></p></a></li>
<li><a href='#update_SigmaINV_faster_q0'>
<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component for <code class="reqn">q=0</code></p></a></li>
<li><a href='#update_SigmaINV_faster_q0_sameSigma'>
<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component for <code class="reqn">q=0</code></p></a></li>
<li><a href='#update_SigmaINV_faster_Sj'>
<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component</p></a></li>
<li><a href='#update_SigmaINV_xCC'>
<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> for xCC models</p></a></li>
<li><a href='#update_SigmaINV_xUC'>
<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component for xUC models</p></a></li>
<li><a href='#update_z_b'>
<p>Gibbs sampling for <code class="reqn">z</code></p></a></li>
<li><a href='#update_z_b_Sj'>
<p>Gibbs sampling for <code class="reqn">z</code></p></a></li>
<li><a href='#update_z_q0'>
<p>Gibbs sampling for <code class="reqn">z</code> for <code class="reqn">q=0</code></p></a></li>
<li><a href='#update_z_q0_sameSigma'>
<p>Gibbs sampling for <code class="reqn">z</code> for <code class="reqn">q=0</code></p></a></li>
<li><a href='#update_z2'>
<p>Collapsed Gibbs for <code class="reqn">z</code> using matrix inversion lemma</p></a></li>
<li><a href='#update_z2_Sj'>
<p>Collapsed Gibbs for <code class="reqn">z</code> using matrix inversion lemma</p></a></li>
<li><a href='#update_z4'>
<p>Collapsed Gibbs for <code class="reqn">z</code></p></a></li>
<li><a href='#update_z4_Sj'>
<p>Collapsed Gibbs for <code class="reqn">z</code></p></a></li>
<li><a href='#waveDataset1500'><p>Wave dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Overfitting Bayesian Mixtures of Factor Analyzers with
Parsimonious Covariance and Unknown Number of Components</td>
</tr>
<tr>
<td>Version:</td>
<td>5.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-12</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Panagiotis Papastamoulis &lt;papapast@yahoo.gr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Model-based clustering of multivariate continuous data using Bayesian mixtures of factor analyzers (Papastamoulis (2019) &lt;<a href="https://doi.org/10.1007%2Fs11222-019-09891-z">doi:10.1007/s11222-019-09891-z</a>&gt; (2018) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2018.03.007">doi:10.1016/j.csda.2018.03.007</a>&gt;). The number of clusters is estimated using overfitting mixture models (Rousseau and Mengersen (2011) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2011.00781.x">doi:10.1111/j.1467-9868.2011.00781.x</a>&gt;): suitable prior assumptions ensure that asymptotically the extra components will have zero posterior weight, therefore, the inference is based on the &ldquo;alive&rdquo; components. A Gibbs sampler is implemented in order to (approximately) sample from the posterior distribution of the overfitting mixture. A prior parallel tempering scheme is also available, which allows to run multiple parallel chains with different prior distributions on the mixture weights. These chains run in parallel and can swap states using a Metropolis-Hastings move. Eight different parameterizations give rise to parsimonious representations of the covariance per cluster (following Mc Nicholas and Murphy (2008) &lt;<a href="https://doi.org/10.1007%2Fs11222-008-9056-0">doi:10.1007/s11222-008-9056-0</a>&gt;). The model parameterization and number of factors is selected according to the Bayesian Information Criterion. Identifiability issues related to label switching are dealt by post-processing the simulated output with the Equivalence Classes Representatives algorithm (Papastamoulis and Iliopoulos (2010) &lt;<a href="https://doi.org/10.1198%2Fjcgs.2010.09008">doi:10.1198/jcgs.2010.09008</a>&gt;, Papastamoulis (2016) &lt;<a href="https://doi.org/10.18637%2Fjss.v069.c01">doi:10.18637/jss.v069.c01</a>&gt;). </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mqbssppe/overfittingFABMix">https://github.com/mqbssppe/overfittingFABMix</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.17), MASS, doParallel, foreach, label.switching,
mvtnorm, RColorBrewer, corrplot, mclust, coda, ggplot2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-12 08:43:21 UTC; panagiotis</td>
</tr>
<tr>
<td>Author:</td>
<td>Panagiotis Papastamoulis
    <a href="https://orcid.org/0000-0001-9468-7613"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-12 09:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='fabMix-package'>
Overfitting Bayesian Mixtures of Factor Analyzers with Parsimonious Covariance and Unknown Number of Components
</h2><span id='topic+fabMix-package'></span>

<h3>Description</h3>

<p>Model-based clustering of multivariate continuous data using Bayesian mixtures of factor analyzers (Papastamoulis (2019) &lt;DOI:10.1007/s11222-019-09891-z&gt; (2018) &lt;DOI:10.1016/j.csda.2018.03.007&gt;). The number of clusters is estimated using overfitting mixture models (Rousseau and Mengersen (2011) &lt;DOI:10.1111/j.1467-9868.2011.00781.x&gt;): suitable prior assumptions ensure that asymptotically the extra components will have zero posterior weight, therefore, the inference is based on the &ldquo;alive&rdquo; components. A Gibbs sampler is implemented in order to (approximately) sample from the posterior distribution of the overfitting mixture. A prior parallel tempering scheme is also available, which allows to run multiple parallel chains with different prior distributions on the mixture weights. These chains run in parallel and can swap states using a Metropolis-Hastings move. Eight different parameterizations give rise to parsimonious representations of the covariance per cluster (following Mc Nicholas and Murphy (2008) &lt;DOI:10.1007/s11222-008-9056-0&gt;). The model parameterization and number of factors is selected according to the Bayesian Information Criterion. Identifiability issues related to label switching are dealt by post-processing the simulated output with the Equivalence Classes Representatives algorithm (Papastamoulis and Iliopoulos (2010) &lt;DOI:10.1198/jcgs.2010.09008&gt;, Papastamoulis (2016) &lt;DOI:10.18637/jss.v069.c01&gt;). 
</p>
<p>The main fuction of the package is <code><a href="#topic+fabMix">fabMix</a></code>. 
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>
<p>Maintainer: Panagiotis Papastamoulis &lt;papapast@yahoo.gr&gt;
</p>


<h3>References</h3>

<p>Fokoue, E. and Titterington, D.M. (2003). Mixtures of Factor Analysers: Bayesian Estimation and Inference by Stochastic Simulation. Machine Learing, 50(1): 73-94.
</p>
<p>McNicholas, P.D. and Murphy, T.B. Statistics and Computing (2008) 18: 285. https://doi.org/10.1007/s11222-008-9056-0.
</p>
<p>Papastamoulis P. and Iliopoulos G. (2010). An artificial allocations based solution to the label switching problem in Bayesian analysis of mixtures of distributions. Journal of Computational and Graphical Statistics, 19: 313-331.
</p>
<p>Rousseau, J. and Mengersen, K. (2011). Asymptotic behaviour of the posterior distribution in overfitted mixture models. Journal of the Royal Statistical Society, Series B (methodological), 73(5): 689-710.
</p>
<p>van Havre, Z., White, N., Rousseau, J. and Mengersen, K. (2015). Overfitting Bayesian Mixture Models with an Unknown Number of Components. PLOS ONE, 10(7): 1-27.
</p>
<p>Papastamoulis, P. (2016). <code>label.switching</code>: An R Package for Dealing with the Label Switching Problem in MCMC Outputs. Journal of Statistical Software, 69(1), 1-24.
</p>
<p>Papastamoulis, P. (2018). Overfitting Bayesian mixtures of factor analyzers with an unknown number of components. Computational Statistics and Data Analysis, 124: 220-234. DOI: 10.1016/j.csda.2018.03.007.
</p>
<p>Papastamoulis, P (2019).  Clustering multivariate data using factor analytic Bayesian mixtures with an unknown number of components. Statistics and Computing, doi: 10.1007/s11222-019-09891-z.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fabMix">fabMix</a></code>, <code><a href="#topic+plot.fabMix.object">plot.fabMix.object</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># TOY EXAMPLE (very small numbers... only for CRAN check purposes)

#################################################################
# (a) using 2 cores in parallel, each one running 2 heated chains.
#################################################################
library('fabMix')

n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2		     # true number of clusters

sINV_diag = 1/((1:p))	 # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
			sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)

# Run `fabMix` for a _small_ number of iterations  
#	considering only `UUU` (maximal model),
# 	using the default prior parallel heating parameters `dirPriorAlphas`.
#	NOTE: `dirPriorAlphas` may require some tuning in general.


qRange &lt;- 2	# values for the number of factors (only the true number 
#                                                    is considered here)
Kmax &lt;- 2	# number of components for the overfitted mixture model
nChains &lt;- 2	# number of parallel heated chains

set.seed(1)
fm &lt;- fabMix( model = c("UUU"), nChains = nChains, 
	rawData = syntheticDataset$data, outDir = "toyExample",
        Kmax = Kmax, mCycles = 4, burnCycles = 1, q = qRange,
        g = 0.5, h = 0.5, alpha_sigma = 0.5, beta_sigma = 0.5, 
        warm_up_overfitting = 2, warm_up = 5) 

# WARNING: the following parameters: 
#  Kmax, nChains, mCycles, burnCycles, warm_up_overfitting, warm_up 
#	 should take (much) _larger_ values. E.g. a typical implementation consists of:
#        Kmax = 20, nChains &gt;= 3, mCycles = 1100, burnCycles = 100, 
#        warm_up_overfitting = 500, warm_up = 5000. 

# Now print a run summary and produce some plots. 
print(fm)
# you may also plot, summary the output. 

#################################################################
# (b) using 12 cores_____________________________________________
#_______4 models with 3 heated chains running in parallel________
#_______considering all 8 model parameterizations________________
#################################################################
## Not run: 
library('fabMix')
set.seed(99)
n = 100                # sample size
p = 30                # number of variables
q = 2                # number of factors
K = 5		     # number of clusters
sINV_diag = rep(1/100,p) 	# diagonal of inverse variance of errors
syntheticDataset &lt;- simData(sameLambda=FALSE,K.true = K, n = n, q = q, p = p, 
			sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
qRange &lt;- 1:3	# range of values for the number of factors
Kmax &lt;- 20	# number of components for the overfitted mixture model
nChains &lt;- 3	# number of parallel heated chains

# the next command takes ~ 1 hour in a Linux workstation with 12 threads.
fm &lt;- fabMix( parallelModels = 4, 
	nChains = nChains, 
	model = c("UUU","CUU","UCU","CCU","UCC","UUC","CUC","CCC"), 
	rawData = syntheticDataset$data, outDir = "toyExample_b",
        Kmax = Kmax, mCycles = 600, burnCycles = 100, q = qRange,
        g = 0.5, h = 0.5, alpha_sigma = 0.5, beta_sigma = 0.5, 
        warm_up_overfitting = 500, warm_up = 5000) 
print(fm)
plot(fm, what = "BIC")
plot(fm, what = "classification_pairs")


## End(Not run)

</code></pre>

<hr>
<h2 id='complete.log.likelihood'>
Complete log-likelihood function for xCx models.
</h2><span id='topic+complete.log.likelihood'></span>

<h3>Description</h3>

<p>Complete log-likelihood function for models with same error variance per component (xCx).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complete.log.likelihood(x_data, w, mu, Lambda, SigmaINV, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="complete.log.likelihood_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the data
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_+3A_w">w</code></td>
<td>

<p>a vector of length <code class="reqn">K</code> containing the mixture weights
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> matrix containing the marginal means per component
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p\times q</code> array of factor loadings per component
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">p\times p</code> precision matrix (inverse covariance)
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_+3A_z">z</code></td>
<td>

<p>A vector of length <code class="reqn">n</code> containing the allocations of the <code class="reqn">n</code> datapoints to the <code class="reqn">K</code> mixture components
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>complete log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- waveDataset1500[ 1:20, -1] # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	Lambda &lt;- array( runif(K*p*q), dim = c(K,p,q) )
	SigmaINV &lt;- array(1, dim = c(p,p))
	# compute the complete.log.likelihood
	complete.log.likelihood(x_data = x_data, w = w, mu = mu, 
		Lambda = Lambda, SigmaINV = SigmaINV, z = z)
</code></pre>

<hr>
<h2 id='complete.log.likelihood_q0'>
Complete log-likelihood function for xUx models and <code class="reqn">q=0</code>
</h2><span id='topic+complete.log.likelihood_q0'></span>

<h3>Description</h3>

<p>Complete log-likelihood function for models with different error variance per component (xUx) and diagonal covariance structure per component (<code class="reqn">q=0</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complete.log.likelihood_q0(x_data, w, mu, SigmaINV, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="complete.log.likelihood_q0_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the data
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_+3A_w">w</code></td>
<td>

<p>a vector of length <code class="reqn">K</code> containing the mixture weights
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> matrix containing the marginal means per component
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">K\times p\times p</code> precision matrix (inverse covariance) per component
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_+3A_z">z</code></td>
<td>

<p>A vector of length <code class="reqn">n</code> containing the allocations of the <code class="reqn">n</code> datapoints to the <code class="reqn">K</code> mixture components
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>complete log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- scale(waveDataset1500[ 1:20, -1]) # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( -0.1 + 0.2*runif(K * p), dim = c(K,p) )
	SigmaINV &lt;- array( 1, dim = c(K,p,p))
	# compute the complete.log.likelihood ( -inf )
	complete.log.likelihood_q0(x_data = x_data, w = w, mu = mu, 
		SigmaINV = SigmaINV, z = z)
</code></pre>

<hr>
<h2 id='complete.log.likelihood_q0_sameSigma'>
Complete log-likelihood function for xCx models and <code class="reqn">q=0</code>
</h2><span id='topic+complete.log.likelihood_q0_sameSigma'></span>

<h3>Description</h3>

<p>Complete log-likelihood function for models with same  error variance per component (xCx) and diagonal covariance structure per component (<code class="reqn">q=0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complete.log.likelihood_q0_sameSigma(x_data, w, mu, SigmaINV, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="complete.log.likelihood_q0_sameSigma_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the data
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_sameSigma_+3A_w">w</code></td>
<td>

<p>a vector of length <code class="reqn">K</code> containing the mixture weights	
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_sameSigma_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> matrix containing the marginal means per component
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_sameSigma_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">p\times p</code> precision matrix (inverse covariance)
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_q0_sameSigma_+3A_z">z</code></td>
<td>

<p>A vector of length <code class="reqn">n</code> containing the allocations of the <code class="reqn">n</code> datapoints to the <code class="reqn">K</code> mixture components
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>complete log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- scale(waveDataset1500[ 1:20, -1]) # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( -0.1 + 0.2*runif(K * p), dim = c(K,p) )
	SigmaINV &lt;- array( 1, dim = c(p,p))
	# compute the complete.log.likelihood ( -inf )
	complete.log.likelihood_q0_sameSigma(x_data = x_data, w = w, mu = mu, 
		SigmaINV = SigmaINV, z = z)
</code></pre>

<hr>
<h2 id='complete.log.likelihood_Sj'>
Complete log-likelihood function for xUx models.
</h2><span id='topic+complete.log.likelihood_Sj'></span>

<h3>Description</h3>

<p>Complete log-likelihood function for models with different error variance per component (xUx).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complete.log.likelihood_Sj(x_data, w, mu, Lambda, SigmaINV, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="complete.log.likelihood_Sj_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the data
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_Sj_+3A_w">w</code></td>
<td>

<p>a vector of length <code class="reqn">K</code> containing the mixture weights
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_Sj_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> matrix containing the marginal means per component
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_Sj_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p\times q</code> array of factor loadings per component (maybe restricted to be the same)
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_Sj_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">K\times p\times p</code> precision matrix (inverse covariance) per component
</p>
</td></tr>
<tr><td><code id="complete.log.likelihood_Sj_+3A_z">z</code></td>
<td>

<p>The allocation vector.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>complete log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- waveDataset1500[ 1:20, -1] # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	Lambda &lt;- array( runif(K*p*q), dim = c(K,p,q) )
	SigmaINV &lt;- array( c(0.5, 0.75, 1), dim = c(K,p,p))
	# compute the complete.log.likelihood
	complete.log.likelihood_Sj(x_data = x_data, w = w, mu = mu, 
		Lambda = Lambda, SigmaINV = SigmaINV, z = z)
</code></pre>

<hr>
<h2 id='compute_A_B_G_D_and_simulate_mu_Lambda'>
Computation and simulations
</h2><span id='topic+compute_A_B_G_D_and_simulate_mu_Lambda'></span>

<h3>Description</h3>

<p>This function simulates <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	compute_A_B_G_D_and_simulate_mu_Lambda(SigmaINV, 
		suff_statistics, OmegaINV, K, priorConst1, T_INV, v_r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix <code class="reqn">\Sigma^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_+3A_suff_statistics">suff_statistics</code></td>
<td>

<p>Sufficient statistics
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_+3A_omegainv">OmegaINV</code></td>
<td>

<p>Prior parameter: <code class="reqn">\Omega^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_+3A_k">K</code></td>
<td>

<p>Number of overfitting mixture components
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_+3A_priorconst1">priorConst1</code></td>
<td>

<p>Prior constant: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_+3A_t_inv">T_INV</code></td>
<td>

<p>Prior parameter: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_+3A_v_r">v_r</code></td>
<td>

<p>This vector is used to set to zero the upper right <code class="reqn">(q-1)\times(q-1)</code> diagonal block of factor loadings for identifiability purposes.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a draw from the conditional distributions of <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code>:
</p>
<table role = "presentation">
<tr><td><code>Lambdas</code></td>
<td>
<p><code class="reqn">K\times p\times q</code> array (factor loadings per component)</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p><code class="reqn">K\times p</code> array  (marginal mean per component)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- scale(as.matrix(waveDataset1500[ 1:20, -1])) # data
	z &lt;-  waveDataset1500[ 1:20, 1] # class
	p &lt;- dim(x_data)[2]
	n &lt;- dim(x_data)[1]
	q &lt;- 2
	K &lt;- length(table(z))           # 3 classes

	T_INV &lt;- array(data = 0, dim = c(p,p))
	diag(T_INV) &lt;- diag(var(x_data))
	diag(T_INV) &lt;- 1/diag(T_INV)
	ksi &lt;- colMeans(x_data)
	priorConst1 &lt;- array(diag(T_INV)*ksi, dim =c(p,1))
	# give some arbitrary values to the parameters:
	set.seed(1)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	y &lt;- array(rnorm(n = q*n), dim = c(n,q))
	SigmaINV &lt;- array(data = 0, dim = c(p,p) )
	diag(SigmaINV) &lt;- 0.5 + 0.5*runif(p)
	OmegaINV &lt;- diag(q)
	# compute sufficient stats 
	suf_stat &lt;- compute_sufficient_statistics(y = y, 
	 z = z, K = K, x_data = x_data)

	v_r &lt;- numeric(p) #indicates the non-zero values of Lambdas
	for( r in 1:p ){
		v_r[r] &lt;- min(r,q)
	}
	# now simulate mu and Lambda
	f2 &lt;- compute_A_B_G_D_and_simulate_mu_Lambda(SigmaINV = SigmaINV, 
                suff_statistics = suf_stat, OmegaINV = OmegaINV, 
                K = K, priorConst1 = priorConst1, T_INV = T_INV, v_r = v_r)
	# f2$mu contains the simulated means
	# f2$Lambdas contains the simulated factor loadings

</code></pre>

<hr>
<h2 id='compute_A_B_G_D_and_simulate_mu_Lambda_CCU'>
Computation and simulations for CCU
</h2><span id='topic+compute_A_B_G_D_and_simulate_mu_Lambda_CCU'></span>

<h3>Description</h3>

<p>This function simulates <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code> for the CCU model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	compute_A_B_G_D_and_simulate_mu_Lambda_CCU(SigmaINV, 
		suff_statistics, OmegaINV, K, priorConst1, T_INV, v_r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CCU_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix <code class="reqn">\Sigma^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CCU_+3A_suff_statistics">suff_statistics</code></td>
<td>

<p>Sufficient statistics
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CCU_+3A_omegainv">OmegaINV</code></td>
<td>

<p>Prior parameter: <code class="reqn">\Omega^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CCU_+3A_k">K</code></td>
<td>

<p>Number of overfitting mixture components
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CCU_+3A_priorconst1">priorConst1</code></td>
<td>

<p>Prior constant: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CCU_+3A_t_inv">T_INV</code></td>
<td>

<p>Prior parameter: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CCU_+3A_v_r">v_r</code></td>
<td>

<p>This vector is used to set to zero the upper right <code class="reqn">(q-1)\times(q-1)</code> diagonal block of factor loadings for identifiability purposes.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a draw from the conditional distributions of <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code>:
</p>
<table role = "presentation">
<tr><td><code>Lambdas</code></td>
<td>
<p><code class="reqn">K\times p\times q</code> array (factor loadings per component)</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p><code class="reqn">K\times p</code> array  (marginal mean per component)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- scale(as.matrix(waveDataset1500[ 1:20, -1])) # data
	z &lt;-  waveDataset1500[ 1:20, 1] # class
	p &lt;- dim(x_data)[2]
	n &lt;- dim(x_data)[1]
	q &lt;- 2
	K &lt;- length(table(z))           # 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	y &lt;- array(rnorm(n = q*n), dim = c(n,q))
	SigmaINV &lt;- array(data = 0, dim = c(p,p) )
	diag(SigmaINV) = 0.5 + 0.5*runif(p)
	OmegaINV &lt;- diag(q)
	# compute sufficient stats 
	suf_stat &lt;- compute_sufficient_statistics_given_mu(y = y, 
	 z = z, K = K, x_data = x_data, mu = mu)

	v_r &lt;- numeric(p) #indicates the non-zero values of Lambdas
	for( r in 1:p ){
		v_r[r] &lt;- min(r,q)
	}
	T_INV &lt;- array(data = 0, dim = c(p,p))
	diag(T_INV) &lt;- diag(var(x_data))
	diag(T_INV) &lt;- 1/diag(T_INV)
	ksi &lt;- colMeans(x_data)
	priorConst1 &lt;- array(diag(T_INV)*ksi, dim =c(p,1))
	# now simulate mu and Lambda
	f2 &lt;- compute_A_B_G_D_and_simulate_mu_Lambda_CCU(SigmaINV = SigmaINV, 
                suff_statistics = suf_stat, OmegaINV = OmegaINV, 
                K = K, priorConst1 = priorConst1, T_INV = T_INV, v_r = v_r)
	# f2$mu contains the simulated means
	# f2$Lambdas contains the simulated factor loadings

</code></pre>

<hr>
<h2 id='compute_A_B_G_D_and_simulate_mu_Lambda_CUU'>
Computation and simulations for CUU
</h2><span id='topic+compute_A_B_G_D_and_simulate_mu_Lambda_CUU'></span>

<h3>Description</h3>

<p>This function simulates <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code> for the CUU model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	compute_A_B_G_D_and_simulate_mu_Lambda_CUU(SigmaINV, 
		suff_statistics, OmegaINV, K, priorConst1, T_INV, v_r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CUU_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix <code class="reqn">\Sigma^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CUU_+3A_suff_statistics">suff_statistics</code></td>
<td>

<p>Sufficient statistics
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CUU_+3A_omegainv">OmegaINV</code></td>
<td>

<p>Prior parameter: <code class="reqn">\Omega^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CUU_+3A_k">K</code></td>
<td>

<p>Number of overfitting mixture components
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CUU_+3A_priorconst1">priorConst1</code></td>
<td>

<p>Prior constant: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CUU_+3A_t_inv">T_INV</code></td>
<td>

<p>Prior parameter: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_CUU_+3A_v_r">v_r</code></td>
<td>

<p>This vector is used to set to zero the upper right <code class="reqn">(q-1)\times(q-1)</code> diagonal block of factor loadings for identifiability purposes.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a draw from the conditional distributions of <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code>:
</p>
<table role = "presentation">
<tr><td><code>Lambdas</code></td>
<td>
<p><code class="reqn">K\times p\times q</code> array (factor loadings per component)</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p><code class="reqn">K\times p</code> array  (marginal mean per component)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- scale(as.matrix(waveDataset1500[ 1:20, -1])) # data
	z &lt;-  waveDataset1500[ 1:20, 1] # class
	p &lt;- dim(x_data)[2]
	n &lt;- dim(x_data)[1]
	q &lt;- 2
	K &lt;- length(table(z))           # 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	y &lt;- array(rnorm(n = q*n), dim = c(n,q))
	SigmaINV &lt;- array(data = 0, dim = c(K,p,p) )
	for(k in 1:K){
		diag(SigmaINV[k,,]) &lt;- 0.5 + 0.5*runif(p)
	}
	OmegaINV &lt;- diag(q)
	# compute sufficient stats 
	suf_stat &lt;- compute_sufficient_statistics_given_mu(y = y, 
	 z = z, K = K, x_data = x_data, mu = mu)

	v_r &lt;- numeric(p) #indicates the non-zero values of Lambdas
	for( r in 1:p ){
		v_r[r] &lt;- min(r,q)
	}
	T_INV &lt;- array(data = 0, dim = c(p,p))
	diag(T_INV) &lt;- diag(var(x_data))
	diag(T_INV) &lt;- 1/diag(T_INV)
	ksi &lt;- colMeans(x_data)
	priorConst1 &lt;- array(diag(T_INV)*ksi, dim =c(p,1))
	# now simulate mu and Lambda
	f2 &lt;- compute_A_B_G_D_and_simulate_mu_Lambda_CUU(SigmaINV = SigmaINV, 
                suff_statistics = suf_stat, OmegaINV = OmegaINV, 
                K = K, priorConst1 = priorConst1, T_INV = T_INV, v_r = v_r)
	# f2$mu contains the simulated means
	# f2$Lambdas contains the simulated factor loadings

</code></pre>

<hr>
<h2 id='compute_A_B_G_D_and_simulate_mu_Lambda_q0'>
Computation and simulations for <code class="reqn">q = 0</code>.
</h2><span id='topic+compute_A_B_G_D_and_simulate_mu_Lambda_q0'></span>

<h3>Description</h3>

<p>This function simulates <code class="reqn">\mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	compute_A_B_G_D_and_simulate_mu_Lambda_q0(SigmaINV, 
		suff_statistics, K, priorConst1, T_INV, v_r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix <code class="reqn">\Sigma^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_+3A_suff_statistics">suff_statistics</code></td>
<td>

<p>Sufficient statistics
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_+3A_k">K</code></td>
<td>

<p>Number of overfitting mixture components
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_+3A_priorconst1">priorConst1</code></td>
<td>

<p>Prior constant: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_+3A_t_inv">T_INV</code></td>
<td>

<p>Prior parameter: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_+3A_v_r">v_r</code></td>
<td>

<p>This vector is used to set to zero the upper right <code class="reqn">(q-1)\times(q-1)</code> diagonal block of factor loadings for identifiability purposes.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a draw from the conditional distributions of <code class="reqn">\mu</code>:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p><code class="reqn">K\times p</code> array  (marginal mean per component)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma'>
Computation and simulations for <code class="reqn">q = 0</code>.
</h2><span id='topic+compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma'></span>

<h3>Description</h3>

<p>This function simulates <code class="reqn">\mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma(SigmaINV, 
		suff_statistics, K, priorConst1, T_INV, v_r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix <code class="reqn">\Sigma^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma_+3A_suff_statistics">suff_statistics</code></td>
<td>

<p>Sufficient statistics
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma_+3A_k">K</code></td>
<td>

<p>Number of overfitting mixture components
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma_+3A_priorconst1">priorConst1</code></td>
<td>

<p>Prior constant: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma_+3A_t_inv">T_INV</code></td>
<td>

<p>Prior parameter: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_q0_sameSigma_+3A_v_r">v_r</code></td>
<td>

<p>This vector is used to set to zero the upper right <code class="reqn">(q-1)\times(q-1)</code> diagonal block of factor loadings for identifiability purposes.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a draw from the conditional distributions of <code class="reqn">\mu</code>:
</p>
<table role = "presentation">
<tr><td><code>mu</code></td>
<td>
<p><code class="reqn">K\times p</code> array  (marginal mean per component)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='compute_A_B_G_D_and_simulate_mu_Lambda_Sj'>
Computation and simulations
</h2><span id='topic+compute_A_B_G_D_and_simulate_mu_Lambda_Sj'></span>

<h3>Description</h3>

<p>This function simulates <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	compute_A_B_G_D_and_simulate_mu_Lambda_Sj(SigmaINV, 
		suff_statistics, OmegaINV, K, priorConst1, T_INV, v_r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_Sj_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix <code class="reqn">\Sigma^{-1}</code> per component
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_Sj_+3A_suff_statistics">suff_statistics</code></td>
<td>

<p>Sufficient statistics
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_Sj_+3A_omegainv">OmegaINV</code></td>
<td>

<p>Prior parameter: <code class="reqn">\Omega^{-1}</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_Sj_+3A_k">K</code></td>
<td>

<p>Number of overfitting mixture components
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_Sj_+3A_priorconst1">priorConst1</code></td>
<td>

<p>Prior constant: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_Sj_+3A_t_inv">T_INV</code></td>
<td>

<p>Prior parameter: <code class="reqn">T^{-1}\xi</code>
</p>
</td></tr>
<tr><td><code id="compute_A_B_G_D_and_simulate_mu_Lambda_Sj_+3A_v_r">v_r</code></td>
<td>

<p>This vector is used to set to zero the upper right <code class="reqn">(q-1)\times(q-1)</code> diagonal block of factor loadings for identifiability purposes.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a draw from the conditional distributions of <code class="reqn">\mu</code> and <code class="reqn">\Lambda</code>:
</p>
<table role = "presentation">
<tr><td><code>Lambdas</code></td>
<td>
<p><code class="reqn">K\times p\times q</code> array (factor loadings per component)</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p><code class="reqn">K\times p</code> array  (marginal mean per component)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- scale(as.matrix(waveDataset1500[ 1:20, -1])) # data
	z &lt;-  waveDataset1500[ 1:20, 1] # class
	p &lt;- dim(x_data)[2]
	n &lt;- dim(x_data)[1]
	q &lt;- 2
	K &lt;- length(table(z))           # 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	y &lt;- array(rnorm(n = q*n), dim = c(n,q))
	SigmaINV &lt;- array(data = 0, dim = c(K,p,p) )
	for(k in 1:K){
		diag(SigmaINV[k,,]) &lt;- 0.5 + 0.5*runif(p)
	}
	OmegaINV &lt;- diag(q)
	# compute sufficient stats 
	suf_stat &lt;- compute_sufficient_statistics(y = y, 
	 z = z, K = K, x_data = x_data)

	v_r &lt;- numeric(p) #indicates the non-zero values of Lambdas
	for( r in 1:p ){
		v_r[r] &lt;- min(r,q)
	}
	T_INV &lt;- array(data = 0, dim = c(p,p))
	diag(T_INV) &lt;- diag(var(x_data))
	diag(T_INV) &lt;- 1/diag(T_INV)
	ksi &lt;- colMeans(x_data)
	priorConst1 &lt;- array(diag(T_INV)*ksi, dim =c(p,1))
	# now simulate mu and Lambda
	f2 &lt;- compute_A_B_G_D_and_simulate_mu_Lambda_Sj(SigmaINV = SigmaINV, 
                suff_statistics = suf_stat, OmegaINV = OmegaINV, 
                K = K, priorConst1 = priorConst1, T_INV = T_INV, v_r = v_r)
	# f2$mu contains the simulated means
	# f2$Lambdas contains the simulated factor loadings

</code></pre>

<hr>
<h2 id='compute_sufficient_statistics'>
Compute sufficient statistics
</h2><span id='topic+compute_sufficient_statistics'></span>

<h3>Description</h3>

<p>Compute sufficient statistics given <code class="reqn">y</code> and <code class="reqn">z</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_sufficient_statistics(y, z, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_sufficient_statistics_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix of factors
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix with observed data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with six entries of sufficient statistics.
</p>
<table role = "presentation">
<tr><td><code>cluster_size</code></td>
<td>
<p> Integer vector of length <code class="reqn">K</code> </p>
</td></tr>
<tr><td><code>sx</code></td>
<td>
 <p><code class="reqn">K\times p</code> array </p>
</td></tr>
<tr><td><code>sy</code></td>
<td>
 <p><code class="reqn">K\times q</code> array </p>
</td></tr>
<tr><td><code>sxx</code></td>
<td>
<p> Not used </p>
</td></tr>
<tr><td><code>syy</code></td>
<td>
 <p><code class="reqn">K\times q \times q</code> array </p>
</td></tr>
<tr><td><code>sxy</code></td>
<td>
 <p><code class="reqn">K\times p \times q</code> array </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>        data(waveDataset1500)
        x_data &lt;- as.matrix(waveDataset1500[ 1:20, -1]) # data
        z &lt;-  waveDataset1500[ 1:20, 1] # class
        p &lt;- dim(x_data)[2]
        n &lt;- dim(x_data)[1]
        q &lt;- 2
        K &lt;- length(table(z))           # 3 classes
        # give some arbitrary values to the parameters:
        set.seed(1)
	y &lt;- array(rnorm(n = q*n), dim = c(n,q))
	# compute sufficient stats 
	suf_stat &lt;- compute_sufficient_statistics(y = y, 
	 z = z, K = K, x_data = x_data)
</code></pre>

<hr>
<h2 id='compute_sufficient_statistics_given_mu'>
Compute sufficient statistics given mu
</h2><span id='topic+compute_sufficient_statistics_given_mu'></span>

<h3>Description</h3>

<p>Compute sufficient statistics given <code class="reqn">y</code>, <code class="reqn">z</code> and <code class="reqn">\mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_sufficient_statistics_given_mu(y, z, K, x_data,mu)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_sufficient_statistics_given_mu_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix of factors
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_given_mu_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_given_mu_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_given_mu_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix with observed data
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_given_mu_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> matrix with marignal means per component
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with six entries of sufficient statistics.
</p>
<table role = "presentation">
<tr><td><code>cluster_size</code></td>
<td>
<p> Integer vector of length <code class="reqn">K</code> </p>
</td></tr>
<tr><td><code>sx</code></td>
<td>
 <p><code class="reqn">K\times p</code> array </p>
</td></tr>
<tr><td><code>sy</code></td>
<td>
 <p><code class="reqn">K\times q</code> array </p>
</td></tr>
<tr><td><code>sxx</code></td>
<td>
<p> Not used </p>
</td></tr>
<tr><td><code>syy</code></td>
<td>
 <p><code class="reqn">K\times q \times q</code> array </p>
</td></tr>
<tr><td><code>sxy</code></td>
<td>
 <p><code class="reqn">K\times p \times q</code> array </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>        data(waveDataset1500)
        x_data &lt;- as.matrix(waveDataset1500[ 1:20, -1]) # data
        z &lt;-  waveDataset1500[ 1:20, 1] # class
        p &lt;- dim(x_data)[2]
        n &lt;- dim(x_data)[1]
        q &lt;- 2
        K &lt;- length(table(z))           # 3 classes
        # give some arbitrary values to the parameters:
        set.seed(1)
        mu &lt;- array( runif(K * p), dim = c(K,p) )
	y &lt;- array(rnorm(n = q*n), dim = c(n,q))
	# compute sufficient stats 
	suf_stat &lt;- compute_sufficient_statistics_given_mu(y = y, 
	 z = z, K = K, x_data = x_data, mu = mu)
</code></pre>

<hr>
<h2 id='compute_sufficient_statistics_q0'>
Compute sufficient statistics for <code class="reqn">q = 0</code>
</h2><span id='topic+compute_sufficient_statistics_q0'></span>

<h3>Description</h3>

<p>Compute sufficient statistics given <code class="reqn">z</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_sufficient_statistics_q0(z, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_sufficient_statistics_q0_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_q0_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="compute_sufficient_statistics_q0_+3A_x_data">x_data</code></td>
<td>

<p>Data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with six entries of sufficient statistics.
</p>
<table role = "presentation">
<tr><td><code>cluster_size</code></td>
<td>
<p> Integer vector of length <code class="reqn">K</code> </p>
</td></tr>
<tr><td><code>sx</code></td>
<td>
 <p><code class="reqn">K\times p</code> array </p>
</td></tr>
<tr><td><code>sy</code></td>
<td>
<p> Not used here </p>
</td></tr>
<tr><td><code>sxx</code></td>
<td>
<p> Not used </p>
</td></tr>
<tr><td><code>syy</code></td>
<td>
<p> Not used here </p>
</td></tr>
<tr><td><code>sxy</code></td>
<td>
<p> Not used here </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>        data(waveDataset1500)
        x_data &lt;- as.matrix(waveDataset1500[ 1:20, -1]) # data
        z &lt;-  waveDataset1500[ 1:20, 1] # class
        p &lt;- dim(x_data)[2]
        n &lt;- dim(x_data)[1]
        q &lt;- 2
        K &lt;- length(table(z))           # 3 classes
	# compute sufficient stats 
	suf_stat &lt;- compute_sufficient_statistics_q0(
	 z = z, K = K, x_data = x_data)
</code></pre>

<hr>
<h2 id='CorMat_mcmc_summary'>
Compute quantiles for the correlation matrix. 
</h2><span id='topic+CorMat_mcmc_summary'></span>

<h3>Description</h3>

<p>Compute quantiles for the correlation matrix per cluster based on the MCMC output stored in a <code>fabMix.object</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CorMat_mcmc_summary(x, quantile_probs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CorMat_mcmc_summary_+3A_x">x</code></td>
<td>

<p>An object of class <code>fabMix.object</code>.
</p>
</td></tr>
<tr><td><code id="CorMat_mcmc_summary_+3A_quantile_probs">quantile_probs</code></td>
<td>

<p>Vector of probabilities for computing the corresponding quantiles.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>quantiles</code></td>
<td>
<p>A list containing the quantiles for the correlation matrix per component. Each element is a <code class="reqn">p\times p \times K</code> array, where <code class="reqn">p</code> and <code class="reqn">K</code> denote the dimension of the multivariate data and number of alive components for the selected model, respectively.</p>
</td></tr>
<tr><td><code>p_matrix</code></td>
<td>
<p> A <code class="reqn">p\times p\times K</code> array, where for each <code class="reqn">k = 1,\ldots,K</code> the <code class="reqn">p\times p</code> matrix <code>p_matrix[,,k]</code> contains the posterior probability <code class="reqn">1-2|0.5-P(\rho_{ij} &gt; 0)|</code> for <code class="reqn">i=1,\ldots,p</code>;  <code class="reqn">j=1,\ldots,p</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='CovMat_mcmc_summary'>
Compute quantiles for the covariance matrix. 
</h2><span id='topic+CovMat_mcmc_summary'></span>

<h3>Description</h3>

<p>Compute quantiles for the covariance matrix per cluster based on the MCMC output stored in a <code>fabMix.object</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovMat_mcmc_summary(x, quantile_probs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CovMat_mcmc_summary_+3A_x">x</code></td>
<td>

<p>An object of class <code>fabMix.object</code>.
</p>
</td></tr>
<tr><td><code id="CovMat_mcmc_summary_+3A_quantile_probs">quantile_probs</code></td>
<td>

<p>Vector of probabilities for computing the corresponding quantiles.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the quantiles for the covariance matrix per component. Each element is a <code class="reqn">p\times p \times K</code> array, where <code class="reqn">p</code> and <code class="reqn">K</code> denote the dimension of the multivariate data and number of alive components for the selected model, respectively.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='dealWithLabelSwitching'>
Apply label switching algorithms
</h2><span id='topic+dealWithLabelSwitching'></span>

<h3>Description</h3>

<p>This functions is a wrapper for the <code>label.switching</code> package and applies the <code>ECR</code> and <code>ECR.ITERATIVE.1</code> algorithms. The model may have the same variance of error terms per cluster or not. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dealWithLabelSwitching(sameSigma, x_data, outputFolder, q, burn, 
		z.true, compute_regularized_expression, Km)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dealWithLabelSwitching_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical value indicating whether the parameterization with the same error variance per cluster is used.
</p>
</td></tr>
<tr><td><code id="dealWithLabelSwitching_+3A_x_data">x_data</code></td>
<td>

<p>Data
</p>
</td></tr>
<tr><td><code id="dealWithLabelSwitching_+3A_outputfolder">outputFolder</code></td>
<td>

<p>Name of the folder where the <code>fabMix</code> function has saved its output
</p>
</td></tr>
<tr><td><code id="dealWithLabelSwitching_+3A_q">q</code></td>
<td>

<p>Number of factors
</p>
</td></tr>
<tr><td><code id="dealWithLabelSwitching_+3A_burn">burn</code></td>
<td>

<p>Discard observations as burn-in period (optional). 
</p>
</td></tr>
<tr><td><code id="dealWithLabelSwitching_+3A_z.true">z.true</code></td>
<td>

<p>An (optional) vector of cluster assignments which is considered as the groun-truth clustering of the data. Useful for direct comparisons against the real parameter values in simulated data. 
</p>
</td></tr>
<tr><td><code id="dealWithLabelSwitching_+3A_compute_regularized_expression">compute_regularized_expression</code></td>
<td>

<p>Logical. Should regularized expression be computed?
</p>
</td></tr>
<tr><td><code id="dealWithLabelSwitching_+3A_km">Km</code></td>
<td>

<p>Number of components in the overfitted mixture model.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The following files are produced in the output folder:
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>References</h3>

<p>Papastamoulis, P. (2016). <code>label.switching</code>: An R Package for Dealing with the Label Switching Problem in MCMC Outputs. Journal of Statistical Software, 69(1), 1-24.
</p>

<hr>
<h2 id='fabMix'>
Main function
</h2><span id='topic+fabMix'></span>

<h3>Description</h3>

<p>This function runs parallel chains under a prior tempering scheme of the Dirichlet prior distribution of mixture weights. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabMix(model, nChains, dirPriorAlphas, rawData, outDir, Kmax, mCycles, 
	burnCycles, g, h, alpha_sigma, beta_sigma, q, normalize,  
	thinning, zStart, nIterPerCycle, gibbs_z, 
	warm_up_overfitting, warm_up, overfittingInitialization, 
	progressGraphs, gwar, rmDir, parallelModels, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fabMix_+3A_model">model</code></td>
<td>

<p>Any subset of &quot;UUU&quot; &quot;CUU&quot; &quot;UCU&quot; &quot;CCU&quot; &quot;UCC&quot; &quot;UUC&quot; &quot;CUC&quot;, &quot;CCC&quot; indicating the fitted models. By default, all models are fitted. 
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_nchains">nChains</code></td>
<td>

<p>The number of parallel heated chains. When 'dirPriorAlphas' is supplied, 'nChains' can be ignored.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_dirprioralphas">dirPriorAlphas</code></td>
<td>

<p>vector of length <code>nChains</code> in the form of an increasing sequence of positive scalars. Each entry contains the (common) prior Dirichlet parameter for the corresponding chain. Default: <code>dirPriorAlphas = c(1, 1 + dN*(2:nChains - 1))/Kmax</code>, where <code>dN = 1</code>, for <code>nChains &gt; 1</code>. Otherwise, <code>dirPriorAlphas = 1/Kmax</code>. 
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_rawdata">rawData</code></td>
<td>

<p>The observed data as an <code class="reqn">n\times p</code> matrix. Clustering is performed on the rows of the matrix.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_outdir">outDir</code></td>
<td>

<p>Name of the output folder. An error is thrown if the directory already exists inside the current working directory. Note: it should NOT correspond to an absolute path, e.g.: <code>outDir = `fabMix_example`</code> is acceptable, but <code>outDir = `C:\Username\Documents\fabMix_example`</code> is not. 
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_kmax">Kmax</code></td>
<td>

<p>Number of components in the overfitted mixture. Default: 20.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_mcycles">mCycles</code></td>
<td>

<p>Number of MCMC cycles. Each cycle consists of <code>nIterPerCycle</code> MCMC iterations. At the end of each cycle a swap of the state of two randomly chosen adjacent chains is attempted.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_burncycles">burnCycles</code></td>
<td>

<p>Number of cycles that will be discarded as burn-in period.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_q">q</code></td>
<td>

<p>A vector containing the number of factors to be fitted.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Default value: TRUE. (Recommended) 
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_thinning">thinning</code></td>
<td>

<p>Optional integer denoting the thinning of the keeped MCMC cycles.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_zstart">zStart</code></td>
<td>

<p>Optional starting value for the allocation vector.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_niterpercycle">nIterPerCycle</code></td>
<td>

<p>Number of iteration per MCMC cycle. Default value: 10.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Select the gibbs sampling scheme for updating latent allocations of mixture model. Default value: 1.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_warm_up_overfitting">warm_up_overfitting</code></td>
<td>

<p>Number of iterations for the overfitting initialization scheme. Default value: 500.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_warm_up">warm_up</code></td>
<td>

<p>Number of iterations that will be used to initialize the models before starting proposing switchings. Default value: 5000.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_overfittinginitialization">overfittingInitialization</code></td>
<td>

<p>Logical value indicating whether the chains are initialized via the overfitting initialization scheme. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_progressgraphs">progressGraphs</code></td>
<td>

<p>Logical value indicating whether to plot successive states of the chains while the sampler runs. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_gwar">gwar</code></td>
<td>

<p>Initialization parameter. Default: 0.05.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_rmdir">rmDir</code></td>
<td>

<p>Logical value indicating whether to delete the <code>outDir</code> directory. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_parallelmodels">parallelModels</code></td>
<td>

<p>Model-level parallelization: An optional integer specifying the number of cores that will be used in order to fit in parallel each member of <code>model</code>. Default: NULL (no model-level parallelization).
</p>
</td></tr>
<tr><td><code id="fabMix_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\boldsymbol{X}_i</code>; <code class="reqn">i =1,\ldots,n</code> denote independent <code class="reqn">p</code>-dimensional random vectors. Let <code class="reqn">Y_i\in  R^q</code> with <code class="reqn">q &lt; p</code> denote the latent factor for observation <code class="reqn">i = 1,\ldots,n</code>. In the typical factor analysis model, each observation is modelled as <code class="reqn">\boldsymbol{X}_i = \boldsymbol{\mu} + \boldsymbol{\Lambda} \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i </code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\boldsymbol{\Sigma})</code>, where <code class="reqn">\boldsymbol{\varepsilon}_i</code> and <code class="reqn">Y_i</code> are assumed independent, <code class="reqn">i =1,\ldots,n</code>. The <code class="reqn">p\times q</code> matrix <code class="reqn">\Lambda</code> consists of the factor loadings. Assume that there are <code class="reqn">K</code> clusters and let <code class="reqn">Z_i</code> denotes the latent allocation of observation <code class="reqn">i</code> to one amongs the  <code class="reqn">k</code> clusters, with prior probability <code class="reqn">P(Z_i = k) = w_k</code>, <code class="reqn">k = 1,\ldots,K</code>, independent for <code class="reqn">i=1,\ldots,n</code>.  Following McNicholas et al (2008), the following parameterizations are used:
</p>
<p>UUU model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda}_k \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\boldsymbol{\Sigma}_k)</code>
</p>
<p>UCU model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda}_k \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\boldsymbol{\Sigma})</code>
</p>
<p>UUC model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda}_k \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\sigma_k \boldsymbol{I}_p)</code>
</p>
<p>UCC model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda}_k \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\sigma \boldsymbol{I}_p)</code>
</p>
<p>CUU model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda} \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\boldsymbol{\Sigma}_k)</code>
</p>
<p>CCU model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda} \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\boldsymbol{\Sigma})</code>
</p>
<p>CUC model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda} \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\sigma_k \boldsymbol{I}_p)</code>
</p>
<p>CCC model: <code class="reqn">(\boldsymbol{X}_i|Z_i = k) = \boldsymbol{\mu}_k + \boldsymbol{\Lambda} \boldsymbol{Y}_i + \boldsymbol{\varepsilon}_i</code>, with <code class="reqn">\boldsymbol{\varepsilon}_i \sim \mathcal N(0,\sigma \boldsymbol{I}_p)</code>
</p>
<p>In all cases, <code class="reqn">\boldsymbol{\varepsilon}_i</code> and <code class="reqn">\boldsymbol{Y}_i</code> are assumed independent, <code class="reqn">i =1,\ldots,n</code>. Note that <code class="reqn">\boldsymbol{\Sigma}_k</code> and <code class="reqn">\boldsymbol{\Sigma}</code> denote positive definite matrices, <code class="reqn">\boldsymbol{I}_p</code> denotes the <code class="reqn">p\times p</code> identity matrix and <code class="reqn">\sigma_k</code>, <code class="reqn">\sigma</code> denote positive scalars. 
</p>


<h3>Value</h3>

<p>An object of class <code>fabMix.object</code>, that is, a list consisting of the following entries:
</p>
<table role = "presentation">
<tr><td><code>bic</code></td>
<td>
<p>Bayesian Information Criterion per model and number of factors.</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>The estimated single best clustering of the observations according to the selected model.</p>
</td></tr>
<tr><td><code>n_Clusters_per_model</code></td>
<td>
<p>The most probable number of clusters (number of non-empty components of the overfitted mixture) per model and number of factors.</p>
</td></tr>
<tr><td><code>posterior_probability</code></td>
<td>
<p>The posterior probability of the estimated allocations according to the selected model.</p>
</td></tr>
<tr><td><code>covariance_matrix</code></td>
<td>
<p>The estimated posterior mean of the covariance matrix per cluster according to the selected model.</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>The estimated posterior mean of the mean per cluster according to the selected model.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>The estimated posterior mean of the mixing proportions according to the selected model.</p>
</td></tr>
<tr><td><code>selected_model</code></td>
<td>
<p>Data frame containing the parameterization, number of clusters and factors of the selected model.</p>
</td></tr>
<tr><td><code>mcmc</code></td>
<td>
<p>A list containing the MCMC draws for the parameters of the selected model. Each entry is returned as an <code>mcmc</code> object, a class imported from the <code>coda</code> package (Plummer et al, 2006). All component-specific parameters have been reordered according to the ECR algorithm in order to undo the label switching problem. However, the output corresponding to factor scores and factor loadings is not identifiable due to sign-switching across the MCMC trace.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>The observed data.</p>
</td></tr>
<tr><td><code>regularizedExpression</code></td>
<td>
<p>The regularized expressions of variable scores to each factor per cluster  (see Papastamoulis 2018, CSDA). </p>
</td></tr>
<tr><td><code>Kmap_prob</code></td>
<td>
<p>The posterior probability of the Maximum A Posteriori number of alive clusters for each parameterization and factor level.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>It is recommended to use: <code>normalize = TRUE</code> (default). Tuning of <code>dirPriorAlphas</code> may be necessary to achieve reasonable acceptance rates of chain swaps. Note that the output is reordered in order to deal with the label switching problem, according to the ECR algorithm applied by <code><a href="#topic+dealWithLabelSwitching">dealWithLabelSwitching</a></code> function. 
</p>
<p>Parallelization is enabled in both the chain-level as well as the model-level. By default all heated chains (specified by the <code>nchains</code> argument) run in parallel using (at most) the same number of threads (if available). If <code>parallelModels = NULL</code> (default), then the selected parameterizations will run (serially) on the same thread. Otherwise, if <code>parallelModels = x</code> (where <code>x</code> denotes a positive integer), the algorithm will first use <code>x</code> threads to fit the specified model parameterizations in parallel, and furthermore will also parallelize the heated chains (according to the remaining free cores on the user's system). The user should combine <code>parallelModels</code> with <code>nChains</code> efficiently, for example: if the number of available threads equals 12 and the user wishes to run 3 heated chains per model (recall that there are 8 parameterizations in total), then, an ideal allocation would be <code>parallelModels = 4</code> and <code>nChains = 3</code> because all available threads will be constantly busy. If the user wishes to run <code>nChains = 4</code> heated chains per model using 12 threads, then an ideal allocation would be <code>parallelModels = 3</code> models running in parallel. In the case where <code>parallelModels*nChains</code> &gt; <code>m</code>, with <code>m</code> denoting the available number of threads, the algorithm will first allocate min(<code>parallelModels</code>, <code>m</code>) threads to run the same number of parameterizations in parallel, and then the remaining threads (if any) will be used to process the parallel heated chains. If no other threads are available, the heated chains will be allocated to single threads. 
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>References</h3>

<p>Martyn Plummer, Nicky Best, Kate Cowles and Karen Vines (2006). CODA: Convergence Diagnosis and Output Analysis for MCMC, R News, vol 6, 7-11.
</p>
<p>McNicholas, P.D. and Murphy, T.B. Stat Comput (2008) 18: 285. https://doi.org/10.1007/s11222-008-9056-0.
</p>
<p>Papastamoulis, P. (2018). Overfitting Bayesian mixtures of factor analyzers with an unknown number of components. Computational Statistics and Data Analysis, 124: 220-234. DOI: 10.1016/j.csda.2018.03.007.
</p>
<p>Papastamoulis, P (2019).  Clustering multivariate data using factor analytic Bayesian mixtures with an unknown number of components. Statistics and Computing, doi: 10.1007/s11222-019-09891-z.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.fabMix.object">plot.fabMix.object</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># TOY EXAMPLE (very small numbers... only for CRAN check purposes)

#################################################################
# (a) using 2 cores in parallel, each one running 2 heated chains.
#################################################################
library('fabMix')

n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2		     # true number of clusters

sINV_diag = 1/((1:p))	 # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
			sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)

# Run `fabMix` for a _small_ number of iterations 
#	but considering only the `UUU` (maximal model),
# 	using the default prior parallel heating parameters `dirPriorAlphas`.
#	NOTE: `dirPriorAlphas` may require some tuning in general.


qRange &lt;- 2	# values for the number of factors (only the true number 
#                                                    is considered here)
Kmax &lt;- 2	# number of components for the overfitted mixture model
nChains &lt;- 2	# number of parallel heated chains

set.seed(1)
fm &lt;- fabMix( model = "UUU", nChains = nChains, 
	rawData = syntheticDataset$data, outDir = "toyExample",
        Kmax = Kmax, mCycles = 4, burnCycles = 1, q = qRange,
        g = 0.5, h = 0.5, alpha_sigma = 0.5, beta_sigma = 0.5, 
        warm_up_overfitting = 2, warm_up = 5) 

# WARNING: the following parameters: 
#  Kmax, nChains, mCycles, burnCycles, warm_up_overfitting, warm_up 
#	 should take (much) _larger_ values. E.g. a typical implementation consists of:
#        Kmax = 20, nChains &gt;= 3, mCycles = 1100, burnCycles = 100, 
#        warm_up_overfitting = 500, warm_up = 5000. 

# You may also print and plot
# print(fm)
# plot(fm)

#################################################################
# (b) using 12 cores_____________________________________________
#_______4 models with 3 heated chains running in parallel________
#_______considering all 8 model parameterizations________________
#################################################################
## Not run: 
library('fabMix')
set.seed(99)
n = 200                # sample size
p = 30                # number of variables
q = 2                # number of factors
K = 5		     # number of clusters
sINV_diag = rep(1/20,p) 	# diagonal of inverse variance of errors
syntheticDataset &lt;- simData(sameLambda=FALSE,K.true = K, n = n, q = q, p = p, 
			sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
qRange &lt;- 1:3	# range of values for the number of factors
Kmax &lt;- 20	# number of components for the overfitted mixture model
nChains &lt;- 3	# number of parallel heated chains

# the next command takes ~ 2 hours in a Linux machine with 12 threads.

fm &lt;- fabMix( parallelModels = 4, 
	nChains = nChains, 
	model = c("UUU","CUU","UCU","CCU","UCC","UUC","CUC","CCC"), 
	rawData = syntheticDataset$data, outDir = "toyExample_b",
        Kmax = Kmax, mCycles = 1100, burnCycles = 100, q = qRange) 

print(fm)
plot(fm, what = "BIC")
# see also
# plot(fm); summary(fm)


## End(Not run)


</code></pre>

<hr>
<h2 id='fabMix_CxC'>
Function to estimate the <code>CUC</code> and <code>CCC</code> models
</h2><span id='topic+fabMix_CxC'></span>

<h3>Description</h3>

<p>This function runs parallel chains under a prior tempering scheme of the Dirichlet prior distribution of mixture weights. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabMix_CxC(sameSigma, dirPriorAlphas, rawData, outDir, Kmax, mCycles, 
	burnCycles, g, h, alpha_sigma, beta_sigma, q, normalize,  
	thinning, zStart, nIterPerCycle, gibbs_z, 
	warm_up_overfitting, warm_up, overfittingInitialization, 
	progressGraphs, gwar, cccStart, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fabMix_CxC_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical value denoting the parameterization of the error variance per component. If <code>TRUE</code>, the parameterization CCU is fitted. Otherwise, the parameterization CUU is fitted.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_dirprioralphas">dirPriorAlphas</code></td>
<td>

<p>The prior Dirichlet parameters for each chain.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_rawdata">rawData</code></td>
<td>

<p>The observed data as an <code class="reqn">n\times p</code> matrix. Clustering is performed on the rows of the matrix.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_outdir">outDir</code></td>
<td>

<p>Name of the output folder.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_kmax">Kmax</code></td>
<td>

<p>Number of components in the overfitted mixture. Default: 20.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_mcycles">mCycles</code></td>
<td>

<p>Number of MCMC cycles. Each cycle consists of <code>nIterPerCycle</code> MCMC iterations. At the end of each cycle a swap of the state of two randomly chosen adjacent chains is attempted.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_burncycles">burnCycles</code></td>
<td>

<p>Number of cycles that will be discarded as burn-in period.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_q">q</code></td>
<td>

<p>Number of factors <code class="reqn">q</code>, where <code class="reqn">1 \leq q \leq L</code>. An error is thrown if the Ledermann bound (<code class="reqn">L</code>) is exceeded.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Default value: TRUE. 
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_thinning">thinning</code></td>
<td>

<p>Optional integer denoting the thinning of the keeped MCMC cycles.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_zstart">zStart</code></td>
<td>

<p>Optional starting value for the allocation vector.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_niterpercycle">nIterPerCycle</code></td>
<td>

<p>Number of iteration per MCMC cycle. Default value: 10.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Select the gibbs sampling scheme for updating latent allocations of mixture model. Default value: 1.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_warm_up_overfitting">warm_up_overfitting</code></td>
<td>

<p>Number of iterations for the overfitting initialization scheme. Default value: 100.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_warm_up">warm_up</code></td>
<td>

<p>Number of iterations that will be used to initialize the models before starting proposing switchings. Default value: 500.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_overfittinginitialization">overfittingInitialization</code></td>
<td>

<p>Logical value indicating whether the chains are initialized via the overfitting initialization scheme. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_progressgraphs">progressGraphs</code></td>
<td>

<p>Logical value indicating whether to plot successive states of the chains while the sampler runs. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_gwar">gwar</code></td>
<td>

<p>Initialization parameter. Default: 0.05.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_cccstart">cccStart</code></td>
<td>

<p>Initialization from the CCC model.
</p>
</td></tr>
<tr><td><code id="fabMix_CxC_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files written to <code>outDir</code>
</p>


<h3>Note</h3>

<p>It is recommended to always use: <code>normalize = TRUE</code> (default). Tuning of <code>dirPriorAlphas</code> may be necessary to achieve reasonable acceptance rates of chain swaps. Also note that the output is not identifiable due to label switching and the user has to subsequently call the <code>dealWithLabelSwitching</code> function. See the <code><a href="#topic+fabMix">fabMix</a></code> function for examples.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fabMix">fabMix</a></code>
</p>

<hr>
<h2 id='fabMix_CxU'>
Function to estimate the <code>CCU</code> and <code>CUU</code> models
</h2><span id='topic+fabMix_CxU'></span>

<h3>Description</h3>

<p>This function runs parallel chains under a prior tempering scheme of the Dirichlet prior distribution of mixture weights. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabMix_CxU(sameSigma, dirPriorAlphas, rawData, outDir, Kmax, mCycles, 
	burnCycles, g, h, alpha_sigma, beta_sigma, q, normalize,  
	thinning, zStart, nIterPerCycle, gibbs_z, 
	warm_up_overfitting, warm_up, overfittingInitialization, 
	progressGraphs, gwar, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fabMix_CxU_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical value denoting the parameterization of the error variance per component. If <code>TRUE</code>, the parameterization CCU is fitted. Otherwise, the parameterization CUU is fitted.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_dirprioralphas">dirPriorAlphas</code></td>
<td>

<p>The prior Dirichlet parameters for each chain.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_rawdata">rawData</code></td>
<td>

<p>The observed data as an <code class="reqn">n\times p</code> matrix. Clustering is performed on the rows of the matrix.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_outdir">outDir</code></td>
<td>

<p>Name of the output folder.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_kmax">Kmax</code></td>
<td>

<p>Number of components in the overfitted mixture. Default: 20.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_mcycles">mCycles</code></td>
<td>

<p>Number of MCMC cycles. Each cycle consists of <code>nIterPerCycle</code> MCMC iterations. At the end of each cycle a swap of the state of two randomly chosen adjacent chains is attempted.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_burncycles">burnCycles</code></td>
<td>

<p>Number of cycles that will be discarded as burn-in period.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_q">q</code></td>
<td>

<p>Number of factors <code class="reqn">q</code>, where <code class="reqn">1 \leq q \leq L</code>. An error is thrown if the Ledermann bound (<code class="reqn">L</code>) is exceeded.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Default value: TRUE. 
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_thinning">thinning</code></td>
<td>

<p>Optional integer denoting the thinning of the keeped MCMC cycles.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_zstart">zStart</code></td>
<td>

<p>Optional starting value for the allocation vector.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_niterpercycle">nIterPerCycle</code></td>
<td>

<p>Number of iteration per MCMC cycle. Default value: 10.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Select the gibbs sampling scheme for updating latent allocations of mixture model. Default value: 1.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_warm_up_overfitting">warm_up_overfitting</code></td>
<td>

<p>Number of iterations for the overfitting initialization scheme. Default value: 100.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_warm_up">warm_up</code></td>
<td>

<p>Number of iterations that will be used to initialize the models before starting proposing switchings. Default value: 500.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_overfittinginitialization">overfittingInitialization</code></td>
<td>

<p>Logical value indicating whether the chains are initialized via the overfitting initialization scheme. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_progressgraphs">progressGraphs</code></td>
<td>

<p>Logical value indicating whether to plot successive states of the chains while the sampler runs. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_gwar">gwar</code></td>
<td>

<p>Initialization parameter. Default: 0.05.
</p>
</td></tr>
<tr><td><code id="fabMix_CxU_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files written to <code>outDir</code>
</p>


<h3>Note</h3>

<p>It is recommended to always use: <code>normalize = TRUE</code> (default). Tuning of <code>dirPriorAlphas</code> may be necessary to achieve reasonable acceptance rates of chain swaps. Also note that the output is not identifiable due to label switching and the user has to subsequently call the <code>dealWithLabelSwitching</code> function. See the <code><a href="#topic+fabMix">fabMix</a></code> function for examples.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fabMix">fabMix</a></code>
</p>

<hr>
<h2 id='fabMix_missing_values'>
Function to estimate the UUU or UCU models in case of missing values
</h2><span id='topic+fabMix_missing_values'></span>

<h3>Description</h3>

<p>This function runs parallel chains under a prior tempering scheme of the Dirichlet prior distribution of mixture weights. Missing values are simulated from their full conditional posterior distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabMix_missing_values(sameSigma, dirPriorAlphas, rawData, outDir, Kmax, mCycles, 
	burnCycles, g, h, alpha_sigma, beta_sigma, q, normalize,  
	thinning, zStart, nIterPerCycle, gibbs_z, warm_up, 
	progressGraphs, gwar, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fabMix_missing_values_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical value denoting the parameterization of the error variance per component. If <code>sameSigma = TRUE</code>, the parameterization <code>UCU</code> is fitted, otherwise the <code>UUU</code> model is fitted.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_dirprioralphas">dirPriorAlphas</code></td>
<td>

<p>The prior Dirichlet parameters for each chain.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_rawdata">rawData</code></td>
<td>

<p>The observed data as an <code class="reqn">n\times p</code> matrix. Clustering is performed on the rows of the matrix.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_outdir">outDir</code></td>
<td>

<p>Name of the output folder.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_kmax">Kmax</code></td>
<td>

<p>Number of components in the overfitted mixture. Default: 20.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_mcycles">mCycles</code></td>
<td>

<p>Number of MCMC cycles. Each cycle consists of <code>nIterPerCycle</code> MCMC iterations. At the end of each cycle a swap of the state of two randomly chosen adjacent chains is attempted.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_burncycles">burnCycles</code></td>
<td>

<p>Number of cycles that will be discarded as burn-in period.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_q">q</code></td>
<td>

<p>Number of factors <code class="reqn">q</code>, where <code class="reqn">1 \leq q \leq L</code>. An error is thrown if the Ledermann bound (<code class="reqn">L</code>) is exceeded.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Default value: TRUE. 
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_thinning">thinning</code></td>
<td>

<p>Optional integer denoting the thinning of the keeped MCMC cycles.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_zstart">zStart</code></td>
<td>

<p>Optional starting value for the allocation vector.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_niterpercycle">nIterPerCycle</code></td>
<td>

<p>Number of iteration per MCMC cycle. Default value: 10.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Select the gibbs sampling scheme for updating latent allocations of mixture model. Default value: 1.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_warm_up">warm_up</code></td>
<td>

<p>NUmber of iterations that will be used to initialize the models before starting proposing switchings. Default value: 500.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_progressgraphs">progressGraphs</code></td>
<td>

<p>Logical value indicating whether to plot successive states of the chains while the sampler runs. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_gwar">gwar</code></td>
<td>

<p>Initialization parameter. Default: 0.05.
</p>
</td></tr>
<tr><td><code id="fabMix_missing_values_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files written to <code>outDir</code>
</p>


<h3>Note</h3>

<p>It is recommended to always use: <code>normalize = TRUE</code> (default). Tuning of <code>dirPriorAlphas</code> may be necessary to achieve reasonable acceptance rates of chain swaps. Also note that the output is not identifiable due to label switching and the user has to subsequently call the <code>dealWithLabelSwitching</code> function.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='fabMix_parallelModels'>
Function for model-level parallelization
</h2><span id='topic+fabMix_parallelModels'></span>

<h3>Description</h3>

<p>This function runs multiple copies of the <code>fabMix</code> function in parallel. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabMix_parallelModels(model, nChains, dirPriorAlphas, rawData, outDir, Kmax, mCycles, 
	burnCycles, g, h, alpha_sigma, beta_sigma, q, normalize,  
	thinning, zStart, nIterPerCycle, gibbs_z, 
	warm_up_overfitting, warm_up, overfittingInitialization, 
	progressGraphs, gwar, rmDir, parallelModels, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fabMix_parallelModels_+3A_model">model</code></td>
<td>

<p>Any subset of &quot;UUU&quot; &quot;CUU&quot; &quot;UCU&quot; &quot;CCU&quot; &quot;UCC&quot; &quot;UUC&quot; &quot;CUC&quot;, &quot;CCC&quot; indicating the fitted models.  
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_nchains">nChains</code></td>
<td>

<p>The number of parallel heated chains. When 'dirPriorAlphas' is supplied, 'nChains' can be ignored.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_dirprioralphas">dirPriorAlphas</code></td>
<td>

<p>vector of length <code>nChains</code> in the form of an increasing sequence of positive scalars. Each entry contains the (common) prior Dirichlet parameter for the corresponding chain. Default: <code>dirPriorAlphas = c(1, 1 + dN*(2:nChains - 1))/Kmax</code>, where <code>dN = 1</code>, for <code>nChains &gt; 1</code>. Otherwise, <code>dirPriorAlphas = 1/Kmax</code>. 
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_rawdata">rawData</code></td>
<td>

<p>The observed data as an <code class="reqn">n\times p</code> matrix. Clustering is performed on the rows of the matrix.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_outdir">outDir</code></td>
<td>

<p>Name of the output folder. An error is thrown if this directory already exists.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_kmax">Kmax</code></td>
<td>

<p>Number of components in the overfitted mixture. Default: 20.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_mcycles">mCycles</code></td>
<td>

<p>Number of MCMC cycles. Each cycle consists of <code>nIterPerCycle</code> MCMC iterations. At the end of each cycle a swap of the state of two randomly chosen adjacent chains is attempted.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_burncycles">burnCycles</code></td>
<td>

<p>Number of cycles that will be discarded as burn-in period.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_q">q</code></td>
<td>

<p>A vector containing the number of factors to be fitted.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Default value: TRUE. (Recommended) 
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_thinning">thinning</code></td>
<td>

<p>Optional integer denoting the thinning of the keeped MCMC cycles.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_zstart">zStart</code></td>
<td>

<p>Optional starting value for the allocation vector.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_niterpercycle">nIterPerCycle</code></td>
<td>

<p>Number of iteration per MCMC cycle. Default value: 10.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Select the gibbs sampling scheme for updating latent allocations of mixture model. Default value: 1.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_warm_up_overfitting">warm_up_overfitting</code></td>
<td>

<p>Number of iterations for the overfitting initialization scheme. Default value: 500.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_warm_up">warm_up</code></td>
<td>

<p>Number of iterations that will be used to initialize the models before starting proposing switchings. Default value: 5000.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_overfittinginitialization">overfittingInitialization</code></td>
<td>

<p>Logical value indicating whether the chains are initialized via the overfitting initialization scheme. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_progressgraphs">progressGraphs</code></td>
<td>

<p>Logical value indicating whether to plot successive states of the chains while the sampler runs. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_gwar">gwar</code></td>
<td>

<p>Initialization parameter. Default: 0.05.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_rmdir">rmDir</code></td>
<td>

<p>Logical value indicating whether to delete the <code>outDir</code> directory. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_parallelmodels">parallelModels</code></td>
<td>

<p>Model-level parallelization: An optional integer specifying the number of cores that will be used in order to fit in parallel each member of <code>model</code>. 
</p>
</td></tr>
<tr><td><code id="fabMix_parallelModels_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>fabMix.object</code> (see the <code><a href="#topic+fabMix">fabMix</a></code> function).
</p>


<h3>Note</h3>

<p>See the <code><a href="#topic+fabMix">fabMix</a></code> function for examples.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='fabMix_UxC'>
Function to estimate the <code>UUC</code> and <code>UCC</code> models
</h2><span id='topic+fabMix_UxC'></span>

<h3>Description</h3>

<p>This function runs parallel chains under a prior tempering scheme of the Dirichlet prior distribution of mixture weights. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabMix_UxC(sameSigma, dirPriorAlphas, rawData, outDir, Kmax, mCycles, 
	burnCycles, g, h, alpha_sigma, beta_sigma, q, normalize,  
	thinning, zStart, nIterPerCycle, gibbs_z, 
	warm_up_overfitting, warm_up, overfittingInitialization, 
	progressGraphs, gwar, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fabMix_UxC_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical value denoting the parameterization of the error variance per component. If <code>TRUE</code>, the parameterization CCU is fitted. Otherwise, the parameterization CUU is fitted.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_dirprioralphas">dirPriorAlphas</code></td>
<td>

<p>The prior Dirichlet parameters for each chain.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_rawdata">rawData</code></td>
<td>

<p>The observed data as an <code class="reqn">n\times p</code> matrix. Clustering is performed on the rows of the matrix.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_outdir">outDir</code></td>
<td>

<p>Name of the output folder.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_kmax">Kmax</code></td>
<td>

<p>Number of components in the overfitted mixture. Default: 20.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_mcycles">mCycles</code></td>
<td>

<p>Number of MCMC cycles. Each cycle consists of <code>nIterPerCycle</code> MCMC iterations. At the end of each cycle a swap of the state of two randomly chosen adjacent chains is attempted.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_burncycles">burnCycles</code></td>
<td>

<p>Number of cycles that will be discarded as burn-in period.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_q">q</code></td>
<td>

<p>Number of factors <code class="reqn">q</code>, where <code class="reqn">1 \leq q \leq L</code>. An error is thrown if the Ledermann bound (<code class="reqn">L</code>) is exceeded.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Default value: TRUE. 
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_thinning">thinning</code></td>
<td>

<p>Optional integer denoting the thinning of the keeped MCMC cycles.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_zstart">zStart</code></td>
<td>

<p>Optional starting value for the allocation vector.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_niterpercycle">nIterPerCycle</code></td>
<td>

<p>Number of iteration per MCMC cycle. Default value: 10.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Select the gibbs sampling scheme for updating latent allocations of mixture model. Default value: 1.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_warm_up_overfitting">warm_up_overfitting</code></td>
<td>

<p>Number of iterations for the overfitting initialization scheme. Default value: 100.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_warm_up">warm_up</code></td>
<td>

<p>Number of iterations that will be used to initialize the models before starting proposing switchings. Default value: 500.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_overfittinginitialization">overfittingInitialization</code></td>
<td>

<p>Logical value indicating whether the chains are initialized via the overfitting initialization scheme. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_progressgraphs">progressGraphs</code></td>
<td>

<p>Logical value indicating whether to plot successive states of the chains while the sampler runs. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_gwar">gwar</code></td>
<td>

<p>Initialization parameter. Default: 0.05.
</p>
</td></tr>
<tr><td><code id="fabMix_UxC_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files written to <code>outDir</code>
</p>


<h3>Note</h3>

<p>It is recommended to always use: <code>normalize = TRUE</code> (default). Tuning of <code>dirPriorAlphas</code> may be necessary to achieve reasonable acceptance rates of chain swaps. Also note that the output is not identifiable due to label switching and the user has to subsequently call the <code>dealWithLabelSwitching</code> function. See the <code><a href="#topic+fabMix">fabMix</a></code> function for examples.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fabMix">fabMix</a></code>
</p>

<hr>
<h2 id='fabMix_UxU'>
Function to estimate the <code>UUU</code> and <code>UCU</code> model
</h2><span id='topic+fabMix_UxU'></span>

<h3>Description</h3>

<p>This function runs parallel chains under a prior tempering scheme of the Dirichlet prior distribution of mixture weights. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fabMix_UxU(sameSigma, dirPriorAlphas, rawData, outDir, Kmax, mCycles, 
	burnCycles, g, h, alpha_sigma, beta_sigma, q, normalize,  
	thinning, zStart, nIterPerCycle, gibbs_z, 
	warm_up_overfitting, warm_up, overfittingInitialization, 
	progressGraphs, gwar, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fabMix_UxU_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical value denoting the parameterization of the error variance per component. If <code>TRUE</code>, the parameterization <code class="reqn">\Sigma_1 = \ldots = \Sigma_K</code> is fitted.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_dirprioralphas">dirPriorAlphas</code></td>
<td>

<p>The prior Dirichlet parameters for each chain.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_rawdata">rawData</code></td>
<td>

<p>The observed data as an <code class="reqn">n\times p</code> matrix. Clustering is performed on the rows of the matrix.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_outdir">outDir</code></td>
<td>

<p>Name of the output folder.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_kmax">Kmax</code></td>
<td>

<p>Number of components in the overfitted mixture. Default: 20.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_mcycles">mCycles</code></td>
<td>

<p>Number of MCMC cycles. Each cycle consists of <code>nIterPerCycle</code> MCMC iterations. At the end of each cycle a swap of the state of two randomly chosen adjacent chains is attempted.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_burncycles">burnCycles</code></td>
<td>

<p>Number of cycles that will be discarded as burn-in period.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_q">q</code></td>
<td>

<p>Number of factors <code class="reqn">q</code>, where <code class="reqn">1 \leq q \leq L</code>. An error is thrown if the Ledermann bound (<code class="reqn">L</code>) is exceeded.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Default value: TRUE. 
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_thinning">thinning</code></td>
<td>

<p>Optional integer denoting the thinning of the keeped MCMC cycles.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_zstart">zStart</code></td>
<td>

<p>Optional starting value for the allocation vector.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_niterpercycle">nIterPerCycle</code></td>
<td>

<p>Number of iteration per MCMC cycle. Default value: 10.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Select the gibbs sampling scheme for updating latent allocations of mixture model. Default value: 1.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_warm_up_overfitting">warm_up_overfitting</code></td>
<td>

<p>Number of iterations for the overfitting initialization scheme. Default value: 100.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_warm_up">warm_up</code></td>
<td>

<p>Number of iterations that will be used to initialize the models before starting proposing switchings. Default value: 500.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_overfittinginitialization">overfittingInitialization</code></td>
<td>

<p>Logical value indicating whether the chains are initialized via the overfitting initialization scheme. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_progressgraphs">progressGraphs</code></td>
<td>

<p>Logical value indicating whether to plot successive states of the chains while the sampler runs. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_gwar">gwar</code></td>
<td>

<p>Initialization parameter. Default: 0.05.
</p>
</td></tr>
<tr><td><code id="fabMix_UxU_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files written to <code>outDir</code>
</p>


<h3>Note</h3>

<p>It is recommended to always use: <code>normalize = TRUE</code> (default). Tuning of <code>dirPriorAlphas</code> may be necessary to achieve reasonable acceptance rates of chain swaps. Also note that the output is not identifiable due to label switching and the user has to subsequently call the <code>dealWithLabelSwitching</code> function. See the <code><a href="#topic+fabMix">fabMix</a></code> function for examples.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fabMix">fabMix</a></code>
</p>

<hr>
<h2 id='getStuffForDIC'>
Compute information criteria
</h2><span id='topic+getStuffForDIC'></span>

<h3>Description</h3>

<p>This function computes four information criteria for a given run of the <code>fabMix</code> algorithm, namely: AIC, BIC, DIC and <code class="reqn">\mbox{DIC}_2</code>. Given various runs with different number of factors, the selected model corresponds to the one with the smalled value of the selected criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getStuffForDIC(sameSigma, sameLambda, isotropic, x_data, outputFolder, q, burn, 
				Km, normalize, discardLower)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getStuffForDIC_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical value indicating whether the parameterization with the same variance of errors per component is used. Default: TRUE.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_samelambda">sameLambda</code></td>
<td>

<p>Logical value indicating whether the parameterization with same loadings per component is used. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_isotropic">isotropic</code></td>
<td>

<p>Logical value indicating whether the parameterization with isotropic error variance per component is used. Default: FALSE.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_x_data">x_data</code></td>
<td>

<p>Observed data.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_outputfolder">outputFolder</code></td>
<td>

<p>Name of the folder where the <code>fabMix</code> function has saved its output.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_q">q</code></td>
<td>

<p>Number of factors. Note that this should coincide with the number of factors in the <code>fabMix</code> run.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_burn">burn</code></td>
<td>

<p>Discard observations as burn-in period (optional).
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_km">Km</code></td>
<td>

<p>Number of components in the overfitted mixture model. Note that this should coincide with the same entry in the <code>fabMix</code> run.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_normalize">normalize</code></td>
<td>

<p>Should the observed data be normalized? Note that this should coincide with the same entry in the <code>fabMix</code> run. Default value: TRUE.
</p>
</td></tr>
<tr><td><code id="getStuffForDIC_+3A_discardlower">discardLower</code></td>
<td>

<p>Discard draws with log-likelihood values lower than the specific quantile. This applied only for the DIC computation. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The information criteria are saved to the <code>informationCriteria_map_model.txt</code> file in the <code>outputFolder</code>. 
</p>


<h3>Note</h3>

<p>It is well known that DIC tends to overfit, so it advised to compare models with different number of factors using AIC or BIC. The main function of the package uses BIC. 
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='log_dirichlet_pdf'>
Log-density function of the Dirichlet distribution
</h2><span id='topic+log_dirichlet_pdf'></span>

<h3>Description</h3>

<p>Log-density function of the Dirichlet distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_dirichlet_pdf(alpha, weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_dirichlet_pdf_+3A_alpha">alpha</code></td>
<td>

<p>Parameter vector
</p>
</td></tr>
<tr><td><code id="log_dirichlet_pdf_+3A_weights">weights</code></td>
<td>

<p>Vector of weights
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-density of the <code class="reqn">D(alpha_1,\ldots,\alpha_k)</code> evaluated at <code class="reqn">w_1,\ldots,w_k</code>.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='myDirichlet'>
Simulate from the Dirichlet distribution
</h2><span id='topic+myDirichlet'></span>

<h3>Description</h3>

<p>Generate a random draw from the Dirichlet distribution <code class="reqn">D(\alpha_1,\ldots,\alpha_k)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>myDirichlet(alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="myDirichlet_+3A_alpha">alpha</code></td>
<td>

<p>Parameter vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Simulated vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='observed.log.likelihood0'>
Log-likelihood of the mixture model
</h2><span id='topic+observed.log.likelihood0'></span>

<h3>Description</h3>

<p>Log-likelihood of the mixture model evaluated only at the alive components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>observed.log.likelihood0(x_data, w, mu, Lambda, Sigma, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="observed.log.likelihood0_+3A_x_data">x_data</code></td>
<td>

<p>The observed data
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_+3A_w">w</code></td>
<td>

<p>Vector of mixture weights
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_+3A_mu">mu</code></td>
<td>

<p>Vector of marginal means
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_+3A_lambda">Lambda</code></td>
<td>

<p>Factor loadings
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_+3A_sigma">Sigma</code></td>
<td>

<p>Diagonal of the common covariance matrix of the errors per cluster
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- waveDataset1500[ 1:20, -1] # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	Lambda &lt;- array( runif(K*p*q), dim = c(K,p,q) )
	SigmaINV &lt;- array(1, dim = c(p,p))
	Sigma &lt;- 1/diag(SigmaINV)
	# compute the complete.log.likelihood
	observed.log.likelihood0(x_data = x_data, w = w, 
		mu = mu, Lambda = Lambda, Sigma = Sigma, z = z)
</code></pre>

<hr>
<h2 id='observed.log.likelihood0_q0_sameSigma'>
Log-likelihood of the mixture model for <code class="reqn">q=0</code> and same variance of errors
</h2><span id='topic+observed.log.likelihood0_q0_sameSigma'></span>

<h3>Description</h3>

<p>Log-likelihood of the mixture model evaluated only at the alive components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>observed.log.likelihood0_q0_sameSigma(x_data, w, mu, Sigma, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="observed.log.likelihood0_q0_sameSigma_+3A_x_data">x_data</code></td>
<td>

<p>The observed data
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_q0_sameSigma_+3A_w">w</code></td>
<td>

<p>Vector of mixture weights
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_q0_sameSigma_+3A_mu">mu</code></td>
<td>

<p>Vector of marginal means
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_q0_sameSigma_+3A_sigma">Sigma</code></td>
<td>

<p>Covariance matrix of the errors per cluster
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_q0_sameSigma_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- waveDataset1500[ 1:20, -1] # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	SigmaINV &lt;- array(1, dim = c(p,p))
	Sigma &lt;- 1/diag(SigmaINV)
	# compute the complete.log.likelihood
	observed.log.likelihood0_q0_sameSigma(x_data = x_data, w = w, 
		mu = mu,  Sigma = Sigma, z = z)
</code></pre>

<hr>
<h2 id='observed.log.likelihood0_Sj'>
Log-likelihood of the mixture model
</h2><span id='topic+observed.log.likelihood0_Sj'></span>

<h3>Description</h3>

<p>Log-likelihood of the mixture model evaluated only at the alive components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>observed.log.likelihood0_Sj(x_data, w, mu, Lambda, Sigma, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="observed.log.likelihood0_Sj_+3A_x_data">x_data</code></td>
<td>

<p>The observed data
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_+3A_w">w</code></td>
<td>

<p>Vector of mixture weights
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_+3A_mu">mu</code></td>
<td>

<p>Vector of marginal means
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_+3A_lambda">Lambda</code></td>
<td>

<p>Factor loadings
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_+3A_sigma">Sigma</code></td>
<td>

<p><code class="reqn">K\times p</code> matrix with each row containing the diagonal of the covariance matrix of the errors per cluster
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- waveDataset1500[ 1:20, -1] # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	Lambda &lt;- array( runif(K*p*q), dim = c(K,p,q) )
	Sigma &lt;- matrix(1:K, nrow = K, ncol = p)
	# compute the complete.log.likelihood
	observed.log.likelihood0_Sj(x_data = x_data, w = w, 
		mu = mu, Lambda = Lambda, Sigma = Sigma, z = z)
</code></pre>

<hr>
<h2 id='observed.log.likelihood0_Sj_q0'>
Log-likelihood of the mixture model for <code class="reqn">q=0</code>
</h2><span id='topic+observed.log.likelihood0_Sj_q0'></span>

<h3>Description</h3>

<p>Log-likelihood of the mixture model evaluated only at the alive components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>observed.log.likelihood0_Sj_q0(x_data, w, mu, Sigma, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="observed.log.likelihood0_Sj_q0_+3A_x_data">x_data</code></td>
<td>

<p>The observed data
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_q0_+3A_w">w</code></td>
<td>

<p>Vector of mixture weights
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_q0_+3A_mu">mu</code></td>
<td>

<p>Vector of marginal means
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_q0_+3A_sigma">Sigma</code></td>
<td>

<p><code class="reqn">K\times p</code> matrix with each row containing the diagonal of the covariance matrix of the errors per cluster
</p>
</td></tr>
<tr><td><code id="observed.log.likelihood0_Sj_q0_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood value
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	library('fabMix')
	data(waveDataset1500)
	x_data &lt;- waveDataset1500[ 1:20, -1] # data
	z &lt;-  waveDataset1500[ 1:20, 1]	# class
	p &lt;- dim(x_data)[2]
	q &lt;- 2
	K &lt;- length(table(z))		# 3 classes
	# give some arbitrary values to the parameters:
	set.seed(1)
	w &lt;- rep(1/K, K)
	mu &lt;- array( runif(K * p), dim = c(K,p) )
	Sigma &lt;- matrix(1:K, nrow = K, ncol = p)
	# compute the complete.log.likelihood
	observed.log.likelihood0_Sj_q0(x_data = x_data, w = w, 
		mu = mu, Sigma = Sigma, z = z)
</code></pre>

<hr>
<h2 id='overfitting_q0'>
MCMC sampler for <code class="reqn">q=0</code>
</h2><span id='topic+overfitting_q0'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a mixture model with diagonal covariance structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfitting_q0(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfitting_q0_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfitting_q0_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='overfitting_q0_sameSigma'>
MCMC sampler for <code class="reqn">q=0</code> and same error variance parameterization
</h2><span id='topic+overfitting_q0_sameSigma'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a mixture model with diagonal covariance structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfitting_q0_sameSigma(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfitting_q0_sameSigma_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfitting_q0_sameSigma_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='overfittingMFA'>
Basic MCMC sampler for the <code>UCU</code> model
</h2><span id='topic+overfittingMFA'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='overfittingMFA_CCC'>
Basic MCMC sampler for the <code>CCC</code> model
</h2><span id='topic+overfittingMFA_CCC'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a CCC mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_CCC(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_CCC_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCC_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA_CCC &lt;- overfittingMFA_CCC(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='overfittingMFA_CCU'>
Basic MCMC sampler for the <code>CCU</code> model
</h2><span id='topic+overfittingMFA_CCU'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a CCU mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_CCU(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_CCU_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CCU_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA_CCU(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='overfittingMFA_CUC'>
Basic MCMC sampler for the <code>CUC</code> model
</h2><span id='topic+overfittingMFA_CUC'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a CUC mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_CUC(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_CUC_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUC_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA_CUC(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='overfittingMFA_CUU'>
Basic MCMC sampler for the <code>CUU</code> model
</h2><span id='topic+overfittingMFA_CUU'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a CUU mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_CUU(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_CUU_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_CUU_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA_CUU(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='overfittingMFA_missing_values'>
Basic MCMC sampler for the case of missing data
</h2><span id='topic+overfittingMFA_missing_values'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_missing_values(missing_entries, x_data, originalX, outputDirectory, Kmax, 
	m, thinning, burn, g, h, alpha_prior, alpha_sigma, 
	beta_sigma, start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_missing_values_+3A_missing_entries">missing_entries</code></td>
<td>

<p>list which contains the row number (1st entry) and column indexes (subsequent entries) for every row containing missing values.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_missing_values_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='overfittingMFA_Sj'>
Basic MCMC sampler for the <code>UUU</code> model
</h2><span id='topic+overfittingMFA_Sj'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_Sj(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_Sj_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA_Sj(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='overfittingMFA_Sj_missing_values'>
Basic MCMC sampler for the case of missing data and different error variance
</h2><span id='topic+overfittingMFA_Sj_missing_values'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_Sj_missing_values(missing_entries, x_data, originalX, 
	outputDirectory, Kmax, 
	m, thinning, burn, g, h, alpha_prior, alpha_sigma, 
	beta_sigma, start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_missing_entries">missing_entries</code></td>
<td>

<p>list which contains the row number (1st entry) and column indexes (subsequent entries) for every row containing missing values.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_Sj_missing_values_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of files</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='overfittingMFA_UCC'>
Basic MCMC sampler for the <code>UCC</code> model
</h2><span id='topic+overfittingMFA_UCC'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a UCC mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_UCC(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_UCC_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UCC_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA_UCC(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='overfittingMFA_UUC'>
Basic MCMC sampler for the <code>UUC</code> model
</h2><span id='topic+overfittingMFA_UUC'></span>

<h3>Description</h3>

<p>Gibbs sampling for fitting a UUC mixture model of factor analyzers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overfittingMFA_UUC(x_data, originalX, outputDirectory, Kmax, m, thinning, burn, 
	g, h, alpha_prior, alpha_sigma, beta_sigma, 
	start_values, q, zStart, gibbs_z, lowerTriangular)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="overfittingMFA_UUC_+3A_x_data">x_data</code></td>
<td>

<p>normalized data
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_originalx">originalX</code></td>
<td>

<p>observed raw data (only for plotting purpose)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_outputdirectory">outputDirectory</code></td>
<td>

<p>Name of the output folder
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_kmax">Kmax</code></td>
<td>

<p>Number of mixture components
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_m">m</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_thinning">thinning</code></td>
<td>

<p>Thinning of chain
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_burn">burn</code></td>
<td>

<p>Burn-in period
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_g">g</code></td>
<td>

<p>Prior parameter <code class="reqn">g</code>. Default value: <code class="reqn">g = 2</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_h">h</code></td>
<td>

<p>Prior parameter <code class="reqn">h</code>. Default value: <code class="reqn">h = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_alpha_prior">alpha_prior</code></td>
<td>

<p>Parameters of the Dirichlet prior distribution of mixture weights.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>. Default value: <code class="reqn">\alpha = 2</code>.	
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>. Default value: <code class="reqn">\beta = 1</code>.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_start_values">start_values</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_q">q</code></td>
<td>

<p>Number of factors.
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_zstart">zStart</code></td>
<td>

<p>Optional (not used)
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_gibbs_z">gibbs_z</code></td>
<td>

<p>Optional
</p>
</td></tr>
<tr><td><code id="overfittingMFA_UUC_+3A_lowertriangular">lowerTriangular</code></td>
<td>

<p>logical value indicating whether a lower triangular parameterization should be imposed on the matrix of factor loadings (if TRUE) or not. Default: TRUE.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of files written in <code>outputDirectory</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
colnames(syntheticDataset$data) &lt;- paste0("x_",1:p)
Kmax &lt;- 4       # number of components for the overfitted mixture model

set.seed(1)
overfittingMFA_UUC(x_data = syntheticDataset$data, 
	originalX = syntheticDataset$data, outputDirectory = 'outDir', 
	Kmax = Kmax, m = 5, burn = 1, 
	g = 0.5, h = 0.5, alpha_prior = rep(1, Kmax), 
	alpha_sigma = 0.5, beta_sigma = 0.5, 
	start_values = FALSE, q = 2,  gibbs_z = 1)
list.files('outDir')
unlink('outDir', recursive = TRUE)

</code></pre>

<hr>
<h2 id='plot.fabMix.object'>
Plot function
</h2><span id='topic+plot.fabMix.object'></span>

<h3>Description</h3>

<p>This function plots <code>fabMix</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fabMix.object'
plot(x, what, variableSubset, class_mfrow, sig_correlation, confidence, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.fabMix.object_+3A_x">x</code></td>
<td>

<p>An object of class <code>fabMix.object</code>, which is returned by the <code>fabMix</code> function.
</p>
</td></tr>
<tr><td><code id="plot.fabMix.object_+3A_what">what</code></td>
<td>

<p>One of the &quot;BIC&quot;, &quot;classification_matplot&quot;, &quot;classification_pairs&quot;, &quot;correlation&quot;, &quot;factor_loadings&quot;. The plot will display the BIC values per model and number of factors (along with the most probable number of clusters as text), a matplot per cluster for the selected model, scatterplots pairs, the estimated correlation matrix per cluster, and the MAP estimate of factor loadings, respectively.
</p>
</td></tr>
<tr><td><code id="plot.fabMix.object_+3A_variablesubset">variableSubset</code></td>
<td>

<p>An optional subset of the variables. By default, all variables are selected.
</p>
</td></tr>
<tr><td><code id="plot.fabMix.object_+3A_class_mfrow">class_mfrow</code></td>
<td>

<p>An optional integer vector of length 2, that will be used to set the <code>mfrow</code> for &quot;classification_matplot&quot; and &quot;correlation&quot; plots. By default, each plot is printed to a new plotting area.
</p>
</td></tr>
<tr><td><code id="plot.fabMix.object_+3A_sig_correlation">sig_correlation</code></td>
<td>

<p>The &ldquo;significance-level&rdquo; for plotting the correlation between variables. Note that this is an estimate of a posterior probability and not a significance level as defined in frequentist statistics. Default value: NULL (all correlations are plotted).
</p>
</td></tr>
<tr><td><code id="plot.fabMix.object_+3A_confidence">confidence</code></td>
<td>

<p>Confidence level(s) for plotting the Highest Density Interval(s) (as shown via <code>what = 2</code>). Default: <code>confidence = 0.95</code>.
</p>
</td></tr>
<tr><td><code id="plot.fabMix.object_+3A_...">...</code></td>
<td>

<p>ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the BIC values are plotted, a number indicates the most probable number of &ldquo;alive&rdquo; clusters. The pairwise scatterplots (<code>what = "classification_pairs"</code>) are created using the <code>coordProj</code> function of the <code>mclust</code> package. The <code>what = "correlation"</code> is plotted using the <code>corrplot</code> package. Note that the <code>what = "classification_matplot"</code> plots the original data (before scaling and centering). On the other hand, the option <code>what = "classification_pairs"</code> plots the centered and scaled data. 
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>References</h3>

<p>Luca Scrucca and Michael Fop and Thomas Brendan Murphy and Adrian E. Raftery (2017). mclust 5: clustering, classification and density estimation using Gaussian finite mixture models. The R Journal, 8(1): 205&ndash;233.
</p>
<p>Taiyun Wei and Viliam Simko (2017). R package &quot;corrplot&quot;:
Visualization of a Correlation Matrix (Version 0.84). Available from
https://github.com/taiyun/corrplot
</p>

<hr>
<h2 id='print.fabMix.object'>
Print function
</h2><span id='topic+print.fabMix.object'></span>

<h3>Description</h3>

<p>This function prints a summary of objects returned by the <code>fabMix</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fabMix.object'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.fabMix.object_+3A_x">x</code></td>
<td>

<p>An object of class <code>fabMix.object</code>, which is returned by the <code>fabMix</code> function.
</p>
</td></tr>
<tr><td><code id="print.fabMix.object_+3A_...">...</code></td>
<td>

<p>ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function prints some basic information for a <code>fabMix.object</code>.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='readLambdaValues'>
Read Lambda values.
</h2><span id='topic+readLambdaValues'></span>

<h3>Description</h3>

<p>Function to read Lambda values from file. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readLambdaValues(myFile,K,p,q)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="readLambdaValues_+3A_myfile">myFile</code></td>
<td>

<p>File containing Lambda values
</p>
</td></tr>
<tr><td><code id="readLambdaValues_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="readLambdaValues_+3A_p">p</code></td>
<td>

<p>Number of variables
</p>
</td></tr>
<tr><td><code id="readLambdaValues_+3A_q">q</code></td>
<td>

<p>Number of factors
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">K\times p \times q</code> array of factor loadings. 
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='simData'>
Synthetic data generator
</h2><span id='topic+simData'></span>

<h3>Description</h3>

<p>Simulate data from a multivariate normal mixture using a mixture of factor analyzers mechanism. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simData(sameSigma, sameLambda, p, q, K.true, n, loading_means, loading_sd, sINV_values)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simData_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical. 
</p>
</td></tr>
<tr><td><code id="simData_+3A_samelambda">sameLambda</code></td>
<td>

<p>Logical. 
</p>
</td></tr>
<tr><td><code id="simData_+3A_p">p</code></td>
<td>

<p>The dimension of the multivariate normal distribution (<code class="reqn">p &gt; 1</code>). 
</p>
</td></tr>
<tr><td><code id="simData_+3A_q">q</code></td>
<td>

<p>Number of factors. It should be strictly smaller than p.
</p>
</td></tr>
<tr><td><code id="simData_+3A_k.true">K.true</code></td>
<td>

<p>The number of mixture components (clusters).
</p>
</td></tr>
<tr><td><code id="simData_+3A_n">n</code></td>
<td>

<p>Sample size.
</p>
</td></tr>
<tr><td><code id="simData_+3A_loading_means">loading_means</code></td>
<td>

<p>A vector which contains the means of blocks of factor loadings.
</p>
<p>Default: <code>loading_means = c(-30,-20,-10,10, 20, 30)</code>.
</p>
</td></tr>
<tr><td><code id="simData_+3A_loading_sd">loading_sd</code></td>
<td>

<p>A vector which contains the standard deviations of blocks of factor loadings. 
</p>
<p>Default: <code>loading_sd &lt;- rep(2, length(loading_means))</code>.
</p>
</td></tr>
<tr><td><code id="simData_+3A_sinv_values">sINV_values</code></td>
<td>

<p>A vector which contains the values of the diagonal of the (common) inverse covariance matrix, if <code>sigmaTrue = TRUE</code>. An <code class="reqn">K\times p</code> matrix which contains the values of the diagonal of the inverse covariance matrix per component, if <code>sigmaTrue = FALSE</code>. 
</p>
<p>Default: <code> sINV_values = rgamma(p, shape = 1, rate = 1)</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following entries:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>

<p><code class="reqn">n\times p</code> array containing the simulated data.
</p>
</td></tr>
<tr><td><code>class</code></td>
<td>

<p><code class="reqn">n</code>-dimensional vector containing the class of each observation.
</p>
</td></tr>
<tr><td><code>factorLoadings</code></td>
<td>

<p><code class="reqn">K.true\times p \times q</code>-array containing the factor loadings <code class="reqn">\Lambda_{krj}</code> per cluster <code class="reqn">k</code>, feature <code class="reqn">r</code> and factor <code class="reqn">j</code>, where <code class="reqn">k=1,\ldots,K</code>; <code class="reqn">r=1,\ldots,p</code>; <code class="reqn">j=1,\ldots,q</code>.
</p>
</td></tr>
<tr><td><code>means</code></td>
<td>

<p><code class="reqn">K.true\times p</code> matrix containing the marginal means <code class="reqn">\mu_{kr}</code>, <code class="reqn">k=1,\ldots,K</code>; <code class="reqn">r=1,\ldots,p</code>.
</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>

<p><code class="reqn">p\times p</code> diagonal matrix containing the variance of errors <code class="reqn">\sigma_{rr}</code>, <code class="reqn">r=1,\ldots,p</code>. Note that the same variance of errors is assumed for each cluster.
</p>
</td></tr>
<tr><td><code>factors</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix containing the simulated factor values.
</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>

<p><code class="reqn">K.true</code>-dimensional vector containing the weight of each cluster.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The marginal variance for cluster <code class="reqn">k</code> is equal to <code class="reqn">\Lambda_k\Lambda_k^{T} + \Sigma</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')

n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
summary(syntheticDataset)
</code></pre>

<hr>
<h2 id='simData2'>
Synthetic data generator 2
</h2><span id='topic+simData2'></span>

<h3>Description</h3>

<p>Simulate data from a multivariate normal mixture using a mixture of factor analyzers mechanism. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simData2(sameSigma,  p, q, K.true, n, loading_means, loading_sd, sINV_values)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simData2_+3A_samesigma">sameSigma</code></td>
<td>

<p>Logical. 
</p>
</td></tr>
<tr><td><code id="simData2_+3A_p">p</code></td>
<td>

<p>The dimension of the multivariate normal distribution (<code class="reqn">p &gt; 1</code>). 
</p>
</td></tr>
<tr><td><code id="simData2_+3A_q">q</code></td>
<td>

<p>Number of factors. It should be strictly smaller than p.
</p>
</td></tr>
<tr><td><code id="simData2_+3A_k.true">K.true</code></td>
<td>

<p>The number of mixture components (clusters).
</p>
</td></tr>
<tr><td><code id="simData2_+3A_n">n</code></td>
<td>

<p>Sample size.
</p>
</td></tr>
<tr><td><code id="simData2_+3A_loading_means">loading_means</code></td>
<td>

<p>A vector which contains the means of blocks of factor loadings.
</p>
<p>Default: <code>loading_means = c(-30,-20,-10,10, 20, 30)</code>.
</p>
</td></tr>
<tr><td><code id="simData2_+3A_loading_sd">loading_sd</code></td>
<td>

<p>A vector which contains the standard deviations of blocks of factor loadings. 
</p>
<p>Default: <code>loading_sd &lt;- rep(2, length(loading_means))</code>.
</p>
</td></tr>
<tr><td><code id="simData2_+3A_sinv_values">sINV_values</code></td>
<td>

<p>A vector which contains the values of the diagonal of the (common) inverse covariance matrix, if <code>sigmaTrue = TRUE</code>. An <code class="reqn">K\times p</code> matrix which contains the values of the diagonal of the inverse covariance matrix per component, if <code>sigmaTrue = FALSE</code>. 
</p>
<p>Default: <code> sINV_values = rgamma(p, shape = 1, rate = 1)</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following entries:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>

<p><code class="reqn">n\times p</code> array containing the simulated data.
</p>
</td></tr>
<tr><td><code>class</code></td>
<td>

<p><code class="reqn">n</code>-dimensional vector containing the class of each observation.
</p>
</td></tr>
<tr><td><code>factorLoadings</code></td>
<td>

<p><code class="reqn">K.true\times p \times q</code>-array containing the factor loadings <code class="reqn">\Lambda_{krj}</code> per cluster <code class="reqn">k</code>, feature <code class="reqn">r</code> and factor <code class="reqn">j</code>, where <code class="reqn">k=1,\ldots,K</code>; <code class="reqn">r=1,\ldots,p</code>; <code class="reqn">j=1,\ldots,q</code>.
</p>
</td></tr>
<tr><td><code>means</code></td>
<td>

<p><code class="reqn">K.true\times p</code> matrix containing the marginal means <code class="reqn">\mu_{kr}</code>, <code class="reqn">k=1,\ldots,K</code>; <code class="reqn">r=1,\ldots,p</code>.
</p>
</td></tr>
<tr><td><code>variance</code></td>
<td>

<p><code class="reqn">p\times p</code> diagonal matrix containing the variance of errors <code class="reqn">\sigma_{rr}</code>, <code class="reqn">r=1,\ldots,p</code>. Note that the same variance of errors is assumed for each cluster.
</p>
</td></tr>
<tr><td><code>factors</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix containing the simulated factor values.
</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>

<p><code class="reqn">K.true</code>-dimensional vector containing the weight of each cluster.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The marginal variance for cluster <code class="reqn">k</code> is equal to <code class="reqn">\Lambda_k\Lambda_k^{T} + \Sigma</code>.</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')

n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData2(K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
summary(syntheticDataset)
</code></pre>

<hr>
<h2 id='summary.fabMix.object'>
Summary method
</h2><span id='topic+summary.fabMix.object'></span>

<h3>Description</h3>

<p>S3 method for printing a summary of a <code>fabMix.object</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fabMix.object'
summary(object, quantile_probs, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fabMix.object_+3A_object">object</code></td>
<td>

<p>An object of class <code>fabMix.object</code>, which is returned by the <code>fabMix</code> function.
</p>
</td></tr>
<tr><td><code id="summary.fabMix.object_+3A_quantile_probs">quantile_probs</code></td>
<td>

<p>A vector of quantiles to evaluate for each variable.
</p>
</td></tr>
<tr><td><code id="summary.fabMix.object_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function prints and returns a summary of the estimated posterior means for the parameters of the selected model for a <code>fabMix.object</code>. In particular, the method prints the ergodic means of the mixing proportions, marginal means and covariance matrix per component, as well as the corresponding quantiles.   
</p>


<h3>Value</h3>

<p>A list consisting of the following entries:
</p>
<table role = "presentation">
<tr><td><code>alive_cluster_labels</code></td>
<td>
<p>The labels of the &ldquo;alive&rdquo; components of the overfitting mixture model.</p>
</td></tr>
<tr><td><code>posterior_means</code></td>
<td>
<p>Posterior means of mixing proportion, marginal means and covariance matrix per (alive) cluster. </p>
</td></tr>
<tr><td><code>quantiles</code></td>
<td>
<p>A matrix containing the quantiles for each parameter.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>summary</code> function of the <code>coda</code> package to the <code>mcmc</code> object <code>object$mcmc</code> is used for computing quantiles.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='update_all_y'>
Gibbs sampling for <code class="reqn">y</code> in <code>xCx</code> model
</h2><span id='topic+update_all_y'></span>

<h3>Description</h3>

<p>Gibbs sampling for updating the factors <code class="reqn">y</code> for models with same variance of errors per component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_all_y(x_data, mu, SigmaINV, Lambda, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_all_y_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix with obseved data
</p>
</td></tr>
<tr><td><code id="update_all_y_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix of marginal means
</p>
</td></tr>
<tr><td><code id="update_all_y_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">p\times p</code> precision matrix
</p>
</td></tr>
<tr><td><code id="update_all_y_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">p\times q</code> matrix of factor loadings
</p>
</td></tr>
<tr><td><code id="update_all_y_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with generated factors
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')

n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
# use the real values as input and simulate factors
update_all_y(x_data = syntheticDataset$data, 
		mu = syntheticDataset$means, 
		SigmaINV = diag(1/diag(syntheticDataset$variance)), 
		Lambda = syntheticDataset$factorLoadings, 
		z = syntheticDataset$class)

</code></pre>

<hr>
<h2 id='update_all_y_Sj'>
Gibbs sampling for <code class="reqn">y</code>  in <code>xUx</code> model
</h2><span id='topic+update_all_y_Sj'></span>

<h3>Description</h3>

<p>Gibbs sampling for updating the factors <code class="reqn">y</code> for models with different variance of errors per component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_all_y_Sj(x_data, mu, SigmaINV, Lambda, z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_all_y_Sj_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix with obseved data
</p>
</td></tr>
<tr><td><code id="update_all_y_Sj_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix of marginal means
</p>
</td></tr>
<tr><td><code id="update_all_y_Sj_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">K\times p\times p</code> array containing the precision matrix per component
</p>
</td></tr>
<tr><td><code id="update_all_y_Sj_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">p\times q</code> matrix of factor loadings
</p>
</td></tr>
<tr><td><code id="update_all_y_Sj_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with generated factors
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')

n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters

sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
# add some noise here:
SigmaINV &lt;- array(data = 0, dim = c(K,p,p))
for(k in 1:K){
        diag(SigmaINV[k,,]) &lt;- 1/diag(syntheticDataset$variance) + rgamma(p, shape=1, rate = 1)
}

# use the real values as input and simulate factors
update_all_y_Sj(x_data = syntheticDataset$data, 
		mu = syntheticDataset$means, 
		SigmaINV = SigmaINV, 
		Lambda = syntheticDataset$factorLoadings, 
		z = syntheticDataset$class)

</code></pre>

<hr>
<h2 id='update_OmegaINV'>
Gibbs sampling for <code class="reqn">\Omega^{-1}</code>
</h2><span id='topic+update_OmegaINV'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">\Omega^{-1}</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_OmegaINV(Lambda, K, g, h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_OmegaINV_+3A_lambda">Lambda</code></td>
<td>

<p>Factor loadings
</p>
</td></tr>
<tr><td><code id="update_OmegaINV_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_OmegaINV_+3A_g">g</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
<tr><td><code id="update_OmegaINV_+3A_h">h</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">q\times q</code> matrix <code class="reqn">\Omega^{-1}</code>
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
SigmaINV &lt;- array(data = 0, dim = c(K,p,p))
for(k in 1:K){
        diag(SigmaINV[k,,]) &lt;- 1/diag(syntheticDataset$variance) + rgamma(p, shape=1, rate = 1)
}

# use the real values as input and simulate allocations
update_OmegaINV(Lambda = syntheticDataset$factorLoadings, 
        K = K, g=0.5, h = 0.5)

</code></pre>

<hr>
<h2 id='update_OmegaINV_Cxx'>
Gibbs sampling for <code class="reqn">\Omega^{-1}</code> for Cxx model
</h2><span id='topic+update_OmegaINV_Cxx'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">\Omega^{-1}</code> for Cxx model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_OmegaINV_Cxx(Lambda, K, g, h)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_OmegaINV_Cxx_+3A_lambda">Lambda</code></td>
<td>

<p>Factor loadings, in the form of <code class="reqn">K\times p\times q</code> matrix, under the restriction that all components share the factor loadings.
</p>
</td></tr>
<tr><td><code id="update_OmegaINV_Cxx_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_OmegaINV_Cxx_+3A_g">g</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
<tr><td><code id="update_OmegaINV_Cxx_+3A_h">h</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">q\times q</code> matrix <code class="reqn">\Omega^{-1}</code>
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
SigmaINV &lt;- array(data = 0, dim = c(K,p,p))
for(k in 1:K){
        diag(SigmaINV[k,,]) &lt;- 1/diag(syntheticDataset$variance) + rgamma(p, shape=1, rate = 1)
}

# Use the real values as input and simulate allocations.
# Mmake sure that in this case Lambda[k,,] is the same  
# for all k = 1,..., K
update_OmegaINV_Cxx(Lambda = syntheticDataset$factorLoadings, 
        K = K, g=0.5, h = 0.5)

</code></pre>

<hr>
<h2 id='update_SigmaINV_faster'>
Gibbs sampling for <code class="reqn">\Sigma^{-1}</code>
</h2><span id='topic+update_SigmaINV_faster'></span>

<h3>Description</h3>

<p>Gibbs sampling for updating <code class="reqn">\Sigma^{-1}</code> for the <code>xCU</code> model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SigmaINV_faster(x_data, z, y, Lambda, mu, K, alpha_sigma, beta_sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_SigmaINV_faster_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix containing the latent factors
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p\times q</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">alpha</code>
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">beta</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">p\times p</code> matrix with the common variance of errors per component <code class="reqn">\Sigma^{-1}.</code>
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis	
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)

# use the real values as input and update SigmaINV
update_SigmaINV_faster(x_data = syntheticDataset$data, 
	z = syntheticDataset$class, 
	y = syntheticDataset$factors, 
	Lambda = syntheticDataset$factorLoadings, 
	mu = syntheticDataset$means, 
	K = K, 
	alpha_sigma = 0.5, beta_sigma = 0.5)

</code></pre>

<hr>
<h2 id='update_SigmaINV_faster_q0'>
Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component for <code class="reqn">q=0</code>
</h2><span id='topic+update_SigmaINV_faster_q0'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SigmaINV_faster_q0( z, mu, K, alpha_sigma, beta_sigma, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_SigmaINV_faster_q0_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_+3A_mu">mu</code></td>
<td>

<p>Marginal means
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_+3A_x_data">x_data</code></td>
<td>

<p>Data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">\Sigma^{-1}</code>
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis	
</p>

<hr>
<h2 id='update_SigmaINV_faster_q0_sameSigma'>
Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component for <code class="reqn">q=0</code>
</h2><span id='topic+update_SigmaINV_faster_q0_sameSigma'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SigmaINV_faster_q0_sameSigma( z, mu, K, alpha_sigma, beta_sigma, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_SigmaINV_faster_q0_sameSigma_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_sameSigma_+3A_mu">mu</code></td>
<td>

<p>Marginal means
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_sameSigma_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_sameSigma_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_sameSigma_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_q0_sameSigma_+3A_x_data">x_data</code></td>
<td>

<p>Data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">\Sigma^{-1}</code>
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis	
</p>

<hr>
<h2 id='update_SigmaINV_faster_Sj'>
Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component
</h2><span id='topic+update_SigmaINV_faster_Sj'></span>

<h3>Description</h3>

<p>Gibbs sampling for updating <code class="reqn">\Sigma^{-1}</code> for the <code>xUU</code> model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SigmaINV_faster_Sj(x_data, z, y, Lambda, mu, K, alpha_sigma, beta_sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix containing the latent factors
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p\times q</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\alpha</code>
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_faster_Sj_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">\beta</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">K\times p\times p</code> array with the variance of errors per component <code class="reqn">\Sigma^{-1}_k</code>, <code class="reqn">k = 1,\ldots,K</code>.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis	
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)

# use the real values as input and update SigmaINV
update_SigmaINV_faster_Sj(x_data = syntheticDataset$data, 
	z = syntheticDataset$class, 
	y = syntheticDataset$factors, 
	Lambda = syntheticDataset$factorLoadings, 
	mu = syntheticDataset$means, 
	K = K, 
	alpha_sigma = 0.5, beta_sigma = 0.5)

</code></pre>

<hr>
<h2 id='update_SigmaINV_xCC'>
Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> for xCC models
</h2><span id='topic+update_SigmaINV_xCC'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> for xCC models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SigmaINV_xCC(x_data, z, y, Lambda, mu, K, alpha_sigma, beta_sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_SigmaINV_xCC_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xCC_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xCC_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix containing the latent factors
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xCC_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p\times q</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xCC_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xCC_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xCC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">alpha</code>
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xCC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">beta</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">p\times p</code> matrix with the common variance of errors per component <code class="reqn">\Sigma^{-1} = \sigma I_p</code>.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis	
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)

# use the real values as input and update SigmaINV
update_SigmaINV_xCC(x_data = syntheticDataset$data, 
	z = syntheticDataset$class, 
	y = syntheticDataset$factors, 
	Lambda = syntheticDataset$factorLoadings, 
	mu = syntheticDataset$means, 
	K = K, 
	alpha_sigma = 0.5, beta_sigma = 0.5)

</code></pre>

<hr>
<h2 id='update_SigmaINV_xUC'>
Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component for xUC models
</h2><span id='topic+update_SigmaINV_xUC'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">\Sigma^{-1}</code> per component for xUC models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_SigmaINV_xUC(x_data, z, y, Lambda, mu, K, alpha_sigma, beta_sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_SigmaINV_xUC_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xUC_+3A_z">z</code></td>
<td>

<p>Allocation vector
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xUC_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> matrix containing the latent factors
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xUC_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p\times q</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xUC_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xUC_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xUC_+3A_alpha_sigma">alpha_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">alpha</code>
</p>
</td></tr>
<tr><td><code id="update_SigmaINV_xUC_+3A_beta_sigma">beta_sigma</code></td>
<td>

<p>Prior parameter <code class="reqn">beta</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">K\times p\times p</code> array containing the inverse variance of errors per component under the restriction: <code class="reqn">\Sigma^{-1}_k = \sigma_k I_p</code>, where <code class="reqn">\sigma_k &gt; 0</code>.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis	
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)

# use the real values as input and update SigmaINV
update_SigmaINV_xUC(x_data = syntheticDataset$data, 
	z = syntheticDataset$class, 
	y = syntheticDataset$factors, 
	Lambda = syntheticDataset$factorLoadings, 
	mu = syntheticDataset$means, 
	K = K, 
	alpha_sigma = 0.5, beta_sigma = 0.5)

</code></pre>

<hr>
<h2 id='update_z_b'>
Gibbs sampling for <code class="reqn">z</code>
</h2><span id='topic+update_z_b'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">z</code>: here the full conditional distribution is being used (that is, the distribution is also conditioned on the values of factors <code class="reqn">y</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z_b(w, mu, Lambda, y, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z_b_+3A_w">w</code></td>
<td>

<p>vector with length <code class="reqn">K</code> consisting of mixture weights
</p>
</td></tr>
<tr><td><code id="update_z_b_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_z_b_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_z_b_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> Matrix of factors
</p>
</td></tr>
<tr><td><code id="update_z_b_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix
</p>
</td></tr>
<tr><td><code id="update_z_b_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z_b_+3A_x_data">x_data</code></td>
<td>

<p>Data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Allocation vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)

# use the real values as input and simulate allocations
update_z_b(w = syntheticDataset$weights, mu = syntheticDataset$means, 
	Lambda = syntheticDataset$factorLoadings, 
	y = syntheticDataset$factors,
	SigmaINV = diag(1/diag(syntheticDataset$variance)), 
	K = K, x_data = syntheticDataset$data)$z

</code></pre>

<hr>
<h2 id='update_z_b_Sj'>
Gibbs sampling for <code class="reqn">z</code>
</h2><span id='topic+update_z_b_Sj'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">z</code>: here the full conditional distribution is being used (that is, the distribution is also conditioned on the values of factors <code class="reqn">y</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z_b_Sj(w, mu, Lambda, y, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z_b_Sj_+3A_w">w</code></td>
<td>

<p>vector with length <code class="reqn">K</code> consisting of mixture weights
</p>
</td></tr>
<tr><td><code id="update_z_b_Sj_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_z_b_Sj_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_z_b_Sj_+3A_y">y</code></td>
<td>

<p><code class="reqn">n\times q</code> Matrix of factors
</p>
</td></tr>
<tr><td><code id="update_z_b_Sj_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">K\times p\times p</code> array containing the precision matrix per component
</p>
</td></tr>
<tr><td><code id="update_z_b_Sj_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z_b_Sj_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Allocation vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
SigmaINV &lt;- array(data = 0, dim = c(K,p,p))
for(k in 1:K){
	diag(SigmaINV[k,,]) &lt;- 1/diag(syntheticDataset$variance) + rgamma(p, shape=1, rate = 1)
}

# use the real values as input and simulate allocations
update_z_b_Sj(w = syntheticDataset$weights, mu = syntheticDataset$means, 
	Lambda = syntheticDataset$factorLoadings, 
	y = syntheticDataset$factors,
	SigmaINV = SigmaINV, 
	K = K, x_data = syntheticDataset$data)$z

</code></pre>

<hr>
<h2 id='update_z_q0'>
Gibbs sampling for <code class="reqn">z</code> for <code class="reqn">q=0</code>
</h2><span id='topic+update_z_q0'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">z</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z_q0(w, mu, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z_q0_+3A_w">w</code></td>
<td>

<p>Mixture weights
</p>
</td></tr>
<tr><td><code id="update_z_q0_+3A_mu">mu</code></td>
<td>

<p>Marginal means
</p>
</td></tr>
<tr><td><code id="update_z_q0_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix per component
</p>
</td></tr>
<tr><td><code id="update_z_q0_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z_q0_+3A_x_data">x_data</code></td>
<td>

<p>Data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Allocation vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='update_z_q0_sameSigma'>
Gibbs sampling for <code class="reqn">z</code> for <code class="reqn">q=0</code>
</h2><span id='topic+update_z_q0_sameSigma'></span>

<h3>Description</h3>

<p>Gibbs sampling for <code class="reqn">z</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z_q0_sameSigma(w, mu, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z_q0_sameSigma_+3A_w">w</code></td>
<td>

<p>Mixture weights
</p>
</td></tr>
<tr><td><code id="update_z_q0_sameSigma_+3A_mu">mu</code></td>
<td>

<p>Marginal means
</p>
</td></tr>
<tr><td><code id="update_z_q0_sameSigma_+3A_sigmainv">SigmaINV</code></td>
<td>

<p>Precision matrix per component
</p>
</td></tr>
<tr><td><code id="update_z_q0_sameSigma_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z_q0_sameSigma_+3A_x_data">x_data</code></td>
<td>

<p>Data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Allocation vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>

<hr>
<h2 id='update_z2'>
Collapsed Gibbs for <code class="reqn">z</code> using matrix inversion lemma
</h2><span id='topic+update_z2'></span>

<h3>Description</h3>

<p>Collapsed Gibbs for <code class="reqn">z</code> using matrix inversion lemma
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z2(w, mu, Lambda, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z2_+3A_w">w</code></td>
<td>

<p>vector with length <code class="reqn">K</code> consisting of mixture weights
</p>
</td></tr>
<tr><td><code id="update_z2_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_z2_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_z2_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">p\times p</code> precision matrix
</p>
</td></tr>
<tr><td><code id="update_z2_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z2_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Allocation vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
# use the real values as input and simulate allocations
update_z2(w = syntheticDataset$weights, mu = syntheticDataset$means, 
	Lambda = syntheticDataset$factorLoadings, 
	SigmaINV = diag(1/diag(syntheticDataset$variance)), 
	K = K, x_data = syntheticDataset$data)$z

</code></pre>

<hr>
<h2 id='update_z2_Sj'>
Collapsed Gibbs for <code class="reqn">z</code> using matrix inversion lemma
</h2><span id='topic+update_z2_Sj'></span>

<h3>Description</h3>

<p>Collapsed Gibbs for <code class="reqn">z</code> using matrix inversion lemma
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z2_Sj(w, mu, Lambda, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z2_Sj_+3A_w">w</code></td>
<td>

<p>vector with length <code class="reqn">K</code> consisting of mixture weights
</p>
</td></tr>
<tr><td><code id="update_z2_Sj_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_z2_Sj_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_z2_Sj_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">K\times p\times p</code> array containing the precision matrix per component
</p>
</td></tr>
<tr><td><code id="update_z2_Sj_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z2_Sj_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Allocation vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
SigmaINV &lt;- array(data = 0, dim = c(K,p,p))
for(k in 1:K){
	diag(SigmaINV[k,,]) &lt;- 1/diag(syntheticDataset$variance) + rgamma(p, shape=1, rate = 1)
}

# use the real values as input and simulate allocations
update_z2_Sj(w = syntheticDataset$weights, mu = syntheticDataset$means, 
	Lambda = syntheticDataset$factorLoadings, 
	SigmaINV = SigmaINV, 
	K = K, x_data = syntheticDataset$data)$z

</code></pre>

<hr>
<h2 id='update_z4'>
Collapsed Gibbs for <code class="reqn">z</code>
</h2><span id='topic+update_z4'></span>

<h3>Description</h3>

<p>Collapsed Gibbs for <code class="reqn">z</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z4(w, mu, Lambda, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z4_+3A_w">w</code></td>
<td>

<p>vector with length <code class="reqn">K</code> consisting of mixture weights
</p>
</td></tr>
<tr><td><code id="update_z4_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_z4_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_z4_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">p\times p</code> precision matrix
</p>
</td></tr>
<tr><td><code id="update_z4_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z4_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code class="reqn">n</code> with the simulated allocation of each observation among the <code class="reqn">K</code> components.
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
# use the real values as input and simulate allocations
update_z4(w = syntheticDataset$weights, mu = syntheticDataset$means, 
	Lambda = syntheticDataset$factorLoadings, 
	SigmaINV = diag(1/diag(syntheticDataset$variance)), 
	K = K, x_data = syntheticDataset$data)$z

</code></pre>

<hr>
<h2 id='update_z4_Sj'>
Collapsed Gibbs for <code class="reqn">z</code>
</h2><span id='topic+update_z4_Sj'></span>

<h3>Description</h3>

<p>Collapsed Gibbs for <code class="reqn">z</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update_z4_Sj(w, mu, Lambda, SigmaINV, K, x_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="update_z4_Sj_+3A_w">w</code></td>
<td>

<p>vector with length <code class="reqn">K</code> consisting of mixture weights
</p>
</td></tr>
<tr><td><code id="update_z4_Sj_+3A_mu">mu</code></td>
<td>

<p><code class="reqn">K\times p</code> array containing the marginal means
</p>
</td></tr>
<tr><td><code id="update_z4_Sj_+3A_lambda">Lambda</code></td>
<td>

<p><code class="reqn">K\times p</code> array with factor loadings
</p>
</td></tr>
<tr><td><code id="update_z4_Sj_+3A_sigmainv">SigmaINV</code></td>
<td>

<p><code class="reqn">K\times p\times p</code> array containing the precision matrix per component
</p>
</td></tr>
<tr><td><code id="update_z4_Sj_+3A_k">K</code></td>
<td>

<p>Number of components
</p>
</td></tr>
<tr><td><code id="update_z4_Sj_+3A_x_data">x_data</code></td>
<td>

<p><code class="reqn">n\times p</code> matrix containing the observed data
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Allocation vector
</p>


<h3>Author(s)</h3>

<p>Panagiotis Papastamoulis
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library('fabMix')
# simulate some data
n = 8                # sample size
p = 5                # number of variables
q = 2                # number of factors
K = 2                # true number of clusters
sINV_diag = 1/((1:p))    # diagonal of inverse variance of errors
set.seed(100)
syntheticDataset &lt;- simData(sameLambda=TRUE,K.true = K, n = n, q = q, p = p, 
                        sINV_values = sINV_diag)
SigmaINV &lt;- array(data = 0, dim = c(K,p,p))
for(k in 1:K){
	diag(SigmaINV[k,,]) &lt;- 1/diag(syntheticDataset$variance) + rgamma(p, shape=1, rate = 1)
}

# use the real values as input and simulate allocations
update_z4_Sj(w = syntheticDataset$weights, mu = syntheticDataset$means, 
	Lambda = syntheticDataset$factorLoadings, 
	SigmaINV = SigmaINV, 
	K = K, x_data = syntheticDataset$data)$z

</code></pre>

<hr>
<h2 id='waveDataset1500'>Wave dataset</h2><span id='topic+waveDataset1500'></span>

<h3>Description</h3>

<p>A subset of 1500 randomly sampled observations from the wave dataset (version 1), available from the UCI machine learning repository. It contains 3 classes of waves (variable <code>class</code> with values &ldquo;1&rdquo;, &ldquo;2&rdquo; and &ldquo;3&rdquo;) and 21 attributes. Each class is generated from a combination of 2 of 3 base waves with noise.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(waveDataset1500)</code></pre>


<h3>Format</h3>

<p>A data frame with 1500 rows and 22 columns. The first column denotes the class of each observation.</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+(Version+1)">https://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+(Version+1)</a></p>


<h3>References</h3>

<p>Lichman, M. (2013). UCI Machine Learning Repository <a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>. Irvine, CA: University of California, School of Information and Computer Science.
</p>
<p>Breiman,L., Friedman,J.H., Olshen,R.A. and Stone,C.J. (1984). Classification and Regression Trees. Wadsworth International Group: Belmont, California.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
