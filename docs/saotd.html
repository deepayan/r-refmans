<!DOCTYPE html><html><head><title>Help for package saotd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {saotd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bigram'><p>Twitter Bi-Grams</p></a></li>
<li><a href='#bigram_network'><p>Twitter Bi-Gram Network</p></a></li>
<li><a href='#merge_terms'><p>Merge Terms</p></a></li>
<li><a href='#number_topics'><p>Number Topics</p></a></li>
<li><a href='#posneg_words'><p>Twitter Positive and Negative Words</p></a></li>
<li><a href='#raw_tweets'><p>Twitter Data Set</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#saotd'><p>Sentiment Analysis of Twitter Data</p></a></li>
<li><a href='#trigram'><p>Twitter Tri-Grams</p></a></li>
<li><a href='#tweet_acquire'><p>Acquire Twitter Tweets</p></a></li>
<li><a href='#tweet_box'><p>Twitter Data Box Plot</p></a></li>
<li><a href='#tweet_corpus_distribution'><p>Twitter Corpus Distribution</p></a></li>
<li><a href='#tweet_distribution'><p>Twitter Hashtag or Topic Distribution</p></a></li>
<li><a href='#tweet_max_scores'><p>Twitter Data Maximum Scores</p></a></li>
<li><a href='#tweet_min_scores'><p>Twitter Data Minimum Scores</p></a></li>
<li><a href='#tweet_scores'><p>Score Tidy Twitter Data</p></a></li>
<li><a href='#tweet_tidy'><p>Tidy Twitter Data</p></a></li>
<li><a href='#tweet_time'><p>Twitter Data Timeseries Plot.</p></a></li>
<li><a href='#tweet_topics'><p>Tweet Topics</p></a></li>
<li><a href='#tweet_violin'><p>Twitter Data Violin Plot</p></a></li>
<li><a href='#unigram'><p>Twitter Uni-Grams</p></a></li>
<li><a href='#word_corr'><p>Twitter Word Correlations</p></a></li>
<li><a href='#word_corr_network'><p>Twitter Word Correlations Plot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Sentiment Analysis of Twitter Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-03</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Evan Munson &lt;evan.l.munson@gmail.com&gt;</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/evan-l-munson/saotd/issues">https://github.com/evan-l-munson/saotd/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>This analytic is an in initial foray into sentiment analysis.  
    This analytic will allow a user to access the Twitter API (once they create 
    their own developer account), ingest tweets of their interest, clean / tidy 
    data, perform topic modeling if interested, compute sentiment scores 
    utilizing the Bing Lexicon, and output visualizations.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/evan-l-munson/saotd">https://github.com/evan-l-munson/saotd</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, widyr, stringr, tidytext, rtweet, tidyr, igraph,
ggplot2, ggraph, scales, reshape2, lubridate, utils, stats,
magrittr, ldatuning, topicmodels</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), knitr, rmarkdown, httr, base64enc,
tibble, covr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GSL (&gt;=2.4), MPFR (&gt;= 4.0.0), udunits2 (&gt;=2.2.26-3)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>true</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-03 23:38:21 UTC; munson</td>
</tr>
<tr>
<td>Author:</td>
<td>Evan Munson <a href="https://orcid.org/0000-0002-9958-6800"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Christopher Smith <a href="https://orcid.org/0000-0002-8288-270X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Bradley Boehmke <a href="https://orcid.org/0000-0002-3611-8516"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Jason Freels <a href="https://orcid.org/0000-0002-2415-0340"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-04 08:40:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='bigram'>Twitter Bi-Grams</h2><span id='topic+bigram'></span>

<h3>Description</h3>

<p>Determines and displays the text Bi-Grams within the Twitter 
data in sequence from the most used to the least used.  A Bi-Gram is a 
combination of two consecutive words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bigram(DataFrame)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigram_+3A_dataframe">DataFrame</code></td>
<td>
<p>Data Frame of Twitter Data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
TD_Bigram &lt;- bigram(DataFrame = data)
TD_Bigram

## End(Not run)
</code></pre>

<hr>
<h2 id='bigram_network'>Twitter Bi-Gram Network</h2><span id='topic+bigram_network'></span>

<h3>Description</h3>

<p>Displays the Bi-Gram Network.  Bi-Gram networks builds on 
computed Bi-Grams.  Bi-Gram networks serve as a visualization tool that 
displays the relationships between the words simultaneously as opposed to 
a tabular display of Bi-Gram words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bigram_network(
  BiGramDataFrame,
  number,
  layout = "fr",
  edge_color = "royalblue",
  node_color = "black",
  node_size = 3,
  set_seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigram_network_+3A_bigramdataframe">BiGramDataFrame</code></td>
<td>
<p>Data Frame of Bi-Grams.</p>
</td></tr>
<tr><td><code id="bigram_network_+3A_number">number</code></td>
<td>
<p>The minimum desired number of Bi-Gram occurrences to be 
displayed (number = 300, would display all Bi-Grams that have at least 
300 instances).</p>
</td></tr>
<tr><td><code id="bigram_network_+3A_layout">layout</code></td>
<td>
<p>Desired layout from the 'ggraph' package.
Acceptable layouts:  &quot;star&quot;, &quot;circle&quot;, &quot;gem&quot;, &quot;dh&quot;, &quot;graphopt&quot;, &quot;grid&quot;, 
&quot;mds&quot;, &quot;randomly&quot;, &quot;fr&quot;, &quot;kk&quot;, &quot;drl&quot;, &quot;lgl&quot;</p>
</td></tr>
<tr><td><code id="bigram_network_+3A_edge_color">edge_color</code></td>
<td>
<p>User desired edge color.</p>
</td></tr>
<tr><td><code id="bigram_network_+3A_node_color">node_color</code></td>
<td>
<p>User desired node color.</p>
</td></tr>
<tr><td><code id="bigram_network_+3A_node_size">node_size</code></td>
<td>
<p>User desired node size.</p>
</td></tr>
<tr><td><code id="bigram_network_+3A_set_seed">set_seed</code></td>
<td>
<p>Seed for reproducible results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggraph plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
TD_Bigram &lt;- bigram(DataFrame = data)
TD_Bigram_Network &lt;- bigram_network(BiGramDataFrame = TD_Bigram,
                                    number = 300,
                                    layout = "fr",
                                    edge_color = "royalblue",
                                    node_color = "black",
                                    node_size = 3,
                                    set_seed = 1234)

TD_Bigram_Network

## End(Not run)
</code></pre>

<hr>
<h2 id='merge_terms'>Merge Terms</h2><span id='topic+merge_terms'></span>

<h3>Description</h3>

<p>Function to merge terms within a data frame and prevent 
redundancy in the analysis.  For example many users may refer to the same
entity in multiple different ways: President Trump, The U.S. President, 
POTUS, Trump, President Donald Trump, Donald Trump, etc.  While each entry 
is different, they all refer to the same individual.  Using Merge Terms 
will allow all be converted into a single term.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_terms(DataFrame, term, term_replacement, ignore_case = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_terms_+3A_dataframe">DataFrame</code></td>
<td>
<p>Data Frame of Twitter Data.</p>
</td></tr>
<tr><td><code id="merge_terms_+3A_term">term</code></td>
<td>
<p>Term selected for merging.</p>
</td></tr>
<tr><td><code id="merge_terms_+3A_term_replacement">term_replacement</code></td>
<td>
<p>Desired replacement term.</p>
</td></tr>
<tr><td><code id="merge_terms_+3A_ignore_case">ignore_case</code></td>
<td>
<p>True is the default setting and will ignore case 
sensitivity of the selected terms.  Selecting FALSE will maintain 
case sensitivity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tibble with user selected term replacement.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
data &lt;- merge_terms(DataFrame = data,
                    term = "ice cream",
                    term_replacement = "ice_cream")
data

## End(Not run)
</code></pre>

<hr>
<h2 id='number_topics'>Number Topics</h2><span id='topic+number_topics'></span>

<h3>Description</h3>

<p>Determines the optimal number of Latent topics within a 
data frame by tuning the Latent Dirichlet Allocation (LDA) model 
parameters.  Uses the 'ldatuning' package and outputs an ldatuning plot.  
__This process can be time consuming depending on the size of the input 
data frame.__
</p>


<h3>Usage</h3>

<pre><code class='language-R'>number_topics(
  DataFrame,
  num_cores = 1L,
  min_clusters = 2,
  max_clusters = 12,
  skip = 2,
  set_seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="number_topics_+3A_dataframe">DataFrame</code></td>
<td>
<p>Data Frame of Twitter Data.</p>
</td></tr>
<tr><td><code id="number_topics_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of CPU cores to processes models simultaneously 
(2L for dual core processor).</p>
</td></tr>
<tr><td><code id="number_topics_+3A_min_clusters">min_clusters</code></td>
<td>
<p>Lower range for the number of clusters.</p>
</td></tr>
<tr><td><code id="number_topics_+3A_max_clusters">max_clusters</code></td>
<td>
<p>Upper range for the number of clusters.</p>
</td></tr>
<tr><td><code id="number_topics_+3A_skip">skip</code></td>
<td>
<p>Integer; The number of clusters to skip between entries.</p>
</td></tr>
<tr><td><code id="number_topics_+3A_set_seed">set_seed</code></td>
<td>
<p>Seed for reproducible results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tidy DataFrame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
LDA_Topic_Plot &lt;- number_topics(DataFrame = data,
                                num_cores = 2L,
                                min_clusters = 2,
                                max_clusters = 12, 
                                skip = 2,
                                set_seed = 1234)

LDA_Topic_Plot 

## End(Not run)
</code></pre>

<hr>
<h2 id='posneg_words'>Twitter Positive and Negative Words</h2><span id='topic+posneg_words'></span>

<h3>Description</h3>

<p>Determines and displays the most positive and negative words 
within the twitter data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posneg_words(DataFrameTidy, num_words, filterword = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="posneg_words_+3A_dataframetidy">DataFrameTidy</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd.</p>
</td></tr>
<tr><td><code id="posneg_words_+3A_num_words">num_words</code></td>
<td>
<p>Desired number of words to be returned.</p>
</td></tr>
<tr><td><code id="posneg_words_+3A_filterword">filterword</code></td>
<td>
<p>Word or words to be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
posneg &lt;- posneg_words(DataFrameTidy = tidy_data,
                       n = 10)
posneg

data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
posneg &lt;- posneg_words(DataFrameTidy = tidy_data,
                       n = 10,
                       filterword = "fail")
posneg

data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
posneg &lt;- posneg_words(DataFrameTidy = tidy_data,
                       n = 10,
                       filterword = c("fail", "urgent"))            
posneg

## End(Not run)
</code></pre>

<hr>
<h2 id='raw_tweets'>Twitter Data Set</h2><span id='topic+raw_tweets'></span>

<h3>Description</h3>

<p>Dataset from a [Twitter US Airline Sentiment]
(https://www.kaggle.com/crowdflower/twitter-airline-sentiment) Kaggle 
competition, from December 2017.  The dataset contains 14,487 tweets from 6 
different hashtags (2,604 x #American, 2,220 x #Delta, 2,420 x #Southwest, 
3,822 x #United, 2,913 x #US Airways, 504 x #Virgin America).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(raw_tweets)
</code></pre>


<h3>Format</h3>

<p>A <code>tribble</code> with 14,483 rows and 6 variables.
</p>

<dl>
<dt>id</dt><dd><p>ID of this status.</p>
</dd>
<dt>hashtags</dt><dd><p>Hashtag that the individual tweet was acquired from.</p>
</dd>
<dt>screenName</dt><dd><p>Screen name of the user who posted this status.</p>
</dd>
<dt>text</dt><dd><p>The text of the status.</p>
</dd>
<dt>created_at</dt><dd><p>When this status was created.</p>
</dd>
<dt>key</dt><dd><p>Unique key based on the tweets originators user id and the created date time group.</p>
</dd>
</dl>


<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
</dl>

<hr>
<h2 id='saotd'>Sentiment Analysis of Twitter Data</h2><span id='topic+saotd'></span><span id='topic+saotd-package'></span>

<h3>Description</h3>

<p>This analytic is an in initial foray into sentiment analysis.  
This analytic will allow a user to access the Twitter API (once they 
create their own developer account), ingest tweets of their interest, 
clean / tidy data, perform topic modeling if interested, compute sentiment 
scores utilizing the Bing Lexicon, and output visualizations.
</p>
<p>For additional information and a description on how to use the package, 
please look at the package vignette: utils::vignette('saotd').
</p>

<hr>
<h2 id='trigram'>Twitter Tri-Grams</h2><span id='topic+trigram'></span>

<h3>Description</h3>

<p>Determines and displays the text Tri-Grams within the Twitter 
data in sequence from the most used to the least used.  A Tri-Gram is a 
combination of three consecutive words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trigram(DataFrame)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trigram_+3A_dataframe">DataFrame</code></td>
<td>
<p>Data Frame of Twitter Data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tribble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
TD_Trigram &lt;- trigram(DataFrame = data)
TD_Trigram

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_acquire'>Acquire Twitter Tweets</h2><span id='topic+tweet_acquire'></span>

<h3>Description</h3>

<p>Function will enable a user to access the Twitter API through
the [Twitter Developers Account](https://dev.twitter.com/) site.  Once a
user has a Twitter developers account and has received their individual
consumer key, consumer secret key, access token, and access secret they
can acquire Tweets based on a list of hashtags and a requested number of
entries per query.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_acquire(
  twitter_app,
  consumer_api_key,
  consumer_api_secret_key,
  access_token,
  access_token_secret,
  query,
  num_tweets,
  reduced_tweets = TRUE,
  distinct = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_acquire_+3A_twitter_app">twitter_app</code></td>
<td>
<p>The name of user created Twitter Application.</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_consumer_api_key">consumer_api_key</code></td>
<td>
<p>Twitter Application management consumer API key.</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_consumer_api_secret_key">consumer_api_secret_key</code></td>
<td>
<p>Twitter Application management consumer API
secret key.  Application must have <code>Read and write</code> access level and
<code>Callback URL</code> of <code>http://127.0.0.1:1410</code>.</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_access_token">access_token</code></td>
<td>
<p>Twitter Application management access token 
(apps.twitter.com).</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_access_token_secret">access_token_secret</code></td>
<td>
<p>Twitter Application management access secret 
token (apps.twitter.com).</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_query">query</code></td>
<td>
<p>A single query or a list of queries the user has specified.
Character string, not to exceed 500 characters.  To search for tweets 
containing at least one of multiple possible terms, separate each search 
term with spaces and &quot;OR&quot; (in caps).  For example, the search <code>q =
"data science"</code> looks for tweets containing both &quot;data&quot; and &quot;science&quot; 
located anywhere in the tweets and in any order.  When &quot;OR&quot; is entered 
between search terms, <code>query = "data OR science"</code>, Twitter's REST API 
should return any tweet that contains either &quot;data&quot; or &quot;science.&quot;</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_num_tweets">num_tweets</code></td>
<td>
<p>Number of Tweets to be acquired per each hashtag.</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_reduced_tweets">reduced_tweets</code></td>
<td>
<p>Logical.  If reduced_tweets = TRUE, the data frame 
returned to the user will be significantly reduced specifically for use in 
the 'saotd' package.  If reduced_tweets = FALSE, the full results from the 
Twitter API will be returned.</p>
</td></tr>
<tr><td><code id="tweet_acquire_+3A_distinct">distinct</code></td>
<td>
<p>Logical.  If distinct = TRUE, the function removes multiple 
Tweets that originate from the same Twitter id at the exact same time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Data Frame with tweets and meta data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
twitter_app &lt;- "super_app"
consumer_api_key &lt;- "XXXXXXXXXXXXXXXXXXXXXXXXX"
consumer_api_secret_key &lt;- "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
access_token &lt;- "XXXXXXXXXXXXXXXXXX-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
access_token_secret &lt;- "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"

tweets &lt;- tweet_acquire(
  twitter_app = "twitter_app",
  consumer_api_key = consumer_api_key,
  consumer_api_secret_key = consumer_api_secret_key,
  access_token = access_token,
  access_token_secret = access_token_secret,
  query = "#icecream",
  num_tweets = 100,
  distinct = TRUE)

Or the Twitter API keys and tokens can be saved as an .Renviron file in the 
working directory.  If using a `.Renviron` file, the data should be saved 
like the below example:

consumer_api_key=XXXXXXXXXXXXXXXXXXXXXXXXX
consumer_api_secret_key=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
access_token=XXXXXXXXXXXXXXXXXX-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
access_token_secret=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

The `tweet_acquire` function would access the keys and tokens using the 
`Sys.getenv()` function and would appear like the below example:

tweets &lt;- tweet_acquire(
  twitter_app = "twitter_app",
  consumer_api_key = Sys.getenv('consumer_api_key'),
  consumer_api_secret_key = Sys.getenv('consumer_api_secret_key'),
  access_token = Sys.getenv('access_token'),
  access_token_secret = Sys.getenv('access_token_secret'),
  query = "#icecream",
  num_tweets = 100,
  distinct = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_box'>Twitter Data Box Plot</h2><span id='topic+tweet_box'></span>

<h3>Description</h3>

<p>Displays the distribution scores of either hashtag or topic 
Twitter data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_box(DataFrameTidyScores, HT_Topic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_box_+3A_dataframetidyscores">DataFrameTidyScores</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd 
and scored.</p>
</td></tr>
<tr><td><code id="tweet_box_+3A_ht_topic">HT_Topic</code></td>
<td>
<p>If using hashtag data select:  &quot;hashtag&quot;.  If using topic 
data select:  &quot;topic&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot box plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
ht_box &lt;- tweet_box(DataFrameTidyScores = score_data,
                    HT_Topic = "hashtag")
ht_box

data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "topic")
topic_box &lt;- tweet_box(DataFrameTidyScores = score_data,
                       HT_Topic = "topic") 
topic_box                    

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_corpus_distribution'>Twitter Corpus Distribution</h2><span id='topic+tweet_corpus_distribution'></span>

<h3>Description</h3>

<p>Determines the scores distribution for the entire Twitter 
data corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_corpus_distribution(
  DataFrameTidyScores,
  binwidth = 1,
  color = "black",
  fill = "grey"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_corpus_distribution_+3A_dataframetidyscores">DataFrameTidyScores</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd 
and scored.</p>
</td></tr>
<tr><td><code id="tweet_corpus_distribution_+3A_binwidth">binwidth</code></td>
<td>
<p>The width of the bins.  Default is 1.</p>
</td></tr>
<tr><td><code id="tweet_corpus_distribution_+3A_color">color</code></td>
<td>
<p>The user selected color to highlight the bins.</p>
</td></tr>
<tr><td><code id="tweet_corpus_distribution_+3A_fill">fill</code></td>
<td>
<p>The interior color of the bins.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
Corp_Dist &lt;- tweet_corpus_distribution(DataFrameTidyScores = score_data,
                                       binwidth = 1,
                                       color = "black",
                                       fill = "white")
Corp_Dist

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_distribution'>Twitter Hashtag or Topic Distribution</h2><span id='topic+tweet_distribution'></span>

<h3>Description</h3>

<p>Determines the scores distribution by hashtag or topic for 
Twitter data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_distribution(
  DataFrameTidyScores,
  HT_Topic,
  bin_width = 1,
  color = "black",
  fill = "black"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_distribution_+3A_dataframetidyscores">DataFrameTidyScores</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd 
and scored.</p>
</td></tr>
<tr><td><code id="tweet_distribution_+3A_ht_topic">HT_Topic</code></td>
<td>
<p>If using hashtag data select:  &quot;hashtag&quot;.  If using topic 
data select:  &quot;topic&quot;.</p>
</td></tr>
<tr><td><code id="tweet_distribution_+3A_bin_width">bin_width</code></td>
<td>
<p>The width of the bins.  Default is 1.</p>
</td></tr>
<tr><td><code id="tweet_distribution_+3A_color">color</code></td>
<td>
<p>The user selected color to highlight the bins.</p>
</td></tr>
<tr><td><code id="tweet_distribution_+3A_fill">fill</code></td>
<td>
<p>The interior color of the bins.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A facet wrap ggplot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
Dist &lt;- tweet_distribution(DataFrameTidyScores = score_data,
                     HT_Topic = "hashtag",
                     bin_width = 1,
                     color = "black",
                     fill = "white")
Dist

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_max_scores'>Twitter Data Maximum Scores</h2><span id='topic+tweet_max_scores'></span>

<h3>Description</h3>

<p>Determines the Maximum scores for either the entire dataset or 
the Maximum scores associated with a hashtag or topic analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_max_scores(DataFrameTidyScores, HT_Topic, HT_Topic_Selection = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_max_scores_+3A_dataframetidyscores">DataFrameTidyScores</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd 
and scored.</p>
</td></tr>
<tr><td><code id="tweet_max_scores_+3A_ht_topic">HT_Topic</code></td>
<td>
<p>If using hashtag data select:  &quot;hashtag&quot;.  If using topic 
data select:  &quot;topic&quot;.</p>
</td></tr>
<tr><td><code id="tweet_max_scores_+3A_ht_topic_selection">HT_Topic_Selection</code></td>
<td>
<p>The hashtag or topic to be investigated.  NULL will 
find min across entire data frame.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tibble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
min_scores &lt;- tweet_max_scores(DataFrameTidyScores = score_data,
                               HT_Topic = "hashtag")

data &lt;- twitter_data
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
min_scores &lt;- tweet_max_scores(DataFrameTidyScores = score_data,
                               HT_Topic = "hashtag",
                               HT_Topic_Selection = "icecream")

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_min_scores'>Twitter Data Minimum Scores</h2><span id='topic+tweet_min_scores'></span>

<h3>Description</h3>

<p>Determines the minimum scores for either the entire dataset or 
the minimum scores associated with a hashtag or topic analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_min_scores(DataFrameTidyScores, HT_Topic, HT_Topic_Selection = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_min_scores_+3A_dataframetidyscores">DataFrameTidyScores</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd 
and scored.</p>
</td></tr>
<tr><td><code id="tweet_min_scores_+3A_ht_topic">HT_Topic</code></td>
<td>
<p>If using hashtag data select:  &quot;hashtag&quot;.  If using topic 
data select:  &quot;topic&quot;.</p>
</td></tr>
<tr><td><code id="tweet_min_scores_+3A_ht_topic_selection">HT_Topic_Selection</code></td>
<td>
<p>The hashtag or topic to be investigated.  NULL will 
find min across entire dataframe.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tibble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
min_scores &lt;- tweet_min_scores(DataFrameTidyScores = score_data,
                               HT_Topic = "hashtag")
                            
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                     HT_Topic = "hashtag")
min_scores &lt;- tweet_min_scores(DataFrameTidyScores = score_data,
                               HT_Topic = "hashtag",
                               HT_Topic_Selection = "icecream")

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_scores'>Score Tidy Twitter Data</h2><span id='topic+tweet_scores'></span>

<h3>Description</h3>

<p>Function to Calculate Sentiment Scores that will account for 
sentiment by hashtag or topic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_scores(DataFrameTidy, HT_Topic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_scores_+3A_dataframetidy">DataFrameTidy</code></td>
<td>
<p>Data Frame of Twitter Data that has been tidy'd.</p>
</td></tr>
<tr><td><code id="tweet_scores_+3A_ht_topic">HT_Topic</code></td>
<td>
<p>If using hashtag data select:  &quot;hashtag&quot;.  If using topic 
data select:  &quot;topic&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Scored DataFrame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
score_data

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_tidy'>Tidy Twitter Data</h2><span id='topic+tweet_tidy'></span>

<h3>Description</h3>

<p>Function to Tidy Twitter Data.  This function will remove a 
significant amount of the original twitter metadata, as it is not needed 
to determine the sentiment of the tweets. This function will remove all 
emoticons, punctuation, weblinks while maintaining actual Tweet text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_tidy(DataFrame)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_tidy_+3A_dataframe">DataFrame</code></td>
<td>
<p>Data Frame of Twitter Data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tidy tibble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)

data &lt;- raw_tweets
tidy_data &lt;- tweet_tidy(DataFrame = data)
tidy_data


## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_time'>Twitter Data Timeseries Plot.</h2><span id='topic+tweet_time'></span>

<h3>Description</h3>

<p>Displays the Twitter data sentiment scores through time.  The 
sentiment scores by hashtag or topic are summed per day and plotted to 
show the change in sentiment through time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_time(DataFrameTidyScores, HT_Topic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_time_+3A_dataframetidyscores">DataFrameTidyScores</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd 
and scored.</p>
</td></tr>
<tr><td><code id="tweet_time_+3A_ht_topic">HT_Topic</code></td>
<td>
<p>If using hashtag data select:  &quot;hashtag&quot;.  If using topic 
data select:  &quot;topic&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
ht_time &lt;- tweet_time(DataFrameTidyScores = score_data,
                      HT_Topic = "hashtag")
ht_time

data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "topic")
topic_time &lt;- tweet_time(DataFrameTidyScores = score_data,
                         HT_Topic = "topic")
topic_time                    

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_topics'>Tweet Topics</h2><span id='topic+tweet_topics'></span>

<h3>Description</h3>

<p>Determines the Latent topics within a data frame by using Latent
Dirichlet Allocation (LDA) model parameters.  Uses the 'ldatuning' package 
and outputs an ldatuning plot.  Prepares Tweet text, creates DTM, conducts 
LDA, display data terms associated with each topic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_topics(
  DataFrame,
  clusters,
  method = "Gibbs",
  num_terms = 10,
  set_seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_topics_+3A_dataframe">DataFrame</code></td>
<td>
<p>Data Frame of Twitter Data.</p>
</td></tr>
<tr><td><code id="tweet_topics_+3A_clusters">clusters</code></td>
<td>
<p>The number of latent clusters.</p>
</td></tr>
<tr><td><code id="tweet_topics_+3A_method">method</code></td>
<td>
<p>method = &quot;Gibbs&quot;</p>
</td></tr>
<tr><td><code id="tweet_topics_+3A_num_terms">num_terms</code></td>
<td>
<p>The desired number of terms to be returned for each topic.</p>
</td></tr>
<tr><td><code id="tweet_topics_+3A_set_seed">set_seed</code></td>
<td>
<p>Seed for reproducible results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns LDA topics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
LDA_data &lt;- tweet_topics(DataFrame = data,
                         clusters = 8,
                         method = "Gibbs",
                         set_seed = 1234,
                         num_terms = 10)

LDA_data

## End(Not run)
</code></pre>

<hr>
<h2 id='tweet_violin'>Twitter Data Violin Plot</h2><span id='topic+tweet_violin'></span>

<h3>Description</h3>

<p>Displays the distribution scores of either hashtag or topic 
Twitter data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tweet_violin(DataFrameTidyScores, HT_Topic)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tweet_violin_+3A_dataframetidyscores">DataFrameTidyScores</code></td>
<td>
<p>DataFrame of Twitter Data that has been tidy'd 
and scored.</p>
</td></tr>
<tr><td><code id="tweet_violin_+3A_ht_topic">HT_Topic</code></td>
<td>
<p>If using hashtag data select:  &quot;hashtag&quot;.  If using topic 
data select:  &quot;topic&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot violin plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "hashtag")
ht_violin &lt;- tweet_violin(DataFrameTidyScores = score_data,
                          HT_Topic = "hashtag")
ht_violin

data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
score_data &lt;- tweet_scores(DataFrameTidy = tidy_data,
                           HT_Topic = "topic")
topic_violin &lt;- tweet_violin(DataFrameTidyScores = score_data,
                             HT_Topic = "topic") 
topic_violin                    

## End(Not run)
</code></pre>

<hr>
<h2 id='unigram'>Twitter Uni-Grams</h2><span id='topic+unigram'></span>

<h3>Description</h3>

<p>Determines and displays the text Uni-Grams within the Twitter 
data in sequence from the most used to the least used.  A Uni-Gram is a 
single word.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unigram(DataFrame)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unigram_+3A_dataframe">DataFrame</code></td>
<td>
<p>Data Frame of Twitter Data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
TD_Unigram &lt;- unigram(DataFrame = data)
TD_Unigram

## End(Not run)             
</code></pre>

<hr>
<h2 id='word_corr'>Twitter Word Correlations</h2><span id='topic+word_corr'></span>

<h3>Description</h3>

<p>The word correlation displays the mutual relationship between 
words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_corr(DataFrameTidy, number, sort = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_corr_+3A_dataframetidy">DataFrameTidy</code></td>
<td>
<p>Data Frame of Twitter Data that has been tidy'd.</p>
</td></tr>
<tr><td><code id="word_corr_+3A_number">number</code></td>
<td>
<p>The number of word instances to be included.</p>
</td></tr>
<tr><td><code id="word_corr_+3A_sort">sort</code></td>
<td>
<p>Rank order the results from most to least correlated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A Tibble.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
TD_Word_Corr &lt;- word_corr(DataFrameTidy = tidy_data,
                          number = 500,
                          sort = TRUE)

TD_Word_Corr

## End(Not run)                    
</code></pre>

<hr>
<h2 id='word_corr_network'>Twitter Word Correlations Plot</h2><span id='topic+word_corr_network'></span>

<h3>Description</h3>

<p>The word correlation network displays the mutual relationship 
between words.  The correlation network shows higher correlations with a 
thicker and darker edge color.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_corr_network(
  WordCorr,
  Correlation = 0.15,
  layout = "fr",
  edge_color = "royalblue",
  node_color = "black",
  node_size = 2,
  set_seed = 1234
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="word_corr_network_+3A_wordcorr">WordCorr</code></td>
<td>
<p>Data Frame of Word Correlations.</p>
</td></tr>
<tr><td><code id="word_corr_network_+3A_correlation">Correlation</code></td>
<td>
<p>Minimum level of correlation to be displayed.</p>
</td></tr>
<tr><td><code id="word_corr_network_+3A_layout">layout</code></td>
<td>
<p>Desired layout from the 'ggraph' package.
Acceptable layouts:  &quot;star&quot;, &quot;circle&quot;, &quot;gem&quot;, &quot;dh&quot;, &quot;graphopt&quot;, &quot;grid&quot;, 
&quot;mds&quot;, &quot;randomly&quot;, &quot;fr&quot;, &quot;kk&quot;, &quot;drl&quot;, &quot;lgl&quot;</p>
</td></tr>
<tr><td><code id="word_corr_network_+3A_edge_color">edge_color</code></td>
<td>
<p>User desired edge color.</p>
</td></tr>
<tr><td><code id="word_corr_network_+3A_node_color">node_color</code></td>
<td>
<p>User desired node color.</p>
</td></tr>
<tr><td><code id="word_corr_network_+3A_node_size">node_size</code></td>
<td>
<p>User desired node size.</p>
</td></tr>
<tr><td><code id="word_corr_network_+3A_set_seed">set_seed</code></td>
<td>
<p>Seed for reproducible results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An igraph plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(saotd)
data &lt;- raw_tweets
tidy_data &lt;- Tidy(DataFrame = data)
TD_Word_Corr &lt;- word_corr(DataFrameTidy = tidy_data,
                          number = 500,
                          sort = TRUE)
TD_Word_Corr_Network &lt;- word_corr_network(WordCorr = TD_Word_Corr,
                                       Correlation = 0.15,
                                       layout = "fr",
                                       edge_color = "royalblue",
                                       node_color = "black",
                                       node_size = 2,
                                       set_seed = 1234)

TD_Word_Corr_Network

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
