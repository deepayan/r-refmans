<!DOCTYPE html><html><head><title>Help for package word.alignment</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {word.alignment}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#word.alignment-package'>
<p>Computing Word Alignment Using IBM Model 1 (and Symmetrization) for a Given Parallel Corpus and Its Evaluation</p></a></li>
<li><a href='#align.ibm1'>
<p>Computing One-to-Many and Symmetric Word Alignment Using IBM Model 1 for a Given Sentence-Aligned Parallel Corpus</p></a></li>
<li><a href='#align.test'>
<p>Computing One-to-Many Word Alignment Using a Parallel Corpus for a Given Test Set</p></a></li>
<li><a href='#bidictionary'>
<p>Building an Automatic Bilingual Dictionary</p></a></li>
<li><a href='#cross.table'>
<p>Constructing  Cross Tables of the Source Language Words vs the Target Language Words of Sentence Pairs</p></a></li>
<li><a href='#evaluation'>
<p>Evaluation of Word Alignment Quality</p></a></li>
<li><a href='#excel2rdata'>
<p>Converting Excel Files Into Required R Format</p></a></li>
<li><a href='#neighbor'>
<p>Finding Neighborhood Locations</p></a></li>
<li><a href='#nfirst2lower'>
<p>Make a String's First n Characters Lowercase</p></a></li>
<li><a href='#prepare.data'>
<p>Initial Preparations of Bitext before the Word Alignment and the Evaluation of Word Alignment Quality</p></a></li>
<li><a href='#remove.punct'>
<p>Tokenizing and Removing Punctuation Marks</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Computing Word Alignment Using IBM Model 1 (and Symmetrization)
for a Given Parallel Corpus and Its Evaluation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-04-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Neda Daneshagr and Majid Sarmad.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Neda Daneshgar&lt;ne_da978@stu-mail.um.ac.ir&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>For a given Sentence-Aligned Parallel Corpus, it aligns words for each sentence pair. It considers one-to-many and symmetrization alignments. Moreover, it evaluates the quality of word alignment based on this package and some other software. It also builds an automatic dictionary of two languages based on given parallel corpus.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.2.2), data.table, openxlsx</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-04-15 08:55:50 UTC; daneshgar</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-04-15 09:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='word.alignment-package'>
Computing Word Alignment Using IBM Model 1 (and Symmetrization) for a Given Parallel Corpus and Its Evaluation
</h2><span id='topic+word.alignment-package'></span><span id='topic+word.alignment'></span>

<h3>Description</h3>

<p>For a given Sentence-Aligned Parallel Corpus, it aligns words for each sentence pair. It considers one-to-many alignment in the function <code><a href="#topic+align.ibm1">align.ibm1</a></code>  and symmetric word alignment in the function <code><a href="#topic+align.symmet">align.symmet</a></code>. Moreover, it evaluates the quality of word alignment from <code><a href="#topic+align.ibm1">align.ibm1</a></code> function or from some other software in the function <code><a href="#topic+evaluation">evaluation</a></code>. It also builds an automatic bilingual dictionary of two languages using the given corpus in the function <code><a href="#topic+bidictionary">bidictionary</a></code>.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> word.alignment</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2019-04-04</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>
<p>Maintainer: Neda Daneshgar&lt;ne_da978@stu-mail.um.ac.ir&gt;
</p>


<h3>References</h3>

<p>Fraser F., Marcu D. (2007), &quot;Measuring Word Alignment Quality for
Statistical Machine Translation.&quot;, Computational Linguistics, 33(3), 293-303.
</p>
<p>Koehn P. (2010), &quot;Statistical Machine Translation.&quot;,
Cambridge University, New York.
</p>
<p>Lopez A. (2008), &quot;Statistical Machine Translation.&quot;, ACM Computing Surveys, 40(3).
</p>
<p>Peter F., Brown J., (1990), &quot;A Statistical Approach to Machine Translation.&quot;, Computational Linguistics, 16(2), 79-85.
</p>
<p>Supreme Council of Information and Communication Technology. (2013), Mizan English-Persian Parallel Corpus. Tehran, I.R. Iran. Retrieved from http://dadegan.ir/catalog/mizan.
</p>
<p><a href="http://statmt.org/europarl/v7/bg-en.tgz">http://statmt.org/europarl/v7/bg-en.tgz</a>
</p>
<p>Och F., Ney H. (2003), &quot;A Systematic Comparison Of Various Statistical Alignment Models.&quot;, 2003 Association for Computational Linguistics, J03-1002, 29(1).
</p>
<p>Wang X. &quot;Evaluation of Two Word Alignment Systems.&quot;, Final Thesis, Department of Computer and Information Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Since the extraction of  bg-en.tgz in Europarl corpus is time consuming, 
# so the aforementioned unzip files have been temporarily exported to 
# http://www.um.ac.ir/~sarmad/... .

## Not run: 

ww = align.ibm1 ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en',
                      n=2000, encode.sorc = 'UTF-8')

ss = align.symmet ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en',
                      n = 50, encode.sorc = 'UTF-8')

## End(Not run)
</code></pre>

<hr>
<h2 id='align.ibm1'>
Computing One-to-Many and Symmetric Word Alignment Using IBM Model 1 for a Given Sentence-Aligned Parallel Corpus
</h2><span id='topic+align.ibm1'></span><span id='topic+align.symmet'></span><span id='topic+print.align'></span>

<h3>Description</h3>

<p>For a given sentence-aligned parallel corpus, it calculates source-to-target and target-to-source alignments using IBM Model 1, as well as symmetric word alignment models such as intersection, union, or grow-diag in each sentence pair. Moreover, it calculates the expected length and vocabulary size of each language (source and taget language) and also shows word translation probability as a data.table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>align.ibm1(...,
              iter = 5, dtfile.path = NULL, 
              name.sorc = 'f',name.trgt = 'e', 
              result.file = 'result', input = FALSE)
align.symmet(file.sorc, file.trgt, 
             n = -1L, iter = 4, 
             method = c ('union', 'intersection', 'grow-diag'), 
             encode.sorc = 'unknown', encode.trgt = 'unknown', 
             name.sorc = 'f', name.trgt = 'e', ...)              
              
## S3 method for class 'align'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="align.ibm1_+3A_file.sorc">file.sorc</code></td>
<td>

<p>the name of  source language file.
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_file.trgt">file.trgt</code></td>
<td>

<p>the name of  target language file.
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_n">n</code></td>
<td>

<p>the number of sentences to be read.If  -1, it considers all sentences.
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_iter">iter</code></td>
<td>

<p>the number of iterations for IBM Model 1.
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_method">method</code></td>
<td>

<p>character string specifying the symmetric word alignment method (union, intersection, or grow-diag alignment).
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_encode.sorc">encode.sorc</code></td>
<td>

<p>encoding to be assumed for the source language. If the value is &quot;latin1&quot; or &quot;UTF-8&quot; it is used to mark character strings as known to be in Latin-1 or UTF-8. For more details please see <code><a href="base.html#topic+scan">scan</a></code> function.   
</p>
</td></tr> 
<tr><td><code id="align.ibm1_+3A_encode.trgt">encode.trgt</code></td>
<td>

<p>encoding to be assumed for the target language. If the value is &quot;latin1&quot; or &quot;UTF-8&quot; it is used to mark character strings as known to be in Latin-1 or UTF-8. For more details please see <code><a href="base.html#topic+scan">scan</a></code> function.	 
</p>
</td></tr> 
<tr><td><code id="align.ibm1_+3A_name.sorc">name.sorc</code></td>
<td>

<p>it is a notation for the source language (default = <code>'f'</code>).
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_name.trgt">name.trgt</code></td>
<td>

<p>it is a notation for the target language (default = <code>'e'</code>).   
</p>
</td></tr> 
<tr><td><code id="align.ibm1_+3A_dtfile.path">dtfile.path</code></td>
<td>

<p>if <code>NULL</code> (usually for the first time), a data.table will be created contaning cross words of all sentences with their matched probabilities. It saves into a file named as a combination of <code>name.sorc</code>, <code>name.trgt</code>, <code>nrec</code> and <code>iter</code> as 'name.sorc.name.trgt.n.iter.RData'.
If specific file name is set, it will be read and continue the rest of the function, i.e. : finding the word alignments.
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_result.file">result.file</code></td>
<td>

<p>the output results file name.	 
</p>
</td></tr> 
<tr><td><code id="align.ibm1_+3A_input">input</code></td>
<td>

<p>logical. If <code>TRUE</code>, the output can be used by <code><a href="#topic+bidictionary">bidictionary</a></code> and <code><a href="#topic+align.test">align.test</a></code> functions.
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_x">x</code></td>
<td>

<p>an object of class <code>'align'</code>.
</p>
</td></tr>
<tr><td><code id="align.ibm1_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods and further arguments of function prepare.data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here, word alignment is a map of the target language to the source language. 
</p>
<p>The results depend on the corpus. As an example, we have used English-Persian parallel corpus named Mizan which consists of more than 1,000,000 sentence pairs with a size of 170 Mb. If all sentences are considered, it takes about 50.96671 mins using a computer with cpu: intel Xeon X5570 2.93GHZ and Ram: 8*8 G = 64 G and word alignment is good. But for the 10,000 first sentences, the word alignment might not be good. In fact, it is sensitive to the original translation type (lexical or conceptual). The results can be found at 
</p>
<p><a href="http://www.um.ac.ir/~sarmad/word.a/example.align.ibm1.pdf">http://www.um.ac.ir/~sarmad/word.a/example.align.ibm1.pdf</a>
</p>


<h3>Value</h3>

<p><code>align.ibm1</code> and <code>align.symmet</code> returns an object of class <code>'align'</code>.
</p>
<p>An object of class <code>'align'</code> is a list containing the following components:
</p>
<p>If  <code>input = TRUE</code>
</p>
<table>
<tr><td><code>dd1</code></td>
<td>
<p>A data.table.</p>
</td></tr>
</table>
<p>Otherwise, 
</p>
<table>
<tr><td><code>model</code></td>
<td>
<p>'IBM1'</p>
</td></tr>  
<tr><td><code>initial_n</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>used_n</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>A number. (in second/minute/hour)</p>
</td></tr>
<tr><td><code>iterIBM1</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>expended_l_source</code></td>
<td>
<p>A non-negative real number.</p>
</td></tr>
<tr><td><code>expended_l_target</code></td>
<td>
<p>A non-negative real number.</p>
</td></tr>
<tr><td><code>VocabularySize_source</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>VocabularySize_target</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>word_translation_prob</code></td>
<td>
<p>A data.table.</p>
</td></tr>
<tr><td><code>word_align</code></td>
<td>
<p>A list of one-to-many word alignment for each sentence pair (it is as word by word).</p>
</td></tr>
<tr><td><code>align_init</code></td>
<td>
<p>One-to-many word alignment for the first three sentences.</p>
</td></tr>
<tr><td><code>align_end</code></td>
<td>
<p>One-to-many word alignment for the last three sentences.</p>
</td></tr>
<tr><td><code>number_align</code></td>
<td>
<p>A list of one-to-many word alignment for each sentence pair (it is as numbers).</p>
</td></tr>
<tr><td><code>aa</code></td>
<td>
<p>A matrix (n*2), where <code>n</code> is the number of remained sentence pairs after preprocessing.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>symmetric word alignment method (union, intersection or grow-diag alignment).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that we have a memory restriction and so just special computers with a high
CPU and a big RAM can allocate the vectors of this function. Of course, it depends on the
corpus size. 
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>References</h3>

<p>Koehn P. (2010), &quot;Statistical Machine Translation.&quot;,
Cambridge University, New York.
</p>
<p>Lopez A. (2008), &quot;Statistical Machine Translation.&quot;, ACM Computing Surveys, 40(3).
</p>
<p>Peter F., Brown J. (1990), &quot;A Statistical
Approach to Machine Translation.&quot;, Computational Linguistics, 16(2), 79-85.
</p>
<p>Supreme Council of Information and Communication Technology. (2013), Mizan English-Persian Parallel Corpus. Tehran, I.R. Iran. Retrieved from http://dadegan.ir/catalog/mizan.
</p>
<p><a href="http://statmt.org/europarl/v7/bg-en.tgz">http://statmt.org/europarl/v7/bg-en.tgz</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+align.test">align.test</a></code>, <code><a href="#topic+align.symmet">align.symmet</a></code>, <code><a href="#topic+bidictionary">bidictionary</a></code>, <code><a href="base.html#topic+scan">scan</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Since the extraction of  bg-en.tgz in Europarl corpus is time consuming, 
# so the aforementioned unzip files have been temporarily exported to 
# http://www.um.ac.ir/~sarmad/... .
## Not run: 

w1 = align.ibm1 ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en',
                      n = 30, encode.sorc = 'UTF-8')
                 
w2 = align.ibm1 ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en',
                      n = 30, encode.sorc = 'UTF-8', remove.pt = FALSE)

S1 = align.symmet ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en',
                      n = 200, encode.sorc = 'UTF-8')
                      
S2 = align.symmet ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en',
                      n = 200, encode.sorc = 'UTF-8', method = 'grow-diag')


## End(Not run)
</code></pre>

<hr>
<h2 id='align.test'>
Computing One-to-Many Word Alignment Using a Parallel Corpus for a Given Test Set 
</h2><span id='topic+align.test'></span>

<h3>Description</h3>

<p>For a given parallel corpus based on IBM Model 1, it aligns the words of a given sentence-aligned test set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>align.test(file.sorc, file.trgt, test.sorc, test.trgt, 
           n.train = -1, n.test = -1, minlen.train = 5, maxlen.train = 40, 
           minlen.test = 5, maxlen.test = 40, null.tokens = TRUE, 
           dtfile.path = NULL, file.align = 'alignment',
           name.sorc='f',name.trgt='e',iter = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="align.test_+3A_file.sorc">file.sorc</code></td>
<td>

<p>the name of source language file in training set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_file.trgt">file.trgt</code></td>
<td>

<p>the name of  target language file in training set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_test.sorc">test.sorc</code></td>
<td>

<p>the name of source language file in test set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_test.trgt">test.trgt</code></td>
<td>

<p>the name of target language file in test set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_n.train">n.train</code></td>
<td>

<p>the number of sentences in the training set to be read. If  -1, it considers all sentences.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_n.test">n.test</code></td>
<td>

<p>the number of sentences in the test set to be read. If  -1, it considers all sentences.
</p>
</td></tr> 
<tr><td><code id="align.test_+3A_minlen.train">minlen.train</code></td>
<td>

<p>a minimum length of sentences in training set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_maxlen.train">maxlen.train</code></td>
<td>

<p>a maximum length of sentences in training set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_minlen.test">minlen.test</code></td>
<td>

<p>a minimum length of sentences in test set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_maxlen.test">maxlen.test</code></td>
<td>

<p>a maximum length of sentences in test set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_null.tokens">null.tokens</code></td>
<td>

<p>logical. If <code>TRUE</code>, &quot;null&quot; is added at the first of each source sentence of the test set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_dtfile.path">dtfile.path</code></td>
<td>

<p>if <code>NULL</code> (usually for the first time), a data.table will be created contaning cross words of all sentences with their matched probabilities. It saves into a file named as a combination of <code>name.sorc</code>, <code>name.trgt</code>, <code>n</code> and <code>iter</code> as &quot;f.e.n.iter.RData&quot;.
</p>
<p>If specific file name is set, it will be read and continue the rest of the function, i.e. : finding the word alignments for the test set.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_file.align">file.align</code></td>
<td>

<p>the output results file name.
</p>
</td></tr>  
<tr><td><code id="align.test_+3A_name.sorc">name.sorc</code></td>
<td>

<p>it is a notation for the source language (default = <code>'f'</code>).
</p>
</td></tr>
<tr><td><code id="align.test_+3A_name.trgt">name.trgt</code></td>
<td>

<p>it is a notation for the target language (default = <code>'e'</code>).
</p>
</td></tr>
<tr><td><code id="align.test_+3A_iter">iter</code></td>
<td>

<p>the number of  iterations for IBM Model 1.
</p>
</td></tr>
<tr><td><code id="align.test_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>prepare.data</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>dtfile.path = NULL</code>, the following question will be asked:
</p>
<p>&quot;Are you sure that you want to run the align.ibm1 function (It takes time)? (Yes/ No: if you want to specify word alignment path, please press 'No'.)
</p>


<h3>Value</h3>

<p>an RData object as &quot;file.align.n.iter.Rdata&quot;.
</p>


<h3>Note</h3>

<p>Note that we have a memory restriction and so just special computers with a high
CPU and a big RAM can allocate the vectors of this function. Of course, it depends on the
corpus size. 
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>References</h3>

<p>Koehn P. (2010), &quot;Statistical Machine Translation.&quot;,
Cambridge University, New York.
</p>
<p>Lopez A. (2008), &quot;Statistical Machine Translation.&quot;, ACM Computing Surveys, 40(3).
</p>
<p>Peter F., Brown J. (1990), &quot;A Statistical
Approach to Machine Translation.&quot;, Computational Linguistics, 16(2), 79-85.
</p>
<p>Supreme Council of Information and Communication Technology. (2013), Mizan English-Persian Parallel Corpus. Tehran, I.R. Iran. Retrieved from http://dadegan.ir/catalog/mizan.
</p>
<p><a href="http://statmt.org/europarl/v7/bg-en.tgz">http://statmt.org/europarl/v7/bg-en.tgz</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+align.ibm1">align.ibm1</a></code>, <code><a href="#topic+evaluation">evaluation</a></code>, <code><a href="base.html#topic+scan">scan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Since the extraction of  bg-en.tgz in Europarl corpus is time consuming, 
# so the aforementioned unzip files have been temporarily exported to 
# http://www.um.ac.ir/~sarmad/... .
# In addition, in this example we use the first five sentence pairs of training set as the 
# test set.
## Not run: 

ats = align.test ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                      'http://www.um.ac.ir/~sarmad/word.a/euro.en',  
                      'http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                      'http://www.um.ac.ir/~sarmad/word.a/euro.en',
                       n.train = 100,n.test = 5, encode.sorc = 'UTF-8')               

## End(Not run)
</code></pre>

<hr>
<h2 id='bidictionary'>
Building an Automatic Bilingual Dictionary
</h2><span id='topic+bidictionary'></span>

<h3>Description</h3>

<p>It builds an automatic bilingual dictionary of two languages based on given sentence-aligned parallel corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bidictionary (..., n = -1L, iter = 15, prob = 0.8,  
              dtfile.path = NULL, name.sorc = 'f', name.trgt = 'e')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bidictionary_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>prepare.data</code>.</p>
</td></tr>
<tr><td><code id="bidictionary_+3A_n">n</code></td>
<td>
<p>Number of sentences to be read.</p>
</td></tr>
<tr><td><code id="bidictionary_+3A_iter">iter</code></td>
<td>

<p>the number of  iterations for IBM Model 1.
</p>
</td></tr>
<tr><td><code id="bidictionary_+3A_prob">prob</code></td>
<td>

<p>the minimum word translation probanility.
</p>
</td></tr>
<tr><td><code id="bidictionary_+3A_dtfile.path">dtfile.path</code></td>
<td>

<p>if <code>NULL</code> (usually for the first time), a data.table will be created contaning cross words of all sentences with their matched probabilities. It saves into a file named as a combination of <code>name.sorc</code>, <code>name.trgt</code>, <code>n</code> and <code>iter</code> as &quot;f.e.n.iter.RData&quot;.
</p>
<p>If specific file name is set, it will be read and continue the rest of the function, i.e. : finding dictionary of two given languages.
</p>
</td></tr>
<tr><td><code id="bidictionary_+3A_name.sorc">name.sorc</code></td>
<td>

<p>source language's name in mydictionary.
</p>
</td></tr>
<tr><td><code id="bidictionary_+3A_name.trgt">name.trgt</code></td>
<td>

<p>traget language's name in mydictionary.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The results depend on the corpus. As an example, we have used English-Persian parallel corpus named Mizan which consists of more than 1,000,000 sentence pairs with a size of 170 Mb. For the 10,000 first sentences, we have a nice dictionary. It just takes 1.356784 mins using an ordinary computer. The results can be found at 
</p>
<p><a href="http://www.um.ac.ir/~sarmad/word.a/bidictionary.pdf">http://www.um.ac.ir/~sarmad/word.a/bidictionary.pdf</a>
</p>


<h3>Value</h3>

<p>A list.
</p>
<table>
<tr><td><code>time</code></td>
<td>
<p>A number. (in second/minute/hour)</p>
</td></tr>
<tr><td><code>number_input</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>Value_prob</code></td>
<td>
<p>A decimal number between 0 and 1.</p>
</td></tr>
<tr><td><code>iterIBM1</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>dictionary</code></td>
<td>
<p>A matrix.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that we have a memory restriction and just special computers with high cpu and big ram can allocate the vectors of this function. Of course, it depends on corpus size.
</p>
<p>In addition, if <code>dtfile.path = NULL</code>, the following question will be asked:
</p>
<p>&quot;Are you sure that you want to run the align.ibm1 function (It takes time)? (Yes/ No: if you want to specify word alignment path, please press 'No'.)
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>References</h3>

<p>Supreme Council of Information and Communication Technology. (2013), Mizan English-Persian Parallel Corpus. Tehran, I.R. Iran. Retrieved from http://dadegan.ir/catalog/mizan.
</p>
<p><a href="http://statmt.org/europarl/v7/bg-en.tgz">http://statmt.org/europarl/v7/bg-en.tgz</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+scan">scan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Since the extraction of  bg-en.tgz in Europarl corpus is time consuming, 
# so the aforementioned unzip files have been temporarily exported to 
# http://www.um.ac.ir/~sarmad/... .

## Not run: 

dic1 = bidictionary ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en', 
                      n = 2000, encode.sorc = 'UTF-8', 
                      name.sorc = 'BULGARIAN', name.trgt = 'ENGLISH')
              
dic2 = bidictionary ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                     'http://www.um.ac.ir/~sarmad/word.a/euro.en', 
                      n = 2000, encode.sorc = 'UTF-8', 
                      name.sorc = 'BULGARIAN', name.trgt = 'ENGLISH',
                      remove.pt = FALSE)

## End(Not run)              
</code></pre>

<hr>
<h2 id='cross.table'>
Constructing  Cross Tables of the Source Language Words vs the Target Language Words of Sentence Pairs
</h2><span id='topic+cross.table'></span>

<h3>Description</h3>

<p>It is a function to create the cross tables of the source language words vs the target language words of sentence pairs  as the gold standard or as the alignment matrix of another software. For the gold standard, the created cross table is filled by an expert. He/she sets '1' for Sure alignments and '2' for Possible alignments in cross between the source and the target words. For alignment results of another software, '1' in cross between each aligned source and target words is set by the user.
</p>
<p>It works with two formats: 
</p>
<p>For the first format, it constructs a cross table  of the source language words vs the target language words of a given sentence pair.  Then, after filling as mentioned above sentence by sentence, it builds a list of cross tables and finally, it saves the created list as &quot;file.align.RData&quot;. 
</p>
<p>In the second format, it creates an excel file with <code>n</code> sheets. Each sheet includes a cross table of the two language words related each sentence pair.  The file is as &quot;file.align.xlsx&quot;. The created file  to be filled as mentioned above.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cross.table( ..., 
             null.tokens = TRUE, 
             out.format = c('rdata','excel'), 
             file.align = 'alignment')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cross.table_+3A_...">...</code></td>
<td>

<p>Further agguments to be passed to <code>prepare.data</code> and <code>align.test</code>
</p>
</td></tr>
<tr><td><code id="cross.table_+3A_null.tokens">null.tokens</code></td>
<td>

<p>logical. If <code>TRUE</code>,  &quot;null&quot; is added at the first of each source and target sentence, when we use RData format.
</p>
</td></tr>
<tr><td><code id="cross.table_+3A_out.format">out.format</code></td>
<td>

<p>a character string including two options.For <code>"rdata"</code> format, it constructs a cross table of the source language words vs the target language words of a given
sentence pair. Then, after filling it as mentioned in the description sentence
by sentence, it builds a list of cross tables and finally, it saves the created list as &quot;file.align.RData&quot;. In the <code>"excel"</code> format, it creates
an excel file with n sheets. Each sheet includes a cross table of the two language
words related to each sentence pair. The file is as &quot;file.align.xlsx&quot;. The
created file to be filled as mentioned in description.
</p>
</td></tr>
<tr><td><code id="cross.table_+3A_file.align">file.align</code></td>
<td>

<p>the output file name. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an RData object as &quot;file.align.RData&quot; or an excel file as &quot;file.align.xlsx&quot;.
</p>


<h3>Note</h3>

<p>If you have not the non-ascii problem, you can set <code>out.format</code> as <code>'rdata'</code>. 
</p>
<p>If ypu assign <code>out.format</code> to <code>'excel'</code>, it is necessary to bring two notes into consideration. The first note is that in order to use the created excel file for <code><a href="#topic+evaluation">evaluation</a></code> function, don't forget to use <code><a href="#topic+excel2rdata">excel2rdata</a></code> function to convert the excel file into required R format. The second note focouses on this:
ocassionally, there is a problem with 'openxlsx' package which is used in the function and it might be solved by  'installr::install.rtools() on Windows'.
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>References</h3>

<p>Holmqvist M., Ahrenberg L. (2011), &quot;A Gold Standard for English-Swedish Word Alignment.&quot;, NODALIDA 2011 Conference Proceedings, 106 - 113.
</p>
<p>Och F., Ney H.(2003), &quot;A Systematic Comparison Of Various Statistical Alignment Models.&quot;, 2003 Association for Computational Linguistics, J03-1002, 29(1).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation">evaluation</a></code>, <code><a href="#topic+excel2rdata">excel2rdata</a></code>, <code><a href="base.html#topic+scan">scan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

cross.table('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
           'http://www.um.ac.ir/~sarmad/word.a/euro.en',
           n = 10, encode.sorc = 'UTF-8')

cross.table('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
           'http://www.um.ac.ir/~sarmad/word.a/euro.en', 
           n = 5, encode.sorc = 'UTF-8', out.format = 'excel')

## End(Not run)
</code></pre>

<hr>
<h2 id='evaluation'>
Evaluation of Word Alignment Quality
</h2><span id='topic+evaluation'></span>

<h3>Description</h3>

<p>It measures Precision, Recall, AER, and F_measurs metrics to evaluate the quality of word alignment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation(file.gold = 'gold.RData', 
           file.align = 'alignment.-1.3.RData', 
           agn = c('my.agn','an.agn'), alpha = 0.3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation_+3A_file.gold">file.gold</code></td>
<td>

<p>the gold standarad file name.</p>
</td></tr>
<tr><td><code id="evaluation_+3A_file.align">file.align</code></td>
<td>

<p>the alignment file name.
</p>
</td></tr>
<tr><td><code id="evaluation_+3A_agn">agn</code></td>
<td>

<p>character string including two values. If <code>"my.agn"</code>, the user wants to evaluate one-to-many word alignment using the <code>align.ibm1</code> function in this package. If <code>"an.agn"</code>, the user wants to evaluate word alignment results which are obtained by another software.
</p>
</td></tr>
<tr><td><code id="evaluation_+3A_alpha">alpha</code></td>
<td>

<p>is a parameter that sets the trade-off between Precision and Recall.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To evaluate word alignment quality, we need to a &quot;reference alignment&quot; (a gold standard for the word alignment) of a test set.
In order to read the gold into RData format and to compare it with the word alignment results, the gold standard file name must be set in <code>file.gold</code>. 
</p>


<h3>Value</h3>

<p>A list.
</p>
<table>
<tr><td><code>Recall</code></td>
<td>
<p>A decimal number.</p>
</td></tr>
<tr><td><code>Precision</code></td>
<td>
<p>A decimal number.</p>
</td></tr>
<tr><td><code>AER</code></td>
<td>
<p>A decimal number.</p>
</td></tr>
<tr><td><code>F_measure.PS</code></td>
<td>
<p>A decimal number.</p>
</td></tr>
<tr><td><code>F_measure.S</code></td>
<td>
<p>A decimal number.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>References</h3>

<p>Fraser F., Marcu D. (2007), &quot;MeasuringWord Alignment Quality for
Statistical Machine Translation.&quot;, Computational Linguistics, 33(3), 293-303.
</p>
<p>Koehn P. (2010), &quot;Statistical Machine Translation.&quot;,
Cambridge University, New York.
</p>
<p>Och F., Ney H.(2003).&quot;A Systematic Comparison Of Various Statistical Alignment Models.&quot;, 2003 Association for Computational Linguistics, J03-1002, 29(1).
</p>
<p>Wang X. &quot;Evaluation of Two Word Alignment Systems.&quot;, Final Thesis, Department of Computer and Information Science.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cross.table">cross.table</a></code>, <code><a href="#topic+align.test">align.test</a></code>, <code><a href="#topic+align.ibm1">align.ibm1</a></code>
</p>

<hr>
<h2 id='excel2rdata'>
Converting Excel Files Into Required R Format 
</h2><span id='topic+excel2rdata'></span>

<h3>Description</h3>

<p>This function converts the excel files into required RData format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>excel2rdata(file.align = 'alignment.xlsx', null.tokens = TRUE, len = len)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="excel2rdata_+3A_file.align">file.align</code></td>
<td>

<p>the excel file name which we want to convert it into required RData format. 
</p>
</td></tr>
<tr><td><code id="excel2rdata_+3A_null.tokens">null.tokens</code></td>
<td>

<p>logical. If &lsquo;<span class="samp">&#8288;TRUE&#8288;</span>&rsquo;, 'null' is added at the first of each source sentence of the test set.
</p>
</td></tr>
<tr><td><code id="excel2rdata_+3A_len">len</code></td>
<td>

<p>the  number of sheets of the excel file to be converted into RData format. It must be assigned by the user.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an RData object as 'file.align.RData'.
</p>


<h3>Note</h3>

<p>Note that in order to use the created excel file for the function <code><a href="#topic+evaluation">evaluation</a></code>, don't forget to use <code><a href="#topic+excel2rdata">excel2rdata</a></code> function to convert the excel file into required <code>RData</code> format.
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cross.table">cross.table</a></code>, <code><a href="#topic+evaluation">evaluation</a></code>
</p>

<hr>
<h2 id='neighbor'>
Finding Neighborhood Locations
</h2><span id='topic+neighbor'></span>

<h3>Description</h3>

<p>Starting with the intersection of ef and fe alignment one by one and finding the square neighbors including the union and intersection, recursively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neighbor(fe, ef, n.row)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neighbor_+3A_fe">fe</code></td>
<td>

<p>an integer vector.
</p>
</td></tr>
<tr><td><code id="neighbor_+3A_ef">ef</code></td>
<td>

<p>an integer vector.
</p>
</td></tr>
<tr><td><code id="neighbor_+3A_n.row">n.row</code></td>
<td>

<p>an integer. Number of rows of an initial matrix. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An integer vector.
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>References</h3>

<p>Koehn P. (2010), &quot;Statistical Machine Translation.&quot;,
Cambridge University, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fe = c(1,4,2,4,2)
ef = c(3,2,1,5)
n.row = 4
neighbor (fe, ef, n.row)
</code></pre>

<hr>
<h2 id='nfirst2lower'>
Make a String's First n Characters Lowercase
</h2><span id='topic+nfirst2lower'></span>

<h3>Description</h3>

<p>Converts uppercase to lowercase letters for the first n characters  of a character string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nfirst2lower(x, n = 1, first = TRUE, second = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nfirst2lower_+3A_x">x</code></td>
<td>

<p>a character string.
</p>
</td></tr>
<tr><td><code id="nfirst2lower_+3A_n">n</code></td>
<td>

<p>an integer. Number of characters that we want to convert.
</p>
</td></tr>
<tr><td><code id="nfirst2lower_+3A_first">first</code></td>
<td>

<p>logical. If <code>TRUE</code>, it converts the n first characters into lowercase.
</p>
</td></tr>
<tr><td><code id="nfirst2lower_+3A_second">second</code></td>
<td>

<p>logical. If <code>TRUE</code>, it checks if the second letter of <code>x</code> is uppercase, the whole word will be converted to lower.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is a function to convert some uppercase letters  into lowercase for which words with uppercase second letter. If <code><a href="base.html#topic+tolower">tolower</a></code> in base R is used, it will be sometimes created a problem for proper nouns. Because, as we know, a name or proper noun starts with capital letter and we do not want to convert them into lowercase. But sometimes there are some words which are not a name or proper noun and displayed in capital letters. These words are the target of this function.
</p>
<p>If we have a text of several sentences and we want to convert  the first n letters of every sentence to lowercase, separately. We have to split text to sentences, furthermore we should consider <code>first=TRUE</code> and apply the function for each sentence (see the examples below).
</p>
<p>If we have a list, it works fine.
</p>


<h3>Value</h3>

<p>A character string.
</p>


<h3>Note</h3>

<p>Because of all sentences begin with uppercase letters, <code>first=TRUE</code> is considered  as a default. But, if the second character of a word be capital, it is usually
concluded that all its characters are capital. In this case, you can consider <code>second=TRUE</code>. Of course, there are some exceptations in these cases that they can be ignored (see the examples below).
</p>
<p>In general, if there are not a lot of proper nouns in your text string, we suggest you to use <code><a href="base.html#topic+tolower">tolower</a></code> in base R. As an ability of this function, <code>lower</code> is considered as a third argument.
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+tolower">tolower</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># x is a list

x=list('W-A for an English-Persian Parallel Corpus (Mizan).','ALIGNMENT is a link between words.')

nfirst2lower(x, n=8) ## nfirst2lower(x, n=8) is not a list

y='MT is the automatic translation. SMT is one of the methods of MT.'

nfirst2lower(y) # only run for the first sentence

u1=unlist(strsplit(y, ". ", fixed = TRUE))
sapply(1:length(u1),function(x)nfirst2lower(u1[x])) ## run for all sentences

h = 'It is a METHOD for this function.'
nfirst2lower (h, second = TRUE) #only run for the first word

h1 = strsplit(h, ' ')[[1]]
nfirst2lower(h1, second = TRUE) # run for all words
</code></pre>

<hr>
<h2 id='prepare.data'>
Initial Preparations of Bitext before the Word Alignment and the Evaluation of Word Alignment Quality
</h2><span id='topic+prepare.data'></span>

<h3>Description</h3>

<p>For a given Sentence-Aligned Parallel Corpus, it prepars sentence pairs as an input for <code><a href="#topic+align.ibm1">align.ibm1</a></code> and <code><a href="#topic+evaluation">evaluation</a></code> functions in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepare.data(file.sorc, file.trgt, n = -1L, 
             encode.sorc = 'unknown' , encode.trgt = 'unknown', 
             min.len = 5, max.len = 40, remove.pt = TRUE, word.align = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepare.data_+3A_file.sorc">file.sorc</code></td>
<td>

<p>the name of source language file.
</p>
</td></tr>
<tr><td><code id="prepare.data_+3A_file.trgt">file.trgt</code></td>
<td>

<p>the name of target language file.
</p>
</td></tr>
<tr><td><code id="prepare.data_+3A_n">n</code></td>
<td>

<p>the number of sentences to be read.If  -1, it considers all sentences.
</p>
</td></tr>
<tr><td><code id="prepare.data_+3A_encode.sorc">encode.sorc</code></td>
<td>

<p>encoding to be assumed for the source language. If the value is &quot;latin1&quot; or &quot;UTF-8&quot; it is used to mark character strings as known to be in Latin-1 or UTF-8. For more details please see <code><a href="base.html#topic+scan">scan</a></code> function.	 
</p>
</td></tr> 
<tr><td><code id="prepare.data_+3A_encode.trgt">encode.trgt</code></td>
<td>

<p>encoding to be assumed for the target language. If the value is &quot;latin1&quot; or &quot;UTF-8&quot; it is used to mark character strings as known to be in Latin-1 or UTF-8. For more details please see <code><a href="base.html#topic+scan">scan</a></code> function.	 
</p>
</td></tr> 
<tr><td><code id="prepare.data_+3A_min.len">min.len</code></td>
<td>

<p>a minimum length of sentences.
</p>
</td></tr>
<tr><td><code id="prepare.data_+3A_max.len">max.len</code></td>
<td>

<p>a maximum length of sentences.
</p>
</td></tr>
<tr><td><code id="prepare.data_+3A_remove.pt">remove.pt</code></td>
<td>

<p>logical. If &lsquo;<span class="samp">&#8288;TRUE&#8288;</span>&rsquo;, it removes all punctuation marks.
</p>
</td></tr>   
<tr><td><code id="prepare.data_+3A_word.align">word.align</code></td>
<td>

<p>logical. If &lsquo;<span class="samp">&#8288;FALSE&#8288;</span>&rsquo;, it divides each sentence into its words. Results can be used in <code><a href="#topic+align.symmet">align.symmet</a></code>, <code><a href="#topic+cross.table">cross.table</a></code>, <code><a href="#topic+align.test">align.test</a></code> and <code><a href="#topic+evaluation">evaluation</a></code> functions. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It balances between source and target language as much as possible. For example, it removes extra blank sentences and equalization sentence pairs. Also, using <code><a href="#topic+nfirst2lower">nfirst2lower</a></code> function, it converts the first letter of each sentence into lowercase. Moreover, it removes  short and long sentences.
</p>


<h3>Value</h3>

<p>A list.
</p>
<p>if  <code>word_align = TRUE</code>
</p>
<table>
<tr><td><code>len1</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>aa</code></td>
<td>
<p>A matrix (n*2), where &lsquo;<span class="samp">&#8288;n&#8288;</span>&rsquo; is the number of remained sentence pairs after preprocessing.</p>
</td></tr>
</table>
<p>otherwise,
</p>
<table>
<tr><td><code>initial</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>used</code></td>
<td>
<p>An integer.</p>
</td></tr>
<tr><td><code>source.tok</code></td>
<td>
<p>A list of words for each the source sentence.</p>
</td></tr>
<tr><td><code>target.tok</code></td>
<td>
<p>A list of words for each the target sentence.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that if there is a few proper nouns in the parallel corpus, we suggest you to set <code>all=TRUE</code> to convert all text into lowercase.
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad.
</p>


<h3>References</h3>

<p>Koehn P. (2010), &quot;Statistical Machine Translation.&quot;,
Cambridge University, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation">evaluation</a></code>, <code><a href="#topic+nfirst2lower">nfirst2lower</a></code>, <code><a href="#topic+align.ibm1">align.ibm1</a></code>, <code><a href="base.html#topic+scan">scan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Since the extraction of  bg-en.tgz in Europarl corpus is time consuming, 
# so the aforementioned unzip files have been temporarily exported to 
# http://www.um.ac.ir/~sarmad/... .
## Not run: 

aa1 = prepare.data ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                   'http://www.um.ac.ir/~sarmad/word.a/euro.en', 
                    n = 20, encode.sorc = 'UTF-8')
 
aa2 = prepare.data ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                   'http://www.um.ac.ir/~sarmad/word.a/euro.en', 
                    n = 20, encode.sorc = 'UTF-8', word.align = FALSE)
                   
aa3 = prepare.data ('http://www.um.ac.ir/~sarmad/word.a/euro.bg',
                   'http://www.um.ac.ir/~sarmad/word.a/euro.en', 
                    n = 20, encode.sorc = 'UTF-8', remove.pt = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='remove.punct'>
Tokenizing and Removing Punctuation Marks
</h2><span id='topic+remove.punct'></span>

<h3>Description</h3>

<p>It splits a given text into separated words and removes its punctuation marks. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove.punct(text)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove.punct_+3A_text">text</code></td>
<td>

<p>an object.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function also considers numbers as a separated word.
</p>
<p>Note that This function removes &quot;dot&quot;&quot; only if it is at the end of the sentence, separately. Meanwhile, it does not eliminate dash and hyper.Because it is assumed that words containing these punctuations are one word.
</p>


<h3>Value</h3>

<p>A vector of character string.
</p>


<h3>Author(s)</h3>

<p>Neda Daneshgar and Majid Sarmad
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x = "This is an  example-based MT!"  
remove.punct (x)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
