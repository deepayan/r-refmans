<!DOCTYPE html><html><head><title>Help for package GFA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GFA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#GFA-package'>
<p>Group factor analysis.</p></a></li>
<li><a href='#getDefaultOpts'><p>A function for generating the default priors of GFA model</p></a></li>
<li><a href='#gfa'><p>Gibbs sampling for group factor analysis</p></a></li>
<li><a href='#informativeNoisePrior'><p>Informative noise residual prior</p></a></li>
<li><a href='#normalizeData'><p>Normalize data to be used by GFA</p></a></li>
<li><a href='#reconstruction'><p>Full data reconstruction based on posterior samples</p></a></li>
<li><a href='#robustComponents'><p>Robust GFA components</p></a></li>
<li><a href='#sequentialGfaPrediction'><p>Sequential prediction of new samples from observed data views to unobserved</p></a></li>
<li><a href='#undoNormalizeData'><p>A function for returning predictions into the original data space</p></a></li>
<li><a href='#visualizeComponents'><p>Visualize GFA components</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Group Factor Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Eemeli Leppäaho [aut, cre],
  Seppo Virtanen [aut],
  Muhammad Ammad-ud-din [ctb],
  Suleiman A Khan [ctb],
  Tommi Suvitaival [ctb],
  Inka Saarinen [ctb],
  Samuel Kaski [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Eemeli Leppäaho &lt;eemeli.leppaaho@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Factor analysis implementation for multiple data sources, i.e., for groups of variables. The whole data analysis pipeline is provided, including functions and recommendations for data normalization and model definition, as well as missing value prediction and model visualization. The model group factor analysis (GFA) is inferred with Gibbs sampling, and it has been presented originally by Virtanen et al. (2012), and extended in Klami et al. (2015) &lt;<a href="https://doi.org/10.1109%2FTNNLS.2014.2376974">doi:10.1109/TNNLS.2014.2376974</a>&gt; and Bunte et al. (2016) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtw207">doi:10.1093/bioinformatics/btw207</a>&gt;; for details, see the citation info.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-21 08:56:39 UTC; leppaahe</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-21 09:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='GFA-package'>
Group factor analysis.
</h2><span id='topic+GFA-package'></span><span id='topic+GFA'></span>

<h3>Description</h3>

<p>GFA does factor analysis for multiple data sets having matched observations, for exploratory or predictive data analysis.
</p>


<h3>Details</h3>

<p>The posterior distribution of GFA model parameters can be inferred with
function <code><a href="#topic+gfa">gfa</a></code>, once the priors have been defined with
<code><a href="#topic+getDefaultOpts">getDefaultOpts</a></code>. The priors are widely customizable, with two
recommended setups: (i) dense group-sparse components (default; similar to
package CCAGFA that provides variational Bayesian inference for the same
model) and (ii) components interpretable as biclusters. It is recommended
to preprocess the data with function <code><a href="#topic+normalizeData">normalizeData</a></code>.
Functions are provided for predicting missing data, choosing a prior for
the residual noise, identifying robust components and
visualizing the inferred model. A simple toy example of the pipeline
is provided as demo(GFApipeline), and a more elaborate one as
demo(GFAexample). Finally, the experiment presented in (Bunte, Leppaaho,
Saarinen and Kaski: Sparse group factor analysis for biclustering of
multiple data sources, Bioinformatics, 32(16):2457&ndash;2463, 2016) can
be replicated with demo(GFAdream). Most of the computational complexity
of the package is related to matrix operations, which can be parallelized
inherently by using e.g. OpenBLAS libraries.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Data generation
X &lt;- matrix(rnorm(20*3),20,3)                     #Latent variables
W &lt;- matrix(rnorm(30*3),30,3)                     #Projection matrix
Y &lt;- tcrossprod(X,W) + matrix(rnorm(20*30),20,30) #Observations
Y &lt;- sweep(Y, MARGIN=2, runif(30), "+")           #Feature means
Y &lt;- list(Y[,1:10], Y[,11:30])                    #Data grouping
#Model inference and visualization
norm &lt;- normalizeData(Y, type="center")           #Centering
opts &lt;- getDefaultOpts()                          #Model options
#Fast runs for the demo, default options recommended in general
opts[c("iter.burnin", "iter.max")] &lt;- c(500, 1000)
res &lt;- gfa(norm$train, K=5, opts=opts)            #Model inference
rec &lt;- reconstruction(res)                        #Reconstruction
recOrig &lt;- undoNormalizeData(rec, norm)           #... to original space
vis &lt;- visualizeComponents(res, Y, norm)          #Visualization
</code></pre>

<hr>
<h2 id='getDefaultOpts'>A function for generating the default priors of GFA model</h2><span id='topic+getDefaultOpts'></span>

<h3>Description</h3>

<p><code>getDefaultOpts</code> returns the priors of GFA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDefaultOpts(bicluster = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getDefaultOpts_+3A_bicluster">bicluster</code></td>
<td>
<p>Use binary sparsity priors in both the data modes? If FALSE
(default), the components will be dense in the data sources, but
group-sparse, i.e., each component is active in a (potentially
different) subset of the data sources. If TRUE, binary sparsity is
inferred for each data sample and feature, resulting in each component
to be interpretable as a multi-source bicluster.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns options defining the model's high-level structure
(sparsity priors) and the model's hyperparameters, defining uninformative
priors. We recommend keeping these as provided, with one exception: if the
uninformative prior of the noise residual (tau) seems to result in an overly
complex model (no components become shut down even if the initial K is set
high), risking overfitting, we recommend using
function <code><a href="#topic+informativeNoisePrior">informativeNoisePrior</a></code> to adjust the priors.
</p>


<h3>Value</h3>

<p>A list with the following model options:
</p>
<table>
<tr><td><code>tauGrouped</code></td>
<td>
<p>If TRUE (default), data views have separate noise
precisions, otherwise each feature has.</p>
</td></tr>
<tr><td><code>normalLatents</code></td>
<td>
<p>If TRUE, X will have a normal prior; if FALSE
X, will have a spike-and-slab prior.</p>
</td></tr>
<tr><td><code>spikeW</code></td>
<td>
<p>Sparsity prior of W. &quot;group&quot;=group sparsity, &quot;element&quot;=
element-wise sparsity with shared hyperparameter across views, &quot;shared&quot;=
element-wise sparsity with no grouping.</p>
</td></tr>
<tr><td><code>ARDW</code></td>
<td>
<p>ARD prior type for W, determining the scale of the inferred
components. &quot;shared&quot;=same scale for all the data sources, &quot;grouped&quot;
(default)= separate scale for each data source, &quot;element&quot;=separate scale
for each feature.</p>
</td></tr>
<tr><td><code>ARDLatent</code></td>
<td>
<p>ARD prior type for X: &quot;shared&quot; (default)=shared scale for
all the samples, &quot;element&quot;=separate scale for each sample.</p>
</td></tr>
<tr><td><code>imputation</code></td>
<td>
<p>Missing value imputation type: &quot;Bayesian&quot; (default)=proper 
Bayesian handling of missing values. &quot;conservative&quot;=missing values result
in smaller parameter scale, which can be useful if tricky missing value
structure causes exaggerated imputed values with the default setting
(which can also be dealt with informative priors for alpha and beta).</p>
</td></tr>
<tr><td><code>iter.max</code></td>
<td>
<p>The total number of Gibbs sampling steps (default 5000).</p>
</td></tr>
<tr><td><code>iter.saved</code></td>
<td>
<p>The number of saved posterior samples (default 100).</p>
</td></tr>
<tr><td><code>iter.burnin</code></td>
<td>
<p>The number of burn-in samples (default 2500).</p>
</td></tr>
<tr><td><code>init.tau</code></td>
<td>
<p>The initial noise precision. High values imply initializing
the model with an adequate number of components. Default 1000.</p>
</td></tr>
<tr><td><code>sampleZ</code></td>
<td>
<p>When to start sampling spike and slab parameters (default:
Gibbs sample 1).</p>
</td></tr>
<tr><td><code>prior.alpha_0t</code></td>
<td>
<p>The shape parameter of tau's prior (default 10).</p>
</td></tr>
<tr><td><code>prior.beta_0t</code></td>
<td>
<p>The rate parameter of tau's prior (default 10).</p>
</td></tr>
<tr><td><code>prior.alpha_0</code></td>
<td>
<p>The shape parameter of alpha's prior (default 10).</p>
</td></tr>
<tr><td><code>prior.beta_0</code></td>
<td>
<p>The rate parameter of alpha's prior (default 01).</p>
</td></tr>
<tr><td><code>prior.alpha_0X</code></td>
<td>
<p>The shape parameter of beta's prior (default 10).</p>
</td></tr>
<tr><td><code>prior.beta_0X</code></td>
<td>
<p>The rate parameter of beta's prior (default 1).</p>
</td></tr>
<tr><td><code>prior.beta</code></td>
<td>
<p>Bernoulli prior for the spike-and-slab prior of W (counts
for 1s and 0s; default c(1,1)).</p>
</td></tr>
<tr><td><code>prior.betaX</code></td>
<td>
<p>Bernoulli prior for the possible spike-and-slab prior of
X (default c(1,1)).</p>
</td></tr>
<tr><td><code>verbose</code></td>
<td>
<p>The verbosity level. 0=no printing, 1=moderate printing,
2=maximal printing (default 1).</p>
</td></tr>
<tr><td><code>convergenceCheck</code></td>
<td>
<p>Check for the convergence of the data reconstruction,
based on the Geweke diagnostic (default FALSE).</p>
</td></tr>
<tr><td><code>save.posterior</code></td>
<td>
<p>A list determining which parameters' posterior samples are
saved (default: X, W and tau).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>#Given pre-specified data collection Y and component number K
opts &lt;- getDefaultOpts(bicluster=FALSE)
opts$normalLatents &lt;- FALSE #Binary sparsity for each sample and data source
 ## Not run: model &lt;- gfa(Y,opts,K)
</code></pre>

<hr>
<h2 id='gfa'>Gibbs sampling for group factor analysis</h2><span id='topic+gfa'></span>

<h3>Description</h3>

<p><code>gfa</code> returns posterior samples of group factor analysis model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gfa(Y, opts, K = NULL, projection = NULL, filename = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gfa_+3A_y">Y</code></td>
<td>
<p>Either </p>

<ol>
<li><p>Data sources with co-occuring samples: a list of data
matrices, where Y[[m]] is a numeric <code class="reqn">N \times D_m</code> matrix, or
</p>
</li>
<li><p>Data sources paired in two modes (some data sources share the
samples of the first data source, and some share its features): A list with
two elements structured as 1. The data collections Y[[1]] and
Y[[2]] should be connected by sharing their first data source, i.e.
Y[[1]][[1]] should equal the transpose of Y[[2]][[1]].
</p>
</li></ol>

<p>NOTE: The data features should have roughly zero mean and unit variance.
If this is not the case, preprocessing with function
<code><a href="#topic+normalizeData">normalizeData</a></code> is recommended.</p>
</td></tr>
<tr><td><code id="gfa_+3A_opts">opts</code></td>
<td>
<p>List of model options; see function <code><a href="#topic+getDefaultOpts">getDefaultOpts</a></code>.</p>
</td></tr>
<tr><td><code id="gfa_+3A_k">K</code></td>
<td>
<p>The number of components (i.e. latent variables). Recommended to be
set somewhat higher than the expected component number, so that the sampler
can determine the model complexity by shutting down excessive components.
High values result in high CPU time. Default: half of the minimum of the
sample size and total data dimensionality.</p>
</td></tr>
<tr><td><code id="gfa_+3A_projection">projection</code></td>
<td>
<p>Fixed projections. Only intended for sequential prediction
use via function <code><a href="#topic+sequentialGfaPrediction">sequentialGfaPrediction</a></code>. Default: NULL.</p>
</td></tr>
<tr><td><code id="gfa_+3A_filename">filename</code></td>
<td>
<p>A string. If provided, will save the sampling chain to this
file every 100 iterations. Default &quot;&quot;, inducing no saving.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GFA allows factor analysis of multiple data sources (i.e. data sets).
The priors of the model can be set to infer bicluster structure
from the data sources; see <code><a href="#topic+getDefaultOpts">getDefaultOpts</a></code>.
Missing values (NAs) are inherently supported. They will not affect the model
parameters, but can be predicted with function <code><a href="#topic+reconstruction">reconstruction</a></code>,
based on the observed values of the corresponding sample and feature.
The association of a data source to each component is inferred based on
the data. Letting only a subset of the components to explain a data source
results in the posterior identifying relationships between any subset of the
data sources. In the extreme cases, a component can explain relationships
within a single data source only (&quot;structured noise&quot;), or across all the data
sources.
</p>


<h3>Value</h3>

<p>A list containing the model parameters - in case of pairing in two
modes, each element is a list of length 2; one element for each mode.
For most parameters, the final posterior sample is provided to aid in
initial checks; all the posterior samples should be used for model
analysis. The list elements are:   
</p>
<table>
<tr><td><code>W</code></td>
<td>
<p>The loading matrix (final posterior sample); <code class="reqn">D \times K</code>
matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>The latent variables (final sample); <code class="reqn">N \times K</code> matrix.</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>The spike-and-slab parameters (final sample); <code class="reqn">D \times K</code>
matrix.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>The probability of slab in Z (final sample).</p>
</td></tr>
<tr><td><code>rz</code></td>
<td>
<p>The probability of slab in the spike-and-slab prior of X
(final sample).</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>The noise precisions (final sample); D-element vector.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The precisions of the projection weights W (final sample);
<code class="reqn">D \times K</code> matrix.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The precisions of the latent variables X (final sample);
<code class="reqn">N \times K</code> matrix.</p>
</td></tr>
<tr><td><code>groups</code></td>
<td>
<p>A list denoting which features belong to each data source.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>Data dimensionalities; M-element vector.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>The number of components inferred. May be less than the initial K.</p>
</td></tr>
</table>
<p>and the following elements:
</p>
<table>
<tr><td><code>posterior</code></td>
<td>
<p>the posterior samples of, by default, X, W and tau.</p>
</td></tr>
<tr><td><code>cost</code></td>
<td>
<p>The likelihood of all the posterior samples.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>The Akaike information criterion of all the posterior samples.</p>
</td></tr>
<tr><td><code>opts</code></td>
<td>
<p>The options used for the GFA model.</p>
</td></tr>
<tr><td><code>conv</code></td>
<td>
<p>An estimate of the convergence of the model's reconstruction
based on Geweke diagnostic. Values significantly above 0.05 imply a
non-converged model, and hence the need for a longer sampling chain.</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>The CPU time (in seconds) used to sample the model.</p>
</td></tr>
</table>

<hr>
<h2 id='informativeNoisePrior'>Informative noise residual prior</h2><span id='topic+informativeNoisePrior'></span>

<h3>Description</h3>

<p><code>informativeNoisePrior</code> returns an informative noise prior for GFA, for
a given data collection. The function sets the noise residual parameters
such that the expected proportion of
variance explained is for all variables and groups (in contrast to being
proportional to their original scale). Recommended e.g. when the data is
'small n, large p', and the standard prior from <code><a href="#topic+getDefaultOpts">getDefaultOpts</a></code>
seems to overfit the model by not shutting off any component with high
initial K.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>informativeNoisePrior(Y, opts, noiseProportion = 0.5, conf = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="informativeNoisePrior_+3A_y">Y</code></td>
<td>
<p>The data. For details, see function <code><a href="#topic+gfa">gfa</a></code>.</p>
</td></tr>
<tr><td><code id="informativeNoisePrior_+3A_opts">opts</code></td>
<td>
<p>Model options. See function <code><a href="#topic+getDefaultOpts">getDefaultOpts</a></code> for
details. If option tauGrouped is TRUE (default), each data source is given
equal importance (feature importance may vary within each
source). If it is FALSE, each feature is given equal importance.</p>
</td></tr>
<tr><td><code id="informativeNoisePrior_+3A_noiseproportion">noiseProportion</code></td>
<td>
<p>proportion of total variance to be
explained by noise. Suggested to lie between 0.01 and 0.99.</p>
</td></tr>
<tr><td><code id="informativeNoisePrior_+3A_conf">conf</code></td>
<td>
<p>Confidence in the prior, relative to confidence in the data.
Suggested to lie between 0.01 and 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input model options (opts) with an updated residual
noise prior, corresponding to the elements prior.alpha_0t and
prior.beta_0t.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Given data collection Y
opts &lt;- getDefaultOpts()
## Not run: opts &lt;- informativeNoisePrior(Y,opts,0.2,1)
## Not run: res &lt;- gfa(Y,opts=opts)
</code></pre>

<hr>
<h2 id='normalizeData'>Normalize data to be used by GFA</h2><span id='topic+normalizeData'></span>

<h3>Description</h3>

<p><code>normalizeData</code> is used to transform a data collection into a normalized
form suitable for GFA.
This function does two things: 1. It centers each variable. GFA assumes
zero-mean data, as it models variances. 2. It normalizes the scales of
variables and/or variable groups. Features with higher variance will
affect the model structure more; if this is not desired, the normalization
should be done. In GFA it is additionally possible to normalize the
importance of variable groups (data sources), in addition or instead of
individual variables. Finally, the total variance of data is normalized for
numerical reasons. This is particularly important if no other normalization
is done. NOTE: the function assumes continuous-valued data.
If some features are e.g. binary with only a small portion of 1s, we do not
recommend centering them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalizeData(train, test = NULL, type = "scaleOverAll")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalizeData_+3A_train">train</code></td>
<td>
<p>a training data set. For a detailed description, see parameter Y
in <code><a href="#topic+gfa">gfa</a></code>.</p>
</td></tr>
<tr><td><code id="normalizeData_+3A_test">test</code></td>
<td>
<p>a test dataset. Should be provided if sequential prediction
is used later.</p>
</td></tr>
<tr><td><code id="normalizeData_+3A_type">type</code></td>
<td>
<p>Specifies the type of normalization to do. Mean-centering of the
features is performed in all the cases, and option &quot;center&quot;
does not perform any scaling. Option &quot;scaleOverall&quot; (default) uses a
single parameter to scale the variance of the
whole data collection to 1, while &quot;scaleSources&quot; scales each data
source to have variance 1. Finally, &quot;scaleFeatures&quot; performs
z-normalization, i.e. assigns the variance of each feature to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table>
<tr><td><code>train</code></td>
<td>
<p>Normalized training data.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>Normalized test data for sequential prediction (if provided as
input).</p>
</td></tr>
<tr><td><code>trainMean</code></td>
<td>
<p>Feature-wise means of the training data sources.</p>
</td></tr>
<tr><td><code>trainSd</code></td>
<td>
<p>Feature-wise/overall standard deviations of the training data
sources.</p>
</td></tr>
</table>

<hr>
<h2 id='reconstruction'>Full data reconstruction based on posterior samples</h2><span id='topic+reconstruction'></span>

<h3>Description</h3>

<p><code>reconstruction</code> returns the full data reconstruction based on given
posterior samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reconstruction(res, average = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reconstruction_+3A_res">res</code></td>
<td>
<p>The sampled model from function <code><a href="#topic+gfa">gfa</a></code></p>
</td></tr>
<tr><td><code id="reconstruction_+3A_average">average</code></td>
<td>
<p>If TRUE (default), averages the reconstruction over the
posterior predictive samples. If set to
FALSE, the output may require a large amount of memory. In case of large
input data, we recommend acquiring the posterior predictive samples for
subsets of data at a time, based on this implementation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The data reconstruction, a numeric  <code class="reqn">N \times \sum_{m=1}^M D_m</code> 
matrix, if average is TRUE (default). Otherwise, the reconstruction is a
<code class="reqn">N \times \sum_{m=1}^M D_m \times Npost</code> array, with posterior samples
in the third dimension. If the input data has been paired in two modes, the
output will be a list of length 2, one element corresponding to each mode.
</p>

<hr>
<h2 id='robustComponents'>Robust GFA components</h2><span id='topic+robustComponents'></span>

<h3>Description</h3>

<p><code>robustComponents</code> analyzes a collection of sampling chains and returns
robust components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>robustComponents(models, corThr = 0.9, matchThr = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="robustComponents_+3A_models">models</code></td>
<td>
<p>Either a vector containing the file names, where the models are
saved as 'res', or a list containing the models.</p>
</td></tr>
<tr><td><code id="robustComponents_+3A_corthr">corThr</code></td>
<td>
<p>How close two components are required to be, in terms of
correlation, in order to match them.</p>
</td></tr>
<tr><td><code id="robustComponents_+3A_matchthr">matchThr</code></td>
<td>
<p>How big proportion of the chains need to contain the
component to include it in the robust components.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the effects (i.e. reconstructions) of robust components
to the data level. It is useful for a thorough model interpretation,
accumulating power over several sampling chains by
comparing them in the observation space (as opposed to the latent space).
The function is needed for this task, as the extreme multi-modality of factor
analysis prohibits efficient sampling techniques that would result in a
posterior estimate converging to the true posterior in practice.
The function uses a heuristic correlation-based procedure to analyze which
components occur frequently in GFA sampling chains.
</p>


<h3>Value</h3>

<p>A list with the following elements (when input data are paired in two
modes, the returned list is of length 2, containing the following elements
for each mode):
</p>
<table>
<tr><td><code>Krobust</code></td>
<td>
<p>The number of robust components found with the given
thresholds.</p>
</td></tr>
<tr><td><code>effect</code></td>
<td>
<p>The component effect in the data space; and array of size
<code class="reqn">N \times \sum_{m=1}^M D_m \times Krobust.</code></p>
</td></tr>
<tr><td><code>indices</code></td>
<td>
<p>The corresponding component indices; a <code class="reqn">length(models)
  \times Krobust</code> matrix. Negative indices denote the closest component in
the corresponding repetition, having no components above the threshold.</p>
</td></tr>
<tr><td><code>cor</code></td>
<td>
<p>The correlations of the components matched to this robust
component; a matrix of size <code class="reqn">length(models) \times Krobust</code>. The
correlations are reported relative to the first repetition with this
component observed.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(10*2),10,2)
W &lt;- matrix(rnorm(15*2),15,2)
Y &lt;- tcrossprod(X,W) + matrix(rnorm(10*15),10,15)
opts &lt;- getDefaultOpts() #Default options
#Fast runs for the demo, default options recommended in general
opts[c("iter.burnin", "iter.max")] &lt;- c(500, 1000)
res &lt;- list()
for(i in 1:4) res[[i]] &lt;- gfa(list(Y[,1:6],Y[,7:15]),opts=opts,K=3)
rob &lt;- robustComponents(res)
</code></pre>

<hr>
<h2 id='sequentialGfaPrediction'>Sequential prediction of new samples from observed data views to unobserved</h2><span id='topic+sequentialGfaPrediction'></span>

<h3>Description</h3>

<p><code>sequentialGfaPrediction</code> returns predictions for unobserved data
sources of a new set of data samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sequentialGfaPrediction(Y, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sequentialGfaPrediction_+3A_y">Y</code></td>
<td>
<p>The new data samples, in a similar format as in function
<code><a href="#topic+gfa">gfa</a></code></p>
</td></tr>
<tr><td><code id="sequentialGfaPrediction_+3A_model">model</code></td>
<td>
<p>The sampled model from function <code><a href="#topic+gfa">gfa</a></code>, with
model$opts$predict being a logical vector with the length matching the
length of Y, describing which data views will be predicted (TRUE), and
which have been observed (FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the predictions, with the observed
data sources empty. Additionally, sampling MSE is given as element 'mse',
and likelihood as 'cost'.
</p>

<hr>
<h2 id='undoNormalizeData'>A function for returning predictions into the original data space</h2><span id='topic+undoNormalizeData'></span>

<h3>Description</h3>

<p><code>undoNormalizeData</code> returns the predictions on normalized data acquired
from <code><a href="#topic+normalizeData">normalizeData</a></code> into the original data space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>undoNormalizeData(pred, normalization)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="undoNormalizeData_+3A_pred">pred</code></td>
<td>
<p>The predictions acquired from <code><a href="#topic+reconstruction">reconstruction</a></code>.</p>
</td></tr>
<tr><td><code id="undoNormalizeData_+3A_normalization">normalization</code></td>
<td>
<p>The output list obtained from
<code><a href="#topic+normalizeData">normalizeData</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predictions in the original data space.
</p>

<hr>
<h2 id='visualizeComponents'>Visualize GFA components</h2><span id='topic+visualizeComponents'></span>

<h3>Description</h3>

<p><code>visualizeComponents</code> illustrates the factorization inferred by GFA,
averaging over the posteriors of the parameters, if they have been stored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualizeComponents(
  model,
  Y = NULL,
  norm = NULL,
  mode = 1,
  showAll = TRUE,
  hclust = FALSE,
  topK = 3,
  topFeatures = NA,
  topSamples = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualizeComponents_+3A_model">model</code></td>
<td>
<p>The learned GFA model.</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_y">Y</code></td>
<td>
<p>The used input data to be plotted, if supplied. Default NULL.</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_norm">norm</code></td>
<td>
<p>The normalization acquired from <code><a href="#topic+normalizeData">normalizeData</a></code>, if
applied. If provided, the reconstruction is shown in the original data
space. Default NULL.</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_mode">mode</code></td>
<td>
<p>Determines which mode to visualize in case of pairing in two
modes (default: 1).</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_showall">showAll</code></td>
<td>
<p>Show the full predictions and factorizations? May be
cumbersome for large data. Default TRUE.</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_hclust">hclust</code></td>
<td>
<p>Order features and samples based on hierarchical clustering?
Default FALSE.</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_topk">topK</code></td>
<td>
<p>Number of strongest components visualized in the data space.
Default 3.</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_topfeatures">topFeatures</code></td>
<td>
<p>How many most relevant features to show for the data space
visualizations? Default NA, showing all the features.</p>
</td></tr>
<tr><td><code id="visualizeComponents_+3A_topsamples">topSamples</code></td>
<td>
<p>How many most relevant samples to show for the data space
visualizations? Default NA, showing all the samples.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the matrices that have been visualized.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
