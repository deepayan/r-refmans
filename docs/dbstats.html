<!DOCTYPE html><html><head><title>Help for package dbstats</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dbstats}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.D2'>
<p>D2 objects</p></a></li>
<li><a href='#as.Gram'>
<p>Gram objects</p></a></li>
<li><a href='#D2toDist'>
<p>Distance conversion: D2 to dist</p></a></li>
<li><a href='#D2toG'>
<p>Distance conversion: D2 to G</p></a></li>
<li><a href='#dbglm'>
<p>Distance-based generalized linear models</p></a></li>
<li><a href='#dbglm-inl'><p>Internal functions</p></a></li>
<li><a href='#dblm'>
<p>Distance-based linear model</p></a></li>
<li><a href='#dblm-inl'><p>Internal  functions</p></a></li>
<li><a href='#dbplsr'>
<p>Distance-based partial least squares regression</p></a></li>
<li><a href='#dbplsr-inl'><p>Internal  functions</p></a></li>
<li><a href='#dbstats-package'>
<p>Distance-based statistics (dbstats)</p></a></li>
<li><a href='#disttoD2'>
<p>Distance conversion: dist to D2</p></a></li>
<li><a href='#GtoD2'>
<p>Distance conversion: dist to D2</p></a></li>
<li><a href='#ldbglm'>
<p>Local distance-based generalized linear model</p></a></li>
<li><a href='#ldbglm-inl'><p>Internal  functions</p></a></li>
<li><a href='#ldblm'>
<p>Local distance-based linear model</p></a></li>
<li><a href='#ldblm-inl'><p>Internal  functions</p></a></li>
<li><a href='#plot.dblm'>
<p>Plots for objects of clases dblm or dbglm</p></a></li>
<li><a href='#plot.dbplsr'>
<p>Plots for a dbplsr object</p></a></li>
<li><a href='#plot.ldblm'>
<p>Plots for objects of clases ldblm or ldbglm</p></a></li>
<li><a href='#predict.dbglm'>
<p>Predicted values for a dbglm object</p></a></li>
<li><a href='#predict.dblm'>
<p>Predicted values for a dblm object</p></a></li>
<li><a href='#predict.dbplsr'>
<p>Predicted values for a dbpls object</p></a></li>
<li><a href='#predict.ldbglm'>
<p>Predicted values for a ldbglm object</p></a></li>
<li><a href='#predict.ldblm'>
<p>Predicted values for a ldblm object</p></a></li>
<li><a href='#summary.dbglm'>
<p>Summarizing distance-based generalized linear model fits</p></a></li>
<li><a href='#summary.dblm'>
<p>Summarizing distance-based linear model fits</p></a></li>
<li><a href='#summary.dbplsr'>
<p>Summarizing distance-based partial least squares fits</p></a></li>
<li><a href='#summary.ldbglm'>
<p>Summarizing local distance-based generalized linear model fits</p></a></li>
<li><a href='#summary.ldblm'>
<p>Summarizing local distance-based linear model fits</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Distance-Based Statistics</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-26</td>
</tr>
<tr>
<td>Author:</td>
<td>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@irb.barcelona.org&gt;, Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;. </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Eva Boj &lt;evaboj@ub.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Prediction methods where explanatory information is coded as a matrix of distances between individuals. Distances can either be directly input as a distances matrix, a squared distances matrix, an inner-products matrix or computed from observed predictors. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3), cluster, pls</td>
</tr>
<tr>
<td>Suggests:</td>
<td>proxy</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-26 18:23:02 UTC; evaboj</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-26 18:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.D2'>
D2 objects
</h2><span id='topic+as.D2'></span><span id='topic+is.D2'></span>

<h3>Description</h3>

<p><code>as.D2</code> attempts to turn its argument into a <code>D2</code> class object.
</p>
<p><code>is.D2</code> tests if its argument is a (strict) <code>D2</code> class object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  as.D2(x)

  is.D2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.D2_+3A_x">x</code></td>
<td>

<p>an R object.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>D2</code> containing the squared distances 
matrix between individuals.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D2toG">D2toG</a></code>, <code><a href="#topic+disttoD2">disttoD2</a></code>, <code><a href="#topic+D2toDist">D2toDist</a></code> and 
<code><a href="#topic+GtoD2">GtoD2</a></code> for conversions.
</p>

<hr>
<h2 id='as.Gram'>
Gram objects
</h2><span id='topic+as.Gram'></span><span id='topic+is.Gram'></span>

<h3>Description</h3>

<p><code>as.Gram</code> attempts to turn its argument into a <code>Gram</code> class object. 
</p>
<p><code>is.Gram</code> tests if its argument is a (strict) <code>Gram</code> class object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  as.Gram(x)
  
  is.Gram(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.Gram_+3A_x">x</code></td>
<td>

<p>an R object.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>Gram</code> class object. Weighted centered inner products matrix of the 
squared distances matrix. 
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D2toG">D2toG</a></code>, <code><a href="#topic+disttoD2">disttoD2</a></code>, <code><a href="#topic+D2toDist">D2toDist</a></code> and 
<code><a href="#topic+GtoD2">GtoD2</a></code> for conversions.
</p>

<hr>
<h2 id='D2toDist'>
Distance conversion: D2 to dist
</h2><span id='topic+D2toDist'></span>

<h3>Description</h3>

<p>Converts <code>D2</code> class object into <code>dist</code> class object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  D2toDist(D2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D2toDist_+3A_d2">D2</code></td>
<td>

<p><code>D2</code> object. Squared distances matrix between individuals.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>dist</code>. See function <code><a href="stats.html#topic+dist">dist</a></code> for 
details.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GtoD2">GtoD2</a></code><br />
<code><a href="#topic+D2toG">D2toG</a></code><br /> 
<code><a href="#topic+disttoD2">disttoD2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- matrix(rnorm(100*3),nrow=100)
distance &lt;- daisy(X,"manhattan")
D2 &lt;- disttoD2(distance)
distance2 &lt;- D2toDist(D2)

</code></pre>

<hr>
<h2 id='D2toG'>
Distance conversion: D2 to G
</h2><span id='topic+D2toG'></span>

<h3>Description</h3>

<p>Converts <code>D2</code> class object into <code>Gram</code> class object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  D2toG(D2,weights)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D2toG_+3A_d2">D2</code></td>
<td>

<p><code>D2</code> object. Squared distances matrix between individuals.  
</p>
</td></tr>
<tr><td><code id="D2toG_+3A_weights">weights</code></td>
<td>

<p>an optional numeric vector of weights. By default all individuals 
have the same weight.  
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>Gram</code> containing the Doubly centered 
inner product matrix of <code>D2</code>.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GtoD2">GtoD2</a></code><br /> 
<code><a href="#topic+disttoD2">disttoD2</a></code><br />
<code><a href="#topic+D2toDist">D2toDist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- matrix(rnorm(100*3),nrow=100)
D2 &lt;- as.matrix(dist(X)^2)
class(D2) &lt;- "D2"
G &lt;- D2toG(D2,weights=NULL)

</code></pre>

<hr>
<h2 id='dbglm'>
Distance-based generalized linear models                                                                 
</h2><span id='topic+dbglm'></span><span id='topic+dbglm.formula'></span><span id='topic+dbglm.dist'></span><span id='topic+dbglm.D2'></span><span id='topic+dbglm.Gram'></span><span id='topic+print.dbglm'></span>

<h3>Description</h3>

<p><code>dbglm</code> is a variety of generalized linear model where explanatory 
information is coded as distances between individuals. These distances 
can either be computed from observed explanatory variables or directly 
input as a squared distances matrix. 
</p>
<p>Response and link function as in the <code>glm</code> function for ordinary 
generalized linear models.
</p>
<p>Notation convention: in distance-based methods we must distinguish 
<em>observed explanatory variables</em> which we denote by Z or z, from 
<em>Euclidean coordinates</em> which we denote by X or x. For explanation
on the meaning of both terms see the bibliography references below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'formula'
dbglm(formula, data, family=gaussian, method ="GCV", full.search=TRUE,...,
        metric="euclidean", weights, maxiter=100, eps1=1e-10,
        eps2=1e-10, rel.gvar=0.95, eff.rank=NULL, offset, mustart=NULL, range.eff.rank) 
   
## S3 method for class 'dist'
dbglm(distance,y,family=gaussian, method ="GCV", full.search=TRUE, weights,
        maxiter=100,eps1=1e-10,eps2=1e-10,rel.gvar=0.95,eff.rank=NULL,
        offset,mustart=NULL, range.eff.rank,...)
                
## S3 method for class 'D2'
dbglm(D2,y,...,family=gaussian, method ="GCV", full.search=TRUE, weights,maxiter=100,
        eps1=1e-10,eps2=1e-10,rel.gvar=0.95,eff.rank=NULL,offset,
        mustart=NULL, range.eff.rank)

## S3 method for class 'Gram'
dbglm(G,y,...,family=gaussian, method ="GCV", full.search=TRUE, weights,maxiter=100,
        eps1=1e-10,eps2=1e-10,rel.gvar=0.95,eff.rank=NULL,
        offset,mustart=NULL, range.eff.rank)              
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbglm_+3A_formula">formula</code></td>
<td>

<p>an object of class <code><a href="stats.html#topic+formula">formula</a></code>. A formula of the form <code>y~Z</code>.
This argument is a remnant of the <code><a href="stats.html#topic+glm">glm</a></code> function, 
kept for compatibility.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in the model 
(both response and explanatory variables, either
the observed ones, Z, or a Euclidean configuration X). 	  
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_y">y</code></td>
<td>

<p>(required if no formula is given as the principal argument). 
Response (dependent variable) must be numeric, factor, matrix or data.frame.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_distance">distance</code></td>
<td>

<p>a <code>dist</code> or <code>dissimilarity</code> class object. See functions
<code><a href="stats.html#topic+dist">dist</a></code> in the package <code>stats</code> and <code><a href="cluster.html#topic+daisy">daisy</a></code> 
in the package <code>cluster</code>.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_d2">D2</code></td>
<td>

<p>a <code>D2</code> class object.  Squared distances matrix between individuals.  
See the Details section in <code><a href="#topic+dblm">dblm</a></code> to learn the usage.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_g">G</code></td>
<td>

<p>a <code>Gram</code> class object. Doubly centered inner product matrix of the 
squared distances matrix <code>D2</code>. See details in <code><a href="#topic+dblm">dblm</a></code>.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_family">family</code></td>
<td>

<p>a description of the error distribution and link function to be used 
in the model. 
This can be a character string naming a family function, a family 
function or the result of a call to a family function. 
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_metric">metric</code></td>
<td>

<p>metric function to be used when computing distances from observed 
explanatory variables. 
One of <code>"euclidean"</code> (the default), <code>"manhattan"</code>, 
or <code>"gower"</code>. 
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_weights">weights</code></td>
<td>

<p>an optional numeric vector of prior weights to be used in the 
fitting process. 
By default all individuals have the same weight.  
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_method">method</code></td>
<td>

<p>sets the method to be used in deciding the <em>effective rank</em>, 
which is defined as the number of linearly independent Euclidean 
coordinates used in prediction. 
There are five different methods: <code>"AIC"</code>, <code>"BIC"</code>, 
<code>"GCV"</code>(default), <code>"eff.rank"</code> and 
<code>"rel.gvar"</code>.
<code>GCV</code> take the effective rank minimizing 
a cross-validatory quantity. 
<code>AIC</code> and <code>BIC</code> take the effective rank minimizing,
respectively, the Akaike or Bayesian Information Criterion 
(see <code><a href="stats.html#topic+AIC">AIC</a></code> for more details). 
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_full.search">full.search</code></td>
<td>
<p>sets which optimization procedure will be used to
minimize the modelling criterion specified in <code>method</code>.
Needs to be specified only if <code>method</code> is <code>"AIC"</code>, 
<code>"BIC"</code> or <code>"GCV"</code>. 
If <code>full.search=TRUE</code>, <em>effective rank</em> is set to its
global best value, after evaluating the criterion for all possible ranks.
Potentially too computationally expensive.
If <code>full.search=FALSE</code>, the <code><a href="stats.html#topic+optimize">optimize</a></code> function 
is called. Then computation time is shorter, but the result may be 
found a local minimum. 
</p>
</td></tr>  
<tr><td><code id="dbglm_+3A_maxiter">maxiter</code></td>
<td>

<p>maximum number of iterations in the iterated <code>dblm</code> algorithm. 
(Default = 100) 
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_eps1">eps1</code></td>
<td>

<p>stopping criterion 1, <code>"DevStat"</code>: convergence tolerance <code>eps1</code>, 
a positive (small) number; 
the iterations converge when <code>|dev - dev_{old}|/(|dev|) &lt; eps1</code>.
Stationarity of deviance has been attained.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_eps2">eps2</code></td>
<td>

<p>stopping criterion 2, <code>"mustat"</code>: convergence tolerance <code>eps2</code>,
a positive (small) number; 
the iterations converge when <code>|mu - mu_{old}|/(|mu|) &lt; eps2</code>.
Stationarity of fitted.values <code>mu</code> has been attained.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_rel.gvar">rel.gvar</code></td>
<td>

<p>relative geometric variability (a real number between 0 and 1). 
In each <code>dblm</code> iteration, take the lowest effective rank, with 
a relative geometric variability higher or equal to <code>rel.gvar</code>. 
Default value (<code>rel.gvar=0.95</code>) uses the 95% of the total
variability.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_eff.rank">eff.rank</code></td>
<td>

<p>integer between 1 and the number of observations minus one. 
Number of Euclidean coordinates used for model fitting in
each <code>dblm</code> iteration. If specified its value overrides
<code>rel.gvar</code>. When <code>eff.rank=NULL</code> (default), 
calls to <code>dblm</code> are made with <code>method=rel.gvar</code>.  
</p>
</td></tr>  
<tr><td><code id="dbglm_+3A_offset">offset</code></td>
<td>

<p>this can be used to specify an a priori known component to be included
in the linear predictor during fitting. This should be NULL or 
a numeric vector of length equal to the number of cases.
</p>
</td></tr>
<tr><td><code id="dbglm_+3A_mustart">mustart</code></td>
<td>

<p>starting values for the vector of means.  
</p>
</td></tr>              
<tr><td><code id="dbglm_+3A_range.eff.rank">range.eff.rank</code></td>
<td>

<p>vector of size two defining the range of values for the effective rank with which the dblm iterations
will be evaluated (must be specified when <code>method</code> is <code>"AIC"</code>, <code>"BIC"</code> or <code>"GCV"</code>). The range should 
be restrict between <code>c(1,n-1)</code>.   
</p>
</td></tr>      
<tr><td><code id="dbglm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Details</h3>

   
<p>The various possible ways for inputting the model explanatory 
information through distances, or their squares, etc., are the 
same as in <code><a href="#topic+dblm">dblm</a></code>. 
</p>
<p>For gamma distributions, the domain of the canonical link function 
is not the same as the permitted range of the mean. In particular, 
the linear predictor might be negative, obtaining an impossible 
negative mean. Should that event occur, <code>dbglm</code> stops with
an error message. Proposed alternative is to use a non-canonical link 
function.
</p>


<h3>Value</h3>

<p>A list of class <code>dbglm</code> containing the following components: 
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>the <code>working</code> residuals, that is the <code>dblm</code>
residuals in the last iteration of <code>dblm</code> fit.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values, results of final <code>dblm</code> 
iteration.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the <code><a href="stats.html#topic+family">family</a></code> object used. </p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>measure of discrepancy or badness of fit. Proportional to 
twice the difference between the maximum achievable log-likelihood and
that achieved by the current model.</p>
</td></tr>
<tr><td><code>aic.model</code></td>
<td>
<p>a version of Akaike's Information Criterion. Equal to minus
twice the maximized log-likelihood plus twice the number of
parameters. Computed by the aic component of the family. 
For binomial and Poison families the dispersion is fixed at
one and the number of parameters is the number of coefficients. 
For gaussian, Gamma and inverse gaussian families the dispersion is 
estimated from the residual deviance, and the number of parameters is 
the number of coefficients plus one. For a gaussian family the MLE 
of the dispersion is used so this is a valid value of AIC, but for
Gamma and inverse gaussian families it is not. For families fitted by 
quasi-likelihood the value is NA. </p>
</td></tr>
<tr><td><code>bic.model</code></td>
<td>
<p>a version of the Bayessian Information Criterion. Equal to 
minus twice the maximized log-likelihood plus the logarithm of the 
number of observations by the number of parameters (see, e.g.,
Wood 2006).</p>
</td></tr>
<tr><td><code>gcv.model</code></td>
<td>
<p>a version of the Generalized Cross-Validation Criterion. We
refer to Wood (2006) pp. 177-178 for details.</p>
</td></tr>
<tr><td><code>null.deviance</code></td>
<td>
<p>the deviance for the null model. The null model will 
include the offset, and an intercept if there is one in the model. 
Note that this will be incorrect if the link function depends on 
the data other than through the fitted mean: specify a zero offset 
to force a correct calculation.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of Fisher scoring (<code>dblm</code>) iterations.</p>
</td></tr>
<tr><td><code>prior.weights</code></td>
<td>
<p>the original weights.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the <code>working</code> weights, that are the weights in the 
last iteration of <code>dblm</code> fit.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>df.null</code></td>
<td>
<p> 	the residual degrees of freedom for the null model.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p> the response vector used.</p>
</td></tr>
<tr><td><code>convcrit</code></td>
<td>
<p>convergence criterion. One of: <code>"DevStat"</code> 
(stopping criterion 1), <code>"muStat"</code> (stopping criterion 2), 
<code>"maxiter"</code> (maximum allowed number of iterations 
has been exceeded).</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>hat matrix projector of the last <code>dblm</code> iteration.</p>
</td></tr>
<tr><td><code>rel.gvar</code></td>
<td>
<p>the relative geometric variabiliy in the last <code>dblm</code> iteration.</p>
</td></tr>
<tr><td><code>eff.rank</code></td>
<td>
<p>the <code>working</code> effective rank, that is the <code>eff.rank</code>
in the last <code>dblm</code> iteration.</p>
</td></tr>
<tr><td><code>varmu</code></td>
<td>
<p>vector of estimated variance of each observation.</p>
</td></tr>
<tr><td><code>dev.resids</code></td>
<td>
<p>deviance residuals</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr> 
</table>
<p>Objects of class <code>"dbglm"</code> are actually of class 
<code>c("dbglm", "dblm")</code>, inheriting the <code><a href="#topic+plot.dblm">plot.dblm</a></code> method
from class <code>"dblm"</code>.
</p>


<h3>Note</h3>

<p>When the Euclidean distance is used the <code>dbglm</code> model reduces 
to the generalized linear  model (<code>glm</code>).  
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

       
<p>Boj E, Caballe, A., Delicado P, Esteve, A., Fortiana J (2016). <em>Global and local distance-based generalized linear models</em>.
TEST 25, 170-195.
</p>
<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>
<p>Wood SN (2006). <em>Generalized Additive Models: An Introduction with R</em>. Chapman &amp; Hall,
Boca Raton.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.dbglm">summary.dbglm</a></code> for summary.<br />
<code><a href="#topic+plot.dbglm">plot.dbglm</a></code> for plots.<br />
<code><a href="#topic+predict.dbglm">predict.dbglm</a></code> for predictions.<br />
<code><a href="#topic+dblm">dblm</a></code> for distance-based linear models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## CASE POISSON
z &lt;- rnorm(100)
y &lt;- rpois(100, exp(1+z))
glm1 &lt;- glm(y ~z, family = poisson(link = "log"))
D2 &lt;- as.matrix(dist(z))^2
class(D2) &lt;- "D2"
dbglm1 &lt;- dbglm(D2,y,family = poisson(link = "log"), method="rel.gvar")

plot(z,y)
points(z,glm1$fitted.values,col=2)
points(z,dbglm1$fitted.values,col=3)
sum((glm1$fitted.values-y)^2)
sum((dbglm1$fitted.values-y)^2)

## CASE BINOMIAL
y &lt;- rbinom(100, 1, plogis(z))
# needs to set a starting value for the next fit
glm2 &lt;- glm(y ~z, family = binomial(link = "logit"))
D2 &lt;- as.matrix(dist(z))^2
class(D2) &lt;- "D2"
dbglm2 &lt;- dbglm(D2,y,family = binomial(link = "logit"), method="rel.gvar")

plot(z,y)
points(z,glm2$fitted.values,col=2)
points(z,dbglm2$fitted.values,col=3)
sum((glm2$fitted.values-y)^2)
sum((dbglm2$fitted.values-y)^2)
</code></pre>

<hr>
<h2 id='dbglm-inl'>Internal functions</h2><span id='topic+dbglm-internal'></span><span id='topic+control_family'></span><span id='topic+controls_dbglm'></span><span id='topic+dbglm_iteration'></span>

<h3>Description</h3>

<p>Internal functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>control_family(family)
controls_dbglm(distance,weights,offset,rel.gvar,maxiter,eps1,eps2,y, method)
dbglm_iteration(y, mu, weights, nobs, eta, Delta, method, offset, n, 
    eff.rank = NULL, rel.gvar, dev.resids, aic, mu.eta, valideta, validmu,
    family, variance, linkinv, problem.links, eps1,eps2,maxiter)
</code></pre>


<h3>Details</h3>

<p>Not to be called by users</p>

<hr>
<h2 id='dblm'>
Distance-based linear model
</h2><span id='topic+dblm'></span><span id='topic+dblm.formula'></span><span id='topic+dblm.dist'></span><span id='topic+dblm.D2'></span><span id='topic+dblm.Gram'></span><span id='topic+print.dblm'></span>

<h3>Description</h3>

<p><code>dblm</code> is a variety of linear model where explanatory information 
is coded as distances between individuals. These distances can either 
be computed from observed explanatory variables or directly input as 
a squared distances matrix. The response is a continuous variable as 
in the ordinary linear model. Since distances can be computed from a mixture 
of continuous and qualitative explanatory variables or, 
in fact, from more general quantities, <code>dblm</code> is a proper extension of 
<code>lm</code>.
</p>
<p>Notation convention: in distance-based methods we must distinguish 
<em>observed explanatory variables</em> which we denote by Z or z, from 
<em>Euclidean coordinates</em> which we denote by X or x. For explanation
on the meaning of both terms see the bibliography references below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'formula'
dblm(formula,data,...,metric="euclidean",method="OCV",full.search=TRUE,
        weights,rel.gvar=0.95,eff.rank)

## S3 method for class 'dist'
dblm(distance,y,...,method="OCV",full.search=TRUE,
        weights,rel.gvar=0.95,eff.rank)

## S3 method for class 'D2'
dblm(D2,y,...,method="OCV",full.search=TRUE,weights,rel.gvar=0.95,
        eff.rank)
              
## S3 method for class 'Gram'
dblm(G,y,...,method="OCV",full.search=TRUE,weights,rel.gvar=0.95,
        eff.rank)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dblm_+3A_formula">formula</code></td>
<td>

<p>an object of class <code><a href="stats.html#topic+formula">formula</a></code>. A formula of the form <code>y~Z</code>.
This argument is a remnant of the <code><a href="stats.html#topic+lm">lm</a></code> function, 
kept for compatibility. 
</p>
</td></tr>
<tr><td><code id="dblm_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in the model 
(both response and explanatory variables, either
the observed ones, Z, or a Euclidean configuration X).  
</p>
</td></tr>
<tr><td><code id="dblm_+3A_y">y</code></td>
<td>

<p>(required if no formula is given as the principal argument). 
Response (dependent variable) must be numeric, matrix or data.frame.
</p>
</td></tr>
<tr><td><code id="dblm_+3A_distance">distance</code></td>
<td>

<p>a <code>dist</code> or <code>dissimilarity</code> class object. See functions
<code><a href="stats.html#topic+dist">dist</a></code> in the package <code>stats</code> and <code><a href="cluster.html#topic+daisy">daisy</a></code> 
in the package <code>cluster</code>.
</p>
</td></tr>
<tr><td><code id="dblm_+3A_d2">D2</code></td>
<td>

<p>a <code>D2</code> class object. Squared distances matrix between individuals.  
</p>
</td></tr>
<tr><td><code id="dblm_+3A_g">G</code></td>
<td>

<p>a <code>Gram</code> class object. Doubly centered inner product matrix  of the 
squared distances matrix <code>D2</code>. 
</p>
</td></tr>
<tr><td><code id="dblm_+3A_metric">metric</code></td>
<td>

<p>metric function to be used when computing distances from observed 
explanatory variables. 
One of <code>"euclidean"</code> (default), <code>"manhattan"</code>, 
or <code>"gower"</code>. 
</p>
</td></tr>
<tr><td><code id="dblm_+3A_method">method</code></td>
<td>

<p>sets the method to be used in deciding the <em>effective rank</em>, 
which is defined as the number of linearly independent Euclidean 
coordinates used in prediction. 
There are six different methods: <code>"AIC"</code>, <code>"BIC"</code>, 
<code>"OCV"</code> (default), <code>"GCV"</code>, <code>"eff.rank"</code> and 
<code>"rel.gvar"</code>.
<code>OCV</code> and <code>GCV</code> take the effective rank minimizing 
a cross-validatory quantity (either <code>ocv</code> or <code>gcv</code>). 
<code>AIC</code> and <code>BIC</code> take the effective rank minimizing,
respectively, the Akaike or Bayesian Information Criterion 
(see <code><a href="stats.html#topic+AIC">AIC</a></code> for more details). 
The optimizacion procedure to be used in the above four methods
can be set with the <code>full.search</code> optional parameter.
</p>
<p>When method is <code>eff.rank</code>, the effective rank is explicitly
set by the user through the <code>eff.rank</code> optional parameter 
which, in this case,   becomes mandatory.
</p>
<p>When method is <code>rel.gvar</code>, the fraction of the data 
<em>geometric variability</em> for model fitting is explicitly
set by the user through the <code>rel.gvar</code> optional parameter which, 
in this case,  becomes mandatory.
</p>
</td></tr>
<tr><td><code id="dblm_+3A_full.search">full.search</code></td>
<td>
<p>sets which optimization procedure will be used to
minimize the modelling criterion specified in <code>method</code>.
Needs to be specified only if <code>method</code> is <code>"AIC"</code>, 
<code>"BIC"</code>, <code>"OCV"</code> or <code>"GCV"</code>. 
If <code>full.search=TRUE</code>, <em>effective rank</em> is set to its
global best value, after evaluating the criterion for all possible ranks.
Potentially too computationally expensive.
If <code>full.search=FALSE</code>, the <code><a href="stats.html#topic+optimize">optimize</a></code> function 
is called. Then computation time is shorter, but the result may be 
found a local minimum. 
</p>
</td></tr>  
<tr><td><code id="dblm_+3A_weights">weights</code></td>
<td>

<p>an optional numeric vector of weights to be used in the fitting process. 
By default all individuals have the same weight.  
</p>
</td></tr>
<tr><td><code id="dblm_+3A_rel.gvar">rel.gvar</code></td>
<td>

<p>relative geometric variability (real between 0 and 1). Take the 
lowest effective rank with a relative geometric variability higher 
or equal to <code>rel.gvar</code>. Default value (<code>rel.gvar=0.95</code>) 
uses a 95% of the total variability.
Applies only <code>rel.gvar</code> if <code>method="rel.gvar"</code>.
</p>
</td></tr>
<tr><td><code id="dblm_+3A_eff.rank">eff.rank</code></td>
<td>

<p>integer between 1 and the number of observations minus one. 
Number of Euclidean coordinates used for model fitting. Applies only  
if <code>method="eff.rank"</code>.  
</p>
</td></tr>
<tr><td><code id="dblm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>dblm</code> model uses the distance matrix between individuals 
to find an appropriate prediction method. 
There are many ways to compute and calculate this matrix, besides
the three included as parameters in this function. 
Several packages in R also study this problem. In particular 
<code><a href="stats.html#topic+dist">dist</a></code> in the package <code>stats</code> and <code><a href="cluster.html#topic+daisy">daisy</a></code>
in the package	<code>cluster</code> (the three metrics in <code>dblm</code> call
the <code>daisy</code> function).
</p>
<p>Another way to enter a distance matrix to the model is through an object 
of class <code>"D2"</code> (containing the squared distances matrix).
An object of class <code>"dist"</code> or <code>"dissimilarity"</code> can 
easily be transformed into one of class <code>"D2"</code>. See <code><a href="#topic+disttoD2">disttoD2</a></code>.
Reciprocally, an object of class <code>"D2"</code> can be transformed into one 
of class <code>"dist"</code>. See <code><a href="#topic+D2toDist">D2toDist</a></code>.
</p>
<p>S3 method Gram uses the Doubly centered inner product matrix G=XX'.
Its also easily to transformed into one of class <code>"D2"</code>. 
See <code><a href="#topic+D2toG">D2toG</a></code> and <code><a href="#topic+GtoD2">GtoD2</a></code>.
</p>
<p>The weights array is adequate when responses for different individuals
have different variances. In this case the weights array should be 
(proportional to) the reciprocal of the variances vector.  
</p>
<p>When using method <code>method="eff.rank"</code> or <code>method="rel.gvar"</code>,
a compromise between possible consequences of a bad choice has to be 
reached. If the rank is too large, the model can be overfitted, possibly 
leading to an increased prediction error for new cases 
(even though R2 is higher). On the other hand, a small rank suggests  
a model inadequacy (R2 is small).  The other four methods are less error 
prone (but still they do not guarantee good predictions). 
</p>


<h3>Value</h3>

<p>A list of class <code>dblm</code> containing the following components: 
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals (response minus fitted values).</p>
</td></tr> 
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values.</p>
</td></tr>
<tr><td><code>df.residuals</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the specified weights.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response used to fit the model.</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>the hat matrix projector.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr> 
<tr><td><code>rel.gvar</code></td>
<td>
<p>the relative geometric variabiliy, used to fit the model.</p>
</td></tr>
<tr><td><code>eff.rank</code></td>
<td>
<p>the dimensions chosen to estimate the model.</p>
</td></tr>
<tr><td><code>ocv</code></td>
<td>
<p>the ordinary cross-validation estimate of the prediction error.</p>
</td></tr>
<tr><td><code>gcv</code></td>
<td>
<p>the generalized cross-validation estimate of the prediction error.</p>
</td></tr> 
<tr><td><code>aic</code></td>
<td>
<p>the Akaike Value Criterium of the model (only if <code>method="AIC"</code>).</p>
</td></tr> 
<tr><td><code>bic</code></td>
<td>
<p>the Bayesian Value Criterium of the model (only if <code>method="BIC"</code>).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>When the Euclidean distance is used the <code>dblm</code> model reduces to the linear 
model (<code>lm</code>). 
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Caballe, A., Delicado P, Esteve, A., Fortiana J (2016). <em>Global and local distance-based generalized linear models</em>.
TEST 25, 170-195.
</p>
<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.dblm">summary.dblm</a></code> for summary.<br />
<code><a href="#topic+plot.dblm">plot.dblm</a></code> for plots.<br />
<code><a href="#topic+predict.dblm">predict.dblm</a></code> for predictions.<br />
<code><a href="#topic+ldblm">ldblm</a></code> for distance-based local linear models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># easy example to illustrate usage of the dblm function
n &lt;- 100
p &lt;- 3
k &lt;- 5

Z &lt;- matrix(rnorm(n*p),nrow=n)
b &lt;- matrix(runif(p)*k,nrow=p)
s &lt;- 1
e &lt;- rnorm(n)*s
y &lt;- Z%*%b + e

D&lt;-dist(Z)

dblm1 &lt;- dblm(D,y)
lm1 &lt;- lm(y~Z)
# the same fitted values with the lm
mean(lm1$fitted.values-dblm1$fitted.values)

</code></pre>

<hr>
<h2 id='dblm-inl'>Internal  functions</h2><span id='topic+dblm-internal'></span><span id='topic+Gcalc'></span><span id='topic+HwProject'></span><span id='topic+Hwyhat'></span><span id='topic+control_method'></span><span id='topic+control_metric'></span><span id='topic+controls_dblm'></span><span id='topic+formula_to_zy'></span>

<h3>Description</h3>

<p>Internal  functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>Gcalc(n,weights,Delta)
HwProject(G,Dsqw,rk,epsilon,cvyes=FALSE,n)
Hwyhat(G,n,Dsqw,weights,rk,epsilon,y,y0,cvyes=FALSE,ori_weights,...)
control_method(method,class_call)
control_metric(metric)
controls_dblm(G,weights,eff.rank,rel.gvar,method,y)
formula_to_zy(formula,data,mf,class_mod,metric)
</code></pre>


<h3>Details</h3>

<p>Not to be called by users</p>

<hr>
<h2 id='dbplsr'>
Distance-based partial least squares regression
</h2><span id='topic+dbplsr'></span><span id='topic+dbplsr.formula'></span><span id='topic+dbplsr.dist'></span><span id='topic+dbplsr.D2'></span><span id='topic+dbplsr.Gram'></span><span id='topic+print.dbplsr'></span>

<h3>Description</h3>

<p><code>dbplsr</code> is a variety of partial least squares regression 
where explanatory information is coded as distances between individuals.
These distances can either be computed from observed explanatory variables
or directly input as a squared distances matrix. 
</p>
<p>Since distances can be computed from a mixture of continuous and 
qualitative explanatory variables or, in fact, from more general 
quantities, <code>dbplsr</code> is a proper extension of <code>plsr</code>.
</p>
<p>Notation convention: in distance-based methods we must distinguish 
<em>observed explanatory variables</em> which we denote by Z or z, from 
<em>Euclidean coordinates</em> which we denote by X or x. For explanation
on the meaning of both terms see the bibliography references below. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'formula'
dbplsr(formula,data,...,metric="euclidean",
        method="ncomp",weights,ncomp) 

## S3 method for class 'dist'
dbplsr(distance,y,...,weights,ncomp=ncomp,method="ncomp")

## S3 method for class 'D2'
dbplsr(D2,y,...,weights,ncomp=ncomp,method="ncomp")

## S3 method for class 'Gram'
dbplsr(G,y,...,weights,ncomp=ncomp,method="ncomp")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbplsr_+3A_formula">formula</code></td>
<td>

<p>an object of class <code><a href="stats.html#topic+formula">formula</a></code>. A formula of the form <code>y~Z</code>.
This argument is a remnant of the <code><a href="pls.html#topic+plsr">plsr</a></code> function, 
kept for compatibility. 
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in the model 
(both response and explanatory variables, either
the observed ones, Z, or a Euclidean configuration X).  
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_y">y</code></td>
<td>

<p>(required if no formula is given as the principal argument). 
Response (dependent variable) must be numeric, matrix or data.frame.
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_distance">distance</code></td>
<td>

<p>a <code>dist</code> or <code>dissimilarity</code> class object. See functions
<code><a href="stats.html#topic+dist">dist</a></code> in the package <code>stats</code> and <code><a href="cluster.html#topic+daisy">daisy</a></code> 
in the package <code>cluster</code>.
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_d2">D2</code></td>
<td>

<p>a <code>D2</code> class object. Squared distances matrix between individuals.  
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_g">G</code></td>
<td>

<p>a <code>Gram</code> class object. Weighted centered inner products matrix of the 
squared distances matrix <code>D2</code>. 
See details in <code><a href="#topic+dblm">dblm</a></code>.
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_metric">metric</code></td>
<td>

<p>metric function to be used when computing distances from observed 
explanatory variables. 
One of <code>"euclidean"</code> (default), <code>"manhattan"</code>, 
or <code>"gower"</code>. 
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_method">method</code></td>
<td>

<p>sets the method to be used in deciding how many components needed to fit
the best model for new predictions.
There are five different methods, <code>"AIC"</code>, <code>"BIC"</code>, <code>"OCV"</code>, 
<code>"GCV"</code> and <code>"ncomp"</code> (default).
<code>OCV</code> and <code>GCV</code> find the number of components that minimizes 
the Cross-validation coefficient (<code>ocv</code> or <code>gcv</code>). 
<code>AIC</code> and <code>BIC</code> find the number of components that minimizes 
the Akaike or Bayesian Information Criterion (see <code><a href="stats.html#topic+AIC">AIC</a></code> 
for more details).  
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_weights">weights</code></td>
<td>

<p>an optional numeric vector of weights to be used in the fitting process. 
By default all individuals have the same weight.  
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_ncomp">ncomp</code></td>
<td>
 
<p>the number of components to include in the model.
</p>
</td></tr>
<tr><td><code id="dbplsr_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Partial least squares (PLS) is a method for constructing
predictive models when the factors (Z) are many and highly collinear. 
A PLS model will try to find the multidimensional direction
in the Z space that explains the maximum multidimensional variance direction 
in the Y space. <code>dbplsr</code> is particularly suited when the matrix of 
predictors has more variables than observations. 
By contrast, standard regression (<code>dblm</code>) will fail in these cases.
</p>
<p>The various possible ways for inputting the model explanatory 
information through distances, or their squares, etc., are the 
same as in <code><a href="#topic+dblm">dblm</a></code>. 
</p>
<p>The number of components to fit is specified with the argument <code>ncomp</code>.  
</p>


<h3>Value</h3>

<p>A list of class <code>dbplsr</code> containing the following components: 
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>a list containing the residuals (response minus fitted values)
for each iteration.</p>
</td></tr>   
<tr><td><code>fitted.values</code></td>
<td>
<p>a list containing the fitted values for each iteration.</p>
</td></tr>
<tr><td><code>fk</code></td>
<td>
<p>a list containing the scores for each iteration.</p>
</td></tr> 
<tr><td><code>bk</code></td>
<td>
<p>regression coefficients. <code>fitted.values = fk*bk</code> </p>
</td></tr>
<tr><td><code>Pk</code></td>
<td>
<p>orthogonal projector on the one-dimensional linear space by <code>fk</code>.</p>
</td></tr> 
<tr><td><code>ncomp</code></td>
<td>
<p>number of components included in the model.</p>
</td></tr>  
<tr><td><code>ncomp.opt</code></td>
<td>
<p>optimum number of components according to the selected method.</p>
</td></tr>  
<tr><td><code>weights</code></td>
<td>
<p>the specified weights.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the using method.</p>
</td></tr> 
<tr><td><code>y</code></td>
<td>
<p>the response used to fit the model.</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>the hat matrix projector.</p>
</td></tr>
<tr><td><code>G0</code></td>
<td>
<p>initial weighted centered inner products matrix of the squared 
distance matrix.</p>
</td></tr>  
<tr><td><code>Gk</code></td>
<td>
<p>weighted centered inner products matrix in last iteration.</p>
</td></tr>   
<tr><td><code>gvar</code></td>
<td>
<p>total weighted geometric variability.</p>
</td></tr>   
<tr><td><code>gvec</code></td>
<td>
<p>the diagonal entries in <code>G0</code>.</p>
</td></tr>
<tr><td><code>gvar.iter</code></td>
<td>
<p> geometric variability for each iteration.</p>
</td></tr>
<tr><td><code>ocv</code></td>
<td>
<p>the ordinary cross-validation estimate of the prediction error.</p>
</td></tr>
<tr><td><code>gcv</code></td>
<td>
<p>the generalized cross-validation estimate of the prediction error.</p>
</td></tr> 
<tr><td><code>aic</code></td>
<td>
<p>the Akaike Value Criterium of the model.</p>
</td></tr> 
<tr><td><code>bic</code></td>
<td>
<p>the Bayesian Value Criterium of the model.</p>
</td></tr>               
</table>


<h3>Note</h3>

<p>When the Euclidean distance is used the <code>dbplsr</code> model reduces to the 
traditional partial least squares (<code>plsr</code>). 
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Implementing PLS for distance-based regression: 
computational issues</em>.
<em>Computational Statistics</em> 22, 237-248.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.dbplsr">summary.dbplsr</a></code> for summary.<br />
<code><a href="#topic+plot.dbplsr">plot.dbplsr</a></code> for plots.<br />
<code><a href="#topic+predict.dbplsr">predict.dbplsr</a></code> for predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#require(pls)
library(pls)
data(yarn)
## Default methods:
yarn.dbplsr &lt;- dbplsr(density ~ NIR, data = yarn, ncomp=6, method="GCV")


</code></pre>

<hr>
<h2 id='dbplsr-inl'>Internal  functions</h2><span id='topic+dbplsr-internal'></span><span id='topic+Gproduct'></span><span id='topic+controls_dbplsr'></span>

<h3>Description</h3>

<p>Internal  functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Gproduct(f,Dw,G0)
  controls_dbplsr(distance,weights,ncomp,y)
</code></pre>


<h3>Details</h3>

<p>Not to be called by users</p>

<hr>
<h2 id='dbstats-package'>
Distance-based statistics (dbstats)
</h2><span id='topic+dbstats-package'></span><span id='topic+dbstats'></span>

<h3>Description</h3>

<p>This package contains functions for distance-based prediction methods. 
</p>
<p>These are methods for prediction where predictor information is coded
as a matrix of distances between individuals. 
</p>
<p>In the currently implemented methods the response is a univariate variable
as in the ordinary linear model or in the generalized linear model.
</p>
<p>Distances can either be directly input as an distances matrix,
a squared distances matrix, an inner-products matrix 
(see <code><a href="#topic+GtoD2">GtoD2</a></code>) or computed from observed 
explanatory variables. 
</p>
<p>Notation convention: in distance-based methods we must distinguish 
<em>observed explanatory variables</em> which we denote by Z or z, from 
<em>Euclidean coordinates</em> which we denote by X or x. For explanation
on the meaning of both terms see the bibliography references below.
</p>
<p>Observed explanatory variables z are possibly a mixture of continuous and 
qualitative explanatory variables or more general quantities.
</p>
<p><span class="pkg">dbstats</span> does not provide specific functions for computing distances,
depending instead on other functions and packages, such as:
</p>

<ul>
<li> <p><code><a href="stats.html#topic+dist">dist</a></code> in the <span class="pkg">stats</span> package.
</p>
</li>
<li> <p><code><a href="proxy.html#topic+dist">dist</a></code> in the <span class="pkg">proxy</span> package. When the 
<span class="pkg">proxy</span> package is loaded, its <code><a href="proxy.html#topic+dist">dist</a></code> function 
supersedes the one in the <span class="pkg">stats</span> package.
</p>
</li>
<li> <p><code><a href="cluster.html#topic+daisy">daisy</a></code> in the <span class="pkg">cluster</span> package. 
Compared to both instances of <code><a href="stats.html#topic+dist">dist</a></code> above whose input must be 
numeric variables, the main feature of <code><a href="cluster.html#topic+daisy">daisy</a></code> is 
its ability to handle other variable types as well (e.g. nominal, ordinal, 
(a)symmetric binary) even when different types occur in the same data set.
</p>
<p>Actually the last statement is not hundred percent true: it refers only to
the default behaviour of both <code><a href="stats.html#topic+dist">dist</a></code> functions, whereas the 
<code><a href="proxy.html#topic+dist">dist</a></code> function in the <span class="pkg">proxy</span> package can 
evaluate distances between observations with a user-provided function, 
entered as a parameter, hence it can deal with any type of data. See the
examples in <code><a href="proxy.html#topic+pr_DB">pr_DB</a></code>.
</p>
</li></ul>

<p>Functions of <span class="pkg">dbstats</span> package:  <br />
</p>
<p>Linear and local linear models with a continuous response: 
</p>

<ul>
<li> <p><code><a href="#topic+dblm">dblm</a></code> for distance-based linear models.
</p>
</li>
<li> <p><code><a href="#topic+ldblm">ldblm</a></code> for local distance-based linear models.
</p>
</li>
<li> <p><code><a href="#topic+dbplsr">dbplsr</a></code> for distance-based partial least squares.   <br />
</p>
</li></ul>

<p>Generalized linear and local generalized linear models with a numeric response:
</p>

<ul>
<li> <p><code><a href="#topic+dbglm">dbglm</a></code> for distance-based generalized linear models.
</p>
</li>
<li> <p><code><a href="#topic+ldbglm">ldbglm</a></code> for local distance-based generalized linear models.  
</p>
</li></ul>



<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> dbstats</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.0.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-01-26</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> 	GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">     
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;, Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Caballe, A., Delicado P, Esteve, A., Fortiana J (2016). <em>Global and local distance-based generalized linear models</em>.
TEST 25, 170-195.
</p>
<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Implementing PLS for distance-based regression: 
computational issues</em>.
<em>Computational Statistics</em> 22, 237-248.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>

<hr>
<h2 id='disttoD2'>
Distance conversion: dist to D2
</h2><span id='topic+disttoD2'></span>

<h3>Description</h3>

<p>Converts <code>dist</code> or <code>dissimilarity</code> class object into <code>D2</code> class object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  disttoD2(distance)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disttoD2_+3A_distance">distance</code></td>
<td>

<p><code>dist</code> or <code>dissimilarity</code> class object. See functions
<code><a href="stats.html#topic+dist">dist</a></code> in the package <code>stats</code> and <code><a href="cluster.html#topic+daisy">daisy</a></code>
in the package <code>cluster</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>D2</code> containing the squared distances matrix 
between individuals.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GtoD2">GtoD2</a></code><br /> 
<code><a href="#topic+D2toG">D2toG</a></code><br /> 
<code><a href="#topic+D2toDist">D2toDist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- matrix(rnorm(100*3),nrow=100)
distance &lt;- daisy(X,"manhattan")
D2 &lt;- disttoD2(distance)

</code></pre>

<hr>
<h2 id='GtoD2'>
Distance conversion: dist to D2
</h2><span id='topic+GtoD2'></span>

<h3>Description</h3>

<p>Converts <code>Gram</code> class object into <code>D2</code> class object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  GtoD2(G)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GtoD2_+3A_g">G</code></td>
<td>

<p><code>Gram</code> class object. Weighted centered inner products matrix of the 
squared distances matrix. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>D2</code> containing the squared distances matrix 
between individuals.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+D2toG">D2toG</a></code><br /> 
<code><a href="#topic+disttoD2">disttoD2</a></code><br /> 
<code><a href="#topic+D2toDist">D2toDist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- matrix(rnorm(100*3),nrow=100)
D2 &lt;- as.matrix(dist(X)^2)
class(D2) &lt;- "D2"
G &lt;- D2toG(D2,weights=NULL)
class(G) &lt;- "Gram"
D22 &lt;- GtoD2(G)


</code></pre>

<hr>
<h2 id='ldbglm'>
Local distance-based generalized linear model
</h2><span id='topic+ldbglm'></span><span id='topic+ldbglm.formula'></span><span id='topic+ldbglm.dist'></span><span id='topic+ldbglm.D2'></span><span id='topic+ldbglm.Gram'></span><span id='topic+print.ldbglm'></span>

<h3>Description</h3>

<p><code>ldbglm</code> is a localized version of a distance-based generalized linear
model. As in the global model <code><a href="#topic+dbglm">dbglm</a></code>, explanatory information is 
coded as distances between individuals.
</p>
<p>Neighborhood definition for localizing is done by the (semi)metric
<code>dist1</code> whereas a second (semi)metric <code>dist2</code> (which may coincide
with <code>dist1</code>) is used for distance-based prediction.  
Both <code>dist1</code> and <code>dist2</code> can either be computed from observed 
explanatory variables or directly input as a squared distances 
matrix or as a <code>Gram</code> matrix. Response and link function are as in the                                                                 
<code>dbglm</code> function for ordinary generalized linear models. 
The model allows for a mixture of continuous and qualitative explanatory 
variables or, in fact, from more general quantities such as functional data. 
</p>
<p>Notation convention: in distance-based methods we must distinguish 
<em>observed explanatory variables</em> which we denote by Z or z, from 
<em>Euclidean coordinates</em> which we denote by X or x. For explanation
on the meaning of both terms see the bibliography references below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'formula'
ldbglm(formula,data,...,family=gaussian(),kind.of.kernel=1,
        metric1="euclidean",metric2=metric1,method.h="GCV",weights,
        user.h=NULL,h.range=NULL,noh=10,k.knn=3,
        rel.gvar=0.95,eff.rank=NULL,maxiter=100,eps1=1e-10,
        eps2=1e-10)

## S3 method for class 'dist'
ldbglm(dist1,dist2=dist1,y,family=gaussian(),kind.of.kernel=1,
        method.h="GCV",weights,user.h=quantile(dist1,.25),
        h.range=quantile(as.matrix(dist1),c(.05,.5)),noh=10,k.knn=3,
        rel.gvar=0.95,eff.rank=NULL,maxiter=100,eps1=1e-10,eps2=1e-10,...)

## S3 method for class 'D2'
ldbglm(D2.1,D2.2=D2.1,y,family=gaussian(),kind.of.kernel=1,
        method.h="GCV",weights,user.h=quantile(D2.1,.25)^.5,
        h.range=quantile(as.matrix(D2.1),c(.05,.5))^.5,noh=10,
        k.knn=3,rel.gvar=0.95,eff.rank=NULL,maxiter=100,eps1=1e-10,
        eps2=1e-10,...) 

## S3 method for class 'Gram'
ldbglm(G1,G2=G1,y,kind.of.kernel=1,user.h=NULL,
        family=gaussian(),method.h="GCV",weights,h.range=NULL,noh=10,
        k.knn=3,rel.gvar=0.95,eff.rank=NULL,maxiter=100,eps1=1e-10,
        eps2=1e-10,...)                
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldbglm_+3A_formula">formula</code></td>
<td>

<p>an object of class <code><a href="stats.html#topic+formula">formula</a></code>. A formula of the form <code>y~Z</code>.
This argument is a remnant of the <code><a href="stats.html#topic+loess">loess</a></code> function, 
kept for compatibility. 
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in the model 
(both response and explanatory variables, either
the observed ones, Z, or a Euclidean configuration X).  
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_y">y</code></td>
<td>

<p>(required if no formula is given as the principal argument). 
Response (dependent variable) must be numeric, matrix or data.frame.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_dist1">dist1</code></td>
<td>

<p>a <code>dist</code> or <code>dissimilarity</code> class object.   
Distances between observations, used for neighborhood localizing 
definition. Weights for observations are computed as a decreasing
function of their <code>dist1</code> distances to the neighborhood
center, e.g. a new observation whose reoponse has to be predicted. 
These weights are then entered to a <code>dbglm</code>, where distances 
are evaluated with <code>dist2</code>.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_dist2">dist2</code></td>
<td>

<p>a <code>dist</code> or <code>dissimilarity</code> class object.
Distances between observations, used for fitting <code><a href="#topic+dbglm">dbglm</a></code>. 
Default <code>dist2=dist1</code>. 
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_d2.1">D2.1</code></td>
<td>

<p>a <code>D2</code> class object. Squared distances matrix between individuals. 
One of the alternative ways of entering distance information
to a function. See the Details section in <code><a href="#topic+dblm">dblm</a></code>.
See above <code>dist1</code> for explanation of its role in this function.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_d2.2">D2.2</code></td>
<td>

<p>a <code>D2</code> class object. Squared distances between observations.
One of the alternative ways of entering distance information
to a function. See the Details section in <code><a href="#topic+dblm">dblm</a></code>.
See above <code>dist2</code> for explanation of its role in this function.
Default <code>D2.2=D2.1</code>. 
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_g1">G1</code></td>
<td>

<p>a <code>Gram</code> class object. Doubly centered inner product matrix 
associated with the squared distances matrix <code>D2.1</code>.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_g2">G2</code></td>
<td>

<p>a <code>Gram</code> class object. Doubly centered inner product matrix 
associated with the squared distances matrix <code>D2.2</code>.
Default <code>G2=G1</code>
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_family">family</code></td>
<td>

<p>a description of the error distribution and link function to be used 
in the model. This can be a character string naming a family 
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)
</p>
</td></tr> 
<tr><td><code id="ldbglm_+3A_kind.of.kernel">kind.of.kernel</code></td>
<td>

<p>integer number between 1 and 6 which determines the user's choice 
of smoothing kernel.
(1) Epanechnikov (Default), (2) Biweight, (3) Triweight, (4) Normal, 
(5) Triangular, (6) Uniform.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_metric1">metric1</code></td>
<td>

<p>metric function to be used when computing <code>dist1</code> from observed 
explanatory variables. 
One of <code>"euclidean"</code> (default), <code>"manhattan"</code>, 
or <code>"gower"</code>. 
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_metric2">metric2</code></td>
<td>

<p>metric function to be used when computing <code>dist2</code> from observed 
explanatory variables. 
One of <code>"euclidean"</code> (default), <code>"manhattan"</code>, 
or <code>"gower"</code>. 
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_method.h">method.h</code></td>
<td>

<p>sets the method to be used in deciding the <em>optimal bandwidth h</em>.
There are four different methods, <code>AIC</code>, <code>BIC</code>,
<code>GCV</code> (default) and <code>user.h</code>. 
<code>GCV</code> take the optimal bandwidth minimizing 
a cross-validatory quantity.  
<code>AIC</code> and <code>BIC</code> take the optimal bandwidth minimizing,
respectively, the Akaike or Bayesian Information Criterion 
(see <code><a href="stats.html#topic+AIC">AIC</a></code> for more details). 
When <code>method.h</code> is <code>user.h</code>, the bandwidth is explicitly
set by the user through the <code>user.h</code> optional parameter 
which, in this case, becomes mandatory.   
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_weights">weights</code></td>
<td>

<p>an optional numeric vector of weights to be used in the fitting process. 
By default all individuals have the same weight.  
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_user.h">user.h</code></td>
<td>

<p>global bandwidth <code>user.h</code>, set by the user, controlling the size 
of the local neighborhood of Z.
Smoothing parameter (Default: 1st quartile of all the distances 
d(i,j) in <code>dist1</code>). Applies only if <code>method.h="user.h"</code>.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_h.range">h.range</code></td>
<td>

<p>a vector of length 2 giving the range for automatic bandwidth 
choice. (Default: quantiles 0.05 and 0.5 of d(i,j) in <code>dist1</code>).
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_noh">noh</code></td>
<td>

<p>number of bandwidth <code>h</code> values within <code>h.range</code> for 
automatic bandwidth choice (if <code>method.h!="user.h"</code>).
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_k.knn">k.knn</code></td>
<td>

<p>minimum number of observations with positive weight
in neighborhood localizing. To avoid runtime errors
due to a too small bandwidth originating neighborhoods 
with only one observation. By default <code>k.nn=3</code>.	
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_rel.gvar">rel.gvar</code></td>
<td>

<p>relative geometric variability (a real number between 0 and 1). 
In each <code>dblm</code> iteration, take the lowest effective rank, with 
a relative geometric variability higher or equal to <code>rel.gvar</code>. 
Default value (<code>rel.gvar=0.95</code>) uses the 95% of the total
variability.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_eff.rank">eff.rank</code></td>
<td>

<p>integer between 1 and the number of observations minus one. 
Number of Euclidean coordinates used for model fitting in
each <code>dblm</code> iteration. If specified its value overrides
<code>rel.gvar</code>. When <code>eff.rank=NULL</code> (default), 
calls to <code>dblm</code> are made with <code>method=rel.gvar</code>.  
</p>
</td></tr> 
<tr><td><code id="ldbglm_+3A_maxiter">maxiter</code></td>
<td>

<p>maximum number of iterations in the iterated <code>dblm</code> algorithm. 
(Default = 100) 
</p>
</td></tr> 
<tr><td><code id="ldbglm_+3A_eps1">eps1</code></td>
<td>

<p>stopping criterion 1, <code>"DevStat"</code>: convergence tolerance <code>eps1</code>, 
a positive (small) number; 
the iterations converge when <code>|dev - dev_{old}|/(|dev|) &lt; eps1</code>.
Stationarity of deviance has been attained.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_eps2">eps2</code></td>
<td>

<p>stopping criterion 2, <code>"mustat"</code>: convergence tolerance <code>eps2</code>,
a positive (small) number; 
the iterations converge when <code>|mu - mu_{old}|/(|mu|) &lt; eps2</code>.
Stationarity of fitted.values <code>mu</code> has been attained.
</p>
</td></tr>
<tr><td><code id="ldbglm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>    
</table>


<h3>Details</h3>

<p>The various possible ways for inputting the model explanatory 
information through distances, or their squares, etc., are the 
same as in <code><a href="#topic+dblm">dblm</a></code>. 
</p>
<p>The set of bandwidth <code>h</code> values checked in automatic 
bandwidth choice is defined by <code>h.range</code> and <code>noh</code>, 
together with <code>k.knn</code>. For each <code>h</code> in it a local generalized 
linear model is fitted and the optimal <code>h</code> is decided according to the 
statistic specified in <code>method.h</code>.
</p>
<p><code>kind.of.kernel</code> designates which kernel function is to be used
in determining individual weights from <code>dist1</code> values. 
See <code><a href="stats.html#topic+density">density</a></code> for more information.
</p>
<p>For gamma distributions, the domain of the canonical link function 
is not the same as the permitted range of the mean. In particular, 
the linear predictor might be negative, obtaining an impossible 
negative mean. Should that event occur, <code>dbglm</code> stops with
an error message. Proposed alternative is to use a non-canonical link 
function.
</p>


<h3>Value</h3>

          
<p>A list of class <code>ldbglm</code> containing the following components: 
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals (response minus fitted values).</p>
</td></tr> 
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values.</p>
</td></tr>
<tr><td><code>h.opt</code></td>
<td>
<p>the optimal bandwidth <code>h</code> used in the fitting proces (<code>if method.h!=user.h</code>).</p>
</td></tr> 
<tr><td><code>family</code></td>
<td>
<p>the <code><a href="stats.html#topic+family">family</a></code> object used.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response variable used.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>the Smoother hat projector.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the specified weights.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>dist1</code></td>
<td>
<p>the distance matrix (object of class <code>"D2"</code> or <code>"dist"</code>) used to calculate the weights of the observations.</p>
</td></tr>
<tr><td><code>dist2</code></td>
<td>
<p>the distance matrix (object of class <code>"D2"</code> or <code>"dist"</code>) used to fit the <code><a href="#topic+dbglm">dbglm</a></code>.</p>
</td></tr>  
</table>
<p>Objects of class <code>"ldbglm"</code> are actually of class 
<code>c("ldbglm", "ldblm")</code>, inheriting the <code><a href="#topic+plot.ldblm">plot.ldblm</a></code> and
<code><a href="#topic+summary.ldblm">summary.ldblm</a></code> method from class <code>"ldblm"</code>.
</p>


<h3>Note</h3>

<p>Model fitting is repeated <code>n</code> times (<code>n=</code> number of observations)
for each bandwidth (<code>noh*n</code> times). 
For a <code>noh</code> too large or a sample with many observations, the time of 
this function can be very high.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Caballe, A., Delicado P, Esteve, A., Fortiana J (2016). <em>Global and local distance-based generalized linear models</em>.
TEST 25, 170-195.
</p>
<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbglm">dbglm</a></code> for distance-based generalized linear models.<br />
<code><a href="#topic+ldblm">ldblm</a></code> for local distance-based linear models.<br /> 
<code><a href="#topic+summary.ldbglm">summary.ldbglm</a></code> for summary.<br />
<code><a href="#topic+plot.ldbglm">plot.ldbglm</a></code> for plots.<br /> 
<code><a href="#topic+predict.ldbglm">predict.ldbglm</a></code> for predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example of ldbglm usage
 z &lt;- rnorm(100)
 y &lt;- rbinom(100, 1, plogis(z))
 D2 &lt;- as.matrix(dist(z))^2
 class(D2) &lt;- "D2"
 
 # Distance-based generalized linear model
 dbglm2 &lt;- dbglm(D2,y,family=binomial(link = "logit"), method="rel.gvar")
 # Local Distance-based generalized linear model
 ldbglm2 &lt;- ldbglm(D2,y=y,family=binomial(link = "logit"),noh=3)
 
 # check the difference of both
 sum((y-ldbglm2$fit)^2)
 sum((y-dbglm2$fit)^2)
 plot(z,y)
 points(z,ldbglm2$fit,col=3)
 points(z,dbglm2$fit,col=2) 
 
 
</code></pre>

<hr>
<h2 id='ldbglm-inl'>Internal  functions</h2><span id='topic+ldbglm-internal'></span><span id='topic+pred.train.sample.dbglm'></span>

<h3>Description</h3>

<p>Internal  functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>pred.train.sample.dbglm(y,dist1,dist2,n,h,h.knn,kind.of.kernel,family,weights,
    rel.gvar,eff.rank,maxiter,eps1,eps2)
</code></pre>


<h3>Details</h3>

<p>These are not to be called by the user</p>

<hr>
<h2 id='ldblm'>
Local distance-based linear model
</h2><span id='topic+ldblm'></span><span id='topic+ldblm.formula'></span><span id='topic+ldblm.dist'></span><span id='topic+ldblm.D2'></span><span id='topic+ldblm.Gram'></span><span id='topic+print.ldblm'></span>

<h3>Description</h3>

<p><code>ldblm</code> is a localized version of a distance-based linear model. 
As in the global model <code>dblm</code>, explanatory information is coded as 
distances between individuals.
</p>
<p>Neighborhood definition for localizing is done by the (semi)metric
<code>dist1</code> whereas a second (semi)metric <code>dist2</code> (which may coincide
with <code>dist1</code>) is used for distance-based prediction.  
Both <code>dist1</code> and <code>dist2</code>  can either be computed from observed 
explanatory variables or directly input as a squared distances 
matrix or as a <code>Gram</code> matrix. The response is a continuous variable 
as in the ordinary linear model. The model allows for a mixture of 
continuous and qualitative explanatory variables or, in fact, from more 
general quantities such as functional data. 
</p>
<p>Notation convention: in distance-based methods we must distinguish 
<em>observed explanatory variables</em> which we denote by Z or z, from 
<em>Euclidean coordinates</em> which we denote by X or x. For explanation
on the meaning of both terms see the bibliography references below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'formula'
ldblm(formula,data,...,kind.of.kernel=1,
        metric1="euclidean",metric2=metric1,method.h="GCV",weights,
        user.h=NULL,h.range=NULL,noh=10,k.knn=3,rel.gvar=0.95,eff.rank=NULL)

## S3 method for class 'dist'
ldblm(dist1,dist2=dist1,y,kind.of.kernel=1,
        method.h="GCV",weights,user.h=quantile(dist1,.25),
        h.range=quantile(as.matrix(dist1),c(.05,.5)),noh=10,
        k.knn=3,rel.gvar=0.95,eff.rank=NULL,...)  

## S3 method for class 'D2'
ldblm(D2.1,D2.2=D2.1,y,kind.of.kernel=1,method.h="GCV",
        weights,user.h=quantile(D2.1,.25)^.5,
        h.range=quantile(as.matrix(D2.1),c(.05,.5))^.5,noh=10,k.knn=3,
        rel.gvar=0.95,eff.rank=NULL,...) 
         
## S3 method for class 'Gram'
ldblm(G1,G2=G1,y,kind.of.kernel=1,method.h="GCV",
        weights,user.h=NULL,h.range=NULL,noh=10,k.knn=3,rel.gvar=0.95,
        eff.rank=NULL,...)       
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldblm_+3A_formula">formula</code></td>
<td>

<p>an object of class <code><a href="stats.html#topic+formula">formula</a></code>. A formula of the form <code>y~Z</code>.
This argument is a remnant of the <code><a href="stats.html#topic+loess">loess</a></code> function, 
kept for compatibility. 
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_data">data</code></td>
<td>

<p>an optional data frame containing the variables in the model 
(both response and explanatory variables, either
the observed ones, Z, or a Euclidean configuration X).  
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_y">y</code></td>
<td>

<p>(required if no formula is given as the principal argument). 
Response (dependent variable) must be numeric, matrix or data.frame.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_dist1">dist1</code></td>
<td>

<p>a <code>dist</code> or <code>dissimilarity</code> class object.   
Distances between observations, used for neighborhood localizing 
definition. Weights for observations are computed as a decreasing
function of their <code>dist1</code> distances to the neighborhood
center, e.g. a new observation whose reoponse has to be predicted. 
These weights are then entered to a <code>dblm</code>, where distances 
are evaluated with <code>dist2</code>.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_dist2">dist2</code></td>
<td>

<p>a <code>dist</code> or <code>dissimilarity</code> class object.
Distances between observations, used for fitting <code><a href="#topic+dblm">dblm</a></code>. 
Default <code>dist2=dist1</code>. 
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_d2.1">D2.1</code></td>
<td>

<p>a <code>D2</code> class object. Squared distances matrix between individuals. 
One of the alternative ways of entering distance information
to a function. See the Details section in <code><a href="#topic+dblm">dblm</a></code>.
See above <code>dist1</code> for explanation of its role in this function.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_d2.2">D2.2</code></td>
<td>

<p>a <code>D2</code> class object. Squared distances between observations.
One of the alternative ways of entering distance information
to a function. See the Details section in <code><a href="#topic+dblm">dblm</a></code>.
See above <code>dist2</code> for explanation of its role in this function.
Default <code>D2.2=D2.1</code>. 
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_g1">G1</code></td>
<td>

<p>a <code>Gram</code> class object. Doubly centered inner product matrix 
associated with the squared distances matrix <code>D2.1</code>.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_g2">G2</code></td>
<td>

<p>a <code>Gram</code> class object. Doubly centered inner product matrix 
associated with the squared distances matrix <code>D2.2</code>.
Default <code>G2=G1</code>
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_kind.of.kernel">kind.of.kernel</code></td>
<td>

<p>integer number between 1 and 6 which determines the user's choice 
of smoothing kernel.
(1) Epanechnikov (Default), (2) Biweight, (3) Triweight, (4) Normal, 
(5) Triangular, (6) Uniform.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_metric1">metric1</code></td>
<td>

<p>metric function to be used when computing <code>dist1</code> from observed 
explanatory variables. 
One of <code>"euclidean"</code> (default), <code>"manhattan"</code>, 
or <code>"gower"</code>. 
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_metric2">metric2</code></td>
<td>

<p>metric function to be used when computing <code>dist2</code> from observed 
explanatory variables. 
One of <code>"euclidean"</code> (default), <code>"manhattan"</code>, 
or <code>"gower"</code>. 
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_method.h">method.h</code></td>
<td>

<p>sets the method to be used in deciding the <em>optimal bandwidth h</em>.
There are five different methods, <code>AIC</code>, <code>BIC</code>, <code>OCV</code>, 
<code>GCV</code> (default) and <code>user.h</code>. 
<code>OCV</code> and <code>GCV</code> take the optimal bandwidth minimizing 
a cross-validatory quantity (either <code>ocv</code> or <code>gcv</code>).  
<code>AIC</code> and <code>BIC</code> take the optimal bandwidth minimizing,
respectively, the Akaike or Bayesian Information Criterion 
(see <code><a href="stats.html#topic+AIC">AIC</a></code> for more details). 
When <code>method.h</code> is <code>user.h</code>, the bandwidth is explicitly
set by the user through the <code>user.h</code> optional parameter 
which, in this case, becomes mandatory.   
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_weights">weights</code></td>
<td>

<p>an optional numeric vector of weights to be used in the fitting process. 
By default all individuals have the same weight.  
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_user.h">user.h</code></td>
<td>

<p>global bandwidth <code>user.h</code>, set by the user, controlling the size 
of the local neighborhood of Z.
Smoothing parameter (Default: 1st quartile of all the distances 
d(i,j) in <code>dist1</code>). Applies only if <code>method.h="user.h"</code>.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_h.range">h.range</code></td>
<td>

<p>a vector of length 2 giving the range for automatic bandwidth 
choice. (Default: quantiles 0.05 and 0.5 of d(i,j) in <code>dist1</code>).
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_noh">noh</code></td>
<td>

<p>number of bandwidth <code>h</code> values within <code>h.range</code> for 
automatic bandwidth choice (if <code>method.h!="user.h"</code>).
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_k.knn">k.knn</code></td>
<td>

<p>minimum number of observations with positive weight
in neighborhood localizing. To avoid runtime errors
due to a too small bandwidth originating neighborhoods 
with only one observation. By default <code>k.nn=3</code>.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_rel.gvar">rel.gvar</code></td>
<td>

<p>relative geometric variability (a real number between 0 and 1). 
In each <code>dblm</code> iteration, take the lowest effective rank, with 
a relative geometric variability higher or equal to <code>rel.gvar</code>. 
Default value (<code>rel.gvar=0.95</code>) uses the 95% of the total
variability.
</p>
</td></tr>
<tr><td><code id="ldblm_+3A_eff.rank">eff.rank</code></td>
<td>

<p>integer between 1 and the number of observations minus one. 
Number of Euclidean coordinates used for model fitting in
each <code>dblm</code> iteration. If specified its value overrides
<code>rel.gvar</code>. When <code>eff.rank=NULL</code> (default), 
calls to <code>dblm</code> are made with <code>method=rel.gvar</code>.  
</p>
</td></tr>  
<tr><td><code id="ldblm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>   
</table>


<h3>Details</h3>

<p>There are two semi-metrics involved in local linear distance-based estimation:
<code>dist1</code> and <code>dist2</code>. Both semi-metrics can coincide. 
For instance, when <code>dist1=||xi-xj||</code> and 
<code>dist2=||(xi,xi^2,xi^3)-(xj,xj^2,xj^3)||</code> the estimator 
for new observations coincides with fitting a local cubic polynomial 
regression.  
</p>
<p>The set of bandwidth <code>h</code> values checked in automatic 
bandwidth choice is defined by <code>h.range</code> and <code>noh</code>, 
together with <code>k.knn</code>. For each <code>h</code> in it a local linear 
model is fitted and the optimal <code>h</code> is decided according to the 
statistic specified in <code>method.h</code>.
</p>
<p><code>kind.of.kernel</code> designates which kernel function is to be used
in determining individual weights from <code>dist1</code> values. 
See <code><a href="stats.html#topic+density">density</a></code> for more information.
</p>


<h3>Value</h3>

          
<p>A list of class <code>ldblm</code> containing the following components: 
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals (response minus fitted values).</p>
</td></tr> 
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values.</p>
</td></tr>
<tr><td><code>h.opt</code></td>
<td>
<p>the optimal bandwidth h used in the fitting proces 
(<code>if method.h!=user.h</code>).</p>
</td></tr> 
<tr><td><code>S</code></td>
<td>
<p>the Smoother hat projector.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the specified weights.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response variable used.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>dist1</code></td>
<td>
<p>the distance matrix (object of class <code>"D2"</code> or <code>"dist"</code>) used to calculate the weights of the observations.</p>
</td></tr>
<tr><td><code>dist2</code></td>
<td>
<p>the distance matrix (object of class <code>"D2"</code> or <code>"dist"</code>) used to fit the <code><a href="#topic+dblm">dblm</a></code>.</p>
</td></tr>      
</table>


<h3>Note</h3>

<p>Model fitting is repeated <code>n</code> times (<code>n=</code> number of observations)
for each bandwidth (<code>noh*n</code> times). 
For a <code>noh</code> too large or a sample with many observations, the time of 
this function can be very high.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;, Delicado, 
Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Caballe, A., Delicado P, Esteve, A., Fortiana J (2016). <em>Global and local distance-based generalized linear models</em>.
TEST 25, 170-195.
</p>
<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dblm">dblm</a></code> for distance-based linear models.<br />
<code><a href="#topic+ldbglm">ldbglm</a></code> for local distance-based generalized linear models.<br />
<code><a href="#topic+summary.ldblm">summary.ldblm</a></code> for summary.<br /> 
<code><a href="#topic+plot.ldblm">plot.ldblm</a></code> for plots.<br />
<code><a href="#topic+predict.ldblm">predict.ldblm</a></code> for predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example to use of the ldblm function
n &lt;- 100
p &lt;- 1
k &lt;- 5

Z &lt;- matrix(rnorm(n*p),nrow=n)
b1 &lt;- matrix(runif(p)*k,nrow=p)
b2 &lt;- matrix(runif(p)*k,nrow=p)
b3 &lt;- matrix(runif(p)*k,nrow=p)

s &lt;- 1
e &lt;- rnorm(n)*s


y &lt;- Z%*%b1 + Z^2%*%b2 +Z^3%*%b3 + e

D2 &lt;- as.matrix(dist(Z)^2)
class(D2) &lt;- "D2"

ldblm1 &lt;- ldblm(y~Z,kind.of.kernel=1,method="GCV",noh=3,k.knn=3)
ldblm2 &lt;- ldblm(D2.1=D2,D2.2=D2,y,kind.of.kernel=1,method="user.h",k.knn=3)
 
 
 
</code></pre>

<hr>
<h2 id='ldblm-inl'>Internal  functions</h2><span id='topic+ldblm-internal'></span><span id='topic+pred.train.sample'></span><span id='topic+kernel.number'></span><span id='topic+h.knn.funct'></span><span id='topic+controls_ldblm'></span>

<h3>Description</h3>

<p>Internal  functions</p>


<h3>Usage</h3>

<pre><code class='language-R'>pred.train.sample(y,dist1,dist2,n,h,h.knn,kind.of.kernel,weights,
        rel.gvar,eff.rank)
kernel.number(u,j=1)
h.knn.funct(dist,k=3)
controls_ldblm(dist1,dist2,user.h,method,h.range,noh,k.knn,kind.of.kernel,y,weights)
</code></pre>


<h3>Details</h3>

<p>These are not to be called by the user</p>

<hr>
<h2 id='plot.dblm'>
Plots for objects of clases dblm or dbglm
</h2><span id='topic+plot.dblm'></span><span id='topic+plot.dbglm'></span>

<h3>Description</h3>

<p>Six plots (selected by <code>which</code>) are available: a plot of residual vs 
fitted values, the Q-Qplot of normality, a Scale-Location plot of 
<code>sqrt(|residuals|)</code> against fitted values. A plot of Cook's distances 
versus row labels, a plot of residuals against leverages, and the optimal 
effective rank of <code>"OCV"</code>, <code>"GCV"</code>, <code>"AIC"</code> or <code>"BIC"</code> 
method (only if one of these four methods have been chosen in function <code>dblm</code>). 
By default, only the first three and <code>5</code> are provided.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dblm'
plot(x,which=c(1:3, 5),id.n=3,main="",
        cook.levels = c(0.5, 1),cex.id = 0.75,
        type.pred=c("link","response"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.dblm_+3A_x">x</code></td>
<td>

<p>an object of class <code><a href="#topic+dblm">dblm</a></code> or <code><a href="#topic+dbglm">dbglm</a></code>. 
</p>
</td></tr>
<tr><td><code id="plot.dblm_+3A_which">which</code></td>
<td>

<p>if a subset of the plots is required, specify a subset of the numbers 1:6.
</p>
</td></tr>
<tr><td><code id="plot.dblm_+3A_id.n">id.n</code></td>
<td>

<p>number of points to be labelled in each plot, starting with the most extreme.
</p>
</td></tr>
<tr><td><code id="plot.dblm_+3A_main">main</code></td>
<td>

<p>an overall title for the plot. Only if one of the six plots is selected.
</p>
</td></tr>
<tr><td><code id="plot.dblm_+3A_cook.levels">cook.levels</code></td>
<td>

<p>levels of Cook's distance at which to draw contours.
</p>
</td></tr>
<tr><td><code id="plot.dblm_+3A_cex.id">cex.id</code></td>
<td>

<p>magnification of point labels.
</p>
</td></tr>
<tr><td><code id="plot.dblm_+3A_type.pred">type.pred</code></td>
<td>

<p>the type of prediction (required only for a <code>dbglm</code> class object). 
Like <code><a href="#topic+predict.dbglm">predict.dbglm</a></code>, the default <code>"link"</code> is on the scale
of the linear predictors; the alternative <code>"response"</code> is on the scale 
of the response variable. 
</p>
</td></tr>
<tr><td><code id="plot.dblm_+3A_...">...</code></td>
<td>

<p>other parameters to be passed through to plotting functions.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The five first plots are very useful to the residual analysis and are 
the same that <code><a href="stats.html#topic+plot.lm">plot.lm</a></code>. A plot of residuals against fitted 
values sees if the variance is constant. The qq-plot checks if the residuals 
are normal (see <code><a href="stats.html#topic+qqnorm">qqnorm</a></code>). 
The plot between <code>"Scale-Location"</code> and the fitted values takes the 
square root of the absolute residuals in order to diminish skewness.
The Cook's distance against the row labels, measures the effect of deleting a 
given observation (estimate of the influence of a data point). Points with a 
large Cook's distance are considered to merit closer examination in the analysis. 
Finally, the Residual-Leverage plot also shows the most influence points 
(labelled by Cook's distance). See <code><a href="stats.html#topic+cooks.distance">cooks.distance</a></code>.
</p>
<p>The last plot, allows to view the <code>"OCV"</code> (just for <code>dblm</code>), <code>"GCV"</code>, <code>"AIC"</code>
or <code>"BIC"</code> criterion according to the used rank in the 
<code><a href="#topic+dblm">dblm</a></code> or <code><a href="#topic+dbglm">dbglm</a></code> functions, and chosen the minimum. Applies only if 
the parameter <code>full.search</code> its <code>TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>
<p>Belsley, D. A., Kuh, E. and Welsch, R. E. (1980). <em>Regression Diagnostics</em>. New York: Wiley. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dblm">dblm</a></code> for distance-based linear models.<br />
<code><a href="#topic+dbglm">dbglm</a></code> for distance-based generalized linear models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 64
p &lt;- 4
k &lt;- 3

Z &lt;- matrix(rnorm(n*p),nrow=n)
b &lt;- matrix(runif(p)*k,nrow=p)
s &lt;- 1
e &lt;- rnorm(n)*s
y &lt;- Z%*%b + e

dblm1 &lt;- dblm(y~Z,metric="gower",method="GCV", full.search=FALSE)
plot(dblm1)
plot(dblm1,which=4)

</code></pre>

<hr>
<h2 id='plot.dbplsr'>
Plots for a dbplsr object
</h2><span id='topic+plot.dbplsr'></span>

<h3>Description</h3>

<p>Four plots (selected by <code>which</code>) are available: plot of scores, 
response vs scores, R2 contribution in each component and the value of 
<code>"OCV"</code>, <code>"GCV"</code>, <code>"AIC"</code> or <code>"BIC"</code> vs the number 
of component chosen.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dbplsr'
plot(x,which=c(1L:4L),main="",scores.comps=1:2,
        component=1,method=c("OCV","GCV","AIC","BIC"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.dbplsr_+3A_x">x</code></td>
<td>

<p>an object of class <code>dbplsr</code>.
</p>
</td></tr>
<tr><td><code id="plot.dbplsr_+3A_which">which</code></td>
<td>

<p>if a subset of the plots is required, specify a subset of the numbers 1:4.
</p>
</td></tr>
<tr><td><code id="plot.dbplsr_+3A_main">main</code></td>
<td>

<p>an overall title for the plot. Only if one of the four plots is selected.
</p>
</td></tr>
<tr><td><code id="plot.dbplsr_+3A_scores.comps">scores.comps</code></td>
<td>

<p>array containing the component scores crossed in the first plot 
(default the first two).
</p>
</td></tr>
<tr><td><code id="plot.dbplsr_+3A_component">component</code></td>
<td>

<p>numeric value. Component vs response in the second plot
(Default the first component). 
</p>
</td></tr>
<tr><td><code id="plot.dbplsr_+3A_method">method</code></td>
<td>

<p>choosen method <code>"OCV"</code>, <code>"GCV"</code>, <code>"AIC"</code> or <code>"BIC"</code> 
in the last plot.
</p>
</td></tr>
<tr><td><code id="plot.dbplsr_+3A_...">...</code></td>
<td>

<p>other parameters to be passed through to plotting functions.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Implementing PLS for distance-based regression: 
computational issues</em>.
<em>Computational Statistics</em> 22, 237-248.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>
<p>Belsley, D. A., Kuh, E. and Welsch, R. E. (1980). <em>Regression Diagnostics</em>. New York: Wiley. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbplsr">dbplsr</a></code> for distance-based partial least squares.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#require(pls)
library(pls)
data(yarn)
## Default methods:
yarn.dbplsr &lt;- dbplsr(density ~ NIR, data = yarn, ncomp=6, method="GCV")
plot(yarn.dbplsr,scores.comps=1:3)

</code></pre>

<hr>
<h2 id='plot.ldblm'>
Plots for objects of clases ldblm or ldbglm
</h2><span id='topic+plot.ldblm'></span><span id='topic+plot.ldbglm'></span>

<h3>Description</h3>

<p>Three plots (selected by <code>which</code>) are available: a plot of 
fitted values vs response, a plot of residuals vs fitted and the 
optimal bandwidth <code>h</code> of <code>"OCV"</code>, <code>"GCV"</code>, <code>"AIC"</code> or 
<code>"BIC"</code> criterion (only if one of these four methods have been chosen 
in the <code>ldblm</code> function). By default, only the first and the second 
are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldblm'
plot(x,which=c(1,2),id.n=3,main="",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ldblm_+3A_x">x</code></td>
<td>

<p>an object of class <code><a href="#topic+ldblm">ldblm</a></code> or <code><a href="#topic+ldbglm">ldbglm</a></code>.
</p>
</td></tr>
<tr><td><code id="plot.ldblm_+3A_which">which</code></td>
<td>

<p>if a subset of the plots is required, specify a subset of the numbers 1:3.
</p>
</td></tr>
<tr><td><code id="plot.ldblm_+3A_id.n">id.n</code></td>
<td>

<p>number of points to be labelled in each plot, starting with the most extreme.
</p>
</td></tr>
<tr><td><code id="plot.ldblm_+3A_main">main</code></td>
<td>

<p>an overall title for the plot. Only if one of the three plots is selected.
</p>
</td></tr>
<tr><td><code id="plot.ldblm_+3A_...">...</code></td>
<td>

<p>other parameters to be passed through to plotting functions.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>
<p>Belsley, D. A., Kuh, E. and Welsch, R. E. (1980). <em>Regression Diagnostics</em>. New York: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ldblm">ldblm</a></code>  for local distance-based linear models.<br />
<code><a href="#topic+ldbglm">ldbglm</a></code> for local distance-based generalized linear models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example to use of the ldblm function
n &lt;- 100
p &lt;- 1
k &lt;- 5

Z &lt;- matrix(rnorm(n*p),nrow=n)
b1 &lt;- matrix(runif(p)*k,nrow=p)
b2 &lt;- matrix(runif(p)*k,nrow=p)
b3 &lt;- matrix(runif(p)*k,nrow=p)

s &lt;- 1
e &lt;- rnorm(n)*s


y &lt;- Z%*%b1 + Z^2%*%b2 +Z^3%*%b3 + e

D2 &lt;- as.matrix(dist(Z))^2
class(D2) &lt;- "D2"

ldblm1 &lt;- ldblm(D2,y=y,kind.of.kernel=1,method.h="AIC",noh=5,h.knn=NULL)
plot(ldblm1)
plot(ldblm1,which=3)


</code></pre>

<hr>
<h2 id='predict.dbglm'>
Predicted values for a dbglm object
</h2><span id='topic+predict.dbglm'></span>

<h3>Description</h3>

<p><code>predict.dbglm</code> returns the predicted values, obtained by tested the 
generalized distance regression function in the new data (<code>newdata</code>). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dbglm'
predict(object,newdata,type.pred=c("link", "response"),
        type.var="Z",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.dbglm_+3A_object">object</code></td>
<td>

<p>an object of class <code>dbglm</code>. Result of <code><a href="#topic+dbglm">dbglm</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.dbglm_+3A_newdata">newdata</code></td>
<td>

<p>data.frame or matrix which contains the values of Z (if <code>type.var="Z"</code>. 
The squared distances between k new individuals and the original n individuals (only if <code>type.var="D2"</code>). 
Finally, the G inner products matrix (if <code>type.var="G"</code>).
</p>
</td></tr>
<tr><td><code id="predict.dbglm_+3A_type.pred">type.pred</code></td>
<td>

<p>the type of prediction (required). The default <code>"link"</code> is on the scale 
of the linear predictors; the alternative <code>"response"</code> is on the scale 
of the response variable. 
</p>
</td></tr>
<tr><td><code id="predict.dbglm_+3A_type.var">type.var</code></td>
<td>

<p>set de type of newdata. Can be <code>"Z"</code> if newdata 
contains the values of the explanatory variables, <code>"D2"</code> if 
contains the squared distances matrix or <code>"G"</code> if contains the 
inner products matrix.    
</p>
</td></tr>
<tr><td><code id="predict.dbglm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predicted values may be the expected mean values of response for the new 
data (<code>type.pred="response"</code>), or the linear predictors evaluated in the 
estimated <code>dblm</code> of the last iteration.
</p>
<p>In classical linear models the mean and the linear predictor are the same 
(makes use of the identity link). However, other distributions such as 
Poisson or binomial, the link could change. It's easy to get the predicted 
mean values, as these are calculated by the inverse link of linear predictors. 
See <code><a href="stats.html#topic+family">family</a></code> to view how to use <code>linkfun</code> and <code>linkinv</code>.    
</p>


<h3>Value</h3>

<p><code>predict.dbglm</code> produces a vector of predictions for the k new individuals.
</p>


<h3>Note</h3>

<p>Look at which way (or <code>type.var</code>) was made the dbglm call.
The parameter <code>type.var</code> must be consistent with the data type 
that is introduced to <code>dbglm</code>.    
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbglm">dbglm</a></code> for distance-based generalized linear models.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
z &lt;- rnorm(100)
y &lt;- rpois(100, exp(1+z))
glm1 &lt;- glm(y ~z, family=quasi("identity"))
dbglm1 &lt;- dbglm(y~z,family=quasi("identity"), method="rel.gvar")

newdata&lt;-0

pr1 &lt;- predict(dbglm1,newdata,type.pred="response",type.var="Z")
print(pr1)
plot(z,y)
points(z,dbglm1$fitt,col=2)
points(0,pr1,col=2)
abline(v=0,col=2)
abline(h=pr1,col=2)

</code></pre>

<hr>
<h2 id='predict.dblm'>
Predicted values for a dblm object
</h2><span id='topic+predict.dblm'></span>

<h3>Description</h3>

<p><code>predict.dblm</code> returns the predicted values, obtained by evaluating the 
distance regression function in the new data (<code>newdata</code>).
<code>newdata</code> can be the values of the explanatory variables of these new 
cases, the squared distances between these new individuals 
and the originals ones, or rows of new doubly weighted and centered inner 
products matrix G.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dblm'
predict(object,newdata,type.var="Z",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.dblm_+3A_object">object</code></td>
<td>

<p>an object of class <code>dblm</code>. Result of <code><a href="#topic+dblm">dblm</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.dblm_+3A_newdata">newdata</code></td>
<td>

<p>data.frame or matrix which contains the values of Z (if <code>type.var="Z"</code>. 
The squared distances between k new individuals and the original n individuals (only if <code>type.var="D2"</code>). 
Finally, the G inner products matrix (if <code>type.var="G"</code>).
</p>
</td></tr>
<tr><td><code id="predict.dblm_+3A_type.var">type.var</code></td>
<td>

<p>set de type.var of newdata. Can be <code>"Z"</code> if newdata 
contains the values of the explanatory variables, <code>"D2"</code> if 
contains the squared distances matrix or <code>"G"</code> if contains the 
inner products matrix.      
</p>
</td></tr>
<tr><td><code id="predict.dblm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.dblm</code> produces a vector of predictions for the k new individuals.
</p>


<h3>Note</h3>

<p>Look at which way (or <code>type.var</code>) was made the <code>dblm</code> call. 
The parameter <code>type.var</code> must be consistent with the data type that is 
introduced to <code>dblm</code>.    
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dblm">dblm</a></code> for distance-based linear models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# prediction of new observations newdata
n &lt;- 100
p &lt;- 3
k &lt;- 5

Z &lt;- matrix(rnorm(n*p),nrow=n)
b &lt;- matrix(runif(p)*k,nrow=p)
s &lt;- 1
e &lt;- rnorm(n)*s
y &lt;- Z%*%b + e

D &lt;- dist(Z)
D2 &lt;- disttoD2(D)
D2_train &lt;- D2[1:90,1:90]
class(D2_train)&lt;-"D2"

dblm1 &lt;- dblm(D2_train,y[1:90])

newdata &lt;- D2[91:100,1:90]
predict(dblm1,newdata,type.var="D2")


</code></pre>

<hr>
<h2 id='predict.dbplsr'>
Predicted values for a dbpls object
</h2><span id='topic+predict.dbplsr'></span>

<h3>Description</h3>

<p><code>predict.dbplsr</code> returns the predicted values, obtained by evaluating the 
Distance-based partial least squares function in the new data (<code>newdata</code>).
<code>newdata</code> can be the values of the explanatory variables of these new 
cases, the squared distances between these new individuals 
and the originals ones, or rows of new doubly weighted and centered inner 
products matrix G.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dbplsr'
predict(object,newdata,type.var="Z",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.dbplsr_+3A_object">object</code></td>
<td>

<p>an object of class <code>dbplsr</code>. Result of <code><a href="#topic+dbplsr">dbplsr</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.dbplsr_+3A_newdata">newdata</code></td>
<td>

<p>data.frame or matrix which contains the values of Z (if <code>type.var="Z"</code>. 
The squared distances between k new individuals and the original n individuals (only if <code>type.var="D2"</code>). 
Finally, the G inner products matrix (if <code>type.var="G"</code>).
</p>
</td></tr>
<tr><td><code id="predict.dbplsr_+3A_type.var">type.var</code></td>
<td>

<p>set de type of newdata. Can be <code>"Z"</code> if newdata 
contains the values of the explanatory variables, <code>"D2"</code> if 
contains the squared distances matrix or <code>"G"</code> if contains the 
inner products matrix.      
</p>
</td></tr>
<tr><td><code id="predict.dbplsr_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.dbplsr</code> produces a vector of predictions for the k new individuals.
</p>


<h3>Note</h3>

<p>Look at which way (or <code>type.var</code>) was made the <code>dbplsr</code> call. 
The parameter <code>type.var</code> must be consistent with the data type that is 
introduced to <code>dbplsr</code>.     
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Implementing PLS for distance-based regression: 
computational issues</em>.
<em>Computational Statistics</em> 22, 237-248.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbplsr">dbplsr</a></code> for distance-based partial least squares.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>          
#require(pls)
# prediction of new observations newdata
library(pls)
data(yarn)
## Default methods:
yarn.dbplsr &lt;- dbplsr(density[1:27] ~ NIR[1:27,], data = yarn, ncomp=6, method="GCV")
pr_yarn_28 &lt;- predict(yarn.dbplsr,newdata=t(as.matrix(yarn$NIR[28,])))
print(pr_yarn_28)
print(yarn$density[28])


</code></pre>

<hr>
<h2 id='predict.ldbglm'>
Predicted values for a ldbglm object
</h2><span id='topic+predict.ldbglm'></span><span id='topic+print.predict.ldbglm'></span>

<h3>Description</h3>

<p><code>predict.ldbglm</code> returns the predicted values, obtained by evaluating
the local distance-based generalized linear model in the new data 
(<code>newdata2</code>), using <code>newdata1</code> to estimate the &quot;kernel weights&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldbglm'
predict(object,newdata1,newdata2=newdata1,
        new.k.knn=3,type.pred=c("link","response"),
        type.var="Z",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ldbglm_+3A_object">object</code></td>
<td>

<p>an object of class <code>ldbglm</code>. Result of <code><a href="#topic+ldbglm">ldbglm</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.ldbglm_+3A_newdata1">newdata1</code></td>
<td>

<p>data.frame or matrix which contains the values of Z (if <code>type.var="Z"</code>. 
The squared distances between k new individuals and the original n individuals (only if <code>type.var="D2"</code>). 
Finally, the G inner products matrix (if <code>type.var="G"</code>). <code>newdata1</code> is used to compute kernels and local weights.
</p>
</td></tr>
<tr><td><code id="predict.ldbglm_+3A_newdata2">newdata2</code></td>
<td>

<p>the same logic as <code>newdata1</code>.
<code>newdata2</code> is used to compute the distance-based generalized regressions 
with (<code><a href="#topic+dbglm">dbglm</a></code>). If <code>newdata2</code>=NULL, <code>newdata2 &lt;- newdata1</code>.
</p>
</td></tr>
<tr><td><code id="predict.ldbglm_+3A_new.k.knn">new.k.knn</code></td>
<td>

<p>setting a minimum bandwidth in order to check that a candidate bandwidth h
doesn't contains DB linear models with only one observation.
If <code>new.h.knn=NULL</code>, takes the distance that includes the 3 nearest
neighbors for each new individual row. 
</p>
</td></tr>
<tr><td><code id="predict.ldbglm_+3A_type.pred">type.pred</code></td>
<td>

<p>the type of prediction (required). The default <code>link</code> is on the 
scale of the linear predictors; the alternative <code>"response"</code> 
is on the scale of the response variable. 
</p>
</td></tr> 
<tr><td><code id="predict.ldbglm_+3A_type.var">type.var</code></td>
<td>

<p>set de type of the newdata paramater. Can be <code>"Z"</code> if newdata
contains the values of the explanatory variables, <code>"D2"</code> if contains 
the squared distances matrix or <code>"G"</code> if contains the inner 
products matrix. 
</p>
</td></tr>
<tr><td><code id="predict.ldbglm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Value</h3>

                
<p>A list of class <code>predict.ldbglm</code> containing the following components: 
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>predicted values for the k new individuals.</p>
</td></tr>
<tr><td><code>newS</code></td>
<td>
<p>matrix (with dimension (k,n)) of weights used to compute the predictions.</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>Look at which way (or <code>type.var</code>) was made the <code>ldbglm</code> call. The parameter 
<code>type.var</code> must be consistent with the data type that is introduced 
to <code>ldbglm</code>.    
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ldbglm">ldbglm</a></code> for local distance-based generalized linear models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example to use of the predict.ldbglm function
 z &lt;- rnorm(100)
 y &lt;- rpois(100, exp(1+z))
 glm5 &lt;- glm(y ~z, family=quasi("identity"))
 ldbglm5 &lt;- ldbglm(dist(z),y=y,family=quasi("identity"),noh=3)
 plot(z,y)
 points(z,glm5$fitt,col=2)
 points(z,ldbglm5$fitt,col=3)

 pr_ldbglm5 &lt;- predict(ldbglm5,as.matrix(dist(z)^2),type.pred="response",type.var="D2")
 max(pr_ldbglm5$fit-ldbglm5$fitt)

</code></pre>

<hr>
<h2 id='predict.ldblm'>
Predicted values for a ldblm object
</h2><span id='topic+predict.ldblm'></span><span id='topic+print.predict.ldblm'></span>

<h3>Description</h3>

<p><code>predict.ldblm</code> returns the predicted values, obtained by evaluating
the local distance-based linear model in the new data 
(<code>newdata2</code>), using <code>newdata1</code> to estimate the &quot;kernel weights&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>                                  
## S3 method for class 'ldblm'
predict(object,newdata1,newdata2=newdata1,
        new.k.knn=3,type.var="Z",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ldblm_+3A_object">object</code></td>
<td>

<p>an object of class <code>ldblm</code>. Result of <code><a href="#topic+ldblm">ldblm</a></code>.
</p>
</td></tr>
<tr><td><code id="predict.ldblm_+3A_newdata1">newdata1</code></td>
<td>

<p>data.frame or matrix which contains the values of Z (if <code>type.var="Z"</code>. 
The squared distances between k new individuals and the original n individuals (only if <code>type.var="D2"</code>). 
Finally, the G inner products matrix (if <code>type.var="G"</code>). <code>newdata1</code> is used to compute kernels and local weights.
</p>
</td></tr>
<tr><td><code id="predict.ldblm_+3A_newdata2">newdata2</code></td>
<td>

<p>the same logic as <code>newdata1</code>.
<code>newdata2</code> is used to compute the Distance-based Regressions with
(<code><a href="#topic+dblm">dblm</a></code>). If <code>newdata2</code>=NULL, <code>newdata2 &lt;- newdata1</code>.
</p>
</td></tr>
<tr><td><code id="predict.ldblm_+3A_new.k.knn">new.k.knn</code></td>
<td>

<p>setting a minimum bandwidth in order to check that a candidate bandwidth h
doesn't contains DB linear models with only one observation.
If <code>new.h.knn=NULL</code>, takes the distance that includes the 3 nearest
neighbors for each new individual row. 
</p>
</td></tr>
<tr><td><code id="predict.ldblm_+3A_type.var">type.var</code></td>
<td>

<p>set de type of the newdata paramater. Can be <code>"Z"</code> if newdata
contains the values of the explanatory variables, <code>"D2"</code> if contains 
the squared distances matrix or <code>"G"</code> if contains the inner 
products matrix. 
</p>
</td></tr>
<tr><td><code id="predict.ldblm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Value</h3>

                
<p>A list of class <code>predict.ldblm</code> containing the following components: 
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>predicted values for the k new individuals.</p>
</td></tr>
<tr><td><code>newS</code></td>
<td>
<p>matrix (with dimension (k,n)) of weights used to compute the predictions.</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>Look at which way (or <code>type.var</code>) was made the <code>ldblm</code> call. 
The parameter <code>type.var</code> must be consistent with the data type that 
is introduced to <code>ldblm</code>.    
</p>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ldblm">ldblm</a></code> for local distance-based linear models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example to use of the predict.ldblm function

n &lt;- 100
p &lt;- 1
k &lt;- 5

Z &lt;- matrix(rnorm(n*p),nrow=n)
b1 &lt;- matrix(runif(p)*k,nrow=p)
b2 &lt;- matrix(runif(p)*k,nrow=p)
b3 &lt;- matrix(runif(p)*k,nrow=p)

s &lt;- 1
e &lt;- rnorm(n)*s

y &lt;- Z%*%b1 + Z^2%*%b2 +Z^3%*%b3 + e

D &lt;- as.matrix(dist(Z))
D2 &lt;- D^2

newdata1 &lt;- 0

ldblm1 &lt;- ldblm(y~Z,kind.of.kernel=1,method="GCV",noh=3,k.knn=3)
pr1 &lt;- predict(ldblm1,newdata1)
print(pr1)
plot(Z,y)
points(0,pr1$fit,col=2)
abline(v=0,col=2)
abline(h=pr1$fit,col=2)

</code></pre>

<hr>
<h2 id='summary.dbglm'>
Summarizing distance-based generalized linear model fits
</h2><span id='topic+summary.dbglm'></span><span id='topic+print.summary.dbglm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"dbglm"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dbglm'
summary(object,dispersion,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.dbglm_+3A_object">object</code></td>
<td>

<p>an object of class <code>dbglm</code>. Result of <code><a href="#topic+dbglm">dbglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.dbglm_+3A_dispersion">dispersion</code></td>
<td>

<p>the dispersion parameter for the family used. 
Either a single numerical value or <code>NULL</code> (the default)
</p>
</td></tr>
<tr><td><code id="summary.dbglm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>summary.dbglm</code> containing the following components: 
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>	the matched call. </p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p> the <code><a href="stats.html#topic+family">family</a></code> object used.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p> measure of discrepancy or goodness of fitt. Proportional 
to twice the difference between the maximum log likelihood 
achievable and that achieved by the model under investigation.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p> Akaike's An Information Criterion.</p>
</td></tr>                 
<tr><td><code>df.residual</code></td>
<td>
<p>  the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>null.deviance</code></td>
<td>
<p> the deviance for the null model.</p>
</td></tr>
<tr><td><code>df.null</code></td>
<td>
<p> the residual degrees of freedom for the null model.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p> number of Fisher Scoring (<code>dblm</code>) iterations.</p>
</td></tr>
<tr><td><code>deviance.resid</code></td>
<td>
<p> the deviance residuals for each observation: 
sign(y-mu)*sqrt(di).</p>
</td></tr>
<tr><td><code>pears.resid</code></td>
<td>
<p> the raw residual scaled by the estimated standard 
deviation of <code>y</code>.</p>
</td></tr>
<tr><td><code>dispersion</code></td>
<td>
<p>  the dispersion is taken as 1 for the binomial and Poisson
families, and otherwise estimated by the residual 
Chisquared statistic (calculated from cases with non-zero 
weights) divided by the residual degrees of freedom. </p>
</td></tr>   
<tr><td><code>gvar</code></td>
<td>
<p>	weighted geometric variability of the squared distance matrix. </p>
</td></tr>
<tr><td><code>gvec</code></td>
<td>
<p>	diagonal entries in weighted inner products matrix G. </p>
</td></tr>                     
<tr><td><code>convcrit</code></td>
<td>
<p>convergence criterion. One of: <code>"DevStat"</code> 
(stopping criterion 1), <code>"muStat"</code> (stopping criterion 2), 
<code>"maxiter"</code> (maximum allowed number of iterations 
has been exceeded).</p>
</td></tr>                           
</table>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbglm">dbglm</a></code>  for distance-based generalized linear models.
</p>

<hr>
<h2 id='summary.dblm'>
Summarizing distance-based linear model fits
</h2><span id='topic+summary.dblm'></span><span id='topic+print.summary.dblm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"dblm"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dblm'
summary(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.dblm_+3A_object">object</code></td>
<td>

<p>an object of class <code>dblm</code>. Result of <code><a href="#topic+dblm">dblm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.dblm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>A list of class <code>summary.dblm</code> containing the following components: 
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p> the residuals (response minus fitted values).</p>
</td></tr>  
<tr><td><code>sigma</code></td>
<td>
<p> the residual standard error.</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p> the coefficient of determination R2.</p>
</td></tr>
<tr><td><code>adj.r.squared</code></td>
<td>
<p> adjusted R-squared.</p>
</td></tr>
<tr><td><code>rdf</code></td>
<td>
<p> the residual degrees of freedom.</p>
</td></tr>     
<tr><td><code>call</code></td>
<td>
<p>	the matched call. </p>
</td></tr>
<tr><td><code>gvar</code></td>
<td>
<p>	weighted geometric variability of the squared distance matrix. </p>
</td></tr>
<tr><td><code>gvec</code></td>
<td>
<p>	diagonal entries in weighted inner products matrix G. </p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p> method used to decide the <em>effective rank</em>. </p>
</td></tr>
<tr><td><code>eff.rank</code></td>
<td>

<p>integer between 1 and the number of observations minus one. 
Number of Euclidean coordinates used for model fitting. Applies only  
if <code>method="eff.rank"</code>.  
</p>
</td></tr>
<tr><td><code>rel.gvar</code></td>
<td>

<p>relative geometric variability (real between 0 and 1). Take the 
lowest effective rank with a relative geometric variability higher 
or equal to <code>rel.gvar</code>. Default value (<code>rel.gvar=0.95</code>) 
uses a 95% of the total variability.
Applies only <code>rel.gvar</code> if <code>method="rel.gvar"</code>.
</p>
</td></tr>
<tr><td><code>crit.value</code></td>
<td>
<p> value of criterion defined in <code>method</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dblm">dblm</a></code>  for distance-based linear models.
</p>

<hr>
<h2 id='summary.dbplsr'>
Summarizing distance-based partial least squares fits
</h2><span id='topic+summary.dbplsr'></span><span id='topic+print.summary.dbplsr'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"dbplsr"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dbplsr'
summary(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.dbplsr_+3A_object">object</code></td>
<td>

<p>an object of class <code>dbplsr</code>. Result of <code><a href="#topic+dbplsr">dbplsr</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.dbplsr_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>summary.dbplsr</code> containing the following components: 
</p>
<table>
<tr><td><code>ncomp</code></td>
<td>
<p> the number of components of the model.</p>
</td></tr>     
<tr><td><code>r.squared</code></td>
<td>
<p> the coefficient of determination R2.</p>
</td></tr>
<tr><td><code>adj.r.squared</code></td>
<td>
<p> adjusted R-squared.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>	the matched call. </p>
</td></tr>                  
<tr><td><code>residuals</code></td>
<td>
<p> a list containing the residuals for each iteration 
(response minus fitted values).</p>
</td></tr>  
<tr><td><code>sigma</code></td>
<td>
<p> the residual standard error.</p>
</td></tr>
<tr><td><code>gvar</code></td>
<td>
<p>total weighted geometric variability.</p>
</td></tr>  
<tr><td><code>gvec</code></td>
<td>
<p>the diagonal entries in G0.</p>
</td></tr> 
<tr><td><code>gvar.iter</code></td>
<td>
<p> geometric variability for each iteration.</p>
</td></tr>   
<tr><td><code>method</code></td>
<td>
<p> the using method to set <code>ncomp</code>.</p>
</td></tr>
<tr><td><code>crit.value</code></td>
<td>
<p> value of criterion defined in <code>method</code>.</p>
</td></tr>
<tr><td><code>ncomp.opt</code></td>
<td>
<p>optimum number of components according to the selected method.</p>
</td></tr>  
</table>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Implementing PLS for distance-based regression: 
computational issues</em>.
<em>Computational Statistics</em> 22, 237-248.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbplsr">dbplsr</a></code> for distance-based partial least squares.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># require(pls)
library(pls)
data(yarn)
## Default methods:
yarn.dbplsr &lt;- dbplsr(density ~ NIR, data = yarn, ncomp=6, method="GCV")
summary(yarn.dbplsr)
</code></pre>

<hr>
<h2 id='summary.ldbglm'>
Summarizing local distance-based generalized linear model fits
</h2><span id='topic+summary.ldbglm'></span><span id='topic+print.summary.ldbglm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"ldbglm"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'ldbglm'
summary(object,dispersion = NULL,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ldbglm_+3A_object">object</code></td>
<td>

<p>an object of class <code>ldbglm</code>. 
Result of <code><a href="#topic+ldbglm">ldbglm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.ldbglm_+3A_dispersion">dispersion</code></td>
<td>

<p>the dispersion parameter for the family used. 
Either a single numerical value or <code>NULL</code> (the default)
</p>
</td></tr>
<tr><td><code id="summary.ldbglm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>                                                                              
</table>


<h3>Value</h3>

<p>A list of class <code>summary.ldgblm</code> containing the following components: 
</p>
<table>
<tr><td><code>nobs</code></td>
<td>
<p>number of observations.</p>
</td></tr>
<tr><td><code>trace.hat</code></td>
<td>
<p>Trace of smoother matrix.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>  the matched call.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p> the <code><a href="stats.html#topic+family">family</a></code> object used.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p> measure of discrepancy or goodness of fitt. Proportional 
to twice the difference between the maximum log likelihood 
achievable and that achieved by the model under investigation.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>  the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>null.deviance</code></td>
<td>
<p> the deviance for the null model.</p>
</td></tr>
<tr><td><code>df.null</code></td>
<td>
<p> the residual degrees of freedom for the null model.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p> number of Fisher Scoring (<code>dblm</code>) iterations.</p>
</td></tr>
<tr><td><code>deviance.resid</code></td>
<td>
<p> the deviance residuals for each observation: 
sign(y-mu)*sqrt(di).</p>
</td></tr>
<tr><td><code>pears.resid</code></td>
<td>
<p> the raw residual scaled by the estimated standard 
deviation of <code>y</code>.</p>
</td></tr>
<tr><td><code>dispersion</code></td>
<td>
<p>  the dispersion is taken as 1 for the binomial and Poisson
families, and otherwise estimated by the residual 
Chisquared statistic (calculated from cases with non-zero 
weights) divided by the residual degrees of freedom. </p>
</td></tr>   
<tr><td><code>kind.kernel</code></td>
<td>
<p> smoothing kernel function.</p>
</td></tr>
<tr><td><code>method.h</code></td>
<td>
<p> method used to decide the optimal bandwidth. </p>
</td></tr>
<tr><td><code>h.opt</code></td>
<td>
<p>the optimal bandwidth h used in the fitting proces 
(<code>if method.h!=user.h</code>).</p>
</td></tr> 
<tr><td><code>crit.value</code></td>
<td>
<p> value of criterion defined in <code>method.h</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ldbglm">ldbglm</a></code> for local distance-based generalized linear models.
</p>

<hr>
<h2 id='summary.ldblm'>
Summarizing local distance-based linear model fits
</h2><span id='topic+summary.ldblm'></span><span id='topic+print.summary.ldblm'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"ldblm"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ldblm'
summary(object,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ldblm_+3A_object">object</code></td>
<td>

<p>an object of class <code>ldblm</code>. 
Result of <code><a href="#topic+ldblm">ldblm</a></code>.
</p>
</td></tr>
<tr><td><code id="summary.ldblm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods to the low level. 
</p>
</td></tr>                                                                              
</table>


<h3>Value</h3>

<p>A list of class <code>summary.ldblm</code> containing the following components: 
</p>
<table>
<tr><td><code>nobs</code></td>
<td>
<p>number of observations.</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p> the coefficient of determination R2.</p>
</td></tr>
<tr><td><code>trace.hat</code></td>
<td>
<p>Trace of smoother matrix .</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>	the matched call. </p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p> the residuals (the response minus fitted values).</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p> the <code><a href="stats.html#topic+family">family</a></code> object used.</p>
</td></tr>
<tr><td><code>kind.kernel</code></td>
<td>
<p> smoothing kernel function.</p>
</td></tr>
<tr><td><code>method.h</code></td>
<td>
<p> method used to decide the optimal bandwidth. </p>
</td></tr>
<tr><td><code>h.opt</code></td>
<td>
<p>the optimal bandwidth h used in the fitting proces 
(<code>if method.h!=user.h</code>).</p>
</td></tr> 
<tr><td><code>crit.value</code></td>
<td>
<p> value of criterion defined in <code>method.h</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Boj, Eva &lt;evaboj@ub.edu&gt;, Caballe, Adria &lt;adria.caballe@upc.edu&gt;,
Delicado, Pedro &lt;pedro.delicado@upc.edu&gt; and Fortiana, Josep &lt;fortiana@ub.edu&gt;
</p>


<h3>References</h3>

<p>Boj E, Delicado P, Fortiana J (2010). <em>Distance-based local linear regression for functional predictors</em>.
Computational Statistics and Data Analysis 54, 429-437.
</p>
<p>Boj E, Grane A, Fortiana J, Claramunt MM (2007). <em>Selection of predictors in distance-based regression</em>.
Communications in Statistics B - Simulation and Computation 36, 87-98.
</p>
<p>Cuadras CM, Arenas C, Fortiana J (1996). <em>Some computational aspects of a distance-based model
for prediction</em>. Communications in Statistics B - Simulation and Computation 25, 593-609.
</p>
<p>Cuadras C, Arenas C (1990). <em>A distance-based regression model for prediction with mixed data</em>.
Communications in Statistics A - Theory and Methods 19, 2261-2279.
</p>
<p>Cuadras CM (1989). <em>Distance analysis in discrimination and classification using both 
continuous and categorical variables</em>. In: Y. Dodge (ed.), <em>Statistical Data Analysis and Inference</em>.		
Amsterdam, The Netherlands: North-Holland Publishing Co., pp. 459-473.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ldblm">ldblm</a></code> for local distance-based linear models.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
