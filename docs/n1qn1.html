<!DOCTYPE html><html lang="en"><head><title>Help for package n1qn1</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {n1qn1}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.n1qn1ptr'><p>This gives the function pointers in the n1qn1 library</p></a></li>
<li><a href='#n1qn1'><p>n1qn1 optimization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Port of the 'Scilab' 'n1qn1' Module for Unconstrained BFGS
Optimization</td>
</tr>
<tr>
<td>Version:</td>
<td>6.0.1-12</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matthew Fidler &lt;matthew.fidler@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides 'Scilab' 'n1qn1'. This takes more memory than traditional L-BFGS.  The n1qn1 routine is useful since it allows prespecification of a Hessian.
       If the Hessian is near enough the truth in optimization it can speed up the optimization problem. The algorithm is described in the
       'Scilab' optimization documentation located at
       <a href="https://www.scilab.org/sites/default/files/optimization_in_scilab.pdf">https://www.scilab.org/sites/default/files/optimization_in_scilab.pdf</a>. This version uses manually modified code from 'f2c' to make this a C only binary.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/nlmixr2/n1qn1c">https://github.com/nlmixr2/n1qn1c</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/nlmixr2/n1qn1c/issues">https://github.com/nlmixr2/n1qn1c/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.3)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, covr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.cecill.info/licences/Licence_CeCILL_V2-en.txt">CeCILL-2</a></td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>RcppArmadillo (&ge; 0.5.600.2.0), Rcpp (&ge; 0.12.3)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-17 21:50:00 UTC; matt</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthew Fidler [aut, cre],
  Wenping Wang [aut],
  Claude Lemarechal [aut, ctb],
  Joseph Bonnans [ctb],
  Jean-Charles Gilbert [ctb],
  Claudia Sagastizabal [ctb],
  Stephen L. Campbell, [ctb],
  Jean-Philippe Chancelier [ctb],
  Ramine Nikoukhah [ctb],
  Dirk Eddelbuettel [ctb],
  Bruno Jofret [ctb],
  INRIA [cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-17 22:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='.n1qn1ptr'>This gives the function pointers in the n1qn1 library</h2><span id='topic+.n1qn1ptr'></span>

<h3>Description</h3>

<p>Using this will allow C-level linking by function pointers instead
of abi.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.n1qn1ptr()
</code></pre>


<h3>Value</h3>

<p>list of pointers to the n1qn1 functions
</p>


<h3>Author(s)</h3>

<p>Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
.n1qn1ptr()

</code></pre>

<hr>
<h2 id='n1qn1'>n1qn1 optimization</h2><span id='topic+n1qn1'></span>

<h3>Description</h3>

<p>This is an R port of the n1qn1 optimization procedure in scilab.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n1qn1(
  call_eval,
  call_grad,
  vars,
  environment = parent.frame(1),
  ...,
  epsilon = .Machine$double.eps,
  max_iterations = 100,
  nsim = 100,
  imp = 0,
  invisible = NULL,
  zm = NULL,
  restart = FALSE,
  assign = FALSE,
  print.functions = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="n1qn1_+3A_call_eval">call_eval</code></td>
<td>
<p>Objective function</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_call_grad">call_grad</code></td>
<td>
<p>Gradient Function</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_vars">vars</code></td>
<td>
<p>Initial starting point for line search</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_environment">environment</code></td>
<td>
<p>Environment where call_eval/call_grad are
evaluated.</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_...">...</code></td>
<td>
<p>Ignored additional parameters.</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_epsilon">epsilon</code></td>
<td>
<p>Precision of estimate</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_max_iterations">max_iterations</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_nsim">nsim</code></td>
<td>
<p>Number of function evaluations</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_imp">imp</code></td>
<td>
<p>Verbosity of messages.</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_invisible">invisible</code></td>
<td>
<p>boolean to control if the output of the minimizer
is suppressed.</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_zm">zm</code></td>
<td>
<p>Prior Hessian (in compressed format; This format is
output in <code>c.hess</code>).</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_restart">restart</code></td>
<td>
<p>Is this an estimation restart?</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_assign">assign</code></td>
<td>
<p>Assign hessian to c.hess in environment environment?
(Default FALSE)</p>
</td></tr>
<tr><td><code id="n1qn1_+3A_print.functions">print.functions</code></td>
<td>
<p>Boolean to control if the function value
and parameter estimates are echoed every time a function is
called.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The return value is a list with the following elements:
</p>

<ul>
<li> <p><code>value</code> The value at the minimized function.
</p>
</li>
<li> <p><code>par</code> The parameter value that minimized the function.
</p>
</li>
<li> <p><code>H</code> The estimated Hessian at the final parameter estimate.
</p>
</li>
<li> <p><code>c.hess</code> Compressed Hessian for saving curvature.
</p>
</li>
<li> <p><code>n.fn</code> Number of function evaluations
</p>
</li>
<li> <p><code>n.gr</code> Number of gradient evaluations
</p>
</li></ul>



<h3>Author(s)</h3>

<p>C. Lemarechal, Stephen L. Campbell, Jean-Philippe
Chancelier, Ramine Nikoukhah, Wenping Wang &amp; Matthew L. Fidler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Rosenbrock's banana function
n=3; p=100

fr = function(x)
{
    f=1.0
    for(i in 2:n) {
        f=f+p*(x[i]-x[i-1]**2)**2+(1.0-x[i])**2
    }
    f
}

grr = function(x)
{
    g = double(n)
    g[1]=-4.0*p*(x[2]-x[1]**2)*x[1]
    if(n&gt;2) {
        for(i in 2:(n-1)) {
            g[i]=2.0*p*(x[i]-x[i-1]**2)-4.0*p*(x[i+1]-x[i]**2)*x[i]-2.0*(1.0-x[i])
        }
    }
    g[n]=2.0*p*(x[n]-x[n-1]**2)-2.0*(1.0-x[n])
    g
}

x = c(1.02,1.02,1.02)
eps=1e-3
n=length(x); niter=100L; nsim=100L; imp=3L;
nzm=as.integer(n*(n+13L)/2L)
zm=double(nzm)

(op1 &lt;- n1qn1(fr, grr, x, imp=3))

## Note there are 40 function calls and 40 gradient calls in the above optimization

## Now assume we know something about the Hessian:
c.hess &lt;- c(797.861115,
            -393.801473,
            -2.795134,
            991.271179,
            -395.382900,
            200.024349)
c.hess &lt;- c(c.hess, rep(0, 24 - length(c.hess)))

(op2 &lt;- n1qn1(fr, grr, x,imp=3, zm=c.hess))

## Note with this knowledge, there were only 29 function/gradient calls

(op3 &lt;- n1qn1(fr, grr, x, imp=3, zm=op1$c.hess))

## The number of function evaluations is still reduced because the Hessian
## is closer to what it should be than the initial guess.

## With certain optimization procedures this can be helpful in reducing the
## Optimization time.

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
