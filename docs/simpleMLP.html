<!DOCTYPE html><html><head><title>Help for package simpleMLP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {simpleMLP}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#backprop'><p>Backpropagation</p></a></li>
<li><a href='#evaluate'><p>Evaluate Model</p></a></li>
<li><a href='#forwardprop'><p>Forward propagation</p></a></li>
<li><a href='#init_nn'><p>Initialize network</p></a></li>
<li><a href='#load_mnist'><p>Load Training Data</p></a></li>
<li><a href='#one_hot_encoding'><p>One Hot Encoding</p></a></li>
<li><a href='#plot_accuracy'><p>Plot Accuracy</p></a></li>
<li><a href='#train_nn'><p>Train Network</p></a></li>
<li><a href='#update'><p>Update Model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Simple Multilayer Perceptron Neural Network</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Create and train a multilayer perceptron, a type of feedforward, 
    fully connected neural network. Features 2 ReLU hidden layers. Learn more 
    about about the activation functions and backpropagation used by this 
    network in Goodfellow et al. (2016, ISBN: 9780262035613) "Deep Learning".</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, readr, stats</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-03-27 03:34:57 UTC; Cullen Pu</td>
</tr>
<tr>
<td>Author:</td>
<td>Cullen Pu [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Cullen Pu &lt;cullenpu@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-03-28 06:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='backprop'>Backpropagation</h2><span id='topic+backprop'></span>

<h3>Description</h3>

<p>Runs a backwards pass through the network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backprop(model, error, forward_pass)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backprop_+3A_model">model</code></td>
<td>
<p>list of all the weights and biases</p>
</td></tr>
<tr><td><code id="backprop_+3A_error">error</code></td>
<td>
<p>gradients to the output of the network</p>
</td></tr>
<tr><td><code id="backprop_+3A_forward_pass">forward_pass</code></td>
<td>
<p>intermediate values from the forward pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of derivatives after the backwards pass
</p>

<hr>
<h2 id='evaluate'>Evaluate Model</h2><span id='topic+evaluate'></span>

<h3>Description</h3>

<p>Evaluates the performance of a model on a given dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate(inputs, target, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate_+3A_inputs">inputs</code></td>
<td>
<p>set of inputs to the model</p>
</td></tr>
<tr><td><code id="evaluate_+3A_target">target</code></td>
<td>
<p>set of targets in one-hot encoded form</p>
</td></tr>
<tr><td><code id="evaluate_+3A_model">model</code></td>
<td>
<p>list of weights and biases</p>
</td></tr>
</table>


<h3>Value</h3>

<p>accuracy of the model
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
evaluate(train_data, train_target, mlp_model)

## End(Not run)
</code></pre>

<hr>
<h2 id='forwardprop'>Forward propagation</h2><span id='topic+forwardprop'></span>

<h3>Description</h3>

<p>Runs a forward pass through the network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forwardprop(model, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forwardprop_+3A_model">model</code></td>
<td>
<p>list of all the weights and biases</p>
</td></tr>
<tr><td><code id="forwardprop_+3A_x">x</code></td>
<td>
<p>input to the network</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of all intermediate values
</p>

<hr>
<h2 id='init_nn'>Initialize network</h2><span id='topic+init_nn'></span>

<h3>Description</h3>

<p>Initialize 3 layer fully connected neural network, also known as multilayer
perceptron, setting biases to 0 and using the Xavier initialization method
for weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>init_nn(num_inputs, num_hidden_1, num_hidden_2, num_outputs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="init_nn_+3A_num_inputs">num_inputs</code></td>
<td>
<p>dimension of inputs</p>
</td></tr>
<tr><td><code id="init_nn_+3A_num_hidden_1">num_hidden_1</code></td>
<td>
<p>dimension of first hidden layer</p>
</td></tr>
<tr><td><code id="init_nn_+3A_num_hidden_2">num_hidden_2</code></td>
<td>
<p>dimension of second hidden layer</p>
</td></tr>
<tr><td><code id="init_nn_+3A_num_outputs">num_outputs</code></td>
<td>
<p>dimension of output</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing weight and bias matrices in each layer of the network
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mlp_model &lt;- init_nn(784, 100, 50, 10)
</code></pre>

<hr>
<h2 id='load_mnist'>Load Training Data</h2><span id='topic+load_mnist'></span>

<h3>Description</h3>

<p>Loads MNIST training, validation, and test data and generates one hot
encodings for the targets. The test set proportion is not specified and is
instead the remainder from the test and validation proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>load_mnist(train_prop = 0.8, validate_prop = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="load_mnist_+3A_train_prop">train_prop</code></td>
<td>
<p>proportion of the data used for the training set</p>
</td></tr>
<tr><td><code id="load_mnist_+3A_validate_prop">validate_prop</code></td>
<td>
<p>proportion of the data used for the validation set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of training and validation data and targets
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mnist &lt;- load_mnist(0.8, 0.1)
train_data &lt;- mnist[1]
train_target &lt;- mnist[2]
validate_data &lt;- mnist[3]
validate_target &lt;- mnist[4]
test_data &lt;- mnist[5]
test_target &lt;- mnist[6]

</code></pre>

<hr>
<h2 id='one_hot_encoding'>One Hot Encoding</h2><span id='topic+one_hot_encoding'></span>

<h3>Description</h3>

<p>Creates a one hot encoding matrix with the specified number of categories
for the targets. Target must be the first column of the data_raw input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>one_hot_encoding(data_raw, ncat = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="one_hot_encoding_+3A_data_raw">data_raw</code></td>
<td>
<p>data input to create encoding; target must be first column</p>
</td></tr>
<tr><td><code id="one_hot_encoding_+3A_ncat">ncat</code></td>
<td>
<p>number of categories to use for the encoding</p>
</td></tr>
</table>


<h3>Value</h3>

<p>targets in a one hot encoding matrix
</p>

<hr>
<h2 id='plot_accuracy'>Plot Accuracy</h2><span id='topic+plot_accuracy'></span>

<h3>Description</h3>

<p>Plot the training and validation accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_accuracy(accuracy_train, accuracy_validate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_accuracy_+3A_accuracy_train">accuracy_train</code></td>
<td>
<p>list of training accuracy</p>
</td></tr>
<tr><td><code id="plot_accuracy_+3A_accuracy_validate">accuracy_validate</code></td>
<td>
<p>list of validation accuracy</p>
</td></tr>
</table>

<hr>
<h2 id='train_nn'>Train Network</h2><span id='topic+train_nn'></span>

<h3>Description</h3>

<p>Train the network with specified hyperparameters and return the trained
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_nn(
  train_data,
  train_target,
  validate_data,
  validate_target,
  model,
  alpha,
  epochs,
  batch_size = nrow(train_data),
  plot_acc = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_nn_+3A_train_data">train_data</code></td>
<td>
<p>set of training data</p>
</td></tr>
<tr><td><code id="train_nn_+3A_train_target">train_target</code></td>
<td>
<p>set of training data targets in one-hot encoded form</p>
</td></tr>
<tr><td><code id="train_nn_+3A_validate_data">validate_data</code></td>
<td>
<p>set of validation data targets in one-hot encoded form</p>
</td></tr>
<tr><td><code id="train_nn_+3A_validate_target">validate_target</code></td>
<td>
<p>set of targets in</p>
</td></tr>
<tr><td><code id="train_nn_+3A_model">model</code></td>
<td>
<p>list of weights and biases</p>
</td></tr>
<tr><td><code id="train_nn_+3A_alpha">alpha</code></td>
<td>
<p>learning rate</p>
</td></tr>
<tr><td><code id="train_nn_+3A_epochs">epochs</code></td>
<td>
<p>number of epochs</p>
</td></tr>
<tr><td><code id="train_nn_+3A_batch_size">batch_size</code></td>
<td>
<p>mini-batch size</p>
</td></tr>
<tr><td><code id="train_nn_+3A_plot_acc">plot_acc</code></td>
<td>
<p>whether or not to plot training and validation accuracy</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of weights and biases after training
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mlp_model &lt;- init_nn(784, 100, 50, 10)
mnist &lt;- load_mnist()
train_data &lt;- mnist[1]
train_target &lt;- mnist[2]
validate_data &lt;- mnist[3]
validate_target &lt;- mnist[4]
mlp_model &lt;- train_nn(train_data, train_target, validate_data,
validate_target, mlp_model, 0.01, 1, 64)

## End(Not run)
</code></pre>

<hr>
<h2 id='update'>Update Model</h2><span id='topic+update'></span>

<h3>Description</h3>

<p>Updates the model using derivatives from a backward pass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>update(model, back_pass, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update_+3A_model">model</code></td>
<td>
<p>list of all the weights and biases</p>
</td></tr>
<tr><td><code id="update_+3A_back_pass">back_pass</code></td>
<td>
<p>derivatives from a backwards pass through the network</p>
</td></tr>
<tr><td><code id="update_+3A_alpha">alpha</code></td>
<td>
<p>learning rate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>updated list of the weights and biases
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
