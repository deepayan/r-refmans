<!DOCTYPE html><html><head><title>Help for package rodd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rodd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#KLopt.lnorm'><p>Calculation of <code class="reqn">KL</code>-optimal discriminating design for lognormal errors</p></a></li>
<li><a href='#plot.KLopt.lnorm'><p>Plot of <code class="reqn">\Psi</code> function for resulting design</p></a></li>
<li><a href='#plot.tpopt'><p>Plot of <code class="reqn">\Psi</code> function for resulting design</p></a></li>
<li><a href='#print.KLopt.lnorm'><p>Short information about the input</p></a></li>
<li><a href='#print.tpopt'><p>Short information about the input</p></a></li>
<li><a href='#rodd-package'><p>Optimal Discriminating Designs</p></a></li>
<li><a href='#summary.KLopt.lnorm'><p>Detailed information about the input</p></a></li>
<li><a href='#summary.tpopt'><p>Detailed information about the input</p></a></li>
<li><a href='#tpopt'><p>Calculation of optimal discriminating design</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Optimal Discriminating Designs</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2-1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>numDeriv, quadprog, Matrix, rootSolve, matrixcalc</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mvtnorm</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of functions for numerical construction of optimal discriminating designs. At the current moment T-optimal designs (which maximize the lower bound for the power of F-test for regression model discrimination), KL-optimal designs (for lognormal errors) and their robust analogues can be calculated with the package.  </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-01-11 23:18:37 UTC; Roman</td>
</tr>
<tr>
<td>Author:</td>
<td>Roman Guchenko [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Roman Guchenko &lt;RomanGuchenko@yandex.ru&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-01-12 00:30:32</td>
</tr>
</table>
<hr>
<h2 id='KLopt.lnorm'>Calculation of <code class="reqn">KL</code>-optimal discriminating design for lognormal errors</h2><span id='topic+KLopt.lnorm'></span>

<h3>Description</h3>

<p>Calculates an approximation <code class="reqn">\xi^{**}</code> of the <code class="reqn">KL</code>-optimal design (in case of lognormal errors) <code class="reqn">\xi^*</code> for discrimination between a given list of error densities <code class="reqn">\{f_i(x,\theta_i),\; i = 1,\dots,\nu\}</code>. This procedure is based on the work [8]. This function mimics <code><a href="#topic+tpopt">tpopt</a></code> almost entirely. It is planed to combine <code><a href="#topic+tpopt">tpopt</a></code> and <code><a href="#topic+KLopt.lnorm">KLopt.lnorm</a></code> in the future. See <code><a href="#topic+tpopt">tpopt</a></code> for the detailed description of the arguments marked with &ldquo;-//-&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KLopt.lnorm(    x, 
                w = rep(1, length(x)) / length(x), 
                eta, 
                sq.var,
                theta.fix, 
                theta.var = NULL, 
                p, 
                x.lb = min(x), 
                x.rb = max(x), 
                opt = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KLopt.lnorm_+3A_x">x</code></td>
<td>
<p>-//-</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_w">w</code></td>
<td>
<p>-//-</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_eta">eta</code></td>
<td>
<p>a list of means for the error densities <code class="reqn">\{f_i(x,\theta_i),\; i = 1,\dots,\nu\}</code> between which proposed optimization should be performed. Every function from this list should be defined in the form of <code class="reqn">\eta_i(x,\theta_i)</code>, where <code class="reqn">x</code> is one dimensional variable from <code class="reqn">\mathcal{X}</code> and <code class="reqn">\theta_i</code> is a vector of corresponding model parameters. We will refer to length of this list as <code class="reqn">\nu</code>.</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_sq.var">sq.var</code></td>
<td>
<p>a list of variances for the error densities <code class="reqn">\{f_i(x,\theta_i),\; i = 1,\dots,\nu\}</code> between which proposed optimization should be performed. Every function from this list should be defined in the form of <code class="reqn">v^2_i(x,\theta_i)</code>. This list also has the length equal to <code class="reqn">\nu</code>.</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_theta.fix">theta.fix</code></td>
<td>
<p>-//-</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_theta.var">theta.var</code></td>
<td>
<p>-//-</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_p">p</code></td>
<td>
<p>-//-</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_x.lb">x.lb</code></td>
<td>
<p>-//-</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_x.rb">x.rb</code></td>
<td>
<p>-//-</p>
</td></tr>
<tr><td><code id="KLopt.lnorm_+3A_opt">opt</code></td>
<td>
<p>-//-</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class &ldquo;KLopt.lnorm&rdquo; which contains the following fields:
</p>

<dl>
<dt>x, w, efficiency, functional</dt><dd><p>-//-</p>
</dd>
<dt>eta</dt><dd><p>a list of means from the input.</p>
</dd>
<dt>sq.var</dt><dd><p>a list of variances from the input.</p>
</dd>
<dt>theta.fix, theta.var, p, x.lb, x.rb, max.iter, done.iter, des.eff, time</dt><dd><p>-//-</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+plot.KLopt.lnorm">plot.KLopt.lnorm</a></code>, <code><a href="#topic+summary.KLopt.lnorm">summary.KLopt.lnorm</a></code>, <code><a href="#topic+print.KLopt.lnorm">print.KLopt.lnorm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
### Examples from [8]
### Cases 1 and 3 are presented here; case 2 can be computed using the
### function tpopt (see the description of this function for exact example)
 
library(mvtnorm)

### Example 1 from [8]; EMAX vs MM

#List of models
eta.1 &lt;- function(x, theta.1) 
    theta.1[1] * x + theta.1[2] * x / (x + theta.1[3])

eta.2 &lt;- function(x, theta.2) 
    theta.2[1] * x / (x + theta.2[2])

eta &lt;- list(eta.1, eta.2)

#List of fixed parameters
theta.1 &lt;- c(1, 1, 1)
theta.2 &lt;- c(1, 1)
theta.fix &lt;- list(theta.1, theta.2)

#Comparison table
p &lt;- matrix(
    c(
        0,1,
        0,0
    ), c(length(eta), length(eta)), byrow = TRUE)

### Case 1 

#List of variances
sq.var.1 &lt;- function(x, theta.1)
    1
    
sq.var.2 &lt;- function(x, theta.2)
    1

sq.var &lt;- list(sq.var.1, sq.var.2)
    
#Case 1, method 1
res &lt;- KLopt.lnorm(
    x = seq(0.1, 5, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p,  
    opt = list(method = 1)
)
plot(res)
summary(res)

#Case 1, method 2
res &lt;- KLopt.lnorm(
    x = seq(0.1, 5, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p,  
    opt = list(method = 2)
)
plot(res)
summary(res)

### case 3
#List of variances
sq.var.1 &lt;- function(x, theta.1)
    exp(eta.1(x, theta.1))
    
sq.var.2 &lt;- function(x, theta.2)
    exp(eta.2(x, theta.2))

sq.var &lt;- list(sq.var.1, sq.var.2)

#Case 3, method 1
res &lt;- KLopt.lnorm(
    x = seq(0.1, 5, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p,  
    opt = list(method = 1)
)
plot(res)
summary(res)

#Case 3, method 2
res &lt;- KLopt.lnorm(
    x = seq(0.1, 5, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p,  
    opt = list(method = 2)
)
plot(res)
summary(res)

### Example 2 from [8]; sigmoidal

#List of models
eta.1 = function(x, theta.1)
    theta.1[1] - theta.1[2] * exp(-theta.1[3] * x ^ theta.1[4])

eta.2 &lt;- function(x, theta.2)
    theta.2[1] - theta.2[2] * exp(-theta.2[3] * x)

#List of fixed parameters
theta.1.mean &lt;- c(2, 1, 0.8, 1.5)
sigma &lt;- 0.3
theta.1.sigma &lt;- matrix(
    c(
        sigma,0,
        0,sigma
    ), c(2, 2), byrow = TRUE)
grid &lt;- expand.grid(
    theta.1.mean[1],
    theta.1.mean[2],
    seq(theta.1.mean[3] - sqrt(sigma), theta.1.mean[3] + sqrt(sigma), length.out = 5),
    seq(theta.1.mean[4] - sqrt(sigma), theta.1.mean[4] + sqrt(sigma), length.out = 5)
)

theta.2 &lt;- c(2,1,1)

theta.fix &lt;- list()
for(i in 1:length(grid[,1]))
    theta.fix[[length(theta.fix)+1]] &lt;- as.numeric(grid[i,])
theta.fix[[length(theta.fix)+1]] &lt;- theta.2

density.on.grid &lt;- dmvnorm(grid[,3:4], mean = theta.1.mean[3:4], sigma = theta.1.sigma)
density.on.grid &lt;- density.on.grid / sum(density.on.grid)
    
eta &lt;- list()
for(i in 1:length(grid[,1]))
    eta &lt;- c(eta, eta.1)
eta &lt;- c(eta, eta.2)

#Comparison table
p &lt;- rep(0,length(eta))
for(i in 1:length(grid[,1]))
    p &lt;- rbind(p, c(rep(0,length(eta)-1), density.on.grid[i]))
p &lt;- rbind(p, rep(0,length(eta)))
p &lt;- p[-1,]

### Case 1

sq.var.1 &lt;- function(x, theta.1)
    1

sq.var.2 &lt;- function(x, theta.2)
    1

sq.var &lt;- list()
for(i in 1:length(grid[,1]))
    sq.var &lt;- c(sq.var, sq.var.1)
sq.var &lt;- c(sq.var, sq.var.2)

#Case 1, method 1
res &lt;- KLopt.lnorm(
    x = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(method = 1)
)
plot(res)
summary(res)

#Case 1, method 2 
res &lt;- KLopt.lnorm(
    x = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(method = 2)
)
plot(res)
summary(res)

### Case 3

sq.var.1 &lt;- function(x, theta.1)
    exp(eta.1(x, theta.1))

sq.var.2 &lt;- function(x, theta.2)
    exp(eta.2(x, theta.2))

sq.var &lt;- list()
for(i in 1:length(grid[,1]))
    sq.var &lt;- c(sq.var, sq.var.1)
sq.var &lt;- c(sq.var, sq.var.2)

#Case 3, method 1 
res &lt;- KLopt.lnorm(
    x = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(method = 1)
)
plot(res)
summary(res)

#Case 3, method 2 
res &lt;- KLopt.lnorm(
    x = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(method = 2)
)
plot(res)
summary(res)

### Example 3 from [8]; dose response

#List of models
eta.1 &lt;- function(x, theta.1)
    theta.1[1] + theta.1[2] * x

eta.2 &lt;- function(x, theta.2)
    theta.2[1] + theta.2[2] * x * (theta.2[3] - x)

eta.3 &lt;- function(x, theta.3)
    theta.3[1] + theta.3[2] * x / (theta.3[3] + x)

eta.4 &lt;- function(x, theta.4)
    theta.4[1] + theta.4[2] / (1 + exp((theta.4[3] - x) / theta.4[4]))

#List of fixed parameters
theta.1 &lt;- c(60, 0.56)
theta.2 &lt;- c(60, 7 / 2250, 600)
theta.3 &lt;- c(60, 294, 25)
theta.4.mean &lt;- c(49.62, 290.51, 150, 45.51)
a &lt;- 45
b &lt;- 20
grid &lt;- expand.grid(
        c(theta.4.mean[1] - b, theta.4.mean[1], theta.4.mean[1] + a), 
        c(theta.4.mean[2] - b, theta.4.mean[2], theta.4.mean[2] + a), 
        c(theta.4.mean[3] - b, theta.4.mean[3], theta.4.mean[3] + a), 
        c(theta.4.mean[4] - b, theta.4.mean[4], theta.4.mean[4] + a)  
        )

eta &lt;- list()
eta &lt;- c(eta, eta.1, eta.2, eta.3)
for(i in 1:length(grid[,1]))
    eta &lt;- c(eta, eta.4)

theta.fix &lt;- list(theta.1, theta.2, theta.3)
for(i in 1:length(grid[,1]))
    theta.fix[[length(theta.fix) + 1]] &lt;- as.numeric(grid[i,])

density.on.grid &lt;- rep(1,length(grid[,1]))
density.on.grid &lt;- density.on.grid / sum(density.on.grid)

#Comparison table
p &lt;- rep(0, length(eta))
p &lt;- rbind(p, c(1, rep(0, length(eta) - 1)))
p &lt;- rbind(p, c(1, 1, rep(0,length(eta) - 2)))
for(i in 1:length(grid[,1]))
    p &lt;- rbind(p, c(rep(density.on.grid[i], 3), rep(0, length(eta) - 3)))

### Case 1

#List of variances
sq.var.1 &lt;- function(x, theta.1)
    1
    
sq.var.2 &lt;- function(x, theta.2)
    1

sq.var.3 &lt;- function(x, theta.3)
    1

sq.var.4 &lt;- function(x, theta.4)
    1

sq.var &lt;- list()
sq.var &lt;- c(sq.var, sq.var.1, sq.var.2, sq.var.3)
for(i in 1:length(grid[,1]))
    sq.var &lt;- c(sq.var, sq.var.4)

#Case 1, method 1

#Design estimation
res &lt;- KLopt.lnorm(
    x = seq(0, 500, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(max.iter = 10)
)
plot(res)
summary(res)

#Case 1, method 2

#Design estimation
res &lt;- KLopt.lnorm(
    x = seq(0, 500, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(
        method = 2, 
        max.iter = 10, 
        weights.evaluation.max.iter = 50, 
        support.epsilon = 1e-4
    )
)
plot(res)
summary(res)

### Case 3

#List of variances
sq.var.1 &lt;- function(x, theta.1)
    exp(1e-2 * eta.1(x,theta.1))
    
sq.var.2 &lt;- function(x, theta.2)
    exp(1e-2 * eta.2(x,theta.2))

sq.var.3 &lt;- function(x, theta.3)
    exp(1e-2 * eta.3(x,theta.3))

sq.var.4 &lt;- function(x, theta.4)
    exp(1e-2 * eta.4(x,theta.4))
    
sq.var &lt;- list()
sq.var &lt;- c(sq.var, sq.var.1, sq.var.2, sq.var.3)
for(i in 1:length(grid[,1]))
    sq.var &lt;- c(sq.var, sq.var.4)

#Case 3, method 1
    
#Design estimation
res &lt;- KLopt.lnorm(
    x = seq(0, 500, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(max.iter = 10)
)
plot(res)
summary(res)

#Case 3, method 2

eta.2 &lt;- function(x, theta.2)
    theta.2[1] + theta.2[2] * x - theta.2[3] * x * x

theta.2 &lt;- c(60, 7 * 600 / 2250, 7 / 2250)

eta &lt;- list()
eta &lt;- c(eta, eta.1, eta.2, eta.3)
for(i in 1:length(grid[,1]))
    eta &lt;- c(eta, eta.4)

theta.fix &lt;- list(theta.1, theta.2, theta.3)
for(i in 1:length(grid[,1]))
    theta.fix[[length(theta.fix) + 1]] &lt;- as.numeric(grid[i,])

#Design estimation
res &lt;- KLopt.lnorm(
    x = seq(0, 500, length.out = 10), 
    eta = eta, sq.var = sq.var, theta.fix = theta.fix, p = p, 
    opt = list(max.iter = 6, method = 2)
)
plot(res)
summary(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.KLopt.lnorm'>Plot of <code class="reqn">\Psi</code> function for resulting design</h2><span id='topic+plot.KLopt.lnorm'></span>

<h3>Description</h3>

<p>Plots the function from the formulation of the equivalence theorem for resulting approximation <code class="reqn">\xi^{**}</code> of the <code class="reqn">KL</code>-optimal design achieved with the help of <code><a href="#topic+KLopt.lnorm">KLopt.lnorm</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KLopt.lnorm'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.KLopt.lnorm_+3A_x">x</code></td>
<td>
<p>an object of type &quot;tpopt&quot;.</p>
</td></tr>
<tr><td><code id="plot.KLopt.lnorm_+3A_...">...</code></td>
<td>
<p>additional graphical parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+tpopt">tpopt</a></code>, <code><a href="#topic+summary.tpopt">summary.tpopt</a></code>, <code><a href="#topic+print.tpopt">print.tpopt</a></code></p>

<hr>
<h2 id='plot.tpopt'>Plot of <code class="reqn">\Psi</code> function for resulting design</h2><span id='topic+plot.tpopt'></span>

<h3>Description</h3>

<p>Plots the <code class="reqn">\Psi(x,\xi)</code> function for resulting approximation <code class="reqn">\xi^{**}</code> of the <code class="reqn">T_{\mathrm{P}}</code>-optimal design achieved with the help of <code><a href="#topic+tpopt">tpopt</a></code>. The definition of <code class="reqn">\Psi(x,\xi)</code> can be found in the &ldquo;details&rdquo; section of function's <code><a href="#topic+tpopt">tpopt</a></code> specifications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tpopt'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.tpopt_+3A_x">x</code></td>
<td>
<p>an object of type &quot;tpopt&quot;.</p>
</td></tr>
<tr><td><code id="plot.tpopt_+3A_...">...</code></td>
<td>
<p>additional graphical parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We are interested in the shape of function <code class="reqn">\Psi(x,\xi^{**})</code> when we want to ensure the convergence of the algorithm. If algorithm had converged, then support points of <code class="reqn">\xi^{**}</code> (which are represented by dots) will be near local maximums of the mentioned function. Furthermore, at all local maximums <code class="reqn">\Psi(x,\xi^{**})</code> should have the same value. Otherwise something went wrong and the algorithm should be restarted with another parameters.</p>


<h3>See Also</h3>

<p><code><a href="#topic+tpopt">tpopt</a></code>, <code><a href="#topic+summary.tpopt">summary.tpopt</a></code>, <code><a href="#topic+print.tpopt">print.tpopt</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#List of models
eta.1 = function(x, theta.1) 
    theta.1[1] + theta.1[2] * x + theta.1[3] * (x ^ 2) + 
    theta.1[4] * (x ^ 3) + theta.1[5] * (x ^ 4)

eta.2 = function(x, theta.2) 
    theta.2[1] + theta.2[2] * x + theta.2[3] * (x ^ 2)

eta &lt;- list(eta.1, eta.2)

#List of fixed parameters
theta.1 &lt;- c(1,1,1,1,1)
theta.2 &lt;- c(1,1,1)
theta.fix &lt;- list(theta.1, theta.2)

#Comparison table
p &lt;- matrix(
    c(
        0, 1,
        0, 0
    ), c(length(eta), length(eta)), byrow = TRUE)

x &lt;- seq(-1, 1, 0.1)
opt.1 &lt;- list(method = 1, max.iter = 1)
opt.2 &lt;- list(method = 1, max.iter = 2)
opt.3 &lt;- list(method = 1)

res.1 &lt;- tpopt(x = x, eta = eta, theta.fix = theta.fix, p = p, opt = opt.1)
res.2 &lt;- tpopt(x = x, eta = eta, theta.fix = theta.fix, p = p, opt = opt.2)
res.3 &lt;- tpopt(x = x, eta = eta, theta.fix = theta.fix, p = p, opt = opt.3)

plot(res.1)
plot(res.2)
plot(res.3)
</code></pre>

<hr>
<h2 id='print.KLopt.lnorm'>Short information about the input</h2><span id='topic+print.KLopt.lnorm'></span>

<h3>Description</h3>

<p>Prints short information about the input object of class &ldquo;KLopt.lnorm&rdquo;.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KLopt.lnorm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.KLopt.lnorm_+3A_x">x</code></td>
<td>
<p>an object of type &quot;KLopt.lnorm&quot;.</p>
</td></tr>
<tr><td><code id="print.KLopt.lnorm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>List of models, list of fixed parameters and resulting design are displayed.</p>


<h3>See Also</h3>

<p><code><a href="#topic+KLopt.lnorm">KLopt.lnorm</a></code>, <code><a href="#topic+summary.KLopt.lnorm">summary.KLopt.lnorm</a></code>, <code><a href="#topic+plot.KLopt.lnorm">plot.KLopt.lnorm</a></code></p>

<hr>
<h2 id='print.tpopt'>Short information about the input</h2><span id='topic+print.tpopt'></span>

<h3>Description</h3>

<p>Prints short information about the input object of class &ldquo;tpopt&rdquo;.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tpopt'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.tpopt_+3A_x">x</code></td>
<td>
<p>an object of type &quot;tpopt&quot;.</p>
</td></tr>
<tr><td><code id="print.tpopt_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>List of models, list of fixed parameters and resulting design are displayed.</p>


<h3>See Also</h3>

<p><code><a href="#topic+tpopt">tpopt</a></code>, <code><a href="#topic+summary.tpopt">summary.tpopt</a></code>, <code><a href="#topic+plot.tpopt">plot.tpopt</a></code></p>

<hr>
<h2 id='rodd-package'>Optimal Discriminating Designs</h2><span id='topic+rodd-package'></span><span id='topic+rodd'></span>

<h3>Description</h3>

<p>This package provides several functions suitable for efficient numerical construction of optimal discriminative designs.</p>


<h3>Details</h3>

<p>At the current state this package provides the routine <code><a href="#topic+tpopt">tpopt</a></code> for the construction of <code class="reqn">T_{\mathrm{P}}</code>-optimal designs, the routine <code><a href="#topic+KLopt.lnorm">KLopt.lnorm</a></code> for the calculation of <code class="reqn">KL</code>-optimal designs (for lognormal errors) and several auxiliary procedures to represent the results. Function <code><a href="#topic+tpopt">tpopt</a></code> is based on the algorithms that were developed in [7]. Function <code><a href="#topic+KLopt.lnorm">KLopt.lnorm</a></code> is based on the methodology proposed in [8]. See the references for more details.  
</p>
<p>It is planned to add several new routines for different types of discriminative designs. 
</p>


<h3>References</h3>

<p>[1] Atkinson A.C., Fedorov V.V. (1975) <em>The design of experiments for discriminating between two rival models</em>. Biometrika, vol. 62(1), pp. 57&ndash;70.
</p>
<p>[2] Atkinson A.C., Fedorov V.V. (1975) <em>Optimal design: Experiments for discriminating between several models</em>. Biometrika, vol. 62(2), pp. 289&ndash;303.
</p>
<p>[3] Dette H., Pepelyshev A. (2008) <em>Efficient experimental designs for sigmoidal growth models</em>. Journal of statistical planning and inference, vol. 138, pp. 2&ndash;17.
</p>
<p>[4] Dette H., Melas V.B., Shpilev P. (2013) <em>Robust T-optimal discriminating designs</em>. Annals of Statistics, vol. 41(4), pp. 1693&ndash;1715.
</p>
<p>[5] Braess D., Dette H. (2013) <em>Optimal discriminating designs for several competing regression models</em>. Annals of Statistics, vol. 41(2), pp. 897&ndash;922.
</p>
<p>[6] Braess D., Dette H. (2013) <em>Supplement to &ldquo;Optimal discriminating designs for several competing regression models&rdquo;</em>. Annals of Statistics, online supplementary material.
</p>
<p>[7] Dette H., Melas V.B., Guchenko R. (2014) <em>Bayesian T-optimal discriminating designs</em>. <a href="http://arxiv.org/abs/1412.2548">ArXiv link</a>.
</p>
<p>[8] Dette H., Guchenko R., Melas V.B. (2015) <em>Efficient computation of Bayesian optimal discriminating designs</em>. <a href="http://arxiv.org/abs/1508.00279">ArXiv link</a>.
</p>

<hr>
<h2 id='summary.KLopt.lnorm'>Detailed information about the input</h2><span id='topic+summary.KLopt.lnorm'></span>

<h3>Description</h3>

<p>Prints detailed information about the input object of class &ldquo;KLopt.lnorm&rdquo;.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KLopt.lnorm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.KLopt.lnorm_+3A_object">object</code></td>
<td>
<p>an object of type &quot;KLopt.lnorm&quot;.</p>
</td></tr>
<tr><td><code id="summary.KLopt.lnorm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Call, list of models, list of fixed parameters, resulting design, efficiency by iteration and overall execution time are displayed.</p>


<h3>See Also</h3>

<p><code><a href="#topic+KLopt.lnorm">KLopt.lnorm</a></code>, <code><a href="#topic+plot.KLopt.lnorm">plot.KLopt.lnorm</a></code>, <code><a href="#topic+print.KLopt.lnorm">print.KLopt.lnorm</a></code></p>

<hr>
<h2 id='summary.tpopt'>Detailed information about the input</h2><span id='topic+summary.tpopt'></span>

<h3>Description</h3>

<p>Prints detailed information about the input object of class &ldquo;tpopt&rdquo;.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tpopt'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.tpopt_+3A_object">object</code></td>
<td>
<p>an object of type &quot;tpopt&quot;.</p>
</td></tr>
<tr><td><code id="summary.tpopt_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Call, list of models, list of fixed parameters, resulting design, efficiency by iteration and overall execution time are displayed.</p>


<h3>See Also</h3>

<p><code><a href="#topic+tpopt">tpopt</a></code>, <code><a href="#topic+plot.tpopt">plot.tpopt</a></code>, <code><a href="#topic+print.tpopt">print.tpopt</a></code></p>

<hr>
<h2 id='tpopt'>Calculation of optimal discriminating design</h2><span id='topic+tpopt'></span>

<h3>Description</h3>

<p>Calculates an approximation <code class="reqn">\xi^{**}</code> of the <code class="reqn">T_{\mathrm{P}}</code>-optimal design <code class="reqn">\xi^*</code> for discrimination between a given list of models <code class="reqn">\{\eta_i(x,\theta_i),\; i = 1,\dots,\nu\}</code>. This procedure is based on the algorithms developed by Holger Dette, Viatcheslav B. Melas and Roman Guchenko in [7]. <code class="reqn">T_{\mathrm{P}}</code>-optimal design is a probability measure, which maximizes the functional 
</p>
<p style="text-align: center;"><code class="reqn">T_{\mathrm{P}}(\xi) = \sum_{i,j=1}^{\nu} p_{i,j} \inf_{\theta_{i,j} \in \Theta_j} \int_{\mathcal{X}} \Big[ \eta_i(x,\overline{\theta}_{i}) - \eta_j(x,\theta_{i,j}) \Big]^2 \xi(dx),</code>
</p>

<p>where <code class="reqn">\xi</code> is an arbitrary design on <code class="reqn">\mathcal{X}</code> (it is presumed here, that <code class="reqn">\mathcal{X}</code> is an interval from <code class="reqn">\mathbf{R}</code>), <code class="reqn">\mathrm{P} = \{ p_{i,j} \}_{i,j = 1}^{\nu}</code> is a table of non-negative weights with zeros on the diagonal (comparison table) and <code class="reqn">\overline{\theta}_{i}</code> are predefined fixed parameters.
</p>
<p>It was also shown in [7] that calculation of Bayesian <code class="reqn">T_{\mathrm{P}}</code>-optimal design, which maximizes more complicated criterion
</p>
<p style="text-align: center;"><code class="reqn">T_{\mathrm{P}}^{\mathrm{B}}(\xi) = \sum_{i,j=1}^{\nu} p_{i,j} \int_{\Theta_i} \inf_{\theta_{i,j} \in \Theta_j} \int_{\mathcal{X}} \Big[ \eta_i(x,\lambda_i) - \eta_j(x,\theta_{i,j}) \Big]^2 \xi(dx) \mathcal{P}_i(d \lambda_i),</code>
</p>

<p>can be reduced to calculation of ordinary <code class="reqn">T_{\mathrm{P}}</code>-optimal design, when distributions <code class="reqn">\mathcal{P}_i</code> are discrete. That is why in this case the current function is also suitable for calculation of Bayesian designs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tpopt(  x, 
        w = rep(1, length(x)) / length(x), 
        eta, 
        theta.fix, 
        theta.var = NULL, 
        p, 
        x.lb = min(x), 
        x.rb = max(x), 
        opt = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tpopt_+3A_x">x</code></td>
<td>
<p>a numeric vector specifying support points from <code class="reqn">\mathcal{X}</code> for initial design. Current algorithm operates under the assumption, that <code class="reqn">\mathcal{X}</code> is an interval from <code class="reqn">\mathbf{R}</code></p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="tpopt_+3A_w">w</code></td>
<td>
<p>a numeric vector specifying weights for initial design. This vector should have the same length as vector of support points. Furthermore, the weights of the design should sum to 1. If this vector is not specified, then the weights are presumed to be equal.</p>
</td></tr>
<tr><td><code id="tpopt_+3A_eta">eta</code></td>
<td>
<p>a list of models between which proposed optimization should be performed. Every function from this list should be defined in the form of <code class="reqn">\eta_i(x,\theta_i)</code>, where <code class="reqn">x</code> is one dimensional variable from <code class="reqn">\mathcal{X}</code> and <code class="reqn">\theta_i</code> is a vector of corresponding model parameters. We will refer to length of this list as <code class="reqn">\nu</code>.</p>
</td></tr>
<tr><td><code id="tpopt_+3A_theta.fix">theta.fix</code></td>
<td>
<p>a list of fixed model parameters <code class="reqn">\overline{\theta}_{i}</code> from the functional <code class="reqn">T_{\mathrm{P}}</code>. This list should have the same length as the list of models.</p>
</td></tr>
<tr><td><code id="tpopt_+3A_theta.var">theta.var</code></td>
<td>
<p>an array with two dimensions specifying initial values for parameter vectors <code class="reqn">\theta_{i,j}</code>. The default value here is NULL, which means that initial guess is calculated automatically.</p>
</td></tr>
<tr><td><code id="tpopt_+3A_p">p</code></td>
<td>
<p>a <code class="reqn">\nu\times\nu</code> square table (R-matrix) containing non-negative weights for comparison. The diagonal values of this table should all be zeros. If one want to include comparison of the <code class="reqn">i</code>'th model with fixed parameters against <code class="reqn">j</code>'th model with variable parameters into optimization, then he/she should place non-negative weight <code class="reqn">p_{i,j}</code> into the table; otherwise this weight should be zero.</p>
</td></tr>
<tr><td><code id="tpopt_+3A_x.lb">x.lb</code></td>
<td>
<p>a left bound for support points. If it is not specified, then minimal value from input vector <code class="reqn">x</code> is taken.</p>
</td></tr>
<tr><td><code id="tpopt_+3A_x.rb">x.rb</code></td>
<td>
<p>a right bound for support points. If it is not specified, then maximal value from input vector <code class="reqn">x</code> is taken.</p>
</td></tr>
<tr><td><code id="tpopt_+3A_opt">opt</code></td>
<td>
<p>a list of options containing such named fields:
</p>

<dl>
<dt>method</dt><dd><p>a variable specifying the method to be used in inner weight optimization step. See details section for more info. The value &ldquo;1&rdquo; stands for quadratic programming based procedure and &ldquo;2&rdquo; stands for specific gradient method. See [7] for more details on that methods.</p>
</dd>
<dt>max.iter</dt><dd><p>maximum number of iterations for the main loop. Reaching this number of iterations is one of the possible stopping conditions.</p>
</dd>
<dt>des.eff</dt><dd><p>desired efficiency for resulted approximation of optimal design. Reaching efficiency of more than des.eff is another stopping condition (to be exact, efficiency lower bound is calculated on each iteration of the algorithm instead of efficiency). See details section for exact definition of efficiency.</p>
</dd>
<dt>derivative.epsilon</dt><dd><p>a value that is used for numerical computation of first and second order derivatives.</p>
</dd>
<dt>support.epsilon</dt><dd><p>a value that is used for support points exclusion, if corresponding weight's value is less then support.epsilon.</p>
</dd>
<dt>weights.evaluation.epsilon</dt><dd><p>a value that is used in the inner loop for weights evaluation.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>Firstly, lets define
</p>
<p style="text-align: center;"><code class="reqn">\Psi(x,\xi) = \sum_{i,j=1}^{\nu} p_{i,j} \Big[ \eta_i(x,\overline{\theta}_{i}) - \eta_j(x,\widehat{\theta}_{i,j}) \Big]^2, \widehat{\theta}_{i,j} = \arg\inf_{\theta_{i,j} \in \Theta_j} \int_{\mathcal{X}} \Big[ \eta_i(x,\overline{\theta}_i) - \eta_j(x, \theta_{i,j}) \Big]^2 \xi(dx).</code>
</p>

<p>The simplified algorithm schema is as follows:
</p>
<p>Let <code class="reqn">\xi_s</code> denotes the design obtained on the s'th iteration of the algorithm. Then
</p>

<dl>
<dt>Step 1.</dt><dd><p>Support of the new design <code class="reqn">\xi_{s+1}</code> consists of all local maximums of function <code class="reqn">\Psi(x,\xi_s)</code> on <code class="reqn">\mathcal{X}</code> united with the support of current design <code class="reqn">\xi_s</code>.</p>
</dd> 
<dt>Step 2.</dt><dd><p>Weights of the new design <code class="reqn">\xi_{s+1}</code> are calculated so that the functional <code class="reqn">T_{\mathrm{P}}(\xi)</code> achieves its maximum in the class of all designs with support from previous step.</p>
</dd>
</dl>



<h3>Value</h3>

<p>Object of class &ldquo;tpopt&rdquo; which contains the following fields:
</p>

<dl>
<dt>x</dt><dd><p>the numeric vector of support points from <code class="reqn">\mathcal{X}</code> for resulting approximation of <code class="reqn">T_{\mathrm{P}}</code>-optimal design.</p>
</dd>
<dt>w</dt><dd><p>the numeric vector of weights for resulting approximation of <code class="reqn">T_{\mathrm{P}}</code>-optimal design. The values of this vector sum to 1.</p>
</dd>
<dt>efficiency</dt><dd><p>the numeric vector containing efficiency lower bound values by iteration. See details section for definition.</p>
</dd>
<dt>functional</dt><dd><p>the numeric vector containing values of functional <code class="reqn">T_{\mathrm{P}}</code> by iteration.</p>
</dd>
<dt>eta</dt><dd><p>the list of models, which is exactly the same as one from the arguments list.</p>
</dd>
<dt>theta.fix</dt><dd><p>the list of fixed model parameters. It goes to the result without any changes too.</p>
</dd>
<dt>theta.var</dt><dd><p>the array with two dimensions specifying calculated values for parameter vectors <code class="reqn">\theta_{i,j}</code> according to resulting design.</p>
</dd>
<dt>p, x.lb, x.rb</dt><dd><p>same as in input.</p>
</dd>
<dt>max.iter</dt><dd><p>max.iter from options list.</p>
</dd>
<dt>done.iter</dt><dd><p>number of iterations done.</p>
</dd>
<dt>des.eff</dt><dd><p>desired efficiency from options list.</p>
</dd>
<dt>time</dt><dd><p>overall execution time.</p>
</dd>
</dl>



<h3>References</h3>

<p>[1] Atkinson A.C., Fedorov V.V. (1975) <em>The design of experiments for discriminating between two rival models</em>. Biometrika, vol. 62(1), pp. 57&ndash;70.
</p>
<p>[2] Atkinson A.C., Fedorov V.V. (1975) <em>Optimal design: Experiments for discriminating between several models</em>. Biometrika, vol. 62(2), pp. 289&ndash;303.
</p>
<p>[3] Dette H., Pepelyshev A. (2008) <em>Efficient experimental designs for sigmoidal growth models</em>. Journal of statistical planning and inference, vol. 138, pp. 2&ndash;17.
</p>
<p>[4] Dette H., Melas V.B., Shpilev P. (2013) <em>Robust T-optimal discriminating designs</em>. Annals of Statistics, vol. 41(4), pp. 1693&ndash;1715.
</p>
<p>[5] Braess D., Dette H. (2013) <em>Optimal discriminating designs for several competing regression models</em>. Annals of Statistics, vol. 41(2), pp. 897&ndash;922.
</p>
<p>[6] Braess D., Dette H. (2013) <em>Supplement to &ldquo;Optimal discriminating designs for several competing regression models&rdquo;</em>. Annals of Statistics, online supplementary material.
</p>
<p>[7] Dette H., Melas V.B., Guchenko R. (2014) <em>Bayesian T-optimal discriminating designs</em>. <a href="http://arxiv.org/abs/1412.2548">ArXiv link</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.tpopt">plot.tpopt</a></code>, <code><a href="#topic+summary.tpopt">summary.tpopt</a></code>, <code><a href="#topic+print.tpopt">print.tpopt</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>### Auxiliary libraries for examples
library(mvtnorm)
### EMAX vs MM
#List of models
eta.1 &lt;- function(x, theta.1) 
    theta.1[1] + theta.1[2] * x / (x + theta.1[3])

eta.2 &lt;- function(x, theta.2) 
    theta.2[1] * x / (x + theta.2[2])

eta &lt;- list(eta.1, eta.2)

#List of fixed parameters
theta.1 &lt;- c(1, 1, 1)
theta.2 &lt;- c(1, 1)
theta.fix &lt;- list(theta.1, theta.2)

#Comparison table
p &lt;- matrix(
    c(
        0, 1,
        0, 0
    ), c(2, 2), byrow = TRUE)

#Design estimation
res &lt;- tpopt(x = c(1.2, 1.5, 1.7), eta = eta, theta.fix = theta.fix, p = p, 
    x.lb = 1, x.rb = 2)

plot(res)
summary(res)

### Sigmoidal second
#List of models
eta.1 &lt;- function(x, theta.1)
    theta.1[1] / (1 + theta.1[2] * exp(-theta.1[3] * x)) ^ theta.1[4]
    
eta.2 &lt;- function(x, theta.2)
    theta.2[1] / (1 + theta.2[2] * exp(-theta.2[3] * x))

eta &lt;- list(eta.1, eta.2)

#List of fixed parameters
theta.1 &lt;- c(2, 5, 1, 2)
theta.2 &lt;- c(3, 5, 0.7)
theta.fix &lt;- list(theta.1, theta.2)

#Comparison table
p &lt;- matrix(
    c(  
        0, 1,
        0, 0 
    ), c(2, 2), byrow = TRUE)

#Design estimation
res &lt;- tpopt(x = seq(0, 10), eta = eta, theta.fix = theta.fix, p = p)

plot(res)
summary(res)

### Sigmoidal first
#List of models
eta.1 &lt;- function(x, theta.1)
    theta.1[1] - theta.1[2] * exp(-theta.1[3] * x ^ theta.1[4])

eta.2 &lt;- function(x, theta.2)
    theta.2[1] - theta.2[2] * exp(-theta.2[3] * x)

eta &lt;- list(eta.1, eta.2)

#List of fixed parameters
theta.1 &lt;- c(2, 1, 0.8, 1.5)
theta.2 &lt;- c(2, 1, 1)
theta.fix &lt;- list(theta.1, theta.2)

#Comparision table
p &lt;- matrix(
    c(
        0, 1,
        0, 0
    ), c(2, 2), byrow = TRUE)

#Design estimation
res &lt;- tpopt(x = seq(0, 10), eta = eta, theta.fix = theta.fix, p = p)

plot(res)
summary(res)

### Sigmoidal first --- Bayes

#List of fixed parameters
sigma &lt;- sqrt(0.3)
theta.1.sigma &lt;- matrix(
    c(
        sigma^2, 0,
        0, sigma^2
    ), c(2, 2), byrow = TRUE)
grid &lt;- expand.grid(
    theta.1[1],
    theta.1[2],
    seq(theta.1[3] - sigma, theta.1[3] + sigma, length.out = 5),
    seq(theta.1[4] - sigma, theta.1[4] + sigma, length.out = 5)
    )

eta &lt;- c(replicate(length(grid[,1]), eta.1, simplify = FALSE), eta.2)

theta.fix &lt;- list()
for(i in 1:length(grid[,1]))
    theta.fix[[length(theta.fix) + 1]] &lt;- as.numeric(grid[i,])
theta.fix[[length(theta.fix) + 1]] &lt;- theta.2

density.on.grid &lt;- dmvnorm(grid[,3:4], mean = theta.1[3:4], sigma = theta.1.sigma)
density.on.grid &lt;- density.on.grid / sum(density.on.grid)

#Comparison table
p &lt;- rep(0,length(eta))
for(i in 1:length(grid[,1]))
    p &lt;- rbind(p, c(rep(0,length(eta) - 1), density.on.grid[i]))
p &lt;- rbind(p, rep(0,length(eta)))
p &lt;- p[-1,]

res &lt;- tpopt(x = seq(0, 10), eta = eta, theta.fix = theta.fix, p = p)

plot(res)
summary(res)

### Dose response study 
#List of models
eta.1 &lt;- function(x, theta.1)
    theta.1[1] + theta.1[2] * x

eta.2 &lt;- function(x, theta.2)
    theta.2[1] + theta.2[2] * x * (theta.2[3] - x)

eta.3 &lt;- function(x, theta.3)
    theta.3[1] + theta.3[2] * x / (theta.3[3] + x)

eta.4 &lt;- function(x, theta.4)
    theta.4[1] + theta.4[2] / (1 + exp((theta.4[3] - x) / theta.4[4]))

eta &lt;- list(eta.1, eta.2, eta.3, eta.4)

#List of fixed parameters
theta.1 &lt;- c(60, 0.56)
theta.2 &lt;- c(60, 7/2250, 600)
theta.3 &lt;- c(60, 294, 25)
theta.4 &lt;- c(49.62, 290.51, 150, 45.51)

theta.fix &lt;- list(theta.1, theta.2, theta.3, theta.4)

#Comparison table
p &lt;- matrix(
    c(
        0, 0, 0, 0,
        1, 0, 0, 0,
        1, 1, 0, 0,
        1, 1, 1 ,0
    ), c(4, 4), byrow = TRUE)

#Design estimation
res &lt;- tpopt(x = seq(0, 500, 100), eta = eta, theta.fix = theta.fix, p = p)

plot(res)
summary(res)

### Dose response study --- Bayes

#List of fixed parameters
sigma &lt;- 37
theta.4.sigma &lt;- matrix(
    c(
        sigma^2, 0, 0, 0,
        0, sigma^2, 0, 0,
        0, 0, sigma^2, 0,
        0, 0, 0, sigma^2
    ), c(4, 4), byrow = TRUE)
grid &lt;- expand.grid(
    seq(theta.4[1] - sigma, theta.4[1] + sigma, length.out = 3),
    seq(theta.4[2] - sigma, theta.4[2] + sigma, length.out = 3),
    seq(theta.4[3] - sigma, theta.4[3] + sigma, length.out = 3),
    seq(theta.4[4] - sigma, theta.4[4] + sigma, length.out = 3)
    )

eta &lt;- c(eta.1, eta.2, eta.3, replicate(length(grid[,1]), eta.4, simplify = FALSE))

theta.fix &lt;- list(theta.1, theta.2, theta.3)
for(i in 1:length(grid[,1]))
    theta.fix[[length(theta.fix) + 1]] &lt;- as.numeric(grid[i,])

density.on.grid &lt;- dmvnorm(grid, mean = theta.4, sigma = theta.4.sigma)
density.on.grid &lt;- density.on.grid / sum(density.on.grid)

#Comparison table
p &lt;- rbind(
    rep(0, length(eta)), 
    c(1, rep(0, length(eta) - 1)), 
    c(1, 1, rep(0,length(eta) - 2))
    )
for(i in 1:length(grid[,1]))
    p &lt;- rbind(p, c(rep(density.on.grid[i], 3), rep(0, length(eta) - 3)))

#Design estimation
## Not run: 
res &lt;- tpopt(x = seq(0, 500, 100), eta = eta, theta.fix = theta.fix, p = p)
## End(Not run)

plot(res)
summary(res)

## Not run: 
### Example from [8]
### An example of how case 2 can be computed for example 1 in [8] with tpopt function

#List of models
eta.1 &lt;- function(x, theta.1) 
    log(theta.1[1] * x + theta.1[2] * x / (x + theta.1[3]))

eta.2 &lt;- function(x, theta.2) 
    log(theta.2[1] * x / (x + theta.2[2]))

eta &lt;- list(eta.1, eta.2)
    
#List of fixed parameters
theta.1 &lt;- c(1, 1, 1)
theta.2 &lt;- c(1, 1)
theta.fix &lt;- list(theta.1, theta.2)

#Comparison table
p &lt;- matrix(
    c(
        0,1,
        0,0
    ), c(length(eta), length(eta)), byrow = TRUE)

#Case 2, method 1
#Design estimation
res &lt;- tpopt(
    x = seq(0.1, 5, length.out = 10), 
    eta = eta, theta.fix = theta.fix, p = p, x.lb = 0.1, x.rb = 5, 
    opt = list(method = 1)
)
plot(res)
summary(res)

#Case 2, method 2
#Design estimation
res &lt;- tpopt(
    x = seq(0.1, 5, length.out = 10), 
    eta = eta, theta.fix = theta.fix, p = p, x.lb = 0.1, x.rb = 5, 
    opt = list(method = 2)
)
plot(res)
summary(res)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
