<!DOCTYPE html><html><head><title>Help for package RobRegression</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RobRegression}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#RobRegression-package'>
<p>Robust Multivariate Regression</p></a></li>
<li><a href='#Robust_Mahalanobis_regression'><p>Robust_Mahalanobis_regression</p></a></li>
<li><a href='#Robust_regression'><p>Robust_regression</p></a></li>
<li><a href='#Robust_Variance'><p>Robust_Variance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust Multivariate Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Robust methods for estimating the parameters of multivariate Gaussian linear models. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, foreach, doParallel, mvtnorm,parallel,RSpectra ,
capushe, KneeArrower, fastmatrix, DescTools</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-22 17:56:54 UTC; pug56</td>
</tr>
<tr>
<td>Author:</td>
<td>Antoine Godichon-Baggioni [aut, cre, cph],
  Stéphane Robin [aut],
  Laure Sansonnet [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Antoine Godichon-Baggioni &lt;antoine.godichon_baggioni@upmc.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-23 09:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='RobRegression-package'>
Robust Multivariate Regression
</h2><span id='topic+RobRegression-package'></span>

<h3>Description</h3>

<p>This Package focuses on multivariate robust Guassian linear regression.
We provide a function <code><a href="#topic+Robust_Mahalanobis_regression">Robust_Mahalanobis_regression</a></code> which enables to obtain robust estimates of the parameters of Multivariate Gaussian Linear Models with the help of the Mahalanobis distance, using a Stochastic Gradient algorithm or a Fix point. This is based on the function <code><a href="#topic+Robust_Variance">Robust_Variance</a></code> which allows to obtain robust estimation of the variance, and so, also for low rank matrices (see Godichon-Baggioni and RObin (2024) &lt;doi:10.1007/s11222-023-10362-9&gt;)
Robust methods for estimating the parameters of multivariate Gaussian linear models. .
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> RobRegression</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Robust Multivariate Regression</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person("Antoine","Godichon-Baggioni", role = c("aut", "cre","cph"),
                      email = "antoine.godichon_baggioni@upmc.fr"),
               person("Stéphane","Robin", role = "aut"),
               person("Laure","Sansonnet", role = "aut"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Robust methods for estimating the parameters of multivariate Gaussian linear models. </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;">
Encoding: </td><td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyData: </td><td style="text-align: left;"> true</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> Rcpp, foreach, doParallel, mvtnorm,parallel,RSpectra ,
capushe, KneeArrower, fastmatrix, DescTools</td>
</tr>
<tr>
 <td style="text-align: left;">
LinkingTo: </td><td style="text-align: left;"> Rcpp, RcppArmadillo</td>
</tr>
<tr>
 <td style="text-align: left;">
NeedsCompilation: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Roxygen: </td><td style="text-align: left;"> list(markdown = True)</td>
</tr>
<tr>
 <td style="text-align: left;">
RoxygenNote: </td><td style="text-align: left;"> 7.1.2</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Antoine Godichon-Baggioni [aut, cre, cph],
  Stéphane Robin [aut],
  Laure Sansonnet [aut]</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Antoine Godichon-Baggioni &lt;antoine.godichon_baggioni@upmc.fr&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Archs: </td><td style="text-align: left;"> x64</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
RobRegression-package   Robust Multivariate Regression
Robust_Mahalanobis_regression
                        Robust_Mahalanobis_regression
Robust_Variance         Robust_Variance
Robust_regression       Robust_regression
</pre>


<h3>Author(s)</h3>

<p>NA
</p>
<p>Maintainer: NA
</p>


<h3>References</h3>

<p>Cardot, H., Cenac, P. and Zitt, P-A. (2013). Efficient and fast estimation of the geometric median in Hilbert spaces with an averaged stochastic gradient algorithm. <em>Bernoulli</em>, 19, 18-43.
</p>
<p>Cardot, H. and Godichon-Baggioni, A. (2017). Fast Estimation of the Median Covariation Matrix with Application to Online Robust Principal Components Analysis. <em>Test</em>, 26(3), 461-480
</p>
<p>Godichon-Baggioni, A. and Robin, S. (2024). Recursive ridge regression using second-order stochastic <em>algorithms. Computational Statistics &amp; Data Analysis, 190, 107854.</em>
</p>
<p>Vardi, Y. and Zhang, C.-H. (2000). The multivariate L1-median and associated data depth. <em>Proc. Natl. Acad. Sci. USA</em>, 97(4):1423-1426.
</p>

<hr>
<h2 id='Robust_Mahalanobis_regression'>Robust_Mahalanobis_regression</h2><span id='topic+Robust_Mahalanobis_regression'></span>

<h3>Description</h3>

<p>We propose here a function which enables to provide a robust estimation of the parameters of Multivariate Gaussian Linear Models of the form <code class="reqn">Y = X \beta + \epsilon</code> where <code class="reqn">\epsilon</code> is a 0-mean Gaussian vector of variance <code class="reqn">\Sigma</code>. In addition, one can aslo consider a low-rank variance of the form <code class="reqn">\Sigma = C + \sigma I</code> where <code class="reqn">\sigma</code> is a positive scalar and <code class="reqn">C</code> is a matrix of rank <code class="reqn">d</code>. More precisely, the aim is to minimize the functional
</p>
<p><code class="reqn">G_\lambda(\hat{\beta}) = \mathbb{E}\left(\| Y-X\hat{\beta} \|_{\Sigma^{-1}}\right) + \lambda \|\hat{\beta}\|^{\text{Ridge}}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Robust_Mahalanobis_regression(X, Y, alphaRM=0.66, alphareg=0.66, w=2, lambda=0,
                              creg='default', K=2:30, par=TRUE, epsilon=10^(-8),
                              method_regression='Offline', niter_regression=50,
                              cRM='default', mc_sample_size='default',
                              method_MCM='Weiszfeld', methodMC='Robbins',
                              niterMC=50, ridge=1, eps_vp=10^(-4), nlambda=50,
                              scale='none', tol=10^(-3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">(n,p)</code>-matrix whose rows are the explaining data.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_y">Y</code></td>
<td>
<p>A <code class="reqn">(n,q)</code>-matrix whose rows are the variables to be explained.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_method_regression">method_regression</code></td>
<td>
<p>The method used for estimating the parameter. Should be <code>method_regression='Offline'</code> if the fix point algorithm is used, and <code>method_regression='Online'</code> if the (weighted) averaged stochastic gradient algorithm is used. Default is <code>'Offline'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_niter_regression">niter_regression</code></td>
<td>
<p>The maximum number of regression iterations if the fix point algorithm is used, i.e. if <code>method_regression='Offline'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_epsilon">epsilon</code></td>
<td>
<p>Stoping condition for the fix point algorithm if <code>method_regression='Offline'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_scale">scale</code></td>
<td>
<p>If a scaling is used. <code>scale='robust'</code> should be used if a robust scaling of <code>Y</code> is desired.  Default is <code>'none'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_ridge">ridge</code></td>
<td>
<p>The power of the penalty: i.e. should be <code>2</code> if the squared norm is considered or <code>1</code> if the norm is considered.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_lambda">lambda</code></td>
<td>
<p>A vector giving the different studied penalizations. If <code>lambda='default'</code>, would be a vector of preselected penalizations.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_par">par</code></td>
<td>
<p>Is equal to <code>T</code> if the parallelization of the algorithm for estimating robustly the variance of the noise is allowed.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of tested penalizations if <code>lambda='default'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_alpharm">alphaRM</code></td>
<td>
<p>A scalar between 1/2 and 1 used in the stepsequence if the Robbins-Monro algorithm is used, i.e. if <code>methodMC='Robbins'</code>. Default is <code>0.66</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_alphareg">alphareg</code></td>
<td>
<p>A scalar between 1/2 and 1 used in the stepsequence for stochastic gradient algorithm if <code>method_regression='Online'</code>. Default is <code>0.66</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_w">w</code></td>
<td>
<p>The power for the weighted averaged algorithms if <code>method_regression='Online'</code> or if <code>methodMC='Robbins'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_creg">creg</code></td>
<td>
<p>The constant in the stepsequence if the averaged stochastic gradient algorithm is used, i.e. if <code>method='Online'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_k">K</code></td>
<td>
<p>A vector containing the possible values of <code class="reqn">d</code>. The good <code class="reqn">d</code> is chosen with the help of a penatly criterion if the length of <code>K</code> is larger than 10. Default is <code>ncol(X)</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_mc_sample_size">mc_sample_size</code></td>
<td>
<p>The number of data generated for the Monte-Carlo method for estimating robustly the eigenvalues of the variance.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_method_mcm">method_MCM</code></td>
<td>
<p>The method chosen to estimate Median Covariation Matrix. Can be <code>'Weiszfeld'</code> if the Weiszfeld algorithm is used, or <code>'ASGD'</code> if one chooses the Averaged Stochastic Gradient Descent algorithm.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_methodmc">methodMC</code></td>
<td>
<p>The method chosen to estimate robustly the variance. Can be <code>'Robbins'</code>, <code>'Grad'</code> or <code>'Fix'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_nitermc">niterMC</code></td>
<td>
<p>The number of iterations for estimating robustly the variance of each class if <code>methodMC='Fix'</code> or <code>methodMC='Grad'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_eps_vp">eps_vp</code></td>
<td>
<p>The minimum values for the estimates of the eigenvalues of the Variance can take. Default is <code>10^-4</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_crm">cRM</code></td>
<td>
<p>The constant in the stepsequence if the Robbins-Monro algorithm is used to robustly estimate the variance, i.e. if <code>methodMC='Robbins'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Mahalanobis_regression_+3A_tol">tol</code></td>
<td>
<p>A scalar that avoid numerical problems if method='Offline'. Default is <code>10^(-3)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A <code class="reqn">(p,q)</code>-matrix giving the estimation of the parameters of the MultivariateGaussian Linear Regression.</p>
</td></tr>
<tr><td><code>Residual_Variance</code></td>
<td>
<p>A <code class="reqn">(q,q)</code>-matrix giving the estimation of the variance of the residuals.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>A vector giving the loss for the different chosen <code>lambda</code>. If <code>scale='robust'</code>, it is calculated on the scaled data. </p>
</td></tr>
<tr><td><code>all_beta</code></td>
<td>
<p>A list containing the different estimation of the parameters (with respect to the different choices of <code>lambda</code>).</p>
</td></tr>
<tr><td><code>lambda_opt</code></td>
<td>
<p>A scalar giving the selected <code>lambda</code>.</p>
</td></tr>
<tr><td><code>variance_results</code></td>
<td>
<p>A list giving the results on the variance of the noise obtained with the help of the function <code>Robust_Variance</code>. If <code>scale='robust'</code>, it is calculated on the scaled data. The details are given above.</p>
</td></tr>
</table>
<p>Details of the list <code>variance_results</code>:
</p>
<table>
<tr><td><code>Sigma</code></td>
<td>
<p>The robust estimation of the variance.</p>
</td></tr>
<tr><td><code>invSigma</code></td>
<td>
<p>The robuste estimation of the inverse of the variance.</p>
</td></tr>
<tr><td><code>MCM</code></td>
<td>
<p>The Median Covariation Matrix.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>A vector containing the estimation of the <code class="reqn">d+1</code> main eigenvalues of the variance, where <code class="reqn">d+1</code> is the optimal choice belonging to <code>K</code>.</p>
</td></tr>
<tr><td><code>MCM_eigenvalues</code></td>
<td>
<p>A vector containing the estimation of the <code class="reqn">d+1</code> main eigenvalues of the Median Covariation Matrix, where <code class="reqn">d+1</code> is the optimal choice belonging to <code>K</code>.</p>
</td></tr>
<tr><td><code>cap</code></td>
<td>
<p>The result given for capushe for selecting <code class="reqn">d</code> if the length of <code>K</code> is larger than 10.</p>
</td></tr>
<tr><td><code>reduction_results</code></td>
<td>
<p>A list containing the results for all possible <code>K</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cardot, H., Cenac, P. and Zitt, P-A. (2013). Efficient and fast estimation of the geometric median in Hilbert spaces with an averaged stochastic gradient algorithm. <em>Bernoulli</em>, 19, 18-43.
</p>
<p>Cardot, H. and Godichon-Baggioni, A. (2017). Fast Estimation of the Median Covariation Matrix with Application to Online Robust Principal Components Analysis. <em>Test</em>, 26(3), 461-480
</p>
<p>Vardi, Y. and Zhang, C.-H. (2000). The multivariate L1-median and associated data depth. <em>Proc. Natl. Acad. Sci. USA</em>, 97(4):1423-1426.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+Robust_Variance">Robust_Variance</a></code>, <code><a href="#topic+Robust_regression">Robust_regression</a></code> and <code><a href="#topic+RobRegression-package">RobRegression-package</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
p=5
q=10
n=2000
mu=rep(0,q)
Sigma=diag(c(q,rep(0.1,q-1)))
epsilon=mvtnorm::rmvnorm(n = n,mean = mu,sigma = Sigma)
X=mvtnorm::rmvnorm(n=n,mean=rep(0,p))
beta=matrix(rnorm(p*q),ncol=q)
Y=X %*% beta+epsilon
Res_reg=Robust_Mahalanobis_regression(X,Y,par=FALSE)
sum((Res_reg$beta-beta)^2)

</code></pre>

<hr>
<h2 id='Robust_regression'>Robust_regression</h2><span id='topic+Robust_regression'></span>

<h3>Description</h3>

<p>This function gives robust estimates of the paramter of the Multivariate Linear regression with the help of the euclidean distance, or with the help of the Mahalanobis distance for some matrice Sigma. More precisely, the aim is to minimize
</p>
<p><code class="reqn">
G(\hat{\beta}) = \mathbb{E}[ \| Y-X\hat{\beta} \|_{\Sigma}] + \lambda \| \hat{\beta}\|^{\text{ridge}}
</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Robust_regression(X,Y, Mat_Mahalanobis=diag(rep(1,ncol(Y))),
                  niter=50,lambda=0,c='default',method='Offline',
                  alpha=0.66,w=2,ridge=1,nlambda=50,
                  init=matrix(runif(ncol(X)*ncol(Y))-0.5,nrow=ncol(X),ncol=ncol(Y)),
                  epsilon=10^(-8), Mahalanobis_distance = FALSE,
                  par=TRUE,scale='none',tol=10^(-3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Robust_regression_+3A_x">X</code></td>
<td>
<p>A (n,p)-matrix whose raws are the explaining data.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_y">Y</code></td>
<td>
<p>A (n,q)-matrix whose raws are the variables to be explained.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_method">method</code></td>
<td>
<p>The method used for estimating the parameter. Should be <code>method='Offline'</code> if the fix point algorithm is used, and <code>'Online'</code> if the (weighted) averaged stochastic gradient algorithm is used. Default is <code>'Offline'</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_mat_mahalanobis">Mat_Mahalanobis</code></td>
<td>
<p>A (q,q)-matrix giving <code class="reqn">\Sigma</code> for the Mahalanobis distance. Default is identity.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_mahalanobis_distance">Mahalanobis_distance</code></td>
<td>
<p>A logical telling if the Mahalanobis distance is used. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_scale">scale</code></td>
<td>
<p>If a scaling is used.  <code>scale='robust'</code> should be used if a robust scaling of <code>Y</code> is desired.  Default is <code>'none'</code></p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_niter">niter</code></td>
<td>
<p>The maximum number of iteration if <code>method='Offline'</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_init">init</code></td>
<td>
<p>A (p,q)-matrix which gives the initialization of the algorithm.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_ridge">ridge</code></td>
<td>
<p>The power of the penalty: i.e should be <code>2</code> if the squared norm is considered or <code>1</code> if the norm is considered.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_lambda">lambda</code></td>
<td>
<p>A vector giving the different studied penalizations. If <code>lambda='default'</code>, would be a vector of preselected penalizations.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of tested penalizations if <code>lambda='default'</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_par">par</code></td>
<td>
<p>Is equal to <code>TRUE</code> if the parallelization of the algorithm for estimating robustly the variance of the noise is allowed.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_c">c</code></td>
<td>
<p>The constant in the stepsequence if the averaged stochastic gradient algorithm, i.e if <code>method='Online'</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_alpha">alpha</code></td>
<td>
<p>A scalar between 1/2 and 1 used in the stepsequence for stochastic gradient algorithm if <code>method='Online'</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_w">w</code></td>
<td>
<p>The power for the weighted averaged Robbins-Monro algorithm if <code>method='Online'</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_epsilon">epsilon</code></td>
<td>
<p>Stoping condition for the fix point algorithm if <code>method='Offline'</code>.</p>
</td></tr>
<tr><td><code id="Robust_regression_+3A_tol">tol</code></td>
<td>
<p>A scalar that avoid numerical problems if method='Offline'. Default is <code>10^(-3)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with:
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>A (p,q)-matrix giving the estimation of the parameters.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>A vector giving the loss for the different chosen <code>lambda</code>. If <code>sale='robust'</code>, it is calculated on the scaled data. </p>
</td></tr>
<tr><td><code>all_beta</code></td>
<td>
<p>A list containing the different estimation of the parameters (with respect to the different coices of <code>lambda</code>).</p>
</td></tr>
<tr><td><code>lambda_opt</code></td>
<td>
<p>A scalar giving the selected <code>lambda</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Godichon-Baggioni, A., Robin, S. and Sansonnet, L. (2023): A robust multivariate linear regression based on the Mahalanobis distance
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+Robust_Variance">Robust_Variance</a></code>, <code><a href="#topic+Robust_Mahalanobis_regression">Robust_Mahalanobis_regression</a></code> and <code><a href="#topic+RobRegression-package">RobRegression-package</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
p=5
q=10
n=2000
mu=rep(0,q)
epsilon=mvtnorm::rmvnorm(n = n,mean = mu)
X=mvtnorm::rmvnorm(n=n,mean=rep(0,p))
beta=matrix(rnorm(p*q),ncol=q)
Y=X %*% beta+epsilon
Res_reg=Robust_regression(X,Y)
sum((Res_reg$beta-beta)^2)

</code></pre>

<hr>
<h2 id='Robust_Variance'>Robust_Variance</h2><span id='topic+Robust_Variance'></span>

<h3>Description</h3>

<p>The aim is to provide a robust estimation of the variance for Guassian models with reduction dimension. More precisely we considering a q dimensional random vector  whose variance can be written as <code class="reqn">\Sigma = C + \sigma I</code> where C is a matrix of rank d, with d possibly much smaller than q, <code class="reqn">sigma</code> is a positive scalar, and I is the identity matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Robust_Variance(X,K=ncol(X),par=TRUE,alphaRM=0.75,
                c='default',w=2,mc_sample_size='default',
                methodMC='Robbins',niterMC=50,method_MCM='Weiszfeld',
                eps_vp=10^(-6))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Robust_Variance_+3A_x">X</code></td>
<td>
<p>A matrix whose raws are the vector we want to estimate the variance.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_k">K</code></td>
<td>
<p>A vector containing the possible values of d. The 'good' d is chosen with the help of a penatly criterion if the length of K is larger than 10. Default is <code>ncol(X)</code>.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_par">par</code></td>
<td>
<p>Is equal to <code>TRUE</code> if the parallelization of the algorithm is allowed.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_mc_sample_size">mc_sample_size</code></td>
<td>
<p>The number of data generated for the Monte-Carlo method for estimating robustly the eigenvalues of the variance.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_methodmc">methodMC</code></td>
<td>
<p>The method chosen to estimate robustly the variance. Can be <code>'Robbins'</code>, <code>'Grad'</code> or <code>'Fix'</code>. Default is <code>'Robbins'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_nitermc">niterMC</code></td>
<td>
<p>The number of iterations for estimating robustly the variance of each class if <code>methodMC='Fix'</code> or <code>methodMC='Grad'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_method_mcm">method_MCM</code></td>
<td>
<p>The method chosen to estimate Median Covariation Matrix. Can be <code>'Weiszfeld'</code> or <code>'ASGD'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_alpharm">alphaRM</code></td>
<td>
<p>A scalar between 1/2 and 1 used in the stepsequence for the Robbins-Monro method if <code>methodMC='Robbins'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_c">c</code></td>
<td>
<p>The constant in the stepsequence if <code>methodMC='Robbins'</code>.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_w">w</code></td>
<td>
<p>The power for the weighted averaged Robbins-Monro algorithm if <code>methodMC='Robbins'</code>. Default is <code>2</code>.</p>
</td></tr>
<tr><td><code id="Robust_Variance_+3A_eps_vp">eps_vp</code></td>
<td>
<p>The minimum values for the estimates of the eigenvalues of the Variance can take. Default is <code>10^-6</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with:
</p>
<table>
<tr><td><code>Sigma</code></td>
<td>
<p>The robust estimation of the variance.</p>
</td></tr>
<tr><td><code>invSigma</code></td>
<td>
<p>The robuste estimation of the inverse of the variance.</p>
</td></tr>
<tr><td><code>MCM</code></td>
<td>
<p>The Median Covariation Matrix.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>A vector containing the estimation of the d+1 main eigenvalues of the variance, where d+1 is the optimal choice belong K.</p>
</td></tr>
<tr><td><code>MCM_eigenvalues</code></td>
<td>
<p>A vector containing the estimation of the d+1 main eigenvalues of the Median Covariation Matrix, where d+1 is the optimal choice belong K.</p>
</td></tr>
<tr><td><code>cap</code></td>
<td>
<p>The result given for capushe for selecting d if the length of K is larger than 10.</p>
</td></tr>
<tr><td><code>reduction_results</code></td>
<td>
<p>A list containing the results for all possible K.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cardot, H., Cenac, P. and Zitt, P-A. (2013). Efficient and fast estimation of the geometric median in Hilbert spaces with an averaged stochastic gradient algorithm. <em>Bernoulli</em>, 19, 18-43.
</p>
<p>Cardot, H. and Godichon-Baggioni, A. (2017). Fast Estimation of the Median Covariation Matrix with Application to Online Robust Principal Components Analysis.  <em>Test</em>, 26(3), 461-480
</p>
<p>Vardi, Y. and Zhang, C.-H. (2000). The multivariate L1-median and associated data depth. <em>Proc. Natl. Acad. Sci. USA</em>, 97(4):1423-1426.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+Robust_Mahalanobis_regression">Robust_Mahalanobis_regression</a></code>, <code><a href="#topic+Robust_regression">Robust_regression</a></code> and <code><a href="#topic+RobRegression-package">RobRegression-package</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
q&lt;-100
d&lt;-10
n&lt;-2000
Sigma&lt;- diag(c(d:1,rep(0,q-d)))+ diag(rep(0.1,q))
X=mvtnorm::rmvnorm(n=n,sigma=Sigma)
RobVar = Robust_Variance(X,K=q)
sum((RobVar$Sigma-Sigma)^2)/q

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
